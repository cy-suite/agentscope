{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3166711528413319,
  "eval_steps": 500,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.5833557642066596e-05,
      "grad_norm": 0.009549028240144253,
      "learning_rate": 9.99984166442358e-06,
      "loss": 0.0022,
      "step": 1
    },
    {
      "epoch": 3.166711528413319e-05,
      "grad_norm": 0.0017209409270435572,
      "learning_rate": 9.999683328847159e-06,
      "loss": 0.0007,
      "step": 2
    },
    {
      "epoch": 4.7500672926199785e-05,
      "grad_norm": 0.012444515712559223,
      "learning_rate": 9.999524993270738e-06,
      "loss": 0.0511,
      "step": 3
    },
    {
      "epoch": 6.333423056826638e-05,
      "grad_norm": 0.02099083736538887,
      "learning_rate": 9.999366657694319e-06,
      "loss": 0.0437,
      "step": 4
    },
    {
      "epoch": 7.916778821033298e-05,
      "grad_norm": 0.024516690522432327,
      "learning_rate": 9.999208322117896e-06,
      "loss": 0.0033,
      "step": 5
    },
    {
      "epoch": 9.500134585239957e-05,
      "grad_norm": 0.0017424607649445534,
      "learning_rate": 9.999049986541477e-06,
      "loss": 0.0031,
      "step": 6
    },
    {
      "epoch": 0.00011083490349446618,
      "grad_norm": 0.08374258130788803,
      "learning_rate": 9.998891650965056e-06,
      "loss": 0.477,
      "step": 7
    },
    {
      "epoch": 0.00012666846113653277,
      "grad_norm": 0.0025217514485120773,
      "learning_rate": 9.998733315388635e-06,
      "loss": 0.0016,
      "step": 8
    },
    {
      "epoch": 0.00014250201877859936,
      "grad_norm": 0.10024815052747726,
      "learning_rate": 9.998574979812214e-06,
      "loss": 0.4695,
      "step": 9
    },
    {
      "epoch": 0.00015833557642066595,
      "grad_norm": 0.06881558150053024,
      "learning_rate": 9.998416644235795e-06,
      "loss": 0.5057,
      "step": 10
    },
    {
      "epoch": 0.00017416913406273255,
      "grad_norm": 0.049916237592697144,
      "learning_rate": 9.998258308659372e-06,
      "loss": 0.3245,
      "step": 11
    },
    {
      "epoch": 0.00019000269170479914,
      "grad_norm": 0.13558970391750336,
      "learning_rate": 9.998099973082953e-06,
      "loss": 0.6892,
      "step": 12
    },
    {
      "epoch": 0.00020583624934686576,
      "grad_norm": 0.31221309304237366,
      "learning_rate": 9.997941637506532e-06,
      "loss": 0.223,
      "step": 13
    },
    {
      "epoch": 0.00022166980698893235,
      "grad_norm": 0.0009371935157105327,
      "learning_rate": 9.997783301930111e-06,
      "loss": 0.0006,
      "step": 14
    },
    {
      "epoch": 0.00023750336463099894,
      "grad_norm": 0.08024498075246811,
      "learning_rate": 9.99762496635369e-06,
      "loss": 0.8434,
      "step": 15
    },
    {
      "epoch": 0.00025333692227306554,
      "grad_norm": 0.07346603274345398,
      "learning_rate": 9.997466630777271e-06,
      "loss": 0.3763,
      "step": 16
    },
    {
      "epoch": 0.00026917047991513216,
      "grad_norm": 0.12533129751682281,
      "learning_rate": 9.997308295200849e-06,
      "loss": 0.8408,
      "step": 17
    },
    {
      "epoch": 0.0002850040375571987,
      "grad_norm": 0.10334694385528564,
      "learning_rate": 9.99714995962443e-06,
      "loss": 0.4418,
      "step": 18
    },
    {
      "epoch": 0.00030083759519926534,
      "grad_norm": 0.0735989362001419,
      "learning_rate": 9.996991624048008e-06,
      "loss": 0.4275,
      "step": 19
    },
    {
      "epoch": 0.0003166711528413319,
      "grad_norm": 0.18988938629627228,
      "learning_rate": 9.996833288471587e-06,
      "loss": 1.6,
      "step": 20
    },
    {
      "epoch": 0.00033250471048339853,
      "grad_norm": 0.08330987393856049,
      "learning_rate": 9.996674952895167e-06,
      "loss": 0.5237,
      "step": 21
    },
    {
      "epoch": 0.0003483382681254651,
      "grad_norm": 0.0009659160277806222,
      "learning_rate": 9.996516617318747e-06,
      "loss": 0.0009,
      "step": 22
    },
    {
      "epoch": 0.0003641718257675317,
      "grad_norm": 0.001814314629882574,
      "learning_rate": 9.996358281742325e-06,
      "loss": 0.0005,
      "step": 23
    },
    {
      "epoch": 0.0003800053834095983,
      "grad_norm": 0.13740240037441254,
      "learning_rate": 9.996199946165906e-06,
      "loss": 0.9509,
      "step": 24
    },
    {
      "epoch": 0.0003958389410516649,
      "grad_norm": 0.11589418351650238,
      "learning_rate": 9.996041610589485e-06,
      "loss": 0.8276,
      "step": 25
    },
    {
      "epoch": 0.0004116724986937315,
      "grad_norm": 0.01746157929301262,
      "learning_rate": 9.995883275013064e-06,
      "loss": 0.0038,
      "step": 26
    },
    {
      "epoch": 0.0004275060563357981,
      "grad_norm": 0.12686511874198914,
      "learning_rate": 9.995724939436643e-06,
      "loss": 1.2706,
      "step": 27
    },
    {
      "epoch": 0.0004433396139778647,
      "grad_norm": 0.2126140296459198,
      "learning_rate": 9.995566603860222e-06,
      "loss": 0.8804,
      "step": 28
    },
    {
      "epoch": 0.00045917317161993127,
      "grad_norm": 0.00014149839989840984,
      "learning_rate": 9.995408268283801e-06,
      "loss": 0.0001,
      "step": 29
    },
    {
      "epoch": 0.0004750067292619979,
      "grad_norm": 0.0024453471414744854,
      "learning_rate": 9.99524993270738e-06,
      "loss": 0.0026,
      "step": 30
    },
    {
      "epoch": 0.0004908402869040645,
      "grad_norm": 0.001601002411916852,
      "learning_rate": 9.99509159713096e-06,
      "loss": 0.0013,
      "step": 31
    },
    {
      "epoch": 0.0005066738445461311,
      "grad_norm": 0.10811514407396317,
      "learning_rate": 9.99493326155454e-06,
      "loss": 0.6468,
      "step": 32
    },
    {
      "epoch": 0.0005225074021881976,
      "grad_norm": 0.0012616730527952313,
      "learning_rate": 9.994774925978119e-06,
      "loss": 0.0013,
      "step": 33
    },
    {
      "epoch": 0.0005383409598302643,
      "grad_norm": 0.15551474690437317,
      "learning_rate": 9.994616590401698e-06,
      "loss": 1.148,
      "step": 34
    },
    {
      "epoch": 0.0005541745174723309,
      "grad_norm": 0.054219868034124374,
      "learning_rate": 9.994458254825277e-06,
      "loss": 0.3273,
      "step": 35
    },
    {
      "epoch": 0.0005700080751143974,
      "grad_norm": 0.1302778720855713,
      "learning_rate": 9.994299919248856e-06,
      "loss": 0.8915,
      "step": 36
    },
    {
      "epoch": 0.000585841632756464,
      "grad_norm": 0.08080433309078217,
      "learning_rate": 9.994141583672437e-06,
      "loss": 0.4028,
      "step": 37
    },
    {
      "epoch": 0.0006016751903985307,
      "grad_norm": 0.08283331245183945,
      "learning_rate": 9.993983248096016e-06,
      "loss": 0.5418,
      "step": 38
    },
    {
      "epoch": 0.0006175087480405972,
      "grad_norm": 0.07551029324531555,
      "learning_rate": 9.993824912519595e-06,
      "loss": 0.4436,
      "step": 39
    },
    {
      "epoch": 0.0006333423056826638,
      "grad_norm": 0.19364207983016968,
      "learning_rate": 9.993666576943174e-06,
      "loss": 1.1459,
      "step": 40
    },
    {
      "epoch": 0.0006491758633247304,
      "grad_norm": 0.08432217687368393,
      "learning_rate": 9.993508241366753e-06,
      "loss": 0.5505,
      "step": 41
    },
    {
      "epoch": 0.0006650094209667971,
      "grad_norm": 0.020948216319084167,
      "learning_rate": 9.993349905790332e-06,
      "loss": 0.0161,
      "step": 42
    },
    {
      "epoch": 0.0006808429786088636,
      "grad_norm": 0.2126137763261795,
      "learning_rate": 9.993191570213913e-06,
      "loss": 1.0368,
      "step": 43
    },
    {
      "epoch": 0.0006966765362509302,
      "grad_norm": 0.2826763391494751,
      "learning_rate": 9.993033234637492e-06,
      "loss": 1.2182,
      "step": 44
    },
    {
      "epoch": 0.0007125100938929969,
      "grad_norm": 0.087503582239151,
      "learning_rate": 9.992874899061071e-06,
      "loss": 0.5854,
      "step": 45
    },
    {
      "epoch": 0.0007283436515350634,
      "grad_norm": 0.10889165103435516,
      "learning_rate": 9.99271656348465e-06,
      "loss": 0.4563,
      "step": 46
    },
    {
      "epoch": 0.00074417720917713,
      "grad_norm": 0.09513632953166962,
      "learning_rate": 9.99255822790823e-06,
      "loss": 0.411,
      "step": 47
    },
    {
      "epoch": 0.0007600107668191966,
      "grad_norm": 0.011006605811417103,
      "learning_rate": 9.992399892331808e-06,
      "loss": 0.0034,
      "step": 48
    },
    {
      "epoch": 0.0007758443244612632,
      "grad_norm": 0.11770033091306686,
      "learning_rate": 9.992241556755388e-06,
      "loss": 0.6058,
      "step": 49
    },
    {
      "epoch": 0.0007916778821033298,
      "grad_norm": 0.0026376894675195217,
      "learning_rate": 9.992083221178968e-06,
      "loss": 0.0005,
      "step": 50
    },
    {
      "epoch": 0.0008075114397453964,
      "grad_norm": 0.15608087182044983,
      "learning_rate": 9.991924885602546e-06,
      "loss": 0.9222,
      "step": 51
    },
    {
      "epoch": 0.000823344997387463,
      "grad_norm": 0.19168764352798462,
      "learning_rate": 9.991766550026127e-06,
      "loss": 0.4958,
      "step": 52
    },
    {
      "epoch": 0.0008391785550295296,
      "grad_norm": 0.0017862268723547459,
      "learning_rate": 9.991608214449706e-06,
      "loss": 0.0003,
      "step": 53
    },
    {
      "epoch": 0.0008550121126715962,
      "grad_norm": 0.11516502499580383,
      "learning_rate": 9.991449878873285e-06,
      "loss": 0.5747,
      "step": 54
    },
    {
      "epoch": 0.0008708456703136627,
      "grad_norm": 0.024485934525728226,
      "learning_rate": 9.991291543296864e-06,
      "loss": 0.0385,
      "step": 55
    },
    {
      "epoch": 0.0008866792279557294,
      "grad_norm": 0.16667406260967255,
      "learning_rate": 9.991133207720445e-06,
      "loss": 0.4092,
      "step": 56
    },
    {
      "epoch": 0.000902512785597796,
      "grad_norm": 0.20859448611736298,
      "learning_rate": 9.990974872144022e-06,
      "loss": 1.0125,
      "step": 57
    },
    {
      "epoch": 0.0009183463432398625,
      "grad_norm": 0.001060187118127942,
      "learning_rate": 9.990816536567603e-06,
      "loss": 0.0011,
      "step": 58
    },
    {
      "epoch": 0.0009341799008819292,
      "grad_norm": 0.2154386043548584,
      "learning_rate": 9.990658200991182e-06,
      "loss": 1.0443,
      "step": 59
    },
    {
      "epoch": 0.0009500134585239958,
      "grad_norm": 0.1269068568944931,
      "learning_rate": 9.99049986541476e-06,
      "loss": 0.475,
      "step": 60
    },
    {
      "epoch": 0.0009658470161660623,
      "grad_norm": 0.0009222918306477368,
      "learning_rate": 9.99034152983834e-06,
      "loss": 0.0011,
      "step": 61
    },
    {
      "epoch": 0.000981680573808129,
      "grad_norm": 0.13616850972175598,
      "learning_rate": 9.99018319426192e-06,
      "loss": 0.6892,
      "step": 62
    },
    {
      "epoch": 0.0009975141314501955,
      "grad_norm": 0.10625823587179184,
      "learning_rate": 9.990024858685498e-06,
      "loss": 0.4045,
      "step": 63
    },
    {
      "epoch": 0.0010133476890922621,
      "grad_norm": 0.06626837700605392,
      "learning_rate": 9.989866523109079e-06,
      "loss": 0.0151,
      "step": 64
    },
    {
      "epoch": 0.0010291812467343288,
      "grad_norm": 0.13001835346221924,
      "learning_rate": 9.989708187532658e-06,
      "loss": 0.5253,
      "step": 65
    },
    {
      "epoch": 0.0010450148043763953,
      "grad_norm": 0.29824236035346985,
      "learning_rate": 9.989549851956237e-06,
      "loss": 1.2763,
      "step": 66
    },
    {
      "epoch": 0.001060848362018462,
      "grad_norm": 0.00824787374585867,
      "learning_rate": 9.989391516379816e-06,
      "loss": 0.0014,
      "step": 67
    },
    {
      "epoch": 0.0010766819196605286,
      "grad_norm": 0.1510777473449707,
      "learning_rate": 9.989233180803395e-06,
      "loss": 0.5492,
      "step": 68
    },
    {
      "epoch": 0.001092515477302595,
      "grad_norm": 0.11179883033037186,
      "learning_rate": 9.989074845226974e-06,
      "loss": 0.3297,
      "step": 69
    },
    {
      "epoch": 0.0011083490349446618,
      "grad_norm": 0.025956137105822563,
      "learning_rate": 9.988916509650555e-06,
      "loss": 0.011,
      "step": 70
    },
    {
      "epoch": 0.0011241825925867282,
      "grad_norm": 0.08283741027116776,
      "learning_rate": 9.988758174074134e-06,
      "loss": 0.0078,
      "step": 71
    },
    {
      "epoch": 0.0011400161502287949,
      "grad_norm": 0.055794715881347656,
      "learning_rate": 9.988599838497713e-06,
      "loss": 0.0077,
      "step": 72
    },
    {
      "epoch": 0.0011558497078708616,
      "grad_norm": 0.0012560684699565172,
      "learning_rate": 9.988441502921292e-06,
      "loss": 0.0002,
      "step": 73
    },
    {
      "epoch": 0.001171683265512928,
      "grad_norm": 0.017799796536564827,
      "learning_rate": 9.988283167344871e-06,
      "loss": 0.0247,
      "step": 74
    },
    {
      "epoch": 0.0011875168231549947,
      "grad_norm": 0.38171806931495667,
      "learning_rate": 9.98812483176845e-06,
      "loss": 0.6108,
      "step": 75
    },
    {
      "epoch": 0.0012033503807970614,
      "grad_norm": 0.16280591487884521,
      "learning_rate": 9.98796649619203e-06,
      "loss": 0.5415,
      "step": 76
    },
    {
      "epoch": 0.0012191839384391278,
      "grad_norm": 0.021820012480020523,
      "learning_rate": 9.98780816061561e-06,
      "loss": 0.062,
      "step": 77
    },
    {
      "epoch": 0.0012350174960811945,
      "grad_norm": 0.27795130014419556,
      "learning_rate": 9.987649825039188e-06,
      "loss": 1.0931,
      "step": 78
    },
    {
      "epoch": 0.0012508510537232612,
      "grad_norm": 0.11948113143444061,
      "learning_rate": 9.987491489462768e-06,
      "loss": 0.4695,
      "step": 79
    },
    {
      "epoch": 0.0012666846113653276,
      "grad_norm": 0.17866678535938263,
      "learning_rate": 9.987333153886348e-06,
      "loss": 0.595,
      "step": 80
    },
    {
      "epoch": 0.0012825181690073943,
      "grad_norm": 0.10373400151729584,
      "learning_rate": 9.987174818309927e-06,
      "loss": 0.4021,
      "step": 81
    },
    {
      "epoch": 0.0012983517266494608,
      "grad_norm": 0.17529912292957306,
      "learning_rate": 9.987016482733506e-06,
      "loss": 0.6249,
      "step": 82
    },
    {
      "epoch": 0.0013141852842915274,
      "grad_norm": 0.0009613331058062613,
      "learning_rate": 9.986858147157086e-06,
      "loss": 0.0004,
      "step": 83
    },
    {
      "epoch": 0.0013300188419335941,
      "grad_norm": 0.1065700426697731,
      "learning_rate": 9.986699811580664e-06,
      "loss": 0.6118,
      "step": 84
    },
    {
      "epoch": 0.0013458523995756606,
      "grad_norm": 0.1624743938446045,
      "learning_rate": 9.986541476004245e-06,
      "loss": 0.5322,
      "step": 85
    },
    {
      "epoch": 0.0013616859572177272,
      "grad_norm": 0.0004935457836836576,
      "learning_rate": 9.986383140427824e-06,
      "loss": 0.0001,
      "step": 86
    },
    {
      "epoch": 0.001377519514859794,
      "grad_norm": 0.15382859110832214,
      "learning_rate": 9.986224804851403e-06,
      "loss": 0.5005,
      "step": 87
    },
    {
      "epoch": 0.0013933530725018604,
      "grad_norm": 0.13668665289878845,
      "learning_rate": 9.986066469274982e-06,
      "loss": 0.5103,
      "step": 88
    },
    {
      "epoch": 0.001409186630143927,
      "grad_norm": 0.006998836062848568,
      "learning_rate": 9.985908133698563e-06,
      "loss": 0.0019,
      "step": 89
    },
    {
      "epoch": 0.0014250201877859937,
      "grad_norm": 0.20401957631111145,
      "learning_rate": 9.98574979812214e-06,
      "loss": 0.535,
      "step": 90
    },
    {
      "epoch": 0.0014408537454280602,
      "grad_norm": 0.23224419355392456,
      "learning_rate": 9.98559146254572e-06,
      "loss": 0.7848,
      "step": 91
    },
    {
      "epoch": 0.0014566873030701268,
      "grad_norm": 0.09886462241411209,
      "learning_rate": 9.9854331269693e-06,
      "loss": 0.0128,
      "step": 92
    },
    {
      "epoch": 0.0014725208607121935,
      "grad_norm": 0.0012029223144054413,
      "learning_rate": 9.985274791392879e-06,
      "loss": 0.001,
      "step": 93
    },
    {
      "epoch": 0.00148835441835426,
      "grad_norm": 0.06808362156152725,
      "learning_rate": 9.985116455816458e-06,
      "loss": 0.0108,
      "step": 94
    },
    {
      "epoch": 0.0015041879759963267,
      "grad_norm": 0.09977144747972488,
      "learning_rate": 9.984958120240039e-06,
      "loss": 0.3551,
      "step": 95
    },
    {
      "epoch": 0.0015200215336383931,
      "grad_norm": 0.09376240521669388,
      "learning_rate": 9.984799784663616e-06,
      "loss": 0.8363,
      "step": 96
    },
    {
      "epoch": 0.0015358550912804598,
      "grad_norm": 0.17177484929561615,
      "learning_rate": 9.984641449087195e-06,
      "loss": 0.6697,
      "step": 97
    },
    {
      "epoch": 0.0015516886489225265,
      "grad_norm": 0.19827400147914886,
      "learning_rate": 9.984483113510776e-06,
      "loss": 0.4899,
      "step": 98
    },
    {
      "epoch": 0.001567522206564593,
      "grad_norm": 0.023699043318629265,
      "learning_rate": 9.984324777934355e-06,
      "loss": 0.0106,
      "step": 99
    },
    {
      "epoch": 0.0015833557642066596,
      "grad_norm": 0.2619759738445282,
      "learning_rate": 9.984166442357934e-06,
      "loss": 0.6906,
      "step": 100
    },
    {
      "epoch": 0.0015991893218487263,
      "grad_norm": 0.1015174388885498,
      "learning_rate": 9.984008106781513e-06,
      "loss": 0.6035,
      "step": 101
    },
    {
      "epoch": 0.0016150228794907927,
      "grad_norm": 0.31170666217803955,
      "learning_rate": 9.983849771205092e-06,
      "loss": 1.0896,
      "step": 102
    },
    {
      "epoch": 0.0016308564371328594,
      "grad_norm": 0.15823842585086823,
      "learning_rate": 9.983691435628671e-06,
      "loss": 0.5058,
      "step": 103
    },
    {
      "epoch": 0.001646689994774926,
      "grad_norm": 0.009703189134597778,
      "learning_rate": 9.983533100052252e-06,
      "loss": 0.0061,
      "step": 104
    },
    {
      "epoch": 0.0016625235524169925,
      "grad_norm": 0.2551317512989044,
      "learning_rate": 9.983374764475831e-06,
      "loss": 0.748,
      "step": 105
    },
    {
      "epoch": 0.0016783571100590592,
      "grad_norm": 0.16905830800533295,
      "learning_rate": 9.98321642889941e-06,
      "loss": 0.4767,
      "step": 106
    },
    {
      "epoch": 0.0016941906677011257,
      "grad_norm": 0.0016261546406894922,
      "learning_rate": 9.98305809332299e-06,
      "loss": 0.0003,
      "step": 107
    },
    {
      "epoch": 0.0017100242253431923,
      "grad_norm": 0.13766929507255554,
      "learning_rate": 9.982899757746569e-06,
      "loss": 0.3647,
      "step": 108
    },
    {
      "epoch": 0.001725857782985259,
      "grad_norm": 0.0020476875361055136,
      "learning_rate": 9.982741422170148e-06,
      "loss": 0.0014,
      "step": 109
    },
    {
      "epoch": 0.0017416913406273255,
      "grad_norm": 0.14967814087867737,
      "learning_rate": 9.982583086593728e-06,
      "loss": 0.0252,
      "step": 110
    },
    {
      "epoch": 0.0017575248982693921,
      "grad_norm": 0.14309704303741455,
      "learning_rate": 9.982424751017307e-06,
      "loss": 0.4388,
      "step": 111
    },
    {
      "epoch": 0.0017733584559114588,
      "grad_norm": 0.13660967350006104,
      "learning_rate": 9.982266415440887e-06,
      "loss": 0.9232,
      "step": 112
    },
    {
      "epoch": 0.0017891920135535253,
      "grad_norm": 0.2733531892299652,
      "learning_rate": 9.982108079864466e-06,
      "loss": 1.1023,
      "step": 113
    },
    {
      "epoch": 0.001805025571195592,
      "grad_norm": 0.004135933704674244,
      "learning_rate": 9.981949744288045e-06,
      "loss": 0.0019,
      "step": 114
    },
    {
      "epoch": 0.0018208591288376586,
      "grad_norm": 0.16974951326847076,
      "learning_rate": 9.981791408711624e-06,
      "loss": 0.6332,
      "step": 115
    },
    {
      "epoch": 0.001836692686479725,
      "grad_norm": 0.030651528388261795,
      "learning_rate": 9.981633073135205e-06,
      "loss": 0.0085,
      "step": 116
    },
    {
      "epoch": 0.0018525262441217917,
      "grad_norm": 0.0011418514186516404,
      "learning_rate": 9.981474737558784e-06,
      "loss": 0.0002,
      "step": 117
    },
    {
      "epoch": 0.0018683598017638584,
      "grad_norm": 0.25053536891937256,
      "learning_rate": 9.981316401982363e-06,
      "loss": 2.0716,
      "step": 118
    },
    {
      "epoch": 0.0018841933594059249,
      "grad_norm": 0.2738971710205078,
      "learning_rate": 9.981158066405942e-06,
      "loss": 0.6449,
      "step": 119
    },
    {
      "epoch": 0.0019000269170479916,
      "grad_norm": 0.0035754155833274126,
      "learning_rate": 9.980999730829521e-06,
      "loss": 0.002,
      "step": 120
    },
    {
      "epoch": 0.001915860474690058,
      "grad_norm": 0.0011735304724425077,
      "learning_rate": 9.9808413952531e-06,
      "loss": 0.0007,
      "step": 121
    },
    {
      "epoch": 0.0019316940323321247,
      "grad_norm": 0.17823772132396698,
      "learning_rate": 9.980683059676679e-06,
      "loss": 0.5969,
      "step": 122
    },
    {
      "epoch": 0.0019475275899741914,
      "grad_norm": 0.15650323033332825,
      "learning_rate": 9.98052472410026e-06,
      "loss": 0.4019,
      "step": 123
    },
    {
      "epoch": 0.001963361147616258,
      "grad_norm": 0.1470641940832138,
      "learning_rate": 9.980366388523837e-06,
      "loss": 0.3414,
      "step": 124
    },
    {
      "epoch": 0.0019791947052583245,
      "grad_norm": 0.21640987694263458,
      "learning_rate": 9.980208052947418e-06,
      "loss": 0.5302,
      "step": 125
    },
    {
      "epoch": 0.001995028262900391,
      "grad_norm": 0.30398809909820557,
      "learning_rate": 9.980049717370997e-06,
      "loss": 0.9125,
      "step": 126
    },
    {
      "epoch": 0.002010861820542458,
      "grad_norm": 0.19463799893856049,
      "learning_rate": 9.979891381794576e-06,
      "loss": 0.1336,
      "step": 127
    },
    {
      "epoch": 0.0020266953781845243,
      "grad_norm": 0.15077227354049683,
      "learning_rate": 9.979733046218155e-06,
      "loss": 0.4297,
      "step": 128
    },
    {
      "epoch": 0.0020425289358265908,
      "grad_norm": 0.20800620317459106,
      "learning_rate": 9.979574710641734e-06,
      "loss": 0.5247,
      "step": 129
    },
    {
      "epoch": 0.0020583624934686576,
      "grad_norm": 0.19781212508678436,
      "learning_rate": 9.979416375065313e-06,
      "loss": 0.3354,
      "step": 130
    },
    {
      "epoch": 0.002074196051110724,
      "grad_norm": 0.11103102564811707,
      "learning_rate": 9.979258039488894e-06,
      "loss": 0.3653,
      "step": 131
    },
    {
      "epoch": 0.0020900296087527906,
      "grad_norm": 0.3256242573261261,
      "learning_rate": 9.979099703912473e-06,
      "loss": 0.7,
      "step": 132
    },
    {
      "epoch": 0.0021058631663948574,
      "grad_norm": 0.0018955058185383677,
      "learning_rate": 9.978941368336052e-06,
      "loss": 0.0003,
      "step": 133
    },
    {
      "epoch": 0.002121696724036924,
      "grad_norm": 0.0036404321435838938,
      "learning_rate": 9.978783032759631e-06,
      "loss": 0.0005,
      "step": 134
    },
    {
      "epoch": 0.0021375302816789904,
      "grad_norm": 0.16861359775066376,
      "learning_rate": 9.97862469718321e-06,
      "loss": 0.3639,
      "step": 135
    },
    {
      "epoch": 0.0021533638393210573,
      "grad_norm": 0.14039890468120575,
      "learning_rate": 9.97846636160679e-06,
      "loss": 0.2633,
      "step": 136
    },
    {
      "epoch": 0.0021691973969631237,
      "grad_norm": 0.0025500082410871983,
      "learning_rate": 9.97830802603037e-06,
      "loss": 0.0017,
      "step": 137
    },
    {
      "epoch": 0.00218503095460519,
      "grad_norm": 0.17217987775802612,
      "learning_rate": 9.97814969045395e-06,
      "loss": 0.5646,
      "step": 138
    },
    {
      "epoch": 0.0022008645122472566,
      "grad_norm": 0.24327801167964935,
      "learning_rate": 9.977991354877528e-06,
      "loss": 0.587,
      "step": 139
    },
    {
      "epoch": 0.0022166980698893235,
      "grad_norm": 0.004667855799198151,
      "learning_rate": 9.977833019301108e-06,
      "loss": 0.004,
      "step": 140
    },
    {
      "epoch": 0.00223253162753139,
      "grad_norm": 0.3195638954639435,
      "learning_rate": 9.977674683724687e-06,
      "loss": 0.7712,
      "step": 141
    },
    {
      "epoch": 0.0022483651851734564,
      "grad_norm": 0.1912132203578949,
      "learning_rate": 9.977516348148266e-06,
      "loss": 0.4726,
      "step": 142
    },
    {
      "epoch": 0.0022641987428155233,
      "grad_norm": 0.3067915439605713,
      "learning_rate": 9.977358012571846e-06,
      "loss": 0.8928,
      "step": 143
    },
    {
      "epoch": 0.0022800323004575898,
      "grad_norm": 0.25456109642982483,
      "learning_rate": 9.977199676995426e-06,
      "loss": 0.4765,
      "step": 144
    },
    {
      "epoch": 0.0022958658580996562,
      "grad_norm": 0.18634775280952454,
      "learning_rate": 9.977041341419003e-06,
      "loss": 0.454,
      "step": 145
    },
    {
      "epoch": 0.002311699415741723,
      "grad_norm": 0.002807406708598137,
      "learning_rate": 9.976883005842584e-06,
      "loss": 0.0004,
      "step": 146
    },
    {
      "epoch": 0.0023275329733837896,
      "grad_norm": 0.0019052557181566954,
      "learning_rate": 9.976724670266163e-06,
      "loss": 0.0004,
      "step": 147
    },
    {
      "epoch": 0.002343366531025856,
      "grad_norm": 0.0014433516189455986,
      "learning_rate": 9.976566334689742e-06,
      "loss": 0.0009,
      "step": 148
    },
    {
      "epoch": 0.002359200088667923,
      "grad_norm": 0.17246361076831818,
      "learning_rate": 9.976407999113321e-06,
      "loss": 0.3897,
      "step": 149
    },
    {
      "epoch": 0.0023750336463099894,
      "grad_norm": 0.02206731215119362,
      "learning_rate": 9.976249663536902e-06,
      "loss": 0.0771,
      "step": 150
    },
    {
      "epoch": 0.002390867203952056,
      "grad_norm": 0.0317988395690918,
      "learning_rate": 9.976091327960479e-06,
      "loss": 0.0237,
      "step": 151
    },
    {
      "epoch": 0.0024067007615941227,
      "grad_norm": 0.024743998423218727,
      "learning_rate": 9.97593299238406e-06,
      "loss": 0.0526,
      "step": 152
    },
    {
      "epoch": 0.002422534319236189,
      "grad_norm": 0.0057337223552167416,
      "learning_rate": 9.975774656807639e-06,
      "loss": 0.0005,
      "step": 153
    },
    {
      "epoch": 0.0024383678768782556,
      "grad_norm": 0.30469992756843567,
      "learning_rate": 9.975616321231218e-06,
      "loss": 0.4933,
      "step": 154
    },
    {
      "epoch": 0.0024542014345203225,
      "grad_norm": 0.1619243621826172,
      "learning_rate": 9.975457985654797e-06,
      "loss": 0.4114,
      "step": 155
    },
    {
      "epoch": 0.002470034992162389,
      "grad_norm": 0.46053797006607056,
      "learning_rate": 9.975299650078378e-06,
      "loss": 1.0309,
      "step": 156
    },
    {
      "epoch": 0.0024858685498044555,
      "grad_norm": 0.19906608760356903,
      "learning_rate": 9.975141314501955e-06,
      "loss": 0.465,
      "step": 157
    },
    {
      "epoch": 0.0025017021074465223,
      "grad_norm": 0.003262799931690097,
      "learning_rate": 9.974982978925536e-06,
      "loss": 0.0004,
      "step": 158
    },
    {
      "epoch": 0.002517535665088589,
      "grad_norm": 0.1754283457994461,
      "learning_rate": 9.974824643349115e-06,
      "loss": 0.3165,
      "step": 159
    },
    {
      "epoch": 0.0025333692227306553,
      "grad_norm": 0.005975264590233564,
      "learning_rate": 9.974666307772694e-06,
      "loss": 0.0039,
      "step": 160
    },
    {
      "epoch": 0.002549202780372722,
      "grad_norm": 0.29889431595802307,
      "learning_rate": 9.974507972196273e-06,
      "loss": 0.7497,
      "step": 161
    },
    {
      "epoch": 0.0025650363380147886,
      "grad_norm": 0.15220099687576294,
      "learning_rate": 9.974349636619854e-06,
      "loss": 0.3473,
      "step": 162
    },
    {
      "epoch": 0.002580869895656855,
      "grad_norm": 0.016549037769436836,
      "learning_rate": 9.974191301043431e-06,
      "loss": 0.004,
      "step": 163
    },
    {
      "epoch": 0.0025967034532989215,
      "grad_norm": 0.05167160928249359,
      "learning_rate": 9.974032965467012e-06,
      "loss": 0.0099,
      "step": 164
    },
    {
      "epoch": 0.0026125370109409884,
      "grad_norm": 0.12245532870292664,
      "learning_rate": 9.973874629890591e-06,
      "loss": 0.3639,
      "step": 165
    },
    {
      "epoch": 0.002628370568583055,
      "grad_norm": 0.09160980582237244,
      "learning_rate": 9.97371629431417e-06,
      "loss": 0.3302,
      "step": 166
    },
    {
      "epoch": 0.0026442041262251213,
      "grad_norm": 0.7140626907348633,
      "learning_rate": 9.97355795873775e-06,
      "loss": 1.2638,
      "step": 167
    },
    {
      "epoch": 0.0026600376838671882,
      "grad_norm": 0.008477488532662392,
      "learning_rate": 9.97339962316133e-06,
      "loss": 0.0032,
      "step": 168
    },
    {
      "epoch": 0.0026758712415092547,
      "grad_norm": 0.35834288597106934,
      "learning_rate": 9.973241287584908e-06,
      "loss": 0.9396,
      "step": 169
    },
    {
      "epoch": 0.002691704799151321,
      "grad_norm": 0.15275996923446655,
      "learning_rate": 9.973082952008487e-06,
      "loss": 0.2898,
      "step": 170
    },
    {
      "epoch": 0.002707538356793388,
      "grad_norm": 0.008951704949140549,
      "learning_rate": 9.972924616432067e-06,
      "loss": 0.0026,
      "step": 171
    },
    {
      "epoch": 0.0027233719144354545,
      "grad_norm": 0.002589691197499633,
      "learning_rate": 9.972766280855647e-06,
      "loss": 0.0017,
      "step": 172
    },
    {
      "epoch": 0.002739205472077521,
      "grad_norm": 0.15915228426456451,
      "learning_rate": 9.972607945279226e-06,
      "loss": 0.3517,
      "step": 173
    },
    {
      "epoch": 0.002755039029719588,
      "grad_norm": 0.23325404524803162,
      "learning_rate": 9.972449609702805e-06,
      "loss": 0.3936,
      "step": 174
    },
    {
      "epoch": 0.0027708725873616543,
      "grad_norm": 0.002361560706049204,
      "learning_rate": 9.972291274126384e-06,
      "loss": 0.0004,
      "step": 175
    },
    {
      "epoch": 0.0027867061450037207,
      "grad_norm": 0.19060209393501282,
      "learning_rate": 9.972132938549963e-06,
      "loss": 0.3529,
      "step": 176
    },
    {
      "epoch": 0.0028025397026457876,
      "grad_norm": 0.06073798984289169,
      "learning_rate": 9.971974602973544e-06,
      "loss": 0.0104,
      "step": 177
    },
    {
      "epoch": 0.002818373260287854,
      "grad_norm": 0.3064928948879242,
      "learning_rate": 9.971816267397123e-06,
      "loss": 0.9666,
      "step": 178
    },
    {
      "epoch": 0.0028342068179299205,
      "grad_norm": 0.591271162033081,
      "learning_rate": 9.971657931820702e-06,
      "loss": 1.1767,
      "step": 179
    },
    {
      "epoch": 0.0028500403755719874,
      "grad_norm": 0.006068781949579716,
      "learning_rate": 9.971499596244281e-06,
      "loss": 0.0008,
      "step": 180
    },
    {
      "epoch": 0.002865873933214054,
      "grad_norm": 0.17346562445163727,
      "learning_rate": 9.97134126066786e-06,
      "loss": 0.2947,
      "step": 181
    },
    {
      "epoch": 0.0028817074908561204,
      "grad_norm": 0.1792832911014557,
      "learning_rate": 9.971182925091439e-06,
      "loss": 0.3838,
      "step": 182
    },
    {
      "epoch": 0.0028975410484981872,
      "grad_norm": 0.12663432955741882,
      "learning_rate": 9.97102458951502e-06,
      "loss": 0.0603,
      "step": 183
    },
    {
      "epoch": 0.0029133746061402537,
      "grad_norm": 0.13010068237781525,
      "learning_rate": 9.970866253938599e-06,
      "loss": 0.4028,
      "step": 184
    },
    {
      "epoch": 0.00292920816378232,
      "grad_norm": 0.005660518538206816,
      "learning_rate": 9.970707918362178e-06,
      "loss": 0.0006,
      "step": 185
    },
    {
      "epoch": 0.002945041721424387,
      "grad_norm": 0.0230889692902565,
      "learning_rate": 9.970549582785757e-06,
      "loss": 0.0045,
      "step": 186
    },
    {
      "epoch": 0.0029608752790664535,
      "grad_norm": 0.21668608486652374,
      "learning_rate": 9.970391247209336e-06,
      "loss": 0.3557,
      "step": 187
    },
    {
      "epoch": 0.00297670883670852,
      "grad_norm": 0.010715280659496784,
      "learning_rate": 9.970232911632915e-06,
      "loss": 0.0027,
      "step": 188
    },
    {
      "epoch": 0.0029925423943505864,
      "grad_norm": 0.010224621742963791,
      "learning_rate": 9.970074576056496e-06,
      "loss": 0.0029,
      "step": 189
    },
    {
      "epoch": 0.0030083759519926533,
      "grad_norm": 0.0040183099918067455,
      "learning_rate": 9.969916240480075e-06,
      "loss": 0.0014,
      "step": 190
    },
    {
      "epoch": 0.0030242095096347198,
      "grad_norm": 0.17297323048114777,
      "learning_rate": 9.969757904903654e-06,
      "loss": 0.3947,
      "step": 191
    },
    {
      "epoch": 0.0030400430672767862,
      "grad_norm": 0.10081689059734344,
      "learning_rate": 9.969599569327233e-06,
      "loss": 0.4316,
      "step": 192
    },
    {
      "epoch": 0.003055876624918853,
      "grad_norm": 0.004345884080976248,
      "learning_rate": 9.969441233750812e-06,
      "loss": 0.0022,
      "step": 193
    },
    {
      "epoch": 0.0030717101825609196,
      "grad_norm": 0.006702863611280918,
      "learning_rate": 9.969282898174391e-06,
      "loss": 0.0014,
      "step": 194
    },
    {
      "epoch": 0.003087543740202986,
      "grad_norm": 0.014808648265898228,
      "learning_rate": 9.96912456259797e-06,
      "loss": 0.0024,
      "step": 195
    },
    {
      "epoch": 0.003103377297845053,
      "grad_norm": 0.17169295251369476,
      "learning_rate": 9.96896622702155e-06,
      "loss": 0.3934,
      "step": 196
    },
    {
      "epoch": 0.0031192108554871194,
      "grad_norm": 0.1552625596523285,
      "learning_rate": 9.968807891445129e-06,
      "loss": 0.5404,
      "step": 197
    },
    {
      "epoch": 0.003135044413129186,
      "grad_norm": 0.23274265229701996,
      "learning_rate": 9.96864955586871e-06,
      "loss": 0.363,
      "step": 198
    },
    {
      "epoch": 0.0031508779707712527,
      "grad_norm": 0.3716132640838623,
      "learning_rate": 9.968491220292288e-06,
      "loss": 0.7521,
      "step": 199
    },
    {
      "epoch": 0.003166711528413319,
      "grad_norm": 0.1431673914194107,
      "learning_rate": 9.968332884715868e-06,
      "loss": 0.8664,
      "step": 200
    },
    {
      "epoch": 0.0031825450860553856,
      "grad_norm": 0.008871303871273994,
      "learning_rate": 9.968174549139447e-06,
      "loss": 0.0009,
      "step": 201
    },
    {
      "epoch": 0.0031983786436974525,
      "grad_norm": 0.0032362372148782015,
      "learning_rate": 9.968016213563026e-06,
      "loss": 0.0004,
      "step": 202
    },
    {
      "epoch": 0.003214212201339519,
      "grad_norm": 0.018232207745313644,
      "learning_rate": 9.967857877986605e-06,
      "loss": 0.0062,
      "step": 203
    },
    {
      "epoch": 0.0032300457589815854,
      "grad_norm": 0.13140001893043518,
      "learning_rate": 9.967699542410186e-06,
      "loss": 0.2526,
      "step": 204
    },
    {
      "epoch": 0.0032458793166236523,
      "grad_norm": 0.026272466406226158,
      "learning_rate": 9.967541206833765e-06,
      "loss": 0.0026,
      "step": 205
    },
    {
      "epoch": 0.003261712874265719,
      "grad_norm": 0.1726243644952774,
      "learning_rate": 9.967382871257344e-06,
      "loss": 0.351,
      "step": 206
    },
    {
      "epoch": 0.0032775464319077852,
      "grad_norm": 0.1572379767894745,
      "learning_rate": 9.967224535680923e-06,
      "loss": 0.2905,
      "step": 207
    },
    {
      "epoch": 0.003293379989549852,
      "grad_norm": 0.14853259921073914,
      "learning_rate": 9.967066200104502e-06,
      "loss": 0.4431,
      "step": 208
    },
    {
      "epoch": 0.0033092135471919186,
      "grad_norm": 0.017935890704393387,
      "learning_rate": 9.966907864528081e-06,
      "loss": 0.0072,
      "step": 209
    },
    {
      "epoch": 0.003325047104833985,
      "grad_norm": 0.10735051333904266,
      "learning_rate": 9.966749528951662e-06,
      "loss": 0.3725,
      "step": 210
    },
    {
      "epoch": 0.003340880662476052,
      "grad_norm": 0.17696513235569,
      "learning_rate": 9.96659119337524e-06,
      "loss": 0.3849,
      "step": 211
    },
    {
      "epoch": 0.0033567142201181184,
      "grad_norm": 0.0032565610017627478,
      "learning_rate": 9.96643285779882e-06,
      "loss": 0.0005,
      "step": 212
    },
    {
      "epoch": 0.003372547777760185,
      "grad_norm": 0.16482013463974,
      "learning_rate": 9.966274522222399e-06,
      "loss": 0.5169,
      "step": 213
    },
    {
      "epoch": 0.0033883813354022513,
      "grad_norm": 0.2144971340894699,
      "learning_rate": 9.966116186645978e-06,
      "loss": 0.4596,
      "step": 214
    },
    {
      "epoch": 0.003404214893044318,
      "grad_norm": 0.2146884649991989,
      "learning_rate": 9.965957851069557e-06,
      "loss": 0.391,
      "step": 215
    },
    {
      "epoch": 0.0034200484506863847,
      "grad_norm": 0.2358623743057251,
      "learning_rate": 9.965799515493138e-06,
      "loss": 0.2683,
      "step": 216
    },
    {
      "epoch": 0.003435882008328451,
      "grad_norm": 0.23018477857112885,
      "learning_rate": 9.965641179916717e-06,
      "loss": 0.8922,
      "step": 217
    },
    {
      "epoch": 0.003451715565970518,
      "grad_norm": 0.007566220127046108,
      "learning_rate": 9.965482844340294e-06,
      "loss": 0.0025,
      "step": 218
    },
    {
      "epoch": 0.0034675491236125845,
      "grad_norm": 0.19855187833309174,
      "learning_rate": 9.965324508763875e-06,
      "loss": 0.3329,
      "step": 219
    },
    {
      "epoch": 0.003483382681254651,
      "grad_norm": 0.21579797565937042,
      "learning_rate": 9.965166173187454e-06,
      "loss": 0.4329,
      "step": 220
    },
    {
      "epoch": 0.003499216238896718,
      "grad_norm": 0.009744573384523392,
      "learning_rate": 9.965007837611033e-06,
      "loss": 0.003,
      "step": 221
    },
    {
      "epoch": 0.0035150497965387843,
      "grad_norm": 0.205060675740242,
      "learning_rate": 9.964849502034612e-06,
      "loss": 0.2828,
      "step": 222
    },
    {
      "epoch": 0.0035308833541808507,
      "grad_norm": 0.11512064933776855,
      "learning_rate": 9.964691166458193e-06,
      "loss": 0.3015,
      "step": 223
    },
    {
      "epoch": 0.0035467169118229176,
      "grad_norm": 0.15732184052467346,
      "learning_rate": 9.96453283088177e-06,
      "loss": 0.245,
      "step": 224
    },
    {
      "epoch": 0.003562550469464984,
      "grad_norm": 0.0054745920933783054,
      "learning_rate": 9.964374495305351e-06,
      "loss": 0.0019,
      "step": 225
    },
    {
      "epoch": 0.0035783840271070505,
      "grad_norm": 0.009767338633537292,
      "learning_rate": 9.96421615972893e-06,
      "loss": 0.0022,
      "step": 226
    },
    {
      "epoch": 0.0035942175847491174,
      "grad_norm": 0.18345136940479279,
      "learning_rate": 9.96405782415251e-06,
      "loss": 0.3169,
      "step": 227
    },
    {
      "epoch": 0.003610051142391184,
      "grad_norm": 0.10999652743339539,
      "learning_rate": 9.963899488576089e-06,
      "loss": 0.2694,
      "step": 228
    },
    {
      "epoch": 0.0036258847000332503,
      "grad_norm": 0.18546287715435028,
      "learning_rate": 9.96374115299967e-06,
      "loss": 0.3931,
      "step": 229
    },
    {
      "epoch": 0.0036417182576753172,
      "grad_norm": 0.13805978000164032,
      "learning_rate": 9.963582817423247e-06,
      "loss": 0.2938,
      "step": 230
    },
    {
      "epoch": 0.0036575518153173837,
      "grad_norm": 0.2351319044828415,
      "learning_rate": 9.963424481846827e-06,
      "loss": 0.5793,
      "step": 231
    },
    {
      "epoch": 0.00367338537295945,
      "grad_norm": 0.015063561499118805,
      "learning_rate": 9.963266146270407e-06,
      "loss": 0.0021,
      "step": 232
    },
    {
      "epoch": 0.003689218930601517,
      "grad_norm": 0.029820695519447327,
      "learning_rate": 9.963107810693986e-06,
      "loss": 0.0219,
      "step": 233
    },
    {
      "epoch": 0.0037050524882435835,
      "grad_norm": 0.30157724022865295,
      "learning_rate": 9.962949475117565e-06,
      "loss": 0.5479,
      "step": 234
    },
    {
      "epoch": 0.00372088604588565,
      "grad_norm": 0.03394952043890953,
      "learning_rate": 9.962791139541146e-06,
      "loss": 0.0032,
      "step": 235
    },
    {
      "epoch": 0.003736719603527717,
      "grad_norm": 0.052624449133872986,
      "learning_rate": 9.962632803964723e-06,
      "loss": 0.0039,
      "step": 236
    },
    {
      "epoch": 0.0037525531611697833,
      "grad_norm": 0.19180668890476227,
      "learning_rate": 9.962474468388304e-06,
      "loss": 0.3366,
      "step": 237
    },
    {
      "epoch": 0.0037683867188118498,
      "grad_norm": 0.006749501917511225,
      "learning_rate": 9.962316132811883e-06,
      "loss": 0.0014,
      "step": 238
    },
    {
      "epoch": 0.003784220276453916,
      "grad_norm": 0.044387638568878174,
      "learning_rate": 9.962157797235462e-06,
      "loss": 0.0035,
      "step": 239
    },
    {
      "epoch": 0.003800053834095983,
      "grad_norm": 0.112523153424263,
      "learning_rate": 9.961999461659041e-06,
      "loss": 0.2028,
      "step": 240
    },
    {
      "epoch": 0.0038158873917380496,
      "grad_norm": 0.23372362554073334,
      "learning_rate": 9.96184112608262e-06,
      "loss": 0.4424,
      "step": 241
    },
    {
      "epoch": 0.003831720949380116,
      "grad_norm": 0.2404651790857315,
      "learning_rate": 9.961682790506199e-06,
      "loss": 0.3158,
      "step": 242
    },
    {
      "epoch": 0.003847554507022183,
      "grad_norm": 0.3821435570716858,
      "learning_rate": 9.961524454929778e-06,
      "loss": 0.765,
      "step": 243
    },
    {
      "epoch": 0.0038633880646642494,
      "grad_norm": 0.2227005809545517,
      "learning_rate": 9.961366119353359e-06,
      "loss": 0.5147,
      "step": 244
    },
    {
      "epoch": 0.003879221622306316,
      "grad_norm": 0.13781504333019257,
      "learning_rate": 9.961207783776938e-06,
      "loss": 0.5487,
      "step": 245
    },
    {
      "epoch": 0.0038950551799483827,
      "grad_norm": 0.29882925748825073,
      "learning_rate": 9.961049448200517e-06,
      "loss": 1.1469,
      "step": 246
    },
    {
      "epoch": 0.003910888737590449,
      "grad_norm": 0.2488427758216858,
      "learning_rate": 9.960891112624096e-06,
      "loss": 0.0428,
      "step": 247
    },
    {
      "epoch": 0.003926722295232516,
      "grad_norm": 0.24822445213794708,
      "learning_rate": 9.960732777047675e-06,
      "loss": 0.4768,
      "step": 248
    },
    {
      "epoch": 0.003942555852874582,
      "grad_norm": 0.01221451535820961,
      "learning_rate": 9.960574441471254e-06,
      "loss": 0.0061,
      "step": 249
    },
    {
      "epoch": 0.003958389410516649,
      "grad_norm": 0.11343801021575928,
      "learning_rate": 9.960416105894835e-06,
      "loss": 0.8271,
      "step": 250
    },
    {
      "epoch": 0.003974222968158716,
      "grad_norm": 0.04255273565649986,
      "learning_rate": 9.960257770318414e-06,
      "loss": 0.0501,
      "step": 251
    },
    {
      "epoch": 0.003990056525800782,
      "grad_norm": 0.06271181255578995,
      "learning_rate": 9.960099434741993e-06,
      "loss": 0.0085,
      "step": 252
    },
    {
      "epoch": 0.004005890083442849,
      "grad_norm": 0.2606784403324127,
      "learning_rate": 9.959941099165572e-06,
      "loss": 1.6378,
      "step": 253
    },
    {
      "epoch": 0.004021723641084916,
      "grad_norm": 0.1851351112127304,
      "learning_rate": 9.959782763589151e-06,
      "loss": 0.247,
      "step": 254
    },
    {
      "epoch": 0.004037557198726982,
      "grad_norm": 0.053956013172864914,
      "learning_rate": 9.95962442801273e-06,
      "loss": 0.0378,
      "step": 255
    },
    {
      "epoch": 0.004053390756369049,
      "grad_norm": 0.11883155256509781,
      "learning_rate": 9.959466092436311e-06,
      "loss": 0.2095,
      "step": 256
    },
    {
      "epoch": 0.0040692243140111155,
      "grad_norm": 0.15312603116035461,
      "learning_rate": 9.95930775685989e-06,
      "loss": 0.2427,
      "step": 257
    },
    {
      "epoch": 0.0040850578716531815,
      "grad_norm": 0.040300481021404266,
      "learning_rate": 9.95914942128347e-06,
      "loss": 0.0233,
      "step": 258
    },
    {
      "epoch": 0.004100891429295248,
      "grad_norm": 0.21111571788787842,
      "learning_rate": 9.958991085707048e-06,
      "loss": 0.4325,
      "step": 259
    },
    {
      "epoch": 0.004116724986937315,
      "grad_norm": 0.3649633824825287,
      "learning_rate": 9.958832750130628e-06,
      "loss": 0.7276,
      "step": 260
    },
    {
      "epoch": 0.004132558544579381,
      "grad_norm": 0.3292938768863678,
      "learning_rate": 9.958674414554207e-06,
      "loss": 0.827,
      "step": 261
    },
    {
      "epoch": 0.004148392102221448,
      "grad_norm": 0.2477172613143921,
      "learning_rate": 9.958516078977787e-06,
      "loss": 0.6388,
      "step": 262
    },
    {
      "epoch": 0.004164225659863515,
      "grad_norm": 0.15332692861557007,
      "learning_rate": 9.958357743401365e-06,
      "loss": 0.1967,
      "step": 263
    },
    {
      "epoch": 0.004180059217505581,
      "grad_norm": 0.01941896788775921,
      "learning_rate": 9.958199407824946e-06,
      "loss": 0.0015,
      "step": 264
    },
    {
      "epoch": 0.004195892775147648,
      "grad_norm": 0.27537915110588074,
      "learning_rate": 9.958041072248525e-06,
      "loss": 0.4076,
      "step": 265
    },
    {
      "epoch": 0.004211726332789715,
      "grad_norm": 0.1563398241996765,
      "learning_rate": 9.957882736672104e-06,
      "loss": 0.2748,
      "step": 266
    },
    {
      "epoch": 0.004227559890431781,
      "grad_norm": 0.00428351853042841,
      "learning_rate": 9.957724401095683e-06,
      "loss": 0.0008,
      "step": 267
    },
    {
      "epoch": 0.004243393448073848,
      "grad_norm": 0.17370988428592682,
      "learning_rate": 9.957566065519262e-06,
      "loss": 0.2683,
      "step": 268
    },
    {
      "epoch": 0.004259227005715915,
      "grad_norm": 0.1664610207080841,
      "learning_rate": 9.957407729942841e-06,
      "loss": 0.2667,
      "step": 269
    },
    {
      "epoch": 0.004275060563357981,
      "grad_norm": 0.12281399965286255,
      "learning_rate": 9.95724939436642e-06,
      "loss": 0.2528,
      "step": 270
    },
    {
      "epoch": 0.004290894121000048,
      "grad_norm": 0.043227940797805786,
      "learning_rate": 9.95709105879e-06,
      "loss": 0.0234,
      "step": 271
    },
    {
      "epoch": 0.0043067276786421145,
      "grad_norm": 0.13840356469154358,
      "learning_rate": 9.95693272321358e-06,
      "loss": 0.537,
      "step": 272
    },
    {
      "epoch": 0.0043225612362841805,
      "grad_norm": 0.012726793065667152,
      "learning_rate": 9.956774387637159e-06,
      "loss": 0.0019,
      "step": 273
    },
    {
      "epoch": 0.004338394793926247,
      "grad_norm": 0.024622773751616478,
      "learning_rate": 9.956616052060738e-06,
      "loss": 0.0039,
      "step": 274
    },
    {
      "epoch": 0.004354228351568314,
      "grad_norm": 0.14618360996246338,
      "learning_rate": 9.956457716484317e-06,
      "loss": 0.352,
      "step": 275
    },
    {
      "epoch": 0.00437006190921038,
      "grad_norm": 0.03999729081988335,
      "learning_rate": 9.956299380907896e-06,
      "loss": 0.003,
      "step": 276
    },
    {
      "epoch": 0.004385895466852447,
      "grad_norm": 0.018252728506922722,
      "learning_rate": 9.956141045331477e-06,
      "loss": 0.0016,
      "step": 277
    },
    {
      "epoch": 0.004401729024494513,
      "grad_norm": 0.18866556882858276,
      "learning_rate": 9.955982709755056e-06,
      "loss": 0.4541,
      "step": 278
    },
    {
      "epoch": 0.00441756258213658,
      "grad_norm": 0.23655040562152863,
      "learning_rate": 9.955824374178635e-06,
      "loss": 0.4127,
      "step": 279
    },
    {
      "epoch": 0.004433396139778647,
      "grad_norm": 0.2078113555908203,
      "learning_rate": 9.955666038602214e-06,
      "loss": 0.2871,
      "step": 280
    },
    {
      "epoch": 0.004449229697420713,
      "grad_norm": 0.11422951519489288,
      "learning_rate": 9.955507703025793e-06,
      "loss": 0.233,
      "step": 281
    },
    {
      "epoch": 0.00446506325506278,
      "grad_norm": 0.11236073076725006,
      "learning_rate": 9.955349367449372e-06,
      "loss": 0.3888,
      "step": 282
    },
    {
      "epoch": 0.004480896812704847,
      "grad_norm": 0.1475507915019989,
      "learning_rate": 9.955191031872953e-06,
      "loss": 0.272,
      "step": 283
    },
    {
      "epoch": 0.004496730370346913,
      "grad_norm": 0.19572071731090546,
      "learning_rate": 9.955032696296532e-06,
      "loss": 0.2484,
      "step": 284
    },
    {
      "epoch": 0.00451256392798898,
      "grad_norm": 0.14682739973068237,
      "learning_rate": 9.954874360720111e-06,
      "loss": 0.2324,
      "step": 285
    },
    {
      "epoch": 0.004528397485631047,
      "grad_norm": 0.1866181343793869,
      "learning_rate": 9.95471602514369e-06,
      "loss": 0.2648,
      "step": 286
    },
    {
      "epoch": 0.004544231043273113,
      "grad_norm": 0.28730860352516174,
      "learning_rate": 9.95455768956727e-06,
      "loss": 0.5845,
      "step": 287
    },
    {
      "epoch": 0.0045600646009151796,
      "grad_norm": 0.18464899063110352,
      "learning_rate": 9.954399353990849e-06,
      "loss": 0.362,
      "step": 288
    },
    {
      "epoch": 0.0045758981585572464,
      "grad_norm": 0.14025232195854187,
      "learning_rate": 9.954241018414428e-06,
      "loss": 0.7008,
      "step": 289
    },
    {
      "epoch": 0.0045917317161993125,
      "grad_norm": 0.11472612619400024,
      "learning_rate": 9.954082682838008e-06,
      "loss": 0.2205,
      "step": 290
    },
    {
      "epoch": 0.004607565273841379,
      "grad_norm": 0.18133628368377686,
      "learning_rate": 9.953924347261586e-06,
      "loss": 0.2485,
      "step": 291
    },
    {
      "epoch": 0.004623398831483446,
      "grad_norm": 0.008414819836616516,
      "learning_rate": 9.953766011685167e-06,
      "loss": 0.0005,
      "step": 292
    },
    {
      "epoch": 0.004639232389125512,
      "grad_norm": 0.28746575117111206,
      "learning_rate": 9.953607676108746e-06,
      "loss": 0.5678,
      "step": 293
    },
    {
      "epoch": 0.004655065946767579,
      "grad_norm": 0.29579460620880127,
      "learning_rate": 9.953449340532325e-06,
      "loss": 0.2618,
      "step": 294
    },
    {
      "epoch": 0.004670899504409646,
      "grad_norm": 0.14591187238693237,
      "learning_rate": 9.953291004955904e-06,
      "loss": 0.3874,
      "step": 295
    },
    {
      "epoch": 0.004686733062051712,
      "grad_norm": 0.14124096930027008,
      "learning_rate": 9.953132669379485e-06,
      "loss": 0.2825,
      "step": 296
    },
    {
      "epoch": 0.004702566619693779,
      "grad_norm": 0.02158026583492756,
      "learning_rate": 9.952974333803062e-06,
      "loss": 0.003,
      "step": 297
    },
    {
      "epoch": 0.004718400177335846,
      "grad_norm": 0.049700018018484116,
      "learning_rate": 9.952815998226643e-06,
      "loss": 0.0042,
      "step": 298
    },
    {
      "epoch": 0.004734233734977912,
      "grad_norm": 0.26115500926971436,
      "learning_rate": 9.952657662650222e-06,
      "loss": 1.0829,
      "step": 299
    },
    {
      "epoch": 0.004750067292619979,
      "grad_norm": 0.015550561249256134,
      "learning_rate": 9.952499327073801e-06,
      "loss": 0.0036,
      "step": 300
    },
    {
      "epoch": 0.004765900850262046,
      "grad_norm": 0.186232328414917,
      "learning_rate": 9.95234099149738e-06,
      "loss": 0.2149,
      "step": 301
    },
    {
      "epoch": 0.004781734407904112,
      "grad_norm": 0.21860481798648834,
      "learning_rate": 9.95218265592096e-06,
      "loss": 0.3145,
      "step": 302
    },
    {
      "epoch": 0.004797567965546179,
      "grad_norm": 0.1449349820613861,
      "learning_rate": 9.952024320344538e-06,
      "loss": 0.4146,
      "step": 303
    },
    {
      "epoch": 0.0048134015231882455,
      "grad_norm": 0.2860616147518158,
      "learning_rate": 9.951865984768119e-06,
      "loss": 0.7534,
      "step": 304
    },
    {
      "epoch": 0.0048292350808303115,
      "grad_norm": 0.22614073753356934,
      "learning_rate": 9.951707649191698e-06,
      "loss": 0.4586,
      "step": 305
    },
    {
      "epoch": 0.004845068638472378,
      "grad_norm": 0.1271626353263855,
      "learning_rate": 9.951549313615277e-06,
      "loss": 0.2974,
      "step": 306
    },
    {
      "epoch": 0.004860902196114445,
      "grad_norm": 0.20471598207950592,
      "learning_rate": 9.951390978038856e-06,
      "loss": 0.0106,
      "step": 307
    },
    {
      "epoch": 0.004876735753756511,
      "grad_norm": 0.18087147176265717,
      "learning_rate": 9.951232642462437e-06,
      "loss": 0.6018,
      "step": 308
    },
    {
      "epoch": 0.004892569311398578,
      "grad_norm": 0.2274368703365326,
      "learning_rate": 9.951074306886014e-06,
      "loss": 0.4812,
      "step": 309
    },
    {
      "epoch": 0.004908402869040645,
      "grad_norm": 0.11501148343086243,
      "learning_rate": 9.950915971309595e-06,
      "loss": 0.2864,
      "step": 310
    },
    {
      "epoch": 0.004924236426682711,
      "grad_norm": 0.2931443154811859,
      "learning_rate": 9.950757635733174e-06,
      "loss": 0.0362,
      "step": 311
    },
    {
      "epoch": 0.004940069984324778,
      "grad_norm": 0.10908076912164688,
      "learning_rate": 9.950599300156753e-06,
      "loss": 0.4254,
      "step": 312
    },
    {
      "epoch": 0.004955903541966845,
      "grad_norm": 0.20615004003047943,
      "learning_rate": 9.950440964580332e-06,
      "loss": 0.3864,
      "step": 313
    },
    {
      "epoch": 0.004971737099608911,
      "grad_norm": 0.12444325536489487,
      "learning_rate": 9.950282629003911e-06,
      "loss": 0.543,
      "step": 314
    },
    {
      "epoch": 0.004987570657250978,
      "grad_norm": 0.008557585068047047,
      "learning_rate": 9.95012429342749e-06,
      "loss": 0.0026,
      "step": 315
    },
    {
      "epoch": 0.005003404214893045,
      "grad_norm": 0.29145023226737976,
      "learning_rate": 9.94996595785107e-06,
      "loss": 0.4602,
      "step": 316
    },
    {
      "epoch": 0.005019237772535111,
      "grad_norm": 0.1262989491224289,
      "learning_rate": 9.94980762227465e-06,
      "loss": 0.188,
      "step": 317
    },
    {
      "epoch": 0.005035071330177178,
      "grad_norm": 0.015278558246791363,
      "learning_rate": 9.94964928669823e-06,
      "loss": 0.0028,
      "step": 318
    },
    {
      "epoch": 0.0050509048878192445,
      "grad_norm": 0.13242878019809723,
      "learning_rate": 9.949490951121809e-06,
      "loss": 0.2811,
      "step": 319
    },
    {
      "epoch": 0.0050667384454613105,
      "grad_norm": 0.12145698815584183,
      "learning_rate": 9.949332615545388e-06,
      "loss": 0.3533,
      "step": 320
    },
    {
      "epoch": 0.005082572003103377,
      "grad_norm": 0.10661057382822037,
      "learning_rate": 9.949174279968967e-06,
      "loss": 0.722,
      "step": 321
    },
    {
      "epoch": 0.005098405560745444,
      "grad_norm": 0.03199078515172005,
      "learning_rate": 9.949015944392546e-06,
      "loss": 0.0158,
      "step": 322
    },
    {
      "epoch": 0.00511423911838751,
      "grad_norm": 0.06099319830536842,
      "learning_rate": 9.948857608816127e-06,
      "loss": 0.0291,
      "step": 323
    },
    {
      "epoch": 0.005130072676029577,
      "grad_norm": 0.18134257197380066,
      "learning_rate": 9.948699273239704e-06,
      "loss": 0.379,
      "step": 324
    },
    {
      "epoch": 0.005145906233671644,
      "grad_norm": 0.042172182351350784,
      "learning_rate": 9.948540937663285e-06,
      "loss": 0.0023,
      "step": 325
    },
    {
      "epoch": 0.00516173979131371,
      "grad_norm": 0.06923355907201767,
      "learning_rate": 9.948382602086864e-06,
      "loss": 0.0096,
      "step": 326
    },
    {
      "epoch": 0.005177573348955777,
      "grad_norm": 0.018550213426351547,
      "learning_rate": 9.948224266510443e-06,
      "loss": 0.0022,
      "step": 327
    },
    {
      "epoch": 0.005193406906597843,
      "grad_norm": 0.09898251295089722,
      "learning_rate": 9.948065930934022e-06,
      "loss": 0.1128,
      "step": 328
    },
    {
      "epoch": 0.00520924046423991,
      "grad_norm": 0.20357738435268402,
      "learning_rate": 9.947907595357603e-06,
      "loss": 0.2149,
      "step": 329
    },
    {
      "epoch": 0.005225074021881977,
      "grad_norm": 0.06990405172109604,
      "learning_rate": 9.94774925978118e-06,
      "loss": 0.2796,
      "step": 330
    },
    {
      "epoch": 0.005240907579524043,
      "grad_norm": 0.23168805241584778,
      "learning_rate": 9.947590924204761e-06,
      "loss": 0.436,
      "step": 331
    },
    {
      "epoch": 0.00525674113716611,
      "grad_norm": 0.016833720728754997,
      "learning_rate": 9.94743258862834e-06,
      "loss": 0.0053,
      "step": 332
    },
    {
      "epoch": 0.005272574694808177,
      "grad_norm": 0.11891798675060272,
      "learning_rate": 9.947274253051919e-06,
      "loss": 0.1616,
      "step": 333
    },
    {
      "epoch": 0.005288408252450243,
      "grad_norm": 0.026209698989987373,
      "learning_rate": 9.947115917475498e-06,
      "loss": 0.0023,
      "step": 334
    },
    {
      "epoch": 0.0053042418100923095,
      "grad_norm": 0.17521606385707855,
      "learning_rate": 9.946957581899079e-06,
      "loss": 0.1971,
      "step": 335
    },
    {
      "epoch": 0.0053200753677343764,
      "grad_norm": 0.30822885036468506,
      "learning_rate": 9.946799246322656e-06,
      "loss": 0.4833,
      "step": 336
    },
    {
      "epoch": 0.0053359089253764425,
      "grad_norm": 0.046953920274972916,
      "learning_rate": 9.946640910746235e-06,
      "loss": 0.0133,
      "step": 337
    },
    {
      "epoch": 0.005351742483018509,
      "grad_norm": 0.03136293217539787,
      "learning_rate": 9.946482575169816e-06,
      "loss": 0.0024,
      "step": 338
    },
    {
      "epoch": 0.005367576040660576,
      "grad_norm": 0.009246259927749634,
      "learning_rate": 9.946324239593395e-06,
      "loss": 0.0004,
      "step": 339
    },
    {
      "epoch": 0.005383409598302642,
      "grad_norm": 0.012457126751542091,
      "learning_rate": 9.946165904016974e-06,
      "loss": 0.0009,
      "step": 340
    },
    {
      "epoch": 0.005399243155944709,
      "grad_norm": 0.026538778096437454,
      "learning_rate": 9.946007568440553e-06,
      "loss": 0.002,
      "step": 341
    },
    {
      "epoch": 0.005415076713586776,
      "grad_norm": 0.31829872727394104,
      "learning_rate": 9.945849232864132e-06,
      "loss": 0.6211,
      "step": 342
    },
    {
      "epoch": 0.005430910271228842,
      "grad_norm": 0.27685338258743286,
      "learning_rate": 9.945690897287712e-06,
      "loss": 0.3833,
      "step": 343
    },
    {
      "epoch": 0.005446743828870909,
      "grad_norm": 0.014884773641824722,
      "learning_rate": 9.945532561711292e-06,
      "loss": 0.0016,
      "step": 344
    },
    {
      "epoch": 0.005462577386512976,
      "grad_norm": 0.13214871287345886,
      "learning_rate": 9.945374226134871e-06,
      "loss": 0.2384,
      "step": 345
    },
    {
      "epoch": 0.005478410944155042,
      "grad_norm": 0.008882617577910423,
      "learning_rate": 9.94521589055845e-06,
      "loss": 0.0016,
      "step": 346
    },
    {
      "epoch": 0.005494244501797109,
      "grad_norm": 0.06924037635326385,
      "learning_rate": 9.94505755498203e-06,
      "loss": 0.0049,
      "step": 347
    },
    {
      "epoch": 0.005510078059439176,
      "grad_norm": 0.018024537712335587,
      "learning_rate": 9.944899219405609e-06,
      "loss": 0.0018,
      "step": 348
    },
    {
      "epoch": 0.005525911617081242,
      "grad_norm": 0.26894134283065796,
      "learning_rate": 9.944740883829188e-06,
      "loss": 1.1813,
      "step": 349
    },
    {
      "epoch": 0.005541745174723309,
      "grad_norm": 0.20416727662086487,
      "learning_rate": 9.944582548252768e-06,
      "loss": 0.3872,
      "step": 350
    },
    {
      "epoch": 0.0055575787323653755,
      "grad_norm": 0.08384701609611511,
      "learning_rate": 9.944424212676348e-06,
      "loss": 0.0565,
      "step": 351
    },
    {
      "epoch": 0.0055734122900074415,
      "grad_norm": 0.020032603293657303,
      "learning_rate": 9.944265877099927e-06,
      "loss": 0.0017,
      "step": 352
    },
    {
      "epoch": 0.005589245847649508,
      "grad_norm": 0.14328362047672272,
      "learning_rate": 9.944107541523506e-06,
      "loss": 0.1359,
      "step": 353
    },
    {
      "epoch": 0.005605079405291575,
      "grad_norm": 0.29666927456855774,
      "learning_rate": 9.943949205947085e-06,
      "loss": 0.4649,
      "step": 354
    },
    {
      "epoch": 0.005620912962933641,
      "grad_norm": 0.28270223736763,
      "learning_rate": 9.943790870370664e-06,
      "loss": 0.3714,
      "step": 355
    },
    {
      "epoch": 0.005636746520575708,
      "grad_norm": 0.11123662441968918,
      "learning_rate": 9.943632534794245e-06,
      "loss": 0.1079,
      "step": 356
    },
    {
      "epoch": 0.005652580078217775,
      "grad_norm": 0.2356419861316681,
      "learning_rate": 9.943474199217824e-06,
      "loss": 0.2631,
      "step": 357
    },
    {
      "epoch": 0.005668413635859841,
      "grad_norm": 0.14847031235694885,
      "learning_rate": 9.943315863641403e-06,
      "loss": 0.3745,
      "step": 358
    },
    {
      "epoch": 0.005684247193501908,
      "grad_norm": 0.25727933645248413,
      "learning_rate": 9.943157528064982e-06,
      "loss": 0.8646,
      "step": 359
    },
    {
      "epoch": 0.005700080751143975,
      "grad_norm": 0.3071674108505249,
      "learning_rate": 9.942999192488561e-06,
      "loss": 0.8148,
      "step": 360
    },
    {
      "epoch": 0.005715914308786041,
      "grad_norm": 0.20067144930362701,
      "learning_rate": 9.94284085691214e-06,
      "loss": 0.4132,
      "step": 361
    },
    {
      "epoch": 0.005731747866428108,
      "grad_norm": 0.14473895728588104,
      "learning_rate": 9.942682521335719e-06,
      "loss": 0.1559,
      "step": 362
    },
    {
      "epoch": 0.005747581424070175,
      "grad_norm": 0.015038612298667431,
      "learning_rate": 9.9425241857593e-06,
      "loss": 0.0015,
      "step": 363
    },
    {
      "epoch": 0.005763414981712241,
      "grad_norm": 0.01923498511314392,
      "learning_rate": 9.942365850182877e-06,
      "loss": 0.0011,
      "step": 364
    },
    {
      "epoch": 0.005779248539354308,
      "grad_norm": 0.1821965128183365,
      "learning_rate": 9.942207514606458e-06,
      "loss": 0.4055,
      "step": 365
    },
    {
      "epoch": 0.0057950820969963745,
      "grad_norm": 0.14633508026599884,
      "learning_rate": 9.942049179030037e-06,
      "loss": 0.2447,
      "step": 366
    },
    {
      "epoch": 0.0058109156546384405,
      "grad_norm": 0.07674510776996613,
      "learning_rate": 9.941890843453616e-06,
      "loss": 0.007,
      "step": 367
    },
    {
      "epoch": 0.005826749212280507,
      "grad_norm": 0.24609623849391937,
      "learning_rate": 9.941732507877195e-06,
      "loss": 0.7572,
      "step": 368
    },
    {
      "epoch": 0.005842582769922574,
      "grad_norm": 0.05781614035367966,
      "learning_rate": 9.941574172300776e-06,
      "loss": 0.0031,
      "step": 369
    },
    {
      "epoch": 0.00585841632756464,
      "grad_norm": 0.1666058897972107,
      "learning_rate": 9.941415836724353e-06,
      "loss": 0.3879,
      "step": 370
    },
    {
      "epoch": 0.005874249885206707,
      "grad_norm": 0.0401301309466362,
      "learning_rate": 9.941257501147934e-06,
      "loss": 0.033,
      "step": 371
    },
    {
      "epoch": 0.005890083442848774,
      "grad_norm": 0.12475882470607758,
      "learning_rate": 9.941099165571513e-06,
      "loss": 0.1519,
      "step": 372
    },
    {
      "epoch": 0.00590591700049084,
      "grad_norm": 0.2074122577905655,
      "learning_rate": 9.940940829995092e-06,
      "loss": 0.3386,
      "step": 373
    },
    {
      "epoch": 0.005921750558132907,
      "grad_norm": 0.22648866474628448,
      "learning_rate": 9.940782494418671e-06,
      "loss": 0.2413,
      "step": 374
    },
    {
      "epoch": 0.005937584115774974,
      "grad_norm": 0.1250697672367096,
      "learning_rate": 9.940624158842252e-06,
      "loss": 0.6122,
      "step": 375
    },
    {
      "epoch": 0.00595341767341704,
      "grad_norm": 0.1677875965833664,
      "learning_rate": 9.94046582326583e-06,
      "loss": 0.1576,
      "step": 376
    },
    {
      "epoch": 0.005969251231059107,
      "grad_norm": 0.3978118300437927,
      "learning_rate": 9.94030748768941e-06,
      "loss": 0.3889,
      "step": 377
    },
    {
      "epoch": 0.005985084788701173,
      "grad_norm": 0.18630985915660858,
      "learning_rate": 9.94014915211299e-06,
      "loss": 0.289,
      "step": 378
    },
    {
      "epoch": 0.00600091834634324,
      "grad_norm": 0.01646358333528042,
      "learning_rate": 9.939990816536569e-06,
      "loss": 0.0022,
      "step": 379
    },
    {
      "epoch": 0.006016751903985307,
      "grad_norm": 0.20479357242584229,
      "learning_rate": 9.939832480960148e-06,
      "loss": 0.9228,
      "step": 380
    },
    {
      "epoch": 0.006032585461627373,
      "grad_norm": 0.40290388464927673,
      "learning_rate": 9.939674145383728e-06,
      "loss": 0.5464,
      "step": 381
    },
    {
      "epoch": 0.0060484190192694395,
      "grad_norm": 0.18146799504756927,
      "learning_rate": 9.939515809807306e-06,
      "loss": 0.1915,
      "step": 382
    },
    {
      "epoch": 0.006064252576911506,
      "grad_norm": 0.02340736798942089,
      "learning_rate": 9.939357474230887e-06,
      "loss": 0.0024,
      "step": 383
    },
    {
      "epoch": 0.0060800861345535724,
      "grad_norm": 0.3594001233577728,
      "learning_rate": 9.939199138654466e-06,
      "loss": 0.2888,
      "step": 384
    },
    {
      "epoch": 0.006095919692195639,
      "grad_norm": 0.008274676278233528,
      "learning_rate": 9.939040803078045e-06,
      "loss": 0.0003,
      "step": 385
    },
    {
      "epoch": 0.006111753249837706,
      "grad_norm": 0.07803957164287567,
      "learning_rate": 9.938882467501624e-06,
      "loss": 0.0472,
      "step": 386
    },
    {
      "epoch": 0.006127586807479772,
      "grad_norm": 0.18930356204509735,
      "learning_rate": 9.938724131925203e-06,
      "loss": 0.1622,
      "step": 387
    },
    {
      "epoch": 0.006143420365121839,
      "grad_norm": 0.0035104251001030207,
      "learning_rate": 9.938565796348782e-06,
      "loss": 0.0002,
      "step": 388
    },
    {
      "epoch": 0.006159253922763906,
      "grad_norm": 0.2796124219894409,
      "learning_rate": 9.938407460772361e-06,
      "loss": 0.2857,
      "step": 389
    },
    {
      "epoch": 0.006175087480405972,
      "grad_norm": 0.1787189543247223,
      "learning_rate": 9.938249125195942e-06,
      "loss": 0.4628,
      "step": 390
    },
    {
      "epoch": 0.006190921038048039,
      "grad_norm": 0.1503419727087021,
      "learning_rate": 9.93809078961952e-06,
      "loss": 0.3722,
      "step": 391
    },
    {
      "epoch": 0.006206754595690106,
      "grad_norm": 0.23440538346767426,
      "learning_rate": 9.9379324540431e-06,
      "loss": 0.012,
      "step": 392
    },
    {
      "epoch": 0.006222588153332172,
      "grad_norm": 0.10974723100662231,
      "learning_rate": 9.937774118466679e-06,
      "loss": 0.5149,
      "step": 393
    },
    {
      "epoch": 0.006238421710974239,
      "grad_norm": 0.13677158951759338,
      "learning_rate": 9.937615782890258e-06,
      "loss": 0.3477,
      "step": 394
    },
    {
      "epoch": 0.006254255268616306,
      "grad_norm": 0.06661403924226761,
      "learning_rate": 9.937457447313837e-06,
      "loss": 0.0406,
      "step": 395
    },
    {
      "epoch": 0.006270088826258372,
      "grad_norm": 0.014045697636902332,
      "learning_rate": 9.937299111737418e-06,
      "loss": 0.0039,
      "step": 396
    },
    {
      "epoch": 0.0062859223839004386,
      "grad_norm": 0.006769078318029642,
      "learning_rate": 9.937140776160995e-06,
      "loss": 0.0004,
      "step": 397
    },
    {
      "epoch": 0.0063017559415425055,
      "grad_norm": 0.5536237955093384,
      "learning_rate": 9.936982440584576e-06,
      "loss": 0.2623,
      "step": 398
    },
    {
      "epoch": 0.0063175894991845715,
      "grad_norm": 0.2288985699415207,
      "learning_rate": 9.936824105008155e-06,
      "loss": 0.1804,
      "step": 399
    },
    {
      "epoch": 0.006333423056826638,
      "grad_norm": 0.10425763577222824,
      "learning_rate": 9.936665769431734e-06,
      "loss": 0.3883,
      "step": 400
    },
    {
      "epoch": 0.006349256614468705,
      "grad_norm": 0.14722710847854614,
      "learning_rate": 9.936507433855313e-06,
      "loss": 0.1404,
      "step": 401
    },
    {
      "epoch": 0.006365090172110771,
      "grad_norm": 0.025067949667572975,
      "learning_rate": 9.936349098278894e-06,
      "loss": 0.001,
      "step": 402
    },
    {
      "epoch": 0.006380923729752838,
      "grad_norm": 0.17934143543243408,
      "learning_rate": 9.936190762702472e-06,
      "loss": 0.908,
      "step": 403
    },
    {
      "epoch": 0.006396757287394905,
      "grad_norm": 0.12092451751232147,
      "learning_rate": 9.936032427126052e-06,
      "loss": 0.1067,
      "step": 404
    },
    {
      "epoch": 0.006412590845036971,
      "grad_norm": 0.2972470223903656,
      "learning_rate": 9.935874091549631e-06,
      "loss": 0.4315,
      "step": 405
    },
    {
      "epoch": 0.006428424402679038,
      "grad_norm": 0.32957693934440613,
      "learning_rate": 9.93571575597321e-06,
      "loss": 0.4621,
      "step": 406
    },
    {
      "epoch": 0.006444257960321105,
      "grad_norm": 0.20266124606132507,
      "learning_rate": 9.93555742039679e-06,
      "loss": 0.2083,
      "step": 407
    },
    {
      "epoch": 0.006460091517963171,
      "grad_norm": 0.17974995076656342,
      "learning_rate": 9.93539908482037e-06,
      "loss": 0.622,
      "step": 408
    },
    {
      "epoch": 0.006475925075605238,
      "grad_norm": 0.057230476289987564,
      "learning_rate": 9.935240749243948e-06,
      "loss": 0.0292,
      "step": 409
    },
    {
      "epoch": 0.006491758633247305,
      "grad_norm": 0.18825788795948029,
      "learning_rate": 9.935082413667527e-06,
      "loss": 0.2019,
      "step": 410
    },
    {
      "epoch": 0.006507592190889371,
      "grad_norm": 0.024086033925414085,
      "learning_rate": 9.934924078091108e-06,
      "loss": 0.0045,
      "step": 411
    },
    {
      "epoch": 0.006523425748531438,
      "grad_norm": 0.001938547007739544,
      "learning_rate": 9.934765742514687e-06,
      "loss": 0.0002,
      "step": 412
    },
    {
      "epoch": 0.0065392593061735045,
      "grad_norm": 0.12466089427471161,
      "learning_rate": 9.934607406938266e-06,
      "loss": 0.2278,
      "step": 413
    },
    {
      "epoch": 0.0065550928638155705,
      "grad_norm": 0.3511088192462921,
      "learning_rate": 9.934449071361845e-06,
      "loss": 0.4743,
      "step": 414
    },
    {
      "epoch": 0.006570926421457637,
      "grad_norm": 0.021653732284903526,
      "learning_rate": 9.934290735785424e-06,
      "loss": 0.0006,
      "step": 415
    },
    {
      "epoch": 0.006586759979099704,
      "grad_norm": 0.016445783898234367,
      "learning_rate": 9.934132400209003e-06,
      "loss": 0.0018,
      "step": 416
    },
    {
      "epoch": 0.00660259353674177,
      "grad_norm": 0.22100557386875153,
      "learning_rate": 9.933974064632584e-06,
      "loss": 0.2458,
      "step": 417
    },
    {
      "epoch": 0.006618427094383837,
      "grad_norm": 0.18607787787914276,
      "learning_rate": 9.933815729056163e-06,
      "loss": 0.32,
      "step": 418
    },
    {
      "epoch": 0.006634260652025904,
      "grad_norm": 0.20915812253952026,
      "learning_rate": 9.933657393479742e-06,
      "loss": 0.446,
      "step": 419
    },
    {
      "epoch": 0.00665009420966797,
      "grad_norm": 0.0031291956547647715,
      "learning_rate": 9.933499057903321e-06,
      "loss": 0.0002,
      "step": 420
    },
    {
      "epoch": 0.006665927767310037,
      "grad_norm": 0.20261895656585693,
      "learning_rate": 9.9333407223269e-06,
      "loss": 0.3613,
      "step": 421
    },
    {
      "epoch": 0.006681761324952104,
      "grad_norm": 0.3306773602962494,
      "learning_rate": 9.933182386750479e-06,
      "loss": 0.0238,
      "step": 422
    },
    {
      "epoch": 0.00669759488259417,
      "grad_norm": 0.26247361302375793,
      "learning_rate": 9.93302405117406e-06,
      "loss": 0.4387,
      "step": 423
    },
    {
      "epoch": 0.006713428440236237,
      "grad_norm": 0.3074961006641388,
      "learning_rate": 9.932865715597639e-06,
      "loss": 0.2086,
      "step": 424
    },
    {
      "epoch": 0.006729261997878304,
      "grad_norm": 0.0040196687914431095,
      "learning_rate": 9.932707380021218e-06,
      "loss": 0.001,
      "step": 425
    },
    {
      "epoch": 0.00674509555552037,
      "grad_norm": 0.2285570502281189,
      "learning_rate": 9.932549044444797e-06,
      "loss": 0.3949,
      "step": 426
    },
    {
      "epoch": 0.006760929113162437,
      "grad_norm": 0.08787815272808075,
      "learning_rate": 9.932390708868376e-06,
      "loss": 0.038,
      "step": 427
    },
    {
      "epoch": 0.006776762670804503,
      "grad_norm": 0.012052350677549839,
      "learning_rate": 9.932232373291955e-06,
      "loss": 0.0019,
      "step": 428
    },
    {
      "epoch": 0.0067925962284465695,
      "grad_norm": 0.00402620155364275,
      "learning_rate": 9.932074037715536e-06,
      "loss": 0.0002,
      "step": 429
    },
    {
      "epoch": 0.006808429786088636,
      "grad_norm": 0.3033667504787445,
      "learning_rate": 9.931915702139115e-06,
      "loss": 0.567,
      "step": 430
    },
    {
      "epoch": 0.0068242633437307024,
      "grad_norm": 0.10274910926818848,
      "learning_rate": 9.931757366562694e-06,
      "loss": 0.0967,
      "step": 431
    },
    {
      "epoch": 0.006840096901372769,
      "grad_norm": 0.1196698248386383,
      "learning_rate": 9.931599030986273e-06,
      "loss": 0.0766,
      "step": 432
    },
    {
      "epoch": 0.006855930459014836,
      "grad_norm": 0.17395059764385223,
      "learning_rate": 9.931440695409852e-06,
      "loss": 0.0101,
      "step": 433
    },
    {
      "epoch": 0.006871764016656902,
      "grad_norm": 0.24219702184200287,
      "learning_rate": 9.931282359833431e-06,
      "loss": 0.2944,
      "step": 434
    },
    {
      "epoch": 0.006887597574298969,
      "grad_norm": 0.4138032793998718,
      "learning_rate": 9.93112402425701e-06,
      "loss": 1.1903,
      "step": 435
    },
    {
      "epoch": 0.006903431131941036,
      "grad_norm": 0.23079189658164978,
      "learning_rate": 9.930965688680591e-06,
      "loss": 0.2093,
      "step": 436
    },
    {
      "epoch": 0.006919264689583102,
      "grad_norm": 0.009299476630985737,
      "learning_rate": 9.930807353104169e-06,
      "loss": 0.0023,
      "step": 437
    },
    {
      "epoch": 0.006935098247225169,
      "grad_norm": 0.27972325682640076,
      "learning_rate": 9.93064901752775e-06,
      "loss": 0.8619,
      "step": 438
    },
    {
      "epoch": 0.006950931804867236,
      "grad_norm": 0.18542450666427612,
      "learning_rate": 9.930490681951329e-06,
      "loss": 0.1994,
      "step": 439
    },
    {
      "epoch": 0.006966765362509302,
      "grad_norm": 0.10218259692192078,
      "learning_rate": 9.930332346374908e-06,
      "loss": 0.0682,
      "step": 440
    },
    {
      "epoch": 0.006982598920151369,
      "grad_norm": 0.11620473116636276,
      "learning_rate": 9.930174010798487e-06,
      "loss": 0.1543,
      "step": 441
    },
    {
      "epoch": 0.006998432477793436,
      "grad_norm": 0.17965057492256165,
      "learning_rate": 9.930015675222067e-06,
      "loss": 0.0107,
      "step": 442
    },
    {
      "epoch": 0.007014266035435502,
      "grad_norm": 0.2045314908027649,
      "learning_rate": 9.929857339645645e-06,
      "loss": 0.3271,
      "step": 443
    },
    {
      "epoch": 0.0070300995930775685,
      "grad_norm": 0.17406268417835236,
      "learning_rate": 9.929699004069226e-06,
      "loss": 0.6297,
      "step": 444
    },
    {
      "epoch": 0.0070459331507196354,
      "grad_norm": 0.3396933376789093,
      "learning_rate": 9.929540668492805e-06,
      "loss": 0.4231,
      "step": 445
    },
    {
      "epoch": 0.0070617667083617015,
      "grad_norm": 0.19698193669319153,
      "learning_rate": 9.929382332916384e-06,
      "loss": 0.4297,
      "step": 446
    },
    {
      "epoch": 0.007077600266003768,
      "grad_norm": 0.12297069281339645,
      "learning_rate": 9.929223997339963e-06,
      "loss": 0.1222,
      "step": 447
    },
    {
      "epoch": 0.007093433823645835,
      "grad_norm": 0.0054575675167143345,
      "learning_rate": 9.929065661763542e-06,
      "loss": 0.0011,
      "step": 448
    },
    {
      "epoch": 0.007109267381287901,
      "grad_norm": 0.23864680528640747,
      "learning_rate": 9.928907326187121e-06,
      "loss": 0.1858,
      "step": 449
    },
    {
      "epoch": 0.007125100938929968,
      "grad_norm": 0.01114620640873909,
      "learning_rate": 9.928748990610702e-06,
      "loss": 0.0021,
      "step": 450
    },
    {
      "epoch": 0.007140934496572035,
      "grad_norm": 0.007045639678835869,
      "learning_rate": 9.928590655034281e-06,
      "loss": 0.0014,
      "step": 451
    },
    {
      "epoch": 0.007156768054214101,
      "grad_norm": 0.16470001637935638,
      "learning_rate": 9.92843231945786e-06,
      "loss": 0.549,
      "step": 452
    },
    {
      "epoch": 0.007172601611856168,
      "grad_norm": 0.10956254601478577,
      "learning_rate": 9.928273983881439e-06,
      "loss": 0.0931,
      "step": 453
    },
    {
      "epoch": 0.007188435169498235,
      "grad_norm": 0.35809555649757385,
      "learning_rate": 9.928115648305018e-06,
      "loss": 0.3142,
      "step": 454
    },
    {
      "epoch": 0.007204268727140301,
      "grad_norm": 0.006458303425461054,
      "learning_rate": 9.927957312728597e-06,
      "loss": 0.0009,
      "step": 455
    },
    {
      "epoch": 0.007220102284782368,
      "grad_norm": 0.1624583899974823,
      "learning_rate": 9.927798977152178e-06,
      "loss": 0.2785,
      "step": 456
    },
    {
      "epoch": 0.007235935842424435,
      "grad_norm": 0.24366475641727448,
      "learning_rate": 9.927640641575757e-06,
      "loss": 0.072,
      "step": 457
    },
    {
      "epoch": 0.007251769400066501,
      "grad_norm": 0.15057329833507538,
      "learning_rate": 9.927482305999334e-06,
      "loss": 0.2952,
      "step": 458
    },
    {
      "epoch": 0.007267602957708568,
      "grad_norm": 0.15956181287765503,
      "learning_rate": 9.927323970422915e-06,
      "loss": 0.1499,
      "step": 459
    },
    {
      "epoch": 0.0072834365153506345,
      "grad_norm": 0.12118963152170181,
      "learning_rate": 9.927165634846494e-06,
      "loss": 0.0701,
      "step": 460
    },
    {
      "epoch": 0.0072992700729927005,
      "grad_norm": 0.24531133472919464,
      "learning_rate": 9.927007299270073e-06,
      "loss": 0.5738,
      "step": 461
    },
    {
      "epoch": 0.007315103630634767,
      "grad_norm": 0.4076966345310211,
      "learning_rate": 9.926848963693652e-06,
      "loss": 0.1394,
      "step": 462
    },
    {
      "epoch": 0.007330937188276834,
      "grad_norm": 0.4340772330760956,
      "learning_rate": 9.926690628117233e-06,
      "loss": 0.4344,
      "step": 463
    },
    {
      "epoch": 0.0073467707459189,
      "grad_norm": 0.1503659039735794,
      "learning_rate": 9.92653229254081e-06,
      "loss": 0.0882,
      "step": 464
    },
    {
      "epoch": 0.007362604303560967,
      "grad_norm": 0.21641811728477478,
      "learning_rate": 9.926373956964391e-06,
      "loss": 0.1681,
      "step": 465
    },
    {
      "epoch": 0.007378437861203034,
      "grad_norm": 0.27003225684165955,
      "learning_rate": 9.92621562138797e-06,
      "loss": 0.8069,
      "step": 466
    },
    {
      "epoch": 0.0073942714188451,
      "grad_norm": 0.17110112309455872,
      "learning_rate": 9.92605728581155e-06,
      "loss": 0.1603,
      "step": 467
    },
    {
      "epoch": 0.007410104976487167,
      "grad_norm": 0.5133691430091858,
      "learning_rate": 9.925898950235129e-06,
      "loss": 0.2352,
      "step": 468
    },
    {
      "epoch": 0.007425938534129234,
      "grad_norm": 0.005046075209975243,
      "learning_rate": 9.92574061465871e-06,
      "loss": 0.0009,
      "step": 469
    },
    {
      "epoch": 0.0074417720917713,
      "grad_norm": 0.002766478806734085,
      "learning_rate": 9.925582279082287e-06,
      "loss": 0.0005,
      "step": 470
    },
    {
      "epoch": 0.007457605649413367,
      "grad_norm": 0.3346391022205353,
      "learning_rate": 9.925423943505868e-06,
      "loss": 0.8637,
      "step": 471
    },
    {
      "epoch": 0.007473439207055434,
      "grad_norm": 0.00764854159206152,
      "learning_rate": 9.925265607929447e-06,
      "loss": 0.0014,
      "step": 472
    },
    {
      "epoch": 0.0074892727646975,
      "grad_norm": 0.16513241827487946,
      "learning_rate": 9.925107272353026e-06,
      "loss": 0.2284,
      "step": 473
    },
    {
      "epoch": 0.007505106322339567,
      "grad_norm": 0.004683326464146376,
      "learning_rate": 9.924948936776605e-06,
      "loss": 0.0008,
      "step": 474
    },
    {
      "epoch": 0.0075209398799816335,
      "grad_norm": 0.33542707562446594,
      "learning_rate": 9.924790601200186e-06,
      "loss": 0.0488,
      "step": 475
    },
    {
      "epoch": 0.0075367734376236995,
      "grad_norm": 0.14071804285049438,
      "learning_rate": 9.924632265623763e-06,
      "loss": 0.0349,
      "step": 476
    },
    {
      "epoch": 0.007552606995265766,
      "grad_norm": 0.1206224337220192,
      "learning_rate": 9.924473930047344e-06,
      "loss": 0.1461,
      "step": 477
    },
    {
      "epoch": 0.007568440552907832,
      "grad_norm": 0.11448629945516586,
      "learning_rate": 9.924315594470923e-06,
      "loss": 0.1084,
      "step": 478
    },
    {
      "epoch": 0.007584274110549899,
      "grad_norm": 0.2541140615940094,
      "learning_rate": 9.924157258894502e-06,
      "loss": 0.8753,
      "step": 479
    },
    {
      "epoch": 0.007600107668191966,
      "grad_norm": 0.0011801292421296239,
      "learning_rate": 9.923998923318081e-06,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 0.007615941225834032,
      "grad_norm": 0.16744975745677948,
      "learning_rate": 9.923840587741662e-06,
      "loss": 0.1024,
      "step": 481
    },
    {
      "epoch": 0.007631774783476099,
      "grad_norm": 0.24471817910671234,
      "learning_rate": 9.923682252165239e-06,
      "loss": 0.2524,
      "step": 482
    },
    {
      "epoch": 0.007647608341118166,
      "grad_norm": 0.12861649692058563,
      "learning_rate": 9.923523916588818e-06,
      "loss": 0.1252,
      "step": 483
    },
    {
      "epoch": 0.007663441898760232,
      "grad_norm": 0.09119585901498795,
      "learning_rate": 9.923365581012399e-06,
      "loss": 0.0063,
      "step": 484
    },
    {
      "epoch": 0.007679275456402299,
      "grad_norm": 0.1965228170156479,
      "learning_rate": 9.923207245435978e-06,
      "loss": 0.2145,
      "step": 485
    },
    {
      "epoch": 0.007695109014044366,
      "grad_norm": 0.1866941750049591,
      "learning_rate": 9.923048909859557e-06,
      "loss": 0.0906,
      "step": 486
    },
    {
      "epoch": 0.007710942571686432,
      "grad_norm": 0.048414140939712524,
      "learning_rate": 9.922890574283136e-06,
      "loss": 0.0009,
      "step": 487
    },
    {
      "epoch": 0.007726776129328499,
      "grad_norm": 0.015936216339468956,
      "learning_rate": 9.922732238706715e-06,
      "loss": 0.0026,
      "step": 488
    },
    {
      "epoch": 0.007742609686970566,
      "grad_norm": 0.46749791502952576,
      "learning_rate": 9.922573903130294e-06,
      "loss": 1.0663,
      "step": 489
    },
    {
      "epoch": 0.007758443244612632,
      "grad_norm": 0.24306955933570862,
      "learning_rate": 9.922415567553875e-06,
      "loss": 0.3412,
      "step": 490
    },
    {
      "epoch": 0.0077742768022546985,
      "grad_norm": 0.17493344843387604,
      "learning_rate": 9.922257231977454e-06,
      "loss": 0.244,
      "step": 491
    },
    {
      "epoch": 0.007790110359896765,
      "grad_norm": 0.24237821996212006,
      "learning_rate": 9.922098896401033e-06,
      "loss": 0.2026,
      "step": 492
    },
    {
      "epoch": 0.0078059439175388315,
      "grad_norm": 0.0008758165640756488,
      "learning_rate": 9.921940560824612e-06,
      "loss": 0.0,
      "step": 493
    },
    {
      "epoch": 0.007821777475180898,
      "grad_norm": 0.1528089940547943,
      "learning_rate": 9.921782225248191e-06,
      "loss": 0.102,
      "step": 494
    },
    {
      "epoch": 0.007837611032822964,
      "grad_norm": 0.005115389823913574,
      "learning_rate": 9.92162388967177e-06,
      "loss": 0.0009,
      "step": 495
    },
    {
      "epoch": 0.007853444590465032,
      "grad_norm": 0.2850903570652008,
      "learning_rate": 9.921465554095351e-06,
      "loss": 0.556,
      "step": 496
    },
    {
      "epoch": 0.007869278148107098,
      "grad_norm": 0.3389894366264343,
      "learning_rate": 9.92130721851893e-06,
      "loss": 0.1846,
      "step": 497
    },
    {
      "epoch": 0.007885111705749164,
      "grad_norm": 0.00027438855613581836,
      "learning_rate": 9.92114888294251e-06,
      "loss": 0.0,
      "step": 498
    },
    {
      "epoch": 0.007900945263391232,
      "grad_norm": 0.10812778770923615,
      "learning_rate": 9.920990547366089e-06,
      "loss": 0.1013,
      "step": 499
    },
    {
      "epoch": 0.007916778821033298,
      "grad_norm": 0.0031444134656339884,
      "learning_rate": 9.920832211789668e-06,
      "loss": 0.0005,
      "step": 500
    },
    {
      "epoch": 0.007932612378675364,
      "grad_norm": 0.1860533207654953,
      "learning_rate": 9.920673876213247e-06,
      "loss": 0.328,
      "step": 501
    },
    {
      "epoch": 0.007948445936317432,
      "grad_norm": 0.12316174060106277,
      "learning_rate": 9.920515540636828e-06,
      "loss": 0.2886,
      "step": 502
    },
    {
      "epoch": 0.007964279493959498,
      "grad_norm": 0.5482801198959351,
      "learning_rate": 9.920357205060407e-06,
      "loss": 0.0975,
      "step": 503
    },
    {
      "epoch": 0.007980113051601564,
      "grad_norm": 0.3646445572376251,
      "learning_rate": 9.920198869483986e-06,
      "loss": 0.549,
      "step": 504
    },
    {
      "epoch": 0.007995946609243632,
      "grad_norm": 0.5679334998130798,
      "learning_rate": 9.920040533907565e-06,
      "loss": 0.1177,
      "step": 505
    },
    {
      "epoch": 0.008011780166885698,
      "grad_norm": 0.11137101799249649,
      "learning_rate": 9.919882198331144e-06,
      "loss": 0.1294,
      "step": 506
    },
    {
      "epoch": 0.008027613724527764,
      "grad_norm": 0.20839069783687592,
      "learning_rate": 9.919723862754723e-06,
      "loss": 0.2051,
      "step": 507
    },
    {
      "epoch": 0.008043447282169831,
      "grad_norm": 0.5764037370681763,
      "learning_rate": 9.919565527178302e-06,
      "loss": 0.1444,
      "step": 508
    },
    {
      "epoch": 0.008059280839811897,
      "grad_norm": 0.11373446881771088,
      "learning_rate": 9.919407191601883e-06,
      "loss": 0.0993,
      "step": 509
    },
    {
      "epoch": 0.008075114397453963,
      "grad_norm": 0.2872902452945709,
      "learning_rate": 9.91924885602546e-06,
      "loss": 0.1496,
      "step": 510
    },
    {
      "epoch": 0.008090947955096031,
      "grad_norm": 0.2817120850086212,
      "learning_rate": 9.919090520449041e-06,
      "loss": 0.5065,
      "step": 511
    },
    {
      "epoch": 0.008106781512738097,
      "grad_norm": 0.01712021231651306,
      "learning_rate": 9.91893218487262e-06,
      "loss": 0.002,
      "step": 512
    },
    {
      "epoch": 0.008122615070380163,
      "grad_norm": 0.0006617412436753511,
      "learning_rate": 9.918773849296199e-06,
      "loss": 0.0,
      "step": 513
    },
    {
      "epoch": 0.008138448628022231,
      "grad_norm": 0.4967556893825531,
      "learning_rate": 9.918615513719778e-06,
      "loss": 0.3359,
      "step": 514
    },
    {
      "epoch": 0.008154282185664297,
      "grad_norm": 0.12370916455984116,
      "learning_rate": 9.918457178143357e-06,
      "loss": 0.4318,
      "step": 515
    },
    {
      "epoch": 0.008170115743306363,
      "grad_norm": 0.2984420955181122,
      "learning_rate": 9.918298842566936e-06,
      "loss": 0.2741,
      "step": 516
    },
    {
      "epoch": 0.00818594930094843,
      "grad_norm": 0.002389810746535659,
      "learning_rate": 9.918140506990517e-06,
      "loss": 0.0004,
      "step": 517
    },
    {
      "epoch": 0.008201782858590497,
      "grad_norm": 0.018952321261167526,
      "learning_rate": 9.917982171414096e-06,
      "loss": 0.0006,
      "step": 518
    },
    {
      "epoch": 0.008217616416232563,
      "grad_norm": 0.006373904645442963,
      "learning_rate": 9.917823835837675e-06,
      "loss": 0.001,
      "step": 519
    },
    {
      "epoch": 0.00823344997387463,
      "grad_norm": 0.001194702577777207,
      "learning_rate": 9.917665500261254e-06,
      "loss": 0.0,
      "step": 520
    },
    {
      "epoch": 0.008249283531516697,
      "grad_norm": 0.12056237459182739,
      "learning_rate": 9.917507164684833e-06,
      "loss": 0.1737,
      "step": 521
    },
    {
      "epoch": 0.008265117089158763,
      "grad_norm": 0.002995030488818884,
      "learning_rate": 9.917348829108412e-06,
      "loss": 0.0002,
      "step": 522
    },
    {
      "epoch": 0.00828095064680083,
      "grad_norm": 0.5704007744789124,
      "learning_rate": 9.917190493531993e-06,
      "loss": 0.0834,
      "step": 523
    },
    {
      "epoch": 0.008296784204442896,
      "grad_norm": 0.3038080930709839,
      "learning_rate": 9.917032157955572e-06,
      "loss": 0.341,
      "step": 524
    },
    {
      "epoch": 0.008312617762084962,
      "grad_norm": 0.16801242530345917,
      "learning_rate": 9.916873822379151e-06,
      "loss": 0.9016,
      "step": 525
    },
    {
      "epoch": 0.00832845131972703,
      "grad_norm": 0.16182294487953186,
      "learning_rate": 9.91671548680273e-06,
      "loss": 0.1518,
      "step": 526
    },
    {
      "epoch": 0.008344284877369096,
      "grad_norm": 0.1738498955965042,
      "learning_rate": 9.91655715122631e-06,
      "loss": 0.4432,
      "step": 527
    },
    {
      "epoch": 0.008360118435011162,
      "grad_norm": 0.03444599360227585,
      "learning_rate": 9.916398815649889e-06,
      "loss": 0.0272,
      "step": 528
    },
    {
      "epoch": 0.00837595199265323,
      "grad_norm": 0.3353728950023651,
      "learning_rate": 9.91624048007347e-06,
      "loss": 0.1687,
      "step": 529
    },
    {
      "epoch": 0.008391785550295296,
      "grad_norm": 0.13900943100452423,
      "learning_rate": 9.916082144497049e-06,
      "loss": 0.2318,
      "step": 530
    },
    {
      "epoch": 0.008407619107937362,
      "grad_norm": 0.010477317497134209,
      "learning_rate": 9.915923808920626e-06,
      "loss": 0.0016,
      "step": 531
    },
    {
      "epoch": 0.00842345266557943,
      "grad_norm": 0.196328803896904,
      "learning_rate": 9.915765473344207e-06,
      "loss": 0.3099,
      "step": 532
    },
    {
      "epoch": 0.008439286223221496,
      "grad_norm": 0.14459475874900818,
      "learning_rate": 9.915607137767786e-06,
      "loss": 0.2003,
      "step": 533
    },
    {
      "epoch": 0.008455119780863562,
      "grad_norm": 0.004228019621223211,
      "learning_rate": 9.915448802191365e-06,
      "loss": 0.0007,
      "step": 534
    },
    {
      "epoch": 0.00847095333850563,
      "grad_norm": 0.1255909949541092,
      "learning_rate": 9.915290466614944e-06,
      "loss": 0.1983,
      "step": 535
    },
    {
      "epoch": 0.008486786896147696,
      "grad_norm": 0.22452016174793243,
      "learning_rate": 9.915132131038525e-06,
      "loss": 0.0157,
      "step": 536
    },
    {
      "epoch": 0.008502620453789762,
      "grad_norm": 0.16815637052059174,
      "learning_rate": 9.914973795462102e-06,
      "loss": 0.0522,
      "step": 537
    },
    {
      "epoch": 0.00851845401143183,
      "grad_norm": 0.18841131031513214,
      "learning_rate": 9.914815459885683e-06,
      "loss": 0.2294,
      "step": 538
    },
    {
      "epoch": 0.008534287569073895,
      "grad_norm": 0.16428382694721222,
      "learning_rate": 9.914657124309262e-06,
      "loss": 0.4027,
      "step": 539
    },
    {
      "epoch": 0.008550121126715961,
      "grad_norm": 0.1680772602558136,
      "learning_rate": 9.914498788732841e-06,
      "loss": 0.2729,
      "step": 540
    },
    {
      "epoch": 0.00856595468435803,
      "grad_norm": 0.1620749980211258,
      "learning_rate": 9.91434045315642e-06,
      "loss": 0.1574,
      "step": 541
    },
    {
      "epoch": 0.008581788242000095,
      "grad_norm": 0.21055302023887634,
      "learning_rate": 9.914182117580001e-06,
      "loss": 0.1206,
      "step": 542
    },
    {
      "epoch": 0.008597621799642161,
      "grad_norm": 0.0034190674778074026,
      "learning_rate": 9.914023782003578e-06,
      "loss": 0.0001,
      "step": 543
    },
    {
      "epoch": 0.008613455357284229,
      "grad_norm": 0.35671257972717285,
      "learning_rate": 9.913865446427159e-06,
      "loss": 0.1145,
      "step": 544
    },
    {
      "epoch": 0.008629288914926295,
      "grad_norm": 0.0021180908661335707,
      "learning_rate": 9.913707110850738e-06,
      "loss": 0.0003,
      "step": 545
    },
    {
      "epoch": 0.008645122472568361,
      "grad_norm": 0.10732036828994751,
      "learning_rate": 9.913548775274317e-06,
      "loss": 0.2084,
      "step": 546
    },
    {
      "epoch": 0.008660956030210429,
      "grad_norm": 0.10659465193748474,
      "learning_rate": 9.913390439697896e-06,
      "loss": 0.1242,
      "step": 547
    },
    {
      "epoch": 0.008676789587852495,
      "grad_norm": 0.22552630305290222,
      "learning_rate": 9.913232104121477e-06,
      "loss": 0.2256,
      "step": 548
    },
    {
      "epoch": 0.00869262314549456,
      "grad_norm": 0.22442644834518433,
      "learning_rate": 9.913073768545054e-06,
      "loss": 0.192,
      "step": 549
    },
    {
      "epoch": 0.008708456703136629,
      "grad_norm": 0.17977623641490936,
      "learning_rate": 9.912915432968635e-06,
      "loss": 0.0938,
      "step": 550
    },
    {
      "epoch": 0.008724290260778695,
      "grad_norm": 0.21836748719215393,
      "learning_rate": 9.912757097392214e-06,
      "loss": 0.0735,
      "step": 551
    },
    {
      "epoch": 0.00874012381842076,
      "grad_norm": 0.23047074675559998,
      "learning_rate": 9.912598761815793e-06,
      "loss": 0.234,
      "step": 552
    },
    {
      "epoch": 0.008755957376062828,
      "grad_norm": 0.0007137034554034472,
      "learning_rate": 9.912440426239372e-06,
      "loss": 0.0,
      "step": 553
    },
    {
      "epoch": 0.008771790933704894,
      "grad_norm": 0.11167491972446442,
      "learning_rate": 9.912282090662952e-06,
      "loss": 0.3437,
      "step": 554
    },
    {
      "epoch": 0.00878762449134696,
      "grad_norm": 0.02683841437101364,
      "learning_rate": 9.91212375508653e-06,
      "loss": 0.0035,
      "step": 555
    },
    {
      "epoch": 0.008803458048989026,
      "grad_norm": 0.22801603376865387,
      "learning_rate": 9.91196541951011e-06,
      "loss": 0.3121,
      "step": 556
    },
    {
      "epoch": 0.008819291606631094,
      "grad_norm": 0.31407901644706726,
      "learning_rate": 9.91180708393369e-06,
      "loss": 0.5302,
      "step": 557
    },
    {
      "epoch": 0.00883512516427316,
      "grad_norm": 0.1580042541027069,
      "learning_rate": 9.91164874835727e-06,
      "loss": 0.4226,
      "step": 558
    },
    {
      "epoch": 0.008850958721915226,
      "grad_norm": 0.00048290376435033977,
      "learning_rate": 9.911490412780849e-06,
      "loss": 0.0,
      "step": 559
    },
    {
      "epoch": 0.008866792279557294,
      "grad_norm": 0.1570255160331726,
      "learning_rate": 9.911332077204428e-06,
      "loss": 0.2448,
      "step": 560
    },
    {
      "epoch": 0.00888262583719936,
      "grad_norm": 0.11854482442140579,
      "learning_rate": 9.911173741628007e-06,
      "loss": 0.1133,
      "step": 561
    },
    {
      "epoch": 0.008898459394841426,
      "grad_norm": 0.38206595182418823,
      "learning_rate": 9.911015406051586e-06,
      "loss": 0.3473,
      "step": 562
    },
    {
      "epoch": 0.008914292952483494,
      "grad_norm": 0.0030509568750858307,
      "learning_rate": 9.910857070475167e-06,
      "loss": 0.0002,
      "step": 563
    },
    {
      "epoch": 0.00893012651012556,
      "grad_norm": 0.2144039273262024,
      "learning_rate": 9.910698734898746e-06,
      "loss": 0.2621,
      "step": 564
    },
    {
      "epoch": 0.008945960067767626,
      "grad_norm": 0.33115702867507935,
      "learning_rate": 9.910540399322325e-06,
      "loss": 0.2022,
      "step": 565
    },
    {
      "epoch": 0.008961793625409694,
      "grad_norm": 0.2293154001235962,
      "learning_rate": 9.910382063745904e-06,
      "loss": 0.3069,
      "step": 566
    },
    {
      "epoch": 0.00897762718305176,
      "grad_norm": 0.24360057711601257,
      "learning_rate": 9.910223728169483e-06,
      "loss": 0.241,
      "step": 567
    },
    {
      "epoch": 0.008993460740693826,
      "grad_norm": 0.12641510367393494,
      "learning_rate": 9.910065392593062e-06,
      "loss": 0.1547,
      "step": 568
    },
    {
      "epoch": 0.009009294298335893,
      "grad_norm": 0.3290146589279175,
      "learning_rate": 9.909907057016643e-06,
      "loss": 0.0794,
      "step": 569
    },
    {
      "epoch": 0.00902512785597796,
      "grad_norm": 0.10169757157564163,
      "learning_rate": 9.909748721440222e-06,
      "loss": 0.146,
      "step": 570
    },
    {
      "epoch": 0.009040961413620026,
      "grad_norm": 0.0005475611542351544,
      "learning_rate": 9.909590385863801e-06,
      "loss": 0.0,
      "step": 571
    },
    {
      "epoch": 0.009056794971262093,
      "grad_norm": 0.27528947591781616,
      "learning_rate": 9.90943205028738e-06,
      "loss": 0.6647,
      "step": 572
    },
    {
      "epoch": 0.00907262852890416,
      "grad_norm": 0.11961095035076141,
      "learning_rate": 9.909273714710959e-06,
      "loss": 0.0948,
      "step": 573
    },
    {
      "epoch": 0.009088462086546225,
      "grad_norm": 0.1290542632341385,
      "learning_rate": 9.909115379134538e-06,
      "loss": 0.0452,
      "step": 574
    },
    {
      "epoch": 0.009104295644188293,
      "grad_norm": 0.004359581507742405,
      "learning_rate": 9.908957043558119e-06,
      "loss": 0.0006,
      "step": 575
    },
    {
      "epoch": 0.009120129201830359,
      "grad_norm": 0.842438817024231,
      "learning_rate": 9.908798707981698e-06,
      "loss": 0.1332,
      "step": 576
    },
    {
      "epoch": 0.009135962759472425,
      "grad_norm": 0.15271617472171783,
      "learning_rate": 9.908640372405277e-06,
      "loss": 0.1368,
      "step": 577
    },
    {
      "epoch": 0.009151796317114493,
      "grad_norm": 0.20593339204788208,
      "learning_rate": 9.908482036828856e-06,
      "loss": 0.1061,
      "step": 578
    },
    {
      "epoch": 0.009167629874756559,
      "grad_norm": 0.041886068880558014,
      "learning_rate": 9.908323701252435e-06,
      "loss": 0.0012,
      "step": 579
    },
    {
      "epoch": 0.009183463432398625,
      "grad_norm": 0.15713420510292053,
      "learning_rate": 9.908165365676014e-06,
      "loss": 0.1037,
      "step": 580
    },
    {
      "epoch": 0.009199296990040693,
      "grad_norm": 0.07670062780380249,
      "learning_rate": 9.908007030099593e-06,
      "loss": 0.1153,
      "step": 581
    },
    {
      "epoch": 0.009215130547682759,
      "grad_norm": 0.10249734669923782,
      "learning_rate": 9.907848694523173e-06,
      "loss": 0.1024,
      "step": 582
    },
    {
      "epoch": 0.009230964105324825,
      "grad_norm": 0.32977399230003357,
      "learning_rate": 9.907690358946752e-06,
      "loss": 0.1346,
      "step": 583
    },
    {
      "epoch": 0.009246797662966892,
      "grad_norm": 0.16181613504886627,
      "learning_rate": 9.907532023370332e-06,
      "loss": 0.4391,
      "step": 584
    },
    {
      "epoch": 0.009262631220608959,
      "grad_norm": 0.13735973834991455,
      "learning_rate": 9.907373687793911e-06,
      "loss": 0.1301,
      "step": 585
    },
    {
      "epoch": 0.009278464778251025,
      "grad_norm": 0.19234196841716766,
      "learning_rate": 9.90721535221749e-06,
      "loss": 0.1227,
      "step": 586
    },
    {
      "epoch": 0.009294298335893092,
      "grad_norm": 0.0008679121965542436,
      "learning_rate": 9.90705701664107e-06,
      "loss": 0.0001,
      "step": 587
    },
    {
      "epoch": 0.009310131893535158,
      "grad_norm": 0.007019930053502321,
      "learning_rate": 9.906898681064649e-06,
      "loss": 0.0011,
      "step": 588
    },
    {
      "epoch": 0.009325965451177224,
      "grad_norm": 0.3522869348526001,
      "learning_rate": 9.906740345488228e-06,
      "loss": 0.4563,
      "step": 589
    },
    {
      "epoch": 0.009341799008819292,
      "grad_norm": 0.13088764250278473,
      "learning_rate": 9.906582009911809e-06,
      "loss": 0.0912,
      "step": 590
    },
    {
      "epoch": 0.009357632566461358,
      "grad_norm": 0.007143805734813213,
      "learning_rate": 9.906423674335388e-06,
      "loss": 0.0014,
      "step": 591
    },
    {
      "epoch": 0.009373466124103424,
      "grad_norm": 0.27736997604370117,
      "learning_rate": 9.906265338758967e-06,
      "loss": 0.1457,
      "step": 592
    },
    {
      "epoch": 0.009389299681745492,
      "grad_norm": 0.22913308441638947,
      "learning_rate": 9.906107003182546e-06,
      "loss": 0.3918,
      "step": 593
    },
    {
      "epoch": 0.009405133239387558,
      "grad_norm": 0.03880467265844345,
      "learning_rate": 9.905948667606125e-06,
      "loss": 0.0151,
      "step": 594
    },
    {
      "epoch": 0.009420966797029624,
      "grad_norm": 0.16890734434127808,
      "learning_rate": 9.905790332029704e-06,
      "loss": 0.2169,
      "step": 595
    },
    {
      "epoch": 0.009436800354671692,
      "grad_norm": 0.14732715487480164,
      "learning_rate": 9.905631996453285e-06,
      "loss": 0.4806,
      "step": 596
    },
    {
      "epoch": 0.009452633912313758,
      "grad_norm": 0.12676678597927094,
      "learning_rate": 9.905473660876864e-06,
      "loss": 0.0726,
      "step": 597
    },
    {
      "epoch": 0.009468467469955824,
      "grad_norm": 0.19942253828048706,
      "learning_rate": 9.905315325300443e-06,
      "loss": 0.107,
      "step": 598
    },
    {
      "epoch": 0.009484301027597892,
      "grad_norm": 0.16183370351791382,
      "learning_rate": 9.905156989724022e-06,
      "loss": 0.324,
      "step": 599
    },
    {
      "epoch": 0.009500134585239958,
      "grad_norm": 0.2328149527311325,
      "learning_rate": 9.904998654147601e-06,
      "loss": 0.2967,
      "step": 600
    },
    {
      "epoch": 0.009515968142882024,
      "grad_norm": 0.2233864963054657,
      "learning_rate": 9.90484031857118e-06,
      "loss": 0.2847,
      "step": 601
    },
    {
      "epoch": 0.009531801700524091,
      "grad_norm": 0.004482703283429146,
      "learning_rate": 9.90468198299476e-06,
      "loss": 0.0006,
      "step": 602
    },
    {
      "epoch": 0.009547635258166157,
      "grad_norm": 0.24971868097782135,
      "learning_rate": 9.90452364741834e-06,
      "loss": 0.1247,
      "step": 603
    },
    {
      "epoch": 0.009563468815808223,
      "grad_norm": 0.11665043234825134,
      "learning_rate": 9.904365311841917e-06,
      "loss": 0.0921,
      "step": 604
    },
    {
      "epoch": 0.009579302373450291,
      "grad_norm": 0.3431459367275238,
      "learning_rate": 9.904206976265498e-06,
      "loss": 0.8109,
      "step": 605
    },
    {
      "epoch": 0.009595135931092357,
      "grad_norm": 0.15591225028038025,
      "learning_rate": 9.904048640689077e-06,
      "loss": 0.1872,
      "step": 606
    },
    {
      "epoch": 0.009610969488734423,
      "grad_norm": 0.05753123015165329,
      "learning_rate": 9.903890305112656e-06,
      "loss": 0.0026,
      "step": 607
    },
    {
      "epoch": 0.009626803046376491,
      "grad_norm": 0.22491797804832458,
      "learning_rate": 9.903731969536235e-06,
      "loss": 0.1819,
      "step": 608
    },
    {
      "epoch": 0.009642636604018557,
      "grad_norm": 0.2618364989757538,
      "learning_rate": 9.903573633959816e-06,
      "loss": 0.2785,
      "step": 609
    },
    {
      "epoch": 0.009658470161660623,
      "grad_norm": 0.21224386990070343,
      "learning_rate": 9.903415298383394e-06,
      "loss": 0.1997,
      "step": 610
    },
    {
      "epoch": 0.00967430371930269,
      "grad_norm": 0.22123102843761444,
      "learning_rate": 9.903256962806974e-06,
      "loss": 0.1771,
      "step": 611
    },
    {
      "epoch": 0.009690137276944757,
      "grad_norm": 0.18782861530780792,
      "learning_rate": 9.903098627230553e-06,
      "loss": 0.1108,
      "step": 612
    },
    {
      "epoch": 0.009705970834586823,
      "grad_norm": 0.15224222838878632,
      "learning_rate": 9.902940291654132e-06,
      "loss": 0.263,
      "step": 613
    },
    {
      "epoch": 0.00972180439222889,
      "grad_norm": 0.30735117197036743,
      "learning_rate": 9.902781956077712e-06,
      "loss": 0.7994,
      "step": 614
    },
    {
      "epoch": 0.009737637949870957,
      "grad_norm": 0.000487033132230863,
      "learning_rate": 9.902623620501292e-06,
      "loss": 0.0,
      "step": 615
    },
    {
      "epoch": 0.009753471507513023,
      "grad_norm": 0.13484646379947662,
      "learning_rate": 9.90246528492487e-06,
      "loss": 0.2214,
      "step": 616
    },
    {
      "epoch": 0.00976930506515509,
      "grad_norm": 0.008057071827352047,
      "learning_rate": 9.90230694934845e-06,
      "loss": 0.0011,
      "step": 617
    },
    {
      "epoch": 0.009785138622797156,
      "grad_norm": 0.1489749252796173,
      "learning_rate": 9.90214861377203e-06,
      "loss": 0.0756,
      "step": 618
    },
    {
      "epoch": 0.009800972180439222,
      "grad_norm": 0.5749388337135315,
      "learning_rate": 9.901990278195609e-06,
      "loss": 0.2786,
      "step": 619
    },
    {
      "epoch": 0.00981680573808129,
      "grad_norm": 0.4012594223022461,
      "learning_rate": 9.901831942619188e-06,
      "loss": 0.0342,
      "step": 620
    },
    {
      "epoch": 0.009832639295723356,
      "grad_norm": 0.136914923787117,
      "learning_rate": 9.901673607042768e-06,
      "loss": 0.1563,
      "step": 621
    },
    {
      "epoch": 0.009848472853365422,
      "grad_norm": 0.09799312055110931,
      "learning_rate": 9.901515271466346e-06,
      "loss": 0.0845,
      "step": 622
    },
    {
      "epoch": 0.00986430641100749,
      "grad_norm": 0.25248539447784424,
      "learning_rate": 9.901356935889927e-06,
      "loss": 0.3094,
      "step": 623
    },
    {
      "epoch": 0.009880139968649556,
      "grad_norm": 0.6593313813209534,
      "learning_rate": 9.901198600313506e-06,
      "loss": 0.1174,
      "step": 624
    },
    {
      "epoch": 0.009895973526291622,
      "grad_norm": 0.11892316490411758,
      "learning_rate": 9.901040264737085e-06,
      "loss": 0.462,
      "step": 625
    },
    {
      "epoch": 0.00991180708393369,
      "grad_norm": 0.1580301970243454,
      "learning_rate": 9.900881929160664e-06,
      "loss": 0.2728,
      "step": 626
    },
    {
      "epoch": 0.009927640641575756,
      "grad_norm": 0.13546122610569,
      "learning_rate": 9.900723593584243e-06,
      "loss": 0.0353,
      "step": 627
    },
    {
      "epoch": 0.009943474199217822,
      "grad_norm": 0.1864871084690094,
      "learning_rate": 9.900565258007822e-06,
      "loss": 0.265,
      "step": 628
    },
    {
      "epoch": 0.00995930775685989,
      "grad_norm": 0.05721933767199516,
      "learning_rate": 9.900406922431401e-06,
      "loss": 0.0226,
      "step": 629
    },
    {
      "epoch": 0.009975141314501956,
      "grad_norm": 0.004169785417616367,
      "learning_rate": 9.900248586854982e-06,
      "loss": 0.0005,
      "step": 630
    },
    {
      "epoch": 0.009990974872144022,
      "grad_norm": 0.23123787343502045,
      "learning_rate": 9.900090251278561e-06,
      "loss": 0.4124,
      "step": 631
    },
    {
      "epoch": 0.01000680842978609,
      "grad_norm": 0.13639138638973236,
      "learning_rate": 9.89993191570214e-06,
      "loss": 0.0954,
      "step": 632
    },
    {
      "epoch": 0.010022641987428155,
      "grad_norm": 0.10353206098079681,
      "learning_rate": 9.899773580125719e-06,
      "loss": 0.0463,
      "step": 633
    },
    {
      "epoch": 0.010038475545070221,
      "grad_norm": 0.14749795198440552,
      "learning_rate": 9.899615244549298e-06,
      "loss": 0.2396,
      "step": 634
    },
    {
      "epoch": 0.01005430910271229,
      "grad_norm": 0.27587220072746277,
      "learning_rate": 9.899456908972877e-06,
      "loss": 0.0158,
      "step": 635
    },
    {
      "epoch": 0.010070142660354355,
      "grad_norm": 0.0010060203494504094,
      "learning_rate": 9.899298573396458e-06,
      "loss": 0.0001,
      "step": 636
    },
    {
      "epoch": 0.010085976217996421,
      "grad_norm": 0.09201911836862564,
      "learning_rate": 9.899140237820037e-06,
      "loss": 0.0261,
      "step": 637
    },
    {
      "epoch": 0.010101809775638489,
      "grad_norm": 0.27794814109802246,
      "learning_rate": 9.898981902243616e-06,
      "loss": 0.1537,
      "step": 638
    },
    {
      "epoch": 0.010117643333280555,
      "grad_norm": 0.268767386674881,
      "learning_rate": 9.898823566667195e-06,
      "loss": 0.6924,
      "step": 639
    },
    {
      "epoch": 0.010133476890922621,
      "grad_norm": 0.0719422772526741,
      "learning_rate": 9.898665231090774e-06,
      "loss": 0.0102,
      "step": 640
    },
    {
      "epoch": 0.010149310448564689,
      "grad_norm": 0.12347095459699631,
      "learning_rate": 9.898506895514353e-06,
      "loss": 0.1007,
      "step": 641
    },
    {
      "epoch": 0.010165144006206755,
      "grad_norm": 0.21105365455150604,
      "learning_rate": 9.898348559937934e-06,
      "loss": 0.049,
      "step": 642
    },
    {
      "epoch": 0.01018097756384882,
      "grad_norm": 0.19000674784183502,
      "learning_rate": 9.898190224361512e-06,
      "loss": 0.3048,
      "step": 643
    },
    {
      "epoch": 0.010196811121490889,
      "grad_norm": 0.12041661888360977,
      "learning_rate": 9.898031888785092e-06,
      "loss": 0.0746,
      "step": 644
    },
    {
      "epoch": 0.010212644679132955,
      "grad_norm": 0.13407176733016968,
      "learning_rate": 9.897873553208671e-06,
      "loss": 0.251,
      "step": 645
    },
    {
      "epoch": 0.01022847823677502,
      "grad_norm": 0.20853038132190704,
      "learning_rate": 9.89771521763225e-06,
      "loss": 0.0154,
      "step": 646
    },
    {
      "epoch": 0.010244311794417088,
      "grad_norm": 0.009828821755945683,
      "learning_rate": 9.89755688205583e-06,
      "loss": 0.0013,
      "step": 647
    },
    {
      "epoch": 0.010260145352059154,
      "grad_norm": 0.13567085564136505,
      "learning_rate": 9.89739854647941e-06,
      "loss": 0.1118,
      "step": 648
    },
    {
      "epoch": 0.01027597890970122,
      "grad_norm": 0.15364988148212433,
      "learning_rate": 9.897240210902988e-06,
      "loss": 0.1416,
      "step": 649
    },
    {
      "epoch": 0.010291812467343288,
      "grad_norm": 0.1322309821844101,
      "learning_rate": 9.897081875326567e-06,
      "loss": 0.1385,
      "step": 650
    },
    {
      "epoch": 0.010307646024985354,
      "grad_norm": 0.0007033093716017902,
      "learning_rate": 9.896923539750148e-06,
      "loss": 0.0,
      "step": 651
    },
    {
      "epoch": 0.01032347958262742,
      "grad_norm": 0.1413312405347824,
      "learning_rate": 9.896765204173727e-06,
      "loss": 0.1198,
      "step": 652
    },
    {
      "epoch": 0.010339313140269488,
      "grad_norm": 0.12585343420505524,
      "learning_rate": 9.896606868597306e-06,
      "loss": 0.4183,
      "step": 653
    },
    {
      "epoch": 0.010355146697911554,
      "grad_norm": 0.2081059366464615,
      "learning_rate": 9.896448533020885e-06,
      "loss": 0.2811,
      "step": 654
    },
    {
      "epoch": 0.01037098025555362,
      "grad_norm": 0.20360423624515533,
      "learning_rate": 9.896290197444464e-06,
      "loss": 0.5934,
      "step": 655
    },
    {
      "epoch": 0.010386813813195686,
      "grad_norm": 0.09086161106824875,
      "learning_rate": 9.896131861868043e-06,
      "loss": 0.3371,
      "step": 656
    },
    {
      "epoch": 0.010402647370837754,
      "grad_norm": 0.019334787502884865,
      "learning_rate": 9.895973526291624e-06,
      "loss": 0.0016,
      "step": 657
    },
    {
      "epoch": 0.01041848092847982,
      "grad_norm": 0.2285521924495697,
      "learning_rate": 9.895815190715203e-06,
      "loss": 0.1432,
      "step": 658
    },
    {
      "epoch": 0.010434314486121886,
      "grad_norm": 0.011415368877351284,
      "learning_rate": 9.895656855138782e-06,
      "loss": 0.0012,
      "step": 659
    },
    {
      "epoch": 0.010450148043763954,
      "grad_norm": 0.40031540393829346,
      "learning_rate": 9.895498519562361e-06,
      "loss": 0.772,
      "step": 660
    },
    {
      "epoch": 0.01046598160140602,
      "grad_norm": 0.1311563402414322,
      "learning_rate": 9.89534018398594e-06,
      "loss": 0.1074,
      "step": 661
    },
    {
      "epoch": 0.010481815159048086,
      "grad_norm": 0.0006249173893593252,
      "learning_rate": 9.89518184840952e-06,
      "loss": 0.0,
      "step": 662
    },
    {
      "epoch": 0.010497648716690153,
      "grad_norm": 0.0636143758893013,
      "learning_rate": 9.8950235128331e-06,
      "loss": 0.0098,
      "step": 663
    },
    {
      "epoch": 0.01051348227433222,
      "grad_norm": 0.007976981811225414,
      "learning_rate": 9.894865177256679e-06,
      "loss": 0.0017,
      "step": 664
    },
    {
      "epoch": 0.010529315831974286,
      "grad_norm": 0.07209618389606476,
      "learning_rate": 9.894706841680258e-06,
      "loss": 0.0472,
      "step": 665
    },
    {
      "epoch": 0.010545149389616353,
      "grad_norm": 0.24698317050933838,
      "learning_rate": 9.894548506103837e-06,
      "loss": 0.6915,
      "step": 666
    },
    {
      "epoch": 0.01056098294725842,
      "grad_norm": 0.3060181140899658,
      "learning_rate": 9.894390170527416e-06,
      "loss": 0.3335,
      "step": 667
    },
    {
      "epoch": 0.010576816504900485,
      "grad_norm": 1.1496374607086182,
      "learning_rate": 9.894231834950995e-06,
      "loss": 0.4733,
      "step": 668
    },
    {
      "epoch": 0.010592650062542553,
      "grad_norm": 0.09974686801433563,
      "learning_rate": 9.894073499374576e-06,
      "loss": 0.0406,
      "step": 669
    },
    {
      "epoch": 0.010608483620184619,
      "grad_norm": 0.02144831046462059,
      "learning_rate": 9.893915163798155e-06,
      "loss": 0.0033,
      "step": 670
    },
    {
      "epoch": 0.010624317177826685,
      "grad_norm": 0.011031761765480042,
      "learning_rate": 9.893756828221734e-06,
      "loss": 0.0015,
      "step": 671
    },
    {
      "epoch": 0.010640150735468753,
      "grad_norm": 0.2079346925020218,
      "learning_rate": 9.893598492645313e-06,
      "loss": 0.5336,
      "step": 672
    },
    {
      "epoch": 0.010655984293110819,
      "grad_norm": 0.08365631103515625,
      "learning_rate": 9.893440157068892e-06,
      "loss": 0.0519,
      "step": 673
    },
    {
      "epoch": 0.010671817850752885,
      "grad_norm": 0.11199688166379929,
      "learning_rate": 9.893281821492472e-06,
      "loss": 0.0829,
      "step": 674
    },
    {
      "epoch": 0.010687651408394953,
      "grad_norm": 0.09391134232282639,
      "learning_rate": 9.89312348591605e-06,
      "loss": 0.1241,
      "step": 675
    },
    {
      "epoch": 0.010703484966037019,
      "grad_norm": 0.0004732778179459274,
      "learning_rate": 9.892965150339631e-06,
      "loss": 0.0,
      "step": 676
    },
    {
      "epoch": 0.010719318523679085,
      "grad_norm": 0.11590702086687088,
      "learning_rate": 9.892806814763209e-06,
      "loss": 0.4718,
      "step": 677
    },
    {
      "epoch": 0.010735152081321152,
      "grad_norm": 0.1207687258720398,
      "learning_rate": 9.89264847918679e-06,
      "loss": 0.1115,
      "step": 678
    },
    {
      "epoch": 0.010750985638963219,
      "grad_norm": 0.014555007219314575,
      "learning_rate": 9.892490143610369e-06,
      "loss": 0.0035,
      "step": 679
    },
    {
      "epoch": 0.010766819196605285,
      "grad_norm": 0.00334149575792253,
      "learning_rate": 9.892331808033948e-06,
      "loss": 0.0005,
      "step": 680
    },
    {
      "epoch": 0.010782652754247352,
      "grad_norm": 0.000600659113842994,
      "learning_rate": 9.892173472457527e-06,
      "loss": 0.0,
      "step": 681
    },
    {
      "epoch": 0.010798486311889418,
      "grad_norm": 0.15534961223602295,
      "learning_rate": 9.892015136881108e-06,
      "loss": 0.0659,
      "step": 682
    },
    {
      "epoch": 0.010814319869531484,
      "grad_norm": 0.16013476252555847,
      "learning_rate": 9.891856801304685e-06,
      "loss": 0.3372,
      "step": 683
    },
    {
      "epoch": 0.010830153427173552,
      "grad_norm": 0.16107335686683655,
      "learning_rate": 9.891698465728266e-06,
      "loss": 0.1404,
      "step": 684
    },
    {
      "epoch": 0.010845986984815618,
      "grad_norm": 0.03416791185736656,
      "learning_rate": 9.891540130151845e-06,
      "loss": 0.0013,
      "step": 685
    },
    {
      "epoch": 0.010861820542457684,
      "grad_norm": 0.012790314853191376,
      "learning_rate": 9.891381794575424e-06,
      "loss": 0.0019,
      "step": 686
    },
    {
      "epoch": 0.010877654100099752,
      "grad_norm": 0.30667737126350403,
      "learning_rate": 9.891223458999003e-06,
      "loss": 0.0568,
      "step": 687
    },
    {
      "epoch": 0.010893487657741818,
      "grad_norm": 0.2725077271461487,
      "learning_rate": 9.891065123422584e-06,
      "loss": 0.7008,
      "step": 688
    },
    {
      "epoch": 0.010909321215383884,
      "grad_norm": 0.1523822695016861,
      "learning_rate": 9.890906787846161e-06,
      "loss": 0.0857,
      "step": 689
    },
    {
      "epoch": 0.010925154773025952,
      "grad_norm": 0.3014080226421356,
      "learning_rate": 9.890748452269742e-06,
      "loss": 1.5885,
      "step": 690
    },
    {
      "epoch": 0.010940988330668018,
      "grad_norm": 0.002539721317589283,
      "learning_rate": 9.890590116693321e-06,
      "loss": 0.0,
      "step": 691
    },
    {
      "epoch": 0.010956821888310084,
      "grad_norm": 0.1444011926651001,
      "learning_rate": 9.8904317811169e-06,
      "loss": 0.1931,
      "step": 692
    },
    {
      "epoch": 0.010972655445952152,
      "grad_norm": 0.09293606877326965,
      "learning_rate": 9.890273445540479e-06,
      "loss": 0.1245,
      "step": 693
    },
    {
      "epoch": 0.010988489003594218,
      "grad_norm": 0.025914473459124565,
      "learning_rate": 9.89011510996406e-06,
      "loss": 0.0101,
      "step": 694
    },
    {
      "epoch": 0.011004322561236284,
      "grad_norm": 0.1903005689382553,
      "learning_rate": 9.889956774387637e-06,
      "loss": 0.2909,
      "step": 695
    },
    {
      "epoch": 0.011020156118878351,
      "grad_norm": 0.20134001970291138,
      "learning_rate": 9.889798438811218e-06,
      "loss": 0.3532,
      "step": 696
    },
    {
      "epoch": 0.011035989676520417,
      "grad_norm": 0.5187063217163086,
      "learning_rate": 9.889640103234797e-06,
      "loss": 0.385,
      "step": 697
    },
    {
      "epoch": 0.011051823234162483,
      "grad_norm": 0.47729408740997314,
      "learning_rate": 9.889481767658376e-06,
      "loss": 0.0903,
      "step": 698
    },
    {
      "epoch": 0.011067656791804551,
      "grad_norm": 0.2061307728290558,
      "learning_rate": 9.889323432081955e-06,
      "loss": 0.4348,
      "step": 699
    },
    {
      "epoch": 0.011083490349446617,
      "grad_norm": 0.3189311623573303,
      "learning_rate": 9.889165096505534e-06,
      "loss": 0.2685,
      "step": 700
    },
    {
      "epoch": 0.011099323907088683,
      "grad_norm": 0.3883686065673828,
      "learning_rate": 9.889006760929113e-06,
      "loss": 0.182,
      "step": 701
    },
    {
      "epoch": 0.011115157464730751,
      "grad_norm": 0.22419032454490662,
      "learning_rate": 9.888848425352693e-06,
      "loss": 0.0686,
      "step": 702
    },
    {
      "epoch": 0.011130991022372817,
      "grad_norm": 0.9490784406661987,
      "learning_rate": 9.888690089776273e-06,
      "loss": 0.3189,
      "step": 703
    },
    {
      "epoch": 0.011146824580014883,
      "grad_norm": 0.3470587134361267,
      "learning_rate": 9.888531754199852e-06,
      "loss": 0.1475,
      "step": 704
    },
    {
      "epoch": 0.01116265813765695,
      "grad_norm": 0.004022796172648668,
      "learning_rate": 9.888373418623431e-06,
      "loss": 0.0005,
      "step": 705
    },
    {
      "epoch": 0.011178491695299017,
      "grad_norm": 0.0008399140206165612,
      "learning_rate": 9.88821508304701e-06,
      "loss": 0.0,
      "step": 706
    },
    {
      "epoch": 0.011194325252941083,
      "grad_norm": 0.17178186774253845,
      "learning_rate": 9.88805674747059e-06,
      "loss": 0.2027,
      "step": 707
    },
    {
      "epoch": 0.01121015881058315,
      "grad_norm": 0.1331586241722107,
      "learning_rate": 9.887898411894169e-06,
      "loss": 0.3581,
      "step": 708
    },
    {
      "epoch": 0.011225992368225217,
      "grad_norm": 0.26027965545654297,
      "learning_rate": 9.88774007631775e-06,
      "loss": 0.197,
      "step": 709
    },
    {
      "epoch": 0.011241825925867283,
      "grad_norm": 0.10797062516212463,
      "learning_rate": 9.887581740741327e-06,
      "loss": 0.0415,
      "step": 710
    },
    {
      "epoch": 0.01125765948350935,
      "grad_norm": 0.011348539963364601,
      "learning_rate": 9.887423405164908e-06,
      "loss": 0.0008,
      "step": 711
    },
    {
      "epoch": 0.011273493041151416,
      "grad_norm": 0.02176702953875065,
      "learning_rate": 9.887265069588487e-06,
      "loss": 0.0043,
      "step": 712
    },
    {
      "epoch": 0.011289326598793482,
      "grad_norm": 0.09069015085697174,
      "learning_rate": 9.887106734012066e-06,
      "loss": 0.0079,
      "step": 713
    },
    {
      "epoch": 0.01130516015643555,
      "grad_norm": 0.12679822742938995,
      "learning_rate": 9.886948398435645e-06,
      "loss": 0.0778,
      "step": 714
    },
    {
      "epoch": 0.011320993714077616,
      "grad_norm": 0.11488168686628342,
      "learning_rate": 9.886790062859226e-06,
      "loss": 0.3441,
      "step": 715
    },
    {
      "epoch": 0.011336827271719682,
      "grad_norm": 0.308884859085083,
      "learning_rate": 9.886631727282803e-06,
      "loss": 0.1672,
      "step": 716
    },
    {
      "epoch": 0.01135266082936175,
      "grad_norm": 0.4225795269012451,
      "learning_rate": 9.886473391706384e-06,
      "loss": 0.666,
      "step": 717
    },
    {
      "epoch": 0.011368494387003816,
      "grad_norm": 0.006300037726759911,
      "learning_rate": 9.886315056129963e-06,
      "loss": 0.0009,
      "step": 718
    },
    {
      "epoch": 0.011384327944645882,
      "grad_norm": 0.18215878307819366,
      "learning_rate": 9.886156720553542e-06,
      "loss": 0.3581,
      "step": 719
    },
    {
      "epoch": 0.01140016150228795,
      "grad_norm": 0.21029339730739594,
      "learning_rate": 9.885998384977121e-06,
      "loss": 0.0996,
      "step": 720
    },
    {
      "epoch": 0.011415995059930016,
      "grad_norm": 0.700093150138855,
      "learning_rate": 9.885840049400702e-06,
      "loss": 0.0944,
      "step": 721
    },
    {
      "epoch": 0.011431828617572082,
      "grad_norm": 0.0002973829105030745,
      "learning_rate": 9.88568171382428e-06,
      "loss": 0.0,
      "step": 722
    },
    {
      "epoch": 0.01144766217521415,
      "grad_norm": 0.18251781165599823,
      "learning_rate": 9.885523378247858e-06,
      "loss": 0.2192,
      "step": 723
    },
    {
      "epoch": 0.011463495732856216,
      "grad_norm": 0.09082294255495071,
      "learning_rate": 9.885365042671439e-06,
      "loss": 0.0058,
      "step": 724
    },
    {
      "epoch": 0.011479329290498282,
      "grad_norm": 0.006589248310774565,
      "learning_rate": 9.885206707095018e-06,
      "loss": 0.0008,
      "step": 725
    },
    {
      "epoch": 0.01149516284814035,
      "grad_norm": 0.1214446872472763,
      "learning_rate": 9.885048371518597e-06,
      "loss": 0.5981,
      "step": 726
    },
    {
      "epoch": 0.011510996405782415,
      "grad_norm": 0.2869561016559601,
      "learning_rate": 9.884890035942176e-06,
      "loss": 0.0165,
      "step": 727
    },
    {
      "epoch": 0.011526829963424481,
      "grad_norm": 0.12903371453285217,
      "learning_rate": 9.884731700365755e-06,
      "loss": 0.3896,
      "step": 728
    },
    {
      "epoch": 0.01154266352106655,
      "grad_norm": 0.11257928609848022,
      "learning_rate": 9.884573364789334e-06,
      "loss": 0.1107,
      "step": 729
    },
    {
      "epoch": 0.011558497078708615,
      "grad_norm": 0.061468563973903656,
      "learning_rate": 9.884415029212915e-06,
      "loss": 0.0124,
      "step": 730
    },
    {
      "epoch": 0.011574330636350681,
      "grad_norm": 0.00031541037606075406,
      "learning_rate": 9.884256693636494e-06,
      "loss": 0.0,
      "step": 731
    },
    {
      "epoch": 0.011590164193992749,
      "grad_norm": 0.3023359179496765,
      "learning_rate": 9.884098358060073e-06,
      "loss": 0.1972,
      "step": 732
    },
    {
      "epoch": 0.011605997751634815,
      "grad_norm": 0.1714288741350174,
      "learning_rate": 9.883940022483652e-06,
      "loss": 0.1304,
      "step": 733
    },
    {
      "epoch": 0.011621831309276881,
      "grad_norm": 0.09699272364377975,
      "learning_rate": 9.883781686907232e-06,
      "loss": 0.0821,
      "step": 734
    },
    {
      "epoch": 0.011637664866918949,
      "grad_norm": 0.00037757668178528547,
      "learning_rate": 9.88362335133081e-06,
      "loss": 0.0,
      "step": 735
    },
    {
      "epoch": 0.011653498424561015,
      "grad_norm": 0.33370402455329895,
      "learning_rate": 9.883465015754391e-06,
      "loss": 0.3153,
      "step": 736
    },
    {
      "epoch": 0.01166933198220308,
      "grad_norm": 0.08093868941068649,
      "learning_rate": 9.88330668017797e-06,
      "loss": 0.1146,
      "step": 737
    },
    {
      "epoch": 0.011685165539845149,
      "grad_norm": 0.3348827362060547,
      "learning_rate": 9.88314834460155e-06,
      "loss": 0.1201,
      "step": 738
    },
    {
      "epoch": 0.011700999097487215,
      "grad_norm": 0.6770622134208679,
      "learning_rate": 9.882990009025129e-06,
      "loss": 0.6745,
      "step": 739
    },
    {
      "epoch": 0.01171683265512928,
      "grad_norm": 0.7026774883270264,
      "learning_rate": 9.882831673448708e-06,
      "loss": 0.2279,
      "step": 740
    },
    {
      "epoch": 0.011732666212771348,
      "grad_norm": 0.1505044847726822,
      "learning_rate": 9.882673337872287e-06,
      "loss": 0.1022,
      "step": 741
    },
    {
      "epoch": 0.011748499770413414,
      "grad_norm": 0.20799358189105988,
      "learning_rate": 9.882515002295868e-06,
      "loss": 0.2152,
      "step": 742
    },
    {
      "epoch": 0.01176433332805548,
      "grad_norm": 0.16184400022029877,
      "learning_rate": 9.882356666719447e-06,
      "loss": 0.125,
      "step": 743
    },
    {
      "epoch": 0.011780166885697548,
      "grad_norm": 0.002826302545145154,
      "learning_rate": 9.882198331143026e-06,
      "loss": 0.0005,
      "step": 744
    },
    {
      "epoch": 0.011796000443339614,
      "grad_norm": 0.02155025489628315,
      "learning_rate": 9.882039995566605e-06,
      "loss": 0.0005,
      "step": 745
    },
    {
      "epoch": 0.01181183400098168,
      "grad_norm": 0.013735217042267323,
      "learning_rate": 9.881881659990184e-06,
      "loss": 0.0017,
      "step": 746
    },
    {
      "epoch": 0.011827667558623748,
      "grad_norm": 0.3179418742656708,
      "learning_rate": 9.881723324413763e-06,
      "loss": 0.1589,
      "step": 747
    },
    {
      "epoch": 0.011843501116265814,
      "grad_norm": 0.3097347319126129,
      "learning_rate": 9.881564988837342e-06,
      "loss": 0.5523,
      "step": 748
    },
    {
      "epoch": 0.01185933467390788,
      "grad_norm": 0.4108816087245941,
      "learning_rate": 9.881406653260923e-06,
      "loss": 0.1773,
      "step": 749
    },
    {
      "epoch": 0.011875168231549948,
      "grad_norm": 0.004062117543071508,
      "learning_rate": 9.8812483176845e-06,
      "loss": 0.0002,
      "step": 750
    },
    {
      "epoch": 0.011891001789192014,
      "grad_norm": 0.03686654567718506,
      "learning_rate": 9.881089982108081e-06,
      "loss": 0.003,
      "step": 751
    },
    {
      "epoch": 0.01190683534683408,
      "grad_norm": 0.023513400927186012,
      "learning_rate": 9.88093164653166e-06,
      "loss": 0.0031,
      "step": 752
    },
    {
      "epoch": 0.011922668904476148,
      "grad_norm": 0.203761488199234,
      "learning_rate": 9.88077331095524e-06,
      "loss": 0.64,
      "step": 753
    },
    {
      "epoch": 0.011938502462118214,
      "grad_norm": 0.11818791180849075,
      "learning_rate": 9.880614975378818e-06,
      "loss": 0.4015,
      "step": 754
    },
    {
      "epoch": 0.01195433601976028,
      "grad_norm": 0.3849150538444519,
      "learning_rate": 9.880456639802399e-06,
      "loss": 0.1949,
      "step": 755
    },
    {
      "epoch": 0.011970169577402346,
      "grad_norm": 0.015458697453141212,
      "learning_rate": 9.880298304225976e-06,
      "loss": 0.001,
      "step": 756
    },
    {
      "epoch": 0.011986003135044413,
      "grad_norm": 0.24676689505577087,
      "learning_rate": 9.880139968649557e-06,
      "loss": 0.6185,
      "step": 757
    },
    {
      "epoch": 0.01200183669268648,
      "grad_norm": 0.1876205950975418,
      "learning_rate": 9.879981633073136e-06,
      "loss": 0.1862,
      "step": 758
    },
    {
      "epoch": 0.012017670250328545,
      "grad_norm": 0.25310665369033813,
      "learning_rate": 9.879823297496715e-06,
      "loss": 0.6786,
      "step": 759
    },
    {
      "epoch": 0.012033503807970613,
      "grad_norm": 0.1661648005247116,
      "learning_rate": 9.879664961920294e-06,
      "loss": 0.2675,
      "step": 760
    },
    {
      "epoch": 0.01204933736561268,
      "grad_norm": 0.014966050162911415,
      "learning_rate": 9.879506626343875e-06,
      "loss": 0.0021,
      "step": 761
    },
    {
      "epoch": 0.012065170923254745,
      "grad_norm": 0.14396418631076813,
      "learning_rate": 9.879348290767453e-06,
      "loss": 0.1632,
      "step": 762
    },
    {
      "epoch": 0.012081004480896813,
      "grad_norm": 0.16464030742645264,
      "learning_rate": 9.879189955191033e-06,
      "loss": 0.0659,
      "step": 763
    },
    {
      "epoch": 0.012096838038538879,
      "grad_norm": 0.09436269104480743,
      "learning_rate": 9.879031619614612e-06,
      "loss": 0.1048,
      "step": 764
    },
    {
      "epoch": 0.012112671596180945,
      "grad_norm": 0.055303145200014114,
      "learning_rate": 9.878873284038191e-06,
      "loss": 0.0246,
      "step": 765
    },
    {
      "epoch": 0.012128505153823013,
      "grad_norm": 0.1969558596611023,
      "learning_rate": 9.87871494846177e-06,
      "loss": 0.2399,
      "step": 766
    },
    {
      "epoch": 0.012144338711465079,
      "grad_norm": 0.0033078480046242476,
      "learning_rate": 9.878556612885351e-06,
      "loss": 0.0001,
      "step": 767
    },
    {
      "epoch": 0.012160172269107145,
      "grad_norm": 0.1355588287115097,
      "learning_rate": 9.878398277308929e-06,
      "loss": 0.0709,
      "step": 768
    },
    {
      "epoch": 0.012176005826749213,
      "grad_norm": 0.11788182705640793,
      "learning_rate": 9.87823994173251e-06,
      "loss": 0.0821,
      "step": 769
    },
    {
      "epoch": 0.012191839384391279,
      "grad_norm": 0.0023887534625828266,
      "learning_rate": 9.878081606156089e-06,
      "loss": 0.0001,
      "step": 770
    },
    {
      "epoch": 0.012207672942033345,
      "grad_norm": 0.13075613975524902,
      "learning_rate": 9.877923270579668e-06,
      "loss": 0.3348,
      "step": 771
    },
    {
      "epoch": 0.012223506499675412,
      "grad_norm": 0.8403295278549194,
      "learning_rate": 9.877764935003247e-06,
      "loss": 0.1434,
      "step": 772
    },
    {
      "epoch": 0.012239340057317478,
      "grad_norm": 0.2810913622379303,
      "learning_rate": 9.877606599426826e-06,
      "loss": 0.2209,
      "step": 773
    },
    {
      "epoch": 0.012255173614959545,
      "grad_norm": 0.15633924305438995,
      "learning_rate": 9.877448263850405e-06,
      "loss": 0.0729,
      "step": 774
    },
    {
      "epoch": 0.012271007172601612,
      "grad_norm": 0.15734414756298065,
      "learning_rate": 9.877289928273984e-06,
      "loss": 0.4002,
      "step": 775
    },
    {
      "epoch": 0.012286840730243678,
      "grad_norm": 0.15567202866077423,
      "learning_rate": 9.877131592697565e-06,
      "loss": 0.3765,
      "step": 776
    },
    {
      "epoch": 0.012302674287885744,
      "grad_norm": 0.18091288208961487,
      "learning_rate": 9.876973257121142e-06,
      "loss": 0.8215,
      "step": 777
    },
    {
      "epoch": 0.012318507845527812,
      "grad_norm": 0.372118204832077,
      "learning_rate": 9.876814921544723e-06,
      "loss": 0.1915,
      "step": 778
    },
    {
      "epoch": 0.012334341403169878,
      "grad_norm": 0.24423159658908844,
      "learning_rate": 9.876656585968302e-06,
      "loss": 0.0908,
      "step": 779
    },
    {
      "epoch": 0.012350174960811944,
      "grad_norm": 0.0007880999473854899,
      "learning_rate": 9.876498250391881e-06,
      "loss": 0.0,
      "step": 780
    },
    {
      "epoch": 0.012366008518454012,
      "grad_norm": 0.16098329424858093,
      "learning_rate": 9.87633991481546e-06,
      "loss": 0.436,
      "step": 781
    },
    {
      "epoch": 0.012381842076096078,
      "grad_norm": 0.24300283193588257,
      "learning_rate": 9.876181579239041e-06,
      "loss": 0.2251,
      "step": 782
    },
    {
      "epoch": 0.012397675633738144,
      "grad_norm": 0.18720002472400665,
      "learning_rate": 9.876023243662618e-06,
      "loss": 0.0805,
      "step": 783
    },
    {
      "epoch": 0.012413509191380212,
      "grad_norm": 0.16914844512939453,
      "learning_rate": 9.875864908086199e-06,
      "loss": 0.5029,
      "step": 784
    },
    {
      "epoch": 0.012429342749022278,
      "grad_norm": 0.29408371448516846,
      "learning_rate": 9.875706572509778e-06,
      "loss": 0.5636,
      "step": 785
    },
    {
      "epoch": 0.012445176306664344,
      "grad_norm": 0.004040357191115618,
      "learning_rate": 9.875548236933357e-06,
      "loss": 0.0001,
      "step": 786
    },
    {
      "epoch": 0.012461009864306411,
      "grad_norm": 0.3523278832435608,
      "learning_rate": 9.875389901356936e-06,
      "loss": 0.3411,
      "step": 787
    },
    {
      "epoch": 0.012476843421948478,
      "grad_norm": 0.1286684274673462,
      "learning_rate": 9.875231565780517e-06,
      "loss": 0.1203,
      "step": 788
    },
    {
      "epoch": 0.012492676979590544,
      "grad_norm": 0.10025297850370407,
      "learning_rate": 9.875073230204094e-06,
      "loss": 0.0456,
      "step": 789
    },
    {
      "epoch": 0.012508510537232611,
      "grad_norm": 0.4225686490535736,
      "learning_rate": 9.874914894627675e-06,
      "loss": 0.1145,
      "step": 790
    },
    {
      "epoch": 0.012524344094874677,
      "grad_norm": 0.14524388313293457,
      "learning_rate": 9.874756559051254e-06,
      "loss": 0.0579,
      "step": 791
    },
    {
      "epoch": 0.012540177652516743,
      "grad_norm": 0.17208006978034973,
      "learning_rate": 9.874598223474833e-06,
      "loss": 0.3313,
      "step": 792
    },
    {
      "epoch": 0.012556011210158811,
      "grad_norm": 0.2834396958351135,
      "learning_rate": 9.874439887898413e-06,
      "loss": 0.0179,
      "step": 793
    },
    {
      "epoch": 0.012571844767800877,
      "grad_norm": 0.23674432933330536,
      "learning_rate": 9.874281552321992e-06,
      "loss": 0.3018,
      "step": 794
    },
    {
      "epoch": 0.012587678325442943,
      "grad_norm": 0.24835152924060822,
      "learning_rate": 9.87412321674557e-06,
      "loss": 0.246,
      "step": 795
    },
    {
      "epoch": 0.012603511883085011,
      "grad_norm": 0.4167848825454712,
      "learning_rate": 9.87396488116915e-06,
      "loss": 0.5032,
      "step": 796
    },
    {
      "epoch": 0.012619345440727077,
      "grad_norm": 0.05355679243803024,
      "learning_rate": 9.87380654559273e-06,
      "loss": 0.0052,
      "step": 797
    },
    {
      "epoch": 0.012635178998369143,
      "grad_norm": 0.16873395442962646,
      "learning_rate": 9.87364821001631e-06,
      "loss": 0.2106,
      "step": 798
    },
    {
      "epoch": 0.01265101255601121,
      "grad_norm": 0.0010185912251472473,
      "learning_rate": 9.873489874439889e-06,
      "loss": 0.0,
      "step": 799
    },
    {
      "epoch": 0.012666846113653277,
      "grad_norm": 0.031452476978302,
      "learning_rate": 9.873331538863468e-06,
      "loss": 0.0045,
      "step": 800
    },
    {
      "epoch": 0.012682679671295343,
      "grad_norm": 0.25817736983299255,
      "learning_rate": 9.873173203287047e-06,
      "loss": 0.7794,
      "step": 801
    },
    {
      "epoch": 0.01269851322893741,
      "grad_norm": 0.005121726077049971,
      "learning_rate": 9.873014867710626e-06,
      "loss": 0.0005,
      "step": 802
    },
    {
      "epoch": 0.012714346786579477,
      "grad_norm": 0.01921714097261429,
      "learning_rate": 9.872856532134207e-06,
      "loss": 0.0022,
      "step": 803
    },
    {
      "epoch": 0.012730180344221543,
      "grad_norm": 0.00034688360756263137,
      "learning_rate": 9.872698196557786e-06,
      "loss": 0.0,
      "step": 804
    },
    {
      "epoch": 0.01274601390186361,
      "grad_norm": 0.823332667350769,
      "learning_rate": 9.872539860981365e-06,
      "loss": 0.3205,
      "step": 805
    },
    {
      "epoch": 0.012761847459505676,
      "grad_norm": 0.20351813733577728,
      "learning_rate": 9.872381525404944e-06,
      "loss": 0.0646,
      "step": 806
    },
    {
      "epoch": 0.012777681017147742,
      "grad_norm": 0.2882081866264343,
      "learning_rate": 9.872223189828523e-06,
      "loss": 0.2307,
      "step": 807
    },
    {
      "epoch": 0.01279351457478981,
      "grad_norm": 0.25344979763031006,
      "learning_rate": 9.872064854252102e-06,
      "loss": 0.3571,
      "step": 808
    },
    {
      "epoch": 0.012809348132431876,
      "grad_norm": 0.30762970447540283,
      "learning_rate": 9.871906518675683e-06,
      "loss": 0.0876,
      "step": 809
    },
    {
      "epoch": 0.012825181690073942,
      "grad_norm": 0.30692043900489807,
      "learning_rate": 9.871748183099262e-06,
      "loss": 0.7638,
      "step": 810
    },
    {
      "epoch": 0.01284101524771601,
      "grad_norm": 0.17507924139499664,
      "learning_rate": 9.871589847522841e-06,
      "loss": 0.117,
      "step": 811
    },
    {
      "epoch": 0.012856848805358076,
      "grad_norm": 0.0001772078830981627,
      "learning_rate": 9.87143151194642e-06,
      "loss": 0.0,
      "step": 812
    },
    {
      "epoch": 0.012872682363000142,
      "grad_norm": 0.20068618655204773,
      "learning_rate": 9.87127317637e-06,
      "loss": 0.264,
      "step": 813
    },
    {
      "epoch": 0.01288851592064221,
      "grad_norm": 0.16057434678077698,
      "learning_rate": 9.871114840793578e-06,
      "loss": 0.2793,
      "step": 814
    },
    {
      "epoch": 0.012904349478284276,
      "grad_norm": 0.02194494940340519,
      "learning_rate": 9.870956505217159e-06,
      "loss": 0.0031,
      "step": 815
    },
    {
      "epoch": 0.012920183035926342,
      "grad_norm": 0.09580826014280319,
      "learning_rate": 9.870798169640738e-06,
      "loss": 0.0463,
      "step": 816
    },
    {
      "epoch": 0.01293601659356841,
      "grad_norm": 0.05214225500822067,
      "learning_rate": 9.870639834064317e-06,
      "loss": 0.0445,
      "step": 817
    },
    {
      "epoch": 0.012951850151210476,
      "grad_norm": 0.23591375350952148,
      "learning_rate": 9.870481498487896e-06,
      "loss": 0.2149,
      "step": 818
    },
    {
      "epoch": 0.012967683708852542,
      "grad_norm": 0.6041731834411621,
      "learning_rate": 9.870323162911475e-06,
      "loss": 0.5746,
      "step": 819
    },
    {
      "epoch": 0.01298351726649461,
      "grad_norm": 0.14000079035758972,
      "learning_rate": 9.870164827335054e-06,
      "loss": 0.0651,
      "step": 820
    },
    {
      "epoch": 0.012999350824136675,
      "grad_norm": 0.2673950493335724,
      "learning_rate": 9.870006491758634e-06,
      "loss": 0.2583,
      "step": 821
    },
    {
      "epoch": 0.013015184381778741,
      "grad_norm": 0.018329543992877007,
      "learning_rate": 9.869848156182214e-06,
      "loss": 0.0023,
      "step": 822
    },
    {
      "epoch": 0.01303101793942081,
      "grad_norm": 0.2700289785861969,
      "learning_rate": 9.869689820605792e-06,
      "loss": 0.1267,
      "step": 823
    },
    {
      "epoch": 0.013046851497062875,
      "grad_norm": 0.14938269555568695,
      "learning_rate": 9.869531485029372e-06,
      "loss": 0.1115,
      "step": 824
    },
    {
      "epoch": 0.013062685054704941,
      "grad_norm": 0.13691702485084534,
      "learning_rate": 9.869373149452952e-06,
      "loss": 0.233,
      "step": 825
    },
    {
      "epoch": 0.013078518612347009,
      "grad_norm": 0.17819033563137054,
      "learning_rate": 9.86921481387653e-06,
      "loss": 0.3792,
      "step": 826
    },
    {
      "epoch": 0.013094352169989075,
      "grad_norm": 0.1259356588125229,
      "learning_rate": 9.86905647830011e-06,
      "loss": 0.1003,
      "step": 827
    },
    {
      "epoch": 0.013110185727631141,
      "grad_norm": 0.30765867233276367,
      "learning_rate": 9.86889814272369e-06,
      "loss": 0.2696,
      "step": 828
    },
    {
      "epoch": 0.013126019285273209,
      "grad_norm": 0.13274015486240387,
      "learning_rate": 9.868739807147268e-06,
      "loss": 0.3086,
      "step": 829
    },
    {
      "epoch": 0.013141852842915275,
      "grad_norm": 0.0014494581846520305,
      "learning_rate": 9.868581471570849e-06,
      "loss": 0.0001,
      "step": 830
    },
    {
      "epoch": 0.01315768640055734,
      "grad_norm": 0.15983375906944275,
      "learning_rate": 9.868423135994428e-06,
      "loss": 0.0843,
      "step": 831
    },
    {
      "epoch": 0.013173519958199409,
      "grad_norm": 0.16698789596557617,
      "learning_rate": 9.868264800418007e-06,
      "loss": 0.1741,
      "step": 832
    },
    {
      "epoch": 0.013189353515841475,
      "grad_norm": 0.11725477874279022,
      "learning_rate": 9.868106464841586e-06,
      "loss": 0.1108,
      "step": 833
    },
    {
      "epoch": 0.01320518707348354,
      "grad_norm": 0.1650470495223999,
      "learning_rate": 9.867948129265165e-06,
      "loss": 0.11,
      "step": 834
    },
    {
      "epoch": 0.013221020631125608,
      "grad_norm": 0.1555768847465515,
      "learning_rate": 9.867789793688744e-06,
      "loss": 0.0393,
      "step": 835
    },
    {
      "epoch": 0.013236854188767674,
      "grad_norm": 0.13792107999324799,
      "learning_rate": 9.867631458112325e-06,
      "loss": 0.0654,
      "step": 836
    },
    {
      "epoch": 0.01325268774640974,
      "grad_norm": 0.11732828617095947,
      "learning_rate": 9.867473122535904e-06,
      "loss": 0.1009,
      "step": 837
    },
    {
      "epoch": 0.013268521304051808,
      "grad_norm": 0.13270403444766998,
      "learning_rate": 9.867314786959483e-06,
      "loss": 0.1506,
      "step": 838
    },
    {
      "epoch": 0.013284354861693874,
      "grad_norm": 0.002806274453178048,
      "learning_rate": 9.867156451383062e-06,
      "loss": 0.0001,
      "step": 839
    },
    {
      "epoch": 0.01330018841933594,
      "grad_norm": 0.0020325074438005686,
      "learning_rate": 9.866998115806641e-06,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 0.013316021976978008,
      "grad_norm": 0.26140642166137695,
      "learning_rate": 9.86683978023022e-06,
      "loss": 0.2087,
      "step": 841
    },
    {
      "epoch": 0.013331855534620074,
      "grad_norm": 0.23854094743728638,
      "learning_rate": 9.866681444653801e-06,
      "loss": 0.1913,
      "step": 842
    },
    {
      "epoch": 0.01334768909226214,
      "grad_norm": 0.16999614238739014,
      "learning_rate": 9.86652310907738e-06,
      "loss": 0.1028,
      "step": 843
    },
    {
      "epoch": 0.013363522649904208,
      "grad_norm": 0.0005182767054066062,
      "learning_rate": 9.866364773500957e-06,
      "loss": 0.0,
      "step": 844
    },
    {
      "epoch": 0.013379356207546274,
      "grad_norm": 0.10831165313720703,
      "learning_rate": 9.866206437924538e-06,
      "loss": 0.0426,
      "step": 845
    },
    {
      "epoch": 0.01339518976518834,
      "grad_norm": 0.013771072030067444,
      "learning_rate": 9.866048102348117e-06,
      "loss": 0.0017,
      "step": 846
    },
    {
      "epoch": 0.013411023322830408,
      "grad_norm": 0.10882890224456787,
      "learning_rate": 9.865889766771696e-06,
      "loss": 0.3139,
      "step": 847
    },
    {
      "epoch": 0.013426856880472474,
      "grad_norm": 0.12245538085699081,
      "learning_rate": 9.865731431195275e-06,
      "loss": 0.066,
      "step": 848
    },
    {
      "epoch": 0.01344269043811454,
      "grad_norm": 0.002820781199261546,
      "learning_rate": 9.865573095618856e-06,
      "loss": 0.0001,
      "step": 849
    },
    {
      "epoch": 0.013458523995756607,
      "grad_norm": 0.32129499316215515,
      "learning_rate": 9.865414760042434e-06,
      "loss": 0.1907,
      "step": 850
    },
    {
      "epoch": 0.013474357553398673,
      "grad_norm": 0.14752840995788574,
      "learning_rate": 9.865256424466014e-06,
      "loss": 0.7336,
      "step": 851
    },
    {
      "epoch": 0.01349019111104074,
      "grad_norm": 0.0031999978236854076,
      "learning_rate": 9.865098088889593e-06,
      "loss": 0.0003,
      "step": 852
    },
    {
      "epoch": 0.013506024668682807,
      "grad_norm": 0.0772356167435646,
      "learning_rate": 9.864939753313173e-06,
      "loss": 0.0661,
      "step": 853
    },
    {
      "epoch": 0.013521858226324873,
      "grad_norm": 0.005300198215991259,
      "learning_rate": 9.864781417736752e-06,
      "loss": 0.0005,
      "step": 854
    },
    {
      "epoch": 0.01353769178396694,
      "grad_norm": 0.188967764377594,
      "learning_rate": 9.864623082160332e-06,
      "loss": 0.4396,
      "step": 855
    },
    {
      "epoch": 0.013553525341609005,
      "grad_norm": 0.29686906933784485,
      "learning_rate": 9.86446474658391e-06,
      "loss": 0.0542,
      "step": 856
    },
    {
      "epoch": 0.013569358899251073,
      "grad_norm": 0.08094549179077148,
      "learning_rate": 9.86430641100749e-06,
      "loss": 0.0825,
      "step": 857
    },
    {
      "epoch": 0.013585192456893139,
      "grad_norm": 0.4085392355918884,
      "learning_rate": 9.86414807543107e-06,
      "loss": 0.2048,
      "step": 858
    },
    {
      "epoch": 0.013601026014535205,
      "grad_norm": 0.007914851419627666,
      "learning_rate": 9.863989739854649e-06,
      "loss": 0.0005,
      "step": 859
    },
    {
      "epoch": 0.013616859572177273,
      "grad_norm": 0.26707831025123596,
      "learning_rate": 9.863831404278228e-06,
      "loss": 0.6373,
      "step": 860
    },
    {
      "epoch": 0.013632693129819339,
      "grad_norm": 0.11822493374347687,
      "learning_rate": 9.863673068701809e-06,
      "loss": 0.0064,
      "step": 861
    },
    {
      "epoch": 0.013648526687461405,
      "grad_norm": 0.1973702311515808,
      "learning_rate": 9.863514733125386e-06,
      "loss": 0.1634,
      "step": 862
    },
    {
      "epoch": 0.013664360245103473,
      "grad_norm": 0.0017134540248662233,
      "learning_rate": 9.863356397548967e-06,
      "loss": 0.0002,
      "step": 863
    },
    {
      "epoch": 0.013680193802745539,
      "grad_norm": 0.3092583417892456,
      "learning_rate": 9.863198061972546e-06,
      "loss": 0.3678,
      "step": 864
    },
    {
      "epoch": 0.013696027360387605,
      "grad_norm": 0.21265117824077606,
      "learning_rate": 9.863039726396125e-06,
      "loss": 0.2798,
      "step": 865
    },
    {
      "epoch": 0.013711860918029672,
      "grad_norm": 0.19013765454292297,
      "learning_rate": 9.862881390819704e-06,
      "loss": 0.1054,
      "step": 866
    },
    {
      "epoch": 0.013727694475671738,
      "grad_norm": 0.20415471494197845,
      "learning_rate": 9.862723055243283e-06,
      "loss": 0.1603,
      "step": 867
    },
    {
      "epoch": 0.013743528033313804,
      "grad_norm": 0.28017452359199524,
      "learning_rate": 9.862564719666862e-06,
      "loss": 0.2435,
      "step": 868
    },
    {
      "epoch": 0.013759361590955872,
      "grad_norm": 0.3203125596046448,
      "learning_rate": 9.862406384090441e-06,
      "loss": 0.2452,
      "step": 869
    },
    {
      "epoch": 0.013775195148597938,
      "grad_norm": 0.15808291733264923,
      "learning_rate": 9.862248048514022e-06,
      "loss": 0.2268,
      "step": 870
    },
    {
      "epoch": 0.013791028706240004,
      "grad_norm": 0.2922210395336151,
      "learning_rate": 9.862089712937601e-06,
      "loss": 0.1712,
      "step": 871
    },
    {
      "epoch": 0.013806862263882072,
      "grad_norm": 0.27436670660972595,
      "learning_rate": 9.86193137736118e-06,
      "loss": 0.3065,
      "step": 872
    },
    {
      "epoch": 0.013822695821524138,
      "grad_norm": 0.007323646917939186,
      "learning_rate": 9.86177304178476e-06,
      "loss": 0.0008,
      "step": 873
    },
    {
      "epoch": 0.013838529379166204,
      "grad_norm": 0.40434613823890686,
      "learning_rate": 9.861614706208338e-06,
      "loss": 0.8212,
      "step": 874
    },
    {
      "epoch": 0.013854362936808272,
      "grad_norm": 0.134018212556839,
      "learning_rate": 9.861456370631917e-06,
      "loss": 0.0743,
      "step": 875
    },
    {
      "epoch": 0.013870196494450338,
      "grad_norm": 0.3965778648853302,
      "learning_rate": 9.861298035055498e-06,
      "loss": 0.2129,
      "step": 876
    },
    {
      "epoch": 0.013886030052092404,
      "grad_norm": 0.14583061635494232,
      "learning_rate": 9.861139699479077e-06,
      "loss": 0.2004,
      "step": 877
    },
    {
      "epoch": 0.013901863609734472,
      "grad_norm": 0.09235819429159164,
      "learning_rate": 9.860981363902656e-06,
      "loss": 0.0238,
      "step": 878
    },
    {
      "epoch": 0.013917697167376538,
      "grad_norm": 0.32452595233917236,
      "learning_rate": 9.860823028326235e-06,
      "loss": 0.3293,
      "step": 879
    },
    {
      "epoch": 0.013933530725018604,
      "grad_norm": 0.11173044145107269,
      "learning_rate": 9.860664692749814e-06,
      "loss": 0.174,
      "step": 880
    },
    {
      "epoch": 0.013949364282660671,
      "grad_norm": 0.196629598736763,
      "learning_rate": 9.860506357173394e-06,
      "loss": 0.1261,
      "step": 881
    },
    {
      "epoch": 0.013965197840302737,
      "grad_norm": 0.3231077492237091,
      "learning_rate": 9.860348021596974e-06,
      "loss": 0.0557,
      "step": 882
    },
    {
      "epoch": 0.013981031397944804,
      "grad_norm": 0.3262975215911865,
      "learning_rate": 9.860189686020553e-06,
      "loss": 0.5116,
      "step": 883
    },
    {
      "epoch": 0.013996864955586871,
      "grad_norm": 0.1403467208147049,
      "learning_rate": 9.860031350444132e-06,
      "loss": 0.0626,
      "step": 884
    },
    {
      "epoch": 0.014012698513228937,
      "grad_norm": 0.0006183889345265925,
      "learning_rate": 9.859873014867712e-06,
      "loss": 0.0,
      "step": 885
    },
    {
      "epoch": 0.014028532070871003,
      "grad_norm": 0.3104361891746521,
      "learning_rate": 9.85971467929129e-06,
      "loss": 0.2143,
      "step": 886
    },
    {
      "epoch": 0.014044365628513071,
      "grad_norm": 0.1753973811864853,
      "learning_rate": 9.85955634371487e-06,
      "loss": 0.0922,
      "step": 887
    },
    {
      "epoch": 0.014060199186155137,
      "grad_norm": 0.0004758697177749127,
      "learning_rate": 9.85939800813845e-06,
      "loss": 0.0,
      "step": 888
    },
    {
      "epoch": 0.014076032743797203,
      "grad_norm": 0.44657352566719055,
      "learning_rate": 9.85923967256203e-06,
      "loss": 0.3173,
      "step": 889
    },
    {
      "epoch": 0.014091866301439271,
      "grad_norm": 0.864925742149353,
      "learning_rate": 9.859081336985609e-06,
      "loss": 0.2848,
      "step": 890
    },
    {
      "epoch": 0.014107699859081337,
      "grad_norm": 0.3690597116947174,
      "learning_rate": 9.858923001409188e-06,
      "loss": 0.083,
      "step": 891
    },
    {
      "epoch": 0.014123533416723403,
      "grad_norm": 0.16696946322917938,
      "learning_rate": 9.858764665832767e-06,
      "loss": 0.216,
      "step": 892
    },
    {
      "epoch": 0.01413936697436547,
      "grad_norm": 0.4570220112800598,
      "learning_rate": 9.858606330256346e-06,
      "loss": 0.1404,
      "step": 893
    },
    {
      "epoch": 0.014155200532007537,
      "grad_norm": 0.11804496496915817,
      "learning_rate": 9.858447994679925e-06,
      "loss": 0.046,
      "step": 894
    },
    {
      "epoch": 0.014171034089649603,
      "grad_norm": 0.16220149397850037,
      "learning_rate": 9.858289659103506e-06,
      "loss": 0.7737,
      "step": 895
    },
    {
      "epoch": 0.01418686764729167,
      "grad_norm": 0.14851023256778717,
      "learning_rate": 9.858131323527083e-06,
      "loss": 0.1381,
      "step": 896
    },
    {
      "epoch": 0.014202701204933737,
      "grad_norm": 0.11442571878433228,
      "learning_rate": 9.857972987950664e-06,
      "loss": 0.0637,
      "step": 897
    },
    {
      "epoch": 0.014218534762575803,
      "grad_norm": 0.3451237380504608,
      "learning_rate": 9.857814652374243e-06,
      "loss": 0.1921,
      "step": 898
    },
    {
      "epoch": 0.01423436832021787,
      "grad_norm": 0.1203659176826477,
      "learning_rate": 9.857656316797822e-06,
      "loss": 0.1452,
      "step": 899
    },
    {
      "epoch": 0.014250201877859936,
      "grad_norm": 0.3449884355068207,
      "learning_rate": 9.857497981221401e-06,
      "loss": 0.4897,
      "step": 900
    },
    {
      "epoch": 0.014266035435502002,
      "grad_norm": 0.1142086610198021,
      "learning_rate": 9.85733964564498e-06,
      "loss": 0.3485,
      "step": 901
    },
    {
      "epoch": 0.01428186899314407,
      "grad_norm": 0.001648701960220933,
      "learning_rate": 9.85718131006856e-06,
      "loss": 0.0001,
      "step": 902
    },
    {
      "epoch": 0.014297702550786136,
      "grad_norm": 0.1457752138376236,
      "learning_rate": 9.85702297449214e-06,
      "loss": 0.1747,
      "step": 903
    },
    {
      "epoch": 0.014313536108428202,
      "grad_norm": 0.18777626752853394,
      "learning_rate": 9.856864638915719e-06,
      "loss": 0.1663,
      "step": 904
    },
    {
      "epoch": 0.01432936966607027,
      "grad_norm": 0.03181138634681702,
      "learning_rate": 9.856706303339298e-06,
      "loss": 0.0058,
      "step": 905
    },
    {
      "epoch": 0.014345203223712336,
      "grad_norm": 0.00015145924407988787,
      "learning_rate": 9.856547967762877e-06,
      "loss": 0.0,
      "step": 906
    },
    {
      "epoch": 0.014361036781354402,
      "grad_norm": 0.1372474581003189,
      "learning_rate": 9.856389632186456e-06,
      "loss": 0.2438,
      "step": 907
    },
    {
      "epoch": 0.01437687033899647,
      "grad_norm": 0.111269012093544,
      "learning_rate": 9.856231296610035e-06,
      "loss": 0.1256,
      "step": 908
    },
    {
      "epoch": 0.014392703896638536,
      "grad_norm": 0.12283377349376678,
      "learning_rate": 9.856072961033616e-06,
      "loss": 0.0221,
      "step": 909
    },
    {
      "epoch": 0.014408537454280602,
      "grad_norm": 0.11391652375459671,
      "learning_rate": 9.855914625457195e-06,
      "loss": 0.1497,
      "step": 910
    },
    {
      "epoch": 0.01442437101192267,
      "grad_norm": 0.2250295877456665,
      "learning_rate": 9.855756289880774e-06,
      "loss": 0.1136,
      "step": 911
    },
    {
      "epoch": 0.014440204569564736,
      "grad_norm": 0.14705076813697815,
      "learning_rate": 9.855597954304353e-06,
      "loss": 0.1514,
      "step": 912
    },
    {
      "epoch": 0.014456038127206802,
      "grad_norm": 0.1802295744419098,
      "learning_rate": 9.855439618727933e-06,
      "loss": 0.036,
      "step": 913
    },
    {
      "epoch": 0.01447187168484887,
      "grad_norm": 0.005093245301395655,
      "learning_rate": 9.855281283151512e-06,
      "loss": 0.0005,
      "step": 914
    },
    {
      "epoch": 0.014487705242490935,
      "grad_norm": 0.007397923152893782,
      "learning_rate": 9.85512294757509e-06,
      "loss": 0.0004,
      "step": 915
    },
    {
      "epoch": 0.014503538800133001,
      "grad_norm": 0.14018630981445312,
      "learning_rate": 9.854964611998671e-06,
      "loss": 0.2188,
      "step": 916
    },
    {
      "epoch": 0.014519372357775069,
      "grad_norm": 0.0034134765155613422,
      "learning_rate": 9.854806276422249e-06,
      "loss": 0.0002,
      "step": 917
    },
    {
      "epoch": 0.014535205915417135,
      "grad_norm": 0.260312020778656,
      "learning_rate": 9.85464794084583e-06,
      "loss": 0.2543,
      "step": 918
    },
    {
      "epoch": 0.014551039473059201,
      "grad_norm": 0.21724876761436462,
      "learning_rate": 9.854489605269409e-06,
      "loss": 0.6062,
      "step": 919
    },
    {
      "epoch": 0.014566873030701269,
      "grad_norm": 0.017899690195918083,
      "learning_rate": 9.854331269692988e-06,
      "loss": 0.002,
      "step": 920
    },
    {
      "epoch": 0.014582706588343335,
      "grad_norm": 0.19470632076263428,
      "learning_rate": 9.854172934116567e-06,
      "loss": 0.277,
      "step": 921
    },
    {
      "epoch": 0.014598540145985401,
      "grad_norm": 0.08836271613836288,
      "learning_rate": 9.854014598540148e-06,
      "loss": 0.0299,
      "step": 922
    },
    {
      "epoch": 0.014614373703627469,
      "grad_norm": 0.18569013476371765,
      "learning_rate": 9.853856262963725e-06,
      "loss": 0.252,
      "step": 923
    },
    {
      "epoch": 0.014630207261269535,
      "grad_norm": 0.24837428331375122,
      "learning_rate": 9.853697927387306e-06,
      "loss": 0.4351,
      "step": 924
    },
    {
      "epoch": 0.0146460408189116,
      "grad_norm": 0.3690418601036072,
      "learning_rate": 9.853539591810885e-06,
      "loss": 0.2474,
      "step": 925
    },
    {
      "epoch": 0.014661874376553669,
      "grad_norm": 0.14698563516139984,
      "learning_rate": 9.853381256234464e-06,
      "loss": 0.0998,
      "step": 926
    },
    {
      "epoch": 0.014677707934195735,
      "grad_norm": 0.005860166158527136,
      "learning_rate": 9.853222920658043e-06,
      "loss": 0.0007,
      "step": 927
    },
    {
      "epoch": 0.0146935414918378,
      "grad_norm": 0.00837101973593235,
      "learning_rate": 9.853064585081624e-06,
      "loss": 0.0011,
      "step": 928
    },
    {
      "epoch": 0.014709375049479868,
      "grad_norm": 0.09892037510871887,
      "learning_rate": 9.852906249505201e-06,
      "loss": 0.0786,
      "step": 929
    },
    {
      "epoch": 0.014725208607121934,
      "grad_norm": 0.12181924283504486,
      "learning_rate": 9.852747913928782e-06,
      "loss": 0.0917,
      "step": 930
    },
    {
      "epoch": 0.014741042164764,
      "grad_norm": 0.0032597046811133623,
      "learning_rate": 9.852589578352361e-06,
      "loss": 0.0003,
      "step": 931
    },
    {
      "epoch": 0.014756875722406068,
      "grad_norm": 0.08643785864114761,
      "learning_rate": 9.85243124277594e-06,
      "loss": 0.0259,
      "step": 932
    },
    {
      "epoch": 0.014772709280048134,
      "grad_norm": 0.007737277541309595,
      "learning_rate": 9.85227290719952e-06,
      "loss": 0.0008,
      "step": 933
    },
    {
      "epoch": 0.0147885428376902,
      "grad_norm": 0.11600598692893982,
      "learning_rate": 9.8521145716231e-06,
      "loss": 0.007,
      "step": 934
    },
    {
      "epoch": 0.014804376395332268,
      "grad_norm": 0.10673227161169052,
      "learning_rate": 9.851956236046677e-06,
      "loss": 0.1185,
      "step": 935
    },
    {
      "epoch": 0.014820209952974334,
      "grad_norm": 0.21688322722911835,
      "learning_rate": 9.851797900470258e-06,
      "loss": 0.1138,
      "step": 936
    },
    {
      "epoch": 0.0148360435106164,
      "grad_norm": 0.13450893759727478,
      "learning_rate": 9.851639564893837e-06,
      "loss": 0.2454,
      "step": 937
    },
    {
      "epoch": 0.014851877068258468,
      "grad_norm": 0.12048172950744629,
      "learning_rate": 9.851481229317416e-06,
      "loss": 0.2808,
      "step": 938
    },
    {
      "epoch": 0.014867710625900534,
      "grad_norm": 0.22164250910282135,
      "learning_rate": 9.851322893740995e-06,
      "loss": 0.277,
      "step": 939
    },
    {
      "epoch": 0.0148835441835426,
      "grad_norm": 0.11774879693984985,
      "learning_rate": 9.851164558164574e-06,
      "loss": 0.2114,
      "step": 940
    },
    {
      "epoch": 0.014899377741184668,
      "grad_norm": 0.24759837985038757,
      "learning_rate": 9.851006222588154e-06,
      "loss": 0.4049,
      "step": 941
    },
    {
      "epoch": 0.014915211298826734,
      "grad_norm": 1.1255528926849365,
      "learning_rate": 9.850847887011733e-06,
      "loss": 0.0991,
      "step": 942
    },
    {
      "epoch": 0.0149310448564688,
      "grad_norm": 0.09572003036737442,
      "learning_rate": 9.850689551435313e-06,
      "loss": 0.0317,
      "step": 943
    },
    {
      "epoch": 0.014946878414110867,
      "grad_norm": 0.20149414241313934,
      "learning_rate": 9.850531215858892e-06,
      "loss": 0.3051,
      "step": 944
    },
    {
      "epoch": 0.014962711971752933,
      "grad_norm": 0.2941173017024994,
      "learning_rate": 9.850372880282472e-06,
      "loss": 0.2026,
      "step": 945
    },
    {
      "epoch": 0.014978545529395,
      "grad_norm": 0.13589535653591156,
      "learning_rate": 9.85021454470605e-06,
      "loss": 0.0491,
      "step": 946
    },
    {
      "epoch": 0.014994379087037067,
      "grad_norm": 0.15113718807697296,
      "learning_rate": 9.85005620912963e-06,
      "loss": 0.0989,
      "step": 947
    },
    {
      "epoch": 0.015010212644679133,
      "grad_norm": 0.003633239772170782,
      "learning_rate": 9.849897873553209e-06,
      "loss": 0.0001,
      "step": 948
    },
    {
      "epoch": 0.0150260462023212,
      "grad_norm": 0.17637024819850922,
      "learning_rate": 9.84973953797679e-06,
      "loss": 0.3139,
      "step": 949
    },
    {
      "epoch": 0.015041879759963267,
      "grad_norm": 0.004081406630575657,
      "learning_rate": 9.849581202400369e-06,
      "loss": 0.0004,
      "step": 950
    },
    {
      "epoch": 0.015057713317605333,
      "grad_norm": 0.12411785125732422,
      "learning_rate": 9.849422866823948e-06,
      "loss": 0.0994,
      "step": 951
    },
    {
      "epoch": 0.015073546875247399,
      "grad_norm": 0.259051114320755,
      "learning_rate": 9.849264531247527e-06,
      "loss": 0.1756,
      "step": 952
    },
    {
      "epoch": 0.015089380432889467,
      "grad_norm": 0.0044496068730950356,
      "learning_rate": 9.849106195671106e-06,
      "loss": 0.0004,
      "step": 953
    },
    {
      "epoch": 0.015105213990531533,
      "grad_norm": 0.5929469466209412,
      "learning_rate": 9.848947860094685e-06,
      "loss": 0.2833,
      "step": 954
    },
    {
      "epoch": 0.015121047548173599,
      "grad_norm": 0.13863013684749603,
      "learning_rate": 9.848789524518266e-06,
      "loss": 0.4382,
      "step": 955
    },
    {
      "epoch": 0.015136881105815665,
      "grad_norm": 0.0010258639231324196,
      "learning_rate": 9.848631188941845e-06,
      "loss": 0.0001,
      "step": 956
    },
    {
      "epoch": 0.015152714663457733,
      "grad_norm": 0.2529086470603943,
      "learning_rate": 9.848472853365424e-06,
      "loss": 0.7442,
      "step": 957
    },
    {
      "epoch": 0.015168548221099799,
      "grad_norm": 0.4305349886417389,
      "learning_rate": 9.848314517789003e-06,
      "loss": 0.0228,
      "step": 958
    },
    {
      "epoch": 0.015184381778741865,
      "grad_norm": 0.16054458916187286,
      "learning_rate": 9.848156182212582e-06,
      "loss": 0.0399,
      "step": 959
    },
    {
      "epoch": 0.015200215336383932,
      "grad_norm": 0.38345155119895935,
      "learning_rate": 9.847997846636161e-06,
      "loss": 1.0834,
      "step": 960
    },
    {
      "epoch": 0.015216048894025998,
      "grad_norm": 0.2763131856918335,
      "learning_rate": 9.847839511059742e-06,
      "loss": 0.905,
      "step": 961
    },
    {
      "epoch": 0.015231882451668064,
      "grad_norm": 0.2716766893863678,
      "learning_rate": 9.84768117548332e-06,
      "loss": 0.0576,
      "step": 962
    },
    {
      "epoch": 0.015247716009310132,
      "grad_norm": 0.12171907722949982,
      "learning_rate": 9.847522839906898e-06,
      "loss": 0.0349,
      "step": 963
    },
    {
      "epoch": 0.015263549566952198,
      "grad_norm": 0.14523446559906006,
      "learning_rate": 9.847364504330479e-06,
      "loss": 0.0239,
      "step": 964
    },
    {
      "epoch": 0.015279383124594264,
      "grad_norm": 0.019303904846310616,
      "learning_rate": 9.847206168754058e-06,
      "loss": 0.0041,
      "step": 965
    },
    {
      "epoch": 0.015295216682236332,
      "grad_norm": 0.31075748801231384,
      "learning_rate": 9.847047833177637e-06,
      "loss": 0.206,
      "step": 966
    },
    {
      "epoch": 0.015311050239878398,
      "grad_norm": 0.1404036283493042,
      "learning_rate": 9.846889497601216e-06,
      "loss": 0.0908,
      "step": 967
    },
    {
      "epoch": 0.015326883797520464,
      "grad_norm": 0.35372668504714966,
      "learning_rate": 9.846731162024795e-06,
      "loss": 0.3461,
      "step": 968
    },
    {
      "epoch": 0.015342717355162532,
      "grad_norm": 0.13869501650333405,
      "learning_rate": 9.846572826448375e-06,
      "loss": 0.0147,
      "step": 969
    },
    {
      "epoch": 0.015358550912804598,
      "grad_norm": 0.19220159947872162,
      "learning_rate": 9.846414490871955e-06,
      "loss": 0.0869,
      "step": 970
    },
    {
      "epoch": 0.015374384470446664,
      "grad_norm": 0.6997653841972351,
      "learning_rate": 9.846256155295534e-06,
      "loss": 0.0788,
      "step": 971
    },
    {
      "epoch": 0.015390218028088732,
      "grad_norm": 0.10727263242006302,
      "learning_rate": 9.846097819719113e-06,
      "loss": 0.0051,
      "step": 972
    },
    {
      "epoch": 0.015406051585730798,
      "grad_norm": 0.1658703237771988,
      "learning_rate": 9.845939484142693e-06,
      "loss": 0.1044,
      "step": 973
    },
    {
      "epoch": 0.015421885143372864,
      "grad_norm": 0.3414897620677948,
      "learning_rate": 9.845781148566272e-06,
      "loss": 0.4131,
      "step": 974
    },
    {
      "epoch": 0.015437718701014931,
      "grad_norm": 0.1953303962945938,
      "learning_rate": 9.84562281298985e-06,
      "loss": 0.1051,
      "step": 975
    },
    {
      "epoch": 0.015453552258656997,
      "grad_norm": 0.147767573595047,
      "learning_rate": 9.845464477413431e-06,
      "loss": 0.0332,
      "step": 976
    },
    {
      "epoch": 0.015469385816299063,
      "grad_norm": 0.21231873333454132,
      "learning_rate": 9.84530614183701e-06,
      "loss": 0.1429,
      "step": 977
    },
    {
      "epoch": 0.015485219373941131,
      "grad_norm": 0.3149797022342682,
      "learning_rate": 9.84514780626059e-06,
      "loss": 0.2124,
      "step": 978
    },
    {
      "epoch": 0.015501052931583197,
      "grad_norm": 0.19360031187534332,
      "learning_rate": 9.844989470684169e-06,
      "loss": 0.5445,
      "step": 979
    },
    {
      "epoch": 0.015516886489225263,
      "grad_norm": 0.04290264472365379,
      "learning_rate": 9.844831135107748e-06,
      "loss": 0.002,
      "step": 980
    },
    {
      "epoch": 0.015532720046867331,
      "grad_norm": 0.3376097083091736,
      "learning_rate": 9.844672799531327e-06,
      "loss": 0.2437,
      "step": 981
    },
    {
      "epoch": 0.015548553604509397,
      "grad_norm": 0.11659225076436996,
      "learning_rate": 9.844514463954908e-06,
      "loss": 0.0081,
      "step": 982
    },
    {
      "epoch": 0.015564387162151463,
      "grad_norm": 0.002593307290226221,
      "learning_rate": 9.844356128378487e-06,
      "loss": 0.0,
      "step": 983
    },
    {
      "epoch": 0.01558022071979353,
      "grad_norm": 0.20387431979179382,
      "learning_rate": 9.844197792802066e-06,
      "loss": 0.2228,
      "step": 984
    },
    {
      "epoch": 0.015596054277435597,
      "grad_norm": 0.2898221015930176,
      "learning_rate": 9.844039457225645e-06,
      "loss": 0.2159,
      "step": 985
    },
    {
      "epoch": 0.015611887835077663,
      "grad_norm": 0.12529802322387695,
      "learning_rate": 9.843881121649224e-06,
      "loss": 0.1226,
      "step": 986
    },
    {
      "epoch": 0.01562772139271973,
      "grad_norm": 0.3965023159980774,
      "learning_rate": 9.843722786072803e-06,
      "loss": 0.1272,
      "step": 987
    },
    {
      "epoch": 0.015643554950361797,
      "grad_norm": 0.05040335655212402,
      "learning_rate": 9.843564450496382e-06,
      "loss": 0.0018,
      "step": 988
    },
    {
      "epoch": 0.015659388508003864,
      "grad_norm": 0.14206096529960632,
      "learning_rate": 9.843406114919963e-06,
      "loss": 0.1536,
      "step": 989
    },
    {
      "epoch": 0.01567522206564593,
      "grad_norm": 0.1631268560886383,
      "learning_rate": 9.84324777934354e-06,
      "loss": 0.1472,
      "step": 990
    },
    {
      "epoch": 0.015691055623287996,
      "grad_norm": 0.009340743534266949,
      "learning_rate": 9.843089443767121e-06,
      "loss": 0.001,
      "step": 991
    },
    {
      "epoch": 0.015706889180930064,
      "grad_norm": 0.1623033881187439,
      "learning_rate": 9.8429311081907e-06,
      "loss": 0.1601,
      "step": 992
    },
    {
      "epoch": 0.01572272273857213,
      "grad_norm": 0.04052407667040825,
      "learning_rate": 9.84277277261428e-06,
      "loss": 0.0028,
      "step": 993
    },
    {
      "epoch": 0.015738556296214196,
      "grad_norm": 0.16260144114494324,
      "learning_rate": 9.842614437037858e-06,
      "loss": 0.1406,
      "step": 994
    },
    {
      "epoch": 0.015754389853856264,
      "grad_norm": 0.00012719507503788918,
      "learning_rate": 9.842456101461439e-06,
      "loss": 0.0,
      "step": 995
    },
    {
      "epoch": 0.01577022341149833,
      "grad_norm": 0.22060143947601318,
      "learning_rate": 9.842297765885016e-06,
      "loss": 0.786,
      "step": 996
    },
    {
      "epoch": 0.015786056969140396,
      "grad_norm": 0.0005926218000240624,
      "learning_rate": 9.842139430308597e-06,
      "loss": 0.0,
      "step": 997
    },
    {
      "epoch": 0.015801890526782464,
      "grad_norm": 0.11517470329999924,
      "learning_rate": 9.841981094732176e-06,
      "loss": 0.0598,
      "step": 998
    },
    {
      "epoch": 0.015817724084424528,
      "grad_norm": 0.00042574017425067723,
      "learning_rate": 9.841822759155755e-06,
      "loss": 0.0,
      "step": 999
    },
    {
      "epoch": 0.015833557642066596,
      "grad_norm": 0.15467621386051178,
      "learning_rate": 9.841664423579334e-06,
      "loss": 0.092,
      "step": 1000
    },
    {
      "epoch": 0.015849391199708664,
      "grad_norm": 0.10366616398096085,
      "learning_rate": 9.841506088002915e-06,
      "loss": 0.0036,
      "step": 1001
    },
    {
      "epoch": 0.015865224757350728,
      "grad_norm": 0.2919307351112366,
      "learning_rate": 9.841347752426493e-06,
      "loss": 0.1255,
      "step": 1002
    },
    {
      "epoch": 0.015881058314992796,
      "grad_norm": 0.26256561279296875,
      "learning_rate": 9.841189416850073e-06,
      "loss": 0.3889,
      "step": 1003
    },
    {
      "epoch": 0.015896891872634863,
      "grad_norm": 0.03694721683859825,
      "learning_rate": 9.841031081273652e-06,
      "loss": 0.0039,
      "step": 1004
    },
    {
      "epoch": 0.015912725430276928,
      "grad_norm": 0.2552127242088318,
      "learning_rate": 9.840872745697232e-06,
      "loss": 0.6576,
      "step": 1005
    },
    {
      "epoch": 0.015928558987918996,
      "grad_norm": 0.028635133057832718,
      "learning_rate": 9.84071441012081e-06,
      "loss": 0.0031,
      "step": 1006
    },
    {
      "epoch": 0.015944392545561063,
      "grad_norm": 0.018951117992401123,
      "learning_rate": 9.840556074544391e-06,
      "loss": 0.0019,
      "step": 1007
    },
    {
      "epoch": 0.015960226103203128,
      "grad_norm": 0.38955309987068176,
      "learning_rate": 9.840397738967969e-06,
      "loss": 0.8619,
      "step": 1008
    },
    {
      "epoch": 0.015976059660845195,
      "grad_norm": 0.011359748430550098,
      "learning_rate": 9.84023940339155e-06,
      "loss": 0.0011,
      "step": 1009
    },
    {
      "epoch": 0.015991893218487263,
      "grad_norm": 0.0005795288598164916,
      "learning_rate": 9.840081067815129e-06,
      "loss": 0.0,
      "step": 1010
    },
    {
      "epoch": 0.016007726776129327,
      "grad_norm": 0.006602240260690451,
      "learning_rate": 9.839922732238708e-06,
      "loss": 0.0006,
      "step": 1011
    },
    {
      "epoch": 0.016023560333771395,
      "grad_norm": 0.008457690477371216,
      "learning_rate": 9.839764396662287e-06,
      "loss": 0.001,
      "step": 1012
    },
    {
      "epoch": 0.016039393891413463,
      "grad_norm": 0.19468629360198975,
      "learning_rate": 9.839606061085866e-06,
      "loss": 0.1612,
      "step": 1013
    },
    {
      "epoch": 0.016055227449055527,
      "grad_norm": 0.026795515790581703,
      "learning_rate": 9.839447725509445e-06,
      "loss": 0.0008,
      "step": 1014
    },
    {
      "epoch": 0.016071061006697595,
      "grad_norm": 0.042510613799095154,
      "learning_rate": 9.839289389933024e-06,
      "loss": 0.0041,
      "step": 1015
    },
    {
      "epoch": 0.016086894564339663,
      "grad_norm": 0.3323068618774414,
      "learning_rate": 9.839131054356605e-06,
      "loss": 0.187,
      "step": 1016
    },
    {
      "epoch": 0.016102728121981727,
      "grad_norm": 0.1801418513059616,
      "learning_rate": 9.838972718780184e-06,
      "loss": 0.1047,
      "step": 1017
    },
    {
      "epoch": 0.016118561679623795,
      "grad_norm": 0.2092423439025879,
      "learning_rate": 9.838814383203763e-06,
      "loss": 0.4768,
      "step": 1018
    },
    {
      "epoch": 0.016134395237265862,
      "grad_norm": 0.0038325295317918062,
      "learning_rate": 9.838656047627342e-06,
      "loss": 0.0003,
      "step": 1019
    },
    {
      "epoch": 0.016150228794907927,
      "grad_norm": 0.034527700394392014,
      "learning_rate": 9.838497712050921e-06,
      "loss": 0.0049,
      "step": 1020
    },
    {
      "epoch": 0.016166062352549995,
      "grad_norm": 0.23410075902938843,
      "learning_rate": 9.8383393764745e-06,
      "loss": 0.0402,
      "step": 1021
    },
    {
      "epoch": 0.016181895910192062,
      "grad_norm": 0.14261247217655182,
      "learning_rate": 9.838181040898081e-06,
      "loss": 0.259,
      "step": 1022
    },
    {
      "epoch": 0.016197729467834127,
      "grad_norm": 0.16138917207717896,
      "learning_rate": 9.83802270532166e-06,
      "loss": 0.0652,
      "step": 1023
    },
    {
      "epoch": 0.016213563025476194,
      "grad_norm": 0.2989893853664398,
      "learning_rate": 9.83786436974524e-06,
      "loss": 0.5842,
      "step": 1024
    },
    {
      "epoch": 0.016229396583118262,
      "grad_norm": 0.19027139246463776,
      "learning_rate": 9.837706034168818e-06,
      "loss": 0.0307,
      "step": 1025
    },
    {
      "epoch": 0.016245230140760326,
      "grad_norm": 0.13757087290287018,
      "learning_rate": 9.837547698592397e-06,
      "loss": 0.1069,
      "step": 1026
    },
    {
      "epoch": 0.016261063698402394,
      "grad_norm": 0.15610812604427338,
      "learning_rate": 9.837389363015976e-06,
      "loss": 0.0815,
      "step": 1027
    },
    {
      "epoch": 0.016276897256044462,
      "grad_norm": 0.2618808448314667,
      "learning_rate": 9.837231027439557e-06,
      "loss": 1.059,
      "step": 1028
    },
    {
      "epoch": 0.016292730813686526,
      "grad_norm": 0.13951805233955383,
      "learning_rate": 9.837072691863135e-06,
      "loss": 0.185,
      "step": 1029
    },
    {
      "epoch": 0.016308564371328594,
      "grad_norm": 0.3626885712146759,
      "learning_rate": 9.836914356286715e-06,
      "loss": 0.2149,
      "step": 1030
    },
    {
      "epoch": 0.01632439792897066,
      "grad_norm": 0.3035602867603302,
      "learning_rate": 9.836756020710294e-06,
      "loss": 0.0189,
      "step": 1031
    },
    {
      "epoch": 0.016340231486612726,
      "grad_norm": 0.3155122697353363,
      "learning_rate": 9.836597685133874e-06,
      "loss": 0.3981,
      "step": 1032
    },
    {
      "epoch": 0.016356065044254794,
      "grad_norm": 0.2910010814666748,
      "learning_rate": 9.836439349557453e-06,
      "loss": 0.4133,
      "step": 1033
    },
    {
      "epoch": 0.01637189860189686,
      "grad_norm": 0.19506271183490753,
      "learning_rate": 9.836281013981033e-06,
      "loss": 0.2428,
      "step": 1034
    },
    {
      "epoch": 0.016387732159538926,
      "grad_norm": 0.22157080471515656,
      "learning_rate": 9.83612267840461e-06,
      "loss": 0.8163,
      "step": 1035
    },
    {
      "epoch": 0.016403565717180994,
      "grad_norm": 0.2585146427154541,
      "learning_rate": 9.83596434282819e-06,
      "loss": 0.0402,
      "step": 1036
    },
    {
      "epoch": 0.01641939927482306,
      "grad_norm": 0.08834140747785568,
      "learning_rate": 9.83580600725177e-06,
      "loss": 0.0099,
      "step": 1037
    },
    {
      "epoch": 0.016435232832465126,
      "grad_norm": 0.41324177384376526,
      "learning_rate": 9.83564767167535e-06,
      "loss": 0.0293,
      "step": 1038
    },
    {
      "epoch": 0.016451066390107193,
      "grad_norm": 0.2024921178817749,
      "learning_rate": 9.835489336098929e-06,
      "loss": 0.0402,
      "step": 1039
    },
    {
      "epoch": 0.01646689994774926,
      "grad_norm": 0.029548391699790955,
      "learning_rate": 9.835331000522508e-06,
      "loss": 0.0018,
      "step": 1040
    },
    {
      "epoch": 0.016482733505391325,
      "grad_norm": 0.21871349215507507,
      "learning_rate": 9.835172664946087e-06,
      "loss": 0.0817,
      "step": 1041
    },
    {
      "epoch": 0.016498567063033393,
      "grad_norm": 0.17799760401248932,
      "learning_rate": 9.835014329369666e-06,
      "loss": 0.16,
      "step": 1042
    },
    {
      "epoch": 0.01651440062067546,
      "grad_norm": 0.009903055615723133,
      "learning_rate": 9.834855993793247e-06,
      "loss": 0.0008,
      "step": 1043
    },
    {
      "epoch": 0.016530234178317525,
      "grad_norm": 0.24484172463417053,
      "learning_rate": 9.834697658216826e-06,
      "loss": 0.2903,
      "step": 1044
    },
    {
      "epoch": 0.016546067735959593,
      "grad_norm": 0.0003154478908982128,
      "learning_rate": 9.834539322640405e-06,
      "loss": 0.0,
      "step": 1045
    },
    {
      "epoch": 0.01656190129360166,
      "grad_norm": 0.03775349631905556,
      "learning_rate": 9.834380987063984e-06,
      "loss": 0.0021,
      "step": 1046
    },
    {
      "epoch": 0.016577734851243725,
      "grad_norm": 0.6625392436981201,
      "learning_rate": 9.834222651487563e-06,
      "loss": 0.0384,
      "step": 1047
    },
    {
      "epoch": 0.016593568408885793,
      "grad_norm": 0.22043117880821228,
      "learning_rate": 9.834064315911142e-06,
      "loss": 0.2926,
      "step": 1048
    },
    {
      "epoch": 0.01660940196652786,
      "grad_norm": 0.3131462335586548,
      "learning_rate": 9.833905980334723e-06,
      "loss": 0.2568,
      "step": 1049
    },
    {
      "epoch": 0.016625235524169925,
      "grad_norm": 0.0809522271156311,
      "learning_rate": 9.833747644758302e-06,
      "loss": 0.0345,
      "step": 1050
    },
    {
      "epoch": 0.016641069081811993,
      "grad_norm": 0.00891120359301567,
      "learning_rate": 9.833589309181881e-06,
      "loss": 0.0006,
      "step": 1051
    },
    {
      "epoch": 0.01665690263945406,
      "grad_norm": 0.0012653834419324994,
      "learning_rate": 9.83343097360546e-06,
      "loss": 0.0,
      "step": 1052
    },
    {
      "epoch": 0.016672736197096125,
      "grad_norm": 0.013570980168879032,
      "learning_rate": 9.83327263802904e-06,
      "loss": 0.001,
      "step": 1053
    },
    {
      "epoch": 0.016688569754738192,
      "grad_norm": 0.0006537039880640805,
      "learning_rate": 9.833114302452618e-06,
      "loss": 0.0,
      "step": 1054
    },
    {
      "epoch": 0.01670440331238026,
      "grad_norm": 0.00018303311662748456,
      "learning_rate": 9.832955966876199e-06,
      "loss": 0.0,
      "step": 1055
    },
    {
      "epoch": 0.016720236870022324,
      "grad_norm": 0.14929503202438354,
      "learning_rate": 9.832797631299778e-06,
      "loss": 0.0295,
      "step": 1056
    },
    {
      "epoch": 0.016736070427664392,
      "grad_norm": 0.12295302003622055,
      "learning_rate": 9.832639295723357e-06,
      "loss": 0.0345,
      "step": 1057
    },
    {
      "epoch": 0.01675190398530646,
      "grad_norm": 0.3339938521385193,
      "learning_rate": 9.832480960146936e-06,
      "loss": 0.7346,
      "step": 1058
    },
    {
      "epoch": 0.016767737542948524,
      "grad_norm": 0.17342200875282288,
      "learning_rate": 9.832322624570515e-06,
      "loss": 0.2243,
      "step": 1059
    },
    {
      "epoch": 0.016783571100590592,
      "grad_norm": 0.353693425655365,
      "learning_rate": 9.832164288994095e-06,
      "loss": 0.1161,
      "step": 1060
    },
    {
      "epoch": 0.01679940465823266,
      "grad_norm": 0.6946433186531067,
      "learning_rate": 9.832005953417674e-06,
      "loss": 0.3016,
      "step": 1061
    },
    {
      "epoch": 0.016815238215874724,
      "grad_norm": 0.24998487532138824,
      "learning_rate": 9.831847617841254e-06,
      "loss": 0.1865,
      "step": 1062
    },
    {
      "epoch": 0.016831071773516792,
      "grad_norm": 0.1759006381034851,
      "learning_rate": 9.831689282264832e-06,
      "loss": 0.127,
      "step": 1063
    },
    {
      "epoch": 0.01684690533115886,
      "grad_norm": 0.04659826681017876,
      "learning_rate": 9.831530946688413e-06,
      "loss": 0.0126,
      "step": 1064
    },
    {
      "epoch": 0.016862738888800924,
      "grad_norm": 0.24754680693149567,
      "learning_rate": 9.831372611111992e-06,
      "loss": 0.2611,
      "step": 1065
    },
    {
      "epoch": 0.01687857244644299,
      "grad_norm": 0.010215491987764835,
      "learning_rate": 9.83121427553557e-06,
      "loss": 0.0007,
      "step": 1066
    },
    {
      "epoch": 0.01689440600408506,
      "grad_norm": 0.07888483256101608,
      "learning_rate": 9.83105593995915e-06,
      "loss": 0.025,
      "step": 1067
    },
    {
      "epoch": 0.016910239561727124,
      "grad_norm": 0.001157440710812807,
      "learning_rate": 9.83089760438273e-06,
      "loss": 0.0001,
      "step": 1068
    },
    {
      "epoch": 0.01692607311936919,
      "grad_norm": 0.09593687951564789,
      "learning_rate": 9.830739268806308e-06,
      "loss": 0.0717,
      "step": 1069
    },
    {
      "epoch": 0.01694190667701126,
      "grad_norm": 0.413824200630188,
      "learning_rate": 9.830580933229889e-06,
      "loss": 0.6709,
      "step": 1070
    },
    {
      "epoch": 0.016957740234653323,
      "grad_norm": 0.21964417397975922,
      "learning_rate": 9.830422597653468e-06,
      "loss": 0.5176,
      "step": 1071
    },
    {
      "epoch": 0.01697357379229539,
      "grad_norm": 0.031087545678019524,
      "learning_rate": 9.830264262077047e-06,
      "loss": 0.0014,
      "step": 1072
    },
    {
      "epoch": 0.01698940734993746,
      "grad_norm": 0.004262885078787804,
      "learning_rate": 9.830105926500626e-06,
      "loss": 0.0004,
      "step": 1073
    },
    {
      "epoch": 0.017005240907579523,
      "grad_norm": 0.27246180176734924,
      "learning_rate": 9.829947590924207e-06,
      "loss": 0.1903,
      "step": 1074
    },
    {
      "epoch": 0.01702107446522159,
      "grad_norm": 0.0003943058545701206,
      "learning_rate": 9.829789255347784e-06,
      "loss": 0.0,
      "step": 1075
    },
    {
      "epoch": 0.01703690802286366,
      "grad_norm": 0.3330336809158325,
      "learning_rate": 9.829630919771365e-06,
      "loss": 0.1993,
      "step": 1076
    },
    {
      "epoch": 0.017052741580505723,
      "grad_norm": 0.003488523419946432,
      "learning_rate": 9.829472584194944e-06,
      "loss": 0.0002,
      "step": 1077
    },
    {
      "epoch": 0.01706857513814779,
      "grad_norm": 0.3519037365913391,
      "learning_rate": 9.829314248618523e-06,
      "loss": 1.1867,
      "step": 1078
    },
    {
      "epoch": 0.01708440869578986,
      "grad_norm": 0.16716308891773224,
      "learning_rate": 9.829155913042102e-06,
      "loss": 0.2046,
      "step": 1079
    },
    {
      "epoch": 0.017100242253431923,
      "grad_norm": 0.019289104267954826,
      "learning_rate": 9.828997577465683e-06,
      "loss": 0.0062,
      "step": 1080
    },
    {
      "epoch": 0.01711607581107399,
      "grad_norm": 0.22748176753520966,
      "learning_rate": 9.82883924188926e-06,
      "loss": 0.1076,
      "step": 1081
    },
    {
      "epoch": 0.01713190936871606,
      "grad_norm": 0.30207595229148865,
      "learning_rate": 9.828680906312841e-06,
      "loss": 0.1461,
      "step": 1082
    },
    {
      "epoch": 0.017147742926358123,
      "grad_norm": 0.11784487217664719,
      "learning_rate": 9.82852257073642e-06,
      "loss": 0.0102,
      "step": 1083
    },
    {
      "epoch": 0.01716357648400019,
      "grad_norm": 0.0006843197625130415,
      "learning_rate": 9.82836423516e-06,
      "loss": 0.0,
      "step": 1084
    },
    {
      "epoch": 0.017179410041642258,
      "grad_norm": 0.07302732765674591,
      "learning_rate": 9.828205899583578e-06,
      "loss": 0.0094,
      "step": 1085
    },
    {
      "epoch": 0.017195243599284322,
      "grad_norm": 0.2147589921951294,
      "learning_rate": 9.828047564007157e-06,
      "loss": 0.207,
      "step": 1086
    },
    {
      "epoch": 0.01721107715692639,
      "grad_norm": 0.2967601716518402,
      "learning_rate": 9.827889228430736e-06,
      "loss": 0.1095,
      "step": 1087
    },
    {
      "epoch": 0.017226910714568458,
      "grad_norm": 0.0006822427967563272,
      "learning_rate": 9.827730892854316e-06,
      "loss": 0.0,
      "step": 1088
    },
    {
      "epoch": 0.017242744272210522,
      "grad_norm": 0.038767483085393906,
      "learning_rate": 9.827572557277896e-06,
      "loss": 0.0035,
      "step": 1089
    },
    {
      "epoch": 0.01725857782985259,
      "grad_norm": 0.0004438176692929119,
      "learning_rate": 9.827414221701475e-06,
      "loss": 0.0,
      "step": 1090
    },
    {
      "epoch": 0.017274411387494658,
      "grad_norm": 0.12243156880140305,
      "learning_rate": 9.827255886125054e-06,
      "loss": 0.0675,
      "step": 1091
    },
    {
      "epoch": 0.017290244945136722,
      "grad_norm": 0.19578450918197632,
      "learning_rate": 9.827097550548634e-06,
      "loss": 0.7097,
      "step": 1092
    },
    {
      "epoch": 0.01730607850277879,
      "grad_norm": 0.2061467468738556,
      "learning_rate": 9.826939214972213e-06,
      "loss": 0.0739,
      "step": 1093
    },
    {
      "epoch": 0.017321912060420858,
      "grad_norm": 0.007302087731659412,
      "learning_rate": 9.826780879395792e-06,
      "loss": 0.0007,
      "step": 1094
    },
    {
      "epoch": 0.017337745618062922,
      "grad_norm": 0.03044877201318741,
      "learning_rate": 9.826622543819372e-06,
      "loss": 0.0048,
      "step": 1095
    },
    {
      "epoch": 0.01735357917570499,
      "grad_norm": 0.007906761020421982,
      "learning_rate": 9.82646420824295e-06,
      "loss": 0.0006,
      "step": 1096
    },
    {
      "epoch": 0.017369412733347057,
      "grad_norm": 0.17894351482391357,
      "learning_rate": 9.82630587266653e-06,
      "loss": 0.1418,
      "step": 1097
    },
    {
      "epoch": 0.01738524629098912,
      "grad_norm": 0.49967366456985474,
      "learning_rate": 9.82614753709011e-06,
      "loss": 0.2036,
      "step": 1098
    },
    {
      "epoch": 0.01740107984863119,
      "grad_norm": 0.2511719763278961,
      "learning_rate": 9.825989201513689e-06,
      "loss": 0.1157,
      "step": 1099
    },
    {
      "epoch": 0.017416913406273257,
      "grad_norm": 0.011547796428203583,
      "learning_rate": 9.825830865937268e-06,
      "loss": 0.0007,
      "step": 1100
    },
    {
      "epoch": 0.01743274696391532,
      "grad_norm": 0.1666993349790573,
      "learning_rate": 9.825672530360849e-06,
      "loss": 0.1092,
      "step": 1101
    },
    {
      "epoch": 0.01744858052155739,
      "grad_norm": 0.2679998278617859,
      "learning_rate": 9.825514194784426e-06,
      "loss": 0.304,
      "step": 1102
    },
    {
      "epoch": 0.017464414079199457,
      "grad_norm": 0.008850212208926678,
      "learning_rate": 9.825355859208007e-06,
      "loss": 0.0007,
      "step": 1103
    },
    {
      "epoch": 0.01748024763684152,
      "grad_norm": 0.19729821383953094,
      "learning_rate": 9.825197523631586e-06,
      "loss": 0.3859,
      "step": 1104
    },
    {
      "epoch": 0.01749608119448359,
      "grad_norm": 0.41517412662506104,
      "learning_rate": 9.825039188055165e-06,
      "loss": 0.209,
      "step": 1105
    },
    {
      "epoch": 0.017511914752125657,
      "grad_norm": 0.2198951095342636,
      "learning_rate": 9.824880852478744e-06,
      "loss": 0.4647,
      "step": 1106
    },
    {
      "epoch": 0.01752774830976772,
      "grad_norm": 0.3416651785373688,
      "learning_rate": 9.824722516902323e-06,
      "loss": 1.2803,
      "step": 1107
    },
    {
      "epoch": 0.01754358186740979,
      "grad_norm": 0.34624603390693665,
      "learning_rate": 9.824564181325902e-06,
      "loss": 0.1828,
      "step": 1108
    },
    {
      "epoch": 0.017559415425051853,
      "grad_norm": 0.010970779694616795,
      "learning_rate": 9.824405845749481e-06,
      "loss": 0.0009,
      "step": 1109
    },
    {
      "epoch": 0.01757524898269392,
      "grad_norm": 0.0036879531107842922,
      "learning_rate": 9.824247510173062e-06,
      "loss": 0.0003,
      "step": 1110
    },
    {
      "epoch": 0.01759108254033599,
      "grad_norm": 0.10267233848571777,
      "learning_rate": 9.824089174596641e-06,
      "loss": 0.0744,
      "step": 1111
    },
    {
      "epoch": 0.017606916097978053,
      "grad_norm": 0.21742616593837738,
      "learning_rate": 9.82393083902022e-06,
      "loss": 0.2508,
      "step": 1112
    },
    {
      "epoch": 0.01762274965562012,
      "grad_norm": 0.0087844617664814,
      "learning_rate": 9.8237725034438e-06,
      "loss": 0.0006,
      "step": 1113
    },
    {
      "epoch": 0.01763858321326219,
      "grad_norm": 0.004960497375577688,
      "learning_rate": 9.823614167867378e-06,
      "loss": 0.0004,
      "step": 1114
    },
    {
      "epoch": 0.017654416770904253,
      "grad_norm": 0.020268065854907036,
      "learning_rate": 9.823455832290957e-06,
      "loss": 0.0006,
      "step": 1115
    },
    {
      "epoch": 0.01767025032854632,
      "grad_norm": 0.14755843579769135,
      "learning_rate": 9.823297496714538e-06,
      "loss": 0.2718,
      "step": 1116
    },
    {
      "epoch": 0.01768608388618839,
      "grad_norm": 0.11409737914800644,
      "learning_rate": 9.823139161138117e-06,
      "loss": 0.0651,
      "step": 1117
    },
    {
      "epoch": 0.017701917443830453,
      "grad_norm": 0.001979869557544589,
      "learning_rate": 9.822980825561696e-06,
      "loss": 0.0002,
      "step": 1118
    },
    {
      "epoch": 0.01771775100147252,
      "grad_norm": 0.17927370965480804,
      "learning_rate": 9.822822489985275e-06,
      "loss": 0.2619,
      "step": 1119
    },
    {
      "epoch": 0.017733584559114588,
      "grad_norm": 0.12374573945999146,
      "learning_rate": 9.822664154408855e-06,
      "loss": 0.0918,
      "step": 1120
    },
    {
      "epoch": 0.017749418116756652,
      "grad_norm": 0.002446996048092842,
      "learning_rate": 9.822505818832434e-06,
      "loss": 0.0001,
      "step": 1121
    },
    {
      "epoch": 0.01776525167439872,
      "grad_norm": 0.051329355686903,
      "learning_rate": 9.822347483256014e-06,
      "loss": 0.0083,
      "step": 1122
    },
    {
      "epoch": 0.017781085232040788,
      "grad_norm": 0.40007996559143066,
      "learning_rate": 9.822189147679593e-06,
      "loss": 0.1094,
      "step": 1123
    },
    {
      "epoch": 0.017796918789682852,
      "grad_norm": 0.41432034969329834,
      "learning_rate": 9.822030812103173e-06,
      "loss": 0.1091,
      "step": 1124
    },
    {
      "epoch": 0.01781275234732492,
      "grad_norm": 0.16691987216472626,
      "learning_rate": 9.821872476526752e-06,
      "loss": 0.1827,
      "step": 1125
    },
    {
      "epoch": 0.017828585904966988,
      "grad_norm": 0.1664479672908783,
      "learning_rate": 9.82171414095033e-06,
      "loss": 0.0569,
      "step": 1126
    },
    {
      "epoch": 0.017844419462609052,
      "grad_norm": 0.11790922284126282,
      "learning_rate": 9.82155580537391e-06,
      "loss": 0.0621,
      "step": 1127
    },
    {
      "epoch": 0.01786025302025112,
      "grad_norm": 0.14056606590747833,
      "learning_rate": 9.82139746979749e-06,
      "loss": 0.0401,
      "step": 1128
    },
    {
      "epoch": 0.017876086577893188,
      "grad_norm": 0.2266111969947815,
      "learning_rate": 9.82123913422107e-06,
      "loss": 0.0735,
      "step": 1129
    },
    {
      "epoch": 0.017891920135535252,
      "grad_norm": 0.0022326260805130005,
      "learning_rate": 9.821080798644649e-06,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 0.01790775369317732,
      "grad_norm": 0.1445501297712326,
      "learning_rate": 9.820922463068228e-06,
      "loss": 0.2188,
      "step": 1131
    },
    {
      "epoch": 0.017923587250819387,
      "grad_norm": 0.14642807841300964,
      "learning_rate": 9.820764127491807e-06,
      "loss": 0.0676,
      "step": 1132
    },
    {
      "epoch": 0.01793942080846145,
      "grad_norm": 0.15574200451374054,
      "learning_rate": 9.820605791915386e-06,
      "loss": 0.0491,
      "step": 1133
    },
    {
      "epoch": 0.01795525436610352,
      "grad_norm": 0.19233913719654083,
      "learning_rate": 9.820447456338965e-06,
      "loss": 0.024,
      "step": 1134
    },
    {
      "epoch": 0.017971087923745587,
      "grad_norm": 0.13236026465892792,
      "learning_rate": 9.820289120762546e-06,
      "loss": 0.0342,
      "step": 1135
    },
    {
      "epoch": 0.01798692148138765,
      "grad_norm": 0.00016934478480834514,
      "learning_rate": 9.820130785186123e-06,
      "loss": 0.0,
      "step": 1136
    },
    {
      "epoch": 0.01800275503902972,
      "grad_norm": 0.20833222568035126,
      "learning_rate": 9.819972449609704e-06,
      "loss": 0.0012,
      "step": 1137
    },
    {
      "epoch": 0.018018588596671787,
      "grad_norm": 0.25757917761802673,
      "learning_rate": 9.819814114033283e-06,
      "loss": 0.5947,
      "step": 1138
    },
    {
      "epoch": 0.01803442215431385,
      "grad_norm": 0.2846888601779938,
      "learning_rate": 9.819655778456862e-06,
      "loss": 0.2704,
      "step": 1139
    },
    {
      "epoch": 0.01805025571195592,
      "grad_norm": 0.012799190357327461,
      "learning_rate": 9.819497442880441e-06,
      "loss": 0.0013,
      "step": 1140
    },
    {
      "epoch": 0.018066089269597987,
      "grad_norm": 0.008501293137669563,
      "learning_rate": 9.819339107304022e-06,
      "loss": 0.0008,
      "step": 1141
    },
    {
      "epoch": 0.01808192282724005,
      "grad_norm": 0.00477543193846941,
      "learning_rate": 9.8191807717276e-06,
      "loss": 0.0004,
      "step": 1142
    },
    {
      "epoch": 0.01809775638488212,
      "grad_norm": 0.00025475354050286114,
      "learning_rate": 9.81902243615118e-06,
      "loss": 0.0,
      "step": 1143
    },
    {
      "epoch": 0.018113589942524187,
      "grad_norm": 0.12972554564476013,
      "learning_rate": 9.81886410057476e-06,
      "loss": 0.0425,
      "step": 1144
    },
    {
      "epoch": 0.01812942350016625,
      "grad_norm": 0.10355586558580399,
      "learning_rate": 9.818705764998338e-06,
      "loss": 0.0783,
      "step": 1145
    },
    {
      "epoch": 0.01814525705780832,
      "grad_norm": 0.1742583066225052,
      "learning_rate": 9.818547429421917e-06,
      "loss": 0.2715,
      "step": 1146
    },
    {
      "epoch": 0.018161090615450386,
      "grad_norm": 0.11905334889888763,
      "learning_rate": 9.818389093845498e-06,
      "loss": 0.1383,
      "step": 1147
    },
    {
      "epoch": 0.01817692417309245,
      "grad_norm": 0.3691530227661133,
      "learning_rate": 9.818230758269076e-06,
      "loss": 0.1611,
      "step": 1148
    },
    {
      "epoch": 0.01819275773073452,
      "grad_norm": 0.20284023880958557,
      "learning_rate": 9.818072422692656e-06,
      "loss": 0.0794,
      "step": 1149
    },
    {
      "epoch": 0.018208591288376586,
      "grad_norm": 0.08887042850255966,
      "learning_rate": 9.817914087116235e-06,
      "loss": 0.0655,
      "step": 1150
    },
    {
      "epoch": 0.01822442484601865,
      "grad_norm": 0.26120632886886597,
      "learning_rate": 9.817755751539814e-06,
      "loss": 0.3368,
      "step": 1151
    },
    {
      "epoch": 0.018240258403660718,
      "grad_norm": 0.14282920956611633,
      "learning_rate": 9.817597415963394e-06,
      "loss": 0.0791,
      "step": 1152
    },
    {
      "epoch": 0.018256091961302786,
      "grad_norm": 0.011415495537221432,
      "learning_rate": 9.817439080386973e-06,
      "loss": 0.0012,
      "step": 1153
    },
    {
      "epoch": 0.01827192551894485,
      "grad_norm": 0.018891600891947746,
      "learning_rate": 9.817280744810552e-06,
      "loss": 0.0021,
      "step": 1154
    },
    {
      "epoch": 0.018287759076586918,
      "grad_norm": 0.0006573281134478748,
      "learning_rate": 9.81712240923413e-06,
      "loss": 0.0,
      "step": 1155
    },
    {
      "epoch": 0.018303592634228986,
      "grad_norm": 0.14027169346809387,
      "learning_rate": 9.816964073657712e-06,
      "loss": 0.0686,
      "step": 1156
    },
    {
      "epoch": 0.01831942619187105,
      "grad_norm": 4.883650779724121,
      "learning_rate": 9.816805738081289e-06,
      "loss": 0.8695,
      "step": 1157
    },
    {
      "epoch": 0.018335259749513118,
      "grad_norm": 0.2708306908607483,
      "learning_rate": 9.81664740250487e-06,
      "loss": 0.3334,
      "step": 1158
    },
    {
      "epoch": 0.018351093307155186,
      "grad_norm": 0.13862620294094086,
      "learning_rate": 9.816489066928449e-06,
      "loss": 0.2436,
      "step": 1159
    },
    {
      "epoch": 0.01836692686479725,
      "grad_norm": 0.22858689725399017,
      "learning_rate": 9.816330731352028e-06,
      "loss": 0.5372,
      "step": 1160
    },
    {
      "epoch": 0.018382760422439318,
      "grad_norm": 0.4826166331768036,
      "learning_rate": 9.816172395775607e-06,
      "loss": 0.2014,
      "step": 1161
    },
    {
      "epoch": 0.018398593980081385,
      "grad_norm": 0.008807161822915077,
      "learning_rate": 9.816014060199188e-06,
      "loss": 0.0007,
      "step": 1162
    },
    {
      "epoch": 0.01841442753772345,
      "grad_norm": 0.1225212812423706,
      "learning_rate": 9.815855724622765e-06,
      "loss": 0.0771,
      "step": 1163
    },
    {
      "epoch": 0.018430261095365517,
      "grad_norm": 0.00034410806256346405,
      "learning_rate": 9.815697389046346e-06,
      "loss": 0.0,
      "step": 1164
    },
    {
      "epoch": 0.018446094653007585,
      "grad_norm": 0.30127835273742676,
      "learning_rate": 9.815539053469925e-06,
      "loss": 0.1203,
      "step": 1165
    },
    {
      "epoch": 0.01846192821064965,
      "grad_norm": 0.14817030727863312,
      "learning_rate": 9.815380717893504e-06,
      "loss": 0.0887,
      "step": 1166
    },
    {
      "epoch": 0.018477761768291717,
      "grad_norm": 0.28493329882621765,
      "learning_rate": 9.815222382317083e-06,
      "loss": 1.7386,
      "step": 1167
    },
    {
      "epoch": 0.018493595325933785,
      "grad_norm": 0.0174053143709898,
      "learning_rate": 9.815064046740664e-06,
      "loss": 0.0018,
      "step": 1168
    },
    {
      "epoch": 0.01850942888357585,
      "grad_norm": 0.42152997851371765,
      "learning_rate": 9.814905711164241e-06,
      "loss": 0.0734,
      "step": 1169
    },
    {
      "epoch": 0.018525262441217917,
      "grad_norm": 0.11931940913200378,
      "learning_rate": 9.814747375587822e-06,
      "loss": 0.1126,
      "step": 1170
    },
    {
      "epoch": 0.018541095998859985,
      "grad_norm": 0.006718419957906008,
      "learning_rate": 9.814589040011401e-06,
      "loss": 0.0006,
      "step": 1171
    },
    {
      "epoch": 0.01855692955650205,
      "grad_norm": 0.20719584822654724,
      "learning_rate": 9.81443070443498e-06,
      "loss": 0.4375,
      "step": 1172
    },
    {
      "epoch": 0.018572763114144117,
      "grad_norm": 0.4075062572956085,
      "learning_rate": 9.81427236885856e-06,
      "loss": 0.1734,
      "step": 1173
    },
    {
      "epoch": 0.018588596671786185,
      "grad_norm": 0.6870152950286865,
      "learning_rate": 9.81411403328214e-06,
      "loss": 0.0656,
      "step": 1174
    },
    {
      "epoch": 0.01860443022942825,
      "grad_norm": 0.46712350845336914,
      "learning_rate": 9.813955697705717e-06,
      "loss": 0.1704,
      "step": 1175
    },
    {
      "epoch": 0.018620263787070317,
      "grad_norm": 0.1976577490568161,
      "learning_rate": 9.813797362129298e-06,
      "loss": 0.0116,
      "step": 1176
    },
    {
      "epoch": 0.018636097344712384,
      "grad_norm": 0.2755480408668518,
      "learning_rate": 9.813639026552877e-06,
      "loss": 0.2069,
      "step": 1177
    },
    {
      "epoch": 0.01865193090235445,
      "grad_norm": 0.00039275275776162744,
      "learning_rate": 9.813480690976456e-06,
      "loss": 0.0,
      "step": 1178
    },
    {
      "epoch": 0.018667764459996516,
      "grad_norm": 0.01091793179512024,
      "learning_rate": 9.813322355400035e-06,
      "loss": 0.0011,
      "step": 1179
    },
    {
      "epoch": 0.018683598017638584,
      "grad_norm": 0.16268761456012726,
      "learning_rate": 9.813164019823615e-06,
      "loss": 0.0076,
      "step": 1180
    },
    {
      "epoch": 0.01869943157528065,
      "grad_norm": 0.2374630570411682,
      "learning_rate": 9.813005684247194e-06,
      "loss": 0.2836,
      "step": 1181
    },
    {
      "epoch": 0.018715265132922716,
      "grad_norm": 0.1890849471092224,
      "learning_rate": 9.812847348670773e-06,
      "loss": 0.4253,
      "step": 1182
    },
    {
      "epoch": 0.018731098690564784,
      "grad_norm": 0.13948535919189453,
      "learning_rate": 9.812689013094353e-06,
      "loss": 0.1057,
      "step": 1183
    },
    {
      "epoch": 0.01874693224820685,
      "grad_norm": 0.1382155418395996,
      "learning_rate": 9.812530677517933e-06,
      "loss": 0.5322,
      "step": 1184
    },
    {
      "epoch": 0.018762765805848916,
      "grad_norm": 0.5412607192993164,
      "learning_rate": 9.812372341941512e-06,
      "loss": 0.1055,
      "step": 1185
    },
    {
      "epoch": 0.018778599363490984,
      "grad_norm": 0.0785910114645958,
      "learning_rate": 9.81221400636509e-06,
      "loss": 0.0048,
      "step": 1186
    },
    {
      "epoch": 0.018794432921133048,
      "grad_norm": 0.019679289311170578,
      "learning_rate": 9.81205567078867e-06,
      "loss": 0.002,
      "step": 1187
    },
    {
      "epoch": 0.018810266478775116,
      "grad_norm": 0.7274472713470459,
      "learning_rate": 9.811897335212249e-06,
      "loss": 0.2425,
      "step": 1188
    },
    {
      "epoch": 0.018826100036417184,
      "grad_norm": 0.31653913855552673,
      "learning_rate": 9.81173899963583e-06,
      "loss": 0.2166,
      "step": 1189
    },
    {
      "epoch": 0.018841933594059248,
      "grad_norm": 0.35364386439323425,
      "learning_rate": 9.811580664059409e-06,
      "loss": 0.294,
      "step": 1190
    },
    {
      "epoch": 0.018857767151701316,
      "grad_norm": 0.00030256601166911423,
      "learning_rate": 9.811422328482988e-06,
      "loss": 0.0,
      "step": 1191
    },
    {
      "epoch": 0.018873600709343383,
      "grad_norm": 0.23267942667007446,
      "learning_rate": 9.811263992906567e-06,
      "loss": 0.6347,
      "step": 1192
    },
    {
      "epoch": 0.018889434266985448,
      "grad_norm": 0.2893056869506836,
      "learning_rate": 9.811105657330146e-06,
      "loss": 0.3846,
      "step": 1193
    },
    {
      "epoch": 0.018905267824627515,
      "grad_norm": 0.5385487079620361,
      "learning_rate": 9.810947321753725e-06,
      "loss": 0.2103,
      "step": 1194
    },
    {
      "epoch": 0.018921101382269583,
      "grad_norm": 0.180441752076149,
      "learning_rate": 9.810788986177306e-06,
      "loss": 0.0167,
      "step": 1195
    },
    {
      "epoch": 0.018936934939911648,
      "grad_norm": 0.21099697053432465,
      "learning_rate": 9.810630650600885e-06,
      "loss": 0.1825,
      "step": 1196
    },
    {
      "epoch": 0.018952768497553715,
      "grad_norm": 0.1186661422252655,
      "learning_rate": 9.810472315024464e-06,
      "loss": 0.1214,
      "step": 1197
    },
    {
      "epoch": 0.018968602055195783,
      "grad_norm": 0.1303475797176361,
      "learning_rate": 9.810313979448043e-06,
      "loss": 0.1102,
      "step": 1198
    },
    {
      "epoch": 0.018984435612837847,
      "grad_norm": 0.3105955421924591,
      "learning_rate": 9.810155643871622e-06,
      "loss": 0.6496,
      "step": 1199
    },
    {
      "epoch": 0.019000269170479915,
      "grad_norm": 0.46303653717041016,
      "learning_rate": 9.809997308295201e-06,
      "loss": 0.1472,
      "step": 1200
    },
    {
      "epoch": 0.019016102728121983,
      "grad_norm": 0.2809060215950012,
      "learning_rate": 9.809838972718782e-06,
      "loss": 0.0816,
      "step": 1201
    },
    {
      "epoch": 0.019031936285764047,
      "grad_norm": 0.20791301131248474,
      "learning_rate": 9.809680637142361e-06,
      "loss": 0.5082,
      "step": 1202
    },
    {
      "epoch": 0.019047769843406115,
      "grad_norm": 0.2321985363960266,
      "learning_rate": 9.809522301565938e-06,
      "loss": 0.331,
      "step": 1203
    },
    {
      "epoch": 0.019063603401048183,
      "grad_norm": 0.27797555923461914,
      "learning_rate": 9.80936396598952e-06,
      "loss": 0.7931,
      "step": 1204
    },
    {
      "epoch": 0.019079436958690247,
      "grad_norm": 0.01039035338908434,
      "learning_rate": 9.809205630413098e-06,
      "loss": 0.0008,
      "step": 1205
    },
    {
      "epoch": 0.019095270516332315,
      "grad_norm": 0.15166214108467102,
      "learning_rate": 9.809047294836677e-06,
      "loss": 0.2708,
      "step": 1206
    },
    {
      "epoch": 0.019111104073974382,
      "grad_norm": 0.22056211531162262,
      "learning_rate": 9.808888959260256e-06,
      "loss": 0.3723,
      "step": 1207
    },
    {
      "epoch": 0.019126937631616447,
      "grad_norm": 0.3389981687068939,
      "learning_rate": 9.808730623683837e-06,
      "loss": 0.3342,
      "step": 1208
    },
    {
      "epoch": 0.019142771189258515,
      "grad_norm": 0.34306150674819946,
      "learning_rate": 9.808572288107415e-06,
      "loss": 0.1955,
      "step": 1209
    },
    {
      "epoch": 0.019158604746900582,
      "grad_norm": 3.6088149547576904,
      "learning_rate": 9.808413952530995e-06,
      "loss": 0.7323,
      "step": 1210
    },
    {
      "epoch": 0.019174438304542647,
      "grad_norm": 0.24774356186389923,
      "learning_rate": 9.808255616954574e-06,
      "loss": 0.9383,
      "step": 1211
    },
    {
      "epoch": 0.019190271862184714,
      "grad_norm": 0.29119494557380676,
      "learning_rate": 9.808097281378154e-06,
      "loss": 0.3774,
      "step": 1212
    },
    {
      "epoch": 0.019206105419826782,
      "grad_norm": 0.19935406744480133,
      "learning_rate": 9.807938945801733e-06,
      "loss": 0.1499,
      "step": 1213
    },
    {
      "epoch": 0.019221938977468846,
      "grad_norm": 0.08627239614725113,
      "learning_rate": 9.807780610225313e-06,
      "loss": 0.0045,
      "step": 1214
    },
    {
      "epoch": 0.019237772535110914,
      "grad_norm": 0.10991550981998444,
      "learning_rate": 9.80762227464889e-06,
      "loss": 0.0503,
      "step": 1215
    },
    {
      "epoch": 0.019253606092752982,
      "grad_norm": 0.08603787422180176,
      "learning_rate": 9.807463939072472e-06,
      "loss": 0.0503,
      "step": 1216
    },
    {
      "epoch": 0.019269439650395046,
      "grad_norm": 0.32624515891075134,
      "learning_rate": 9.80730560349605e-06,
      "loss": 0.3785,
      "step": 1217
    },
    {
      "epoch": 0.019285273208037114,
      "grad_norm": 0.005796859506517649,
      "learning_rate": 9.80714726791963e-06,
      "loss": 0.0005,
      "step": 1218
    },
    {
      "epoch": 0.01930110676567918,
      "grad_norm": 0.28420913219451904,
      "learning_rate": 9.806988932343209e-06,
      "loss": 0.0617,
      "step": 1219
    },
    {
      "epoch": 0.019316940323321246,
      "grad_norm": 0.0025379417929798365,
      "learning_rate": 9.806830596766788e-06,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 0.019332773880963314,
      "grad_norm": 0.1900254487991333,
      "learning_rate": 9.806672261190367e-06,
      "loss": 0.427,
      "step": 1221
    },
    {
      "epoch": 0.01934860743860538,
      "grad_norm": 0.20734941959381104,
      "learning_rate": 9.806513925613948e-06,
      "loss": 0.1545,
      "step": 1222
    },
    {
      "epoch": 0.019364440996247446,
      "grad_norm": 0.24112391471862793,
      "learning_rate": 9.806355590037527e-06,
      "loss": 0.2938,
      "step": 1223
    },
    {
      "epoch": 0.019380274553889514,
      "grad_norm": 0.3080074191093445,
      "learning_rate": 9.806197254461106e-06,
      "loss": 0.3292,
      "step": 1224
    },
    {
      "epoch": 0.01939610811153158,
      "grad_norm": 0.014475211501121521,
      "learning_rate": 9.806038918884685e-06,
      "loss": 0.0002,
      "step": 1225
    },
    {
      "epoch": 0.019411941669173646,
      "grad_norm": 0.006963518913835287,
      "learning_rate": 9.805880583308264e-06,
      "loss": 0.0006,
      "step": 1226
    },
    {
      "epoch": 0.019427775226815713,
      "grad_norm": 0.13752472400665283,
      "learning_rate": 9.805722247731843e-06,
      "loss": 0.4556,
      "step": 1227
    },
    {
      "epoch": 0.01944360878445778,
      "grad_norm": 0.008423535153269768,
      "learning_rate": 9.805563912155422e-06,
      "loss": 0.0007,
      "step": 1228
    },
    {
      "epoch": 0.019459442342099845,
      "grad_norm": 0.13140058517456055,
      "learning_rate": 9.805405576579003e-06,
      "loss": 0.0759,
      "step": 1229
    },
    {
      "epoch": 0.019475275899741913,
      "grad_norm": 0.1780419498682022,
      "learning_rate": 9.80524724100258e-06,
      "loss": 0.3025,
      "step": 1230
    },
    {
      "epoch": 0.01949110945738398,
      "grad_norm": 0.004319692961871624,
      "learning_rate": 9.805088905426161e-06,
      "loss": 0.0001,
      "step": 1231
    },
    {
      "epoch": 0.019506943015026045,
      "grad_norm": 0.03994155675172806,
      "learning_rate": 9.80493056984974e-06,
      "loss": 0.0006,
      "step": 1232
    },
    {
      "epoch": 0.019522776572668113,
      "grad_norm": 0.509560763835907,
      "learning_rate": 9.80477223427332e-06,
      "loss": 0.0746,
      "step": 1233
    },
    {
      "epoch": 0.01953861013031018,
      "grad_norm": 0.0022438927553594112,
      "learning_rate": 9.804613898696898e-06,
      "loss": 0.0001,
      "step": 1234
    },
    {
      "epoch": 0.019554443687952245,
      "grad_norm": 0.3877907395362854,
      "learning_rate": 9.80445556312048e-06,
      "loss": 0.229,
      "step": 1235
    },
    {
      "epoch": 0.019570277245594313,
      "grad_norm": 0.14604470133781433,
      "learning_rate": 9.804297227544057e-06,
      "loss": 0.4836,
      "step": 1236
    },
    {
      "epoch": 0.01958611080323638,
      "grad_norm": 0.1399136334657669,
      "learning_rate": 9.804138891967637e-06,
      "loss": 0.2144,
      "step": 1237
    },
    {
      "epoch": 0.019601944360878445,
      "grad_norm": 0.004725488368421793,
      "learning_rate": 9.803980556391216e-06,
      "loss": 0.0003,
      "step": 1238
    },
    {
      "epoch": 0.019617777918520513,
      "grad_norm": 0.02028781548142433,
      "learning_rate": 9.803822220814795e-06,
      "loss": 0.0024,
      "step": 1239
    },
    {
      "epoch": 0.01963361147616258,
      "grad_norm": 0.15354029834270477,
      "learning_rate": 9.803663885238375e-06,
      "loss": 0.0915,
      "step": 1240
    },
    {
      "epoch": 0.019649445033804645,
      "grad_norm": 0.29055875539779663,
      "learning_rate": 9.803505549661955e-06,
      "loss": 0.4102,
      "step": 1241
    },
    {
      "epoch": 0.019665278591446712,
      "grad_norm": 0.19148045778274536,
      "learning_rate": 9.803347214085533e-06,
      "loss": 0.0594,
      "step": 1242
    },
    {
      "epoch": 0.01968111214908878,
      "grad_norm": 0.2463051825761795,
      "learning_rate": 9.803188878509113e-06,
      "loss": 0.2253,
      "step": 1243
    },
    {
      "epoch": 0.019696945706730844,
      "grad_norm": 0.1389198750257492,
      "learning_rate": 9.803030542932693e-06,
      "loss": 0.027,
      "step": 1244
    },
    {
      "epoch": 0.019712779264372912,
      "grad_norm": 0.1517263650894165,
      "learning_rate": 9.802872207356272e-06,
      "loss": 0.5172,
      "step": 1245
    },
    {
      "epoch": 0.01972861282201498,
      "grad_norm": 0.12843680381774902,
      "learning_rate": 9.80271387177985e-06,
      "loss": 0.271,
      "step": 1246
    },
    {
      "epoch": 0.019744446379657044,
      "grad_norm": 0.00262918951921165,
      "learning_rate": 9.802555536203432e-06,
      "loss": 0.0001,
      "step": 1247
    },
    {
      "epoch": 0.019760279937299112,
      "grad_norm": 0.07648025453090668,
      "learning_rate": 9.802397200627009e-06,
      "loss": 0.0344,
      "step": 1248
    },
    {
      "epoch": 0.01977611349494118,
      "grad_norm": 0.3042580783367157,
      "learning_rate": 9.80223886505059e-06,
      "loss": 0.1994,
      "step": 1249
    },
    {
      "epoch": 0.019791947052583244,
      "grad_norm": 0.3017566204071045,
      "learning_rate": 9.802080529474169e-06,
      "loss": 0.2549,
      "step": 1250
    },
    {
      "epoch": 0.019807780610225312,
      "grad_norm": 0.36510488390922546,
      "learning_rate": 9.801922193897748e-06,
      "loss": 0.0995,
      "step": 1251
    },
    {
      "epoch": 0.01982361416786738,
      "grad_norm": 0.2078775018453598,
      "learning_rate": 9.801763858321327e-06,
      "loss": 0.0511,
      "step": 1252
    },
    {
      "epoch": 0.019839447725509444,
      "grad_norm": 0.27893733978271484,
      "learning_rate": 9.801605522744906e-06,
      "loss": 0.2275,
      "step": 1253
    },
    {
      "epoch": 0.01985528128315151,
      "grad_norm": 0.3166007995605469,
      "learning_rate": 9.801447187168485e-06,
      "loss": 0.1189,
      "step": 1254
    },
    {
      "epoch": 0.01987111484079358,
      "grad_norm": 0.13555532693862915,
      "learning_rate": 9.801288851592064e-06,
      "loss": 0.0489,
      "step": 1255
    },
    {
      "epoch": 0.019886948398435644,
      "grad_norm": 0.08517822623252869,
      "learning_rate": 9.801130516015645e-06,
      "loss": 0.0211,
      "step": 1256
    },
    {
      "epoch": 0.01990278195607771,
      "grad_norm": 0.22982032597064972,
      "learning_rate": 9.800972180439224e-06,
      "loss": 0.3887,
      "step": 1257
    },
    {
      "epoch": 0.01991861551371978,
      "grad_norm": 0.08775466680526733,
      "learning_rate": 9.800813844862803e-06,
      "loss": 0.0093,
      "step": 1258
    },
    {
      "epoch": 0.019934449071361843,
      "grad_norm": 0.17641647160053253,
      "learning_rate": 9.800655509286382e-06,
      "loss": 0.1463,
      "step": 1259
    },
    {
      "epoch": 0.01995028262900391,
      "grad_norm": 0.2480398416519165,
      "learning_rate": 9.800497173709961e-06,
      "loss": 0.1361,
      "step": 1260
    },
    {
      "epoch": 0.01996611618664598,
      "grad_norm": 0.2781534492969513,
      "learning_rate": 9.80033883813354e-06,
      "loss": 0.2301,
      "step": 1261
    },
    {
      "epoch": 0.019981949744288043,
      "grad_norm": 0.27662062644958496,
      "learning_rate": 9.800180502557121e-06,
      "loss": 0.1206,
      "step": 1262
    },
    {
      "epoch": 0.01999778330193011,
      "grad_norm": 0.26252758502960205,
      "learning_rate": 9.8000221669807e-06,
      "loss": 0.14,
      "step": 1263
    },
    {
      "epoch": 0.02001361685957218,
      "grad_norm": 0.11522158980369568,
      "learning_rate": 9.79986383140428e-06,
      "loss": 0.2996,
      "step": 1264
    },
    {
      "epoch": 0.020029450417214243,
      "grad_norm": 0.015147381462156773,
      "learning_rate": 9.799705495827858e-06,
      "loss": 0.0012,
      "step": 1265
    },
    {
      "epoch": 0.02004528397485631,
      "grad_norm": 0.1819886565208435,
      "learning_rate": 9.799547160251437e-06,
      "loss": 0.5057,
      "step": 1266
    },
    {
      "epoch": 0.02006111753249838,
      "grad_norm": 0.21898452937602997,
      "learning_rate": 9.799388824675016e-06,
      "loss": 0.5568,
      "step": 1267
    },
    {
      "epoch": 0.020076951090140443,
      "grad_norm": 0.10588287562131882,
      "learning_rate": 9.799230489098597e-06,
      "loss": 0.0083,
      "step": 1268
    },
    {
      "epoch": 0.02009278464778251,
      "grad_norm": 0.6144198775291443,
      "learning_rate": 9.799072153522176e-06,
      "loss": 0.3215,
      "step": 1269
    },
    {
      "epoch": 0.02010861820542458,
      "grad_norm": 0.28605538606643677,
      "learning_rate": 9.798913817945755e-06,
      "loss": 0.3801,
      "step": 1270
    },
    {
      "epoch": 0.020124451763066643,
      "grad_norm": 0.18258318305015564,
      "learning_rate": 9.798755482369335e-06,
      "loss": 0.1776,
      "step": 1271
    },
    {
      "epoch": 0.02014028532070871,
      "grad_norm": 0.2504761219024658,
      "learning_rate": 9.798597146792914e-06,
      "loss": 0.1429,
      "step": 1272
    },
    {
      "epoch": 0.020156118878350778,
      "grad_norm": 0.023819006979465485,
      "learning_rate": 9.798438811216493e-06,
      "loss": 0.0017,
      "step": 1273
    },
    {
      "epoch": 0.020171952435992842,
      "grad_norm": 0.010769879445433617,
      "learning_rate": 9.798280475640073e-06,
      "loss": 0.0004,
      "step": 1274
    },
    {
      "epoch": 0.02018778599363491,
      "grad_norm": 0.1339343786239624,
      "learning_rate": 9.798122140063653e-06,
      "loss": 0.003,
      "step": 1275
    },
    {
      "epoch": 0.020203619551276978,
      "grad_norm": 0.18296273052692413,
      "learning_rate": 9.79796380448723e-06,
      "loss": 0.1327,
      "step": 1276
    },
    {
      "epoch": 0.020219453108919042,
      "grad_norm": 0.00828382559120655,
      "learning_rate": 9.79780546891081e-06,
      "loss": 0.0005,
      "step": 1277
    },
    {
      "epoch": 0.02023528666656111,
      "grad_norm": 0.35741233825683594,
      "learning_rate": 9.79764713333439e-06,
      "loss": 0.1018,
      "step": 1278
    },
    {
      "epoch": 0.020251120224203178,
      "grad_norm": 0.002954653697088361,
      "learning_rate": 9.797488797757969e-06,
      "loss": 0.0001,
      "step": 1279
    },
    {
      "epoch": 0.020266953781845242,
      "grad_norm": 0.30867648124694824,
      "learning_rate": 9.797330462181548e-06,
      "loss": 0.1195,
      "step": 1280
    },
    {
      "epoch": 0.02028278733948731,
      "grad_norm": 0.17308633029460907,
      "learning_rate": 9.797172126605129e-06,
      "loss": 0.0933,
      "step": 1281
    },
    {
      "epoch": 0.020298620897129378,
      "grad_norm": 0.27358192205429077,
      "learning_rate": 9.797013791028706e-06,
      "loss": 0.0843,
      "step": 1282
    },
    {
      "epoch": 0.020314454454771442,
      "grad_norm": 0.40835726261138916,
      "learning_rate": 9.796855455452287e-06,
      "loss": 0.0308,
      "step": 1283
    },
    {
      "epoch": 0.02033028801241351,
      "grad_norm": 0.32077568769454956,
      "learning_rate": 9.796697119875866e-06,
      "loss": 0.4761,
      "step": 1284
    },
    {
      "epoch": 0.020346121570055577,
      "grad_norm": 0.33897465467453003,
      "learning_rate": 9.796538784299445e-06,
      "loss": 0.0377,
      "step": 1285
    },
    {
      "epoch": 0.02036195512769764,
      "grad_norm": 0.17299354076385498,
      "learning_rate": 9.796380448723024e-06,
      "loss": 0.2519,
      "step": 1286
    },
    {
      "epoch": 0.02037778868533971,
      "grad_norm": 0.3031158149242401,
      "learning_rate": 9.796222113146603e-06,
      "loss": 0.3792,
      "step": 1287
    },
    {
      "epoch": 0.020393622242981777,
      "grad_norm": 0.24066036939620972,
      "learning_rate": 9.796063777570182e-06,
      "loss": 0.1748,
      "step": 1288
    },
    {
      "epoch": 0.02040945580062384,
      "grad_norm": 0.1874336451292038,
      "learning_rate": 9.795905441993763e-06,
      "loss": 0.2026,
      "step": 1289
    },
    {
      "epoch": 0.02042528935826591,
      "grad_norm": 0.014294960536062717,
      "learning_rate": 9.795747106417342e-06,
      "loss": 0.001,
      "step": 1290
    },
    {
      "epoch": 0.020441122915907977,
      "grad_norm": 0.2692914605140686,
      "learning_rate": 9.795588770840921e-06,
      "loss": 0.1138,
      "step": 1291
    },
    {
      "epoch": 0.02045695647355004,
      "grad_norm": 0.3228006660938263,
      "learning_rate": 9.7954304352645e-06,
      "loss": 0.2562,
      "step": 1292
    },
    {
      "epoch": 0.02047279003119211,
      "grad_norm": 0.008657047525048256,
      "learning_rate": 9.79527209968808e-06,
      "loss": 0.0008,
      "step": 1293
    },
    {
      "epoch": 0.020488623588834177,
      "grad_norm": 0.25960296392440796,
      "learning_rate": 9.795113764111658e-06,
      "loss": 0.0142,
      "step": 1294
    },
    {
      "epoch": 0.02050445714647624,
      "grad_norm": 0.0010479813208803535,
      "learning_rate": 9.79495542853524e-06,
      "loss": 0.0,
      "step": 1295
    },
    {
      "epoch": 0.02052029070411831,
      "grad_norm": 0.1677124798297882,
      "learning_rate": 9.794797092958818e-06,
      "loss": 0.0643,
      "step": 1296
    },
    {
      "epoch": 0.020536124261760377,
      "grad_norm": 0.007007558364421129,
      "learning_rate": 9.794638757382397e-06,
      "loss": 0.0004,
      "step": 1297
    },
    {
      "epoch": 0.02055195781940244,
      "grad_norm": 0.0232051070779562,
      "learning_rate": 9.794480421805976e-06,
      "loss": 0.004,
      "step": 1298
    },
    {
      "epoch": 0.02056779137704451,
      "grad_norm": 0.04555541276931763,
      "learning_rate": 9.794322086229556e-06,
      "loss": 0.0022,
      "step": 1299
    },
    {
      "epoch": 0.020583624934686576,
      "grad_norm": 0.29738160967826843,
      "learning_rate": 9.794163750653135e-06,
      "loss": 1.2485,
      "step": 1300
    },
    {
      "epoch": 0.02059945849232864,
      "grad_norm": 0.32330116629600525,
      "learning_rate": 9.794005415076714e-06,
      "loss": 0.1182,
      "step": 1301
    },
    {
      "epoch": 0.02061529204997071,
      "grad_norm": 0.3500559329986572,
      "learning_rate": 9.793847079500294e-06,
      "loss": 0.5294,
      "step": 1302
    },
    {
      "epoch": 0.020631125607612776,
      "grad_norm": 0.0014797128969803452,
      "learning_rate": 9.793688743923872e-06,
      "loss": 0.0,
      "step": 1303
    },
    {
      "epoch": 0.02064695916525484,
      "grad_norm": 0.6506023406982422,
      "learning_rate": 9.793530408347453e-06,
      "loss": 0.1427,
      "step": 1304
    },
    {
      "epoch": 0.02066279272289691,
      "grad_norm": 0.2579982578754425,
      "learning_rate": 9.793372072771032e-06,
      "loss": 0.2718,
      "step": 1305
    },
    {
      "epoch": 0.020678626280538976,
      "grad_norm": 0.43280690908432007,
      "learning_rate": 9.79321373719461e-06,
      "loss": 0.3445,
      "step": 1306
    },
    {
      "epoch": 0.02069445983818104,
      "grad_norm": 0.23143848776817322,
      "learning_rate": 9.79305540161819e-06,
      "loss": 0.1205,
      "step": 1307
    },
    {
      "epoch": 0.020710293395823108,
      "grad_norm": 0.5357481241226196,
      "learning_rate": 9.79289706604177e-06,
      "loss": 0.0266,
      "step": 1308
    },
    {
      "epoch": 0.020726126953465172,
      "grad_norm": 0.20544488728046417,
      "learning_rate": 9.792738730465348e-06,
      "loss": 0.2151,
      "step": 1309
    },
    {
      "epoch": 0.02074196051110724,
      "grad_norm": 0.6261719465255737,
      "learning_rate": 9.792580394888929e-06,
      "loss": 0.2305,
      "step": 1310
    },
    {
      "epoch": 0.020757794068749308,
      "grad_norm": 0.08669248968362808,
      "learning_rate": 9.792422059312508e-06,
      "loss": 0.0424,
      "step": 1311
    },
    {
      "epoch": 0.020773627626391372,
      "grad_norm": 0.018658041954040527,
      "learning_rate": 9.792263723736087e-06,
      "loss": 0.0008,
      "step": 1312
    },
    {
      "epoch": 0.02078946118403344,
      "grad_norm": 0.11490418761968613,
      "learning_rate": 9.792105388159666e-06,
      "loss": 0.1414,
      "step": 1313
    },
    {
      "epoch": 0.020805294741675508,
      "grad_norm": 2.2477691173553467,
      "learning_rate": 9.791947052583247e-06,
      "loss": 0.3409,
      "step": 1314
    },
    {
      "epoch": 0.020821128299317572,
      "grad_norm": 0.41241776943206787,
      "learning_rate": 9.791788717006824e-06,
      "loss": 0.048,
      "step": 1315
    },
    {
      "epoch": 0.02083696185695964,
      "grad_norm": 0.35067638754844666,
      "learning_rate": 9.791630381430405e-06,
      "loss": 0.3135,
      "step": 1316
    },
    {
      "epoch": 0.020852795414601707,
      "grad_norm": 0.37361007928848267,
      "learning_rate": 9.791472045853984e-06,
      "loss": 1.32,
      "step": 1317
    },
    {
      "epoch": 0.020868628972243772,
      "grad_norm": 0.18163131177425385,
      "learning_rate": 9.791313710277563e-06,
      "loss": 0.121,
      "step": 1318
    },
    {
      "epoch": 0.02088446252988584,
      "grad_norm": 0.18758980929851532,
      "learning_rate": 9.791155374701142e-06,
      "loss": 0.1274,
      "step": 1319
    },
    {
      "epoch": 0.020900296087527907,
      "grad_norm": 0.19551002979278564,
      "learning_rate": 9.790997039124723e-06,
      "loss": 0.5562,
      "step": 1320
    },
    {
      "epoch": 0.02091612964516997,
      "grad_norm": 0.2286403477191925,
      "learning_rate": 9.7908387035483e-06,
      "loss": 0.1758,
      "step": 1321
    },
    {
      "epoch": 0.02093196320281204,
      "grad_norm": 0.1703656166791916,
      "learning_rate": 9.790680367971881e-06,
      "loss": 0.0673,
      "step": 1322
    },
    {
      "epoch": 0.020947796760454107,
      "grad_norm": 0.15686924755573273,
      "learning_rate": 9.79052203239546e-06,
      "loss": 0.2393,
      "step": 1323
    },
    {
      "epoch": 0.02096363031809617,
      "grad_norm": 0.08055649697780609,
      "learning_rate": 9.79036369681904e-06,
      "loss": 0.0857,
      "step": 1324
    },
    {
      "epoch": 0.02097946387573824,
      "grad_norm": 0.4200853705406189,
      "learning_rate": 9.790205361242618e-06,
      "loss": 0.1126,
      "step": 1325
    },
    {
      "epoch": 0.020995297433380307,
      "grad_norm": 0.007743312045931816,
      "learning_rate": 9.790047025666197e-06,
      "loss": 0.0006,
      "step": 1326
    },
    {
      "epoch": 0.02101113099102237,
      "grad_norm": 0.4638499617576599,
      "learning_rate": 9.789888690089777e-06,
      "loss": 0.0719,
      "step": 1327
    },
    {
      "epoch": 0.02102696454866444,
      "grad_norm": 0.43021321296691895,
      "learning_rate": 9.789730354513356e-06,
      "loss": 0.1797,
      "step": 1328
    },
    {
      "epoch": 0.021042798106306507,
      "grad_norm": 0.07641587406396866,
      "learning_rate": 9.789572018936936e-06,
      "loss": 0.0014,
      "step": 1329
    },
    {
      "epoch": 0.02105863166394857,
      "grad_norm": 0.023343142122030258,
      "learning_rate": 9.789413683360515e-06,
      "loss": 0.0031,
      "step": 1330
    },
    {
      "epoch": 0.02107446522159064,
      "grad_norm": 0.2697482109069824,
      "learning_rate": 9.789255347784095e-06,
      "loss": 0.2875,
      "step": 1331
    },
    {
      "epoch": 0.021090298779232707,
      "grad_norm": 0.007786606438457966,
      "learning_rate": 9.789097012207674e-06,
      "loss": 0.0008,
      "step": 1332
    },
    {
      "epoch": 0.02110613233687477,
      "grad_norm": 0.0921768769621849,
      "learning_rate": 9.788938676631253e-06,
      "loss": 0.0532,
      "step": 1333
    },
    {
      "epoch": 0.02112196589451684,
      "grad_norm": 0.0003681585658341646,
      "learning_rate": 9.788780341054832e-06,
      "loss": 0.0,
      "step": 1334
    },
    {
      "epoch": 0.021137799452158906,
      "grad_norm": 0.23567789793014526,
      "learning_rate": 9.788622005478413e-06,
      "loss": 0.035,
      "step": 1335
    },
    {
      "epoch": 0.02115363300980097,
      "grad_norm": 0.4721473455429077,
      "learning_rate": 9.788463669901992e-06,
      "loss": 0.1529,
      "step": 1336
    },
    {
      "epoch": 0.02116946656744304,
      "grad_norm": 0.2420348823070526,
      "learning_rate": 9.78830533432557e-06,
      "loss": 0.0979,
      "step": 1337
    },
    {
      "epoch": 0.021185300125085106,
      "grad_norm": 0.014460079371929169,
      "learning_rate": 9.78814699874915e-06,
      "loss": 0.0011,
      "step": 1338
    },
    {
      "epoch": 0.02120113368272717,
      "grad_norm": 0.34473416209220886,
      "learning_rate": 9.787988663172729e-06,
      "loss": 0.2692,
      "step": 1339
    },
    {
      "epoch": 0.021216967240369238,
      "grad_norm": 0.0006285851704888046,
      "learning_rate": 9.787830327596308e-06,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.021232800798011306,
      "grad_norm": 0.13506393134593964,
      "learning_rate": 9.787671992019889e-06,
      "loss": 0.0825,
      "step": 1341
    },
    {
      "epoch": 0.02124863435565337,
      "grad_norm": 0.2591502070426941,
      "learning_rate": 9.787513656443468e-06,
      "loss": 0.2223,
      "step": 1342
    },
    {
      "epoch": 0.021264467913295438,
      "grad_norm": 0.0017965288134291768,
      "learning_rate": 9.787355320867047e-06,
      "loss": 0.0,
      "step": 1343
    },
    {
      "epoch": 0.021280301470937506,
      "grad_norm": 0.006093097850680351,
      "learning_rate": 9.787196985290626e-06,
      "loss": 0.0006,
      "step": 1344
    },
    {
      "epoch": 0.02129613502857957,
      "grad_norm": 0.022089309990406036,
      "learning_rate": 9.787038649714205e-06,
      "loss": 0.0022,
      "step": 1345
    },
    {
      "epoch": 0.021311968586221638,
      "grad_norm": 0.9780541658401489,
      "learning_rate": 9.786880314137784e-06,
      "loss": 0.2027,
      "step": 1346
    },
    {
      "epoch": 0.021327802143863706,
      "grad_norm": 0.0004989092121832073,
      "learning_rate": 9.786721978561365e-06,
      "loss": 0.0,
      "step": 1347
    },
    {
      "epoch": 0.02134363570150577,
      "grad_norm": 0.012799997813999653,
      "learning_rate": 9.786563642984942e-06,
      "loss": 0.0012,
      "step": 1348
    },
    {
      "epoch": 0.021359469259147838,
      "grad_norm": 0.19506050646305084,
      "learning_rate": 9.786405307408521e-06,
      "loss": 0.1826,
      "step": 1349
    },
    {
      "epoch": 0.021375302816789905,
      "grad_norm": 0.08106569200754166,
      "learning_rate": 9.786246971832102e-06,
      "loss": 0.0177,
      "step": 1350
    },
    {
      "epoch": 0.02139113637443197,
      "grad_norm": 0.38635921478271484,
      "learning_rate": 9.786088636255681e-06,
      "loss": 0.2556,
      "step": 1351
    },
    {
      "epoch": 0.021406969932074037,
      "grad_norm": 0.00032941915560513735,
      "learning_rate": 9.78593030067926e-06,
      "loss": 0.0,
      "step": 1352
    },
    {
      "epoch": 0.021422803489716105,
      "grad_norm": 0.13161788880825043,
      "learning_rate": 9.78577196510284e-06,
      "loss": 0.0671,
      "step": 1353
    },
    {
      "epoch": 0.02143863704735817,
      "grad_norm": 0.1824280023574829,
      "learning_rate": 9.785613629526418e-06,
      "loss": 0.2512,
      "step": 1354
    },
    {
      "epoch": 0.021454470605000237,
      "grad_norm": 0.011965110898017883,
      "learning_rate": 9.785455293949998e-06,
      "loss": 0.0009,
      "step": 1355
    },
    {
      "epoch": 0.021470304162642305,
      "grad_norm": 0.28614163398742676,
      "learning_rate": 9.785296958373578e-06,
      "loss": 0.3881,
      "step": 1356
    },
    {
      "epoch": 0.02148613772028437,
      "grad_norm": 0.0001710309588816017,
      "learning_rate": 9.785138622797157e-06,
      "loss": 0.0,
      "step": 1357
    },
    {
      "epoch": 0.021501971277926437,
      "grad_norm": 0.21685022115707397,
      "learning_rate": 9.784980287220736e-06,
      "loss": 0.0934,
      "step": 1358
    },
    {
      "epoch": 0.021517804835568505,
      "grad_norm": 0.1250048577785492,
      "learning_rate": 9.784821951644316e-06,
      "loss": 0.0902,
      "step": 1359
    },
    {
      "epoch": 0.02153363839321057,
      "grad_norm": 0.14852258563041687,
      "learning_rate": 9.784663616067895e-06,
      "loss": 0.0658,
      "step": 1360
    },
    {
      "epoch": 0.021549471950852637,
      "grad_norm": 0.20543867349624634,
      "learning_rate": 9.784505280491474e-06,
      "loss": 0.0888,
      "step": 1361
    },
    {
      "epoch": 0.021565305508494705,
      "grad_norm": 0.1585494875907898,
      "learning_rate": 9.784346944915054e-06,
      "loss": 0.0922,
      "step": 1362
    },
    {
      "epoch": 0.02158113906613677,
      "grad_norm": 0.22728218138217926,
      "learning_rate": 9.784188609338634e-06,
      "loss": 0.5488,
      "step": 1363
    },
    {
      "epoch": 0.021596972623778837,
      "grad_norm": 0.41539016366004944,
      "learning_rate": 9.784030273762213e-06,
      "loss": 0.4278,
      "step": 1364
    },
    {
      "epoch": 0.021612806181420904,
      "grad_norm": 0.12754184007644653,
      "learning_rate": 9.783871938185792e-06,
      "loss": 0.0659,
      "step": 1365
    },
    {
      "epoch": 0.02162863973906297,
      "grad_norm": 0.20545288920402527,
      "learning_rate": 9.78371360260937e-06,
      "loss": 0.3831,
      "step": 1366
    },
    {
      "epoch": 0.021644473296705036,
      "grad_norm": 0.23839320242404938,
      "learning_rate": 9.78355526703295e-06,
      "loss": 0.0753,
      "step": 1367
    },
    {
      "epoch": 0.021660306854347104,
      "grad_norm": 0.21781215071678162,
      "learning_rate": 9.78339693145653e-06,
      "loss": 0.2968,
      "step": 1368
    },
    {
      "epoch": 0.02167614041198917,
      "grad_norm": 0.10760504007339478,
      "learning_rate": 9.78323859588011e-06,
      "loss": 0.0526,
      "step": 1369
    },
    {
      "epoch": 0.021691973969631236,
      "grad_norm": 0.2687279284000397,
      "learning_rate": 9.783080260303689e-06,
      "loss": 0.257,
      "step": 1370
    },
    {
      "epoch": 0.021707807527273304,
      "grad_norm": 0.24619229137897491,
      "learning_rate": 9.782921924727268e-06,
      "loss": 0.4092,
      "step": 1371
    },
    {
      "epoch": 0.02172364108491537,
      "grad_norm": 0.03349776566028595,
      "learning_rate": 9.782763589150847e-06,
      "loss": 0.0016,
      "step": 1372
    },
    {
      "epoch": 0.021739474642557436,
      "grad_norm": 0.2963785231113434,
      "learning_rate": 9.782605253574426e-06,
      "loss": 0.0962,
      "step": 1373
    },
    {
      "epoch": 0.021755308200199504,
      "grad_norm": 0.05059376731514931,
      "learning_rate": 9.782446917998005e-06,
      "loss": 0.0049,
      "step": 1374
    },
    {
      "epoch": 0.021771141757841568,
      "grad_norm": 0.41075563430786133,
      "learning_rate": 9.782288582421586e-06,
      "loss": 0.3474,
      "step": 1375
    },
    {
      "epoch": 0.021786975315483636,
      "grad_norm": 0.19534391164779663,
      "learning_rate": 9.782130246845163e-06,
      "loss": 0.0448,
      "step": 1376
    },
    {
      "epoch": 0.021802808873125704,
      "grad_norm": 0.31403565406799316,
      "learning_rate": 9.781971911268744e-06,
      "loss": 0.9909,
      "step": 1377
    },
    {
      "epoch": 0.021818642430767768,
      "grad_norm": 0.23567698895931244,
      "learning_rate": 9.781813575692323e-06,
      "loss": 0.2544,
      "step": 1378
    },
    {
      "epoch": 0.021834475988409836,
      "grad_norm": 0.06704030930995941,
      "learning_rate": 9.781655240115902e-06,
      "loss": 0.01,
      "step": 1379
    },
    {
      "epoch": 0.021850309546051903,
      "grad_norm": 0.3037234842777252,
      "learning_rate": 9.781496904539481e-06,
      "loss": 0.2352,
      "step": 1380
    },
    {
      "epoch": 0.021866143103693968,
      "grad_norm": 0.14165472984313965,
      "learning_rate": 9.781338568963062e-06,
      "loss": 0.216,
      "step": 1381
    },
    {
      "epoch": 0.021881976661336035,
      "grad_norm": 0.2635970115661621,
      "learning_rate": 9.78118023338664e-06,
      "loss": 0.1148,
      "step": 1382
    },
    {
      "epoch": 0.021897810218978103,
      "grad_norm": 0.012990019284188747,
      "learning_rate": 9.78102189781022e-06,
      "loss": 0.0012,
      "step": 1383
    },
    {
      "epoch": 0.021913643776620167,
      "grad_norm": 0.007838738150894642,
      "learning_rate": 9.7808635622338e-06,
      "loss": 0.0006,
      "step": 1384
    },
    {
      "epoch": 0.021929477334262235,
      "grad_norm": 0.25270944833755493,
      "learning_rate": 9.780705226657378e-06,
      "loss": 0.1025,
      "step": 1385
    },
    {
      "epoch": 0.021945310891904303,
      "grad_norm": 0.1336379200220108,
      "learning_rate": 9.780546891080957e-06,
      "loss": 0.3064,
      "step": 1386
    },
    {
      "epoch": 0.021961144449546367,
      "grad_norm": 0.37044039368629456,
      "learning_rate": 9.780388555504538e-06,
      "loss": 0.1342,
      "step": 1387
    },
    {
      "epoch": 0.021976978007188435,
      "grad_norm": 0.00020866634440608323,
      "learning_rate": 9.780230219928116e-06,
      "loss": 0.0,
      "step": 1388
    },
    {
      "epoch": 0.021992811564830503,
      "grad_norm": 0.1955777406692505,
      "learning_rate": 9.780071884351696e-06,
      "loss": 0.1243,
      "step": 1389
    },
    {
      "epoch": 0.022008645122472567,
      "grad_norm": 0.0242893286049366,
      "learning_rate": 9.779913548775275e-06,
      "loss": 0.0017,
      "step": 1390
    },
    {
      "epoch": 0.022024478680114635,
      "grad_norm": 0.18376941978931427,
      "learning_rate": 9.779755213198855e-06,
      "loss": 0.1852,
      "step": 1391
    },
    {
      "epoch": 0.022040312237756703,
      "grad_norm": 0.00012928544310852885,
      "learning_rate": 9.779596877622434e-06,
      "loss": 0.0,
      "step": 1392
    },
    {
      "epoch": 0.022056145795398767,
      "grad_norm": 0.39941486716270447,
      "learning_rate": 9.779438542046014e-06,
      "loss": 0.1426,
      "step": 1393
    },
    {
      "epoch": 0.022071979353040835,
      "grad_norm": 0.0003352397179696709,
      "learning_rate": 9.779280206469592e-06,
      "loss": 0.0,
      "step": 1394
    },
    {
      "epoch": 0.022087812910682902,
      "grad_norm": 0.2112663835287094,
      "learning_rate": 9.779121870893173e-06,
      "loss": 0.0507,
      "step": 1395
    },
    {
      "epoch": 0.022103646468324967,
      "grad_norm": 0.213114932179451,
      "learning_rate": 9.778963535316752e-06,
      "loss": 0.1686,
      "step": 1396
    },
    {
      "epoch": 0.022119480025967034,
      "grad_norm": 0.25770413875579834,
      "learning_rate": 9.77880519974033e-06,
      "loss": 0.0606,
      "step": 1397
    },
    {
      "epoch": 0.022135313583609102,
      "grad_norm": 0.2667613625526428,
      "learning_rate": 9.77864686416391e-06,
      "loss": 0.0834,
      "step": 1398
    },
    {
      "epoch": 0.022151147141251167,
      "grad_norm": 0.2208484262228012,
      "learning_rate": 9.778488528587489e-06,
      "loss": 0.1142,
      "step": 1399
    },
    {
      "epoch": 0.022166980698893234,
      "grad_norm": 0.2119283229112625,
      "learning_rate": 9.778330193011068e-06,
      "loss": 0.1984,
      "step": 1400
    },
    {
      "epoch": 0.022182814256535302,
      "grad_norm": 0.17476266622543335,
      "learning_rate": 9.778171857434647e-06,
      "loss": 0.0968,
      "step": 1401
    },
    {
      "epoch": 0.022198647814177366,
      "grad_norm": 0.0031518812756985426,
      "learning_rate": 9.778013521858228e-06,
      "loss": 0.0003,
      "step": 1402
    },
    {
      "epoch": 0.022214481371819434,
      "grad_norm": 0.31742405891418457,
      "learning_rate": 9.777855186281807e-06,
      "loss": 0.1215,
      "step": 1403
    },
    {
      "epoch": 0.022230314929461502,
      "grad_norm": 0.2989650368690491,
      "learning_rate": 9.777696850705386e-06,
      "loss": 0.4019,
      "step": 1404
    },
    {
      "epoch": 0.022246148487103566,
      "grad_norm": 0.17913848161697388,
      "learning_rate": 9.777538515128965e-06,
      "loss": 0.3959,
      "step": 1405
    },
    {
      "epoch": 0.022261982044745634,
      "grad_norm": 0.15338072180747986,
      "learning_rate": 9.777380179552544e-06,
      "loss": 0.029,
      "step": 1406
    },
    {
      "epoch": 0.0222778156023877,
      "grad_norm": 0.007288332562893629,
      "learning_rate": 9.777221843976123e-06,
      "loss": 0.0008,
      "step": 1407
    },
    {
      "epoch": 0.022293649160029766,
      "grad_norm": 0.14597105979919434,
      "learning_rate": 9.777063508399704e-06,
      "loss": 0.1037,
      "step": 1408
    },
    {
      "epoch": 0.022309482717671834,
      "grad_norm": 0.467485249042511,
      "learning_rate": 9.776905172823283e-06,
      "loss": 0.1354,
      "step": 1409
    },
    {
      "epoch": 0.0223253162753139,
      "grad_norm": 0.6921747922897339,
      "learning_rate": 9.776746837246862e-06,
      "loss": 1.3666,
      "step": 1410
    },
    {
      "epoch": 0.022341149832955966,
      "grad_norm": 0.24210301041603088,
      "learning_rate": 9.776588501670441e-06,
      "loss": 0.5047,
      "step": 1411
    },
    {
      "epoch": 0.022356983390598033,
      "grad_norm": 0.309433251619339,
      "learning_rate": 9.77643016609402e-06,
      "loss": 0.4728,
      "step": 1412
    },
    {
      "epoch": 0.0223728169482401,
      "grad_norm": 0.21908767521381378,
      "learning_rate": 9.7762718305176e-06,
      "loss": 0.2234,
      "step": 1413
    },
    {
      "epoch": 0.022388650505882166,
      "grad_norm": 0.3651784658432007,
      "learning_rate": 9.77611349494118e-06,
      "loss": 0.7308,
      "step": 1414
    },
    {
      "epoch": 0.022404484063524233,
      "grad_norm": 0.08690936863422394,
      "learning_rate": 9.775955159364758e-06,
      "loss": 0.1447,
      "step": 1415
    },
    {
      "epoch": 0.0224203176211663,
      "grad_norm": 0.19075272977352142,
      "learning_rate": 9.775796823788338e-06,
      "loss": 0.2498,
      "step": 1416
    },
    {
      "epoch": 0.022436151178808365,
      "grad_norm": 0.24447806179523468,
      "learning_rate": 9.775638488211917e-06,
      "loss": 0.7979,
      "step": 1417
    },
    {
      "epoch": 0.022451984736450433,
      "grad_norm": 0.7578630447387695,
      "learning_rate": 9.775480152635496e-06,
      "loss": 0.1172,
      "step": 1418
    },
    {
      "epoch": 0.0224678182940925,
      "grad_norm": 0.3428960144519806,
      "learning_rate": 9.775321817059076e-06,
      "loss": 0.0824,
      "step": 1419
    },
    {
      "epoch": 0.022483651851734565,
      "grad_norm": 0.231130450963974,
      "learning_rate": 9.775163481482655e-06,
      "loss": 0.1754,
      "step": 1420
    },
    {
      "epoch": 0.022499485409376633,
      "grad_norm": 0.013739210553467274,
      "learning_rate": 9.775005145906234e-06,
      "loss": 0.001,
      "step": 1421
    },
    {
      "epoch": 0.0225153189670187,
      "grad_norm": 0.17843981087207794,
      "learning_rate": 9.774846810329813e-06,
      "loss": 0.2331,
      "step": 1422
    },
    {
      "epoch": 0.022531152524660765,
      "grad_norm": 0.17603550851345062,
      "learning_rate": 9.774688474753394e-06,
      "loss": 0.1051,
      "step": 1423
    },
    {
      "epoch": 0.022546986082302833,
      "grad_norm": 0.1805001199245453,
      "learning_rate": 9.774530139176973e-06,
      "loss": 0.2857,
      "step": 1424
    },
    {
      "epoch": 0.0225628196399449,
      "grad_norm": 0.34466296434402466,
      "learning_rate": 9.774371803600552e-06,
      "loss": 0.0635,
      "step": 1425
    },
    {
      "epoch": 0.022578653197586965,
      "grad_norm": 0.4409661293029785,
      "learning_rate": 9.77421346802413e-06,
      "loss": 0.6628,
      "step": 1426
    },
    {
      "epoch": 0.022594486755229033,
      "grad_norm": 0.13380393385887146,
      "learning_rate": 9.77405513244771e-06,
      "loss": 0.1316,
      "step": 1427
    },
    {
      "epoch": 0.0226103203128711,
      "grad_norm": 0.15805228054523468,
      "learning_rate": 9.773896796871289e-06,
      "loss": 0.0701,
      "step": 1428
    },
    {
      "epoch": 0.022626153870513165,
      "grad_norm": 0.16441231966018677,
      "learning_rate": 9.77373846129487e-06,
      "loss": 0.0759,
      "step": 1429
    },
    {
      "epoch": 0.022641987428155232,
      "grad_norm": 0.11807499080896378,
      "learning_rate": 9.773580125718449e-06,
      "loss": 0.0693,
      "step": 1430
    },
    {
      "epoch": 0.0226578209857973,
      "grad_norm": 0.21759094297885895,
      "learning_rate": 9.773421790142028e-06,
      "loss": 0.3235,
      "step": 1431
    },
    {
      "epoch": 0.022673654543439364,
      "grad_norm": 0.39889782667160034,
      "learning_rate": 9.773263454565607e-06,
      "loss": 0.3078,
      "step": 1432
    },
    {
      "epoch": 0.022689488101081432,
      "grad_norm": 0.005205975379794836,
      "learning_rate": 9.773105118989186e-06,
      "loss": 0.0005,
      "step": 1433
    },
    {
      "epoch": 0.0227053216587235,
      "grad_norm": 0.04188202694058418,
      "learning_rate": 9.772946783412765e-06,
      "loss": 0.0045,
      "step": 1434
    },
    {
      "epoch": 0.022721155216365564,
      "grad_norm": 0.4532817304134369,
      "learning_rate": 9.772788447836346e-06,
      "loss": 0.4638,
      "step": 1435
    },
    {
      "epoch": 0.022736988774007632,
      "grad_norm": 0.027560895308852196,
      "learning_rate": 9.772630112259925e-06,
      "loss": 0.0048,
      "step": 1436
    },
    {
      "epoch": 0.0227528223316497,
      "grad_norm": 0.015319452621042728,
      "learning_rate": 9.772471776683504e-06,
      "loss": 0.0014,
      "step": 1437
    },
    {
      "epoch": 0.022768655889291764,
      "grad_norm": 0.2699643671512604,
      "learning_rate": 9.772313441107083e-06,
      "loss": 0.0804,
      "step": 1438
    },
    {
      "epoch": 0.022784489446933832,
      "grad_norm": 0.19552870094776154,
      "learning_rate": 9.772155105530662e-06,
      "loss": 0.2237,
      "step": 1439
    },
    {
      "epoch": 0.0228003230045759,
      "grad_norm": 0.0013844968052580953,
      "learning_rate": 9.771996769954241e-06,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.022816156562217964,
      "grad_norm": 0.23291237652301788,
      "learning_rate": 9.771838434377822e-06,
      "loss": 0.173,
      "step": 1441
    },
    {
      "epoch": 0.02283199011986003,
      "grad_norm": 0.04115493595600128,
      "learning_rate": 9.771680098801401e-06,
      "loss": 0.0032,
      "step": 1442
    },
    {
      "epoch": 0.0228478236775021,
      "grad_norm": 0.14974519610404968,
      "learning_rate": 9.77152176322498e-06,
      "loss": 0.1403,
      "step": 1443
    },
    {
      "epoch": 0.022863657235144164,
      "grad_norm": 0.006117349490523338,
      "learning_rate": 9.77136342764856e-06,
      "loss": 0.0004,
      "step": 1444
    },
    {
      "epoch": 0.02287949079278623,
      "grad_norm": 0.3137219548225403,
      "learning_rate": 9.771205092072138e-06,
      "loss": 0.4273,
      "step": 1445
    },
    {
      "epoch": 0.0228953243504283,
      "grad_norm": 0.02475205436348915,
      "learning_rate": 9.771046756495717e-06,
      "loss": 0.0019,
      "step": 1446
    },
    {
      "epoch": 0.022911157908070363,
      "grad_norm": 0.46512889862060547,
      "learning_rate": 9.770888420919297e-06,
      "loss": 1.1392,
      "step": 1447
    },
    {
      "epoch": 0.02292699146571243,
      "grad_norm": 0.18453899025917053,
      "learning_rate": 9.770730085342877e-06,
      "loss": 0.2427,
      "step": 1448
    },
    {
      "epoch": 0.0229428250233545,
      "grad_norm": 0.5066955089569092,
      "learning_rate": 9.770571749766455e-06,
      "loss": 0.0199,
      "step": 1449
    },
    {
      "epoch": 0.022958658580996563,
      "grad_norm": 0.38988351821899414,
      "learning_rate": 9.770413414190035e-06,
      "loss": 1.055,
      "step": 1450
    },
    {
      "epoch": 0.02297449213863863,
      "grad_norm": 0.041963737457990646,
      "learning_rate": 9.770255078613615e-06,
      "loss": 0.0049,
      "step": 1451
    },
    {
      "epoch": 0.0229903256962807,
      "grad_norm": 0.38452810049057007,
      "learning_rate": 9.770096743037194e-06,
      "loss": 0.7204,
      "step": 1452
    },
    {
      "epoch": 0.023006159253922763,
      "grad_norm": 0.16696539521217346,
      "learning_rate": 9.769938407460773e-06,
      "loss": 0.2371,
      "step": 1453
    },
    {
      "epoch": 0.02302199281156483,
      "grad_norm": 0.004238991532474756,
      "learning_rate": 9.769780071884353e-06,
      "loss": 0.0003,
      "step": 1454
    },
    {
      "epoch": 0.0230378263692069,
      "grad_norm": 0.37321051955223083,
      "learning_rate": 9.769621736307931e-06,
      "loss": 0.0542,
      "step": 1455
    },
    {
      "epoch": 0.023053659926848963,
      "grad_norm": 0.16511860489845276,
      "learning_rate": 9.769463400731512e-06,
      "loss": 0.3512,
      "step": 1456
    },
    {
      "epoch": 0.02306949348449103,
      "grad_norm": 0.6604575514793396,
      "learning_rate": 9.76930506515509e-06,
      "loss": 0.827,
      "step": 1457
    },
    {
      "epoch": 0.0230853270421331,
      "grad_norm": 0.0003390556375961751,
      "learning_rate": 9.76914672957867e-06,
      "loss": 0.0,
      "step": 1458
    },
    {
      "epoch": 0.023101160599775163,
      "grad_norm": 0.00010287523764418438,
      "learning_rate": 9.768988394002249e-06,
      "loss": 0.0,
      "step": 1459
    },
    {
      "epoch": 0.02311699415741723,
      "grad_norm": 0.027842054143548012,
      "learning_rate": 9.76883005842583e-06,
      "loss": 0.0019,
      "step": 1460
    },
    {
      "epoch": 0.023132827715059298,
      "grad_norm": 0.049668461084365845,
      "learning_rate": 9.768671722849407e-06,
      "loss": 0.1769,
      "step": 1461
    },
    {
      "epoch": 0.023148661272701362,
      "grad_norm": 0.0009006208274513483,
      "learning_rate": 9.768513387272988e-06,
      "loss": 0.0,
      "step": 1462
    },
    {
      "epoch": 0.02316449483034343,
      "grad_norm": 0.20167158544063568,
      "learning_rate": 9.768355051696567e-06,
      "loss": 0.1911,
      "step": 1463
    },
    {
      "epoch": 0.023180328387985498,
      "grad_norm": 0.0987536758184433,
      "learning_rate": 9.768196716120146e-06,
      "loss": 0.0057,
      "step": 1464
    },
    {
      "epoch": 0.023196161945627562,
      "grad_norm": 0.42582136392593384,
      "learning_rate": 9.768038380543725e-06,
      "loss": 0.0499,
      "step": 1465
    },
    {
      "epoch": 0.02321199550326963,
      "grad_norm": 0.19457146525382996,
      "learning_rate": 9.767880044967306e-06,
      "loss": 0.3905,
      "step": 1466
    },
    {
      "epoch": 0.023227829060911698,
      "grad_norm": 1.2404723167419434,
      "learning_rate": 9.767721709390883e-06,
      "loss": 0.042,
      "step": 1467
    },
    {
      "epoch": 0.023243662618553762,
      "grad_norm": 0.4515347480773926,
      "learning_rate": 9.767563373814462e-06,
      "loss": 0.3397,
      "step": 1468
    },
    {
      "epoch": 0.02325949617619583,
      "grad_norm": 0.37830379605293274,
      "learning_rate": 9.767405038238043e-06,
      "loss": 1.2918,
      "step": 1469
    },
    {
      "epoch": 0.023275329733837898,
      "grad_norm": 0.017810363322496414,
      "learning_rate": 9.767246702661622e-06,
      "loss": 0.0007,
      "step": 1470
    },
    {
      "epoch": 0.023291163291479962,
      "grad_norm": 0.00037142535438761115,
      "learning_rate": 9.767088367085201e-06,
      "loss": 0.0,
      "step": 1471
    },
    {
      "epoch": 0.02330699684912203,
      "grad_norm": 0.28610605001449585,
      "learning_rate": 9.76693003150878e-06,
      "loss": 0.0743,
      "step": 1472
    },
    {
      "epoch": 0.023322830406764097,
      "grad_norm": 0.4445142447948456,
      "learning_rate": 9.76677169593236e-06,
      "loss": 0.5032,
      "step": 1473
    },
    {
      "epoch": 0.02333866396440616,
      "grad_norm": 0.252277672290802,
      "learning_rate": 9.766613360355938e-06,
      "loss": 0.139,
      "step": 1474
    },
    {
      "epoch": 0.02335449752204823,
      "grad_norm": 0.4216349422931671,
      "learning_rate": 9.76645502477952e-06,
      "loss": 0.6891,
      "step": 1475
    },
    {
      "epoch": 0.023370331079690297,
      "grad_norm": 0.13323068618774414,
      "learning_rate": 9.766296689203098e-06,
      "loss": 0.0311,
      "step": 1476
    },
    {
      "epoch": 0.02338616463733236,
      "grad_norm": 0.004584637004882097,
      "learning_rate": 9.766138353626677e-06,
      "loss": 0.0003,
      "step": 1477
    },
    {
      "epoch": 0.02340199819497443,
      "grad_norm": 0.19789499044418335,
      "learning_rate": 9.765980018050256e-06,
      "loss": 0.2282,
      "step": 1478
    },
    {
      "epoch": 0.023417831752616497,
      "grad_norm": 0.2846505641937256,
      "learning_rate": 9.765821682473836e-06,
      "loss": 0.1886,
      "step": 1479
    },
    {
      "epoch": 0.02343366531025856,
      "grad_norm": 0.3021849989891052,
      "learning_rate": 9.765663346897415e-06,
      "loss": 0.2875,
      "step": 1480
    },
    {
      "epoch": 0.02344949886790063,
      "grad_norm": 0.20432433485984802,
      "learning_rate": 9.765505011320995e-06,
      "loss": 0.0166,
      "step": 1481
    },
    {
      "epoch": 0.023465332425542697,
      "grad_norm": 0.3535306453704834,
      "learning_rate": 9.765346675744573e-06,
      "loss": 0.1907,
      "step": 1482
    },
    {
      "epoch": 0.02348116598318476,
      "grad_norm": 0.003402319271117449,
      "learning_rate": 9.765188340168154e-06,
      "loss": 0.0001,
      "step": 1483
    },
    {
      "epoch": 0.02349699954082683,
      "grad_norm": 0.769307553768158,
      "learning_rate": 9.765030004591733e-06,
      "loss": 0.6128,
      "step": 1484
    },
    {
      "epoch": 0.023512833098468897,
      "grad_norm": 0.17617173492908478,
      "learning_rate": 9.764871669015312e-06,
      "loss": 0.0052,
      "step": 1485
    },
    {
      "epoch": 0.02352866665611096,
      "grad_norm": 0.007321585435420275,
      "learning_rate": 9.76471333343889e-06,
      "loss": 0.0004,
      "step": 1486
    },
    {
      "epoch": 0.02354450021375303,
      "grad_norm": 0.15220175683498383,
      "learning_rate": 9.764554997862472e-06,
      "loss": 0.146,
      "step": 1487
    },
    {
      "epoch": 0.023560333771395096,
      "grad_norm": 0.6812030076980591,
      "learning_rate": 9.764396662286049e-06,
      "loss": 0.0735,
      "step": 1488
    },
    {
      "epoch": 0.02357616732903716,
      "grad_norm": 0.1212698444724083,
      "learning_rate": 9.76423832670963e-06,
      "loss": 0.0349,
      "step": 1489
    },
    {
      "epoch": 0.02359200088667923,
      "grad_norm": 0.1995323747396469,
      "learning_rate": 9.764079991133209e-06,
      "loss": 0.1182,
      "step": 1490
    },
    {
      "epoch": 0.023607834444321296,
      "grad_norm": 0.14506597816944122,
      "learning_rate": 9.763921655556788e-06,
      "loss": 0.0553,
      "step": 1491
    },
    {
      "epoch": 0.02362366800196336,
      "grad_norm": 0.008549707941710949,
      "learning_rate": 9.763763319980367e-06,
      "loss": 0.0002,
      "step": 1492
    },
    {
      "epoch": 0.023639501559605428,
      "grad_norm": 0.24193768203258514,
      "learning_rate": 9.763604984403946e-06,
      "loss": 0.2031,
      "step": 1493
    },
    {
      "epoch": 0.023655335117247496,
      "grad_norm": 0.09586244076490402,
      "learning_rate": 9.763446648827525e-06,
      "loss": 0.0064,
      "step": 1494
    },
    {
      "epoch": 0.02367116867488956,
      "grad_norm": 0.1460445076227188,
      "learning_rate": 9.763288313251104e-06,
      "loss": 0.1844,
      "step": 1495
    },
    {
      "epoch": 0.023687002232531628,
      "grad_norm": 0.00446630734950304,
      "learning_rate": 9.763129977674685e-06,
      "loss": 0.0003,
      "step": 1496
    },
    {
      "epoch": 0.023702835790173696,
      "grad_norm": 0.6009989976882935,
      "learning_rate": 9.762971642098264e-06,
      "loss": 0.1036,
      "step": 1497
    },
    {
      "epoch": 0.02371866934781576,
      "grad_norm": 0.0015113175613805652,
      "learning_rate": 9.762813306521843e-06,
      "loss": 0.0,
      "step": 1498
    },
    {
      "epoch": 0.023734502905457828,
      "grad_norm": 0.0001030397615977563,
      "learning_rate": 9.762654970945422e-06,
      "loss": 0.0,
      "step": 1499
    },
    {
      "epoch": 0.023750336463099896,
      "grad_norm": 0.17585697770118713,
      "learning_rate": 9.762496635369001e-06,
      "loss": 0.022,
      "step": 1500
    },
    {
      "epoch": 0.02376617002074196,
      "grad_norm": 0.31242698431015015,
      "learning_rate": 9.76233829979258e-06,
      "loss": 0.5352,
      "step": 1501
    },
    {
      "epoch": 0.023782003578384028,
      "grad_norm": 0.5091687440872192,
      "learning_rate": 9.762179964216161e-06,
      "loss": 1.1272,
      "step": 1502
    },
    {
      "epoch": 0.023797837136026095,
      "grad_norm": 0.21785889565944672,
      "learning_rate": 9.76202162863974e-06,
      "loss": 0.1207,
      "step": 1503
    },
    {
      "epoch": 0.02381367069366816,
      "grad_norm": 0.5137768983840942,
      "learning_rate": 9.76186329306332e-06,
      "loss": 0.3549,
      "step": 1504
    },
    {
      "epoch": 0.023829504251310227,
      "grad_norm": 0.004117592703551054,
      "learning_rate": 9.761704957486898e-06,
      "loss": 0.0003,
      "step": 1505
    },
    {
      "epoch": 0.023845337808952295,
      "grad_norm": 0.0004653297655750066,
      "learning_rate": 9.761546621910477e-06,
      "loss": 0.0,
      "step": 1506
    },
    {
      "epoch": 0.02386117136659436,
      "grad_norm": 0.28760990500450134,
      "learning_rate": 9.761388286334057e-06,
      "loss": 0.3158,
      "step": 1507
    },
    {
      "epoch": 0.023877004924236427,
      "grad_norm": 0.1497085988521576,
      "learning_rate": 9.761229950757637e-06,
      "loss": 0.1348,
      "step": 1508
    },
    {
      "epoch": 0.02389283848187849,
      "grad_norm": 0.2988128066062927,
      "learning_rate": 9.761071615181216e-06,
      "loss": 0.748,
      "step": 1509
    },
    {
      "epoch": 0.02390867203952056,
      "grad_norm": 0.14431650936603546,
      "learning_rate": 9.760913279604796e-06,
      "loss": 0.0984,
      "step": 1510
    },
    {
      "epoch": 0.023924505597162627,
      "grad_norm": 0.12488822638988495,
      "learning_rate": 9.760754944028375e-06,
      "loss": 0.1738,
      "step": 1511
    },
    {
      "epoch": 0.02394033915480469,
      "grad_norm": 0.21463364362716675,
      "learning_rate": 9.760596608451954e-06,
      "loss": 0.7782,
      "step": 1512
    },
    {
      "epoch": 0.02395617271244676,
      "grad_norm": 0.2716904580593109,
      "learning_rate": 9.760438272875533e-06,
      "loss": 0.1005,
      "step": 1513
    },
    {
      "epoch": 0.023972006270088827,
      "grad_norm": 0.4028022885322571,
      "learning_rate": 9.760279937299114e-06,
      "loss": 0.2443,
      "step": 1514
    },
    {
      "epoch": 0.02398783982773089,
      "grad_norm": 0.12327561527490616,
      "learning_rate": 9.760121601722693e-06,
      "loss": 0.1895,
      "step": 1515
    },
    {
      "epoch": 0.02400367338537296,
      "grad_norm": 0.019279981032013893,
      "learning_rate": 9.75996326614627e-06,
      "loss": 0.0013,
      "step": 1516
    },
    {
      "epoch": 0.024019506943015027,
      "grad_norm": 0.5144664645195007,
      "learning_rate": 9.75980493056985e-06,
      "loss": 0.0719,
      "step": 1517
    },
    {
      "epoch": 0.02403534050065709,
      "grad_norm": 0.4682839810848236,
      "learning_rate": 9.75964659499343e-06,
      "loss": 0.8088,
      "step": 1518
    },
    {
      "epoch": 0.02405117405829916,
      "grad_norm": 0.03916177153587341,
      "learning_rate": 9.759488259417009e-06,
      "loss": 0.0021,
      "step": 1519
    },
    {
      "epoch": 0.024067007615941226,
      "grad_norm": 0.10851497948169708,
      "learning_rate": 9.759329923840588e-06,
      "loss": 0.2144,
      "step": 1520
    },
    {
      "epoch": 0.02408284117358329,
      "grad_norm": 0.2988293468952179,
      "learning_rate": 9.759171588264169e-06,
      "loss": 0.211,
      "step": 1521
    },
    {
      "epoch": 0.02409867473122536,
      "grad_norm": 0.03400726243853569,
      "learning_rate": 9.759013252687746e-06,
      "loss": 0.0014,
      "step": 1522
    },
    {
      "epoch": 0.024114508288867426,
      "grad_norm": 0.22574487328529358,
      "learning_rate": 9.758854917111327e-06,
      "loss": 0.713,
      "step": 1523
    },
    {
      "epoch": 0.02413034184650949,
      "grad_norm": 0.25951918959617615,
      "learning_rate": 9.758696581534906e-06,
      "loss": 0.0565,
      "step": 1524
    },
    {
      "epoch": 0.02414617540415156,
      "grad_norm": 0.004520993679761887,
      "learning_rate": 9.758538245958485e-06,
      "loss": 0.0003,
      "step": 1525
    },
    {
      "epoch": 0.024162008961793626,
      "grad_norm": 0.010589041747152805,
      "learning_rate": 9.758379910382064e-06,
      "loss": 0.0002,
      "step": 1526
    },
    {
      "epoch": 0.02417784251943569,
      "grad_norm": 0.29182168841362,
      "learning_rate": 9.758221574805645e-06,
      "loss": 0.0906,
      "step": 1527
    },
    {
      "epoch": 0.024193676077077758,
      "grad_norm": 0.03230539336800575,
      "learning_rate": 9.758063239229222e-06,
      "loss": 0.0008,
      "step": 1528
    },
    {
      "epoch": 0.024209509634719826,
      "grad_norm": 0.12001316994428635,
      "learning_rate": 9.757904903652803e-06,
      "loss": 0.004,
      "step": 1529
    },
    {
      "epoch": 0.02422534319236189,
      "grad_norm": 0.15230105817317963,
      "learning_rate": 9.757746568076382e-06,
      "loss": 0.343,
      "step": 1530
    },
    {
      "epoch": 0.024241176750003958,
      "grad_norm": 0.1428784877061844,
      "learning_rate": 9.757588232499961e-06,
      "loss": 0.081,
      "step": 1531
    },
    {
      "epoch": 0.024257010307646026,
      "grad_norm": 0.24690507352352142,
      "learning_rate": 9.75742989692354e-06,
      "loss": 0.1241,
      "step": 1532
    },
    {
      "epoch": 0.02427284386528809,
      "grad_norm": 0.20140478014945984,
      "learning_rate": 9.757271561347121e-06,
      "loss": 0.0901,
      "step": 1533
    },
    {
      "epoch": 0.024288677422930158,
      "grad_norm": 0.2089235484600067,
      "learning_rate": 9.757113225770698e-06,
      "loss": 0.0289,
      "step": 1534
    },
    {
      "epoch": 0.024304510980572226,
      "grad_norm": 0.30445602536201477,
      "learning_rate": 9.75695489019428e-06,
      "loss": 0.07,
      "step": 1535
    },
    {
      "epoch": 0.02432034453821429,
      "grad_norm": 0.20210251212120056,
      "learning_rate": 9.756796554617858e-06,
      "loss": 0.1906,
      "step": 1536
    },
    {
      "epoch": 0.024336178095856358,
      "grad_norm": 0.9062479138374329,
      "learning_rate": 9.756638219041437e-06,
      "loss": 0.0259,
      "step": 1537
    },
    {
      "epoch": 0.024352011653498425,
      "grad_norm": 0.25534531474113464,
      "learning_rate": 9.756479883465017e-06,
      "loss": 0.2055,
      "step": 1538
    },
    {
      "epoch": 0.02436784521114049,
      "grad_norm": 0.30504992604255676,
      "learning_rate": 9.756321547888596e-06,
      "loss": 0.3879,
      "step": 1539
    },
    {
      "epoch": 0.024383678768782557,
      "grad_norm": 0.13079902529716492,
      "learning_rate": 9.756163212312175e-06,
      "loss": 0.0692,
      "step": 1540
    },
    {
      "epoch": 0.024399512326424625,
      "grad_norm": 0.07651886343955994,
      "learning_rate": 9.756004876735754e-06,
      "loss": 0.038,
      "step": 1541
    },
    {
      "epoch": 0.02441534588406669,
      "grad_norm": 0.0070991069078445435,
      "learning_rate": 9.755846541159335e-06,
      "loss": 0.0004,
      "step": 1542
    },
    {
      "epoch": 0.024431179441708757,
      "grad_norm": 0.2922329008579254,
      "learning_rate": 9.755688205582912e-06,
      "loss": 0.6011,
      "step": 1543
    },
    {
      "epoch": 0.024447012999350825,
      "grad_norm": 0.003486995818093419,
      "learning_rate": 9.755529870006493e-06,
      "loss": 0.0,
      "step": 1544
    },
    {
      "epoch": 0.02446284655699289,
      "grad_norm": 0.2582740783691406,
      "learning_rate": 9.755371534430072e-06,
      "loss": 0.3649,
      "step": 1545
    },
    {
      "epoch": 0.024478680114634957,
      "grad_norm": 0.11371719092130661,
      "learning_rate": 9.75521319885365e-06,
      "loss": 0.1079,
      "step": 1546
    },
    {
      "epoch": 0.024494513672277025,
      "grad_norm": 0.42176851630210876,
      "learning_rate": 9.75505486327723e-06,
      "loss": 0.2765,
      "step": 1547
    },
    {
      "epoch": 0.02451034722991909,
      "grad_norm": 0.24007117748260498,
      "learning_rate": 9.75489652770081e-06,
      "loss": 0.1151,
      "step": 1548
    },
    {
      "epoch": 0.024526180787561157,
      "grad_norm": 0.16237643361091614,
      "learning_rate": 9.754738192124388e-06,
      "loss": 0.2369,
      "step": 1549
    },
    {
      "epoch": 0.024542014345203225,
      "grad_norm": 0.35145604610443115,
      "learning_rate": 9.754579856547969e-06,
      "loss": 0.315,
      "step": 1550
    },
    {
      "epoch": 0.02455784790284529,
      "grad_norm": 0.08576461672782898,
      "learning_rate": 9.754421520971548e-06,
      "loss": 0.1151,
      "step": 1551
    },
    {
      "epoch": 0.024573681460487357,
      "grad_norm": 0.47745954990386963,
      "learning_rate": 9.754263185395127e-06,
      "loss": 0.2133,
      "step": 1552
    },
    {
      "epoch": 0.024589515018129424,
      "grad_norm": 0.16657480597496033,
      "learning_rate": 9.754104849818706e-06,
      "loss": 0.0837,
      "step": 1553
    },
    {
      "epoch": 0.02460534857577149,
      "grad_norm": 0.04493272677063942,
      "learning_rate": 9.753946514242287e-06,
      "loss": 0.0063,
      "step": 1554
    },
    {
      "epoch": 0.024621182133413556,
      "grad_norm": 0.009582401253283024,
      "learning_rate": 9.753788178665864e-06,
      "loss": 0.0006,
      "step": 1555
    },
    {
      "epoch": 0.024637015691055624,
      "grad_norm": 0.15741659700870514,
      "learning_rate": 9.753629843089445e-06,
      "loss": 0.0787,
      "step": 1556
    },
    {
      "epoch": 0.02465284924869769,
      "grad_norm": 0.015538769774138927,
      "learning_rate": 9.753471507513024e-06,
      "loss": 0.001,
      "step": 1557
    },
    {
      "epoch": 0.024668682806339756,
      "grad_norm": 0.13116414844989777,
      "learning_rate": 9.753313171936603e-06,
      "loss": 0.2433,
      "step": 1558
    },
    {
      "epoch": 0.024684516363981824,
      "grad_norm": 0.192230224609375,
      "learning_rate": 9.753154836360182e-06,
      "loss": 0.0512,
      "step": 1559
    },
    {
      "epoch": 0.024700349921623888,
      "grad_norm": 0.06764914840459824,
      "learning_rate": 9.752996500783763e-06,
      "loss": 0.0031,
      "step": 1560
    },
    {
      "epoch": 0.024716183479265956,
      "grad_norm": 0.12397594004869461,
      "learning_rate": 9.75283816520734e-06,
      "loss": 0.0394,
      "step": 1561
    },
    {
      "epoch": 0.024732017036908024,
      "grad_norm": 0.14967073500156403,
      "learning_rate": 9.752679829630921e-06,
      "loss": 0.0767,
      "step": 1562
    },
    {
      "epoch": 0.024747850594550088,
      "grad_norm": 0.21712778508663177,
      "learning_rate": 9.7525214940545e-06,
      "loss": 0.0347,
      "step": 1563
    },
    {
      "epoch": 0.024763684152192156,
      "grad_norm": 0.19447295367717743,
      "learning_rate": 9.75236315847808e-06,
      "loss": 0.1466,
      "step": 1564
    },
    {
      "epoch": 0.024779517709834224,
      "grad_norm": 0.21117563545703888,
      "learning_rate": 9.752204822901658e-06,
      "loss": 0.0662,
      "step": 1565
    },
    {
      "epoch": 0.024795351267476288,
      "grad_norm": 0.14829878509044647,
      "learning_rate": 9.752046487325238e-06,
      "loss": 0.0854,
      "step": 1566
    },
    {
      "epoch": 0.024811184825118356,
      "grad_norm": 0.13579490780830383,
      "learning_rate": 9.751888151748817e-06,
      "loss": 0.0567,
      "step": 1567
    },
    {
      "epoch": 0.024827018382760423,
      "grad_norm": 0.1621522158384323,
      "learning_rate": 9.751729816172396e-06,
      "loss": 0.1526,
      "step": 1568
    },
    {
      "epoch": 0.024842851940402488,
      "grad_norm": 0.2811354994773865,
      "learning_rate": 9.751571480595976e-06,
      "loss": 0.1496,
      "step": 1569
    },
    {
      "epoch": 0.024858685498044555,
      "grad_norm": 0.01383222546428442,
      "learning_rate": 9.751413145019556e-06,
      "loss": 0.0012,
      "step": 1570
    },
    {
      "epoch": 0.024874519055686623,
      "grad_norm": 0.2206149846315384,
      "learning_rate": 9.751254809443135e-06,
      "loss": 0.0563,
      "step": 1571
    },
    {
      "epoch": 0.024890352613328687,
      "grad_norm": 0.016843179240822792,
      "learning_rate": 9.751096473866714e-06,
      "loss": 0.0009,
      "step": 1572
    },
    {
      "epoch": 0.024906186170970755,
      "grad_norm": 0.21323443949222565,
      "learning_rate": 9.750938138290293e-06,
      "loss": 0.1374,
      "step": 1573
    },
    {
      "epoch": 0.024922019728612823,
      "grad_norm": 0.07339973747730255,
      "learning_rate": 9.750779802713872e-06,
      "loss": 0.0233,
      "step": 1574
    },
    {
      "epoch": 0.024937853286254887,
      "grad_norm": 0.006325129885226488,
      "learning_rate": 9.750621467137453e-06,
      "loss": 0.0003,
      "step": 1575
    },
    {
      "epoch": 0.024953686843896955,
      "grad_norm": 0.31159746646881104,
      "learning_rate": 9.750463131561032e-06,
      "loss": 0.1395,
      "step": 1576
    },
    {
      "epoch": 0.024969520401539023,
      "grad_norm": 0.37339136004447937,
      "learning_rate": 9.75030479598461e-06,
      "loss": 0.8185,
      "step": 1577
    },
    {
      "epoch": 0.024985353959181087,
      "grad_norm": 0.15747730433940887,
      "learning_rate": 9.75014646040819e-06,
      "loss": 0.1152,
      "step": 1578
    },
    {
      "epoch": 0.025001187516823155,
      "grad_norm": 0.037688713520765305,
      "learning_rate": 9.749988124831769e-06,
      "loss": 0.0026,
      "step": 1579
    },
    {
      "epoch": 0.025017021074465223,
      "grad_norm": 0.20730680227279663,
      "learning_rate": 9.749829789255348e-06,
      "loss": 0.0544,
      "step": 1580
    },
    {
      "epoch": 0.025032854632107287,
      "grad_norm": 0.12136804312467575,
      "learning_rate": 9.749671453678929e-06,
      "loss": 0.0688,
      "step": 1581
    },
    {
      "epoch": 0.025048688189749355,
      "grad_norm": 0.25797170400619507,
      "learning_rate": 9.749513118102508e-06,
      "loss": 0.0783,
      "step": 1582
    },
    {
      "epoch": 0.025064521747391422,
      "grad_norm": 0.3510279655456543,
      "learning_rate": 9.749354782526087e-06,
      "loss": 0.081,
      "step": 1583
    },
    {
      "epoch": 0.025080355305033487,
      "grad_norm": 0.3167218267917633,
      "learning_rate": 9.749196446949666e-06,
      "loss": 0.7033,
      "step": 1584
    },
    {
      "epoch": 0.025096188862675554,
      "grad_norm": 0.011688021011650562,
      "learning_rate": 9.749038111373245e-06,
      "loss": 0.0008,
      "step": 1585
    },
    {
      "epoch": 0.025112022420317622,
      "grad_norm": 0.00025243908748961985,
      "learning_rate": 9.748879775796824e-06,
      "loss": 0.0,
      "step": 1586
    },
    {
      "epoch": 0.025127855977959686,
      "grad_norm": 0.2927757501602173,
      "learning_rate": 9.748721440220405e-06,
      "loss": 0.5705,
      "step": 1587
    },
    {
      "epoch": 0.025143689535601754,
      "grad_norm": 0.12079326063394547,
      "learning_rate": 9.748563104643984e-06,
      "loss": 0.0313,
      "step": 1588
    },
    {
      "epoch": 0.025159523093243822,
      "grad_norm": 0.03136926516890526,
      "learning_rate": 9.748404769067561e-06,
      "loss": 0.0016,
      "step": 1589
    },
    {
      "epoch": 0.025175356650885886,
      "grad_norm": 0.1615365445613861,
      "learning_rate": 9.748246433491142e-06,
      "loss": 0.065,
      "step": 1590
    },
    {
      "epoch": 0.025191190208527954,
      "grad_norm": 0.00043143596849404275,
      "learning_rate": 9.748088097914721e-06,
      "loss": 0.0,
      "step": 1591
    },
    {
      "epoch": 0.025207023766170022,
      "grad_norm": 0.18280979990959167,
      "learning_rate": 9.7479297623383e-06,
      "loss": 0.3305,
      "step": 1592
    },
    {
      "epoch": 0.025222857323812086,
      "grad_norm": 0.25898951292037964,
      "learning_rate": 9.74777142676188e-06,
      "loss": 0.2462,
      "step": 1593
    },
    {
      "epoch": 0.025238690881454154,
      "grad_norm": 0.246128112077713,
      "learning_rate": 9.74761309118546e-06,
      "loss": 0.3276,
      "step": 1594
    },
    {
      "epoch": 0.02525452443909622,
      "grad_norm": 0.4963019788265228,
      "learning_rate": 9.747454755609038e-06,
      "loss": 1.2499,
      "step": 1595
    },
    {
      "epoch": 0.025270357996738286,
      "grad_norm": 0.24048350751399994,
      "learning_rate": 9.747296420032618e-06,
      "loss": 0.1549,
      "step": 1596
    },
    {
      "epoch": 0.025286191554380354,
      "grad_norm": 0.006302051246166229,
      "learning_rate": 9.747138084456197e-06,
      "loss": 0.0004,
      "step": 1597
    },
    {
      "epoch": 0.02530202511202242,
      "grad_norm": 0.016490770503878593,
      "learning_rate": 9.746979748879777e-06,
      "loss": 0.0009,
      "step": 1598
    },
    {
      "epoch": 0.025317858669664486,
      "grad_norm": 0.3752472996711731,
      "learning_rate": 9.746821413303356e-06,
      "loss": 0.3158,
      "step": 1599
    },
    {
      "epoch": 0.025333692227306553,
      "grad_norm": 0.2740267515182495,
      "learning_rate": 9.746663077726936e-06,
      "loss": 0.0794,
      "step": 1600
    },
    {
      "epoch": 0.02534952578494862,
      "grad_norm": 0.3344615399837494,
      "learning_rate": 9.746504742150514e-06,
      "loss": 0.2385,
      "step": 1601
    },
    {
      "epoch": 0.025365359342590686,
      "grad_norm": 0.003980426117777824,
      "learning_rate": 9.746346406574095e-06,
      "loss": 0.0002,
      "step": 1602
    },
    {
      "epoch": 0.025381192900232753,
      "grad_norm": 0.638421893119812,
      "learning_rate": 9.746188070997674e-06,
      "loss": 0.9655,
      "step": 1603
    },
    {
      "epoch": 0.02539702645787482,
      "grad_norm": 0.009411867707967758,
      "learning_rate": 9.746029735421253e-06,
      "loss": 0.0005,
      "step": 1604
    },
    {
      "epoch": 0.025412860015516885,
      "grad_norm": 0.004929245915263891,
      "learning_rate": 9.745871399844832e-06,
      "loss": 0.0001,
      "step": 1605
    },
    {
      "epoch": 0.025428693573158953,
      "grad_norm": 0.26866814494132996,
      "learning_rate": 9.745713064268411e-06,
      "loss": 0.226,
      "step": 1606
    },
    {
      "epoch": 0.02544452713080102,
      "grad_norm": 0.215188667178154,
      "learning_rate": 9.74555472869199e-06,
      "loss": 0.1244,
      "step": 1607
    },
    {
      "epoch": 0.025460360688443085,
      "grad_norm": 0.0035229583736509085,
      "learning_rate": 9.74539639311557e-06,
      "loss": 0.0002,
      "step": 1608
    },
    {
      "epoch": 0.025476194246085153,
      "grad_norm": 0.18101057410240173,
      "learning_rate": 9.74523805753915e-06,
      "loss": 0.1975,
      "step": 1609
    },
    {
      "epoch": 0.02549202780372722,
      "grad_norm": 0.2406495362520218,
      "learning_rate": 9.745079721962729e-06,
      "loss": 0.0654,
      "step": 1610
    },
    {
      "epoch": 0.025507861361369285,
      "grad_norm": 0.19783924520015717,
      "learning_rate": 9.744921386386308e-06,
      "loss": 0.9179,
      "step": 1611
    },
    {
      "epoch": 0.025523694919011353,
      "grad_norm": 0.015601448714733124,
      "learning_rate": 9.744763050809887e-06,
      "loss": 0.0005,
      "step": 1612
    },
    {
      "epoch": 0.02553952847665342,
      "grad_norm": 0.1888335645198822,
      "learning_rate": 9.744604715233466e-06,
      "loss": 0.1051,
      "step": 1613
    },
    {
      "epoch": 0.025555362034295485,
      "grad_norm": 0.2067771852016449,
      "learning_rate": 9.744446379657045e-06,
      "loss": 0.128,
      "step": 1614
    },
    {
      "epoch": 0.025571195591937552,
      "grad_norm": 0.3062668740749359,
      "learning_rate": 9.744288044080626e-06,
      "loss": 0.0483,
      "step": 1615
    },
    {
      "epoch": 0.02558702914957962,
      "grad_norm": 0.0035284063778817654,
      "learning_rate": 9.744129708504203e-06,
      "loss": 0.0002,
      "step": 1616
    },
    {
      "epoch": 0.025602862707221685,
      "grad_norm": 0.00713273836299777,
      "learning_rate": 9.743971372927784e-06,
      "loss": 0.0004,
      "step": 1617
    },
    {
      "epoch": 0.025618696264863752,
      "grad_norm": 0.16164730489253998,
      "learning_rate": 9.743813037351363e-06,
      "loss": 0.1218,
      "step": 1618
    },
    {
      "epoch": 0.02563452982250582,
      "grad_norm": 6.31781731499359e-05,
      "learning_rate": 9.743654701774942e-06,
      "loss": 0.0,
      "step": 1619
    },
    {
      "epoch": 0.025650363380147884,
      "grad_norm": 0.009808164089918137,
      "learning_rate": 9.743496366198521e-06,
      "loss": 0.0007,
      "step": 1620
    },
    {
      "epoch": 0.025666196937789952,
      "grad_norm": 0.0003079346497543156,
      "learning_rate": 9.743338030622102e-06,
      "loss": 0.0,
      "step": 1621
    },
    {
      "epoch": 0.02568203049543202,
      "grad_norm": 0.23826347291469574,
      "learning_rate": 9.74317969504568e-06,
      "loss": 0.2767,
      "step": 1622
    },
    {
      "epoch": 0.025697864053074084,
      "grad_norm": 0.0074169267900288105,
      "learning_rate": 9.74302135946926e-06,
      "loss": 0.0004,
      "step": 1623
    },
    {
      "epoch": 0.025713697610716152,
      "grad_norm": 0.08661199361085892,
      "learning_rate": 9.74286302389284e-06,
      "loss": 0.0043,
      "step": 1624
    },
    {
      "epoch": 0.02572953116835822,
      "grad_norm": 0.14018675684928894,
      "learning_rate": 9.742704688316418e-06,
      "loss": 0.0955,
      "step": 1625
    },
    {
      "epoch": 0.025745364726000284,
      "grad_norm": 0.11986232548952103,
      "learning_rate": 9.742546352739998e-06,
      "loss": 0.1191,
      "step": 1626
    },
    {
      "epoch": 0.02576119828364235,
      "grad_norm": 0.009281975217163563,
      "learning_rate": 9.742388017163578e-06,
      "loss": 0.0006,
      "step": 1627
    },
    {
      "epoch": 0.02577703184128442,
      "grad_norm": 0.002904642838984728,
      "learning_rate": 9.742229681587156e-06,
      "loss": 0.0002,
      "step": 1628
    },
    {
      "epoch": 0.025792865398926484,
      "grad_norm": 0.2934626638889313,
      "learning_rate": 9.742071346010736e-06,
      "loss": 1.0049,
      "step": 1629
    },
    {
      "epoch": 0.02580869895656855,
      "grad_norm": 0.00013376024435274303,
      "learning_rate": 9.741913010434316e-06,
      "loss": 0.0,
      "step": 1630
    },
    {
      "epoch": 0.02582453251421062,
      "grad_norm": 0.17596492171287537,
      "learning_rate": 9.741754674857895e-06,
      "loss": 0.0082,
      "step": 1631
    },
    {
      "epoch": 0.025840366071852684,
      "grad_norm": 0.1972682923078537,
      "learning_rate": 9.741596339281474e-06,
      "loss": 0.8234,
      "step": 1632
    },
    {
      "epoch": 0.02585619962949475,
      "grad_norm": 0.2285757064819336,
      "learning_rate": 9.741438003705054e-06,
      "loss": 0.136,
      "step": 1633
    },
    {
      "epoch": 0.02587203318713682,
      "grad_norm": 0.17983731627464294,
      "learning_rate": 9.741279668128632e-06,
      "loss": 0.1824,
      "step": 1634
    },
    {
      "epoch": 0.025887866744778883,
      "grad_norm": 0.011484883725643158,
      "learning_rate": 9.741121332552213e-06,
      "loss": 0.0005,
      "step": 1635
    },
    {
      "epoch": 0.02590370030242095,
      "grad_norm": 0.2855910062789917,
      "learning_rate": 9.740962996975792e-06,
      "loss": 0.7997,
      "step": 1636
    },
    {
      "epoch": 0.02591953386006302,
      "grad_norm": 0.2337479293346405,
      "learning_rate": 9.74080466139937e-06,
      "loss": 0.1531,
      "step": 1637
    },
    {
      "epoch": 0.025935367417705083,
      "grad_norm": 0.02431819774210453,
      "learning_rate": 9.74064632582295e-06,
      "loss": 0.0034,
      "step": 1638
    },
    {
      "epoch": 0.02595120097534715,
      "grad_norm": 0.0002733107830863446,
      "learning_rate": 9.740487990246529e-06,
      "loss": 0.0,
      "step": 1639
    },
    {
      "epoch": 0.02596703453298922,
      "grad_norm": 0.012320132926106453,
      "learning_rate": 9.740329654670108e-06,
      "loss": 0.0009,
      "step": 1640
    },
    {
      "epoch": 0.025982868090631283,
      "grad_norm": 0.0006595695740543306,
      "learning_rate": 9.740171319093687e-06,
      "loss": 0.0,
      "step": 1641
    },
    {
      "epoch": 0.02599870164827335,
      "grad_norm": 0.030271273106336594,
      "learning_rate": 9.740012983517268e-06,
      "loss": 0.0008,
      "step": 1642
    },
    {
      "epoch": 0.02601453520591542,
      "grad_norm": 0.34061190485954285,
      "learning_rate": 9.739854647940847e-06,
      "loss": 0.2544,
      "step": 1643
    },
    {
      "epoch": 0.026030368763557483,
      "grad_norm": 0.3298720717430115,
      "learning_rate": 9.739696312364426e-06,
      "loss": 0.4256,
      "step": 1644
    },
    {
      "epoch": 0.02604620232119955,
      "grad_norm": 0.0018171245465055108,
      "learning_rate": 9.739537976788005e-06,
      "loss": 0.0001,
      "step": 1645
    },
    {
      "epoch": 0.02606203587884162,
      "grad_norm": 0.029819509014487267,
      "learning_rate": 9.739379641211584e-06,
      "loss": 0.002,
      "step": 1646
    },
    {
      "epoch": 0.026077869436483683,
      "grad_norm": 0.2260809689760208,
      "learning_rate": 9.739221305635163e-06,
      "loss": 0.1438,
      "step": 1647
    },
    {
      "epoch": 0.02609370299412575,
      "grad_norm": 0.2596101760864258,
      "learning_rate": 9.739062970058744e-06,
      "loss": 0.0745,
      "step": 1648
    },
    {
      "epoch": 0.026109536551767818,
      "grad_norm": 0.235568568110466,
      "learning_rate": 9.738904634482323e-06,
      "loss": 0.0519,
      "step": 1649
    },
    {
      "epoch": 0.026125370109409882,
      "grad_norm": 0.00027302480884827673,
      "learning_rate": 9.738746298905902e-06,
      "loss": 0.0,
      "step": 1650
    },
    {
      "epoch": 0.02614120366705195,
      "grad_norm": 0.3305518925189972,
      "learning_rate": 9.738587963329481e-06,
      "loss": 0.73,
      "step": 1651
    },
    {
      "epoch": 0.026157037224694018,
      "grad_norm": 0.23432451486587524,
      "learning_rate": 9.73842962775306e-06,
      "loss": 0.2432,
      "step": 1652
    },
    {
      "epoch": 0.026172870782336082,
      "grad_norm": 0.3157850205898285,
      "learning_rate": 9.73827129217664e-06,
      "loss": 0.1978,
      "step": 1653
    },
    {
      "epoch": 0.02618870433997815,
      "grad_norm": 0.14137113094329834,
      "learning_rate": 9.73811295660022e-06,
      "loss": 0.5543,
      "step": 1654
    },
    {
      "epoch": 0.026204537897620218,
      "grad_norm": 0.0001804707571864128,
      "learning_rate": 9.7379546210238e-06,
      "loss": 0.0,
      "step": 1655
    },
    {
      "epoch": 0.026220371455262282,
      "grad_norm": 0.24603642523288727,
      "learning_rate": 9.737796285447378e-06,
      "loss": 0.1562,
      "step": 1656
    },
    {
      "epoch": 0.02623620501290435,
      "grad_norm": 0.19683313369750977,
      "learning_rate": 9.737637949870957e-06,
      "loss": 0.0415,
      "step": 1657
    },
    {
      "epoch": 0.026252038570546418,
      "grad_norm": 0.009363292716443539,
      "learning_rate": 9.737479614294537e-06,
      "loss": 0.0004,
      "step": 1658
    },
    {
      "epoch": 0.026267872128188482,
      "grad_norm": 0.4620562195777893,
      "learning_rate": 9.737321278718116e-06,
      "loss": 0.169,
      "step": 1659
    },
    {
      "epoch": 0.02628370568583055,
      "grad_norm": 0.2489183396100998,
      "learning_rate": 9.737162943141696e-06,
      "loss": 0.0161,
      "step": 1660
    },
    {
      "epoch": 0.026299539243472617,
      "grad_norm": 0.0003294708440080285,
      "learning_rate": 9.737004607565275e-06,
      "loss": 0.0,
      "step": 1661
    },
    {
      "epoch": 0.02631537280111468,
      "grad_norm": 0.22158820927143097,
      "learning_rate": 9.736846271988853e-06,
      "loss": 0.1694,
      "step": 1662
    },
    {
      "epoch": 0.02633120635875675,
      "grad_norm": 0.15092451870441437,
      "learning_rate": 9.736687936412434e-06,
      "loss": 0.0599,
      "step": 1663
    },
    {
      "epoch": 0.026347039916398817,
      "grad_norm": 1.1725902557373047,
      "learning_rate": 9.736529600836013e-06,
      "loss": 0.1389,
      "step": 1664
    },
    {
      "epoch": 0.02636287347404088,
      "grad_norm": 0.283894807100296,
      "learning_rate": 9.736371265259592e-06,
      "loss": 0.1471,
      "step": 1665
    },
    {
      "epoch": 0.02637870703168295,
      "grad_norm": 0.1816900074481964,
      "learning_rate": 9.736212929683171e-06,
      "loss": 0.0771,
      "step": 1666
    },
    {
      "epoch": 0.026394540589325017,
      "grad_norm": 0.14643734693527222,
      "learning_rate": 9.73605459410675e-06,
      "loss": 0.1117,
      "step": 1667
    },
    {
      "epoch": 0.02641037414696708,
      "grad_norm": 0.34100645780563354,
      "learning_rate": 9.735896258530329e-06,
      "loss": 0.0512,
      "step": 1668
    },
    {
      "epoch": 0.02642620770460915,
      "grad_norm": 0.15832722187042236,
      "learning_rate": 9.73573792295391e-06,
      "loss": 0.5531,
      "step": 1669
    },
    {
      "epoch": 0.026442041262251217,
      "grad_norm": 0.0004038835468236357,
      "learning_rate": 9.735579587377489e-06,
      "loss": 0.0,
      "step": 1670
    },
    {
      "epoch": 0.02645787481989328,
      "grad_norm": 0.003941538278013468,
      "learning_rate": 9.735421251801068e-06,
      "loss": 0.0002,
      "step": 1671
    },
    {
      "epoch": 0.02647370837753535,
      "grad_norm": 0.24217328429222107,
      "learning_rate": 9.735262916224647e-06,
      "loss": 0.0693,
      "step": 1672
    },
    {
      "epoch": 0.026489541935177417,
      "grad_norm": 0.33422669768333435,
      "learning_rate": 9.735104580648226e-06,
      "loss": 0.152,
      "step": 1673
    },
    {
      "epoch": 0.02650537549281948,
      "grad_norm": 0.22123713791370392,
      "learning_rate": 9.734946245071805e-06,
      "loss": 0.0036,
      "step": 1674
    },
    {
      "epoch": 0.02652120905046155,
      "grad_norm": 0.3639938533306122,
      "learning_rate": 9.734787909495386e-06,
      "loss": 0.4668,
      "step": 1675
    },
    {
      "epoch": 0.026537042608103616,
      "grad_norm": 0.005679260939359665,
      "learning_rate": 9.734629573918965e-06,
      "loss": 0.0004,
      "step": 1676
    },
    {
      "epoch": 0.02655287616574568,
      "grad_norm": 0.19630149006843567,
      "learning_rate": 9.734471238342544e-06,
      "loss": 0.0678,
      "step": 1677
    },
    {
      "epoch": 0.02656870972338775,
      "grad_norm": 0.18312574923038483,
      "learning_rate": 9.734312902766123e-06,
      "loss": 0.2015,
      "step": 1678
    },
    {
      "epoch": 0.026584543281029816,
      "grad_norm": 0.3063490688800812,
      "learning_rate": 9.734154567189702e-06,
      "loss": 0.1274,
      "step": 1679
    },
    {
      "epoch": 0.02660037683867188,
      "grad_norm": 0.39257538318634033,
      "learning_rate": 9.733996231613281e-06,
      "loss": 0.1218,
      "step": 1680
    },
    {
      "epoch": 0.026616210396313948,
      "grad_norm": 0.18338806927204132,
      "learning_rate": 9.733837896036862e-06,
      "loss": 0.0077,
      "step": 1681
    },
    {
      "epoch": 0.026632043953956016,
      "grad_norm": 0.20010991394519806,
      "learning_rate": 9.733679560460441e-06,
      "loss": 0.0987,
      "step": 1682
    },
    {
      "epoch": 0.02664787751159808,
      "grad_norm": 0.12946628034114838,
      "learning_rate": 9.73352122488402e-06,
      "loss": 0.1408,
      "step": 1683
    },
    {
      "epoch": 0.026663711069240148,
      "grad_norm": 0.19858968257904053,
      "learning_rate": 9.7333628893076e-06,
      "loss": 0.0388,
      "step": 1684
    },
    {
      "epoch": 0.026679544626882216,
      "grad_norm": 0.1882573515176773,
      "learning_rate": 9.733204553731178e-06,
      "loss": 0.2596,
      "step": 1685
    },
    {
      "epoch": 0.02669537818452428,
      "grad_norm": 0.28013646602630615,
      "learning_rate": 9.733046218154758e-06,
      "loss": 0.1237,
      "step": 1686
    },
    {
      "epoch": 0.026711211742166348,
      "grad_norm": 0.00032462383387610316,
      "learning_rate": 9.732887882578337e-06,
      "loss": 0.0,
      "step": 1687
    },
    {
      "epoch": 0.026727045299808416,
      "grad_norm": 0.22890393435955048,
      "learning_rate": 9.732729547001917e-06,
      "loss": 0.5819,
      "step": 1688
    },
    {
      "epoch": 0.02674287885745048,
      "grad_norm": 0.20139360427856445,
      "learning_rate": 9.732571211425495e-06,
      "loss": 0.0939,
      "step": 1689
    },
    {
      "epoch": 0.026758712415092548,
      "grad_norm": 0.004329651594161987,
      "learning_rate": 9.732412875849076e-06,
      "loss": 0.0003,
      "step": 1690
    },
    {
      "epoch": 0.026774545972734615,
      "grad_norm": 0.10690625756978989,
      "learning_rate": 9.732254540272655e-06,
      "loss": 0.0482,
      "step": 1691
    },
    {
      "epoch": 0.02679037953037668,
      "grad_norm": 0.0002562545705586672,
      "learning_rate": 9.732096204696234e-06,
      "loss": 0.0,
      "step": 1692
    },
    {
      "epoch": 0.026806213088018747,
      "grad_norm": 0.5846765041351318,
      "learning_rate": 9.731937869119813e-06,
      "loss": 0.1824,
      "step": 1693
    },
    {
      "epoch": 0.026822046645660815,
      "grad_norm": 0.013707845471799374,
      "learning_rate": 9.731779533543394e-06,
      "loss": 0.0012,
      "step": 1694
    },
    {
      "epoch": 0.02683788020330288,
      "grad_norm": 0.2111404538154602,
      "learning_rate": 9.731621197966971e-06,
      "loss": 0.1734,
      "step": 1695
    },
    {
      "epoch": 0.026853713760944947,
      "grad_norm": 0.4286491274833679,
      "learning_rate": 9.731462862390552e-06,
      "loss": 0.1224,
      "step": 1696
    },
    {
      "epoch": 0.026869547318587015,
      "grad_norm": 0.3043610155582428,
      "learning_rate": 9.73130452681413e-06,
      "loss": 0.2159,
      "step": 1697
    },
    {
      "epoch": 0.02688538087622908,
      "grad_norm": 1.0074864625930786,
      "learning_rate": 9.73114619123771e-06,
      "loss": 0.4689,
      "step": 1698
    },
    {
      "epoch": 0.026901214433871147,
      "grad_norm": 0.1556234359741211,
      "learning_rate": 9.730987855661289e-06,
      "loss": 0.2491,
      "step": 1699
    },
    {
      "epoch": 0.026917047991513215,
      "grad_norm": 0.04158613458275795,
      "learning_rate": 9.73082952008487e-06,
      "loss": 0.0103,
      "step": 1700
    },
    {
      "epoch": 0.02693288154915528,
      "grad_norm": 0.47957244515419006,
      "learning_rate": 9.730671184508447e-06,
      "loss": 0.0503,
      "step": 1701
    },
    {
      "epoch": 0.026948715106797347,
      "grad_norm": 0.22570914030075073,
      "learning_rate": 9.730512848932028e-06,
      "loss": 0.2255,
      "step": 1702
    },
    {
      "epoch": 0.026964548664439415,
      "grad_norm": 0.2550075352191925,
      "learning_rate": 9.730354513355607e-06,
      "loss": 0.1509,
      "step": 1703
    },
    {
      "epoch": 0.02698038222208148,
      "grad_norm": 0.0035339058376848698,
      "learning_rate": 9.730196177779186e-06,
      "loss": 0.0003,
      "step": 1704
    },
    {
      "epoch": 0.026996215779723547,
      "grad_norm": 0.31917592883110046,
      "learning_rate": 9.730037842202765e-06,
      "loss": 0.1768,
      "step": 1705
    },
    {
      "epoch": 0.027012049337365614,
      "grad_norm": 0.016109906136989594,
      "learning_rate": 9.729879506626346e-06,
      "loss": 0.0022,
      "step": 1706
    },
    {
      "epoch": 0.02702788289500768,
      "grad_norm": 0.10456658154726028,
      "learning_rate": 9.729721171049923e-06,
      "loss": 0.0228,
      "step": 1707
    },
    {
      "epoch": 0.027043716452649746,
      "grad_norm": 0.5601552724838257,
      "learning_rate": 9.729562835473504e-06,
      "loss": 0.2595,
      "step": 1708
    },
    {
      "epoch": 0.027059550010291814,
      "grad_norm": 0.09775695204734802,
      "learning_rate": 9.729404499897083e-06,
      "loss": 0.0756,
      "step": 1709
    },
    {
      "epoch": 0.02707538356793388,
      "grad_norm": 0.2509939968585968,
      "learning_rate": 9.729246164320662e-06,
      "loss": 0.5409,
      "step": 1710
    },
    {
      "epoch": 0.027091217125575946,
      "grad_norm": 0.16586834192276,
      "learning_rate": 9.729087828744241e-06,
      "loss": 0.4152,
      "step": 1711
    },
    {
      "epoch": 0.02710705068321801,
      "grad_norm": 0.2365867793560028,
      "learning_rate": 9.72892949316782e-06,
      "loss": 0.1563,
      "step": 1712
    },
    {
      "epoch": 0.02712288424086008,
      "grad_norm": 2.041818857192993,
      "learning_rate": 9.7287711575914e-06,
      "loss": 0.1371,
      "step": 1713
    },
    {
      "epoch": 0.027138717798502146,
      "grad_norm": 0.4363483786582947,
      "learning_rate": 9.728612822014979e-06,
      "loss": 0.4134,
      "step": 1714
    },
    {
      "epoch": 0.02715455135614421,
      "grad_norm": 0.26025447249412537,
      "learning_rate": 9.72845448643856e-06,
      "loss": 0.1679,
      "step": 1715
    },
    {
      "epoch": 0.027170384913786278,
      "grad_norm": 0.476954847574234,
      "learning_rate": 9.728296150862138e-06,
      "loss": 0.3759,
      "step": 1716
    },
    {
      "epoch": 0.027186218471428346,
      "grad_norm": 0.10497832298278809,
      "learning_rate": 9.728137815285717e-06,
      "loss": 0.0028,
      "step": 1717
    },
    {
      "epoch": 0.02720205202907041,
      "grad_norm": 0.21470847725868225,
      "learning_rate": 9.727979479709297e-06,
      "loss": 0.0666,
      "step": 1718
    },
    {
      "epoch": 0.027217885586712478,
      "grad_norm": 0.0995163843035698,
      "learning_rate": 9.727821144132876e-06,
      "loss": 0.0459,
      "step": 1719
    },
    {
      "epoch": 0.027233719144354546,
      "grad_norm": 0.18354062736034393,
      "learning_rate": 9.727662808556455e-06,
      "loss": 0.4439,
      "step": 1720
    },
    {
      "epoch": 0.02724955270199661,
      "grad_norm": 0.09641716629266739,
      "learning_rate": 9.727504472980035e-06,
      "loss": 0.0565,
      "step": 1721
    },
    {
      "epoch": 0.027265386259638678,
      "grad_norm": 0.0014750693226233125,
      "learning_rate": 9.727346137403615e-06,
      "loss": 0.0,
      "step": 1722
    },
    {
      "epoch": 0.027281219817280745,
      "grad_norm": 0.1947847455739975,
      "learning_rate": 9.727187801827194e-06,
      "loss": 0.4965,
      "step": 1723
    },
    {
      "epoch": 0.02729705337492281,
      "grad_norm": 0.27710992097854614,
      "learning_rate": 9.727029466250773e-06,
      "loss": 0.7872,
      "step": 1724
    },
    {
      "epoch": 0.027312886932564878,
      "grad_norm": 0.15671406686306,
      "learning_rate": 9.726871130674352e-06,
      "loss": 0.4057,
      "step": 1725
    },
    {
      "epoch": 0.027328720490206945,
      "grad_norm": 0.006357854697853327,
      "learning_rate": 9.726712795097931e-06,
      "loss": 0.0005,
      "step": 1726
    },
    {
      "epoch": 0.02734455404784901,
      "grad_norm": 0.14544418454170227,
      "learning_rate": 9.726554459521512e-06,
      "loss": 0.0832,
      "step": 1727
    },
    {
      "epoch": 0.027360387605491077,
      "grad_norm": 0.1072259470820427,
      "learning_rate": 9.72639612394509e-06,
      "loss": 0.0616,
      "step": 1728
    },
    {
      "epoch": 0.027376221163133145,
      "grad_norm": 0.0860704854130745,
      "learning_rate": 9.72623778836867e-06,
      "loss": 0.0417,
      "step": 1729
    },
    {
      "epoch": 0.02739205472077521,
      "grad_norm": 0.26416435837745667,
      "learning_rate": 9.726079452792249e-06,
      "loss": 0.7758,
      "step": 1730
    },
    {
      "epoch": 0.027407888278417277,
      "grad_norm": 0.4183577299118042,
      "learning_rate": 9.725921117215828e-06,
      "loss": 0.4285,
      "step": 1731
    },
    {
      "epoch": 0.027423721836059345,
      "grad_norm": 0.005830325186252594,
      "learning_rate": 9.725762781639407e-06,
      "loss": 0.0004,
      "step": 1732
    },
    {
      "epoch": 0.02743955539370141,
      "grad_norm": 0.14452984929084778,
      "learning_rate": 9.725604446062986e-06,
      "loss": 0.0703,
      "step": 1733
    },
    {
      "epoch": 0.027455388951343477,
      "grad_norm": 0.34863385558128357,
      "learning_rate": 9.725446110486565e-06,
      "loss": 0.0671,
      "step": 1734
    },
    {
      "epoch": 0.027471222508985545,
      "grad_norm": 0.3528331518173218,
      "learning_rate": 9.725287774910144e-06,
      "loss": 0.0781,
      "step": 1735
    },
    {
      "epoch": 0.02748705606662761,
      "grad_norm": 0.0005517816753126681,
      "learning_rate": 9.725129439333725e-06,
      "loss": 0.0,
      "step": 1736
    },
    {
      "epoch": 0.027502889624269677,
      "grad_norm": 0.0038614319637417793,
      "learning_rate": 9.724971103757304e-06,
      "loss": 0.0002,
      "step": 1737
    },
    {
      "epoch": 0.027518723181911744,
      "grad_norm": 0.029802845790982246,
      "learning_rate": 9.724812768180883e-06,
      "loss": 0.0043,
      "step": 1738
    },
    {
      "epoch": 0.02753455673955381,
      "grad_norm": 0.10246898978948593,
      "learning_rate": 9.724654432604462e-06,
      "loss": 0.0511,
      "step": 1739
    },
    {
      "epoch": 0.027550390297195877,
      "grad_norm": 0.4894116222858429,
      "learning_rate": 9.724496097028041e-06,
      "loss": 0.1758,
      "step": 1740
    },
    {
      "epoch": 0.027566223854837944,
      "grad_norm": 0.1039317175745964,
      "learning_rate": 9.72433776145162e-06,
      "loss": 0.0065,
      "step": 1741
    },
    {
      "epoch": 0.02758205741248001,
      "grad_norm": 0.012840159237384796,
      "learning_rate": 9.724179425875201e-06,
      "loss": 0.0004,
      "step": 1742
    },
    {
      "epoch": 0.027597890970122076,
      "grad_norm": 0.3250957727432251,
      "learning_rate": 9.72402109029878e-06,
      "loss": 0.4813,
      "step": 1743
    },
    {
      "epoch": 0.027613724527764144,
      "grad_norm": 0.19702307879924774,
      "learning_rate": 9.72386275472236e-06,
      "loss": 0.0806,
      "step": 1744
    },
    {
      "epoch": 0.02762955808540621,
      "grad_norm": 0.1369095891714096,
      "learning_rate": 9.723704419145938e-06,
      "loss": 0.1501,
      "step": 1745
    },
    {
      "epoch": 0.027645391643048276,
      "grad_norm": 0.01341831311583519,
      "learning_rate": 9.723546083569518e-06,
      "loss": 0.0012,
      "step": 1746
    },
    {
      "epoch": 0.027661225200690344,
      "grad_norm": 0.010638189502060413,
      "learning_rate": 9.723387747993097e-06,
      "loss": 0.0008,
      "step": 1747
    },
    {
      "epoch": 0.027677058758332408,
      "grad_norm": 0.1203567385673523,
      "learning_rate": 9.723229412416677e-06,
      "loss": 0.0845,
      "step": 1748
    },
    {
      "epoch": 0.027692892315974476,
      "grad_norm": 0.20380254089832306,
      "learning_rate": 9.723071076840257e-06,
      "loss": 0.4204,
      "step": 1749
    },
    {
      "epoch": 0.027708725873616544,
      "grad_norm": 0.5905002355575562,
      "learning_rate": 9.722912741263836e-06,
      "loss": 0.3858,
      "step": 1750
    },
    {
      "epoch": 0.027724559431258608,
      "grad_norm": 0.15631777048110962,
      "learning_rate": 9.722754405687415e-06,
      "loss": 0.4527,
      "step": 1751
    },
    {
      "epoch": 0.027740392988900676,
      "grad_norm": 0.01443876326084137,
      "learning_rate": 9.722596070110994e-06,
      "loss": 0.0011,
      "step": 1752
    },
    {
      "epoch": 0.027756226546542744,
      "grad_norm": 0.23903560638427734,
      "learning_rate": 9.722437734534573e-06,
      "loss": 0.5353,
      "step": 1753
    },
    {
      "epoch": 0.027772060104184808,
      "grad_norm": 0.5189651250839233,
      "learning_rate": 9.722279398958154e-06,
      "loss": 0.2303,
      "step": 1754
    },
    {
      "epoch": 0.027787893661826876,
      "grad_norm": 0.18743892014026642,
      "learning_rate": 9.722121063381733e-06,
      "loss": 0.2847,
      "step": 1755
    },
    {
      "epoch": 0.027803727219468943,
      "grad_norm": 0.00011379765055608004,
      "learning_rate": 9.721962727805312e-06,
      "loss": 0.0,
      "step": 1756
    },
    {
      "epoch": 0.027819560777111008,
      "grad_norm": 0.01898748241364956,
      "learning_rate": 9.72180439222889e-06,
      "loss": 0.0015,
      "step": 1757
    },
    {
      "epoch": 0.027835394334753075,
      "grad_norm": 0.15553855895996094,
      "learning_rate": 9.72164605665247e-06,
      "loss": 0.1045,
      "step": 1758
    },
    {
      "epoch": 0.027851227892395143,
      "grad_norm": 0.0002603870234452188,
      "learning_rate": 9.721487721076049e-06,
      "loss": 0.0,
      "step": 1759
    },
    {
      "epoch": 0.027867061450037207,
      "grad_norm": 0.17590487003326416,
      "learning_rate": 9.721329385499628e-06,
      "loss": 0.5003,
      "step": 1760
    },
    {
      "epoch": 0.027882895007679275,
      "grad_norm": 0.13364583253860474,
      "learning_rate": 9.721171049923209e-06,
      "loss": 0.2538,
      "step": 1761
    },
    {
      "epoch": 0.027898728565321343,
      "grad_norm": 0.2582436203956604,
      "learning_rate": 9.721012714346786e-06,
      "loss": 0.2309,
      "step": 1762
    },
    {
      "epoch": 0.027914562122963407,
      "grad_norm": 0.16229774057865143,
      "learning_rate": 9.720854378770367e-06,
      "loss": 0.0993,
      "step": 1763
    },
    {
      "epoch": 0.027930395680605475,
      "grad_norm": 0.00016677513485774398,
      "learning_rate": 9.720696043193946e-06,
      "loss": 0.0,
      "step": 1764
    },
    {
      "epoch": 0.027946229238247543,
      "grad_norm": 0.8705059885978699,
      "learning_rate": 9.720537707617525e-06,
      "loss": 0.6949,
      "step": 1765
    },
    {
      "epoch": 0.027962062795889607,
      "grad_norm": 0.2129056602716446,
      "learning_rate": 9.720379372041104e-06,
      "loss": 0.3213,
      "step": 1766
    },
    {
      "epoch": 0.027977896353531675,
      "grad_norm": 0.10007579624652863,
      "learning_rate": 9.720221036464685e-06,
      "loss": 0.005,
      "step": 1767
    },
    {
      "epoch": 0.027993729911173743,
      "grad_norm": 0.00013340922305360436,
      "learning_rate": 9.720062700888262e-06,
      "loss": 0.0,
      "step": 1768
    },
    {
      "epoch": 0.028009563468815807,
      "grad_norm": 0.021365713328123093,
      "learning_rate": 9.719904365311843e-06,
      "loss": 0.0016,
      "step": 1769
    },
    {
      "epoch": 0.028025397026457875,
      "grad_norm": 0.0005519484402611852,
      "learning_rate": 9.719746029735422e-06,
      "loss": 0.0,
      "step": 1770
    },
    {
      "epoch": 0.028041230584099942,
      "grad_norm": 0.6245179176330566,
      "learning_rate": 9.719587694159001e-06,
      "loss": 0.2527,
      "step": 1771
    },
    {
      "epoch": 0.028057064141742007,
      "grad_norm": 0.00019654126663226634,
      "learning_rate": 9.71942935858258e-06,
      "loss": 0.0,
      "step": 1772
    },
    {
      "epoch": 0.028072897699384074,
      "grad_norm": 0.00432869466021657,
      "learning_rate": 9.719271023006161e-06,
      "loss": 0.0002,
      "step": 1773
    },
    {
      "epoch": 0.028088731257026142,
      "grad_norm": 0.23214508593082428,
      "learning_rate": 9.719112687429739e-06,
      "loss": 0.2041,
      "step": 1774
    },
    {
      "epoch": 0.028104564814668206,
      "grad_norm": 0.18223083019256592,
      "learning_rate": 9.71895435185332e-06,
      "loss": 0.0835,
      "step": 1775
    },
    {
      "epoch": 0.028120398372310274,
      "grad_norm": 0.29518285393714905,
      "learning_rate": 9.718796016276898e-06,
      "loss": 0.1014,
      "step": 1776
    },
    {
      "epoch": 0.028136231929952342,
      "grad_norm": 0.3085813522338867,
      "learning_rate": 9.718637680700478e-06,
      "loss": 0.0787,
      "step": 1777
    },
    {
      "epoch": 0.028152065487594406,
      "grad_norm": 0.3057204484939575,
      "learning_rate": 9.718479345124057e-06,
      "loss": 0.5758,
      "step": 1778
    },
    {
      "epoch": 0.028167899045236474,
      "grad_norm": 0.0005428005242720246,
      "learning_rate": 9.718321009547637e-06,
      "loss": 0.0,
      "step": 1779
    },
    {
      "epoch": 0.028183732602878542,
      "grad_norm": 0.002352245384827256,
      "learning_rate": 9.718162673971215e-06,
      "loss": 0.0,
      "step": 1780
    },
    {
      "epoch": 0.028199566160520606,
      "grad_norm": 0.36501121520996094,
      "learning_rate": 9.718004338394794e-06,
      "loss": 0.2635,
      "step": 1781
    },
    {
      "epoch": 0.028215399718162674,
      "grad_norm": 0.2001630961894989,
      "learning_rate": 9.717846002818375e-06,
      "loss": 0.0744,
      "step": 1782
    },
    {
      "epoch": 0.02823123327580474,
      "grad_norm": 0.03143000230193138,
      "learning_rate": 9.717687667241954e-06,
      "loss": 0.0026,
      "step": 1783
    },
    {
      "epoch": 0.028247066833446806,
      "grad_norm": 0.1881580352783203,
      "learning_rate": 9.717529331665533e-06,
      "loss": 0.122,
      "step": 1784
    },
    {
      "epoch": 0.028262900391088874,
      "grad_norm": 0.030267536640167236,
      "learning_rate": 9.717370996089112e-06,
      "loss": 0.0026,
      "step": 1785
    },
    {
      "epoch": 0.02827873394873094,
      "grad_norm": 0.12837840616703033,
      "learning_rate": 9.717212660512691e-06,
      "loss": 0.0642,
      "step": 1786
    },
    {
      "epoch": 0.028294567506373006,
      "grad_norm": 0.15853773057460785,
      "learning_rate": 9.71705432493627e-06,
      "loss": 0.0236,
      "step": 1787
    },
    {
      "epoch": 0.028310401064015073,
      "grad_norm": 0.3098299205303192,
      "learning_rate": 9.71689598935985e-06,
      "loss": 0.0756,
      "step": 1788
    },
    {
      "epoch": 0.02832623462165714,
      "grad_norm": 0.16242116689682007,
      "learning_rate": 9.71673765378343e-06,
      "loss": 0.1712,
      "step": 1789
    },
    {
      "epoch": 0.028342068179299205,
      "grad_norm": 0.010127837769687176,
      "learning_rate": 9.716579318207009e-06,
      "loss": 0.0007,
      "step": 1790
    },
    {
      "epoch": 0.028357901736941273,
      "grad_norm": 0.19622431695461273,
      "learning_rate": 9.716420982630588e-06,
      "loss": 0.0903,
      "step": 1791
    },
    {
      "epoch": 0.02837373529458334,
      "grad_norm": 0.00032852301956154406,
      "learning_rate": 9.716262647054167e-06,
      "loss": 0.0,
      "step": 1792
    },
    {
      "epoch": 0.028389568852225405,
      "grad_norm": 0.21056868135929108,
      "learning_rate": 9.716104311477746e-06,
      "loss": 0.0942,
      "step": 1793
    },
    {
      "epoch": 0.028405402409867473,
      "grad_norm": 0.1483861654996872,
      "learning_rate": 9.715945975901327e-06,
      "loss": 0.124,
      "step": 1794
    },
    {
      "epoch": 0.02842123596750954,
      "grad_norm": 0.6197649836540222,
      "learning_rate": 9.715787640324906e-06,
      "loss": 0.094,
      "step": 1795
    },
    {
      "epoch": 0.028437069525151605,
      "grad_norm": 0.09924707561731339,
      "learning_rate": 9.715629304748485e-06,
      "loss": 0.0501,
      "step": 1796
    },
    {
      "epoch": 0.028452903082793673,
      "grad_norm": 0.0025045531801879406,
      "learning_rate": 9.715470969172064e-06,
      "loss": 0.0001,
      "step": 1797
    },
    {
      "epoch": 0.02846873664043574,
      "grad_norm": 0.22770939767360687,
      "learning_rate": 9.715312633595643e-06,
      "loss": 0.3252,
      "step": 1798
    },
    {
      "epoch": 0.028484570198077805,
      "grad_norm": 0.004143220372498035,
      "learning_rate": 9.715154298019222e-06,
      "loss": 0.0002,
      "step": 1799
    },
    {
      "epoch": 0.028500403755719873,
      "grad_norm": 0.3029457628726959,
      "learning_rate": 9.714995962442803e-06,
      "loss": 0.3283,
      "step": 1800
    },
    {
      "epoch": 0.02851623731336194,
      "grad_norm": 0.013250058516860008,
      "learning_rate": 9.71483762686638e-06,
      "loss": 0.0009,
      "step": 1801
    },
    {
      "epoch": 0.028532070871004005,
      "grad_norm": 0.2365933358669281,
      "learning_rate": 9.714679291289961e-06,
      "loss": 0.0949,
      "step": 1802
    },
    {
      "epoch": 0.028547904428646072,
      "grad_norm": 0.14798064529895782,
      "learning_rate": 9.71452095571354e-06,
      "loss": 0.0515,
      "step": 1803
    },
    {
      "epoch": 0.02856373798628814,
      "grad_norm": 0.2742673456668854,
      "learning_rate": 9.71436262013712e-06,
      "loss": 0.9122,
      "step": 1804
    },
    {
      "epoch": 0.028579571543930204,
      "grad_norm": 0.2885439395904541,
      "learning_rate": 9.714204284560699e-06,
      "loss": 0.2152,
      "step": 1805
    },
    {
      "epoch": 0.028595405101572272,
      "grad_norm": 0.4264698922634125,
      "learning_rate": 9.714045948984278e-06,
      "loss": 0.3223,
      "step": 1806
    },
    {
      "epoch": 0.02861123865921434,
      "grad_norm": 0.21086643636226654,
      "learning_rate": 9.713887613407857e-06,
      "loss": 0.0536,
      "step": 1807
    },
    {
      "epoch": 0.028627072216856404,
      "grad_norm": 0.17957189679145813,
      "learning_rate": 9.713729277831436e-06,
      "loss": 0.1138,
      "step": 1808
    },
    {
      "epoch": 0.028642905774498472,
      "grad_norm": 0.2281426191329956,
      "learning_rate": 9.713570942255017e-06,
      "loss": 0.4654,
      "step": 1809
    },
    {
      "epoch": 0.02865873933214054,
      "grad_norm": 0.2419581264257431,
      "learning_rate": 9.713412606678596e-06,
      "loss": 0.0348,
      "step": 1810
    },
    {
      "epoch": 0.028674572889782604,
      "grad_norm": 0.0034377677366137505,
      "learning_rate": 9.713254271102175e-06,
      "loss": 0.0002,
      "step": 1811
    },
    {
      "epoch": 0.028690406447424672,
      "grad_norm": 0.1724785417318344,
      "learning_rate": 9.713095935525754e-06,
      "loss": 0.1378,
      "step": 1812
    },
    {
      "epoch": 0.02870624000506674,
      "grad_norm": 0.012096368707716465,
      "learning_rate": 9.712937599949333e-06,
      "loss": 0.0009,
      "step": 1813
    },
    {
      "epoch": 0.028722073562708804,
      "grad_norm": 0.5211818218231201,
      "learning_rate": 9.712779264372912e-06,
      "loss": 0.2343,
      "step": 1814
    },
    {
      "epoch": 0.02873790712035087,
      "grad_norm": 0.5609136819839478,
      "learning_rate": 9.712620928796493e-06,
      "loss": 0.9206,
      "step": 1815
    },
    {
      "epoch": 0.02875374067799294,
      "grad_norm": 0.19536447525024414,
      "learning_rate": 9.712462593220072e-06,
      "loss": 0.1107,
      "step": 1816
    },
    {
      "epoch": 0.028769574235635004,
      "grad_norm": 0.006095638033002615,
      "learning_rate": 9.712304257643651e-06,
      "loss": 0.0003,
      "step": 1817
    },
    {
      "epoch": 0.02878540779327707,
      "grad_norm": 0.508224606513977,
      "learning_rate": 9.71214592206723e-06,
      "loss": 0.1474,
      "step": 1818
    },
    {
      "epoch": 0.02880124135091914,
      "grad_norm": 0.2830575406551361,
      "learning_rate": 9.711987586490809e-06,
      "loss": 0.1741,
      "step": 1819
    },
    {
      "epoch": 0.028817074908561204,
      "grad_norm": 0.9340721368789673,
      "learning_rate": 9.711829250914388e-06,
      "loss": 0.4822,
      "step": 1820
    },
    {
      "epoch": 0.02883290846620327,
      "grad_norm": 0.2159697711467743,
      "learning_rate": 9.711670915337969e-06,
      "loss": 0.3452,
      "step": 1821
    },
    {
      "epoch": 0.02884874202384534,
      "grad_norm": 0.02284093201160431,
      "learning_rate": 9.711512579761548e-06,
      "loss": 0.0015,
      "step": 1822
    },
    {
      "epoch": 0.028864575581487403,
      "grad_norm": 0.12485475093126297,
      "learning_rate": 9.711354244185127e-06,
      "loss": 0.0679,
      "step": 1823
    },
    {
      "epoch": 0.02888040913912947,
      "grad_norm": 0.004199136048555374,
      "learning_rate": 9.711195908608706e-06,
      "loss": 0.0002,
      "step": 1824
    },
    {
      "epoch": 0.02889624269677154,
      "grad_norm": 0.25298917293548584,
      "learning_rate": 9.711037573032285e-06,
      "loss": 0.1946,
      "step": 1825
    },
    {
      "epoch": 0.028912076254413603,
      "grad_norm": 0.29215094447135925,
      "learning_rate": 9.710879237455864e-06,
      "loss": 0.2433,
      "step": 1826
    },
    {
      "epoch": 0.02892790981205567,
      "grad_norm": 0.1441289186477661,
      "learning_rate": 9.710720901879445e-06,
      "loss": 0.1394,
      "step": 1827
    },
    {
      "epoch": 0.02894374336969774,
      "grad_norm": 0.08200503140687943,
      "learning_rate": 9.710562566303024e-06,
      "loss": 0.0359,
      "step": 1828
    },
    {
      "epoch": 0.028959576927339803,
      "grad_norm": 1.1912546157836914,
      "learning_rate": 9.710404230726602e-06,
      "loss": 0.1618,
      "step": 1829
    },
    {
      "epoch": 0.02897541048498187,
      "grad_norm": 0.008557453751564026,
      "learning_rate": 9.710245895150182e-06,
      "loss": 0.0006,
      "step": 1830
    },
    {
      "epoch": 0.02899124404262394,
      "grad_norm": 0.012055735103785992,
      "learning_rate": 9.710087559573761e-06,
      "loss": 0.0007,
      "step": 1831
    },
    {
      "epoch": 0.029007077600266003,
      "grad_norm": 0.27134019136428833,
      "learning_rate": 9.70992922399734e-06,
      "loss": 0.6819,
      "step": 1832
    },
    {
      "epoch": 0.02902291115790807,
      "grad_norm": 0.00025198678486049175,
      "learning_rate": 9.70977088842092e-06,
      "loss": 0.0,
      "step": 1833
    },
    {
      "epoch": 0.029038744715550138,
      "grad_norm": 0.21490031480789185,
      "learning_rate": 9.7096125528445e-06,
      "loss": 0.3876,
      "step": 1834
    },
    {
      "epoch": 0.029054578273192203,
      "grad_norm": 0.0026293836999684572,
      "learning_rate": 9.709454217268078e-06,
      "loss": 0.0001,
      "step": 1835
    },
    {
      "epoch": 0.02907041183083427,
      "grad_norm": 0.36035871505737305,
      "learning_rate": 9.709295881691658e-06,
      "loss": 0.4146,
      "step": 1836
    },
    {
      "epoch": 0.029086245388476338,
      "grad_norm": 0.10502099990844727,
      "learning_rate": 9.709137546115238e-06,
      "loss": 0.0525,
      "step": 1837
    },
    {
      "epoch": 0.029102078946118402,
      "grad_norm": 0.353179007768631,
      "learning_rate": 9.708979210538817e-06,
      "loss": 0.2372,
      "step": 1838
    },
    {
      "epoch": 0.02911791250376047,
      "grad_norm": 1.6364244222640991,
      "learning_rate": 9.708820874962396e-06,
      "loss": 0.1273,
      "step": 1839
    },
    {
      "epoch": 0.029133746061402538,
      "grad_norm": 0.17224852740764618,
      "learning_rate": 9.708662539385976e-06,
      "loss": 0.1149,
      "step": 1840
    },
    {
      "epoch": 0.029149579619044602,
      "grad_norm": 0.0003566953237168491,
      "learning_rate": 9.708504203809554e-06,
      "loss": 0.0,
      "step": 1841
    },
    {
      "epoch": 0.02916541317668667,
      "grad_norm": 0.23367057740688324,
      "learning_rate": 9.708345868233135e-06,
      "loss": 0.1021,
      "step": 1842
    },
    {
      "epoch": 0.029181246734328738,
      "grad_norm": 0.19353418052196503,
      "learning_rate": 9.708187532656714e-06,
      "loss": 0.1788,
      "step": 1843
    },
    {
      "epoch": 0.029197080291970802,
      "grad_norm": 0.0017298985039815307,
      "learning_rate": 9.708029197080293e-06,
      "loss": 0.0,
      "step": 1844
    },
    {
      "epoch": 0.02921291384961287,
      "grad_norm": 0.5569878816604614,
      "learning_rate": 9.707870861503872e-06,
      "loss": 0.0911,
      "step": 1845
    },
    {
      "epoch": 0.029228747407254937,
      "grad_norm": 0.1662166863679886,
      "learning_rate": 9.707712525927453e-06,
      "loss": 0.5837,
      "step": 1846
    },
    {
      "epoch": 0.029244580964897002,
      "grad_norm": 0.2608770430088043,
      "learning_rate": 9.70755419035103e-06,
      "loss": 0.1351,
      "step": 1847
    },
    {
      "epoch": 0.02926041452253907,
      "grad_norm": 0.004995341412723064,
      "learning_rate": 9.70739585477461e-06,
      "loss": 0.0004,
      "step": 1848
    },
    {
      "epoch": 0.029276248080181137,
      "grad_norm": 0.15613968670368195,
      "learning_rate": 9.70723751919819e-06,
      "loss": 0.1226,
      "step": 1849
    },
    {
      "epoch": 0.0292920816378232,
      "grad_norm": 0.016816021874547005,
      "learning_rate": 9.707079183621769e-06,
      "loss": 0.0015,
      "step": 1850
    },
    {
      "epoch": 0.02930791519546527,
      "grad_norm": 0.010074201971292496,
      "learning_rate": 9.706920848045348e-06,
      "loss": 0.0007,
      "step": 1851
    },
    {
      "epoch": 0.029323748753107337,
      "grad_norm": 0.2898135483264923,
      "learning_rate": 9.706762512468929e-06,
      "loss": 0.155,
      "step": 1852
    },
    {
      "epoch": 0.0293395823107494,
      "grad_norm": 0.5362422466278076,
      "learning_rate": 9.706604176892506e-06,
      "loss": 0.7859,
      "step": 1853
    },
    {
      "epoch": 0.02935541586839147,
      "grad_norm": 0.16908405721187592,
      "learning_rate": 9.706445841316085e-06,
      "loss": 0.1958,
      "step": 1854
    },
    {
      "epoch": 0.029371249426033537,
      "grad_norm": 0.2658422887325287,
      "learning_rate": 9.706287505739666e-06,
      "loss": 0.5945,
      "step": 1855
    },
    {
      "epoch": 0.0293870829836756,
      "grad_norm": 9.387256432091817e-05,
      "learning_rate": 9.706129170163245e-06,
      "loss": 0.0,
      "step": 1856
    },
    {
      "epoch": 0.02940291654131767,
      "grad_norm": 0.22515171766281128,
      "learning_rate": 9.705970834586824e-06,
      "loss": 0.1697,
      "step": 1857
    },
    {
      "epoch": 0.029418750098959737,
      "grad_norm": 0.13880088925361633,
      "learning_rate": 9.705812499010403e-06,
      "loss": 0.0317,
      "step": 1858
    },
    {
      "epoch": 0.0294345836566018,
      "grad_norm": 0.2158890664577484,
      "learning_rate": 9.705654163433982e-06,
      "loss": 0.1378,
      "step": 1859
    },
    {
      "epoch": 0.02945041721424387,
      "grad_norm": 0.330409437417984,
      "learning_rate": 9.705495827857561e-06,
      "loss": 0.09,
      "step": 1860
    },
    {
      "epoch": 0.029466250771885936,
      "grad_norm": 0.3015693426132202,
      "learning_rate": 9.705337492281142e-06,
      "loss": 0.2721,
      "step": 1861
    },
    {
      "epoch": 0.029482084329528,
      "grad_norm": 0.0003686852869577706,
      "learning_rate": 9.70517915670472e-06,
      "loss": 0.0,
      "step": 1862
    },
    {
      "epoch": 0.02949791788717007,
      "grad_norm": 0.21660968661308289,
      "learning_rate": 9.7050208211283e-06,
      "loss": 0.1547,
      "step": 1863
    },
    {
      "epoch": 0.029513751444812136,
      "grad_norm": 0.16736391186714172,
      "learning_rate": 9.70486248555188e-06,
      "loss": 0.0061,
      "step": 1864
    },
    {
      "epoch": 0.0295295850024542,
      "grad_norm": 0.5195777416229248,
      "learning_rate": 9.704704149975459e-06,
      "loss": 0.3654,
      "step": 1865
    },
    {
      "epoch": 0.02954541856009627,
      "grad_norm": 0.007998497225344181,
      "learning_rate": 9.704545814399038e-06,
      "loss": 0.0006,
      "step": 1866
    },
    {
      "epoch": 0.029561252117738336,
      "grad_norm": 0.3119013011455536,
      "learning_rate": 9.704387478822618e-06,
      "loss": 0.4406,
      "step": 1867
    },
    {
      "epoch": 0.0295770856753804,
      "grad_norm": 0.0001645764714339748,
      "learning_rate": 9.704229143246196e-06,
      "loss": 0.0,
      "step": 1868
    },
    {
      "epoch": 0.029592919233022468,
      "grad_norm": 0.14350099861621857,
      "learning_rate": 9.704070807669777e-06,
      "loss": 0.0882,
      "step": 1869
    },
    {
      "epoch": 0.029608752790664536,
      "grad_norm": 0.0001558955991640687,
      "learning_rate": 9.703912472093356e-06,
      "loss": 0.0,
      "step": 1870
    },
    {
      "epoch": 0.0296245863483066,
      "grad_norm": 0.19803296029567719,
      "learning_rate": 9.703754136516935e-06,
      "loss": 0.2945,
      "step": 1871
    },
    {
      "epoch": 0.029640419905948668,
      "grad_norm": 0.3970946669578552,
      "learning_rate": 9.703595800940514e-06,
      "loss": 0.0639,
      "step": 1872
    },
    {
      "epoch": 0.029656253463590736,
      "grad_norm": 0.17919188737869263,
      "learning_rate": 9.703437465364095e-06,
      "loss": 0.0919,
      "step": 1873
    },
    {
      "epoch": 0.0296720870212328,
      "grad_norm": 0.20659643411636353,
      "learning_rate": 9.703279129787672e-06,
      "loss": 0.1504,
      "step": 1874
    },
    {
      "epoch": 0.029687920578874868,
      "grad_norm": 0.10338149219751358,
      "learning_rate": 9.703120794211253e-06,
      "loss": 0.0576,
      "step": 1875
    },
    {
      "epoch": 0.029703754136516936,
      "grad_norm": 0.1573709100484848,
      "learning_rate": 9.702962458634832e-06,
      "loss": 0.1177,
      "step": 1876
    },
    {
      "epoch": 0.029719587694159,
      "grad_norm": 0.38605618476867676,
      "learning_rate": 9.702804123058411e-06,
      "loss": 0.7045,
      "step": 1877
    },
    {
      "epoch": 0.029735421251801068,
      "grad_norm": 0.34253185987472534,
      "learning_rate": 9.70264578748199e-06,
      "loss": 0.1589,
      "step": 1878
    },
    {
      "epoch": 0.029751254809443135,
      "grad_norm": 0.6847509145736694,
      "learning_rate": 9.702487451905569e-06,
      "loss": 0.0557,
      "step": 1879
    },
    {
      "epoch": 0.0297670883670852,
      "grad_norm": 0.32918158173561096,
      "learning_rate": 9.702329116329148e-06,
      "loss": 0.5439,
      "step": 1880
    },
    {
      "epoch": 0.029782921924727267,
      "grad_norm": 0.01805983856320381,
      "learning_rate": 9.702170780752727e-06,
      "loss": 0.001,
      "step": 1881
    },
    {
      "epoch": 0.029798755482369335,
      "grad_norm": 0.6920174956321716,
      "learning_rate": 9.702012445176308e-06,
      "loss": 1.6267,
      "step": 1882
    },
    {
      "epoch": 0.0298145890400114,
      "grad_norm": 0.00525559252128005,
      "learning_rate": 9.701854109599887e-06,
      "loss": 0.0001,
      "step": 1883
    },
    {
      "epoch": 0.029830422597653467,
      "grad_norm": 0.00042932506767101586,
      "learning_rate": 9.701695774023466e-06,
      "loss": 0.0,
      "step": 1884
    },
    {
      "epoch": 0.029846256155295535,
      "grad_norm": 0.17226333916187286,
      "learning_rate": 9.701537438447045e-06,
      "loss": 0.3587,
      "step": 1885
    },
    {
      "epoch": 0.0298620897129376,
      "grad_norm": 0.2559664249420166,
      "learning_rate": 9.701379102870624e-06,
      "loss": 0.7238,
      "step": 1886
    },
    {
      "epoch": 0.029877923270579667,
      "grad_norm": 0.00018934215768240392,
      "learning_rate": 9.701220767294203e-06,
      "loss": 0.0,
      "step": 1887
    },
    {
      "epoch": 0.029893756828221735,
      "grad_norm": 0.19211141765117645,
      "learning_rate": 9.701062431717784e-06,
      "loss": 0.1046,
      "step": 1888
    },
    {
      "epoch": 0.0299095903858638,
      "grad_norm": 0.5944538712501526,
      "learning_rate": 9.700904096141363e-06,
      "loss": 0.1493,
      "step": 1889
    },
    {
      "epoch": 0.029925423943505867,
      "grad_norm": 0.14092913269996643,
      "learning_rate": 9.700745760564942e-06,
      "loss": 0.0716,
      "step": 1890
    },
    {
      "epoch": 0.029941257501147935,
      "grad_norm": 0.002501468872651458,
      "learning_rate": 9.700587424988521e-06,
      "loss": 0.0001,
      "step": 1891
    },
    {
      "epoch": 0.02995709105879,
      "grad_norm": 0.0046016741544008255,
      "learning_rate": 9.7004290894121e-06,
      "loss": 0.0004,
      "step": 1892
    },
    {
      "epoch": 0.029972924616432067,
      "grad_norm": 0.676157534122467,
      "learning_rate": 9.70027075383568e-06,
      "loss": 0.0876,
      "step": 1893
    },
    {
      "epoch": 0.029988758174074134,
      "grad_norm": 0.5803866982460022,
      "learning_rate": 9.70011241825926e-06,
      "loss": 0.4765,
      "step": 1894
    },
    {
      "epoch": 0.0300045917317162,
      "grad_norm": 0.23516079783439636,
      "learning_rate": 9.69995408268284e-06,
      "loss": 0.0595,
      "step": 1895
    },
    {
      "epoch": 0.030020425289358266,
      "grad_norm": 0.8369619250297546,
      "learning_rate": 9.699795747106418e-06,
      "loss": 0.8945,
      "step": 1896
    },
    {
      "epoch": 0.030036258847000334,
      "grad_norm": 0.13825617730617523,
      "learning_rate": 9.699637411529998e-06,
      "loss": 0.0317,
      "step": 1897
    },
    {
      "epoch": 0.0300520924046424,
      "grad_norm": 0.3154263198375702,
      "learning_rate": 9.699479075953577e-06,
      "loss": 0.0412,
      "step": 1898
    },
    {
      "epoch": 0.030067925962284466,
      "grad_norm": 0.689670979976654,
      "learning_rate": 9.699320740377156e-06,
      "loss": 0.5023,
      "step": 1899
    },
    {
      "epoch": 0.030083759519926534,
      "grad_norm": 0.1105612963438034,
      "learning_rate": 9.699162404800736e-06,
      "loss": 0.0054,
      "step": 1900
    },
    {
      "epoch": 0.030099593077568598,
      "grad_norm": 0.012203938327729702,
      "learning_rate": 9.699004069224316e-06,
      "loss": 0.0008,
      "step": 1901
    },
    {
      "epoch": 0.030115426635210666,
      "grad_norm": 0.01416669599711895,
      "learning_rate": 9.698845733647893e-06,
      "loss": 0.0011,
      "step": 1902
    },
    {
      "epoch": 0.030131260192852734,
      "grad_norm": 0.14548134803771973,
      "learning_rate": 9.698687398071474e-06,
      "loss": 0.0915,
      "step": 1903
    },
    {
      "epoch": 0.030147093750494798,
      "grad_norm": 0.021153977140784264,
      "learning_rate": 9.698529062495053e-06,
      "loss": 0.0012,
      "step": 1904
    },
    {
      "epoch": 0.030162927308136866,
      "grad_norm": 0.018149157986044884,
      "learning_rate": 9.698370726918632e-06,
      "loss": 0.0004,
      "step": 1905
    },
    {
      "epoch": 0.030178760865778934,
      "grad_norm": 0.5482870936393738,
      "learning_rate": 9.698212391342211e-06,
      "loss": 0.603,
      "step": 1906
    },
    {
      "epoch": 0.030194594423420998,
      "grad_norm": 0.00014318659668788314,
      "learning_rate": 9.698054055765792e-06,
      "loss": 0.0,
      "step": 1907
    },
    {
      "epoch": 0.030210427981063066,
      "grad_norm": 0.01210174523293972,
      "learning_rate": 9.697895720189369e-06,
      "loss": 0.0006,
      "step": 1908
    },
    {
      "epoch": 0.030226261538705133,
      "grad_norm": 0.1628986895084381,
      "learning_rate": 9.69773738461295e-06,
      "loss": 0.0912,
      "step": 1909
    },
    {
      "epoch": 0.030242095096347198,
      "grad_norm": 0.006569907069206238,
      "learning_rate": 9.697579049036529e-06,
      "loss": 0.0003,
      "step": 1910
    },
    {
      "epoch": 0.030257928653989265,
      "grad_norm": 0.09044191986322403,
      "learning_rate": 9.697420713460108e-06,
      "loss": 0.0016,
      "step": 1911
    },
    {
      "epoch": 0.03027376221163133,
      "grad_norm": 0.28513258695602417,
      "learning_rate": 9.697262377883687e-06,
      "loss": 0.554,
      "step": 1912
    },
    {
      "epoch": 0.030289595769273397,
      "grad_norm": 0.23000220954418182,
      "learning_rate": 9.697104042307268e-06,
      "loss": 0.021,
      "step": 1913
    },
    {
      "epoch": 0.030305429326915465,
      "grad_norm": 0.13763004541397095,
      "learning_rate": 9.696945706730845e-06,
      "loss": 0.1902,
      "step": 1914
    },
    {
      "epoch": 0.03032126288455753,
      "grad_norm": 0.3466101288795471,
      "learning_rate": 9.696787371154426e-06,
      "loss": 0.4967,
      "step": 1915
    },
    {
      "epoch": 0.030337096442199597,
      "grad_norm": 0.025730200111865997,
      "learning_rate": 9.696629035578005e-06,
      "loss": 0.0017,
      "step": 1916
    },
    {
      "epoch": 0.030352929999841665,
      "grad_norm": 0.33237525820732117,
      "learning_rate": 9.696470700001584e-06,
      "loss": 0.583,
      "step": 1917
    },
    {
      "epoch": 0.03036876355748373,
      "grad_norm": 0.2562853991985321,
      "learning_rate": 9.696312364425163e-06,
      "loss": 0.0985,
      "step": 1918
    },
    {
      "epoch": 0.030384597115125797,
      "grad_norm": 0.06790286302566528,
      "learning_rate": 9.696154028848744e-06,
      "loss": 0.0069,
      "step": 1919
    },
    {
      "epoch": 0.030400430672767865,
      "grad_norm": 0.13863882422447205,
      "learning_rate": 9.695995693272321e-06,
      "loss": 0.0364,
      "step": 1920
    },
    {
      "epoch": 0.03041626423040993,
      "grad_norm": 0.0034359944984316826,
      "learning_rate": 9.695837357695902e-06,
      "loss": 0.0002,
      "step": 1921
    },
    {
      "epoch": 0.030432097788051997,
      "grad_norm": 0.22136889398097992,
      "learning_rate": 9.695679022119481e-06,
      "loss": 0.6082,
      "step": 1922
    },
    {
      "epoch": 0.030447931345694065,
      "grad_norm": 0.14283116161823273,
      "learning_rate": 9.69552068654306e-06,
      "loss": 0.0641,
      "step": 1923
    },
    {
      "epoch": 0.03046376490333613,
      "grad_norm": 0.007065733429044485,
      "learning_rate": 9.69536235096664e-06,
      "loss": 0.0004,
      "step": 1924
    },
    {
      "epoch": 0.030479598460978197,
      "grad_norm": 0.1745954304933548,
      "learning_rate": 9.695204015390219e-06,
      "loss": 0.1721,
      "step": 1925
    },
    {
      "epoch": 0.030495432018620264,
      "grad_norm": 0.1459772288799286,
      "learning_rate": 9.695045679813798e-06,
      "loss": 0.0163,
      "step": 1926
    },
    {
      "epoch": 0.03051126557626233,
      "grad_norm": 0.00017942739941645414,
      "learning_rate": 9.694887344237377e-06,
      "loss": 0.0,
      "step": 1927
    },
    {
      "epoch": 0.030527099133904396,
      "grad_norm": 0.00026076234644278884,
      "learning_rate": 9.694729008660957e-06,
      "loss": 0.0,
      "step": 1928
    },
    {
      "epoch": 0.030542932691546464,
      "grad_norm": 0.2580487132072449,
      "learning_rate": 9.694570673084535e-06,
      "loss": 0.0835,
      "step": 1929
    },
    {
      "epoch": 0.03055876624918853,
      "grad_norm": 0.19458815455436707,
      "learning_rate": 9.694412337508116e-06,
      "loss": 0.1976,
      "step": 1930
    },
    {
      "epoch": 0.030574599806830596,
      "grad_norm": 0.639995276927948,
      "learning_rate": 9.694254001931695e-06,
      "loss": 0.1076,
      "step": 1931
    },
    {
      "epoch": 0.030590433364472664,
      "grad_norm": 0.31292060017585754,
      "learning_rate": 9.694095666355274e-06,
      "loss": 0.1506,
      "step": 1932
    },
    {
      "epoch": 0.03060626692211473,
      "grad_norm": 0.3737933039665222,
      "learning_rate": 9.693937330778853e-06,
      "loss": 0.3307,
      "step": 1933
    },
    {
      "epoch": 0.030622100479756796,
      "grad_norm": 0.18381503224372864,
      "learning_rate": 9.693778995202434e-06,
      "loss": 0.1515,
      "step": 1934
    },
    {
      "epoch": 0.030637934037398864,
      "grad_norm": 0.14940300583839417,
      "learning_rate": 9.693620659626011e-06,
      "loss": 0.1034,
      "step": 1935
    },
    {
      "epoch": 0.030653767595040928,
      "grad_norm": 0.00524567486718297,
      "learning_rate": 9.693462324049592e-06,
      "loss": 0.0003,
      "step": 1936
    },
    {
      "epoch": 0.030669601152682996,
      "grad_norm": 0.18093657493591309,
      "learning_rate": 9.693303988473171e-06,
      "loss": 0.4142,
      "step": 1937
    },
    {
      "epoch": 0.030685434710325064,
      "grad_norm": 0.5718003511428833,
      "learning_rate": 9.69314565289675e-06,
      "loss": 0.2575,
      "step": 1938
    },
    {
      "epoch": 0.030701268267967128,
      "grad_norm": 0.013595428317785263,
      "learning_rate": 9.692987317320329e-06,
      "loss": 0.0008,
      "step": 1939
    },
    {
      "epoch": 0.030717101825609196,
      "grad_norm": 0.35775691270828247,
      "learning_rate": 9.69282898174391e-06,
      "loss": 0.5272,
      "step": 1940
    },
    {
      "epoch": 0.030732935383251263,
      "grad_norm": 0.3018918037414551,
      "learning_rate": 9.692670646167487e-06,
      "loss": 0.1151,
      "step": 1941
    },
    {
      "epoch": 0.030748768940893328,
      "grad_norm": 0.21571482717990875,
      "learning_rate": 9.692512310591068e-06,
      "loss": 0.337,
      "step": 1942
    },
    {
      "epoch": 0.030764602498535396,
      "grad_norm": 0.21505911648273468,
      "learning_rate": 9.692353975014647e-06,
      "loss": 0.1784,
      "step": 1943
    },
    {
      "epoch": 0.030780436056177463,
      "grad_norm": 0.5731784105300903,
      "learning_rate": 9.692195639438226e-06,
      "loss": 0.4397,
      "step": 1944
    },
    {
      "epoch": 0.030796269613819528,
      "grad_norm": 0.19093632698059082,
      "learning_rate": 9.692037303861805e-06,
      "loss": 0.1863,
      "step": 1945
    },
    {
      "epoch": 0.030812103171461595,
      "grad_norm": 0.19052118062973022,
      "learning_rate": 9.691878968285386e-06,
      "loss": 0.1137,
      "step": 1946
    },
    {
      "epoch": 0.030827936729103663,
      "grad_norm": 0.014717831276357174,
      "learning_rate": 9.691720632708963e-06,
      "loss": 0.0012,
      "step": 1947
    },
    {
      "epoch": 0.030843770286745727,
      "grad_norm": 0.16262076795101166,
      "learning_rate": 9.691562297132544e-06,
      "loss": 0.0872,
      "step": 1948
    },
    {
      "epoch": 0.030859603844387795,
      "grad_norm": 0.1619231253862381,
      "learning_rate": 9.691403961556123e-06,
      "loss": 0.0944,
      "step": 1949
    },
    {
      "epoch": 0.030875437402029863,
      "grad_norm": 0.0034595103934407234,
      "learning_rate": 9.691245625979702e-06,
      "loss": 0.0001,
      "step": 1950
    },
    {
      "epoch": 0.030891270959671927,
      "grad_norm": 0.18249720335006714,
      "learning_rate": 9.691087290403281e-06,
      "loss": 0.312,
      "step": 1951
    },
    {
      "epoch": 0.030907104517313995,
      "grad_norm": 0.1513909250497818,
      "learning_rate": 9.69092895482686e-06,
      "loss": 0.2391,
      "step": 1952
    },
    {
      "epoch": 0.030922938074956063,
      "grad_norm": 0.18987146019935608,
      "learning_rate": 9.69077061925044e-06,
      "loss": 0.1388,
      "step": 1953
    },
    {
      "epoch": 0.030938771632598127,
      "grad_norm": 0.00018876715330407023,
      "learning_rate": 9.690612283674019e-06,
      "loss": 0.0,
      "step": 1954
    },
    {
      "epoch": 0.030954605190240195,
      "grad_norm": 0.37268173694610596,
      "learning_rate": 9.6904539480976e-06,
      "loss": 0.1755,
      "step": 1955
    },
    {
      "epoch": 0.030970438747882263,
      "grad_norm": 0.15118053555488586,
      "learning_rate": 9.690295612521178e-06,
      "loss": 0.1871,
      "step": 1956
    },
    {
      "epoch": 0.030986272305524327,
      "grad_norm": 0.009452128782868385,
      "learning_rate": 9.690137276944758e-06,
      "loss": 0.0005,
      "step": 1957
    },
    {
      "epoch": 0.031002105863166395,
      "grad_norm": 0.007407063152641058,
      "learning_rate": 9.689978941368337e-06,
      "loss": 0.0004,
      "step": 1958
    },
    {
      "epoch": 0.031017939420808462,
      "grad_norm": 0.01996256597340107,
      "learning_rate": 9.689820605791916e-06,
      "loss": 0.0001,
      "step": 1959
    },
    {
      "epoch": 0.031033772978450527,
      "grad_norm": 0.23976513743400574,
      "learning_rate": 9.689662270215495e-06,
      "loss": 0.1274,
      "step": 1960
    },
    {
      "epoch": 0.031049606536092594,
      "grad_norm": 0.3124808669090271,
      "learning_rate": 9.689503934639076e-06,
      "loss": 0.3259,
      "step": 1961
    },
    {
      "epoch": 0.031065440093734662,
      "grad_norm": 0.15169766545295715,
      "learning_rate": 9.689345599062655e-06,
      "loss": 0.3017,
      "step": 1962
    },
    {
      "epoch": 0.031081273651376726,
      "grad_norm": 0.07580346614122391,
      "learning_rate": 9.689187263486234e-06,
      "loss": 0.0067,
      "step": 1963
    },
    {
      "epoch": 0.031097107209018794,
      "grad_norm": 0.4125097692012787,
      "learning_rate": 9.689028927909813e-06,
      "loss": 0.0888,
      "step": 1964
    },
    {
      "epoch": 0.031112940766660862,
      "grad_norm": 0.2578946650028229,
      "learning_rate": 9.688870592333392e-06,
      "loss": 0.0061,
      "step": 1965
    },
    {
      "epoch": 0.031128774324302926,
      "grad_norm": 0.19765233993530273,
      "learning_rate": 9.688712256756971e-06,
      "loss": 0.0618,
      "step": 1966
    },
    {
      "epoch": 0.031144607881944994,
      "grad_norm": 0.4278434216976166,
      "learning_rate": 9.688553921180552e-06,
      "loss": 0.1036,
      "step": 1967
    },
    {
      "epoch": 0.03116044143958706,
      "grad_norm": 0.19339661300182343,
      "learning_rate": 9.68839558560413e-06,
      "loss": 0.2139,
      "step": 1968
    },
    {
      "epoch": 0.031176274997229126,
      "grad_norm": 0.2512953281402588,
      "learning_rate": 9.68823725002771e-06,
      "loss": 0.1685,
      "step": 1969
    },
    {
      "epoch": 0.031192108554871194,
      "grad_norm": 0.1938313990831375,
      "learning_rate": 9.688078914451289e-06,
      "loss": 0.0884,
      "step": 1970
    },
    {
      "epoch": 0.03120794211251326,
      "grad_norm": 0.32991883158683777,
      "learning_rate": 9.687920578874868e-06,
      "loss": 0.5497,
      "step": 1971
    },
    {
      "epoch": 0.031223775670155326,
      "grad_norm": 0.0018933296669274569,
      "learning_rate": 9.687762243298447e-06,
      "loss": 0.0001,
      "step": 1972
    },
    {
      "epoch": 0.031239609227797394,
      "grad_norm": 0.00012564851203933358,
      "learning_rate": 9.687603907722026e-06,
      "loss": 0.0,
      "step": 1973
    },
    {
      "epoch": 0.03125544278543946,
      "grad_norm": 0.1919986605644226,
      "learning_rate": 9.687445572145607e-06,
      "loss": 0.229,
      "step": 1974
    },
    {
      "epoch": 0.03127127634308153,
      "grad_norm": 0.11902052909135818,
      "learning_rate": 9.687287236569184e-06,
      "loss": 0.0557,
      "step": 1975
    },
    {
      "epoch": 0.03128710990072359,
      "grad_norm": 0.3205230236053467,
      "learning_rate": 9.687128900992765e-06,
      "loss": 0.1939,
      "step": 1976
    },
    {
      "epoch": 0.03130294345836566,
      "grad_norm": 0.00037969183176755905,
      "learning_rate": 9.686970565416344e-06,
      "loss": 0.0,
      "step": 1977
    },
    {
      "epoch": 0.03131877701600773,
      "grad_norm": 0.012355748564004898,
      "learning_rate": 9.686812229839923e-06,
      "loss": 0.0007,
      "step": 1978
    },
    {
      "epoch": 0.03133461057364979,
      "grad_norm": 0.008255538530647755,
      "learning_rate": 9.686653894263502e-06,
      "loss": 0.0006,
      "step": 1979
    },
    {
      "epoch": 0.03135044413129186,
      "grad_norm": 0.017909327521920204,
      "learning_rate": 9.686495558687083e-06,
      "loss": 0.0006,
      "step": 1980
    },
    {
      "epoch": 0.03136627768893393,
      "grad_norm": 0.3000657260417938,
      "learning_rate": 9.68633722311066e-06,
      "loss": 0.7075,
      "step": 1981
    },
    {
      "epoch": 0.03138211124657599,
      "grad_norm": 0.44029122591018677,
      "learning_rate": 9.686178887534241e-06,
      "loss": 0.7174,
      "step": 1982
    },
    {
      "epoch": 0.03139794480421806,
      "grad_norm": 0.006772732362151146,
      "learning_rate": 9.68602055195782e-06,
      "loss": 0.0005,
      "step": 1983
    },
    {
      "epoch": 0.03141377836186013,
      "grad_norm": 0.02128923311829567,
      "learning_rate": 9.6858622163814e-06,
      "loss": 0.0015,
      "step": 1984
    },
    {
      "epoch": 0.03142961191950219,
      "grad_norm": 0.035649798810482025,
      "learning_rate": 9.685703880804979e-06,
      "loss": 0.0034,
      "step": 1985
    },
    {
      "epoch": 0.03144544547714426,
      "grad_norm": 0.14758865535259247,
      "learning_rate": 9.68554554522856e-06,
      "loss": 0.3082,
      "step": 1986
    },
    {
      "epoch": 0.03146127903478633,
      "grad_norm": 0.0026540029793977737,
      "learning_rate": 9.685387209652137e-06,
      "loss": 0.0001,
      "step": 1987
    },
    {
      "epoch": 0.03147711259242839,
      "grad_norm": 0.00043251211172901094,
      "learning_rate": 9.685228874075718e-06,
      "loss": 0.0,
      "step": 1988
    },
    {
      "epoch": 0.03149294615007046,
      "grad_norm": 0.006239705719053745,
      "learning_rate": 9.685070538499297e-06,
      "loss": 0.0004,
      "step": 1989
    },
    {
      "epoch": 0.03150877970771253,
      "grad_norm": 0.23846901953220367,
      "learning_rate": 9.684912202922876e-06,
      "loss": 0.2406,
      "step": 1990
    },
    {
      "epoch": 0.03152461326535459,
      "grad_norm": 0.02229161001741886,
      "learning_rate": 9.684753867346455e-06,
      "loss": 0.0013,
      "step": 1991
    },
    {
      "epoch": 0.03154044682299666,
      "grad_norm": 0.25386494398117065,
      "learning_rate": 9.684595531770034e-06,
      "loss": 0.2626,
      "step": 1992
    },
    {
      "epoch": 0.03155628038063873,
      "grad_norm": 0.2732141613960266,
      "learning_rate": 9.684437196193613e-06,
      "loss": 0.3375,
      "step": 1993
    },
    {
      "epoch": 0.03157211393828079,
      "grad_norm": 0.10494605451822281,
      "learning_rate": 9.684278860617194e-06,
      "loss": 0.0418,
      "step": 1994
    },
    {
      "epoch": 0.031587947495922857,
      "grad_norm": 0.22286970913410187,
      "learning_rate": 9.684120525040773e-06,
      "loss": 0.2331,
      "step": 1995
    },
    {
      "epoch": 0.03160378105356493,
      "grad_norm": 0.17606224119663239,
      "learning_rate": 9.683962189464352e-06,
      "loss": 0.0322,
      "step": 1996
    },
    {
      "epoch": 0.03161961461120699,
      "grad_norm": 0.4663783609867096,
      "learning_rate": 9.683803853887931e-06,
      "loss": 0.4684,
      "step": 1997
    },
    {
      "epoch": 0.031635448168849056,
      "grad_norm": 0.3044084310531616,
      "learning_rate": 9.68364551831151e-06,
      "loss": 0.1626,
      "step": 1998
    },
    {
      "epoch": 0.03165128172649113,
      "grad_norm": 0.14416292309761047,
      "learning_rate": 9.683487182735089e-06,
      "loss": 0.1248,
      "step": 1999
    },
    {
      "epoch": 0.03166711528413319,
      "grad_norm": 1.4886828660964966,
      "learning_rate": 9.683328847158668e-06,
      "loss": 0.066,
      "step": 2000
    },
    {
      "epoch": 0.031682948841775256,
      "grad_norm": 0.4000561833381653,
      "learning_rate": 9.683170511582249e-06,
      "loss": 0.1394,
      "step": 2001
    },
    {
      "epoch": 0.03169878239941733,
      "grad_norm": 0.005760205443948507,
      "learning_rate": 9.683012176005826e-06,
      "loss": 0.0004,
      "step": 2002
    },
    {
      "epoch": 0.03171461595705939,
      "grad_norm": 0.15310750901699066,
      "learning_rate": 9.682853840429407e-06,
      "loss": 0.0607,
      "step": 2003
    },
    {
      "epoch": 0.031730449514701456,
      "grad_norm": 0.0002403965627308935,
      "learning_rate": 9.682695504852986e-06,
      "loss": 0.0,
      "step": 2004
    },
    {
      "epoch": 0.03174628307234353,
      "grad_norm": 0.2719877362251282,
      "learning_rate": 9.682537169276565e-06,
      "loss": 0.2655,
      "step": 2005
    },
    {
      "epoch": 0.03176211662998559,
      "grad_norm": 0.14378459751605988,
      "learning_rate": 9.682378833700144e-06,
      "loss": 0.0321,
      "step": 2006
    },
    {
      "epoch": 0.031777950187627656,
      "grad_norm": 0.1483507603406906,
      "learning_rate": 9.682220498123725e-06,
      "loss": 0.0409,
      "step": 2007
    },
    {
      "epoch": 0.03179378374526973,
      "grad_norm": 0.012172005139291286,
      "learning_rate": 9.682062162547302e-06,
      "loss": 0.0009,
      "step": 2008
    },
    {
      "epoch": 0.03180961730291179,
      "grad_norm": 0.3712207078933716,
      "learning_rate": 9.681903826970883e-06,
      "loss": 0.1961,
      "step": 2009
    },
    {
      "epoch": 0.031825450860553856,
      "grad_norm": 0.25140616297721863,
      "learning_rate": 9.681745491394462e-06,
      "loss": 0.6151,
      "step": 2010
    },
    {
      "epoch": 0.03184128441819593,
      "grad_norm": 0.02170138619840145,
      "learning_rate": 9.681587155818041e-06,
      "loss": 0.0015,
      "step": 2011
    },
    {
      "epoch": 0.03185711797583799,
      "grad_norm": 0.5938337445259094,
      "learning_rate": 9.68142882024162e-06,
      "loss": 0.2281,
      "step": 2012
    },
    {
      "epoch": 0.031872951533480055,
      "grad_norm": 0.46404939889907837,
      "learning_rate": 9.681270484665201e-06,
      "loss": 0.4202,
      "step": 2013
    },
    {
      "epoch": 0.03188878509112213,
      "grad_norm": 0.013232942670583725,
      "learning_rate": 9.681112149088779e-06,
      "loss": 0.0008,
      "step": 2014
    },
    {
      "epoch": 0.03190461864876419,
      "grad_norm": 0.00011784306116169319,
      "learning_rate": 9.68095381351236e-06,
      "loss": 0.0,
      "step": 2015
    },
    {
      "epoch": 0.031920452206406255,
      "grad_norm": 0.17759430408477783,
      "learning_rate": 9.680795477935939e-06,
      "loss": 0.109,
      "step": 2016
    },
    {
      "epoch": 0.031936285764048326,
      "grad_norm": 0.1998685896396637,
      "learning_rate": 9.680637142359518e-06,
      "loss": 0.163,
      "step": 2017
    },
    {
      "epoch": 0.03195211932169039,
      "grad_norm": 0.004821801092475653,
      "learning_rate": 9.680478806783097e-06,
      "loss": 0.0002,
      "step": 2018
    },
    {
      "epoch": 0.031967952879332455,
      "grad_norm": 0.23503127694129944,
      "learning_rate": 9.680320471206677e-06,
      "loss": 0.2817,
      "step": 2019
    },
    {
      "epoch": 0.031983786436974526,
      "grad_norm": 0.0016730487113818526,
      "learning_rate": 9.680162135630255e-06,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 0.03199961999461659,
      "grad_norm": 0.014393207617104053,
      "learning_rate": 9.680003800053836e-06,
      "loss": 0.0002,
      "step": 2021
    },
    {
      "epoch": 0.032015453552258655,
      "grad_norm": 0.19439899921417236,
      "learning_rate": 9.679845464477415e-06,
      "loss": 0.1284,
      "step": 2022
    },
    {
      "epoch": 0.032031287109900726,
      "grad_norm": 0.14138473570346832,
      "learning_rate": 9.679687128900994e-06,
      "loss": 0.0711,
      "step": 2023
    },
    {
      "epoch": 0.03204712066754279,
      "grad_norm": 0.06057453900575638,
      "learning_rate": 9.679528793324573e-06,
      "loss": 0.0603,
      "step": 2024
    },
    {
      "epoch": 0.032062954225184855,
      "grad_norm": 0.3308837115764618,
      "learning_rate": 9.679370457748152e-06,
      "loss": 0.1667,
      "step": 2025
    },
    {
      "epoch": 0.032078787782826926,
      "grad_norm": 0.11067065596580505,
      "learning_rate": 9.679212122171731e-06,
      "loss": 0.0273,
      "step": 2026
    },
    {
      "epoch": 0.03209462134046899,
      "grad_norm": 0.41131964325904846,
      "learning_rate": 9.67905378659531e-06,
      "loss": 0.4641,
      "step": 2027
    },
    {
      "epoch": 0.032110454898111054,
      "grad_norm": 0.020413661375641823,
      "learning_rate": 9.678895451018891e-06,
      "loss": 0.002,
      "step": 2028
    },
    {
      "epoch": 0.032126288455753126,
      "grad_norm": 0.19940881431102753,
      "learning_rate": 9.67873711544247e-06,
      "loss": 0.1086,
      "step": 2029
    },
    {
      "epoch": 0.03214212201339519,
      "grad_norm": 0.2597472071647644,
      "learning_rate": 9.678578779866049e-06,
      "loss": 0.7026,
      "step": 2030
    },
    {
      "epoch": 0.032157955571037254,
      "grad_norm": 0.2200799435377121,
      "learning_rate": 9.678420444289628e-06,
      "loss": 0.0445,
      "step": 2031
    },
    {
      "epoch": 0.032173789128679325,
      "grad_norm": 0.3025928735733032,
      "learning_rate": 9.678262108713207e-06,
      "loss": 0.1251,
      "step": 2032
    },
    {
      "epoch": 0.03218962268632139,
      "grad_norm": 0.01117409486323595,
      "learning_rate": 9.678103773136786e-06,
      "loss": 0.001,
      "step": 2033
    },
    {
      "epoch": 0.032205456243963454,
      "grad_norm": 0.16396492719650269,
      "learning_rate": 9.677945437560367e-06,
      "loss": 0.1199,
      "step": 2034
    },
    {
      "epoch": 0.032221289801605525,
      "grad_norm": 0.6404245495796204,
      "learning_rate": 9.677787101983946e-06,
      "loss": 0.2584,
      "step": 2035
    },
    {
      "epoch": 0.03223712335924759,
      "grad_norm": 0.2728918194770813,
      "learning_rate": 9.677628766407525e-06,
      "loss": 0.1101,
      "step": 2036
    },
    {
      "epoch": 0.032252956916889654,
      "grad_norm": 0.20720095932483673,
      "learning_rate": 9.677470430831104e-06,
      "loss": 0.2764,
      "step": 2037
    },
    {
      "epoch": 0.032268790474531725,
      "grad_norm": 0.1166716068983078,
      "learning_rate": 9.677312095254683e-06,
      "loss": 0.0416,
      "step": 2038
    },
    {
      "epoch": 0.03228462403217379,
      "grad_norm": 0.14010129868984222,
      "learning_rate": 9.677153759678262e-06,
      "loss": 0.0563,
      "step": 2039
    },
    {
      "epoch": 0.032300457589815854,
      "grad_norm": 0.013091780245304108,
      "learning_rate": 9.676995424101843e-06,
      "loss": 0.0012,
      "step": 2040
    },
    {
      "epoch": 0.032316291147457925,
      "grad_norm": 0.004962557461112738,
      "learning_rate": 9.676837088525422e-06,
      "loss": 0.0004,
      "step": 2041
    },
    {
      "epoch": 0.03233212470509999,
      "grad_norm": 0.384764701128006,
      "learning_rate": 9.676678752949001e-06,
      "loss": 0.2217,
      "step": 2042
    },
    {
      "epoch": 0.03234795826274205,
      "grad_norm": 0.00023112859344109893,
      "learning_rate": 9.67652041737258e-06,
      "loss": 0.0,
      "step": 2043
    },
    {
      "epoch": 0.032363791820384125,
      "grad_norm": 0.20759446918964386,
      "learning_rate": 9.67636208179616e-06,
      "loss": 0.0763,
      "step": 2044
    },
    {
      "epoch": 0.03237962537802619,
      "grad_norm": 0.1655268371105194,
      "learning_rate": 9.676203746219739e-06,
      "loss": 0.0495,
      "step": 2045
    },
    {
      "epoch": 0.03239545893566825,
      "grad_norm": 0.3046110272407532,
      "learning_rate": 9.676045410643318e-06,
      "loss": 0.1049,
      "step": 2046
    },
    {
      "epoch": 0.032411292493310324,
      "grad_norm": 0.17047618329524994,
      "learning_rate": 9.675887075066898e-06,
      "loss": 0.1706,
      "step": 2047
    },
    {
      "epoch": 0.03242712605095239,
      "grad_norm": 0.22902275621891022,
      "learning_rate": 9.675728739490476e-06,
      "loss": 0.2094,
      "step": 2048
    },
    {
      "epoch": 0.03244295960859445,
      "grad_norm": 0.20395155251026154,
      "learning_rate": 9.675570403914057e-06,
      "loss": 0.0635,
      "step": 2049
    },
    {
      "epoch": 0.032458793166236524,
      "grad_norm": 0.24626654386520386,
      "learning_rate": 9.675412068337636e-06,
      "loss": 0.2286,
      "step": 2050
    },
    {
      "epoch": 0.03247462672387859,
      "grad_norm": 0.08439657837152481,
      "learning_rate": 9.675253732761215e-06,
      "loss": 0.0635,
      "step": 2051
    },
    {
      "epoch": 0.03249046028152065,
      "grad_norm": 0.1730087548494339,
      "learning_rate": 9.675095397184794e-06,
      "loss": 0.4537,
      "step": 2052
    },
    {
      "epoch": 0.032506293839162724,
      "grad_norm": 2.740614652633667,
      "learning_rate": 9.674937061608373e-06,
      "loss": 0.1576,
      "step": 2053
    },
    {
      "epoch": 0.03252212739680479,
      "grad_norm": 0.018109288066625595,
      "learning_rate": 9.674778726031952e-06,
      "loss": 0.0014,
      "step": 2054
    },
    {
      "epoch": 0.03253796095444685,
      "grad_norm": 0.2105119675397873,
      "learning_rate": 9.674620390455533e-06,
      "loss": 0.1295,
      "step": 2055
    },
    {
      "epoch": 0.032553794512088924,
      "grad_norm": 0.14878450334072113,
      "learning_rate": 9.674462054879112e-06,
      "loss": 0.0253,
      "step": 2056
    },
    {
      "epoch": 0.03256962806973099,
      "grad_norm": 0.011661477386951447,
      "learning_rate": 9.674303719302691e-06,
      "loss": 0.0009,
      "step": 2057
    },
    {
      "epoch": 0.03258546162737305,
      "grad_norm": 0.33686384558677673,
      "learning_rate": 9.67414538372627e-06,
      "loss": 0.066,
      "step": 2058
    },
    {
      "epoch": 0.032601295185015124,
      "grad_norm": 0.12405002117156982,
      "learning_rate": 9.673987048149849e-06,
      "loss": 0.0897,
      "step": 2059
    },
    {
      "epoch": 0.03261712874265719,
      "grad_norm": 0.11429840326309204,
      "learning_rate": 9.673828712573428e-06,
      "loss": 0.1272,
      "step": 2060
    },
    {
      "epoch": 0.03263296230029925,
      "grad_norm": 0.14246731996536255,
      "learning_rate": 9.673670376997009e-06,
      "loss": 0.0869,
      "step": 2061
    },
    {
      "epoch": 0.03264879585794132,
      "grad_norm": 0.08477145433425903,
      "learning_rate": 9.673512041420588e-06,
      "loss": 0.0534,
      "step": 2062
    },
    {
      "epoch": 0.03266462941558339,
      "grad_norm": 0.3187282085418701,
      "learning_rate": 9.673353705844167e-06,
      "loss": 0.5207,
      "step": 2063
    },
    {
      "epoch": 0.03268046297322545,
      "grad_norm": 0.06848010420799255,
      "learning_rate": 9.673195370267746e-06,
      "loss": 0.0054,
      "step": 2064
    },
    {
      "epoch": 0.03269629653086752,
      "grad_norm": 0.24459248781204224,
      "learning_rate": 9.673037034691325e-06,
      "loss": 0.0282,
      "step": 2065
    },
    {
      "epoch": 0.03271213008850959,
      "grad_norm": 0.0203145332634449,
      "learning_rate": 9.672878699114904e-06,
      "loss": 0.0017,
      "step": 2066
    },
    {
      "epoch": 0.03272796364615165,
      "grad_norm": 0.23086097836494446,
      "learning_rate": 9.672720363538485e-06,
      "loss": 0.1494,
      "step": 2067
    },
    {
      "epoch": 0.03274379720379372,
      "grad_norm": 0.003103673690930009,
      "learning_rate": 9.672562027962064e-06,
      "loss": 0.0002,
      "step": 2068
    },
    {
      "epoch": 0.03275963076143579,
      "grad_norm": 0.1319248080253601,
      "learning_rate": 9.672403692385643e-06,
      "loss": 0.0732,
      "step": 2069
    },
    {
      "epoch": 0.03277546431907785,
      "grad_norm": 0.13518981635570526,
      "learning_rate": 9.672245356809222e-06,
      "loss": 0.0417,
      "step": 2070
    },
    {
      "epoch": 0.03279129787671992,
      "grad_norm": 0.26994645595550537,
      "learning_rate": 9.672087021232801e-06,
      "loss": 0.0522,
      "step": 2071
    },
    {
      "epoch": 0.03280713143436199,
      "grad_norm": 0.18438035249710083,
      "learning_rate": 9.67192868565638e-06,
      "loss": 0.0869,
      "step": 2072
    },
    {
      "epoch": 0.03282296499200405,
      "grad_norm": 0.12442560493946075,
      "learning_rate": 9.67177035007996e-06,
      "loss": 0.0418,
      "step": 2073
    },
    {
      "epoch": 0.03283879854964612,
      "grad_norm": 0.17571663856506348,
      "learning_rate": 9.67161201450354e-06,
      "loss": 0.0637,
      "step": 2074
    },
    {
      "epoch": 0.03285463210728819,
      "grad_norm": 0.14903363585472107,
      "learning_rate": 9.671453678927118e-06,
      "loss": 0.0372,
      "step": 2075
    },
    {
      "epoch": 0.03287046566493025,
      "grad_norm": 0.00017476372886449099,
      "learning_rate": 9.671295343350699e-06,
      "loss": 0.0,
      "step": 2076
    },
    {
      "epoch": 0.03288629922257232,
      "grad_norm": 0.14050240814685822,
      "learning_rate": 9.671137007774278e-06,
      "loss": 0.0763,
      "step": 2077
    },
    {
      "epoch": 0.03290213278021439,
      "grad_norm": 0.14354489743709564,
      "learning_rate": 9.670978672197857e-06,
      "loss": 0.3168,
      "step": 2078
    },
    {
      "epoch": 0.03291796633785645,
      "grad_norm": 0.37143808603286743,
      "learning_rate": 9.670820336621436e-06,
      "loss": 0.15,
      "step": 2079
    },
    {
      "epoch": 0.03293379989549852,
      "grad_norm": 0.006989198736846447,
      "learning_rate": 9.670662001045017e-06,
      "loss": 0.0004,
      "step": 2080
    },
    {
      "epoch": 0.03294963345314059,
      "grad_norm": 0.009917644783854485,
      "learning_rate": 9.670503665468594e-06,
      "loss": 0.0006,
      "step": 2081
    },
    {
      "epoch": 0.03296546701078265,
      "grad_norm": 0.000981319579295814,
      "learning_rate": 9.670345329892175e-06,
      "loss": 0.0,
      "step": 2082
    },
    {
      "epoch": 0.03298130056842472,
      "grad_norm": 0.000287287519313395,
      "learning_rate": 9.670186994315754e-06,
      "loss": 0.0,
      "step": 2083
    },
    {
      "epoch": 0.032997134126066786,
      "grad_norm": 0.2433471977710724,
      "learning_rate": 9.670028658739333e-06,
      "loss": 0.4408,
      "step": 2084
    },
    {
      "epoch": 0.03301296768370885,
      "grad_norm": 0.44445937871932983,
      "learning_rate": 9.669870323162912e-06,
      "loss": 0.0516,
      "step": 2085
    },
    {
      "epoch": 0.03302880124135092,
      "grad_norm": 1.7324674129486084,
      "learning_rate": 9.669711987586493e-06,
      "loss": 0.0691,
      "step": 2086
    },
    {
      "epoch": 0.033044634798992986,
      "grad_norm": 0.6625894904136658,
      "learning_rate": 9.66955365201007e-06,
      "loss": 0.3316,
      "step": 2087
    },
    {
      "epoch": 0.03306046835663505,
      "grad_norm": 0.40457749366760254,
      "learning_rate": 9.669395316433651e-06,
      "loss": 0.3675,
      "step": 2088
    },
    {
      "epoch": 0.03307630191427712,
      "grad_norm": 0.17996318638324738,
      "learning_rate": 9.66923698085723e-06,
      "loss": 0.0784,
      "step": 2089
    },
    {
      "epoch": 0.033092135471919186,
      "grad_norm": 0.40664878487586975,
      "learning_rate": 9.669078645280809e-06,
      "loss": 0.1133,
      "step": 2090
    },
    {
      "epoch": 0.03310796902956125,
      "grad_norm": 0.14557644724845886,
      "learning_rate": 9.668920309704388e-06,
      "loss": 0.1095,
      "step": 2091
    },
    {
      "epoch": 0.03312380258720332,
      "grad_norm": 0.011412744410336018,
      "learning_rate": 9.668761974127969e-06,
      "loss": 0.0003,
      "step": 2092
    },
    {
      "epoch": 0.033139636144845386,
      "grad_norm": 0.13237109780311584,
      "learning_rate": 9.668603638551546e-06,
      "loss": 0.0811,
      "step": 2093
    },
    {
      "epoch": 0.03315546970248745,
      "grad_norm": 0.0073761469684541225,
      "learning_rate": 9.668445302975125e-06,
      "loss": 0.0004,
      "step": 2094
    },
    {
      "epoch": 0.03317130326012952,
      "grad_norm": 0.3744485378265381,
      "learning_rate": 9.668286967398706e-06,
      "loss": 0.24,
      "step": 2095
    },
    {
      "epoch": 0.033187136817771586,
      "grad_norm": 0.18215355277061462,
      "learning_rate": 9.668128631822285e-06,
      "loss": 0.0533,
      "step": 2096
    },
    {
      "epoch": 0.03320297037541365,
      "grad_norm": 0.25800949335098267,
      "learning_rate": 9.667970296245864e-06,
      "loss": 0.0974,
      "step": 2097
    },
    {
      "epoch": 0.03321880393305572,
      "grad_norm": 0.27793580293655396,
      "learning_rate": 9.667811960669443e-06,
      "loss": 0.1013,
      "step": 2098
    },
    {
      "epoch": 0.033234637490697785,
      "grad_norm": 0.0017412990564480424,
      "learning_rate": 9.667653625093022e-06,
      "loss": 0.0001,
      "step": 2099
    },
    {
      "epoch": 0.03325047104833985,
      "grad_norm": 0.1664513349533081,
      "learning_rate": 9.667495289516602e-06,
      "loss": 0.1497,
      "step": 2100
    },
    {
      "epoch": 0.03326630460598192,
      "grad_norm": 0.9049971103668213,
      "learning_rate": 9.667336953940182e-06,
      "loss": 0.9841,
      "step": 2101
    },
    {
      "epoch": 0.033282138163623985,
      "grad_norm": 9.398103429703042e-05,
      "learning_rate": 9.667178618363761e-06,
      "loss": 0.0,
      "step": 2102
    },
    {
      "epoch": 0.03329797172126605,
      "grad_norm": 0.20133373141288757,
      "learning_rate": 9.66702028278734e-06,
      "loss": 0.0975,
      "step": 2103
    },
    {
      "epoch": 0.03331380527890812,
      "grad_norm": 0.42100000381469727,
      "learning_rate": 9.66686194721092e-06,
      "loss": 0.1436,
      "step": 2104
    },
    {
      "epoch": 0.033329638836550185,
      "grad_norm": 0.019253183156251907,
      "learning_rate": 9.666703611634499e-06,
      "loss": 0.0012,
      "step": 2105
    },
    {
      "epoch": 0.03334547239419225,
      "grad_norm": 0.00016724254237487912,
      "learning_rate": 9.666545276058078e-06,
      "loss": 0.0,
      "step": 2106
    },
    {
      "epoch": 0.03336130595183432,
      "grad_norm": 0.17096585035324097,
      "learning_rate": 9.666386940481658e-06,
      "loss": 0.0896,
      "step": 2107
    },
    {
      "epoch": 0.033377139509476385,
      "grad_norm": 0.17430251836776733,
      "learning_rate": 9.666228604905238e-06,
      "loss": 0.2863,
      "step": 2108
    },
    {
      "epoch": 0.03339297306711845,
      "grad_norm": 0.21349550783634186,
      "learning_rate": 9.666070269328817e-06,
      "loss": 0.0387,
      "step": 2109
    },
    {
      "epoch": 0.03340880662476052,
      "grad_norm": 0.2514702379703522,
      "learning_rate": 9.665911933752396e-06,
      "loss": 0.083,
      "step": 2110
    },
    {
      "epoch": 0.033424640182402585,
      "grad_norm": 0.5950531363487244,
      "learning_rate": 9.665753598175975e-06,
      "loss": 0.6839,
      "step": 2111
    },
    {
      "epoch": 0.03344047374004465,
      "grad_norm": 0.1497335433959961,
      "learning_rate": 9.665595262599554e-06,
      "loss": 0.1217,
      "step": 2112
    },
    {
      "epoch": 0.03345630729768672,
      "grad_norm": 0.15007220208644867,
      "learning_rate": 9.665436927023135e-06,
      "loss": 0.1189,
      "step": 2113
    },
    {
      "epoch": 0.033472140855328784,
      "grad_norm": 0.22950546443462372,
      "learning_rate": 9.665278591446714e-06,
      "loss": 0.1548,
      "step": 2114
    },
    {
      "epoch": 0.03348797441297085,
      "grad_norm": 0.2778874635696411,
      "learning_rate": 9.665120255870293e-06,
      "loss": 0.1647,
      "step": 2115
    },
    {
      "epoch": 0.03350380797061292,
      "grad_norm": 0.31734123826026917,
      "learning_rate": 9.664961920293872e-06,
      "loss": 0.6214,
      "step": 2116
    },
    {
      "epoch": 0.033519641528254984,
      "grad_norm": 0.2311195284128189,
      "learning_rate": 9.664803584717451e-06,
      "loss": 0.1341,
      "step": 2117
    },
    {
      "epoch": 0.03353547508589705,
      "grad_norm": 0.10243549942970276,
      "learning_rate": 9.66464524914103e-06,
      "loss": 0.0837,
      "step": 2118
    },
    {
      "epoch": 0.03355130864353912,
      "grad_norm": 0.006332019809633493,
      "learning_rate": 9.664486913564609e-06,
      "loss": 0.0003,
      "step": 2119
    },
    {
      "epoch": 0.033567142201181184,
      "grad_norm": 0.18471118807792664,
      "learning_rate": 9.664328577988188e-06,
      "loss": 0.1791,
      "step": 2120
    },
    {
      "epoch": 0.03358297575882325,
      "grad_norm": 0.34212055802345276,
      "learning_rate": 9.664170242411767e-06,
      "loss": 0.5927,
      "step": 2121
    },
    {
      "epoch": 0.03359880931646532,
      "grad_norm": 0.228125661611557,
      "learning_rate": 9.664011906835348e-06,
      "loss": 0.0616,
      "step": 2122
    },
    {
      "epoch": 0.033614642874107384,
      "grad_norm": 0.02461891993880272,
      "learning_rate": 9.663853571258927e-06,
      "loss": 0.0016,
      "step": 2123
    },
    {
      "epoch": 0.03363047643174945,
      "grad_norm": 0.3071076571941376,
      "learning_rate": 9.663695235682506e-06,
      "loss": 0.6393,
      "step": 2124
    },
    {
      "epoch": 0.03364630998939152,
      "grad_norm": 0.274188369512558,
      "learning_rate": 9.663536900106085e-06,
      "loss": 0.1298,
      "step": 2125
    },
    {
      "epoch": 0.033662143547033584,
      "grad_norm": 0.23923420906066895,
      "learning_rate": 9.663378564529664e-06,
      "loss": 0.3102,
      "step": 2126
    },
    {
      "epoch": 0.03367797710467565,
      "grad_norm": 0.13099616765975952,
      "learning_rate": 9.663220228953243e-06,
      "loss": 0.003,
      "step": 2127
    },
    {
      "epoch": 0.03369381066231772,
      "grad_norm": 0.19126665592193604,
      "learning_rate": 9.663061893376824e-06,
      "loss": 0.1617,
      "step": 2128
    },
    {
      "epoch": 0.03370964421995978,
      "grad_norm": 0.24501492083072662,
      "learning_rate": 9.662903557800403e-06,
      "loss": 0.1692,
      "step": 2129
    },
    {
      "epoch": 0.03372547777760185,
      "grad_norm": 0.0798797532916069,
      "learning_rate": 9.662745222223982e-06,
      "loss": 0.0122,
      "step": 2130
    },
    {
      "epoch": 0.03374131133524392,
      "grad_norm": 7.52436972106807e-05,
      "learning_rate": 9.662586886647561e-06,
      "loss": 0.0,
      "step": 2131
    },
    {
      "epoch": 0.03375714489288598,
      "grad_norm": 0.2331257313489914,
      "learning_rate": 9.66242855107114e-06,
      "loss": 0.159,
      "step": 2132
    },
    {
      "epoch": 0.03377297845052805,
      "grad_norm": 0.013619376346468925,
      "learning_rate": 9.66227021549472e-06,
      "loss": 0.0007,
      "step": 2133
    },
    {
      "epoch": 0.03378881200817012,
      "grad_norm": 0.29710352420806885,
      "learning_rate": 9.6621118799183e-06,
      "loss": 0.1097,
      "step": 2134
    },
    {
      "epoch": 0.03380464556581218,
      "grad_norm": 0.20276162028312683,
      "learning_rate": 9.66195354434188e-06,
      "loss": 0.0329,
      "step": 2135
    },
    {
      "epoch": 0.03382047912345425,
      "grad_norm": 0.1501714438199997,
      "learning_rate": 9.661795208765459e-06,
      "loss": 0.0526,
      "step": 2136
    },
    {
      "epoch": 0.03383631268109632,
      "grad_norm": 1.8878066839533858e-05,
      "learning_rate": 9.661636873189038e-06,
      "loss": 0.0,
      "step": 2137
    },
    {
      "epoch": 0.03385214623873838,
      "grad_norm": 0.18440423905849457,
      "learning_rate": 9.661478537612617e-06,
      "loss": 0.0672,
      "step": 2138
    },
    {
      "epoch": 0.03386797979638045,
      "grad_norm": 1.1874607801437378,
      "learning_rate": 9.661320202036196e-06,
      "loss": 0.2476,
      "step": 2139
    },
    {
      "epoch": 0.03388381335402252,
      "grad_norm": 0.24751845002174377,
      "learning_rate": 9.661161866459777e-06,
      "loss": 0.1335,
      "step": 2140
    },
    {
      "epoch": 0.03389964691166458,
      "grad_norm": 0.4777428209781647,
      "learning_rate": 9.661003530883356e-06,
      "loss": 0.1239,
      "step": 2141
    },
    {
      "epoch": 0.03391548046930665,
      "grad_norm": 0.17438678443431854,
      "learning_rate": 9.660845195306933e-06,
      "loss": 0.0814,
      "step": 2142
    },
    {
      "epoch": 0.03393131402694872,
      "grad_norm": 0.017587484791874886,
      "learning_rate": 9.660686859730514e-06,
      "loss": 0.0003,
      "step": 2143
    },
    {
      "epoch": 0.03394714758459078,
      "grad_norm": 0.13224910199642181,
      "learning_rate": 9.660528524154093e-06,
      "loss": 0.0191,
      "step": 2144
    },
    {
      "epoch": 0.03396298114223285,
      "grad_norm": 0.6968604326248169,
      "learning_rate": 9.660370188577672e-06,
      "loss": 0.8235,
      "step": 2145
    },
    {
      "epoch": 0.03397881469987492,
      "grad_norm": 0.33090320229530334,
      "learning_rate": 9.660211853001251e-06,
      "loss": 0.8817,
      "step": 2146
    },
    {
      "epoch": 0.03399464825751698,
      "grad_norm": 0.4840832054615021,
      "learning_rate": 9.660053517424832e-06,
      "loss": 0.8849,
      "step": 2147
    },
    {
      "epoch": 0.03401048181515905,
      "grad_norm": 0.3098939061164856,
      "learning_rate": 9.65989518184841e-06,
      "loss": 0.3443,
      "step": 2148
    },
    {
      "epoch": 0.03402631537280112,
      "grad_norm": 0.01418212428689003,
      "learning_rate": 9.65973684627199e-06,
      "loss": 0.0008,
      "step": 2149
    },
    {
      "epoch": 0.03404214893044318,
      "grad_norm": 0.6017822027206421,
      "learning_rate": 9.659578510695569e-06,
      "loss": 0.3026,
      "step": 2150
    },
    {
      "epoch": 0.034057982488085246,
      "grad_norm": 0.28512251377105713,
      "learning_rate": 9.659420175119148e-06,
      "loss": 0.1262,
      "step": 2151
    },
    {
      "epoch": 0.03407381604572732,
      "grad_norm": 0.23068416118621826,
      "learning_rate": 9.659261839542727e-06,
      "loss": 0.0749,
      "step": 2152
    },
    {
      "epoch": 0.03408964960336938,
      "grad_norm": 0.5050410032272339,
      "learning_rate": 9.659103503966308e-06,
      "loss": 0.3235,
      "step": 2153
    },
    {
      "epoch": 0.034105483161011446,
      "grad_norm": 0.33644476532936096,
      "learning_rate": 9.658945168389885e-06,
      "loss": 0.0514,
      "step": 2154
    },
    {
      "epoch": 0.03412131671865352,
      "grad_norm": 0.5148358941078186,
      "learning_rate": 9.658786832813466e-06,
      "loss": 0.3209,
      "step": 2155
    },
    {
      "epoch": 0.03413715027629558,
      "grad_norm": 0.012389694340527058,
      "learning_rate": 9.658628497237045e-06,
      "loss": 0.0007,
      "step": 2156
    },
    {
      "epoch": 0.034152983833937646,
      "grad_norm": 0.15053333342075348,
      "learning_rate": 9.658470161660624e-06,
      "loss": 0.2385,
      "step": 2157
    },
    {
      "epoch": 0.03416881739157972,
      "grad_norm": 0.19707348942756653,
      "learning_rate": 9.658311826084203e-06,
      "loss": 0.1542,
      "step": 2158
    },
    {
      "epoch": 0.03418465094922178,
      "grad_norm": 0.36746978759765625,
      "learning_rate": 9.658153490507784e-06,
      "loss": 0.0427,
      "step": 2159
    },
    {
      "epoch": 0.034200484506863846,
      "grad_norm": 0.3191019296646118,
      "learning_rate": 9.657995154931362e-06,
      "loss": 0.4827,
      "step": 2160
    },
    {
      "epoch": 0.03421631806450592,
      "grad_norm": 0.2191353738307953,
      "learning_rate": 9.657836819354942e-06,
      "loss": 0.0623,
      "step": 2161
    },
    {
      "epoch": 0.03423215162214798,
      "grad_norm": 0.18761666119098663,
      "learning_rate": 9.657678483778521e-06,
      "loss": 0.0655,
      "step": 2162
    },
    {
      "epoch": 0.034247985179790046,
      "grad_norm": 0.3940878212451935,
      "learning_rate": 9.6575201482021e-06,
      "loss": 0.2134,
      "step": 2163
    },
    {
      "epoch": 0.03426381873743212,
      "grad_norm": 0.329495370388031,
      "learning_rate": 9.65736181262568e-06,
      "loss": 0.265,
      "step": 2164
    },
    {
      "epoch": 0.03427965229507418,
      "grad_norm": 0.21555747091770172,
      "learning_rate": 9.65720347704926e-06,
      "loss": 0.0491,
      "step": 2165
    },
    {
      "epoch": 0.034295485852716245,
      "grad_norm": 0.16673342883586884,
      "learning_rate": 9.657045141472838e-06,
      "loss": 0.0633,
      "step": 2166
    },
    {
      "epoch": 0.03431131941035832,
      "grad_norm": 0.027389591559767723,
      "learning_rate": 9.656886805896417e-06,
      "loss": 0.0021,
      "step": 2167
    },
    {
      "epoch": 0.03432715296800038,
      "grad_norm": 0.015699544921517372,
      "learning_rate": 9.656728470319998e-06,
      "loss": 0.0012,
      "step": 2168
    },
    {
      "epoch": 0.034342986525642445,
      "grad_norm": 0.3216994106769562,
      "learning_rate": 9.656570134743577e-06,
      "loss": 0.151,
      "step": 2169
    },
    {
      "epoch": 0.034358820083284516,
      "grad_norm": 0.3131158947944641,
      "learning_rate": 9.656411799167156e-06,
      "loss": 0.1719,
      "step": 2170
    },
    {
      "epoch": 0.03437465364092658,
      "grad_norm": 0.012527799233794212,
      "learning_rate": 9.656253463590735e-06,
      "loss": 0.0008,
      "step": 2171
    },
    {
      "epoch": 0.034390487198568645,
      "grad_norm": 0.2533019483089447,
      "learning_rate": 9.656095128014314e-06,
      "loss": 0.1759,
      "step": 2172
    },
    {
      "epoch": 0.034406320756210716,
      "grad_norm": 0.2332921177148819,
      "learning_rate": 9.655936792437893e-06,
      "loss": 0.0754,
      "step": 2173
    },
    {
      "epoch": 0.03442215431385278,
      "grad_norm": 0.1787082850933075,
      "learning_rate": 9.655778456861474e-06,
      "loss": 0.137,
      "step": 2174
    },
    {
      "epoch": 0.034437987871494845,
      "grad_norm": 0.13913357257843018,
      "learning_rate": 9.655620121285053e-06,
      "loss": 0.2155,
      "step": 2175
    },
    {
      "epoch": 0.034453821429136916,
      "grad_norm": 0.005569706205278635,
      "learning_rate": 9.655461785708632e-06,
      "loss": 0.0003,
      "step": 2176
    },
    {
      "epoch": 0.03446965498677898,
      "grad_norm": 0.28633275628089905,
      "learning_rate": 9.655303450132211e-06,
      "loss": 0.5814,
      "step": 2177
    },
    {
      "epoch": 0.034485488544421045,
      "grad_norm": 0.009467987343668938,
      "learning_rate": 9.65514511455579e-06,
      "loss": 0.0006,
      "step": 2178
    },
    {
      "epoch": 0.034501322102063116,
      "grad_norm": 0.19236548244953156,
      "learning_rate": 9.654986778979369e-06,
      "loss": 0.0668,
      "step": 2179
    },
    {
      "epoch": 0.03451715565970518,
      "grad_norm": 0.16720643639564514,
      "learning_rate": 9.65482844340295e-06,
      "loss": 0.0841,
      "step": 2180
    },
    {
      "epoch": 0.034532989217347244,
      "grad_norm": 0.0037829980719834566,
      "learning_rate": 9.654670107826527e-06,
      "loss": 0.0001,
      "step": 2181
    },
    {
      "epoch": 0.034548822774989316,
      "grad_norm": 0.3914591372013092,
      "learning_rate": 9.654511772250108e-06,
      "loss": 0.1293,
      "step": 2182
    },
    {
      "epoch": 0.03456465633263138,
      "grad_norm": 0.29865187406539917,
      "learning_rate": 9.654353436673687e-06,
      "loss": 0.1058,
      "step": 2183
    },
    {
      "epoch": 0.034580489890273444,
      "grad_norm": 0.0001851027918746695,
      "learning_rate": 9.654195101097266e-06,
      "loss": 0.0,
      "step": 2184
    },
    {
      "epoch": 0.034596323447915515,
      "grad_norm": 0.09117244929075241,
      "learning_rate": 9.654036765520845e-06,
      "loss": 0.0437,
      "step": 2185
    },
    {
      "epoch": 0.03461215700555758,
      "grad_norm": 0.3571338951587677,
      "learning_rate": 9.653878429944426e-06,
      "loss": 0.285,
      "step": 2186
    },
    {
      "epoch": 0.034627990563199644,
      "grad_norm": 0.25765594840049744,
      "learning_rate": 9.653720094368003e-06,
      "loss": 0.118,
      "step": 2187
    },
    {
      "epoch": 0.034643824120841715,
      "grad_norm": 0.17753514647483826,
      "learning_rate": 9.653561758791584e-06,
      "loss": 0.115,
      "step": 2188
    },
    {
      "epoch": 0.03465965767848378,
      "grad_norm": 0.001499860198237002,
      "learning_rate": 9.653403423215163e-06,
      "loss": 0.0,
      "step": 2189
    },
    {
      "epoch": 0.034675491236125844,
      "grad_norm": 0.5826377272605896,
      "learning_rate": 9.653245087638742e-06,
      "loss": 0.2024,
      "step": 2190
    },
    {
      "epoch": 0.034691324793767915,
      "grad_norm": 0.2624950706958771,
      "learning_rate": 9.653086752062321e-06,
      "loss": 0.0848,
      "step": 2191
    },
    {
      "epoch": 0.03470715835140998,
      "grad_norm": 0.21188335120677948,
      "learning_rate": 9.6529284164859e-06,
      "loss": 0.1402,
      "step": 2192
    },
    {
      "epoch": 0.034722991909052044,
      "grad_norm": 0.16023065149784088,
      "learning_rate": 9.65277008090948e-06,
      "loss": 0.059,
      "step": 2193
    },
    {
      "epoch": 0.034738825466694115,
      "grad_norm": 0.10419537127017975,
      "learning_rate": 9.652611745333059e-06,
      "loss": 0.0814,
      "step": 2194
    },
    {
      "epoch": 0.03475465902433618,
      "grad_norm": 0.13548745214939117,
      "learning_rate": 9.65245340975664e-06,
      "loss": 0.0635,
      "step": 2195
    },
    {
      "epoch": 0.03477049258197824,
      "grad_norm": 0.352615088224411,
      "learning_rate": 9.652295074180219e-06,
      "loss": 0.1343,
      "step": 2196
    },
    {
      "epoch": 0.034786326139620315,
      "grad_norm": 0.4252481758594513,
      "learning_rate": 9.652136738603798e-06,
      "loss": 0.0307,
      "step": 2197
    },
    {
      "epoch": 0.03480215969726238,
      "grad_norm": 0.0026529072783887386,
      "learning_rate": 9.651978403027377e-06,
      "loss": 0.0,
      "step": 2198
    },
    {
      "epoch": 0.03481799325490444,
      "grad_norm": 0.006505422294139862,
      "learning_rate": 9.651820067450956e-06,
      "loss": 0.0003,
      "step": 2199
    },
    {
      "epoch": 0.034833826812546514,
      "grad_norm": 0.27451178431510925,
      "learning_rate": 9.651661731874535e-06,
      "loss": 0.1361,
      "step": 2200
    },
    {
      "epoch": 0.03484966037018858,
      "grad_norm": 0.10754604637622833,
      "learning_rate": 9.651503396298116e-06,
      "loss": 0.1658,
      "step": 2201
    },
    {
      "epoch": 0.03486549392783064,
      "grad_norm": 0.00011441967217251658,
      "learning_rate": 9.651345060721695e-06,
      "loss": 0.0,
      "step": 2202
    },
    {
      "epoch": 0.034881327485472714,
      "grad_norm": 0.4376071095466614,
      "learning_rate": 9.651186725145274e-06,
      "loss": 0.1111,
      "step": 2203
    },
    {
      "epoch": 0.03489716104311478,
      "grad_norm": 0.2621849775314331,
      "learning_rate": 9.651028389568853e-06,
      "loss": 0.2527,
      "step": 2204
    },
    {
      "epoch": 0.03491299460075684,
      "grad_norm": 0.06444969028234482,
      "learning_rate": 9.650870053992432e-06,
      "loss": 0.0062,
      "step": 2205
    },
    {
      "epoch": 0.034928828158398914,
      "grad_norm": 0.16647066175937653,
      "learning_rate": 9.650711718416011e-06,
      "loss": 0.2209,
      "step": 2206
    },
    {
      "epoch": 0.03494466171604098,
      "grad_norm": 0.2023501992225647,
      "learning_rate": 9.650553382839592e-06,
      "loss": 0.0425,
      "step": 2207
    },
    {
      "epoch": 0.03496049527368304,
      "grad_norm": 0.15597933530807495,
      "learning_rate": 9.650395047263171e-06,
      "loss": 0.1313,
      "step": 2208
    },
    {
      "epoch": 0.034976328831325114,
      "grad_norm": 0.17480003833770752,
      "learning_rate": 9.65023671168675e-06,
      "loss": 0.5545,
      "step": 2209
    },
    {
      "epoch": 0.03499216238896718,
      "grad_norm": 0.0104835145175457,
      "learning_rate": 9.650078376110329e-06,
      "loss": 0.0004,
      "step": 2210
    },
    {
      "epoch": 0.03500799594660924,
      "grad_norm": 9.069534280570224e-05,
      "learning_rate": 9.649920040533908e-06,
      "loss": 0.0,
      "step": 2211
    },
    {
      "epoch": 0.035023829504251314,
      "grad_norm": 0.2753390967845917,
      "learning_rate": 9.649761704957487e-06,
      "loss": 0.2495,
      "step": 2212
    },
    {
      "epoch": 0.03503966306189338,
      "grad_norm": 0.07644589245319366,
      "learning_rate": 9.649603369381068e-06,
      "loss": 0.0101,
      "step": 2213
    },
    {
      "epoch": 0.03505549661953544,
      "grad_norm": 0.23350180685520172,
      "learning_rate": 9.649445033804647e-06,
      "loss": 0.1244,
      "step": 2214
    },
    {
      "epoch": 0.03507133017717751,
      "grad_norm": 0.2091517448425293,
      "learning_rate": 9.649286698228224e-06,
      "loss": 0.2914,
      "step": 2215
    },
    {
      "epoch": 0.03508716373481958,
      "grad_norm": 0.0017411586595699191,
      "learning_rate": 9.649128362651805e-06,
      "loss": 0.0,
      "step": 2216
    },
    {
      "epoch": 0.03510299729246164,
      "grad_norm": 0.20330336689949036,
      "learning_rate": 9.648970027075384e-06,
      "loss": 0.2072,
      "step": 2217
    },
    {
      "epoch": 0.035118830850103706,
      "grad_norm": 0.0077331773936748505,
      "learning_rate": 9.648811691498963e-06,
      "loss": 0.0003,
      "step": 2218
    },
    {
      "epoch": 0.03513466440774578,
      "grad_norm": 0.16486497223377228,
      "learning_rate": 9.648653355922542e-06,
      "loss": 0.1403,
      "step": 2219
    },
    {
      "epoch": 0.03515049796538784,
      "grad_norm": 0.21216300129890442,
      "learning_rate": 9.648495020346123e-06,
      "loss": 0.0318,
      "step": 2220
    },
    {
      "epoch": 0.035166331523029906,
      "grad_norm": 0.040101271122694016,
      "learning_rate": 9.6483366847697e-06,
      "loss": 0.0025,
      "step": 2221
    },
    {
      "epoch": 0.03518216508067198,
      "grad_norm": 0.19404961168766022,
      "learning_rate": 9.648178349193281e-06,
      "loss": 0.0985,
      "step": 2222
    },
    {
      "epoch": 0.03519799863831404,
      "grad_norm": 0.008840011432766914,
      "learning_rate": 9.64802001361686e-06,
      "loss": 0.0005,
      "step": 2223
    },
    {
      "epoch": 0.035213832195956106,
      "grad_norm": 0.13936132192611694,
      "learning_rate": 9.64786167804044e-06,
      "loss": 0.1236,
      "step": 2224
    },
    {
      "epoch": 0.03522966575359818,
      "grad_norm": 0.2759804129600525,
      "learning_rate": 9.647703342464019e-06,
      "loss": 0.2226,
      "step": 2225
    },
    {
      "epoch": 0.03524549931124024,
      "grad_norm": 0.3755699396133423,
      "learning_rate": 9.6475450068876e-06,
      "loss": 0.7531,
      "step": 2226
    },
    {
      "epoch": 0.035261332868882306,
      "grad_norm": 0.17159603536128998,
      "learning_rate": 9.647386671311177e-06,
      "loss": 0.1616,
      "step": 2227
    },
    {
      "epoch": 0.03527716642652438,
      "grad_norm": 0.0011583180166780949,
      "learning_rate": 9.647228335734758e-06,
      "loss": 0.0,
      "step": 2228
    },
    {
      "epoch": 0.03529299998416644,
      "grad_norm": 0.24403762817382812,
      "learning_rate": 9.647070000158337e-06,
      "loss": 0.0536,
      "step": 2229
    },
    {
      "epoch": 0.035308833541808506,
      "grad_norm": 0.11752799898386002,
      "learning_rate": 9.646911664581916e-06,
      "loss": 0.1365,
      "step": 2230
    },
    {
      "epoch": 0.03532466709945058,
      "grad_norm": 0.011621647514402866,
      "learning_rate": 9.646753329005495e-06,
      "loss": 0.0006,
      "step": 2231
    },
    {
      "epoch": 0.03534050065709264,
      "grad_norm": 0.0003310173924546689,
      "learning_rate": 9.646594993429076e-06,
      "loss": 0.0,
      "step": 2232
    },
    {
      "epoch": 0.035356334214734705,
      "grad_norm": 0.0035198675468564034,
      "learning_rate": 9.646436657852653e-06,
      "loss": 0.0002,
      "step": 2233
    },
    {
      "epoch": 0.03537216777237678,
      "grad_norm": 0.15675723552703857,
      "learning_rate": 9.646278322276234e-06,
      "loss": 0.0673,
      "step": 2234
    },
    {
      "epoch": 0.03538800133001884,
      "grad_norm": 0.47589603066444397,
      "learning_rate": 9.646119986699813e-06,
      "loss": 0.5154,
      "step": 2235
    },
    {
      "epoch": 0.035403834887660905,
      "grad_norm": 0.0075715952552855015,
      "learning_rate": 9.645961651123392e-06,
      "loss": 0.0004,
      "step": 2236
    },
    {
      "epoch": 0.035419668445302976,
      "grad_norm": 0.49976494908332825,
      "learning_rate": 9.645803315546971e-06,
      "loss": 0.1721,
      "step": 2237
    },
    {
      "epoch": 0.03543550200294504,
      "grad_norm": 0.2876819968223572,
      "learning_rate": 9.64564497997055e-06,
      "loss": 0.1744,
      "step": 2238
    },
    {
      "epoch": 0.035451335560587105,
      "grad_norm": 0.24689055979251862,
      "learning_rate": 9.645486644394129e-06,
      "loss": 0.0527,
      "step": 2239
    },
    {
      "epoch": 0.035467169118229176,
      "grad_norm": 0.3671773672103882,
      "learning_rate": 9.645328308817708e-06,
      "loss": 0.2019,
      "step": 2240
    },
    {
      "epoch": 0.03548300267587124,
      "grad_norm": 0.5032632946968079,
      "learning_rate": 9.645169973241289e-06,
      "loss": 0.362,
      "step": 2241
    },
    {
      "epoch": 0.035498836233513305,
      "grad_norm": 0.24190200865268707,
      "learning_rate": 9.645011637664868e-06,
      "loss": 0.1295,
      "step": 2242
    },
    {
      "epoch": 0.035514669791155376,
      "grad_norm": 0.03174448758363724,
      "learning_rate": 9.644853302088447e-06,
      "loss": 0.0009,
      "step": 2243
    },
    {
      "epoch": 0.03553050334879744,
      "grad_norm": 0.22728408873081207,
      "learning_rate": 9.644694966512026e-06,
      "loss": 0.2731,
      "step": 2244
    },
    {
      "epoch": 0.035546336906439505,
      "grad_norm": 0.21861764788627625,
      "learning_rate": 9.644536630935605e-06,
      "loss": 0.102,
      "step": 2245
    },
    {
      "epoch": 0.035562170464081576,
      "grad_norm": 0.18751703202724457,
      "learning_rate": 9.644378295359184e-06,
      "loss": 0.1393,
      "step": 2246
    },
    {
      "epoch": 0.03557800402172364,
      "grad_norm": 0.17482499778270721,
      "learning_rate": 9.644219959782765e-06,
      "loss": 0.2942,
      "step": 2247
    },
    {
      "epoch": 0.035593837579365704,
      "grad_norm": 0.16319511830806732,
      "learning_rate": 9.644061624206343e-06,
      "loss": 0.0447,
      "step": 2248
    },
    {
      "epoch": 0.035609671137007776,
      "grad_norm": 0.22522194683551788,
      "learning_rate": 9.643903288629923e-06,
      "loss": 0.0537,
      "step": 2249
    },
    {
      "epoch": 0.03562550469464984,
      "grad_norm": 0.30492183566093445,
      "learning_rate": 9.643744953053502e-06,
      "loss": 0.4262,
      "step": 2250
    },
    {
      "epoch": 0.035641338252291904,
      "grad_norm": 0.1825820356607437,
      "learning_rate": 9.643586617477081e-06,
      "loss": 0.1568,
      "step": 2251
    },
    {
      "epoch": 0.035657171809933975,
      "grad_norm": 0.13816313445568085,
      "learning_rate": 9.64342828190066e-06,
      "loss": 0.0125,
      "step": 2252
    },
    {
      "epoch": 0.03567300536757604,
      "grad_norm": 0.16334973275661469,
      "learning_rate": 9.643269946324241e-06,
      "loss": 0.0615,
      "step": 2253
    },
    {
      "epoch": 0.035688838925218104,
      "grad_norm": 0.19463452696800232,
      "learning_rate": 9.643111610747819e-06,
      "loss": 0.2067,
      "step": 2254
    },
    {
      "epoch": 0.035704672482860175,
      "grad_norm": 0.2930385172367096,
      "learning_rate": 9.6429532751714e-06,
      "loss": 0.405,
      "step": 2255
    },
    {
      "epoch": 0.03572050604050224,
      "grad_norm": 0.16059695184230804,
      "learning_rate": 9.642794939594979e-06,
      "loss": 0.2816,
      "step": 2256
    },
    {
      "epoch": 0.035736339598144304,
      "grad_norm": 0.24982009828090668,
      "learning_rate": 9.642636604018558e-06,
      "loss": 0.2969,
      "step": 2257
    },
    {
      "epoch": 0.035752173155786375,
      "grad_norm": 0.17414042353630066,
      "learning_rate": 9.642478268442137e-06,
      "loss": 0.0555,
      "step": 2258
    },
    {
      "epoch": 0.03576800671342844,
      "grad_norm": 1.695571780204773,
      "learning_rate": 9.642319932865718e-06,
      "loss": 0.1128,
      "step": 2259
    },
    {
      "epoch": 0.035783840271070504,
      "grad_norm": 0.16352394223213196,
      "learning_rate": 9.642161597289295e-06,
      "loss": 0.092,
      "step": 2260
    },
    {
      "epoch": 0.035799673828712575,
      "grad_norm": 0.2522270679473877,
      "learning_rate": 9.642003261712876e-06,
      "loss": 0.1018,
      "step": 2261
    },
    {
      "epoch": 0.03581550738635464,
      "grad_norm": 0.9070124626159668,
      "learning_rate": 9.641844926136455e-06,
      "loss": 0.3451,
      "step": 2262
    },
    {
      "epoch": 0.0358313409439967,
      "grad_norm": 0.2575909197330475,
      "learning_rate": 9.641686590560034e-06,
      "loss": 0.0493,
      "step": 2263
    },
    {
      "epoch": 0.035847174501638775,
      "grad_norm": 0.36974450945854187,
      "learning_rate": 9.641528254983613e-06,
      "loss": 1.0191,
      "step": 2264
    },
    {
      "epoch": 0.03586300805928084,
      "grad_norm": 0.16440321505069733,
      "learning_rate": 9.641369919407192e-06,
      "loss": 0.1266,
      "step": 2265
    },
    {
      "epoch": 0.0358788416169229,
      "grad_norm": 0.2436601221561432,
      "learning_rate": 9.641211583830771e-06,
      "loss": 0.4369,
      "step": 2266
    },
    {
      "epoch": 0.035894675174564974,
      "grad_norm": 0.07923034578561783,
      "learning_rate": 9.64105324825435e-06,
      "loss": 0.0029,
      "step": 2267
    },
    {
      "epoch": 0.03591050873220704,
      "grad_norm": 0.2328445315361023,
      "learning_rate": 9.640894912677931e-06,
      "loss": 0.1106,
      "step": 2268
    },
    {
      "epoch": 0.0359263422898491,
      "grad_norm": 0.26113754510879517,
      "learning_rate": 9.64073657710151e-06,
      "loss": 0.0482,
      "step": 2269
    },
    {
      "epoch": 0.035942175847491174,
      "grad_norm": 0.7567091584205627,
      "learning_rate": 9.640578241525089e-06,
      "loss": 0.5353,
      "step": 2270
    },
    {
      "epoch": 0.03595800940513324,
      "grad_norm": 0.2547876536846161,
      "learning_rate": 9.640419905948668e-06,
      "loss": 0.4224,
      "step": 2271
    },
    {
      "epoch": 0.0359738429627753,
      "grad_norm": 0.18015849590301514,
      "learning_rate": 9.640261570372247e-06,
      "loss": 0.0325,
      "step": 2272
    },
    {
      "epoch": 0.035989676520417374,
      "grad_norm": 0.19975507259368896,
      "learning_rate": 9.640103234795826e-06,
      "loss": 0.1892,
      "step": 2273
    },
    {
      "epoch": 0.03600551007805944,
      "grad_norm": 0.39109230041503906,
      "learning_rate": 9.639944899219407e-06,
      "loss": 0.2001,
      "step": 2274
    },
    {
      "epoch": 0.0360213436357015,
      "grad_norm": 0.10439812391996384,
      "learning_rate": 9.639786563642986e-06,
      "loss": 0.1123,
      "step": 2275
    },
    {
      "epoch": 0.036037177193343574,
      "grad_norm": 6.340337131405249e-05,
      "learning_rate": 9.639628228066565e-06,
      "loss": 0.0,
      "step": 2276
    },
    {
      "epoch": 0.03605301075098564,
      "grad_norm": 0.10222204029560089,
      "learning_rate": 9.639469892490144e-06,
      "loss": 0.0508,
      "step": 2277
    },
    {
      "epoch": 0.0360688443086277,
      "grad_norm": 0.0046998015604913235,
      "learning_rate": 9.639311556913723e-06,
      "loss": 0.0004,
      "step": 2278
    },
    {
      "epoch": 0.036084677866269774,
      "grad_norm": 0.3103429675102234,
      "learning_rate": 9.639153221337302e-06,
      "loss": 0.8836,
      "step": 2279
    },
    {
      "epoch": 0.03610051142391184,
      "grad_norm": 0.6954065561294556,
      "learning_rate": 9.638994885760883e-06,
      "loss": 0.5928,
      "step": 2280
    },
    {
      "epoch": 0.0361163449815539,
      "grad_norm": 0.16289834678173065,
      "learning_rate": 9.638836550184462e-06,
      "loss": 0.1621,
      "step": 2281
    },
    {
      "epoch": 0.036132178539195973,
      "grad_norm": 9.02386091183871e-05,
      "learning_rate": 9.638678214608041e-06,
      "loss": 0.0,
      "step": 2282
    },
    {
      "epoch": 0.03614801209683804,
      "grad_norm": 0.2508172392845154,
      "learning_rate": 9.63851987903162e-06,
      "loss": 0.1283,
      "step": 2283
    },
    {
      "epoch": 0.0361638456544801,
      "grad_norm": 0.17317575216293335,
      "learning_rate": 9.6383615434552e-06,
      "loss": 0.101,
      "step": 2284
    },
    {
      "epoch": 0.03617967921212217,
      "grad_norm": 0.3194368779659271,
      "learning_rate": 9.638203207878779e-06,
      "loss": 0.3874,
      "step": 2285
    },
    {
      "epoch": 0.03619551276976424,
      "grad_norm": 0.25014156103134155,
      "learning_rate": 9.638044872302358e-06,
      "loss": 0.4978,
      "step": 2286
    },
    {
      "epoch": 0.0362113463274063,
      "grad_norm": 0.17048704624176025,
      "learning_rate": 9.637886536725939e-06,
      "loss": 0.0978,
      "step": 2287
    },
    {
      "epoch": 0.03622717988504837,
      "grad_norm": 0.2440919280052185,
      "learning_rate": 9.637728201149516e-06,
      "loss": 0.2977,
      "step": 2288
    },
    {
      "epoch": 0.03624301344269044,
      "grad_norm": 0.12405233830213547,
      "learning_rate": 9.637569865573097e-06,
      "loss": 0.0396,
      "step": 2289
    },
    {
      "epoch": 0.0362588470003325,
      "grad_norm": 0.23852457106113434,
      "learning_rate": 9.637411529996676e-06,
      "loss": 0.2197,
      "step": 2290
    },
    {
      "epoch": 0.03627468055797457,
      "grad_norm": 0.19832763075828552,
      "learning_rate": 9.637253194420255e-06,
      "loss": 0.2246,
      "step": 2291
    },
    {
      "epoch": 0.03629051411561664,
      "grad_norm": 0.277351975440979,
      "learning_rate": 9.637094858843834e-06,
      "loss": 0.0877,
      "step": 2292
    },
    {
      "epoch": 0.0363063476732587,
      "grad_norm": 0.005729359108954668,
      "learning_rate": 9.636936523267415e-06,
      "loss": 0.0004,
      "step": 2293
    },
    {
      "epoch": 0.03632218123090077,
      "grad_norm": 0.24045045673847198,
      "learning_rate": 9.636778187690992e-06,
      "loss": 0.0627,
      "step": 2294
    },
    {
      "epoch": 0.03633801478854284,
      "grad_norm": 0.19809992611408234,
      "learning_rate": 9.636619852114573e-06,
      "loss": 0.2602,
      "step": 2295
    },
    {
      "epoch": 0.0363538483461849,
      "grad_norm": 0.35121625661849976,
      "learning_rate": 9.636461516538152e-06,
      "loss": 0.522,
      "step": 2296
    },
    {
      "epoch": 0.03636968190382697,
      "grad_norm": 0.14925318956375122,
      "learning_rate": 9.636303180961731e-06,
      "loss": 0.0179,
      "step": 2297
    },
    {
      "epoch": 0.03638551546146904,
      "grad_norm": 0.4679991900920868,
      "learning_rate": 9.63614484538531e-06,
      "loss": 0.2312,
      "step": 2298
    },
    {
      "epoch": 0.0364013490191111,
      "grad_norm": 0.23544643819332123,
      "learning_rate": 9.635986509808891e-06,
      "loss": 0.0085,
      "step": 2299
    },
    {
      "epoch": 0.03641718257675317,
      "grad_norm": 0.30615055561065674,
      "learning_rate": 9.635828174232468e-06,
      "loss": 0.3087,
      "step": 2300
    },
    {
      "epoch": 0.03643301613439524,
      "grad_norm": 0.14277289807796478,
      "learning_rate": 9.635669838656049e-06,
      "loss": 0.1261,
      "step": 2301
    },
    {
      "epoch": 0.0364488496920373,
      "grad_norm": 0.013628248125314713,
      "learning_rate": 9.635511503079628e-06,
      "loss": 0.0008,
      "step": 2302
    },
    {
      "epoch": 0.03646468324967937,
      "grad_norm": 0.15200866758823395,
      "learning_rate": 9.635353167503207e-06,
      "loss": 0.0313,
      "step": 2303
    },
    {
      "epoch": 0.036480516807321436,
      "grad_norm": 0.2135559618473053,
      "learning_rate": 9.635194831926786e-06,
      "loss": 0.5549,
      "step": 2304
    },
    {
      "epoch": 0.0364963503649635,
      "grad_norm": 0.32898223400115967,
      "learning_rate": 9.635036496350367e-06,
      "loss": 0.9807,
      "step": 2305
    },
    {
      "epoch": 0.03651218392260557,
      "grad_norm": 0.2382412552833557,
      "learning_rate": 9.634878160773944e-06,
      "loss": 0.0336,
      "step": 2306
    },
    {
      "epoch": 0.036528017480247636,
      "grad_norm": 0.502782940864563,
      "learning_rate": 9.634719825197525e-06,
      "loss": 0.163,
      "step": 2307
    },
    {
      "epoch": 0.0365438510378897,
      "grad_norm": 0.130975142121315,
      "learning_rate": 9.634561489621104e-06,
      "loss": 0.0165,
      "step": 2308
    },
    {
      "epoch": 0.03655968459553177,
      "grad_norm": 0.17457067966461182,
      "learning_rate": 9.634403154044683e-06,
      "loss": 0.1768,
      "step": 2309
    },
    {
      "epoch": 0.036575518153173836,
      "grad_norm": 0.00010036381718236953,
      "learning_rate": 9.634244818468262e-06,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 0.0365913517108159,
      "grad_norm": 0.16081702709197998,
      "learning_rate": 9.634086482891842e-06,
      "loss": 0.0991,
      "step": 2311
    },
    {
      "epoch": 0.03660718526845797,
      "grad_norm": 0.33653974533081055,
      "learning_rate": 9.63392814731542e-06,
      "loss": 0.183,
      "step": 2312
    },
    {
      "epoch": 0.036623018826100036,
      "grad_norm": 4.2538278648862615e-05,
      "learning_rate": 9.633769811739e-06,
      "loss": 0.0,
      "step": 2313
    },
    {
      "epoch": 0.0366388523837421,
      "grad_norm": 0.352954238653183,
      "learning_rate": 9.63361147616258e-06,
      "loss": 0.545,
      "step": 2314
    },
    {
      "epoch": 0.03665468594138417,
      "grad_norm": 0.0015862889122217894,
      "learning_rate": 9.633453140586158e-06,
      "loss": 0.0,
      "step": 2315
    },
    {
      "epoch": 0.036670519499026236,
      "grad_norm": 0.21768590807914734,
      "learning_rate": 9.633294805009739e-06,
      "loss": 0.1899,
      "step": 2316
    },
    {
      "epoch": 0.0366863530566683,
      "grad_norm": 0.2397667020559311,
      "learning_rate": 9.633136469433318e-06,
      "loss": 0.1322,
      "step": 2317
    },
    {
      "epoch": 0.03670218661431037,
      "grad_norm": 0.2021428495645523,
      "learning_rate": 9.632978133856897e-06,
      "loss": 0.0832,
      "step": 2318
    },
    {
      "epoch": 0.036718020171952435,
      "grad_norm": 0.19091233611106873,
      "learning_rate": 9.632819798280476e-06,
      "loss": 0.6377,
      "step": 2319
    },
    {
      "epoch": 0.0367338537295945,
      "grad_norm": 0.2312638759613037,
      "learning_rate": 9.632661462704057e-06,
      "loss": 0.1321,
      "step": 2320
    },
    {
      "epoch": 0.03674968728723657,
      "grad_norm": 0.2831008732318878,
      "learning_rate": 9.632503127127634e-06,
      "loss": 0.1202,
      "step": 2321
    },
    {
      "epoch": 0.036765520844878635,
      "grad_norm": 5.138817310333252,
      "learning_rate": 9.632344791551215e-06,
      "loss": 0.5869,
      "step": 2322
    },
    {
      "epoch": 0.0367813544025207,
      "grad_norm": 0.025907164439558983,
      "learning_rate": 9.632186455974794e-06,
      "loss": 0.0014,
      "step": 2323
    },
    {
      "epoch": 0.03679718796016277,
      "grad_norm": 0.3517865240573883,
      "learning_rate": 9.632028120398373e-06,
      "loss": 0.2778,
      "step": 2324
    },
    {
      "epoch": 0.036813021517804835,
      "grad_norm": 0.019581014290452003,
      "learning_rate": 9.631869784821952e-06,
      "loss": 0.0015,
      "step": 2325
    },
    {
      "epoch": 0.0368288550754469,
      "grad_norm": 0.09988363832235336,
      "learning_rate": 9.631711449245533e-06,
      "loss": 0.1143,
      "step": 2326
    },
    {
      "epoch": 0.03684468863308897,
      "grad_norm": 4.922886728309095e-05,
      "learning_rate": 9.63155311366911e-06,
      "loss": 0.0,
      "step": 2327
    },
    {
      "epoch": 0.036860522190731035,
      "grad_norm": 0.43868646025657654,
      "learning_rate": 9.631394778092691e-06,
      "loss": 0.6408,
      "step": 2328
    },
    {
      "epoch": 0.0368763557483731,
      "grad_norm": 0.28848254680633545,
      "learning_rate": 9.63123644251627e-06,
      "loss": 0.128,
      "step": 2329
    },
    {
      "epoch": 0.03689218930601517,
      "grad_norm": 0.025764362886548042,
      "learning_rate": 9.631078106939849e-06,
      "loss": 0.0018,
      "step": 2330
    },
    {
      "epoch": 0.036908022863657235,
      "grad_norm": 0.2709597647190094,
      "learning_rate": 9.630919771363428e-06,
      "loss": 0.2626,
      "step": 2331
    },
    {
      "epoch": 0.0369238564212993,
      "grad_norm": 1.2569782733917236,
      "learning_rate": 9.630761435787009e-06,
      "loss": 0.0655,
      "step": 2332
    },
    {
      "epoch": 0.03693968997894137,
      "grad_norm": 0.17587676644325256,
      "learning_rate": 9.630603100210586e-06,
      "loss": 0.2161,
      "step": 2333
    },
    {
      "epoch": 0.036955523536583434,
      "grad_norm": 0.2807467579841614,
      "learning_rate": 9.630444764634165e-06,
      "loss": 0.3681,
      "step": 2334
    },
    {
      "epoch": 0.0369713570942255,
      "grad_norm": 0.019110750406980515,
      "learning_rate": 9.630286429057746e-06,
      "loss": 0.0013,
      "step": 2335
    },
    {
      "epoch": 0.03698719065186757,
      "grad_norm": 0.1969696432352066,
      "learning_rate": 9.630128093481325e-06,
      "loss": 0.1156,
      "step": 2336
    },
    {
      "epoch": 0.037003024209509634,
      "grad_norm": 0.17432419955730438,
      "learning_rate": 9.629969757904904e-06,
      "loss": 0.2449,
      "step": 2337
    },
    {
      "epoch": 0.0370188577671517,
      "grad_norm": 0.12854109704494476,
      "learning_rate": 9.629811422328483e-06,
      "loss": 0.1803,
      "step": 2338
    },
    {
      "epoch": 0.03703469132479377,
      "grad_norm": 0.018470700830221176,
      "learning_rate": 9.629653086752063e-06,
      "loss": 0.0014,
      "step": 2339
    },
    {
      "epoch": 0.037050524882435834,
      "grad_norm": 0.028178667649626732,
      "learning_rate": 9.629494751175642e-06,
      "loss": 0.0019,
      "step": 2340
    },
    {
      "epoch": 0.0370663584400779,
      "grad_norm": 0.3453865647315979,
      "learning_rate": 9.629336415599222e-06,
      "loss": 0.6998,
      "step": 2341
    },
    {
      "epoch": 0.03708219199771997,
      "grad_norm": 0.7412229180335999,
      "learning_rate": 9.629178080022801e-06,
      "loss": 0.1095,
      "step": 2342
    },
    {
      "epoch": 0.037098025555362034,
      "grad_norm": 0.2002539336681366,
      "learning_rate": 9.62901974444638e-06,
      "loss": 0.0068,
      "step": 2343
    },
    {
      "epoch": 0.0371138591130041,
      "grad_norm": 0.296813040971756,
      "learning_rate": 9.62886140886996e-06,
      "loss": 0.6175,
      "step": 2344
    },
    {
      "epoch": 0.03712969267064617,
      "grad_norm": 0.14289215207099915,
      "learning_rate": 9.628703073293539e-06,
      "loss": 0.1168,
      "step": 2345
    },
    {
      "epoch": 0.037145526228288234,
      "grad_norm": 0.3494161069393158,
      "learning_rate": 9.628544737717118e-06,
      "loss": 0.9223,
      "step": 2346
    },
    {
      "epoch": 0.0371613597859303,
      "grad_norm": 0.5921170115470886,
      "learning_rate": 9.628386402140699e-06,
      "loss": 0.6181,
      "step": 2347
    },
    {
      "epoch": 0.03717719334357237,
      "grad_norm": 0.0058856550604105,
      "learning_rate": 9.628228066564278e-06,
      "loss": 0.0004,
      "step": 2348
    },
    {
      "epoch": 0.037193026901214433,
      "grad_norm": 0.17721296846866608,
      "learning_rate": 9.628069730987857e-06,
      "loss": 0.0722,
      "step": 2349
    },
    {
      "epoch": 0.0372088604588565,
      "grad_norm": 0.017464114353060722,
      "learning_rate": 9.627911395411436e-06,
      "loss": 0.0022,
      "step": 2350
    },
    {
      "epoch": 0.03722469401649857,
      "grad_norm": 0.02134157530963421,
      "learning_rate": 9.627753059835015e-06,
      "loss": 0.0014,
      "step": 2351
    },
    {
      "epoch": 0.03724052757414063,
      "grad_norm": 0.005136486608535051,
      "learning_rate": 9.627594724258594e-06,
      "loss": 0.0004,
      "step": 2352
    },
    {
      "epoch": 0.0372563611317827,
      "grad_norm": 0.012684760615229607,
      "learning_rate": 9.627436388682175e-06,
      "loss": 0.001,
      "step": 2353
    },
    {
      "epoch": 0.03727219468942477,
      "grad_norm": 0.4291542172431946,
      "learning_rate": 9.627278053105754e-06,
      "loss": 0.2372,
      "step": 2354
    },
    {
      "epoch": 0.03728802824706683,
      "grad_norm": 0.09854841977357864,
      "learning_rate": 9.627119717529333e-06,
      "loss": 0.0049,
      "step": 2355
    },
    {
      "epoch": 0.0373038618047089,
      "grad_norm": 0.00032504339469596744,
      "learning_rate": 9.626961381952912e-06,
      "loss": 0.0,
      "step": 2356
    },
    {
      "epoch": 0.03731969536235097,
      "grad_norm": 0.19297006726264954,
      "learning_rate": 9.626803046376491e-06,
      "loss": 0.0408,
      "step": 2357
    },
    {
      "epoch": 0.03733552891999303,
      "grad_norm": 0.29288673400878906,
      "learning_rate": 9.62664471080007e-06,
      "loss": 0.2929,
      "step": 2358
    },
    {
      "epoch": 0.0373513624776351,
      "grad_norm": 0.00018135854043066502,
      "learning_rate": 9.62648637522365e-06,
      "loss": 0.0,
      "step": 2359
    },
    {
      "epoch": 0.03736719603527717,
      "grad_norm": 0.4961111545562744,
      "learning_rate": 9.62632803964723e-06,
      "loss": 0.0637,
      "step": 2360
    },
    {
      "epoch": 0.03738302959291923,
      "grad_norm": 0.7149310111999512,
      "learning_rate": 9.626169704070807e-06,
      "loss": 0.8313,
      "step": 2361
    },
    {
      "epoch": 0.0373988631505613,
      "grad_norm": 0.014205406419932842,
      "learning_rate": 9.626011368494388e-06,
      "loss": 0.0022,
      "step": 2362
    },
    {
      "epoch": 0.03741469670820337,
      "grad_norm": 0.015457730740308762,
      "learning_rate": 9.625853032917967e-06,
      "loss": 0.0013,
      "step": 2363
    },
    {
      "epoch": 0.03743053026584543,
      "grad_norm": 0.15157684683799744,
      "learning_rate": 9.625694697341546e-06,
      "loss": 0.1015,
      "step": 2364
    },
    {
      "epoch": 0.0374463638234875,
      "grad_norm": 0.016613824293017387,
      "learning_rate": 9.625536361765125e-06,
      "loss": 0.0015,
      "step": 2365
    },
    {
      "epoch": 0.03746219738112957,
      "grad_norm": 0.19315432012081146,
      "learning_rate": 9.625378026188706e-06,
      "loss": 0.4909,
      "step": 2366
    },
    {
      "epoch": 0.03747803093877163,
      "grad_norm": 0.17820203304290771,
      "learning_rate": 9.625219690612284e-06,
      "loss": 0.0981,
      "step": 2367
    },
    {
      "epoch": 0.0374938644964137,
      "grad_norm": 0.43128085136413574,
      "learning_rate": 9.625061355035864e-06,
      "loss": 0.097,
      "step": 2368
    },
    {
      "epoch": 0.03750969805405577,
      "grad_norm": 0.00038639098056592047,
      "learning_rate": 9.624903019459443e-06,
      "loss": 0.0,
      "step": 2369
    },
    {
      "epoch": 0.03752553161169783,
      "grad_norm": 0.010212321765720844,
      "learning_rate": 9.624744683883022e-06,
      "loss": 0.0008,
      "step": 2370
    },
    {
      "epoch": 0.037541365169339896,
      "grad_norm": 0.16552124917507172,
      "learning_rate": 9.624586348306602e-06,
      "loss": 0.9525,
      "step": 2371
    },
    {
      "epoch": 0.03755719872698197,
      "grad_norm": 0.0003574842703528702,
      "learning_rate": 9.62442801273018e-06,
      "loss": 0.0,
      "step": 2372
    },
    {
      "epoch": 0.03757303228462403,
      "grad_norm": 0.0636560469865799,
      "learning_rate": 9.62426967715376e-06,
      "loss": 0.0068,
      "step": 2373
    },
    {
      "epoch": 0.037588865842266096,
      "grad_norm": 0.0003051795647479594,
      "learning_rate": 9.62411134157734e-06,
      "loss": 0.0,
      "step": 2374
    },
    {
      "epoch": 0.03760469939990817,
      "grad_norm": 0.10956041514873505,
      "learning_rate": 9.62395300600092e-06,
      "loss": 0.0437,
      "step": 2375
    },
    {
      "epoch": 0.03762053295755023,
      "grad_norm": 0.47827261686325073,
      "learning_rate": 9.623794670424499e-06,
      "loss": 0.6541,
      "step": 2376
    },
    {
      "epoch": 0.037636366515192296,
      "grad_norm": 0.22102701663970947,
      "learning_rate": 9.623636334848078e-06,
      "loss": 0.1407,
      "step": 2377
    },
    {
      "epoch": 0.03765220007283437,
      "grad_norm": 0.08352378755807877,
      "learning_rate": 9.623477999271657e-06,
      "loss": 0.0063,
      "step": 2378
    },
    {
      "epoch": 0.03766803363047643,
      "grad_norm": 0.002909030532464385,
      "learning_rate": 9.623319663695236e-06,
      "loss": 0.0001,
      "step": 2379
    },
    {
      "epoch": 0.037683867188118496,
      "grad_norm": 0.020570384338498116,
      "learning_rate": 9.623161328118817e-06,
      "loss": 0.0029,
      "step": 2380
    },
    {
      "epoch": 0.03769970074576057,
      "grad_norm": 0.17432402074337006,
      "learning_rate": 9.623002992542396e-06,
      "loss": 0.216,
      "step": 2381
    },
    {
      "epoch": 0.03771553430340263,
      "grad_norm": 0.1846025288105011,
      "learning_rate": 9.622844656965973e-06,
      "loss": 0.4738,
      "step": 2382
    },
    {
      "epoch": 0.037731367861044696,
      "grad_norm": 0.31369802355766296,
      "learning_rate": 9.622686321389554e-06,
      "loss": 0.3687,
      "step": 2383
    },
    {
      "epoch": 0.03774720141868677,
      "grad_norm": 0.010574974119663239,
      "learning_rate": 9.622527985813133e-06,
      "loss": 0.0007,
      "step": 2384
    },
    {
      "epoch": 0.03776303497632883,
      "grad_norm": 0.03458017483353615,
      "learning_rate": 9.622369650236712e-06,
      "loss": 0.0023,
      "step": 2385
    },
    {
      "epoch": 0.037778868533970895,
      "grad_norm": 5.877941657672636e-05,
      "learning_rate": 9.622211314660291e-06,
      "loss": 0.0,
      "step": 2386
    },
    {
      "epoch": 0.03779470209161297,
      "grad_norm": 0.23927028477191925,
      "learning_rate": 9.622052979083872e-06,
      "loss": 0.0832,
      "step": 2387
    },
    {
      "epoch": 0.03781053564925503,
      "grad_norm": 0.046031154692173004,
      "learning_rate": 9.62189464350745e-06,
      "loss": 0.0012,
      "step": 2388
    },
    {
      "epoch": 0.037826369206897095,
      "grad_norm": 0.0002138307609129697,
      "learning_rate": 9.62173630793103e-06,
      "loss": 0.0,
      "step": 2389
    },
    {
      "epoch": 0.037842202764539166,
      "grad_norm": 0.28830277919769287,
      "learning_rate": 9.621577972354609e-06,
      "loss": 0.1959,
      "step": 2390
    },
    {
      "epoch": 0.03785803632218123,
      "grad_norm": 0.26613545417785645,
      "learning_rate": 9.621419636778188e-06,
      "loss": 0.1486,
      "step": 2391
    },
    {
      "epoch": 0.037873869879823295,
      "grad_norm": 0.0038959041703492403,
      "learning_rate": 9.621261301201767e-06,
      "loss": 0.0003,
      "step": 2392
    },
    {
      "epoch": 0.037889703437465366,
      "grad_norm": 0.0009579664329066873,
      "learning_rate": 9.621102965625348e-06,
      "loss": 0.0,
      "step": 2393
    },
    {
      "epoch": 0.03790553699510743,
      "grad_norm": 0.38434937596321106,
      "learning_rate": 9.620944630048925e-06,
      "loss": 1.5548,
      "step": 2394
    },
    {
      "epoch": 0.037921370552749495,
      "grad_norm": 0.3330758213996887,
      "learning_rate": 9.620786294472506e-06,
      "loss": 0.1553,
      "step": 2395
    },
    {
      "epoch": 0.037937204110391566,
      "grad_norm": 0.217409148812294,
      "learning_rate": 9.620627958896085e-06,
      "loss": 0.1155,
      "step": 2396
    },
    {
      "epoch": 0.03795303766803363,
      "grad_norm": 0.31824687123298645,
      "learning_rate": 9.620469623319664e-06,
      "loss": 0.2036,
      "step": 2397
    },
    {
      "epoch": 0.037968871225675695,
      "grad_norm": 0.44291695952415466,
      "learning_rate": 9.620311287743243e-06,
      "loss": 0.3164,
      "step": 2398
    },
    {
      "epoch": 0.037984704783317766,
      "grad_norm": 0.1679408848285675,
      "learning_rate": 9.620152952166824e-06,
      "loss": 0.0438,
      "step": 2399
    },
    {
      "epoch": 0.03800053834095983,
      "grad_norm": 0.6519336700439453,
      "learning_rate": 9.619994616590402e-06,
      "loss": 0.2861,
      "step": 2400
    },
    {
      "epoch": 0.038016371898601894,
      "grad_norm": 0.1767701357603073,
      "learning_rate": 9.619836281013982e-06,
      "loss": 0.1997,
      "step": 2401
    },
    {
      "epoch": 0.038032205456243966,
      "grad_norm": 0.2885819971561432,
      "learning_rate": 9.619677945437561e-06,
      "loss": 0.4293,
      "step": 2402
    },
    {
      "epoch": 0.03804803901388603,
      "grad_norm": 0.1601427048444748,
      "learning_rate": 9.61951960986114e-06,
      "loss": 0.0656,
      "step": 2403
    },
    {
      "epoch": 0.038063872571528094,
      "grad_norm": 0.43006473779678345,
      "learning_rate": 9.61936127428472e-06,
      "loss": 0.6387,
      "step": 2404
    },
    {
      "epoch": 0.038079706129170166,
      "grad_norm": 0.01681973785161972,
      "learning_rate": 9.6192029387083e-06,
      "loss": 0.0014,
      "step": 2405
    },
    {
      "epoch": 0.03809553968681223,
      "grad_norm": 0.018252085894346237,
      "learning_rate": 9.619044603131878e-06,
      "loss": 0.0012,
      "step": 2406
    },
    {
      "epoch": 0.038111373244454294,
      "grad_norm": 0.1806401163339615,
      "learning_rate": 9.618886267555457e-06,
      "loss": 0.078,
      "step": 2407
    },
    {
      "epoch": 0.038127206802096365,
      "grad_norm": 0.004772108513861895,
      "learning_rate": 9.618727931979038e-06,
      "loss": 0.0002,
      "step": 2408
    },
    {
      "epoch": 0.03814304035973843,
      "grad_norm": 0.21324211359024048,
      "learning_rate": 9.618569596402617e-06,
      "loss": 0.1447,
      "step": 2409
    },
    {
      "epoch": 0.038158873917380494,
      "grad_norm": 0.23929552733898163,
      "learning_rate": 9.618411260826196e-06,
      "loss": 0.1336,
      "step": 2410
    },
    {
      "epoch": 0.038174707475022565,
      "grad_norm": 0.03374297171831131,
      "learning_rate": 9.618252925249775e-06,
      "loss": 0.0007,
      "step": 2411
    },
    {
      "epoch": 0.03819054103266463,
      "grad_norm": 0.2535785138607025,
      "learning_rate": 9.618094589673354e-06,
      "loss": 0.0727,
      "step": 2412
    },
    {
      "epoch": 0.038206374590306694,
      "grad_norm": 0.030126826837658882,
      "learning_rate": 9.617936254096933e-06,
      "loss": 0.0031,
      "step": 2413
    },
    {
      "epoch": 0.038222208147948765,
      "grad_norm": 0.37891802191734314,
      "learning_rate": 9.617777918520514e-06,
      "loss": 0.2683,
      "step": 2414
    },
    {
      "epoch": 0.03823804170559083,
      "grad_norm": 0.19422931969165802,
      "learning_rate": 9.617619582944093e-06,
      "loss": 0.074,
      "step": 2415
    },
    {
      "epoch": 0.038253875263232893,
      "grad_norm": 0.1510234773159027,
      "learning_rate": 9.617461247367672e-06,
      "loss": 0.0046,
      "step": 2416
    },
    {
      "epoch": 0.038269708820874965,
      "grad_norm": 0.4412555992603302,
      "learning_rate": 9.617302911791251e-06,
      "loss": 0.1154,
      "step": 2417
    },
    {
      "epoch": 0.03828554237851703,
      "grad_norm": 0.17912457883358002,
      "learning_rate": 9.61714457621483e-06,
      "loss": 0.0658,
      "step": 2418
    },
    {
      "epoch": 0.03830137593615909,
      "grad_norm": 0.021527333185076714,
      "learning_rate": 9.61698624063841e-06,
      "loss": 0.0036,
      "step": 2419
    },
    {
      "epoch": 0.038317209493801165,
      "grad_norm": 0.00017867634596768767,
      "learning_rate": 9.61682790506199e-06,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 0.03833304305144323,
      "grad_norm": 0.19943225383758545,
      "learning_rate": 9.616669569485569e-06,
      "loss": 0.0352,
      "step": 2421
    },
    {
      "epoch": 0.03834887660908529,
      "grad_norm": 0.21140816807746887,
      "learning_rate": 9.616511233909148e-06,
      "loss": 0.2201,
      "step": 2422
    },
    {
      "epoch": 0.038364710166727364,
      "grad_norm": 0.19531875848770142,
      "learning_rate": 9.616352898332727e-06,
      "loss": 0.0884,
      "step": 2423
    },
    {
      "epoch": 0.03838054372436943,
      "grad_norm": 0.14033666253089905,
      "learning_rate": 9.616194562756306e-06,
      "loss": 0.1112,
      "step": 2424
    },
    {
      "epoch": 0.03839637728201149,
      "grad_norm": 0.11248625069856644,
      "learning_rate": 9.616036227179885e-06,
      "loss": 0.1056,
      "step": 2425
    },
    {
      "epoch": 0.038412210839653564,
      "grad_norm": 0.02344396896660328,
      "learning_rate": 9.615877891603466e-06,
      "loss": 0.0016,
      "step": 2426
    },
    {
      "epoch": 0.03842804439729563,
      "grad_norm": 0.18675905466079712,
      "learning_rate": 9.615719556027045e-06,
      "loss": 0.4051,
      "step": 2427
    },
    {
      "epoch": 0.03844387795493769,
      "grad_norm": 0.21088938415050507,
      "learning_rate": 9.615561220450624e-06,
      "loss": 0.1332,
      "step": 2428
    },
    {
      "epoch": 0.038459711512579764,
      "grad_norm": 0.008226051926612854,
      "learning_rate": 9.615402884874203e-06,
      "loss": 0.0004,
      "step": 2429
    },
    {
      "epoch": 0.03847554507022183,
      "grad_norm": 0.23963378369808197,
      "learning_rate": 9.615244549297782e-06,
      "loss": 0.1424,
      "step": 2430
    },
    {
      "epoch": 0.03849137862786389,
      "grad_norm": 0.0035508093424141407,
      "learning_rate": 9.615086213721362e-06,
      "loss": 0.0003,
      "step": 2431
    },
    {
      "epoch": 0.038507212185505964,
      "grad_norm": 0.16036009788513184,
      "learning_rate": 9.61492787814494e-06,
      "loss": 0.0025,
      "step": 2432
    },
    {
      "epoch": 0.03852304574314803,
      "grad_norm": 0.22391580045223236,
      "learning_rate": 9.614769542568521e-06,
      "loss": 0.0636,
      "step": 2433
    },
    {
      "epoch": 0.03853887930079009,
      "grad_norm": 0.3100396692752838,
      "learning_rate": 9.614611206992099e-06,
      "loss": 0.1876,
      "step": 2434
    },
    {
      "epoch": 0.038554712858432164,
      "grad_norm": 0.1191185936331749,
      "learning_rate": 9.61445287141568e-06,
      "loss": 0.0399,
      "step": 2435
    },
    {
      "epoch": 0.03857054641607423,
      "grad_norm": 0.20137111842632294,
      "learning_rate": 9.614294535839259e-06,
      "loss": 0.3814,
      "step": 2436
    },
    {
      "epoch": 0.03858637997371629,
      "grad_norm": 0.1282501220703125,
      "learning_rate": 9.614136200262838e-06,
      "loss": 0.247,
      "step": 2437
    },
    {
      "epoch": 0.03860221353135836,
      "grad_norm": 0.38270288705825806,
      "learning_rate": 9.613977864686417e-06,
      "loss": 0.598,
      "step": 2438
    },
    {
      "epoch": 0.03861804708900043,
      "grad_norm": 0.16847601532936096,
      "learning_rate": 9.613819529109996e-06,
      "loss": 0.2319,
      "step": 2439
    },
    {
      "epoch": 0.03863388064664249,
      "grad_norm": 0.22964569926261902,
      "learning_rate": 9.613661193533575e-06,
      "loss": 0.0778,
      "step": 2440
    },
    {
      "epoch": 0.03864971420428456,
      "grad_norm": 0.28629207611083984,
      "learning_rate": 9.613502857957156e-06,
      "loss": 0.0778,
      "step": 2441
    },
    {
      "epoch": 0.03866554776192663,
      "grad_norm": 0.27178633213043213,
      "learning_rate": 9.613344522380735e-06,
      "loss": 0.1555,
      "step": 2442
    },
    {
      "epoch": 0.03868138131956869,
      "grad_norm": 0.1619936227798462,
      "learning_rate": 9.613186186804314e-06,
      "loss": 0.0284,
      "step": 2443
    },
    {
      "epoch": 0.03869721487721076,
      "grad_norm": 0.3034757375717163,
      "learning_rate": 9.613027851227893e-06,
      "loss": 0.4192,
      "step": 2444
    },
    {
      "epoch": 0.03871304843485283,
      "grad_norm": 0.24834376573562622,
      "learning_rate": 9.612869515651472e-06,
      "loss": 0.3941,
      "step": 2445
    },
    {
      "epoch": 0.03872888199249489,
      "grad_norm": 0.1474708467721939,
      "learning_rate": 9.612711180075051e-06,
      "loss": 0.3096,
      "step": 2446
    },
    {
      "epoch": 0.03874471555013696,
      "grad_norm": 0.26692646741867065,
      "learning_rate": 9.612552844498632e-06,
      "loss": 0.1741,
      "step": 2447
    },
    {
      "epoch": 0.03876054910777903,
      "grad_norm": 0.3750495910644531,
      "learning_rate": 9.612394508922211e-06,
      "loss": 0.6669,
      "step": 2448
    },
    {
      "epoch": 0.03877638266542109,
      "grad_norm": 0.12952907383441925,
      "learning_rate": 9.61223617334579e-06,
      "loss": 0.0296,
      "step": 2449
    },
    {
      "epoch": 0.03879221622306316,
      "grad_norm": 0.007893337868154049,
      "learning_rate": 9.612077837769369e-06,
      "loss": 0.0007,
      "step": 2450
    },
    {
      "epoch": 0.03880804978070523,
      "grad_norm": 0.17191314697265625,
      "learning_rate": 9.611919502192948e-06,
      "loss": 0.2397,
      "step": 2451
    },
    {
      "epoch": 0.03882388333834729,
      "grad_norm": 0.1445620208978653,
      "learning_rate": 9.611761166616527e-06,
      "loss": 0.0544,
      "step": 2452
    },
    {
      "epoch": 0.03883971689598936,
      "grad_norm": 0.18612851202487946,
      "learning_rate": 9.611602831040108e-06,
      "loss": 0.327,
      "step": 2453
    },
    {
      "epoch": 0.03885555045363143,
      "grad_norm": 0.1971685141324997,
      "learning_rate": 9.611444495463687e-06,
      "loss": 0.1477,
      "step": 2454
    },
    {
      "epoch": 0.03887138401127349,
      "grad_norm": 2.1880930944462307e-05,
      "learning_rate": 9.611286159887265e-06,
      "loss": 0.0,
      "step": 2455
    },
    {
      "epoch": 0.03888721756891556,
      "grad_norm": 0.5033878087997437,
      "learning_rate": 9.611127824310845e-06,
      "loss": 0.0474,
      "step": 2456
    },
    {
      "epoch": 0.038903051126557626,
      "grad_norm": 0.3223523199558258,
      "learning_rate": 9.610969488734424e-06,
      "loss": 0.1047,
      "step": 2457
    },
    {
      "epoch": 0.03891888468419969,
      "grad_norm": 0.358635276556015,
      "learning_rate": 9.610811153158003e-06,
      "loss": 0.279,
      "step": 2458
    },
    {
      "epoch": 0.03893471824184176,
      "grad_norm": 0.006550786085426807,
      "learning_rate": 9.610652817581583e-06,
      "loss": 0.0005,
      "step": 2459
    },
    {
      "epoch": 0.038950551799483826,
      "grad_norm": 0.22215352952480316,
      "learning_rate": 9.610494482005163e-06,
      "loss": 0.1413,
      "step": 2460
    },
    {
      "epoch": 0.03896638535712589,
      "grad_norm": 0.0001921823131851852,
      "learning_rate": 9.61033614642874e-06,
      "loss": 0.0,
      "step": 2461
    },
    {
      "epoch": 0.03898221891476796,
      "grad_norm": 0.039812661707401276,
      "learning_rate": 9.610177810852321e-06,
      "loss": 0.0034,
      "step": 2462
    },
    {
      "epoch": 0.038998052472410026,
      "grad_norm": 0.31563836336135864,
      "learning_rate": 9.6100194752759e-06,
      "loss": 0.2117,
      "step": 2463
    },
    {
      "epoch": 0.03901388603005209,
      "grad_norm": 0.6064561009407043,
      "learning_rate": 9.60986113969948e-06,
      "loss": 0.7385,
      "step": 2464
    },
    {
      "epoch": 0.03902971958769416,
      "grad_norm": 0.019838273525238037,
      "learning_rate": 9.609702804123059e-06,
      "loss": 0.0014,
      "step": 2465
    },
    {
      "epoch": 0.039045553145336226,
      "grad_norm": 0.4142135977745056,
      "learning_rate": 9.60954446854664e-06,
      "loss": 0.2804,
      "step": 2466
    },
    {
      "epoch": 0.03906138670297829,
      "grad_norm": 0.0005338639602996409,
      "learning_rate": 9.609386132970217e-06,
      "loss": 0.0,
      "step": 2467
    },
    {
      "epoch": 0.03907722026062036,
      "grad_norm": 6.359741382766515e-05,
      "learning_rate": 9.609227797393798e-06,
      "loss": 0.0,
      "step": 2468
    },
    {
      "epoch": 0.039093053818262426,
      "grad_norm": 0.20114898681640625,
      "learning_rate": 9.609069461817377e-06,
      "loss": 0.0508,
      "step": 2469
    },
    {
      "epoch": 0.03910888737590449,
      "grad_norm": 0.23108705878257751,
      "learning_rate": 9.608911126240956e-06,
      "loss": 0.0239,
      "step": 2470
    },
    {
      "epoch": 0.03912472093354656,
      "grad_norm": 0.0063627175986766815,
      "learning_rate": 9.608752790664535e-06,
      "loss": 0.0004,
      "step": 2471
    },
    {
      "epoch": 0.039140554491188626,
      "grad_norm": 0.33919423818588257,
      "learning_rate": 9.608594455088116e-06,
      "loss": 0.2115,
      "step": 2472
    },
    {
      "epoch": 0.03915638804883069,
      "grad_norm": 0.1730022430419922,
      "learning_rate": 9.608436119511693e-06,
      "loss": 0.3093,
      "step": 2473
    },
    {
      "epoch": 0.03917222160647276,
      "grad_norm": 0.007286380976438522,
      "learning_rate": 9.608277783935274e-06,
      "loss": 0.0006,
      "step": 2474
    },
    {
      "epoch": 0.039188055164114825,
      "grad_norm": 0.23976412415504456,
      "learning_rate": 9.608119448358853e-06,
      "loss": 0.2212,
      "step": 2475
    },
    {
      "epoch": 0.03920388872175689,
      "grad_norm": 0.0008290827972814441,
      "learning_rate": 9.607961112782432e-06,
      "loss": 0.0,
      "step": 2476
    },
    {
      "epoch": 0.03921972227939896,
      "grad_norm": 0.003545984858646989,
      "learning_rate": 9.607802777206011e-06,
      "loss": 0.0001,
      "step": 2477
    },
    {
      "epoch": 0.039235555837041025,
      "grad_norm": 0.11661713570356369,
      "learning_rate": 9.607644441629592e-06,
      "loss": 0.0244,
      "step": 2478
    },
    {
      "epoch": 0.03925138939468309,
      "grad_norm": 0.18465928733348846,
      "learning_rate": 9.60748610605317e-06,
      "loss": 0.0927,
      "step": 2479
    },
    {
      "epoch": 0.03926722295232516,
      "grad_norm": 0.39648038148880005,
      "learning_rate": 9.607327770476748e-06,
      "loss": 0.1051,
      "step": 2480
    },
    {
      "epoch": 0.039283056509967225,
      "grad_norm": 0.5352205038070679,
      "learning_rate": 9.607169434900329e-06,
      "loss": 0.6103,
      "step": 2481
    },
    {
      "epoch": 0.03929889006760929,
      "grad_norm": 0.23738136887550354,
      "learning_rate": 9.607011099323908e-06,
      "loss": 0.1385,
      "step": 2482
    },
    {
      "epoch": 0.03931472362525136,
      "grad_norm": 0.20610538125038147,
      "learning_rate": 9.606852763747487e-06,
      "loss": 0.5263,
      "step": 2483
    },
    {
      "epoch": 0.039330557182893425,
      "grad_norm": 0.17641659080982208,
      "learning_rate": 9.606694428171066e-06,
      "loss": 0.0305,
      "step": 2484
    },
    {
      "epoch": 0.03934639074053549,
      "grad_norm": 0.35552966594696045,
      "learning_rate": 9.606536092594645e-06,
      "loss": 0.083,
      "step": 2485
    },
    {
      "epoch": 0.03936222429817756,
      "grad_norm": 0.36347728967666626,
      "learning_rate": 9.606377757018224e-06,
      "loss": 0.3018,
      "step": 2486
    },
    {
      "epoch": 0.039378057855819625,
      "grad_norm": 0.1866600662469864,
      "learning_rate": 9.606219421441805e-06,
      "loss": 0.2291,
      "step": 2487
    },
    {
      "epoch": 0.03939389141346169,
      "grad_norm": 0.1747291535139084,
      "learning_rate": 9.606061085865384e-06,
      "loss": 0.0911,
      "step": 2488
    },
    {
      "epoch": 0.03940972497110376,
      "grad_norm": 0.02348126657307148,
      "learning_rate": 9.605902750288963e-06,
      "loss": 0.0018,
      "step": 2489
    },
    {
      "epoch": 0.039425558528745824,
      "grad_norm": 0.38016578555107117,
      "learning_rate": 9.605744414712542e-06,
      "loss": 0.3333,
      "step": 2490
    },
    {
      "epoch": 0.03944139208638789,
      "grad_norm": 0.13946522772312164,
      "learning_rate": 9.605586079136122e-06,
      "loss": 0.0571,
      "step": 2491
    },
    {
      "epoch": 0.03945722564402996,
      "grad_norm": 0.3581361770629883,
      "learning_rate": 9.6054277435597e-06,
      "loss": 0.188,
      "step": 2492
    },
    {
      "epoch": 0.039473059201672024,
      "grad_norm": 0.3058589696884155,
      "learning_rate": 9.605269407983281e-06,
      "loss": 0.2534,
      "step": 2493
    },
    {
      "epoch": 0.03948889275931409,
      "grad_norm": 0.5364047288894653,
      "learning_rate": 9.60511107240686e-06,
      "loss": 1.0946,
      "step": 2494
    },
    {
      "epoch": 0.03950472631695616,
      "grad_norm": 0.15221206843852997,
      "learning_rate": 9.60495273683044e-06,
      "loss": 0.0814,
      "step": 2495
    },
    {
      "epoch": 0.039520559874598224,
      "grad_norm": 4.755149348056875e-05,
      "learning_rate": 9.604794401254019e-06,
      "loss": 0.0,
      "step": 2496
    },
    {
      "epoch": 0.03953639343224029,
      "grad_norm": 0.2670913338661194,
      "learning_rate": 9.604636065677598e-06,
      "loss": 0.1539,
      "step": 2497
    },
    {
      "epoch": 0.03955222698988236,
      "grad_norm": 0.04150371626019478,
      "learning_rate": 9.604477730101177e-06,
      "loss": 0.0051,
      "step": 2498
    },
    {
      "epoch": 0.039568060547524424,
      "grad_norm": 0.34675538539886475,
      "learning_rate": 9.604319394524758e-06,
      "loss": 0.1664,
      "step": 2499
    },
    {
      "epoch": 0.03958389410516649,
      "grad_norm": 0.13461105525493622,
      "learning_rate": 9.604161058948337e-06,
      "loss": 0.077,
      "step": 2500
    },
    {
      "epoch": 0.03959972766280856,
      "grad_norm": 0.00013964904064778239,
      "learning_rate": 9.604002723371916e-06,
      "loss": 0.0,
      "step": 2501
    },
    {
      "epoch": 0.039615561220450624,
      "grad_norm": 0.18313923478126526,
      "learning_rate": 9.603844387795495e-06,
      "loss": 0.0804,
      "step": 2502
    },
    {
      "epoch": 0.03963139477809269,
      "grad_norm": 0.03735746443271637,
      "learning_rate": 9.603686052219074e-06,
      "loss": 0.003,
      "step": 2503
    },
    {
      "epoch": 0.03964722833573476,
      "grad_norm": 0.21450486779212952,
      "learning_rate": 9.603527716642653e-06,
      "loss": 0.2338,
      "step": 2504
    },
    {
      "epoch": 0.03966306189337682,
      "grad_norm": 0.35953080654144287,
      "learning_rate": 9.603369381066232e-06,
      "loss": 0.2624,
      "step": 2505
    },
    {
      "epoch": 0.03967889545101889,
      "grad_norm": 0.013283421285450459,
      "learning_rate": 9.603211045489811e-06,
      "loss": 0.0011,
      "step": 2506
    },
    {
      "epoch": 0.03969472900866096,
      "grad_norm": 0.3713766038417816,
      "learning_rate": 9.60305270991339e-06,
      "loss": 0.1123,
      "step": 2507
    },
    {
      "epoch": 0.03971056256630302,
      "grad_norm": 0.3568452000617981,
      "learning_rate": 9.602894374336971e-06,
      "loss": 0.6835,
      "step": 2508
    },
    {
      "epoch": 0.03972639612394509,
      "grad_norm": 0.016487106680870056,
      "learning_rate": 9.60273603876055e-06,
      "loss": 0.001,
      "step": 2509
    },
    {
      "epoch": 0.03974222968158716,
      "grad_norm": 0.028959039598703384,
      "learning_rate": 9.60257770318413e-06,
      "loss": 0.0013,
      "step": 2510
    },
    {
      "epoch": 0.03975806323922922,
      "grad_norm": 0.21640263497829437,
      "learning_rate": 9.602419367607708e-06,
      "loss": 0.297,
      "step": 2511
    },
    {
      "epoch": 0.03977389679687129,
      "grad_norm": 0.6169019341468811,
      "learning_rate": 9.602261032031287e-06,
      "loss": 0.13,
      "step": 2512
    },
    {
      "epoch": 0.03978973035451336,
      "grad_norm": 0.268353134393692,
      "learning_rate": 9.602102696454866e-06,
      "loss": 0.1824,
      "step": 2513
    },
    {
      "epoch": 0.03980556391215542,
      "grad_norm": 0.2866036593914032,
      "learning_rate": 9.601944360878447e-06,
      "loss": 0.5906,
      "step": 2514
    },
    {
      "epoch": 0.03982139746979749,
      "grad_norm": 0.30646082758903503,
      "learning_rate": 9.601786025302026e-06,
      "loss": 0.3069,
      "step": 2515
    },
    {
      "epoch": 0.03983723102743956,
      "grad_norm": 0.36768826842308044,
      "learning_rate": 9.601627689725605e-06,
      "loss": 0.2669,
      "step": 2516
    },
    {
      "epoch": 0.03985306458508162,
      "grad_norm": 0.018291447311639786,
      "learning_rate": 9.601469354149184e-06,
      "loss": 0.0012,
      "step": 2517
    },
    {
      "epoch": 0.03986889814272369,
      "grad_norm": 0.1925843358039856,
      "learning_rate": 9.601311018572763e-06,
      "loss": 0.0628,
      "step": 2518
    },
    {
      "epoch": 0.03988473170036576,
      "grad_norm": 0.03853030502796173,
      "learning_rate": 9.601152682996343e-06,
      "loss": 0.0023,
      "step": 2519
    },
    {
      "epoch": 0.03990056525800782,
      "grad_norm": 0.0005284125218167901,
      "learning_rate": 9.600994347419923e-06,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 0.03991639881564989,
      "grad_norm": 0.14232157170772552,
      "learning_rate": 9.600836011843502e-06,
      "loss": 0.0054,
      "step": 2521
    },
    {
      "epoch": 0.03993223237329196,
      "grad_norm": 0.17278419435024261,
      "learning_rate": 9.600677676267082e-06,
      "loss": 0.153,
      "step": 2522
    },
    {
      "epoch": 0.03994806593093402,
      "grad_norm": 0.1752084493637085,
      "learning_rate": 9.60051934069066e-06,
      "loss": 0.0153,
      "step": 2523
    },
    {
      "epoch": 0.039963899488576086,
      "grad_norm": 0.5914977788925171,
      "learning_rate": 9.60036100511424e-06,
      "loss": 0.7645,
      "step": 2524
    },
    {
      "epoch": 0.03997973304621816,
      "grad_norm": 0.17591112852096558,
      "learning_rate": 9.600202669537819e-06,
      "loss": 0.2557,
      "step": 2525
    },
    {
      "epoch": 0.03999556660386022,
      "grad_norm": 0.17562299966812134,
      "learning_rate": 9.6000443339614e-06,
      "loss": 0.1112,
      "step": 2526
    },
    {
      "epoch": 0.040011400161502286,
      "grad_norm": 0.03786285221576691,
      "learning_rate": 9.599885998384979e-06,
      "loss": 0.0045,
      "step": 2527
    },
    {
      "epoch": 0.04002723371914436,
      "grad_norm": 0.024807577952742577,
      "learning_rate": 9.599727662808556e-06,
      "loss": 0.0015,
      "step": 2528
    },
    {
      "epoch": 0.04004306727678642,
      "grad_norm": 0.395304411649704,
      "learning_rate": 9.599569327232137e-06,
      "loss": 0.4542,
      "step": 2529
    },
    {
      "epoch": 0.040058900834428486,
      "grad_norm": 0.2629961371421814,
      "learning_rate": 9.599410991655716e-06,
      "loss": 0.1894,
      "step": 2530
    },
    {
      "epoch": 0.04007473439207056,
      "grad_norm": 0.15298794209957123,
      "learning_rate": 9.599252656079295e-06,
      "loss": 0.052,
      "step": 2531
    },
    {
      "epoch": 0.04009056794971262,
      "grad_norm": 0.21312807500362396,
      "learning_rate": 9.599094320502874e-06,
      "loss": 0.1604,
      "step": 2532
    },
    {
      "epoch": 0.040106401507354686,
      "grad_norm": 0.3416026532649994,
      "learning_rate": 9.598935984926455e-06,
      "loss": 0.6639,
      "step": 2533
    },
    {
      "epoch": 0.04012223506499676,
      "grad_norm": 0.13120391964912415,
      "learning_rate": 9.598777649350032e-06,
      "loss": 0.0134,
      "step": 2534
    },
    {
      "epoch": 0.04013806862263882,
      "grad_norm": 6.0438884247560054e-05,
      "learning_rate": 9.598619313773613e-06,
      "loss": 0.0,
      "step": 2535
    },
    {
      "epoch": 0.040153902180280886,
      "grad_norm": 0.0032093713525682688,
      "learning_rate": 9.598460978197192e-06,
      "loss": 0.0002,
      "step": 2536
    },
    {
      "epoch": 0.04016973573792296,
      "grad_norm": 0.36280596256256104,
      "learning_rate": 9.598302642620771e-06,
      "loss": 0.3027,
      "step": 2537
    },
    {
      "epoch": 0.04018556929556502,
      "grad_norm": 0.33244630694389343,
      "learning_rate": 9.59814430704435e-06,
      "loss": 0.2973,
      "step": 2538
    },
    {
      "epoch": 0.040201402853207086,
      "grad_norm": 0.32686546444892883,
      "learning_rate": 9.597985971467931e-06,
      "loss": 0.3624,
      "step": 2539
    },
    {
      "epoch": 0.04021723641084916,
      "grad_norm": 0.28894132375717163,
      "learning_rate": 9.597827635891508e-06,
      "loss": 0.2719,
      "step": 2540
    },
    {
      "epoch": 0.04023306996849122,
      "grad_norm": 0.5983544588088989,
      "learning_rate": 9.597669300315089e-06,
      "loss": 0.4665,
      "step": 2541
    },
    {
      "epoch": 0.040248903526133285,
      "grad_norm": 0.013009022921323776,
      "learning_rate": 9.597510964738668e-06,
      "loss": 0.0007,
      "step": 2542
    },
    {
      "epoch": 0.04026473708377536,
      "grad_norm": 0.0003607612452469766,
      "learning_rate": 9.597352629162247e-06,
      "loss": 0.0,
      "step": 2543
    },
    {
      "epoch": 0.04028057064141742,
      "grad_norm": 0.5873808264732361,
      "learning_rate": 9.597194293585826e-06,
      "loss": 0.1484,
      "step": 2544
    },
    {
      "epoch": 0.040296404199059485,
      "grad_norm": 0.36444148421287537,
      "learning_rate": 9.597035958009407e-06,
      "loss": 0.1091,
      "step": 2545
    },
    {
      "epoch": 0.040312237756701556,
      "grad_norm": 0.24759246408939362,
      "learning_rate": 9.596877622432985e-06,
      "loss": 0.8596,
      "step": 2546
    },
    {
      "epoch": 0.04032807131434362,
      "grad_norm": 0.0004172952030785382,
      "learning_rate": 9.596719286856565e-06,
      "loss": 0.0,
      "step": 2547
    },
    {
      "epoch": 0.040343904871985685,
      "grad_norm": 0.37130457162857056,
      "learning_rate": 9.596560951280144e-06,
      "loss": 0.1853,
      "step": 2548
    },
    {
      "epoch": 0.040359738429627756,
      "grad_norm": 0.9645060300827026,
      "learning_rate": 9.596402615703723e-06,
      "loss": 0.1247,
      "step": 2549
    },
    {
      "epoch": 0.04037557198726982,
      "grad_norm": 2.1477186237461865e-05,
      "learning_rate": 9.596244280127303e-06,
      "loss": 0.0,
      "step": 2550
    },
    {
      "epoch": 0.040391405544911885,
      "grad_norm": 0.020619913935661316,
      "learning_rate": 9.596085944550882e-06,
      "loss": 0.0014,
      "step": 2551
    },
    {
      "epoch": 0.040407239102553956,
      "grad_norm": 0.010523761622607708,
      "learning_rate": 9.59592760897446e-06,
      "loss": 0.0006,
      "step": 2552
    },
    {
      "epoch": 0.04042307266019602,
      "grad_norm": 0.26519227027893066,
      "learning_rate": 9.59576927339804e-06,
      "loss": 0.7132,
      "step": 2553
    },
    {
      "epoch": 0.040438906217838085,
      "grad_norm": 0.14789257943630219,
      "learning_rate": 9.59561093782162e-06,
      "loss": 0.2972,
      "step": 2554
    },
    {
      "epoch": 0.040454739775480156,
      "grad_norm": 0.008372578769922256,
      "learning_rate": 9.5954526022452e-06,
      "loss": 0.0006,
      "step": 2555
    },
    {
      "epoch": 0.04047057333312222,
      "grad_norm": 0.2549852132797241,
      "learning_rate": 9.595294266668779e-06,
      "loss": 0.0275,
      "step": 2556
    },
    {
      "epoch": 0.040486406890764284,
      "grad_norm": 8.96657511475496e-05,
      "learning_rate": 9.595135931092358e-06,
      "loss": 0.0,
      "step": 2557
    },
    {
      "epoch": 0.040502240448406356,
      "grad_norm": 0.16920706629753113,
      "learning_rate": 9.594977595515937e-06,
      "loss": 0.2087,
      "step": 2558
    },
    {
      "epoch": 0.04051807400604842,
      "grad_norm": 0.22374822199344635,
      "learning_rate": 9.594819259939516e-06,
      "loss": 0.1244,
      "step": 2559
    },
    {
      "epoch": 0.040533907563690484,
      "grad_norm": 0.25939667224884033,
      "learning_rate": 9.594660924363097e-06,
      "loss": 0.1402,
      "step": 2560
    },
    {
      "epoch": 0.040549741121332555,
      "grad_norm": 0.384369432926178,
      "learning_rate": 9.594502588786676e-06,
      "loss": 0.1186,
      "step": 2561
    },
    {
      "epoch": 0.04056557467897462,
      "grad_norm": 0.030432527884840965,
      "learning_rate": 9.594344253210255e-06,
      "loss": 0.0012,
      "step": 2562
    },
    {
      "epoch": 0.040581408236616684,
      "grad_norm": 0.1238776221871376,
      "learning_rate": 9.594185917633834e-06,
      "loss": 0.1098,
      "step": 2563
    },
    {
      "epoch": 0.040597241794258755,
      "grad_norm": 0.011602443642914295,
      "learning_rate": 9.594027582057413e-06,
      "loss": 0.0008,
      "step": 2564
    },
    {
      "epoch": 0.04061307535190082,
      "grad_norm": 0.21978911757469177,
      "learning_rate": 9.593869246480992e-06,
      "loss": 0.1016,
      "step": 2565
    },
    {
      "epoch": 0.040628908909542884,
      "grad_norm": 0.10477190464735031,
      "learning_rate": 9.593710910904573e-06,
      "loss": 0.0451,
      "step": 2566
    },
    {
      "epoch": 0.040644742467184955,
      "grad_norm": 0.13862992823123932,
      "learning_rate": 9.59355257532815e-06,
      "loss": 0.2546,
      "step": 2567
    },
    {
      "epoch": 0.04066057602482702,
      "grad_norm": 0.17630140483379364,
      "learning_rate": 9.593394239751731e-06,
      "loss": 0.2795,
      "step": 2568
    },
    {
      "epoch": 0.040676409582469084,
      "grad_norm": 0.4531501531600952,
      "learning_rate": 9.59323590417531e-06,
      "loss": 0.3292,
      "step": 2569
    },
    {
      "epoch": 0.040692243140111155,
      "grad_norm": 0.21279391646385193,
      "learning_rate": 9.59307756859889e-06,
      "loss": 0.3133,
      "step": 2570
    },
    {
      "epoch": 0.04070807669775322,
      "grad_norm": 0.51209956407547,
      "learning_rate": 9.592919233022468e-06,
      "loss": 0.21,
      "step": 2571
    },
    {
      "epoch": 0.04072391025539528,
      "grad_norm": 0.31652283668518066,
      "learning_rate": 9.592760897446049e-06,
      "loss": 0.2021,
      "step": 2572
    },
    {
      "epoch": 0.040739743813037355,
      "grad_norm": 0.2642032206058502,
      "learning_rate": 9.592602561869626e-06,
      "loss": 0.1474,
      "step": 2573
    },
    {
      "epoch": 0.04075557737067942,
      "grad_norm": 0.17445725202560425,
      "learning_rate": 9.592444226293207e-06,
      "loss": 0.211,
      "step": 2574
    },
    {
      "epoch": 0.04077141092832148,
      "grad_norm": 0.22465170919895172,
      "learning_rate": 9.592285890716786e-06,
      "loss": 0.1831,
      "step": 2575
    },
    {
      "epoch": 0.040787244485963554,
      "grad_norm": 0.0027124362532049417,
      "learning_rate": 9.592127555140365e-06,
      "loss": 0.0,
      "step": 2576
    },
    {
      "epoch": 0.04080307804360562,
      "grad_norm": 0.1547963172197342,
      "learning_rate": 9.591969219563944e-06,
      "loss": 0.0702,
      "step": 2577
    },
    {
      "epoch": 0.04081891160124768,
      "grad_norm": 0.17449209094047546,
      "learning_rate": 9.591810883987524e-06,
      "loss": 0.0961,
      "step": 2578
    },
    {
      "epoch": 0.040834745158889754,
      "grad_norm": 0.15342983603477478,
      "learning_rate": 9.591652548411103e-06,
      "loss": 0.1419,
      "step": 2579
    },
    {
      "epoch": 0.04085057871653182,
      "grad_norm": 0.010570096783339977,
      "learning_rate": 9.591494212834682e-06,
      "loss": 0.0006,
      "step": 2580
    },
    {
      "epoch": 0.04086641227417388,
      "grad_norm": 0.010522767901420593,
      "learning_rate": 9.591335877258262e-06,
      "loss": 0.0006,
      "step": 2581
    },
    {
      "epoch": 0.040882245831815954,
      "grad_norm": 0.007827337831258774,
      "learning_rate": 9.591177541681842e-06,
      "loss": 0.0004,
      "step": 2582
    },
    {
      "epoch": 0.04089807938945802,
      "grad_norm": 0.2741861343383789,
      "learning_rate": 9.59101920610542e-06,
      "loss": 0.0931,
      "step": 2583
    },
    {
      "epoch": 0.04091391294710008,
      "grad_norm": 0.39982178807258606,
      "learning_rate": 9.590860870529e-06,
      "loss": 0.0785,
      "step": 2584
    },
    {
      "epoch": 0.040929746504742154,
      "grad_norm": 0.1969478875398636,
      "learning_rate": 9.590702534952579e-06,
      "loss": 0.3825,
      "step": 2585
    },
    {
      "epoch": 0.04094558006238422,
      "grad_norm": 0.43267831206321716,
      "learning_rate": 9.590544199376158e-06,
      "loss": 0.5673,
      "step": 2586
    },
    {
      "epoch": 0.04096141362002628,
      "grad_norm": 0.15592710673809052,
      "learning_rate": 9.590385863799739e-06,
      "loss": 0.0507,
      "step": 2587
    },
    {
      "epoch": 0.040977247177668354,
      "grad_norm": 0.04084897041320801,
      "learning_rate": 9.590227528223318e-06,
      "loss": 0.0024,
      "step": 2588
    },
    {
      "epoch": 0.04099308073531042,
      "grad_norm": 0.25267380475997925,
      "learning_rate": 9.590069192646897e-06,
      "loss": 0.0312,
      "step": 2589
    },
    {
      "epoch": 0.04100891429295248,
      "grad_norm": 0.15442074835300446,
      "learning_rate": 9.589910857070476e-06,
      "loss": 0.0687,
      "step": 2590
    },
    {
      "epoch": 0.04102474785059455,
      "grad_norm": 0.20196907222270966,
      "learning_rate": 9.589752521494055e-06,
      "loss": 0.5227,
      "step": 2591
    },
    {
      "epoch": 0.04104058140823662,
      "grad_norm": 0.0068452367559075356,
      "learning_rate": 9.589594185917634e-06,
      "loss": 0.0004,
      "step": 2592
    },
    {
      "epoch": 0.04105641496587868,
      "grad_norm": 6.048022987670265e-05,
      "learning_rate": 9.589435850341215e-06,
      "loss": 0.0,
      "step": 2593
    },
    {
      "epoch": 0.04107224852352075,
      "grad_norm": 0.2348337024450302,
      "learning_rate": 9.589277514764794e-06,
      "loss": 0.0426,
      "step": 2594
    },
    {
      "epoch": 0.04108808208116282,
      "grad_norm": 0.05638828128576279,
      "learning_rate": 9.589119179188373e-06,
      "loss": 0.0019,
      "step": 2595
    },
    {
      "epoch": 0.04110391563880488,
      "grad_norm": 0.13468578457832336,
      "learning_rate": 9.588960843611952e-06,
      "loss": 0.1077,
      "step": 2596
    },
    {
      "epoch": 0.04111974919644695,
      "grad_norm": 8.15145467640832e-05,
      "learning_rate": 9.588802508035531e-06,
      "loss": 0.0,
      "step": 2597
    },
    {
      "epoch": 0.04113558275408902,
      "grad_norm": 0.002264331793412566,
      "learning_rate": 9.58864417245911e-06,
      "loss": 0.0001,
      "step": 2598
    },
    {
      "epoch": 0.04115141631173108,
      "grad_norm": 0.16689103841781616,
      "learning_rate": 9.58848583688269e-06,
      "loss": 0.2602,
      "step": 2599
    },
    {
      "epoch": 0.04116724986937315,
      "grad_norm": 0.29931795597076416,
      "learning_rate": 9.58832750130627e-06,
      "loss": 0.4952,
      "step": 2600
    },
    {
      "epoch": 0.04118308342701522,
      "grad_norm": 8.708496898179874e-05,
      "learning_rate": 9.588169165729847e-06,
      "loss": 0.0,
      "step": 2601
    },
    {
      "epoch": 0.04119891698465728,
      "grad_norm": 0.38029980659484863,
      "learning_rate": 9.588010830153428e-06,
      "loss": 0.2799,
      "step": 2602
    },
    {
      "epoch": 0.04121475054229935,
      "grad_norm": 0.01594998687505722,
      "learning_rate": 9.587852494577007e-06,
      "loss": 0.0011,
      "step": 2603
    },
    {
      "epoch": 0.04123058409994142,
      "grad_norm": 0.11272268742322922,
      "learning_rate": 9.587694159000586e-06,
      "loss": 0.0818,
      "step": 2604
    },
    {
      "epoch": 0.04124641765758348,
      "grad_norm": 0.5537500381469727,
      "learning_rate": 9.587535823424165e-06,
      "loss": 0.2133,
      "step": 2605
    },
    {
      "epoch": 0.04126225121522555,
      "grad_norm": 0.16561102867126465,
      "learning_rate": 9.587377487847746e-06,
      "loss": 0.0361,
      "step": 2606
    },
    {
      "epoch": 0.04127808477286762,
      "grad_norm": 0.20604878664016724,
      "learning_rate": 9.587219152271324e-06,
      "loss": 0.1191,
      "step": 2607
    },
    {
      "epoch": 0.04129391833050968,
      "grad_norm": 0.2670052945613861,
      "learning_rate": 9.587060816694904e-06,
      "loss": 0.021,
      "step": 2608
    },
    {
      "epoch": 0.04130975188815175,
      "grad_norm": 0.20050935447216034,
      "learning_rate": 9.586902481118483e-06,
      "loss": 0.3827,
      "step": 2609
    },
    {
      "epoch": 0.04132558544579382,
      "grad_norm": 0.01898265816271305,
      "learning_rate": 9.586744145542063e-06,
      "loss": 0.0014,
      "step": 2610
    },
    {
      "epoch": 0.04134141900343588,
      "grad_norm": 0.34561964869499207,
      "learning_rate": 9.586585809965642e-06,
      "loss": 0.0056,
      "step": 2611
    },
    {
      "epoch": 0.04135725256107795,
      "grad_norm": 0.3642352521419525,
      "learning_rate": 9.586427474389222e-06,
      "loss": 0.2062,
      "step": 2612
    },
    {
      "epoch": 0.041373086118720016,
      "grad_norm": 0.22316952049732208,
      "learning_rate": 9.5862691388128e-06,
      "loss": 0.1133,
      "step": 2613
    },
    {
      "epoch": 0.04138891967636208,
      "grad_norm": 0.5638969540596008,
      "learning_rate": 9.58611080323638e-06,
      "loss": 0.2075,
      "step": 2614
    },
    {
      "epoch": 0.041404753234004145,
      "grad_norm": 0.1916263997554779,
      "learning_rate": 9.58595246765996e-06,
      "loss": 0.0974,
      "step": 2615
    },
    {
      "epoch": 0.041420586791646216,
      "grad_norm": 0.26548877358436584,
      "learning_rate": 9.585794132083539e-06,
      "loss": 0.0551,
      "step": 2616
    },
    {
      "epoch": 0.04143642034928828,
      "grad_norm": 0.1715630143880844,
      "learning_rate": 9.585635796507118e-06,
      "loss": 0.377,
      "step": 2617
    },
    {
      "epoch": 0.041452253906930345,
      "grad_norm": 0.043593261390924454,
      "learning_rate": 9.585477460930699e-06,
      "loss": 0.0065,
      "step": 2618
    },
    {
      "epoch": 0.041468087464572416,
      "grad_norm": 0.004518034867942333,
      "learning_rate": 9.585319125354276e-06,
      "loss": 0.0002,
      "step": 2619
    },
    {
      "epoch": 0.04148392102221448,
      "grad_norm": 0.41492533683776855,
      "learning_rate": 9.585160789777857e-06,
      "loss": 0.4926,
      "step": 2620
    },
    {
      "epoch": 0.041499754579856545,
      "grad_norm": 0.00010281663708155975,
      "learning_rate": 9.585002454201436e-06,
      "loss": 0.0,
      "step": 2621
    },
    {
      "epoch": 0.041515588137498616,
      "grad_norm": 0.17002147436141968,
      "learning_rate": 9.584844118625015e-06,
      "loss": 0.1452,
      "step": 2622
    },
    {
      "epoch": 0.04153142169514068,
      "grad_norm": 0.13410978019237518,
      "learning_rate": 9.584685783048594e-06,
      "loss": 0.1197,
      "step": 2623
    },
    {
      "epoch": 0.041547255252782744,
      "grad_norm": 0.0001711233489913866,
      "learning_rate": 9.584527447472173e-06,
      "loss": 0.0,
      "step": 2624
    },
    {
      "epoch": 0.041563088810424816,
      "grad_norm": 0.00020839407807216048,
      "learning_rate": 9.584369111895752e-06,
      "loss": 0.0,
      "step": 2625
    },
    {
      "epoch": 0.04157892236806688,
      "grad_norm": 0.28710126876831055,
      "learning_rate": 9.584210776319331e-06,
      "loss": 0.0757,
      "step": 2626
    },
    {
      "epoch": 0.041594755925708944,
      "grad_norm": 0.2346828132867813,
      "learning_rate": 9.584052440742912e-06,
      "loss": 0.1284,
      "step": 2627
    },
    {
      "epoch": 0.041610589483351015,
      "grad_norm": 0.182534322142601,
      "learning_rate": 9.583894105166491e-06,
      "loss": 0.3343,
      "step": 2628
    },
    {
      "epoch": 0.04162642304099308,
      "grad_norm": 8.058928506216034e-05,
      "learning_rate": 9.58373576959007e-06,
      "loss": 0.0,
      "step": 2629
    },
    {
      "epoch": 0.041642256598635144,
      "grad_norm": 0.11963587999343872,
      "learning_rate": 9.58357743401365e-06,
      "loss": 0.0363,
      "step": 2630
    },
    {
      "epoch": 0.041658090156277215,
      "grad_norm": 0.31556791067123413,
      "learning_rate": 9.583419098437228e-06,
      "loss": 1.1183,
      "step": 2631
    },
    {
      "epoch": 0.04167392371391928,
      "grad_norm": 0.30077436566352844,
      "learning_rate": 9.583260762860807e-06,
      "loss": 0.1787,
      "step": 2632
    },
    {
      "epoch": 0.041689757271561344,
      "grad_norm": 0.13405272364616394,
      "learning_rate": 9.583102427284388e-06,
      "loss": 0.0092,
      "step": 2633
    },
    {
      "epoch": 0.041705590829203415,
      "grad_norm": 4.9203456001123413e-05,
      "learning_rate": 9.582944091707966e-06,
      "loss": 0.0,
      "step": 2634
    },
    {
      "epoch": 0.04172142438684548,
      "grad_norm": 0.007636163849383593,
      "learning_rate": 9.582785756131546e-06,
      "loss": 0.0004,
      "step": 2635
    },
    {
      "epoch": 0.041737257944487544,
      "grad_norm": 0.002769327722489834,
      "learning_rate": 9.582627420555125e-06,
      "loss": 0.0002,
      "step": 2636
    },
    {
      "epoch": 0.041753091502129615,
      "grad_norm": 0.006315050646662712,
      "learning_rate": 9.582469084978704e-06,
      "loss": 0.0004,
      "step": 2637
    },
    {
      "epoch": 0.04176892505977168,
      "grad_norm": 0.0061051626689732075,
      "learning_rate": 9.582310749402284e-06,
      "loss": 0.0004,
      "step": 2638
    },
    {
      "epoch": 0.04178475861741374,
      "grad_norm": 0.01361195556819439,
      "learning_rate": 9.582152413825864e-06,
      "loss": 0.0009,
      "step": 2639
    },
    {
      "epoch": 0.041800592175055815,
      "grad_norm": 0.22000178694725037,
      "learning_rate": 9.581994078249442e-06,
      "loss": 0.1348,
      "step": 2640
    },
    {
      "epoch": 0.04181642573269788,
      "grad_norm": 0.3439115881919861,
      "learning_rate": 9.581835742673022e-06,
      "loss": 0.3497,
      "step": 2641
    },
    {
      "epoch": 0.04183225929033994,
      "grad_norm": 0.3751281499862671,
      "learning_rate": 9.581677407096602e-06,
      "loss": 0.2981,
      "step": 2642
    },
    {
      "epoch": 0.041848092847982014,
      "grad_norm": 4.8128142225323245e-05,
      "learning_rate": 9.58151907152018e-06,
      "loss": 0.0,
      "step": 2643
    },
    {
      "epoch": 0.04186392640562408,
      "grad_norm": 0.29601484537124634,
      "learning_rate": 9.58136073594376e-06,
      "loss": 0.2484,
      "step": 2644
    },
    {
      "epoch": 0.04187975996326614,
      "grad_norm": 0.2332678884267807,
      "learning_rate": 9.58120240036734e-06,
      "loss": 0.1329,
      "step": 2645
    },
    {
      "epoch": 0.041895593520908214,
      "grad_norm": 0.08757971972227097,
      "learning_rate": 9.581044064790918e-06,
      "loss": 0.0161,
      "step": 2646
    },
    {
      "epoch": 0.04191142707855028,
      "grad_norm": 0.26028627157211304,
      "learning_rate": 9.580885729214497e-06,
      "loss": 0.2642,
      "step": 2647
    },
    {
      "epoch": 0.04192726063619234,
      "grad_norm": 0.24442645907402039,
      "learning_rate": 9.580727393638078e-06,
      "loss": 0.2198,
      "step": 2648
    },
    {
      "epoch": 0.041943094193834414,
      "grad_norm": 0.33582398295402527,
      "learning_rate": 9.580569058061657e-06,
      "loss": 0.2068,
      "step": 2649
    },
    {
      "epoch": 0.04195892775147648,
      "grad_norm": 0.00025594167527742684,
      "learning_rate": 9.580410722485236e-06,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 0.04197476130911854,
      "grad_norm": 0.17198149859905243,
      "learning_rate": 9.580252386908815e-06,
      "loss": 0.0531,
      "step": 2651
    },
    {
      "epoch": 0.041990594866760614,
      "grad_norm": 0.3267371952533722,
      "learning_rate": 9.580094051332394e-06,
      "loss": 0.246,
      "step": 2652
    },
    {
      "epoch": 0.04200642842440268,
      "grad_norm": 0.39957213401794434,
      "learning_rate": 9.579935715755973e-06,
      "loss": 0.4662,
      "step": 2653
    },
    {
      "epoch": 0.04202226198204474,
      "grad_norm": 0.00024104792100843042,
      "learning_rate": 9.579777380179554e-06,
      "loss": 0.0,
      "step": 2654
    },
    {
      "epoch": 0.042038095539686814,
      "grad_norm": 0.19216546416282654,
      "learning_rate": 9.579619044603133e-06,
      "loss": 0.1547,
      "step": 2655
    },
    {
      "epoch": 0.04205392909732888,
      "grad_norm": 0.03235781192779541,
      "learning_rate": 9.579460709026712e-06,
      "loss": 0.001,
      "step": 2656
    },
    {
      "epoch": 0.04206976265497094,
      "grad_norm": 0.018697589635849,
      "learning_rate": 9.579302373450291e-06,
      "loss": 0.0011,
      "step": 2657
    },
    {
      "epoch": 0.04208559621261301,
      "grad_norm": 0.14728014171123505,
      "learning_rate": 9.57914403787387e-06,
      "loss": 0.0528,
      "step": 2658
    },
    {
      "epoch": 0.04210142977025508,
      "grad_norm": 0.008958518505096436,
      "learning_rate": 9.57898570229745e-06,
      "loss": 0.0006,
      "step": 2659
    },
    {
      "epoch": 0.04211726332789714,
      "grad_norm": 0.4313611090183258,
      "learning_rate": 9.57882736672103e-06,
      "loss": 0.1893,
      "step": 2660
    },
    {
      "epoch": 0.04213309688553921,
      "grad_norm": 0.1284356415271759,
      "learning_rate": 9.578669031144609e-06,
      "loss": 0.0591,
      "step": 2661
    },
    {
      "epoch": 0.04214893044318128,
      "grad_norm": 0.4918127954006195,
      "learning_rate": 9.578510695568188e-06,
      "loss": 0.2079,
      "step": 2662
    },
    {
      "epoch": 0.04216476400082334,
      "grad_norm": 0.3936024606227875,
      "learning_rate": 9.578352359991767e-06,
      "loss": 0.9095,
      "step": 2663
    },
    {
      "epoch": 0.04218059755846541,
      "grad_norm": 0.11367720365524292,
      "learning_rate": 9.578194024415346e-06,
      "loss": 0.0836,
      "step": 2664
    },
    {
      "epoch": 0.04219643111610748,
      "grad_norm": 0.15339267253875732,
      "learning_rate": 9.578035688838925e-06,
      "loss": 0.0689,
      "step": 2665
    },
    {
      "epoch": 0.04221226467374954,
      "grad_norm": 0.311454176902771,
      "learning_rate": 9.577877353262506e-06,
      "loss": 0.3897,
      "step": 2666
    },
    {
      "epoch": 0.04222809823139161,
      "grad_norm": 0.20211327075958252,
      "learning_rate": 9.577719017686085e-06,
      "loss": 0.0518,
      "step": 2667
    },
    {
      "epoch": 0.04224393178903368,
      "grad_norm": 0.19826684892177582,
      "learning_rate": 9.577560682109664e-06,
      "loss": 0.2776,
      "step": 2668
    },
    {
      "epoch": 0.04225976534667574,
      "grad_norm": 0.2610440254211426,
      "learning_rate": 9.577402346533243e-06,
      "loss": 0.2143,
      "step": 2669
    },
    {
      "epoch": 0.04227559890431781,
      "grad_norm": 0.18043845891952515,
      "learning_rate": 9.577244010956823e-06,
      "loss": 0.0578,
      "step": 2670
    },
    {
      "epoch": 0.04229143246195988,
      "grad_norm": 0.11066903173923492,
      "learning_rate": 9.577085675380402e-06,
      "loss": 0.0482,
      "step": 2671
    },
    {
      "epoch": 0.04230726601960194,
      "grad_norm": 0.004962692968547344,
      "learning_rate": 9.57692733980398e-06,
      "loss": 0.0003,
      "step": 2672
    },
    {
      "epoch": 0.04232309957724401,
      "grad_norm": 0.2547040283679962,
      "learning_rate": 9.576769004227561e-06,
      "loss": 0.3527,
      "step": 2673
    },
    {
      "epoch": 0.04233893313488608,
      "grad_norm": 0.025677554309368134,
      "learning_rate": 9.576610668651139e-06,
      "loss": 0.0019,
      "step": 2674
    },
    {
      "epoch": 0.04235476669252814,
      "grad_norm": 0.2791871726512909,
      "learning_rate": 9.57645233307472e-06,
      "loss": 0.0585,
      "step": 2675
    },
    {
      "epoch": 0.04237060025017021,
      "grad_norm": 0.16401539742946625,
      "learning_rate": 9.576293997498299e-06,
      "loss": 0.047,
      "step": 2676
    },
    {
      "epoch": 0.04238643380781228,
      "grad_norm": 0.0006163982907310128,
      "learning_rate": 9.576135661921878e-06,
      "loss": 0.0,
      "step": 2677
    },
    {
      "epoch": 0.04240226736545434,
      "grad_norm": 0.21547502279281616,
      "learning_rate": 9.575977326345457e-06,
      "loss": 0.058,
      "step": 2678
    },
    {
      "epoch": 0.04241810092309641,
      "grad_norm": 0.21695926785469055,
      "learning_rate": 9.575818990769038e-06,
      "loss": 0.1611,
      "step": 2679
    },
    {
      "epoch": 0.042433934480738476,
      "grad_norm": 0.005713543388992548,
      "learning_rate": 9.575660655192615e-06,
      "loss": 0.0003,
      "step": 2680
    },
    {
      "epoch": 0.04244976803838054,
      "grad_norm": 0.00024064072931651026,
      "learning_rate": 9.575502319616196e-06,
      "loss": 0.0,
      "step": 2681
    },
    {
      "epoch": 0.04246560159602261,
      "grad_norm": 0.2879912257194519,
      "learning_rate": 9.575343984039775e-06,
      "loss": 0.1097,
      "step": 2682
    },
    {
      "epoch": 0.042481435153664676,
      "grad_norm": 0.021065402776002884,
      "learning_rate": 9.575185648463354e-06,
      "loss": 0.0014,
      "step": 2683
    },
    {
      "epoch": 0.04249726871130674,
      "grad_norm": 0.19994617998600006,
      "learning_rate": 9.575027312886933e-06,
      "loss": 0.204,
      "step": 2684
    },
    {
      "epoch": 0.04251310226894881,
      "grad_norm": 0.1883566826581955,
      "learning_rate": 9.574868977310514e-06,
      "loss": 0.2393,
      "step": 2685
    },
    {
      "epoch": 0.042528935826590876,
      "grad_norm": 0.00015325588174164295,
      "learning_rate": 9.574710641734091e-06,
      "loss": 0.0,
      "step": 2686
    },
    {
      "epoch": 0.04254476938423294,
      "grad_norm": 0.0038900738582015038,
      "learning_rate": 9.574552306157672e-06,
      "loss": 0.0002,
      "step": 2687
    },
    {
      "epoch": 0.04256060294187501,
      "grad_norm": 0.14916305243968964,
      "learning_rate": 9.574393970581251e-06,
      "loss": 0.0325,
      "step": 2688
    },
    {
      "epoch": 0.042576436499517076,
      "grad_norm": 0.2529420256614685,
      "learning_rate": 9.57423563500483e-06,
      "loss": 0.1078,
      "step": 2689
    },
    {
      "epoch": 0.04259227005715914,
      "grad_norm": 0.13934174180030823,
      "learning_rate": 9.57407729942841e-06,
      "loss": 0.0286,
      "step": 2690
    },
    {
      "epoch": 0.04260810361480121,
      "grad_norm": 0.2961046099662781,
      "learning_rate": 9.57391896385199e-06,
      "loss": 0.8734,
      "step": 2691
    },
    {
      "epoch": 0.042623937172443276,
      "grad_norm": 0.20439966022968292,
      "learning_rate": 9.573760628275567e-06,
      "loss": 0.0746,
      "step": 2692
    },
    {
      "epoch": 0.04263977073008534,
      "grad_norm": 0.02376309409737587,
      "learning_rate": 9.573602292699148e-06,
      "loss": 0.0005,
      "step": 2693
    },
    {
      "epoch": 0.04265560428772741,
      "grad_norm": 0.21218521893024445,
      "learning_rate": 9.573443957122727e-06,
      "loss": 0.1927,
      "step": 2694
    },
    {
      "epoch": 0.042671437845369475,
      "grad_norm": 0.27903541922569275,
      "learning_rate": 9.573285621546306e-06,
      "loss": 0.2003,
      "step": 2695
    },
    {
      "epoch": 0.04268727140301154,
      "grad_norm": 0.3106652796268463,
      "learning_rate": 9.573127285969885e-06,
      "loss": 0.2141,
      "step": 2696
    },
    {
      "epoch": 0.04270310496065361,
      "grad_norm": 0.2186606526374817,
      "learning_rate": 9.572968950393464e-06,
      "loss": 0.1454,
      "step": 2697
    },
    {
      "epoch": 0.042718938518295675,
      "grad_norm": 0.017654459923505783,
      "learning_rate": 9.572810614817044e-06,
      "loss": 0.0009,
      "step": 2698
    },
    {
      "epoch": 0.04273477207593774,
      "grad_norm": 0.003853149712085724,
      "learning_rate": 9.572652279240623e-06,
      "loss": 0.0002,
      "step": 2699
    },
    {
      "epoch": 0.04275060563357981,
      "grad_norm": 0.1567426323890686,
      "learning_rate": 9.572493943664203e-06,
      "loss": 0.0255,
      "step": 2700
    },
    {
      "epoch": 0.042766439191221875,
      "grad_norm": 0.15329669415950775,
      "learning_rate": 9.57233560808778e-06,
      "loss": 0.1128,
      "step": 2701
    },
    {
      "epoch": 0.04278227274886394,
      "grad_norm": 0.3686073422431946,
      "learning_rate": 9.572177272511362e-06,
      "loss": 0.0142,
      "step": 2702
    },
    {
      "epoch": 0.04279810630650601,
      "grad_norm": 0.1691971868276596,
      "learning_rate": 9.57201893693494e-06,
      "loss": 0.0787,
      "step": 2703
    },
    {
      "epoch": 0.042813939864148075,
      "grad_norm": 0.010884175077080727,
      "learning_rate": 9.57186060135852e-06,
      "loss": 0.0007,
      "step": 2704
    },
    {
      "epoch": 0.04282977342179014,
      "grad_norm": 0.2613900303840637,
      "learning_rate": 9.571702265782099e-06,
      "loss": 0.1394,
      "step": 2705
    },
    {
      "epoch": 0.04284560697943221,
      "grad_norm": 0.13601481914520264,
      "learning_rate": 9.57154393020568e-06,
      "loss": 0.0536,
      "step": 2706
    },
    {
      "epoch": 0.042861440537074275,
      "grad_norm": 0.19938677549362183,
      "learning_rate": 9.571385594629257e-06,
      "loss": 0.2458,
      "step": 2707
    },
    {
      "epoch": 0.04287727409471634,
      "grad_norm": 0.01732606440782547,
      "learning_rate": 9.571227259052838e-06,
      "loss": 0.001,
      "step": 2708
    },
    {
      "epoch": 0.04289310765235841,
      "grad_norm": 0.18649651110172272,
      "learning_rate": 9.571068923476417e-06,
      "loss": 0.0622,
      "step": 2709
    },
    {
      "epoch": 0.042908941210000474,
      "grad_norm": 0.14929239451885223,
      "learning_rate": 9.570910587899996e-06,
      "loss": 0.0185,
      "step": 2710
    },
    {
      "epoch": 0.04292477476764254,
      "grad_norm": 0.1707276850938797,
      "learning_rate": 9.570752252323575e-06,
      "loss": 0.0726,
      "step": 2711
    },
    {
      "epoch": 0.04294060832528461,
      "grad_norm": 0.37650439143180847,
      "learning_rate": 9.570593916747156e-06,
      "loss": 0.6403,
      "step": 2712
    },
    {
      "epoch": 0.042956441882926674,
      "grad_norm": 0.003825913183391094,
      "learning_rate": 9.570435581170733e-06,
      "loss": 0.0002,
      "step": 2713
    },
    {
      "epoch": 0.04297227544056874,
      "grad_norm": 0.06294536590576172,
      "learning_rate": 9.570277245594314e-06,
      "loss": 0.0014,
      "step": 2714
    },
    {
      "epoch": 0.04298810899821081,
      "grad_norm": 0.5581181645393372,
      "learning_rate": 9.570118910017893e-06,
      "loss": 0.6624,
      "step": 2715
    },
    {
      "epoch": 0.043003942555852874,
      "grad_norm": 0.3356453478336334,
      "learning_rate": 9.569960574441472e-06,
      "loss": 0.1663,
      "step": 2716
    },
    {
      "epoch": 0.04301977611349494,
      "grad_norm": 0.38092607259750366,
      "learning_rate": 9.569802238865051e-06,
      "loss": 0.6416,
      "step": 2717
    },
    {
      "epoch": 0.04303560967113701,
      "grad_norm": 0.17050187289714813,
      "learning_rate": 9.569643903288632e-06,
      "loss": 0.0659,
      "step": 2718
    },
    {
      "epoch": 0.043051443228779074,
      "grad_norm": 9.199037594953552e-05,
      "learning_rate": 9.56948556771221e-06,
      "loss": 0.0,
      "step": 2719
    },
    {
      "epoch": 0.04306727678642114,
      "grad_norm": 0.1835985630750656,
      "learning_rate": 9.569327232135788e-06,
      "loss": 0.041,
      "step": 2720
    },
    {
      "epoch": 0.04308311034406321,
      "grad_norm": 0.4173605144023895,
      "learning_rate": 9.56916889655937e-06,
      "loss": 0.2911,
      "step": 2721
    },
    {
      "epoch": 0.043098943901705274,
      "grad_norm": 0.2690803110599518,
      "learning_rate": 9.569010560982948e-06,
      "loss": 0.1429,
      "step": 2722
    },
    {
      "epoch": 0.04311477745934734,
      "grad_norm": 0.4544312357902527,
      "learning_rate": 9.568852225406527e-06,
      "loss": 0.3522,
      "step": 2723
    },
    {
      "epoch": 0.04313061101698941,
      "grad_norm": 0.29977428913116455,
      "learning_rate": 9.568693889830106e-06,
      "loss": 0.544,
      "step": 2724
    },
    {
      "epoch": 0.04314644457463147,
      "grad_norm": 0.022271107882261276,
      "learning_rate": 9.568535554253685e-06,
      "loss": 0.0012,
      "step": 2725
    },
    {
      "epoch": 0.04316227813227354,
      "grad_norm": 0.4481164813041687,
      "learning_rate": 9.568377218677265e-06,
      "loss": 0.0478,
      "step": 2726
    },
    {
      "epoch": 0.04317811168991561,
      "grad_norm": 0.03133709728717804,
      "learning_rate": 9.568218883100845e-06,
      "loss": 0.004,
      "step": 2727
    },
    {
      "epoch": 0.04319394524755767,
      "grad_norm": 0.31357643008232117,
      "learning_rate": 9.568060547524424e-06,
      "loss": 0.217,
      "step": 2728
    },
    {
      "epoch": 0.04320977880519974,
      "grad_norm": 4.745516343973577e-05,
      "learning_rate": 9.567902211948003e-06,
      "loss": 0.0,
      "step": 2729
    },
    {
      "epoch": 0.04322561236284181,
      "grad_norm": 0.04413112625479698,
      "learning_rate": 9.567743876371583e-06,
      "loss": 0.0073,
      "step": 2730
    },
    {
      "epoch": 0.04324144592048387,
      "grad_norm": 0.018198346719145775,
      "learning_rate": 9.567585540795162e-06,
      "loss": 0.0005,
      "step": 2731
    },
    {
      "epoch": 0.04325727947812594,
      "grad_norm": 0.08935393393039703,
      "learning_rate": 9.56742720521874e-06,
      "loss": 0.0289,
      "step": 2732
    },
    {
      "epoch": 0.04327311303576801,
      "grad_norm": 0.23292501270771027,
      "learning_rate": 9.567268869642322e-06,
      "loss": 0.336,
      "step": 2733
    },
    {
      "epoch": 0.04328894659341007,
      "grad_norm": 0.22719182074069977,
      "learning_rate": 9.5671105340659e-06,
      "loss": 0.346,
      "step": 2734
    },
    {
      "epoch": 0.04330478015105214,
      "grad_norm": 0.3772391378879547,
      "learning_rate": 9.56695219848948e-06,
      "loss": 0.2638,
      "step": 2735
    },
    {
      "epoch": 0.04332061370869421,
      "grad_norm": 2.583420753479004,
      "learning_rate": 9.566793862913059e-06,
      "loss": 0.1953,
      "step": 2736
    },
    {
      "epoch": 0.04333644726633627,
      "grad_norm": 0.2346140593290329,
      "learning_rate": 9.566635527336638e-06,
      "loss": 0.0827,
      "step": 2737
    },
    {
      "epoch": 0.04335228082397834,
      "grad_norm": 0.00041683969902805984,
      "learning_rate": 9.566477191760217e-06,
      "loss": 0.0,
      "step": 2738
    },
    {
      "epoch": 0.04336811438162041,
      "grad_norm": 0.18936073780059814,
      "learning_rate": 9.566318856183798e-06,
      "loss": 0.2159,
      "step": 2739
    },
    {
      "epoch": 0.04338394793926247,
      "grad_norm": 0.257319837808609,
      "learning_rate": 9.566160520607377e-06,
      "loss": 0.2028,
      "step": 2740
    },
    {
      "epoch": 0.04339978149690454,
      "grad_norm": 0.008782237768173218,
      "learning_rate": 9.566002185030956e-06,
      "loss": 0.0005,
      "step": 2741
    },
    {
      "epoch": 0.04341561505454661,
      "grad_norm": 0.32244473695755005,
      "learning_rate": 9.565843849454535e-06,
      "loss": 0.706,
      "step": 2742
    },
    {
      "epoch": 0.04343144861218867,
      "grad_norm": 0.2701543867588043,
      "learning_rate": 9.565685513878114e-06,
      "loss": 0.189,
      "step": 2743
    },
    {
      "epoch": 0.04344728216983074,
      "grad_norm": 0.3323199152946472,
      "learning_rate": 9.565527178301693e-06,
      "loss": 0.4265,
      "step": 2744
    },
    {
      "epoch": 0.04346311572747281,
      "grad_norm": 0.1830955594778061,
      "learning_rate": 9.565368842725272e-06,
      "loss": 0.1834,
      "step": 2745
    },
    {
      "epoch": 0.04347894928511487,
      "grad_norm": 0.17021498084068298,
      "learning_rate": 9.565210507148853e-06,
      "loss": 0.2051,
      "step": 2746
    },
    {
      "epoch": 0.043494782842756936,
      "grad_norm": 0.038236528635025024,
      "learning_rate": 9.56505217157243e-06,
      "loss": 0.0037,
      "step": 2747
    },
    {
      "epoch": 0.04351061640039901,
      "grad_norm": 0.0006926608621142805,
      "learning_rate": 9.564893835996011e-06,
      "loss": 0.0,
      "step": 2748
    },
    {
      "epoch": 0.04352644995804107,
      "grad_norm": 0.2855294942855835,
      "learning_rate": 9.56473550041959e-06,
      "loss": 0.0344,
      "step": 2749
    },
    {
      "epoch": 0.043542283515683136,
      "grad_norm": 0.30252203345298767,
      "learning_rate": 9.56457716484317e-06,
      "loss": 0.5406,
      "step": 2750
    },
    {
      "epoch": 0.04355811707332521,
      "grad_norm": 0.1965821236371994,
      "learning_rate": 9.564418829266748e-06,
      "loss": 0.1323,
      "step": 2751
    },
    {
      "epoch": 0.04357395063096727,
      "grad_norm": 0.12022922188043594,
      "learning_rate": 9.564260493690329e-06,
      "loss": 0.0367,
      "step": 2752
    },
    {
      "epoch": 0.043589784188609336,
      "grad_norm": 0.0012996889417991042,
      "learning_rate": 9.564102158113906e-06,
      "loss": 0.0,
      "step": 2753
    },
    {
      "epoch": 0.04360561774625141,
      "grad_norm": 0.147008016705513,
      "learning_rate": 9.563943822537487e-06,
      "loss": 0.0668,
      "step": 2754
    },
    {
      "epoch": 0.04362145130389347,
      "grad_norm": 0.2726682722568512,
      "learning_rate": 9.563785486961066e-06,
      "loss": 0.1062,
      "step": 2755
    },
    {
      "epoch": 0.043637284861535536,
      "grad_norm": 0.0012395201483741403,
      "learning_rate": 9.563627151384645e-06,
      "loss": 0.0,
      "step": 2756
    },
    {
      "epoch": 0.04365311841917761,
      "grad_norm": 0.25314861536026,
      "learning_rate": 9.563468815808224e-06,
      "loss": 0.1565,
      "step": 2757
    },
    {
      "epoch": 0.04366895197681967,
      "grad_norm": 0.3412947654724121,
      "learning_rate": 9.563310480231804e-06,
      "loss": 0.7389,
      "step": 2758
    },
    {
      "epoch": 0.043684785534461736,
      "grad_norm": 0.20832104980945587,
      "learning_rate": 9.563152144655383e-06,
      "loss": 0.1798,
      "step": 2759
    },
    {
      "epoch": 0.04370061909210381,
      "grad_norm": 0.16770799458026886,
      "learning_rate": 9.562993809078963e-06,
      "loss": 0.1784,
      "step": 2760
    },
    {
      "epoch": 0.04371645264974587,
      "grad_norm": 0.39973869919776917,
      "learning_rate": 9.562835473502543e-06,
      "loss": 0.1373,
      "step": 2761
    },
    {
      "epoch": 0.043732286207387935,
      "grad_norm": 0.2215854525566101,
      "learning_rate": 9.562677137926122e-06,
      "loss": 0.118,
      "step": 2762
    },
    {
      "epoch": 0.04374811976503001,
      "grad_norm": 0.1571452021598816,
      "learning_rate": 9.5625188023497e-06,
      "loss": 0.2426,
      "step": 2763
    },
    {
      "epoch": 0.04376395332267207,
      "grad_norm": 0.1667812168598175,
      "learning_rate": 9.56236046677328e-06,
      "loss": 0.0408,
      "step": 2764
    },
    {
      "epoch": 0.043779786880314135,
      "grad_norm": 0.21554113924503326,
      "learning_rate": 9.562202131196859e-06,
      "loss": 0.0709,
      "step": 2765
    },
    {
      "epoch": 0.043795620437956206,
      "grad_norm": 0.4376116096973419,
      "learning_rate": 9.56204379562044e-06,
      "loss": 0.1732,
      "step": 2766
    },
    {
      "epoch": 0.04381145399559827,
      "grad_norm": 0.3162975013256073,
      "learning_rate": 9.561885460044019e-06,
      "loss": 0.0818,
      "step": 2767
    },
    {
      "epoch": 0.043827287553240335,
      "grad_norm": 0.26726415753364563,
      "learning_rate": 9.561727124467596e-06,
      "loss": 0.0928,
      "step": 2768
    },
    {
      "epoch": 0.043843121110882406,
      "grad_norm": 0.19036689400672913,
      "learning_rate": 9.561568788891177e-06,
      "loss": 0.1129,
      "step": 2769
    },
    {
      "epoch": 0.04385895466852447,
      "grad_norm": 0.22175101935863495,
      "learning_rate": 9.561410453314756e-06,
      "loss": 0.2055,
      "step": 2770
    },
    {
      "epoch": 0.043874788226166535,
      "grad_norm": 0.2795112729072571,
      "learning_rate": 9.561252117738335e-06,
      "loss": 0.3525,
      "step": 2771
    },
    {
      "epoch": 0.043890621783808606,
      "grad_norm": 0.012790955603122711,
      "learning_rate": 9.561093782161914e-06,
      "loss": 0.0008,
      "step": 2772
    },
    {
      "epoch": 0.04390645534145067,
      "grad_norm": 0.2518511712551117,
      "learning_rate": 9.560935446585495e-06,
      "loss": 0.2173,
      "step": 2773
    },
    {
      "epoch": 0.043922288899092735,
      "grad_norm": 0.14744876325130463,
      "learning_rate": 9.560777111009072e-06,
      "loss": 0.0171,
      "step": 2774
    },
    {
      "epoch": 0.043938122456734806,
      "grad_norm": 0.24569909274578094,
      "learning_rate": 9.560618775432653e-06,
      "loss": 0.0885,
      "step": 2775
    },
    {
      "epoch": 0.04395395601437687,
      "grad_norm": 0.014120809733867645,
      "learning_rate": 9.560460439856232e-06,
      "loss": 0.0008,
      "step": 2776
    },
    {
      "epoch": 0.043969789572018934,
      "grad_norm": 0.27275145053863525,
      "learning_rate": 9.560302104279811e-06,
      "loss": 0.326,
      "step": 2777
    },
    {
      "epoch": 0.043985623129661006,
      "grad_norm": 0.00025864344206638634,
      "learning_rate": 9.56014376870339e-06,
      "loss": 0.0,
      "step": 2778
    },
    {
      "epoch": 0.04400145668730307,
      "grad_norm": 0.006685313768684864,
      "learning_rate": 9.559985433126971e-06,
      "loss": 0.0005,
      "step": 2779
    },
    {
      "epoch": 0.044017290244945134,
      "grad_norm": 0.33543822169303894,
      "learning_rate": 9.559827097550548e-06,
      "loss": 0.4755,
      "step": 2780
    },
    {
      "epoch": 0.044033123802587205,
      "grad_norm": 0.2111055552959442,
      "learning_rate": 9.55966876197413e-06,
      "loss": 0.0991,
      "step": 2781
    },
    {
      "epoch": 0.04404895736022927,
      "grad_norm": 0.23333795368671417,
      "learning_rate": 9.559510426397708e-06,
      "loss": 0.0998,
      "step": 2782
    },
    {
      "epoch": 0.044064790917871334,
      "grad_norm": 0.07996624708175659,
      "learning_rate": 9.559352090821287e-06,
      "loss": 0.0329,
      "step": 2783
    },
    {
      "epoch": 0.044080624475513405,
      "grad_norm": 0.03757377341389656,
      "learning_rate": 9.559193755244866e-06,
      "loss": 0.0026,
      "step": 2784
    },
    {
      "epoch": 0.04409645803315547,
      "grad_norm": 0.557287871837616,
      "learning_rate": 9.559035419668447e-06,
      "loss": 0.4884,
      "step": 2785
    },
    {
      "epoch": 0.044112291590797534,
      "grad_norm": 0.01830420456826687,
      "learning_rate": 9.558877084092025e-06,
      "loss": 0.0009,
      "step": 2786
    },
    {
      "epoch": 0.044128125148439605,
      "grad_norm": 0.01349679660052061,
      "learning_rate": 9.558718748515605e-06,
      "loss": 0.0009,
      "step": 2787
    },
    {
      "epoch": 0.04414395870608167,
      "grad_norm": 0.21720920503139496,
      "learning_rate": 9.558560412939184e-06,
      "loss": 0.2249,
      "step": 2788
    },
    {
      "epoch": 0.044159792263723734,
      "grad_norm": 0.17132630944252014,
      "learning_rate": 9.558402077362764e-06,
      "loss": 0.0612,
      "step": 2789
    },
    {
      "epoch": 0.044175625821365805,
      "grad_norm": 0.00015691353473812342,
      "learning_rate": 9.558243741786343e-06,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 0.04419145937900787,
      "grad_norm": 9.691115701571107e-05,
      "learning_rate": 9.558085406209922e-06,
      "loss": 0.0,
      "step": 2791
    },
    {
      "epoch": 0.04420729293664993,
      "grad_norm": 0.34748661518096924,
      "learning_rate": 9.5579270706335e-06,
      "loss": 0.2821,
      "step": 2792
    },
    {
      "epoch": 0.044223126494292005,
      "grad_norm": 0.4748176038265228,
      "learning_rate": 9.55776873505708e-06,
      "loss": 0.1861,
      "step": 2793
    },
    {
      "epoch": 0.04423896005193407,
      "grad_norm": 0.13372762501239777,
      "learning_rate": 9.55761039948066e-06,
      "loss": 0.0293,
      "step": 2794
    },
    {
      "epoch": 0.04425479360957613,
      "grad_norm": 0.12676189839839935,
      "learning_rate": 9.55745206390424e-06,
      "loss": 0.0373,
      "step": 2795
    },
    {
      "epoch": 0.044270627167218204,
      "grad_norm": 0.19396494328975677,
      "learning_rate": 9.557293728327819e-06,
      "loss": 0.0772,
      "step": 2796
    },
    {
      "epoch": 0.04428646072486027,
      "grad_norm": 5.65284353797324e-05,
      "learning_rate": 9.557135392751398e-06,
      "loss": 0.0,
      "step": 2797
    },
    {
      "epoch": 0.04430229428250233,
      "grad_norm": 0.3465065360069275,
      "learning_rate": 9.556977057174977e-06,
      "loss": 0.7892,
      "step": 2798
    },
    {
      "epoch": 0.044318127840144404,
      "grad_norm": 0.011788654141128063,
      "learning_rate": 9.556818721598556e-06,
      "loss": 0.0007,
      "step": 2799
    },
    {
      "epoch": 0.04433396139778647,
      "grad_norm": 0.23117513954639435,
      "learning_rate": 9.556660386022137e-06,
      "loss": 0.1065,
      "step": 2800
    },
    {
      "epoch": 0.04434979495542853,
      "grad_norm": 0.44751402735710144,
      "learning_rate": 9.556502050445716e-06,
      "loss": 0.1986,
      "step": 2801
    },
    {
      "epoch": 0.044365628513070604,
      "grad_norm": 0.2788543701171875,
      "learning_rate": 9.556343714869295e-06,
      "loss": 0.2593,
      "step": 2802
    },
    {
      "epoch": 0.04438146207071267,
      "grad_norm": 0.16165155172348022,
      "learning_rate": 9.556185379292874e-06,
      "loss": 0.0831,
      "step": 2803
    },
    {
      "epoch": 0.04439729562835473,
      "grad_norm": 0.329475462436676,
      "learning_rate": 9.556027043716453e-06,
      "loss": 0.1452,
      "step": 2804
    },
    {
      "epoch": 0.044413129185996804,
      "grad_norm": 0.18024395406246185,
      "learning_rate": 9.555868708140032e-06,
      "loss": 0.1053,
      "step": 2805
    },
    {
      "epoch": 0.04442896274363887,
      "grad_norm": 0.16150256991386414,
      "learning_rate": 9.555710372563613e-06,
      "loss": 0.0494,
      "step": 2806
    },
    {
      "epoch": 0.04444479630128093,
      "grad_norm": 0.5298454761505127,
      "learning_rate": 9.555552036987192e-06,
      "loss": 0.1219,
      "step": 2807
    },
    {
      "epoch": 0.044460629858923004,
      "grad_norm": 0.0056101358495652676,
      "learning_rate": 9.555393701410771e-06,
      "loss": 0.0003,
      "step": 2808
    },
    {
      "epoch": 0.04447646341656507,
      "grad_norm": 0.2752605676651001,
      "learning_rate": 9.55523536583435e-06,
      "loss": 0.0995,
      "step": 2809
    },
    {
      "epoch": 0.04449229697420713,
      "grad_norm": 0.23112159967422485,
      "learning_rate": 9.55507703025793e-06,
      "loss": 0.1221,
      "step": 2810
    },
    {
      "epoch": 0.044508130531849203,
      "grad_norm": 0.2927340865135193,
      "learning_rate": 9.554918694681508e-06,
      "loss": 0.0792,
      "step": 2811
    },
    {
      "epoch": 0.04452396408949127,
      "grad_norm": 0.23062530159950256,
      "learning_rate": 9.554760359105089e-06,
      "loss": 0.1427,
      "step": 2812
    },
    {
      "epoch": 0.04453979764713333,
      "grad_norm": 0.450038343667984,
      "learning_rate": 9.554602023528668e-06,
      "loss": 0.253,
      "step": 2813
    },
    {
      "epoch": 0.0445556312047754,
      "grad_norm": 0.17358289659023285,
      "learning_rate": 9.554443687952247e-06,
      "loss": 0.0757,
      "step": 2814
    },
    {
      "epoch": 0.04457146476241747,
      "grad_norm": 0.010302543640136719,
      "learning_rate": 9.554285352375826e-06,
      "loss": 0.0005,
      "step": 2815
    },
    {
      "epoch": 0.04458729832005953,
      "grad_norm": 0.0049104951322078705,
      "learning_rate": 9.554127016799405e-06,
      "loss": 0.0003,
      "step": 2816
    },
    {
      "epoch": 0.0446031318777016,
      "grad_norm": 0.347194641828537,
      "learning_rate": 9.553968681222985e-06,
      "loss": 0.0467,
      "step": 2817
    },
    {
      "epoch": 0.04461896543534367,
      "grad_norm": 0.0032373247668147087,
      "learning_rate": 9.553810345646564e-06,
      "loss": 0.0001,
      "step": 2818
    },
    {
      "epoch": 0.04463479899298573,
      "grad_norm": 0.018724851310253143,
      "learning_rate": 9.553652010070144e-06,
      "loss": 0.001,
      "step": 2819
    },
    {
      "epoch": 0.0446506325506278,
      "grad_norm": 0.25799810886383057,
      "learning_rate": 9.553493674493722e-06,
      "loss": 0.1331,
      "step": 2820
    },
    {
      "epoch": 0.04466646610826987,
      "grad_norm": 0.285251647233963,
      "learning_rate": 9.553335338917303e-06,
      "loss": 0.279,
      "step": 2821
    },
    {
      "epoch": 0.04468229966591193,
      "grad_norm": 0.27973780035972595,
      "learning_rate": 9.553177003340882e-06,
      "loss": 0.0529,
      "step": 2822
    },
    {
      "epoch": 0.044698133223554,
      "grad_norm": 0.34280964732170105,
      "learning_rate": 9.55301866776446e-06,
      "loss": 0.206,
      "step": 2823
    },
    {
      "epoch": 0.04471396678119607,
      "grad_norm": 0.09624728560447693,
      "learning_rate": 9.55286033218804e-06,
      "loss": 0.0131,
      "step": 2824
    },
    {
      "epoch": 0.04472980033883813,
      "grad_norm": 0.34211230278015137,
      "learning_rate": 9.552701996611619e-06,
      "loss": 0.0151,
      "step": 2825
    },
    {
      "epoch": 0.0447456338964802,
      "grad_norm": 0.0005412776372395456,
      "learning_rate": 9.552543661035198e-06,
      "loss": 0.0,
      "step": 2826
    },
    {
      "epoch": 0.04476146745412227,
      "grad_norm": 0.0808369442820549,
      "learning_rate": 9.552385325458779e-06,
      "loss": 0.0018,
      "step": 2827
    },
    {
      "epoch": 0.04477730101176433,
      "grad_norm": 0.2844981253147125,
      "learning_rate": 9.552226989882358e-06,
      "loss": 0.1123,
      "step": 2828
    },
    {
      "epoch": 0.0447931345694064,
      "grad_norm": 0.2699401378631592,
      "learning_rate": 9.552068654305937e-06,
      "loss": 0.1551,
      "step": 2829
    },
    {
      "epoch": 0.04480896812704847,
      "grad_norm": 0.00021142212790437043,
      "learning_rate": 9.551910318729516e-06,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 0.04482480168469053,
      "grad_norm": 0.1498013734817505,
      "learning_rate": 9.551751983153095e-06,
      "loss": 0.0565,
      "step": 2831
    },
    {
      "epoch": 0.0448406352423326,
      "grad_norm": 0.025195498019456863,
      "learning_rate": 9.551593647576674e-06,
      "loss": 0.0017,
      "step": 2832
    },
    {
      "epoch": 0.044856468799974666,
      "grad_norm": 0.19119910895824432,
      "learning_rate": 9.551435312000255e-06,
      "loss": 0.1072,
      "step": 2833
    },
    {
      "epoch": 0.04487230235761673,
      "grad_norm": 0.22533977031707764,
      "learning_rate": 9.551276976423834e-06,
      "loss": 0.1236,
      "step": 2834
    },
    {
      "epoch": 0.0448881359152588,
      "grad_norm": 0.19382475316524506,
      "learning_rate": 9.551118640847413e-06,
      "loss": 0.0415,
      "step": 2835
    },
    {
      "epoch": 0.044903969472900866,
      "grad_norm": 0.00027974395197816193,
      "learning_rate": 9.550960305270992e-06,
      "loss": 0.0,
      "step": 2836
    },
    {
      "epoch": 0.04491980303054293,
      "grad_norm": 0.295206755399704,
      "learning_rate": 9.550801969694571e-06,
      "loss": 0.1505,
      "step": 2837
    },
    {
      "epoch": 0.044935636588185,
      "grad_norm": 0.19858390092849731,
      "learning_rate": 9.55064363411815e-06,
      "loss": 0.0961,
      "step": 2838
    },
    {
      "epoch": 0.044951470145827066,
      "grad_norm": 0.20614668726921082,
      "learning_rate": 9.550485298541731e-06,
      "loss": 0.1323,
      "step": 2839
    },
    {
      "epoch": 0.04496730370346913,
      "grad_norm": 1.903058409690857,
      "learning_rate": 9.55032696296531e-06,
      "loss": 0.1303,
      "step": 2840
    },
    {
      "epoch": 0.0449831372611112,
      "grad_norm": 0.3931833803653717,
      "learning_rate": 9.550168627388888e-06,
      "loss": 0.0686,
      "step": 2841
    },
    {
      "epoch": 0.044998970818753266,
      "grad_norm": 0.32795262336730957,
      "learning_rate": 9.550010291812468e-06,
      "loss": 0.1442,
      "step": 2842
    },
    {
      "epoch": 0.04501480437639533,
      "grad_norm": 0.13700532913208008,
      "learning_rate": 9.549851956236047e-06,
      "loss": 0.0791,
      "step": 2843
    },
    {
      "epoch": 0.0450306379340374,
      "grad_norm": 0.013507421128451824,
      "learning_rate": 9.549693620659626e-06,
      "loss": 0.0006,
      "step": 2844
    },
    {
      "epoch": 0.045046471491679466,
      "grad_norm": 0.006685621105134487,
      "learning_rate": 9.549535285083206e-06,
      "loss": 0.0003,
      "step": 2845
    },
    {
      "epoch": 0.04506230504932153,
      "grad_norm": 0.1383964866399765,
      "learning_rate": 9.549376949506786e-06,
      "loss": 0.1166,
      "step": 2846
    },
    {
      "epoch": 0.0450781386069636,
      "grad_norm": 0.2365627884864807,
      "learning_rate": 9.549218613930364e-06,
      "loss": 0.437,
      "step": 2847
    },
    {
      "epoch": 0.045093972164605665,
      "grad_norm": 0.03838960826396942,
      "learning_rate": 9.549060278353944e-06,
      "loss": 0.0033,
      "step": 2848
    },
    {
      "epoch": 0.04510980572224773,
      "grad_norm": 0.19763807952404022,
      "learning_rate": 9.548901942777524e-06,
      "loss": 0.0719,
      "step": 2849
    },
    {
      "epoch": 0.0451256392798898,
      "grad_norm": 0.38737285137176514,
      "learning_rate": 9.548743607201103e-06,
      "loss": 0.174,
      "step": 2850
    },
    {
      "epoch": 0.045141472837531865,
      "grad_norm": 0.2664961516857147,
      "learning_rate": 9.548585271624682e-06,
      "loss": 0.1701,
      "step": 2851
    },
    {
      "epoch": 0.04515730639517393,
      "grad_norm": 0.0003225266991648823,
      "learning_rate": 9.548426936048262e-06,
      "loss": 0.0,
      "step": 2852
    },
    {
      "epoch": 0.045173139952816,
      "grad_norm": 0.24461837112903595,
      "learning_rate": 9.54826860047184e-06,
      "loss": 0.1534,
      "step": 2853
    },
    {
      "epoch": 0.045188973510458065,
      "grad_norm": 0.18797600269317627,
      "learning_rate": 9.54811026489542e-06,
      "loss": 0.1083,
      "step": 2854
    },
    {
      "epoch": 0.04520480706810013,
      "grad_norm": 0.004033118020743132,
      "learning_rate": 9.547951929319e-06,
      "loss": 0.0003,
      "step": 2855
    },
    {
      "epoch": 0.0452206406257422,
      "grad_norm": 0.005762308370321989,
      "learning_rate": 9.547793593742579e-06,
      "loss": 0.0003,
      "step": 2856
    },
    {
      "epoch": 0.045236474183384265,
      "grad_norm": 0.2687215209007263,
      "learning_rate": 9.547635258166158e-06,
      "loss": 0.0194,
      "step": 2857
    },
    {
      "epoch": 0.04525230774102633,
      "grad_norm": 0.5278180837631226,
      "learning_rate": 9.547476922589739e-06,
      "loss": 0.4067,
      "step": 2858
    },
    {
      "epoch": 0.0452681412986684,
      "grad_norm": 0.30884042382240295,
      "learning_rate": 9.547318587013316e-06,
      "loss": 0.1406,
      "step": 2859
    },
    {
      "epoch": 0.045283974856310465,
      "grad_norm": 0.398542582988739,
      "learning_rate": 9.547160251436897e-06,
      "loss": 0.7493,
      "step": 2860
    },
    {
      "epoch": 0.04529980841395253,
      "grad_norm": 0.2771572768688202,
      "learning_rate": 9.547001915860476e-06,
      "loss": 0.0502,
      "step": 2861
    },
    {
      "epoch": 0.0453156419715946,
      "grad_norm": 0.22682137787342072,
      "learning_rate": 9.546843580284055e-06,
      "loss": 0.1742,
      "step": 2862
    },
    {
      "epoch": 0.045331475529236664,
      "grad_norm": 0.17098353803157806,
      "learning_rate": 9.546685244707634e-06,
      "loss": 0.0461,
      "step": 2863
    },
    {
      "epoch": 0.04534730908687873,
      "grad_norm": 0.34254124760627747,
      "learning_rate": 9.546526909131213e-06,
      "loss": 0.1905,
      "step": 2864
    },
    {
      "epoch": 0.0453631426445208,
      "grad_norm": 0.21687494218349457,
      "learning_rate": 9.546368573554792e-06,
      "loss": 0.141,
      "step": 2865
    },
    {
      "epoch": 0.045378976202162864,
      "grad_norm": 0.21754851937294006,
      "learning_rate": 9.546210237978371e-06,
      "loss": 0.1361,
      "step": 2866
    },
    {
      "epoch": 0.04539480975980493,
      "grad_norm": 0.19917048513889313,
      "learning_rate": 9.546051902401952e-06,
      "loss": 0.6767,
      "step": 2867
    },
    {
      "epoch": 0.045410643317447,
      "grad_norm": 0.0004668148176278919,
      "learning_rate": 9.545893566825531e-06,
      "loss": 0.0,
      "step": 2868
    },
    {
      "epoch": 0.045426476875089064,
      "grad_norm": 0.09884808212518692,
      "learning_rate": 9.54573523124911e-06,
      "loss": 0.0026,
      "step": 2869
    },
    {
      "epoch": 0.04544231043273113,
      "grad_norm": 0.18164880573749542,
      "learning_rate": 9.54557689567269e-06,
      "loss": 0.196,
      "step": 2870
    },
    {
      "epoch": 0.0454581439903732,
      "grad_norm": 0.26178738474845886,
      "learning_rate": 9.545418560096268e-06,
      "loss": 0.0314,
      "step": 2871
    },
    {
      "epoch": 0.045473977548015264,
      "grad_norm": 0.21623052656650543,
      "learning_rate": 9.545260224519847e-06,
      "loss": 0.1348,
      "step": 2872
    },
    {
      "epoch": 0.04548981110565733,
      "grad_norm": 0.01462891697883606,
      "learning_rate": 9.545101888943428e-06,
      "loss": 0.0006,
      "step": 2873
    },
    {
      "epoch": 0.0455056446632994,
      "grad_norm": 0.24391689896583557,
      "learning_rate": 9.544943553367007e-06,
      "loss": 0.1859,
      "step": 2874
    },
    {
      "epoch": 0.045521478220941464,
      "grad_norm": 0.34995582699775696,
      "learning_rate": 9.544785217790586e-06,
      "loss": 0.4519,
      "step": 2875
    },
    {
      "epoch": 0.04553731177858353,
      "grad_norm": 0.3748111128807068,
      "learning_rate": 9.544626882214165e-06,
      "loss": 0.5958,
      "step": 2876
    },
    {
      "epoch": 0.0455531453362256,
      "grad_norm": 0.5474520921707153,
      "learning_rate": 9.544468546637745e-06,
      "loss": 0.5191,
      "step": 2877
    },
    {
      "epoch": 0.045568978893867663,
      "grad_norm": 0.00015300085942726582,
      "learning_rate": 9.544310211061324e-06,
      "loss": 0.0,
      "step": 2878
    },
    {
      "epoch": 0.04558481245150973,
      "grad_norm": 0.1591777503490448,
      "learning_rate": 9.544151875484904e-06,
      "loss": 0.1804,
      "step": 2879
    },
    {
      "epoch": 0.0456006460091518,
      "grad_norm": 0.22560955584049225,
      "learning_rate": 9.543993539908483e-06,
      "loss": 0.1809,
      "step": 2880
    },
    {
      "epoch": 0.04561647956679386,
      "grad_norm": 0.17281842231750488,
      "learning_rate": 9.543835204332063e-06,
      "loss": 0.1005,
      "step": 2881
    },
    {
      "epoch": 0.04563231312443593,
      "grad_norm": 0.4555535912513733,
      "learning_rate": 9.543676868755642e-06,
      "loss": 0.7019,
      "step": 2882
    },
    {
      "epoch": 0.045648146682078,
      "grad_norm": 0.00959241297096014,
      "learning_rate": 9.54351853317922e-06,
      "loss": 0.0005,
      "step": 2883
    },
    {
      "epoch": 0.04566398023972006,
      "grad_norm": 0.41261374950408936,
      "learning_rate": 9.5433601976028e-06,
      "loss": 0.2093,
      "step": 2884
    },
    {
      "epoch": 0.04567981379736213,
      "grad_norm": 0.16399125754833221,
      "learning_rate": 9.54320186202638e-06,
      "loss": 0.0673,
      "step": 2885
    },
    {
      "epoch": 0.0456956473550042,
      "grad_norm": 0.28902536630630493,
      "learning_rate": 9.543043526449958e-06,
      "loss": 0.1834,
      "step": 2886
    },
    {
      "epoch": 0.04571148091264626,
      "grad_norm": 0.3018750846385956,
      "learning_rate": 9.542885190873539e-06,
      "loss": 0.2718,
      "step": 2887
    },
    {
      "epoch": 0.04572731447028833,
      "grad_norm": 0.25013411045074463,
      "learning_rate": 9.542726855297118e-06,
      "loss": 0.1321,
      "step": 2888
    },
    {
      "epoch": 0.0457431480279304,
      "grad_norm": 0.4327862858772278,
      "learning_rate": 9.542568519720697e-06,
      "loss": 0.237,
      "step": 2889
    },
    {
      "epoch": 0.04575898158557246,
      "grad_norm": 6.330360338324681e-05,
      "learning_rate": 9.542410184144276e-06,
      "loss": 0.0,
      "step": 2890
    },
    {
      "epoch": 0.04577481514321453,
      "grad_norm": 0.25905218720436096,
      "learning_rate": 9.542251848567855e-06,
      "loss": 0.4495,
      "step": 2891
    },
    {
      "epoch": 0.0457906487008566,
      "grad_norm": 3.0544877517968416e-05,
      "learning_rate": 9.542093512991434e-06,
      "loss": 0.0,
      "step": 2892
    },
    {
      "epoch": 0.04580648225849866,
      "grad_norm": 0.14059031009674072,
      "learning_rate": 9.541935177415013e-06,
      "loss": 0.0639,
      "step": 2893
    },
    {
      "epoch": 0.04582231581614073,
      "grad_norm": 0.2800884246826172,
      "learning_rate": 9.541776841838594e-06,
      "loss": 0.0298,
      "step": 2894
    },
    {
      "epoch": 0.0458381493737828,
      "grad_norm": 0.01977887935936451,
      "learning_rate": 9.541618506262173e-06,
      "loss": 0.0009,
      "step": 2895
    },
    {
      "epoch": 0.04585398293142486,
      "grad_norm": 0.17855948209762573,
      "learning_rate": 9.541460170685752e-06,
      "loss": 0.1086,
      "step": 2896
    },
    {
      "epoch": 0.04586981648906693,
      "grad_norm": 0.0001858368777902797,
      "learning_rate": 9.541301835109331e-06,
      "loss": 0.0,
      "step": 2897
    },
    {
      "epoch": 0.045885650046709,
      "grad_norm": 0.24133770167827606,
      "learning_rate": 9.54114349953291e-06,
      "loss": 0.0358,
      "step": 2898
    },
    {
      "epoch": 0.04590148360435106,
      "grad_norm": 0.023838309571146965,
      "learning_rate": 9.54098516395649e-06,
      "loss": 0.0012,
      "step": 2899
    },
    {
      "epoch": 0.045917317161993126,
      "grad_norm": 0.17994263768196106,
      "learning_rate": 9.54082682838007e-06,
      "loss": 0.0309,
      "step": 2900
    },
    {
      "epoch": 0.0459331507196352,
      "grad_norm": 0.31158167123794556,
      "learning_rate": 9.54066849280365e-06,
      "loss": 0.1819,
      "step": 2901
    },
    {
      "epoch": 0.04594898427727726,
      "grad_norm": 0.01120244711637497,
      "learning_rate": 9.540510157227228e-06,
      "loss": 0.0005,
      "step": 2902
    },
    {
      "epoch": 0.045964817834919326,
      "grad_norm": 0.0077894749119877815,
      "learning_rate": 9.540351821650807e-06,
      "loss": 0.0004,
      "step": 2903
    },
    {
      "epoch": 0.0459806513925614,
      "grad_norm": 5.957937901257537e-05,
      "learning_rate": 9.540193486074386e-06,
      "loss": 0.0,
      "step": 2904
    },
    {
      "epoch": 0.04599648495020346,
      "grad_norm": 9.51460751821287e-05,
      "learning_rate": 9.540035150497966e-06,
      "loss": 0.0,
      "step": 2905
    },
    {
      "epoch": 0.046012318507845526,
      "grad_norm": 0.018122656270861626,
      "learning_rate": 9.539876814921546e-06,
      "loss": 0.0004,
      "step": 2906
    },
    {
      "epoch": 0.0460281520654876,
      "grad_norm": 0.00697725173085928,
      "learning_rate": 9.539718479345125e-06,
      "loss": 0.0004,
      "step": 2907
    },
    {
      "epoch": 0.04604398562312966,
      "grad_norm": 0.26618248224258423,
      "learning_rate": 9.539560143768704e-06,
      "loss": 0.4889,
      "step": 2908
    },
    {
      "epoch": 0.046059819180771726,
      "grad_norm": 0.027099138125777245,
      "learning_rate": 9.539401808192284e-06,
      "loss": 0.0014,
      "step": 2909
    },
    {
      "epoch": 0.0460756527384138,
      "grad_norm": 0.1312868297100067,
      "learning_rate": 9.539243472615863e-06,
      "loss": 0.0729,
      "step": 2910
    },
    {
      "epoch": 0.04609148629605586,
      "grad_norm": 0.34934234619140625,
      "learning_rate": 9.539085137039442e-06,
      "loss": 0.2064,
      "step": 2911
    },
    {
      "epoch": 0.046107319853697926,
      "grad_norm": 0.20553472638130188,
      "learning_rate": 9.53892680146302e-06,
      "loss": 0.0466,
      "step": 2912
    },
    {
      "epoch": 0.04612315341134,
      "grad_norm": 0.30725568532943726,
      "learning_rate": 9.538768465886602e-06,
      "loss": 0.2103,
      "step": 2913
    },
    {
      "epoch": 0.04613898696898206,
      "grad_norm": 0.15818536281585693,
      "learning_rate": 9.538610130310179e-06,
      "loss": 0.0415,
      "step": 2914
    },
    {
      "epoch": 0.046154820526624125,
      "grad_norm": 0.046832069754600525,
      "learning_rate": 9.53845179473376e-06,
      "loss": 0.0001,
      "step": 2915
    },
    {
      "epoch": 0.0461706540842662,
      "grad_norm": 0.16963668167591095,
      "learning_rate": 9.538293459157339e-06,
      "loss": 0.0621,
      "step": 2916
    },
    {
      "epoch": 0.04618648764190826,
      "grad_norm": 0.046458806842565536,
      "learning_rate": 9.538135123580918e-06,
      "loss": 0.0047,
      "step": 2917
    },
    {
      "epoch": 0.046202321199550325,
      "grad_norm": 0.2370653748512268,
      "learning_rate": 9.537976788004497e-06,
      "loss": 0.2643,
      "step": 2918
    },
    {
      "epoch": 0.046218154757192396,
      "grad_norm": 0.2634598910808563,
      "learning_rate": 9.537818452428078e-06,
      "loss": 0.0531,
      "step": 2919
    },
    {
      "epoch": 0.04623398831483446,
      "grad_norm": 0.14027509093284607,
      "learning_rate": 9.537660116851655e-06,
      "loss": 0.0575,
      "step": 2920
    },
    {
      "epoch": 0.046249821872476525,
      "grad_norm": 0.33724445104599,
      "learning_rate": 9.537501781275236e-06,
      "loss": 0.4181,
      "step": 2921
    },
    {
      "epoch": 0.046265655430118596,
      "grad_norm": 0.5322287082672119,
      "learning_rate": 9.537343445698815e-06,
      "loss": 0.4711,
      "step": 2922
    },
    {
      "epoch": 0.04628148898776066,
      "grad_norm": 0.0018046105979010463,
      "learning_rate": 9.537185110122394e-06,
      "loss": 0.0,
      "step": 2923
    },
    {
      "epoch": 0.046297322545402725,
      "grad_norm": 0.00010182914411416277,
      "learning_rate": 9.537026774545973e-06,
      "loss": 0.0,
      "step": 2924
    },
    {
      "epoch": 0.046313156103044796,
      "grad_norm": 0.16991287469863892,
      "learning_rate": 9.536868438969554e-06,
      "loss": 0.1252,
      "step": 2925
    },
    {
      "epoch": 0.04632898966068686,
      "grad_norm": 0.018293989822268486,
      "learning_rate": 9.536710103393131e-06,
      "loss": 0.0011,
      "step": 2926
    },
    {
      "epoch": 0.046344823218328925,
      "grad_norm": 0.23093706369400024,
      "learning_rate": 9.536551767816712e-06,
      "loss": 0.1048,
      "step": 2927
    },
    {
      "epoch": 0.046360656775970996,
      "grad_norm": 0.29460716247558594,
      "learning_rate": 9.536393432240291e-06,
      "loss": 0.1347,
      "step": 2928
    },
    {
      "epoch": 0.04637649033361306,
      "grad_norm": 0.49170172214508057,
      "learning_rate": 9.53623509666387e-06,
      "loss": 0.0797,
      "step": 2929
    },
    {
      "epoch": 0.046392323891255124,
      "grad_norm": 0.14654850959777832,
      "learning_rate": 9.53607676108745e-06,
      "loss": 0.1419,
      "step": 2930
    },
    {
      "epoch": 0.046408157448897196,
      "grad_norm": 0.557471752166748,
      "learning_rate": 9.53591842551103e-06,
      "loss": 0.2512,
      "step": 2931
    },
    {
      "epoch": 0.04642399100653926,
      "grad_norm": 0.07300570607185364,
      "learning_rate": 9.535760089934607e-06,
      "loss": 0.0047,
      "step": 2932
    },
    {
      "epoch": 0.046439824564181324,
      "grad_norm": 0.14793545007705688,
      "learning_rate": 9.535601754358188e-06,
      "loss": 0.0496,
      "step": 2933
    },
    {
      "epoch": 0.046455658121823395,
      "grad_norm": 0.33215534687042236,
      "learning_rate": 9.535443418781767e-06,
      "loss": 0.0745,
      "step": 2934
    },
    {
      "epoch": 0.04647149167946546,
      "grad_norm": 0.10338149964809418,
      "learning_rate": 9.535285083205346e-06,
      "loss": 0.0418,
      "step": 2935
    },
    {
      "epoch": 0.046487325237107524,
      "grad_norm": 0.14954257011413574,
      "learning_rate": 9.535126747628925e-06,
      "loss": 0.02,
      "step": 2936
    },
    {
      "epoch": 0.046503158794749595,
      "grad_norm": 0.12402965128421783,
      "learning_rate": 9.534968412052505e-06,
      "loss": 0.0241,
      "step": 2937
    },
    {
      "epoch": 0.04651899235239166,
      "grad_norm": 0.003415542421862483,
      "learning_rate": 9.534810076476084e-06,
      "loss": 0.0001,
      "step": 2938
    },
    {
      "epoch": 0.046534825910033724,
      "grad_norm": 0.13989220559597015,
      "learning_rate": 9.534651740899663e-06,
      "loss": 0.0358,
      "step": 2939
    },
    {
      "epoch": 0.046550659467675795,
      "grad_norm": 0.23171575367450714,
      "learning_rate": 9.534493405323243e-06,
      "loss": 0.2872,
      "step": 2940
    },
    {
      "epoch": 0.04656649302531786,
      "grad_norm": 0.3751122057437897,
      "learning_rate": 9.534335069746823e-06,
      "loss": 0.2149,
      "step": 2941
    },
    {
      "epoch": 0.046582326582959924,
      "grad_norm": 0.3500088155269623,
      "learning_rate": 9.534176734170402e-06,
      "loss": 0.1606,
      "step": 2942
    },
    {
      "epoch": 0.046598160140601995,
      "grad_norm": 0.18482773005962372,
      "learning_rate": 9.53401839859398e-06,
      "loss": 0.113,
      "step": 2943
    },
    {
      "epoch": 0.04661399369824406,
      "grad_norm": 0.13870736956596375,
      "learning_rate": 9.53386006301756e-06,
      "loss": 0.1465,
      "step": 2944
    },
    {
      "epoch": 0.046629827255886123,
      "grad_norm": 0.0150450449436903,
      "learning_rate": 9.533701727441139e-06,
      "loss": 0.0009,
      "step": 2945
    },
    {
      "epoch": 0.046645660813528195,
      "grad_norm": 0.25229591131210327,
      "learning_rate": 9.53354339186472e-06,
      "loss": 0.0072,
      "step": 2946
    },
    {
      "epoch": 0.04666149437117026,
      "grad_norm": 0.15094392001628876,
      "learning_rate": 9.533385056288299e-06,
      "loss": 0.0585,
      "step": 2947
    },
    {
      "epoch": 0.04667732792881232,
      "grad_norm": 0.004802952986210585,
      "learning_rate": 9.533226720711878e-06,
      "loss": 0.0002,
      "step": 2948
    },
    {
      "epoch": 0.046693161486454395,
      "grad_norm": 0.3786640465259552,
      "learning_rate": 9.533068385135457e-06,
      "loss": 0.1912,
      "step": 2949
    },
    {
      "epoch": 0.04670899504409646,
      "grad_norm": 0.5857585668563843,
      "learning_rate": 9.532910049559036e-06,
      "loss": 0.2698,
      "step": 2950
    },
    {
      "epoch": 0.04672482860173852,
      "grad_norm": 0.1440339833498001,
      "learning_rate": 9.532751713982615e-06,
      "loss": 0.0701,
      "step": 2951
    },
    {
      "epoch": 0.046740662159380594,
      "grad_norm": 0.667610764503479,
      "learning_rate": 9.532593378406196e-06,
      "loss": 0.0969,
      "step": 2952
    },
    {
      "epoch": 0.04675649571702266,
      "grad_norm": 0.26545676589012146,
      "learning_rate": 9.532435042829773e-06,
      "loss": 0.1186,
      "step": 2953
    },
    {
      "epoch": 0.04677232927466472,
      "grad_norm": 0.48856502771377563,
      "learning_rate": 9.532276707253354e-06,
      "loss": 0.7618,
      "step": 2954
    },
    {
      "epoch": 0.046788162832306794,
      "grad_norm": 0.24344301223754883,
      "learning_rate": 9.532118371676933e-06,
      "loss": 0.0783,
      "step": 2955
    },
    {
      "epoch": 0.04680399638994886,
      "grad_norm": 0.39275991916656494,
      "learning_rate": 9.531960036100512e-06,
      "loss": 0.2019,
      "step": 2956
    },
    {
      "epoch": 0.04681982994759092,
      "grad_norm": 0.006932069547474384,
      "learning_rate": 9.531801700524091e-06,
      "loss": 0.0003,
      "step": 2957
    },
    {
      "epoch": 0.046835663505232994,
      "grad_norm": 0.14562088251113892,
      "learning_rate": 9.531643364947672e-06,
      "loss": 0.0844,
      "step": 2958
    },
    {
      "epoch": 0.04685149706287506,
      "grad_norm": 0.3095614016056061,
      "learning_rate": 9.53148502937125e-06,
      "loss": 0.926,
      "step": 2959
    },
    {
      "epoch": 0.04686733062051712,
      "grad_norm": 0.23938240110874176,
      "learning_rate": 9.531326693794828e-06,
      "loss": 0.0691,
      "step": 2960
    },
    {
      "epoch": 0.046883164178159194,
      "grad_norm": 0.004648889880627394,
      "learning_rate": 9.53116835821841e-06,
      "loss": 0.0002,
      "step": 2961
    },
    {
      "epoch": 0.04689899773580126,
      "grad_norm": 0.33027127385139465,
      "learning_rate": 9.531010022641988e-06,
      "loss": 0.056,
      "step": 2962
    },
    {
      "epoch": 0.04691483129344332,
      "grad_norm": 0.1414068043231964,
      "learning_rate": 9.530851687065567e-06,
      "loss": 0.0836,
      "step": 2963
    },
    {
      "epoch": 0.046930664851085394,
      "grad_norm": 0.0017192171653732657,
      "learning_rate": 9.530693351489146e-06,
      "loss": 0.0,
      "step": 2964
    },
    {
      "epoch": 0.04694649840872746,
      "grad_norm": 0.36922934651374817,
      "learning_rate": 9.530535015912726e-06,
      "loss": 0.6773,
      "step": 2965
    },
    {
      "epoch": 0.04696233196636952,
      "grad_norm": 0.1855543851852417,
      "learning_rate": 9.530376680336305e-06,
      "loss": 0.0835,
      "step": 2966
    },
    {
      "epoch": 0.04697816552401159,
      "grad_norm": 0.15940004587173462,
      "learning_rate": 9.530218344759885e-06,
      "loss": 0.0343,
      "step": 2967
    },
    {
      "epoch": 0.04699399908165366,
      "grad_norm": 0.09820403903722763,
      "learning_rate": 9.530060009183464e-06,
      "loss": 0.0596,
      "step": 2968
    },
    {
      "epoch": 0.04700983263929572,
      "grad_norm": 0.00011831821029772982,
      "learning_rate": 9.529901673607044e-06,
      "loss": 0.0,
      "step": 2969
    },
    {
      "epoch": 0.04702566619693779,
      "grad_norm": 0.11373927444219589,
      "learning_rate": 9.529743338030623e-06,
      "loss": 0.0097,
      "step": 2970
    },
    {
      "epoch": 0.04704149975457986,
      "grad_norm": 0.41257521510124207,
      "learning_rate": 9.529585002454202e-06,
      "loss": 0.4177,
      "step": 2971
    },
    {
      "epoch": 0.04705733331222192,
      "grad_norm": 0.20744045078754425,
      "learning_rate": 9.52942666687778e-06,
      "loss": 0.2175,
      "step": 2972
    },
    {
      "epoch": 0.04707316686986399,
      "grad_norm": 0.009426558390259743,
      "learning_rate": 9.529268331301362e-06,
      "loss": 0.0005,
      "step": 2973
    },
    {
      "epoch": 0.04708900042750606,
      "grad_norm": 0.00012552764383144677,
      "learning_rate": 9.52910999572494e-06,
      "loss": 0.0,
      "step": 2974
    },
    {
      "epoch": 0.04710483398514812,
      "grad_norm": 0.2724049687385559,
      "learning_rate": 9.52895166014852e-06,
      "loss": 0.0934,
      "step": 2975
    },
    {
      "epoch": 0.04712066754279019,
      "grad_norm": 0.32039326429367065,
      "learning_rate": 9.528793324572099e-06,
      "loss": 0.0507,
      "step": 2976
    },
    {
      "epoch": 0.04713650110043226,
      "grad_norm": 0.23484408855438232,
      "learning_rate": 9.528634988995678e-06,
      "loss": 0.2754,
      "step": 2977
    },
    {
      "epoch": 0.04715233465807432,
      "grad_norm": 0.15278290212154388,
      "learning_rate": 9.528476653419257e-06,
      "loss": 0.052,
      "step": 2978
    },
    {
      "epoch": 0.04716816821571639,
      "grad_norm": 6.288666190812364e-05,
      "learning_rate": 9.528318317842838e-06,
      "loss": 0.0,
      "step": 2979
    },
    {
      "epoch": 0.04718400177335846,
      "grad_norm": 9.841596329351887e-05,
      "learning_rate": 9.528159982266417e-06,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 0.04719983533100052,
      "grad_norm": 0.027430014684796333,
      "learning_rate": 9.528001646689996e-06,
      "loss": 0.0018,
      "step": 2981
    },
    {
      "epoch": 0.04721566888864259,
      "grad_norm": 0.17630867660045624,
      "learning_rate": 9.527843311113575e-06,
      "loss": 0.1202,
      "step": 2982
    },
    {
      "epoch": 0.04723150244628466,
      "grad_norm": 0.12649022042751312,
      "learning_rate": 9.527684975537154e-06,
      "loss": 0.0517,
      "step": 2983
    },
    {
      "epoch": 0.04724733600392672,
      "grad_norm": 0.27394402027130127,
      "learning_rate": 9.527526639960733e-06,
      "loss": 0.1387,
      "step": 2984
    },
    {
      "epoch": 0.04726316956156879,
      "grad_norm": 0.1553238481283188,
      "learning_rate": 9.527368304384312e-06,
      "loss": 0.0867,
      "step": 2985
    },
    {
      "epoch": 0.047279003119210856,
      "grad_norm": 0.5013685822486877,
      "learning_rate": 9.527209968807893e-06,
      "loss": 0.0233,
      "step": 2986
    },
    {
      "epoch": 0.04729483667685292,
      "grad_norm": 0.5856660604476929,
      "learning_rate": 9.52705163323147e-06,
      "loss": 0.0881,
      "step": 2987
    },
    {
      "epoch": 0.04731067023449499,
      "grad_norm": 0.13950686156749725,
      "learning_rate": 9.526893297655051e-06,
      "loss": 0.0373,
      "step": 2988
    },
    {
      "epoch": 0.047326503792137056,
      "grad_norm": 0.8825330138206482,
      "learning_rate": 9.52673496207863e-06,
      "loss": 0.0673,
      "step": 2989
    },
    {
      "epoch": 0.04734233734977912,
      "grad_norm": 0.2205466330051422,
      "learning_rate": 9.52657662650221e-06,
      "loss": 0.3023,
      "step": 2990
    },
    {
      "epoch": 0.04735817090742119,
      "grad_norm": 0.18944290280342102,
      "learning_rate": 9.526418290925788e-06,
      "loss": 0.0669,
      "step": 2991
    },
    {
      "epoch": 0.047374004465063256,
      "grad_norm": 0.4592667818069458,
      "learning_rate": 9.52625995534937e-06,
      "loss": 0.201,
      "step": 2992
    },
    {
      "epoch": 0.04738983802270532,
      "grad_norm": 0.05426446720957756,
      "learning_rate": 9.526101619772947e-06,
      "loss": 0.0033,
      "step": 2993
    },
    {
      "epoch": 0.04740567158034739,
      "grad_norm": 0.33852216601371765,
      "learning_rate": 9.525943284196527e-06,
      "loss": 0.7632,
      "step": 2994
    },
    {
      "epoch": 0.047421505137989456,
      "grad_norm": 0.26885029673576355,
      "learning_rate": 9.525784948620106e-06,
      "loss": 0.1867,
      "step": 2995
    },
    {
      "epoch": 0.04743733869563152,
      "grad_norm": 0.16686640679836273,
      "learning_rate": 9.525626613043686e-06,
      "loss": 0.0893,
      "step": 2996
    },
    {
      "epoch": 0.04745317225327359,
      "grad_norm": 0.21296004951000214,
      "learning_rate": 9.525468277467265e-06,
      "loss": 0.0779,
      "step": 2997
    },
    {
      "epoch": 0.047469005810915656,
      "grad_norm": 0.14435815811157227,
      "learning_rate": 9.525309941890845e-06,
      "loss": 0.0961,
      "step": 2998
    },
    {
      "epoch": 0.04748483936855772,
      "grad_norm": 0.020931104198098183,
      "learning_rate": 9.525151606314423e-06,
      "loss": 0.0004,
      "step": 2999
    },
    {
      "epoch": 0.04750067292619979,
      "grad_norm": 0.00438942713662982,
      "learning_rate": 9.524993270738004e-06,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 0.047516506483841855,
      "grad_norm": 0.15655359625816345,
      "learning_rate": 9.524834935161583e-06,
      "loss": 0.1531,
      "step": 3001
    },
    {
      "epoch": 0.04753234004148392,
      "grad_norm": 0.17417491972446442,
      "learning_rate": 9.524676599585162e-06,
      "loss": 0.1587,
      "step": 3002
    },
    {
      "epoch": 0.04754817359912599,
      "grad_norm": 0.00957653857767582,
      "learning_rate": 9.52451826400874e-06,
      "loss": 0.0005,
      "step": 3003
    },
    {
      "epoch": 0.047564007156768055,
      "grad_norm": 0.6192219853401184,
      "learning_rate": 9.524359928432322e-06,
      "loss": 0.1094,
      "step": 3004
    },
    {
      "epoch": 0.04757984071441012,
      "grad_norm": 0.7117235064506531,
      "learning_rate": 9.524201592855899e-06,
      "loss": 0.286,
      "step": 3005
    },
    {
      "epoch": 0.04759567427205219,
      "grad_norm": 0.16470876336097717,
      "learning_rate": 9.52404325727948e-06,
      "loss": 0.3004,
      "step": 3006
    },
    {
      "epoch": 0.047611507829694255,
      "grad_norm": 0.006058920174837112,
      "learning_rate": 9.523884921703059e-06,
      "loss": 0.0004,
      "step": 3007
    },
    {
      "epoch": 0.04762734138733632,
      "grad_norm": 0.017077907919883728,
      "learning_rate": 9.523726586126638e-06,
      "loss": 0.0009,
      "step": 3008
    },
    {
      "epoch": 0.04764317494497839,
      "grad_norm": 0.3060593008995056,
      "learning_rate": 9.523568250550217e-06,
      "loss": 0.3381,
      "step": 3009
    },
    {
      "epoch": 0.047659008502620455,
      "grad_norm": 0.3540397584438324,
      "learning_rate": 9.523409914973796e-06,
      "loss": 0.6388,
      "step": 3010
    },
    {
      "epoch": 0.04767484206026252,
      "grad_norm": 0.4695564806461334,
      "learning_rate": 9.523251579397375e-06,
      "loss": 0.2671,
      "step": 3011
    },
    {
      "epoch": 0.04769067561790459,
      "grad_norm": 0.1366479992866516,
      "learning_rate": 9.523093243820954e-06,
      "loss": 0.2668,
      "step": 3012
    },
    {
      "epoch": 0.047706509175546655,
      "grad_norm": 0.21871718764305115,
      "learning_rate": 9.522934908244535e-06,
      "loss": 0.1895,
      "step": 3013
    },
    {
      "epoch": 0.04772234273318872,
      "grad_norm": 0.09199639409780502,
      "learning_rate": 9.522776572668114e-06,
      "loss": 0.0071,
      "step": 3014
    },
    {
      "epoch": 0.04773817629083079,
      "grad_norm": 0.3509499430656433,
      "learning_rate": 9.522618237091693e-06,
      "loss": 0.3342,
      "step": 3015
    },
    {
      "epoch": 0.047754009848472855,
      "grad_norm": 0.009369853883981705,
      "learning_rate": 9.522459901515272e-06,
      "loss": 0.0006,
      "step": 3016
    },
    {
      "epoch": 0.04776984340611492,
      "grad_norm": 0.0007735745166428387,
      "learning_rate": 9.522301565938851e-06,
      "loss": 0.0,
      "step": 3017
    },
    {
      "epoch": 0.04778567696375698,
      "grad_norm": 0.5139538049697876,
      "learning_rate": 9.52214323036243e-06,
      "loss": 0.1342,
      "step": 3018
    },
    {
      "epoch": 0.047801510521399054,
      "grad_norm": 0.18893016874790192,
      "learning_rate": 9.521984894786011e-06,
      "loss": 0.1776,
      "step": 3019
    },
    {
      "epoch": 0.04781734407904112,
      "grad_norm": 0.5351142287254333,
      "learning_rate": 9.521826559209588e-06,
      "loss": 0.1339,
      "step": 3020
    },
    {
      "epoch": 0.04783317763668318,
      "grad_norm": 0.20356152951717377,
      "learning_rate": 9.52166822363317e-06,
      "loss": 0.2164,
      "step": 3021
    },
    {
      "epoch": 0.047849011194325254,
      "grad_norm": 0.3547482490539551,
      "learning_rate": 9.521509888056748e-06,
      "loss": 0.0823,
      "step": 3022
    },
    {
      "epoch": 0.04786484475196732,
      "grad_norm": 0.014579687267541885,
      "learning_rate": 9.521351552480327e-06,
      "loss": 0.0009,
      "step": 3023
    },
    {
      "epoch": 0.04788067830960938,
      "grad_norm": 0.15092267096042633,
      "learning_rate": 9.521193216903907e-06,
      "loss": 0.0491,
      "step": 3024
    },
    {
      "epoch": 0.047896511867251454,
      "grad_norm": 0.18958427011966705,
      "learning_rate": 9.521034881327487e-06,
      "loss": 0.1472,
      "step": 3025
    },
    {
      "epoch": 0.04791234542489352,
      "grad_norm": 0.24437780678272247,
      "learning_rate": 9.520876545751065e-06,
      "loss": 0.1053,
      "step": 3026
    },
    {
      "epoch": 0.04792817898253558,
      "grad_norm": 0.24023526906967163,
      "learning_rate": 9.520718210174645e-06,
      "loss": 0.0426,
      "step": 3027
    },
    {
      "epoch": 0.047944012540177654,
      "grad_norm": 0.39186909794807434,
      "learning_rate": 9.520559874598225e-06,
      "loss": 0.2439,
      "step": 3028
    },
    {
      "epoch": 0.04795984609781972,
      "grad_norm": 0.01677163876593113,
      "learning_rate": 9.520401539021804e-06,
      "loss": 0.001,
      "step": 3029
    },
    {
      "epoch": 0.04797567965546178,
      "grad_norm": 0.08677788078784943,
      "learning_rate": 9.520243203445383e-06,
      "loss": 0.0148,
      "step": 3030
    },
    {
      "epoch": 0.047991513213103854,
      "grad_norm": 0.00024571697576902807,
      "learning_rate": 9.520084867868963e-06,
      "loss": 0.0,
      "step": 3031
    },
    {
      "epoch": 0.04800734677074592,
      "grad_norm": 0.2673178017139435,
      "learning_rate": 9.51992653229254e-06,
      "loss": 0.2176,
      "step": 3032
    },
    {
      "epoch": 0.04802318032838798,
      "grad_norm": 0.054302748292684555,
      "learning_rate": 9.51976819671612e-06,
      "loss": 0.0104,
      "step": 3033
    },
    {
      "epoch": 0.04803901388603005,
      "grad_norm": 0.2891137897968292,
      "learning_rate": 9.5196098611397e-06,
      "loss": 0.0738,
      "step": 3034
    },
    {
      "epoch": 0.04805484744367212,
      "grad_norm": 0.2213631421327591,
      "learning_rate": 9.51945152556328e-06,
      "loss": 0.2247,
      "step": 3035
    },
    {
      "epoch": 0.04807068100131418,
      "grad_norm": 0.31717589497566223,
      "learning_rate": 9.519293189986859e-06,
      "loss": 0.5111,
      "step": 3036
    },
    {
      "epoch": 0.04808651455895625,
      "grad_norm": 0.16830319166183472,
      "learning_rate": 9.519134854410438e-06,
      "loss": 0.0517,
      "step": 3037
    },
    {
      "epoch": 0.04810234811659832,
      "grad_norm": 0.6102517247200012,
      "learning_rate": 9.518976518834017e-06,
      "loss": 0.0482,
      "step": 3038
    },
    {
      "epoch": 0.04811818167424038,
      "grad_norm": 0.5605877041816711,
      "learning_rate": 9.518818183257596e-06,
      "loss": 1.1991,
      "step": 3039
    },
    {
      "epoch": 0.04813401523188245,
      "grad_norm": 0.2634751498699188,
      "learning_rate": 9.518659847681177e-06,
      "loss": 0.1556,
      "step": 3040
    },
    {
      "epoch": 0.04814984878952452,
      "grad_norm": 0.35085123777389526,
      "learning_rate": 9.518501512104756e-06,
      "loss": 0.2185,
      "step": 3041
    },
    {
      "epoch": 0.04816568234716658,
      "grad_norm": 2.489079713821411,
      "learning_rate": 9.518343176528335e-06,
      "loss": 0.4154,
      "step": 3042
    },
    {
      "epoch": 0.04818151590480865,
      "grad_norm": 0.00013609087909571826,
      "learning_rate": 9.518184840951914e-06,
      "loss": 0.0,
      "step": 3043
    },
    {
      "epoch": 0.04819734946245072,
      "grad_norm": 0.0009821598650887609,
      "learning_rate": 9.518026505375493e-06,
      "loss": 0.0,
      "step": 3044
    },
    {
      "epoch": 0.04821318302009278,
      "grad_norm": 0.27016809582710266,
      "learning_rate": 9.517868169799072e-06,
      "loss": 0.3205,
      "step": 3045
    },
    {
      "epoch": 0.04822901657773485,
      "grad_norm": 0.17560413479804993,
      "learning_rate": 9.517709834222653e-06,
      "loss": 0.2588,
      "step": 3046
    },
    {
      "epoch": 0.04824485013537692,
      "grad_norm": 0.005084407515823841,
      "learning_rate": 9.517551498646232e-06,
      "loss": 0.0001,
      "step": 3047
    },
    {
      "epoch": 0.04826068369301898,
      "grad_norm": 0.40671399235725403,
      "learning_rate": 9.517393163069811e-06,
      "loss": 0.2111,
      "step": 3048
    },
    {
      "epoch": 0.04827651725066105,
      "grad_norm": 0.16557271778583527,
      "learning_rate": 9.51723482749339e-06,
      "loss": 0.1425,
      "step": 3049
    },
    {
      "epoch": 0.04829235080830312,
      "grad_norm": 0.30220121145248413,
      "learning_rate": 9.51707649191697e-06,
      "loss": 0.0754,
      "step": 3050
    },
    {
      "epoch": 0.04830818436594518,
      "grad_norm": 0.21651707589626312,
      "learning_rate": 9.516918156340548e-06,
      "loss": 0.1654,
      "step": 3051
    },
    {
      "epoch": 0.04832401792358725,
      "grad_norm": 0.3105863630771637,
      "learning_rate": 9.51675982076413e-06,
      "loss": 0.0603,
      "step": 3052
    },
    {
      "epoch": 0.048339851481229316,
      "grad_norm": 0.29064568877220154,
      "learning_rate": 9.516601485187708e-06,
      "loss": 0.4784,
      "step": 3053
    },
    {
      "epoch": 0.04835568503887138,
      "grad_norm": 0.429712176322937,
      "learning_rate": 9.516443149611287e-06,
      "loss": 0.0889,
      "step": 3054
    },
    {
      "epoch": 0.04837151859651345,
      "grad_norm": 0.01725633069872856,
      "learning_rate": 9.516284814034866e-06,
      "loss": 0.0011,
      "step": 3055
    },
    {
      "epoch": 0.048387352154155516,
      "grad_norm": 0.8054636716842651,
      "learning_rate": 9.516126478458446e-06,
      "loss": 0.0286,
      "step": 3056
    },
    {
      "epoch": 0.04840318571179758,
      "grad_norm": 0.19340498745441437,
      "learning_rate": 9.515968142882025e-06,
      "loss": 0.5325,
      "step": 3057
    },
    {
      "epoch": 0.04841901926943965,
      "grad_norm": 0.012696245685219765,
      "learning_rate": 9.515809807305604e-06,
      "loss": 0.0007,
      "step": 3058
    },
    {
      "epoch": 0.048434852827081716,
      "grad_norm": 0.24621529877185822,
      "learning_rate": 9.515651471729184e-06,
      "loss": 0.0835,
      "step": 3059
    },
    {
      "epoch": 0.04845068638472378,
      "grad_norm": 0.4519304037094116,
      "learning_rate": 9.515493136152762e-06,
      "loss": 0.4467,
      "step": 3060
    },
    {
      "epoch": 0.04846651994236585,
      "grad_norm": 0.15251849591732025,
      "learning_rate": 9.515334800576343e-06,
      "loss": 0.0642,
      "step": 3061
    },
    {
      "epoch": 0.048482353500007916,
      "grad_norm": 0.1147250160574913,
      "learning_rate": 9.515176464999922e-06,
      "loss": 0.0085,
      "step": 3062
    },
    {
      "epoch": 0.04849818705764998,
      "grad_norm": 0.18574340641498566,
      "learning_rate": 9.5150181294235e-06,
      "loss": 0.0163,
      "step": 3063
    },
    {
      "epoch": 0.04851402061529205,
      "grad_norm": 0.5519943237304688,
      "learning_rate": 9.51485979384708e-06,
      "loss": 0.177,
      "step": 3064
    },
    {
      "epoch": 0.048529854172934116,
      "grad_norm": 0.40269792079925537,
      "learning_rate": 9.51470145827066e-06,
      "loss": 0.8536,
      "step": 3065
    },
    {
      "epoch": 0.04854568773057618,
      "grad_norm": 0.0003562290803529322,
      "learning_rate": 9.514543122694238e-06,
      "loss": 0.0,
      "step": 3066
    },
    {
      "epoch": 0.04856152128821825,
      "grad_norm": 0.35050928592681885,
      "learning_rate": 9.514384787117819e-06,
      "loss": 0.0154,
      "step": 3067
    },
    {
      "epoch": 0.048577354845860315,
      "grad_norm": 0.007627183571457863,
      "learning_rate": 9.514226451541398e-06,
      "loss": 0.0001,
      "step": 3068
    },
    {
      "epoch": 0.04859318840350238,
      "grad_norm": 0.01563931629061699,
      "learning_rate": 9.514068115964977e-06,
      "loss": 0.001,
      "step": 3069
    },
    {
      "epoch": 0.04860902196114445,
      "grad_norm": 0.19623027741909027,
      "learning_rate": 9.513909780388556e-06,
      "loss": 0.1816,
      "step": 3070
    },
    {
      "epoch": 0.048624855518786515,
      "grad_norm": 0.31195276975631714,
      "learning_rate": 9.513751444812137e-06,
      "loss": 0.4242,
      "step": 3071
    },
    {
      "epoch": 0.04864068907642858,
      "grad_norm": 0.15905223786830902,
      "learning_rate": 9.513593109235714e-06,
      "loss": 0.1395,
      "step": 3072
    },
    {
      "epoch": 0.04865652263407065,
      "grad_norm": 0.18144182860851288,
      "learning_rate": 9.513434773659295e-06,
      "loss": 0.2829,
      "step": 3073
    },
    {
      "epoch": 0.048672356191712715,
      "grad_norm": 0.18852011859416962,
      "learning_rate": 9.513276438082874e-06,
      "loss": 0.0393,
      "step": 3074
    },
    {
      "epoch": 0.04868818974935478,
      "grad_norm": 2.8812315464019775,
      "learning_rate": 9.513118102506453e-06,
      "loss": 0.0765,
      "step": 3075
    },
    {
      "epoch": 0.04870402330699685,
      "grad_norm": 0.38564348220825195,
      "learning_rate": 9.512959766930032e-06,
      "loss": 0.2823,
      "step": 3076
    },
    {
      "epoch": 0.048719856864638915,
      "grad_norm": 0.017638789489865303,
      "learning_rate": 9.512801431353611e-06,
      "loss": 0.0011,
      "step": 3077
    },
    {
      "epoch": 0.04873569042228098,
      "grad_norm": 1.2130943536758423,
      "learning_rate": 9.51264309577719e-06,
      "loss": 0.1521,
      "step": 3078
    },
    {
      "epoch": 0.04875152397992305,
      "grad_norm": 0.27756401896476746,
      "learning_rate": 9.512484760200771e-06,
      "loss": 0.0856,
      "step": 3079
    },
    {
      "epoch": 0.048767357537565115,
      "grad_norm": 0.17712973058223724,
      "learning_rate": 9.51232642462435e-06,
      "loss": 0.0326,
      "step": 3080
    },
    {
      "epoch": 0.04878319109520718,
      "grad_norm": 0.16688109934329987,
      "learning_rate": 9.512168089047928e-06,
      "loss": 0.174,
      "step": 3081
    },
    {
      "epoch": 0.04879902465284925,
      "grad_norm": 0.003023938275873661,
      "learning_rate": 9.512009753471508e-06,
      "loss": 0.0002,
      "step": 3082
    },
    {
      "epoch": 0.048814858210491315,
      "grad_norm": 0.3611888587474823,
      "learning_rate": 9.511851417895087e-06,
      "loss": 0.8079,
      "step": 3083
    },
    {
      "epoch": 0.04883069176813338,
      "grad_norm": 0.03097635880112648,
      "learning_rate": 9.511693082318667e-06,
      "loss": 0.0014,
      "step": 3084
    },
    {
      "epoch": 0.04884652532577545,
      "grad_norm": 0.17254841327667236,
      "learning_rate": 9.511534746742246e-06,
      "loss": 0.0727,
      "step": 3085
    },
    {
      "epoch": 0.048862358883417514,
      "grad_norm": 0.25931838154792786,
      "learning_rate": 9.511376411165826e-06,
      "loss": 0.0461,
      "step": 3086
    },
    {
      "epoch": 0.04887819244105958,
      "grad_norm": 0.23637232184410095,
      "learning_rate": 9.511218075589404e-06,
      "loss": 0.1358,
      "step": 3087
    },
    {
      "epoch": 0.04889402599870165,
      "grad_norm": 0.3239976763725281,
      "learning_rate": 9.511059740012985e-06,
      "loss": 0.4726,
      "step": 3088
    },
    {
      "epoch": 0.048909859556343714,
      "grad_norm": 0.14179566502571106,
      "learning_rate": 9.510901404436564e-06,
      "loss": 0.0341,
      "step": 3089
    },
    {
      "epoch": 0.04892569311398578,
      "grad_norm": 0.008997559547424316,
      "learning_rate": 9.510743068860143e-06,
      "loss": 0.0006,
      "step": 3090
    },
    {
      "epoch": 0.04894152667162785,
      "grad_norm": 1.2827317714691162,
      "learning_rate": 9.510584733283722e-06,
      "loss": 0.0835,
      "step": 3091
    },
    {
      "epoch": 0.048957360229269914,
      "grad_norm": 0.599227249622345,
      "learning_rate": 9.510426397707303e-06,
      "loss": 0.882,
      "step": 3092
    },
    {
      "epoch": 0.04897319378691198,
      "grad_norm": 0.4008488059043884,
      "learning_rate": 9.51026806213088e-06,
      "loss": 0.2462,
      "step": 3093
    },
    {
      "epoch": 0.04898902734455405,
      "grad_norm": 0.22888706624507904,
      "learning_rate": 9.51010972655446e-06,
      "loss": 0.2774,
      "step": 3094
    },
    {
      "epoch": 0.049004860902196114,
      "grad_norm": 4.087978231837042e-05,
      "learning_rate": 9.50995139097804e-06,
      "loss": 0.0,
      "step": 3095
    },
    {
      "epoch": 0.04902069445983818,
      "grad_norm": 0.49720266461372375,
      "learning_rate": 9.509793055401619e-06,
      "loss": 0.1131,
      "step": 3096
    },
    {
      "epoch": 0.04903652801748025,
      "grad_norm": 0.19110488891601562,
      "learning_rate": 9.509634719825198e-06,
      "loss": 0.0633,
      "step": 3097
    },
    {
      "epoch": 0.049052361575122314,
      "grad_norm": 0.3347189426422119,
      "learning_rate": 9.509476384248779e-06,
      "loss": 0.0269,
      "step": 3098
    },
    {
      "epoch": 0.04906819513276438,
      "grad_norm": 0.0172402523458004,
      "learning_rate": 9.509318048672356e-06,
      "loss": 0.0014,
      "step": 3099
    },
    {
      "epoch": 0.04908402869040645,
      "grad_norm": 0.3985386788845062,
      "learning_rate": 9.509159713095937e-06,
      "loss": 0.1819,
      "step": 3100
    },
    {
      "epoch": 0.04909986224804851,
      "grad_norm": 0.17875488102436066,
      "learning_rate": 9.509001377519516e-06,
      "loss": 0.6281,
      "step": 3101
    },
    {
      "epoch": 0.04911569580569058,
      "grad_norm": 0.01182536594569683,
      "learning_rate": 9.508843041943095e-06,
      "loss": 0.0006,
      "step": 3102
    },
    {
      "epoch": 0.04913152936333265,
      "grad_norm": 0.32133838534355164,
      "learning_rate": 9.508684706366674e-06,
      "loss": 0.3929,
      "step": 3103
    },
    {
      "epoch": 0.04914736292097471,
      "grad_norm": 0.0003403589071240276,
      "learning_rate": 9.508526370790253e-06,
      "loss": 0.0,
      "step": 3104
    },
    {
      "epoch": 0.04916319647861678,
      "grad_norm": 0.5406513810157776,
      "learning_rate": 9.508368035213832e-06,
      "loss": 0.671,
      "step": 3105
    },
    {
      "epoch": 0.04917903003625885,
      "grad_norm": 0.18342208862304688,
      "learning_rate": 9.508209699637411e-06,
      "loss": 0.1373,
      "step": 3106
    },
    {
      "epoch": 0.04919486359390091,
      "grad_norm": 0.07264930009841919,
      "learning_rate": 9.508051364060992e-06,
      "loss": 0.0041,
      "step": 3107
    },
    {
      "epoch": 0.04921069715154298,
      "grad_norm": 0.16129134595394135,
      "learning_rate": 9.507893028484571e-06,
      "loss": 0.0554,
      "step": 3108
    },
    {
      "epoch": 0.04922653070918505,
      "grad_norm": 0.21690800786018372,
      "learning_rate": 9.50773469290815e-06,
      "loss": 0.2795,
      "step": 3109
    },
    {
      "epoch": 0.04924236426682711,
      "grad_norm": 0.17201276123523712,
      "learning_rate": 9.50757635733173e-06,
      "loss": 0.1221,
      "step": 3110
    },
    {
      "epoch": 0.04925819782446918,
      "grad_norm": 0.00011049624299630523,
      "learning_rate": 9.507418021755308e-06,
      "loss": 0.0,
      "step": 3111
    },
    {
      "epoch": 0.04927403138211125,
      "grad_norm": 0.6616012454032898,
      "learning_rate": 9.507259686178888e-06,
      "loss": 0.1609,
      "step": 3112
    },
    {
      "epoch": 0.04928986493975331,
      "grad_norm": 0.3361899256706238,
      "learning_rate": 9.507101350602468e-06,
      "loss": 0.2204,
      "step": 3113
    },
    {
      "epoch": 0.04930569849739538,
      "grad_norm": 0.41792407631874084,
      "learning_rate": 9.506943015026047e-06,
      "loss": 0.8278,
      "step": 3114
    },
    {
      "epoch": 0.04932153205503745,
      "grad_norm": 0.0012434679083526134,
      "learning_rate": 9.506784679449626e-06,
      "loss": 0.0,
      "step": 3115
    },
    {
      "epoch": 0.04933736561267951,
      "grad_norm": 0.2357766330242157,
      "learning_rate": 9.506626343873206e-06,
      "loss": 0.3025,
      "step": 3116
    },
    {
      "epoch": 0.04935319917032158,
      "grad_norm": 0.1893119513988495,
      "learning_rate": 9.506468008296785e-06,
      "loss": 0.1055,
      "step": 3117
    },
    {
      "epoch": 0.04936903272796365,
      "grad_norm": 0.32703638076782227,
      "learning_rate": 9.506309672720364e-06,
      "loss": 0.2694,
      "step": 3118
    },
    {
      "epoch": 0.04938486628560571,
      "grad_norm": 0.00014658864529337734,
      "learning_rate": 9.506151337143944e-06,
      "loss": 0.0,
      "step": 3119
    },
    {
      "epoch": 0.049400699843247776,
      "grad_norm": 0.00022479734616354108,
      "learning_rate": 9.505993001567524e-06,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 0.04941653340088985,
      "grad_norm": 0.2985672056674957,
      "learning_rate": 9.505834665991103e-06,
      "loss": 0.5898,
      "step": 3121
    },
    {
      "epoch": 0.04943236695853191,
      "grad_norm": 0.0042205858044326305,
      "learning_rate": 9.505676330414682e-06,
      "loss": 0.0002,
      "step": 3122
    },
    {
      "epoch": 0.049448200516173976,
      "grad_norm": 0.14628678560256958,
      "learning_rate": 9.50551799483826e-06,
      "loss": 0.1478,
      "step": 3123
    },
    {
      "epoch": 0.04946403407381605,
      "grad_norm": 0.1705237179994583,
      "learning_rate": 9.50535965926184e-06,
      "loss": 0.0824,
      "step": 3124
    },
    {
      "epoch": 0.04947986763145811,
      "grad_norm": 0.45032426714897156,
      "learning_rate": 9.50520132368542e-06,
      "loss": 0.6356,
      "step": 3125
    },
    {
      "epoch": 0.049495701189100176,
      "grad_norm": 0.5642430782318115,
      "learning_rate": 9.505042988109e-06,
      "loss": 0.8568,
      "step": 3126
    },
    {
      "epoch": 0.04951153474674225,
      "grad_norm": 0.001285082777030766,
      "learning_rate": 9.504884652532579e-06,
      "loss": 0.0001,
      "step": 3127
    },
    {
      "epoch": 0.04952736830438431,
      "grad_norm": 0.04289797320961952,
      "learning_rate": 9.504726316956158e-06,
      "loss": 0.0013,
      "step": 3128
    },
    {
      "epoch": 0.049543201862026376,
      "grad_norm": 0.27141010761260986,
      "learning_rate": 9.504567981379737e-06,
      "loss": 0.2042,
      "step": 3129
    },
    {
      "epoch": 0.04955903541966845,
      "grad_norm": 0.1592726707458496,
      "learning_rate": 9.504409645803316e-06,
      "loss": 0.0349,
      "step": 3130
    },
    {
      "epoch": 0.04957486897731051,
      "grad_norm": 0.24662859737873077,
      "learning_rate": 9.504251310226895e-06,
      "loss": 0.0978,
      "step": 3131
    },
    {
      "epoch": 0.049590702534952576,
      "grad_norm": 0.23249000310897827,
      "learning_rate": 9.504092974650476e-06,
      "loss": 0.1661,
      "step": 3132
    },
    {
      "epoch": 0.04960653609259465,
      "grad_norm": 0.4314413070678711,
      "learning_rate": 9.503934639074053e-06,
      "loss": 0.1287,
      "step": 3133
    },
    {
      "epoch": 0.04962236965023671,
      "grad_norm": 0.1982213705778122,
      "learning_rate": 9.503776303497634e-06,
      "loss": 0.0977,
      "step": 3134
    },
    {
      "epoch": 0.049638203207878775,
      "grad_norm": 0.8761141896247864,
      "learning_rate": 9.503617967921213e-06,
      "loss": 0.0864,
      "step": 3135
    },
    {
      "epoch": 0.04965403676552085,
      "grad_norm": 0.3607306480407715,
      "learning_rate": 9.503459632344792e-06,
      "loss": 0.0092,
      "step": 3136
    },
    {
      "epoch": 0.04966987032316291,
      "grad_norm": 0.005314398091286421,
      "learning_rate": 9.503301296768371e-06,
      "loss": 0.0004,
      "step": 3137
    },
    {
      "epoch": 0.049685703880804975,
      "grad_norm": 0.000124476951896213,
      "learning_rate": 9.503142961191952e-06,
      "loss": 0.0,
      "step": 3138
    },
    {
      "epoch": 0.049701537438447047,
      "grad_norm": 0.21151581406593323,
      "learning_rate": 9.50298462561553e-06,
      "loss": 0.0318,
      "step": 3139
    },
    {
      "epoch": 0.04971737099608911,
      "grad_norm": 0.007749043870717287,
      "learning_rate": 9.50282629003911e-06,
      "loss": 0.0005,
      "step": 3140
    },
    {
      "epoch": 0.049733204553731175,
      "grad_norm": 0.3778652846813202,
      "learning_rate": 9.50266795446269e-06,
      "loss": 0.0911,
      "step": 3141
    },
    {
      "epoch": 0.049749038111373246,
      "grad_norm": 0.018177952617406845,
      "learning_rate": 9.502509618886268e-06,
      "loss": 0.0008,
      "step": 3142
    },
    {
      "epoch": 0.04976487166901531,
      "grad_norm": 0.6644328832626343,
      "learning_rate": 9.502351283309847e-06,
      "loss": 0.0535,
      "step": 3143
    },
    {
      "epoch": 0.049780705226657375,
      "grad_norm": 0.11555428802967072,
      "learning_rate": 9.502192947733427e-06,
      "loss": 0.0623,
      "step": 3144
    },
    {
      "epoch": 0.049796538784299446,
      "grad_norm": 0.8996164202690125,
      "learning_rate": 9.502034612157006e-06,
      "loss": 0.0461,
      "step": 3145
    },
    {
      "epoch": 0.04981237234194151,
      "grad_norm": 0.01570410095155239,
      "learning_rate": 9.501876276580586e-06,
      "loss": 0.0008,
      "step": 3146
    },
    {
      "epoch": 0.049828205899583575,
      "grad_norm": 0.1906139999628067,
      "learning_rate": 9.501717941004165e-06,
      "loss": 0.0555,
      "step": 3147
    },
    {
      "epoch": 0.049844039457225646,
      "grad_norm": 0.40936583280563354,
      "learning_rate": 9.501559605427745e-06,
      "loss": 0.1022,
      "step": 3148
    },
    {
      "epoch": 0.04985987301486771,
      "grad_norm": 0.34155699610710144,
      "learning_rate": 9.501401269851324e-06,
      "loss": 0.0645,
      "step": 3149
    },
    {
      "epoch": 0.049875706572509775,
      "grad_norm": 0.1477288454771042,
      "learning_rate": 9.501242934274903e-06,
      "loss": 0.0674,
      "step": 3150
    },
    {
      "epoch": 0.049891540130151846,
      "grad_norm": 0.29863715171813965,
      "learning_rate": 9.501084598698482e-06,
      "loss": 0.192,
      "step": 3151
    },
    {
      "epoch": 0.04990737368779391,
      "grad_norm": 0.00014568700862582773,
      "learning_rate": 9.500926263122061e-06,
      "loss": 0.0,
      "step": 3152
    },
    {
      "epoch": 0.049923207245435974,
      "grad_norm": 0.35376450419425964,
      "learning_rate": 9.500767927545642e-06,
      "loss": 0.4615,
      "step": 3153
    },
    {
      "epoch": 0.049939040803078046,
      "grad_norm": 0.3966400623321533,
      "learning_rate": 9.500609591969219e-06,
      "loss": 0.3249,
      "step": 3154
    },
    {
      "epoch": 0.04995487436072011,
      "grad_norm": 0.17900626361370087,
      "learning_rate": 9.5004512563928e-06,
      "loss": 0.2077,
      "step": 3155
    },
    {
      "epoch": 0.049970707918362174,
      "grad_norm": 0.025558574125170708,
      "learning_rate": 9.500292920816379e-06,
      "loss": 0.0015,
      "step": 3156
    },
    {
      "epoch": 0.049986541476004245,
      "grad_norm": 0.2722357213497162,
      "learning_rate": 9.500134585239958e-06,
      "loss": 0.0067,
      "step": 3157
    },
    {
      "epoch": 0.05000237503364631,
      "grad_norm": 0.5014975070953369,
      "learning_rate": 9.499976249663537e-06,
      "loss": 0.1813,
      "step": 3158
    },
    {
      "epoch": 0.050018208591288374,
      "grad_norm": 0.23461908102035522,
      "learning_rate": 9.499817914087118e-06,
      "loss": 0.2661,
      "step": 3159
    },
    {
      "epoch": 0.050034042148930445,
      "grad_norm": 0.0014731594128534198,
      "learning_rate": 9.499659578510695e-06,
      "loss": 0.0001,
      "step": 3160
    },
    {
      "epoch": 0.05004987570657251,
      "grad_norm": 0.2463424950838089,
      "learning_rate": 9.499501242934276e-06,
      "loss": 0.1582,
      "step": 3161
    },
    {
      "epoch": 0.050065709264214574,
      "grad_norm": 0.01805185154080391,
      "learning_rate": 9.499342907357855e-06,
      "loss": 0.0018,
      "step": 3162
    },
    {
      "epoch": 0.050081542821856645,
      "grad_norm": 0.12910188734531403,
      "learning_rate": 9.499184571781434e-06,
      "loss": 0.0311,
      "step": 3163
    },
    {
      "epoch": 0.05009737637949871,
      "grad_norm": 0.2298203557729721,
      "learning_rate": 9.499026236205013e-06,
      "loss": 0.0602,
      "step": 3164
    },
    {
      "epoch": 0.050113209937140774,
      "grad_norm": 0.25986170768737793,
      "learning_rate": 9.498867900628594e-06,
      "loss": 0.1462,
      "step": 3165
    },
    {
      "epoch": 0.050129043494782845,
      "grad_norm": 0.4068487286567688,
      "learning_rate": 9.498709565052171e-06,
      "loss": 0.0311,
      "step": 3166
    },
    {
      "epoch": 0.05014487705242491,
      "grad_norm": 0.25559723377227783,
      "learning_rate": 9.498551229475752e-06,
      "loss": 0.081,
      "step": 3167
    },
    {
      "epoch": 0.05016071061006697,
      "grad_norm": 0.4136394262313843,
      "learning_rate": 9.498392893899331e-06,
      "loss": 0.0832,
      "step": 3168
    },
    {
      "epoch": 0.050176544167709045,
      "grad_norm": 0.026620915159583092,
      "learning_rate": 9.49823455832291e-06,
      "loss": 0.0015,
      "step": 3169
    },
    {
      "epoch": 0.05019237772535111,
      "grad_norm": 5.7206591009162366e-05,
      "learning_rate": 9.49807622274649e-06,
      "loss": 0.0,
      "step": 3170
    },
    {
      "epoch": 0.05020821128299317,
      "grad_norm": 0.13230104744434357,
      "learning_rate": 9.49791788717007e-06,
      "loss": 0.0804,
      "step": 3171
    },
    {
      "epoch": 0.050224044840635244,
      "grad_norm": 0.23470769822597504,
      "learning_rate": 9.497759551593648e-06,
      "loss": 0.1752,
      "step": 3172
    },
    {
      "epoch": 0.05023987839827731,
      "grad_norm": 0.24373875558376312,
      "learning_rate": 9.497601216017228e-06,
      "loss": 0.0731,
      "step": 3173
    },
    {
      "epoch": 0.05025571195591937,
      "grad_norm": 0.0020188859198242426,
      "learning_rate": 9.497442880440807e-06,
      "loss": 0.0,
      "step": 3174
    },
    {
      "epoch": 0.050271545513561444,
      "grad_norm": 0.00012940613669343293,
      "learning_rate": 9.497284544864386e-06,
      "loss": 0.0,
      "step": 3175
    },
    {
      "epoch": 0.05028737907120351,
      "grad_norm": 0.1027422696352005,
      "learning_rate": 9.497126209287966e-06,
      "loss": 0.0494,
      "step": 3176
    },
    {
      "epoch": 0.05030321262884557,
      "grad_norm": 0.12313685566186905,
      "learning_rate": 9.496967873711545e-06,
      "loss": 0.0446,
      "step": 3177
    },
    {
      "epoch": 0.050319046186487644,
      "grad_norm": 0.023552706465125084,
      "learning_rate": 9.496809538135124e-06,
      "loss": 0.0016,
      "step": 3178
    },
    {
      "epoch": 0.05033487974412971,
      "grad_norm": 0.0641687735915184,
      "learning_rate": 9.496651202558703e-06,
      "loss": 0.0126,
      "step": 3179
    },
    {
      "epoch": 0.05035071330177177,
      "grad_norm": 0.1436343938112259,
      "learning_rate": 9.496492866982284e-06,
      "loss": 0.0328,
      "step": 3180
    },
    {
      "epoch": 0.050366546859413844,
      "grad_norm": 0.2985846698284149,
      "learning_rate": 9.496334531405863e-06,
      "loss": 0.2988,
      "step": 3181
    },
    {
      "epoch": 0.05038238041705591,
      "grad_norm": 0.535045325756073,
      "learning_rate": 9.496176195829442e-06,
      "loss": 0.144,
      "step": 3182
    },
    {
      "epoch": 0.05039821397469797,
      "grad_norm": 0.1389448046684265,
      "learning_rate": 9.49601786025302e-06,
      "loss": 0.1006,
      "step": 3183
    },
    {
      "epoch": 0.050414047532340044,
      "grad_norm": 5.86368259973824e-05,
      "learning_rate": 9.4958595246766e-06,
      "loss": 0.0,
      "step": 3184
    },
    {
      "epoch": 0.05042988108998211,
      "grad_norm": 0.11142411082983017,
      "learning_rate": 9.495701189100179e-06,
      "loss": 0.0052,
      "step": 3185
    },
    {
      "epoch": 0.05044571464762417,
      "grad_norm": 0.46392932534217834,
      "learning_rate": 9.49554285352376e-06,
      "loss": 0.277,
      "step": 3186
    },
    {
      "epoch": 0.05046154820526624,
      "grad_norm": 0.2343815118074417,
      "learning_rate": 9.495384517947339e-06,
      "loss": 0.3002,
      "step": 3187
    },
    {
      "epoch": 0.05047738176290831,
      "grad_norm": 0.08454849570989609,
      "learning_rate": 9.495226182370918e-06,
      "loss": 0.0029,
      "step": 3188
    },
    {
      "epoch": 0.05049321532055037,
      "grad_norm": 0.016998864710330963,
      "learning_rate": 9.495067846794497e-06,
      "loss": 0.0012,
      "step": 3189
    },
    {
      "epoch": 0.05050904887819244,
      "grad_norm": 0.27154839038848877,
      "learning_rate": 9.494909511218076e-06,
      "loss": 0.1641,
      "step": 3190
    },
    {
      "epoch": 0.05052488243583451,
      "grad_norm": 0.20075520873069763,
      "learning_rate": 9.494751175641655e-06,
      "loss": 0.1448,
      "step": 3191
    },
    {
      "epoch": 0.05054071599347657,
      "grad_norm": 0.36153215169906616,
      "learning_rate": 9.494592840065236e-06,
      "loss": 0.0935,
      "step": 3192
    },
    {
      "epoch": 0.05055654955111864,
      "grad_norm": 0.09807723015546799,
      "learning_rate": 9.494434504488815e-06,
      "loss": 0.0021,
      "step": 3193
    },
    {
      "epoch": 0.05057238310876071,
      "grad_norm": 0.2696293294429779,
      "learning_rate": 9.494276168912394e-06,
      "loss": 0.0782,
      "step": 3194
    },
    {
      "epoch": 0.05058821666640277,
      "grad_norm": 0.23965094983577728,
      "learning_rate": 9.494117833335973e-06,
      "loss": 0.0824,
      "step": 3195
    },
    {
      "epoch": 0.05060405022404484,
      "grad_norm": 0.37784603238105774,
      "learning_rate": 9.493959497759552e-06,
      "loss": 0.5304,
      "step": 3196
    },
    {
      "epoch": 0.05061988378168691,
      "grad_norm": 0.17517715692520142,
      "learning_rate": 9.493801162183131e-06,
      "loss": 0.0653,
      "step": 3197
    },
    {
      "epoch": 0.05063571733932897,
      "grad_norm": 0.2468690574169159,
      "learning_rate": 9.493642826606712e-06,
      "loss": 0.1272,
      "step": 3198
    },
    {
      "epoch": 0.05065155089697104,
      "grad_norm": 0.212747260928154,
      "learning_rate": 9.493484491030291e-06,
      "loss": 0.0889,
      "step": 3199
    },
    {
      "epoch": 0.05066738445461311,
      "grad_norm": 0.3448713421821594,
      "learning_rate": 9.493326155453869e-06,
      "loss": 0.1461,
      "step": 3200
    },
    {
      "epoch": 0.05068321801225517,
      "grad_norm": 0.33724445104599,
      "learning_rate": 9.49316781987745e-06,
      "loss": 0.401,
      "step": 3201
    },
    {
      "epoch": 0.05069905156989724,
      "grad_norm": 0.017139939591288567,
      "learning_rate": 9.493009484301028e-06,
      "loss": 0.001,
      "step": 3202
    },
    {
      "epoch": 0.05071488512753931,
      "grad_norm": 0.2897612750530243,
      "learning_rate": 9.492851148724607e-06,
      "loss": 0.0388,
      "step": 3203
    },
    {
      "epoch": 0.05073071868518137,
      "grad_norm": 0.3534632921218872,
      "learning_rate": 9.492692813148187e-06,
      "loss": 0.5058,
      "step": 3204
    },
    {
      "epoch": 0.05074655224282344,
      "grad_norm": 0.2766265273094177,
      "learning_rate": 9.492534477571767e-06,
      "loss": 0.3708,
      "step": 3205
    },
    {
      "epoch": 0.050762385800465507,
      "grad_norm": 0.17684240639209747,
      "learning_rate": 9.492376141995345e-06,
      "loss": 0.1223,
      "step": 3206
    },
    {
      "epoch": 0.05077821935810757,
      "grad_norm": 0.013033296912908554,
      "learning_rate": 9.492217806418925e-06,
      "loss": 0.0007,
      "step": 3207
    },
    {
      "epoch": 0.05079405291574964,
      "grad_norm": 0.08839596807956696,
      "learning_rate": 9.492059470842505e-06,
      "loss": 0.0475,
      "step": 3208
    },
    {
      "epoch": 0.050809886473391706,
      "grad_norm": 0.4594787657260895,
      "learning_rate": 9.491901135266084e-06,
      "loss": 0.6174,
      "step": 3209
    },
    {
      "epoch": 0.05082572003103377,
      "grad_norm": 0.22364073991775513,
      "learning_rate": 9.491742799689663e-06,
      "loss": 0.3781,
      "step": 3210
    },
    {
      "epoch": 0.05084155358867584,
      "grad_norm": 0.30036160349845886,
      "learning_rate": 9.491584464113242e-06,
      "loss": 0.0431,
      "step": 3211
    },
    {
      "epoch": 0.050857387146317906,
      "grad_norm": 0.17598167061805725,
      "learning_rate": 9.491426128536821e-06,
      "loss": 0.0686,
      "step": 3212
    },
    {
      "epoch": 0.05087322070395997,
      "grad_norm": 0.16938979923725128,
      "learning_rate": 9.491267792960402e-06,
      "loss": 0.0157,
      "step": 3213
    },
    {
      "epoch": 0.05088905426160204,
      "grad_norm": 0.31533822417259216,
      "learning_rate": 9.49110945738398e-06,
      "loss": 0.1636,
      "step": 3214
    },
    {
      "epoch": 0.050904887819244106,
      "grad_norm": 0.04219396784901619,
      "learning_rate": 9.49095112180756e-06,
      "loss": 0.0021,
      "step": 3215
    },
    {
      "epoch": 0.05092072137688617,
      "grad_norm": 0.6602518558502197,
      "learning_rate": 9.490792786231139e-06,
      "loss": 0.1407,
      "step": 3216
    },
    {
      "epoch": 0.05093655493452824,
      "grad_norm": 9.107076766667888e-05,
      "learning_rate": 9.490634450654718e-06,
      "loss": 0.0,
      "step": 3217
    },
    {
      "epoch": 0.050952388492170306,
      "grad_norm": 0.010486979968845844,
      "learning_rate": 9.490476115078297e-06,
      "loss": 0.0003,
      "step": 3218
    },
    {
      "epoch": 0.05096822204981237,
      "grad_norm": 0.12715575098991394,
      "learning_rate": 9.490317779501878e-06,
      "loss": 0.0826,
      "step": 3219
    },
    {
      "epoch": 0.05098405560745444,
      "grad_norm": 0.4902588427066803,
      "learning_rate": 9.490159443925457e-06,
      "loss": 0.1181,
      "step": 3220
    },
    {
      "epoch": 0.050999889165096506,
      "grad_norm": 5.550810813903809,
      "learning_rate": 9.490001108349036e-06,
      "loss": 0.5798,
      "step": 3221
    },
    {
      "epoch": 0.05101572272273857,
      "grad_norm": 0.21930167078971863,
      "learning_rate": 9.489842772772615e-06,
      "loss": 0.2395,
      "step": 3222
    },
    {
      "epoch": 0.05103155628038064,
      "grad_norm": 0.13967977464199066,
      "learning_rate": 9.489684437196194e-06,
      "loss": 0.1125,
      "step": 3223
    },
    {
      "epoch": 0.051047389838022705,
      "grad_norm": 0.4463514983654022,
      "learning_rate": 9.489526101619773e-06,
      "loss": 0.5132,
      "step": 3224
    },
    {
      "epoch": 0.05106322339566477,
      "grad_norm": 0.3006434142589569,
      "learning_rate": 9.489367766043352e-06,
      "loss": 0.3043,
      "step": 3225
    },
    {
      "epoch": 0.05107905695330684,
      "grad_norm": 0.18020592629909515,
      "learning_rate": 9.489209430466933e-06,
      "loss": 0.0736,
      "step": 3226
    },
    {
      "epoch": 0.051094890510948905,
      "grad_norm": 0.01700383424758911,
      "learning_rate": 9.48905109489051e-06,
      "loss": 0.001,
      "step": 3227
    },
    {
      "epoch": 0.05111072406859097,
      "grad_norm": 0.2986529469490051,
      "learning_rate": 9.488892759314091e-06,
      "loss": 0.1446,
      "step": 3228
    },
    {
      "epoch": 0.05112655762623304,
      "grad_norm": 0.21353980898857117,
      "learning_rate": 9.48873442373767e-06,
      "loss": 0.5168,
      "step": 3229
    },
    {
      "epoch": 0.051142391183875105,
      "grad_norm": 5.1416598580544814e-05,
      "learning_rate": 9.48857608816125e-06,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 0.05115822474151717,
      "grad_norm": 0.24821338057518005,
      "learning_rate": 9.488417752584828e-06,
      "loss": 0.1479,
      "step": 3231
    },
    {
      "epoch": 0.05117405829915924,
      "grad_norm": 0.040125250816345215,
      "learning_rate": 9.48825941700841e-06,
      "loss": 0.0122,
      "step": 3232
    },
    {
      "epoch": 0.051189891856801305,
      "grad_norm": 0.11875433474779129,
      "learning_rate": 9.488101081431987e-06,
      "loss": 0.0907,
      "step": 3233
    },
    {
      "epoch": 0.05120572541444337,
      "grad_norm": 0.10766758024692535,
      "learning_rate": 9.487942745855567e-06,
      "loss": 0.0084,
      "step": 3234
    },
    {
      "epoch": 0.05122155897208544,
      "grad_norm": 0.00023973402858246118,
      "learning_rate": 9.487784410279147e-06,
      "loss": 0.0,
      "step": 3235
    },
    {
      "epoch": 0.051237392529727505,
      "grad_norm": 0.24132026731967926,
      "learning_rate": 9.487626074702726e-06,
      "loss": 0.3363,
      "step": 3236
    },
    {
      "epoch": 0.05125322608736957,
      "grad_norm": 0.04989249259233475,
      "learning_rate": 9.487467739126305e-06,
      "loss": 0.0028,
      "step": 3237
    },
    {
      "epoch": 0.05126905964501164,
      "grad_norm": 0.30694642663002014,
      "learning_rate": 9.487309403549885e-06,
      "loss": 0.1996,
      "step": 3238
    },
    {
      "epoch": 0.051284893202653704,
      "grad_norm": 0.26589930057525635,
      "learning_rate": 9.487151067973463e-06,
      "loss": 0.2891,
      "step": 3239
    },
    {
      "epoch": 0.05130072676029577,
      "grad_norm": 0.18999530375003815,
      "learning_rate": 9.486992732397044e-06,
      "loss": 0.0931,
      "step": 3240
    },
    {
      "epoch": 0.05131656031793784,
      "grad_norm": 0.00016092939767986536,
      "learning_rate": 9.486834396820623e-06,
      "loss": 0.0,
      "step": 3241
    },
    {
      "epoch": 0.051332393875579904,
      "grad_norm": 0.25138482451438904,
      "learning_rate": 9.486676061244202e-06,
      "loss": 0.0353,
      "step": 3242
    },
    {
      "epoch": 0.05134822743322197,
      "grad_norm": 0.4328591525554657,
      "learning_rate": 9.48651772566778e-06,
      "loss": 0.2976,
      "step": 3243
    },
    {
      "epoch": 0.05136406099086404,
      "grad_norm": 0.288782000541687,
      "learning_rate": 9.486359390091362e-06,
      "loss": 0.6915,
      "step": 3244
    },
    {
      "epoch": 0.051379894548506104,
      "grad_norm": 7.006011583143845e-05,
      "learning_rate": 9.486201054514939e-06,
      "loss": 0.0,
      "step": 3245
    },
    {
      "epoch": 0.05139572810614817,
      "grad_norm": 0.11183785647153854,
      "learning_rate": 9.48604271893852e-06,
      "loss": 0.0365,
      "step": 3246
    },
    {
      "epoch": 0.05141156166379024,
      "grad_norm": 0.33772677183151245,
      "learning_rate": 9.485884383362099e-06,
      "loss": 0.1106,
      "step": 3247
    },
    {
      "epoch": 0.051427395221432304,
      "grad_norm": 0.005168743897229433,
      "learning_rate": 9.485726047785678e-06,
      "loss": 0.0003,
      "step": 3248
    },
    {
      "epoch": 0.05144322877907437,
      "grad_norm": 0.16192208230495453,
      "learning_rate": 9.485567712209257e-06,
      "loss": 0.1226,
      "step": 3249
    },
    {
      "epoch": 0.05145906233671644,
      "grad_norm": 0.15022693574428558,
      "learning_rate": 9.485409376632836e-06,
      "loss": 0.0785,
      "step": 3250
    },
    {
      "epoch": 0.051474895894358504,
      "grad_norm": 0.25439557433128357,
      "learning_rate": 9.485251041056415e-06,
      "loss": 0.0602,
      "step": 3251
    },
    {
      "epoch": 0.05149072945200057,
      "grad_norm": 0.15379786491394043,
      "learning_rate": 9.485092705479994e-06,
      "loss": 0.27,
      "step": 3252
    },
    {
      "epoch": 0.05150656300964264,
      "grad_norm": 0.1436670869588852,
      "learning_rate": 9.484934369903575e-06,
      "loss": 0.0968,
      "step": 3253
    },
    {
      "epoch": 0.0515223965672847,
      "grad_norm": 0.31809520721435547,
      "learning_rate": 9.484776034327154e-06,
      "loss": 0.2817,
      "step": 3254
    },
    {
      "epoch": 0.05153823012492677,
      "grad_norm": 0.305608332157135,
      "learning_rate": 9.484617698750733e-06,
      "loss": 0.1447,
      "step": 3255
    },
    {
      "epoch": 0.05155406368256884,
      "grad_norm": 0.26049622893333435,
      "learning_rate": 9.484459363174312e-06,
      "loss": 0.0261,
      "step": 3256
    },
    {
      "epoch": 0.0515698972402109,
      "grad_norm": 0.018240030854940414,
      "learning_rate": 9.484301027597891e-06,
      "loss": 0.0007,
      "step": 3257
    },
    {
      "epoch": 0.05158573079785297,
      "grad_norm": 0.14324644207954407,
      "learning_rate": 9.48414269202147e-06,
      "loss": 0.0639,
      "step": 3258
    },
    {
      "epoch": 0.05160156435549504,
      "grad_norm": 0.43239450454711914,
      "learning_rate": 9.483984356445051e-06,
      "loss": 0.3024,
      "step": 3259
    },
    {
      "epoch": 0.0516173979131371,
      "grad_norm": 0.4056670665740967,
      "learning_rate": 9.48382602086863e-06,
      "loss": 1.7068,
      "step": 3260
    },
    {
      "epoch": 0.05163323147077917,
      "grad_norm": 0.34010323882102966,
      "learning_rate": 9.48366768529221e-06,
      "loss": 0.0628,
      "step": 3261
    },
    {
      "epoch": 0.05164906502842124,
      "grad_norm": 0.027411669492721558,
      "learning_rate": 9.483509349715788e-06,
      "loss": 0.0019,
      "step": 3262
    },
    {
      "epoch": 0.0516648985860633,
      "grad_norm": 0.0013462714850902557,
      "learning_rate": 9.483351014139368e-06,
      "loss": 0.0,
      "step": 3263
    },
    {
      "epoch": 0.05168073214370537,
      "grad_norm": 0.23254278302192688,
      "learning_rate": 9.483192678562947e-06,
      "loss": 0.226,
      "step": 3264
    },
    {
      "epoch": 0.05169656570134744,
      "grad_norm": 0.2733146846294403,
      "learning_rate": 9.483034342986527e-06,
      "loss": 0.532,
      "step": 3265
    },
    {
      "epoch": 0.0517123992589895,
      "grad_norm": 0.1199086606502533,
      "learning_rate": 9.482876007410106e-06,
      "loss": 0.053,
      "step": 3266
    },
    {
      "epoch": 0.05172823281663157,
      "grad_norm": 0.023327408358454704,
      "learning_rate": 9.482717671833686e-06,
      "loss": 0.0015,
      "step": 3267
    },
    {
      "epoch": 0.05174406637427364,
      "grad_norm": 0.25211018323898315,
      "learning_rate": 9.482559336257265e-06,
      "loss": 0.1129,
      "step": 3268
    },
    {
      "epoch": 0.0517598999319157,
      "grad_norm": 0.025625424459576607,
      "learning_rate": 9.482401000680844e-06,
      "loss": 0.0019,
      "step": 3269
    },
    {
      "epoch": 0.05177573348955777,
      "grad_norm": 0.3084900975227356,
      "learning_rate": 9.482242665104423e-06,
      "loss": 0.2769,
      "step": 3270
    },
    {
      "epoch": 0.05179156704719984,
      "grad_norm": 0.00733152125030756,
      "learning_rate": 9.482084329528004e-06,
      "loss": 0.0005,
      "step": 3271
    },
    {
      "epoch": 0.0518074006048419,
      "grad_norm": 0.11568213254213333,
      "learning_rate": 9.481925993951581e-06,
      "loss": 0.0205,
      "step": 3272
    },
    {
      "epoch": 0.051823234162483967,
      "grad_norm": 0.10963480174541473,
      "learning_rate": 9.48176765837516e-06,
      "loss": 0.0874,
      "step": 3273
    },
    {
      "epoch": 0.05183906772012604,
      "grad_norm": 0.4192190170288086,
      "learning_rate": 9.48160932279874e-06,
      "loss": 0.1259,
      "step": 3274
    },
    {
      "epoch": 0.0518549012777681,
      "grad_norm": 0.17803265154361725,
      "learning_rate": 9.48145098722232e-06,
      "loss": 0.0819,
      "step": 3275
    },
    {
      "epoch": 0.051870734835410166,
      "grad_norm": 0.2694368362426758,
      "learning_rate": 9.481292651645899e-06,
      "loss": 0.0455,
      "step": 3276
    },
    {
      "epoch": 0.05188656839305224,
      "grad_norm": 0.6903430223464966,
      "learning_rate": 9.481134316069478e-06,
      "loss": 0.1781,
      "step": 3277
    },
    {
      "epoch": 0.0519024019506943,
      "grad_norm": 0.534539520740509,
      "learning_rate": 9.480975980493057e-06,
      "loss": 0.0629,
      "step": 3278
    },
    {
      "epoch": 0.051918235508336366,
      "grad_norm": 0.27816662192344666,
      "learning_rate": 9.480817644916636e-06,
      "loss": 0.1265,
      "step": 3279
    },
    {
      "epoch": 0.05193406906597844,
      "grad_norm": 0.06092694401741028,
      "learning_rate": 9.480659309340217e-06,
      "loss": 0.0039,
      "step": 3280
    },
    {
      "epoch": 0.0519499026236205,
      "grad_norm": 0.1854197382926941,
      "learning_rate": 9.480500973763796e-06,
      "loss": 0.2489,
      "step": 3281
    },
    {
      "epoch": 0.051965736181262566,
      "grad_norm": 0.3052445650100708,
      "learning_rate": 9.480342638187375e-06,
      "loss": 0.206,
      "step": 3282
    },
    {
      "epoch": 0.05198156973890464,
      "grad_norm": 7.029091648291796e-05,
      "learning_rate": 9.480184302610954e-06,
      "loss": 0.0,
      "step": 3283
    },
    {
      "epoch": 0.0519974032965467,
      "grad_norm": 0.2855454087257385,
      "learning_rate": 9.480025967034533e-06,
      "loss": 0.4461,
      "step": 3284
    },
    {
      "epoch": 0.052013236854188766,
      "grad_norm": 0.013667072169482708,
      "learning_rate": 9.479867631458112e-06,
      "loss": 0.0007,
      "step": 3285
    },
    {
      "epoch": 0.05202907041183084,
      "grad_norm": 0.45937997102737427,
      "learning_rate": 9.479709295881693e-06,
      "loss": 0.1698,
      "step": 3286
    },
    {
      "epoch": 0.0520449039694729,
      "grad_norm": 0.36658263206481934,
      "learning_rate": 9.479550960305272e-06,
      "loss": 0.1378,
      "step": 3287
    },
    {
      "epoch": 0.052060737527114966,
      "grad_norm": 0.003464343026280403,
      "learning_rate": 9.479392624728851e-06,
      "loss": 0.0002,
      "step": 3288
    },
    {
      "epoch": 0.05207657108475704,
      "grad_norm": 0.05124850571155548,
      "learning_rate": 9.47923428915243e-06,
      "loss": 0.0029,
      "step": 3289
    },
    {
      "epoch": 0.0520924046423991,
      "grad_norm": 0.3949817717075348,
      "learning_rate": 9.47907595357601e-06,
      "loss": 0.663,
      "step": 3290
    },
    {
      "epoch": 0.052108238200041165,
      "grad_norm": 0.013857278972864151,
      "learning_rate": 9.478917617999589e-06,
      "loss": 0.0003,
      "step": 3291
    },
    {
      "epoch": 0.05212407175768324,
      "grad_norm": 0.1627240926027298,
      "learning_rate": 9.47875928242317e-06,
      "loss": 0.0603,
      "step": 3292
    },
    {
      "epoch": 0.0521399053153253,
      "grad_norm": 0.2879994213581085,
      "learning_rate": 9.478600946846748e-06,
      "loss": 0.2305,
      "step": 3293
    },
    {
      "epoch": 0.052155738872967365,
      "grad_norm": 9.874806710286066e-05,
      "learning_rate": 9.478442611270327e-06,
      "loss": 0.0,
      "step": 3294
    },
    {
      "epoch": 0.052171572430609436,
      "grad_norm": 0.20484380424022675,
      "learning_rate": 9.478284275693907e-06,
      "loss": 0.506,
      "step": 3295
    },
    {
      "epoch": 0.0521874059882515,
      "grad_norm": 0.359108030796051,
      "learning_rate": 9.478125940117486e-06,
      "loss": 0.1191,
      "step": 3296
    },
    {
      "epoch": 0.052203239545893565,
      "grad_norm": 0.03059733472764492,
      "learning_rate": 9.477967604541065e-06,
      "loss": 0.0024,
      "step": 3297
    },
    {
      "epoch": 0.052219073103535636,
      "grad_norm": 0.25689059495925903,
      "learning_rate": 9.477809268964644e-06,
      "loss": 0.074,
      "step": 3298
    },
    {
      "epoch": 0.0522349066611777,
      "grad_norm": 0.1786472201347351,
      "learning_rate": 9.477650933388225e-06,
      "loss": 0.008,
      "step": 3299
    },
    {
      "epoch": 0.052250740218819765,
      "grad_norm": 0.00022920977789908648,
      "learning_rate": 9.477492597811802e-06,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 0.052266573776461836,
      "grad_norm": 0.09143888205289841,
      "learning_rate": 9.477334262235383e-06,
      "loss": 0.041,
      "step": 3301
    },
    {
      "epoch": 0.0522824073341039,
      "grad_norm": 0.022311775013804436,
      "learning_rate": 9.477175926658962e-06,
      "loss": 0.0015,
      "step": 3302
    },
    {
      "epoch": 0.052298240891745965,
      "grad_norm": 0.6724856495857239,
      "learning_rate": 9.477017591082541e-06,
      "loss": 0.3607,
      "step": 3303
    },
    {
      "epoch": 0.052314074449388036,
      "grad_norm": 0.3705679178237915,
      "learning_rate": 9.47685925550612e-06,
      "loss": 0.1137,
      "step": 3304
    },
    {
      "epoch": 0.0523299080070301,
      "grad_norm": 0.19791066646575928,
      "learning_rate": 9.4767009199297e-06,
      "loss": 0.1271,
      "step": 3305
    },
    {
      "epoch": 0.052345741564672164,
      "grad_norm": 0.22743403911590576,
      "learning_rate": 9.476542584353278e-06,
      "loss": 0.2528,
      "step": 3306
    },
    {
      "epoch": 0.052361575122314236,
      "grad_norm": 0.1734829992055893,
      "learning_rate": 9.476384248776859e-06,
      "loss": 0.1127,
      "step": 3307
    },
    {
      "epoch": 0.0523774086799563,
      "grad_norm": 0.29277676343917847,
      "learning_rate": 9.476225913200438e-06,
      "loss": 0.4952,
      "step": 3308
    },
    {
      "epoch": 0.052393242237598364,
      "grad_norm": 0.40515443682670593,
      "learning_rate": 9.476067577624017e-06,
      "loss": 0.6533,
      "step": 3309
    },
    {
      "epoch": 0.052409075795240435,
      "grad_norm": 0.2307879626750946,
      "learning_rate": 9.475909242047596e-06,
      "loss": 0.6684,
      "step": 3310
    },
    {
      "epoch": 0.0524249093528825,
      "grad_norm": 0.32317858934402466,
      "learning_rate": 9.475750906471177e-06,
      "loss": 0.2392,
      "step": 3311
    },
    {
      "epoch": 0.052440742910524564,
      "grad_norm": 0.9028863906860352,
      "learning_rate": 9.475592570894754e-06,
      "loss": 0.0179,
      "step": 3312
    },
    {
      "epoch": 0.052456576468166635,
      "grad_norm": 0.2606945335865021,
      "learning_rate": 9.475434235318335e-06,
      "loss": 0.1553,
      "step": 3313
    },
    {
      "epoch": 0.0524724100258087,
      "grad_norm": 0.33400389552116394,
      "learning_rate": 9.475275899741914e-06,
      "loss": 0.1324,
      "step": 3314
    },
    {
      "epoch": 0.052488243583450764,
      "grad_norm": 0.17442232370376587,
      "learning_rate": 9.475117564165493e-06,
      "loss": 0.2632,
      "step": 3315
    },
    {
      "epoch": 0.052504077141092835,
      "grad_norm": 0.009174744598567486,
      "learning_rate": 9.474959228589072e-06,
      "loss": 0.0005,
      "step": 3316
    },
    {
      "epoch": 0.0525199106987349,
      "grad_norm": 0.29779717326164246,
      "learning_rate": 9.474800893012653e-06,
      "loss": 0.141,
      "step": 3317
    },
    {
      "epoch": 0.052535744256376964,
      "grad_norm": 0.14373545348644257,
      "learning_rate": 9.47464255743623e-06,
      "loss": 0.0601,
      "step": 3318
    },
    {
      "epoch": 0.052551577814019035,
      "grad_norm": 0.11137892305850983,
      "learning_rate": 9.474484221859811e-06,
      "loss": 0.0526,
      "step": 3319
    },
    {
      "epoch": 0.0525674113716611,
      "grad_norm": 0.3754464387893677,
      "learning_rate": 9.47432588628339e-06,
      "loss": 0.2271,
      "step": 3320
    },
    {
      "epoch": 0.05258324492930316,
      "grad_norm": 0.17908664047718048,
      "learning_rate": 9.47416755070697e-06,
      "loss": 0.0843,
      "step": 3321
    },
    {
      "epoch": 0.052599078486945235,
      "grad_norm": 0.9644784331321716,
      "learning_rate": 9.474009215130548e-06,
      "loss": 0.0168,
      "step": 3322
    },
    {
      "epoch": 0.0526149120445873,
      "grad_norm": 0.7141648530960083,
      "learning_rate": 9.473850879554128e-06,
      "loss": 0.2374,
      "step": 3323
    },
    {
      "epoch": 0.05263074560222936,
      "grad_norm": 0.006790468469262123,
      "learning_rate": 9.473692543977707e-06,
      "loss": 0.0003,
      "step": 3324
    },
    {
      "epoch": 0.052646579159871434,
      "grad_norm": 0.20793600380420685,
      "learning_rate": 9.473534208401286e-06,
      "loss": 0.0869,
      "step": 3325
    },
    {
      "epoch": 0.0526624127175135,
      "grad_norm": 0.0002778543857857585,
      "learning_rate": 9.473375872824866e-06,
      "loss": 0.0,
      "step": 3326
    },
    {
      "epoch": 0.05267824627515556,
      "grad_norm": 0.22211405634880066,
      "learning_rate": 9.473217537248446e-06,
      "loss": 0.1231,
      "step": 3327
    },
    {
      "epoch": 0.052694079832797634,
      "grad_norm": 0.23746536672115326,
      "learning_rate": 9.473059201672025e-06,
      "loss": 0.3111,
      "step": 3328
    },
    {
      "epoch": 0.0527099133904397,
      "grad_norm": 0.21958187222480774,
      "learning_rate": 9.472900866095604e-06,
      "loss": 0.0825,
      "step": 3329
    },
    {
      "epoch": 0.05272574694808176,
      "grad_norm": 0.02061632089316845,
      "learning_rate": 9.472742530519183e-06,
      "loss": 0.0013,
      "step": 3330
    },
    {
      "epoch": 0.052741580505723834,
      "grad_norm": 0.42113396525382996,
      "learning_rate": 9.472584194942762e-06,
      "loss": 0.1866,
      "step": 3331
    },
    {
      "epoch": 0.0527574140633659,
      "grad_norm": 0.0028281742706894875,
      "learning_rate": 9.472425859366343e-06,
      "loss": 0.0001,
      "step": 3332
    },
    {
      "epoch": 0.05277324762100796,
      "grad_norm": 0.26652488112449646,
      "learning_rate": 9.472267523789922e-06,
      "loss": 0.0329,
      "step": 3333
    },
    {
      "epoch": 0.052789081178650034,
      "grad_norm": 0.004905117210000753,
      "learning_rate": 9.4721091882135e-06,
      "loss": 0.0003,
      "step": 3334
    },
    {
      "epoch": 0.0528049147362921,
      "grad_norm": 0.15341734886169434,
      "learning_rate": 9.47195085263708e-06,
      "loss": 0.0369,
      "step": 3335
    },
    {
      "epoch": 0.05282074829393416,
      "grad_norm": 0.01944231614470482,
      "learning_rate": 9.471792517060659e-06,
      "loss": 0.001,
      "step": 3336
    },
    {
      "epoch": 0.052836581851576234,
      "grad_norm": 0.36804479360580444,
      "learning_rate": 9.471634181484238e-06,
      "loss": 0.3303,
      "step": 3337
    },
    {
      "epoch": 0.0528524154092183,
      "grad_norm": 0.7045053243637085,
      "learning_rate": 9.471475845907819e-06,
      "loss": 0.2478,
      "step": 3338
    },
    {
      "epoch": 0.05286824896686036,
      "grad_norm": 0.035869475454092026,
      "learning_rate": 9.471317510331396e-06,
      "loss": 0.0019,
      "step": 3339
    },
    {
      "epoch": 0.05288408252450243,
      "grad_norm": 0.39224353432655334,
      "learning_rate": 9.471159174754977e-06,
      "loss": 0.067,
      "step": 3340
    },
    {
      "epoch": 0.0528999160821445,
      "grad_norm": 0.22762876749038696,
      "learning_rate": 9.471000839178556e-06,
      "loss": 0.072,
      "step": 3341
    },
    {
      "epoch": 0.05291574963978656,
      "grad_norm": 0.3562603294849396,
      "learning_rate": 9.470842503602135e-06,
      "loss": 0.1759,
      "step": 3342
    },
    {
      "epoch": 0.05293158319742863,
      "grad_norm": 0.2810809910297394,
      "learning_rate": 9.470684168025714e-06,
      "loss": 0.286,
      "step": 3343
    },
    {
      "epoch": 0.0529474167550707,
      "grad_norm": 0.13586211204528809,
      "learning_rate": 9.470525832449295e-06,
      "loss": 0.052,
      "step": 3344
    },
    {
      "epoch": 0.05296325031271276,
      "grad_norm": 0.06299912184476852,
      "learning_rate": 9.470367496872872e-06,
      "loss": 0.0056,
      "step": 3345
    },
    {
      "epoch": 0.05297908387035483,
      "grad_norm": 0.4455914795398712,
      "learning_rate": 9.470209161296451e-06,
      "loss": 0.4998,
      "step": 3346
    },
    {
      "epoch": 0.0529949174279969,
      "grad_norm": 0.010662511922419071,
      "learning_rate": 9.470050825720032e-06,
      "loss": 0.0007,
      "step": 3347
    },
    {
      "epoch": 0.05301075098563896,
      "grad_norm": 0.14499399065971375,
      "learning_rate": 9.469892490143611e-06,
      "loss": 0.2582,
      "step": 3348
    },
    {
      "epoch": 0.05302658454328103,
      "grad_norm": 0.04029856622219086,
      "learning_rate": 9.46973415456719e-06,
      "loss": 0.0022,
      "step": 3349
    },
    {
      "epoch": 0.0530424181009231,
      "grad_norm": 0.19121095538139343,
      "learning_rate": 9.46957581899077e-06,
      "loss": 0.0506,
      "step": 3350
    },
    {
      "epoch": 0.05305825165856516,
      "grad_norm": 0.010440438985824585,
      "learning_rate": 9.469417483414349e-06,
      "loss": 0.0008,
      "step": 3351
    },
    {
      "epoch": 0.05307408521620723,
      "grad_norm": 0.027654452249407768,
      "learning_rate": 9.469259147837928e-06,
      "loss": 0.0022,
      "step": 3352
    },
    {
      "epoch": 0.0530899187738493,
      "grad_norm": 1.1731258630752563,
      "learning_rate": 9.469100812261508e-06,
      "loss": 0.1651,
      "step": 3353
    },
    {
      "epoch": 0.05310575233149136,
      "grad_norm": 0.42863723635673523,
      "learning_rate": 9.468942476685087e-06,
      "loss": 0.6933,
      "step": 3354
    },
    {
      "epoch": 0.05312158588913343,
      "grad_norm": 0.21039706468582153,
      "learning_rate": 9.468784141108667e-06,
      "loss": 0.1726,
      "step": 3355
    },
    {
      "epoch": 0.0531374194467755,
      "grad_norm": 0.22253523766994476,
      "learning_rate": 9.468625805532246e-06,
      "loss": 0.0754,
      "step": 3356
    },
    {
      "epoch": 0.05315325300441756,
      "grad_norm": 0.28395381569862366,
      "learning_rate": 9.468467469955825e-06,
      "loss": 0.2399,
      "step": 3357
    },
    {
      "epoch": 0.05316908656205963,
      "grad_norm": 0.19118358194828033,
      "learning_rate": 9.468309134379404e-06,
      "loss": 0.1456,
      "step": 3358
    },
    {
      "epoch": 0.0531849201197017,
      "grad_norm": 0.20842517912387848,
      "learning_rate": 9.468150798802985e-06,
      "loss": 0.2301,
      "step": 3359
    },
    {
      "epoch": 0.05320075367734376,
      "grad_norm": 0.0607139952480793,
      "learning_rate": 9.467992463226564e-06,
      "loss": 0.0203,
      "step": 3360
    },
    {
      "epoch": 0.05321658723498583,
      "grad_norm": 0.013417815789580345,
      "learning_rate": 9.467834127650143e-06,
      "loss": 0.001,
      "step": 3361
    },
    {
      "epoch": 0.053232420792627896,
      "grad_norm": 0.3692377209663391,
      "learning_rate": 9.467675792073722e-06,
      "loss": 0.1732,
      "step": 3362
    },
    {
      "epoch": 0.05324825435026996,
      "grad_norm": 0.2860056161880493,
      "learning_rate": 9.467517456497301e-06,
      "loss": 0.6251,
      "step": 3363
    },
    {
      "epoch": 0.05326408790791203,
      "grad_norm": 0.2964978814125061,
      "learning_rate": 9.46735912092088e-06,
      "loss": 0.4276,
      "step": 3364
    },
    {
      "epoch": 0.053279921465554096,
      "grad_norm": 0.18459561467170715,
      "learning_rate": 9.46720078534446e-06,
      "loss": 0.0723,
      "step": 3365
    },
    {
      "epoch": 0.05329575502319616,
      "grad_norm": 0.2318374067544937,
      "learning_rate": 9.46704244976804e-06,
      "loss": 0.1127,
      "step": 3366
    },
    {
      "epoch": 0.05331158858083823,
      "grad_norm": 0.009403361938893795,
      "learning_rate": 9.466884114191619e-06,
      "loss": 0.0006,
      "step": 3367
    },
    {
      "epoch": 0.053327422138480296,
      "grad_norm": 0.21742185950279236,
      "learning_rate": 9.466725778615198e-06,
      "loss": 0.1089,
      "step": 3368
    },
    {
      "epoch": 0.05334325569612236,
      "grad_norm": 0.0027499927673488855,
      "learning_rate": 9.466567443038777e-06,
      "loss": 0.0002,
      "step": 3369
    },
    {
      "epoch": 0.05335908925376443,
      "grad_norm": 0.06328864395618439,
      "learning_rate": 9.466409107462356e-06,
      "loss": 0.0014,
      "step": 3370
    },
    {
      "epoch": 0.053374922811406496,
      "grad_norm": 0.19652855396270752,
      "learning_rate": 9.466250771885935e-06,
      "loss": 0.1076,
      "step": 3371
    },
    {
      "epoch": 0.05339075636904856,
      "grad_norm": 0.25421470403671265,
      "learning_rate": 9.466092436309516e-06,
      "loss": 0.1889,
      "step": 3372
    },
    {
      "epoch": 0.05340658992669063,
      "grad_norm": 0.005549000110477209,
      "learning_rate": 9.465934100733093e-06,
      "loss": 0.0004,
      "step": 3373
    },
    {
      "epoch": 0.053422423484332696,
      "grad_norm": 0.3289337158203125,
      "learning_rate": 9.465775765156674e-06,
      "loss": 0.297,
      "step": 3374
    },
    {
      "epoch": 0.05343825704197476,
      "grad_norm": 0.04874136298894882,
      "learning_rate": 9.465617429580253e-06,
      "loss": 0.0011,
      "step": 3375
    },
    {
      "epoch": 0.05345409059961683,
      "grad_norm": 0.28329646587371826,
      "learning_rate": 9.465459094003832e-06,
      "loss": 0.256,
      "step": 3376
    },
    {
      "epoch": 0.053469924157258895,
      "grad_norm": 0.3302610218524933,
      "learning_rate": 9.465300758427411e-06,
      "loss": 0.1221,
      "step": 3377
    },
    {
      "epoch": 0.05348575771490096,
      "grad_norm": 0.008238221518695354,
      "learning_rate": 9.465142422850992e-06,
      "loss": 0.0005,
      "step": 3378
    },
    {
      "epoch": 0.05350159127254303,
      "grad_norm": 0.00519780907779932,
      "learning_rate": 9.46498408727457e-06,
      "loss": 0.0002,
      "step": 3379
    },
    {
      "epoch": 0.053517424830185095,
      "grad_norm": 0.5174258351325989,
      "learning_rate": 9.46482575169815e-06,
      "loss": 0.143,
      "step": 3380
    },
    {
      "epoch": 0.05353325838782716,
      "grad_norm": 0.05823134258389473,
      "learning_rate": 9.46466741612173e-06,
      "loss": 0.0014,
      "step": 3381
    },
    {
      "epoch": 0.05354909194546923,
      "grad_norm": 9.942927863448858e-05,
      "learning_rate": 9.464509080545308e-06,
      "loss": 0.0,
      "step": 3382
    },
    {
      "epoch": 0.053564925503111295,
      "grad_norm": 0.02712281234562397,
      "learning_rate": 9.464350744968888e-06,
      "loss": 0.0021,
      "step": 3383
    },
    {
      "epoch": 0.05358075906075336,
      "grad_norm": 0.2875592112541199,
      "learning_rate": 9.464192409392468e-06,
      "loss": 0.1997,
      "step": 3384
    },
    {
      "epoch": 0.05359659261839543,
      "grad_norm": 0.4021095335483551,
      "learning_rate": 9.464034073816046e-06,
      "loss": 0.1392,
      "step": 3385
    },
    {
      "epoch": 0.053612426176037495,
      "grad_norm": 0.18111440539360046,
      "learning_rate": 9.463875738239626e-06,
      "loss": 0.085,
      "step": 3386
    },
    {
      "epoch": 0.05362825973367956,
      "grad_norm": 0.1932944655418396,
      "learning_rate": 9.463717402663206e-06,
      "loss": 0.35,
      "step": 3387
    },
    {
      "epoch": 0.05364409329132163,
      "grad_norm": 0.26686161756515503,
      "learning_rate": 9.463559067086785e-06,
      "loss": 0.076,
      "step": 3388
    },
    {
      "epoch": 0.053659926848963695,
      "grad_norm": 0.3150869607925415,
      "learning_rate": 9.463400731510364e-06,
      "loss": 0.1411,
      "step": 3389
    },
    {
      "epoch": 0.05367576040660576,
      "grad_norm": 0.21629241108894348,
      "learning_rate": 9.463242395933944e-06,
      "loss": 0.0471,
      "step": 3390
    },
    {
      "epoch": 0.05369159396424783,
      "grad_norm": 0.14948299527168274,
      "learning_rate": 9.463084060357522e-06,
      "loss": 0.1025,
      "step": 3391
    },
    {
      "epoch": 0.053707427521889894,
      "grad_norm": 0.19874268770217896,
      "learning_rate": 9.462925724781103e-06,
      "loss": 0.1629,
      "step": 3392
    },
    {
      "epoch": 0.05372326107953196,
      "grad_norm": 0.7951536774635315,
      "learning_rate": 9.462767389204682e-06,
      "loss": 1.0916,
      "step": 3393
    },
    {
      "epoch": 0.05373909463717403,
      "grad_norm": 1.8763181287795305e-05,
      "learning_rate": 9.46260905362826e-06,
      "loss": 0.0,
      "step": 3394
    },
    {
      "epoch": 0.053754928194816094,
      "grad_norm": 0.0008156736148521304,
      "learning_rate": 9.46245071805184e-06,
      "loss": 0.0,
      "step": 3395
    },
    {
      "epoch": 0.05377076175245816,
      "grad_norm": 0.19205600023269653,
      "learning_rate": 9.462292382475419e-06,
      "loss": 0.3113,
      "step": 3396
    },
    {
      "epoch": 0.05378659531010023,
      "grad_norm": 0.183590367436409,
      "learning_rate": 9.462134046898998e-06,
      "loss": 0.1421,
      "step": 3397
    },
    {
      "epoch": 0.053802428867742294,
      "grad_norm": 0.000113706111733336,
      "learning_rate": 9.461975711322577e-06,
      "loss": 0.0,
      "step": 3398
    },
    {
      "epoch": 0.05381826242538436,
      "grad_norm": 0.04032919928431511,
      "learning_rate": 9.461817375746158e-06,
      "loss": 0.0029,
      "step": 3399
    },
    {
      "epoch": 0.05383409598302643,
      "grad_norm": 0.1972665637731552,
      "learning_rate": 9.461659040169735e-06,
      "loss": 0.1499,
      "step": 3400
    },
    {
      "epoch": 0.053849929540668494,
      "grad_norm": 0.17057988047599792,
      "learning_rate": 9.461500704593316e-06,
      "loss": 0.0536,
      "step": 3401
    },
    {
      "epoch": 0.05386576309831056,
      "grad_norm": 0.19964206218719482,
      "learning_rate": 9.461342369016895e-06,
      "loss": 0.0582,
      "step": 3402
    },
    {
      "epoch": 0.05388159665595263,
      "grad_norm": 0.3963404893875122,
      "learning_rate": 9.461184033440474e-06,
      "loss": 0.6335,
      "step": 3403
    },
    {
      "epoch": 0.053897430213594694,
      "grad_norm": 0.16120922565460205,
      "learning_rate": 9.461025697864053e-06,
      "loss": 0.0498,
      "step": 3404
    },
    {
      "epoch": 0.05391326377123676,
      "grad_norm": 0.26542025804519653,
      "learning_rate": 9.460867362287634e-06,
      "loss": 0.3245,
      "step": 3405
    },
    {
      "epoch": 0.05392909732887883,
      "grad_norm": 0.19840216636657715,
      "learning_rate": 9.460709026711211e-06,
      "loss": 0.0779,
      "step": 3406
    },
    {
      "epoch": 0.05394493088652089,
      "grad_norm": 0.1858646124601364,
      "learning_rate": 9.460550691134792e-06,
      "loss": 0.0456,
      "step": 3407
    },
    {
      "epoch": 0.05396076444416296,
      "grad_norm": 0.32303962111473083,
      "learning_rate": 9.460392355558371e-06,
      "loss": 0.3054,
      "step": 3408
    },
    {
      "epoch": 0.05397659800180503,
      "grad_norm": 0.01337018795311451,
      "learning_rate": 9.46023401998195e-06,
      "loss": 0.0009,
      "step": 3409
    },
    {
      "epoch": 0.05399243155944709,
      "grad_norm": 9.023794700624421e-05,
      "learning_rate": 9.46007568440553e-06,
      "loss": 0.0,
      "step": 3410
    },
    {
      "epoch": 0.05400826511708916,
      "grad_norm": 0.195468932390213,
      "learning_rate": 9.45991734882911e-06,
      "loss": 0.36,
      "step": 3411
    },
    {
      "epoch": 0.05402409867473123,
      "grad_norm": 0.2912103831768036,
      "learning_rate": 9.459759013252688e-06,
      "loss": 0.4317,
      "step": 3412
    },
    {
      "epoch": 0.05403993223237329,
      "grad_norm": 0.1905677765607834,
      "learning_rate": 9.459600677676268e-06,
      "loss": 0.1184,
      "step": 3413
    },
    {
      "epoch": 0.05405576579001536,
      "grad_norm": 0.03338906541466713,
      "learning_rate": 9.459442342099847e-06,
      "loss": 0.0022,
      "step": 3414
    },
    {
      "epoch": 0.05407159934765743,
      "grad_norm": 0.02015237882733345,
      "learning_rate": 9.459284006523427e-06,
      "loss": 0.001,
      "step": 3415
    },
    {
      "epoch": 0.05408743290529949,
      "grad_norm": 0.17823971807956696,
      "learning_rate": 9.459125670947006e-06,
      "loss": 0.3199,
      "step": 3416
    },
    {
      "epoch": 0.05410326646294156,
      "grad_norm": 0.41988855600357056,
      "learning_rate": 9.458967335370585e-06,
      "loss": 0.6145,
      "step": 3417
    },
    {
      "epoch": 0.05411910002058363,
      "grad_norm": 0.345779687166214,
      "learning_rate": 9.458808999794164e-06,
      "loss": 0.0954,
      "step": 3418
    },
    {
      "epoch": 0.05413493357822569,
      "grad_norm": 0.043829090893268585,
      "learning_rate": 9.458650664217743e-06,
      "loss": 0.002,
      "step": 3419
    },
    {
      "epoch": 0.05415076713586776,
      "grad_norm": 0.4405054450035095,
      "learning_rate": 9.458492328641324e-06,
      "loss": 0.1269,
      "step": 3420
    },
    {
      "epoch": 0.05416660069350982,
      "grad_norm": 0.35966747999191284,
      "learning_rate": 9.458333993064903e-06,
      "loss": 0.634,
      "step": 3421
    },
    {
      "epoch": 0.05418243425115189,
      "grad_norm": 0.2144044190645218,
      "learning_rate": 9.458175657488482e-06,
      "loss": 0.1078,
      "step": 3422
    },
    {
      "epoch": 0.05419826780879396,
      "grad_norm": 0.31813716888427734,
      "learning_rate": 9.458017321912061e-06,
      "loss": 0.3199,
      "step": 3423
    },
    {
      "epoch": 0.05421410136643602,
      "grad_norm": 9.31637769099325e-05,
      "learning_rate": 9.45785898633564e-06,
      "loss": 0.0,
      "step": 3424
    },
    {
      "epoch": 0.05422993492407809,
      "grad_norm": 0.03044871613383293,
      "learning_rate": 9.457700650759219e-06,
      "loss": 0.0019,
      "step": 3425
    },
    {
      "epoch": 0.05424576848172016,
      "grad_norm": 0.046295296400785446,
      "learning_rate": 9.4575423151828e-06,
      "loss": 0.0066,
      "step": 3426
    },
    {
      "epoch": 0.05426160203936222,
      "grad_norm": 0.0034352699294686317,
      "learning_rate": 9.457383979606379e-06,
      "loss": 0.0001,
      "step": 3427
    },
    {
      "epoch": 0.05427743559700429,
      "grad_norm": 0.1176881492137909,
      "learning_rate": 9.457225644029958e-06,
      "loss": 0.0092,
      "step": 3428
    },
    {
      "epoch": 0.054293269154646356,
      "grad_norm": 3.155332088470459,
      "learning_rate": 9.457067308453537e-06,
      "loss": 0.3764,
      "step": 3429
    },
    {
      "epoch": 0.05430910271228842,
      "grad_norm": 0.024058610200881958,
      "learning_rate": 9.456908972877116e-06,
      "loss": 0.0024,
      "step": 3430
    },
    {
      "epoch": 0.05432493626993049,
      "grad_norm": 0.051477428525686264,
      "learning_rate": 9.456750637300695e-06,
      "loss": 0.0045,
      "step": 3431
    },
    {
      "epoch": 0.054340769827572556,
      "grad_norm": 0.3156699240207672,
      "learning_rate": 9.456592301724276e-06,
      "loss": 0.2793,
      "step": 3432
    },
    {
      "epoch": 0.05435660338521462,
      "grad_norm": 0.031120477244257927,
      "learning_rate": 9.456433966147855e-06,
      "loss": 0.0022,
      "step": 3433
    },
    {
      "epoch": 0.05437243694285669,
      "grad_norm": 0.19842784106731415,
      "learning_rate": 9.456275630571434e-06,
      "loss": 0.0928,
      "step": 3434
    },
    {
      "epoch": 0.054388270500498756,
      "grad_norm": 0.18263229727745056,
      "learning_rate": 9.456117294995013e-06,
      "loss": 0.1701,
      "step": 3435
    },
    {
      "epoch": 0.05440410405814082,
      "grad_norm": 0.3791162073612213,
      "learning_rate": 9.455958959418592e-06,
      "loss": 0.1294,
      "step": 3436
    },
    {
      "epoch": 0.05441993761578289,
      "grad_norm": 0.13480712473392487,
      "learning_rate": 9.455800623842171e-06,
      "loss": 0.0553,
      "step": 3437
    },
    {
      "epoch": 0.054435771173424956,
      "grad_norm": 0.22544974088668823,
      "learning_rate": 9.455642288265752e-06,
      "loss": 0.1008,
      "step": 3438
    },
    {
      "epoch": 0.05445160473106702,
      "grad_norm": 0.27362632751464844,
      "learning_rate": 9.455483952689331e-06,
      "loss": 0.1242,
      "step": 3439
    },
    {
      "epoch": 0.05446743828870909,
      "grad_norm": 0.21786905825138092,
      "learning_rate": 9.45532561711291e-06,
      "loss": 0.162,
      "step": 3440
    },
    {
      "epoch": 0.054483271846351156,
      "grad_norm": 0.0442824587225914,
      "learning_rate": 9.45516728153649e-06,
      "loss": 0.0019,
      "step": 3441
    },
    {
      "epoch": 0.05449910540399322,
      "grad_norm": 0.2491322159767151,
      "learning_rate": 9.455008945960068e-06,
      "loss": 0.1491,
      "step": 3442
    },
    {
      "epoch": 0.05451493896163529,
      "grad_norm": 0.29656025767326355,
      "learning_rate": 9.454850610383648e-06,
      "loss": 0.2436,
      "step": 3443
    },
    {
      "epoch": 0.054530772519277355,
      "grad_norm": 0.01649281196296215,
      "learning_rate": 9.454692274807227e-06,
      "loss": 0.0011,
      "step": 3444
    },
    {
      "epoch": 0.05454660607691942,
      "grad_norm": 0.26039692759513855,
      "learning_rate": 9.454533939230807e-06,
      "loss": 0.2538,
      "step": 3445
    },
    {
      "epoch": 0.05456243963456149,
      "grad_norm": 0.26260659098625183,
      "learning_rate": 9.454375603654385e-06,
      "loss": 0.1344,
      "step": 3446
    },
    {
      "epoch": 0.054578273192203555,
      "grad_norm": 0.32390618324279785,
      "learning_rate": 9.454217268077966e-06,
      "loss": 0.6331,
      "step": 3447
    },
    {
      "epoch": 0.05459410674984562,
      "grad_norm": 0.6191461086273193,
      "learning_rate": 9.454058932501545e-06,
      "loss": 0.202,
      "step": 3448
    },
    {
      "epoch": 0.05460994030748769,
      "grad_norm": 0.14366143941879272,
      "learning_rate": 9.453900596925124e-06,
      "loss": 0.0661,
      "step": 3449
    },
    {
      "epoch": 0.054625773865129755,
      "grad_norm": 0.22064432501792908,
      "learning_rate": 9.453742261348703e-06,
      "loss": 0.2492,
      "step": 3450
    },
    {
      "epoch": 0.05464160742277182,
      "grad_norm": 0.0237590279430151,
      "learning_rate": 9.453583925772284e-06,
      "loss": 0.0016,
      "step": 3451
    },
    {
      "epoch": 0.05465744098041389,
      "grad_norm": 0.17881059646606445,
      "learning_rate": 9.453425590195861e-06,
      "loss": 0.0521,
      "step": 3452
    },
    {
      "epoch": 0.054673274538055955,
      "grad_norm": 0.2579561769962311,
      "learning_rate": 9.453267254619442e-06,
      "loss": 0.417,
      "step": 3453
    },
    {
      "epoch": 0.05468910809569802,
      "grad_norm": 0.28247198462486267,
      "learning_rate": 9.45310891904302e-06,
      "loss": 0.3894,
      "step": 3454
    },
    {
      "epoch": 0.05470494165334009,
      "grad_norm": 0.19211861491203308,
      "learning_rate": 9.4529505834666e-06,
      "loss": 0.0851,
      "step": 3455
    },
    {
      "epoch": 0.054720775210982155,
      "grad_norm": 0.24150219559669495,
      "learning_rate": 9.452792247890179e-06,
      "loss": 0.0526,
      "step": 3456
    },
    {
      "epoch": 0.05473660876862422,
      "grad_norm": 0.14847438037395477,
      "learning_rate": 9.45263391231376e-06,
      "loss": 0.0773,
      "step": 3457
    },
    {
      "epoch": 0.05475244232626629,
      "grad_norm": 0.36468714475631714,
      "learning_rate": 9.452475576737337e-06,
      "loss": 0.3411,
      "step": 3458
    },
    {
      "epoch": 0.054768275883908354,
      "grad_norm": 0.23618508875370026,
      "learning_rate": 9.452317241160918e-06,
      "loss": 0.0428,
      "step": 3459
    },
    {
      "epoch": 0.05478410944155042,
      "grad_norm": 0.259801983833313,
      "learning_rate": 9.452158905584497e-06,
      "loss": 0.1362,
      "step": 3460
    },
    {
      "epoch": 0.05479994299919249,
      "grad_norm": 0.33723342418670654,
      "learning_rate": 9.452000570008076e-06,
      "loss": 0.1071,
      "step": 3461
    },
    {
      "epoch": 0.054815776556834554,
      "grad_norm": 0.13774122297763824,
      "learning_rate": 9.451842234431655e-06,
      "loss": 0.0522,
      "step": 3462
    },
    {
      "epoch": 0.05483161011447662,
      "grad_norm": 0.003313651541247964,
      "learning_rate": 9.451683898855234e-06,
      "loss": 0.0001,
      "step": 3463
    },
    {
      "epoch": 0.05484744367211869,
      "grad_norm": 0.20478014647960663,
      "learning_rate": 9.451525563278813e-06,
      "loss": 0.2064,
      "step": 3464
    },
    {
      "epoch": 0.054863277229760754,
      "grad_norm": 0.18377885222434998,
      "learning_rate": 9.451367227702392e-06,
      "loss": 0.4797,
      "step": 3465
    },
    {
      "epoch": 0.05487911078740282,
      "grad_norm": 0.14217425882816315,
      "learning_rate": 9.451208892125973e-06,
      "loss": 0.0668,
      "step": 3466
    },
    {
      "epoch": 0.05489494434504489,
      "grad_norm": 0.18780842423439026,
      "learning_rate": 9.45105055654955e-06,
      "loss": 0.1373,
      "step": 3467
    },
    {
      "epoch": 0.054910777902686954,
      "grad_norm": 0.00016221325495280325,
      "learning_rate": 9.450892220973131e-06,
      "loss": 0.0,
      "step": 3468
    },
    {
      "epoch": 0.05492661146032902,
      "grad_norm": 0.16522277891635895,
      "learning_rate": 9.45073388539671e-06,
      "loss": 0.2676,
      "step": 3469
    },
    {
      "epoch": 0.05494244501797109,
      "grad_norm": 0.007927236147224903,
      "learning_rate": 9.45057554982029e-06,
      "loss": 0.0005,
      "step": 3470
    },
    {
      "epoch": 0.054958278575613154,
      "grad_norm": 0.44925200939178467,
      "learning_rate": 9.450417214243869e-06,
      "loss": 0.2529,
      "step": 3471
    },
    {
      "epoch": 0.05497411213325522,
      "grad_norm": 0.23134943842887878,
      "learning_rate": 9.45025887866745e-06,
      "loss": 0.1532,
      "step": 3472
    },
    {
      "epoch": 0.05498994569089729,
      "grad_norm": 0.3001256287097931,
      "learning_rate": 9.450100543091027e-06,
      "loss": 0.0695,
      "step": 3473
    },
    {
      "epoch": 0.05500577924853935,
      "grad_norm": 0.002082584425806999,
      "learning_rate": 9.449942207514608e-06,
      "loss": 0.0001,
      "step": 3474
    },
    {
      "epoch": 0.05502161280618142,
      "grad_norm": 0.5625311732292175,
      "learning_rate": 9.449783871938187e-06,
      "loss": 0.3797,
      "step": 3475
    },
    {
      "epoch": 0.05503744636382349,
      "grad_norm": 0.006013139616698027,
      "learning_rate": 9.449625536361766e-06,
      "loss": 0.0003,
      "step": 3476
    },
    {
      "epoch": 0.05505327992146555,
      "grad_norm": 0.02080937661230564,
      "learning_rate": 9.449467200785345e-06,
      "loss": 0.0012,
      "step": 3477
    },
    {
      "epoch": 0.05506911347910762,
      "grad_norm": 0.16362296044826508,
      "learning_rate": 9.449308865208926e-06,
      "loss": 0.0661,
      "step": 3478
    },
    {
      "epoch": 0.05508494703674969,
      "grad_norm": 0.28283554315567017,
      "learning_rate": 9.449150529632503e-06,
      "loss": 0.5089,
      "step": 3479
    },
    {
      "epoch": 0.05510078059439175,
      "grad_norm": 0.42609190940856934,
      "learning_rate": 9.448992194056084e-06,
      "loss": 0.1106,
      "step": 3480
    },
    {
      "epoch": 0.05511661415203382,
      "grad_norm": 0.34248048067092896,
      "learning_rate": 9.448833858479663e-06,
      "loss": 0.1794,
      "step": 3481
    },
    {
      "epoch": 0.05513244770967589,
      "grad_norm": 0.17238351702690125,
      "learning_rate": 9.448675522903242e-06,
      "loss": 0.0029,
      "step": 3482
    },
    {
      "epoch": 0.05514828126731795,
      "grad_norm": 0.5857111811637878,
      "learning_rate": 9.448517187326821e-06,
      "loss": 0.0781,
      "step": 3483
    },
    {
      "epoch": 0.05516411482496002,
      "grad_norm": 0.4041357636451721,
      "learning_rate": 9.448358851750402e-06,
      "loss": 0.1023,
      "step": 3484
    },
    {
      "epoch": 0.05517994838260209,
      "grad_norm": 0.26857009530067444,
      "learning_rate": 9.448200516173979e-06,
      "loss": 0.1535,
      "step": 3485
    },
    {
      "epoch": 0.05519578194024415,
      "grad_norm": 5.1649276429088786e-05,
      "learning_rate": 9.44804218059756e-06,
      "loss": 0.0,
      "step": 3486
    },
    {
      "epoch": 0.05521161549788622,
      "grad_norm": 7.898746967315674,
      "learning_rate": 9.447883845021139e-06,
      "loss": 0.2552,
      "step": 3487
    },
    {
      "epoch": 0.05522744905552829,
      "grad_norm": 0.004078978206962347,
      "learning_rate": 9.447725509444718e-06,
      "loss": 0.0002,
      "step": 3488
    },
    {
      "epoch": 0.05524328261317035,
      "grad_norm": 0.7558526992797852,
      "learning_rate": 9.447567173868297e-06,
      "loss": 0.1058,
      "step": 3489
    },
    {
      "epoch": 0.05525911617081242,
      "grad_norm": 0.8134300112724304,
      "learning_rate": 9.447408838291876e-06,
      "loss": 0.0501,
      "step": 3490
    },
    {
      "epoch": 0.05527494972845449,
      "grad_norm": 0.26197874546051025,
      "learning_rate": 9.447250502715455e-06,
      "loss": 0.0407,
      "step": 3491
    },
    {
      "epoch": 0.05529078328609655,
      "grad_norm": 0.1807786524295807,
      "learning_rate": 9.447092167139034e-06,
      "loss": 0.1858,
      "step": 3492
    },
    {
      "epoch": 0.05530661684373862,
      "grad_norm": 0.002508638659492135,
      "learning_rate": 9.446933831562615e-06,
      "loss": 0.0,
      "step": 3493
    },
    {
      "epoch": 0.05532245040138069,
      "grad_norm": 0.3198380470275879,
      "learning_rate": 9.446775495986194e-06,
      "loss": 0.2033,
      "step": 3494
    },
    {
      "epoch": 0.05533828395902275,
      "grad_norm": 0.1911734789609909,
      "learning_rate": 9.446617160409773e-06,
      "loss": 0.1349,
      "step": 3495
    },
    {
      "epoch": 0.055354117516664816,
      "grad_norm": 0.36027395725250244,
      "learning_rate": 9.446458824833352e-06,
      "loss": 0.0971,
      "step": 3496
    },
    {
      "epoch": 0.05536995107430689,
      "grad_norm": 0.01892121508717537,
      "learning_rate": 9.446300489256931e-06,
      "loss": 0.0012,
      "step": 3497
    },
    {
      "epoch": 0.05538578463194895,
      "grad_norm": 0.12997524440288544,
      "learning_rate": 9.44614215368051e-06,
      "loss": 0.039,
      "step": 3498
    },
    {
      "epoch": 0.055401618189591016,
      "grad_norm": 0.19205829501152039,
      "learning_rate": 9.445983818104091e-06,
      "loss": 0.2719,
      "step": 3499
    },
    {
      "epoch": 0.05541745174723309,
      "grad_norm": 0.28622230887413025,
      "learning_rate": 9.44582548252767e-06,
      "loss": 0.3017,
      "step": 3500
    },
    {
      "epoch": 0.05543328530487515,
      "grad_norm": 0.053900331258773804,
      "learning_rate": 9.44566714695125e-06,
      "loss": 0.0074,
      "step": 3501
    },
    {
      "epoch": 0.055449118862517216,
      "grad_norm": 0.14273105561733246,
      "learning_rate": 9.445508811374829e-06,
      "loss": 0.0884,
      "step": 3502
    },
    {
      "epoch": 0.05546495242015929,
      "grad_norm": 0.16950419545173645,
      "learning_rate": 9.445350475798408e-06,
      "loss": 0.2859,
      "step": 3503
    },
    {
      "epoch": 0.05548078597780135,
      "grad_norm": 0.011178413406014442,
      "learning_rate": 9.445192140221987e-06,
      "loss": 0.0006,
      "step": 3504
    },
    {
      "epoch": 0.055496619535443416,
      "grad_norm": 0.4074665606021881,
      "learning_rate": 9.445033804645567e-06,
      "loss": 0.8856,
      "step": 3505
    },
    {
      "epoch": 0.05551245309308549,
      "grad_norm": 0.4818117916584015,
      "learning_rate": 9.444875469069147e-06,
      "loss": 0.375,
      "step": 3506
    },
    {
      "epoch": 0.05552828665072755,
      "grad_norm": 0.0025187579449266195,
      "learning_rate": 9.444717133492726e-06,
      "loss": 0.0001,
      "step": 3507
    },
    {
      "epoch": 0.055544120208369616,
      "grad_norm": 0.22221575677394867,
      "learning_rate": 9.444558797916305e-06,
      "loss": 0.2398,
      "step": 3508
    },
    {
      "epoch": 0.05555995376601169,
      "grad_norm": 0.30706021189689636,
      "learning_rate": 9.444400462339884e-06,
      "loss": 0.0102,
      "step": 3509
    },
    {
      "epoch": 0.05557578732365375,
      "grad_norm": 9.659965144237503e-05,
      "learning_rate": 9.444242126763463e-06,
      "loss": 0.0,
      "step": 3510
    },
    {
      "epoch": 0.055591620881295815,
      "grad_norm": 0.2533029019832611,
      "learning_rate": 9.444083791187044e-06,
      "loss": 0.0764,
      "step": 3511
    },
    {
      "epoch": 0.05560745443893789,
      "grad_norm": 0.442693829536438,
      "learning_rate": 9.443925455610623e-06,
      "loss": 0.1969,
      "step": 3512
    },
    {
      "epoch": 0.05562328799657995,
      "grad_norm": 0.015994084998965263,
      "learning_rate": 9.4437671200342e-06,
      "loss": 0.001,
      "step": 3513
    },
    {
      "epoch": 0.055639121554222015,
      "grad_norm": 0.01431951392441988,
      "learning_rate": 9.443608784457781e-06,
      "loss": 0.0009,
      "step": 3514
    },
    {
      "epoch": 0.055654955111864086,
      "grad_norm": 0.013470347039401531,
      "learning_rate": 9.44345044888136e-06,
      "loss": 0.0008,
      "step": 3515
    },
    {
      "epoch": 0.05567078866950615,
      "grad_norm": 0.004873139783740044,
      "learning_rate": 9.443292113304939e-06,
      "loss": 0.0002,
      "step": 3516
    },
    {
      "epoch": 0.055686622227148215,
      "grad_norm": 0.0002473352069500834,
      "learning_rate": 9.443133777728518e-06,
      "loss": 0.0,
      "step": 3517
    },
    {
      "epoch": 0.055702455784790286,
      "grad_norm": 0.17551378905773163,
      "learning_rate": 9.442975442152099e-06,
      "loss": 0.3352,
      "step": 3518
    },
    {
      "epoch": 0.05571828934243235,
      "grad_norm": 0.2528208792209625,
      "learning_rate": 9.442817106575676e-06,
      "loss": 0.1356,
      "step": 3519
    },
    {
      "epoch": 0.055734122900074415,
      "grad_norm": 0.03129332885146141,
      "learning_rate": 9.442658770999257e-06,
      "loss": 0.0008,
      "step": 3520
    },
    {
      "epoch": 0.055749956457716486,
      "grad_norm": 0.1732327789068222,
      "learning_rate": 9.442500435422836e-06,
      "loss": 0.1645,
      "step": 3521
    },
    {
      "epoch": 0.05576579001535855,
      "grad_norm": 0.7172510027885437,
      "learning_rate": 9.442342099846415e-06,
      "loss": 0.0956,
      "step": 3522
    },
    {
      "epoch": 0.055781623573000615,
      "grad_norm": 0.18738576769828796,
      "learning_rate": 9.442183764269994e-06,
      "loss": 0.0092,
      "step": 3523
    },
    {
      "epoch": 0.055797457130642686,
      "grad_norm": 6.343495624605566e-05,
      "learning_rate": 9.442025428693575e-06,
      "loss": 0.0,
      "step": 3524
    },
    {
      "epoch": 0.05581329068828475,
      "grad_norm": 0.46862050890922546,
      "learning_rate": 9.441867093117152e-06,
      "loss": 0.6778,
      "step": 3525
    },
    {
      "epoch": 0.055829124245926814,
      "grad_norm": 0.13058781623840332,
      "learning_rate": 9.441708757540733e-06,
      "loss": 0.0504,
      "step": 3526
    },
    {
      "epoch": 0.055844957803568886,
      "grad_norm": 0.19064989686012268,
      "learning_rate": 9.441550421964312e-06,
      "loss": 0.0959,
      "step": 3527
    },
    {
      "epoch": 0.05586079136121095,
      "grad_norm": 0.006185241974890232,
      "learning_rate": 9.441392086387891e-06,
      "loss": 0.0003,
      "step": 3528
    },
    {
      "epoch": 0.055876624918853014,
      "grad_norm": 0.013256008736789227,
      "learning_rate": 9.44123375081147e-06,
      "loss": 0.0005,
      "step": 3529
    },
    {
      "epoch": 0.055892458476495085,
      "grad_norm": 0.31843751668930054,
      "learning_rate": 9.44107541523505e-06,
      "loss": 0.1674,
      "step": 3530
    },
    {
      "epoch": 0.05590829203413715,
      "grad_norm": 0.17077159881591797,
      "learning_rate": 9.440917079658629e-06,
      "loss": 0.1526,
      "step": 3531
    },
    {
      "epoch": 0.055924125591779214,
      "grad_norm": 0.14118921756744385,
      "learning_rate": 9.44075874408221e-06,
      "loss": 0.0573,
      "step": 3532
    },
    {
      "epoch": 0.055939959149421285,
      "grad_norm": 0.31561416387557983,
      "learning_rate": 9.440600408505788e-06,
      "loss": 0.263,
      "step": 3533
    },
    {
      "epoch": 0.05595579270706335,
      "grad_norm": 0.01808815449476242,
      "learning_rate": 9.440442072929368e-06,
      "loss": 0.0009,
      "step": 3534
    },
    {
      "epoch": 0.055971626264705414,
      "grad_norm": 0.011967746540904045,
      "learning_rate": 9.440283737352947e-06,
      "loss": 0.0007,
      "step": 3535
    },
    {
      "epoch": 0.055987459822347485,
      "grad_norm": 0.26227474212646484,
      "learning_rate": 9.440125401776526e-06,
      "loss": 0.487,
      "step": 3536
    },
    {
      "epoch": 0.05600329337998955,
      "grad_norm": 0.14896312355995178,
      "learning_rate": 9.439967066200105e-06,
      "loss": 0.0911,
      "step": 3537
    },
    {
      "epoch": 0.056019126937631614,
      "grad_norm": 0.424805611371994,
      "learning_rate": 9.439808730623684e-06,
      "loss": 0.4071,
      "step": 3538
    },
    {
      "epoch": 0.056034960495273685,
      "grad_norm": 0.12433633208274841,
      "learning_rate": 9.439650395047265e-06,
      "loss": 0.0502,
      "step": 3539
    },
    {
      "epoch": 0.05605079405291575,
      "grad_norm": 0.8235902190208435,
      "learning_rate": 9.439492059470842e-06,
      "loss": 0.6858,
      "step": 3540
    },
    {
      "epoch": 0.05606662761055781,
      "grad_norm": 0.49171680212020874,
      "learning_rate": 9.439333723894423e-06,
      "loss": 0.5691,
      "step": 3541
    },
    {
      "epoch": 0.056082461168199885,
      "grad_norm": 0.4303925633430481,
      "learning_rate": 9.439175388318002e-06,
      "loss": 0.6412,
      "step": 3542
    },
    {
      "epoch": 0.05609829472584195,
      "grad_norm": 0.09903369098901749,
      "learning_rate": 9.439017052741581e-06,
      "loss": 0.0484,
      "step": 3543
    },
    {
      "epoch": 0.05611412828348401,
      "grad_norm": 0.2390260249376297,
      "learning_rate": 9.43885871716516e-06,
      "loss": 0.1601,
      "step": 3544
    },
    {
      "epoch": 0.056129961841126084,
      "grad_norm": 0.026289187371730804,
      "learning_rate": 9.43870038158874e-06,
      "loss": 0.0021,
      "step": 3545
    },
    {
      "epoch": 0.05614579539876815,
      "grad_norm": 0.3439216911792755,
      "learning_rate": 9.438542046012318e-06,
      "loss": 0.6925,
      "step": 3546
    },
    {
      "epoch": 0.05616162895641021,
      "grad_norm": 0.49038687348365784,
      "learning_rate": 9.438383710435899e-06,
      "loss": 0.2084,
      "step": 3547
    },
    {
      "epoch": 0.056177462514052284,
      "grad_norm": 0.29508793354034424,
      "learning_rate": 9.438225374859478e-06,
      "loss": 0.1786,
      "step": 3548
    },
    {
      "epoch": 0.05619329607169435,
      "grad_norm": 0.001107859774492681,
      "learning_rate": 9.438067039283057e-06,
      "loss": 0.0,
      "step": 3549
    },
    {
      "epoch": 0.05620912962933641,
      "grad_norm": 0.203241229057312,
      "learning_rate": 9.437908703706636e-06,
      "loss": 0.571,
      "step": 3550
    },
    {
      "epoch": 0.056224963186978484,
      "grad_norm": 0.0062557109631598,
      "learning_rate": 9.437750368130217e-06,
      "loss": 0.0003,
      "step": 3551
    },
    {
      "epoch": 0.05624079674462055,
      "grad_norm": 0.02199411764740944,
      "learning_rate": 9.437592032553794e-06,
      "loss": 0.0017,
      "step": 3552
    },
    {
      "epoch": 0.05625663030226261,
      "grad_norm": 0.4745028614997864,
      "learning_rate": 9.437433696977375e-06,
      "loss": 0.2549,
      "step": 3553
    },
    {
      "epoch": 0.056272463859904684,
      "grad_norm": 0.15455344319343567,
      "learning_rate": 9.437275361400954e-06,
      "loss": 0.0647,
      "step": 3554
    },
    {
      "epoch": 0.05628829741754675,
      "grad_norm": 0.17911481857299805,
      "learning_rate": 9.437117025824533e-06,
      "loss": 0.0302,
      "step": 3555
    },
    {
      "epoch": 0.05630413097518881,
      "grad_norm": 0.188189297914505,
      "learning_rate": 9.436958690248112e-06,
      "loss": 0.092,
      "step": 3556
    },
    {
      "epoch": 0.056319964532830884,
      "grad_norm": 0.268009215593338,
      "learning_rate": 9.436800354671693e-06,
      "loss": 0.4855,
      "step": 3557
    },
    {
      "epoch": 0.05633579809047295,
      "grad_norm": 0.20523130893707275,
      "learning_rate": 9.43664201909527e-06,
      "loss": 0.0848,
      "step": 3558
    },
    {
      "epoch": 0.05635163164811501,
      "grad_norm": 0.4772661030292511,
      "learning_rate": 9.436483683518851e-06,
      "loss": 1.0994,
      "step": 3559
    },
    {
      "epoch": 0.056367465205757084,
      "grad_norm": 0.3653634488582611,
      "learning_rate": 9.43632534794243e-06,
      "loss": 0.3547,
      "step": 3560
    },
    {
      "epoch": 0.05638329876339915,
      "grad_norm": 0.5744121074676514,
      "learning_rate": 9.43616701236601e-06,
      "loss": 0.3235,
      "step": 3561
    },
    {
      "epoch": 0.05639913232104121,
      "grad_norm": 0.2666742503643036,
      "learning_rate": 9.436008676789589e-06,
      "loss": 0.1646,
      "step": 3562
    },
    {
      "epoch": 0.05641496587868328,
      "grad_norm": 0.10805090516805649,
      "learning_rate": 9.435850341213168e-06,
      "loss": 0.0047,
      "step": 3563
    },
    {
      "epoch": 0.05643079943632535,
      "grad_norm": 0.3359188139438629,
      "learning_rate": 9.435692005636747e-06,
      "loss": 0.2676,
      "step": 3564
    },
    {
      "epoch": 0.05644663299396741,
      "grad_norm": 0.22805725038051605,
      "learning_rate": 9.435533670060326e-06,
      "loss": 0.124,
      "step": 3565
    },
    {
      "epoch": 0.05646246655160948,
      "grad_norm": 0.009311248548328876,
      "learning_rate": 9.435375334483907e-06,
      "loss": 0.0005,
      "step": 3566
    },
    {
      "epoch": 0.05647830010925155,
      "grad_norm": 0.11996836960315704,
      "learning_rate": 9.435216998907486e-06,
      "loss": 0.0192,
      "step": 3567
    },
    {
      "epoch": 0.05649413366689361,
      "grad_norm": 0.31131625175476074,
      "learning_rate": 9.435058663331065e-06,
      "loss": 0.1641,
      "step": 3568
    },
    {
      "epoch": 0.05650996722453568,
      "grad_norm": 0.006351866759359837,
      "learning_rate": 9.434900327754644e-06,
      "loss": 0.0003,
      "step": 3569
    },
    {
      "epoch": 0.05652580078217775,
      "grad_norm": 0.15520866215229034,
      "learning_rate": 9.434741992178223e-06,
      "loss": 0.0491,
      "step": 3570
    },
    {
      "epoch": 0.05654163433981981,
      "grad_norm": 0.24156427383422852,
      "learning_rate": 9.434583656601802e-06,
      "loss": 0.3197,
      "step": 3571
    },
    {
      "epoch": 0.05655746789746188,
      "grad_norm": 0.00019221461843699217,
      "learning_rate": 9.434425321025383e-06,
      "loss": 0.0,
      "step": 3572
    },
    {
      "epoch": 0.05657330145510395,
      "grad_norm": 0.5878669023513794,
      "learning_rate": 9.434266985448962e-06,
      "loss": 0.1396,
      "step": 3573
    },
    {
      "epoch": 0.05658913501274601,
      "grad_norm": 0.1371145397424698,
      "learning_rate": 9.434108649872541e-06,
      "loss": 0.1175,
      "step": 3574
    },
    {
      "epoch": 0.05660496857038808,
      "grad_norm": 0.1800488829612732,
      "learning_rate": 9.43395031429612e-06,
      "loss": 0.0569,
      "step": 3575
    },
    {
      "epoch": 0.05662080212803015,
      "grad_norm": 0.35042229294776917,
      "learning_rate": 9.433791978719699e-06,
      "loss": 0.2185,
      "step": 3576
    },
    {
      "epoch": 0.05663663568567221,
      "grad_norm": 0.025806717574596405,
      "learning_rate": 9.433633643143278e-06,
      "loss": 0.0022,
      "step": 3577
    },
    {
      "epoch": 0.05665246924331428,
      "grad_norm": 0.011353575624525547,
      "learning_rate": 9.433475307566859e-06,
      "loss": 0.0006,
      "step": 3578
    },
    {
      "epoch": 0.05666830280095635,
      "grad_norm": 0.1401538997888565,
      "learning_rate": 9.433316971990438e-06,
      "loss": 0.117,
      "step": 3579
    },
    {
      "epoch": 0.05668413635859841,
      "grad_norm": 0.11763651669025421,
      "learning_rate": 9.433158636414017e-06,
      "loss": 0.0127,
      "step": 3580
    },
    {
      "epoch": 0.05669996991624048,
      "grad_norm": 0.5139588117599487,
      "learning_rate": 9.433000300837596e-06,
      "loss": 0.4033,
      "step": 3581
    },
    {
      "epoch": 0.056715803473882546,
      "grad_norm": 0.3617266118526459,
      "learning_rate": 9.432841965261175e-06,
      "loss": 0.0759,
      "step": 3582
    },
    {
      "epoch": 0.05673163703152461,
      "grad_norm": 0.02062324434518814,
      "learning_rate": 9.432683629684754e-06,
      "loss": 0.0028,
      "step": 3583
    },
    {
      "epoch": 0.05674747058916668,
      "grad_norm": 0.5094500184059143,
      "learning_rate": 9.432525294108335e-06,
      "loss": 0.1025,
      "step": 3584
    },
    {
      "epoch": 0.056763304146808746,
      "grad_norm": 0.1390254944562912,
      "learning_rate": 9.432366958531914e-06,
      "loss": 0.0299,
      "step": 3585
    },
    {
      "epoch": 0.05677913770445081,
      "grad_norm": 9.578585741110146e-05,
      "learning_rate": 9.432208622955492e-06,
      "loss": 0.0,
      "step": 3586
    },
    {
      "epoch": 0.05679497126209288,
      "grad_norm": 0.24588827788829803,
      "learning_rate": 9.432050287379072e-06,
      "loss": 0.1314,
      "step": 3587
    },
    {
      "epoch": 0.056810804819734946,
      "grad_norm": 0.011654476635158062,
      "learning_rate": 9.431891951802651e-06,
      "loss": 0.0007,
      "step": 3588
    },
    {
      "epoch": 0.05682663837737701,
      "grad_norm": 0.2578181326389313,
      "learning_rate": 9.43173361622623e-06,
      "loss": 0.1185,
      "step": 3589
    },
    {
      "epoch": 0.05684247193501908,
      "grad_norm": 0.002922080922871828,
      "learning_rate": 9.43157528064981e-06,
      "loss": 0.0001,
      "step": 3590
    },
    {
      "epoch": 0.056858305492661146,
      "grad_norm": 0.3204590082168579,
      "learning_rate": 9.431416945073389e-06,
      "loss": 0.2684,
      "step": 3591
    },
    {
      "epoch": 0.05687413905030321,
      "grad_norm": 0.09225279092788696,
      "learning_rate": 9.431258609496968e-06,
      "loss": 0.0697,
      "step": 3592
    },
    {
      "epoch": 0.05688997260794528,
      "grad_norm": 0.3783979117870331,
      "learning_rate": 9.431100273920548e-06,
      "loss": 0.9282,
      "step": 3593
    },
    {
      "epoch": 0.056905806165587346,
      "grad_norm": 0.3226949870586395,
      "learning_rate": 9.430941938344128e-06,
      "loss": 0.21,
      "step": 3594
    },
    {
      "epoch": 0.05692163972322941,
      "grad_norm": 0.426537424325943,
      "learning_rate": 9.430783602767707e-06,
      "loss": 0.3638,
      "step": 3595
    },
    {
      "epoch": 0.05693747328087148,
      "grad_norm": 0.11329386383295059,
      "learning_rate": 9.430625267191286e-06,
      "loss": 0.0123,
      "step": 3596
    },
    {
      "epoch": 0.056953306838513545,
      "grad_norm": 0.22644157707691193,
      "learning_rate": 9.430466931614865e-06,
      "loss": 0.1753,
      "step": 3597
    },
    {
      "epoch": 0.05696914039615561,
      "grad_norm": 0.015796774998307228,
      "learning_rate": 9.430308596038444e-06,
      "loss": 0.0008,
      "step": 3598
    },
    {
      "epoch": 0.05698497395379768,
      "grad_norm": 0.3102082312107086,
      "learning_rate": 9.430150260462025e-06,
      "loss": 0.0978,
      "step": 3599
    },
    {
      "epoch": 0.057000807511439745,
      "grad_norm": 0.4148620367050171,
      "learning_rate": 9.429991924885604e-06,
      "loss": 0.5357,
      "step": 3600
    },
    {
      "epoch": 0.05701664106908181,
      "grad_norm": 0.12311948835849762,
      "learning_rate": 9.429833589309183e-06,
      "loss": 0.0085,
      "step": 3601
    },
    {
      "epoch": 0.05703247462672388,
      "grad_norm": 0.0001676834945101291,
      "learning_rate": 9.429675253732762e-06,
      "loss": 0.0,
      "step": 3602
    },
    {
      "epoch": 0.057048308184365945,
      "grad_norm": 0.44018927216529846,
      "learning_rate": 9.429516918156341e-06,
      "loss": 0.0835,
      "step": 3603
    },
    {
      "epoch": 0.05706414174200801,
      "grad_norm": 0.308912456035614,
      "learning_rate": 9.42935858257992e-06,
      "loss": 0.2353,
      "step": 3604
    },
    {
      "epoch": 0.05707997529965008,
      "grad_norm": 0.3848230540752411,
      "learning_rate": 9.4292002470035e-06,
      "loss": 0.5928,
      "step": 3605
    },
    {
      "epoch": 0.057095808857292145,
      "grad_norm": 0.42420879006385803,
      "learning_rate": 9.42904191142708e-06,
      "loss": 0.046,
      "step": 3606
    },
    {
      "epoch": 0.05711164241493421,
      "grad_norm": 0.4007910490036011,
      "learning_rate": 9.428883575850659e-06,
      "loss": 0.3674,
      "step": 3607
    },
    {
      "epoch": 0.05712747597257628,
      "grad_norm": 0.20209935307502747,
      "learning_rate": 9.428725240274238e-06,
      "loss": 0.2901,
      "step": 3608
    },
    {
      "epoch": 0.057143309530218345,
      "grad_norm": 0.0012100618332624435,
      "learning_rate": 9.428566904697817e-06,
      "loss": 0.0001,
      "step": 3609
    },
    {
      "epoch": 0.05715914308786041,
      "grad_norm": 0.13698498904705048,
      "learning_rate": 9.428408569121396e-06,
      "loss": 0.0355,
      "step": 3610
    },
    {
      "epoch": 0.05717497664550248,
      "grad_norm": 0.30622097849845886,
      "learning_rate": 9.428250233544975e-06,
      "loss": 0.1821,
      "step": 3611
    },
    {
      "epoch": 0.057190810203144544,
      "grad_norm": 0.007524773012846708,
      "learning_rate": 9.428091897968556e-06,
      "loss": 0.0004,
      "step": 3612
    },
    {
      "epoch": 0.05720664376078661,
      "grad_norm": 0.0017621505539864302,
      "learning_rate": 9.427933562392133e-06,
      "loss": 0.0001,
      "step": 3613
    },
    {
      "epoch": 0.05722247731842868,
      "grad_norm": 0.21943533420562744,
      "learning_rate": 9.427775226815714e-06,
      "loss": 0.1806,
      "step": 3614
    },
    {
      "epoch": 0.057238310876070744,
      "grad_norm": 0.007020101882517338,
      "learning_rate": 9.427616891239293e-06,
      "loss": 0.0003,
      "step": 3615
    },
    {
      "epoch": 0.05725414443371281,
      "grad_norm": 0.4663848578929901,
      "learning_rate": 9.427458555662872e-06,
      "loss": 0.3517,
      "step": 3616
    },
    {
      "epoch": 0.05726997799135488,
      "grad_norm": 0.274734228849411,
      "learning_rate": 9.427300220086451e-06,
      "loss": 0.2012,
      "step": 3617
    },
    {
      "epoch": 0.057285811548996944,
      "grad_norm": 0.018050307407975197,
      "learning_rate": 9.427141884510032e-06,
      "loss": 0.001,
      "step": 3618
    },
    {
      "epoch": 0.05730164510663901,
      "grad_norm": 0.09305021166801453,
      "learning_rate": 9.42698354893361e-06,
      "loss": 0.0329,
      "step": 3619
    },
    {
      "epoch": 0.05731747866428108,
      "grad_norm": 0.022766519337892532,
      "learning_rate": 9.42682521335719e-06,
      "loss": 0.0015,
      "step": 3620
    },
    {
      "epoch": 0.057333312221923144,
      "grad_norm": 0.5102868676185608,
      "learning_rate": 9.42666687778077e-06,
      "loss": 0.2059,
      "step": 3621
    },
    {
      "epoch": 0.05734914577956521,
      "grad_norm": 0.6979836225509644,
      "learning_rate": 9.426508542204349e-06,
      "loss": 0.1248,
      "step": 3622
    },
    {
      "epoch": 0.05736497933720728,
      "grad_norm": 0.021876327693462372,
      "learning_rate": 9.426350206627928e-06,
      "loss": 0.0014,
      "step": 3623
    },
    {
      "epoch": 0.057380812894849344,
      "grad_norm": 3.750854969024658,
      "learning_rate": 9.426191871051508e-06,
      "loss": 0.0814,
      "step": 3624
    },
    {
      "epoch": 0.05739664645249141,
      "grad_norm": 0.2814846634864807,
      "learning_rate": 9.426033535475086e-06,
      "loss": 0.1364,
      "step": 3625
    },
    {
      "epoch": 0.05741248001013348,
      "grad_norm": 0.27761614322662354,
      "learning_rate": 9.425875199898667e-06,
      "loss": 0.1982,
      "step": 3626
    },
    {
      "epoch": 0.057428313567775544,
      "grad_norm": 0.2502862215042114,
      "learning_rate": 9.425716864322246e-06,
      "loss": 0.2165,
      "step": 3627
    },
    {
      "epoch": 0.05744414712541761,
      "grad_norm": 0.25855058431625366,
      "learning_rate": 9.425558528745825e-06,
      "loss": 0.0437,
      "step": 3628
    },
    {
      "epoch": 0.05745998068305968,
      "grad_norm": 0.3332817852497101,
      "learning_rate": 9.425400193169404e-06,
      "loss": 0.4008,
      "step": 3629
    },
    {
      "epoch": 0.05747581424070174,
      "grad_norm": 0.3037518858909607,
      "learning_rate": 9.425241857592985e-06,
      "loss": 0.2082,
      "step": 3630
    },
    {
      "epoch": 0.05749164779834381,
      "grad_norm": 0.05574093014001846,
      "learning_rate": 9.425083522016562e-06,
      "loss": 0.0062,
      "step": 3631
    },
    {
      "epoch": 0.05750748135598588,
      "grad_norm": 0.2911357581615448,
      "learning_rate": 9.424925186440143e-06,
      "loss": 0.1488,
      "step": 3632
    },
    {
      "epoch": 0.05752331491362794,
      "grad_norm": 0.23703131079673767,
      "learning_rate": 9.424766850863722e-06,
      "loss": 0.2263,
      "step": 3633
    },
    {
      "epoch": 0.05753914847127001,
      "grad_norm": 0.13801543414592743,
      "learning_rate": 9.424608515287301e-06,
      "loss": 0.0467,
      "step": 3634
    },
    {
      "epoch": 0.05755498202891208,
      "grad_norm": 0.24239112436771393,
      "learning_rate": 9.42445017971088e-06,
      "loss": 0.1683,
      "step": 3635
    },
    {
      "epoch": 0.05757081558655414,
      "grad_norm": 0.006341941654682159,
      "learning_rate": 9.424291844134459e-06,
      "loss": 0.0004,
      "step": 3636
    },
    {
      "epoch": 0.05758664914419621,
      "grad_norm": 0.3256123661994934,
      "learning_rate": 9.424133508558038e-06,
      "loss": 0.0419,
      "step": 3637
    },
    {
      "epoch": 0.05760248270183828,
      "grad_norm": 0.2049756646156311,
      "learning_rate": 9.423975172981617e-06,
      "loss": 0.4443,
      "step": 3638
    },
    {
      "epoch": 0.05761831625948034,
      "grad_norm": 0.3160145878791809,
      "learning_rate": 9.423816837405198e-06,
      "loss": 0.6797,
      "step": 3639
    },
    {
      "epoch": 0.05763414981712241,
      "grad_norm": 0.20259420573711395,
      "learning_rate": 9.423658501828777e-06,
      "loss": 0.0732,
      "step": 3640
    },
    {
      "epoch": 0.05764998337476448,
      "grad_norm": 0.2349012792110443,
      "learning_rate": 9.423500166252356e-06,
      "loss": 0.2777,
      "step": 3641
    },
    {
      "epoch": 0.05766581693240654,
      "grad_norm": 0.36133840680122375,
      "learning_rate": 9.423341830675935e-06,
      "loss": 0.1021,
      "step": 3642
    },
    {
      "epoch": 0.05768165049004861,
      "grad_norm": 0.0220938827842474,
      "learning_rate": 9.423183495099514e-06,
      "loss": 0.0015,
      "step": 3643
    },
    {
      "epoch": 0.05769748404769068,
      "grad_norm": 0.005010717082768679,
      "learning_rate": 9.423025159523093e-06,
      "loss": 0.0003,
      "step": 3644
    },
    {
      "epoch": 0.05771331760533274,
      "grad_norm": 0.5049583315849304,
      "learning_rate": 9.422866823946674e-06,
      "loss": 0.4504,
      "step": 3645
    },
    {
      "epoch": 0.05772915116297481,
      "grad_norm": 0.29983896017074585,
      "learning_rate": 9.422708488370253e-06,
      "loss": 0.186,
      "step": 3646
    },
    {
      "epoch": 0.05774498472061688,
      "grad_norm": 0.4857485294342041,
      "learning_rate": 9.422550152793832e-06,
      "loss": 0.064,
      "step": 3647
    },
    {
      "epoch": 0.05776081827825894,
      "grad_norm": 0.23706568777561188,
      "learning_rate": 9.422391817217411e-06,
      "loss": 0.0403,
      "step": 3648
    },
    {
      "epoch": 0.057776651835901006,
      "grad_norm": 0.26255273818969727,
      "learning_rate": 9.42223348164099e-06,
      "loss": 0.2526,
      "step": 3649
    },
    {
      "epoch": 0.05779248539354308,
      "grad_norm": 0.14497238397598267,
      "learning_rate": 9.42207514606457e-06,
      "loss": 0.112,
      "step": 3650
    },
    {
      "epoch": 0.05780831895118514,
      "grad_norm": 0.006176151800900698,
      "learning_rate": 9.42191681048815e-06,
      "loss": 0.0004,
      "step": 3651
    },
    {
      "epoch": 0.057824152508827206,
      "grad_norm": 0.47209957242012024,
      "learning_rate": 9.42175847491173e-06,
      "loss": 0.1696,
      "step": 3652
    },
    {
      "epoch": 0.05783998606646928,
      "grad_norm": 0.22231604158878326,
      "learning_rate": 9.421600139335308e-06,
      "loss": 0.4528,
      "step": 3653
    },
    {
      "epoch": 0.05785581962411134,
      "grad_norm": 0.2978239953517914,
      "learning_rate": 9.421441803758888e-06,
      "loss": 0.0431,
      "step": 3654
    },
    {
      "epoch": 0.057871653181753406,
      "grad_norm": 0.35163918137550354,
      "learning_rate": 9.421283468182467e-06,
      "loss": 0.0331,
      "step": 3655
    },
    {
      "epoch": 0.05788748673939548,
      "grad_norm": 0.20986106991767883,
      "learning_rate": 9.421125132606046e-06,
      "loss": 0.2941,
      "step": 3656
    },
    {
      "epoch": 0.05790332029703754,
      "grad_norm": 0.251790851354599,
      "learning_rate": 9.420966797029626e-06,
      "loss": 0.0565,
      "step": 3657
    },
    {
      "epoch": 0.057919153854679606,
      "grad_norm": 0.5616403818130493,
      "learning_rate": 9.420808461453204e-06,
      "loss": 0.6475,
      "step": 3658
    },
    {
      "epoch": 0.05793498741232168,
      "grad_norm": 0.18472838401794434,
      "learning_rate": 9.420650125876783e-06,
      "loss": 0.3294,
      "step": 3659
    },
    {
      "epoch": 0.05795082096996374,
      "grad_norm": 0.336902916431427,
      "learning_rate": 9.420491790300364e-06,
      "loss": 0.0292,
      "step": 3660
    },
    {
      "epoch": 0.057966654527605806,
      "grad_norm": 0.2854618430137634,
      "learning_rate": 9.420333454723943e-06,
      "loss": 0.5923,
      "step": 3661
    },
    {
      "epoch": 0.05798248808524788,
      "grad_norm": 0.010154848918318748,
      "learning_rate": 9.420175119147522e-06,
      "loss": 0.0008,
      "step": 3662
    },
    {
      "epoch": 0.05799832164288994,
      "grad_norm": 0.017831815406680107,
      "learning_rate": 9.420016783571101e-06,
      "loss": 0.0011,
      "step": 3663
    },
    {
      "epoch": 0.058014155200532005,
      "grad_norm": 0.0020312312990427017,
      "learning_rate": 9.41985844799468e-06,
      "loss": 0.0001,
      "step": 3664
    },
    {
      "epoch": 0.05802998875817408,
      "grad_norm": 0.0910395085811615,
      "learning_rate": 9.419700112418259e-06,
      "loss": 0.0055,
      "step": 3665
    },
    {
      "epoch": 0.05804582231581614,
      "grad_norm": 0.27957770228385925,
      "learning_rate": 9.41954177684184e-06,
      "loss": 0.0576,
      "step": 3666
    },
    {
      "epoch": 0.058061655873458205,
      "grad_norm": 0.48845240473747253,
      "learning_rate": 9.419383441265419e-06,
      "loss": 0.2988,
      "step": 3667
    },
    {
      "epoch": 0.058077489431100277,
      "grad_norm": 0.3065060079097748,
      "learning_rate": 9.419225105688998e-06,
      "loss": 0.0434,
      "step": 3668
    },
    {
      "epoch": 0.05809332298874234,
      "grad_norm": 0.5826291441917419,
      "learning_rate": 9.419066770112577e-06,
      "loss": 0.255,
      "step": 3669
    },
    {
      "epoch": 0.058109156546384405,
      "grad_norm": 0.19883877038955688,
      "learning_rate": 9.418908434536156e-06,
      "loss": 0.0575,
      "step": 3670
    },
    {
      "epoch": 0.058124990104026476,
      "grad_norm": 0.2143358290195465,
      "learning_rate": 9.418750098959735e-06,
      "loss": 0.1024,
      "step": 3671
    },
    {
      "epoch": 0.05814082366166854,
      "grad_norm": 0.19235648214817047,
      "learning_rate": 9.418591763383316e-06,
      "loss": 0.296,
      "step": 3672
    },
    {
      "epoch": 0.058156657219310605,
      "grad_norm": 0.0002508030738681555,
      "learning_rate": 9.418433427806895e-06,
      "loss": 0.0,
      "step": 3673
    },
    {
      "epoch": 0.058172490776952676,
      "grad_norm": 0.26873570680618286,
      "learning_rate": 9.418275092230474e-06,
      "loss": 0.6966,
      "step": 3674
    },
    {
      "epoch": 0.05818832433459474,
      "grad_norm": 0.4030352532863617,
      "learning_rate": 9.418116756654053e-06,
      "loss": 0.2869,
      "step": 3675
    },
    {
      "epoch": 0.058204157892236805,
      "grad_norm": 0.1953803449869156,
      "learning_rate": 9.417958421077632e-06,
      "loss": 0.1183,
      "step": 3676
    },
    {
      "epoch": 0.058219991449878876,
      "grad_norm": 0.29964300990104675,
      "learning_rate": 9.417800085501211e-06,
      "loss": 0.113,
      "step": 3677
    },
    {
      "epoch": 0.05823582500752094,
      "grad_norm": 0.035687003284692764,
      "learning_rate": 9.417641749924792e-06,
      "loss": 0.0024,
      "step": 3678
    },
    {
      "epoch": 0.058251658565163004,
      "grad_norm": 0.4557175934314728,
      "learning_rate": 9.417483414348371e-06,
      "loss": 0.5027,
      "step": 3679
    },
    {
      "epoch": 0.058267492122805076,
      "grad_norm": 0.15468856692314148,
      "learning_rate": 9.41732507877195e-06,
      "loss": 0.1339,
      "step": 3680
    },
    {
      "epoch": 0.05828332568044714,
      "grad_norm": 0.29192814230918884,
      "learning_rate": 9.41716674319553e-06,
      "loss": 0.0269,
      "step": 3681
    },
    {
      "epoch": 0.058299159238089204,
      "grad_norm": 0.8943203091621399,
      "learning_rate": 9.417008407619109e-06,
      "loss": 0.3666,
      "step": 3682
    },
    {
      "epoch": 0.058314992795731276,
      "grad_norm": 0.23288390040397644,
      "learning_rate": 9.416850072042688e-06,
      "loss": 0.059,
      "step": 3683
    },
    {
      "epoch": 0.05833082635337334,
      "grad_norm": 4.5161868911236525e-05,
      "learning_rate": 9.416691736466267e-06,
      "loss": 0.0,
      "step": 3684
    },
    {
      "epoch": 0.058346659911015404,
      "grad_norm": 0.011277991347014904,
      "learning_rate": 9.416533400889847e-06,
      "loss": 0.0005,
      "step": 3685
    },
    {
      "epoch": 0.058362493468657475,
      "grad_norm": 0.21141745150089264,
      "learning_rate": 9.416375065313425e-06,
      "loss": 0.0724,
      "step": 3686
    },
    {
      "epoch": 0.05837832702629954,
      "grad_norm": 0.6432041525840759,
      "learning_rate": 9.416216729737006e-06,
      "loss": 0.6402,
      "step": 3687
    },
    {
      "epoch": 0.058394160583941604,
      "grad_norm": 0.3400830924510956,
      "learning_rate": 9.416058394160585e-06,
      "loss": 0.3759,
      "step": 3688
    },
    {
      "epoch": 0.058409994141583675,
      "grad_norm": 0.22397799789905548,
      "learning_rate": 9.415900058584164e-06,
      "loss": 0.1199,
      "step": 3689
    },
    {
      "epoch": 0.05842582769922574,
      "grad_norm": 0.33638641238212585,
      "learning_rate": 9.415741723007743e-06,
      "loss": 0.1861,
      "step": 3690
    },
    {
      "epoch": 0.058441661256867804,
      "grad_norm": 0.19980676472187042,
      "learning_rate": 9.415583387431324e-06,
      "loss": 0.0502,
      "step": 3691
    },
    {
      "epoch": 0.058457494814509875,
      "grad_norm": 0.36136165261268616,
      "learning_rate": 9.415425051854901e-06,
      "loss": 0.0403,
      "step": 3692
    },
    {
      "epoch": 0.05847332837215194,
      "grad_norm": 0.06877899914979935,
      "learning_rate": 9.415266716278482e-06,
      "loss": 0.0059,
      "step": 3693
    },
    {
      "epoch": 0.058489161929794004,
      "grad_norm": 0.1931696981191635,
      "learning_rate": 9.415108380702061e-06,
      "loss": 0.0543,
      "step": 3694
    },
    {
      "epoch": 0.058504995487436075,
      "grad_norm": 0.23995403945446014,
      "learning_rate": 9.41495004512564e-06,
      "loss": 0.142,
      "step": 3695
    },
    {
      "epoch": 0.05852082904507814,
      "grad_norm": 0.4247558116912842,
      "learning_rate": 9.414791709549219e-06,
      "loss": 0.1505,
      "step": 3696
    },
    {
      "epoch": 0.0585366626027202,
      "grad_norm": 0.7226775884628296,
      "learning_rate": 9.4146333739728e-06,
      "loss": 1.0616,
      "step": 3697
    },
    {
      "epoch": 0.058552496160362275,
      "grad_norm": 0.4213804304599762,
      "learning_rate": 9.414475038396377e-06,
      "loss": 0.1601,
      "step": 3698
    },
    {
      "epoch": 0.05856832971800434,
      "grad_norm": 0.00011795275349868461,
      "learning_rate": 9.414316702819958e-06,
      "loss": 0.0,
      "step": 3699
    },
    {
      "epoch": 0.0585841632756464,
      "grad_norm": 0.2224385142326355,
      "learning_rate": 9.414158367243537e-06,
      "loss": 0.0729,
      "step": 3700
    },
    {
      "epoch": 0.058599996833288474,
      "grad_norm": 0.35071203112602234,
      "learning_rate": 9.414000031667116e-06,
      "loss": 0.162,
      "step": 3701
    },
    {
      "epoch": 0.05861583039093054,
      "grad_norm": 0.288116455078125,
      "learning_rate": 9.413841696090695e-06,
      "loss": 0.1195,
      "step": 3702
    },
    {
      "epoch": 0.0586316639485726,
      "grad_norm": 1.1660938262939453,
      "learning_rate": 9.413683360514276e-06,
      "loss": 0.0263,
      "step": 3703
    },
    {
      "epoch": 0.058647497506214674,
      "grad_norm": 0.013677839189767838,
      "learning_rate": 9.413525024937853e-06,
      "loss": 0.0007,
      "step": 3704
    },
    {
      "epoch": 0.05866333106385674,
      "grad_norm": 0.20646654069423676,
      "learning_rate": 9.413366689361434e-06,
      "loss": 0.2131,
      "step": 3705
    },
    {
      "epoch": 0.0586791646214988,
      "grad_norm": 0.2349117547273636,
      "learning_rate": 9.413208353785013e-06,
      "loss": 0.1639,
      "step": 3706
    },
    {
      "epoch": 0.058694998179140874,
      "grad_norm": 0.09474142640829086,
      "learning_rate": 9.413050018208592e-06,
      "loss": 0.0473,
      "step": 3707
    },
    {
      "epoch": 0.05871083173678294,
      "grad_norm": 0.017055755481123924,
      "learning_rate": 9.412891682632171e-06,
      "loss": 0.0011,
      "step": 3708
    },
    {
      "epoch": 0.058726665294425,
      "grad_norm": 0.35176974534988403,
      "learning_rate": 9.41273334705575e-06,
      "loss": 0.2657,
      "step": 3709
    },
    {
      "epoch": 0.058742498852067074,
      "grad_norm": 0.23964764177799225,
      "learning_rate": 9.41257501147933e-06,
      "loss": 0.1849,
      "step": 3710
    },
    {
      "epoch": 0.05875833240970914,
      "grad_norm": 0.40371936559677124,
      "learning_rate": 9.412416675902909e-06,
      "loss": 0.0437,
      "step": 3711
    },
    {
      "epoch": 0.0587741659673512,
      "grad_norm": 0.2890546917915344,
      "learning_rate": 9.41225834032649e-06,
      "loss": 0.1473,
      "step": 3712
    },
    {
      "epoch": 0.058789999524993274,
      "grad_norm": 0.003772428957745433,
      "learning_rate": 9.412100004750069e-06,
      "loss": 0.0001,
      "step": 3713
    },
    {
      "epoch": 0.05880583308263534,
      "grad_norm": 0.32766193151474,
      "learning_rate": 9.411941669173648e-06,
      "loss": 0.173,
      "step": 3714
    },
    {
      "epoch": 0.0588216666402774,
      "grad_norm": 0.17067934572696686,
      "learning_rate": 9.411783333597227e-06,
      "loss": 0.2354,
      "step": 3715
    },
    {
      "epoch": 0.05883750019791947,
      "grad_norm": 0.27586954832077026,
      "learning_rate": 9.411624998020806e-06,
      "loss": 0.1683,
      "step": 3716
    },
    {
      "epoch": 0.05885333375556154,
      "grad_norm": 0.2344599813222885,
      "learning_rate": 9.411466662444385e-06,
      "loss": 0.1991,
      "step": 3717
    },
    {
      "epoch": 0.0588691673132036,
      "grad_norm": 0.0026309771928936243,
      "learning_rate": 9.411308326867966e-06,
      "loss": 0.0001,
      "step": 3718
    },
    {
      "epoch": 0.05888500087084567,
      "grad_norm": 0.0053760698065161705,
      "learning_rate": 9.411149991291545e-06,
      "loss": 0.0001,
      "step": 3719
    },
    {
      "epoch": 0.05890083442848774,
      "grad_norm": 0.3102704584598541,
      "learning_rate": 9.410991655715124e-06,
      "loss": 0.461,
      "step": 3720
    },
    {
      "epoch": 0.0589166679861298,
      "grad_norm": 0.019329167902469635,
      "learning_rate": 9.410833320138703e-06,
      "loss": 0.001,
      "step": 3721
    },
    {
      "epoch": 0.05893250154377187,
      "grad_norm": 0.016230124980211258,
      "learning_rate": 9.410674984562282e-06,
      "loss": 0.001,
      "step": 3722
    },
    {
      "epoch": 0.05894833510141394,
      "grad_norm": 0.0019499707268550992,
      "learning_rate": 9.410516648985861e-06,
      "loss": 0.0,
      "step": 3723
    },
    {
      "epoch": 0.058964168659056,
      "grad_norm": 0.2908933162689209,
      "learning_rate": 9.410358313409442e-06,
      "loss": 0.11,
      "step": 3724
    },
    {
      "epoch": 0.05898000221669807,
      "grad_norm": 0.19306233525276184,
      "learning_rate": 9.410199977833019e-06,
      "loss": 0.1038,
      "step": 3725
    },
    {
      "epoch": 0.05899583577434014,
      "grad_norm": 0.1328095942735672,
      "learning_rate": 9.4100416422566e-06,
      "loss": 0.049,
      "step": 3726
    },
    {
      "epoch": 0.0590116693319822,
      "grad_norm": 0.5436438918113708,
      "learning_rate": 9.409883306680179e-06,
      "loss": 0.7596,
      "step": 3727
    },
    {
      "epoch": 0.05902750288962427,
      "grad_norm": 0.10573560744524002,
      "learning_rate": 9.409724971103758e-06,
      "loss": 0.0725,
      "step": 3728
    },
    {
      "epoch": 0.05904333644726634,
      "grad_norm": 0.0023519035894423723,
      "learning_rate": 9.409566635527337e-06,
      "loss": 0.0,
      "step": 3729
    },
    {
      "epoch": 0.0590591700049084,
      "grad_norm": 0.6066360473632812,
      "learning_rate": 9.409408299950916e-06,
      "loss": 0.0138,
      "step": 3730
    },
    {
      "epoch": 0.05907500356255047,
      "grad_norm": 0.12105739861726761,
      "learning_rate": 9.409249964374495e-06,
      "loss": 0.0207,
      "step": 3731
    },
    {
      "epoch": 0.05909083712019254,
      "grad_norm": 0.3195386230945587,
      "learning_rate": 9.409091628798074e-06,
      "loss": 0.0814,
      "step": 3732
    },
    {
      "epoch": 0.0591066706778346,
      "grad_norm": 1.594754934310913,
      "learning_rate": 9.408933293221655e-06,
      "loss": 0.0738,
      "step": 3733
    },
    {
      "epoch": 0.05912250423547667,
      "grad_norm": 0.29593926668167114,
      "learning_rate": 9.408774957645234e-06,
      "loss": 0.2505,
      "step": 3734
    },
    {
      "epoch": 0.059138337793118737,
      "grad_norm": 0.18642012774944305,
      "learning_rate": 9.408616622068813e-06,
      "loss": 0.0548,
      "step": 3735
    },
    {
      "epoch": 0.0591541713507608,
      "grad_norm": 0.00010759376164060086,
      "learning_rate": 9.408458286492392e-06,
      "loss": 0.0,
      "step": 3736
    },
    {
      "epoch": 0.05917000490840287,
      "grad_norm": 0.005471395794302225,
      "learning_rate": 9.408299950915971e-06,
      "loss": 0.0003,
      "step": 3737
    },
    {
      "epoch": 0.059185838466044936,
      "grad_norm": 0.27386799454689026,
      "learning_rate": 9.40814161533955e-06,
      "loss": 0.3564,
      "step": 3738
    },
    {
      "epoch": 0.059201672023687,
      "grad_norm": 0.3214533030986786,
      "learning_rate": 9.407983279763131e-06,
      "loss": 0.386,
      "step": 3739
    },
    {
      "epoch": 0.05921750558132907,
      "grad_norm": 0.02847268432378769,
      "learning_rate": 9.40782494418671e-06,
      "loss": 0.0012,
      "step": 3740
    },
    {
      "epoch": 0.059233339138971136,
      "grad_norm": 3.004585232702084e-05,
      "learning_rate": 9.40766660861029e-06,
      "loss": 0.0,
      "step": 3741
    },
    {
      "epoch": 0.0592491726966132,
      "grad_norm": 0.23371411859989166,
      "learning_rate": 9.407508273033869e-06,
      "loss": 0.1315,
      "step": 3742
    },
    {
      "epoch": 0.05926500625425527,
      "grad_norm": 0.40955761075019836,
      "learning_rate": 9.407349937457448e-06,
      "loss": 0.17,
      "step": 3743
    },
    {
      "epoch": 0.059280839811897336,
      "grad_norm": 0.4408082962036133,
      "learning_rate": 9.407191601881027e-06,
      "loss": 0.2471,
      "step": 3744
    },
    {
      "epoch": 0.0592966733695394,
      "grad_norm": 0.14016589522361755,
      "learning_rate": 9.407033266304608e-06,
      "loss": 0.0518,
      "step": 3745
    },
    {
      "epoch": 0.05931250692718147,
      "grad_norm": 0.006533911917358637,
      "learning_rate": 9.406874930728187e-06,
      "loss": 0.0001,
      "step": 3746
    },
    {
      "epoch": 0.059328340484823536,
      "grad_norm": 0.24688932299613953,
      "learning_rate": 9.406716595151766e-06,
      "loss": 0.0887,
      "step": 3747
    },
    {
      "epoch": 0.0593441740424656,
      "grad_norm": 0.41771942377090454,
      "learning_rate": 9.406558259575345e-06,
      "loss": 0.2953,
      "step": 3748
    },
    {
      "epoch": 0.05936000760010767,
      "grad_norm": 0.0715363398194313,
      "learning_rate": 9.406399923998924e-06,
      "loss": 0.0015,
      "step": 3749
    },
    {
      "epoch": 0.059375841157749736,
      "grad_norm": 0.0009680192451924086,
      "learning_rate": 9.406241588422503e-06,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 0.0593916747153918,
      "grad_norm": 0.2044486105442047,
      "learning_rate": 9.406083252846084e-06,
      "loss": 0.0169,
      "step": 3751
    },
    {
      "epoch": 0.05940750827303387,
      "grad_norm": 0.002024140441790223,
      "learning_rate": 9.405924917269663e-06,
      "loss": 0.0,
      "step": 3752
    },
    {
      "epoch": 0.059423341830675935,
      "grad_norm": 0.014726473018527031,
      "learning_rate": 9.405766581693242e-06,
      "loss": 0.0008,
      "step": 3753
    },
    {
      "epoch": 0.059439175388318,
      "grad_norm": 0.8642147779464722,
      "learning_rate": 9.405608246116821e-06,
      "loss": 0.0996,
      "step": 3754
    },
    {
      "epoch": 0.05945500894596007,
      "grad_norm": 0.231632262468338,
      "learning_rate": 9.4054499105404e-06,
      "loss": 0.3318,
      "step": 3755
    },
    {
      "epoch": 0.059470842503602135,
      "grad_norm": 0.09837011247873306,
      "learning_rate": 9.405291574963979e-06,
      "loss": 0.0087,
      "step": 3756
    },
    {
      "epoch": 0.0594866760612442,
      "grad_norm": 0.22036954760551453,
      "learning_rate": 9.405133239387558e-06,
      "loss": 0.2863,
      "step": 3757
    },
    {
      "epoch": 0.05950250961888627,
      "grad_norm": 0.3364049196243286,
      "learning_rate": 9.404974903811139e-06,
      "loss": 0.8991,
      "step": 3758
    },
    {
      "epoch": 0.059518343176528335,
      "grad_norm": 0.006616545841097832,
      "learning_rate": 9.404816568234716e-06,
      "loss": 0.0003,
      "step": 3759
    },
    {
      "epoch": 0.0595341767341704,
      "grad_norm": 0.007059467025101185,
      "learning_rate": 9.404658232658297e-06,
      "loss": 0.0004,
      "step": 3760
    },
    {
      "epoch": 0.05955001029181247,
      "grad_norm": 0.3639408051967621,
      "learning_rate": 9.404499897081876e-06,
      "loss": 0.0505,
      "step": 3761
    },
    {
      "epoch": 0.059565843849454535,
      "grad_norm": 0.5039525628089905,
      "learning_rate": 9.404341561505455e-06,
      "loss": 0.179,
      "step": 3762
    },
    {
      "epoch": 0.0595816774070966,
      "grad_norm": 5.254705905914307,
      "learning_rate": 9.404183225929034e-06,
      "loss": 0.1978,
      "step": 3763
    },
    {
      "epoch": 0.05959751096473867,
      "grad_norm": 0.03728640079498291,
      "learning_rate": 9.404024890352615e-06,
      "loss": 0.0019,
      "step": 3764
    },
    {
      "epoch": 0.059613344522380735,
      "grad_norm": 0.3662351369857788,
      "learning_rate": 9.403866554776192e-06,
      "loss": 0.0783,
      "step": 3765
    },
    {
      "epoch": 0.0596291780800228,
      "grad_norm": 0.3927861452102661,
      "learning_rate": 9.403708219199773e-06,
      "loss": 0.0586,
      "step": 3766
    },
    {
      "epoch": 0.05964501163766487,
      "grad_norm": 0.21525061130523682,
      "learning_rate": 9.403549883623352e-06,
      "loss": 0.1454,
      "step": 3767
    },
    {
      "epoch": 0.059660845195306934,
      "grad_norm": 0.34506604075431824,
      "learning_rate": 9.403391548046931e-06,
      "loss": 0.263,
      "step": 3768
    },
    {
      "epoch": 0.059676678752949,
      "grad_norm": 0.0003545107028912753,
      "learning_rate": 9.40323321247051e-06,
      "loss": 0.0,
      "step": 3769
    },
    {
      "epoch": 0.05969251231059107,
      "grad_norm": 0.024134714156389236,
      "learning_rate": 9.403074876894091e-06,
      "loss": 0.0021,
      "step": 3770
    },
    {
      "epoch": 0.059708345868233134,
      "grad_norm": 0.25855016708374023,
      "learning_rate": 9.402916541317669e-06,
      "loss": 0.1566,
      "step": 3771
    },
    {
      "epoch": 0.0597241794258752,
      "grad_norm": 5.507135938387364e-05,
      "learning_rate": 9.40275820574125e-06,
      "loss": 0.0,
      "step": 3772
    },
    {
      "epoch": 0.05974001298351727,
      "grad_norm": 0.005804781801998615,
      "learning_rate": 9.402599870164829e-06,
      "loss": 0.0003,
      "step": 3773
    },
    {
      "epoch": 0.059755846541159334,
      "grad_norm": 0.6338958144187927,
      "learning_rate": 9.402441534588408e-06,
      "loss": 0.3775,
      "step": 3774
    },
    {
      "epoch": 0.0597716800988014,
      "grad_norm": 0.17291243374347687,
      "learning_rate": 9.402283199011987e-06,
      "loss": 0.2957,
      "step": 3775
    },
    {
      "epoch": 0.05978751365644347,
      "grad_norm": 0.314142644405365,
      "learning_rate": 9.402124863435567e-06,
      "loss": 0.1157,
      "step": 3776
    },
    {
      "epoch": 0.059803347214085534,
      "grad_norm": 0.4336627423763275,
      "learning_rate": 9.401966527859145e-06,
      "loss": 0.3633,
      "step": 3777
    },
    {
      "epoch": 0.0598191807717276,
      "grad_norm": 0.4700326919555664,
      "learning_rate": 9.401808192282724e-06,
      "loss": 0.3597,
      "step": 3778
    },
    {
      "epoch": 0.05983501432936967,
      "grad_norm": 0.041070424020290375,
      "learning_rate": 9.401649856706305e-06,
      "loss": 0.0024,
      "step": 3779
    },
    {
      "epoch": 0.059850847887011734,
      "grad_norm": 0.1558462381362915,
      "learning_rate": 9.401491521129884e-06,
      "loss": 0.0464,
      "step": 3780
    },
    {
      "epoch": 0.0598666814446538,
      "grad_norm": 0.12419337779283524,
      "learning_rate": 9.401333185553463e-06,
      "loss": 0.102,
      "step": 3781
    },
    {
      "epoch": 0.05988251500229587,
      "grad_norm": 0.44598937034606934,
      "learning_rate": 9.401174849977042e-06,
      "loss": 0.3402,
      "step": 3782
    },
    {
      "epoch": 0.05989834855993793,
      "grad_norm": 3.903533797711134e-05,
      "learning_rate": 9.401016514400621e-06,
      "loss": 0.0,
      "step": 3783
    },
    {
      "epoch": 0.05991418211758,
      "grad_norm": 0.02155282348394394,
      "learning_rate": 9.4008581788242e-06,
      "loss": 0.0014,
      "step": 3784
    },
    {
      "epoch": 0.05993001567522207,
      "grad_norm": 0.23516184091567993,
      "learning_rate": 9.400699843247781e-06,
      "loss": 0.0548,
      "step": 3785
    },
    {
      "epoch": 0.05994584923286413,
      "grad_norm": 0.13410934805870056,
      "learning_rate": 9.400541507671358e-06,
      "loss": 0.0324,
      "step": 3786
    },
    {
      "epoch": 0.0599616827905062,
      "grad_norm": 0.5516802072525024,
      "learning_rate": 9.400383172094939e-06,
      "loss": 0.1287,
      "step": 3787
    },
    {
      "epoch": 0.05997751634814827,
      "grad_norm": 0.28350457549095154,
      "learning_rate": 9.400224836518518e-06,
      "loss": 0.043,
      "step": 3788
    },
    {
      "epoch": 0.05999334990579033,
      "grad_norm": 0.2060972899198532,
      "learning_rate": 9.400066500942097e-06,
      "loss": 0.1716,
      "step": 3789
    },
    {
      "epoch": 0.0600091834634324,
      "grad_norm": 0.6711511611938477,
      "learning_rate": 9.399908165365676e-06,
      "loss": 0.2785,
      "step": 3790
    },
    {
      "epoch": 0.06002501702107447,
      "grad_norm": 0.3305024802684784,
      "learning_rate": 9.399749829789257e-06,
      "loss": 0.1422,
      "step": 3791
    },
    {
      "epoch": 0.06004085057871653,
      "grad_norm": 0.2853080928325653,
      "learning_rate": 9.399591494212834e-06,
      "loss": 0.51,
      "step": 3792
    },
    {
      "epoch": 0.0600566841363586,
      "grad_norm": 0.2476661503314972,
      "learning_rate": 9.399433158636415e-06,
      "loss": 0.0467,
      "step": 3793
    },
    {
      "epoch": 0.06007251769400067,
      "grad_norm": 0.3156886696815491,
      "learning_rate": 9.399274823059994e-06,
      "loss": 0.0676,
      "step": 3794
    },
    {
      "epoch": 0.06008835125164273,
      "grad_norm": 0.18996880948543549,
      "learning_rate": 9.399116487483573e-06,
      "loss": 0.1293,
      "step": 3795
    },
    {
      "epoch": 0.0601041848092848,
      "grad_norm": 0.26356497406959534,
      "learning_rate": 9.398958151907152e-06,
      "loss": 0.9458,
      "step": 3796
    },
    {
      "epoch": 0.06012001836692687,
      "grad_norm": 0.26048603653907776,
      "learning_rate": 9.398799816330733e-06,
      "loss": 0.0333,
      "step": 3797
    },
    {
      "epoch": 0.06013585192456893,
      "grad_norm": 0.1474277526140213,
      "learning_rate": 9.39864148075431e-06,
      "loss": 0.0471,
      "step": 3798
    },
    {
      "epoch": 0.060151685482211,
      "grad_norm": 0.15660984814167023,
      "learning_rate": 9.398483145177891e-06,
      "loss": 0.0439,
      "step": 3799
    },
    {
      "epoch": 0.06016751903985307,
      "grad_norm": 0.30688315629959106,
      "learning_rate": 9.39832480960147e-06,
      "loss": 0.2958,
      "step": 3800
    },
    {
      "epoch": 0.06018335259749513,
      "grad_norm": 0.14262323081493378,
      "learning_rate": 9.39816647402505e-06,
      "loss": 0.042,
      "step": 3801
    },
    {
      "epoch": 0.060199186155137197,
      "grad_norm": 0.16002492606639862,
      "learning_rate": 9.398008138448629e-06,
      "loss": 0.1313,
      "step": 3802
    },
    {
      "epoch": 0.06021501971277927,
      "grad_norm": 0.05747320130467415,
      "learning_rate": 9.397849802872208e-06,
      "loss": 0.0049,
      "step": 3803
    },
    {
      "epoch": 0.06023085327042133,
      "grad_norm": 0.010773505084216595,
      "learning_rate": 9.397691467295787e-06,
      "loss": 0.0003,
      "step": 3804
    },
    {
      "epoch": 0.060246686828063396,
      "grad_norm": 0.1794978231191635,
      "learning_rate": 9.397533131719366e-06,
      "loss": 0.0609,
      "step": 3805
    },
    {
      "epoch": 0.06026252038570547,
      "grad_norm": 0.21010610461235046,
      "learning_rate": 9.397374796142947e-06,
      "loss": 0.0324,
      "step": 3806
    },
    {
      "epoch": 0.06027835394334753,
      "grad_norm": 0.639830470085144,
      "learning_rate": 9.397216460566526e-06,
      "loss": 0.3138,
      "step": 3807
    },
    {
      "epoch": 0.060294187500989596,
      "grad_norm": 0.2572617530822754,
      "learning_rate": 9.397058124990105e-06,
      "loss": 0.0759,
      "step": 3808
    },
    {
      "epoch": 0.06031002105863167,
      "grad_norm": 0.05726368725299835,
      "learning_rate": 9.396899789413684e-06,
      "loss": 0.0078,
      "step": 3809
    },
    {
      "epoch": 0.06032585461627373,
      "grad_norm": 0.5629478096961975,
      "learning_rate": 9.396741453837263e-06,
      "loss": 0.0919,
      "step": 3810
    },
    {
      "epoch": 0.060341688173915796,
      "grad_norm": 0.6459384560585022,
      "learning_rate": 9.396583118260842e-06,
      "loss": 0.2038,
      "step": 3811
    },
    {
      "epoch": 0.06035752173155787,
      "grad_norm": 0.31249234080314636,
      "learning_rate": 9.396424782684423e-06,
      "loss": 0.1926,
      "step": 3812
    },
    {
      "epoch": 0.06037335528919993,
      "grad_norm": 0.20466335117816925,
      "learning_rate": 9.396266447108002e-06,
      "loss": 0.008,
      "step": 3813
    },
    {
      "epoch": 0.060389188846841996,
      "grad_norm": 0.19419723749160767,
      "learning_rate": 9.396108111531581e-06,
      "loss": 0.0603,
      "step": 3814
    },
    {
      "epoch": 0.06040502240448407,
      "grad_norm": 0.03868354484438896,
      "learning_rate": 9.39594977595516e-06,
      "loss": 0.0056,
      "step": 3815
    },
    {
      "epoch": 0.06042085596212613,
      "grad_norm": 0.27516037225723267,
      "learning_rate": 9.395791440378739e-06,
      "loss": 0.1639,
      "step": 3816
    },
    {
      "epoch": 0.060436689519768196,
      "grad_norm": 0.1576165109872818,
      "learning_rate": 9.395633104802318e-06,
      "loss": 0.0685,
      "step": 3817
    },
    {
      "epoch": 0.06045252307741027,
      "grad_norm": 0.25833582878112793,
      "learning_rate": 9.395474769225899e-06,
      "loss": 0.1171,
      "step": 3818
    },
    {
      "epoch": 0.06046835663505233,
      "grad_norm": 0.18392659723758698,
      "learning_rate": 9.395316433649478e-06,
      "loss": 0.0848,
      "step": 3819
    },
    {
      "epoch": 0.060484190192694395,
      "grad_norm": 0.19822341203689575,
      "learning_rate": 9.395158098073057e-06,
      "loss": 0.0651,
      "step": 3820
    },
    {
      "epoch": 0.06050002375033647,
      "grad_norm": 0.12381041795015335,
      "learning_rate": 9.394999762496636e-06,
      "loss": 0.0449,
      "step": 3821
    },
    {
      "epoch": 0.06051585730797853,
      "grad_norm": 0.01001045759767294,
      "learning_rate": 9.394841426920215e-06,
      "loss": 0.0005,
      "step": 3822
    },
    {
      "epoch": 0.060531690865620595,
      "grad_norm": 0.16973844170570374,
      "learning_rate": 9.394683091343794e-06,
      "loss": 0.042,
      "step": 3823
    },
    {
      "epoch": 0.06054752442326266,
      "grad_norm": 0.36800840497016907,
      "learning_rate": 9.394524755767375e-06,
      "loss": 0.6008,
      "step": 3824
    },
    {
      "epoch": 0.06056335798090473,
      "grad_norm": 0.8653287887573242,
      "learning_rate": 9.394366420190954e-06,
      "loss": 0.82,
      "step": 3825
    },
    {
      "epoch": 0.060579191538546795,
      "grad_norm": 0.061598341912031174,
      "learning_rate": 9.394208084614532e-06,
      "loss": 0.0021,
      "step": 3826
    },
    {
      "epoch": 0.06059502509618886,
      "grad_norm": 0.19244569540023804,
      "learning_rate": 9.394049749038112e-06,
      "loss": 0.095,
      "step": 3827
    },
    {
      "epoch": 0.06061085865383093,
      "grad_norm": 0.0027165429200977087,
      "learning_rate": 9.393891413461691e-06,
      "loss": 0.0001,
      "step": 3828
    },
    {
      "epoch": 0.060626692211472995,
      "grad_norm": 0.004245849791914225,
      "learning_rate": 9.39373307788527e-06,
      "loss": 0.0002,
      "step": 3829
    },
    {
      "epoch": 0.06064252576911506,
      "grad_norm": 0.5340732932090759,
      "learning_rate": 9.39357474230885e-06,
      "loss": 0.0138,
      "step": 3830
    },
    {
      "epoch": 0.06065835932675713,
      "grad_norm": 0.6268967390060425,
      "learning_rate": 9.39341640673243e-06,
      "loss": 0.3533,
      "step": 3831
    },
    {
      "epoch": 0.060674192884399195,
      "grad_norm": 0.3274461328983307,
      "learning_rate": 9.393258071156008e-06,
      "loss": 0.2209,
      "step": 3832
    },
    {
      "epoch": 0.06069002644204126,
      "grad_norm": 0.008170046843588352,
      "learning_rate": 9.393099735579589e-06,
      "loss": 0.0005,
      "step": 3833
    },
    {
      "epoch": 0.06070585999968333,
      "grad_norm": 0.011558057740330696,
      "learning_rate": 9.392941400003168e-06,
      "loss": 0.0006,
      "step": 3834
    },
    {
      "epoch": 0.060721693557325394,
      "grad_norm": 0.22632238268852234,
      "learning_rate": 9.392783064426747e-06,
      "loss": 0.0581,
      "step": 3835
    },
    {
      "epoch": 0.06073752711496746,
      "grad_norm": 0.6736129522323608,
      "learning_rate": 9.392624728850326e-06,
      "loss": 0.1757,
      "step": 3836
    },
    {
      "epoch": 0.06075336067260953,
      "grad_norm": 0.735246479511261,
      "learning_rate": 9.392466393273907e-06,
      "loss": 0.0294,
      "step": 3837
    },
    {
      "epoch": 0.060769194230251594,
      "grad_norm": 0.2575858235359192,
      "learning_rate": 9.392308057697484e-06,
      "loss": 0.1302,
      "step": 3838
    },
    {
      "epoch": 0.06078502778789366,
      "grad_norm": 0.17485357820987701,
      "learning_rate": 9.392149722121065e-06,
      "loss": 0.0244,
      "step": 3839
    },
    {
      "epoch": 0.06080086134553573,
      "grad_norm": 0.24596482515335083,
      "learning_rate": 9.391991386544644e-06,
      "loss": 0.3534,
      "step": 3840
    },
    {
      "epoch": 0.060816694903177794,
      "grad_norm": 0.2013540118932724,
      "learning_rate": 9.391833050968223e-06,
      "loss": 0.0494,
      "step": 3841
    },
    {
      "epoch": 0.06083252846081986,
      "grad_norm": 0.021784966811537743,
      "learning_rate": 9.391674715391802e-06,
      "loss": 0.0021,
      "step": 3842
    },
    {
      "epoch": 0.06084836201846193,
      "grad_norm": 0.44200921058654785,
      "learning_rate": 9.391516379815383e-06,
      "loss": 0.1072,
      "step": 3843
    },
    {
      "epoch": 0.060864195576103994,
      "grad_norm": 0.0026807915419340134,
      "learning_rate": 9.39135804423896e-06,
      "loss": 0.0001,
      "step": 3844
    },
    {
      "epoch": 0.06088002913374606,
      "grad_norm": 0.2737043797969818,
      "learning_rate": 9.391199708662541e-06,
      "loss": 0.3389,
      "step": 3845
    },
    {
      "epoch": 0.06089586269138813,
      "grad_norm": 0.34583914279937744,
      "learning_rate": 9.39104137308612e-06,
      "loss": 0.0761,
      "step": 3846
    },
    {
      "epoch": 0.060911696249030194,
      "grad_norm": 5.620341471512802e-05,
      "learning_rate": 9.390883037509699e-06,
      "loss": 0.0,
      "step": 3847
    },
    {
      "epoch": 0.06092752980667226,
      "grad_norm": 0.35240036249160767,
      "learning_rate": 9.390724701933278e-06,
      "loss": 0.3993,
      "step": 3848
    },
    {
      "epoch": 0.06094336336431433,
      "grad_norm": 0.003868505824357271,
      "learning_rate": 9.390566366356857e-06,
      "loss": 0.0002,
      "step": 3849
    },
    {
      "epoch": 0.06095919692195639,
      "grad_norm": 0.23380768299102783,
      "learning_rate": 9.390408030780436e-06,
      "loss": 0.0975,
      "step": 3850
    },
    {
      "epoch": 0.06097503047959846,
      "grad_norm": 0.5038753747940063,
      "learning_rate": 9.390249695204015e-06,
      "loss": 0.0102,
      "step": 3851
    },
    {
      "epoch": 0.06099086403724053,
      "grad_norm": 0.3878551423549652,
      "learning_rate": 9.390091359627596e-06,
      "loss": 0.0115,
      "step": 3852
    },
    {
      "epoch": 0.06100669759488259,
      "grad_norm": 0.6064432859420776,
      "learning_rate": 9.389933024051174e-06,
      "loss": 0.2552,
      "step": 3853
    },
    {
      "epoch": 0.06102253115252466,
      "grad_norm": 0.1473228931427002,
      "learning_rate": 9.389774688474754e-06,
      "loss": 0.0395,
      "step": 3854
    },
    {
      "epoch": 0.06103836471016673,
      "grad_norm": 0.08176089078187943,
      "learning_rate": 9.389616352898333e-06,
      "loss": 0.0076,
      "step": 3855
    },
    {
      "epoch": 0.06105419826780879,
      "grad_norm": 0.28968554735183716,
      "learning_rate": 9.389458017321912e-06,
      "loss": 0.0944,
      "step": 3856
    },
    {
      "epoch": 0.06107003182545086,
      "grad_norm": 0.183569997549057,
      "learning_rate": 9.389299681745492e-06,
      "loss": 0.0746,
      "step": 3857
    },
    {
      "epoch": 0.06108586538309293,
      "grad_norm": 0.21863484382629395,
      "learning_rate": 9.389141346169072e-06,
      "loss": 0.1094,
      "step": 3858
    },
    {
      "epoch": 0.06110169894073499,
      "grad_norm": 0.37719419598579407,
      "learning_rate": 9.38898301059265e-06,
      "loss": 0.3029,
      "step": 3859
    },
    {
      "epoch": 0.06111753249837706,
      "grad_norm": 0.19588106870651245,
      "learning_rate": 9.38882467501623e-06,
      "loss": 0.183,
      "step": 3860
    },
    {
      "epoch": 0.06113336605601913,
      "grad_norm": 0.2784881591796875,
      "learning_rate": 9.38866633943981e-06,
      "loss": 0.2168,
      "step": 3861
    },
    {
      "epoch": 0.06114919961366119,
      "grad_norm": 0.03257901221513748,
      "learning_rate": 9.388508003863389e-06,
      "loss": 0.0018,
      "step": 3862
    },
    {
      "epoch": 0.06116503317130326,
      "grad_norm": 0.32910415530204773,
      "learning_rate": 9.388349668286968e-06,
      "loss": 0.4023,
      "step": 3863
    },
    {
      "epoch": 0.06118086672894533,
      "grad_norm": 0.4092034697532654,
      "learning_rate": 9.388191332710548e-06,
      "loss": 0.5099,
      "step": 3864
    },
    {
      "epoch": 0.06119670028658739,
      "grad_norm": 0.34828320145606995,
      "learning_rate": 9.388032997134126e-06,
      "loss": 0.3972,
      "step": 3865
    },
    {
      "epoch": 0.06121253384422946,
      "grad_norm": 3.270620107650757,
      "learning_rate": 9.387874661557707e-06,
      "loss": 0.5517,
      "step": 3866
    },
    {
      "epoch": 0.06122836740187153,
      "grad_norm": 0.5262516140937805,
      "learning_rate": 9.387716325981286e-06,
      "loss": 1.093,
      "step": 3867
    },
    {
      "epoch": 0.06124420095951359,
      "grad_norm": 0.48222583532333374,
      "learning_rate": 9.387557990404865e-06,
      "loss": 0.3543,
      "step": 3868
    },
    {
      "epoch": 0.061260034517155657,
      "grad_norm": 1.071112871170044,
      "learning_rate": 9.387399654828444e-06,
      "loss": 0.2369,
      "step": 3869
    },
    {
      "epoch": 0.06127586807479773,
      "grad_norm": 0.024978032335639,
      "learning_rate": 9.387241319252025e-06,
      "loss": 0.0017,
      "step": 3870
    },
    {
      "epoch": 0.06129170163243979,
      "grad_norm": 0.2568660080432892,
      "learning_rate": 9.387082983675602e-06,
      "loss": 0.1436,
      "step": 3871
    },
    {
      "epoch": 0.061307535190081856,
      "grad_norm": 0.3220796287059784,
      "learning_rate": 9.386924648099183e-06,
      "loss": 0.1005,
      "step": 3872
    },
    {
      "epoch": 0.06132336874772393,
      "grad_norm": 0.5227346420288086,
      "learning_rate": 9.386766312522762e-06,
      "loss": 0.0674,
      "step": 3873
    },
    {
      "epoch": 0.06133920230536599,
      "grad_norm": 0.1770126074552536,
      "learning_rate": 9.386607976946341e-06,
      "loss": 0.1075,
      "step": 3874
    },
    {
      "epoch": 0.061355035863008056,
      "grad_norm": 0.4106267988681793,
      "learning_rate": 9.38644964136992e-06,
      "loss": 0.013,
      "step": 3875
    },
    {
      "epoch": 0.06137086942065013,
      "grad_norm": 0.12568363547325134,
      "learning_rate": 9.386291305793499e-06,
      "loss": 0.0246,
      "step": 3876
    },
    {
      "epoch": 0.06138670297829219,
      "grad_norm": 0.12153270095586777,
      "learning_rate": 9.386132970217078e-06,
      "loss": 0.0496,
      "step": 3877
    },
    {
      "epoch": 0.061402536535934256,
      "grad_norm": 0.1411268562078476,
      "learning_rate": 9.385974634640657e-06,
      "loss": 0.0606,
      "step": 3878
    },
    {
      "epoch": 0.06141837009357633,
      "grad_norm": 0.26589298248291016,
      "learning_rate": 9.385816299064238e-06,
      "loss": 0.049,
      "step": 3879
    },
    {
      "epoch": 0.06143420365121839,
      "grad_norm": 0.41602224111557007,
      "learning_rate": 9.385657963487817e-06,
      "loss": 0.4035,
      "step": 3880
    },
    {
      "epoch": 0.061450037208860456,
      "grad_norm": 0.4536891281604767,
      "learning_rate": 9.385499627911396e-06,
      "loss": 0.0716,
      "step": 3881
    },
    {
      "epoch": 0.06146587076650253,
      "grad_norm": 0.04840497300028801,
      "learning_rate": 9.385341292334975e-06,
      "loss": 0.0039,
      "step": 3882
    },
    {
      "epoch": 0.06148170432414459,
      "grad_norm": 0.13722768425941467,
      "learning_rate": 9.385182956758554e-06,
      "loss": 0.0762,
      "step": 3883
    },
    {
      "epoch": 0.061497537881786656,
      "grad_norm": 0.1862131655216217,
      "learning_rate": 9.385024621182133e-06,
      "loss": 0.083,
      "step": 3884
    },
    {
      "epoch": 0.06151337143942873,
      "grad_norm": 0.4339420795440674,
      "learning_rate": 9.384866285605714e-06,
      "loss": 0.0985,
      "step": 3885
    },
    {
      "epoch": 0.06152920499707079,
      "grad_norm": 0.8890191316604614,
      "learning_rate": 9.384707950029293e-06,
      "loss": 0.0292,
      "step": 3886
    },
    {
      "epoch": 0.061545038554712855,
      "grad_norm": 0.34624263644218445,
      "learning_rate": 9.384549614452872e-06,
      "loss": 0.1261,
      "step": 3887
    },
    {
      "epoch": 0.06156087211235493,
      "grad_norm": 0.061354439705610275,
      "learning_rate": 9.384391278876451e-06,
      "loss": 0.0009,
      "step": 3888
    },
    {
      "epoch": 0.06157670566999699,
      "grad_norm": 0.07908385246992111,
      "learning_rate": 9.38423294330003e-06,
      "loss": 0.0034,
      "step": 3889
    },
    {
      "epoch": 0.061592539227639055,
      "grad_norm": 0.23197318613529205,
      "learning_rate": 9.38407460772361e-06,
      "loss": 0.0861,
      "step": 3890
    },
    {
      "epoch": 0.061608372785281126,
      "grad_norm": 0.40241116285324097,
      "learning_rate": 9.38391627214719e-06,
      "loss": 0.3849,
      "step": 3891
    },
    {
      "epoch": 0.06162420634292319,
      "grad_norm": 0.24957607686519623,
      "learning_rate": 9.38375793657077e-06,
      "loss": 0.0999,
      "step": 3892
    },
    {
      "epoch": 0.061640039900565255,
      "grad_norm": 0.012161332182586193,
      "learning_rate": 9.383599600994349e-06,
      "loss": 0.0006,
      "step": 3893
    },
    {
      "epoch": 0.061655873458207326,
      "grad_norm": 0.16936880350112915,
      "learning_rate": 9.383441265417928e-06,
      "loss": 0.0542,
      "step": 3894
    },
    {
      "epoch": 0.06167170701584939,
      "grad_norm": 0.3863488733768463,
      "learning_rate": 9.383282929841507e-06,
      "loss": 0.125,
      "step": 3895
    },
    {
      "epoch": 0.061687540573491455,
      "grad_norm": 0.02056640014052391,
      "learning_rate": 9.383124594265086e-06,
      "loss": 0.0013,
      "step": 3896
    },
    {
      "epoch": 0.061703374131133526,
      "grad_norm": 0.4198968708515167,
      "learning_rate": 9.382966258688667e-06,
      "loss": 0.6077,
      "step": 3897
    },
    {
      "epoch": 0.06171920768877559,
      "grad_norm": 0.05719615891575813,
      "learning_rate": 9.382807923112246e-06,
      "loss": 0.0084,
      "step": 3898
    },
    {
      "epoch": 0.061735041246417655,
      "grad_norm": 0.3083769679069519,
      "learning_rate": 9.382649587535823e-06,
      "loss": 0.2197,
      "step": 3899
    },
    {
      "epoch": 0.061750874804059726,
      "grad_norm": 0.481081485748291,
      "learning_rate": 9.382491251959404e-06,
      "loss": 0.1582,
      "step": 3900
    },
    {
      "epoch": 0.06176670836170179,
      "grad_norm": 0.37929069995880127,
      "learning_rate": 9.382332916382983e-06,
      "loss": 0.2188,
      "step": 3901
    },
    {
      "epoch": 0.061782541919343854,
      "grad_norm": 0.5099631547927856,
      "learning_rate": 9.382174580806562e-06,
      "loss": 0.2486,
      "step": 3902
    },
    {
      "epoch": 0.061798375476985926,
      "grad_norm": 0.20621080696582794,
      "learning_rate": 9.382016245230141e-06,
      "loss": 0.1488,
      "step": 3903
    },
    {
      "epoch": 0.06181420903462799,
      "grad_norm": 0.8524501919746399,
      "learning_rate": 9.381857909653722e-06,
      "loss": 0.0324,
      "step": 3904
    },
    {
      "epoch": 0.061830042592270054,
      "grad_norm": 0.4780985116958618,
      "learning_rate": 9.3816995740773e-06,
      "loss": 0.6578,
      "step": 3905
    },
    {
      "epoch": 0.061845876149912125,
      "grad_norm": 0.00015949193038977683,
      "learning_rate": 9.38154123850088e-06,
      "loss": 0.0,
      "step": 3906
    },
    {
      "epoch": 0.06186170970755419,
      "grad_norm": 0.17143261432647705,
      "learning_rate": 9.381382902924459e-06,
      "loss": 0.0672,
      "step": 3907
    },
    {
      "epoch": 0.061877543265196254,
      "grad_norm": 0.013143840245902538,
      "learning_rate": 9.381224567348038e-06,
      "loss": 0.0008,
      "step": 3908
    },
    {
      "epoch": 0.061893376822838325,
      "grad_norm": 0.3539162278175354,
      "learning_rate": 9.381066231771617e-06,
      "loss": 0.2153,
      "step": 3909
    },
    {
      "epoch": 0.06190921038048039,
      "grad_norm": 0.11330044269561768,
      "learning_rate": 9.380907896195198e-06,
      "loss": 0.0511,
      "step": 3910
    },
    {
      "epoch": 0.061925043938122454,
      "grad_norm": 0.2856988310813904,
      "learning_rate": 9.380749560618775e-06,
      "loss": 0.0788,
      "step": 3911
    },
    {
      "epoch": 0.061940877495764525,
      "grad_norm": 0.26793181896209717,
      "learning_rate": 9.380591225042356e-06,
      "loss": 0.1654,
      "step": 3912
    },
    {
      "epoch": 0.06195671105340659,
      "grad_norm": 0.008838471956551075,
      "learning_rate": 9.380432889465935e-06,
      "loss": 0.0005,
      "step": 3913
    },
    {
      "epoch": 0.061972544611048654,
      "grad_norm": 0.2559114992618561,
      "learning_rate": 9.380274553889514e-06,
      "loss": 0.1435,
      "step": 3914
    },
    {
      "epoch": 0.061988378168690725,
      "grad_norm": 0.1524578183889389,
      "learning_rate": 9.380116218313093e-06,
      "loss": 0.0824,
      "step": 3915
    },
    {
      "epoch": 0.06200421172633279,
      "grad_norm": 0.038543593138456345,
      "learning_rate": 9.379957882736672e-06,
      "loss": 0.0033,
      "step": 3916
    },
    {
      "epoch": 0.06202004528397485,
      "grad_norm": 0.18871504068374634,
      "learning_rate": 9.379799547160252e-06,
      "loss": 0.2527,
      "step": 3917
    },
    {
      "epoch": 0.062035878841616925,
      "grad_norm": 0.3374054431915283,
      "learning_rate": 9.379641211583832e-06,
      "loss": 0.0853,
      "step": 3918
    },
    {
      "epoch": 0.06205171239925899,
      "grad_norm": 0.22843201458454132,
      "learning_rate": 9.379482876007411e-06,
      "loss": 0.0793,
      "step": 3919
    },
    {
      "epoch": 0.06206754595690105,
      "grad_norm": 0.4690471887588501,
      "learning_rate": 9.37932454043099e-06,
      "loss": 0.7996,
      "step": 3920
    },
    {
      "epoch": 0.062083379514543124,
      "grad_norm": 0.35375598073005676,
      "learning_rate": 9.37916620485457e-06,
      "loss": 0.0502,
      "step": 3921
    },
    {
      "epoch": 0.06209921307218519,
      "grad_norm": 0.28378140926361084,
      "learning_rate": 9.379007869278149e-06,
      "loss": 0.2213,
      "step": 3922
    },
    {
      "epoch": 0.06211504662982725,
      "grad_norm": 0.12802310287952423,
      "learning_rate": 9.378849533701728e-06,
      "loss": 0.0196,
      "step": 3923
    },
    {
      "epoch": 0.062130880187469324,
      "grad_norm": 0.3458057940006256,
      "learning_rate": 9.378691198125307e-06,
      "loss": 0.3723,
      "step": 3924
    },
    {
      "epoch": 0.06214671374511139,
      "grad_norm": 0.03219585120677948,
      "learning_rate": 9.378532862548888e-06,
      "loss": 0.0009,
      "step": 3925
    },
    {
      "epoch": 0.06216254730275345,
      "grad_norm": 0.3117055594921112,
      "learning_rate": 9.378374526972465e-06,
      "loss": 0.2654,
      "step": 3926
    },
    {
      "epoch": 0.062178380860395524,
      "grad_norm": 0.010016690008342266,
      "learning_rate": 9.378216191396046e-06,
      "loss": 0.0005,
      "step": 3927
    },
    {
      "epoch": 0.06219421441803759,
      "grad_norm": 0.21073183417320251,
      "learning_rate": 9.378057855819625e-06,
      "loss": 0.0993,
      "step": 3928
    },
    {
      "epoch": 0.06221004797567965,
      "grad_norm": 0.016845298931002617,
      "learning_rate": 9.377899520243204e-06,
      "loss": 0.0011,
      "step": 3929
    },
    {
      "epoch": 0.062225881533321724,
      "grad_norm": 0.03359502926468849,
      "learning_rate": 9.377741184666783e-06,
      "loss": 0.0022,
      "step": 3930
    },
    {
      "epoch": 0.06224171509096379,
      "grad_norm": 0.3699225187301636,
      "learning_rate": 9.377582849090364e-06,
      "loss": 0.2556,
      "step": 3931
    },
    {
      "epoch": 0.06225754864860585,
      "grad_norm": 0.6288018226623535,
      "learning_rate": 9.377424513513941e-06,
      "loss": 0.1458,
      "step": 3932
    },
    {
      "epoch": 0.062273382206247924,
      "grad_norm": 0.35667258501052856,
      "learning_rate": 9.377266177937522e-06,
      "loss": 0.2008,
      "step": 3933
    },
    {
      "epoch": 0.06228921576388999,
      "grad_norm": 0.31973153352737427,
      "learning_rate": 9.377107842361101e-06,
      "loss": 0.5558,
      "step": 3934
    },
    {
      "epoch": 0.06230504932153205,
      "grad_norm": 0.37573736906051636,
      "learning_rate": 9.37694950678468e-06,
      "loss": 0.2883,
      "step": 3935
    },
    {
      "epoch": 0.06232088287917412,
      "grad_norm": 0.25730985403060913,
      "learning_rate": 9.376791171208259e-06,
      "loss": 0.1141,
      "step": 3936
    },
    {
      "epoch": 0.06233671643681619,
      "grad_norm": 0.14328718185424805,
      "learning_rate": 9.37663283563184e-06,
      "loss": 0.059,
      "step": 3937
    },
    {
      "epoch": 0.06235254999445825,
      "grad_norm": 0.05833081528544426,
      "learning_rate": 9.376474500055417e-06,
      "loss": 0.004,
      "step": 3938
    },
    {
      "epoch": 0.06236838355210032,
      "grad_norm": 0.20175327360630035,
      "learning_rate": 9.376316164478998e-06,
      "loss": 0.0698,
      "step": 3939
    },
    {
      "epoch": 0.06238421710974239,
      "grad_norm": 0.526698887348175,
      "learning_rate": 9.376157828902577e-06,
      "loss": 0.8092,
      "step": 3940
    },
    {
      "epoch": 0.06240005066738445,
      "grad_norm": 0.20553134381771088,
      "learning_rate": 9.375999493326156e-06,
      "loss": 0.2002,
      "step": 3941
    },
    {
      "epoch": 0.06241588422502652,
      "grad_norm": 0.11269223690032959,
      "learning_rate": 9.375841157749735e-06,
      "loss": 0.0428,
      "step": 3942
    },
    {
      "epoch": 0.06243171778266859,
      "grad_norm": 0.5593494176864624,
      "learning_rate": 9.375682822173316e-06,
      "loss": 0.2456,
      "step": 3943
    },
    {
      "epoch": 0.06244755134031065,
      "grad_norm": 0.5447542667388916,
      "learning_rate": 9.375524486596893e-06,
      "loss": 0.0454,
      "step": 3944
    },
    {
      "epoch": 0.06246338489795272,
      "grad_norm": 0.02716005966067314,
      "learning_rate": 9.375366151020474e-06,
      "loss": 0.0015,
      "step": 3945
    },
    {
      "epoch": 0.06247921845559479,
      "grad_norm": 0.3457581400871277,
      "learning_rate": 9.375207815444053e-06,
      "loss": 0.2376,
      "step": 3946
    },
    {
      "epoch": 0.06249505201323685,
      "grad_norm": 0.00465686758980155,
      "learning_rate": 9.375049479867632e-06,
      "loss": 0.0002,
      "step": 3947
    },
    {
      "epoch": 0.06251088557087892,
      "grad_norm": 0.4293231666088104,
      "learning_rate": 9.374891144291211e-06,
      "loss": 0.4029,
      "step": 3948
    },
    {
      "epoch": 0.062526719128521,
      "grad_norm": 0.1462019979953766,
      "learning_rate": 9.37473280871479e-06,
      "loss": 0.0087,
      "step": 3949
    },
    {
      "epoch": 0.06254255268616306,
      "grad_norm": 0.24935966730117798,
      "learning_rate": 9.37457447313837e-06,
      "loss": 0.2035,
      "step": 3950
    },
    {
      "epoch": 0.06255838624380512,
      "grad_norm": 0.003531702794134617,
      "learning_rate": 9.374416137561949e-06,
      "loss": 0.0002,
      "step": 3951
    },
    {
      "epoch": 0.06257421980144719,
      "grad_norm": 0.21756984293460846,
      "learning_rate": 9.37425780198553e-06,
      "loss": 0.2841,
      "step": 3952
    },
    {
      "epoch": 0.06259005335908925,
      "grad_norm": 0.008886423893272877,
      "learning_rate": 9.374099466409109e-06,
      "loss": 0.0006,
      "step": 3953
    },
    {
      "epoch": 0.06260588691673132,
      "grad_norm": 0.13108442723751068,
      "learning_rate": 9.373941130832688e-06,
      "loss": 0.0203,
      "step": 3954
    },
    {
      "epoch": 0.0626217204743734,
      "grad_norm": 0.11936287581920624,
      "learning_rate": 9.373782795256267e-06,
      "loss": 0.0706,
      "step": 3955
    },
    {
      "epoch": 0.06263755403201546,
      "grad_norm": 0.19321885704994202,
      "learning_rate": 9.373624459679846e-06,
      "loss": 0.0437,
      "step": 3956
    },
    {
      "epoch": 0.06265338758965752,
      "grad_norm": 0.24060843884944916,
      "learning_rate": 9.373466124103425e-06,
      "loss": 0.3285,
      "step": 3957
    },
    {
      "epoch": 0.06266922114729959,
      "grad_norm": 1.4117445945739746,
      "learning_rate": 9.373307788527006e-06,
      "loss": 0.1444,
      "step": 3958
    },
    {
      "epoch": 0.06268505470494165,
      "grad_norm": 0.23657791316509247,
      "learning_rate": 9.373149452950585e-06,
      "loss": 0.1198,
      "step": 3959
    },
    {
      "epoch": 0.06270088826258371,
      "grad_norm": 0.2856088876724243,
      "learning_rate": 9.372991117374164e-06,
      "loss": 0.0506,
      "step": 3960
    },
    {
      "epoch": 0.0627167218202258,
      "grad_norm": 0.0803474709391594,
      "learning_rate": 9.372832781797743e-06,
      "loss": 0.0102,
      "step": 3961
    },
    {
      "epoch": 0.06273255537786786,
      "grad_norm": 0.16106447577476501,
      "learning_rate": 9.372674446221322e-06,
      "loss": 0.0337,
      "step": 3962
    },
    {
      "epoch": 0.06274838893550992,
      "grad_norm": 0.010435459204018116,
      "learning_rate": 9.372516110644901e-06,
      "loss": 0.0009,
      "step": 3963
    },
    {
      "epoch": 0.06276422249315199,
      "grad_norm": 7.452621503034607e-05,
      "learning_rate": 9.372357775068482e-06,
      "loss": 0.0,
      "step": 3964
    },
    {
      "epoch": 0.06278005605079405,
      "grad_norm": 0.18912489712238312,
      "learning_rate": 9.372199439492061e-06,
      "loss": 0.2479,
      "step": 3965
    },
    {
      "epoch": 0.06279588960843611,
      "grad_norm": 0.00656973198056221,
      "learning_rate": 9.37204110391564e-06,
      "loss": 0.0004,
      "step": 3966
    },
    {
      "epoch": 0.06281172316607819,
      "grad_norm": 0.2686408460140228,
      "learning_rate": 9.371882768339219e-06,
      "loss": 0.0749,
      "step": 3967
    },
    {
      "epoch": 0.06282755672372026,
      "grad_norm": 3.531740730977617e-05,
      "learning_rate": 9.371724432762798e-06,
      "loss": 0.0,
      "step": 3968
    },
    {
      "epoch": 0.06284339028136232,
      "grad_norm": 0.28071266412734985,
      "learning_rate": 9.371566097186377e-06,
      "loss": 0.0448,
      "step": 3969
    },
    {
      "epoch": 0.06285922383900439,
      "grad_norm": 0.04272167757153511,
      "learning_rate": 9.371407761609956e-06,
      "loss": 0.0039,
      "step": 3970
    },
    {
      "epoch": 0.06287505739664645,
      "grad_norm": 1.1764230728149414,
      "learning_rate": 9.371249426033537e-06,
      "loss": 0.0698,
      "step": 3971
    },
    {
      "epoch": 0.06289089095428851,
      "grad_norm": 0.03522904962301254,
      "learning_rate": 9.371091090457114e-06,
      "loss": 0.0026,
      "step": 3972
    },
    {
      "epoch": 0.06290672451193059,
      "grad_norm": 0.07946357876062393,
      "learning_rate": 9.370932754880695e-06,
      "loss": 0.0119,
      "step": 3973
    },
    {
      "epoch": 0.06292255806957266,
      "grad_norm": 0.00016933587903622538,
      "learning_rate": 9.370774419304274e-06,
      "loss": 0.0,
      "step": 3974
    },
    {
      "epoch": 0.06293839162721472,
      "grad_norm": 0.07538609206676483,
      "learning_rate": 9.370616083727853e-06,
      "loss": 0.0375,
      "step": 3975
    },
    {
      "epoch": 0.06295422518485679,
      "grad_norm": 0.4067666828632355,
      "learning_rate": 9.370457748151432e-06,
      "loss": 0.4764,
      "step": 3976
    },
    {
      "epoch": 0.06297005874249885,
      "grad_norm": 0.5498349070549011,
      "learning_rate": 9.370299412575012e-06,
      "loss": 0.6426,
      "step": 3977
    },
    {
      "epoch": 0.06298589230014091,
      "grad_norm": 0.21309995651245117,
      "learning_rate": 9.37014107699859e-06,
      "loss": 0.2947,
      "step": 3978
    },
    {
      "epoch": 0.06300172585778299,
      "grad_norm": 0.0022524914238601923,
      "learning_rate": 9.369982741422171e-06,
      "loss": 0.0,
      "step": 3979
    },
    {
      "epoch": 0.06301755941542506,
      "grad_norm": 0.024895107373595238,
      "learning_rate": 9.36982440584575e-06,
      "loss": 0.0017,
      "step": 3980
    },
    {
      "epoch": 0.06303339297306712,
      "grad_norm": 0.1848120391368866,
      "learning_rate": 9.36966607026933e-06,
      "loss": 0.0854,
      "step": 3981
    },
    {
      "epoch": 0.06304922653070918,
      "grad_norm": 0.00744311697781086,
      "learning_rate": 9.369507734692909e-06,
      "loss": 0.0003,
      "step": 3982
    },
    {
      "epoch": 0.06306506008835125,
      "grad_norm": 0.22826965153217316,
      "learning_rate": 9.369349399116488e-06,
      "loss": 0.0069,
      "step": 3983
    },
    {
      "epoch": 0.06308089364599331,
      "grad_norm": 0.010888900607824326,
      "learning_rate": 9.369191063540067e-06,
      "loss": 0.0002,
      "step": 3984
    },
    {
      "epoch": 0.06309672720363539,
      "grad_norm": 1.1703866720199585,
      "learning_rate": 9.369032727963648e-06,
      "loss": 0.0554,
      "step": 3985
    },
    {
      "epoch": 0.06311256076127746,
      "grad_norm": 0.0035107408184558153,
      "learning_rate": 9.368874392387227e-06,
      "loss": 0.0001,
      "step": 3986
    },
    {
      "epoch": 0.06312839431891952,
      "grad_norm": 0.09574314951896667,
      "learning_rate": 9.368716056810806e-06,
      "loss": 0.0309,
      "step": 3987
    },
    {
      "epoch": 0.06314422787656158,
      "grad_norm": 0.11686699092388153,
      "learning_rate": 9.368557721234385e-06,
      "loss": 0.037,
      "step": 3988
    },
    {
      "epoch": 0.06316006143420365,
      "grad_norm": 0.13994275033473969,
      "learning_rate": 9.368399385657964e-06,
      "loss": 0.0741,
      "step": 3989
    },
    {
      "epoch": 0.06317589499184571,
      "grad_norm": 0.5975670218467712,
      "learning_rate": 9.368241050081543e-06,
      "loss": 0.3246,
      "step": 3990
    },
    {
      "epoch": 0.06319172854948779,
      "grad_norm": 0.5257788300514221,
      "learning_rate": 9.368082714505124e-06,
      "loss": 0.116,
      "step": 3991
    },
    {
      "epoch": 0.06320756210712986,
      "grad_norm": 0.02199244312942028,
      "learning_rate": 9.367924378928703e-06,
      "loss": 0.0016,
      "step": 3992
    },
    {
      "epoch": 0.06322339566477192,
      "grad_norm": 0.13586705923080444,
      "learning_rate": 9.367766043352282e-06,
      "loss": 0.1375,
      "step": 3993
    },
    {
      "epoch": 0.06323922922241398,
      "grad_norm": 0.23518012464046478,
      "learning_rate": 9.367607707775861e-06,
      "loss": 0.4292,
      "step": 3994
    },
    {
      "epoch": 0.06325506278005605,
      "grad_norm": 0.01131520327180624,
      "learning_rate": 9.36744937219944e-06,
      "loss": 0.0008,
      "step": 3995
    },
    {
      "epoch": 0.06327089633769811,
      "grad_norm": 0.32217535376548767,
      "learning_rate": 9.36729103662302e-06,
      "loss": 0.6364,
      "step": 3996
    },
    {
      "epoch": 0.06328672989534019,
      "grad_norm": 0.20265436172485352,
      "learning_rate": 9.367132701046598e-06,
      "loss": 0.5835,
      "step": 3997
    },
    {
      "epoch": 0.06330256345298226,
      "grad_norm": 0.43287771940231323,
      "learning_rate": 9.366974365470179e-06,
      "loss": 0.0101,
      "step": 3998
    },
    {
      "epoch": 0.06331839701062432,
      "grad_norm": 0.16451270878314972,
      "learning_rate": 9.366816029893756e-06,
      "loss": 0.0827,
      "step": 3999
    },
    {
      "epoch": 0.06333423056826638,
      "grad_norm": 0.33960700035095215,
      "learning_rate": 9.366657694317337e-06,
      "loss": 0.1494,
      "step": 4000
    },
    {
      "epoch": 0.06335006412590845,
      "grad_norm": 7.590375753352419e-05,
      "learning_rate": 9.366499358740916e-06,
      "loss": 0.0,
      "step": 4001
    },
    {
      "epoch": 0.06336589768355051,
      "grad_norm": 0.43934547901153564,
      "learning_rate": 9.366341023164495e-06,
      "loss": 0.1046,
      "step": 4002
    },
    {
      "epoch": 0.06338173124119259,
      "grad_norm": 0.18029607832431793,
      "learning_rate": 9.366182687588074e-06,
      "loss": 0.1098,
      "step": 4003
    },
    {
      "epoch": 0.06339756479883465,
      "grad_norm": 0.012374033220112324,
      "learning_rate": 9.366024352011655e-06,
      "loss": 0.001,
      "step": 4004
    },
    {
      "epoch": 0.06341339835647672,
      "grad_norm": 0.021605342626571655,
      "learning_rate": 9.365866016435233e-06,
      "loss": 0.0016,
      "step": 4005
    },
    {
      "epoch": 0.06342923191411878,
      "grad_norm": 0.6058555841445923,
      "learning_rate": 9.365707680858813e-06,
      "loss": 0.1831,
      "step": 4006
    },
    {
      "epoch": 0.06344506547176085,
      "grad_norm": 0.27982738614082336,
      "learning_rate": 9.365549345282392e-06,
      "loss": 0.0515,
      "step": 4007
    },
    {
      "epoch": 0.06346089902940291,
      "grad_norm": 0.3056641221046448,
      "learning_rate": 9.365391009705972e-06,
      "loss": 0.0979,
      "step": 4008
    },
    {
      "epoch": 0.06347673258704499,
      "grad_norm": 0.6188998818397522,
      "learning_rate": 9.36523267412955e-06,
      "loss": 0.3361,
      "step": 4009
    },
    {
      "epoch": 0.06349256614468705,
      "grad_norm": 0.19949054718017578,
      "learning_rate": 9.365074338553131e-06,
      "loss": 0.0672,
      "step": 4010
    },
    {
      "epoch": 0.06350839970232912,
      "grad_norm": 0.17453093826770782,
      "learning_rate": 9.364916002976709e-06,
      "loss": 0.0554,
      "step": 4011
    },
    {
      "epoch": 0.06352423325997118,
      "grad_norm": 0.16970109939575195,
      "learning_rate": 9.36475766740029e-06,
      "loss": 0.0782,
      "step": 4012
    },
    {
      "epoch": 0.06354006681761325,
      "grad_norm": 0.8423722982406616,
      "learning_rate": 9.364599331823869e-06,
      "loss": 0.7016,
      "step": 4013
    },
    {
      "epoch": 0.06355590037525531,
      "grad_norm": 0.3831770718097687,
      "learning_rate": 9.364440996247448e-06,
      "loss": 0.6439,
      "step": 4014
    },
    {
      "epoch": 0.06357173393289739,
      "grad_norm": 0.15710516273975372,
      "learning_rate": 9.364282660671027e-06,
      "loss": 0.0674,
      "step": 4015
    },
    {
      "epoch": 0.06358756749053945,
      "grad_norm": 0.00014085085422266275,
      "learning_rate": 9.364124325094608e-06,
      "loss": 0.0,
      "step": 4016
    },
    {
      "epoch": 0.06360340104818152,
      "grad_norm": 0.000494139501824975,
      "learning_rate": 9.363965989518185e-06,
      "loss": 0.0,
      "step": 4017
    },
    {
      "epoch": 0.06361923460582358,
      "grad_norm": 0.006847502663731575,
      "learning_rate": 9.363807653941764e-06,
      "loss": 0.0003,
      "step": 4018
    },
    {
      "epoch": 0.06363506816346565,
      "grad_norm": 0.24429842829704285,
      "learning_rate": 9.363649318365345e-06,
      "loss": 0.4489,
      "step": 4019
    },
    {
      "epoch": 0.06365090172110771,
      "grad_norm": 0.006630051415413618,
      "learning_rate": 9.363490982788924e-06,
      "loss": 0.0003,
      "step": 4020
    },
    {
      "epoch": 0.06366673527874979,
      "grad_norm": 0.35901889204978943,
      "learning_rate": 9.363332647212503e-06,
      "loss": 0.1766,
      "step": 4021
    },
    {
      "epoch": 0.06368256883639185,
      "grad_norm": 0.017706695944070816,
      "learning_rate": 9.363174311636082e-06,
      "loss": 0.0004,
      "step": 4022
    },
    {
      "epoch": 0.06369840239403392,
      "grad_norm": 0.1068262830376625,
      "learning_rate": 9.363015976059661e-06,
      "loss": 0.0614,
      "step": 4023
    },
    {
      "epoch": 0.06371423595167598,
      "grad_norm": 0.3073250949382782,
      "learning_rate": 9.36285764048324e-06,
      "loss": 0.0246,
      "step": 4024
    },
    {
      "epoch": 0.06373006950931805,
      "grad_norm": 0.3443407416343689,
      "learning_rate": 9.362699304906821e-06,
      "loss": 0.3602,
      "step": 4025
    },
    {
      "epoch": 0.06374590306696011,
      "grad_norm": 0.18415458500385284,
      "learning_rate": 9.3625409693304e-06,
      "loss": 0.2326,
      "step": 4026
    },
    {
      "epoch": 0.06376173662460217,
      "grad_norm": 0.011773123405873775,
      "learning_rate": 9.362382633753979e-06,
      "loss": 0.0006,
      "step": 4027
    },
    {
      "epoch": 0.06377757018224425,
      "grad_norm": 0.3576243817806244,
      "learning_rate": 9.362224298177558e-06,
      "loss": 0.0916,
      "step": 4028
    },
    {
      "epoch": 0.06379340373988632,
      "grad_norm": 0.0015122322365641594,
      "learning_rate": 9.362065962601137e-06,
      "loss": 0.0,
      "step": 4029
    },
    {
      "epoch": 0.06380923729752838,
      "grad_norm": 0.014856697991490364,
      "learning_rate": 9.361907627024716e-06,
      "loss": 0.0008,
      "step": 4030
    },
    {
      "epoch": 0.06382507085517045,
      "grad_norm": 0.00022005484788678586,
      "learning_rate": 9.361749291448297e-06,
      "loss": 0.0,
      "step": 4031
    },
    {
      "epoch": 0.06384090441281251,
      "grad_norm": 0.5043952465057373,
      "learning_rate": 9.361590955871876e-06,
      "loss": 0.1173,
      "step": 4032
    },
    {
      "epoch": 0.06385673797045457,
      "grad_norm": 0.1610422134399414,
      "learning_rate": 9.361432620295455e-06,
      "loss": 0.0567,
      "step": 4033
    },
    {
      "epoch": 0.06387257152809665,
      "grad_norm": 0.05944884568452835,
      "learning_rate": 9.361274284719034e-06,
      "loss": 0.0148,
      "step": 4034
    },
    {
      "epoch": 0.06388840508573872,
      "grad_norm": 0.199691042304039,
      "learning_rate": 9.361115949142613e-06,
      "loss": 0.0856,
      "step": 4035
    },
    {
      "epoch": 0.06390423864338078,
      "grad_norm": 0.4266897737979889,
      "learning_rate": 9.360957613566193e-06,
      "loss": 0.7349,
      "step": 4036
    },
    {
      "epoch": 0.06392007220102285,
      "grad_norm": 0.3924228549003601,
      "learning_rate": 9.360799277989773e-06,
      "loss": 0.1887,
      "step": 4037
    },
    {
      "epoch": 0.06393590575866491,
      "grad_norm": 0.28441324830055237,
      "learning_rate": 9.360640942413352e-06,
      "loss": 0.1181,
      "step": 4038
    },
    {
      "epoch": 0.06395173931630697,
      "grad_norm": 0.00013702140131499618,
      "learning_rate": 9.360482606836931e-06,
      "loss": 0.0,
      "step": 4039
    },
    {
      "epoch": 0.06396757287394905,
      "grad_norm": 0.008268584497272968,
      "learning_rate": 9.36032427126051e-06,
      "loss": 0.0004,
      "step": 4040
    },
    {
      "epoch": 0.06398340643159112,
      "grad_norm": 0.2609015703201294,
      "learning_rate": 9.36016593568409e-06,
      "loss": 0.2931,
      "step": 4041
    },
    {
      "epoch": 0.06399923998923318,
      "grad_norm": 0.27559182047843933,
      "learning_rate": 9.360007600107669e-06,
      "loss": 0.2869,
      "step": 4042
    },
    {
      "epoch": 0.06401507354687525,
      "grad_norm": 0.36964982748031616,
      "learning_rate": 9.359849264531248e-06,
      "loss": 0.2516,
      "step": 4043
    },
    {
      "epoch": 0.06403090710451731,
      "grad_norm": 0.2723338007926941,
      "learning_rate": 9.359690928954827e-06,
      "loss": 0.1023,
      "step": 4044
    },
    {
      "epoch": 0.06404674066215937,
      "grad_norm": 0.23731426894664764,
      "learning_rate": 9.359532593378406e-06,
      "loss": 0.0867,
      "step": 4045
    },
    {
      "epoch": 0.06406257421980145,
      "grad_norm": 4.2149426008109e-05,
      "learning_rate": 9.359374257801987e-06,
      "loss": 0.0,
      "step": 4046
    },
    {
      "epoch": 0.06407840777744352,
      "grad_norm": 0.018448468297719955,
      "learning_rate": 9.359215922225566e-06,
      "loss": 0.0013,
      "step": 4047
    },
    {
      "epoch": 0.06409424133508558,
      "grad_norm": 0.17599759995937347,
      "learning_rate": 9.359057586649145e-06,
      "loss": 0.1915,
      "step": 4048
    },
    {
      "epoch": 0.06411007489272764,
      "grad_norm": 0.39016300439834595,
      "learning_rate": 9.358899251072724e-06,
      "loss": 0.6065,
      "step": 4049
    },
    {
      "epoch": 0.06412590845036971,
      "grad_norm": 0.28021374344825745,
      "learning_rate": 9.358740915496303e-06,
      "loss": 0.0859,
      "step": 4050
    },
    {
      "epoch": 0.06414174200801177,
      "grad_norm": 0.29719117283821106,
      "learning_rate": 9.358582579919882e-06,
      "loss": 0.3978,
      "step": 4051
    },
    {
      "epoch": 0.06415757556565385,
      "grad_norm": 0.29766273498535156,
      "learning_rate": 9.358424244343463e-06,
      "loss": 0.04,
      "step": 4052
    },
    {
      "epoch": 0.06417340912329592,
      "grad_norm": 0.7586886882781982,
      "learning_rate": 9.358265908767042e-06,
      "loss": 0.4456,
      "step": 4053
    },
    {
      "epoch": 0.06418924268093798,
      "grad_norm": 0.3111509084701538,
      "learning_rate": 9.358107573190621e-06,
      "loss": 0.1644,
      "step": 4054
    },
    {
      "epoch": 0.06420507623858004,
      "grad_norm": 0.22413136065006256,
      "learning_rate": 9.3579492376142e-06,
      "loss": 0.1018,
      "step": 4055
    },
    {
      "epoch": 0.06422090979622211,
      "grad_norm": 0.3932746350765228,
      "learning_rate": 9.35779090203778e-06,
      "loss": 0.2326,
      "step": 4056
    },
    {
      "epoch": 0.06423674335386417,
      "grad_norm": 0.226392924785614,
      "learning_rate": 9.357632566461358e-06,
      "loss": 0.0829,
      "step": 4057
    },
    {
      "epoch": 0.06425257691150625,
      "grad_norm": 0.23303402960300446,
      "learning_rate": 9.357474230884939e-06,
      "loss": 0.0654,
      "step": 4058
    },
    {
      "epoch": 0.06426841046914832,
      "grad_norm": 0.4397757947444916,
      "learning_rate": 9.357315895308518e-06,
      "loss": 0.5834,
      "step": 4059
    },
    {
      "epoch": 0.06428424402679038,
      "grad_norm": 0.31234753131866455,
      "learning_rate": 9.357157559732097e-06,
      "loss": 0.1402,
      "step": 4060
    },
    {
      "epoch": 0.06430007758443244,
      "grad_norm": 0.0034230402670800686,
      "learning_rate": 9.356999224155676e-06,
      "loss": 0.0001,
      "step": 4061
    },
    {
      "epoch": 0.06431591114207451,
      "grad_norm": 0.2326464056968689,
      "learning_rate": 9.356840888579255e-06,
      "loss": 0.1035,
      "step": 4062
    },
    {
      "epoch": 0.06433174469971657,
      "grad_norm": 0.26267048716545105,
      "learning_rate": 9.356682553002834e-06,
      "loss": 0.0751,
      "step": 4063
    },
    {
      "epoch": 0.06434757825735865,
      "grad_norm": 0.44738563895225525,
      "learning_rate": 9.356524217426415e-06,
      "loss": 0.5819,
      "step": 4064
    },
    {
      "epoch": 0.06436341181500072,
      "grad_norm": 0.23949652910232544,
      "learning_rate": 9.356365881849994e-06,
      "loss": 0.0588,
      "step": 4065
    },
    {
      "epoch": 0.06437924537264278,
      "grad_norm": 0.5039908289909363,
      "learning_rate": 9.356207546273573e-06,
      "loss": 0.5461,
      "step": 4066
    },
    {
      "epoch": 0.06439507893028484,
      "grad_norm": 0.20796138048171997,
      "learning_rate": 9.356049210697152e-06,
      "loss": 0.0934,
      "step": 4067
    },
    {
      "epoch": 0.06441091248792691,
      "grad_norm": 0.247730553150177,
      "learning_rate": 9.355890875120732e-06,
      "loss": 0.1203,
      "step": 4068
    },
    {
      "epoch": 0.06442674604556897,
      "grad_norm": 5.8692148741101846e-05,
      "learning_rate": 9.35573253954431e-06,
      "loss": 0.0,
      "step": 4069
    },
    {
      "epoch": 0.06444257960321105,
      "grad_norm": 0.019079463556408882,
      "learning_rate": 9.35557420396789e-06,
      "loss": 0.001,
      "step": 4070
    },
    {
      "epoch": 0.06445841316085311,
      "grad_norm": 0.3018921911716461,
      "learning_rate": 9.35541586839147e-06,
      "loss": 0.0233,
      "step": 4071
    },
    {
      "epoch": 0.06447424671849518,
      "grad_norm": 0.1794130951166153,
      "learning_rate": 9.355257532815048e-06,
      "loss": 0.0669,
      "step": 4072
    },
    {
      "epoch": 0.06449008027613724,
      "grad_norm": 1.0146173238754272,
      "learning_rate": 9.355099197238629e-06,
      "loss": 0.4848,
      "step": 4073
    },
    {
      "epoch": 0.06450591383377931,
      "grad_norm": 0.40515637397766113,
      "learning_rate": 9.354940861662208e-06,
      "loss": 0.2925,
      "step": 4074
    },
    {
      "epoch": 0.06452174739142137,
      "grad_norm": 0.21885643899440765,
      "learning_rate": 9.354782526085787e-06,
      "loss": 0.0619,
      "step": 4075
    },
    {
      "epoch": 0.06453758094906345,
      "grad_norm": 0.0002646429929882288,
      "learning_rate": 9.354624190509366e-06,
      "loss": 0.0,
      "step": 4076
    },
    {
      "epoch": 0.06455341450670551,
      "grad_norm": 0.3576735556125641,
      "learning_rate": 9.354465854932947e-06,
      "loss": 0.3319,
      "step": 4077
    },
    {
      "epoch": 0.06456924806434758,
      "grad_norm": 0.394701212644577,
      "learning_rate": 9.354307519356524e-06,
      "loss": 0.0356,
      "step": 4078
    },
    {
      "epoch": 0.06458508162198964,
      "grad_norm": 0.009679926559329033,
      "learning_rate": 9.354149183780105e-06,
      "loss": 0.0005,
      "step": 4079
    },
    {
      "epoch": 0.06460091517963171,
      "grad_norm": 0.32403475046157837,
      "learning_rate": 9.353990848203684e-06,
      "loss": 0.2646,
      "step": 4080
    },
    {
      "epoch": 0.06461674873727377,
      "grad_norm": 0.3060954809188843,
      "learning_rate": 9.353832512627263e-06,
      "loss": 0.0705,
      "step": 4081
    },
    {
      "epoch": 0.06463258229491585,
      "grad_norm": 0.15417686104774475,
      "learning_rate": 9.353674177050842e-06,
      "loss": 0.0564,
      "step": 4082
    },
    {
      "epoch": 0.06464841585255791,
      "grad_norm": 0.2705274820327759,
      "learning_rate": 9.353515841474423e-06,
      "loss": 0.1132,
      "step": 4083
    },
    {
      "epoch": 0.06466424941019998,
      "grad_norm": 0.23676681518554688,
      "learning_rate": 9.353357505898e-06,
      "loss": 0.2001,
      "step": 4084
    },
    {
      "epoch": 0.06468008296784204,
      "grad_norm": 0.3440946638584137,
      "learning_rate": 9.353199170321581e-06,
      "loss": 0.2218,
      "step": 4085
    },
    {
      "epoch": 0.0646959165254841,
      "grad_norm": 0.43194445967674255,
      "learning_rate": 9.35304083474516e-06,
      "loss": 0.3197,
      "step": 4086
    },
    {
      "epoch": 0.06471175008312617,
      "grad_norm": 0.013835925608873367,
      "learning_rate": 9.352882499168739e-06,
      "loss": 0.0006,
      "step": 4087
    },
    {
      "epoch": 0.06472758364076825,
      "grad_norm": 4.229092883178964e-05,
      "learning_rate": 9.352724163592318e-06,
      "loss": 0.0,
      "step": 4088
    },
    {
      "epoch": 0.06474341719841031,
      "grad_norm": 0.17197184264659882,
      "learning_rate": 9.352565828015899e-06,
      "loss": 0.1421,
      "step": 4089
    },
    {
      "epoch": 0.06475925075605238,
      "grad_norm": 0.0019357859855517745,
      "learning_rate": 9.352407492439476e-06,
      "loss": 0.0,
      "step": 4090
    },
    {
      "epoch": 0.06477508431369444,
      "grad_norm": 0.701881468296051,
      "learning_rate": 9.352249156863055e-06,
      "loss": 0.3549,
      "step": 4091
    },
    {
      "epoch": 0.0647909178713365,
      "grad_norm": 0.21172116696834564,
      "learning_rate": 9.352090821286636e-06,
      "loss": 0.0468,
      "step": 4092
    },
    {
      "epoch": 0.06480675142897857,
      "grad_norm": 0.09906335175037384,
      "learning_rate": 9.351932485710215e-06,
      "loss": 0.0032,
      "step": 4093
    },
    {
      "epoch": 0.06482258498662065,
      "grad_norm": 0.06964525580406189,
      "learning_rate": 9.351774150133794e-06,
      "loss": 0.0033,
      "step": 4094
    },
    {
      "epoch": 0.06483841854426271,
      "grad_norm": 0.19375097751617432,
      "learning_rate": 9.351615814557373e-06,
      "loss": 0.0295,
      "step": 4095
    },
    {
      "epoch": 0.06485425210190478,
      "grad_norm": 0.5005019307136536,
      "learning_rate": 9.351457478980953e-06,
      "loss": 0.5751,
      "step": 4096
    },
    {
      "epoch": 0.06487008565954684,
      "grad_norm": 0.00010536410991335288,
      "learning_rate": 9.351299143404532e-06,
      "loss": 0.0,
      "step": 4097
    },
    {
      "epoch": 0.0648859192171889,
      "grad_norm": 0.5313959717750549,
      "learning_rate": 9.351140807828112e-06,
      "loss": 0.5438,
      "step": 4098
    },
    {
      "epoch": 0.06490175277483097,
      "grad_norm": 0.018718605861067772,
      "learning_rate": 9.350982472251691e-06,
      "loss": 0.001,
      "step": 4099
    },
    {
      "epoch": 0.06491758633247305,
      "grad_norm": 0.03562355041503906,
      "learning_rate": 9.35082413667527e-06,
      "loss": 0.0071,
      "step": 4100
    },
    {
      "epoch": 0.06493341989011511,
      "grad_norm": 0.924060046672821,
      "learning_rate": 9.35066580109885e-06,
      "loss": 0.2978,
      "step": 4101
    },
    {
      "epoch": 0.06494925344775718,
      "grad_norm": 0.576721727848053,
      "learning_rate": 9.350507465522429e-06,
      "loss": 0.3753,
      "step": 4102
    },
    {
      "epoch": 0.06496508700539924,
      "grad_norm": 0.3811706304550171,
      "learning_rate": 9.350349129946008e-06,
      "loss": 0.2937,
      "step": 4103
    },
    {
      "epoch": 0.0649809205630413,
      "grad_norm": 0.00031629332806915045,
      "learning_rate": 9.350190794369589e-06,
      "loss": 0.0,
      "step": 4104
    },
    {
      "epoch": 0.06499675412068337,
      "grad_norm": 8.194205292966217e-05,
      "learning_rate": 9.350032458793166e-06,
      "loss": 0.0,
      "step": 4105
    },
    {
      "epoch": 0.06501258767832545,
      "grad_norm": 0.9437423944473267,
      "learning_rate": 9.349874123216747e-06,
      "loss": 0.5991,
      "step": 4106
    },
    {
      "epoch": 0.06502842123596751,
      "grad_norm": 0.4150114059448242,
      "learning_rate": 9.349715787640326e-06,
      "loss": 0.7206,
      "step": 4107
    },
    {
      "epoch": 0.06504425479360958,
      "grad_norm": 0.21615280210971832,
      "learning_rate": 9.349557452063905e-06,
      "loss": 0.2451,
      "step": 4108
    },
    {
      "epoch": 0.06506008835125164,
      "grad_norm": 8.959625120041892e-05,
      "learning_rate": 9.349399116487484e-06,
      "loss": 0.0,
      "step": 4109
    },
    {
      "epoch": 0.0650759219088937,
      "grad_norm": 0.4006172716617584,
      "learning_rate": 9.349240780911065e-06,
      "loss": 0.1899,
      "step": 4110
    },
    {
      "epoch": 0.06509175546653577,
      "grad_norm": 0.009877316653728485,
      "learning_rate": 9.349082445334642e-06,
      "loss": 0.0004,
      "step": 4111
    },
    {
      "epoch": 0.06510758902417785,
      "grad_norm": 0.0027903076261281967,
      "learning_rate": 9.348924109758223e-06,
      "loss": 0.0002,
      "step": 4112
    },
    {
      "epoch": 0.06512342258181991,
      "grad_norm": 0.3768403232097626,
      "learning_rate": 9.348765774181802e-06,
      "loss": 0.0835,
      "step": 4113
    },
    {
      "epoch": 0.06513925613946198,
      "grad_norm": 0.656783401966095,
      "learning_rate": 9.348607438605381e-06,
      "loss": 0.1322,
      "step": 4114
    },
    {
      "epoch": 0.06515508969710404,
      "grad_norm": 0.22782279551029205,
      "learning_rate": 9.34844910302896e-06,
      "loss": 0.0396,
      "step": 4115
    },
    {
      "epoch": 0.0651709232547461,
      "grad_norm": 0.12608036398887634,
      "learning_rate": 9.34829076745254e-06,
      "loss": 0.0458,
      "step": 4116
    },
    {
      "epoch": 0.06518675681238817,
      "grad_norm": 0.5734068751335144,
      "learning_rate": 9.348132431876118e-06,
      "loss": 0.2346,
      "step": 4117
    },
    {
      "epoch": 0.06520259037003025,
      "grad_norm": 0.00024401361588388681,
      "learning_rate": 9.347974096299697e-06,
      "loss": 0.0,
      "step": 4118
    },
    {
      "epoch": 0.06521842392767231,
      "grad_norm": 0.0002533718361519277,
      "learning_rate": 9.347815760723278e-06,
      "loss": 0.0,
      "step": 4119
    },
    {
      "epoch": 0.06523425748531438,
      "grad_norm": 0.3167949318885803,
      "learning_rate": 9.347657425146857e-06,
      "loss": 0.1119,
      "step": 4120
    },
    {
      "epoch": 0.06525009104295644,
      "grad_norm": 0.25961118936538696,
      "learning_rate": 9.347499089570436e-06,
      "loss": 0.1303,
      "step": 4121
    },
    {
      "epoch": 0.0652659246005985,
      "grad_norm": 0.363655149936676,
      "learning_rate": 9.347340753994015e-06,
      "loss": 1.0694,
      "step": 4122
    },
    {
      "epoch": 0.06528175815824057,
      "grad_norm": 0.0002920563565567136,
      "learning_rate": 9.347182418417594e-06,
      "loss": 0.0,
      "step": 4123
    },
    {
      "epoch": 0.06529759171588265,
      "grad_norm": 0.14368058741092682,
      "learning_rate": 9.347024082841174e-06,
      "loss": 0.0812,
      "step": 4124
    },
    {
      "epoch": 0.06531342527352471,
      "grad_norm": 0.00045513082295656204,
      "learning_rate": 9.346865747264754e-06,
      "loss": 0.0,
      "step": 4125
    },
    {
      "epoch": 0.06532925883116678,
      "grad_norm": 0.16469965875148773,
      "learning_rate": 9.346707411688333e-06,
      "loss": 0.0794,
      "step": 4126
    },
    {
      "epoch": 0.06534509238880884,
      "grad_norm": 0.14746396243572235,
      "learning_rate": 9.346549076111912e-06,
      "loss": 0.0843,
      "step": 4127
    },
    {
      "epoch": 0.0653609259464509,
      "grad_norm": 0.006484694313257933,
      "learning_rate": 9.346390740535492e-06,
      "loss": 0.0004,
      "step": 4128
    },
    {
      "epoch": 0.06537675950409297,
      "grad_norm": 0.33007198572158813,
      "learning_rate": 9.34623240495907e-06,
      "loss": 0.0113,
      "step": 4129
    },
    {
      "epoch": 0.06539259306173505,
      "grad_norm": 0.2725336253643036,
      "learning_rate": 9.34607406938265e-06,
      "loss": 0.5202,
      "step": 4130
    },
    {
      "epoch": 0.06540842661937711,
      "grad_norm": 0.41421186923980713,
      "learning_rate": 9.34591573380623e-06,
      "loss": 0.3295,
      "step": 4131
    },
    {
      "epoch": 0.06542426017701918,
      "grad_norm": 0.00022761263244319707,
      "learning_rate": 9.34575739822981e-06,
      "loss": 0.0,
      "step": 4132
    },
    {
      "epoch": 0.06544009373466124,
      "grad_norm": 0.007761109154671431,
      "learning_rate": 9.345599062653389e-06,
      "loss": 0.0004,
      "step": 4133
    },
    {
      "epoch": 0.0654559272923033,
      "grad_norm": 0.30713126063346863,
      "learning_rate": 9.345440727076968e-06,
      "loss": 0.2765,
      "step": 4134
    },
    {
      "epoch": 0.06547176084994537,
      "grad_norm": 0.18192820250988007,
      "learning_rate": 9.345282391500547e-06,
      "loss": 0.4214,
      "step": 4135
    },
    {
      "epoch": 0.06548759440758745,
      "grad_norm": 0.18959401547908783,
      "learning_rate": 9.345124055924126e-06,
      "loss": 0.0628,
      "step": 4136
    },
    {
      "epoch": 0.06550342796522951,
      "grad_norm": 0.0007892458233982325,
      "learning_rate": 9.344965720347707e-06,
      "loss": 0.0,
      "step": 4137
    },
    {
      "epoch": 0.06551926152287157,
      "grad_norm": 0.16824615001678467,
      "learning_rate": 9.344807384771286e-06,
      "loss": 0.0912,
      "step": 4138
    },
    {
      "epoch": 0.06553509508051364,
      "grad_norm": 0.012680604122579098,
      "learning_rate": 9.344649049194863e-06,
      "loss": 0.0007,
      "step": 4139
    },
    {
      "epoch": 0.0655509286381557,
      "grad_norm": 0.007195174228399992,
      "learning_rate": 9.344490713618444e-06,
      "loss": 0.0004,
      "step": 4140
    },
    {
      "epoch": 0.06556676219579777,
      "grad_norm": 0.39608436822891235,
      "learning_rate": 9.344332378042023e-06,
      "loss": 0.2008,
      "step": 4141
    },
    {
      "epoch": 0.06558259575343985,
      "grad_norm": 0.11521320044994354,
      "learning_rate": 9.344174042465602e-06,
      "loss": 0.0445,
      "step": 4142
    },
    {
      "epoch": 0.06559842931108191,
      "grad_norm": 0.7843912839889526,
      "learning_rate": 9.344015706889181e-06,
      "loss": 0.7578,
      "step": 4143
    },
    {
      "epoch": 0.06561426286872397,
      "grad_norm": 0.2042495757341385,
      "learning_rate": 9.343857371312762e-06,
      "loss": 0.1192,
      "step": 4144
    },
    {
      "epoch": 0.06563009642636604,
      "grad_norm": 0.22509722411632538,
      "learning_rate": 9.34369903573634e-06,
      "loss": 0.1302,
      "step": 4145
    },
    {
      "epoch": 0.0656459299840081,
      "grad_norm": 0.3948742747306824,
      "learning_rate": 9.34354070015992e-06,
      "loss": 0.6591,
      "step": 4146
    },
    {
      "epoch": 0.06566176354165017,
      "grad_norm": 0.217484250664711,
      "learning_rate": 9.343382364583499e-06,
      "loss": 0.1131,
      "step": 4147
    },
    {
      "epoch": 0.06567759709929225,
      "grad_norm": 0.36663517355918884,
      "learning_rate": 9.343224029007078e-06,
      "loss": 0.1285,
      "step": 4148
    },
    {
      "epoch": 0.06569343065693431,
      "grad_norm": 0.012120652943849564,
      "learning_rate": 9.343065693430657e-06,
      "loss": 0.0007,
      "step": 4149
    },
    {
      "epoch": 0.06570926421457637,
      "grad_norm": 0.4514422118663788,
      "learning_rate": 9.342907357854238e-06,
      "loss": 0.0324,
      "step": 4150
    },
    {
      "epoch": 0.06572509777221844,
      "grad_norm": 0.2926446199417114,
      "learning_rate": 9.342749022277815e-06,
      "loss": 0.1799,
      "step": 4151
    },
    {
      "epoch": 0.0657409313298605,
      "grad_norm": 0.31268948316574097,
      "learning_rate": 9.342590686701396e-06,
      "loss": 0.1678,
      "step": 4152
    },
    {
      "epoch": 0.06575676488750257,
      "grad_norm": 0.20646154880523682,
      "learning_rate": 9.342432351124975e-06,
      "loss": 0.1957,
      "step": 4153
    },
    {
      "epoch": 0.06577259844514464,
      "grad_norm": 0.19480696320533752,
      "learning_rate": 9.342274015548554e-06,
      "loss": 0.0974,
      "step": 4154
    },
    {
      "epoch": 0.06578843200278671,
      "grad_norm": 0.025037478655576706,
      "learning_rate": 9.342115679972133e-06,
      "loss": 0.0005,
      "step": 4155
    },
    {
      "epoch": 0.06580426556042877,
      "grad_norm": 0.00047931261360645294,
      "learning_rate": 9.341957344395714e-06,
      "loss": 0.0,
      "step": 4156
    },
    {
      "epoch": 0.06582009911807084,
      "grad_norm": 0.25995880365371704,
      "learning_rate": 9.341799008819292e-06,
      "loss": 0.1963,
      "step": 4157
    },
    {
      "epoch": 0.0658359326757129,
      "grad_norm": 0.4399672746658325,
      "learning_rate": 9.341640673242872e-06,
      "loss": 0.3483,
      "step": 4158
    },
    {
      "epoch": 0.06585176623335497,
      "grad_norm": 0.30365389585494995,
      "learning_rate": 9.341482337666451e-06,
      "loss": 0.4148,
      "step": 4159
    },
    {
      "epoch": 0.06586759979099704,
      "grad_norm": 0.23483547568321228,
      "learning_rate": 9.34132400209003e-06,
      "loss": 0.0636,
      "step": 4160
    },
    {
      "epoch": 0.06588343334863911,
      "grad_norm": 0.39647284150123596,
      "learning_rate": 9.34116566651361e-06,
      "loss": 0.1532,
      "step": 4161
    },
    {
      "epoch": 0.06589926690628117,
      "grad_norm": 0.17948900163173676,
      "learning_rate": 9.34100733093719e-06,
      "loss": 0.086,
      "step": 4162
    },
    {
      "epoch": 0.06591510046392324,
      "grad_norm": 0.2863740921020508,
      "learning_rate": 9.340848995360768e-06,
      "loss": 0.134,
      "step": 4163
    },
    {
      "epoch": 0.0659309340215653,
      "grad_norm": 0.029150478541851044,
      "learning_rate": 9.340690659784347e-06,
      "loss": 0.0018,
      "step": 4164
    },
    {
      "epoch": 0.06594676757920737,
      "grad_norm": 0.7365180253982544,
      "learning_rate": 9.340532324207928e-06,
      "loss": 0.241,
      "step": 4165
    },
    {
      "epoch": 0.06596260113684944,
      "grad_norm": 0.6414923667907715,
      "learning_rate": 9.340373988631507e-06,
      "loss": 0.1081,
      "step": 4166
    },
    {
      "epoch": 0.06597843469449151,
      "grad_norm": 0.04594406113028526,
      "learning_rate": 9.340215653055086e-06,
      "loss": 0.005,
      "step": 4167
    },
    {
      "epoch": 0.06599426825213357,
      "grad_norm": 0.19656215608119965,
      "learning_rate": 9.340057317478665e-06,
      "loss": 0.1664,
      "step": 4168
    },
    {
      "epoch": 0.06601010180977564,
      "grad_norm": 0.020426331087946892,
      "learning_rate": 9.339898981902244e-06,
      "loss": 0.0011,
      "step": 4169
    },
    {
      "epoch": 0.0660259353674177,
      "grad_norm": 0.4384108781814575,
      "learning_rate": 9.339740646325823e-06,
      "loss": 0.0795,
      "step": 4170
    },
    {
      "epoch": 0.06604176892505977,
      "grad_norm": 0.27601170539855957,
      "learning_rate": 9.339582310749404e-06,
      "loss": 0.2897,
      "step": 4171
    },
    {
      "epoch": 0.06605760248270184,
      "grad_norm": 0.4323424696922302,
      "learning_rate": 9.339423975172981e-06,
      "loss": 0.3339,
      "step": 4172
    },
    {
      "epoch": 0.06607343604034391,
      "grad_norm": 0.3184138834476471,
      "learning_rate": 9.339265639596562e-06,
      "loss": 0.3349,
      "step": 4173
    },
    {
      "epoch": 0.06608926959798597,
      "grad_norm": 0.00023807433899492025,
      "learning_rate": 9.339107304020141e-06,
      "loss": 0.0,
      "step": 4174
    },
    {
      "epoch": 0.06610510315562804,
      "grad_norm": 0.27197811007499695,
      "learning_rate": 9.33894896844372e-06,
      "loss": 0.1301,
      "step": 4175
    },
    {
      "epoch": 0.0661209367132701,
      "grad_norm": 0.3377479314804077,
      "learning_rate": 9.3387906328673e-06,
      "loss": 0.5759,
      "step": 4176
    },
    {
      "epoch": 0.06613677027091217,
      "grad_norm": 0.3038674294948578,
      "learning_rate": 9.33863229729088e-06,
      "loss": 0.126,
      "step": 4177
    },
    {
      "epoch": 0.06615260382855424,
      "grad_norm": 0.0019243003334850073,
      "learning_rate": 9.338473961714457e-06,
      "loss": 0.0,
      "step": 4178
    },
    {
      "epoch": 0.06616843738619631,
      "grad_norm": 0.45015713572502136,
      "learning_rate": 9.338315626138038e-06,
      "loss": 0.2687,
      "step": 4179
    },
    {
      "epoch": 0.06618427094383837,
      "grad_norm": 0.5652197003364563,
      "learning_rate": 9.338157290561617e-06,
      "loss": 0.147,
      "step": 4180
    },
    {
      "epoch": 0.06620010450148044,
      "grad_norm": 0.4556371867656708,
      "learning_rate": 9.337998954985196e-06,
      "loss": 0.1481,
      "step": 4181
    },
    {
      "epoch": 0.0662159380591225,
      "grad_norm": 0.21927587687969208,
      "learning_rate": 9.337840619408775e-06,
      "loss": 0.0626,
      "step": 4182
    },
    {
      "epoch": 0.06623177161676456,
      "grad_norm": 0.21786284446716309,
      "learning_rate": 9.337682283832356e-06,
      "loss": 0.0608,
      "step": 4183
    },
    {
      "epoch": 0.06624760517440664,
      "grad_norm": 0.22697819769382477,
      "learning_rate": 9.337523948255934e-06,
      "loss": 0.1996,
      "step": 4184
    },
    {
      "epoch": 0.06626343873204871,
      "grad_norm": 0.49586915969848633,
      "learning_rate": 9.337365612679514e-06,
      "loss": 0.562,
      "step": 4185
    },
    {
      "epoch": 0.06627927228969077,
      "grad_norm": 0.10238143056631088,
      "learning_rate": 9.337207277103093e-06,
      "loss": 0.0482,
      "step": 4186
    },
    {
      "epoch": 0.06629510584733284,
      "grad_norm": 0.13540783524513245,
      "learning_rate": 9.337048941526672e-06,
      "loss": 0.0036,
      "step": 4187
    },
    {
      "epoch": 0.0663109394049749,
      "grad_norm": 0.11547785252332687,
      "learning_rate": 9.336890605950252e-06,
      "loss": 0.0634,
      "step": 4188
    },
    {
      "epoch": 0.06632677296261696,
      "grad_norm": 0.24694949388504028,
      "learning_rate": 9.33673227037383e-06,
      "loss": 0.2913,
      "step": 4189
    },
    {
      "epoch": 0.06634260652025904,
      "grad_norm": 0.0069851805455982685,
      "learning_rate": 9.33657393479741e-06,
      "loss": 0.0004,
      "step": 4190
    },
    {
      "epoch": 0.0663584400779011,
      "grad_norm": 0.007074191700667143,
      "learning_rate": 9.336415599220989e-06,
      "loss": 0.0004,
      "step": 4191
    },
    {
      "epoch": 0.06637427363554317,
      "grad_norm": 0.09719973802566528,
      "learning_rate": 9.33625726364457e-06,
      "loss": 0.012,
      "step": 4192
    },
    {
      "epoch": 0.06639010719318524,
      "grad_norm": 0.007295122370123863,
      "learning_rate": 9.336098928068149e-06,
      "loss": 0.0005,
      "step": 4193
    },
    {
      "epoch": 0.0664059407508273,
      "grad_norm": 0.015635119751095772,
      "learning_rate": 9.335940592491728e-06,
      "loss": 0.0008,
      "step": 4194
    },
    {
      "epoch": 0.06642177430846936,
      "grad_norm": 0.10604830086231232,
      "learning_rate": 9.335782256915307e-06,
      "loss": 0.0409,
      "step": 4195
    },
    {
      "epoch": 0.06643760786611144,
      "grad_norm": 0.2805369198322296,
      "learning_rate": 9.335623921338886e-06,
      "loss": 0.4592,
      "step": 4196
    },
    {
      "epoch": 0.0664534414237535,
      "grad_norm": 0.39161059260368347,
      "learning_rate": 9.335465585762465e-06,
      "loss": 0.5136,
      "step": 4197
    },
    {
      "epoch": 0.06646927498139557,
      "grad_norm": 0.15598763525485992,
      "learning_rate": 9.335307250186046e-06,
      "loss": 0.0533,
      "step": 4198
    },
    {
      "epoch": 0.06648510853903764,
      "grad_norm": 0.18730634450912476,
      "learning_rate": 9.335148914609625e-06,
      "loss": 0.1737,
      "step": 4199
    },
    {
      "epoch": 0.0665009420966797,
      "grad_norm": 0.5662516355514526,
      "learning_rate": 9.334990579033204e-06,
      "loss": 0.4819,
      "step": 4200
    },
    {
      "epoch": 0.06651677565432176,
      "grad_norm": 0.4772419035434723,
      "learning_rate": 9.334832243456783e-06,
      "loss": 0.5067,
      "step": 4201
    },
    {
      "epoch": 0.06653260921196384,
      "grad_norm": 0.22175389528274536,
      "learning_rate": 9.334673907880362e-06,
      "loss": 0.0422,
      "step": 4202
    },
    {
      "epoch": 0.0665484427696059,
      "grad_norm": 0.2878338694572449,
      "learning_rate": 9.334515572303941e-06,
      "loss": 0.1531,
      "step": 4203
    },
    {
      "epoch": 0.06656427632724797,
      "grad_norm": 0.5034818649291992,
      "learning_rate": 9.334357236727522e-06,
      "loss": 0.2573,
      "step": 4204
    },
    {
      "epoch": 0.06658010988489003,
      "grad_norm": 0.0003601779171731323,
      "learning_rate": 9.334198901151101e-06,
      "loss": 0.0,
      "step": 4205
    },
    {
      "epoch": 0.0665959434425321,
      "grad_norm": 0.14858105778694153,
      "learning_rate": 9.33404056557468e-06,
      "loss": 0.0517,
      "step": 4206
    },
    {
      "epoch": 0.06661177700017416,
      "grad_norm": 0.16324011981487274,
      "learning_rate": 9.33388222999826e-06,
      "loss": 0.0179,
      "step": 4207
    },
    {
      "epoch": 0.06662761055781624,
      "grad_norm": 0.0008694845018908381,
      "learning_rate": 9.333723894421838e-06,
      "loss": 0.0,
      "step": 4208
    },
    {
      "epoch": 0.0666434441154583,
      "grad_norm": 0.2894516587257385,
      "learning_rate": 9.333565558845417e-06,
      "loss": 0.1953,
      "step": 4209
    },
    {
      "epoch": 0.06665927767310037,
      "grad_norm": 0.009465008042752743,
      "learning_rate": 9.333407223268998e-06,
      "loss": 0.0005,
      "step": 4210
    },
    {
      "epoch": 0.06667511123074243,
      "grad_norm": 0.06137876212596893,
      "learning_rate": 9.333248887692577e-06,
      "loss": 0.0033,
      "step": 4211
    },
    {
      "epoch": 0.0666909447883845,
      "grad_norm": 0.02456771954894066,
      "learning_rate": 9.333090552116155e-06,
      "loss": 0.0013,
      "step": 4212
    },
    {
      "epoch": 0.06670677834602656,
      "grad_norm": 0.3838564157485962,
      "learning_rate": 9.332932216539735e-06,
      "loss": 0.5196,
      "step": 4213
    },
    {
      "epoch": 0.06672261190366864,
      "grad_norm": 0.8546320199966431,
      "learning_rate": 9.332773880963314e-06,
      "loss": 0.2389,
      "step": 4214
    },
    {
      "epoch": 0.0667384454613107,
      "grad_norm": 0.3973640501499176,
      "learning_rate": 9.332615545386893e-06,
      "loss": 0.5313,
      "step": 4215
    },
    {
      "epoch": 0.06675427901895277,
      "grad_norm": 0.013014671392738819,
      "learning_rate": 9.332457209810473e-06,
      "loss": 0.0007,
      "step": 4216
    },
    {
      "epoch": 0.06677011257659483,
      "grad_norm": 0.4019361734390259,
      "learning_rate": 9.332298874234053e-06,
      "loss": 0.2502,
      "step": 4217
    },
    {
      "epoch": 0.0667859461342369,
      "grad_norm": 0.2228512316942215,
      "learning_rate": 9.33214053865763e-06,
      "loss": 0.1069,
      "step": 4218
    },
    {
      "epoch": 0.06680177969187896,
      "grad_norm": 0.2540700435638428,
      "learning_rate": 9.331982203081212e-06,
      "loss": 0.0761,
      "step": 4219
    },
    {
      "epoch": 0.06681761324952104,
      "grad_norm": 0.4124617576599121,
      "learning_rate": 9.33182386750479e-06,
      "loss": 0.1747,
      "step": 4220
    },
    {
      "epoch": 0.0668334468071631,
      "grad_norm": 0.05593098700046539,
      "learning_rate": 9.33166553192837e-06,
      "loss": 0.0109,
      "step": 4221
    },
    {
      "epoch": 0.06684928036480517,
      "grad_norm": 0.020159753039479256,
      "learning_rate": 9.331507196351949e-06,
      "loss": 0.0009,
      "step": 4222
    },
    {
      "epoch": 0.06686511392244723,
      "grad_norm": 0.008836260996758938,
      "learning_rate": 9.33134886077553e-06,
      "loss": 0.0004,
      "step": 4223
    },
    {
      "epoch": 0.0668809474800893,
      "grad_norm": 0.024472441524267197,
      "learning_rate": 9.331190525199107e-06,
      "loss": 0.0015,
      "step": 4224
    },
    {
      "epoch": 0.06689678103773136,
      "grad_norm": 0.44721513986587524,
      "learning_rate": 9.331032189622688e-06,
      "loss": 0.2402,
      "step": 4225
    },
    {
      "epoch": 0.06691261459537344,
      "grad_norm": 0.01762811839580536,
      "learning_rate": 9.330873854046267e-06,
      "loss": 0.0009,
      "step": 4226
    },
    {
      "epoch": 0.0669284481530155,
      "grad_norm": 0.2663585841655731,
      "learning_rate": 9.330715518469846e-06,
      "loss": 0.2861,
      "step": 4227
    },
    {
      "epoch": 0.06694428171065757,
      "grad_norm": 0.9955976605415344,
      "learning_rate": 9.330557182893425e-06,
      "loss": 0.0508,
      "step": 4228
    },
    {
      "epoch": 0.06696011526829963,
      "grad_norm": 0.0009796081576496363,
      "learning_rate": 9.330398847317006e-06,
      "loss": 0.0,
      "step": 4229
    },
    {
      "epoch": 0.0669759488259417,
      "grad_norm": 0.24858258664608002,
      "learning_rate": 9.330240511740583e-06,
      "loss": 0.3923,
      "step": 4230
    },
    {
      "epoch": 0.06699178238358376,
      "grad_norm": 0.303279846906662,
      "learning_rate": 9.330082176164164e-06,
      "loss": 0.1104,
      "step": 4231
    },
    {
      "epoch": 0.06700761594122584,
      "grad_norm": 0.4448421001434326,
      "learning_rate": 9.329923840587743e-06,
      "loss": 0.1346,
      "step": 4232
    },
    {
      "epoch": 0.0670234494988679,
      "grad_norm": 0.020885974168777466,
      "learning_rate": 9.329765505011322e-06,
      "loss": 0.001,
      "step": 4233
    },
    {
      "epoch": 0.06703928305650997,
      "grad_norm": 0.023092519491910934,
      "learning_rate": 9.329607169434901e-06,
      "loss": 0.0014,
      "step": 4234
    },
    {
      "epoch": 0.06705511661415203,
      "grad_norm": 0.1867394745349884,
      "learning_rate": 9.32944883385848e-06,
      "loss": 0.0438,
      "step": 4235
    },
    {
      "epoch": 0.0670709501717941,
      "grad_norm": 0.2689587473869324,
      "learning_rate": 9.32929049828206e-06,
      "loss": 0.6712,
      "step": 4236
    },
    {
      "epoch": 0.06708678372943616,
      "grad_norm": 0.32804661989212036,
      "learning_rate": 9.329132162705638e-06,
      "loss": 0.3367,
      "step": 4237
    },
    {
      "epoch": 0.06710261728707824,
      "grad_norm": 0.27710816264152527,
      "learning_rate": 9.328973827129219e-06,
      "loss": 0.101,
      "step": 4238
    },
    {
      "epoch": 0.0671184508447203,
      "grad_norm": 0.006132760550826788,
      "learning_rate": 9.328815491552796e-06,
      "loss": 0.0002,
      "step": 4239
    },
    {
      "epoch": 0.06713428440236237,
      "grad_norm": 0.06272929906845093,
      "learning_rate": 9.328657155976377e-06,
      "loss": 0.0032,
      "step": 4240
    },
    {
      "epoch": 0.06715011796000443,
      "grad_norm": 0.001980283297598362,
      "learning_rate": 9.328498820399956e-06,
      "loss": 0.0001,
      "step": 4241
    },
    {
      "epoch": 0.0671659515176465,
      "grad_norm": 0.0006083126063458622,
      "learning_rate": 9.328340484823535e-06,
      "loss": 0.0,
      "step": 4242
    },
    {
      "epoch": 0.06718178507528856,
      "grad_norm": 0.008861442096531391,
      "learning_rate": 9.328182149247114e-06,
      "loss": 0.0004,
      "step": 4243
    },
    {
      "epoch": 0.06719761863293064,
      "grad_norm": 0.32328304648399353,
      "learning_rate": 9.328023813670695e-06,
      "loss": 0.1503,
      "step": 4244
    },
    {
      "epoch": 0.0672134521905727,
      "grad_norm": 0.0001169492315966636,
      "learning_rate": 9.327865478094273e-06,
      "loss": 0.0,
      "step": 4245
    },
    {
      "epoch": 0.06722928574821477,
      "grad_norm": 0.5537222623825073,
      "learning_rate": 9.327707142517853e-06,
      "loss": 0.078,
      "step": 4246
    },
    {
      "epoch": 0.06724511930585683,
      "grad_norm": 0.4254867434501648,
      "learning_rate": 9.327548806941433e-06,
      "loss": 0.1004,
      "step": 4247
    },
    {
      "epoch": 0.0672609528634989,
      "grad_norm": 0.019770918413996696,
      "learning_rate": 9.327390471365012e-06,
      "loss": 0.0012,
      "step": 4248
    },
    {
      "epoch": 0.06727678642114096,
      "grad_norm": 0.5449270606040955,
      "learning_rate": 9.32723213578859e-06,
      "loss": 0.3207,
      "step": 4249
    },
    {
      "epoch": 0.06729261997878304,
      "grad_norm": 0.017505913972854614,
      "learning_rate": 9.327073800212171e-06,
      "loss": 0.0007,
      "step": 4250
    },
    {
      "epoch": 0.0673084535364251,
      "grad_norm": 0.19744092226028442,
      "learning_rate": 9.326915464635749e-06,
      "loss": 0.0568,
      "step": 4251
    },
    {
      "epoch": 0.06732428709406717,
      "grad_norm": 0.47491806745529175,
      "learning_rate": 9.32675712905933e-06,
      "loss": 0.2937,
      "step": 4252
    },
    {
      "epoch": 0.06734012065170923,
      "grad_norm": 1.1703455448150635,
      "learning_rate": 9.326598793482909e-06,
      "loss": 0.1121,
      "step": 4253
    },
    {
      "epoch": 0.0673559542093513,
      "grad_norm": 0.46385085582733154,
      "learning_rate": 9.326440457906488e-06,
      "loss": 0.1188,
      "step": 4254
    },
    {
      "epoch": 0.06737178776699336,
      "grad_norm": 0.023097490891814232,
      "learning_rate": 9.326282122330067e-06,
      "loss": 0.0009,
      "step": 4255
    },
    {
      "epoch": 0.06738762132463544,
      "grad_norm": 0.0001922247902257368,
      "learning_rate": 9.326123786753648e-06,
      "loss": 0.0,
      "step": 4256
    },
    {
      "epoch": 0.0674034548822775,
      "grad_norm": 0.00041536299977451563,
      "learning_rate": 9.325965451177225e-06,
      "loss": 0.0,
      "step": 4257
    },
    {
      "epoch": 0.06741928843991957,
      "grad_norm": 0.46425777673721313,
      "learning_rate": 9.325807115600806e-06,
      "loss": 0.0891,
      "step": 4258
    },
    {
      "epoch": 0.06743512199756163,
      "grad_norm": 0.08089748024940491,
      "learning_rate": 9.325648780024385e-06,
      "loss": 0.0079,
      "step": 4259
    },
    {
      "epoch": 0.0674509555552037,
      "grad_norm": 0.02150500752031803,
      "learning_rate": 9.325490444447964e-06,
      "loss": 0.0006,
      "step": 4260
    },
    {
      "epoch": 0.06746678911284576,
      "grad_norm": 0.219082772731781,
      "learning_rate": 9.325332108871543e-06,
      "loss": 0.1126,
      "step": 4261
    },
    {
      "epoch": 0.06748262267048784,
      "grad_norm": 0.31990158557891846,
      "learning_rate": 9.325173773295122e-06,
      "loss": 0.1555,
      "step": 4262
    },
    {
      "epoch": 0.0674984562281299,
      "grad_norm": 0.00038085755659267306,
      "learning_rate": 9.325015437718701e-06,
      "loss": 0.0,
      "step": 4263
    },
    {
      "epoch": 0.06751428978577197,
      "grad_norm": 0.2357243150472641,
      "learning_rate": 9.32485710214228e-06,
      "loss": 0.3141,
      "step": 4264
    },
    {
      "epoch": 0.06753012334341403,
      "grad_norm": 0.2865573465824127,
      "learning_rate": 9.324698766565861e-06,
      "loss": 0.3763,
      "step": 4265
    },
    {
      "epoch": 0.0675459569010561,
      "grad_norm": 0.24886739253997803,
      "learning_rate": 9.32454043098944e-06,
      "loss": 0.0445,
      "step": 4266
    },
    {
      "epoch": 0.06756179045869816,
      "grad_norm": 0.00020681375463027507,
      "learning_rate": 9.32438209541302e-06,
      "loss": 0.0,
      "step": 4267
    },
    {
      "epoch": 0.06757762401634024,
      "grad_norm": 0.7769109010696411,
      "learning_rate": 9.324223759836598e-06,
      "loss": 0.5815,
      "step": 4268
    },
    {
      "epoch": 0.0675934575739823,
      "grad_norm": 0.10116798430681229,
      "learning_rate": 9.324065424260177e-06,
      "loss": 0.0019,
      "step": 4269
    },
    {
      "epoch": 0.06760929113162437,
      "grad_norm": 0.70123291015625,
      "learning_rate": 9.323907088683756e-06,
      "loss": 0.6073,
      "step": 4270
    },
    {
      "epoch": 0.06762512468926643,
      "grad_norm": 0.008873814716935158,
      "learning_rate": 9.323748753107337e-06,
      "loss": 0.0003,
      "step": 4271
    },
    {
      "epoch": 0.0676409582469085,
      "grad_norm": 0.003080203663557768,
      "learning_rate": 9.323590417530916e-06,
      "loss": 0.0001,
      "step": 4272
    },
    {
      "epoch": 0.06765679180455056,
      "grad_norm": 0.30868780612945557,
      "learning_rate": 9.323432081954495e-06,
      "loss": 0.162,
      "step": 4273
    },
    {
      "epoch": 0.06767262536219264,
      "grad_norm": 0.012048712931573391,
      "learning_rate": 9.323273746378074e-06,
      "loss": 0.0005,
      "step": 4274
    },
    {
      "epoch": 0.0676884589198347,
      "grad_norm": 0.3459072411060333,
      "learning_rate": 9.323115410801654e-06,
      "loss": 0.0196,
      "step": 4275
    },
    {
      "epoch": 0.06770429247747677,
      "grad_norm": 0.18154367804527283,
      "learning_rate": 9.322957075225233e-06,
      "loss": 0.1149,
      "step": 4276
    },
    {
      "epoch": 0.06772012603511883,
      "grad_norm": 0.19121567904949188,
      "learning_rate": 9.322798739648813e-06,
      "loss": 0.0039,
      "step": 4277
    },
    {
      "epoch": 0.0677359595927609,
      "grad_norm": 0.2564276456832886,
      "learning_rate": 9.322640404072392e-06,
      "loss": 0.1924,
      "step": 4278
    },
    {
      "epoch": 0.06775179315040296,
      "grad_norm": 0.4188845157623291,
      "learning_rate": 9.322482068495972e-06,
      "loss": 0.1946,
      "step": 4279
    },
    {
      "epoch": 0.06776762670804504,
      "grad_norm": 0.004138322081416845,
      "learning_rate": 9.32232373291955e-06,
      "loss": 0.0002,
      "step": 4280
    },
    {
      "epoch": 0.0677834602656871,
      "grad_norm": 0.2578960359096527,
      "learning_rate": 9.32216539734313e-06,
      "loss": 0.0606,
      "step": 4281
    },
    {
      "epoch": 0.06779929382332917,
      "grad_norm": 0.00031714627402834594,
      "learning_rate": 9.322007061766709e-06,
      "loss": 0.0,
      "step": 4282
    },
    {
      "epoch": 0.06781512738097123,
      "grad_norm": 0.17012812197208405,
      "learning_rate": 9.321848726190288e-06,
      "loss": 0.0985,
      "step": 4283
    },
    {
      "epoch": 0.0678309609386133,
      "grad_norm": 0.0002795201726257801,
      "learning_rate": 9.321690390613869e-06,
      "loss": 0.0,
      "step": 4284
    },
    {
      "epoch": 0.06784679449625536,
      "grad_norm": 0.1217031180858612,
      "learning_rate": 9.321532055037446e-06,
      "loss": 0.0787,
      "step": 4285
    },
    {
      "epoch": 0.06786262805389744,
      "grad_norm": 0.2738969624042511,
      "learning_rate": 9.321373719461027e-06,
      "loss": 0.1086,
      "step": 4286
    },
    {
      "epoch": 0.0678784616115395,
      "grad_norm": 0.1647726595401764,
      "learning_rate": 9.321215383884606e-06,
      "loss": 0.004,
      "step": 4287
    },
    {
      "epoch": 0.06789429516918156,
      "grad_norm": 0.26521527767181396,
      "learning_rate": 9.321057048308185e-06,
      "loss": 0.1126,
      "step": 4288
    },
    {
      "epoch": 0.06791012872682363,
      "grad_norm": 0.00010839698370546103,
      "learning_rate": 9.320898712731764e-06,
      "loss": 0.0,
      "step": 4289
    },
    {
      "epoch": 0.0679259622844657,
      "grad_norm": 0.19846847653388977,
      "learning_rate": 9.320740377155345e-06,
      "loss": 0.0882,
      "step": 4290
    },
    {
      "epoch": 0.06794179584210776,
      "grad_norm": 0.009078985080122948,
      "learning_rate": 9.320582041578922e-06,
      "loss": 0.0005,
      "step": 4291
    },
    {
      "epoch": 0.06795762939974984,
      "grad_norm": 0.6774230003356934,
      "learning_rate": 9.320423706002503e-06,
      "loss": 0.4761,
      "step": 4292
    },
    {
      "epoch": 0.0679734629573919,
      "grad_norm": 4.942022800445557,
      "learning_rate": 9.320265370426082e-06,
      "loss": 0.3173,
      "step": 4293
    },
    {
      "epoch": 0.06798929651503396,
      "grad_norm": 0.12882183492183685,
      "learning_rate": 9.320107034849661e-06,
      "loss": 0.0575,
      "step": 4294
    },
    {
      "epoch": 0.06800513007267603,
      "grad_norm": 0.256472647190094,
      "learning_rate": 9.31994869927324e-06,
      "loss": 0.6057,
      "step": 4295
    },
    {
      "epoch": 0.0680209636303181,
      "grad_norm": 0.1678859442472458,
      "learning_rate": 9.31979036369682e-06,
      "loss": 0.085,
      "step": 4296
    },
    {
      "epoch": 0.06803679718796016,
      "grad_norm": 0.01583457924425602,
      "learning_rate": 9.319632028120398e-06,
      "loss": 0.0012,
      "step": 4297
    },
    {
      "epoch": 0.06805263074560224,
      "grad_norm": 0.07052848488092422,
      "learning_rate": 9.319473692543979e-06,
      "loss": 0.0033,
      "step": 4298
    },
    {
      "epoch": 0.0680684643032443,
      "grad_norm": 0.5564801692962646,
      "learning_rate": 9.319315356967558e-06,
      "loss": 0.3268,
      "step": 4299
    },
    {
      "epoch": 0.06808429786088636,
      "grad_norm": 0.011590455658733845,
      "learning_rate": 9.319157021391137e-06,
      "loss": 0.0006,
      "step": 4300
    },
    {
      "epoch": 0.06810013141852843,
      "grad_norm": 0.04496588185429573,
      "learning_rate": 9.318998685814716e-06,
      "loss": 0.0025,
      "step": 4301
    },
    {
      "epoch": 0.06811596497617049,
      "grad_norm": 0.06710422039031982,
      "learning_rate": 9.318840350238295e-06,
      "loss": 0.0052,
      "step": 4302
    },
    {
      "epoch": 0.06813179853381256,
      "grad_norm": 0.00033922045258805156,
      "learning_rate": 9.318682014661875e-06,
      "loss": 0.0,
      "step": 4303
    },
    {
      "epoch": 0.06814763209145464,
      "grad_norm": 0.08819681406021118,
      "learning_rate": 9.318523679085455e-06,
      "loss": 0.0145,
      "step": 4304
    },
    {
      "epoch": 0.0681634656490967,
      "grad_norm": 0.2784889042377472,
      "learning_rate": 9.318365343509034e-06,
      "loss": 0.1513,
      "step": 4305
    },
    {
      "epoch": 0.06817929920673876,
      "grad_norm": 0.33806660771369934,
      "learning_rate": 9.318207007932613e-06,
      "loss": 0.7572,
      "step": 4306
    },
    {
      "epoch": 0.06819513276438083,
      "grad_norm": 0.011162611655890942,
      "learning_rate": 9.318048672356193e-06,
      "loss": 0.0005,
      "step": 4307
    },
    {
      "epoch": 0.06821096632202289,
      "grad_norm": 0.008518240414559841,
      "learning_rate": 9.317890336779772e-06,
      "loss": 0.0004,
      "step": 4308
    },
    {
      "epoch": 0.06822679987966496,
      "grad_norm": 0.5567498803138733,
      "learning_rate": 9.31773200120335e-06,
      "loss": 0.7404,
      "step": 4309
    },
    {
      "epoch": 0.06824263343730703,
      "grad_norm": 0.29255303740501404,
      "learning_rate": 9.31757366562693e-06,
      "loss": 0.2066,
      "step": 4310
    },
    {
      "epoch": 0.0682584669949491,
      "grad_norm": 0.00011486974835861474,
      "learning_rate": 9.31741533005051e-06,
      "loss": 0.0,
      "step": 4311
    },
    {
      "epoch": 0.06827430055259116,
      "grad_norm": 0.15186530351638794,
      "learning_rate": 9.317256994474088e-06,
      "loss": 0.1053,
      "step": 4312
    },
    {
      "epoch": 0.06829013411023323,
      "grad_norm": 0.00010241343261441216,
      "learning_rate": 9.317098658897669e-06,
      "loss": 0.0,
      "step": 4313
    },
    {
      "epoch": 0.06830596766787529,
      "grad_norm": 0.03303888067603111,
      "learning_rate": 9.316940323321248e-06,
      "loss": 0.0021,
      "step": 4314
    },
    {
      "epoch": 0.06832180122551736,
      "grad_norm": 0.20677287876605988,
      "learning_rate": 9.316781987744827e-06,
      "loss": 0.1028,
      "step": 4315
    },
    {
      "epoch": 0.06833763478315943,
      "grad_norm": 0.1652238965034485,
      "learning_rate": 9.316623652168406e-06,
      "loss": 0.0383,
      "step": 4316
    },
    {
      "epoch": 0.0683534683408015,
      "grad_norm": 0.448843389749527,
      "learning_rate": 9.316465316591987e-06,
      "loss": 0.0397,
      "step": 4317
    },
    {
      "epoch": 0.06836930189844356,
      "grad_norm": 0.2891272306442261,
      "learning_rate": 9.316306981015564e-06,
      "loss": 0.2226,
      "step": 4318
    },
    {
      "epoch": 0.06838513545608563,
      "grad_norm": 0.21548540890216827,
      "learning_rate": 9.316148645439145e-06,
      "loss": 0.2151,
      "step": 4319
    },
    {
      "epoch": 0.06840096901372769,
      "grad_norm": 0.00027527380734682083,
      "learning_rate": 9.315990309862724e-06,
      "loss": 0.0,
      "step": 4320
    },
    {
      "epoch": 0.06841680257136976,
      "grad_norm": 0.5346307158470154,
      "learning_rate": 9.315831974286303e-06,
      "loss": 0.6409,
      "step": 4321
    },
    {
      "epoch": 0.06843263612901183,
      "grad_norm": 0.2791980803012848,
      "learning_rate": 9.315673638709882e-06,
      "loss": 0.0651,
      "step": 4322
    },
    {
      "epoch": 0.0684484696866539,
      "grad_norm": 0.006382335908710957,
      "learning_rate": 9.315515303133463e-06,
      "loss": 0.0003,
      "step": 4323
    },
    {
      "epoch": 0.06846430324429596,
      "grad_norm": 0.24663704633712769,
      "learning_rate": 9.31535696755704e-06,
      "loss": 0.194,
      "step": 4324
    },
    {
      "epoch": 0.06848013680193803,
      "grad_norm": 0.0005017005023546517,
      "learning_rate": 9.315198631980621e-06,
      "loss": 0.0,
      "step": 4325
    },
    {
      "epoch": 0.06849597035958009,
      "grad_norm": 0.3964652121067047,
      "learning_rate": 9.3150402964042e-06,
      "loss": 0.6902,
      "step": 4326
    },
    {
      "epoch": 0.06851180391722216,
      "grad_norm": 0.245501309633255,
      "learning_rate": 9.31488196082778e-06,
      "loss": 0.1919,
      "step": 4327
    },
    {
      "epoch": 0.06852763747486423,
      "grad_norm": 0.00335508119314909,
      "learning_rate": 9.314723625251358e-06,
      "loss": 0.0002,
      "step": 4328
    },
    {
      "epoch": 0.0685434710325063,
      "grad_norm": 0.0001732672390062362,
      "learning_rate": 9.314565289674939e-06,
      "loss": 0.0,
      "step": 4329
    },
    {
      "epoch": 0.06855930459014836,
      "grad_norm": 0.29265403747558594,
      "learning_rate": 9.314406954098516e-06,
      "loss": 0.0715,
      "step": 4330
    },
    {
      "epoch": 0.06857513814779043,
      "grad_norm": 0.16115324199199677,
      "learning_rate": 9.314248618522096e-06,
      "loss": 0.0511,
      "step": 4331
    },
    {
      "epoch": 0.06859097170543249,
      "grad_norm": 0.3377697467803955,
      "learning_rate": 9.314090282945676e-06,
      "loss": 0.3941,
      "step": 4332
    },
    {
      "epoch": 0.06860680526307456,
      "grad_norm": 0.04636551812291145,
      "learning_rate": 9.313931947369255e-06,
      "loss": 0.0007,
      "step": 4333
    },
    {
      "epoch": 0.06862263882071663,
      "grad_norm": 1.6701778173446655,
      "learning_rate": 9.313773611792834e-06,
      "loss": 0.7557,
      "step": 4334
    },
    {
      "epoch": 0.0686384723783587,
      "grad_norm": 0.0628037303686142,
      "learning_rate": 9.313615276216414e-06,
      "loss": 0.0029,
      "step": 4335
    },
    {
      "epoch": 0.06865430593600076,
      "grad_norm": 0.2650963366031647,
      "learning_rate": 9.313456940639993e-06,
      "loss": 0.346,
      "step": 4336
    },
    {
      "epoch": 0.06867013949364283,
      "grad_norm": 0.21742209792137146,
      "learning_rate": 9.313298605063572e-06,
      "loss": 0.1078,
      "step": 4337
    },
    {
      "epoch": 0.06868597305128489,
      "grad_norm": 0.006426901090890169,
      "learning_rate": 9.313140269487152e-06,
      "loss": 0.0004,
      "step": 4338
    },
    {
      "epoch": 0.06870180660892695,
      "grad_norm": 0.1944754719734192,
      "learning_rate": 9.312981933910732e-06,
      "loss": 0.0742,
      "step": 4339
    },
    {
      "epoch": 0.06871764016656903,
      "grad_norm": 0.20966659486293793,
      "learning_rate": 9.31282359833431e-06,
      "loss": 0.0966,
      "step": 4340
    },
    {
      "epoch": 0.0687334737242111,
      "grad_norm": 0.15321367979049683,
      "learning_rate": 9.31266526275789e-06,
      "loss": 0.0114,
      "step": 4341
    },
    {
      "epoch": 0.06874930728185316,
      "grad_norm": 0.27152150869369507,
      "learning_rate": 9.312506927181469e-06,
      "loss": 0.0901,
      "step": 4342
    },
    {
      "epoch": 0.06876514083949523,
      "grad_norm": 0.48928049206733704,
      "learning_rate": 9.312348591605048e-06,
      "loss": 0.6961,
      "step": 4343
    },
    {
      "epoch": 0.06878097439713729,
      "grad_norm": 0.033319104462862015,
      "learning_rate": 9.312190256028629e-06,
      "loss": 0.0019,
      "step": 4344
    },
    {
      "epoch": 0.06879680795477935,
      "grad_norm": 0.09119877219200134,
      "learning_rate": 9.312031920452208e-06,
      "loss": 0.0077,
      "step": 4345
    },
    {
      "epoch": 0.06881264151242143,
      "grad_norm": 0.37460070848464966,
      "learning_rate": 9.311873584875787e-06,
      "loss": 0.1038,
      "step": 4346
    },
    {
      "epoch": 0.0688284750700635,
      "grad_norm": 0.0017458742950111628,
      "learning_rate": 9.311715249299366e-06,
      "loss": 0.0001,
      "step": 4347
    },
    {
      "epoch": 0.06884430862770556,
      "grad_norm": 0.3296549916267395,
      "learning_rate": 9.311556913722945e-06,
      "loss": 0.1646,
      "step": 4348
    },
    {
      "epoch": 0.06886014218534763,
      "grad_norm": 0.2007635235786438,
      "learning_rate": 9.311398578146524e-06,
      "loss": 0.0279,
      "step": 4349
    },
    {
      "epoch": 0.06887597574298969,
      "grad_norm": 0.0035653547383844852,
      "learning_rate": 9.311240242570105e-06,
      "loss": 0.0001,
      "step": 4350
    },
    {
      "epoch": 0.06889180930063175,
      "grad_norm": 0.42731958627700806,
      "learning_rate": 9.311081906993684e-06,
      "loss": 0.241,
      "step": 4351
    },
    {
      "epoch": 0.06890764285827383,
      "grad_norm": 0.6742885708808899,
      "learning_rate": 9.310923571417263e-06,
      "loss": 0.2062,
      "step": 4352
    },
    {
      "epoch": 0.0689234764159159,
      "grad_norm": 0.002963688690215349,
      "learning_rate": 9.310765235840842e-06,
      "loss": 0.0002,
      "step": 4353
    },
    {
      "epoch": 0.06893930997355796,
      "grad_norm": 0.12526176869869232,
      "learning_rate": 9.310606900264421e-06,
      "loss": 0.0914,
      "step": 4354
    },
    {
      "epoch": 0.06895514353120002,
      "grad_norm": 0.014557369984686375,
      "learning_rate": 9.310448564688e-06,
      "loss": 0.0005,
      "step": 4355
    },
    {
      "epoch": 0.06897097708884209,
      "grad_norm": 0.14188455045223236,
      "learning_rate": 9.31029022911158e-06,
      "loss": 0.0652,
      "step": 4356
    },
    {
      "epoch": 0.06898681064648415,
      "grad_norm": 0.008121710270643234,
      "learning_rate": 9.31013189353516e-06,
      "loss": 0.0004,
      "step": 4357
    },
    {
      "epoch": 0.06900264420412623,
      "grad_norm": 0.0012655251193791628,
      "learning_rate": 9.309973557958737e-06,
      "loss": 0.0,
      "step": 4358
    },
    {
      "epoch": 0.0690184777617683,
      "grad_norm": 0.14109398424625397,
      "learning_rate": 9.309815222382318e-06,
      "loss": 0.0518,
      "step": 4359
    },
    {
      "epoch": 0.06903431131941036,
      "grad_norm": 0.2186834067106247,
      "learning_rate": 9.309656886805897e-06,
      "loss": 0.2091,
      "step": 4360
    },
    {
      "epoch": 0.06905014487705242,
      "grad_norm": 0.43937814235687256,
      "learning_rate": 9.309498551229476e-06,
      "loss": 0.2981,
      "step": 4361
    },
    {
      "epoch": 0.06906597843469449,
      "grad_norm": 0.0007547453860752285,
      "learning_rate": 9.309340215653055e-06,
      "loss": 0.0,
      "step": 4362
    },
    {
      "epoch": 0.06908181199233655,
      "grad_norm": 0.11650510132312775,
      "learning_rate": 9.309181880076635e-06,
      "loss": 0.1946,
      "step": 4363
    },
    {
      "epoch": 0.06909764554997863,
      "grad_norm": 0.00018641586939338595,
      "learning_rate": 9.309023544500214e-06,
      "loss": 0.0,
      "step": 4364
    },
    {
      "epoch": 0.0691134791076207,
      "grad_norm": 0.312203049659729,
      "learning_rate": 9.308865208923794e-06,
      "loss": 0.1385,
      "step": 4365
    },
    {
      "epoch": 0.06912931266526276,
      "grad_norm": 0.18990476429462433,
      "learning_rate": 9.308706873347373e-06,
      "loss": 0.0353,
      "step": 4366
    },
    {
      "epoch": 0.06914514622290482,
      "grad_norm": 0.17807482182979584,
      "learning_rate": 9.308548537770953e-06,
      "loss": 0.0839,
      "step": 4367
    },
    {
      "epoch": 0.06916097978054689,
      "grad_norm": 0.13257770240306854,
      "learning_rate": 9.308390202194532e-06,
      "loss": 0.0674,
      "step": 4368
    },
    {
      "epoch": 0.06917681333818895,
      "grad_norm": 0.043822724372148514,
      "learning_rate": 9.30823186661811e-06,
      "loss": 0.0026,
      "step": 4369
    },
    {
      "epoch": 0.06919264689583103,
      "grad_norm": 0.008173107169568539,
      "learning_rate": 9.30807353104169e-06,
      "loss": 0.0002,
      "step": 4370
    },
    {
      "epoch": 0.0692084804534731,
      "grad_norm": 0.00018028072372544557,
      "learning_rate": 9.30791519546527e-06,
      "loss": 0.0,
      "step": 4371
    },
    {
      "epoch": 0.06922431401111516,
      "grad_norm": 0.27797406911849976,
      "learning_rate": 9.30775685988885e-06,
      "loss": 0.6538,
      "step": 4372
    },
    {
      "epoch": 0.06924014756875722,
      "grad_norm": 0.18072333931922913,
      "learning_rate": 9.307598524312429e-06,
      "loss": 0.0652,
      "step": 4373
    },
    {
      "epoch": 0.06925598112639929,
      "grad_norm": 0.4364873170852661,
      "learning_rate": 9.307440188736008e-06,
      "loss": 0.0322,
      "step": 4374
    },
    {
      "epoch": 0.06927181468404135,
      "grad_norm": 0.17686738073825836,
      "learning_rate": 9.307281853159587e-06,
      "loss": 0.0333,
      "step": 4375
    },
    {
      "epoch": 0.06928764824168343,
      "grad_norm": 0.17507623136043549,
      "learning_rate": 9.307123517583166e-06,
      "loss": 0.1019,
      "step": 4376
    },
    {
      "epoch": 0.0693034817993255,
      "grad_norm": 0.0005733692669309676,
      "learning_rate": 9.306965182006747e-06,
      "loss": 0.0,
      "step": 4377
    },
    {
      "epoch": 0.06931931535696756,
      "grad_norm": 0.2760917842388153,
      "learning_rate": 9.306806846430326e-06,
      "loss": 0.0492,
      "step": 4378
    },
    {
      "epoch": 0.06933514891460962,
      "grad_norm": 0.0028996351175010204,
      "learning_rate": 9.306648510853903e-06,
      "loss": 0.0002,
      "step": 4379
    },
    {
      "epoch": 0.06935098247225169,
      "grad_norm": 0.2039431482553482,
      "learning_rate": 9.306490175277484e-06,
      "loss": 0.1977,
      "step": 4380
    },
    {
      "epoch": 0.06936681602989375,
      "grad_norm": 0.26532068848609924,
      "learning_rate": 9.306331839701063e-06,
      "loss": 0.0694,
      "step": 4381
    },
    {
      "epoch": 0.06938264958753583,
      "grad_norm": 0.0006092839757911861,
      "learning_rate": 9.306173504124642e-06,
      "loss": 0.0,
      "step": 4382
    },
    {
      "epoch": 0.0693984831451779,
      "grad_norm": 0.2229020595550537,
      "learning_rate": 9.306015168548221e-06,
      "loss": 0.1858,
      "step": 4383
    },
    {
      "epoch": 0.06941431670281996,
      "grad_norm": 0.013604494743049145,
      "learning_rate": 9.305856832971802e-06,
      "loss": 0.0008,
      "step": 4384
    },
    {
      "epoch": 0.06943015026046202,
      "grad_norm": 0.3936171531677246,
      "learning_rate": 9.30569849739538e-06,
      "loss": 0.0835,
      "step": 4385
    },
    {
      "epoch": 0.06944598381810409,
      "grad_norm": 0.004322613589465618,
      "learning_rate": 9.30554016181896e-06,
      "loss": 0.0002,
      "step": 4386
    },
    {
      "epoch": 0.06946181737574615,
      "grad_norm": 0.012804587371647358,
      "learning_rate": 9.30538182624254e-06,
      "loss": 0.0006,
      "step": 4387
    },
    {
      "epoch": 0.06947765093338823,
      "grad_norm": 0.00046495551941916347,
      "learning_rate": 9.305223490666118e-06,
      "loss": 0.0,
      "step": 4388
    },
    {
      "epoch": 0.0694934844910303,
      "grad_norm": 0.2995244264602661,
      "learning_rate": 9.305065155089697e-06,
      "loss": 0.095,
      "step": 4389
    },
    {
      "epoch": 0.06950931804867236,
      "grad_norm": 0.27910658717155457,
      "learning_rate": 9.304906819513278e-06,
      "loss": 0.0814,
      "step": 4390
    },
    {
      "epoch": 0.06952515160631442,
      "grad_norm": 0.4194961488246918,
      "learning_rate": 9.304748483936856e-06,
      "loss": 0.3193,
      "step": 4391
    },
    {
      "epoch": 0.06954098516395649,
      "grad_norm": 0.2898971140384674,
      "learning_rate": 9.304590148360436e-06,
      "loss": 0.0914,
      "step": 4392
    },
    {
      "epoch": 0.06955681872159855,
      "grad_norm": 0.013365182094275951,
      "learning_rate": 9.304431812784015e-06,
      "loss": 0.0013,
      "step": 4393
    },
    {
      "epoch": 0.06957265227924063,
      "grad_norm": 0.20832529664039612,
      "learning_rate": 9.304273477207594e-06,
      "loss": 0.162,
      "step": 4394
    },
    {
      "epoch": 0.0695884858368827,
      "grad_norm": 0.21357180178165436,
      "learning_rate": 9.304115141631174e-06,
      "loss": 0.0834,
      "step": 4395
    },
    {
      "epoch": 0.06960431939452476,
      "grad_norm": 0.04249883070588112,
      "learning_rate": 9.303956806054754e-06,
      "loss": 0.0007,
      "step": 4396
    },
    {
      "epoch": 0.06962015295216682,
      "grad_norm": 0.18742001056671143,
      "learning_rate": 9.303798470478332e-06,
      "loss": 0.0593,
      "step": 4397
    },
    {
      "epoch": 0.06963598650980889,
      "grad_norm": 0.35433194041252136,
      "learning_rate": 9.303640134901912e-06,
      "loss": 0.0823,
      "step": 4398
    },
    {
      "epoch": 0.06965182006745095,
      "grad_norm": 0.011350274085998535,
      "learning_rate": 9.303481799325492e-06,
      "loss": 0.0006,
      "step": 4399
    },
    {
      "epoch": 0.06966765362509303,
      "grad_norm": 0.33288633823394775,
      "learning_rate": 9.30332346374907e-06,
      "loss": 0.4602,
      "step": 4400
    },
    {
      "epoch": 0.0696834871827351,
      "grad_norm": 0.5227235555648804,
      "learning_rate": 9.30316512817265e-06,
      "loss": 0.4022,
      "step": 4401
    },
    {
      "epoch": 0.06969932074037716,
      "grad_norm": 0.3069831132888794,
      "learning_rate": 9.30300679259623e-06,
      "loss": 0.2627,
      "step": 4402
    },
    {
      "epoch": 0.06971515429801922,
      "grad_norm": 0.11839550733566284,
      "learning_rate": 9.302848457019808e-06,
      "loss": 0.0311,
      "step": 4403
    },
    {
      "epoch": 0.06973098785566129,
      "grad_norm": 0.0004723839520011097,
      "learning_rate": 9.302690121443387e-06,
      "loss": 0.0,
      "step": 4404
    },
    {
      "epoch": 0.06974682141330335,
      "grad_norm": 0.26702621579170227,
      "learning_rate": 9.302531785866968e-06,
      "loss": 0.2122,
      "step": 4405
    },
    {
      "epoch": 0.06976265497094543,
      "grad_norm": 0.15085576474666595,
      "learning_rate": 9.302373450290547e-06,
      "loss": 0.054,
      "step": 4406
    },
    {
      "epoch": 0.06977848852858749,
      "grad_norm": 0.20919185876846313,
      "learning_rate": 9.302215114714126e-06,
      "loss": 0.006,
      "step": 4407
    },
    {
      "epoch": 0.06979432208622956,
      "grad_norm": 0.0004961001686751842,
      "learning_rate": 9.302056779137705e-06,
      "loss": 0.0,
      "step": 4408
    },
    {
      "epoch": 0.06981015564387162,
      "grad_norm": 0.20107433199882507,
      "learning_rate": 9.301898443561284e-06,
      "loss": 0.0891,
      "step": 4409
    },
    {
      "epoch": 0.06982598920151369,
      "grad_norm": 0.6844995617866516,
      "learning_rate": 9.301740107984863e-06,
      "loss": 0.0269,
      "step": 4410
    },
    {
      "epoch": 0.06984182275915575,
      "grad_norm": 0.13759301602840424,
      "learning_rate": 9.301581772408444e-06,
      "loss": 0.0936,
      "step": 4411
    },
    {
      "epoch": 0.06985765631679783,
      "grad_norm": 0.25996366143226624,
      "learning_rate": 9.301423436832023e-06,
      "loss": 0.3821,
      "step": 4412
    },
    {
      "epoch": 0.06987348987443989,
      "grad_norm": 0.6083376407623291,
      "learning_rate": 9.301265101255602e-06,
      "loss": 0.0491,
      "step": 4413
    },
    {
      "epoch": 0.06988932343208196,
      "grad_norm": 0.009021615609526634,
      "learning_rate": 9.301106765679181e-06,
      "loss": 0.0006,
      "step": 4414
    },
    {
      "epoch": 0.06990515698972402,
      "grad_norm": 0.1798398643732071,
      "learning_rate": 9.30094843010276e-06,
      "loss": 0.0954,
      "step": 4415
    },
    {
      "epoch": 0.06992099054736609,
      "grad_norm": 0.34314945340156555,
      "learning_rate": 9.30079009452634e-06,
      "loss": 0.2127,
      "step": 4416
    },
    {
      "epoch": 0.06993682410500815,
      "grad_norm": 0.0013563017128035426,
      "learning_rate": 9.30063175894992e-06,
      "loss": 0.0001,
      "step": 4417
    },
    {
      "epoch": 0.06995265766265023,
      "grad_norm": 0.007316007278859615,
      "learning_rate": 9.3004734233735e-06,
      "loss": 0.0003,
      "step": 4418
    },
    {
      "epoch": 0.06996849122029229,
      "grad_norm": 0.1398492157459259,
      "learning_rate": 9.300315087797078e-06,
      "loss": 0.0583,
      "step": 4419
    },
    {
      "epoch": 0.06998432477793436,
      "grad_norm": 0.3988648056983948,
      "learning_rate": 9.300156752220657e-06,
      "loss": 0.013,
      "step": 4420
    },
    {
      "epoch": 0.07000015833557642,
      "grad_norm": 0.03519033268094063,
      "learning_rate": 9.299998416644236e-06,
      "loss": 0.0018,
      "step": 4421
    },
    {
      "epoch": 0.07001599189321848,
      "grad_norm": 0.1513431966304779,
      "learning_rate": 9.299840081067815e-06,
      "loss": 0.0824,
      "step": 4422
    },
    {
      "epoch": 0.07003182545086055,
      "grad_norm": 0.43514546751976013,
      "learning_rate": 9.299681745491396e-06,
      "loss": 0.1194,
      "step": 4423
    },
    {
      "epoch": 0.07004765900850263,
      "grad_norm": 0.20025348663330078,
      "learning_rate": 9.299523409914975e-06,
      "loss": 0.1126,
      "step": 4424
    },
    {
      "epoch": 0.07006349256614469,
      "grad_norm": 0.16563118994235992,
      "learning_rate": 9.299365074338554e-06,
      "loss": 0.0723,
      "step": 4425
    },
    {
      "epoch": 0.07007932612378676,
      "grad_norm": 0.0032842424698174,
      "learning_rate": 9.299206738762133e-06,
      "loss": 0.0002,
      "step": 4426
    },
    {
      "epoch": 0.07009515968142882,
      "grad_norm": 0.00011902240657946095,
      "learning_rate": 9.299048403185713e-06,
      "loss": 0.0,
      "step": 4427
    },
    {
      "epoch": 0.07011099323907088,
      "grad_norm": 0.13452307879924774,
      "learning_rate": 9.298890067609292e-06,
      "loss": 0.0162,
      "step": 4428
    },
    {
      "epoch": 0.07012682679671295,
      "grad_norm": 0.6092796921730042,
      "learning_rate": 9.29873173203287e-06,
      "loss": 0.4684,
      "step": 4429
    },
    {
      "epoch": 0.07014266035435501,
      "grad_norm": 6.871859659440815e-05,
      "learning_rate": 9.29857339645645e-06,
      "loss": 0.0,
      "step": 4430
    },
    {
      "epoch": 0.07015849391199709,
      "grad_norm": 0.2087942659854889,
      "learning_rate": 9.298415060880029e-06,
      "loss": 0.0796,
      "step": 4431
    },
    {
      "epoch": 0.07017432746963916,
      "grad_norm": 0.34871402382850647,
      "learning_rate": 9.29825672530361e-06,
      "loss": 0.4638,
      "step": 4432
    },
    {
      "epoch": 0.07019016102728122,
      "grad_norm": 0.006683968473225832,
      "learning_rate": 9.298098389727189e-06,
      "loss": 0.0002,
      "step": 4433
    },
    {
      "epoch": 0.07020599458492328,
      "grad_norm": 0.6952570080757141,
      "learning_rate": 9.297940054150768e-06,
      "loss": 0.0611,
      "step": 4434
    },
    {
      "epoch": 0.07022182814256535,
      "grad_norm": 0.039236925542354584,
      "learning_rate": 9.297781718574347e-06,
      "loss": 0.0021,
      "step": 4435
    },
    {
      "epoch": 0.07023766170020741,
      "grad_norm": 0.006787124555557966,
      "learning_rate": 9.297623382997926e-06,
      "loss": 0.0003,
      "step": 4436
    },
    {
      "epoch": 0.07025349525784949,
      "grad_norm": 0.1665227711200714,
      "learning_rate": 9.297465047421505e-06,
      "loss": 0.0047,
      "step": 4437
    },
    {
      "epoch": 0.07026932881549156,
      "grad_norm": 0.1653217226266861,
      "learning_rate": 9.297306711845086e-06,
      "loss": 0.0878,
      "step": 4438
    },
    {
      "epoch": 0.07028516237313362,
      "grad_norm": 0.18419259786605835,
      "learning_rate": 9.297148376268665e-06,
      "loss": 0.0807,
      "step": 4439
    },
    {
      "epoch": 0.07030099593077568,
      "grad_norm": 0.31200456619262695,
      "learning_rate": 9.296990040692244e-06,
      "loss": 0.1547,
      "step": 4440
    },
    {
      "epoch": 0.07031682948841775,
      "grad_norm": 0.01308570709079504,
      "learning_rate": 9.296831705115823e-06,
      "loss": 0.0008,
      "step": 4441
    },
    {
      "epoch": 0.07033266304605981,
      "grad_norm": 0.5750662684440613,
      "learning_rate": 9.296673369539402e-06,
      "loss": 0.2707,
      "step": 4442
    },
    {
      "epoch": 0.07034849660370189,
      "grad_norm": 0.013214172795414925,
      "learning_rate": 9.296515033962981e-06,
      "loss": 0.0007,
      "step": 4443
    },
    {
      "epoch": 0.07036433016134395,
      "grad_norm": 0.8027545213699341,
      "learning_rate": 9.296356698386562e-06,
      "loss": 0.1922,
      "step": 4444
    },
    {
      "epoch": 0.07038016371898602,
      "grad_norm": 0.4719853699207306,
      "learning_rate": 9.296198362810141e-06,
      "loss": 0.2548,
      "step": 4445
    },
    {
      "epoch": 0.07039599727662808,
      "grad_norm": 0.23893465101718903,
      "learning_rate": 9.29604002723372e-06,
      "loss": 0.1884,
      "step": 4446
    },
    {
      "epoch": 0.07041183083427015,
      "grad_norm": 0.20920692384243011,
      "learning_rate": 9.2958816916573e-06,
      "loss": 0.0847,
      "step": 4447
    },
    {
      "epoch": 0.07042766439191221,
      "grad_norm": 0.0005500360275618732,
      "learning_rate": 9.295723356080878e-06,
      "loss": 0.0,
      "step": 4448
    },
    {
      "epoch": 0.07044349794955429,
      "grad_norm": 0.4511182904243469,
      "learning_rate": 9.295565020504457e-06,
      "loss": 0.3208,
      "step": 4449
    },
    {
      "epoch": 0.07045933150719635,
      "grad_norm": 0.4504566788673401,
      "learning_rate": 9.295406684928038e-06,
      "loss": 0.1579,
      "step": 4450
    },
    {
      "epoch": 0.07047516506483842,
      "grad_norm": 0.23035284876823425,
      "learning_rate": 9.295248349351617e-06,
      "loss": 0.1253,
      "step": 4451
    },
    {
      "epoch": 0.07049099862248048,
      "grad_norm": 0.37307438254356384,
      "learning_rate": 9.295090013775195e-06,
      "loss": 0.1281,
      "step": 4452
    },
    {
      "epoch": 0.07050683218012255,
      "grad_norm": 0.3994351029396057,
      "learning_rate": 9.294931678198775e-06,
      "loss": 0.0682,
      "step": 4453
    },
    {
      "epoch": 0.07052266573776461,
      "grad_norm": 0.2642732262611389,
      "learning_rate": 9.294773342622354e-06,
      "loss": 0.1438,
      "step": 4454
    },
    {
      "epoch": 0.07053849929540669,
      "grad_norm": 0.47264158725738525,
      "learning_rate": 9.294615007045934e-06,
      "loss": 0.0266,
      "step": 4455
    },
    {
      "epoch": 0.07055433285304875,
      "grad_norm": 0.4139178395271301,
      "learning_rate": 9.294456671469513e-06,
      "loss": 0.2734,
      "step": 4456
    },
    {
      "epoch": 0.07057016641069082,
      "grad_norm": 0.0021281512454152107,
      "learning_rate": 9.294298335893093e-06,
      "loss": 0.0001,
      "step": 4457
    },
    {
      "epoch": 0.07058599996833288,
      "grad_norm": 0.014744045212864876,
      "learning_rate": 9.29414000031667e-06,
      "loss": 0.0006,
      "step": 4458
    },
    {
      "epoch": 0.07060183352597495,
      "grad_norm": 0.11338665336370468,
      "learning_rate": 9.293981664740252e-06,
      "loss": 0.0726,
      "step": 4459
    },
    {
      "epoch": 0.07061766708361701,
      "grad_norm": 0.0008438777294941247,
      "learning_rate": 9.29382332916383e-06,
      "loss": 0.0,
      "step": 4460
    },
    {
      "epoch": 0.07063350064125909,
      "grad_norm": 0.20218400657176971,
      "learning_rate": 9.29366499358741e-06,
      "loss": 0.1413,
      "step": 4461
    },
    {
      "epoch": 0.07064933419890115,
      "grad_norm": 0.3872023820877075,
      "learning_rate": 9.293506658010989e-06,
      "loss": 0.2635,
      "step": 4462
    },
    {
      "epoch": 0.07066516775654322,
      "grad_norm": 0.23414526879787445,
      "learning_rate": 9.29334832243457e-06,
      "loss": 0.0361,
      "step": 4463
    },
    {
      "epoch": 0.07068100131418528,
      "grad_norm": 0.1604437381029129,
      "learning_rate": 9.293189986858147e-06,
      "loss": 0.064,
      "step": 4464
    },
    {
      "epoch": 0.07069683487182735,
      "grad_norm": 0.23413634300231934,
      "learning_rate": 9.293031651281728e-06,
      "loss": 0.0628,
      "step": 4465
    },
    {
      "epoch": 0.07071266842946941,
      "grad_norm": 0.07263675332069397,
      "learning_rate": 9.292873315705307e-06,
      "loss": 0.0056,
      "step": 4466
    },
    {
      "epoch": 0.07072850198711149,
      "grad_norm": 0.18645265698432922,
      "learning_rate": 9.292714980128886e-06,
      "loss": 0.0857,
      "step": 4467
    },
    {
      "epoch": 0.07074433554475355,
      "grad_norm": 0.40640154480934143,
      "learning_rate": 9.292556644552465e-06,
      "loss": 0.2457,
      "step": 4468
    },
    {
      "epoch": 0.07076016910239562,
      "grad_norm": 0.320052832365036,
      "learning_rate": 9.292398308976046e-06,
      "loss": 0.0479,
      "step": 4469
    },
    {
      "epoch": 0.07077600266003768,
      "grad_norm": 0.2554054260253906,
      "learning_rate": 9.292239973399623e-06,
      "loss": 0.0775,
      "step": 4470
    },
    {
      "epoch": 0.07079183621767975,
      "grad_norm": 0.18612949550151825,
      "learning_rate": 9.292081637823204e-06,
      "loss": 0.0735,
      "step": 4471
    },
    {
      "epoch": 0.07080766977532181,
      "grad_norm": 0.2971772253513336,
      "learning_rate": 9.291923302246783e-06,
      "loss": 0.3158,
      "step": 4472
    },
    {
      "epoch": 0.07082350333296389,
      "grad_norm": 0.10504749417304993,
      "learning_rate": 9.291764966670362e-06,
      "loss": 0.0375,
      "step": 4473
    },
    {
      "epoch": 0.07083933689060595,
      "grad_norm": 0.3034217655658722,
      "learning_rate": 9.291606631093941e-06,
      "loss": 0.0774,
      "step": 4474
    },
    {
      "epoch": 0.07085517044824802,
      "grad_norm": 0.010226557962596416,
      "learning_rate": 9.291448295517522e-06,
      "loss": 0.0004,
      "step": 4475
    },
    {
      "epoch": 0.07087100400589008,
      "grad_norm": 0.2733875513076782,
      "learning_rate": 9.2912899599411e-06,
      "loss": 0.0061,
      "step": 4476
    },
    {
      "epoch": 0.07088683756353215,
      "grad_norm": 0.2154654860496521,
      "learning_rate": 9.291131624364678e-06,
      "loss": 0.1667,
      "step": 4477
    },
    {
      "epoch": 0.07090267112117421,
      "grad_norm": 0.2984786927700043,
      "learning_rate": 9.29097328878826e-06,
      "loss": 0.3308,
      "step": 4478
    },
    {
      "epoch": 0.07091850467881629,
      "grad_norm": 0.20757880806922913,
      "learning_rate": 9.290814953211838e-06,
      "loss": 0.1001,
      "step": 4479
    },
    {
      "epoch": 0.07093433823645835,
      "grad_norm": 0.2671177089214325,
      "learning_rate": 9.290656617635417e-06,
      "loss": 0.1811,
      "step": 4480
    },
    {
      "epoch": 0.07095017179410042,
      "grad_norm": 0.568147599697113,
      "learning_rate": 9.290498282058996e-06,
      "loss": 0.019,
      "step": 4481
    },
    {
      "epoch": 0.07096600535174248,
      "grad_norm": 0.0013162180548533797,
      "learning_rate": 9.290339946482575e-06,
      "loss": 0.0,
      "step": 4482
    },
    {
      "epoch": 0.07098183890938455,
      "grad_norm": 0.23904770612716675,
      "learning_rate": 9.290181610906155e-06,
      "loss": 0.2063,
      "step": 4483
    },
    {
      "epoch": 0.07099767246702661,
      "grad_norm": 0.3463263511657715,
      "learning_rate": 9.290023275329735e-06,
      "loss": 0.2021,
      "step": 4484
    },
    {
      "epoch": 0.07101350602466869,
      "grad_norm": 0.2873398959636688,
      "learning_rate": 9.289864939753314e-06,
      "loss": 0.1717,
      "step": 4485
    },
    {
      "epoch": 0.07102933958231075,
      "grad_norm": 0.5423697233200073,
      "learning_rate": 9.289706604176894e-06,
      "loss": 0.4062,
      "step": 4486
    },
    {
      "epoch": 0.07104517313995282,
      "grad_norm": 0.0011998639674857259,
      "learning_rate": 9.289548268600473e-06,
      "loss": 0.0,
      "step": 4487
    },
    {
      "epoch": 0.07106100669759488,
      "grad_norm": 0.5709480047225952,
      "learning_rate": 9.289389933024052e-06,
      "loss": 1.0159,
      "step": 4488
    },
    {
      "epoch": 0.07107684025523694,
      "grad_norm": 0.9925618767738342,
      "learning_rate": 9.28923159744763e-06,
      "loss": 0.0538,
      "step": 4489
    },
    {
      "epoch": 0.07109267381287901,
      "grad_norm": 0.4273871183395386,
      "learning_rate": 9.289073261871212e-06,
      "loss": 0.2159,
      "step": 4490
    },
    {
      "epoch": 0.07110850737052109,
      "grad_norm": 0.12073656916618347,
      "learning_rate": 9.288914926294789e-06,
      "loss": 0.0158,
      "step": 4491
    },
    {
      "epoch": 0.07112434092816315,
      "grad_norm": 0.2559122145175934,
      "learning_rate": 9.28875659071837e-06,
      "loss": 0.1046,
      "step": 4492
    },
    {
      "epoch": 0.07114017448580522,
      "grad_norm": 0.03152807429432869,
      "learning_rate": 9.288598255141949e-06,
      "loss": 0.0018,
      "step": 4493
    },
    {
      "epoch": 0.07115600804344728,
      "grad_norm": 0.35506901144981384,
      "learning_rate": 9.288439919565528e-06,
      "loss": 0.0266,
      "step": 4494
    },
    {
      "epoch": 0.07117184160108934,
      "grad_norm": 0.055573057383298874,
      "learning_rate": 9.288281583989107e-06,
      "loss": 0.0212,
      "step": 4495
    },
    {
      "epoch": 0.07118767515873141,
      "grad_norm": 0.1462550014257431,
      "learning_rate": 9.288123248412688e-06,
      "loss": 0.0043,
      "step": 4496
    },
    {
      "epoch": 0.07120350871637349,
      "grad_norm": 0.25524482131004333,
      "learning_rate": 9.287964912836265e-06,
      "loss": 0.1076,
      "step": 4497
    },
    {
      "epoch": 0.07121934227401555,
      "grad_norm": 0.36768868565559387,
      "learning_rate": 9.287806577259846e-06,
      "loss": 0.4716,
      "step": 4498
    },
    {
      "epoch": 0.07123517583165762,
      "grad_norm": 0.38674023747444153,
      "learning_rate": 9.287648241683425e-06,
      "loss": 0.5321,
      "step": 4499
    },
    {
      "epoch": 0.07125100938929968,
      "grad_norm": 0.3665146231651306,
      "learning_rate": 9.287489906107004e-06,
      "loss": 0.3536,
      "step": 4500
    },
    {
      "epoch": 0.07126684294694174,
      "grad_norm": 0.010211295448243618,
      "learning_rate": 9.287331570530583e-06,
      "loss": 0.0004,
      "step": 4501
    },
    {
      "epoch": 0.07128267650458381,
      "grad_norm": 0.4703945517539978,
      "learning_rate": 9.287173234954162e-06,
      "loss": 0.1189,
      "step": 4502
    },
    {
      "epoch": 0.07129851006222589,
      "grad_norm": 0.36653172969818115,
      "learning_rate": 9.287014899377741e-06,
      "loss": 0.4149,
      "step": 4503
    },
    {
      "epoch": 0.07131434361986795,
      "grad_norm": 0.1709926873445511,
      "learning_rate": 9.28685656380132e-06,
      "loss": 0.0569,
      "step": 4504
    },
    {
      "epoch": 0.07133017717751002,
      "grad_norm": 0.3451896905899048,
      "learning_rate": 9.286698228224901e-06,
      "loss": 0.1443,
      "step": 4505
    },
    {
      "epoch": 0.07134601073515208,
      "grad_norm": 0.006582451052963734,
      "learning_rate": 9.28653989264848e-06,
      "loss": 0.0005,
      "step": 4506
    },
    {
      "epoch": 0.07136184429279414,
      "grad_norm": 0.17453984916210175,
      "learning_rate": 9.28638155707206e-06,
      "loss": 0.0667,
      "step": 4507
    },
    {
      "epoch": 0.07137767785043621,
      "grad_norm": 0.03633734956383705,
      "learning_rate": 9.286223221495638e-06,
      "loss": 0.0017,
      "step": 4508
    },
    {
      "epoch": 0.07139351140807829,
      "grad_norm": 0.4945312440395355,
      "learning_rate": 9.286064885919217e-06,
      "loss": 0.2619,
      "step": 4509
    },
    {
      "epoch": 0.07140934496572035,
      "grad_norm": 0.35275208950042725,
      "learning_rate": 9.285906550342797e-06,
      "loss": 0.3555,
      "step": 4510
    },
    {
      "epoch": 0.07142517852336241,
      "grad_norm": 0.3388577699661255,
      "learning_rate": 9.285748214766377e-06,
      "loss": 0.1341,
      "step": 4511
    },
    {
      "epoch": 0.07144101208100448,
      "grad_norm": 0.5881205201148987,
      "learning_rate": 9.285589879189956e-06,
      "loss": 0.1614,
      "step": 4512
    },
    {
      "epoch": 0.07145684563864654,
      "grad_norm": 0.2322888821363449,
      "learning_rate": 9.285431543613535e-06,
      "loss": 0.2446,
      "step": 4513
    },
    {
      "epoch": 0.07147267919628861,
      "grad_norm": 0.004292285535484552,
      "learning_rate": 9.285273208037115e-06,
      "loss": 0.0002,
      "step": 4514
    },
    {
      "epoch": 0.07148851275393069,
      "grad_norm": 1.5488834381103516,
      "learning_rate": 9.285114872460694e-06,
      "loss": 0.199,
      "step": 4515
    },
    {
      "epoch": 0.07150434631157275,
      "grad_norm": 0.1877276450395584,
      "learning_rate": 9.284956536884273e-06,
      "loss": 0.0516,
      "step": 4516
    },
    {
      "epoch": 0.07152017986921481,
      "grad_norm": 0.47252318263053894,
      "learning_rate": 9.284798201307853e-06,
      "loss": 0.1539,
      "step": 4517
    },
    {
      "epoch": 0.07153601342685688,
      "grad_norm": 0.21755318343639374,
      "learning_rate": 9.284639865731433e-06,
      "loss": 0.1177,
      "step": 4518
    },
    {
      "epoch": 0.07155184698449894,
      "grad_norm": 0.001601868076249957,
      "learning_rate": 9.284481530155012e-06,
      "loss": 0.0,
      "step": 4519
    },
    {
      "epoch": 0.07156768054214101,
      "grad_norm": 0.4097434878349304,
      "learning_rate": 9.28432319457859e-06,
      "loss": 0.4456,
      "step": 4520
    },
    {
      "epoch": 0.07158351409978309,
      "grad_norm": 0.09900175780057907,
      "learning_rate": 9.28416485900217e-06,
      "loss": 0.0091,
      "step": 4521
    },
    {
      "epoch": 0.07159934765742515,
      "grad_norm": 0.001948372577317059,
      "learning_rate": 9.284006523425749e-06,
      "loss": 0.0,
      "step": 4522
    },
    {
      "epoch": 0.07161518121506721,
      "grad_norm": 0.030529577285051346,
      "learning_rate": 9.28384818784933e-06,
      "loss": 0.0017,
      "step": 4523
    },
    {
      "epoch": 0.07163101477270928,
      "grad_norm": 0.3329116404056549,
      "learning_rate": 9.283689852272909e-06,
      "loss": 0.0338,
      "step": 4524
    },
    {
      "epoch": 0.07164684833035134,
      "grad_norm": 0.14845257997512817,
      "learning_rate": 9.283531516696486e-06,
      "loss": 0.1668,
      "step": 4525
    },
    {
      "epoch": 0.0716626818879934,
      "grad_norm": 0.18337778747081757,
      "learning_rate": 9.283373181120067e-06,
      "loss": 0.0712,
      "step": 4526
    },
    {
      "epoch": 0.07167851544563549,
      "grad_norm": 0.43788713216781616,
      "learning_rate": 9.283214845543646e-06,
      "loss": 0.1017,
      "step": 4527
    },
    {
      "epoch": 0.07169434900327755,
      "grad_norm": 0.27590763568878174,
      "learning_rate": 9.283056509967225e-06,
      "loss": 0.2214,
      "step": 4528
    },
    {
      "epoch": 0.07171018256091961,
      "grad_norm": 0.7823191285133362,
      "learning_rate": 9.282898174390804e-06,
      "loss": 0.0632,
      "step": 4529
    },
    {
      "epoch": 0.07172601611856168,
      "grad_norm": 0.21816474199295044,
      "learning_rate": 9.282739838814385e-06,
      "loss": 0.0103,
      "step": 4530
    },
    {
      "epoch": 0.07174184967620374,
      "grad_norm": 0.03284381330013275,
      "learning_rate": 9.282581503237962e-06,
      "loss": 0.0011,
      "step": 4531
    },
    {
      "epoch": 0.0717576832338458,
      "grad_norm": 0.19320057332515717,
      "learning_rate": 9.282423167661543e-06,
      "loss": 0.1052,
      "step": 4532
    },
    {
      "epoch": 0.07177351679148788,
      "grad_norm": 0.0139332115650177,
      "learning_rate": 9.282264832085122e-06,
      "loss": 0.0006,
      "step": 4533
    },
    {
      "epoch": 0.07178935034912995,
      "grad_norm": 0.4471241235733032,
      "learning_rate": 9.282106496508701e-06,
      "loss": 0.1291,
      "step": 4534
    },
    {
      "epoch": 0.07180518390677201,
      "grad_norm": 0.007331589236855507,
      "learning_rate": 9.28194816093228e-06,
      "loss": 0.0002,
      "step": 4535
    },
    {
      "epoch": 0.07182101746441408,
      "grad_norm": 0.0001199539692606777,
      "learning_rate": 9.281789825355861e-06,
      "loss": 0.0,
      "step": 4536
    },
    {
      "epoch": 0.07183685102205614,
      "grad_norm": 0.10689514130353928,
      "learning_rate": 9.281631489779438e-06,
      "loss": 0.0027,
      "step": 4537
    },
    {
      "epoch": 0.0718526845796982,
      "grad_norm": 0.2817056477069855,
      "learning_rate": 9.28147315420302e-06,
      "loss": 0.1627,
      "step": 4538
    },
    {
      "epoch": 0.07186851813734028,
      "grad_norm": 0.3188032805919647,
      "learning_rate": 9.281314818626598e-06,
      "loss": 0.0634,
      "step": 4539
    },
    {
      "epoch": 0.07188435169498235,
      "grad_norm": 0.8518829941749573,
      "learning_rate": 9.281156483050177e-06,
      "loss": 0.3368,
      "step": 4540
    },
    {
      "epoch": 0.07190018525262441,
      "grad_norm": 0.35380396246910095,
      "learning_rate": 9.280998147473756e-06,
      "loss": 0.2391,
      "step": 4541
    },
    {
      "epoch": 0.07191601881026648,
      "grad_norm": 0.0013802823377773166,
      "learning_rate": 9.280839811897337e-06,
      "loss": 0.0,
      "step": 4542
    },
    {
      "epoch": 0.07193185236790854,
      "grad_norm": 0.27401259541511536,
      "learning_rate": 9.280681476320915e-06,
      "loss": 0.1443,
      "step": 4543
    },
    {
      "epoch": 0.0719476859255506,
      "grad_norm": 0.0029136950615793467,
      "learning_rate": 9.280523140744495e-06,
      "loss": 0.0001,
      "step": 4544
    },
    {
      "epoch": 0.07196351948319268,
      "grad_norm": 0.1676429659128189,
      "learning_rate": 9.280364805168074e-06,
      "loss": 0.1328,
      "step": 4545
    },
    {
      "epoch": 0.07197935304083475,
      "grad_norm": 0.002847054973244667,
      "learning_rate": 9.280206469591654e-06,
      "loss": 0.0001,
      "step": 4546
    },
    {
      "epoch": 0.07199518659847681,
      "grad_norm": 0.27964597940444946,
      "learning_rate": 9.280048134015233e-06,
      "loss": 0.6043,
      "step": 4547
    },
    {
      "epoch": 0.07201102015611888,
      "grad_norm": 1.4756433963775635,
      "learning_rate": 9.279889798438812e-06,
      "loss": 0.1642,
      "step": 4548
    },
    {
      "epoch": 0.07202685371376094,
      "grad_norm": 0.28378432989120483,
      "learning_rate": 9.27973146286239e-06,
      "loss": 0.1507,
      "step": 4549
    },
    {
      "epoch": 0.072042687271403,
      "grad_norm": 0.8476998209953308,
      "learning_rate": 9.27957312728597e-06,
      "loss": 0.6832,
      "step": 4550
    },
    {
      "epoch": 0.07205852082904508,
      "grad_norm": 0.27551335096359253,
      "learning_rate": 9.27941479170955e-06,
      "loss": 0.0337,
      "step": 4551
    },
    {
      "epoch": 0.07207435438668715,
      "grad_norm": 0.01628473959863186,
      "learning_rate": 9.27925645613313e-06,
      "loss": 0.0007,
      "step": 4552
    },
    {
      "epoch": 0.07209018794432921,
      "grad_norm": 1.3632580041885376,
      "learning_rate": 9.279098120556709e-06,
      "loss": 0.1918,
      "step": 4553
    },
    {
      "epoch": 0.07210602150197128,
      "grad_norm": 0.3807145953178406,
      "learning_rate": 9.278939784980288e-06,
      "loss": 0.0247,
      "step": 4554
    },
    {
      "epoch": 0.07212185505961334,
      "grad_norm": 0.29604077339172363,
      "learning_rate": 9.278781449403867e-06,
      "loss": 0.1749,
      "step": 4555
    },
    {
      "epoch": 0.0721376886172554,
      "grad_norm": 0.31277117133140564,
      "learning_rate": 9.278623113827446e-06,
      "loss": 0.1486,
      "step": 4556
    },
    {
      "epoch": 0.07215352217489748,
      "grad_norm": 0.00025747623294591904,
      "learning_rate": 9.278464778251027e-06,
      "loss": 0.0,
      "step": 4557
    },
    {
      "epoch": 0.07216935573253955,
      "grad_norm": 0.34832197427749634,
      "learning_rate": 9.278306442674604e-06,
      "loss": 0.1963,
      "step": 4558
    },
    {
      "epoch": 0.07218518929018161,
      "grad_norm": 0.20932288467884064,
      "learning_rate": 9.278148107098185e-06,
      "loss": 0.0354,
      "step": 4559
    },
    {
      "epoch": 0.07220102284782368,
      "grad_norm": 0.23668527603149414,
      "learning_rate": 9.277989771521764e-06,
      "loss": 0.0791,
      "step": 4560
    },
    {
      "epoch": 0.07221685640546574,
      "grad_norm": 0.027713891118764877,
      "learning_rate": 9.277831435945343e-06,
      "loss": 0.0006,
      "step": 4561
    },
    {
      "epoch": 0.0722326899631078,
      "grad_norm": 0.36332398653030396,
      "learning_rate": 9.277673100368922e-06,
      "loss": 0.3229,
      "step": 4562
    },
    {
      "epoch": 0.07224852352074988,
      "grad_norm": 0.17503589391708374,
      "learning_rate": 9.277514764792503e-06,
      "loss": 0.0546,
      "step": 4563
    },
    {
      "epoch": 0.07226435707839195,
      "grad_norm": 0.014563655480742455,
      "learning_rate": 9.27735642921608e-06,
      "loss": 0.0007,
      "step": 4564
    },
    {
      "epoch": 0.07228019063603401,
      "grad_norm": 0.0001285560429096222,
      "learning_rate": 9.277198093639661e-06,
      "loss": 0.0,
      "step": 4565
    },
    {
      "epoch": 0.07229602419367608,
      "grad_norm": 0.00013793434482067823,
      "learning_rate": 9.27703975806324e-06,
      "loss": 0.0,
      "step": 4566
    },
    {
      "epoch": 0.07231185775131814,
      "grad_norm": 0.013983705081045628,
      "learning_rate": 9.27688142248682e-06,
      "loss": 0.0006,
      "step": 4567
    },
    {
      "epoch": 0.0723276913089602,
      "grad_norm": 0.1574244648218155,
      "learning_rate": 9.276723086910398e-06,
      "loss": 0.0517,
      "step": 4568
    },
    {
      "epoch": 0.07234352486660228,
      "grad_norm": 0.3291718363761902,
      "learning_rate": 9.276564751333979e-06,
      "loss": 0.0225,
      "step": 4569
    },
    {
      "epoch": 0.07235935842424435,
      "grad_norm": 0.037674278020858765,
      "learning_rate": 9.276406415757557e-06,
      "loss": 0.002,
      "step": 4570
    },
    {
      "epoch": 0.07237519198188641,
      "grad_norm": 0.011022859252989292,
      "learning_rate": 9.276248080181137e-06,
      "loss": 0.0005,
      "step": 4571
    },
    {
      "epoch": 0.07239102553952848,
      "grad_norm": 0.45164620876312256,
      "learning_rate": 9.276089744604716e-06,
      "loss": 0.0849,
      "step": 4572
    },
    {
      "epoch": 0.07240685909717054,
      "grad_norm": 0.1965133398771286,
      "learning_rate": 9.275931409028295e-06,
      "loss": 0.1394,
      "step": 4573
    },
    {
      "epoch": 0.0724226926548126,
      "grad_norm": 0.00021926022600382566,
      "learning_rate": 9.275773073451875e-06,
      "loss": 0.0,
      "step": 4574
    },
    {
      "epoch": 0.07243852621245468,
      "grad_norm": 0.2737444341182709,
      "learning_rate": 9.275614737875454e-06,
      "loss": 0.1093,
      "step": 4575
    },
    {
      "epoch": 0.07245435977009675,
      "grad_norm": 0.1356058120727539,
      "learning_rate": 9.275456402299033e-06,
      "loss": 0.041,
      "step": 4576
    },
    {
      "epoch": 0.07247019332773881,
      "grad_norm": 0.18811072409152985,
      "learning_rate": 9.275298066722612e-06,
      "loss": 0.0672,
      "step": 4577
    },
    {
      "epoch": 0.07248602688538087,
      "grad_norm": 0.29509520530700684,
      "learning_rate": 9.275139731146193e-06,
      "loss": 0.3764,
      "step": 4578
    },
    {
      "epoch": 0.07250186044302294,
      "grad_norm": 0.012533102184534073,
      "learning_rate": 9.274981395569772e-06,
      "loss": 0.0004,
      "step": 4579
    },
    {
      "epoch": 0.072517694000665,
      "grad_norm": 0.2211833894252777,
      "learning_rate": 9.27482305999335e-06,
      "loss": 0.1237,
      "step": 4580
    },
    {
      "epoch": 0.07253352755830708,
      "grad_norm": 0.44802576303482056,
      "learning_rate": 9.27466472441693e-06,
      "loss": 0.1143,
      "step": 4581
    },
    {
      "epoch": 0.07254936111594915,
      "grad_norm": 0.39427080750465393,
      "learning_rate": 9.274506388840509e-06,
      "loss": 0.4021,
      "step": 4582
    },
    {
      "epoch": 0.07256519467359121,
      "grad_norm": 2.0912387371063232,
      "learning_rate": 9.274348053264088e-06,
      "loss": 0.0182,
      "step": 4583
    },
    {
      "epoch": 0.07258102823123327,
      "grad_norm": 0.09005629271268845,
      "learning_rate": 9.274189717687669e-06,
      "loss": 0.0069,
      "step": 4584
    },
    {
      "epoch": 0.07259686178887534,
      "grad_norm": 0.00197312468662858,
      "learning_rate": 9.274031382111248e-06,
      "loss": 0.0001,
      "step": 4585
    },
    {
      "epoch": 0.0726126953465174,
      "grad_norm": 0.028858328238129616,
      "learning_rate": 9.273873046534827e-06,
      "loss": 0.0017,
      "step": 4586
    },
    {
      "epoch": 0.07262852890415948,
      "grad_norm": 0.2535867989063263,
      "learning_rate": 9.273714710958406e-06,
      "loss": 0.3303,
      "step": 4587
    },
    {
      "epoch": 0.07264436246180155,
      "grad_norm": 0.2690235376358032,
      "learning_rate": 9.273556375381985e-06,
      "loss": 0.3448,
      "step": 4588
    },
    {
      "epoch": 0.07266019601944361,
      "grad_norm": 0.008770515210926533,
      "learning_rate": 9.273398039805564e-06,
      "loss": 0.0004,
      "step": 4589
    },
    {
      "epoch": 0.07267602957708567,
      "grad_norm": 0.21859490871429443,
      "learning_rate": 9.273239704229145e-06,
      "loss": 0.1604,
      "step": 4590
    },
    {
      "epoch": 0.07269186313472774,
      "grad_norm": 0.2401042878627777,
      "learning_rate": 9.273081368652724e-06,
      "loss": 0.6324,
      "step": 4591
    },
    {
      "epoch": 0.0727076966923698,
      "grad_norm": 0.2719295918941498,
      "learning_rate": 9.272923033076303e-06,
      "loss": 0.2108,
      "step": 4592
    },
    {
      "epoch": 0.07272353025001188,
      "grad_norm": 0.010996364057064056,
      "learning_rate": 9.272764697499882e-06,
      "loss": 0.0005,
      "step": 4593
    },
    {
      "epoch": 0.07273936380765395,
      "grad_norm": 0.14796759188175201,
      "learning_rate": 9.272606361923461e-06,
      "loss": 0.0555,
      "step": 4594
    },
    {
      "epoch": 0.07275519736529601,
      "grad_norm": 0.24286945164203644,
      "learning_rate": 9.27244802634704e-06,
      "loss": 0.0789,
      "step": 4595
    },
    {
      "epoch": 0.07277103092293807,
      "grad_norm": 7.90459816926159e-05,
      "learning_rate": 9.27228969077062e-06,
      "loss": 0.0,
      "step": 4596
    },
    {
      "epoch": 0.07278686448058014,
      "grad_norm": 0.46586233377456665,
      "learning_rate": 9.2721313551942e-06,
      "loss": 0.8312,
      "step": 4597
    },
    {
      "epoch": 0.0728026980382222,
      "grad_norm": 0.015650587156414986,
      "learning_rate": 9.271973019617778e-06,
      "loss": 0.0009,
      "step": 4598
    },
    {
      "epoch": 0.07281853159586428,
      "grad_norm": 0.3890959918498993,
      "learning_rate": 9.271814684041358e-06,
      "loss": 0.4735,
      "step": 4599
    },
    {
      "epoch": 0.07283436515350634,
      "grad_norm": 0.2164936661720276,
      "learning_rate": 9.271656348464937e-06,
      "loss": 0.0117,
      "step": 4600
    },
    {
      "epoch": 0.07285019871114841,
      "grad_norm": 0.4375769793987274,
      "learning_rate": 9.271498012888516e-06,
      "loss": 0.2467,
      "step": 4601
    },
    {
      "epoch": 0.07286603226879047,
      "grad_norm": 0.0006726729916408658,
      "learning_rate": 9.271339677312096e-06,
      "loss": 0.0,
      "step": 4602
    },
    {
      "epoch": 0.07288186582643254,
      "grad_norm": 0.004283608868718147,
      "learning_rate": 9.271181341735676e-06,
      "loss": 0.0002,
      "step": 4603
    },
    {
      "epoch": 0.0728976993840746,
      "grad_norm": 1.3057684898376465,
      "learning_rate": 9.271023006159254e-06,
      "loss": 1.5143,
      "step": 4604
    },
    {
      "epoch": 0.07291353294171668,
      "grad_norm": 0.4946271777153015,
      "learning_rate": 9.270864670582834e-06,
      "loss": 0.0127,
      "step": 4605
    },
    {
      "epoch": 0.07292936649935874,
      "grad_norm": 0.33272626996040344,
      "learning_rate": 9.270706335006414e-06,
      "loss": 0.071,
      "step": 4606
    },
    {
      "epoch": 0.07294520005700081,
      "grad_norm": 1.888516902923584,
      "learning_rate": 9.270547999429993e-06,
      "loss": 0.2757,
      "step": 4607
    },
    {
      "epoch": 0.07296103361464287,
      "grad_norm": 0.444374144077301,
      "learning_rate": 9.270389663853572e-06,
      "loss": 0.1599,
      "step": 4608
    },
    {
      "epoch": 0.07297686717228494,
      "grad_norm": 0.35024309158325195,
      "learning_rate": 9.270231328277152e-06,
      "loss": 0.085,
      "step": 4609
    },
    {
      "epoch": 0.072992700729927,
      "grad_norm": 0.28409838676452637,
      "learning_rate": 9.27007299270073e-06,
      "loss": 0.1111,
      "step": 4610
    },
    {
      "epoch": 0.07300853428756908,
      "grad_norm": 0.036404456943273544,
      "learning_rate": 9.26991465712431e-06,
      "loss": 0.0018,
      "step": 4611
    },
    {
      "epoch": 0.07302436784521114,
      "grad_norm": 0.01171925850212574,
      "learning_rate": 9.26975632154789e-06,
      "loss": 0.0003,
      "step": 4612
    },
    {
      "epoch": 0.07304020140285321,
      "grad_norm": 0.23608563840389252,
      "learning_rate": 9.269597985971469e-06,
      "loss": 0.098,
      "step": 4613
    },
    {
      "epoch": 0.07305603496049527,
      "grad_norm": 0.2796548902988434,
      "learning_rate": 9.269439650395048e-06,
      "loss": 0.0129,
      "step": 4614
    },
    {
      "epoch": 0.07307186851813734,
      "grad_norm": 0.2211718112230301,
      "learning_rate": 9.269281314818627e-06,
      "loss": 0.045,
      "step": 4615
    },
    {
      "epoch": 0.0730877020757794,
      "grad_norm": 0.3063511550426483,
      "learning_rate": 9.269122979242206e-06,
      "loss": 0.0139,
      "step": 4616
    },
    {
      "epoch": 0.07310353563342148,
      "grad_norm": 0.2957567274570465,
      "learning_rate": 9.268964643665787e-06,
      "loss": 0.2343,
      "step": 4617
    },
    {
      "epoch": 0.07311936919106354,
      "grad_norm": 0.19587023556232452,
      "learning_rate": 9.268806308089366e-06,
      "loss": 0.1471,
      "step": 4618
    },
    {
      "epoch": 0.07313520274870561,
      "grad_norm": 0.010588796809315681,
      "learning_rate": 9.268647972512945e-06,
      "loss": 0.0005,
      "step": 4619
    },
    {
      "epoch": 0.07315103630634767,
      "grad_norm": 0.47800129652023315,
      "learning_rate": 9.268489636936524e-06,
      "loss": 0.093,
      "step": 4620
    },
    {
      "epoch": 0.07316686986398974,
      "grad_norm": 0.2084602415561676,
      "learning_rate": 9.268331301360103e-06,
      "loss": 0.0568,
      "step": 4621
    },
    {
      "epoch": 0.0731827034216318,
      "grad_norm": 0.4076617956161499,
      "learning_rate": 9.268172965783682e-06,
      "loss": 0.7058,
      "step": 4622
    },
    {
      "epoch": 0.07319853697927388,
      "grad_norm": 0.36743032932281494,
      "learning_rate": 9.268014630207261e-06,
      "loss": 0.2819,
      "step": 4623
    },
    {
      "epoch": 0.07321437053691594,
      "grad_norm": 0.3937070071697235,
      "learning_rate": 9.267856294630842e-06,
      "loss": 0.0777,
      "step": 4624
    },
    {
      "epoch": 0.07323020409455801,
      "grad_norm": 0.23917265236377716,
      "learning_rate": 9.26769795905442e-06,
      "loss": 0.1,
      "step": 4625
    },
    {
      "epoch": 0.07324603765220007,
      "grad_norm": 0.2703951895236969,
      "learning_rate": 9.267539623478e-06,
      "loss": 0.2225,
      "step": 4626
    },
    {
      "epoch": 0.07326187120984214,
      "grad_norm": 0.29628416895866394,
      "learning_rate": 9.26738128790158e-06,
      "loss": 0.3157,
      "step": 4627
    },
    {
      "epoch": 0.0732777047674842,
      "grad_norm": 0.2998657822608948,
      "learning_rate": 9.267222952325158e-06,
      "loss": 0.3789,
      "step": 4628
    },
    {
      "epoch": 0.07329353832512628,
      "grad_norm": 0.43095481395721436,
      "learning_rate": 9.267064616748737e-06,
      "loss": 0.2063,
      "step": 4629
    },
    {
      "epoch": 0.07330937188276834,
      "grad_norm": 0.029330283403396606,
      "learning_rate": 9.266906281172318e-06,
      "loss": 0.0014,
      "step": 4630
    },
    {
      "epoch": 0.07332520544041041,
      "grad_norm": 0.40459734201431274,
      "learning_rate": 9.266747945595896e-06,
      "loss": 0.2172,
      "step": 4631
    },
    {
      "epoch": 0.07334103899805247,
      "grad_norm": 0.3649061620235443,
      "learning_rate": 9.266589610019476e-06,
      "loss": 0.289,
      "step": 4632
    },
    {
      "epoch": 0.07335687255569454,
      "grad_norm": 0.3488945960998535,
      "learning_rate": 9.266431274443055e-06,
      "loss": 0.2438,
      "step": 4633
    },
    {
      "epoch": 0.0733727061133366,
      "grad_norm": 0.24726520478725433,
      "learning_rate": 9.266272938866635e-06,
      "loss": 0.1155,
      "step": 4634
    },
    {
      "epoch": 0.07338853967097868,
      "grad_norm": 0.0036362307146191597,
      "learning_rate": 9.266114603290214e-06,
      "loss": 0.0001,
      "step": 4635
    },
    {
      "epoch": 0.07340437322862074,
      "grad_norm": 0.18442387878894806,
      "learning_rate": 9.265956267713794e-06,
      "loss": 0.1387,
      "step": 4636
    },
    {
      "epoch": 0.0734202067862628,
      "grad_norm": 0.5176772475242615,
      "learning_rate": 9.265797932137372e-06,
      "loss": 0.0193,
      "step": 4637
    },
    {
      "epoch": 0.07343604034390487,
      "grad_norm": 0.18837375938892365,
      "learning_rate": 9.265639596560953e-06,
      "loss": 0.0504,
      "step": 4638
    },
    {
      "epoch": 0.07345187390154694,
      "grad_norm": 0.3843373954296112,
      "learning_rate": 9.265481260984532e-06,
      "loss": 0.2596,
      "step": 4639
    },
    {
      "epoch": 0.073467707459189,
      "grad_norm": 0.42918846011161804,
      "learning_rate": 9.26532292540811e-06,
      "loss": 0.3425,
      "step": 4640
    },
    {
      "epoch": 0.07348354101683108,
      "grad_norm": 0.016796523705124855,
      "learning_rate": 9.26516458983169e-06,
      "loss": 0.0003,
      "step": 4641
    },
    {
      "epoch": 0.07349937457447314,
      "grad_norm": 0.05468912422657013,
      "learning_rate": 9.26500625425527e-06,
      "loss": 0.002,
      "step": 4642
    },
    {
      "epoch": 0.0735152081321152,
      "grad_norm": 0.04539060220122337,
      "learning_rate": 9.264847918678848e-06,
      "loss": 0.0013,
      "step": 4643
    },
    {
      "epoch": 0.07353104168975727,
      "grad_norm": 0.294540673494339,
      "learning_rate": 9.264689583102427e-06,
      "loss": 0.4605,
      "step": 4644
    },
    {
      "epoch": 0.07354687524739933,
      "grad_norm": 0.03431426361203194,
      "learning_rate": 9.264531247526008e-06,
      "loss": 0.0006,
      "step": 4645
    },
    {
      "epoch": 0.0735627088050414,
      "grad_norm": 0.4608953297138214,
      "learning_rate": 9.264372911949587e-06,
      "loss": 0.1967,
      "step": 4646
    },
    {
      "epoch": 0.07357854236268348,
      "grad_norm": 0.41090577840805054,
      "learning_rate": 9.264214576373166e-06,
      "loss": 0.1028,
      "step": 4647
    },
    {
      "epoch": 0.07359437592032554,
      "grad_norm": 0.9273951649665833,
      "learning_rate": 9.264056240796745e-06,
      "loss": 0.4877,
      "step": 4648
    },
    {
      "epoch": 0.0736102094779676,
      "grad_norm": 0.17013397812843323,
      "learning_rate": 9.263897905220324e-06,
      "loss": 0.0199,
      "step": 4649
    },
    {
      "epoch": 0.07362604303560967,
      "grad_norm": 0.3372335731983185,
      "learning_rate": 9.263739569643903e-06,
      "loss": 0.2396,
      "step": 4650
    },
    {
      "epoch": 0.07364187659325173,
      "grad_norm": 0.2558270990848541,
      "learning_rate": 9.263581234067484e-06,
      "loss": 0.1383,
      "step": 4651
    },
    {
      "epoch": 0.0736577101508938,
      "grad_norm": 0.26895350217819214,
      "learning_rate": 9.263422898491063e-06,
      "loss": 0.0676,
      "step": 4652
    },
    {
      "epoch": 0.07367354370853588,
      "grad_norm": 0.27609631419181824,
      "learning_rate": 9.263264562914642e-06,
      "loss": 0.1497,
      "step": 4653
    },
    {
      "epoch": 0.07368937726617794,
      "grad_norm": 0.344978004693985,
      "learning_rate": 9.263106227338221e-06,
      "loss": 0.1628,
      "step": 4654
    },
    {
      "epoch": 0.07370521082382,
      "grad_norm": 0.020295754075050354,
      "learning_rate": 9.2629478917618e-06,
      "loss": 0.0009,
      "step": 4655
    },
    {
      "epoch": 0.07372104438146207,
      "grad_norm": 0.20981533825397491,
      "learning_rate": 9.26278955618538e-06,
      "loss": 0.1266,
      "step": 4656
    },
    {
      "epoch": 0.07373687793910413,
      "grad_norm": 0.010930108837783337,
      "learning_rate": 9.26263122060896e-06,
      "loss": 0.0005,
      "step": 4657
    },
    {
      "epoch": 0.0737527114967462,
      "grad_norm": 0.061246566474437714,
      "learning_rate": 9.26247288503254e-06,
      "loss": 0.0022,
      "step": 4658
    },
    {
      "epoch": 0.07376854505438828,
      "grad_norm": 0.2366483509540558,
      "learning_rate": 9.262314549456118e-06,
      "loss": 0.0153,
      "step": 4659
    },
    {
      "epoch": 0.07378437861203034,
      "grad_norm": 0.4806267023086548,
      "learning_rate": 9.262156213879697e-06,
      "loss": 0.6573,
      "step": 4660
    },
    {
      "epoch": 0.0738002121696724,
      "grad_norm": 0.1385229080915451,
      "learning_rate": 9.261997878303276e-06,
      "loss": 0.0381,
      "step": 4661
    },
    {
      "epoch": 0.07381604572731447,
      "grad_norm": 0.263602077960968,
      "learning_rate": 9.261839542726856e-06,
      "loss": 0.0331,
      "step": 4662
    },
    {
      "epoch": 0.07383187928495653,
      "grad_norm": 0.2508193552494049,
      "learning_rate": 9.261681207150436e-06,
      "loss": 0.3443,
      "step": 4663
    },
    {
      "epoch": 0.0738477128425986,
      "grad_norm": 0.19793200492858887,
      "learning_rate": 9.261522871574015e-06,
      "loss": 0.0485,
      "step": 4664
    },
    {
      "epoch": 0.07386354640024068,
      "grad_norm": 0.22980545461177826,
      "learning_rate": 9.261364535997594e-06,
      "loss": 0.1191,
      "step": 4665
    },
    {
      "epoch": 0.07387937995788274,
      "grad_norm": 0.7406411170959473,
      "learning_rate": 9.261206200421174e-06,
      "loss": 0.4883,
      "step": 4666
    },
    {
      "epoch": 0.0738952135155248,
      "grad_norm": 0.1822412610054016,
      "learning_rate": 9.261047864844753e-06,
      "loss": 0.0635,
      "step": 4667
    },
    {
      "epoch": 0.07391104707316687,
      "grad_norm": 0.5655703544616699,
      "learning_rate": 9.260889529268332e-06,
      "loss": 0.0571,
      "step": 4668
    },
    {
      "epoch": 0.07392688063080893,
      "grad_norm": 0.009191102348268032,
      "learning_rate": 9.26073119369191e-06,
      "loss": 0.0004,
      "step": 4669
    },
    {
      "epoch": 0.073942714188451,
      "grad_norm": 0.006275716237723827,
      "learning_rate": 9.260572858115492e-06,
      "loss": 0.0004,
      "step": 4670
    },
    {
      "epoch": 0.07395854774609308,
      "grad_norm": 0.013983205892145634,
      "learning_rate": 9.260414522539069e-06,
      "loss": 0.0009,
      "step": 4671
    },
    {
      "epoch": 0.07397438130373514,
      "grad_norm": 0.06335299462080002,
      "learning_rate": 9.26025618696265e-06,
      "loss": 0.0114,
      "step": 4672
    },
    {
      "epoch": 0.0739902148613772,
      "grad_norm": 0.27727818489074707,
      "learning_rate": 9.260097851386229e-06,
      "loss": 0.1746,
      "step": 4673
    },
    {
      "epoch": 0.07400604841901927,
      "grad_norm": 0.00022636698849964887,
      "learning_rate": 9.259939515809808e-06,
      "loss": 0.0,
      "step": 4674
    },
    {
      "epoch": 0.07402188197666133,
      "grad_norm": 0.48886579275131226,
      "learning_rate": 9.259781180233387e-06,
      "loss": 0.9616,
      "step": 4675
    },
    {
      "epoch": 0.0740377155343034,
      "grad_norm": 0.4746393859386444,
      "learning_rate": 9.259622844656968e-06,
      "loss": 0.4522,
      "step": 4676
    },
    {
      "epoch": 0.07405354909194548,
      "grad_norm": 0.2086164951324463,
      "learning_rate": 9.259464509080545e-06,
      "loss": 0.1465,
      "step": 4677
    },
    {
      "epoch": 0.07406938264958754,
      "grad_norm": 0.3260677754878998,
      "learning_rate": 9.259306173504126e-06,
      "loss": 0.1296,
      "step": 4678
    },
    {
      "epoch": 0.0740852162072296,
      "grad_norm": 0.40009984374046326,
      "learning_rate": 9.259147837927705e-06,
      "loss": 0.2362,
      "step": 4679
    },
    {
      "epoch": 0.07410104976487167,
      "grad_norm": 0.18854543566703796,
      "learning_rate": 9.258989502351284e-06,
      "loss": 0.0716,
      "step": 4680
    },
    {
      "epoch": 0.07411688332251373,
      "grad_norm": 0.3976670205593109,
      "learning_rate": 9.258831166774863e-06,
      "loss": 0.2301,
      "step": 4681
    },
    {
      "epoch": 0.0741327168801558,
      "grad_norm": 0.20765183866024017,
      "learning_rate": 9.258672831198442e-06,
      "loss": 0.1003,
      "step": 4682
    },
    {
      "epoch": 0.07414855043779787,
      "grad_norm": 0.0014517931267619133,
      "learning_rate": 9.258514495622021e-06,
      "loss": 0.0001,
      "step": 4683
    },
    {
      "epoch": 0.07416438399543994,
      "grad_norm": 0.21863026916980743,
      "learning_rate": 9.258356160045602e-06,
      "loss": 0.1127,
      "step": 4684
    },
    {
      "epoch": 0.074180217553082,
      "grad_norm": 0.33366408944129944,
      "learning_rate": 9.258197824469181e-06,
      "loss": 0.1789,
      "step": 4685
    },
    {
      "epoch": 0.07419605111072407,
      "grad_norm": 0.004542632959783077,
      "learning_rate": 9.25803948889276e-06,
      "loss": 0.0003,
      "step": 4686
    },
    {
      "epoch": 0.07421188466836613,
      "grad_norm": 0.010713770985603333,
      "learning_rate": 9.25788115331634e-06,
      "loss": 0.0005,
      "step": 4687
    },
    {
      "epoch": 0.0742277182260082,
      "grad_norm": 0.16438467800617218,
      "learning_rate": 9.257722817739918e-06,
      "loss": 0.0183,
      "step": 4688
    },
    {
      "epoch": 0.07424355178365027,
      "grad_norm": 0.6588646173477173,
      "learning_rate": 9.257564482163497e-06,
      "loss": 0.2015,
      "step": 4689
    },
    {
      "epoch": 0.07425938534129234,
      "grad_norm": 0.0089492192491889,
      "learning_rate": 9.257406146587078e-06,
      "loss": 0.0002,
      "step": 4690
    },
    {
      "epoch": 0.0742752188989344,
      "grad_norm": 0.0168322566896677,
      "learning_rate": 9.257247811010657e-06,
      "loss": 0.0009,
      "step": 4691
    },
    {
      "epoch": 0.07429105245657647,
      "grad_norm": 0.1790088415145874,
      "learning_rate": 9.257089475434235e-06,
      "loss": 0.0618,
      "step": 4692
    },
    {
      "epoch": 0.07430688601421853,
      "grad_norm": 0.2593948245048523,
      "learning_rate": 9.256931139857815e-06,
      "loss": 0.0235,
      "step": 4693
    },
    {
      "epoch": 0.0743227195718606,
      "grad_norm": 0.03320327401161194,
      "learning_rate": 9.256772804281395e-06,
      "loss": 0.0025,
      "step": 4694
    },
    {
      "epoch": 0.07433855312950267,
      "grad_norm": 0.5031522512435913,
      "learning_rate": 9.256614468704974e-06,
      "loss": 0.4352,
      "step": 4695
    },
    {
      "epoch": 0.07435438668714474,
      "grad_norm": 0.2201613336801529,
      "learning_rate": 9.256456133128553e-06,
      "loss": 0.0399,
      "step": 4696
    },
    {
      "epoch": 0.0743702202447868,
      "grad_norm": 0.38476330041885376,
      "learning_rate": 9.256297797552134e-06,
      "loss": 0.0112,
      "step": 4697
    },
    {
      "epoch": 0.07438605380242887,
      "grad_norm": 0.28509971499443054,
      "learning_rate": 9.256139461975711e-06,
      "loss": 0.2075,
      "step": 4698
    },
    {
      "epoch": 0.07440188736007093,
      "grad_norm": 2.9321221518330276e-05,
      "learning_rate": 9.255981126399292e-06,
      "loss": 0.0,
      "step": 4699
    },
    {
      "epoch": 0.074417720917713,
      "grad_norm": 0.1293569654226303,
      "learning_rate": 9.25582279082287e-06,
      "loss": 0.0483,
      "step": 4700
    },
    {
      "epoch": 0.07443355447535507,
      "grad_norm": 0.3011379539966583,
      "learning_rate": 9.25566445524645e-06,
      "loss": 0.3573,
      "step": 4701
    },
    {
      "epoch": 0.07444938803299714,
      "grad_norm": 0.0001684866874711588,
      "learning_rate": 9.255506119670029e-06,
      "loss": 0.0,
      "step": 4702
    },
    {
      "epoch": 0.0744652215906392,
      "grad_norm": 0.00504664471372962,
      "learning_rate": 9.25534778409361e-06,
      "loss": 0.0001,
      "step": 4703
    },
    {
      "epoch": 0.07448105514828127,
      "grad_norm": 0.287119060754776,
      "learning_rate": 9.255189448517187e-06,
      "loss": 0.2598,
      "step": 4704
    },
    {
      "epoch": 0.07449688870592333,
      "grad_norm": 0.10742001235485077,
      "learning_rate": 9.255031112940768e-06,
      "loss": 0.0068,
      "step": 4705
    },
    {
      "epoch": 0.0745127222635654,
      "grad_norm": 0.18730992078781128,
      "learning_rate": 9.254872777364347e-06,
      "loss": 0.1295,
      "step": 4706
    },
    {
      "epoch": 0.07452855582120747,
      "grad_norm": 0.00033751115552149713,
      "learning_rate": 9.254714441787926e-06,
      "loss": 0.0,
      "step": 4707
    },
    {
      "epoch": 0.07454438937884954,
      "grad_norm": 0.029135344550013542,
      "learning_rate": 9.254556106211505e-06,
      "loss": 0.0014,
      "step": 4708
    },
    {
      "epoch": 0.0745602229364916,
      "grad_norm": 0.004460432101041079,
      "learning_rate": 9.254397770635086e-06,
      "loss": 0.0002,
      "step": 4709
    },
    {
      "epoch": 0.07457605649413367,
      "grad_norm": 0.4678909182548523,
      "learning_rate": 9.254239435058663e-06,
      "loss": 0.2321,
      "step": 4710
    },
    {
      "epoch": 0.07459189005177573,
      "grad_norm": 0.5420030355453491,
      "learning_rate": 9.254081099482244e-06,
      "loss": 0.1727,
      "step": 4711
    },
    {
      "epoch": 0.0746077236094178,
      "grad_norm": 0.2943621277809143,
      "learning_rate": 9.253922763905823e-06,
      "loss": 0.1045,
      "step": 4712
    },
    {
      "epoch": 0.07462355716705987,
      "grad_norm": 0.215159609913826,
      "learning_rate": 9.253764428329402e-06,
      "loss": 0.1031,
      "step": 4713
    },
    {
      "epoch": 0.07463939072470194,
      "grad_norm": 0.13570615649223328,
      "learning_rate": 9.253606092752981e-06,
      "loss": 0.0508,
      "step": 4714
    },
    {
      "epoch": 0.074655224282344,
      "grad_norm": 0.2642197012901306,
      "learning_rate": 9.253447757176562e-06,
      "loss": 0.1526,
      "step": 4715
    },
    {
      "epoch": 0.07467105783998607,
      "grad_norm": 0.140349343419075,
      "learning_rate": 9.25328942160014e-06,
      "loss": 0.0628,
      "step": 4716
    },
    {
      "epoch": 0.07468689139762813,
      "grad_norm": 0.4004634618759155,
      "learning_rate": 9.253131086023718e-06,
      "loss": 0.1761,
      "step": 4717
    },
    {
      "epoch": 0.0747027249552702,
      "grad_norm": 0.1859002411365509,
      "learning_rate": 9.2529727504473e-06,
      "loss": 0.0402,
      "step": 4718
    },
    {
      "epoch": 0.07471855851291227,
      "grad_norm": 0.15591983497142792,
      "learning_rate": 9.252814414870878e-06,
      "loss": 0.0386,
      "step": 4719
    },
    {
      "epoch": 0.07473439207055434,
      "grad_norm": 0.3146519362926483,
      "learning_rate": 9.252656079294457e-06,
      "loss": 0.1366,
      "step": 4720
    },
    {
      "epoch": 0.0747502256281964,
      "grad_norm": 0.000129092630231753,
      "learning_rate": 9.252497743718036e-06,
      "loss": 0.0,
      "step": 4721
    },
    {
      "epoch": 0.07476605918583847,
      "grad_norm": 0.5336833000183105,
      "learning_rate": 9.252339408141616e-06,
      "loss": 0.0731,
      "step": 4722
    },
    {
      "epoch": 0.07478189274348053,
      "grad_norm": 0.446232408285141,
      "learning_rate": 9.252181072565195e-06,
      "loss": 0.1766,
      "step": 4723
    },
    {
      "epoch": 0.0747977263011226,
      "grad_norm": 0.32136809825897217,
      "learning_rate": 9.252022736988775e-06,
      "loss": 0.1183,
      "step": 4724
    },
    {
      "epoch": 0.07481355985876467,
      "grad_norm": 0.3520892262458801,
      "learning_rate": 9.251864401412355e-06,
      "loss": 0.4167,
      "step": 4725
    },
    {
      "epoch": 0.07482939341640674,
      "grad_norm": 0.6416807770729065,
      "learning_rate": 9.251706065835934e-06,
      "loss": 0.0406,
      "step": 4726
    },
    {
      "epoch": 0.0748452269740488,
      "grad_norm": 0.39578571915626526,
      "learning_rate": 9.251547730259513e-06,
      "loss": 0.1178,
      "step": 4727
    },
    {
      "epoch": 0.07486106053169087,
      "grad_norm": 0.18181556463241577,
      "learning_rate": 9.251389394683092e-06,
      "loss": 0.0986,
      "step": 4728
    },
    {
      "epoch": 0.07487689408933293,
      "grad_norm": 0.3444109261035919,
      "learning_rate": 9.25123105910667e-06,
      "loss": 0.184,
      "step": 4729
    },
    {
      "epoch": 0.074892727646975,
      "grad_norm": 0.20604655146598816,
      "learning_rate": 9.251072723530252e-06,
      "loss": 0.1062,
      "step": 4730
    },
    {
      "epoch": 0.07490856120461707,
      "grad_norm": 0.04584496095776558,
      "learning_rate": 9.25091438795383e-06,
      "loss": 0.001,
      "step": 4731
    },
    {
      "epoch": 0.07492439476225914,
      "grad_norm": 0.00014399419887922704,
      "learning_rate": 9.25075605237741e-06,
      "loss": 0.0,
      "step": 4732
    },
    {
      "epoch": 0.0749402283199012,
      "grad_norm": 0.00020716914150398225,
      "learning_rate": 9.250597716800989e-06,
      "loss": 0.0,
      "step": 4733
    },
    {
      "epoch": 0.07495606187754326,
      "grad_norm": 0.3774930536746979,
      "learning_rate": 9.250439381224568e-06,
      "loss": 0.8053,
      "step": 4734
    },
    {
      "epoch": 0.07497189543518533,
      "grad_norm": 0.2958763837814331,
      "learning_rate": 9.250281045648147e-06,
      "loss": 0.1243,
      "step": 4735
    },
    {
      "epoch": 0.0749877289928274,
      "grad_norm": 0.20053860545158386,
      "learning_rate": 9.250122710071728e-06,
      "loss": 0.5051,
      "step": 4736
    },
    {
      "epoch": 0.07500356255046947,
      "grad_norm": 0.4116858243942261,
      "learning_rate": 9.249964374495307e-06,
      "loss": 0.5761,
      "step": 4737
    },
    {
      "epoch": 0.07501939610811154,
      "grad_norm": 9.329221211373806e-05,
      "learning_rate": 9.249806038918886e-06,
      "loss": 0.0,
      "step": 4738
    },
    {
      "epoch": 0.0750352296657536,
      "grad_norm": 0.03790516406297684,
      "learning_rate": 9.249647703342465e-06,
      "loss": 0.0026,
      "step": 4739
    },
    {
      "epoch": 0.07505106322339566,
      "grad_norm": 1.4948899745941162,
      "learning_rate": 9.249489367766044e-06,
      "loss": 0.3189,
      "step": 4740
    },
    {
      "epoch": 0.07506689678103773,
      "grad_norm": 0.4576707184314728,
      "learning_rate": 9.249331032189623e-06,
      "loss": 0.0651,
      "step": 4741
    },
    {
      "epoch": 0.07508273033867979,
      "grad_norm": 0.4542628526687622,
      "learning_rate": 9.249172696613202e-06,
      "loss": 0.1039,
      "step": 4742
    },
    {
      "epoch": 0.07509856389632187,
      "grad_norm": 0.3569367527961731,
      "learning_rate": 9.249014361036783e-06,
      "loss": 0.3173,
      "step": 4743
    },
    {
      "epoch": 0.07511439745396394,
      "grad_norm": 0.005788509268313646,
      "learning_rate": 9.24885602546036e-06,
      "loss": 0.0002,
      "step": 4744
    },
    {
      "epoch": 0.075130231011606,
      "grad_norm": 0.2894921898841858,
      "learning_rate": 9.248697689883941e-06,
      "loss": 0.1978,
      "step": 4745
    },
    {
      "epoch": 0.07514606456924806,
      "grad_norm": 0.011330971494317055,
      "learning_rate": 9.24853935430752e-06,
      "loss": 0.0005,
      "step": 4746
    },
    {
      "epoch": 0.07516189812689013,
      "grad_norm": 0.1393541395664215,
      "learning_rate": 9.2483810187311e-06,
      "loss": 0.0743,
      "step": 4747
    },
    {
      "epoch": 0.07517773168453219,
      "grad_norm": 0.2056209146976471,
      "learning_rate": 9.248222683154678e-06,
      "loss": 0.2222,
      "step": 4748
    },
    {
      "epoch": 0.07519356524217427,
      "grad_norm": 0.26813217997550964,
      "learning_rate": 9.248064347578258e-06,
      "loss": 0.1181,
      "step": 4749
    },
    {
      "epoch": 0.07520939879981633,
      "grad_norm": 0.21508607268333435,
      "learning_rate": 9.247906012001837e-06,
      "loss": 0.1977,
      "step": 4750
    },
    {
      "epoch": 0.0752252323574584,
      "grad_norm": 0.2429255098104477,
      "learning_rate": 9.247747676425417e-06,
      "loss": 0.0225,
      "step": 4751
    },
    {
      "epoch": 0.07524106591510046,
      "grad_norm": 0.00019179166702087969,
      "learning_rate": 9.247589340848996e-06,
      "loss": 0.0,
      "step": 4752
    },
    {
      "epoch": 0.07525689947274253,
      "grad_norm": 0.26532965898513794,
      "learning_rate": 9.247431005272576e-06,
      "loss": 0.2448,
      "step": 4753
    },
    {
      "epoch": 0.07527273303038459,
      "grad_norm": 0.015919215977191925,
      "learning_rate": 9.247272669696155e-06,
      "loss": 0.0007,
      "step": 4754
    },
    {
      "epoch": 0.07528856658802667,
      "grad_norm": 0.2726336121559143,
      "learning_rate": 9.247114334119734e-06,
      "loss": 0.149,
      "step": 4755
    },
    {
      "epoch": 0.07530440014566873,
      "grad_norm": 0.40563398599624634,
      "learning_rate": 9.246955998543313e-06,
      "loss": 0.2689,
      "step": 4756
    },
    {
      "epoch": 0.0753202337033108,
      "grad_norm": 0.00037106144009158015,
      "learning_rate": 9.246797662966894e-06,
      "loss": 0.0,
      "step": 4757
    },
    {
      "epoch": 0.07533606726095286,
      "grad_norm": 0.05900353565812111,
      "learning_rate": 9.246639327390473e-06,
      "loss": 0.0079,
      "step": 4758
    },
    {
      "epoch": 0.07535190081859493,
      "grad_norm": 1.0662574768066406,
      "learning_rate": 9.246480991814052e-06,
      "loss": 0.1189,
      "step": 4759
    },
    {
      "epoch": 0.07536773437623699,
      "grad_norm": 0.024970795959234238,
      "learning_rate": 9.24632265623763e-06,
      "loss": 0.0014,
      "step": 4760
    },
    {
      "epoch": 0.07538356793387907,
      "grad_norm": 0.3556983470916748,
      "learning_rate": 9.24616432066121e-06,
      "loss": 0.1979,
      "step": 4761
    },
    {
      "epoch": 0.07539940149152113,
      "grad_norm": 0.5361297726631165,
      "learning_rate": 9.246005985084789e-06,
      "loss": 0.1055,
      "step": 4762
    },
    {
      "epoch": 0.0754152350491632,
      "grad_norm": 0.019188739359378815,
      "learning_rate": 9.24584764950837e-06,
      "loss": 0.0021,
      "step": 4763
    },
    {
      "epoch": 0.07543106860680526,
      "grad_norm": 0.2521708011627197,
      "learning_rate": 9.245689313931949e-06,
      "loss": 0.1228,
      "step": 4764
    },
    {
      "epoch": 0.07544690216444733,
      "grad_norm": 0.426054447889328,
      "learning_rate": 9.245530978355526e-06,
      "loss": 0.1001,
      "step": 4765
    },
    {
      "epoch": 0.07546273572208939,
      "grad_norm": 0.2768668234348297,
      "learning_rate": 9.245372642779107e-06,
      "loss": 0.2509,
      "step": 4766
    },
    {
      "epoch": 0.07547856927973147,
      "grad_norm": 0.06200487166643143,
      "learning_rate": 9.245214307202686e-06,
      "loss": 0.0076,
      "step": 4767
    },
    {
      "epoch": 0.07549440283737353,
      "grad_norm": 0.18416710197925568,
      "learning_rate": 9.245055971626265e-06,
      "loss": 0.2104,
      "step": 4768
    },
    {
      "epoch": 0.0755102363950156,
      "grad_norm": 0.1469154953956604,
      "learning_rate": 9.244897636049844e-06,
      "loss": 0.1362,
      "step": 4769
    },
    {
      "epoch": 0.07552606995265766,
      "grad_norm": 0.505236029624939,
      "learning_rate": 9.244739300473425e-06,
      "loss": 0.1325,
      "step": 4770
    },
    {
      "epoch": 0.07554190351029973,
      "grad_norm": 0.5261582732200623,
      "learning_rate": 9.244580964897002e-06,
      "loss": 0.0158,
      "step": 4771
    },
    {
      "epoch": 0.07555773706794179,
      "grad_norm": 0.42989686131477356,
      "learning_rate": 9.244422629320583e-06,
      "loss": 0.0778,
      "step": 4772
    },
    {
      "epoch": 0.07557357062558387,
      "grad_norm": 0.24392463266849518,
      "learning_rate": 9.244264293744162e-06,
      "loss": 0.1675,
      "step": 4773
    },
    {
      "epoch": 0.07558940418322593,
      "grad_norm": 0.26267147064208984,
      "learning_rate": 9.244105958167741e-06,
      "loss": 0.266,
      "step": 4774
    },
    {
      "epoch": 0.075605237740868,
      "grad_norm": 0.3451005816459656,
      "learning_rate": 9.24394762259132e-06,
      "loss": 1.1438,
      "step": 4775
    },
    {
      "epoch": 0.07562107129851006,
      "grad_norm": 0.2678188383579254,
      "learning_rate": 9.243789287014901e-06,
      "loss": 0.3714,
      "step": 4776
    },
    {
      "epoch": 0.07563690485615213,
      "grad_norm": 0.0005204955232329667,
      "learning_rate": 9.243630951438479e-06,
      "loss": 0.0,
      "step": 4777
    },
    {
      "epoch": 0.07565273841379419,
      "grad_norm": 0.3397988975048065,
      "learning_rate": 9.24347261586206e-06,
      "loss": 0.0772,
      "step": 4778
    },
    {
      "epoch": 0.07566857197143627,
      "grad_norm": 0.4190324544906616,
      "learning_rate": 9.243314280285638e-06,
      "loss": 0.2205,
      "step": 4779
    },
    {
      "epoch": 0.07568440552907833,
      "grad_norm": 0.15381738543510437,
      "learning_rate": 9.243155944709217e-06,
      "loss": 0.0667,
      "step": 4780
    },
    {
      "epoch": 0.0757002390867204,
      "grad_norm": 0.3478794991970062,
      "learning_rate": 9.242997609132797e-06,
      "loss": 0.0615,
      "step": 4781
    },
    {
      "epoch": 0.07571607264436246,
      "grad_norm": 0.26512983441352844,
      "learning_rate": 9.242839273556377e-06,
      "loss": 0.1722,
      "step": 4782
    },
    {
      "epoch": 0.07573190620200453,
      "grad_norm": 0.2058562934398651,
      "learning_rate": 9.242680937979955e-06,
      "loss": 0.1088,
      "step": 4783
    },
    {
      "epoch": 0.07574773975964659,
      "grad_norm": 0.27240949869155884,
      "learning_rate": 9.242522602403535e-06,
      "loss": 0.2482,
      "step": 4784
    },
    {
      "epoch": 0.07576357331728867,
      "grad_norm": 0.14153777062892914,
      "learning_rate": 9.242364266827115e-06,
      "loss": 0.0129,
      "step": 4785
    },
    {
      "epoch": 0.07577940687493073,
      "grad_norm": 0.3858907222747803,
      "learning_rate": 9.242205931250694e-06,
      "loss": 0.394,
      "step": 4786
    },
    {
      "epoch": 0.0757952404325728,
      "grad_norm": 0.36638587713241577,
      "learning_rate": 9.242047595674273e-06,
      "loss": 0.0667,
      "step": 4787
    },
    {
      "epoch": 0.07581107399021486,
      "grad_norm": 0.46904340386390686,
      "learning_rate": 9.241889260097852e-06,
      "loss": 0.1746,
      "step": 4788
    },
    {
      "epoch": 0.07582690754785693,
      "grad_norm": 0.21097931265830994,
      "learning_rate": 9.241730924521431e-06,
      "loss": 0.0692,
      "step": 4789
    },
    {
      "epoch": 0.07584274110549899,
      "grad_norm": 0.006992675829678774,
      "learning_rate": 9.24157258894501e-06,
      "loss": 0.0003,
      "step": 4790
    },
    {
      "epoch": 0.07585857466314107,
      "grad_norm": 0.0794726088643074,
      "learning_rate": 9.24141425336859e-06,
      "loss": 0.0048,
      "step": 4791
    },
    {
      "epoch": 0.07587440822078313,
      "grad_norm": 0.2035001963376999,
      "learning_rate": 9.24125591779217e-06,
      "loss": 0.1222,
      "step": 4792
    },
    {
      "epoch": 0.0758902417784252,
      "grad_norm": 0.22328084707260132,
      "learning_rate": 9.241097582215749e-06,
      "loss": 0.1182,
      "step": 4793
    },
    {
      "epoch": 0.07590607533606726,
      "grad_norm": 0.14648696780204773,
      "learning_rate": 9.240939246639328e-06,
      "loss": 0.0615,
      "step": 4794
    },
    {
      "epoch": 0.07592190889370933,
      "grad_norm": 0.00817856378853321,
      "learning_rate": 9.240780911062907e-06,
      "loss": 0.0005,
      "step": 4795
    },
    {
      "epoch": 0.07593774245135139,
      "grad_norm": 0.0007778815343044698,
      "learning_rate": 9.240622575486486e-06,
      "loss": 0.0,
      "step": 4796
    },
    {
      "epoch": 0.07595357600899347,
      "grad_norm": 0.24395908415317535,
      "learning_rate": 9.240464239910067e-06,
      "loss": 0.0049,
      "step": 4797
    },
    {
      "epoch": 0.07596940956663553,
      "grad_norm": 0.29036715626716614,
      "learning_rate": 9.240305904333646e-06,
      "loss": 0.2869,
      "step": 4798
    },
    {
      "epoch": 0.0759852431242776,
      "grad_norm": 0.36899885535240173,
      "learning_rate": 9.240147568757225e-06,
      "loss": 0.4457,
      "step": 4799
    },
    {
      "epoch": 0.07600107668191966,
      "grad_norm": 0.05446527153253555,
      "learning_rate": 9.239989233180804e-06,
      "loss": 0.0051,
      "step": 4800
    },
    {
      "epoch": 0.07601691023956172,
      "grad_norm": 0.008781291544437408,
      "learning_rate": 9.239830897604383e-06,
      "loss": 0.0004,
      "step": 4801
    },
    {
      "epoch": 0.07603274379720379,
      "grad_norm": 0.3939720094203949,
      "learning_rate": 9.239672562027962e-06,
      "loss": 0.2325,
      "step": 4802
    },
    {
      "epoch": 0.07604857735484587,
      "grad_norm": 0.40590226650238037,
      "learning_rate": 9.239514226451543e-06,
      "loss": 0.2812,
      "step": 4803
    },
    {
      "epoch": 0.07606441091248793,
      "grad_norm": 6.595769809791818e-05,
      "learning_rate": 9.239355890875122e-06,
      "loss": 0.0,
      "step": 4804
    },
    {
      "epoch": 0.07608024447013,
      "grad_norm": 0.2823778986930847,
      "learning_rate": 9.239197555298701e-06,
      "loss": 0.4665,
      "step": 4805
    },
    {
      "epoch": 0.07609607802777206,
      "grad_norm": 1.110823154449463,
      "learning_rate": 9.23903921972228e-06,
      "loss": 0.3997,
      "step": 4806
    },
    {
      "epoch": 0.07611191158541412,
      "grad_norm": 0.012432853691279888,
      "learning_rate": 9.23888088414586e-06,
      "loss": 0.0005,
      "step": 4807
    },
    {
      "epoch": 0.07612774514305619,
      "grad_norm": 0.948373556137085,
      "learning_rate": 9.238722548569438e-06,
      "loss": 0.0322,
      "step": 4808
    },
    {
      "epoch": 0.07614357870069827,
      "grad_norm": 0.0032059387303888798,
      "learning_rate": 9.23856421299302e-06,
      "loss": 0.0001,
      "step": 4809
    },
    {
      "epoch": 0.07615941225834033,
      "grad_norm": 0.39123281836509705,
      "learning_rate": 9.238405877416597e-06,
      "loss": 0.1974,
      "step": 4810
    },
    {
      "epoch": 0.0761752458159824,
      "grad_norm": 0.2167770117521286,
      "learning_rate": 9.238247541840177e-06,
      "loss": 0.0711,
      "step": 4811
    },
    {
      "epoch": 0.07619107937362446,
      "grad_norm": 0.04803185537457466,
      "learning_rate": 9.238089206263756e-06,
      "loss": 0.0024,
      "step": 4812
    },
    {
      "epoch": 0.07620691293126652,
      "grad_norm": 0.4954727590084076,
      "learning_rate": 9.237930870687336e-06,
      "loss": 0.0742,
      "step": 4813
    },
    {
      "epoch": 0.07622274648890859,
      "grad_norm": 0.3072119951248169,
      "learning_rate": 9.237772535110915e-06,
      "loss": 0.0871,
      "step": 4814
    },
    {
      "epoch": 0.07623858004655067,
      "grad_norm": 0.14359337091445923,
      "learning_rate": 9.237614199534494e-06,
      "loss": 0.0497,
      "step": 4815
    },
    {
      "epoch": 0.07625441360419273,
      "grad_norm": 0.511741042137146,
      "learning_rate": 9.237455863958073e-06,
      "loss": 0.0333,
      "step": 4816
    },
    {
      "epoch": 0.0762702471618348,
      "grad_norm": 0.2537190318107605,
      "learning_rate": 9.237297528381652e-06,
      "loss": 0.0889,
      "step": 4817
    },
    {
      "epoch": 0.07628608071947686,
      "grad_norm": 0.5527316331863403,
      "learning_rate": 9.237139192805233e-06,
      "loss": 0.1829,
      "step": 4818
    },
    {
      "epoch": 0.07630191427711892,
      "grad_norm": 0.43905869126319885,
      "learning_rate": 9.236980857228812e-06,
      "loss": 0.269,
      "step": 4819
    },
    {
      "epoch": 0.07631774783476099,
      "grad_norm": 0.21387328207492828,
      "learning_rate": 9.23682252165239e-06,
      "loss": 0.1166,
      "step": 4820
    },
    {
      "epoch": 0.07633358139240307,
      "grad_norm": 0.4284328818321228,
      "learning_rate": 9.23666418607597e-06,
      "loss": 0.324,
      "step": 4821
    },
    {
      "epoch": 0.07634941495004513,
      "grad_norm": 0.21186836063861847,
      "learning_rate": 9.236505850499549e-06,
      "loss": 0.1053,
      "step": 4822
    },
    {
      "epoch": 0.0763652485076872,
      "grad_norm": 0.5942054390907288,
      "learning_rate": 9.236347514923128e-06,
      "loss": 0.0782,
      "step": 4823
    },
    {
      "epoch": 0.07638108206532926,
      "grad_norm": 0.3591577410697937,
      "learning_rate": 9.236189179346709e-06,
      "loss": 0.4636,
      "step": 4824
    },
    {
      "epoch": 0.07639691562297132,
      "grad_norm": 0.5311927795410156,
      "learning_rate": 9.236030843770288e-06,
      "loss": 0.3546,
      "step": 4825
    },
    {
      "epoch": 0.07641274918061339,
      "grad_norm": 0.13240574300289154,
      "learning_rate": 9.235872508193867e-06,
      "loss": 0.057,
      "step": 4826
    },
    {
      "epoch": 0.07642858273825547,
      "grad_norm": 0.1876172125339508,
      "learning_rate": 9.235714172617446e-06,
      "loss": 0.0308,
      "step": 4827
    },
    {
      "epoch": 0.07644441629589753,
      "grad_norm": 0.01255441177636385,
      "learning_rate": 9.235555837041025e-06,
      "loss": 0.0007,
      "step": 4828
    },
    {
      "epoch": 0.0764602498535396,
      "grad_norm": 0.006788039579987526,
      "learning_rate": 9.235397501464604e-06,
      "loss": 0.0003,
      "step": 4829
    },
    {
      "epoch": 0.07647608341118166,
      "grad_norm": 0.23491448163986206,
      "learning_rate": 9.235239165888185e-06,
      "loss": 0.2165,
      "step": 4830
    },
    {
      "epoch": 0.07649191696882372,
      "grad_norm": 0.4127614200115204,
      "learning_rate": 9.235080830311764e-06,
      "loss": 0.1306,
      "step": 4831
    },
    {
      "epoch": 0.07650775052646579,
      "grad_norm": 0.029593555256724358,
      "learning_rate": 9.234922494735343e-06,
      "loss": 0.0016,
      "step": 4832
    },
    {
      "epoch": 0.07652358408410785,
      "grad_norm": 0.2912701666355133,
      "learning_rate": 9.234764159158922e-06,
      "loss": 0.1956,
      "step": 4833
    },
    {
      "epoch": 0.07653941764174993,
      "grad_norm": 0.6530787348747253,
      "learning_rate": 9.234605823582501e-06,
      "loss": 1.0288,
      "step": 4834
    },
    {
      "epoch": 0.076555251199392,
      "grad_norm": 0.16557665169239044,
      "learning_rate": 9.23444748800608e-06,
      "loss": 0.0313,
      "step": 4835
    },
    {
      "epoch": 0.07657108475703406,
      "grad_norm": 0.15701614320278168,
      "learning_rate": 9.234289152429661e-06,
      "loss": 0.2807,
      "step": 4836
    },
    {
      "epoch": 0.07658691831467612,
      "grad_norm": 0.016145814210176468,
      "learning_rate": 9.23413081685324e-06,
      "loss": 0.0008,
      "step": 4837
    },
    {
      "epoch": 0.07660275187231819,
      "grad_norm": 0.03983621299266815,
      "learning_rate": 9.233972481276818e-06,
      "loss": 0.0025,
      "step": 4838
    },
    {
      "epoch": 0.07661858542996025,
      "grad_norm": 0.11860332638025284,
      "learning_rate": 9.233814145700398e-06,
      "loss": 0.1635,
      "step": 4839
    },
    {
      "epoch": 0.07663441898760233,
      "grad_norm": 0.3415888249874115,
      "learning_rate": 9.233655810123977e-06,
      "loss": 0.0919,
      "step": 4840
    },
    {
      "epoch": 0.0766502525452444,
      "grad_norm": 0.0025047380477190018,
      "learning_rate": 9.233497474547557e-06,
      "loss": 0.0001,
      "step": 4841
    },
    {
      "epoch": 0.07666608610288646,
      "grad_norm": 0.1778406798839569,
      "learning_rate": 9.233339138971136e-06,
      "loss": 0.2441,
      "step": 4842
    },
    {
      "epoch": 0.07668191966052852,
      "grad_norm": 0.6246013045310974,
      "learning_rate": 9.233180803394716e-06,
      "loss": 0.3477,
      "step": 4843
    },
    {
      "epoch": 0.07669775321817059,
      "grad_norm": 0.248815655708313,
      "learning_rate": 9.233022467818294e-06,
      "loss": 0.0704,
      "step": 4844
    },
    {
      "epoch": 0.07671358677581265,
      "grad_norm": 0.3118155300617218,
      "learning_rate": 9.232864132241875e-06,
      "loss": 0.0749,
      "step": 4845
    },
    {
      "epoch": 0.07672942033345473,
      "grad_norm": 0.26985520124435425,
      "learning_rate": 9.232705796665454e-06,
      "loss": 0.3038,
      "step": 4846
    },
    {
      "epoch": 0.07674525389109679,
      "grad_norm": 0.028046950697898865,
      "learning_rate": 9.232547461089033e-06,
      "loss": 0.0017,
      "step": 4847
    },
    {
      "epoch": 0.07676108744873886,
      "grad_norm": 0.04228702932596207,
      "learning_rate": 9.232389125512612e-06,
      "loss": 0.0058,
      "step": 4848
    },
    {
      "epoch": 0.07677692100638092,
      "grad_norm": 0.10830087214708328,
      "learning_rate": 9.232230789936193e-06,
      "loss": 0.0416,
      "step": 4849
    },
    {
      "epoch": 0.07679275456402299,
      "grad_norm": 0.028834886848926544,
      "learning_rate": 9.23207245435977e-06,
      "loss": 0.002,
      "step": 4850
    },
    {
      "epoch": 0.07680858812166505,
      "grad_norm": 0.29404181241989136,
      "learning_rate": 9.23191411878335e-06,
      "loss": 0.2128,
      "step": 4851
    },
    {
      "epoch": 0.07682442167930713,
      "grad_norm": 0.017066696658730507,
      "learning_rate": 9.23175578320693e-06,
      "loss": 0.001,
      "step": 4852
    },
    {
      "epoch": 0.07684025523694919,
      "grad_norm": 0.16122272610664368,
      "learning_rate": 9.231597447630509e-06,
      "loss": 0.0431,
      "step": 4853
    },
    {
      "epoch": 0.07685608879459126,
      "grad_norm": 0.0002776490291580558,
      "learning_rate": 9.231439112054088e-06,
      "loss": 0.0,
      "step": 4854
    },
    {
      "epoch": 0.07687192235223332,
      "grad_norm": 0.011785482987761497,
      "learning_rate": 9.231280776477669e-06,
      "loss": 0.0007,
      "step": 4855
    },
    {
      "epoch": 0.07688775590987539,
      "grad_norm": 0.08748846501111984,
      "learning_rate": 9.231122440901246e-06,
      "loss": 0.0073,
      "step": 4856
    },
    {
      "epoch": 0.07690358946751745,
      "grad_norm": 0.36646783351898193,
      "learning_rate": 9.230964105324827e-06,
      "loss": 0.4112,
      "step": 4857
    },
    {
      "epoch": 0.07691942302515953,
      "grad_norm": 0.271450400352478,
      "learning_rate": 9.230805769748406e-06,
      "loss": 0.0312,
      "step": 4858
    },
    {
      "epoch": 0.07693525658280159,
      "grad_norm": 0.12880706787109375,
      "learning_rate": 9.230647434171985e-06,
      "loss": 0.0474,
      "step": 4859
    },
    {
      "epoch": 0.07695109014044366,
      "grad_norm": 0.19318130612373352,
      "learning_rate": 9.230489098595564e-06,
      "loss": 0.1237,
      "step": 4860
    },
    {
      "epoch": 0.07696692369808572,
      "grad_norm": 0.025134917348623276,
      "learning_rate": 9.230330763019143e-06,
      "loss": 0.0015,
      "step": 4861
    },
    {
      "epoch": 0.07698275725572779,
      "grad_norm": 9.646027319831774e-05,
      "learning_rate": 9.230172427442722e-06,
      "loss": 0.0,
      "step": 4862
    },
    {
      "epoch": 0.07699859081336985,
      "grad_norm": 0.23588985204696655,
      "learning_rate": 9.230014091866301e-06,
      "loss": 0.1236,
      "step": 4863
    },
    {
      "epoch": 0.07701442437101193,
      "grad_norm": 0.026083704084157944,
      "learning_rate": 9.229855756289882e-06,
      "loss": 0.0012,
      "step": 4864
    },
    {
      "epoch": 0.07703025792865399,
      "grad_norm": 0.2282390594482422,
      "learning_rate": 9.229697420713461e-06,
      "loss": 0.056,
      "step": 4865
    },
    {
      "epoch": 0.07704609148629606,
      "grad_norm": 0.01676495373249054,
      "learning_rate": 9.22953908513704e-06,
      "loss": 0.0009,
      "step": 4866
    },
    {
      "epoch": 0.07706192504393812,
      "grad_norm": 0.3853208124637604,
      "learning_rate": 9.22938074956062e-06,
      "loss": 0.8375,
      "step": 4867
    },
    {
      "epoch": 0.07707775860158018,
      "grad_norm": 0.2012299746274948,
      "learning_rate": 9.229222413984198e-06,
      "loss": 0.0533,
      "step": 4868
    },
    {
      "epoch": 0.07709359215922225,
      "grad_norm": 0.20049117505550385,
      "learning_rate": 9.229064078407778e-06,
      "loss": 0.1111,
      "step": 4869
    },
    {
      "epoch": 0.07710942571686433,
      "grad_norm": 0.5787917971611023,
      "learning_rate": 9.228905742831358e-06,
      "loss": 0.4016,
      "step": 4870
    },
    {
      "epoch": 0.07712525927450639,
      "grad_norm": 0.0026104324497282505,
      "learning_rate": 9.228747407254937e-06,
      "loss": 0.0001,
      "step": 4871
    },
    {
      "epoch": 0.07714109283214846,
      "grad_norm": 0.14169670641422272,
      "learning_rate": 9.228589071678516e-06,
      "loss": 0.0049,
      "step": 4872
    },
    {
      "epoch": 0.07715692638979052,
      "grad_norm": 0.1611718386411667,
      "learning_rate": 9.228430736102096e-06,
      "loss": 0.0792,
      "step": 4873
    },
    {
      "epoch": 0.07717275994743258,
      "grad_norm": 0.9376377463340759,
      "learning_rate": 9.228272400525675e-06,
      "loss": 0.0184,
      "step": 4874
    },
    {
      "epoch": 0.07718859350507465,
      "grad_norm": 0.3708331286907196,
      "learning_rate": 9.228114064949254e-06,
      "loss": 0.4089,
      "step": 4875
    },
    {
      "epoch": 0.07720442706271673,
      "grad_norm": 0.01517209317535162,
      "learning_rate": 9.227955729372834e-06,
      "loss": 0.0004,
      "step": 4876
    },
    {
      "epoch": 0.07722026062035879,
      "grad_norm": 0.18187952041625977,
      "learning_rate": 9.227797393796412e-06,
      "loss": 0.263,
      "step": 4877
    },
    {
      "epoch": 0.07723609417800086,
      "grad_norm": 0.381330668926239,
      "learning_rate": 9.227639058219993e-06,
      "loss": 0.2251,
      "step": 4878
    },
    {
      "epoch": 0.07725192773564292,
      "grad_norm": 0.37357091903686523,
      "learning_rate": 9.227480722643572e-06,
      "loss": 0.1414,
      "step": 4879
    },
    {
      "epoch": 0.07726776129328498,
      "grad_norm": 0.20174290239810944,
      "learning_rate": 9.22732238706715e-06,
      "loss": 0.0619,
      "step": 4880
    },
    {
      "epoch": 0.07728359485092705,
      "grad_norm": 0.31813642382621765,
      "learning_rate": 9.22716405149073e-06,
      "loss": 0.0665,
      "step": 4881
    },
    {
      "epoch": 0.07729942840856913,
      "grad_norm": 0.15286597609519958,
      "learning_rate": 9.22700571591431e-06,
      "loss": 0.0153,
      "step": 4882
    },
    {
      "epoch": 0.07731526196621119,
      "grad_norm": 0.4902177155017853,
      "learning_rate": 9.226847380337888e-06,
      "loss": 0.2174,
      "step": 4883
    },
    {
      "epoch": 0.07733109552385325,
      "grad_norm": 0.26796722412109375,
      "learning_rate": 9.226689044761469e-06,
      "loss": 0.0437,
      "step": 4884
    },
    {
      "epoch": 0.07734692908149532,
      "grad_norm": 0.363800972700119,
      "learning_rate": 9.226530709185048e-06,
      "loss": 0.2797,
      "step": 4885
    },
    {
      "epoch": 0.07736276263913738,
      "grad_norm": 0.006158797070384026,
      "learning_rate": 9.226372373608627e-06,
      "loss": 0.0001,
      "step": 4886
    },
    {
      "epoch": 0.07737859619677945,
      "grad_norm": 0.035625066608190536,
      "learning_rate": 9.226214038032206e-06,
      "loss": 0.0016,
      "step": 4887
    },
    {
      "epoch": 0.07739442975442153,
      "grad_norm": 0.160244882106781,
      "learning_rate": 9.226055702455785e-06,
      "loss": 0.0349,
      "step": 4888
    },
    {
      "epoch": 0.07741026331206359,
      "grad_norm": 0.17692242562770844,
      "learning_rate": 9.225897366879364e-06,
      "loss": 0.1478,
      "step": 4889
    },
    {
      "epoch": 0.07742609686970565,
      "grad_norm": 0.22018207609653473,
      "learning_rate": 9.225739031302943e-06,
      "loss": 0.0523,
      "step": 4890
    },
    {
      "epoch": 0.07744193042734772,
      "grad_norm": 0.018348781391978264,
      "learning_rate": 9.225580695726524e-06,
      "loss": 0.0006,
      "step": 4891
    },
    {
      "epoch": 0.07745776398498978,
      "grad_norm": 0.018384627997875214,
      "learning_rate": 9.225422360150103e-06,
      "loss": 0.0008,
      "step": 4892
    },
    {
      "epoch": 0.07747359754263185,
      "grad_norm": 0.2051709145307541,
      "learning_rate": 9.225264024573682e-06,
      "loss": 0.1196,
      "step": 4893
    },
    {
      "epoch": 0.07748943110027393,
      "grad_norm": 0.3491176664829254,
      "learning_rate": 9.225105688997261e-06,
      "loss": 0.2954,
      "step": 4894
    },
    {
      "epoch": 0.07750526465791599,
      "grad_norm": 0.0351058654487133,
      "learning_rate": 9.22494735342084e-06,
      "loss": 0.0024,
      "step": 4895
    },
    {
      "epoch": 0.07752109821555805,
      "grad_norm": 0.19832023978233337,
      "learning_rate": 9.22478901784442e-06,
      "loss": 0.0783,
      "step": 4896
    },
    {
      "epoch": 0.07753693177320012,
      "grad_norm": 0.16868729889392853,
      "learning_rate": 9.224630682268e-06,
      "loss": 0.0602,
      "step": 4897
    },
    {
      "epoch": 0.07755276533084218,
      "grad_norm": 0.21762406826019287,
      "learning_rate": 9.22447234669158e-06,
      "loss": 0.2747,
      "step": 4898
    },
    {
      "epoch": 0.07756859888848425,
      "grad_norm": 0.1863638311624527,
      "learning_rate": 9.224314011115158e-06,
      "loss": 0.0308,
      "step": 4899
    },
    {
      "epoch": 0.07758443244612633,
      "grad_norm": 0.005648194812238216,
      "learning_rate": 9.224155675538737e-06,
      "loss": 0.0002,
      "step": 4900
    },
    {
      "epoch": 0.07760026600376839,
      "grad_norm": 0.22734254598617554,
      "learning_rate": 9.223997339962317e-06,
      "loss": 0.1219,
      "step": 4901
    },
    {
      "epoch": 0.07761609956141045,
      "grad_norm": 0.2956627905368805,
      "learning_rate": 9.223839004385896e-06,
      "loss": 0.3862,
      "step": 4902
    },
    {
      "epoch": 0.07763193311905252,
      "grad_norm": 0.010916495695710182,
      "learning_rate": 9.223680668809476e-06,
      "loss": 0.0005,
      "step": 4903
    },
    {
      "epoch": 0.07764776667669458,
      "grad_norm": 0.007207266986370087,
      "learning_rate": 9.223522333233055e-06,
      "loss": 0.0002,
      "step": 4904
    },
    {
      "epoch": 0.07766360023433665,
      "grad_norm": 0.12099501490592957,
      "learning_rate": 9.223363997656635e-06,
      "loss": 0.067,
      "step": 4905
    },
    {
      "epoch": 0.07767943379197872,
      "grad_norm": 0.1626715213060379,
      "learning_rate": 9.223205662080214e-06,
      "loss": 0.0678,
      "step": 4906
    },
    {
      "epoch": 0.07769526734962079,
      "grad_norm": 0.14742515981197357,
      "learning_rate": 9.223047326503793e-06,
      "loss": 0.062,
      "step": 4907
    },
    {
      "epoch": 0.07771110090726285,
      "grad_norm": 0.6296247839927673,
      "learning_rate": 9.222888990927372e-06,
      "loss": 0.1871,
      "step": 4908
    },
    {
      "epoch": 0.07772693446490492,
      "grad_norm": 0.23069003224372864,
      "learning_rate": 9.222730655350951e-06,
      "loss": 0.1145,
      "step": 4909
    },
    {
      "epoch": 0.07774276802254698,
      "grad_norm": 0.003301945747807622,
      "learning_rate": 9.222572319774532e-06,
      "loss": 0.0001,
      "step": 4910
    },
    {
      "epoch": 0.07775860158018905,
      "grad_norm": 0.24728304147720337,
      "learning_rate": 9.222413984198109e-06,
      "loss": 0.0376,
      "step": 4911
    },
    {
      "epoch": 0.07777443513783112,
      "grad_norm": 0.2579995095729828,
      "learning_rate": 9.22225564862169e-06,
      "loss": 0.0784,
      "step": 4912
    },
    {
      "epoch": 0.07779026869547319,
      "grad_norm": 0.2929125130176544,
      "learning_rate": 9.222097313045269e-06,
      "loss": 0.1397,
      "step": 4913
    },
    {
      "epoch": 0.07780610225311525,
      "grad_norm": 0.3003394901752472,
      "learning_rate": 9.221938977468848e-06,
      "loss": 0.1112,
      "step": 4914
    },
    {
      "epoch": 0.07782193581075732,
      "grad_norm": 0.2958095073699951,
      "learning_rate": 9.221780641892427e-06,
      "loss": 0.057,
      "step": 4915
    },
    {
      "epoch": 0.07783776936839938,
      "grad_norm": 0.004208422265946865,
      "learning_rate": 9.221622306316008e-06,
      "loss": 0.0001,
      "step": 4916
    },
    {
      "epoch": 0.07785360292604145,
      "grad_norm": 0.18913480639457703,
      "learning_rate": 9.221463970739585e-06,
      "loss": 0.0737,
      "step": 4917
    },
    {
      "epoch": 0.07786943648368352,
      "grad_norm": 0.38700011372566223,
      "learning_rate": 9.221305635163166e-06,
      "loss": 0.1885,
      "step": 4918
    },
    {
      "epoch": 0.07788527004132559,
      "grad_norm": 0.0314113050699234,
      "learning_rate": 9.221147299586745e-06,
      "loss": 0.0014,
      "step": 4919
    },
    {
      "epoch": 0.07790110359896765,
      "grad_norm": 0.0025363494642078876,
      "learning_rate": 9.220988964010324e-06,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 0.07791693715660972,
      "grad_norm": 0.3753318786621094,
      "learning_rate": 9.220830628433903e-06,
      "loss": 0.2855,
      "step": 4921
    },
    {
      "epoch": 0.07793277071425178,
      "grad_norm": 0.424917608499527,
      "learning_rate": 9.220672292857484e-06,
      "loss": 0.327,
      "step": 4922
    },
    {
      "epoch": 0.07794860427189385,
      "grad_norm": 0.3214416801929474,
      "learning_rate": 9.220513957281061e-06,
      "loss": 0.3748,
      "step": 4923
    },
    {
      "epoch": 0.07796443782953592,
      "grad_norm": 0.02967684343457222,
      "learning_rate": 9.220355621704642e-06,
      "loss": 0.001,
      "step": 4924
    },
    {
      "epoch": 0.07798027138717799,
      "grad_norm": 0.008014635182917118,
      "learning_rate": 9.220197286128221e-06,
      "loss": 0.0003,
      "step": 4925
    },
    {
      "epoch": 0.07799610494482005,
      "grad_norm": 0.011466722004115582,
      "learning_rate": 9.2200389505518e-06,
      "loss": 0.0003,
      "step": 4926
    },
    {
      "epoch": 0.07801193850246212,
      "grad_norm": 0.024750608950853348,
      "learning_rate": 9.21988061497538e-06,
      "loss": 0.001,
      "step": 4927
    },
    {
      "epoch": 0.07802777206010418,
      "grad_norm": 0.6346613764762878,
      "learning_rate": 9.21972227939896e-06,
      "loss": 0.191,
      "step": 4928
    },
    {
      "epoch": 0.07804360561774625,
      "grad_norm": 0.0330205112695694,
      "learning_rate": 9.219563943822538e-06,
      "loss": 0.0016,
      "step": 4929
    },
    {
      "epoch": 0.07805943917538832,
      "grad_norm": 0.18480409681797028,
      "learning_rate": 9.219405608246118e-06,
      "loss": 0.0182,
      "step": 4930
    },
    {
      "epoch": 0.07807527273303039,
      "grad_norm": 0.014225899241864681,
      "learning_rate": 9.219247272669697e-06,
      "loss": 0.0007,
      "step": 4931
    },
    {
      "epoch": 0.07809110629067245,
      "grad_norm": 0.12572264671325684,
      "learning_rate": 9.219088937093276e-06,
      "loss": 0.0571,
      "step": 4932
    },
    {
      "epoch": 0.07810693984831452,
      "grad_norm": 0.0028968716505914927,
      "learning_rate": 9.218930601516856e-06,
      "loss": 0.0001,
      "step": 4933
    },
    {
      "epoch": 0.07812277340595658,
      "grad_norm": 0.0001642287679715082,
      "learning_rate": 9.218772265940435e-06,
      "loss": 0.0,
      "step": 4934
    },
    {
      "epoch": 0.07813860696359864,
      "grad_norm": 0.37555432319641113,
      "learning_rate": 9.218613930364014e-06,
      "loss": 0.1097,
      "step": 4935
    },
    {
      "epoch": 0.07815444052124072,
      "grad_norm": 0.014766234904527664,
      "learning_rate": 9.218455594787593e-06,
      "loss": 0.0006,
      "step": 4936
    },
    {
      "epoch": 0.07817027407888279,
      "grad_norm": 0.23153764009475708,
      "learning_rate": 9.218297259211174e-06,
      "loss": 0.0674,
      "step": 4937
    },
    {
      "epoch": 0.07818610763652485,
      "grad_norm": 0.022146206349134445,
      "learning_rate": 9.218138923634753e-06,
      "loss": 0.0011,
      "step": 4938
    },
    {
      "epoch": 0.07820194119416692,
      "grad_norm": 0.3716859519481659,
      "learning_rate": 9.217980588058332e-06,
      "loss": 0.1285,
      "step": 4939
    },
    {
      "epoch": 0.07821777475180898,
      "grad_norm": 0.4454847276210785,
      "learning_rate": 9.21782225248191e-06,
      "loss": 0.0463,
      "step": 4940
    },
    {
      "epoch": 0.07823360830945104,
      "grad_norm": 0.5814757943153381,
      "learning_rate": 9.21766391690549e-06,
      "loss": 0.4714,
      "step": 4941
    },
    {
      "epoch": 0.07824944186709312,
      "grad_norm": 0.4822233319282532,
      "learning_rate": 9.217505581329069e-06,
      "loss": 0.2365,
      "step": 4942
    },
    {
      "epoch": 0.07826527542473519,
      "grad_norm": 0.801615297794342,
      "learning_rate": 9.21734724575265e-06,
      "loss": 0.2397,
      "step": 4943
    },
    {
      "epoch": 0.07828110898237725,
      "grad_norm": 0.4005994200706482,
      "learning_rate": 9.217188910176227e-06,
      "loss": 0.4098,
      "step": 4944
    },
    {
      "epoch": 0.07829694254001932,
      "grad_norm": 0.3218221068382263,
      "learning_rate": 9.217030574599808e-06,
      "loss": 0.1191,
      "step": 4945
    },
    {
      "epoch": 0.07831277609766138,
      "grad_norm": 0.3523876667022705,
      "learning_rate": 9.216872239023387e-06,
      "loss": 0.1925,
      "step": 4946
    },
    {
      "epoch": 0.07832860965530344,
      "grad_norm": 0.05579762905836105,
      "learning_rate": 9.216713903446966e-06,
      "loss": 0.006,
      "step": 4947
    },
    {
      "epoch": 0.07834444321294552,
      "grad_norm": 0.616655170917511,
      "learning_rate": 9.216555567870545e-06,
      "loss": 0.2501,
      "step": 4948
    },
    {
      "epoch": 0.07836027677058759,
      "grad_norm": 0.005548072978854179,
      "learning_rate": 9.216397232294126e-06,
      "loss": 0.0002,
      "step": 4949
    },
    {
      "epoch": 0.07837611032822965,
      "grad_norm": 0.17090579867362976,
      "learning_rate": 9.216238896717703e-06,
      "loss": 0.0276,
      "step": 4950
    },
    {
      "epoch": 0.07839194388587171,
      "grad_norm": 0.0012105535715818405,
      "learning_rate": 9.216080561141284e-06,
      "loss": 0.0,
      "step": 4951
    },
    {
      "epoch": 0.07840777744351378,
      "grad_norm": 0.0005377937341108918,
      "learning_rate": 9.215922225564863e-06,
      "loss": 0.0,
      "step": 4952
    },
    {
      "epoch": 0.07842361100115584,
      "grad_norm": 0.39740613102912903,
      "learning_rate": 9.215763889988442e-06,
      "loss": 0.125,
      "step": 4953
    },
    {
      "epoch": 0.07843944455879792,
      "grad_norm": 0.3401947319507599,
      "learning_rate": 9.215605554412021e-06,
      "loss": 0.4596,
      "step": 4954
    },
    {
      "epoch": 0.07845527811643999,
      "grad_norm": 0.5190455913543701,
      "learning_rate": 9.215447218835602e-06,
      "loss": 0.4286,
      "step": 4955
    },
    {
      "epoch": 0.07847111167408205,
      "grad_norm": 0.5142607092857361,
      "learning_rate": 9.21528888325918e-06,
      "loss": 0.2545,
      "step": 4956
    },
    {
      "epoch": 0.07848694523172411,
      "grad_norm": 0.47541362047195435,
      "learning_rate": 9.215130547682759e-06,
      "loss": 0.2179,
      "step": 4957
    },
    {
      "epoch": 0.07850277878936618,
      "grad_norm": 0.011996516957879066,
      "learning_rate": 9.21497221210634e-06,
      "loss": 0.0005,
      "step": 4958
    },
    {
      "epoch": 0.07851861234700824,
      "grad_norm": 6.847654731245711e-05,
      "learning_rate": 9.214813876529918e-06,
      "loss": 0.0,
      "step": 4959
    },
    {
      "epoch": 0.07853444590465032,
      "grad_norm": 0.01253659836947918,
      "learning_rate": 9.214655540953497e-06,
      "loss": 0.0006,
      "step": 4960
    },
    {
      "epoch": 0.07855027946229239,
      "grad_norm": 0.2711659073829651,
      "learning_rate": 9.214497205377077e-06,
      "loss": 0.0447,
      "step": 4961
    },
    {
      "epoch": 0.07856611301993445,
      "grad_norm": 0.25405409932136536,
      "learning_rate": 9.214338869800656e-06,
      "loss": 0.0925,
      "step": 4962
    },
    {
      "epoch": 0.07858194657757651,
      "grad_norm": 0.0005365134566091001,
      "learning_rate": 9.214180534224235e-06,
      "loss": 0.0,
      "step": 4963
    },
    {
      "epoch": 0.07859778013521858,
      "grad_norm": 0.09329601377248764,
      "learning_rate": 9.214022198647816e-06,
      "loss": 0.0097,
      "step": 4964
    },
    {
      "epoch": 0.07861361369286064,
      "grad_norm": 0.005492253229022026,
      "learning_rate": 9.213863863071395e-06,
      "loss": 0.0002,
      "step": 4965
    },
    {
      "epoch": 0.07862944725050272,
      "grad_norm": 0.11632100492715836,
      "learning_rate": 9.213705527494974e-06,
      "loss": 0.0372,
      "step": 4966
    },
    {
      "epoch": 0.07864528080814479,
      "grad_norm": 0.10257375240325928,
      "learning_rate": 9.213547191918553e-06,
      "loss": 0.0456,
      "step": 4967
    },
    {
      "epoch": 0.07866111436578685,
      "grad_norm": 0.41017287969589233,
      "learning_rate": 9.213388856342132e-06,
      "loss": 0.8127,
      "step": 4968
    },
    {
      "epoch": 0.07867694792342891,
      "grad_norm": 0.22515042126178741,
      "learning_rate": 9.213230520765711e-06,
      "loss": 0.1754,
      "step": 4969
    },
    {
      "epoch": 0.07869278148107098,
      "grad_norm": 0.3173486590385437,
      "learning_rate": 9.213072185189292e-06,
      "loss": 0.0966,
      "step": 4970
    },
    {
      "epoch": 0.07870861503871304,
      "grad_norm": 0.46715500950813293,
      "learning_rate": 9.21291384961287e-06,
      "loss": 0.3474,
      "step": 4971
    },
    {
      "epoch": 0.07872444859635512,
      "grad_norm": 0.12538078427314758,
      "learning_rate": 9.21275551403645e-06,
      "loss": 0.0604,
      "step": 4972
    },
    {
      "epoch": 0.07874028215399718,
      "grad_norm": 0.0030207715462893248,
      "learning_rate": 9.212597178460029e-06,
      "loss": 0.0001,
      "step": 4973
    },
    {
      "epoch": 0.07875611571163925,
      "grad_norm": 0.43029162287712097,
      "learning_rate": 9.212438842883608e-06,
      "loss": 0.5367,
      "step": 4974
    },
    {
      "epoch": 0.07877194926928131,
      "grad_norm": 0.34079235792160034,
      "learning_rate": 9.212280507307187e-06,
      "loss": 0.156,
      "step": 4975
    },
    {
      "epoch": 0.07878778282692338,
      "grad_norm": 0.008797692134976387,
      "learning_rate": 9.212122171730768e-06,
      "loss": 0.0002,
      "step": 4976
    },
    {
      "epoch": 0.07880361638456544,
      "grad_norm": 0.41926345229148865,
      "learning_rate": 9.211963836154347e-06,
      "loss": 0.2706,
      "step": 4977
    },
    {
      "epoch": 0.07881944994220752,
      "grad_norm": 0.19307591021060944,
      "learning_rate": 9.211805500577926e-06,
      "loss": 0.1262,
      "step": 4978
    },
    {
      "epoch": 0.07883528349984958,
      "grad_norm": 0.28478771448135376,
      "learning_rate": 9.211647165001505e-06,
      "loss": 0.4214,
      "step": 4979
    },
    {
      "epoch": 0.07885111705749165,
      "grad_norm": 0.021137695759534836,
      "learning_rate": 9.211488829425084e-06,
      "loss": 0.0007,
      "step": 4980
    },
    {
      "epoch": 0.07886695061513371,
      "grad_norm": 0.14608483016490936,
      "learning_rate": 9.211330493848663e-06,
      "loss": 0.0562,
      "step": 4981
    },
    {
      "epoch": 0.07888278417277578,
      "grad_norm": 0.22776386141777039,
      "learning_rate": 9.211172158272242e-06,
      "loss": 0.2213,
      "step": 4982
    },
    {
      "epoch": 0.07889861773041784,
      "grad_norm": 0.3258604407310486,
      "learning_rate": 9.211013822695823e-06,
      "loss": 0.3531,
      "step": 4983
    },
    {
      "epoch": 0.07891445128805992,
      "grad_norm": 0.20248863101005554,
      "learning_rate": 9.2108554871194e-06,
      "loss": 0.0866,
      "step": 4984
    },
    {
      "epoch": 0.07893028484570198,
      "grad_norm": 0.00013126057456247509,
      "learning_rate": 9.210697151542981e-06,
      "loss": 0.0,
      "step": 4985
    },
    {
      "epoch": 0.07894611840334405,
      "grad_norm": 0.22005529701709747,
      "learning_rate": 9.21053881596656e-06,
      "loss": 0.1498,
      "step": 4986
    },
    {
      "epoch": 0.07896195196098611,
      "grad_norm": 0.2607173025608063,
      "learning_rate": 9.21038048039014e-06,
      "loss": 0.2129,
      "step": 4987
    },
    {
      "epoch": 0.07897778551862818,
      "grad_norm": 0.24500976502895355,
      "learning_rate": 9.210222144813719e-06,
      "loss": 0.5317,
      "step": 4988
    },
    {
      "epoch": 0.07899361907627024,
      "grad_norm": 0.20827563107013702,
      "learning_rate": 9.2100638092373e-06,
      "loss": 0.0534,
      "step": 4989
    },
    {
      "epoch": 0.07900945263391232,
      "grad_norm": 0.360937237739563,
      "learning_rate": 9.209905473660877e-06,
      "loss": 0.1778,
      "step": 4990
    },
    {
      "epoch": 0.07902528619155438,
      "grad_norm": 0.2578868269920349,
      "learning_rate": 9.209747138084457e-06,
      "loss": 0.1234,
      "step": 4991
    },
    {
      "epoch": 0.07904111974919645,
      "grad_norm": 0.010676100850105286,
      "learning_rate": 9.209588802508037e-06,
      "loss": 0.0006,
      "step": 4992
    },
    {
      "epoch": 0.07905695330683851,
      "grad_norm": 0.023013757541775703,
      "learning_rate": 9.209430466931616e-06,
      "loss": 0.001,
      "step": 4993
    },
    {
      "epoch": 0.07907278686448058,
      "grad_norm": 0.2967606484889984,
      "learning_rate": 9.209272131355195e-06,
      "loss": 0.1438,
      "step": 4994
    },
    {
      "epoch": 0.07908862042212264,
      "grad_norm": 0.00011663527402561158,
      "learning_rate": 9.209113795778775e-06,
      "loss": 0.0,
      "step": 4995
    },
    {
      "epoch": 0.07910445397976472,
      "grad_norm": 0.18290646374225616,
      "learning_rate": 9.208955460202353e-06,
      "loss": 0.1125,
      "step": 4996
    },
    {
      "epoch": 0.07912028753740678,
      "grad_norm": 0.32303452491760254,
      "learning_rate": 9.208797124625934e-06,
      "loss": 0.2863,
      "step": 4997
    },
    {
      "epoch": 0.07913612109504885,
      "grad_norm": 1.6064708232879639,
      "learning_rate": 9.208638789049513e-06,
      "loss": 0.1304,
      "step": 4998
    },
    {
      "epoch": 0.07915195465269091,
      "grad_norm": 0.22026550769805908,
      "learning_rate": 9.208480453473092e-06,
      "loss": 0.1935,
      "step": 4999
    },
    {
      "epoch": 0.07916778821033298,
      "grad_norm": 0.24409860372543335,
      "learning_rate": 9.20832211789667e-06,
      "loss": 0.0793,
      "step": 5000
    },
    {
      "epoch": 0.07918362176797504,
      "grad_norm": 0.17006812989711761,
      "learning_rate": 9.20816378232025e-06,
      "loss": 0.1548,
      "step": 5001
    },
    {
      "epoch": 0.07919945532561712,
      "grad_norm": 0.22312912344932556,
      "learning_rate": 9.208005446743829e-06,
      "loss": 0.0887,
      "step": 5002
    },
    {
      "epoch": 0.07921528888325918,
      "grad_norm": 0.2760586440563202,
      "learning_rate": 9.20784711116741e-06,
      "loss": 0.1608,
      "step": 5003
    },
    {
      "epoch": 0.07923112244090125,
      "grad_norm": 0.19769784808158875,
      "learning_rate": 9.207688775590989e-06,
      "loss": 0.08,
      "step": 5004
    },
    {
      "epoch": 0.07924695599854331,
      "grad_norm": 0.4144383668899536,
      "learning_rate": 9.207530440014566e-06,
      "loss": 0.1991,
      "step": 5005
    },
    {
      "epoch": 0.07926278955618538,
      "grad_norm": 0.3514942228794098,
      "learning_rate": 9.207372104438147e-06,
      "loss": 0.7575,
      "step": 5006
    },
    {
      "epoch": 0.07927862311382744,
      "grad_norm": 0.488211065530777,
      "learning_rate": 9.207213768861726e-06,
      "loss": 0.1568,
      "step": 5007
    },
    {
      "epoch": 0.07929445667146952,
      "grad_norm": 0.4638679027557373,
      "learning_rate": 9.207055433285305e-06,
      "loss": 0.0693,
      "step": 5008
    },
    {
      "epoch": 0.07931029022911158,
      "grad_norm": 0.2323344349861145,
      "learning_rate": 9.206897097708884e-06,
      "loss": 0.3235,
      "step": 5009
    },
    {
      "epoch": 0.07932612378675365,
      "grad_norm": 0.0029896877240389585,
      "learning_rate": 9.206738762132465e-06,
      "loss": 0.0001,
      "step": 5010
    },
    {
      "epoch": 0.07934195734439571,
      "grad_norm": 0.1777004897594452,
      "learning_rate": 9.206580426556042e-06,
      "loss": 0.2901,
      "step": 5011
    },
    {
      "epoch": 0.07935779090203778,
      "grad_norm": 0.23425936698913574,
      "learning_rate": 9.206422090979623e-06,
      "loss": 0.2408,
      "step": 5012
    },
    {
      "epoch": 0.07937362445967984,
      "grad_norm": 0.19205357134342194,
      "learning_rate": 9.206263755403202e-06,
      "loss": 0.0961,
      "step": 5013
    },
    {
      "epoch": 0.07938945801732192,
      "grad_norm": 0.36000800132751465,
      "learning_rate": 9.206105419826781e-06,
      "loss": 0.4018,
      "step": 5014
    },
    {
      "epoch": 0.07940529157496398,
      "grad_norm": 0.23753145337104797,
      "learning_rate": 9.20594708425036e-06,
      "loss": 0.0834,
      "step": 5015
    },
    {
      "epoch": 0.07942112513260605,
      "grad_norm": 0.23573951423168182,
      "learning_rate": 9.205788748673941e-06,
      "loss": 0.1184,
      "step": 5016
    },
    {
      "epoch": 0.07943695869024811,
      "grad_norm": 0.29888418316841125,
      "learning_rate": 9.205630413097519e-06,
      "loss": 0.0271,
      "step": 5017
    },
    {
      "epoch": 0.07945279224789017,
      "grad_norm": 0.005061215255409479,
      "learning_rate": 9.2054720775211e-06,
      "loss": 0.0002,
      "step": 5018
    },
    {
      "epoch": 0.07946862580553224,
      "grad_norm": 0.24490132927894592,
      "learning_rate": 9.205313741944678e-06,
      "loss": 0.3059,
      "step": 5019
    },
    {
      "epoch": 0.07948445936317432,
      "grad_norm": 0.23014870285987854,
      "learning_rate": 9.205155406368258e-06,
      "loss": 0.0532,
      "step": 5020
    },
    {
      "epoch": 0.07950029292081638,
      "grad_norm": 0.01073627918958664,
      "learning_rate": 9.204997070791837e-06,
      "loss": 0.0001,
      "step": 5021
    },
    {
      "epoch": 0.07951612647845845,
      "grad_norm": 0.016757722944021225,
      "learning_rate": 9.204838735215417e-06,
      "loss": 0.0011,
      "step": 5022
    },
    {
      "epoch": 0.07953196003610051,
      "grad_norm": 0.0006005825125612319,
      "learning_rate": 9.204680399638995e-06,
      "loss": 0.0,
      "step": 5023
    },
    {
      "epoch": 0.07954779359374257,
      "grad_norm": 0.4690602421760559,
      "learning_rate": 9.204522064062576e-06,
      "loss": 0.0589,
      "step": 5024
    },
    {
      "epoch": 0.07956362715138464,
      "grad_norm": 0.013196941465139389,
      "learning_rate": 9.204363728486155e-06,
      "loss": 0.0007,
      "step": 5025
    },
    {
      "epoch": 0.07957946070902672,
      "grad_norm": 0.0027189950924366713,
      "learning_rate": 9.204205392909734e-06,
      "loss": 0.0001,
      "step": 5026
    },
    {
      "epoch": 0.07959529426666878,
      "grad_norm": 0.009736883454024792,
      "learning_rate": 9.204047057333313e-06,
      "loss": 0.0005,
      "step": 5027
    },
    {
      "epoch": 0.07961112782431085,
      "grad_norm": 0.28020215034484863,
      "learning_rate": 9.203888721756894e-06,
      "loss": 0.3835,
      "step": 5028
    },
    {
      "epoch": 0.07962696138195291,
      "grad_norm": 0.43708914518356323,
      "learning_rate": 9.203730386180471e-06,
      "loss": 0.2956,
      "step": 5029
    },
    {
      "epoch": 0.07964279493959497,
      "grad_norm": 0.022371571511030197,
      "learning_rate": 9.20357205060405e-06,
      "loss": 0.0013,
      "step": 5030
    },
    {
      "epoch": 0.07965862849723704,
      "grad_norm": 0.015801481902599335,
      "learning_rate": 9.20341371502763e-06,
      "loss": 0.0007,
      "step": 5031
    },
    {
      "epoch": 0.07967446205487912,
      "grad_norm": 0.42881667613983154,
      "learning_rate": 9.20325537945121e-06,
      "loss": 0.0108,
      "step": 5032
    },
    {
      "epoch": 0.07969029561252118,
      "grad_norm": 0.0003982737543992698,
      "learning_rate": 9.203097043874789e-06,
      "loss": 0.0,
      "step": 5033
    },
    {
      "epoch": 0.07970612917016325,
      "grad_norm": 0.011992927640676498,
      "learning_rate": 9.202938708298368e-06,
      "loss": 0.0005,
      "step": 5034
    },
    {
      "epoch": 0.07972196272780531,
      "grad_norm": 0.24582093954086304,
      "learning_rate": 9.202780372721947e-06,
      "loss": 0.1439,
      "step": 5035
    },
    {
      "epoch": 0.07973779628544737,
      "grad_norm": 0.5916411876678467,
      "learning_rate": 9.202622037145526e-06,
      "loss": 0.3285,
      "step": 5036
    },
    {
      "epoch": 0.07975362984308944,
      "grad_norm": 0.007859278470277786,
      "learning_rate": 9.202463701569107e-06,
      "loss": 0.0003,
      "step": 5037
    },
    {
      "epoch": 0.07976946340073152,
      "grad_norm": 4.134210757911205e-05,
      "learning_rate": 9.202305365992686e-06,
      "loss": 0.0,
      "step": 5038
    },
    {
      "epoch": 0.07978529695837358,
      "grad_norm": 0.3887452781200409,
      "learning_rate": 9.202147030416265e-06,
      "loss": 0.0903,
      "step": 5039
    },
    {
      "epoch": 0.07980113051601564,
      "grad_norm": 0.3458107113838196,
      "learning_rate": 9.201988694839844e-06,
      "loss": 0.0092,
      "step": 5040
    },
    {
      "epoch": 0.07981696407365771,
      "grad_norm": 0.4608345329761505,
      "learning_rate": 9.201830359263423e-06,
      "loss": 0.0692,
      "step": 5041
    },
    {
      "epoch": 0.07983279763129977,
      "grad_norm": 0.028546221554279327,
      "learning_rate": 9.201672023687002e-06,
      "loss": 0.0014,
      "step": 5042
    },
    {
      "epoch": 0.07984863118894184,
      "grad_norm": 0.37744930386543274,
      "learning_rate": 9.201513688110583e-06,
      "loss": 0.3815,
      "step": 5043
    },
    {
      "epoch": 0.07986446474658392,
      "grad_norm": 0.013292383402585983,
      "learning_rate": 9.201355352534162e-06,
      "loss": 0.0006,
      "step": 5044
    },
    {
      "epoch": 0.07988029830422598,
      "grad_norm": 0.007981165312230587,
      "learning_rate": 9.201197016957741e-06,
      "loss": 0.0003,
      "step": 5045
    },
    {
      "epoch": 0.07989613186186804,
      "grad_norm": 0.39281511306762695,
      "learning_rate": 9.20103868138132e-06,
      "loss": 0.1591,
      "step": 5046
    },
    {
      "epoch": 0.07991196541951011,
      "grad_norm": 0.12987977266311646,
      "learning_rate": 9.2008803458049e-06,
      "loss": 0.002,
      "step": 5047
    },
    {
      "epoch": 0.07992779897715217,
      "grad_norm": 0.2421666532754898,
      "learning_rate": 9.200722010228479e-06,
      "loss": 0.069,
      "step": 5048
    },
    {
      "epoch": 0.07994363253479424,
      "grad_norm": 0.2527317702770233,
      "learning_rate": 9.20056367465206e-06,
      "loss": 0.1945,
      "step": 5049
    },
    {
      "epoch": 0.07995946609243632,
      "grad_norm": 0.4304102063179016,
      "learning_rate": 9.200405339075638e-06,
      "loss": 0.2441,
      "step": 5050
    },
    {
      "epoch": 0.07997529965007838,
      "grad_norm": 0.0076143499463796616,
      "learning_rate": 9.200247003499217e-06,
      "loss": 0.0003,
      "step": 5051
    },
    {
      "epoch": 0.07999113320772044,
      "grad_norm": 0.5141039490699768,
      "learning_rate": 9.200088667922797e-06,
      "loss": 0.1758,
      "step": 5052
    },
    {
      "epoch": 0.08000696676536251,
      "grad_norm": 0.42807894945144653,
      "learning_rate": 9.199930332346376e-06,
      "loss": 0.5503,
      "step": 5053
    },
    {
      "epoch": 0.08002280032300457,
      "grad_norm": 0.233133003115654,
      "learning_rate": 9.199771996769955e-06,
      "loss": 0.1039,
      "step": 5054
    },
    {
      "epoch": 0.08003863388064664,
      "grad_norm": 0.4780886471271515,
      "learning_rate": 9.199613661193534e-06,
      "loss": 0.1954,
      "step": 5055
    },
    {
      "epoch": 0.08005446743828872,
      "grad_norm": 0.2320072203874588,
      "learning_rate": 9.199455325617115e-06,
      "loss": 0.1192,
      "step": 5056
    },
    {
      "epoch": 0.08007030099593078,
      "grad_norm": 0.181627556681633,
      "learning_rate": 9.199296990040692e-06,
      "loss": 0.0874,
      "step": 5057
    },
    {
      "epoch": 0.08008613455357284,
      "grad_norm": 0.6475256681442261,
      "learning_rate": 9.199138654464273e-06,
      "loss": 0.2114,
      "step": 5058
    },
    {
      "epoch": 0.08010196811121491,
      "grad_norm": 0.0024975910782814026,
      "learning_rate": 9.198980318887852e-06,
      "loss": 0.0001,
      "step": 5059
    },
    {
      "epoch": 0.08011780166885697,
      "grad_norm": 0.16291090846061707,
      "learning_rate": 9.198821983311431e-06,
      "loss": 0.0446,
      "step": 5060
    },
    {
      "epoch": 0.08013363522649904,
      "grad_norm": 0.2782640755176544,
      "learning_rate": 9.19866364773501e-06,
      "loss": 0.2273,
      "step": 5061
    },
    {
      "epoch": 0.08014946878414111,
      "grad_norm": 0.36320286989212036,
      "learning_rate": 9.19850531215859e-06,
      "loss": 0.3947,
      "step": 5062
    },
    {
      "epoch": 0.08016530234178318,
      "grad_norm": 0.09199587255716324,
      "learning_rate": 9.198346976582168e-06,
      "loss": 0.0035,
      "step": 5063
    },
    {
      "epoch": 0.08018113589942524,
      "grad_norm": 0.2406850904226303,
      "learning_rate": 9.198188641005749e-06,
      "loss": 0.1468,
      "step": 5064
    },
    {
      "epoch": 0.08019696945706731,
      "grad_norm": 0.003890024498105049,
      "learning_rate": 9.198030305429328e-06,
      "loss": 0.0001,
      "step": 5065
    },
    {
      "epoch": 0.08021280301470937,
      "grad_norm": 0.38835880160331726,
      "learning_rate": 9.197871969852907e-06,
      "loss": 0.2078,
      "step": 5066
    },
    {
      "epoch": 0.08022863657235144,
      "grad_norm": 0.1289464235305786,
      "learning_rate": 9.197713634276486e-06,
      "loss": 0.0565,
      "step": 5067
    },
    {
      "epoch": 0.08024447012999351,
      "grad_norm": 0.11282406747341156,
      "learning_rate": 9.197555298700065e-06,
      "loss": 0.0375,
      "step": 5068
    },
    {
      "epoch": 0.08026030368763558,
      "grad_norm": 0.267997682094574,
      "learning_rate": 9.197396963123644e-06,
      "loss": 0.6513,
      "step": 5069
    },
    {
      "epoch": 0.08027613724527764,
      "grad_norm": 0.21306094527244568,
      "learning_rate": 9.197238627547225e-06,
      "loss": 0.1786,
      "step": 5070
    },
    {
      "epoch": 0.08029197080291971,
      "grad_norm": 0.512269914150238,
      "learning_rate": 9.197080291970804e-06,
      "loss": 0.1276,
      "step": 5071
    },
    {
      "epoch": 0.08030780436056177,
      "grad_norm": 0.28651347756385803,
      "learning_rate": 9.196921956394383e-06,
      "loss": 0.2195,
      "step": 5072
    },
    {
      "epoch": 0.08032363791820384,
      "grad_norm": 0.3579435348510742,
      "learning_rate": 9.196763620817962e-06,
      "loss": 0.2463,
      "step": 5073
    },
    {
      "epoch": 0.08033947147584591,
      "grad_norm": 0.34250015020370483,
      "learning_rate": 9.196605285241541e-06,
      "loss": 0.1601,
      "step": 5074
    },
    {
      "epoch": 0.08035530503348798,
      "grad_norm": 0.18570898473262787,
      "learning_rate": 9.19644694966512e-06,
      "loss": 0.0569,
      "step": 5075
    },
    {
      "epoch": 0.08037113859113004,
      "grad_norm": 0.23237504065036774,
      "learning_rate": 9.196288614088701e-06,
      "loss": 0.091,
      "step": 5076
    },
    {
      "epoch": 0.0803869721487721,
      "grad_norm": 0.2820090055465698,
      "learning_rate": 9.19613027851228e-06,
      "loss": 0.2317,
      "step": 5077
    },
    {
      "epoch": 0.08040280570641417,
      "grad_norm": 0.9725014567375183,
      "learning_rate": 9.195971942935858e-06,
      "loss": 0.0639,
      "step": 5078
    },
    {
      "epoch": 0.08041863926405624,
      "grad_norm": 0.19200719892978668,
      "learning_rate": 9.195813607359438e-06,
      "loss": 0.0125,
      "step": 5079
    },
    {
      "epoch": 0.08043447282169831,
      "grad_norm": 0.2592640817165375,
      "learning_rate": 9.195655271783018e-06,
      "loss": 0.0368,
      "step": 5080
    },
    {
      "epoch": 0.08045030637934038,
      "grad_norm": 0.4496266543865204,
      "learning_rate": 9.195496936206597e-06,
      "loss": 0.0591,
      "step": 5081
    },
    {
      "epoch": 0.08046613993698244,
      "grad_norm": 0.02710157446563244,
      "learning_rate": 9.195338600630176e-06,
      "loss": 0.0019,
      "step": 5082
    },
    {
      "epoch": 0.0804819734946245,
      "grad_norm": 0.19393889605998993,
      "learning_rate": 9.195180265053756e-06,
      "loss": 0.1478,
      "step": 5083
    },
    {
      "epoch": 0.08049780705226657,
      "grad_norm": 0.3316037952899933,
      "learning_rate": 9.195021929477334e-06,
      "loss": 0.7018,
      "step": 5084
    },
    {
      "epoch": 0.08051364060990863,
      "grad_norm": 0.057526737451553345,
      "learning_rate": 9.194863593900915e-06,
      "loss": 0.0037,
      "step": 5085
    },
    {
      "epoch": 0.08052947416755071,
      "grad_norm": 0.22657127678394318,
      "learning_rate": 9.194705258324494e-06,
      "loss": 0.1052,
      "step": 5086
    },
    {
      "epoch": 0.08054530772519278,
      "grad_norm": 6.489836960099638e-05,
      "learning_rate": 9.194546922748073e-06,
      "loss": 0.0,
      "step": 5087
    },
    {
      "epoch": 0.08056114128283484,
      "grad_norm": 0.4263940453529358,
      "learning_rate": 9.194388587171652e-06,
      "loss": 0.3575,
      "step": 5088
    },
    {
      "epoch": 0.0805769748404769,
      "grad_norm": 0.00013472288264892995,
      "learning_rate": 9.194230251595233e-06,
      "loss": 0.0,
      "step": 5089
    },
    {
      "epoch": 0.08059280839811897,
      "grad_norm": 0.0032100528478622437,
      "learning_rate": 9.19407191601881e-06,
      "loss": 0.0001,
      "step": 5090
    },
    {
      "epoch": 0.08060864195576103,
      "grad_norm": 0.511999249458313,
      "learning_rate": 9.19391358044239e-06,
      "loss": 0.0628,
      "step": 5091
    },
    {
      "epoch": 0.08062447551340311,
      "grad_norm": 0.4737358093261719,
      "learning_rate": 9.19375524486597e-06,
      "loss": 0.1133,
      "step": 5092
    },
    {
      "epoch": 0.08064030907104518,
      "grad_norm": 0.008233150467276573,
      "learning_rate": 9.193596909289549e-06,
      "loss": 0.0004,
      "step": 5093
    },
    {
      "epoch": 0.08065614262868724,
      "grad_norm": 0.9437735080718994,
      "learning_rate": 9.193438573713128e-06,
      "loss": 0.4086,
      "step": 5094
    },
    {
      "epoch": 0.0806719761863293,
      "grad_norm": 0.5479037165641785,
      "learning_rate": 9.193280238136709e-06,
      "loss": 0.4793,
      "step": 5095
    },
    {
      "epoch": 0.08068780974397137,
      "grad_norm": 0.00012166875967523083,
      "learning_rate": 9.193121902560286e-06,
      "loss": 0.0,
      "step": 5096
    },
    {
      "epoch": 0.08070364330161343,
      "grad_norm": 0.3023897707462311,
      "learning_rate": 9.192963566983867e-06,
      "loss": 0.1909,
      "step": 5097
    },
    {
      "epoch": 0.08071947685925551,
      "grad_norm": 0.5125902891159058,
      "learning_rate": 9.192805231407446e-06,
      "loss": 0.1925,
      "step": 5098
    },
    {
      "epoch": 0.08073531041689758,
      "grad_norm": 1.4834308624267578,
      "learning_rate": 9.192646895831025e-06,
      "loss": 0.0847,
      "step": 5099
    },
    {
      "epoch": 0.08075114397453964,
      "grad_norm": 0.17431485652923584,
      "learning_rate": 9.192488560254604e-06,
      "loss": 0.0529,
      "step": 5100
    },
    {
      "epoch": 0.0807669775321817,
      "grad_norm": 0.00012133087875554338,
      "learning_rate": 9.192330224678183e-06,
      "loss": 0.0,
      "step": 5101
    },
    {
      "epoch": 0.08078281108982377,
      "grad_norm": 0.19282905757427216,
      "learning_rate": 9.192171889101762e-06,
      "loss": 0.0875,
      "step": 5102
    },
    {
      "epoch": 0.08079864464746583,
      "grad_norm": 0.5015248656272888,
      "learning_rate": 9.192013553525341e-06,
      "loss": 0.4363,
      "step": 5103
    },
    {
      "epoch": 0.08081447820510791,
      "grad_norm": 0.25570622086524963,
      "learning_rate": 9.191855217948922e-06,
      "loss": 0.0454,
      "step": 5104
    },
    {
      "epoch": 0.08083031176274998,
      "grad_norm": 0.013895408250391483,
      "learning_rate": 9.191696882372501e-06,
      "loss": 0.0007,
      "step": 5105
    },
    {
      "epoch": 0.08084614532039204,
      "grad_norm": 0.002926388755440712,
      "learning_rate": 9.19153854679608e-06,
      "loss": 0.0001,
      "step": 5106
    },
    {
      "epoch": 0.0808619788780341,
      "grad_norm": 0.2670229971408844,
      "learning_rate": 9.19138021121966e-06,
      "loss": 0.1208,
      "step": 5107
    },
    {
      "epoch": 0.08087781243567617,
      "grad_norm": 0.0018322065006941557,
      "learning_rate": 9.191221875643239e-06,
      "loss": 0.0,
      "step": 5108
    },
    {
      "epoch": 0.08089364599331823,
      "grad_norm": 0.18332654237747192,
      "learning_rate": 9.191063540066818e-06,
      "loss": 0.0573,
      "step": 5109
    },
    {
      "epoch": 0.08090947955096031,
      "grad_norm": 0.009854002855718136,
      "learning_rate": 9.190905204490398e-06,
      "loss": 0.0006,
      "step": 5110
    },
    {
      "epoch": 0.08092531310860238,
      "grad_norm": 0.5720303654670715,
      "learning_rate": 9.190746868913977e-06,
      "loss": 0.6632,
      "step": 5111
    },
    {
      "epoch": 0.08094114666624444,
      "grad_norm": 1.767014503479004,
      "learning_rate": 9.190588533337557e-06,
      "loss": 0.1847,
      "step": 5112
    },
    {
      "epoch": 0.0809569802238865,
      "grad_norm": 0.04876630753278732,
      "learning_rate": 9.190430197761136e-06,
      "loss": 0.0012,
      "step": 5113
    },
    {
      "epoch": 0.08097281378152857,
      "grad_norm": 0.4266219735145569,
      "learning_rate": 9.190271862184715e-06,
      "loss": 0.2675,
      "step": 5114
    },
    {
      "epoch": 0.08098864733917063,
      "grad_norm": 0.5271288752555847,
      "learning_rate": 9.190113526608294e-06,
      "loss": 0.1056,
      "step": 5115
    },
    {
      "epoch": 0.08100448089681271,
      "grad_norm": 0.3612763285636902,
      "learning_rate": 9.189955191031875e-06,
      "loss": 0.8375,
      "step": 5116
    },
    {
      "epoch": 0.08102031445445478,
      "grad_norm": 0.000627379457000643,
      "learning_rate": 9.189796855455454e-06,
      "loss": 0.0,
      "step": 5117
    },
    {
      "epoch": 0.08103614801209684,
      "grad_norm": 0.0005131929647177458,
      "learning_rate": 9.189638519879033e-06,
      "loss": 0.0,
      "step": 5118
    },
    {
      "epoch": 0.0810519815697389,
      "grad_norm": 0.21389606595039368,
      "learning_rate": 9.189480184302612e-06,
      "loss": 0.6233,
      "step": 5119
    },
    {
      "epoch": 0.08106781512738097,
      "grad_norm": 0.23662270605564117,
      "learning_rate": 9.189321848726191e-06,
      "loss": 0.0894,
      "step": 5120
    },
    {
      "epoch": 0.08108364868502303,
      "grad_norm": 0.1405160129070282,
      "learning_rate": 9.18916351314977e-06,
      "loss": 0.0054,
      "step": 5121
    },
    {
      "epoch": 0.08109948224266511,
      "grad_norm": 0.33843928575515747,
      "learning_rate": 9.18900517757335e-06,
      "loss": 0.2047,
      "step": 5122
    },
    {
      "epoch": 0.08111531580030718,
      "grad_norm": 0.12181027233600616,
      "learning_rate": 9.18884684199693e-06,
      "loss": 0.0471,
      "step": 5123
    },
    {
      "epoch": 0.08113114935794924,
      "grad_norm": 0.36126473546028137,
      "learning_rate": 9.188688506420509e-06,
      "loss": 0.0472,
      "step": 5124
    },
    {
      "epoch": 0.0811469829155913,
      "grad_norm": 0.01858753338456154,
      "learning_rate": 9.188530170844088e-06,
      "loss": 0.0009,
      "step": 5125
    },
    {
      "epoch": 0.08116281647323337,
      "grad_norm": 0.0005667706136591733,
      "learning_rate": 9.188371835267667e-06,
      "loss": 0.0,
      "step": 5126
    },
    {
      "epoch": 0.08117865003087543,
      "grad_norm": 0.2058967649936676,
      "learning_rate": 9.188213499691246e-06,
      "loss": 0.1361,
      "step": 5127
    },
    {
      "epoch": 0.08119448358851751,
      "grad_norm": 0.11987142264842987,
      "learning_rate": 9.188055164114825e-06,
      "loss": 0.0226,
      "step": 5128
    },
    {
      "epoch": 0.08121031714615957,
      "grad_norm": 0.37866637110710144,
      "learning_rate": 9.187896828538406e-06,
      "loss": 0.6411,
      "step": 5129
    },
    {
      "epoch": 0.08122615070380164,
      "grad_norm": 0.004758932162076235,
      "learning_rate": 9.187738492961983e-06,
      "loss": 0.0002,
      "step": 5130
    },
    {
      "epoch": 0.0812419842614437,
      "grad_norm": 0.5042507648468018,
      "learning_rate": 9.187580157385564e-06,
      "loss": 0.241,
      "step": 5131
    },
    {
      "epoch": 0.08125781781908577,
      "grad_norm": 0.00016371370293200016,
      "learning_rate": 9.187421821809143e-06,
      "loss": 0.0,
      "step": 5132
    },
    {
      "epoch": 0.08127365137672783,
      "grad_norm": 0.7319903373718262,
      "learning_rate": 9.187263486232722e-06,
      "loss": 0.3551,
      "step": 5133
    },
    {
      "epoch": 0.08128948493436991,
      "grad_norm": 0.20213784277439117,
      "learning_rate": 9.187105150656301e-06,
      "loss": 0.3006,
      "step": 5134
    },
    {
      "epoch": 0.08130531849201197,
      "grad_norm": 0.019276408478617668,
      "learning_rate": 9.18694681507988e-06,
      "loss": 0.0008,
      "step": 5135
    },
    {
      "epoch": 0.08132115204965404,
      "grad_norm": 0.12485352903604507,
      "learning_rate": 9.18678847950346e-06,
      "loss": 0.0209,
      "step": 5136
    },
    {
      "epoch": 0.0813369856072961,
      "grad_norm": 0.37277457118034363,
      "learning_rate": 9.18663014392704e-06,
      "loss": 0.5525,
      "step": 5137
    },
    {
      "epoch": 0.08135281916493817,
      "grad_norm": 0.20262983441352844,
      "learning_rate": 9.18647180835062e-06,
      "loss": 0.1493,
      "step": 5138
    },
    {
      "epoch": 0.08136865272258023,
      "grad_norm": 0.4308881163597107,
      "learning_rate": 9.186313472774198e-06,
      "loss": 0.0169,
      "step": 5139
    },
    {
      "epoch": 0.08138448628022231,
      "grad_norm": 0.2526066303253174,
      "learning_rate": 9.186155137197778e-06,
      "loss": 0.1232,
      "step": 5140
    },
    {
      "epoch": 0.08140031983786437,
      "grad_norm": 0.23132160305976868,
      "learning_rate": 9.185996801621357e-06,
      "loss": 0.1463,
      "step": 5141
    },
    {
      "epoch": 0.08141615339550644,
      "grad_norm": 0.1877426654100418,
      "learning_rate": 9.185838466044936e-06,
      "loss": 0.0607,
      "step": 5142
    },
    {
      "epoch": 0.0814319869531485,
      "grad_norm": 0.47587648034095764,
      "learning_rate": 9.185680130468516e-06,
      "loss": 0.3557,
      "step": 5143
    },
    {
      "epoch": 0.08144782051079057,
      "grad_norm": 0.3022184371948242,
      "learning_rate": 9.185521794892096e-06,
      "loss": 0.17,
      "step": 5144
    },
    {
      "epoch": 0.08146365406843263,
      "grad_norm": 0.07277040928602219,
      "learning_rate": 9.185363459315675e-06,
      "loss": 0.0091,
      "step": 5145
    },
    {
      "epoch": 0.08147948762607471,
      "grad_norm": 0.3421320915222168,
      "learning_rate": 9.185205123739254e-06,
      "loss": 0.5716,
      "step": 5146
    },
    {
      "epoch": 0.08149532118371677,
      "grad_norm": 0.11237204074859619,
      "learning_rate": 9.185046788162833e-06,
      "loss": 0.0336,
      "step": 5147
    },
    {
      "epoch": 0.08151115474135884,
      "grad_norm": 0.4280300736427307,
      "learning_rate": 9.184888452586412e-06,
      "loss": 0.0167,
      "step": 5148
    },
    {
      "epoch": 0.0815269882990009,
      "grad_norm": 0.04584366828203201,
      "learning_rate": 9.184730117009991e-06,
      "loss": 0.0004,
      "step": 5149
    },
    {
      "epoch": 0.08154282185664297,
      "grad_norm": 0.06510046869516373,
      "learning_rate": 9.184571781433572e-06,
      "loss": 0.005,
      "step": 5150
    },
    {
      "epoch": 0.08155865541428503,
      "grad_norm": 0.1898120790719986,
      "learning_rate": 9.184413445857149e-06,
      "loss": 0.0566,
      "step": 5151
    },
    {
      "epoch": 0.08157448897192711,
      "grad_norm": 0.0002233566192444414,
      "learning_rate": 9.18425511028073e-06,
      "loss": 0.0,
      "step": 5152
    },
    {
      "epoch": 0.08159032252956917,
      "grad_norm": 0.21226592361927032,
      "learning_rate": 9.184096774704309e-06,
      "loss": 0.0878,
      "step": 5153
    },
    {
      "epoch": 0.08160615608721124,
      "grad_norm": 0.324924111366272,
      "learning_rate": 9.183938439127888e-06,
      "loss": 0.1278,
      "step": 5154
    },
    {
      "epoch": 0.0816219896448533,
      "grad_norm": 0.48888126015663147,
      "learning_rate": 9.183780103551467e-06,
      "loss": 0.1349,
      "step": 5155
    },
    {
      "epoch": 0.08163782320249537,
      "grad_norm": 0.4157557189464569,
      "learning_rate": 9.183621767975048e-06,
      "loss": 0.1055,
      "step": 5156
    },
    {
      "epoch": 0.08165365676013743,
      "grad_norm": 0.23561722040176392,
      "learning_rate": 9.183463432398625e-06,
      "loss": 0.1484,
      "step": 5157
    },
    {
      "epoch": 0.08166949031777951,
      "grad_norm": 0.11116344481706619,
      "learning_rate": 9.183305096822206e-06,
      "loss": 0.0147,
      "step": 5158
    },
    {
      "epoch": 0.08168532387542157,
      "grad_norm": 0.011766061186790466,
      "learning_rate": 9.183146761245785e-06,
      "loss": 0.0007,
      "step": 5159
    },
    {
      "epoch": 0.08170115743306364,
      "grad_norm": 0.0067344652488827705,
      "learning_rate": 9.182988425669364e-06,
      "loss": 0.0004,
      "step": 5160
    },
    {
      "epoch": 0.0817169909907057,
      "grad_norm": 0.11528553813695908,
      "learning_rate": 9.182830090092943e-06,
      "loss": 0.031,
      "step": 5161
    },
    {
      "epoch": 0.08173282454834777,
      "grad_norm": 0.26181888580322266,
      "learning_rate": 9.182671754516524e-06,
      "loss": 0.1338,
      "step": 5162
    },
    {
      "epoch": 0.08174865810598983,
      "grad_norm": 0.3406796157360077,
      "learning_rate": 9.182513418940101e-06,
      "loss": 0.1142,
      "step": 5163
    },
    {
      "epoch": 0.08176449166363191,
      "grad_norm": 0.020098160952329636,
      "learning_rate": 9.182355083363682e-06,
      "loss": 0.0012,
      "step": 5164
    },
    {
      "epoch": 0.08178032522127397,
      "grad_norm": 0.22234377264976501,
      "learning_rate": 9.182196747787261e-06,
      "loss": 0.0697,
      "step": 5165
    },
    {
      "epoch": 0.08179615877891604,
      "grad_norm": 0.08917063474655151,
      "learning_rate": 9.18203841221084e-06,
      "loss": 0.0046,
      "step": 5166
    },
    {
      "epoch": 0.0818119923365581,
      "grad_norm": 0.29910191893577576,
      "learning_rate": 9.18188007663442e-06,
      "loss": 0.1483,
      "step": 5167
    },
    {
      "epoch": 0.08182782589420017,
      "grad_norm": 0.5348455905914307,
      "learning_rate": 9.181721741058e-06,
      "loss": 1.0122,
      "step": 5168
    },
    {
      "epoch": 0.08184365945184223,
      "grad_norm": 0.11550173908472061,
      "learning_rate": 9.181563405481578e-06,
      "loss": 0.0742,
      "step": 5169
    },
    {
      "epoch": 0.08185949300948431,
      "grad_norm": 0.25063586235046387,
      "learning_rate": 9.181405069905158e-06,
      "loss": 0.1814,
      "step": 5170
    },
    {
      "epoch": 0.08187532656712637,
      "grad_norm": 0.27974772453308105,
      "learning_rate": 9.181246734328737e-06,
      "loss": 0.1981,
      "step": 5171
    },
    {
      "epoch": 0.08189116012476844,
      "grad_norm": 0.2994391918182373,
      "learning_rate": 9.181088398752317e-06,
      "loss": 0.1693,
      "step": 5172
    },
    {
      "epoch": 0.0819069936824105,
      "grad_norm": 0.008907495997846127,
      "learning_rate": 9.180930063175896e-06,
      "loss": 0.0005,
      "step": 5173
    },
    {
      "epoch": 0.08192282724005256,
      "grad_norm": 0.8137582540512085,
      "learning_rate": 9.180771727599475e-06,
      "loss": 0.1777,
      "step": 5174
    },
    {
      "epoch": 0.08193866079769463,
      "grad_norm": 0.19307248294353485,
      "learning_rate": 9.180613392023054e-06,
      "loss": 0.0054,
      "step": 5175
    },
    {
      "epoch": 0.08195449435533671,
      "grad_norm": 0.3194161057472229,
      "learning_rate": 9.180455056446633e-06,
      "loss": 0.224,
      "step": 5176
    },
    {
      "epoch": 0.08197032791297877,
      "grad_norm": 0.22355785965919495,
      "learning_rate": 9.180296720870214e-06,
      "loss": 0.1654,
      "step": 5177
    },
    {
      "epoch": 0.08198616147062084,
      "grad_norm": 0.030798157677054405,
      "learning_rate": 9.180138385293793e-06,
      "loss": 0.0014,
      "step": 5178
    },
    {
      "epoch": 0.0820019950282629,
      "grad_norm": 0.4696160852909088,
      "learning_rate": 9.179980049717372e-06,
      "loss": 0.1462,
      "step": 5179
    },
    {
      "epoch": 0.08201782858590496,
      "grad_norm": 0.31950855255126953,
      "learning_rate": 9.179821714140951e-06,
      "loss": 0.1217,
      "step": 5180
    },
    {
      "epoch": 0.08203366214354703,
      "grad_norm": 0.4637540578842163,
      "learning_rate": 9.17966337856453e-06,
      "loss": 0.2054,
      "step": 5181
    },
    {
      "epoch": 0.0820494957011891,
      "grad_norm": 0.3568383753299713,
      "learning_rate": 9.179505042988109e-06,
      "loss": 0.1503,
      "step": 5182
    },
    {
      "epoch": 0.08206532925883117,
      "grad_norm": 0.0047632744535803795,
      "learning_rate": 9.17934670741169e-06,
      "loss": 0.0002,
      "step": 5183
    },
    {
      "epoch": 0.08208116281647324,
      "grad_norm": 0.01953541859984398,
      "learning_rate": 9.179188371835269e-06,
      "loss": 0.0013,
      "step": 5184
    },
    {
      "epoch": 0.0820969963741153,
      "grad_norm": 0.15095731616020203,
      "learning_rate": 9.179030036258848e-06,
      "loss": 0.0671,
      "step": 5185
    },
    {
      "epoch": 0.08211282993175736,
      "grad_norm": 0.020506978034973145,
      "learning_rate": 9.178871700682427e-06,
      "loss": 0.0008,
      "step": 5186
    },
    {
      "epoch": 0.08212866348939943,
      "grad_norm": 0.0002826412965077907,
      "learning_rate": 9.178713365106006e-06,
      "loss": 0.0,
      "step": 5187
    },
    {
      "epoch": 0.0821444970470415,
      "grad_norm": 0.5369424819946289,
      "learning_rate": 9.178555029529585e-06,
      "loss": 0.276,
      "step": 5188
    },
    {
      "epoch": 0.08216033060468357,
      "grad_norm": 0.2732592523097992,
      "learning_rate": 9.178396693953166e-06,
      "loss": 0.1448,
      "step": 5189
    },
    {
      "epoch": 0.08217616416232564,
      "grad_norm": 0.012751275673508644,
      "learning_rate": 9.178238358376745e-06,
      "loss": 0.0005,
      "step": 5190
    },
    {
      "epoch": 0.0821919977199677,
      "grad_norm": 0.16383236646652222,
      "learning_rate": 9.178080022800324e-06,
      "loss": 0.0615,
      "step": 5191
    },
    {
      "epoch": 0.08220783127760976,
      "grad_norm": 0.49103084206581116,
      "learning_rate": 9.177921687223903e-06,
      "loss": 0.1103,
      "step": 5192
    },
    {
      "epoch": 0.08222366483525183,
      "grad_norm": 0.3802379071712494,
      "learning_rate": 9.177763351647482e-06,
      "loss": 0.1858,
      "step": 5193
    },
    {
      "epoch": 0.0822394983928939,
      "grad_norm": 0.01735750399529934,
      "learning_rate": 9.177605016071061e-06,
      "loss": 0.0008,
      "step": 5194
    },
    {
      "epoch": 0.08225533195053597,
      "grad_norm": 0.20185698568820953,
      "learning_rate": 9.177446680494642e-06,
      "loss": 0.1076,
      "step": 5195
    },
    {
      "epoch": 0.08227116550817803,
      "grad_norm": 0.028790311887860298,
      "learning_rate": 9.17728834491822e-06,
      "loss": 0.0015,
      "step": 5196
    },
    {
      "epoch": 0.0822869990658201,
      "grad_norm": 0.3399122357368469,
      "learning_rate": 9.177130009341799e-06,
      "loss": 0.1895,
      "step": 5197
    },
    {
      "epoch": 0.08230283262346216,
      "grad_norm": 0.2504417598247528,
      "learning_rate": 9.17697167376538e-06,
      "loss": 0.0507,
      "step": 5198
    },
    {
      "epoch": 0.08231866618110423,
      "grad_norm": 0.21630819141864777,
      "learning_rate": 9.176813338188959e-06,
      "loss": 0.0546,
      "step": 5199
    },
    {
      "epoch": 0.0823344997387463,
      "grad_norm": 9.596840391168371e-05,
      "learning_rate": 9.176655002612538e-06,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 0.08235033329638837,
      "grad_norm": 0.2900415360927582,
      "learning_rate": 9.176496667036117e-06,
      "loss": 0.1446,
      "step": 5201
    },
    {
      "epoch": 0.08236616685403043,
      "grad_norm": 0.37496358156204224,
      "learning_rate": 9.176338331459696e-06,
      "loss": 0.7114,
      "step": 5202
    },
    {
      "epoch": 0.0823820004116725,
      "grad_norm": 0.00744239054620266,
      "learning_rate": 9.176179995883275e-06,
      "loss": 0.0003,
      "step": 5203
    },
    {
      "epoch": 0.08239783396931456,
      "grad_norm": 0.14190375804901123,
      "learning_rate": 9.176021660306856e-06,
      "loss": 0.002,
      "step": 5204
    },
    {
      "epoch": 0.08241366752695663,
      "grad_norm": 0.2807164192199707,
      "learning_rate": 9.175863324730435e-06,
      "loss": 0.1423,
      "step": 5205
    },
    {
      "epoch": 0.0824295010845987,
      "grad_norm": 0.2764241099357605,
      "learning_rate": 9.175704989154014e-06,
      "loss": 0.2784,
      "step": 5206
    },
    {
      "epoch": 0.08244533464224077,
      "grad_norm": 0.5774295926094055,
      "learning_rate": 9.175546653577593e-06,
      "loss": 0.0123,
      "step": 5207
    },
    {
      "epoch": 0.08246116819988283,
      "grad_norm": 0.09629764407873154,
      "learning_rate": 9.175388318001172e-06,
      "loss": 0.0111,
      "step": 5208
    },
    {
      "epoch": 0.0824770017575249,
      "grad_norm": 0.013060083612799644,
      "learning_rate": 9.175229982424751e-06,
      "loss": 0.0007,
      "step": 5209
    },
    {
      "epoch": 0.08249283531516696,
      "grad_norm": 0.1231154352426529,
      "learning_rate": 9.175071646848332e-06,
      "loss": 0.0496,
      "step": 5210
    },
    {
      "epoch": 0.08250866887280903,
      "grad_norm": 0.021681733429431915,
      "learning_rate": 9.17491331127191e-06,
      "loss": 0.0013,
      "step": 5211
    },
    {
      "epoch": 0.0825245024304511,
      "grad_norm": 0.35716819763183594,
      "learning_rate": 9.17475497569549e-06,
      "loss": 0.054,
      "step": 5212
    },
    {
      "epoch": 0.08254033598809317,
      "grad_norm": 0.28735318779945374,
      "learning_rate": 9.174596640119069e-06,
      "loss": 0.2183,
      "step": 5213
    },
    {
      "epoch": 0.08255616954573523,
      "grad_norm": 0.19302792847156525,
      "learning_rate": 9.174438304542648e-06,
      "loss": 0.0311,
      "step": 5214
    },
    {
      "epoch": 0.0825720031033773,
      "grad_norm": 0.16586323082447052,
      "learning_rate": 9.174279968966227e-06,
      "loss": 0.0547,
      "step": 5215
    },
    {
      "epoch": 0.08258783666101936,
      "grad_norm": 0.05270086228847504,
      "learning_rate": 9.174121633389808e-06,
      "loss": 0.0028,
      "step": 5216
    },
    {
      "epoch": 0.08260367021866143,
      "grad_norm": 0.011568454094231129,
      "learning_rate": 9.173963297813387e-06,
      "loss": 0.0006,
      "step": 5217
    },
    {
      "epoch": 0.0826195037763035,
      "grad_norm": 0.05549980327486992,
      "learning_rate": 9.173804962236966e-06,
      "loss": 0.0051,
      "step": 5218
    },
    {
      "epoch": 0.08263533733394557,
      "grad_norm": 0.2343611717224121,
      "learning_rate": 9.173646626660545e-06,
      "loss": 0.0971,
      "step": 5219
    },
    {
      "epoch": 0.08265117089158763,
      "grad_norm": 0.24256499111652374,
      "learning_rate": 9.173488291084124e-06,
      "loss": 0.1066,
      "step": 5220
    },
    {
      "epoch": 0.0826670044492297,
      "grad_norm": 0.0003321215626783669,
      "learning_rate": 9.173329955507703e-06,
      "loss": 0.0,
      "step": 5221
    },
    {
      "epoch": 0.08268283800687176,
      "grad_norm": 0.03831331059336662,
      "learning_rate": 9.173171619931282e-06,
      "loss": 0.002,
      "step": 5222
    },
    {
      "epoch": 0.08269867156451383,
      "grad_norm": 0.24148230254650116,
      "learning_rate": 9.173013284354863e-06,
      "loss": 0.2499,
      "step": 5223
    },
    {
      "epoch": 0.0827145051221559,
      "grad_norm": 0.007324518635869026,
      "learning_rate": 9.17285494877844e-06,
      "loss": 0.0003,
      "step": 5224
    },
    {
      "epoch": 0.08273033867979797,
      "grad_norm": 0.2460017055273056,
      "learning_rate": 9.172696613202021e-06,
      "loss": 0.2347,
      "step": 5225
    },
    {
      "epoch": 0.08274617223744003,
      "grad_norm": 0.3533971607685089,
      "learning_rate": 9.1725382776256e-06,
      "loss": 0.2429,
      "step": 5226
    },
    {
      "epoch": 0.0827620057950821,
      "grad_norm": 0.13685032725334167,
      "learning_rate": 9.17237994204918e-06,
      "loss": 0.0642,
      "step": 5227
    },
    {
      "epoch": 0.08277783935272416,
      "grad_norm": 0.4931919574737549,
      "learning_rate": 9.172221606472759e-06,
      "loss": 0.9295,
      "step": 5228
    },
    {
      "epoch": 0.08279367291036623,
      "grad_norm": 0.2510641813278198,
      "learning_rate": 9.17206327089634e-06,
      "loss": 0.1316,
      "step": 5229
    },
    {
      "epoch": 0.08280950646800829,
      "grad_norm": 0.4944540858268738,
      "learning_rate": 9.171904935319917e-06,
      "loss": 0.2268,
      "step": 5230
    },
    {
      "epoch": 0.08282534002565037,
      "grad_norm": 0.557182252407074,
      "learning_rate": 9.171746599743498e-06,
      "loss": 0.6204,
      "step": 5231
    },
    {
      "epoch": 0.08284117358329243,
      "grad_norm": 0.15765199065208435,
      "learning_rate": 9.171588264167077e-06,
      "loss": 0.014,
      "step": 5232
    },
    {
      "epoch": 0.0828570071409345,
      "grad_norm": 0.08758246898651123,
      "learning_rate": 9.171429928590656e-06,
      "loss": 0.0029,
      "step": 5233
    },
    {
      "epoch": 0.08287284069857656,
      "grad_norm": 0.27950429916381836,
      "learning_rate": 9.171271593014235e-06,
      "loss": 0.3973,
      "step": 5234
    },
    {
      "epoch": 0.08288867425621863,
      "grad_norm": 0.018100552260875702,
      "learning_rate": 9.171113257437816e-06,
      "loss": 0.0007,
      "step": 5235
    },
    {
      "epoch": 0.08290450781386069,
      "grad_norm": 0.19412609934806824,
      "learning_rate": 9.170954921861393e-06,
      "loss": 0.2218,
      "step": 5236
    },
    {
      "epoch": 0.08292034137150277,
      "grad_norm": 0.007206308655440807,
      "learning_rate": 9.170796586284974e-06,
      "loss": 0.0003,
      "step": 5237
    },
    {
      "epoch": 0.08293617492914483,
      "grad_norm": 0.012489904649555683,
      "learning_rate": 9.170638250708553e-06,
      "loss": 0.0006,
      "step": 5238
    },
    {
      "epoch": 0.0829520084867869,
      "grad_norm": 0.3432047665119171,
      "learning_rate": 9.170479915132132e-06,
      "loss": 0.0873,
      "step": 5239
    },
    {
      "epoch": 0.08296784204442896,
      "grad_norm": 0.4748428761959076,
      "learning_rate": 9.170321579555711e-06,
      "loss": 0.7505,
      "step": 5240
    },
    {
      "epoch": 0.08298367560207102,
      "grad_norm": 0.4299161732196808,
      "learning_rate": 9.170163243979292e-06,
      "loss": 0.2012,
      "step": 5241
    },
    {
      "epoch": 0.08299950915971309,
      "grad_norm": 0.009111142717301846,
      "learning_rate": 9.170004908402869e-06,
      "loss": 0.0005,
      "step": 5242
    },
    {
      "epoch": 0.08301534271735517,
      "grad_norm": 0.3609004616737366,
      "learning_rate": 9.16984657282645e-06,
      "loss": 0.2353,
      "step": 5243
    },
    {
      "epoch": 0.08303117627499723,
      "grad_norm": 0.6337813138961792,
      "learning_rate": 9.169688237250029e-06,
      "loss": 0.7056,
      "step": 5244
    },
    {
      "epoch": 0.0830470098326393,
      "grad_norm": 0.04170766845345497,
      "learning_rate": 9.169529901673608e-06,
      "loss": 0.0023,
      "step": 5245
    },
    {
      "epoch": 0.08306284339028136,
      "grad_norm": 0.30017295479774475,
      "learning_rate": 9.169371566097187e-06,
      "loss": 0.2783,
      "step": 5246
    },
    {
      "epoch": 0.08307867694792342,
      "grad_norm": 0.023795176297426224,
      "learning_rate": 9.169213230520766e-06,
      "loss": 0.0013,
      "step": 5247
    },
    {
      "epoch": 0.08309451050556549,
      "grad_norm": 0.33694297075271606,
      "learning_rate": 9.169054894944345e-06,
      "loss": 0.0983,
      "step": 5248
    },
    {
      "epoch": 0.08311034406320757,
      "grad_norm": 0.2856391668319702,
      "learning_rate": 9.168896559367924e-06,
      "loss": 0.0849,
      "step": 5249
    },
    {
      "epoch": 0.08312617762084963,
      "grad_norm": 0.20368248224258423,
      "learning_rate": 9.168738223791505e-06,
      "loss": 0.0805,
      "step": 5250
    },
    {
      "epoch": 0.0831420111784917,
      "grad_norm": 0.0005327408434823155,
      "learning_rate": 9.168579888215084e-06,
      "loss": 0.0,
      "step": 5251
    },
    {
      "epoch": 0.08315784473613376,
      "grad_norm": 0.39487412571907043,
      "learning_rate": 9.168421552638663e-06,
      "loss": 0.5188,
      "step": 5252
    },
    {
      "epoch": 0.08317367829377582,
      "grad_norm": 1.1501116752624512,
      "learning_rate": 9.168263217062242e-06,
      "loss": 0.206,
      "step": 5253
    },
    {
      "epoch": 0.08318951185141789,
      "grad_norm": 0.004836518317461014,
      "learning_rate": 9.168104881485821e-06,
      "loss": 0.0002,
      "step": 5254
    },
    {
      "epoch": 0.08320534540905997,
      "grad_norm": 0.3792423903942108,
      "learning_rate": 9.1679465459094e-06,
      "loss": 0.5319,
      "step": 5255
    },
    {
      "epoch": 0.08322117896670203,
      "grad_norm": 0.4134223461151123,
      "learning_rate": 9.167788210332981e-06,
      "loss": 0.0883,
      "step": 5256
    },
    {
      "epoch": 0.0832370125243441,
      "grad_norm": 0.268474817276001,
      "learning_rate": 9.16762987475656e-06,
      "loss": 0.2447,
      "step": 5257
    },
    {
      "epoch": 0.08325284608198616,
      "grad_norm": 0.00029017054475843906,
      "learning_rate": 9.16747153918014e-06,
      "loss": 0.0,
      "step": 5258
    },
    {
      "epoch": 0.08326867963962822,
      "grad_norm": 0.26440784335136414,
      "learning_rate": 9.167313203603719e-06,
      "loss": 0.0429,
      "step": 5259
    },
    {
      "epoch": 0.08328451319727029,
      "grad_norm": 0.19656409323215485,
      "learning_rate": 9.167154868027298e-06,
      "loss": 0.1004,
      "step": 5260
    },
    {
      "epoch": 0.08330034675491237,
      "grad_norm": 0.03607969731092453,
      "learning_rate": 9.166996532450877e-06,
      "loss": 0.0014,
      "step": 5261
    },
    {
      "epoch": 0.08331618031255443,
      "grad_norm": 0.00033759258803911507,
      "learning_rate": 9.166838196874457e-06,
      "loss": 0.0,
      "step": 5262
    },
    {
      "epoch": 0.0833320138701965,
      "grad_norm": 0.5852545499801636,
      "learning_rate": 9.166679861298035e-06,
      "loss": 0.5296,
      "step": 5263
    },
    {
      "epoch": 0.08334784742783856,
      "grad_norm": 0.0034500574693083763,
      "learning_rate": 9.166521525721616e-06,
      "loss": 0.0001,
      "step": 5264
    },
    {
      "epoch": 0.08336368098548062,
      "grad_norm": 0.0002277575695188716,
      "learning_rate": 9.166363190145195e-06,
      "loss": 0.0,
      "step": 5265
    },
    {
      "epoch": 0.08337951454312269,
      "grad_norm": 5.829513247590512e-05,
      "learning_rate": 9.166204854568774e-06,
      "loss": 0.0,
      "step": 5266
    },
    {
      "epoch": 0.08339534810076477,
      "grad_norm": 0.37027862668037415,
      "learning_rate": 9.166046518992353e-06,
      "loss": 0.4135,
      "step": 5267
    },
    {
      "epoch": 0.08341118165840683,
      "grad_norm": 0.26252487301826477,
      "learning_rate": 9.165888183415934e-06,
      "loss": 0.1869,
      "step": 5268
    },
    {
      "epoch": 0.0834270152160489,
      "grad_norm": 0.6311300992965698,
      "learning_rate": 9.165729847839511e-06,
      "loss": 0.1004,
      "step": 5269
    },
    {
      "epoch": 0.08344284877369096,
      "grad_norm": 0.24334484338760376,
      "learning_rate": 9.16557151226309e-06,
      "loss": 0.0097,
      "step": 5270
    },
    {
      "epoch": 0.08345868233133302,
      "grad_norm": 0.8459810614585876,
      "learning_rate": 9.165413176686671e-06,
      "loss": 0.2062,
      "step": 5271
    },
    {
      "epoch": 0.08347451588897509,
      "grad_norm": 0.38156142830848694,
      "learning_rate": 9.16525484111025e-06,
      "loss": 0.3007,
      "step": 5272
    },
    {
      "epoch": 0.08349034944661717,
      "grad_norm": 0.34792637825012207,
      "learning_rate": 9.165096505533829e-06,
      "loss": 0.0897,
      "step": 5273
    },
    {
      "epoch": 0.08350618300425923,
      "grad_norm": 0.31691011786460876,
      "learning_rate": 9.164938169957408e-06,
      "loss": 0.0549,
      "step": 5274
    },
    {
      "epoch": 0.0835220165619013,
      "grad_norm": 0.0338633693754673,
      "learning_rate": 9.164779834380987e-06,
      "loss": 0.0021,
      "step": 5275
    },
    {
      "epoch": 0.08353785011954336,
      "grad_norm": 0.22344234585762024,
      "learning_rate": 9.164621498804566e-06,
      "loss": 0.0824,
      "step": 5276
    },
    {
      "epoch": 0.08355368367718542,
      "grad_norm": 0.4127153158187866,
      "learning_rate": 9.164463163228147e-06,
      "loss": 0.5785,
      "step": 5277
    },
    {
      "epoch": 0.08356951723482749,
      "grad_norm": 0.3874788284301758,
      "learning_rate": 9.164304827651726e-06,
      "loss": 0.5896,
      "step": 5278
    },
    {
      "epoch": 0.08358535079246956,
      "grad_norm": 0.2981296181678772,
      "learning_rate": 9.164146492075305e-06,
      "loss": 0.1085,
      "step": 5279
    },
    {
      "epoch": 0.08360118435011163,
      "grad_norm": 0.26636403799057007,
      "learning_rate": 9.163988156498884e-06,
      "loss": 0.0511,
      "step": 5280
    },
    {
      "epoch": 0.0836170179077537,
      "grad_norm": 0.5209909677505493,
      "learning_rate": 9.163829820922463e-06,
      "loss": 0.3155,
      "step": 5281
    },
    {
      "epoch": 0.08363285146539576,
      "grad_norm": 0.2292347550392151,
      "learning_rate": 9.163671485346042e-06,
      "loss": 0.1567,
      "step": 5282
    },
    {
      "epoch": 0.08364868502303782,
      "grad_norm": 0.02918037585914135,
      "learning_rate": 9.163513149769623e-06,
      "loss": 0.0019,
      "step": 5283
    },
    {
      "epoch": 0.08366451858067989,
      "grad_norm": 0.00951374601572752,
      "learning_rate": 9.163354814193202e-06,
      "loss": 0.0002,
      "step": 5284
    },
    {
      "epoch": 0.08368035213832196,
      "grad_norm": 0.051371123641729355,
      "learning_rate": 9.163196478616781e-06,
      "loss": 0.0033,
      "step": 5285
    },
    {
      "epoch": 0.08369618569596403,
      "grad_norm": 0.3081640899181366,
      "learning_rate": 9.16303814304036e-06,
      "loss": 0.0711,
      "step": 5286
    },
    {
      "epoch": 0.0837120192536061,
      "grad_norm": 0.22119995951652527,
      "learning_rate": 9.16287980746394e-06,
      "loss": 0.0826,
      "step": 5287
    },
    {
      "epoch": 0.08372785281124816,
      "grad_norm": 0.22731080651283264,
      "learning_rate": 9.162721471887519e-06,
      "loss": 0.0139,
      "step": 5288
    },
    {
      "epoch": 0.08374368636889022,
      "grad_norm": 0.015254462137818336,
      "learning_rate": 9.1625631363111e-06,
      "loss": 0.0006,
      "step": 5289
    },
    {
      "epoch": 0.08375951992653229,
      "grad_norm": 0.9879387021064758,
      "learning_rate": 9.162404800734678e-06,
      "loss": 1.4635,
      "step": 5290
    },
    {
      "epoch": 0.08377535348417436,
      "grad_norm": 0.8351003527641296,
      "learning_rate": 9.162246465158258e-06,
      "loss": 0.0796,
      "step": 5291
    },
    {
      "epoch": 0.08379118704181643,
      "grad_norm": 0.2456752508878708,
      "learning_rate": 9.162088129581837e-06,
      "loss": 0.1695,
      "step": 5292
    },
    {
      "epoch": 0.08380702059945849,
      "grad_norm": 0.3536009192466736,
      "learning_rate": 9.161929794005416e-06,
      "loss": 0.082,
      "step": 5293
    },
    {
      "epoch": 0.08382285415710056,
      "grad_norm": 0.6939553022384644,
      "learning_rate": 9.161771458428995e-06,
      "loss": 0.7782,
      "step": 5294
    },
    {
      "epoch": 0.08383868771474262,
      "grad_norm": 0.00014227883366402239,
      "learning_rate": 9.161613122852574e-06,
      "loss": 0.0,
      "step": 5295
    },
    {
      "epoch": 0.08385452127238469,
      "grad_norm": 0.0023070485331118107,
      "learning_rate": 9.161454787276155e-06,
      "loss": 0.0001,
      "step": 5296
    },
    {
      "epoch": 0.08387035483002676,
      "grad_norm": 0.31635478138923645,
      "learning_rate": 9.161296451699732e-06,
      "loss": 0.0651,
      "step": 5297
    },
    {
      "epoch": 0.08388618838766883,
      "grad_norm": 0.00038751811371184886,
      "learning_rate": 9.161138116123313e-06,
      "loss": 0.0,
      "step": 5298
    },
    {
      "epoch": 0.08390202194531089,
      "grad_norm": 0.4168018400669098,
      "learning_rate": 9.160979780546892e-06,
      "loss": 0.1859,
      "step": 5299
    },
    {
      "epoch": 0.08391785550295296,
      "grad_norm": 0.13073360919952393,
      "learning_rate": 9.160821444970471e-06,
      "loss": 0.0099,
      "step": 5300
    },
    {
      "epoch": 0.08393368906059502,
      "grad_norm": 0.24614179134368896,
      "learning_rate": 9.16066310939405e-06,
      "loss": 0.1925,
      "step": 5301
    },
    {
      "epoch": 0.08394952261823709,
      "grad_norm": 0.4518938660621643,
      "learning_rate": 9.16050477381763e-06,
      "loss": 0.5691,
      "step": 5302
    },
    {
      "epoch": 0.08396535617587916,
      "grad_norm": 0.3787941634654999,
      "learning_rate": 9.160346438241208e-06,
      "loss": 0.8377,
      "step": 5303
    },
    {
      "epoch": 0.08398118973352123,
      "grad_norm": 0.5275964140892029,
      "learning_rate": 9.160188102664789e-06,
      "loss": 0.4642,
      "step": 5304
    },
    {
      "epoch": 0.08399702329116329,
      "grad_norm": 0.3054542541503906,
      "learning_rate": 9.160029767088368e-06,
      "loss": 0.1772,
      "step": 5305
    },
    {
      "epoch": 0.08401285684880536,
      "grad_norm": 0.29410460591316223,
      "learning_rate": 9.159871431511947e-06,
      "loss": 0.1028,
      "step": 5306
    },
    {
      "epoch": 0.08402869040644742,
      "grad_norm": 0.22313708066940308,
      "learning_rate": 9.159713095935526e-06,
      "loss": 0.0587,
      "step": 5307
    },
    {
      "epoch": 0.08404452396408948,
      "grad_norm": 0.5171745419502258,
      "learning_rate": 9.159554760359107e-06,
      "loss": 0.0038,
      "step": 5308
    },
    {
      "epoch": 0.08406035752173156,
      "grad_norm": 0.3293599784374237,
      "learning_rate": 9.159396424782684e-06,
      "loss": 0.0236,
      "step": 5309
    },
    {
      "epoch": 0.08407619107937363,
      "grad_norm": 0.4618490934371948,
      "learning_rate": 9.159238089206265e-06,
      "loss": 0.2274,
      "step": 5310
    },
    {
      "epoch": 0.08409202463701569,
      "grad_norm": 0.18121495842933655,
      "learning_rate": 9.159079753629844e-06,
      "loss": 0.0407,
      "step": 5311
    },
    {
      "epoch": 0.08410785819465776,
      "grad_norm": 0.00017026982095558196,
      "learning_rate": 9.158921418053423e-06,
      "loss": 0.0,
      "step": 5312
    },
    {
      "epoch": 0.08412369175229982,
      "grad_norm": 0.021689170971512794,
      "learning_rate": 9.158763082477002e-06,
      "loss": 0.0022,
      "step": 5313
    },
    {
      "epoch": 0.08413952530994188,
      "grad_norm": 0.2250269502401352,
      "learning_rate": 9.158604746900583e-06,
      "loss": 0.0934,
      "step": 5314
    },
    {
      "epoch": 0.08415535886758396,
      "grad_norm": 0.5582466125488281,
      "learning_rate": 9.15844641132416e-06,
      "loss": 0.1229,
      "step": 5315
    },
    {
      "epoch": 0.08417119242522603,
      "grad_norm": 0.025844460353255272,
      "learning_rate": 9.158288075747741e-06,
      "loss": 0.0024,
      "step": 5316
    },
    {
      "epoch": 0.08418702598286809,
      "grad_norm": 0.3483882248401642,
      "learning_rate": 9.15812974017132e-06,
      "loss": 0.3446,
      "step": 5317
    },
    {
      "epoch": 0.08420285954051016,
      "grad_norm": 0.05586788058280945,
      "learning_rate": 9.1579714045949e-06,
      "loss": 0.0004,
      "step": 5318
    },
    {
      "epoch": 0.08421869309815222,
      "grad_norm": 0.4070039689540863,
      "learning_rate": 9.157813069018479e-06,
      "loss": 0.5241,
      "step": 5319
    },
    {
      "epoch": 0.08423452665579428,
      "grad_norm": 0.1799144446849823,
      "learning_rate": 9.157654733442058e-06,
      "loss": 0.0886,
      "step": 5320
    },
    {
      "epoch": 0.08425036021343636,
      "grad_norm": 0.00024387903977185488,
      "learning_rate": 9.157496397865637e-06,
      "loss": 0.0,
      "step": 5321
    },
    {
      "epoch": 0.08426619377107843,
      "grad_norm": 0.0039717936888337135,
      "learning_rate": 9.157338062289216e-06,
      "loss": 0.0001,
      "step": 5322
    },
    {
      "epoch": 0.08428202732872049,
      "grad_norm": 0.2325512319803238,
      "learning_rate": 9.157179726712797e-06,
      "loss": 0.1574,
      "step": 5323
    },
    {
      "epoch": 0.08429786088636256,
      "grad_norm": 0.33052000403404236,
      "learning_rate": 9.157021391136374e-06,
      "loss": 0.7453,
      "step": 5324
    },
    {
      "epoch": 0.08431369444400462,
      "grad_norm": 0.19874338805675507,
      "learning_rate": 9.156863055559955e-06,
      "loss": 0.0539,
      "step": 5325
    },
    {
      "epoch": 0.08432952800164668,
      "grad_norm": 0.008694388903677464,
      "learning_rate": 9.156704719983534e-06,
      "loss": 0.0004,
      "step": 5326
    },
    {
      "epoch": 0.08434536155928876,
      "grad_norm": 0.10268086940050125,
      "learning_rate": 9.156546384407113e-06,
      "loss": 0.0534,
      "step": 5327
    },
    {
      "epoch": 0.08436119511693083,
      "grad_norm": 0.21458540856838226,
      "learning_rate": 9.156388048830692e-06,
      "loss": 0.0645,
      "step": 5328
    },
    {
      "epoch": 0.08437702867457289,
      "grad_norm": 0.15630429983139038,
      "learning_rate": 9.156229713254273e-06,
      "loss": 0.058,
      "step": 5329
    },
    {
      "epoch": 0.08439286223221495,
      "grad_norm": 0.022959956899285316,
      "learning_rate": 9.15607137767785e-06,
      "loss": 0.0032,
      "step": 5330
    },
    {
      "epoch": 0.08440869578985702,
      "grad_norm": 0.3986890912055969,
      "learning_rate": 9.155913042101431e-06,
      "loss": 0.2413,
      "step": 5331
    },
    {
      "epoch": 0.08442452934749908,
      "grad_norm": 0.2172234207391739,
      "learning_rate": 9.15575470652501e-06,
      "loss": 0.1927,
      "step": 5332
    },
    {
      "epoch": 0.08444036290514116,
      "grad_norm": 0.2221236377954483,
      "learning_rate": 9.155596370948589e-06,
      "loss": 0.1011,
      "step": 5333
    },
    {
      "epoch": 0.08445619646278323,
      "grad_norm": 0.2855198085308075,
      "learning_rate": 9.155438035372168e-06,
      "loss": 0.0588,
      "step": 5334
    },
    {
      "epoch": 0.08447203002042529,
      "grad_norm": 0.009706063196063042,
      "learning_rate": 9.155279699795749e-06,
      "loss": 0.0005,
      "step": 5335
    },
    {
      "epoch": 0.08448786357806735,
      "grad_norm": 0.04274873062968254,
      "learning_rate": 9.155121364219326e-06,
      "loss": 0.0006,
      "step": 5336
    },
    {
      "epoch": 0.08450369713570942,
      "grad_norm": 0.5858988165855408,
      "learning_rate": 9.154963028642907e-06,
      "loss": 0.0618,
      "step": 5337
    },
    {
      "epoch": 0.08451953069335148,
      "grad_norm": 0.6258258819580078,
      "learning_rate": 9.154804693066486e-06,
      "loss": 0.2145,
      "step": 5338
    },
    {
      "epoch": 0.08453536425099356,
      "grad_norm": 0.005582010373473167,
      "learning_rate": 9.154646357490065e-06,
      "loss": 0.0004,
      "step": 5339
    },
    {
      "epoch": 0.08455119780863563,
      "grad_norm": 0.20070885121822357,
      "learning_rate": 9.154488021913644e-06,
      "loss": 0.0459,
      "step": 5340
    },
    {
      "epoch": 0.08456703136627769,
      "grad_norm": 0.2921510934829712,
      "learning_rate": 9.154329686337225e-06,
      "loss": 0.163,
      "step": 5341
    },
    {
      "epoch": 0.08458286492391975,
      "grad_norm": 0.14010462164878845,
      "learning_rate": 9.154171350760802e-06,
      "loss": 0.069,
      "step": 5342
    },
    {
      "epoch": 0.08459869848156182,
      "grad_norm": 0.023936759680509567,
      "learning_rate": 9.154013015184382e-06,
      "loss": 0.0009,
      "step": 5343
    },
    {
      "epoch": 0.08461453203920388,
      "grad_norm": 0.8831839561462402,
      "learning_rate": 9.153854679607962e-06,
      "loss": 0.7995,
      "step": 5344
    },
    {
      "epoch": 0.08463036559684596,
      "grad_norm": 0.24313031136989594,
      "learning_rate": 9.153696344031541e-06,
      "loss": 0.1871,
      "step": 5345
    },
    {
      "epoch": 0.08464619915448802,
      "grad_norm": 0.44186878204345703,
      "learning_rate": 9.15353800845512e-06,
      "loss": 0.0892,
      "step": 5346
    },
    {
      "epoch": 0.08466203271213009,
      "grad_norm": 0.0024686045944690704,
      "learning_rate": 9.1533796728787e-06,
      "loss": 0.0001,
      "step": 5347
    },
    {
      "epoch": 0.08467786626977215,
      "grad_norm": 0.0009840650018304586,
      "learning_rate": 9.153221337302279e-06,
      "loss": 0.0001,
      "step": 5348
    },
    {
      "epoch": 0.08469369982741422,
      "grad_norm": 0.024584714323282242,
      "learning_rate": 9.153063001725858e-06,
      "loss": 0.0011,
      "step": 5349
    },
    {
      "epoch": 0.08470953338505628,
      "grad_norm": 0.17357255518436432,
      "learning_rate": 9.152904666149438e-06,
      "loss": 0.0326,
      "step": 5350
    },
    {
      "epoch": 0.08472536694269836,
      "grad_norm": 0.2428651601076126,
      "learning_rate": 9.152746330573018e-06,
      "loss": 0.1446,
      "step": 5351
    },
    {
      "epoch": 0.08474120050034042,
      "grad_norm": 0.00015224066737573594,
      "learning_rate": 9.152587994996597e-06,
      "loss": 0.0,
      "step": 5352
    },
    {
      "epoch": 0.08475703405798249,
      "grad_norm": 0.1343529224395752,
      "learning_rate": 9.152429659420176e-06,
      "loss": 0.0681,
      "step": 5353
    },
    {
      "epoch": 0.08477286761562455,
      "grad_norm": 0.1864895522594452,
      "learning_rate": 9.152271323843755e-06,
      "loss": 0.0609,
      "step": 5354
    },
    {
      "epoch": 0.08478870117326662,
      "grad_norm": 0.26176485419273376,
      "learning_rate": 9.152112988267334e-06,
      "loss": 0.1449,
      "step": 5355
    },
    {
      "epoch": 0.08480453473090868,
      "grad_norm": 0.45053988695144653,
      "learning_rate": 9.151954652690915e-06,
      "loss": 0.3721,
      "step": 5356
    },
    {
      "epoch": 0.08482036828855076,
      "grad_norm": 0.24305832386016846,
      "learning_rate": 9.151796317114494e-06,
      "loss": 0.1304,
      "step": 5357
    },
    {
      "epoch": 0.08483620184619282,
      "grad_norm": 0.6043103933334351,
      "learning_rate": 9.151637981538073e-06,
      "loss": 0.2951,
      "step": 5358
    },
    {
      "epoch": 0.08485203540383489,
      "grad_norm": 0.3165460228919983,
      "learning_rate": 9.151479645961652e-06,
      "loss": 0.4736,
      "step": 5359
    },
    {
      "epoch": 0.08486786896147695,
      "grad_norm": 0.0008851454476825893,
      "learning_rate": 9.151321310385231e-06,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 0.08488370251911902,
      "grad_norm": 0.24659106135368347,
      "learning_rate": 9.15116297480881e-06,
      "loss": 0.1408,
      "step": 5361
    },
    {
      "epoch": 0.08489953607676108,
      "grad_norm": 0.3684181869029999,
      "learning_rate": 9.15100463923239e-06,
      "loss": 0.3368,
      "step": 5362
    },
    {
      "epoch": 0.08491536963440316,
      "grad_norm": 0.3548656404018402,
      "learning_rate": 9.15084630365597e-06,
      "loss": 0.1346,
      "step": 5363
    },
    {
      "epoch": 0.08493120319204522,
      "grad_norm": 0.18075565993785858,
      "learning_rate": 9.150687968079549e-06,
      "loss": 0.0974,
      "step": 5364
    },
    {
      "epoch": 0.08494703674968729,
      "grad_norm": 0.23321202397346497,
      "learning_rate": 9.150529632503128e-06,
      "loss": 0.0445,
      "step": 5365
    },
    {
      "epoch": 0.08496287030732935,
      "grad_norm": 0.2826474905014038,
      "learning_rate": 9.150371296926707e-06,
      "loss": 0.0475,
      "step": 5366
    },
    {
      "epoch": 0.08497870386497142,
      "grad_norm": 0.4033825993537903,
      "learning_rate": 9.150212961350286e-06,
      "loss": 0.1894,
      "step": 5367
    },
    {
      "epoch": 0.08499453742261348,
      "grad_norm": 0.24535030126571655,
      "learning_rate": 9.150054625773865e-06,
      "loss": 0.1119,
      "step": 5368
    },
    {
      "epoch": 0.08501037098025556,
      "grad_norm": 0.01988108642399311,
      "learning_rate": 9.149896290197446e-06,
      "loss": 0.001,
      "step": 5369
    },
    {
      "epoch": 0.08502620453789762,
      "grad_norm": 0.05584939941763878,
      "learning_rate": 9.149737954621023e-06,
      "loss": 0.0008,
      "step": 5370
    },
    {
      "epoch": 0.08504203809553969,
      "grad_norm": 0.005313345231115818,
      "learning_rate": 9.149579619044604e-06,
      "loss": 0.0002,
      "step": 5371
    },
    {
      "epoch": 0.08505787165318175,
      "grad_norm": 0.055955588817596436,
      "learning_rate": 9.149421283468183e-06,
      "loss": 0.0024,
      "step": 5372
    },
    {
      "epoch": 0.08507370521082382,
      "grad_norm": 0.2843658924102783,
      "learning_rate": 9.149262947891762e-06,
      "loss": 0.0469,
      "step": 5373
    },
    {
      "epoch": 0.08508953876846588,
      "grad_norm": 0.000454524444648996,
      "learning_rate": 9.149104612315341e-06,
      "loss": 0.0,
      "step": 5374
    },
    {
      "epoch": 0.08510537232610796,
      "grad_norm": 0.416973352432251,
      "learning_rate": 9.148946276738922e-06,
      "loss": 0.1805,
      "step": 5375
    },
    {
      "epoch": 0.08512120588375002,
      "grad_norm": 0.2535545825958252,
      "learning_rate": 9.1487879411625e-06,
      "loss": 0.1611,
      "step": 5376
    },
    {
      "epoch": 0.08513703944139209,
      "grad_norm": 0.2832801043987274,
      "learning_rate": 9.14862960558608e-06,
      "loss": 0.1561,
      "step": 5377
    },
    {
      "epoch": 0.08515287299903415,
      "grad_norm": 0.21483725309371948,
      "learning_rate": 9.14847127000966e-06,
      "loss": 0.1436,
      "step": 5378
    },
    {
      "epoch": 0.08516870655667622,
      "grad_norm": 9.566013613948599e-05,
      "learning_rate": 9.148312934433239e-06,
      "loss": 0.0,
      "step": 5379
    },
    {
      "epoch": 0.08518454011431828,
      "grad_norm": 0.02298087067902088,
      "learning_rate": 9.148154598856818e-06,
      "loss": 0.001,
      "step": 5380
    },
    {
      "epoch": 0.08520037367196036,
      "grad_norm": 0.003846314735710621,
      "learning_rate": 9.147996263280398e-06,
      "loss": 0.0002,
      "step": 5381
    },
    {
      "epoch": 0.08521620722960242,
      "grad_norm": 0.01047348789870739,
      "learning_rate": 9.147837927703976e-06,
      "loss": 0.0001,
      "step": 5382
    },
    {
      "epoch": 0.08523204078724449,
      "grad_norm": 0.3895280063152313,
      "learning_rate": 9.147679592127557e-06,
      "loss": 0.0768,
      "step": 5383
    },
    {
      "epoch": 0.08524787434488655,
      "grad_norm": 1.1051948070526123,
      "learning_rate": 9.147521256551136e-06,
      "loss": 0.0464,
      "step": 5384
    },
    {
      "epoch": 0.08526370790252862,
      "grad_norm": 0.2301746904850006,
      "learning_rate": 9.147362920974715e-06,
      "loss": 0.1288,
      "step": 5385
    },
    {
      "epoch": 0.08527954146017068,
      "grad_norm": 0.0036897012032568455,
      "learning_rate": 9.147204585398294e-06,
      "loss": 0.0001,
      "step": 5386
    },
    {
      "epoch": 0.08529537501781276,
      "grad_norm": 0.04092645272612572,
      "learning_rate": 9.147046249821873e-06,
      "loss": 0.0026,
      "step": 5387
    },
    {
      "epoch": 0.08531120857545482,
      "grad_norm": 0.2009081393480301,
      "learning_rate": 9.146887914245452e-06,
      "loss": 0.0946,
      "step": 5388
    },
    {
      "epoch": 0.08532704213309689,
      "grad_norm": 0.4240402579307556,
      "learning_rate": 9.146729578669033e-06,
      "loss": 0.0823,
      "step": 5389
    },
    {
      "epoch": 0.08534287569073895,
      "grad_norm": 0.04351115599274635,
      "learning_rate": 9.146571243092612e-06,
      "loss": 0.0039,
      "step": 5390
    },
    {
      "epoch": 0.08535870924838102,
      "grad_norm": 0.46755293011665344,
      "learning_rate": 9.14641290751619e-06,
      "loss": 0.1259,
      "step": 5391
    },
    {
      "epoch": 0.08537454280602308,
      "grad_norm": 0.6990203261375427,
      "learning_rate": 9.14625457193977e-06,
      "loss": 0.1556,
      "step": 5392
    },
    {
      "epoch": 0.08539037636366516,
      "grad_norm": 0.0007946835830807686,
      "learning_rate": 9.146096236363349e-06,
      "loss": 0.0,
      "step": 5393
    },
    {
      "epoch": 0.08540620992130722,
      "grad_norm": 0.2452978491783142,
      "learning_rate": 9.145937900786928e-06,
      "loss": 0.1663,
      "step": 5394
    },
    {
      "epoch": 0.08542204347894929,
      "grad_norm": 0.16939806938171387,
      "learning_rate": 9.145779565210507e-06,
      "loss": 0.0703,
      "step": 5395
    },
    {
      "epoch": 0.08543787703659135,
      "grad_norm": 9.777512605069205e-05,
      "learning_rate": 9.145621229634088e-06,
      "loss": 0.0,
      "step": 5396
    },
    {
      "epoch": 0.08545371059423341,
      "grad_norm": 0.3252071440219879,
      "learning_rate": 9.145462894057665e-06,
      "loss": 0.3809,
      "step": 5397
    },
    {
      "epoch": 0.08546954415187548,
      "grad_norm": 0.2593696415424347,
      "learning_rate": 9.145304558481246e-06,
      "loss": 0.1208,
      "step": 5398
    },
    {
      "epoch": 0.08548537770951756,
      "grad_norm": 0.16556905210018158,
      "learning_rate": 9.145146222904825e-06,
      "loss": 0.0547,
      "step": 5399
    },
    {
      "epoch": 0.08550121126715962,
      "grad_norm": 0.015453020110726357,
      "learning_rate": 9.144987887328404e-06,
      "loss": 0.0006,
      "step": 5400
    },
    {
      "epoch": 0.08551704482480169,
      "grad_norm": 0.15046657621860504,
      "learning_rate": 9.144829551751983e-06,
      "loss": 0.0672,
      "step": 5401
    },
    {
      "epoch": 0.08553287838244375,
      "grad_norm": 0.19118283689022064,
      "learning_rate": 9.144671216175564e-06,
      "loss": 0.0479,
      "step": 5402
    },
    {
      "epoch": 0.08554871194008581,
      "grad_norm": 0.767470121383667,
      "learning_rate": 9.144512880599142e-06,
      "loss": 0.5121,
      "step": 5403
    },
    {
      "epoch": 0.08556454549772788,
      "grad_norm": 0.0001629907637834549,
      "learning_rate": 9.144354545022722e-06,
      "loss": 0.0,
      "step": 5404
    },
    {
      "epoch": 0.08558037905536996,
      "grad_norm": 0.21748730540275574,
      "learning_rate": 9.144196209446301e-06,
      "loss": 0.1074,
      "step": 5405
    },
    {
      "epoch": 0.08559621261301202,
      "grad_norm": 0.25836801528930664,
      "learning_rate": 9.14403787386988e-06,
      "loss": 0.2002,
      "step": 5406
    },
    {
      "epoch": 0.08561204617065409,
      "grad_norm": 0.4176535904407501,
      "learning_rate": 9.14387953829346e-06,
      "loss": 0.8074,
      "step": 5407
    },
    {
      "epoch": 0.08562787972829615,
      "grad_norm": 0.24436399340629578,
      "learning_rate": 9.14372120271704e-06,
      "loss": 0.0274,
      "step": 5408
    },
    {
      "epoch": 0.08564371328593821,
      "grad_norm": 0.1574198454618454,
      "learning_rate": 9.143562867140618e-06,
      "loss": 0.0739,
      "step": 5409
    },
    {
      "epoch": 0.08565954684358028,
      "grad_norm": 0.000452206440968439,
      "learning_rate": 9.143404531564198e-06,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 0.08567538040122236,
      "grad_norm": 0.13618028163909912,
      "learning_rate": 9.143246195987778e-06,
      "loss": 0.0579,
      "step": 5411
    },
    {
      "epoch": 0.08569121395886442,
      "grad_norm": 0.28731483221054077,
      "learning_rate": 9.143087860411357e-06,
      "loss": 0.3058,
      "step": 5412
    },
    {
      "epoch": 0.08570704751650648,
      "grad_norm": 0.38953712582588196,
      "learning_rate": 9.142929524834936e-06,
      "loss": 0.144,
      "step": 5413
    },
    {
      "epoch": 0.08572288107414855,
      "grad_norm": 0.4500477612018585,
      "learning_rate": 9.142771189258515e-06,
      "loss": 0.2853,
      "step": 5414
    },
    {
      "epoch": 0.08573871463179061,
      "grad_norm": 0.0004920520004816353,
      "learning_rate": 9.142612853682094e-06,
      "loss": 0.0,
      "step": 5415
    },
    {
      "epoch": 0.08575454818943268,
      "grad_norm": 0.1249367892742157,
      "learning_rate": 9.142454518105673e-06,
      "loss": 0.064,
      "step": 5416
    },
    {
      "epoch": 0.08577038174707476,
      "grad_norm": 0.04557039961218834,
      "learning_rate": 9.142296182529254e-06,
      "loss": 0.0023,
      "step": 5417
    },
    {
      "epoch": 0.08578621530471682,
      "grad_norm": 0.33333057165145874,
      "learning_rate": 9.142137846952833e-06,
      "loss": 0.5001,
      "step": 5418
    },
    {
      "epoch": 0.08580204886235888,
      "grad_norm": 0.07257454842329025,
      "learning_rate": 9.141979511376412e-06,
      "loss": 0.0021,
      "step": 5419
    },
    {
      "epoch": 0.08581788242000095,
      "grad_norm": 0.350558876991272,
      "learning_rate": 9.141821175799991e-06,
      "loss": 0.1254,
      "step": 5420
    },
    {
      "epoch": 0.08583371597764301,
      "grad_norm": 0.4523274302482605,
      "learning_rate": 9.14166284022357e-06,
      "loss": 0.0729,
      "step": 5421
    },
    {
      "epoch": 0.08584954953528508,
      "grad_norm": 0.38860806822776794,
      "learning_rate": 9.141504504647149e-06,
      "loss": 0.0763,
      "step": 5422
    },
    {
      "epoch": 0.08586538309292716,
      "grad_norm": 0.2846994698047638,
      "learning_rate": 9.14134616907073e-06,
      "loss": 0.1646,
      "step": 5423
    },
    {
      "epoch": 0.08588121665056922,
      "grad_norm": 0.049148302525281906,
      "learning_rate": 9.141187833494309e-06,
      "loss": 0.0018,
      "step": 5424
    },
    {
      "epoch": 0.08589705020821128,
      "grad_norm": 0.27904364466667175,
      "learning_rate": 9.141029497917888e-06,
      "loss": 0.1525,
      "step": 5425
    },
    {
      "epoch": 0.08591288376585335,
      "grad_norm": 0.0010843969648703933,
      "learning_rate": 9.140871162341467e-06,
      "loss": 0.0,
      "step": 5426
    },
    {
      "epoch": 0.08592871732349541,
      "grad_norm": 0.3324815332889557,
      "learning_rate": 9.140712826765046e-06,
      "loss": 0.0099,
      "step": 5427
    },
    {
      "epoch": 0.08594455088113748,
      "grad_norm": 0.012686377391219139,
      "learning_rate": 9.140554491188625e-06,
      "loss": 0.0005,
      "step": 5428
    },
    {
      "epoch": 0.08596038443877956,
      "grad_norm": 0.3539709746837616,
      "learning_rate": 9.140396155612206e-06,
      "loss": 0.0507,
      "step": 5429
    },
    {
      "epoch": 0.08597621799642162,
      "grad_norm": 6.255557673284784e-05,
      "learning_rate": 9.140237820035785e-06,
      "loss": 0.0,
      "step": 5430
    },
    {
      "epoch": 0.08599205155406368,
      "grad_norm": 0.23132029175758362,
      "learning_rate": 9.140079484459364e-06,
      "loss": 0.2582,
      "step": 5431
    },
    {
      "epoch": 0.08600788511170575,
      "grad_norm": 0.03576325252652168,
      "learning_rate": 9.139921148882943e-06,
      "loss": 0.0019,
      "step": 5432
    },
    {
      "epoch": 0.08602371866934781,
      "grad_norm": 0.20912058651447296,
      "learning_rate": 9.139762813306522e-06,
      "loss": 0.1421,
      "step": 5433
    },
    {
      "epoch": 0.08603955222698988,
      "grad_norm": 0.6359484195709229,
      "learning_rate": 9.139604477730101e-06,
      "loss": 0.1713,
      "step": 5434
    },
    {
      "epoch": 0.08605538578463195,
      "grad_norm": 0.21101780235767365,
      "learning_rate": 9.139446142153682e-06,
      "loss": 0.1085,
      "step": 5435
    },
    {
      "epoch": 0.08607121934227402,
      "grad_norm": 0.24936780333518982,
      "learning_rate": 9.139287806577261e-06,
      "loss": 0.0904,
      "step": 5436
    },
    {
      "epoch": 0.08608705289991608,
      "grad_norm": 0.019740838557481766,
      "learning_rate": 9.13912947100084e-06,
      "loss": 0.0011,
      "step": 5437
    },
    {
      "epoch": 0.08610288645755815,
      "grad_norm": 0.35614752769470215,
      "learning_rate": 9.13897113542442e-06,
      "loss": 0.0602,
      "step": 5438
    },
    {
      "epoch": 0.08611872001520021,
      "grad_norm": 3.4259079257026315e-05,
      "learning_rate": 9.138812799847999e-06,
      "loss": 0.0,
      "step": 5439
    },
    {
      "epoch": 0.08613455357284228,
      "grad_norm": 0.02707376889884472,
      "learning_rate": 9.138654464271578e-06,
      "loss": 0.0011,
      "step": 5440
    },
    {
      "epoch": 0.08615038713048435,
      "grad_norm": 0.3368019163608551,
      "learning_rate": 9.138496128695157e-06,
      "loss": 0.3742,
      "step": 5441
    },
    {
      "epoch": 0.08616622068812642,
      "grad_norm": 0.22631971538066864,
      "learning_rate": 9.138337793118738e-06,
      "loss": 0.1111,
      "step": 5442
    },
    {
      "epoch": 0.08618205424576848,
      "grad_norm": 0.2886805236339569,
      "learning_rate": 9.138179457542315e-06,
      "loss": 0.1619,
      "step": 5443
    },
    {
      "epoch": 0.08619788780341055,
      "grad_norm": 0.2775610685348511,
      "learning_rate": 9.138021121965896e-06,
      "loss": 0.2486,
      "step": 5444
    },
    {
      "epoch": 0.08621372136105261,
      "grad_norm": 0.3293134570121765,
      "learning_rate": 9.137862786389475e-06,
      "loss": 0.1103,
      "step": 5445
    },
    {
      "epoch": 0.08622955491869468,
      "grad_norm": 0.31824442744255066,
      "learning_rate": 9.137704450813054e-06,
      "loss": 0.0236,
      "step": 5446
    },
    {
      "epoch": 0.08624538847633675,
      "grad_norm": 0.4046071469783783,
      "learning_rate": 9.137546115236633e-06,
      "loss": 0.0563,
      "step": 5447
    },
    {
      "epoch": 0.08626122203397882,
      "grad_norm": 0.3537955582141876,
      "learning_rate": 9.137387779660214e-06,
      "loss": 0.0826,
      "step": 5448
    },
    {
      "epoch": 0.08627705559162088,
      "grad_norm": 0.1825101524591446,
      "learning_rate": 9.137229444083791e-06,
      "loss": 0.0581,
      "step": 5449
    },
    {
      "epoch": 0.08629288914926295,
      "grad_norm": 0.308033287525177,
      "learning_rate": 9.137071108507372e-06,
      "loss": 0.0791,
      "step": 5450
    },
    {
      "epoch": 0.08630872270690501,
      "grad_norm": 0.38147035241127014,
      "learning_rate": 9.136912772930951e-06,
      "loss": 0.1711,
      "step": 5451
    },
    {
      "epoch": 0.08632455626454708,
      "grad_norm": 0.18476836383342743,
      "learning_rate": 9.13675443735453e-06,
      "loss": 0.0543,
      "step": 5452
    },
    {
      "epoch": 0.08634038982218915,
      "grad_norm": 0.19536103308200836,
      "learning_rate": 9.136596101778109e-06,
      "loss": 0.1144,
      "step": 5453
    },
    {
      "epoch": 0.08635622337983122,
      "grad_norm": 2.484938383102417,
      "learning_rate": 9.136437766201688e-06,
      "loss": 0.2836,
      "step": 5454
    },
    {
      "epoch": 0.08637205693747328,
      "grad_norm": 0.0097257811576128,
      "learning_rate": 9.136279430625267e-06,
      "loss": 0.0005,
      "step": 5455
    },
    {
      "epoch": 0.08638789049511535,
      "grad_norm": 0.00014989067858550698,
      "learning_rate": 9.136121095048848e-06,
      "loss": 0.0,
      "step": 5456
    },
    {
      "epoch": 0.08640372405275741,
      "grad_norm": 0.4042203426361084,
      "learning_rate": 9.135962759472427e-06,
      "loss": 0.04,
      "step": 5457
    },
    {
      "epoch": 0.08641955761039948,
      "grad_norm": 0.5480037927627563,
      "learning_rate": 9.135804423896006e-06,
      "loss": 0.5984,
      "step": 5458
    },
    {
      "epoch": 0.08643539116804155,
      "grad_norm": 0.0029167651664465666,
      "learning_rate": 9.135646088319585e-06,
      "loss": 0.0002,
      "step": 5459
    },
    {
      "epoch": 0.08645122472568362,
      "grad_norm": 4.4370157411322e-05,
      "learning_rate": 9.135487752743164e-06,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 0.08646705828332568,
      "grad_norm": 0.00017136185488197953,
      "learning_rate": 9.135329417166743e-06,
      "loss": 0.0,
      "step": 5461
    },
    {
      "epoch": 0.08648289184096775,
      "grad_norm": 0.19598866999149323,
      "learning_rate": 9.135171081590322e-06,
      "loss": 0.2477,
      "step": 5462
    },
    {
      "epoch": 0.08649872539860981,
      "grad_norm": 0.003871303051710129,
      "learning_rate": 9.135012746013903e-06,
      "loss": 0.0002,
      "step": 5463
    },
    {
      "epoch": 0.08651455895625187,
      "grad_norm": 0.23502713441848755,
      "learning_rate": 9.13485441043748e-06,
      "loss": 0.1517,
      "step": 5464
    },
    {
      "epoch": 0.08653039251389395,
      "grad_norm": 0.24185383319854736,
      "learning_rate": 9.134696074861061e-06,
      "loss": 0.1271,
      "step": 5465
    },
    {
      "epoch": 0.08654622607153602,
      "grad_norm": 0.35547569394111633,
      "learning_rate": 9.13453773928464e-06,
      "loss": 0.1022,
      "step": 5466
    },
    {
      "epoch": 0.08656205962917808,
      "grad_norm": 0.38678380846977234,
      "learning_rate": 9.13437940370822e-06,
      "loss": 0.1107,
      "step": 5467
    },
    {
      "epoch": 0.08657789318682015,
      "grad_norm": 0.23957553505897522,
      "learning_rate": 9.134221068131799e-06,
      "loss": 0.0862,
      "step": 5468
    },
    {
      "epoch": 0.08659372674446221,
      "grad_norm": 0.3867385685443878,
      "learning_rate": 9.13406273255538e-06,
      "loss": 0.3883,
      "step": 5469
    },
    {
      "epoch": 0.08660956030210427,
      "grad_norm": 0.00189046876039356,
      "learning_rate": 9.133904396978957e-06,
      "loss": 0.0001,
      "step": 5470
    },
    {
      "epoch": 0.08662539385974635,
      "grad_norm": 0.614645779132843,
      "learning_rate": 9.133746061402538e-06,
      "loss": 0.1961,
      "step": 5471
    },
    {
      "epoch": 0.08664122741738842,
      "grad_norm": 0.3552679717540741,
      "learning_rate": 9.133587725826117e-06,
      "loss": 0.2265,
      "step": 5472
    },
    {
      "epoch": 0.08665706097503048,
      "grad_norm": 0.32258883118629456,
      "learning_rate": 9.133429390249696e-06,
      "loss": 0.1451,
      "step": 5473
    },
    {
      "epoch": 0.08667289453267255,
      "grad_norm": 0.003045748919248581,
      "learning_rate": 9.133271054673275e-06,
      "loss": 0.0001,
      "step": 5474
    },
    {
      "epoch": 0.08668872809031461,
      "grad_norm": 0.0002256243024021387,
      "learning_rate": 9.133112719096856e-06,
      "loss": 0.0,
      "step": 5475
    },
    {
      "epoch": 0.08670456164795667,
      "grad_norm": 0.7529743909835815,
      "learning_rate": 9.132954383520433e-06,
      "loss": 0.2694,
      "step": 5476
    },
    {
      "epoch": 0.08672039520559875,
      "grad_norm": 0.15447954833507538,
      "learning_rate": 9.132796047944014e-06,
      "loss": 0.0699,
      "step": 5477
    },
    {
      "epoch": 0.08673622876324082,
      "grad_norm": 0.3240836560726166,
      "learning_rate": 9.132637712367593e-06,
      "loss": 0.05,
      "step": 5478
    },
    {
      "epoch": 0.08675206232088288,
      "grad_norm": 0.2764265537261963,
      "learning_rate": 9.132479376791172e-06,
      "loss": 0.0927,
      "step": 5479
    },
    {
      "epoch": 0.08676789587852494,
      "grad_norm": 0.4084721505641937,
      "learning_rate": 9.132321041214751e-06,
      "loss": 0.0798,
      "step": 5480
    },
    {
      "epoch": 0.08678372943616701,
      "grad_norm": 0.00010687723261071369,
      "learning_rate": 9.132162705638332e-06,
      "loss": 0.0,
      "step": 5481
    },
    {
      "epoch": 0.08679956299380907,
      "grad_norm": 5.451144897961058e-05,
      "learning_rate": 9.13200437006191e-06,
      "loss": 0.0,
      "step": 5482
    },
    {
      "epoch": 0.08681539655145115,
      "grad_norm": 7.554690819233656e-05,
      "learning_rate": 9.13184603448549e-06,
      "loss": 0.0,
      "step": 5483
    },
    {
      "epoch": 0.08683123010909322,
      "grad_norm": 0.1587599813938141,
      "learning_rate": 9.131687698909069e-06,
      "loss": 0.0708,
      "step": 5484
    },
    {
      "epoch": 0.08684706366673528,
      "grad_norm": 0.22498692572116852,
      "learning_rate": 9.131529363332648e-06,
      "loss": 0.1327,
      "step": 5485
    },
    {
      "epoch": 0.08686289722437734,
      "grad_norm": 0.30727171897888184,
      "learning_rate": 9.131371027756227e-06,
      "loss": 0.0679,
      "step": 5486
    },
    {
      "epoch": 0.08687873078201941,
      "grad_norm": 0.008053160272538662,
      "learning_rate": 9.131212692179806e-06,
      "loss": 0.0004,
      "step": 5487
    },
    {
      "epoch": 0.08689456433966147,
      "grad_norm": 0.5434385538101196,
      "learning_rate": 9.131054356603385e-06,
      "loss": 0.2557,
      "step": 5488
    },
    {
      "epoch": 0.08691039789730355,
      "grad_norm": 0.6192545890808105,
      "learning_rate": 9.130896021026964e-06,
      "loss": 0.7719,
      "step": 5489
    },
    {
      "epoch": 0.08692623145494562,
      "grad_norm": 0.5282269716262817,
      "learning_rate": 9.130737685450545e-06,
      "loss": 0.1517,
      "step": 5490
    },
    {
      "epoch": 0.08694206501258768,
      "grad_norm": 0.3934730887413025,
      "learning_rate": 9.130579349874124e-06,
      "loss": 0.5027,
      "step": 5491
    },
    {
      "epoch": 0.08695789857022974,
      "grad_norm": 0.012455025687813759,
      "learning_rate": 9.130421014297703e-06,
      "loss": 0.0007,
      "step": 5492
    },
    {
      "epoch": 0.08697373212787181,
      "grad_norm": 0.26546451449394226,
      "learning_rate": 9.130262678721282e-06,
      "loss": 0.5553,
      "step": 5493
    },
    {
      "epoch": 0.08698956568551387,
      "grad_norm": 0.0003256367635913193,
      "learning_rate": 9.130104343144862e-06,
      "loss": 0.0,
      "step": 5494
    },
    {
      "epoch": 0.08700539924315595,
      "grad_norm": 0.2277737408876419,
      "learning_rate": 9.12994600756844e-06,
      "loss": 0.1238,
      "step": 5495
    },
    {
      "epoch": 0.08702123280079802,
      "grad_norm": 0.13839544355869293,
      "learning_rate": 9.129787671992021e-06,
      "loss": 0.0531,
      "step": 5496
    },
    {
      "epoch": 0.08703706635844008,
      "grad_norm": 0.4473657011985779,
      "learning_rate": 9.1296293364156e-06,
      "loss": 0.2581,
      "step": 5497
    },
    {
      "epoch": 0.08705289991608214,
      "grad_norm": 0.20695270597934723,
      "learning_rate": 9.12947100083918e-06,
      "loss": 0.1193,
      "step": 5498
    },
    {
      "epoch": 0.08706873347372421,
      "grad_norm": 0.23509517312049866,
      "learning_rate": 9.129312665262759e-06,
      "loss": 0.1125,
      "step": 5499
    },
    {
      "epoch": 0.08708456703136627,
      "grad_norm": 0.9346280097961426,
      "learning_rate": 9.129154329686338e-06,
      "loss": 1.0362,
      "step": 5500
    },
    {
      "epoch": 0.08710040058900835,
      "grad_norm": 2.7491724491119385,
      "learning_rate": 9.128995994109917e-06,
      "loss": 0.4801,
      "step": 5501
    },
    {
      "epoch": 0.08711623414665041,
      "grad_norm": 0.26073339581489563,
      "learning_rate": 9.128837658533498e-06,
      "loss": 0.3718,
      "step": 5502
    },
    {
      "epoch": 0.08713206770429248,
      "grad_norm": 0.010898633860051632,
      "learning_rate": 9.128679322957077e-06,
      "loss": 0.0006,
      "step": 5503
    },
    {
      "epoch": 0.08714790126193454,
      "grad_norm": 0.3504226803779602,
      "learning_rate": 9.128520987380656e-06,
      "loss": 0.3551,
      "step": 5504
    },
    {
      "epoch": 0.08716373481957661,
      "grad_norm": 0.33155709505081177,
      "learning_rate": 9.128362651804235e-06,
      "loss": 0.4729,
      "step": 5505
    },
    {
      "epoch": 0.08717956837721867,
      "grad_norm": 0.24062445759773254,
      "learning_rate": 9.128204316227814e-06,
      "loss": 0.1863,
      "step": 5506
    },
    {
      "epoch": 0.08719540193486075,
      "grad_norm": 0.04550374671816826,
      "learning_rate": 9.128045980651393e-06,
      "loss": 0.003,
      "step": 5507
    },
    {
      "epoch": 0.08721123549250281,
      "grad_norm": 0.0029655734542757273,
      "learning_rate": 9.127887645074974e-06,
      "loss": 0.0001,
      "step": 5508
    },
    {
      "epoch": 0.08722706905014488,
      "grad_norm": 0.4209648370742798,
      "learning_rate": 9.127729309498553e-06,
      "loss": 0.0931,
      "step": 5509
    },
    {
      "epoch": 0.08724290260778694,
      "grad_norm": 0.5611530542373657,
      "learning_rate": 9.12757097392213e-06,
      "loss": 0.0359,
      "step": 5510
    },
    {
      "epoch": 0.08725873616542901,
      "grad_norm": 0.005133769009262323,
      "learning_rate": 9.127412638345711e-06,
      "loss": 0.0002,
      "step": 5511
    },
    {
      "epoch": 0.08727456972307107,
      "grad_norm": 0.0007096377667039633,
      "learning_rate": 9.12725430276929e-06,
      "loss": 0.0,
      "step": 5512
    },
    {
      "epoch": 0.08729040328071315,
      "grad_norm": 0.28093430399894714,
      "learning_rate": 9.127095967192869e-06,
      "loss": 0.1734,
      "step": 5513
    },
    {
      "epoch": 0.08730623683835521,
      "grad_norm": 0.16616204380989075,
      "learning_rate": 9.126937631616448e-06,
      "loss": 0.0408,
      "step": 5514
    },
    {
      "epoch": 0.08732207039599728,
      "grad_norm": 0.35114791989326477,
      "learning_rate": 9.126779296040027e-06,
      "loss": 0.0724,
      "step": 5515
    },
    {
      "epoch": 0.08733790395363934,
      "grad_norm": 0.016929131001234055,
      "learning_rate": 9.126620960463606e-06,
      "loss": 0.0008,
      "step": 5516
    },
    {
      "epoch": 0.0873537375112814,
      "grad_norm": 0.1544640213251114,
      "learning_rate": 9.126462624887187e-06,
      "loss": 0.0633,
      "step": 5517
    },
    {
      "epoch": 0.08736957106892347,
      "grad_norm": 0.20086687803268433,
      "learning_rate": 9.126304289310766e-06,
      "loss": 0.1147,
      "step": 5518
    },
    {
      "epoch": 0.08738540462656555,
      "grad_norm": 0.437750905752182,
      "learning_rate": 9.126145953734345e-06,
      "loss": 0.4404,
      "step": 5519
    },
    {
      "epoch": 0.08740123818420761,
      "grad_norm": 0.4227297008037567,
      "learning_rate": 9.125987618157924e-06,
      "loss": 0.0905,
      "step": 5520
    },
    {
      "epoch": 0.08741707174184968,
      "grad_norm": 0.29025906324386597,
      "learning_rate": 9.125829282581503e-06,
      "loss": 0.1175,
      "step": 5521
    },
    {
      "epoch": 0.08743290529949174,
      "grad_norm": 0.3002965748310089,
      "learning_rate": 9.125670947005083e-06,
      "loss": 0.0793,
      "step": 5522
    },
    {
      "epoch": 0.0874487388571338,
      "grad_norm": 0.5666307210922241,
      "learning_rate": 9.125512611428663e-06,
      "loss": 0.0505,
      "step": 5523
    },
    {
      "epoch": 0.08746457241477587,
      "grad_norm": 0.40868011116981506,
      "learning_rate": 9.125354275852242e-06,
      "loss": 2.0742,
      "step": 5524
    },
    {
      "epoch": 0.08748040597241795,
      "grad_norm": 0.13282032310962677,
      "learning_rate": 9.125195940275821e-06,
      "loss": 0.0541,
      "step": 5525
    },
    {
      "epoch": 0.08749623953006001,
      "grad_norm": 0.40528741478919983,
      "learning_rate": 9.1250376046994e-06,
      "loss": 0.1139,
      "step": 5526
    },
    {
      "epoch": 0.08751207308770208,
      "grad_norm": 0.2453279048204422,
      "learning_rate": 9.12487926912298e-06,
      "loss": 0.1284,
      "step": 5527
    },
    {
      "epoch": 0.08752790664534414,
      "grad_norm": 0.034293804317712784,
      "learning_rate": 9.124720933546559e-06,
      "loss": 0.0024,
      "step": 5528
    },
    {
      "epoch": 0.0875437402029862,
      "grad_norm": 0.005648362450301647,
      "learning_rate": 9.12456259797014e-06,
      "loss": 0.0002,
      "step": 5529
    },
    {
      "epoch": 0.08755957376062827,
      "grad_norm": 0.37312790751457214,
      "learning_rate": 9.124404262393719e-06,
      "loss": 0.2087,
      "step": 5530
    },
    {
      "epoch": 0.08757540731827035,
      "grad_norm": 0.0021534522529691458,
      "learning_rate": 9.124245926817298e-06,
      "loss": 0.0001,
      "step": 5531
    },
    {
      "epoch": 0.08759124087591241,
      "grad_norm": 0.016696514561772346,
      "learning_rate": 9.124087591240877e-06,
      "loss": 0.0009,
      "step": 5532
    },
    {
      "epoch": 0.08760707443355448,
      "grad_norm": 0.1436855047941208,
      "learning_rate": 9.123929255664456e-06,
      "loss": 0.0596,
      "step": 5533
    },
    {
      "epoch": 0.08762290799119654,
      "grad_norm": 0.32146427035331726,
      "learning_rate": 9.123770920088035e-06,
      "loss": 0.1311,
      "step": 5534
    },
    {
      "epoch": 0.0876387415488386,
      "grad_norm": 0.4542737603187561,
      "learning_rate": 9.123612584511614e-06,
      "loss": 0.7362,
      "step": 5535
    },
    {
      "epoch": 0.08765457510648067,
      "grad_norm": 0.6909570693969727,
      "learning_rate": 9.123454248935195e-06,
      "loss": 0.4632,
      "step": 5536
    },
    {
      "epoch": 0.08767040866412275,
      "grad_norm": 0.00015180990158114582,
      "learning_rate": 9.123295913358772e-06,
      "loss": 0.0,
      "step": 5537
    },
    {
      "epoch": 0.08768624222176481,
      "grad_norm": 0.14986473321914673,
      "learning_rate": 9.123137577782353e-06,
      "loss": 0.0589,
      "step": 5538
    },
    {
      "epoch": 0.08770207577940688,
      "grad_norm": 0.5830324292182922,
      "learning_rate": 9.122979242205932e-06,
      "loss": 0.0656,
      "step": 5539
    },
    {
      "epoch": 0.08771790933704894,
      "grad_norm": 0.35870450735092163,
      "learning_rate": 9.122820906629511e-06,
      "loss": 0.2042,
      "step": 5540
    },
    {
      "epoch": 0.087733742894691,
      "grad_norm": 0.613903820514679,
      "learning_rate": 9.12266257105309e-06,
      "loss": 0.4361,
      "step": 5541
    },
    {
      "epoch": 0.08774957645233307,
      "grad_norm": 0.019684284925460815,
      "learning_rate": 9.122504235476671e-06,
      "loss": 0.0006,
      "step": 5542
    },
    {
      "epoch": 0.08776541000997515,
      "grad_norm": 0.2465372383594513,
      "learning_rate": 9.122345899900248e-06,
      "loss": 0.1866,
      "step": 5543
    },
    {
      "epoch": 0.08778124356761721,
      "grad_norm": 0.9202368855476379,
      "learning_rate": 9.122187564323829e-06,
      "loss": 0.1583,
      "step": 5544
    },
    {
      "epoch": 0.08779707712525928,
      "grad_norm": 0.03074272722005844,
      "learning_rate": 9.122029228747408e-06,
      "loss": 0.0013,
      "step": 5545
    },
    {
      "epoch": 0.08781291068290134,
      "grad_norm": 0.07968200743198395,
      "learning_rate": 9.121870893170987e-06,
      "loss": 0.0106,
      "step": 5546
    },
    {
      "epoch": 0.0878287442405434,
      "grad_norm": 0.002193273277953267,
      "learning_rate": 9.121712557594566e-06,
      "loss": 0.0,
      "step": 5547
    },
    {
      "epoch": 0.08784457779818547,
      "grad_norm": 0.26738762855529785,
      "learning_rate": 9.121554222018147e-06,
      "loss": 0.1742,
      "step": 5548
    },
    {
      "epoch": 0.08786041135582755,
      "grad_norm": 0.04311013221740723,
      "learning_rate": 9.121395886441724e-06,
      "loss": 0.0066,
      "step": 5549
    },
    {
      "epoch": 0.08787624491346961,
      "grad_norm": 0.7720202207565308,
      "learning_rate": 9.121237550865305e-06,
      "loss": 0.2313,
      "step": 5550
    },
    {
      "epoch": 0.08789207847111168,
      "grad_norm": 0.0012532839318737388,
      "learning_rate": 9.121079215288884e-06,
      "loss": 0.0,
      "step": 5551
    },
    {
      "epoch": 0.08790791202875374,
      "grad_norm": 0.32757943868637085,
      "learning_rate": 9.120920879712463e-06,
      "loss": 0.1909,
      "step": 5552
    },
    {
      "epoch": 0.0879237455863958,
      "grad_norm": 0.3143359422683716,
      "learning_rate": 9.120762544136042e-06,
      "loss": 0.1131,
      "step": 5553
    },
    {
      "epoch": 0.08793957914403787,
      "grad_norm": 0.0001502253144280985,
      "learning_rate": 9.120604208559623e-06,
      "loss": 0.0,
      "step": 5554
    },
    {
      "epoch": 0.08795541270167995,
      "grad_norm": 0.02736288495361805,
      "learning_rate": 9.1204458729832e-06,
      "loss": 0.0015,
      "step": 5555
    },
    {
      "epoch": 0.08797124625932201,
      "grad_norm": 0.01205176580697298,
      "learning_rate": 9.120287537406781e-06,
      "loss": 0.0006,
      "step": 5556
    },
    {
      "epoch": 0.08798707981696408,
      "grad_norm": 0.21454563736915588,
      "learning_rate": 9.12012920183036e-06,
      "loss": 0.15,
      "step": 5557
    },
    {
      "epoch": 0.08800291337460614,
      "grad_norm": 0.3153746724128723,
      "learning_rate": 9.11997086625394e-06,
      "loss": 0.0678,
      "step": 5558
    },
    {
      "epoch": 0.0880187469322482,
      "grad_norm": 0.28716787695884705,
      "learning_rate": 9.119812530677519e-06,
      "loss": 0.7596,
      "step": 5559
    },
    {
      "epoch": 0.08803458048989027,
      "grad_norm": 0.16376993060112,
      "learning_rate": 9.119654195101098e-06,
      "loss": 0.1322,
      "step": 5560
    },
    {
      "epoch": 0.08805041404753235,
      "grad_norm": 0.46997901797294617,
      "learning_rate": 9.119495859524677e-06,
      "loss": 0.1407,
      "step": 5561
    },
    {
      "epoch": 0.08806624760517441,
      "grad_norm": 0.3564887046813965,
      "learning_rate": 9.119337523948256e-06,
      "loss": 0.3029,
      "step": 5562
    },
    {
      "epoch": 0.08808208116281648,
      "grad_norm": 0.025954455137252808,
      "learning_rate": 9.119179188371837e-06,
      "loss": 0.0007,
      "step": 5563
    },
    {
      "epoch": 0.08809791472045854,
      "grad_norm": 0.00019478198373690248,
      "learning_rate": 9.119020852795416e-06,
      "loss": 0.0,
      "step": 5564
    },
    {
      "epoch": 0.0881137482781006,
      "grad_norm": 0.21861596405506134,
      "learning_rate": 9.118862517218995e-06,
      "loss": 0.0912,
      "step": 5565
    },
    {
      "epoch": 0.08812958183574267,
      "grad_norm": 0.15989841520786285,
      "learning_rate": 9.118704181642574e-06,
      "loss": 0.0833,
      "step": 5566
    },
    {
      "epoch": 0.08814541539338475,
      "grad_norm": 0.009698265232145786,
      "learning_rate": 9.118545846066153e-06,
      "loss": 0.0003,
      "step": 5567
    },
    {
      "epoch": 0.08816124895102681,
      "grad_norm": 0.17193937301635742,
      "learning_rate": 9.118387510489732e-06,
      "loss": 0.0297,
      "step": 5568
    },
    {
      "epoch": 0.08817708250866887,
      "grad_norm": 0.003699801629409194,
      "learning_rate": 9.118229174913313e-06,
      "loss": 0.0001,
      "step": 5569
    },
    {
      "epoch": 0.08819291606631094,
      "grad_norm": 0.20203591883182526,
      "learning_rate": 9.118070839336892e-06,
      "loss": 0.0919,
      "step": 5570
    },
    {
      "epoch": 0.088208749623953,
      "grad_norm": 0.2622535228729248,
      "learning_rate": 9.117912503760471e-06,
      "loss": 0.1653,
      "step": 5571
    },
    {
      "epoch": 0.08822458318159507,
      "grad_norm": 1.075243353843689,
      "learning_rate": 9.11775416818405e-06,
      "loss": 0.1535,
      "step": 5572
    },
    {
      "epoch": 0.08824041673923715,
      "grad_norm": 0.43173089623451233,
      "learning_rate": 9.117595832607629e-06,
      "loss": 1.0402,
      "step": 5573
    },
    {
      "epoch": 0.08825625029687921,
      "grad_norm": 0.11064528673887253,
      "learning_rate": 9.117437497031208e-06,
      "loss": 0.0069,
      "step": 5574
    },
    {
      "epoch": 0.08827208385452127,
      "grad_norm": 0.3975319266319275,
      "learning_rate": 9.117279161454789e-06,
      "loss": 0.1551,
      "step": 5575
    },
    {
      "epoch": 0.08828791741216334,
      "grad_norm": 0.3570253849029541,
      "learning_rate": 9.117120825878368e-06,
      "loss": 0.5509,
      "step": 5576
    },
    {
      "epoch": 0.0883037509698054,
      "grad_norm": 0.39449718594551086,
      "learning_rate": 9.116962490301947e-06,
      "loss": 0.3764,
      "step": 5577
    },
    {
      "epoch": 0.08831958452744747,
      "grad_norm": 0.3051920235157013,
      "learning_rate": 9.116804154725526e-06,
      "loss": 0.4344,
      "step": 5578
    },
    {
      "epoch": 0.08833541808508955,
      "grad_norm": 0.3046642243862152,
      "learning_rate": 9.116645819149105e-06,
      "loss": 0.2133,
      "step": 5579
    },
    {
      "epoch": 0.08835125164273161,
      "grad_norm": 0.02036581002175808,
      "learning_rate": 9.116487483572684e-06,
      "loss": 0.0011,
      "step": 5580
    },
    {
      "epoch": 0.08836708520037367,
      "grad_norm": 0.1759779006242752,
      "learning_rate": 9.116329147996265e-06,
      "loss": 0.0438,
      "step": 5581
    },
    {
      "epoch": 0.08838291875801574,
      "grad_norm": 0.33016708493232727,
      "learning_rate": 9.116170812419843e-06,
      "loss": 0.1808,
      "step": 5582
    },
    {
      "epoch": 0.0883987523156578,
      "grad_norm": 0.6298999190330505,
      "learning_rate": 9.116012476843422e-06,
      "loss": 0.4045,
      "step": 5583
    },
    {
      "epoch": 0.08841458587329987,
      "grad_norm": 0.19955995678901672,
      "learning_rate": 9.115854141267002e-06,
      "loss": 0.1603,
      "step": 5584
    },
    {
      "epoch": 0.08843041943094195,
      "grad_norm": 0.22401297092437744,
      "learning_rate": 9.115695805690581e-06,
      "loss": 0.1753,
      "step": 5585
    },
    {
      "epoch": 0.08844625298858401,
      "grad_norm": 0.11686310172080994,
      "learning_rate": 9.11553747011416e-06,
      "loss": 0.1117,
      "step": 5586
    },
    {
      "epoch": 0.08846208654622607,
      "grad_norm": 0.03880731388926506,
      "learning_rate": 9.11537913453774e-06,
      "loss": 0.0022,
      "step": 5587
    },
    {
      "epoch": 0.08847792010386814,
      "grad_norm": 0.4069405794143677,
      "learning_rate": 9.115220798961319e-06,
      "loss": 0.1702,
      "step": 5588
    },
    {
      "epoch": 0.0884937536615102,
      "grad_norm": 0.18607617914676666,
      "learning_rate": 9.115062463384898e-06,
      "loss": 0.1609,
      "step": 5589
    },
    {
      "epoch": 0.08850958721915227,
      "grad_norm": 0.41741737723350525,
      "learning_rate": 9.114904127808479e-06,
      "loss": 0.5347,
      "step": 5590
    },
    {
      "epoch": 0.08852542077679434,
      "grad_norm": 0.013313126750290394,
      "learning_rate": 9.114745792232058e-06,
      "loss": 0.0008,
      "step": 5591
    },
    {
      "epoch": 0.08854125433443641,
      "grad_norm": 0.49094218015670776,
      "learning_rate": 9.114587456655637e-06,
      "loss": 0.0718,
      "step": 5592
    },
    {
      "epoch": 0.08855708789207847,
      "grad_norm": 0.5306506156921387,
      "learning_rate": 9.114429121079216e-06,
      "loss": 0.1922,
      "step": 5593
    },
    {
      "epoch": 0.08857292144972054,
      "grad_norm": 0.38541892170906067,
      "learning_rate": 9.114270785502795e-06,
      "loss": 0.3073,
      "step": 5594
    },
    {
      "epoch": 0.0885887550073626,
      "grad_norm": 0.1745900958776474,
      "learning_rate": 9.114112449926374e-06,
      "loss": 0.0745,
      "step": 5595
    },
    {
      "epoch": 0.08860458856500467,
      "grad_norm": 0.437310129404068,
      "learning_rate": 9.113954114349955e-06,
      "loss": 0.2161,
      "step": 5596
    },
    {
      "epoch": 0.08862042212264674,
      "grad_norm": 0.06725147366523743,
      "learning_rate": 9.113795778773534e-06,
      "loss": 0.0011,
      "step": 5597
    },
    {
      "epoch": 0.08863625568028881,
      "grad_norm": 3.2746778742875904e-05,
      "learning_rate": 9.113637443197113e-06,
      "loss": 0.0,
      "step": 5598
    },
    {
      "epoch": 0.08865208923793087,
      "grad_norm": 0.05106212571263313,
      "learning_rate": 9.113479107620692e-06,
      "loss": 0.005,
      "step": 5599
    },
    {
      "epoch": 0.08866792279557294,
      "grad_norm": 1.7942719459533691,
      "learning_rate": 9.113320772044271e-06,
      "loss": 0.2264,
      "step": 5600
    },
    {
      "epoch": 0.088683756353215,
      "grad_norm": 0.04653019458055496,
      "learning_rate": 9.11316243646785e-06,
      "loss": 0.0034,
      "step": 5601
    },
    {
      "epoch": 0.08869958991085707,
      "grad_norm": 0.028302744030952454,
      "learning_rate": 9.113004100891431e-06,
      "loss": 0.0013,
      "step": 5602
    },
    {
      "epoch": 0.08871542346849914,
      "grad_norm": 0.48178282380104065,
      "learning_rate": 9.11284576531501e-06,
      "loss": 0.3288,
      "step": 5603
    },
    {
      "epoch": 0.08873125702614121,
      "grad_norm": 0.19602154195308685,
      "learning_rate": 9.112687429738589e-06,
      "loss": 0.0027,
      "step": 5604
    },
    {
      "epoch": 0.08874709058378327,
      "grad_norm": 0.2340545952320099,
      "learning_rate": 9.112529094162168e-06,
      "loss": 0.1176,
      "step": 5605
    },
    {
      "epoch": 0.08876292414142534,
      "grad_norm": 0.0001768414513207972,
      "learning_rate": 9.112370758585747e-06,
      "loss": 0.0,
      "step": 5606
    },
    {
      "epoch": 0.0887787576990674,
      "grad_norm": 0.07241503149271011,
      "learning_rate": 9.112212423009326e-06,
      "loss": 0.0163,
      "step": 5607
    },
    {
      "epoch": 0.08879459125670947,
      "grad_norm": 0.11258896440267563,
      "learning_rate": 9.112054087432905e-06,
      "loss": 0.0238,
      "step": 5608
    },
    {
      "epoch": 0.08881042481435154,
      "grad_norm": 0.6578502058982849,
      "learning_rate": 9.111895751856486e-06,
      "loss": 0.4998,
      "step": 5609
    },
    {
      "epoch": 0.08882625837199361,
      "grad_norm": 0.5099201202392578,
      "learning_rate": 9.111737416280064e-06,
      "loss": 0.3302,
      "step": 5610
    },
    {
      "epoch": 0.08884209192963567,
      "grad_norm": 0.4186899960041046,
      "learning_rate": 9.111579080703644e-06,
      "loss": 0.4998,
      "step": 5611
    },
    {
      "epoch": 0.08885792548727774,
      "grad_norm": 0.47664177417755127,
      "learning_rate": 9.111420745127223e-06,
      "loss": 0.2303,
      "step": 5612
    },
    {
      "epoch": 0.0888737590449198,
      "grad_norm": 0.03486936539411545,
      "learning_rate": 9.111262409550802e-06,
      "loss": 0.0023,
      "step": 5613
    },
    {
      "epoch": 0.08888959260256186,
      "grad_norm": 0.03221843019127846,
      "learning_rate": 9.111104073974382e-06,
      "loss": 0.0018,
      "step": 5614
    },
    {
      "epoch": 0.08890542616020394,
      "grad_norm": 0.15238521993160248,
      "learning_rate": 9.110945738397962e-06,
      "loss": 0.0733,
      "step": 5615
    },
    {
      "epoch": 0.08892125971784601,
      "grad_norm": 0.2697770297527313,
      "learning_rate": 9.11078740282154e-06,
      "loss": 0.1222,
      "step": 5616
    },
    {
      "epoch": 0.08893709327548807,
      "grad_norm": 0.19655488431453705,
      "learning_rate": 9.11062906724512e-06,
      "loss": 0.0751,
      "step": 5617
    },
    {
      "epoch": 0.08895292683313014,
      "grad_norm": 0.25383707880973816,
      "learning_rate": 9.1104707316687e-06,
      "loss": 0.2579,
      "step": 5618
    },
    {
      "epoch": 0.0889687603907722,
      "grad_norm": 0.17493392527103424,
      "learning_rate": 9.110312396092279e-06,
      "loss": 0.067,
      "step": 5619
    },
    {
      "epoch": 0.08898459394841426,
      "grad_norm": 0.46576419472694397,
      "learning_rate": 9.110154060515858e-06,
      "loss": 0.1923,
      "step": 5620
    },
    {
      "epoch": 0.08900042750605634,
      "grad_norm": 0.20281389355659485,
      "learning_rate": 9.109995724939438e-06,
      "loss": 0.0907,
      "step": 5621
    },
    {
      "epoch": 0.08901626106369841,
      "grad_norm": 0.19773617386817932,
      "learning_rate": 9.109837389363016e-06,
      "loss": 0.0437,
      "step": 5622
    },
    {
      "epoch": 0.08903209462134047,
      "grad_norm": 0.052334193140268326,
      "learning_rate": 9.109679053786597e-06,
      "loss": 0.0032,
      "step": 5623
    },
    {
      "epoch": 0.08904792817898254,
      "grad_norm": 0.1632828712463379,
      "learning_rate": 9.109520718210176e-06,
      "loss": 0.0574,
      "step": 5624
    },
    {
      "epoch": 0.0890637617366246,
      "grad_norm": 0.11702457815408707,
      "learning_rate": 9.109362382633755e-06,
      "loss": 0.051,
      "step": 5625
    },
    {
      "epoch": 0.08907959529426666,
      "grad_norm": 0.35498014092445374,
      "learning_rate": 9.109204047057334e-06,
      "loss": 0.1449,
      "step": 5626
    },
    {
      "epoch": 0.08909542885190874,
      "grad_norm": 0.04848852753639221,
      "learning_rate": 9.109045711480915e-06,
      "loss": 0.002,
      "step": 5627
    },
    {
      "epoch": 0.0891112624095508,
      "grad_norm": 0.7049124836921692,
      "learning_rate": 9.108887375904492e-06,
      "loss": 0.4922,
      "step": 5628
    },
    {
      "epoch": 0.08912709596719287,
      "grad_norm": 0.19566912949085236,
      "learning_rate": 9.108729040328073e-06,
      "loss": 0.0719,
      "step": 5629
    },
    {
      "epoch": 0.08914292952483494,
      "grad_norm": 0.14385242760181427,
      "learning_rate": 9.108570704751652e-06,
      "loss": 0.0409,
      "step": 5630
    },
    {
      "epoch": 0.089158763082477,
      "grad_norm": 0.14691492915153503,
      "learning_rate": 9.108412369175231e-06,
      "loss": 0.0773,
      "step": 5631
    },
    {
      "epoch": 0.08917459664011906,
      "grad_norm": 0.21374385058879852,
      "learning_rate": 9.10825403359881e-06,
      "loss": 0.3471,
      "step": 5632
    },
    {
      "epoch": 0.08919043019776113,
      "grad_norm": 0.21439413726329803,
      "learning_rate": 9.108095698022389e-06,
      "loss": 0.1632,
      "step": 5633
    },
    {
      "epoch": 0.0892062637554032,
      "grad_norm": 2.8486077785491943,
      "learning_rate": 9.107937362445968e-06,
      "loss": 0.0888,
      "step": 5634
    },
    {
      "epoch": 0.08922209731304527,
      "grad_norm": 0.07086006551980972,
      "learning_rate": 9.107779026869547e-06,
      "loss": 0.002,
      "step": 5635
    },
    {
      "epoch": 0.08923793087068733,
      "grad_norm": 0.40750938653945923,
      "learning_rate": 9.107620691293128e-06,
      "loss": 0.0612,
      "step": 5636
    },
    {
      "epoch": 0.0892537644283294,
      "grad_norm": 0.278354287147522,
      "learning_rate": 9.107462355716707e-06,
      "loss": 0.0725,
      "step": 5637
    },
    {
      "epoch": 0.08926959798597146,
      "grad_norm": 0.2109740823507309,
      "learning_rate": 9.107304020140286e-06,
      "loss": 0.1812,
      "step": 5638
    },
    {
      "epoch": 0.08928543154361353,
      "grad_norm": 0.1406598836183548,
      "learning_rate": 9.107145684563865e-06,
      "loss": 0.0082,
      "step": 5639
    },
    {
      "epoch": 0.0893012651012556,
      "grad_norm": 0.0005297219031490386,
      "learning_rate": 9.106987348987444e-06,
      "loss": 0.0,
      "step": 5640
    },
    {
      "epoch": 0.08931709865889767,
      "grad_norm": 0.005763145163655281,
      "learning_rate": 9.106829013411023e-06,
      "loss": 0.0002,
      "step": 5641
    },
    {
      "epoch": 0.08933293221653973,
      "grad_norm": 0.24665561318397522,
      "learning_rate": 9.106670677834604e-06,
      "loss": 0.0054,
      "step": 5642
    },
    {
      "epoch": 0.0893487657741818,
      "grad_norm": 0.15701399743556976,
      "learning_rate": 9.106512342258183e-06,
      "loss": 0.0201,
      "step": 5643
    },
    {
      "epoch": 0.08936459933182386,
      "grad_norm": 0.8320066928863525,
      "learning_rate": 9.106354006681762e-06,
      "loss": 0.2726,
      "step": 5644
    },
    {
      "epoch": 0.08938043288946593,
      "grad_norm": 0.29201117157936096,
      "learning_rate": 9.106195671105341e-06,
      "loss": 0.0326,
      "step": 5645
    },
    {
      "epoch": 0.089396266447108,
      "grad_norm": 6.951740942895412e-05,
      "learning_rate": 9.10603733552892e-06,
      "loss": 0.0,
      "step": 5646
    },
    {
      "epoch": 0.08941210000475007,
      "grad_norm": 0.41203147172927856,
      "learning_rate": 9.1058789999525e-06,
      "loss": 0.4166,
      "step": 5647
    },
    {
      "epoch": 0.08942793356239213,
      "grad_norm": 0.22711791098117828,
      "learning_rate": 9.10572066437608e-06,
      "loss": 0.0189,
      "step": 5648
    },
    {
      "epoch": 0.0894437671200342,
      "grad_norm": 0.39252275228500366,
      "learning_rate": 9.105562328799658e-06,
      "loss": 0.2372,
      "step": 5649
    },
    {
      "epoch": 0.08945960067767626,
      "grad_norm": 0.16615872085094452,
      "learning_rate": 9.105403993223239e-06,
      "loss": 0.0032,
      "step": 5650
    },
    {
      "epoch": 0.08947543423531833,
      "grad_norm": 0.20522426068782806,
      "learning_rate": 9.105245657646818e-06,
      "loss": 0.2827,
      "step": 5651
    },
    {
      "epoch": 0.0894912677929604,
      "grad_norm": 0.40409624576568604,
      "learning_rate": 9.105087322070397e-06,
      "loss": 0.1855,
      "step": 5652
    },
    {
      "epoch": 0.08950710135060247,
      "grad_norm": 0.2406604140996933,
      "learning_rate": 9.104928986493976e-06,
      "loss": 0.0582,
      "step": 5653
    },
    {
      "epoch": 0.08952293490824453,
      "grad_norm": 0.3979114294052124,
      "learning_rate": 9.104770650917557e-06,
      "loss": 0.3968,
      "step": 5654
    },
    {
      "epoch": 0.0895387684658866,
      "grad_norm": 0.00044837972382083535,
      "learning_rate": 9.104612315341134e-06,
      "loss": 0.0,
      "step": 5655
    },
    {
      "epoch": 0.08955460202352866,
      "grad_norm": 0.4849660396575928,
      "learning_rate": 9.104453979764713e-06,
      "loss": 0.2149,
      "step": 5656
    },
    {
      "epoch": 0.08957043558117073,
      "grad_norm": 0.4833742380142212,
      "learning_rate": 9.104295644188294e-06,
      "loss": 0.6455,
      "step": 5657
    },
    {
      "epoch": 0.0895862691388128,
      "grad_norm": 0.5252143144607544,
      "learning_rate": 9.104137308611873e-06,
      "loss": 0.6511,
      "step": 5658
    },
    {
      "epoch": 0.08960210269645487,
      "grad_norm": 0.17912444472312927,
      "learning_rate": 9.103978973035452e-06,
      "loss": 0.0587,
      "step": 5659
    },
    {
      "epoch": 0.08961793625409693,
      "grad_norm": 0.48026394844055176,
      "learning_rate": 9.103820637459031e-06,
      "loss": 0.1224,
      "step": 5660
    },
    {
      "epoch": 0.089633769811739,
      "grad_norm": 0.5605505704879761,
      "learning_rate": 9.10366230188261e-06,
      "loss": 0.6114,
      "step": 5661
    },
    {
      "epoch": 0.08964960336938106,
      "grad_norm": 0.3784463703632355,
      "learning_rate": 9.10350396630619e-06,
      "loss": 0.1462,
      "step": 5662
    },
    {
      "epoch": 0.08966543692702313,
      "grad_norm": 0.22817644476890564,
      "learning_rate": 9.10334563072977e-06,
      "loss": 0.049,
      "step": 5663
    },
    {
      "epoch": 0.0896812704846652,
      "grad_norm": 0.0126157496124506,
      "learning_rate": 9.103187295153349e-06,
      "loss": 0.0004,
      "step": 5664
    },
    {
      "epoch": 0.08969710404230727,
      "grad_norm": 0.03187759965658188,
      "learning_rate": 9.103028959576928e-06,
      "loss": 0.0009,
      "step": 5665
    },
    {
      "epoch": 0.08971293759994933,
      "grad_norm": 0.05578775703907013,
      "learning_rate": 9.102870624000507e-06,
      "loss": 0.0018,
      "step": 5666
    },
    {
      "epoch": 0.0897287711575914,
      "grad_norm": 0.6061838865280151,
      "learning_rate": 9.102712288424086e-06,
      "loss": 0.428,
      "step": 5667
    },
    {
      "epoch": 0.08974460471523346,
      "grad_norm": 0.5943474769592285,
      "learning_rate": 9.102553952847665e-06,
      "loss": 0.1131,
      "step": 5668
    },
    {
      "epoch": 0.08976043827287553,
      "grad_norm": 0.3654324412345886,
      "learning_rate": 9.102395617271246e-06,
      "loss": 0.0547,
      "step": 5669
    },
    {
      "epoch": 0.0897762718305176,
      "grad_norm": 0.3171839416027069,
      "learning_rate": 9.102237281694825e-06,
      "loss": 0.4727,
      "step": 5670
    },
    {
      "epoch": 0.08979210538815967,
      "grad_norm": 0.32600855827331543,
      "learning_rate": 9.102078946118404e-06,
      "loss": 0.2024,
      "step": 5671
    },
    {
      "epoch": 0.08980793894580173,
      "grad_norm": 0.40466195344924927,
      "learning_rate": 9.101920610541983e-06,
      "loss": 0.0376,
      "step": 5672
    },
    {
      "epoch": 0.0898237725034438,
      "grad_norm": 0.6711241006851196,
      "learning_rate": 9.101762274965562e-06,
      "loss": 0.0828,
      "step": 5673
    },
    {
      "epoch": 0.08983960606108586,
      "grad_norm": 0.30910757184028625,
      "learning_rate": 9.101603939389142e-06,
      "loss": 0.0566,
      "step": 5674
    },
    {
      "epoch": 0.08985543961872793,
      "grad_norm": 0.7583175897598267,
      "learning_rate": 9.101445603812722e-06,
      "loss": 0.5377,
      "step": 5675
    },
    {
      "epoch": 0.08987127317637,
      "grad_norm": 0.4130851924419403,
      "learning_rate": 9.101287268236301e-06,
      "loss": 0.1298,
      "step": 5676
    },
    {
      "epoch": 0.08988710673401207,
      "grad_norm": 0.02859812043607235,
      "learning_rate": 9.10112893265988e-06,
      "loss": 0.0017,
      "step": 5677
    },
    {
      "epoch": 0.08990294029165413,
      "grad_norm": 0.7179145216941833,
      "learning_rate": 9.10097059708346e-06,
      "loss": 0.2829,
      "step": 5678
    },
    {
      "epoch": 0.0899187738492962,
      "grad_norm": 0.31620320677757263,
      "learning_rate": 9.100812261507039e-06,
      "loss": 0.5399,
      "step": 5679
    },
    {
      "epoch": 0.08993460740693826,
      "grad_norm": 0.022888988256454468,
      "learning_rate": 9.100653925930618e-06,
      "loss": 0.0011,
      "step": 5680
    },
    {
      "epoch": 0.08995044096458032,
      "grad_norm": 0.19608436524868011,
      "learning_rate": 9.100495590354197e-06,
      "loss": 0.086,
      "step": 5681
    },
    {
      "epoch": 0.0899662745222224,
      "grad_norm": 0.335688978433609,
      "learning_rate": 9.100337254777778e-06,
      "loss": 0.0481,
      "step": 5682
    },
    {
      "epoch": 0.08998210807986447,
      "grad_norm": 0.19504296779632568,
      "learning_rate": 9.100178919201355e-06,
      "loss": 0.072,
      "step": 5683
    },
    {
      "epoch": 0.08999794163750653,
      "grad_norm": 0.6935084462165833,
      "learning_rate": 9.100020583624936e-06,
      "loss": 0.76,
      "step": 5684
    },
    {
      "epoch": 0.0900137751951486,
      "grad_norm": 1.067596673965454,
      "learning_rate": 9.099862248048515e-06,
      "loss": 0.4965,
      "step": 5685
    },
    {
      "epoch": 0.09002960875279066,
      "grad_norm": 0.3584855794906616,
      "learning_rate": 9.099703912472094e-06,
      "loss": 0.0551,
      "step": 5686
    },
    {
      "epoch": 0.09004544231043272,
      "grad_norm": 0.003799829864874482,
      "learning_rate": 9.099545576895673e-06,
      "loss": 0.0001,
      "step": 5687
    },
    {
      "epoch": 0.0900612758680748,
      "grad_norm": 0.7218289375305176,
      "learning_rate": 9.099387241319254e-06,
      "loss": 0.3193,
      "step": 5688
    },
    {
      "epoch": 0.09007710942571687,
      "grad_norm": 0.2740188241004944,
      "learning_rate": 9.099228905742831e-06,
      "loss": 0.1207,
      "step": 5689
    },
    {
      "epoch": 0.09009294298335893,
      "grad_norm": 5.756852624472231e-05,
      "learning_rate": 9.099070570166412e-06,
      "loss": 0.0,
      "step": 5690
    },
    {
      "epoch": 0.090108776541001,
      "grad_norm": 0.13854055106639862,
      "learning_rate": 9.098912234589991e-06,
      "loss": 0.0079,
      "step": 5691
    },
    {
      "epoch": 0.09012461009864306,
      "grad_norm": 0.6396028399467468,
      "learning_rate": 9.09875389901357e-06,
      "loss": 0.0539,
      "step": 5692
    },
    {
      "epoch": 0.09014044365628512,
      "grad_norm": 0.7274644374847412,
      "learning_rate": 9.09859556343715e-06,
      "loss": 0.1432,
      "step": 5693
    },
    {
      "epoch": 0.0901562772139272,
      "grad_norm": 0.6753001809120178,
      "learning_rate": 9.09843722786073e-06,
      "loss": 0.2995,
      "step": 5694
    },
    {
      "epoch": 0.09017211077156927,
      "grad_norm": 1.8274213075637817,
      "learning_rate": 9.098278892284307e-06,
      "loss": 0.0242,
      "step": 5695
    },
    {
      "epoch": 0.09018794432921133,
      "grad_norm": 1.632965326309204,
      "learning_rate": 9.098120556707888e-06,
      "loss": 0.7572,
      "step": 5696
    },
    {
      "epoch": 0.0902037778868534,
      "grad_norm": 0.14548765122890472,
      "learning_rate": 9.097962221131467e-06,
      "loss": 0.0465,
      "step": 5697
    },
    {
      "epoch": 0.09021961144449546,
      "grad_norm": 0.38057470321655273,
      "learning_rate": 9.097803885555046e-06,
      "loss": 0.171,
      "step": 5698
    },
    {
      "epoch": 0.09023544500213752,
      "grad_norm": 0.20654551684856415,
      "learning_rate": 9.097645549978625e-06,
      "loss": 0.1021,
      "step": 5699
    },
    {
      "epoch": 0.0902512785597796,
      "grad_norm": 0.026969455182552338,
      "learning_rate": 9.097487214402206e-06,
      "loss": 0.0013,
      "step": 5700
    },
    {
      "epoch": 0.09026711211742167,
      "grad_norm": 0.06986550241708755,
      "learning_rate": 9.097328878825783e-06,
      "loss": 0.004,
      "step": 5701
    },
    {
      "epoch": 0.09028294567506373,
      "grad_norm": 0.015140505507588387,
      "learning_rate": 9.097170543249364e-06,
      "loss": 0.0008,
      "step": 5702
    },
    {
      "epoch": 0.0902987792327058,
      "grad_norm": 0.5821849703788757,
      "learning_rate": 9.097012207672943e-06,
      "loss": 0.0929,
      "step": 5703
    },
    {
      "epoch": 0.09031461279034786,
      "grad_norm": 0.34286266565322876,
      "learning_rate": 9.096853872096522e-06,
      "loss": 0.0712,
      "step": 5704
    },
    {
      "epoch": 0.09033044634798992,
      "grad_norm": 0.42788487672805786,
      "learning_rate": 9.096695536520102e-06,
      "loss": 0.1915,
      "step": 5705
    },
    {
      "epoch": 0.090346279905632,
      "grad_norm": 0.22031255066394806,
      "learning_rate": 9.09653720094368e-06,
      "loss": 0.077,
      "step": 5706
    },
    {
      "epoch": 0.09036211346327407,
      "grad_norm": 0.598578155040741,
      "learning_rate": 9.09637886536726e-06,
      "loss": 0.2419,
      "step": 5707
    },
    {
      "epoch": 0.09037794702091613,
      "grad_norm": 0.6947870254516602,
      "learning_rate": 9.096220529790839e-06,
      "loss": 0.078,
      "step": 5708
    },
    {
      "epoch": 0.0903937805785582,
      "grad_norm": 0.38748982548713684,
      "learning_rate": 9.09606219421442e-06,
      "loss": 0.1749,
      "step": 5709
    },
    {
      "epoch": 0.09040961413620026,
      "grad_norm": 0.30884283781051636,
      "learning_rate": 9.095903858637997e-06,
      "loss": 0.0602,
      "step": 5710
    },
    {
      "epoch": 0.09042544769384232,
      "grad_norm": 0.11411137133836746,
      "learning_rate": 9.095745523061578e-06,
      "loss": 0.0026,
      "step": 5711
    },
    {
      "epoch": 0.0904412812514844,
      "grad_norm": 0.3061297833919525,
      "learning_rate": 9.095587187485157e-06,
      "loss": 0.4091,
      "step": 5712
    },
    {
      "epoch": 0.09045711480912647,
      "grad_norm": 0.000308550224872306,
      "learning_rate": 9.095428851908736e-06,
      "loss": 0.0,
      "step": 5713
    },
    {
      "epoch": 0.09047294836676853,
      "grad_norm": 0.4294414222240448,
      "learning_rate": 9.095270516332315e-06,
      "loss": 0.0999,
      "step": 5714
    },
    {
      "epoch": 0.0904887819244106,
      "grad_norm": 0.0381331741809845,
      "learning_rate": 9.095112180755896e-06,
      "loss": 0.002,
      "step": 5715
    },
    {
      "epoch": 0.09050461548205266,
      "grad_norm": 0.20066650211811066,
      "learning_rate": 9.094953845179473e-06,
      "loss": 0.0938,
      "step": 5716
    },
    {
      "epoch": 0.09052044903969472,
      "grad_norm": 0.6066994667053223,
      "learning_rate": 9.094795509603054e-06,
      "loss": 0.1528,
      "step": 5717
    },
    {
      "epoch": 0.0905362825973368,
      "grad_norm": 0.01254079770296812,
      "learning_rate": 9.094637174026633e-06,
      "loss": 0.0007,
      "step": 5718
    },
    {
      "epoch": 0.09055211615497887,
      "grad_norm": 0.3523259460926056,
      "learning_rate": 9.094478838450212e-06,
      "loss": 0.7043,
      "step": 5719
    },
    {
      "epoch": 0.09056794971262093,
      "grad_norm": 0.4872118830680847,
      "learning_rate": 9.094320502873791e-06,
      "loss": 0.1251,
      "step": 5720
    },
    {
      "epoch": 0.090583783270263,
      "grad_norm": 0.2652900218963623,
      "learning_rate": 9.094162167297372e-06,
      "loss": 0.1314,
      "step": 5721
    },
    {
      "epoch": 0.09059961682790506,
      "grad_norm": 0.21948079764842987,
      "learning_rate": 9.09400383172095e-06,
      "loss": 0.0836,
      "step": 5722
    },
    {
      "epoch": 0.09061545038554712,
      "grad_norm": 0.4132666289806366,
      "learning_rate": 9.09384549614453e-06,
      "loss": 0.1109,
      "step": 5723
    },
    {
      "epoch": 0.0906312839431892,
      "grad_norm": 0.26451125741004944,
      "learning_rate": 9.093687160568109e-06,
      "loss": 0.1335,
      "step": 5724
    },
    {
      "epoch": 0.09064711750083126,
      "grad_norm": 0.0004639483813662082,
      "learning_rate": 9.093528824991688e-06,
      "loss": 0.0,
      "step": 5725
    },
    {
      "epoch": 0.09066295105847333,
      "grad_norm": 0.24323174357414246,
      "learning_rate": 9.093370489415267e-06,
      "loss": 0.1213,
      "step": 5726
    },
    {
      "epoch": 0.0906787846161154,
      "grad_norm": 0.03833441063761711,
      "learning_rate": 9.093212153838846e-06,
      "loss": 0.0025,
      "step": 5727
    },
    {
      "epoch": 0.09069461817375746,
      "grad_norm": 0.442392498254776,
      "learning_rate": 9.093053818262425e-06,
      "loss": 0.2737,
      "step": 5728
    },
    {
      "epoch": 0.09071045173139952,
      "grad_norm": 0.20398610830307007,
      "learning_rate": 9.092895482686004e-06,
      "loss": 0.0761,
      "step": 5729
    },
    {
      "epoch": 0.0907262852890416,
      "grad_norm": 0.2068149745464325,
      "learning_rate": 9.092737147109585e-06,
      "loss": 0.0054,
      "step": 5730
    },
    {
      "epoch": 0.09074211884668366,
      "grad_norm": 0.2290963977575302,
      "learning_rate": 9.092578811533164e-06,
      "loss": 0.0759,
      "step": 5731
    },
    {
      "epoch": 0.09075795240432573,
      "grad_norm": 0.6007131338119507,
      "learning_rate": 9.092420475956743e-06,
      "loss": 0.6457,
      "step": 5732
    },
    {
      "epoch": 0.09077378596196779,
      "grad_norm": 0.2389889359474182,
      "learning_rate": 9.092262140380323e-06,
      "loss": 0.0311,
      "step": 5733
    },
    {
      "epoch": 0.09078961951960986,
      "grad_norm": 0.44880568981170654,
      "learning_rate": 9.092103804803902e-06,
      "loss": 0.1029,
      "step": 5734
    },
    {
      "epoch": 0.09080545307725192,
      "grad_norm": 0.00013012901763431728,
      "learning_rate": 9.09194546922748e-06,
      "loss": 0.0,
      "step": 5735
    },
    {
      "epoch": 0.090821286634894,
      "grad_norm": 0.03099021688103676,
      "learning_rate": 9.091787133651061e-06,
      "loss": 0.0016,
      "step": 5736
    },
    {
      "epoch": 0.09083712019253606,
      "grad_norm": 0.3285142183303833,
      "learning_rate": 9.09162879807464e-06,
      "loss": 0.2428,
      "step": 5737
    },
    {
      "epoch": 0.09085295375017813,
      "grad_norm": 0.7437935471534729,
      "learning_rate": 9.09147046249822e-06,
      "loss": 0.2858,
      "step": 5738
    },
    {
      "epoch": 0.09086878730782019,
      "grad_norm": 0.09568680077791214,
      "learning_rate": 9.091312126921799e-06,
      "loss": 0.0032,
      "step": 5739
    },
    {
      "epoch": 0.09088462086546226,
      "grad_norm": 0.31204453110694885,
      "learning_rate": 9.091153791345378e-06,
      "loss": 0.4376,
      "step": 5740
    },
    {
      "epoch": 0.09090045442310432,
      "grad_norm": 0.1779465675354004,
      "learning_rate": 9.090995455768957e-06,
      "loss": 0.0274,
      "step": 5741
    },
    {
      "epoch": 0.0909162879807464,
      "grad_norm": 0.02886422723531723,
      "learning_rate": 9.090837120192538e-06,
      "loss": 0.0018,
      "step": 5742
    },
    {
      "epoch": 0.09093212153838846,
      "grad_norm": 0.18495765328407288,
      "learning_rate": 9.090678784616117e-06,
      "loss": 0.1198,
      "step": 5743
    },
    {
      "epoch": 0.09094795509603053,
      "grad_norm": 0.0232506413012743,
      "learning_rate": 9.090520449039696e-06,
      "loss": 0.0011,
      "step": 5744
    },
    {
      "epoch": 0.09096378865367259,
      "grad_norm": 0.07447954267263412,
      "learning_rate": 9.090362113463275e-06,
      "loss": 0.004,
      "step": 5745
    },
    {
      "epoch": 0.09097962221131466,
      "grad_norm": 0.3942655026912689,
      "learning_rate": 9.090203777886854e-06,
      "loss": 0.0698,
      "step": 5746
    },
    {
      "epoch": 0.09099545576895672,
      "grad_norm": 0.00022737917606718838,
      "learning_rate": 9.090045442310433e-06,
      "loss": 0.0,
      "step": 5747
    },
    {
      "epoch": 0.0910112893265988,
      "grad_norm": 0.2504061758518219,
      "learning_rate": 9.089887106734014e-06,
      "loss": 0.0726,
      "step": 5748
    },
    {
      "epoch": 0.09102712288424086,
      "grad_norm": 0.29181110858917236,
      "learning_rate": 9.089728771157593e-06,
      "loss": 0.1328,
      "step": 5749
    },
    {
      "epoch": 0.09104295644188293,
      "grad_norm": 0.14084021747112274,
      "learning_rate": 9.089570435581172e-06,
      "loss": 0.0685,
      "step": 5750
    },
    {
      "epoch": 0.09105878999952499,
      "grad_norm": 0.14724208414554596,
      "learning_rate": 9.089412100004751e-06,
      "loss": 0.0576,
      "step": 5751
    },
    {
      "epoch": 0.09107462355716706,
      "grad_norm": 0.5300858020782471,
      "learning_rate": 9.08925376442833e-06,
      "loss": 0.243,
      "step": 5752
    },
    {
      "epoch": 0.09109045711480912,
      "grad_norm": 0.35308733582496643,
      "learning_rate": 9.08909542885191e-06,
      "loss": 0.1532,
      "step": 5753
    },
    {
      "epoch": 0.0911062906724512,
      "grad_norm": 0.04648188501596451,
      "learning_rate": 9.088937093275488e-06,
      "loss": 0.003,
      "step": 5754
    },
    {
      "epoch": 0.09112212423009326,
      "grad_norm": 0.010416976176202297,
      "learning_rate": 9.088778757699069e-06,
      "loss": 0.0006,
      "step": 5755
    },
    {
      "epoch": 0.09113795778773533,
      "grad_norm": 0.0650307759642601,
      "learning_rate": 9.088620422122646e-06,
      "loss": 0.004,
      "step": 5756
    },
    {
      "epoch": 0.09115379134537739,
      "grad_norm": 0.0794135183095932,
      "learning_rate": 9.088462086546227e-06,
      "loss": 0.0023,
      "step": 5757
    },
    {
      "epoch": 0.09116962490301946,
      "grad_norm": 0.0008400598890148103,
      "learning_rate": 9.088303750969806e-06,
      "loss": 0.0,
      "step": 5758
    },
    {
      "epoch": 0.09118545846066152,
      "grad_norm": 0.01852574199438095,
      "learning_rate": 9.088145415393385e-06,
      "loss": 0.0012,
      "step": 5759
    },
    {
      "epoch": 0.0912012920183036,
      "grad_norm": 0.00020597994443960488,
      "learning_rate": 9.087987079816964e-06,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 0.09121712557594566,
      "grad_norm": 0.5501928329467773,
      "learning_rate": 9.087828744240545e-06,
      "loss": 0.1625,
      "step": 5761
    },
    {
      "epoch": 0.09123295913358773,
      "grad_norm": 0.8005174398422241,
      "learning_rate": 9.087670408664123e-06,
      "loss": 0.1413,
      "step": 5762
    },
    {
      "epoch": 0.09124879269122979,
      "grad_norm": 0.3125816583633423,
      "learning_rate": 9.087512073087703e-06,
      "loss": 0.1063,
      "step": 5763
    },
    {
      "epoch": 0.09126462624887186,
      "grad_norm": 0.15327009558677673,
      "learning_rate": 9.087353737511282e-06,
      "loss": 0.0757,
      "step": 5764
    },
    {
      "epoch": 0.09128045980651392,
      "grad_norm": 0.061875153332948685,
      "learning_rate": 9.087195401934862e-06,
      "loss": 0.0046,
      "step": 5765
    },
    {
      "epoch": 0.091296293364156,
      "grad_norm": 0.087650828063488,
      "learning_rate": 9.08703706635844e-06,
      "loss": 0.0041,
      "step": 5766
    },
    {
      "epoch": 0.09131212692179806,
      "grad_norm": 0.3698630928993225,
      "learning_rate": 9.086878730782021e-06,
      "loss": 0.1083,
      "step": 5767
    },
    {
      "epoch": 0.09132796047944013,
      "grad_norm": 0.025434672832489014,
      "learning_rate": 9.086720395205599e-06,
      "loss": 0.0015,
      "step": 5768
    },
    {
      "epoch": 0.09134379403708219,
      "grad_norm": 0.4147333800792694,
      "learning_rate": 9.08656205962918e-06,
      "loss": 0.3207,
      "step": 5769
    },
    {
      "epoch": 0.09135962759472425,
      "grad_norm": 0.0033899859990924597,
      "learning_rate": 9.086403724052759e-06,
      "loss": 0.0001,
      "step": 5770
    },
    {
      "epoch": 0.09137546115236632,
      "grad_norm": 0.2612074911594391,
      "learning_rate": 9.086245388476338e-06,
      "loss": 0.0881,
      "step": 5771
    },
    {
      "epoch": 0.0913912947100084,
      "grad_norm": 0.026464015245437622,
      "learning_rate": 9.086087052899917e-06,
      "loss": 0.0014,
      "step": 5772
    },
    {
      "epoch": 0.09140712826765046,
      "grad_norm": 0.024513602256774902,
      "learning_rate": 9.085928717323496e-06,
      "loss": 0.0012,
      "step": 5773
    },
    {
      "epoch": 0.09142296182529253,
      "grad_norm": 0.2271909862756729,
      "learning_rate": 9.085770381747075e-06,
      "loss": 0.1994,
      "step": 5774
    },
    {
      "epoch": 0.09143879538293459,
      "grad_norm": 0.3073270320892334,
      "learning_rate": 9.085612046170654e-06,
      "loss": 0.1668,
      "step": 5775
    },
    {
      "epoch": 0.09145462894057665,
      "grad_norm": 0.350655734539032,
      "learning_rate": 9.085453710594235e-06,
      "loss": 0.6534,
      "step": 5776
    },
    {
      "epoch": 0.09147046249821872,
      "grad_norm": 0.00027562706964090466,
      "learning_rate": 9.085295375017812e-06,
      "loss": 0.0,
      "step": 5777
    },
    {
      "epoch": 0.0914862960558608,
      "grad_norm": 0.2861775755882263,
      "learning_rate": 9.085137039441393e-06,
      "loss": 0.0923,
      "step": 5778
    },
    {
      "epoch": 0.09150212961350286,
      "grad_norm": 0.32059937715530396,
      "learning_rate": 9.084978703864972e-06,
      "loss": 0.1863,
      "step": 5779
    },
    {
      "epoch": 0.09151796317114493,
      "grad_norm": 0.32655492424964905,
      "learning_rate": 9.084820368288551e-06,
      "loss": 0.1071,
      "step": 5780
    },
    {
      "epoch": 0.09153379672878699,
      "grad_norm": 0.3350878059864044,
      "learning_rate": 9.08466203271213e-06,
      "loss": 0.0996,
      "step": 5781
    },
    {
      "epoch": 0.09154963028642905,
      "grad_norm": 0.29400256276130676,
      "learning_rate": 9.084503697135711e-06,
      "loss": 0.0516,
      "step": 5782
    },
    {
      "epoch": 0.09156546384407112,
      "grad_norm": 0.0625259280204773,
      "learning_rate": 9.084345361559288e-06,
      "loss": 0.0068,
      "step": 5783
    },
    {
      "epoch": 0.0915812974017132,
      "grad_norm": 0.36492374539375305,
      "learning_rate": 9.084187025982869e-06,
      "loss": 0.3532,
      "step": 5784
    },
    {
      "epoch": 0.09159713095935526,
      "grad_norm": 0.04057013615965843,
      "learning_rate": 9.084028690406448e-06,
      "loss": 0.0022,
      "step": 5785
    },
    {
      "epoch": 0.09161296451699733,
      "grad_norm": 0.002320922678336501,
      "learning_rate": 9.083870354830027e-06,
      "loss": 0.0,
      "step": 5786
    },
    {
      "epoch": 0.09162879807463939,
      "grad_norm": 0.23898188769817352,
      "learning_rate": 9.083712019253606e-06,
      "loss": 0.1869,
      "step": 5787
    },
    {
      "epoch": 0.09164463163228145,
      "grad_norm": 0.05794275924563408,
      "learning_rate": 9.083553683677187e-06,
      "loss": 0.0058,
      "step": 5788
    },
    {
      "epoch": 0.09166046518992352,
      "grad_norm": 0.3319404721260071,
      "learning_rate": 9.083395348100765e-06,
      "loss": 0.1712,
      "step": 5789
    },
    {
      "epoch": 0.0916762987475656,
      "grad_norm": 0.348500519990921,
      "learning_rate": 9.083237012524345e-06,
      "loss": 0.0678,
      "step": 5790
    },
    {
      "epoch": 0.09169213230520766,
      "grad_norm": 0.22229665517807007,
      "learning_rate": 9.083078676947924e-06,
      "loss": 0.088,
      "step": 5791
    },
    {
      "epoch": 0.09170796586284972,
      "grad_norm": 0.24129538238048553,
      "learning_rate": 9.082920341371503e-06,
      "loss": 0.1065,
      "step": 5792
    },
    {
      "epoch": 0.09172379942049179,
      "grad_norm": 0.337557315826416,
      "learning_rate": 9.082762005795083e-06,
      "loss": 0.1294,
      "step": 5793
    },
    {
      "epoch": 0.09173963297813385,
      "grad_norm": 0.1454983651638031,
      "learning_rate": 9.082603670218663e-06,
      "loss": 0.0179,
      "step": 5794
    },
    {
      "epoch": 0.09175546653577592,
      "grad_norm": 0.5497968792915344,
      "learning_rate": 9.08244533464224e-06,
      "loss": 0.4069,
      "step": 5795
    },
    {
      "epoch": 0.091771300093418,
      "grad_norm": 0.027852050960063934,
      "learning_rate": 9.082286999065821e-06,
      "loss": 0.0015,
      "step": 5796
    },
    {
      "epoch": 0.09178713365106006,
      "grad_norm": 0.3351980745792389,
      "learning_rate": 9.0821286634894e-06,
      "loss": 0.1843,
      "step": 5797
    },
    {
      "epoch": 0.09180296720870212,
      "grad_norm": 0.32787179946899414,
      "learning_rate": 9.08197032791298e-06,
      "loss": 0.5787,
      "step": 5798
    },
    {
      "epoch": 0.09181880076634419,
      "grad_norm": 0.2966645061969757,
      "learning_rate": 9.081811992336559e-06,
      "loss": 0.1646,
      "step": 5799
    },
    {
      "epoch": 0.09183463432398625,
      "grad_norm": 0.45071256160736084,
      "learning_rate": 9.081653656760138e-06,
      "loss": 0.0816,
      "step": 5800
    },
    {
      "epoch": 0.09185046788162832,
      "grad_norm": 0.8074995875358582,
      "learning_rate": 9.081495321183717e-06,
      "loss": 0.7021,
      "step": 5801
    },
    {
      "epoch": 0.0918663014392704,
      "grad_norm": 0.479740172624588,
      "learning_rate": 9.081336985607296e-06,
      "loss": 0.5351,
      "step": 5802
    },
    {
      "epoch": 0.09188213499691246,
      "grad_norm": 0.16095533967018127,
      "learning_rate": 9.081178650030877e-06,
      "loss": 0.0699,
      "step": 5803
    },
    {
      "epoch": 0.09189796855455452,
      "grad_norm": 0.19188715517520905,
      "learning_rate": 9.081020314454456e-06,
      "loss": 0.1262,
      "step": 5804
    },
    {
      "epoch": 0.09191380211219659,
      "grad_norm": 3.695248960866593e-05,
      "learning_rate": 9.080861978878035e-06,
      "loss": 0.0,
      "step": 5805
    },
    {
      "epoch": 0.09192963566983865,
      "grad_norm": 0.0036513099912554026,
      "learning_rate": 9.080703643301614e-06,
      "loss": 0.0002,
      "step": 5806
    },
    {
      "epoch": 0.09194546922748072,
      "grad_norm": 0.6124995350837708,
      "learning_rate": 9.080545307725193e-06,
      "loss": 0.1832,
      "step": 5807
    },
    {
      "epoch": 0.0919613027851228,
      "grad_norm": 0.6809757351875305,
      "learning_rate": 9.080386972148772e-06,
      "loss": 0.3574,
      "step": 5808
    },
    {
      "epoch": 0.09197713634276486,
      "grad_norm": 0.7021874189376831,
      "learning_rate": 9.080228636572353e-06,
      "loss": 0.2444,
      "step": 5809
    },
    {
      "epoch": 0.09199296990040692,
      "grad_norm": 0.31081944704055786,
      "learning_rate": 9.080070300995932e-06,
      "loss": 0.4748,
      "step": 5810
    },
    {
      "epoch": 0.09200880345804899,
      "grad_norm": 0.20535334944725037,
      "learning_rate": 9.079911965419511e-06,
      "loss": 0.1535,
      "step": 5811
    },
    {
      "epoch": 0.09202463701569105,
      "grad_norm": 0.03226092830300331,
      "learning_rate": 9.07975362984309e-06,
      "loss": 0.0013,
      "step": 5812
    },
    {
      "epoch": 0.09204047057333312,
      "grad_norm": 0.5873685479164124,
      "learning_rate": 9.07959529426667e-06,
      "loss": 0.384,
      "step": 5813
    },
    {
      "epoch": 0.0920563041309752,
      "grad_norm": 0.03621519356966019,
      "learning_rate": 9.079436958690248e-06,
      "loss": 0.0021,
      "step": 5814
    },
    {
      "epoch": 0.09207213768861726,
      "grad_norm": 0.5052183866500854,
      "learning_rate": 9.079278623113829e-06,
      "loss": 1.0119,
      "step": 5815
    },
    {
      "epoch": 0.09208797124625932,
      "grad_norm": 0.13194307684898376,
      "learning_rate": 9.079120287537408e-06,
      "loss": 0.0069,
      "step": 5816
    },
    {
      "epoch": 0.09210380480390139,
      "grad_norm": 0.0002731524873524904,
      "learning_rate": 9.078961951960987e-06,
      "loss": 0.0,
      "step": 5817
    },
    {
      "epoch": 0.09211963836154345,
      "grad_norm": 0.23097282648086548,
      "learning_rate": 9.078803616384566e-06,
      "loss": 0.1667,
      "step": 5818
    },
    {
      "epoch": 0.09213547191918552,
      "grad_norm": 0.2502373158931732,
      "learning_rate": 9.078645280808145e-06,
      "loss": 0.1052,
      "step": 5819
    },
    {
      "epoch": 0.0921513054768276,
      "grad_norm": 0.2685559391975403,
      "learning_rate": 9.078486945231724e-06,
      "loss": 0.1033,
      "step": 5820
    },
    {
      "epoch": 0.09216713903446966,
      "grad_norm": 5.257368087768555,
      "learning_rate": 9.078328609655305e-06,
      "loss": 0.5252,
      "step": 5821
    },
    {
      "epoch": 0.09218297259211172,
      "grad_norm": 0.2669738233089447,
      "learning_rate": 9.078170274078884e-06,
      "loss": 0.1972,
      "step": 5822
    },
    {
      "epoch": 0.09219880614975379,
      "grad_norm": 0.5087182521820068,
      "learning_rate": 9.078011938502462e-06,
      "loss": 0.3545,
      "step": 5823
    },
    {
      "epoch": 0.09221463970739585,
      "grad_norm": 0.0003345929435454309,
      "learning_rate": 9.077853602926042e-06,
      "loss": 0.0,
      "step": 5824
    },
    {
      "epoch": 0.09223047326503792,
      "grad_norm": 0.48733189702033997,
      "learning_rate": 9.077695267349622e-06,
      "loss": 0.2223,
      "step": 5825
    },
    {
      "epoch": 0.09224630682268,
      "grad_norm": 0.42174097895622253,
      "learning_rate": 9.0775369317732e-06,
      "loss": 0.069,
      "step": 5826
    },
    {
      "epoch": 0.09226214038032206,
      "grad_norm": 0.04113880544900894,
      "learning_rate": 9.07737859619678e-06,
      "loss": 0.0014,
      "step": 5827
    },
    {
      "epoch": 0.09227797393796412,
      "grad_norm": 0.12967528402805328,
      "learning_rate": 9.07722026062036e-06,
      "loss": 0.0024,
      "step": 5828
    },
    {
      "epoch": 0.09229380749560619,
      "grad_norm": 0.6084480881690979,
      "learning_rate": 9.077061925043938e-06,
      "loss": 0.1672,
      "step": 5829
    },
    {
      "epoch": 0.09230964105324825,
      "grad_norm": 0.39170992374420166,
      "learning_rate": 9.076903589467519e-06,
      "loss": 0.362,
      "step": 5830
    },
    {
      "epoch": 0.09232547461089032,
      "grad_norm": 0.24421659111976624,
      "learning_rate": 9.076745253891098e-06,
      "loss": 0.1298,
      "step": 5831
    },
    {
      "epoch": 0.0923413081685324,
      "grad_norm": 0.19337162375450134,
      "learning_rate": 9.076586918314677e-06,
      "loss": 0.0194,
      "step": 5832
    },
    {
      "epoch": 0.09235714172617446,
      "grad_norm": 0.28408578038215637,
      "learning_rate": 9.076428582738256e-06,
      "loss": 0.1364,
      "step": 5833
    },
    {
      "epoch": 0.09237297528381652,
      "grad_norm": 0.3022677004337311,
      "learning_rate": 9.076270247161835e-06,
      "loss": 0.2851,
      "step": 5834
    },
    {
      "epoch": 0.09238880884145859,
      "grad_norm": 0.36872994899749756,
      "learning_rate": 9.076111911585414e-06,
      "loss": 0.1438,
      "step": 5835
    },
    {
      "epoch": 0.09240464239910065,
      "grad_norm": 0.25492218136787415,
      "learning_rate": 9.075953576008995e-06,
      "loss": 0.2153,
      "step": 5836
    },
    {
      "epoch": 0.09242047595674271,
      "grad_norm": 0.2481958270072937,
      "learning_rate": 9.075795240432574e-06,
      "loss": 0.1051,
      "step": 5837
    },
    {
      "epoch": 0.09243630951438479,
      "grad_norm": 0.3493894636631012,
      "learning_rate": 9.075636904856153e-06,
      "loss": 0.0617,
      "step": 5838
    },
    {
      "epoch": 0.09245214307202686,
      "grad_norm": 0.4348447322845459,
      "learning_rate": 9.075478569279732e-06,
      "loss": 0.4374,
      "step": 5839
    },
    {
      "epoch": 0.09246797662966892,
      "grad_norm": 0.0006521448958665133,
      "learning_rate": 9.075320233703311e-06,
      "loss": 0.0,
      "step": 5840
    },
    {
      "epoch": 0.09248381018731099,
      "grad_norm": 0.23080721497535706,
      "learning_rate": 9.07516189812689e-06,
      "loss": 0.0534,
      "step": 5841
    },
    {
      "epoch": 0.09249964374495305,
      "grad_norm": 0.24341118335723877,
      "learning_rate": 9.075003562550471e-06,
      "loss": 0.0674,
      "step": 5842
    },
    {
      "epoch": 0.09251547730259511,
      "grad_norm": 0.33761927485466003,
      "learning_rate": 9.07484522697405e-06,
      "loss": 0.1126,
      "step": 5843
    },
    {
      "epoch": 0.09253131086023719,
      "grad_norm": 0.02561218850314617,
      "learning_rate": 9.074686891397629e-06,
      "loss": 0.0018,
      "step": 5844
    },
    {
      "epoch": 0.09254714441787926,
      "grad_norm": 0.3063696026802063,
      "learning_rate": 9.074528555821208e-06,
      "loss": 0.7147,
      "step": 5845
    },
    {
      "epoch": 0.09256297797552132,
      "grad_norm": 0.3578980267047882,
      "learning_rate": 9.074370220244787e-06,
      "loss": 0.3735,
      "step": 5846
    },
    {
      "epoch": 0.09257881153316339,
      "grad_norm": 0.023352457210421562,
      "learning_rate": 9.074211884668366e-06,
      "loss": 0.0014,
      "step": 5847
    },
    {
      "epoch": 0.09259464509080545,
      "grad_norm": 0.43163836002349854,
      "learning_rate": 9.074053549091945e-06,
      "loss": 0.1349,
      "step": 5848
    },
    {
      "epoch": 0.09261047864844751,
      "grad_norm": 0.1451423615217209,
      "learning_rate": 9.073895213515526e-06,
      "loss": 0.0432,
      "step": 5849
    },
    {
      "epoch": 0.09262631220608959,
      "grad_norm": 0.004443335812538862,
      "learning_rate": 9.073736877939104e-06,
      "loss": 0.0002,
      "step": 5850
    },
    {
      "epoch": 0.09264214576373166,
      "grad_norm": 0.2633116841316223,
      "learning_rate": 9.073578542362684e-06,
      "loss": 0.0464,
      "step": 5851
    },
    {
      "epoch": 0.09265797932137372,
      "grad_norm": 0.0005003447877243161,
      "learning_rate": 9.073420206786263e-06,
      "loss": 0.0,
      "step": 5852
    },
    {
      "epoch": 0.09267381287901579,
      "grad_norm": 0.016760317608714104,
      "learning_rate": 9.073261871209843e-06,
      "loss": 0.001,
      "step": 5853
    },
    {
      "epoch": 0.09268964643665785,
      "grad_norm": 0.26327502727508545,
      "learning_rate": 9.073103535633422e-06,
      "loss": 0.1257,
      "step": 5854
    },
    {
      "epoch": 0.09270547999429991,
      "grad_norm": 0.4409800171852112,
      "learning_rate": 9.072945200057002e-06,
      "loss": 0.3075,
      "step": 5855
    },
    {
      "epoch": 0.09272131355194199,
      "grad_norm": 0.23281371593475342,
      "learning_rate": 9.07278686448058e-06,
      "loss": 0.0943,
      "step": 5856
    },
    {
      "epoch": 0.09273714710958406,
      "grad_norm": 0.0454276017844677,
      "learning_rate": 9.07262852890416e-06,
      "loss": 0.0026,
      "step": 5857
    },
    {
      "epoch": 0.09275298066722612,
      "grad_norm": 0.3677877187728882,
      "learning_rate": 9.07247019332774e-06,
      "loss": 0.1285,
      "step": 5858
    },
    {
      "epoch": 0.09276881422486818,
      "grad_norm": 0.4270484745502472,
      "learning_rate": 9.072311857751319e-06,
      "loss": 0.2076,
      "step": 5859
    },
    {
      "epoch": 0.09278464778251025,
      "grad_norm": 0.28889310359954834,
      "learning_rate": 9.072153522174898e-06,
      "loss": 0.2777,
      "step": 5860
    },
    {
      "epoch": 0.09280048134015231,
      "grad_norm": 0.3740634024143219,
      "learning_rate": 9.071995186598479e-06,
      "loss": 0.016,
      "step": 5861
    },
    {
      "epoch": 0.09281631489779439,
      "grad_norm": 0.23775656521320343,
      "learning_rate": 9.071836851022056e-06,
      "loss": 0.0782,
      "step": 5862
    },
    {
      "epoch": 0.09283214845543646,
      "grad_norm": 0.27634307742118835,
      "learning_rate": 9.071678515445637e-06,
      "loss": 0.075,
      "step": 5863
    },
    {
      "epoch": 0.09284798201307852,
      "grad_norm": 0.0016147253336384892,
      "learning_rate": 9.071520179869216e-06,
      "loss": 0.0,
      "step": 5864
    },
    {
      "epoch": 0.09286381557072058,
      "grad_norm": 0.4297201633453369,
      "learning_rate": 9.071361844292795e-06,
      "loss": 0.5084,
      "step": 5865
    },
    {
      "epoch": 0.09287964912836265,
      "grad_norm": 0.40806853771209717,
      "learning_rate": 9.071203508716374e-06,
      "loss": 0.4536,
      "step": 5866
    },
    {
      "epoch": 0.09289548268600471,
      "grad_norm": 0.3242713212966919,
      "learning_rate": 9.071045173139955e-06,
      "loss": 0.1597,
      "step": 5867
    },
    {
      "epoch": 0.09291131624364679,
      "grad_norm": 0.48114970326423645,
      "learning_rate": 9.070886837563532e-06,
      "loss": 0.6177,
      "step": 5868
    },
    {
      "epoch": 0.09292714980128886,
      "grad_norm": 0.3152215778827667,
      "learning_rate": 9.070728501987113e-06,
      "loss": 0.1153,
      "step": 5869
    },
    {
      "epoch": 0.09294298335893092,
      "grad_norm": 0.034606825560331345,
      "learning_rate": 9.070570166410692e-06,
      "loss": 0.0023,
      "step": 5870
    },
    {
      "epoch": 0.09295881691657298,
      "grad_norm": 0.10399846732616425,
      "learning_rate": 9.070411830834271e-06,
      "loss": 0.0266,
      "step": 5871
    },
    {
      "epoch": 0.09297465047421505,
      "grad_norm": 0.012476969510316849,
      "learning_rate": 9.07025349525785e-06,
      "loss": 0.0008,
      "step": 5872
    },
    {
      "epoch": 0.09299048403185711,
      "grad_norm": 0.023636283352971077,
      "learning_rate": 9.07009515968143e-06,
      "loss": 0.0015,
      "step": 5873
    },
    {
      "epoch": 0.09300631758949919,
      "grad_norm": 0.4025680422782898,
      "learning_rate": 9.069936824105008e-06,
      "loss": 0.0229,
      "step": 5874
    },
    {
      "epoch": 0.09302215114714125,
      "grad_norm": 0.40621674060821533,
      "learning_rate": 9.069778488528587e-06,
      "loss": 0.1765,
      "step": 5875
    },
    {
      "epoch": 0.09303798470478332,
      "grad_norm": 0.2597918212413788,
      "learning_rate": 9.069620152952168e-06,
      "loss": 0.0897,
      "step": 5876
    },
    {
      "epoch": 0.09305381826242538,
      "grad_norm": 0.034470703452825546,
      "learning_rate": 9.069461817375747e-06,
      "loss": 0.0018,
      "step": 5877
    },
    {
      "epoch": 0.09306965182006745,
      "grad_norm": 8.53712554089725e-05,
      "learning_rate": 9.069303481799326e-06,
      "loss": 0.0,
      "step": 5878
    },
    {
      "epoch": 0.09308548537770951,
      "grad_norm": 0.3944384753704071,
      "learning_rate": 9.069145146222905e-06,
      "loss": 0.309,
      "step": 5879
    },
    {
      "epoch": 0.09310131893535159,
      "grad_norm": 0.14567042887210846,
      "learning_rate": 9.068986810646484e-06,
      "loss": 0.0484,
      "step": 5880
    },
    {
      "epoch": 0.09311715249299365,
      "grad_norm": 0.5861096978187561,
      "learning_rate": 9.068828475070064e-06,
      "loss": 0.1177,
      "step": 5881
    },
    {
      "epoch": 0.09313298605063572,
      "grad_norm": 0.009005493484437466,
      "learning_rate": 9.068670139493644e-06,
      "loss": 0.0006,
      "step": 5882
    },
    {
      "epoch": 0.09314881960827778,
      "grad_norm": 0.47654297947883606,
      "learning_rate": 9.068511803917223e-06,
      "loss": 0.3736,
      "step": 5883
    },
    {
      "epoch": 0.09316465316591985,
      "grad_norm": 0.5630017518997192,
      "learning_rate": 9.068353468340802e-06,
      "loss": 0.2068,
      "step": 5884
    },
    {
      "epoch": 0.09318048672356191,
      "grad_norm": 0.3085215985774994,
      "learning_rate": 9.068195132764382e-06,
      "loss": 0.2158,
      "step": 5885
    },
    {
      "epoch": 0.09319632028120399,
      "grad_norm": 0.3679243326187134,
      "learning_rate": 9.06803679718796e-06,
      "loss": 0.2252,
      "step": 5886
    },
    {
      "epoch": 0.09321215383884605,
      "grad_norm": 1.4730308055877686,
      "learning_rate": 9.06787846161154e-06,
      "loss": 0.3224,
      "step": 5887
    },
    {
      "epoch": 0.09322798739648812,
      "grad_norm": 0.26275599002838135,
      "learning_rate": 9.06772012603512e-06,
      "loss": 0.0441,
      "step": 5888
    },
    {
      "epoch": 0.09324382095413018,
      "grad_norm": 0.01614355482161045,
      "learning_rate": 9.0675617904587e-06,
      "loss": 0.0009,
      "step": 5889
    },
    {
      "epoch": 0.09325965451177225,
      "grad_norm": 0.33520957827568054,
      "learning_rate": 9.067403454882279e-06,
      "loss": 0.2208,
      "step": 5890
    },
    {
      "epoch": 0.09327548806941431,
      "grad_norm": 0.12166319787502289,
      "learning_rate": 9.067245119305858e-06,
      "loss": 0.0025,
      "step": 5891
    },
    {
      "epoch": 0.09329132162705639,
      "grad_norm": 0.016173003241419792,
      "learning_rate": 9.067086783729437e-06,
      "loss": 0.0008,
      "step": 5892
    },
    {
      "epoch": 0.09330715518469845,
      "grad_norm": 8.261462789960206e-05,
      "learning_rate": 9.066928448153016e-06,
      "loss": 0.0,
      "step": 5893
    },
    {
      "epoch": 0.09332298874234052,
      "grad_norm": 0.08521303534507751,
      "learning_rate": 9.066770112576597e-06,
      "loss": 0.0047,
      "step": 5894
    },
    {
      "epoch": 0.09333882229998258,
      "grad_norm": 0.3752993047237396,
      "learning_rate": 9.066611777000176e-06,
      "loss": 0.6698,
      "step": 5895
    },
    {
      "epoch": 0.09335465585762465,
      "grad_norm": 0.17556217312812805,
      "learning_rate": 9.066453441423753e-06,
      "loss": 0.0594,
      "step": 5896
    },
    {
      "epoch": 0.09337048941526671,
      "grad_norm": 0.34119510650634766,
      "learning_rate": 9.066295105847334e-06,
      "loss": 0.2729,
      "step": 5897
    },
    {
      "epoch": 0.09338632297290879,
      "grad_norm": 0.4599049985408783,
      "learning_rate": 9.066136770270913e-06,
      "loss": 0.4173,
      "step": 5898
    },
    {
      "epoch": 0.09340215653055085,
      "grad_norm": 0.26808831095695496,
      "learning_rate": 9.065978434694492e-06,
      "loss": 0.3251,
      "step": 5899
    },
    {
      "epoch": 0.09341799008819292,
      "grad_norm": 0.3016541302204132,
      "learning_rate": 9.065820099118071e-06,
      "loss": 0.0143,
      "step": 5900
    },
    {
      "epoch": 0.09343382364583498,
      "grad_norm": 0.2431187629699707,
      "learning_rate": 9.06566176354165e-06,
      "loss": 0.3362,
      "step": 5901
    },
    {
      "epoch": 0.09344965720347705,
      "grad_norm": 0.4620019495487213,
      "learning_rate": 9.06550342796523e-06,
      "loss": 0.401,
      "step": 5902
    },
    {
      "epoch": 0.09346549076111911,
      "grad_norm": 0.3770463168621063,
      "learning_rate": 9.06534509238881e-06,
      "loss": 0.1933,
      "step": 5903
    },
    {
      "epoch": 0.09348132431876119,
      "grad_norm": 0.36941465735435486,
      "learning_rate": 9.06518675681239e-06,
      "loss": 0.5631,
      "step": 5904
    },
    {
      "epoch": 0.09349715787640325,
      "grad_norm": 0.44824454188346863,
      "learning_rate": 9.065028421235968e-06,
      "loss": 0.012,
      "step": 5905
    },
    {
      "epoch": 0.09351299143404532,
      "grad_norm": 0.19072754681110382,
      "learning_rate": 9.064870085659547e-06,
      "loss": 0.0442,
      "step": 5906
    },
    {
      "epoch": 0.09352882499168738,
      "grad_norm": 0.45736831426620483,
      "learning_rate": 9.064711750083126e-06,
      "loss": 0.4807,
      "step": 5907
    },
    {
      "epoch": 0.09354465854932945,
      "grad_norm": 0.024608129635453224,
      "learning_rate": 9.064553414506705e-06,
      "loss": 0.0012,
      "step": 5908
    },
    {
      "epoch": 0.09356049210697151,
      "grad_norm": 0.8915692567825317,
      "learning_rate": 9.064395078930286e-06,
      "loss": 0.1285,
      "step": 5909
    },
    {
      "epoch": 0.09357632566461359,
      "grad_norm": 0.4764368534088135,
      "learning_rate": 9.064236743353865e-06,
      "loss": 0.0902,
      "step": 5910
    },
    {
      "epoch": 0.09359215922225565,
      "grad_norm": 0.23792462050914764,
      "learning_rate": 9.064078407777444e-06,
      "loss": 0.0517,
      "step": 5911
    },
    {
      "epoch": 0.09360799277989772,
      "grad_norm": 0.494779109954834,
      "learning_rate": 9.063920072201023e-06,
      "loss": 0.0695,
      "step": 5912
    },
    {
      "epoch": 0.09362382633753978,
      "grad_norm": 0.019819581881165504,
      "learning_rate": 9.063761736624603e-06,
      "loss": 0.0011,
      "step": 5913
    },
    {
      "epoch": 0.09363965989518185,
      "grad_norm": 0.018428975716233253,
      "learning_rate": 9.063603401048182e-06,
      "loss": 0.001,
      "step": 5914
    },
    {
      "epoch": 0.09365549345282391,
      "grad_norm": 0.17932604253292084,
      "learning_rate": 9.063445065471762e-06,
      "loss": 0.0519,
      "step": 5915
    },
    {
      "epoch": 0.09367132701046599,
      "grad_norm": 0.31340280175209045,
      "learning_rate": 9.063286729895342e-06,
      "loss": 0.0272,
      "step": 5916
    },
    {
      "epoch": 0.09368716056810805,
      "grad_norm": 0.3870863914489746,
      "learning_rate": 9.06312839431892e-06,
      "loss": 0.1832,
      "step": 5917
    },
    {
      "epoch": 0.09370299412575012,
      "grad_norm": 0.0642470121383667,
      "learning_rate": 9.0629700587425e-06,
      "loss": 0.0038,
      "step": 5918
    },
    {
      "epoch": 0.09371882768339218,
      "grad_norm": 0.2635810375213623,
      "learning_rate": 9.062811723166079e-06,
      "loss": 0.1727,
      "step": 5919
    },
    {
      "epoch": 0.09373466124103425,
      "grad_norm": 0.7215189337730408,
      "learning_rate": 9.062653387589658e-06,
      "loss": 0.0468,
      "step": 5920
    },
    {
      "epoch": 0.09375049479867631,
      "grad_norm": 0.2727029621601105,
      "learning_rate": 9.062495052013237e-06,
      "loss": 0.1894,
      "step": 5921
    },
    {
      "epoch": 0.09376632835631839,
      "grad_norm": 0.23507775366306305,
      "learning_rate": 9.062336716436818e-06,
      "loss": 0.0991,
      "step": 5922
    },
    {
      "epoch": 0.09378216191396045,
      "grad_norm": 0.154717355966568,
      "learning_rate": 9.062178380860395e-06,
      "loss": 0.06,
      "step": 5923
    },
    {
      "epoch": 0.09379799547160252,
      "grad_norm": 0.01383710466325283,
      "learning_rate": 9.062020045283976e-06,
      "loss": 0.0007,
      "step": 5924
    },
    {
      "epoch": 0.09381382902924458,
      "grad_norm": 0.17246732115745544,
      "learning_rate": 9.061861709707555e-06,
      "loss": 0.0096,
      "step": 5925
    },
    {
      "epoch": 0.09382966258688664,
      "grad_norm": 0.009045890532433987,
      "learning_rate": 9.061703374131134e-06,
      "loss": 0.0004,
      "step": 5926
    },
    {
      "epoch": 0.09384549614452871,
      "grad_norm": 0.19514741003513336,
      "learning_rate": 9.061545038554713e-06,
      "loss": 0.2034,
      "step": 5927
    },
    {
      "epoch": 0.09386132970217079,
      "grad_norm": 0.3352556824684143,
      "learning_rate": 9.061386702978294e-06,
      "loss": 0.3649,
      "step": 5928
    },
    {
      "epoch": 0.09387716325981285,
      "grad_norm": 0.04026595503091812,
      "learning_rate": 9.061228367401871e-06,
      "loss": 0.0024,
      "step": 5929
    },
    {
      "epoch": 0.09389299681745492,
      "grad_norm": 0.40604230761528015,
      "learning_rate": 9.061070031825452e-06,
      "loss": 0.2079,
      "step": 5930
    },
    {
      "epoch": 0.09390883037509698,
      "grad_norm": 0.32527095079421997,
      "learning_rate": 9.060911696249031e-06,
      "loss": 0.034,
      "step": 5931
    },
    {
      "epoch": 0.09392466393273904,
      "grad_norm": 0.3017144203186035,
      "learning_rate": 9.06075336067261e-06,
      "loss": 0.0668,
      "step": 5932
    },
    {
      "epoch": 0.09394049749038111,
      "grad_norm": 0.030416199937462807,
      "learning_rate": 9.06059502509619e-06,
      "loss": 0.0019,
      "step": 5933
    },
    {
      "epoch": 0.09395633104802319,
      "grad_norm": 0.005396407563239336,
      "learning_rate": 9.06043668951977e-06,
      "loss": 0.0003,
      "step": 5934
    },
    {
      "epoch": 0.09397216460566525,
      "grad_norm": 0.01287212036550045,
      "learning_rate": 9.060278353943347e-06,
      "loss": 0.0006,
      "step": 5935
    },
    {
      "epoch": 0.09398799816330732,
      "grad_norm": 0.2817995250225067,
      "learning_rate": 9.060120018366928e-06,
      "loss": 0.2053,
      "step": 5936
    },
    {
      "epoch": 0.09400383172094938,
      "grad_norm": 0.3651367425918579,
      "learning_rate": 9.059961682790507e-06,
      "loss": 0.1746,
      "step": 5937
    },
    {
      "epoch": 0.09401966527859144,
      "grad_norm": 0.26229560375213623,
      "learning_rate": 9.059803347214086e-06,
      "loss": 0.0529,
      "step": 5938
    },
    {
      "epoch": 0.09403549883623351,
      "grad_norm": 0.08429966866970062,
      "learning_rate": 9.059645011637665e-06,
      "loss": 0.0042,
      "step": 5939
    },
    {
      "epoch": 0.09405133239387559,
      "grad_norm": 0.013630121946334839,
      "learning_rate": 9.059486676061246e-06,
      "loss": 0.0007,
      "step": 5940
    },
    {
      "epoch": 0.09406716595151765,
      "grad_norm": 0.1835833638906479,
      "learning_rate": 9.059328340484824e-06,
      "loss": 0.0403,
      "step": 5941
    },
    {
      "epoch": 0.09408299950915971,
      "grad_norm": 0.05037631466984749,
      "learning_rate": 9.059170004908404e-06,
      "loss": 0.0031,
      "step": 5942
    },
    {
      "epoch": 0.09409883306680178,
      "grad_norm": 0.3079792261123657,
      "learning_rate": 9.059011669331983e-06,
      "loss": 0.1377,
      "step": 5943
    },
    {
      "epoch": 0.09411466662444384,
      "grad_norm": 0.023620177060365677,
      "learning_rate": 9.058853333755563e-06,
      "loss": 0.0012,
      "step": 5944
    },
    {
      "epoch": 0.09413050018208591,
      "grad_norm": 0.24038825929164886,
      "learning_rate": 9.058694998179142e-06,
      "loss": 0.1594,
      "step": 5945
    },
    {
      "epoch": 0.09414633373972799,
      "grad_norm": 0.00020682261674664915,
      "learning_rate": 9.05853666260272e-06,
      "loss": 0.0,
      "step": 5946
    },
    {
      "epoch": 0.09416216729737005,
      "grad_norm": 0.3746286630630493,
      "learning_rate": 9.0583783270263e-06,
      "loss": 0.1321,
      "step": 5947
    },
    {
      "epoch": 0.09417800085501211,
      "grad_norm": 0.5073646903038025,
      "learning_rate": 9.058219991449879e-06,
      "loss": 0.1978,
      "step": 5948
    },
    {
      "epoch": 0.09419383441265418,
      "grad_norm": 0.26682254672050476,
      "learning_rate": 9.05806165587346e-06,
      "loss": 0.1418,
      "step": 5949
    },
    {
      "epoch": 0.09420966797029624,
      "grad_norm": 0.11715646833181381,
      "learning_rate": 9.057903320297039e-06,
      "loss": 0.0065,
      "step": 5950
    },
    {
      "epoch": 0.09422550152793831,
      "grad_norm": 0.191183939576149,
      "learning_rate": 9.057744984720618e-06,
      "loss": 0.0501,
      "step": 5951
    },
    {
      "epoch": 0.09424133508558039,
      "grad_norm": 0.4336414933204651,
      "learning_rate": 9.057586649144197e-06,
      "loss": 0.0152,
      "step": 5952
    },
    {
      "epoch": 0.09425716864322245,
      "grad_norm": 0.8271386027336121,
      "learning_rate": 9.057428313567776e-06,
      "loss": 0.4536,
      "step": 5953
    },
    {
      "epoch": 0.09427300220086451,
      "grad_norm": 0.01290454063564539,
      "learning_rate": 9.057269977991355e-06,
      "loss": 0.0007,
      "step": 5954
    },
    {
      "epoch": 0.09428883575850658,
      "grad_norm": 0.012672223150730133,
      "learning_rate": 9.057111642414936e-06,
      "loss": 0.0007,
      "step": 5955
    },
    {
      "epoch": 0.09430466931614864,
      "grad_norm": 0.051447901874780655,
      "learning_rate": 9.056953306838515e-06,
      "loss": 0.0007,
      "step": 5956
    },
    {
      "epoch": 0.09432050287379071,
      "grad_norm": 0.03677435964345932,
      "learning_rate": 9.056794971262094e-06,
      "loss": 0.0037,
      "step": 5957
    },
    {
      "epoch": 0.09433633643143279,
      "grad_norm": 0.31221121549606323,
      "learning_rate": 9.056636635685673e-06,
      "loss": 0.2095,
      "step": 5958
    },
    {
      "epoch": 0.09435216998907485,
      "grad_norm": 0.19038604199886322,
      "learning_rate": 9.056478300109252e-06,
      "loss": 0.1321,
      "step": 5959
    },
    {
      "epoch": 0.09436800354671691,
      "grad_norm": 0.27054694294929504,
      "learning_rate": 9.056319964532831e-06,
      "loss": 0.2313,
      "step": 5960
    },
    {
      "epoch": 0.09438383710435898,
      "grad_norm": 0.26062649488449097,
      "learning_rate": 9.056161628956412e-06,
      "loss": 0.0588,
      "step": 5961
    },
    {
      "epoch": 0.09439967066200104,
      "grad_norm": 0.21205268800258636,
      "learning_rate": 9.056003293379991e-06,
      "loss": 0.0874,
      "step": 5962
    },
    {
      "epoch": 0.0944155042196431,
      "grad_norm": 0.013323236256837845,
      "learning_rate": 9.05584495780357e-06,
      "loss": 0.0008,
      "step": 5963
    },
    {
      "epoch": 0.09443133777728518,
      "grad_norm": 0.1783408224582672,
      "learning_rate": 9.05568662222715e-06,
      "loss": 0.2377,
      "step": 5964
    },
    {
      "epoch": 0.09444717133492725,
      "grad_norm": 0.16492201387882233,
      "learning_rate": 9.055528286650728e-06,
      "loss": 0.0614,
      "step": 5965
    },
    {
      "epoch": 0.09446300489256931,
      "grad_norm": 0.439527302980423,
      "learning_rate": 9.055369951074307e-06,
      "loss": 0.1326,
      "step": 5966
    },
    {
      "epoch": 0.09447883845021138,
      "grad_norm": 4.9429341743234545e-05,
      "learning_rate": 9.055211615497886e-06,
      "loss": 0.0,
      "step": 5967
    },
    {
      "epoch": 0.09449467200785344,
      "grad_norm": 0.02249862439930439,
      "learning_rate": 9.055053279921465e-06,
      "loss": 0.0013,
      "step": 5968
    },
    {
      "epoch": 0.0945105055654955,
      "grad_norm": 0.37215152382850647,
      "learning_rate": 9.054894944345045e-06,
      "loss": 0.0715,
      "step": 5969
    },
    {
      "epoch": 0.09452633912313758,
      "grad_norm": 0.14474010467529297,
      "learning_rate": 9.054736608768625e-06,
      "loss": 0.0355,
      "step": 5970
    },
    {
      "epoch": 0.09454217268077965,
      "grad_norm": 0.17772530019283295,
      "learning_rate": 9.054578273192204e-06,
      "loss": 0.2508,
      "step": 5971
    },
    {
      "epoch": 0.09455800623842171,
      "grad_norm": 0.18240809440612793,
      "learning_rate": 9.054419937615784e-06,
      "loss": 0.1023,
      "step": 5972
    },
    {
      "epoch": 0.09457383979606378,
      "grad_norm": 0.22682686150074005,
      "learning_rate": 9.054261602039363e-06,
      "loss": 0.0899,
      "step": 5973
    },
    {
      "epoch": 0.09458967335370584,
      "grad_norm": 0.29164695739746094,
      "learning_rate": 9.054103266462942e-06,
      "loss": 0.2176,
      "step": 5974
    },
    {
      "epoch": 0.0946055069113479,
      "grad_norm": 0.3111112415790558,
      "learning_rate": 9.05394493088652e-06,
      "loss": 0.385,
      "step": 5975
    },
    {
      "epoch": 0.09462134046898998,
      "grad_norm": 0.3035200834274292,
      "learning_rate": 9.053786595310102e-06,
      "loss": 0.4113,
      "step": 5976
    },
    {
      "epoch": 0.09463717402663205,
      "grad_norm": 0.22806569933891296,
      "learning_rate": 9.05362825973368e-06,
      "loss": 0.1283,
      "step": 5977
    },
    {
      "epoch": 0.09465300758427411,
      "grad_norm": 0.0002063308929791674,
      "learning_rate": 9.05346992415726e-06,
      "loss": 0.0,
      "step": 5978
    },
    {
      "epoch": 0.09466884114191618,
      "grad_norm": 0.23159366846084595,
      "learning_rate": 9.053311588580839e-06,
      "loss": 0.3203,
      "step": 5979
    },
    {
      "epoch": 0.09468467469955824,
      "grad_norm": 0.17513076961040497,
      "learning_rate": 9.053153253004418e-06,
      "loss": 0.1069,
      "step": 5980
    },
    {
      "epoch": 0.0947005082572003,
      "grad_norm": 0.11716502159833908,
      "learning_rate": 9.052994917427997e-06,
      "loss": 0.0291,
      "step": 5981
    },
    {
      "epoch": 0.09471634181484238,
      "grad_norm": 0.02090396359562874,
      "learning_rate": 9.052836581851578e-06,
      "loss": 0.0012,
      "step": 5982
    },
    {
      "epoch": 0.09473217537248445,
      "grad_norm": 0.009892064146697521,
      "learning_rate": 9.052678246275157e-06,
      "loss": 0.0005,
      "step": 5983
    },
    {
      "epoch": 0.09474800893012651,
      "grad_norm": 0.23280690610408783,
      "learning_rate": 9.052519910698736e-06,
      "loss": 0.1077,
      "step": 5984
    },
    {
      "epoch": 0.09476384248776858,
      "grad_norm": 0.5040754079818726,
      "learning_rate": 9.052361575122315e-06,
      "loss": 0.2684,
      "step": 5985
    },
    {
      "epoch": 0.09477967604541064,
      "grad_norm": 0.2958456575870514,
      "learning_rate": 9.052203239545894e-06,
      "loss": 0.0677,
      "step": 5986
    },
    {
      "epoch": 0.0947955096030527,
      "grad_norm": 0.016990114003419876,
      "learning_rate": 9.052044903969473e-06,
      "loss": 0.0009,
      "step": 5987
    },
    {
      "epoch": 0.09481134316069478,
      "grad_norm": 0.012229307554662228,
      "learning_rate": 9.051886568393054e-06,
      "loss": 0.0008,
      "step": 5988
    },
    {
      "epoch": 0.09482717671833685,
      "grad_norm": 0.00017991149798035622,
      "learning_rate": 9.051728232816633e-06,
      "loss": 0.0,
      "step": 5989
    },
    {
      "epoch": 0.09484301027597891,
      "grad_norm": 0.3089560568332672,
      "learning_rate": 9.051569897240212e-06,
      "loss": 0.1969,
      "step": 5990
    },
    {
      "epoch": 0.09485884383362098,
      "grad_norm": 0.24616682529449463,
      "learning_rate": 9.051411561663791e-06,
      "loss": 0.1288,
      "step": 5991
    },
    {
      "epoch": 0.09487467739126304,
      "grad_norm": 6.148899410618469e-05,
      "learning_rate": 9.05125322608737e-06,
      "loss": 0.0,
      "step": 5992
    },
    {
      "epoch": 0.0948905109489051,
      "grad_norm": 0.7908863425254822,
      "learning_rate": 9.05109489051095e-06,
      "loss": 0.4983,
      "step": 5993
    },
    {
      "epoch": 0.09490634450654718,
      "grad_norm": 0.36982253193855286,
      "learning_rate": 9.050936554934528e-06,
      "loss": 0.1176,
      "step": 5994
    },
    {
      "epoch": 0.09492217806418925,
      "grad_norm": 0.574577808380127,
      "learning_rate": 9.050778219358109e-06,
      "loss": 0.1954,
      "step": 5995
    },
    {
      "epoch": 0.09493801162183131,
      "grad_norm": 0.2735643982887268,
      "learning_rate": 9.050619883781687e-06,
      "loss": 0.0598,
      "step": 5996
    },
    {
      "epoch": 0.09495384517947338,
      "grad_norm": 0.005515549331903458,
      "learning_rate": 9.050461548205267e-06,
      "loss": 0.0001,
      "step": 5997
    },
    {
      "epoch": 0.09496967873711544,
      "grad_norm": 0.1772613525390625,
      "learning_rate": 9.050303212628846e-06,
      "loss": 0.0674,
      "step": 5998
    },
    {
      "epoch": 0.0949855122947575,
      "grad_norm": 0.4493388235569,
      "learning_rate": 9.050144877052425e-06,
      "loss": 0.0815,
      "step": 5999
    },
    {
      "epoch": 0.09500134585239958,
      "grad_norm": 0.31077560782432556,
      "learning_rate": 9.049986541476005e-06,
      "loss": 0.2268,
      "step": 6000
    },
    {
      "epoch": 0.09501717941004165,
      "grad_norm": 0.23569993674755096,
      "learning_rate": 9.049828205899585e-06,
      "loss": 0.148,
      "step": 6001
    },
    {
      "epoch": 0.09503301296768371,
      "grad_norm": 0.01206611841917038,
      "learning_rate": 9.049669870323163e-06,
      "loss": 0.0007,
      "step": 6002
    },
    {
      "epoch": 0.09504884652532578,
      "grad_norm": 0.2786259055137634,
      "learning_rate": 9.049511534746743e-06,
      "loss": 0.2218,
      "step": 6003
    },
    {
      "epoch": 0.09506468008296784,
      "grad_norm": 0.1993049681186676,
      "learning_rate": 9.049353199170323e-06,
      "loss": 0.026,
      "step": 6004
    },
    {
      "epoch": 0.0950805136406099,
      "grad_norm": 0.498510479927063,
      "learning_rate": 9.049194863593902e-06,
      "loss": 0.2137,
      "step": 6005
    },
    {
      "epoch": 0.09509634719825198,
      "grad_norm": 0.020502381026744843,
      "learning_rate": 9.04903652801748e-06,
      "loss": 0.0012,
      "step": 6006
    },
    {
      "epoch": 0.09511218075589405,
      "grad_norm": 0.3549404740333557,
      "learning_rate": 9.048878192441061e-06,
      "loss": 0.2785,
      "step": 6007
    },
    {
      "epoch": 0.09512801431353611,
      "grad_norm": 0.5248619318008423,
      "learning_rate": 9.048719856864639e-06,
      "loss": 0.3229,
      "step": 6008
    },
    {
      "epoch": 0.09514384787117817,
      "grad_norm": 0.32372668385505676,
      "learning_rate": 9.04856152128822e-06,
      "loss": 0.0466,
      "step": 6009
    },
    {
      "epoch": 0.09515968142882024,
      "grad_norm": 0.2451012134552002,
      "learning_rate": 9.048403185711799e-06,
      "loss": 0.1056,
      "step": 6010
    },
    {
      "epoch": 0.0951755149864623,
      "grad_norm": 0.302077054977417,
      "learning_rate": 9.048244850135378e-06,
      "loss": 0.1454,
      "step": 6011
    },
    {
      "epoch": 0.09519134854410438,
      "grad_norm": 0.324809730052948,
      "learning_rate": 9.048086514558957e-06,
      "loss": 0.0986,
      "step": 6012
    },
    {
      "epoch": 0.09520718210174645,
      "grad_norm": 0.3061233460903168,
      "learning_rate": 9.047928178982538e-06,
      "loss": 0.2443,
      "step": 6013
    },
    {
      "epoch": 0.09522301565938851,
      "grad_norm": 1.0518198013305664,
      "learning_rate": 9.047769843406115e-06,
      "loss": 0.0671,
      "step": 6014
    },
    {
      "epoch": 0.09523884921703057,
      "grad_norm": 0.8722178936004639,
      "learning_rate": 9.047611507829694e-06,
      "loss": 0.3145,
      "step": 6015
    },
    {
      "epoch": 0.09525468277467264,
      "grad_norm": 0.2277473360300064,
      "learning_rate": 9.047453172253275e-06,
      "loss": 0.0471,
      "step": 6016
    },
    {
      "epoch": 0.0952705163323147,
      "grad_norm": 0.4145934581756592,
      "learning_rate": 9.047294836676854e-06,
      "loss": 0.4174,
      "step": 6017
    },
    {
      "epoch": 0.09528634988995678,
      "grad_norm": 0.030236639082431793,
      "learning_rate": 9.047136501100433e-06,
      "loss": 0.002,
      "step": 6018
    },
    {
      "epoch": 0.09530218344759885,
      "grad_norm": 0.023961713537573814,
      "learning_rate": 9.046978165524012e-06,
      "loss": 0.0014,
      "step": 6019
    },
    {
      "epoch": 0.09531801700524091,
      "grad_norm": 0.35406041145324707,
      "learning_rate": 9.046819829947591e-06,
      "loss": 0.2143,
      "step": 6020
    },
    {
      "epoch": 0.09533385056288297,
      "grad_norm": 0.24824251234531403,
      "learning_rate": 9.04666149437117e-06,
      "loss": 0.0803,
      "step": 6021
    },
    {
      "epoch": 0.09534968412052504,
      "grad_norm": 0.0012578436871990561,
      "learning_rate": 9.046503158794751e-06,
      "loss": 0.0001,
      "step": 6022
    },
    {
      "epoch": 0.0953655176781671,
      "grad_norm": 0.38214144110679626,
      "learning_rate": 9.04634482321833e-06,
      "loss": 0.061,
      "step": 6023
    },
    {
      "epoch": 0.09538135123580918,
      "grad_norm": 0.3561802804470062,
      "learning_rate": 9.04618648764191e-06,
      "loss": 0.0891,
      "step": 6024
    },
    {
      "epoch": 0.09539718479345125,
      "grad_norm": 0.2360638678073883,
      "learning_rate": 9.046028152065488e-06,
      "loss": 0.0829,
      "step": 6025
    },
    {
      "epoch": 0.09541301835109331,
      "grad_norm": 0.0172519963234663,
      "learning_rate": 9.045869816489067e-06,
      "loss": 0.001,
      "step": 6026
    },
    {
      "epoch": 0.09542885190873537,
      "grad_norm": 0.48112115263938904,
      "learning_rate": 9.045711480912646e-06,
      "loss": 0.3169,
      "step": 6027
    },
    {
      "epoch": 0.09544468546637744,
      "grad_norm": 0.39632168412208557,
      "learning_rate": 9.045553145336227e-06,
      "loss": 0.2053,
      "step": 6028
    },
    {
      "epoch": 0.0954605190240195,
      "grad_norm": 0.2770843505859375,
      "learning_rate": 9.045394809759805e-06,
      "loss": 0.1236,
      "step": 6029
    },
    {
      "epoch": 0.09547635258166158,
      "grad_norm": 0.00010347361967433244,
      "learning_rate": 9.045236474183385e-06,
      "loss": 0.0,
      "step": 6030
    },
    {
      "epoch": 0.09549218613930364,
      "grad_norm": 2.224571466445923,
      "learning_rate": 9.045078138606964e-06,
      "loss": 0.1055,
      "step": 6031
    },
    {
      "epoch": 0.09550801969694571,
      "grad_norm": 0.23755478858947754,
      "learning_rate": 9.044919803030544e-06,
      "loss": 0.0998,
      "step": 6032
    },
    {
      "epoch": 0.09552385325458777,
      "grad_norm": 0.2362399399280548,
      "learning_rate": 9.044761467454123e-06,
      "loss": 0.0471,
      "step": 6033
    },
    {
      "epoch": 0.09553968681222984,
      "grad_norm": 0.5262191295623779,
      "learning_rate": 9.044603131877703e-06,
      "loss": 0.5377,
      "step": 6034
    },
    {
      "epoch": 0.0955555203698719,
      "grad_norm": 0.25404828786849976,
      "learning_rate": 9.04444479630128e-06,
      "loss": 0.0945,
      "step": 6035
    },
    {
      "epoch": 0.09557135392751397,
      "grad_norm": 0.27392059564590454,
      "learning_rate": 9.044286460724862e-06,
      "loss": 0.057,
      "step": 6036
    },
    {
      "epoch": 0.09558718748515604,
      "grad_norm": 0.38990527391433716,
      "learning_rate": 9.04412812514844e-06,
      "loss": 0.1274,
      "step": 6037
    },
    {
      "epoch": 0.09560302104279811,
      "grad_norm": 0.00529828853905201,
      "learning_rate": 9.04396978957202e-06,
      "loss": 0.0003,
      "step": 6038
    },
    {
      "epoch": 0.09561885460044017,
      "grad_norm": 0.3100326955318451,
      "learning_rate": 9.043811453995599e-06,
      "loss": 0.2429,
      "step": 6039
    },
    {
      "epoch": 0.09563468815808224,
      "grad_norm": 0.6746481657028198,
      "learning_rate": 9.043653118419178e-06,
      "loss": 0.1875,
      "step": 6040
    },
    {
      "epoch": 0.0956505217157243,
      "grad_norm": 0.20283883810043335,
      "learning_rate": 9.043494782842757e-06,
      "loss": 0.0514,
      "step": 6041
    },
    {
      "epoch": 0.09566635527336637,
      "grad_norm": 0.34220778942108154,
      "learning_rate": 9.043336447266336e-06,
      "loss": 0.1423,
      "step": 6042
    },
    {
      "epoch": 0.09568218883100844,
      "grad_norm": 0.03380274400115013,
      "learning_rate": 9.043178111689917e-06,
      "loss": 0.0018,
      "step": 6043
    },
    {
      "epoch": 0.09569802238865051,
      "grad_norm": 0.614657461643219,
      "learning_rate": 9.043019776113496e-06,
      "loss": 0.0952,
      "step": 6044
    },
    {
      "epoch": 0.09571385594629257,
      "grad_norm": 0.2281530499458313,
      "learning_rate": 9.042861440537075e-06,
      "loss": 0.137,
      "step": 6045
    },
    {
      "epoch": 0.09572968950393464,
      "grad_norm": 0.2167336344718933,
      "learning_rate": 9.042703104960654e-06,
      "loss": 0.1769,
      "step": 6046
    },
    {
      "epoch": 0.0957455230615767,
      "grad_norm": 0.41487833857536316,
      "learning_rate": 9.042544769384233e-06,
      "loss": 0.3489,
      "step": 6047
    },
    {
      "epoch": 0.09576135661921877,
      "grad_norm": 0.6323045492172241,
      "learning_rate": 9.042386433807812e-06,
      "loss": 0.2065,
      "step": 6048
    },
    {
      "epoch": 0.09577719017686084,
      "grad_norm": 0.034201692789793015,
      "learning_rate": 9.042228098231393e-06,
      "loss": 0.0017,
      "step": 6049
    },
    {
      "epoch": 0.09579302373450291,
      "grad_norm": 0.00015700187941547483,
      "learning_rate": 9.042069762654972e-06,
      "loss": 0.0,
      "step": 6050
    },
    {
      "epoch": 0.09580885729214497,
      "grad_norm": 0.5585838556289673,
      "learning_rate": 9.041911427078551e-06,
      "loss": 0.3455,
      "step": 6051
    },
    {
      "epoch": 0.09582469084978704,
      "grad_norm": 0.18786604702472687,
      "learning_rate": 9.04175309150213e-06,
      "loss": 0.0814,
      "step": 6052
    },
    {
      "epoch": 0.0958405244074291,
      "grad_norm": 0.0807119756937027,
      "learning_rate": 9.04159475592571e-06,
      "loss": 0.0043,
      "step": 6053
    },
    {
      "epoch": 0.09585635796507117,
      "grad_norm": 0.20714573562145233,
      "learning_rate": 9.041436420349288e-06,
      "loss": 0.102,
      "step": 6054
    },
    {
      "epoch": 0.09587219152271324,
      "grad_norm": 0.303749144077301,
      "learning_rate": 9.041278084772869e-06,
      "loss": 0.1327,
      "step": 6055
    },
    {
      "epoch": 0.09588802508035531,
      "grad_norm": 0.0029925135895609856,
      "learning_rate": 9.041119749196448e-06,
      "loss": 0.0001,
      "step": 6056
    },
    {
      "epoch": 0.09590385863799737,
      "grad_norm": 0.41964197158813477,
      "learning_rate": 9.040961413620027e-06,
      "loss": 0.0882,
      "step": 6057
    },
    {
      "epoch": 0.09591969219563944,
      "grad_norm": 0.0980868712067604,
      "learning_rate": 9.040803078043606e-06,
      "loss": 0.0585,
      "step": 6058
    },
    {
      "epoch": 0.0959355257532815,
      "grad_norm": 0.002327215624973178,
      "learning_rate": 9.040644742467185e-06,
      "loss": 0.0001,
      "step": 6059
    },
    {
      "epoch": 0.09595135931092356,
      "grad_norm": 0.05441732332110405,
      "learning_rate": 9.040486406890765e-06,
      "loss": 0.0159,
      "step": 6060
    },
    {
      "epoch": 0.09596719286856564,
      "grad_norm": 0.6230672001838684,
      "learning_rate": 9.040328071314345e-06,
      "loss": 0.1158,
      "step": 6061
    },
    {
      "epoch": 0.09598302642620771,
      "grad_norm": 0.2105530947446823,
      "learning_rate": 9.040169735737924e-06,
      "loss": 0.0637,
      "step": 6062
    },
    {
      "epoch": 0.09599885998384977,
      "grad_norm": 0.25423842668533325,
      "learning_rate": 9.040011400161503e-06,
      "loss": 0.1051,
      "step": 6063
    },
    {
      "epoch": 0.09601469354149184,
      "grad_norm": 0.05322975665330887,
      "learning_rate": 9.039853064585083e-06,
      "loss": 0.0044,
      "step": 6064
    },
    {
      "epoch": 0.0960305270991339,
      "grad_norm": 0.5522472262382507,
      "learning_rate": 9.039694729008662e-06,
      "loss": 0.2199,
      "step": 6065
    },
    {
      "epoch": 0.09604636065677596,
      "grad_norm": 0.2879888117313385,
      "learning_rate": 9.03953639343224e-06,
      "loss": 0.1453,
      "step": 6066
    },
    {
      "epoch": 0.09606219421441804,
      "grad_norm": 0.1868080198764801,
      "learning_rate": 9.03937805785582e-06,
      "loss": 0.0664,
      "step": 6067
    },
    {
      "epoch": 0.0960780277720601,
      "grad_norm": 0.012568934820592403,
      "learning_rate": 9.0392197222794e-06,
      "loss": 0.0008,
      "step": 6068
    },
    {
      "epoch": 0.09609386132970217,
      "grad_norm": 0.007430593948811293,
      "learning_rate": 9.039061386702978e-06,
      "loss": 0.0004,
      "step": 6069
    },
    {
      "epoch": 0.09610969488734424,
      "grad_norm": 0.0005025033606216311,
      "learning_rate": 9.038903051126559e-06,
      "loss": 0.0,
      "step": 6070
    },
    {
      "epoch": 0.0961255284449863,
      "grad_norm": 0.016160989180207253,
      "learning_rate": 9.038744715550138e-06,
      "loss": 0.001,
      "step": 6071
    },
    {
      "epoch": 0.09614136200262836,
      "grad_norm": 0.24012689292430878,
      "learning_rate": 9.038586379973717e-06,
      "loss": 0.1535,
      "step": 6072
    },
    {
      "epoch": 0.09615719556027044,
      "grad_norm": 0.9384850263595581,
      "learning_rate": 9.038428044397296e-06,
      "loss": 0.1129,
      "step": 6073
    },
    {
      "epoch": 0.0961730291179125,
      "grad_norm": 0.03920228034257889,
      "learning_rate": 9.038269708820877e-06,
      "loss": 0.0009,
      "step": 6074
    },
    {
      "epoch": 0.09618886267555457,
      "grad_norm": 0.00014259670570027083,
      "learning_rate": 9.038111373244454e-06,
      "loss": 0.0,
      "step": 6075
    },
    {
      "epoch": 0.09620469623319663,
      "grad_norm": 0.24300147593021393,
      "learning_rate": 9.037953037668035e-06,
      "loss": 0.1815,
      "step": 6076
    },
    {
      "epoch": 0.0962205297908387,
      "grad_norm": 0.08478035032749176,
      "learning_rate": 9.037794702091614e-06,
      "loss": 0.01,
      "step": 6077
    },
    {
      "epoch": 0.09623636334848076,
      "grad_norm": 0.18197740614414215,
      "learning_rate": 9.037636366515193e-06,
      "loss": 0.0703,
      "step": 6078
    },
    {
      "epoch": 0.09625219690612284,
      "grad_norm": 0.17734037339687347,
      "learning_rate": 9.037478030938772e-06,
      "loss": 0.1142,
      "step": 6079
    },
    {
      "epoch": 0.0962680304637649,
      "grad_norm": 0.000498536042869091,
      "learning_rate": 9.037319695362353e-06,
      "loss": 0.0,
      "step": 6080
    },
    {
      "epoch": 0.09628386402140697,
      "grad_norm": 0.0025889065582305193,
      "learning_rate": 9.03716135978593e-06,
      "loss": 0.0,
      "step": 6081
    },
    {
      "epoch": 0.09629969757904903,
      "grad_norm": 0.12370293587446213,
      "learning_rate": 9.037003024209511e-06,
      "loss": 0.0313,
      "step": 6082
    },
    {
      "epoch": 0.0963155311366911,
      "grad_norm": 0.5611580014228821,
      "learning_rate": 9.03684468863309e-06,
      "loss": 1.2536,
      "step": 6083
    },
    {
      "epoch": 0.09633136469433316,
      "grad_norm": 0.3597012758255005,
      "learning_rate": 9.03668635305667e-06,
      "loss": 0.2543,
      "step": 6084
    },
    {
      "epoch": 0.09634719825197524,
      "grad_norm": 0.3210659325122833,
      "learning_rate": 9.036528017480248e-06,
      "loss": 0.2001,
      "step": 6085
    },
    {
      "epoch": 0.0963630318096173,
      "grad_norm": 0.3810935914516449,
      "learning_rate": 9.036369681903829e-06,
      "loss": 0.1042,
      "step": 6086
    },
    {
      "epoch": 0.09637886536725937,
      "grad_norm": 0.3393075466156006,
      "learning_rate": 9.036211346327406e-06,
      "loss": 0.3196,
      "step": 6087
    },
    {
      "epoch": 0.09639469892490143,
      "grad_norm": 0.9438132643699646,
      "learning_rate": 9.036053010750986e-06,
      "loss": 1.0048,
      "step": 6088
    },
    {
      "epoch": 0.0964105324825435,
      "grad_norm": 1.1572179794311523,
      "learning_rate": 9.035894675174566e-06,
      "loss": 1.2358,
      "step": 6089
    },
    {
      "epoch": 0.09642636604018556,
      "grad_norm": 0.489299476146698,
      "learning_rate": 9.035736339598145e-06,
      "loss": 0.0787,
      "step": 6090
    },
    {
      "epoch": 0.09644219959782764,
      "grad_norm": 0.14820654690265656,
      "learning_rate": 9.035578004021724e-06,
      "loss": 0.0901,
      "step": 6091
    },
    {
      "epoch": 0.0964580331554697,
      "grad_norm": 0.019596586003899574,
      "learning_rate": 9.035419668445304e-06,
      "loss": 0.0013,
      "step": 6092
    },
    {
      "epoch": 0.09647386671311177,
      "grad_norm": 0.2848913073539734,
      "learning_rate": 9.035261332868883e-06,
      "loss": 0.115,
      "step": 6093
    },
    {
      "epoch": 0.09648970027075383,
      "grad_norm": 0.21933545172214508,
      "learning_rate": 9.035102997292462e-06,
      "loss": 0.1837,
      "step": 6094
    },
    {
      "epoch": 0.0965055338283959,
      "grad_norm": 0.2205103635787964,
      "learning_rate": 9.034944661716042e-06,
      "loss": 0.135,
      "step": 6095
    },
    {
      "epoch": 0.09652136738603796,
      "grad_norm": 0.2361420840024948,
      "learning_rate": 9.03478632613962e-06,
      "loss": 0.1029,
      "step": 6096
    },
    {
      "epoch": 0.09653720094368004,
      "grad_norm": 0.27375438809394836,
      "learning_rate": 9.0346279905632e-06,
      "loss": 0.1469,
      "step": 6097
    },
    {
      "epoch": 0.0965530345013221,
      "grad_norm": 0.012045162729918957,
      "learning_rate": 9.03446965498678e-06,
      "loss": 0.0006,
      "step": 6098
    },
    {
      "epoch": 0.09656886805896417,
      "grad_norm": 0.2132333219051361,
      "learning_rate": 9.034311319410359e-06,
      "loss": 0.0272,
      "step": 6099
    },
    {
      "epoch": 0.09658470161660623,
      "grad_norm": 0.01121042761951685,
      "learning_rate": 9.034152983833938e-06,
      "loss": 0.0008,
      "step": 6100
    },
    {
      "epoch": 0.0966005351742483,
      "grad_norm": 0.18096235394477844,
      "learning_rate": 9.033994648257519e-06,
      "loss": 0.0198,
      "step": 6101
    },
    {
      "epoch": 0.09661636873189036,
      "grad_norm": 0.4647926688194275,
      "learning_rate": 9.033836312681096e-06,
      "loss": 0.1616,
      "step": 6102
    },
    {
      "epoch": 0.09663220228953244,
      "grad_norm": 0.23007608950138092,
      "learning_rate": 9.033677977104677e-06,
      "loss": 0.1076,
      "step": 6103
    },
    {
      "epoch": 0.0966480358471745,
      "grad_norm": 0.25888171792030334,
      "learning_rate": 9.033519641528256e-06,
      "loss": 0.1673,
      "step": 6104
    },
    {
      "epoch": 0.09666386940481657,
      "grad_norm": 0.24535198509693146,
      "learning_rate": 9.033361305951835e-06,
      "loss": 0.1436,
      "step": 6105
    },
    {
      "epoch": 0.09667970296245863,
      "grad_norm": 0.16968046128749847,
      "learning_rate": 9.033202970375414e-06,
      "loss": 0.0875,
      "step": 6106
    },
    {
      "epoch": 0.0966955365201007,
      "grad_norm": 0.5161249041557312,
      "learning_rate": 9.033044634798995e-06,
      "loss": 0.3811,
      "step": 6107
    },
    {
      "epoch": 0.09671137007774276,
      "grad_norm": 0.2663915157318115,
      "learning_rate": 9.032886299222572e-06,
      "loss": 0.1654,
      "step": 6108
    },
    {
      "epoch": 0.09672720363538484,
      "grad_norm": 0.37371471524238586,
      "learning_rate": 9.032727963646153e-06,
      "loss": 0.2353,
      "step": 6109
    },
    {
      "epoch": 0.0967430371930269,
      "grad_norm": 0.2012779712677002,
      "learning_rate": 9.032569628069732e-06,
      "loss": 0.1576,
      "step": 6110
    },
    {
      "epoch": 0.09675887075066897,
      "grad_norm": 0.014732559211552143,
      "learning_rate": 9.032411292493311e-06,
      "loss": 0.0008,
      "step": 6111
    },
    {
      "epoch": 0.09677470430831103,
      "grad_norm": 0.3121284544467926,
      "learning_rate": 9.03225295691689e-06,
      "loss": 0.1415,
      "step": 6112
    },
    {
      "epoch": 0.0967905378659531,
      "grad_norm": 0.1929328292608261,
      "learning_rate": 9.03209462134047e-06,
      "loss": 0.0644,
      "step": 6113
    },
    {
      "epoch": 0.09680637142359516,
      "grad_norm": 1.6054483652114868,
      "learning_rate": 9.031936285764048e-06,
      "loss": 0.0293,
      "step": 6114
    },
    {
      "epoch": 0.09682220498123724,
      "grad_norm": 0.3811565637588501,
      "learning_rate": 9.031777950187627e-06,
      "loss": 0.0499,
      "step": 6115
    },
    {
      "epoch": 0.0968380385388793,
      "grad_norm": 0.04892337694764137,
      "learning_rate": 9.031619614611208e-06,
      "loss": 0.0028,
      "step": 6116
    },
    {
      "epoch": 0.09685387209652137,
      "grad_norm": 0.419807106256485,
      "learning_rate": 9.031461279034787e-06,
      "loss": 0.1556,
      "step": 6117
    },
    {
      "epoch": 0.09686970565416343,
      "grad_norm": 0.588877260684967,
      "learning_rate": 9.031302943458366e-06,
      "loss": 0.0311,
      "step": 6118
    },
    {
      "epoch": 0.0968855392118055,
      "grad_norm": 0.25234267115592957,
      "learning_rate": 9.031144607881945e-06,
      "loss": 0.2062,
      "step": 6119
    },
    {
      "epoch": 0.09690137276944756,
      "grad_norm": 0.0004667233442887664,
      "learning_rate": 9.030986272305525e-06,
      "loss": 0.0,
      "step": 6120
    },
    {
      "epoch": 0.09691720632708964,
      "grad_norm": 0.15164168179035187,
      "learning_rate": 9.030827936729104e-06,
      "loss": 0.03,
      "step": 6121
    },
    {
      "epoch": 0.0969330398847317,
      "grad_norm": 0.13712471723556519,
      "learning_rate": 9.030669601152684e-06,
      "loss": 0.0698,
      "step": 6122
    },
    {
      "epoch": 0.09694887344237377,
      "grad_norm": 0.5442533493041992,
      "learning_rate": 9.030511265576263e-06,
      "loss": 0.1095,
      "step": 6123
    },
    {
      "epoch": 0.09696470700001583,
      "grad_norm": 0.07923586666584015,
      "learning_rate": 9.030352929999843e-06,
      "loss": 0.0081,
      "step": 6124
    },
    {
      "epoch": 0.0969805405576579,
      "grad_norm": 0.09639634937047958,
      "learning_rate": 9.030194594423422e-06,
      "loss": 0.0115,
      "step": 6125
    },
    {
      "epoch": 0.09699637411529996,
      "grad_norm": 0.064958356320858,
      "learning_rate": 9.030036258847e-06,
      "loss": 0.0107,
      "step": 6126
    },
    {
      "epoch": 0.09701220767294204,
      "grad_norm": 0.01059659942984581,
      "learning_rate": 9.02987792327058e-06,
      "loss": 0.0006,
      "step": 6127
    },
    {
      "epoch": 0.0970280412305841,
      "grad_norm": 0.3219563961029053,
      "learning_rate": 9.02971958769416e-06,
      "loss": 0.3746,
      "step": 6128
    },
    {
      "epoch": 0.09704387478822617,
      "grad_norm": 0.013478338718414307,
      "learning_rate": 9.02956125211774e-06,
      "loss": 0.0009,
      "step": 6129
    },
    {
      "epoch": 0.09705970834586823,
      "grad_norm": 0.2306678742170334,
      "learning_rate": 9.029402916541319e-06,
      "loss": 0.1129,
      "step": 6130
    },
    {
      "epoch": 0.0970755419035103,
      "grad_norm": 0.28636154532432556,
      "learning_rate": 9.029244580964898e-06,
      "loss": 0.2298,
      "step": 6131
    },
    {
      "epoch": 0.09709137546115236,
      "grad_norm": 0.18551987409591675,
      "learning_rate": 9.029086245388477e-06,
      "loss": 0.0993,
      "step": 6132
    },
    {
      "epoch": 0.09710720901879444,
      "grad_norm": 0.010934630408883095,
      "learning_rate": 9.028927909812056e-06,
      "loss": 0.0006,
      "step": 6133
    },
    {
      "epoch": 0.0971230425764365,
      "grad_norm": 0.1793818324804306,
      "learning_rate": 9.028769574235637e-06,
      "loss": 0.0544,
      "step": 6134
    },
    {
      "epoch": 0.09713887613407857,
      "grad_norm": 0.04523009434342384,
      "learning_rate": 9.028611238659216e-06,
      "loss": 0.0039,
      "step": 6135
    },
    {
      "epoch": 0.09715470969172063,
      "grad_norm": 0.00841267965734005,
      "learning_rate": 9.028452903082793e-06,
      "loss": 0.0004,
      "step": 6136
    },
    {
      "epoch": 0.0971705432493627,
      "grad_norm": 0.0001672753569437191,
      "learning_rate": 9.028294567506374e-06,
      "loss": 0.0,
      "step": 6137
    },
    {
      "epoch": 0.09718637680700476,
      "grad_norm": 0.3060021698474884,
      "learning_rate": 9.028136231929953e-06,
      "loss": 0.2036,
      "step": 6138
    },
    {
      "epoch": 0.09720221036464684,
      "grad_norm": 0.2346041351556778,
      "learning_rate": 9.027977896353532e-06,
      "loss": 0.0813,
      "step": 6139
    },
    {
      "epoch": 0.0972180439222889,
      "grad_norm": 0.2478322684764862,
      "learning_rate": 9.027819560777111e-06,
      "loss": 0.0493,
      "step": 6140
    },
    {
      "epoch": 0.09723387747993097,
      "grad_norm": 0.1951613426208496,
      "learning_rate": 9.027661225200692e-06,
      "loss": 0.1232,
      "step": 6141
    },
    {
      "epoch": 0.09724971103757303,
      "grad_norm": 0.26278895139694214,
      "learning_rate": 9.02750288962427e-06,
      "loss": 0.1477,
      "step": 6142
    },
    {
      "epoch": 0.0972655445952151,
      "grad_norm": 0.3836963176727295,
      "learning_rate": 9.02734455404785e-06,
      "loss": 0.2038,
      "step": 6143
    },
    {
      "epoch": 0.09728137815285716,
      "grad_norm": 0.421808660030365,
      "learning_rate": 9.02718621847143e-06,
      "loss": 0.3633,
      "step": 6144
    },
    {
      "epoch": 0.09729721171049924,
      "grad_norm": 0.25306758284568787,
      "learning_rate": 9.027027882895008e-06,
      "loss": 0.0725,
      "step": 6145
    },
    {
      "epoch": 0.0973130452681413,
      "grad_norm": 0.00016967453120741993,
      "learning_rate": 9.026869547318587e-06,
      "loss": 0.0,
      "step": 6146
    },
    {
      "epoch": 0.09732887882578337,
      "grad_norm": 1.1316232681274414,
      "learning_rate": 9.026711211742168e-06,
      "loss": 0.3027,
      "step": 6147
    },
    {
      "epoch": 0.09734471238342543,
      "grad_norm": 0.28471478819847107,
      "learning_rate": 9.026552876165746e-06,
      "loss": 0.0403,
      "step": 6148
    },
    {
      "epoch": 0.0973605459410675,
      "grad_norm": 0.214259535074234,
      "learning_rate": 9.026394540589326e-06,
      "loss": 0.0587,
      "step": 6149
    },
    {
      "epoch": 0.09737637949870956,
      "grad_norm": 0.2654092609882355,
      "learning_rate": 9.026236205012905e-06,
      "loss": 0.1041,
      "step": 6150
    },
    {
      "epoch": 0.09739221305635164,
      "grad_norm": 0.9878187775611877,
      "learning_rate": 9.026077869436484e-06,
      "loss": 0.0507,
      "step": 6151
    },
    {
      "epoch": 0.0974080466139937,
      "grad_norm": 0.5545571446418762,
      "learning_rate": 9.025919533860064e-06,
      "loss": 0.7575,
      "step": 6152
    },
    {
      "epoch": 0.09742388017163577,
      "grad_norm": 0.004630229435861111,
      "learning_rate": 9.025761198283644e-06,
      "loss": 0.0003,
      "step": 6153
    },
    {
      "epoch": 0.09743971372927783,
      "grad_norm": 0.46794745326042175,
      "learning_rate": 9.025602862707222e-06,
      "loss": 0.153,
      "step": 6154
    },
    {
      "epoch": 0.0974555472869199,
      "grad_norm": 0.005107771139591932,
      "learning_rate": 9.025444527130803e-06,
      "loss": 0.0001,
      "step": 6155
    },
    {
      "epoch": 0.09747138084456196,
      "grad_norm": 0.3720613121986389,
      "learning_rate": 9.025286191554382e-06,
      "loss": 0.0402,
      "step": 6156
    },
    {
      "epoch": 0.09748721440220404,
      "grad_norm": 0.0030837280210107565,
      "learning_rate": 9.02512785597796e-06,
      "loss": 0.0001,
      "step": 6157
    },
    {
      "epoch": 0.0975030479598461,
      "grad_norm": 0.2923755943775177,
      "learning_rate": 9.02496952040154e-06,
      "loss": 0.32,
      "step": 6158
    },
    {
      "epoch": 0.09751888151748817,
      "grad_norm": 4.838469249079935e-05,
      "learning_rate": 9.024811184825119e-06,
      "loss": 0.0,
      "step": 6159
    },
    {
      "epoch": 0.09753471507513023,
      "grad_norm": 0.2546415627002716,
      "learning_rate": 9.024652849248698e-06,
      "loss": 0.1328,
      "step": 6160
    },
    {
      "epoch": 0.0975505486327723,
      "grad_norm": 0.28623268008232117,
      "learning_rate": 9.024494513672277e-06,
      "loss": 0.1315,
      "step": 6161
    },
    {
      "epoch": 0.09756638219041436,
      "grad_norm": 0.17414352297782898,
      "learning_rate": 9.024336178095858e-06,
      "loss": 0.0451,
      "step": 6162
    },
    {
      "epoch": 0.09758221574805644,
      "grad_norm": 0.3778725266456604,
      "learning_rate": 9.024177842519435e-06,
      "loss": 0.1015,
      "step": 6163
    },
    {
      "epoch": 0.0975980493056985,
      "grad_norm": 0.037414729595184326,
      "learning_rate": 9.024019506943016e-06,
      "loss": 0.0024,
      "step": 6164
    },
    {
      "epoch": 0.09761388286334056,
      "grad_norm": 0.40105482935905457,
      "learning_rate": 9.023861171366595e-06,
      "loss": 0.3105,
      "step": 6165
    },
    {
      "epoch": 0.09762971642098263,
      "grad_norm": 0.3482997417449951,
      "learning_rate": 9.023702835790174e-06,
      "loss": 0.0703,
      "step": 6166
    },
    {
      "epoch": 0.0976455499786247,
      "grad_norm": 0.26885759830474854,
      "learning_rate": 9.023544500213753e-06,
      "loss": 0.0505,
      "step": 6167
    },
    {
      "epoch": 0.09766138353626676,
      "grad_norm": 0.9387511610984802,
      "learning_rate": 9.023386164637334e-06,
      "loss": 0.2197,
      "step": 6168
    },
    {
      "epoch": 0.09767721709390884,
      "grad_norm": 0.4706960916519165,
      "learning_rate": 9.023227829060911e-06,
      "loss": 0.067,
      "step": 6169
    },
    {
      "epoch": 0.0976930506515509,
      "grad_norm": 0.13773515820503235,
      "learning_rate": 9.023069493484492e-06,
      "loss": 0.0549,
      "step": 6170
    },
    {
      "epoch": 0.09770888420919296,
      "grad_norm": 0.36171281337738037,
      "learning_rate": 9.022911157908071e-06,
      "loss": 0.0538,
      "step": 6171
    },
    {
      "epoch": 0.09772471776683503,
      "grad_norm": 0.47910192608833313,
      "learning_rate": 9.02275282233165e-06,
      "loss": 0.289,
      "step": 6172
    },
    {
      "epoch": 0.09774055132447709,
      "grad_norm": 0.6275389790534973,
      "learning_rate": 9.02259448675523e-06,
      "loss": 0.3105,
      "step": 6173
    },
    {
      "epoch": 0.09775638488211916,
      "grad_norm": 0.2913684546947479,
      "learning_rate": 9.02243615117881e-06,
      "loss": 0.1654,
      "step": 6174
    },
    {
      "epoch": 0.09777221843976124,
      "grad_norm": 0.015159811824560165,
      "learning_rate": 9.022277815602387e-06,
      "loss": 0.0003,
      "step": 6175
    },
    {
      "epoch": 0.0977880519974033,
      "grad_norm": 0.4270031750202179,
      "learning_rate": 9.022119480025968e-06,
      "loss": 0.3895,
      "step": 6176
    },
    {
      "epoch": 0.09780388555504536,
      "grad_norm": 0.17611537873744965,
      "learning_rate": 9.021961144449547e-06,
      "loss": 0.1108,
      "step": 6177
    },
    {
      "epoch": 0.09781971911268743,
      "grad_norm": 0.27907493710517883,
      "learning_rate": 9.021802808873126e-06,
      "loss": 0.2065,
      "step": 6178
    },
    {
      "epoch": 0.09783555267032949,
      "grad_norm": 0.00017530241166241467,
      "learning_rate": 9.021644473296705e-06,
      "loss": 0.0,
      "step": 6179
    },
    {
      "epoch": 0.09785138622797156,
      "grad_norm": 0.2595332860946655,
      "learning_rate": 9.021486137720286e-06,
      "loss": 0.1953,
      "step": 6180
    },
    {
      "epoch": 0.09786721978561363,
      "grad_norm": 0.4622271955013275,
      "learning_rate": 9.021327802143864e-06,
      "loss": 0.2479,
      "step": 6181
    },
    {
      "epoch": 0.0978830533432557,
      "grad_norm": 0.03988829627633095,
      "learning_rate": 9.021169466567444e-06,
      "loss": 0.0072,
      "step": 6182
    },
    {
      "epoch": 0.09789888690089776,
      "grad_norm": 0.020509835332632065,
      "learning_rate": 9.021011130991024e-06,
      "loss": 0.0012,
      "step": 6183
    },
    {
      "epoch": 0.09791472045853983,
      "grad_norm": 0.5985223650932312,
      "learning_rate": 9.020852795414603e-06,
      "loss": 0.1194,
      "step": 6184
    },
    {
      "epoch": 0.09793055401618189,
      "grad_norm": 0.1288127899169922,
      "learning_rate": 9.020694459838182e-06,
      "loss": 0.0165,
      "step": 6185
    },
    {
      "epoch": 0.09794638757382396,
      "grad_norm": 0.2542615234851837,
      "learning_rate": 9.02053612426176e-06,
      "loss": 0.4037,
      "step": 6186
    },
    {
      "epoch": 0.09796222113146603,
      "grad_norm": 0.33186209201812744,
      "learning_rate": 9.02037778868534e-06,
      "loss": 0.1493,
      "step": 6187
    },
    {
      "epoch": 0.0979780546891081,
      "grad_norm": 0.007142354268580675,
      "learning_rate": 9.020219453108919e-06,
      "loss": 0.0004,
      "step": 6188
    },
    {
      "epoch": 0.09799388824675016,
      "grad_norm": 0.3978719711303711,
      "learning_rate": 9.0200611175325e-06,
      "loss": 0.1838,
      "step": 6189
    },
    {
      "epoch": 0.09800972180439223,
      "grad_norm": 0.03878350555896759,
      "learning_rate": 9.019902781956079e-06,
      "loss": 0.0059,
      "step": 6190
    },
    {
      "epoch": 0.09802555536203429,
      "grad_norm": 0.4595044255256653,
      "learning_rate": 9.019744446379658e-06,
      "loss": 0.3494,
      "step": 6191
    },
    {
      "epoch": 0.09804138891967636,
      "grad_norm": 0.03551669046282768,
      "learning_rate": 9.019586110803237e-06,
      "loss": 0.0018,
      "step": 6192
    },
    {
      "epoch": 0.09805722247731843,
      "grad_norm": 0.4636828899383545,
      "learning_rate": 9.019427775226816e-06,
      "loss": 0.5197,
      "step": 6193
    },
    {
      "epoch": 0.0980730560349605,
      "grad_norm": 0.16134344041347504,
      "learning_rate": 9.019269439650395e-06,
      "loss": 0.0818,
      "step": 6194
    },
    {
      "epoch": 0.09808888959260256,
      "grad_norm": 0.12822939455509186,
      "learning_rate": 9.019111104073976e-06,
      "loss": 0.0517,
      "step": 6195
    },
    {
      "epoch": 0.09810472315024463,
      "grad_norm": 0.3658200204372406,
      "learning_rate": 9.018952768497555e-06,
      "loss": 0.3472,
      "step": 6196
    },
    {
      "epoch": 0.09812055670788669,
      "grad_norm": 0.0509086512029171,
      "learning_rate": 9.018794432921134e-06,
      "loss": 0.0023,
      "step": 6197
    },
    {
      "epoch": 0.09813639026552876,
      "grad_norm": 0.42936253547668457,
      "learning_rate": 9.018636097344713e-06,
      "loss": 0.1347,
      "step": 6198
    },
    {
      "epoch": 0.09815222382317083,
      "grad_norm": 0.021584339439868927,
      "learning_rate": 9.018477761768292e-06,
      "loss": 0.0012,
      "step": 6199
    },
    {
      "epoch": 0.0981680573808129,
      "grad_norm": 0.09984354674816132,
      "learning_rate": 9.018319426191871e-06,
      "loss": 0.0116,
      "step": 6200
    },
    {
      "epoch": 0.09818389093845496,
      "grad_norm": 0.4820712208747864,
      "learning_rate": 9.018161090615452e-06,
      "loss": 0.659,
      "step": 6201
    },
    {
      "epoch": 0.09819972449609703,
      "grad_norm": 0.00020658982975874096,
      "learning_rate": 9.018002755039031e-06,
      "loss": 0.0,
      "step": 6202
    },
    {
      "epoch": 0.09821555805373909,
      "grad_norm": 0.1434026062488556,
      "learning_rate": 9.01784441946261e-06,
      "loss": 0.0121,
      "step": 6203
    },
    {
      "epoch": 0.09823139161138116,
      "grad_norm": 0.04341677203774452,
      "learning_rate": 9.01768608388619e-06,
      "loss": 0.0029,
      "step": 6204
    },
    {
      "epoch": 0.09824722516902323,
      "grad_norm": 0.2861112654209137,
      "learning_rate": 9.017527748309768e-06,
      "loss": 0.1946,
      "step": 6205
    },
    {
      "epoch": 0.0982630587266653,
      "grad_norm": 0.2764476537704468,
      "learning_rate": 9.017369412733347e-06,
      "loss": 0.1766,
      "step": 6206
    },
    {
      "epoch": 0.09827889228430736,
      "grad_norm": 0.14332187175750732,
      "learning_rate": 9.017211077156928e-06,
      "loss": 0.0997,
      "step": 6207
    },
    {
      "epoch": 0.09829472584194943,
      "grad_norm": 0.09267512708902359,
      "learning_rate": 9.017052741580507e-06,
      "loss": 0.0028,
      "step": 6208
    },
    {
      "epoch": 0.09831055939959149,
      "grad_norm": 0.4948953092098236,
      "learning_rate": 9.016894406004085e-06,
      "loss": 0.1205,
      "step": 6209
    },
    {
      "epoch": 0.09832639295723355,
      "grad_norm": 0.323596715927124,
      "learning_rate": 9.016736070427665e-06,
      "loss": 0.27,
      "step": 6210
    },
    {
      "epoch": 0.09834222651487563,
      "grad_norm": 0.2570343315601349,
      "learning_rate": 9.016577734851245e-06,
      "loss": 0.0677,
      "step": 6211
    },
    {
      "epoch": 0.0983580600725177,
      "grad_norm": 0.07675467431545258,
      "learning_rate": 9.016419399274824e-06,
      "loss": 0.0113,
      "step": 6212
    },
    {
      "epoch": 0.09837389363015976,
      "grad_norm": 0.3162689507007599,
      "learning_rate": 9.016261063698403e-06,
      "loss": 0.1953,
      "step": 6213
    },
    {
      "epoch": 0.09838972718780183,
      "grad_norm": 0.29112547636032104,
      "learning_rate": 9.016102728121983e-06,
      "loss": 0.2,
      "step": 6214
    },
    {
      "epoch": 0.09840556074544389,
      "grad_norm": 0.29223623871803284,
      "learning_rate": 9.01594439254556e-06,
      "loss": 0.1616,
      "step": 6215
    },
    {
      "epoch": 0.09842139430308595,
      "grad_norm": 0.42483779788017273,
      "learning_rate": 9.015786056969142e-06,
      "loss": 0.1185,
      "step": 6216
    },
    {
      "epoch": 0.09843722786072803,
      "grad_norm": 0.19223995506763458,
      "learning_rate": 9.01562772139272e-06,
      "loss": 0.0906,
      "step": 6217
    },
    {
      "epoch": 0.0984530614183701,
      "grad_norm": 0.00035373939317651093,
      "learning_rate": 9.0154693858163e-06,
      "loss": 0.0,
      "step": 6218
    },
    {
      "epoch": 0.09846889497601216,
      "grad_norm": 0.3134836256504059,
      "learning_rate": 9.015311050239879e-06,
      "loss": 0.1524,
      "step": 6219
    },
    {
      "epoch": 0.09848472853365423,
      "grad_norm": 0.488122820854187,
      "learning_rate": 9.015152714663458e-06,
      "loss": 0.0431,
      "step": 6220
    },
    {
      "epoch": 0.09850056209129629,
      "grad_norm": 0.00047177993110381067,
      "learning_rate": 9.014994379087037e-06,
      "loss": 0.0,
      "step": 6221
    },
    {
      "epoch": 0.09851639564893835,
      "grad_norm": 0.07139195501804352,
      "learning_rate": 9.014836043510618e-06,
      "loss": 0.021,
      "step": 6222
    },
    {
      "epoch": 0.09853222920658043,
      "grad_norm": 0.03657263144850731,
      "learning_rate": 9.014677707934197e-06,
      "loss": 0.0024,
      "step": 6223
    },
    {
      "epoch": 0.0985480627642225,
      "grad_norm": 0.12181965261697769,
      "learning_rate": 9.014519372357776e-06,
      "loss": 0.0522,
      "step": 6224
    },
    {
      "epoch": 0.09856389632186456,
      "grad_norm": 0.2980692386627197,
      "learning_rate": 9.014361036781355e-06,
      "loss": 0.0628,
      "step": 6225
    },
    {
      "epoch": 0.09857972987950663,
      "grad_norm": 0.7464076280593872,
      "learning_rate": 9.014202701204934e-06,
      "loss": 0.1161,
      "step": 6226
    },
    {
      "epoch": 0.09859556343714869,
      "grad_norm": 0.6666051149368286,
      "learning_rate": 9.014044365628513e-06,
      "loss": 0.0916,
      "step": 6227
    },
    {
      "epoch": 0.09861139699479075,
      "grad_norm": 0.04010261595249176,
      "learning_rate": 9.013886030052094e-06,
      "loss": 0.001,
      "step": 6228
    },
    {
      "epoch": 0.09862723055243283,
      "grad_norm": 0.08317381888628006,
      "learning_rate": 9.013727694475673e-06,
      "loss": 0.005,
      "step": 6229
    },
    {
      "epoch": 0.0986430641100749,
      "grad_norm": 0.4276309013366699,
      "learning_rate": 9.013569358899252e-06,
      "loss": 0.2166,
      "step": 6230
    },
    {
      "epoch": 0.09865889766771696,
      "grad_norm": 0.3175608813762665,
      "learning_rate": 9.013411023322831e-06,
      "loss": 0.1429,
      "step": 6231
    },
    {
      "epoch": 0.09867473122535902,
      "grad_norm": 0.23395586013793945,
      "learning_rate": 9.01325268774641e-06,
      "loss": 0.2004,
      "step": 6232
    },
    {
      "epoch": 0.09869056478300109,
      "grad_norm": 0.40100806951522827,
      "learning_rate": 9.01309435216999e-06,
      "loss": 0.1706,
      "step": 6233
    },
    {
      "epoch": 0.09870639834064315,
      "grad_norm": 0.47796034812927246,
      "learning_rate": 9.012936016593568e-06,
      "loss": 0.6374,
      "step": 6234
    },
    {
      "epoch": 0.09872223189828523,
      "grad_norm": 0.09704726934432983,
      "learning_rate": 9.01277768101715e-06,
      "loss": 0.0024,
      "step": 6235
    },
    {
      "epoch": 0.0987380654559273,
      "grad_norm": 0.20846492052078247,
      "learning_rate": 9.012619345440727e-06,
      "loss": 0.1126,
      "step": 6236
    },
    {
      "epoch": 0.09875389901356936,
      "grad_norm": 0.2837198078632355,
      "learning_rate": 9.012461009864307e-06,
      "loss": 0.0763,
      "step": 6237
    },
    {
      "epoch": 0.09876973257121142,
      "grad_norm": 0.559339702129364,
      "learning_rate": 9.012302674287886e-06,
      "loss": 0.4519,
      "step": 6238
    },
    {
      "epoch": 0.09878556612885349,
      "grad_norm": 0.149931401014328,
      "learning_rate": 9.012144338711466e-06,
      "loss": 0.0056,
      "step": 6239
    },
    {
      "epoch": 0.09880139968649555,
      "grad_norm": 0.0005089720361866057,
      "learning_rate": 9.011986003135045e-06,
      "loss": 0.0,
      "step": 6240
    },
    {
      "epoch": 0.09881723324413763,
      "grad_norm": 0.25857263803482056,
      "learning_rate": 9.011827667558625e-06,
      "loss": 0.2107,
      "step": 6241
    },
    {
      "epoch": 0.0988330668017797,
      "grad_norm": 0.40199124813079834,
      "learning_rate": 9.011669331982203e-06,
      "loss": 0.4108,
      "step": 6242
    },
    {
      "epoch": 0.09884890035942176,
      "grad_norm": 0.012037589214742184,
      "learning_rate": 9.011510996405784e-06,
      "loss": 0.0007,
      "step": 6243
    },
    {
      "epoch": 0.09886473391706382,
      "grad_norm": 0.00022387283388525248,
      "learning_rate": 9.011352660829363e-06,
      "loss": 0.0,
      "step": 6244
    },
    {
      "epoch": 0.09888056747470589,
      "grad_norm": 0.32239678502082825,
      "learning_rate": 9.011194325252942e-06,
      "loss": 0.2081,
      "step": 6245
    },
    {
      "epoch": 0.09889640103234795,
      "grad_norm": 0.4114382863044739,
      "learning_rate": 9.01103598967652e-06,
      "loss": 0.201,
      "step": 6246
    },
    {
      "epoch": 0.09891223458999003,
      "grad_norm": 0.13573376834392548,
      "learning_rate": 9.010877654100102e-06,
      "loss": 0.0446,
      "step": 6247
    },
    {
      "epoch": 0.0989280681476321,
      "grad_norm": 0.014006957411766052,
      "learning_rate": 9.010719318523679e-06,
      "loss": 0.0005,
      "step": 6248
    },
    {
      "epoch": 0.09894390170527416,
      "grad_norm": 0.04777282103896141,
      "learning_rate": 9.01056098294726e-06,
      "loss": 0.0013,
      "step": 6249
    },
    {
      "epoch": 0.09895973526291622,
      "grad_norm": 0.20792099833488464,
      "learning_rate": 9.010402647370839e-06,
      "loss": 0.0973,
      "step": 6250
    },
    {
      "epoch": 0.09897556882055829,
      "grad_norm": 0.00032060215016826987,
      "learning_rate": 9.010244311794418e-06,
      "loss": 0.0,
      "step": 6251
    },
    {
      "epoch": 0.09899140237820035,
      "grad_norm": 0.3235965967178345,
      "learning_rate": 9.010085976217997e-06,
      "loss": 0.1072,
      "step": 6252
    },
    {
      "epoch": 0.09900723593584243,
      "grad_norm": 0.030355099588632584,
      "learning_rate": 9.009927640641578e-06,
      "loss": 0.0017,
      "step": 6253
    },
    {
      "epoch": 0.0990230694934845,
      "grad_norm": 0.022387409582734108,
      "learning_rate": 9.009769305065155e-06,
      "loss": 0.0002,
      "step": 6254
    },
    {
      "epoch": 0.09903890305112656,
      "grad_norm": 0.006870317738503218,
      "learning_rate": 9.009610969488736e-06,
      "loss": 0.0004,
      "step": 6255
    },
    {
      "epoch": 0.09905473660876862,
      "grad_norm": 0.38468149304389954,
      "learning_rate": 9.009452633912315e-06,
      "loss": 0.5136,
      "step": 6256
    },
    {
      "epoch": 0.09907057016641069,
      "grad_norm": 0.6393344402313232,
      "learning_rate": 9.009294298335894e-06,
      "loss": 0.8955,
      "step": 6257
    },
    {
      "epoch": 0.09908640372405275,
      "grad_norm": 0.024501213803887367,
      "learning_rate": 9.009135962759473e-06,
      "loss": 0.0013,
      "step": 6258
    },
    {
      "epoch": 0.09910223728169483,
      "grad_norm": 0.15300533175468445,
      "learning_rate": 9.008977627183052e-06,
      "loss": 0.0486,
      "step": 6259
    },
    {
      "epoch": 0.0991180708393369,
      "grad_norm": 0.586739182472229,
      "learning_rate": 9.008819291606631e-06,
      "loss": 0.0583,
      "step": 6260
    },
    {
      "epoch": 0.09913390439697896,
      "grad_norm": 0.28302785754203796,
      "learning_rate": 9.00866095603021e-06,
      "loss": 0.1946,
      "step": 6261
    },
    {
      "epoch": 0.09914973795462102,
      "grad_norm": 0.03969438374042511,
      "learning_rate": 9.008502620453791e-06,
      "loss": 0.0026,
      "step": 6262
    },
    {
      "epoch": 0.09916557151226309,
      "grad_norm": 0.32305577397346497,
      "learning_rate": 9.00834428487737e-06,
      "loss": 0.2183,
      "step": 6263
    },
    {
      "epoch": 0.09918140506990515,
      "grad_norm": 0.31357795000076294,
      "learning_rate": 9.00818594930095e-06,
      "loss": 0.7033,
      "step": 6264
    },
    {
      "epoch": 0.09919723862754723,
      "grad_norm": 0.16502702236175537,
      "learning_rate": 9.008027613724528e-06,
      "loss": 0.0495,
      "step": 6265
    },
    {
      "epoch": 0.0992130721851893,
      "grad_norm": 0.21978957951068878,
      "learning_rate": 9.007869278148107e-06,
      "loss": 0.0479,
      "step": 6266
    },
    {
      "epoch": 0.09922890574283136,
      "grad_norm": 0.1567992866039276,
      "learning_rate": 9.007710942571687e-06,
      "loss": 0.0681,
      "step": 6267
    },
    {
      "epoch": 0.09924473930047342,
      "grad_norm": 0.440727174282074,
      "learning_rate": 9.007552606995267e-06,
      "loss": 0.4562,
      "step": 6268
    },
    {
      "epoch": 0.09926057285811549,
      "grad_norm": 0.0028251803014427423,
      "learning_rate": 9.007394271418846e-06,
      "loss": 0.0001,
      "step": 6269
    },
    {
      "epoch": 0.09927640641575755,
      "grad_norm": 0.9315571784973145,
      "learning_rate": 9.007235935842425e-06,
      "loss": 0.7577,
      "step": 6270
    },
    {
      "epoch": 0.09929223997339963,
      "grad_norm": 0.0018692855956032872,
      "learning_rate": 9.007077600266005e-06,
      "loss": 0.0001,
      "step": 6271
    },
    {
      "epoch": 0.0993080735310417,
      "grad_norm": 0.25358378887176514,
      "learning_rate": 9.006919264689584e-06,
      "loss": 0.1206,
      "step": 6272
    },
    {
      "epoch": 0.09932390708868376,
      "grad_norm": 0.005466708447784185,
      "learning_rate": 9.006760929113163e-06,
      "loss": 0.0002,
      "step": 6273
    },
    {
      "epoch": 0.09933974064632582,
      "grad_norm": 0.42535266280174255,
      "learning_rate": 9.006602593536743e-06,
      "loss": 0.2759,
      "step": 6274
    },
    {
      "epoch": 0.09935557420396789,
      "grad_norm": 0.07958308607339859,
      "learning_rate": 9.006444257960323e-06,
      "loss": 0.0089,
      "step": 6275
    },
    {
      "epoch": 0.09937140776160995,
      "grad_norm": 0.15866316854953766,
      "learning_rate": 9.006285922383902e-06,
      "loss": 0.023,
      "step": 6276
    },
    {
      "epoch": 0.09938724131925203,
      "grad_norm": 0.03126838058233261,
      "learning_rate": 9.00612758680748e-06,
      "loss": 0.0019,
      "step": 6277
    },
    {
      "epoch": 0.09940307487689409,
      "grad_norm": 0.19535957276821136,
      "learning_rate": 9.00596925123106e-06,
      "loss": 0.0205,
      "step": 6278
    },
    {
      "epoch": 0.09941890843453616,
      "grad_norm": 0.4166700541973114,
      "learning_rate": 9.005810915654639e-06,
      "loss": 0.5471,
      "step": 6279
    },
    {
      "epoch": 0.09943474199217822,
      "grad_norm": 0.37771323323249817,
      "learning_rate": 9.005652580078218e-06,
      "loss": 0.8691,
      "step": 6280
    },
    {
      "epoch": 0.09945057554982029,
      "grad_norm": 0.4909697473049164,
      "learning_rate": 9.005494244501799e-06,
      "loss": 0.2439,
      "step": 6281
    },
    {
      "epoch": 0.09946640910746235,
      "grad_norm": 0.00020243703329470009,
      "learning_rate": 9.005335908925376e-06,
      "loss": 0.0,
      "step": 6282
    },
    {
      "epoch": 0.09948224266510443,
      "grad_norm": 0.047554343938827515,
      "learning_rate": 9.005177573348957e-06,
      "loss": 0.0028,
      "step": 6283
    },
    {
      "epoch": 0.09949807622274649,
      "grad_norm": 0.14206789433956146,
      "learning_rate": 9.005019237772536e-06,
      "loss": 0.0599,
      "step": 6284
    },
    {
      "epoch": 0.09951390978038856,
      "grad_norm": 0.03090360388159752,
      "learning_rate": 9.004860902196115e-06,
      "loss": 0.0023,
      "step": 6285
    },
    {
      "epoch": 0.09952974333803062,
      "grad_norm": 0.10049375891685486,
      "learning_rate": 9.004702566619694e-06,
      "loss": 0.0031,
      "step": 6286
    },
    {
      "epoch": 0.09954557689567269,
      "grad_norm": 0.374611496925354,
      "learning_rate": 9.004544231043273e-06,
      "loss": 0.1362,
      "step": 6287
    },
    {
      "epoch": 0.09956141045331475,
      "grad_norm": 0.3071529269218445,
      "learning_rate": 9.004385895466852e-06,
      "loss": 0.0809,
      "step": 6288
    },
    {
      "epoch": 0.09957724401095683,
      "grad_norm": 0.06417806446552277,
      "learning_rate": 9.004227559890433e-06,
      "loss": 0.0017,
      "step": 6289
    },
    {
      "epoch": 0.09959307756859889,
      "grad_norm": 0.2060805708169937,
      "learning_rate": 9.004069224314012e-06,
      "loss": 0.0681,
      "step": 6290
    },
    {
      "epoch": 0.09960891112624096,
      "grad_norm": 0.00010280551941832528,
      "learning_rate": 9.003910888737591e-06,
      "loss": 0.0,
      "step": 6291
    },
    {
      "epoch": 0.09962474468388302,
      "grad_norm": 0.26185089349746704,
      "learning_rate": 9.00375255316117e-06,
      "loss": 0.0977,
      "step": 6292
    },
    {
      "epoch": 0.09964057824152509,
      "grad_norm": 1.1867433786392212,
      "learning_rate": 9.00359421758475e-06,
      "loss": 0.3132,
      "step": 6293
    },
    {
      "epoch": 0.09965641179916715,
      "grad_norm": 0.005500170402228832,
      "learning_rate": 9.003435882008328e-06,
      "loss": 0.0001,
      "step": 6294
    },
    {
      "epoch": 0.09967224535680923,
      "grad_norm": 0.098712258040905,
      "learning_rate": 9.00327754643191e-06,
      "loss": 0.0029,
      "step": 6295
    },
    {
      "epoch": 0.09968807891445129,
      "grad_norm": 0.3664725124835968,
      "learning_rate": 9.003119210855488e-06,
      "loss": 0.1109,
      "step": 6296
    },
    {
      "epoch": 0.09970391247209336,
      "grad_norm": 0.3684976100921631,
      "learning_rate": 9.002960875279067e-06,
      "loss": 0.1176,
      "step": 6297
    },
    {
      "epoch": 0.09971974602973542,
      "grad_norm": 0.19000118970870972,
      "learning_rate": 9.002802539702646e-06,
      "loss": 0.0148,
      "step": 6298
    },
    {
      "epoch": 0.09973557958737748,
      "grad_norm": 0.11843173950910568,
      "learning_rate": 9.002644204126226e-06,
      "loss": 0.0445,
      "step": 6299
    },
    {
      "epoch": 0.09975141314501955,
      "grad_norm": 0.5868614315986633,
      "learning_rate": 9.002485868549805e-06,
      "loss": 0.4545,
      "step": 6300
    },
    {
      "epoch": 0.09976724670266163,
      "grad_norm": 0.3918284773826599,
      "learning_rate": 9.002327532973385e-06,
      "loss": 0.1989,
      "step": 6301
    },
    {
      "epoch": 0.09978308026030369,
      "grad_norm": 0.330161452293396,
      "learning_rate": 9.002169197396964e-06,
      "loss": 0.0347,
      "step": 6302
    },
    {
      "epoch": 0.09979891381794576,
      "grad_norm": 0.00036846910370513797,
      "learning_rate": 9.002010861820544e-06,
      "loss": 0.0,
      "step": 6303
    },
    {
      "epoch": 0.09981474737558782,
      "grad_norm": 9.345080616185442e-05,
      "learning_rate": 9.001852526244123e-06,
      "loss": 0.0,
      "step": 6304
    },
    {
      "epoch": 0.09983058093322988,
      "grad_norm": 0.22438538074493408,
      "learning_rate": 9.001694190667702e-06,
      "loss": 0.0953,
      "step": 6305
    },
    {
      "epoch": 0.09984641449087195,
      "grad_norm": 0.4223189651966095,
      "learning_rate": 9.00153585509128e-06,
      "loss": 0.015,
      "step": 6306
    },
    {
      "epoch": 0.09986224804851403,
      "grad_norm": 0.18774354457855225,
      "learning_rate": 9.00137751951486e-06,
      "loss": 0.123,
      "step": 6307
    },
    {
      "epoch": 0.09987808160615609,
      "grad_norm": 0.5281735062599182,
      "learning_rate": 9.00121918393844e-06,
      "loss": 0.208,
      "step": 6308
    },
    {
      "epoch": 0.09989391516379816,
      "grad_norm": 0.2429928481578827,
      "learning_rate": 9.001060848362018e-06,
      "loss": 0.0817,
      "step": 6309
    },
    {
      "epoch": 0.09990974872144022,
      "grad_norm": 0.023411711677908897,
      "learning_rate": 9.000902512785599e-06,
      "loss": 0.0011,
      "step": 6310
    },
    {
      "epoch": 0.09992558227908228,
      "grad_norm": 0.4774479568004608,
      "learning_rate": 9.000744177209178e-06,
      "loss": 0.1608,
      "step": 6311
    },
    {
      "epoch": 0.09994141583672435,
      "grad_norm": 0.31440436840057373,
      "learning_rate": 9.000585841632757e-06,
      "loss": 0.1023,
      "step": 6312
    },
    {
      "epoch": 0.09995724939436643,
      "grad_norm": 0.49939247965812683,
      "learning_rate": 9.000427506056336e-06,
      "loss": 0.1085,
      "step": 6313
    },
    {
      "epoch": 0.09997308295200849,
      "grad_norm": 0.6186599731445312,
      "learning_rate": 9.000269170479917e-06,
      "loss": 0.2609,
      "step": 6314
    },
    {
      "epoch": 0.09998891650965055,
      "grad_norm": 0.20435208082199097,
      "learning_rate": 9.000110834903494e-06,
      "loss": 0.0495,
      "step": 6315
    },
    {
      "epoch": 0.10000475006729262,
      "grad_norm": 0.41094887256622314,
      "learning_rate": 8.999952499327075e-06,
      "loss": 0.5588,
      "step": 6316
    },
    {
      "epoch": 0.10002058362493468,
      "grad_norm": 0.34636199474334717,
      "learning_rate": 8.999794163750654e-06,
      "loss": 0.2009,
      "step": 6317
    },
    {
      "epoch": 0.10003641718257675,
      "grad_norm": 0.0001293108653044328,
      "learning_rate": 8.999635828174233e-06,
      "loss": 0.0,
      "step": 6318
    },
    {
      "epoch": 0.10005225074021883,
      "grad_norm": 0.39854857325553894,
      "learning_rate": 8.999477492597812e-06,
      "loss": 0.6756,
      "step": 6319
    },
    {
      "epoch": 0.10006808429786089,
      "grad_norm": 0.008980026468634605,
      "learning_rate": 8.999319157021393e-06,
      "loss": 0.0005,
      "step": 6320
    },
    {
      "epoch": 0.10008391785550295,
      "grad_norm": 0.33142781257629395,
      "learning_rate": 8.99916082144497e-06,
      "loss": 0.2285,
      "step": 6321
    },
    {
      "epoch": 0.10009975141314502,
      "grad_norm": 0.0005427182768471539,
      "learning_rate": 8.999002485868551e-06,
      "loss": 0.0,
      "step": 6322
    },
    {
      "epoch": 0.10011558497078708,
      "grad_norm": 0.2964540421962738,
      "learning_rate": 8.99884415029213e-06,
      "loss": 0.0485,
      "step": 6323
    },
    {
      "epoch": 0.10013141852842915,
      "grad_norm": 0.0002295336889801547,
      "learning_rate": 8.99868581471571e-06,
      "loss": 0.0,
      "step": 6324
    },
    {
      "epoch": 0.10014725208607123,
      "grad_norm": 0.8250855803489685,
      "learning_rate": 8.998527479139288e-06,
      "loss": 0.1992,
      "step": 6325
    },
    {
      "epoch": 0.10016308564371329,
      "grad_norm": 0.009594212286174297,
      "learning_rate": 8.998369143562869e-06,
      "loss": 0.0005,
      "step": 6326
    },
    {
      "epoch": 0.10017891920135535,
      "grad_norm": 0.43106818199157715,
      "learning_rate": 8.998210807986447e-06,
      "loss": 0.1306,
      "step": 6327
    },
    {
      "epoch": 0.10019475275899742,
      "grad_norm": 0.2863118648529053,
      "learning_rate": 8.998052472410026e-06,
      "loss": 0.0375,
      "step": 6328
    },
    {
      "epoch": 0.10021058631663948,
      "grad_norm": 0.0644250214099884,
      "learning_rate": 8.997894136833606e-06,
      "loss": 0.0027,
      "step": 6329
    },
    {
      "epoch": 0.10022641987428155,
      "grad_norm": 0.17259974777698517,
      "learning_rate": 8.997735801257185e-06,
      "loss": 0.0693,
      "step": 6330
    },
    {
      "epoch": 0.10024225343192363,
      "grad_norm": 0.4878336191177368,
      "learning_rate": 8.997577465680765e-06,
      "loss": 0.2432,
      "step": 6331
    },
    {
      "epoch": 0.10025808698956569,
      "grad_norm": 0.2988819479942322,
      "learning_rate": 8.997419130104344e-06,
      "loss": 0.0494,
      "step": 6332
    },
    {
      "epoch": 0.10027392054720775,
      "grad_norm": 0.014112292788922787,
      "learning_rate": 8.997260794527923e-06,
      "loss": 0.0006,
      "step": 6333
    },
    {
      "epoch": 0.10028975410484982,
      "grad_norm": 0.40428072214126587,
      "learning_rate": 8.997102458951502e-06,
      "loss": 0.2505,
      "step": 6334
    },
    {
      "epoch": 0.10030558766249188,
      "grad_norm": 0.11852753907442093,
      "learning_rate": 8.996944123375083e-06,
      "loss": 0.0452,
      "step": 6335
    },
    {
      "epoch": 0.10032142122013395,
      "grad_norm": 0.32573753595352173,
      "learning_rate": 8.996785787798662e-06,
      "loss": 0.1238,
      "step": 6336
    },
    {
      "epoch": 0.10033725477777602,
      "grad_norm": 0.4746648967266083,
      "learning_rate": 8.99662745222224e-06,
      "loss": 0.328,
      "step": 6337
    },
    {
      "epoch": 0.10035308833541809,
      "grad_norm": 0.2573259174823761,
      "learning_rate": 8.99646911664582e-06,
      "loss": 0.1108,
      "step": 6338
    },
    {
      "epoch": 0.10036892189306015,
      "grad_norm": 0.0014538399409502745,
      "learning_rate": 8.996310781069399e-06,
      "loss": 0.0,
      "step": 6339
    },
    {
      "epoch": 0.10038475545070222,
      "grad_norm": 0.21616323292255402,
      "learning_rate": 8.996152445492978e-06,
      "loss": 0.0982,
      "step": 6340
    },
    {
      "epoch": 0.10040058900834428,
      "grad_norm": 0.3766420781612396,
      "learning_rate": 8.995994109916559e-06,
      "loss": 0.4886,
      "step": 6341
    },
    {
      "epoch": 0.10041642256598635,
      "grad_norm": 0.2769160270690918,
      "learning_rate": 8.995835774340138e-06,
      "loss": 0.1182,
      "step": 6342
    },
    {
      "epoch": 0.10043225612362842,
      "grad_norm": 0.40976035594940186,
      "learning_rate": 8.995677438763717e-06,
      "loss": 0.2499,
      "step": 6343
    },
    {
      "epoch": 0.10044808968127049,
      "grad_norm": 0.4780957102775574,
      "learning_rate": 8.995519103187296e-06,
      "loss": 0.4852,
      "step": 6344
    },
    {
      "epoch": 0.10046392323891255,
      "grad_norm": 0.05042428895831108,
      "learning_rate": 8.995360767610875e-06,
      "loss": 0.0033,
      "step": 6345
    },
    {
      "epoch": 0.10047975679655462,
      "grad_norm": 0.1555670201778412,
      "learning_rate": 8.995202432034454e-06,
      "loss": 0.0495,
      "step": 6346
    },
    {
      "epoch": 0.10049559035419668,
      "grad_norm": 0.23220957815647125,
      "learning_rate": 8.995044096458035e-06,
      "loss": 0.2384,
      "step": 6347
    },
    {
      "epoch": 0.10051142391183875,
      "grad_norm": 0.4172797203063965,
      "learning_rate": 8.994885760881614e-06,
      "loss": 0.0564,
      "step": 6348
    },
    {
      "epoch": 0.10052725746948082,
      "grad_norm": 0.29012274742126465,
      "learning_rate": 8.994727425305193e-06,
      "loss": 0.0405,
      "step": 6349
    },
    {
      "epoch": 0.10054309102712289,
      "grad_norm": 0.3856595754623413,
      "learning_rate": 8.994569089728772e-06,
      "loss": 0.2543,
      "step": 6350
    },
    {
      "epoch": 0.10055892458476495,
      "grad_norm": 0.035267848521471024,
      "learning_rate": 8.994410754152351e-06,
      "loss": 0.0004,
      "step": 6351
    },
    {
      "epoch": 0.10057475814240702,
      "grad_norm": 0.31277596950531006,
      "learning_rate": 8.99425241857593e-06,
      "loss": 0.2507,
      "step": 6352
    },
    {
      "epoch": 0.10059059170004908,
      "grad_norm": 0.21454063057899475,
      "learning_rate": 8.99409408299951e-06,
      "loss": 0.0883,
      "step": 6353
    },
    {
      "epoch": 0.10060642525769115,
      "grad_norm": 0.10580253601074219,
      "learning_rate": 8.993935747423088e-06,
      "loss": 0.0039,
      "step": 6354
    },
    {
      "epoch": 0.10062225881533322,
      "grad_norm": 0.22230865061283112,
      "learning_rate": 8.993777411846668e-06,
      "loss": 0.0931,
      "step": 6355
    },
    {
      "epoch": 0.10063809237297529,
      "grad_norm": 0.2375379204750061,
      "learning_rate": 8.993619076270248e-06,
      "loss": 0.113,
      "step": 6356
    },
    {
      "epoch": 0.10065392593061735,
      "grad_norm": 6.81304227327928e-05,
      "learning_rate": 8.993460740693827e-06,
      "loss": 0.0,
      "step": 6357
    },
    {
      "epoch": 0.10066975948825942,
      "grad_norm": 0.5471953749656677,
      "learning_rate": 8.993302405117406e-06,
      "loss": 0.4028,
      "step": 6358
    },
    {
      "epoch": 0.10068559304590148,
      "grad_norm": 0.8411252498626709,
      "learning_rate": 8.993144069540986e-06,
      "loss": 0.3926,
      "step": 6359
    },
    {
      "epoch": 0.10070142660354355,
      "grad_norm": 0.4237256944179535,
      "learning_rate": 8.992985733964565e-06,
      "loss": 0.1664,
      "step": 6360
    },
    {
      "epoch": 0.10071726016118562,
      "grad_norm": 0.22277016937732697,
      "learning_rate": 8.992827398388144e-06,
      "loss": 0.0194,
      "step": 6361
    },
    {
      "epoch": 0.10073309371882769,
      "grad_norm": 0.31572073698043823,
      "learning_rate": 8.992669062811724e-06,
      "loss": 0.0591,
      "step": 6362
    },
    {
      "epoch": 0.10074892727646975,
      "grad_norm": 0.5739403367042542,
      "learning_rate": 8.992510727235304e-06,
      "loss": 0.4691,
      "step": 6363
    },
    {
      "epoch": 0.10076476083411182,
      "grad_norm": 0.3049217164516449,
      "learning_rate": 8.992352391658883e-06,
      "loss": 0.1671,
      "step": 6364
    },
    {
      "epoch": 0.10078059439175388,
      "grad_norm": 0.21554483473300934,
      "learning_rate": 8.992194056082462e-06,
      "loss": 0.0187,
      "step": 6365
    },
    {
      "epoch": 0.10079642794939594,
      "grad_norm": 0.3743615746498108,
      "learning_rate": 8.99203572050604e-06,
      "loss": 0.1398,
      "step": 6366
    },
    {
      "epoch": 0.10081226150703802,
      "grad_norm": 0.21106676757335663,
      "learning_rate": 8.99187738492962e-06,
      "loss": 0.1536,
      "step": 6367
    },
    {
      "epoch": 0.10082809506468009,
      "grad_norm": 0.20352232456207275,
      "learning_rate": 8.9917190493532e-06,
      "loss": 0.0621,
      "step": 6368
    },
    {
      "epoch": 0.10084392862232215,
      "grad_norm": 0.0001419488398823887,
      "learning_rate": 8.99156071377678e-06,
      "loss": 0.0,
      "step": 6369
    },
    {
      "epoch": 0.10085976217996422,
      "grad_norm": 0.2989419102668762,
      "learning_rate": 8.991402378200359e-06,
      "loss": 0.1081,
      "step": 6370
    },
    {
      "epoch": 0.10087559573760628,
      "grad_norm": 0.4188919961452484,
      "learning_rate": 8.991244042623938e-06,
      "loss": 0.6431,
      "step": 6371
    },
    {
      "epoch": 0.10089142929524834,
      "grad_norm": 0.6045914888381958,
      "learning_rate": 8.991085707047517e-06,
      "loss": 0.146,
      "step": 6372
    },
    {
      "epoch": 0.10090726285289042,
      "grad_norm": 0.11584386974573135,
      "learning_rate": 8.990927371471096e-06,
      "loss": 0.0361,
      "step": 6373
    },
    {
      "epoch": 0.10092309641053249,
      "grad_norm": 0.4451870918273926,
      "learning_rate": 8.990769035894677e-06,
      "loss": 0.1673,
      "step": 6374
    },
    {
      "epoch": 0.10093892996817455,
      "grad_norm": 0.2920602560043335,
      "learning_rate": 8.990610700318256e-06,
      "loss": 0.2132,
      "step": 6375
    },
    {
      "epoch": 0.10095476352581662,
      "grad_norm": 0.13556163012981415,
      "learning_rate": 8.990452364741833e-06,
      "loss": 0.0344,
      "step": 6376
    },
    {
      "epoch": 0.10097059708345868,
      "grad_norm": 0.28720858693122864,
      "learning_rate": 8.990294029165414e-06,
      "loss": 0.0542,
      "step": 6377
    },
    {
      "epoch": 0.10098643064110074,
      "grad_norm": 0.2835906445980072,
      "learning_rate": 8.990135693588993e-06,
      "loss": 0.2339,
      "step": 6378
    },
    {
      "epoch": 0.10100226419874282,
      "grad_norm": 0.009014012292027473,
      "learning_rate": 8.989977358012572e-06,
      "loss": 0.0004,
      "step": 6379
    },
    {
      "epoch": 0.10101809775638489,
      "grad_norm": 0.17043255269527435,
      "learning_rate": 8.989819022436151e-06,
      "loss": 0.06,
      "step": 6380
    },
    {
      "epoch": 0.10103393131402695,
      "grad_norm": 0.0001868520921561867,
      "learning_rate": 8.989660686859732e-06,
      "loss": 0.0,
      "step": 6381
    },
    {
      "epoch": 0.10104976487166901,
      "grad_norm": 0.00013112369924783707,
      "learning_rate": 8.98950235128331e-06,
      "loss": 0.0,
      "step": 6382
    },
    {
      "epoch": 0.10106559842931108,
      "grad_norm": 0.2245793640613556,
      "learning_rate": 8.98934401570689e-06,
      "loss": 0.0776,
      "step": 6383
    },
    {
      "epoch": 0.10108143198695314,
      "grad_norm": 0.12787586450576782,
      "learning_rate": 8.98918568013047e-06,
      "loss": 0.0037,
      "step": 6384
    },
    {
      "epoch": 0.10109726554459522,
      "grad_norm": 0.37486082315444946,
      "learning_rate": 8.989027344554048e-06,
      "loss": 0.2364,
      "step": 6385
    },
    {
      "epoch": 0.10111309910223729,
      "grad_norm": 0.37010419368743896,
      "learning_rate": 8.988869008977627e-06,
      "loss": 0.7553,
      "step": 6386
    },
    {
      "epoch": 0.10112893265987935,
      "grad_norm": 0.40965086221694946,
      "learning_rate": 8.988710673401208e-06,
      "loss": 0.0259,
      "step": 6387
    },
    {
      "epoch": 0.10114476621752141,
      "grad_norm": 0.39785462617874146,
      "learning_rate": 8.988552337824786e-06,
      "loss": 0.2489,
      "step": 6388
    },
    {
      "epoch": 0.10116059977516348,
      "grad_norm": 0.011137129738926888,
      "learning_rate": 8.988394002248366e-06,
      "loss": 0.0006,
      "step": 6389
    },
    {
      "epoch": 0.10117643333280554,
      "grad_norm": 0.21717111766338348,
      "learning_rate": 8.988235666671945e-06,
      "loss": 0.104,
      "step": 6390
    },
    {
      "epoch": 0.10119226689044762,
      "grad_norm": 0.16580034792423248,
      "learning_rate": 8.988077331095525e-06,
      "loss": 0.0426,
      "step": 6391
    },
    {
      "epoch": 0.10120810044808969,
      "grad_norm": 0.00013527440023608506,
      "learning_rate": 8.987918995519104e-06,
      "loss": 0.0,
      "step": 6392
    },
    {
      "epoch": 0.10122393400573175,
      "grad_norm": 0.14728543162345886,
      "learning_rate": 8.987760659942684e-06,
      "loss": 0.0673,
      "step": 6393
    },
    {
      "epoch": 0.10123976756337381,
      "grad_norm": 0.013100695796310902,
      "learning_rate": 8.987602324366262e-06,
      "loss": 0.0008,
      "step": 6394
    },
    {
      "epoch": 0.10125560112101588,
      "grad_norm": 0.1285059005022049,
      "learning_rate": 8.987443988789843e-06,
      "loss": 0.0421,
      "step": 6395
    },
    {
      "epoch": 0.10127143467865794,
      "grad_norm": 5.2915213018422946e-05,
      "learning_rate": 8.987285653213422e-06,
      "loss": 0.0,
      "step": 6396
    },
    {
      "epoch": 0.10128726823630002,
      "grad_norm": 0.1537879854440689,
      "learning_rate": 8.987127317637e-06,
      "loss": 0.0602,
      "step": 6397
    },
    {
      "epoch": 0.10130310179394209,
      "grad_norm": 0.05571677163243294,
      "learning_rate": 8.98696898206058e-06,
      "loss": 0.0016,
      "step": 6398
    },
    {
      "epoch": 0.10131893535158415,
      "grad_norm": 0.3580660820007324,
      "learning_rate": 8.98681064648416e-06,
      "loss": 0.0555,
      "step": 6399
    },
    {
      "epoch": 0.10133476890922621,
      "grad_norm": 0.5432137846946716,
      "learning_rate": 8.986652310907738e-06,
      "loss": 0.2127,
      "step": 6400
    },
    {
      "epoch": 0.10135060246686828,
      "grad_norm": 0.10783028602600098,
      "learning_rate": 8.986493975331317e-06,
      "loss": 0.0036,
      "step": 6401
    },
    {
      "epoch": 0.10136643602451034,
      "grad_norm": 0.29677829146385193,
      "learning_rate": 8.986335639754898e-06,
      "loss": 0.0683,
      "step": 6402
    },
    {
      "epoch": 0.10138226958215242,
      "grad_norm": 0.19651702046394348,
      "learning_rate": 8.986177304178477e-06,
      "loss": 0.1135,
      "step": 6403
    },
    {
      "epoch": 0.10139810313979448,
      "grad_norm": 0.050035469233989716,
      "learning_rate": 8.986018968602056e-06,
      "loss": 0.0036,
      "step": 6404
    },
    {
      "epoch": 0.10141393669743655,
      "grad_norm": 0.5079336762428284,
      "learning_rate": 8.985860633025635e-06,
      "loss": 0.3048,
      "step": 6405
    },
    {
      "epoch": 0.10142977025507861,
      "grad_norm": 0.2912117540836334,
      "learning_rate": 8.985702297449214e-06,
      "loss": 0.5688,
      "step": 6406
    },
    {
      "epoch": 0.10144560381272068,
      "grad_norm": 0.211408331990242,
      "learning_rate": 8.985543961872793e-06,
      "loss": 0.0465,
      "step": 6407
    },
    {
      "epoch": 0.10146143737036274,
      "grad_norm": 0.01455654576420784,
      "learning_rate": 8.985385626296374e-06,
      "loss": 0.0007,
      "step": 6408
    },
    {
      "epoch": 0.10147727092800482,
      "grad_norm": 0.049271274358034134,
      "learning_rate": 8.985227290719953e-06,
      "loss": 0.0035,
      "step": 6409
    },
    {
      "epoch": 0.10149310448564688,
      "grad_norm": 0.1430036425590515,
      "learning_rate": 8.985068955143532e-06,
      "loss": 0.0901,
      "step": 6410
    },
    {
      "epoch": 0.10150893804328895,
      "grad_norm": 0.48783984780311584,
      "learning_rate": 8.984910619567111e-06,
      "loss": 0.3064,
      "step": 6411
    },
    {
      "epoch": 0.10152477160093101,
      "grad_norm": 0.015154673717916012,
      "learning_rate": 8.98475228399069e-06,
      "loss": 0.0011,
      "step": 6412
    },
    {
      "epoch": 0.10154060515857308,
      "grad_norm": 0.0001769865775713697,
      "learning_rate": 8.98459394841427e-06,
      "loss": 0.0,
      "step": 6413
    },
    {
      "epoch": 0.10155643871621514,
      "grad_norm": 0.5451224446296692,
      "learning_rate": 8.98443561283785e-06,
      "loss": 0.8738,
      "step": 6414
    },
    {
      "epoch": 0.10157227227385722,
      "grad_norm": 0.02088531106710434,
      "learning_rate": 8.984277277261428e-06,
      "loss": 0.0012,
      "step": 6415
    },
    {
      "epoch": 0.10158810583149928,
      "grad_norm": 0.011303707957267761,
      "learning_rate": 8.984118941685008e-06,
      "loss": 0.0006,
      "step": 6416
    },
    {
      "epoch": 0.10160393938914135,
      "grad_norm": 0.21325574815273285,
      "learning_rate": 8.983960606108587e-06,
      "loss": 0.0751,
      "step": 6417
    },
    {
      "epoch": 0.10161977294678341,
      "grad_norm": 0.04522085189819336,
      "learning_rate": 8.983802270532166e-06,
      "loss": 0.0038,
      "step": 6418
    },
    {
      "epoch": 0.10163560650442548,
      "grad_norm": 0.007567246910184622,
      "learning_rate": 8.983643934955746e-06,
      "loss": 0.0004,
      "step": 6419
    },
    {
      "epoch": 0.10165144006206754,
      "grad_norm": 0.20896802842617035,
      "learning_rate": 8.983485599379326e-06,
      "loss": 0.0375,
      "step": 6420
    },
    {
      "epoch": 0.10166727361970962,
      "grad_norm": 0.0002325672103324905,
      "learning_rate": 8.983327263802904e-06,
      "loss": 0.0,
      "step": 6421
    },
    {
      "epoch": 0.10168310717735168,
      "grad_norm": 0.5533760786056519,
      "learning_rate": 8.983168928226485e-06,
      "loss": 0.7961,
      "step": 6422
    },
    {
      "epoch": 0.10169894073499375,
      "grad_norm": 0.6479066014289856,
      "learning_rate": 8.983010592650064e-06,
      "loss": 0.0681,
      "step": 6423
    },
    {
      "epoch": 0.10171477429263581,
      "grad_norm": 0.010274344123899937,
      "learning_rate": 8.982852257073643e-06,
      "loss": 0.0006,
      "step": 6424
    },
    {
      "epoch": 0.10173060785027788,
      "grad_norm": 0.28799089789390564,
      "learning_rate": 8.982693921497222e-06,
      "loss": 0.1001,
      "step": 6425
    },
    {
      "epoch": 0.10174644140791994,
      "grad_norm": 0.09593598544597626,
      "learning_rate": 8.9825355859208e-06,
      "loss": 0.0284,
      "step": 6426
    },
    {
      "epoch": 0.10176227496556202,
      "grad_norm": 0.7715091705322266,
      "learning_rate": 8.98237725034438e-06,
      "loss": 0.0977,
      "step": 6427
    },
    {
      "epoch": 0.10177810852320408,
      "grad_norm": 0.0007153907208703458,
      "learning_rate": 8.982218914767959e-06,
      "loss": 0.0,
      "step": 6428
    },
    {
      "epoch": 0.10179394208084615,
      "grad_norm": 0.024669930338859558,
      "learning_rate": 8.98206057919154e-06,
      "loss": 0.0013,
      "step": 6429
    },
    {
      "epoch": 0.10180977563848821,
      "grad_norm": 0.0008444731356576085,
      "learning_rate": 8.981902243615119e-06,
      "loss": 0.0,
      "step": 6430
    },
    {
      "epoch": 0.10182560919613028,
      "grad_norm": 0.25391241908073425,
      "learning_rate": 8.981743908038698e-06,
      "loss": 0.1564,
      "step": 6431
    },
    {
      "epoch": 0.10184144275377234,
      "grad_norm": 0.5415154695510864,
      "learning_rate": 8.981585572462277e-06,
      "loss": 0.0749,
      "step": 6432
    },
    {
      "epoch": 0.10185727631141442,
      "grad_norm": 0.46506527066230774,
      "learning_rate": 8.981427236885856e-06,
      "loss": 0.1595,
      "step": 6433
    },
    {
      "epoch": 0.10187310986905648,
      "grad_norm": 0.04038665443658829,
      "learning_rate": 8.981268901309435e-06,
      "loss": 0.0022,
      "step": 6434
    },
    {
      "epoch": 0.10188894342669855,
      "grad_norm": 0.2928345799446106,
      "learning_rate": 8.981110565733016e-06,
      "loss": 0.1296,
      "step": 6435
    },
    {
      "epoch": 0.10190477698434061,
      "grad_norm": 0.36226198077201843,
      "learning_rate": 8.980952230156595e-06,
      "loss": 0.1723,
      "step": 6436
    },
    {
      "epoch": 0.10192061054198268,
      "grad_norm": 0.27508774399757385,
      "learning_rate": 8.980793894580174e-06,
      "loss": 0.106,
      "step": 6437
    },
    {
      "epoch": 0.10193644409962474,
      "grad_norm": 0.02220979705452919,
      "learning_rate": 8.980635559003753e-06,
      "loss": 0.0012,
      "step": 6438
    },
    {
      "epoch": 0.1019522776572668,
      "grad_norm": 0.3434184789657593,
      "learning_rate": 8.980477223427332e-06,
      "loss": 0.1765,
      "step": 6439
    },
    {
      "epoch": 0.10196811121490888,
      "grad_norm": 0.2956083118915558,
      "learning_rate": 8.980318887850911e-06,
      "loss": 0.0962,
      "step": 6440
    },
    {
      "epoch": 0.10198394477255095,
      "grad_norm": 0.02937469072639942,
      "learning_rate": 8.980160552274492e-06,
      "loss": 0.002,
      "step": 6441
    },
    {
      "epoch": 0.10199977833019301,
      "grad_norm": 0.23286569118499756,
      "learning_rate": 8.980002216698071e-06,
      "loss": 0.1117,
      "step": 6442
    },
    {
      "epoch": 0.10201561188783508,
      "grad_norm": 0.006102383136749268,
      "learning_rate": 8.97984388112165e-06,
      "loss": 0.0002,
      "step": 6443
    },
    {
      "epoch": 0.10203144544547714,
      "grad_norm": 0.3301890194416046,
      "learning_rate": 8.97968554554523e-06,
      "loss": 0.2634,
      "step": 6444
    },
    {
      "epoch": 0.1020472790031192,
      "grad_norm": 0.14143531024456024,
      "learning_rate": 8.979527209968808e-06,
      "loss": 0.0722,
      "step": 6445
    },
    {
      "epoch": 0.10206311256076128,
      "grad_norm": 0.42349526286125183,
      "learning_rate": 8.979368874392387e-06,
      "loss": 0.0974,
      "step": 6446
    },
    {
      "epoch": 0.10207894611840335,
      "grad_norm": 0.014854613691568375,
      "learning_rate": 8.979210538815968e-06,
      "loss": 0.0009,
      "step": 6447
    },
    {
      "epoch": 0.10209477967604541,
      "grad_norm": 0.37895506620407104,
      "learning_rate": 8.979052203239547e-06,
      "loss": 0.0539,
      "step": 6448
    },
    {
      "epoch": 0.10211061323368747,
      "grad_norm": 0.00020134936494287103,
      "learning_rate": 8.978893867663125e-06,
      "loss": 0.0,
      "step": 6449
    },
    {
      "epoch": 0.10212644679132954,
      "grad_norm": 0.28956398367881775,
      "learning_rate": 8.978735532086706e-06,
      "loss": 0.2793,
      "step": 6450
    },
    {
      "epoch": 0.1021422803489716,
      "grad_norm": 0.0060827406123280525,
      "learning_rate": 8.978577196510285e-06,
      "loss": 0.0004,
      "step": 6451
    },
    {
      "epoch": 0.10215811390661368,
      "grad_norm": 0.00018776385695673525,
      "learning_rate": 8.978418860933864e-06,
      "loss": 0.0,
      "step": 6452
    },
    {
      "epoch": 0.10217394746425575,
      "grad_norm": 0.00015985565551090986,
      "learning_rate": 8.978260525357443e-06,
      "loss": 0.0,
      "step": 6453
    },
    {
      "epoch": 0.10218978102189781,
      "grad_norm": 0.012768205255270004,
      "learning_rate": 8.978102189781024e-06,
      "loss": 0.0006,
      "step": 6454
    },
    {
      "epoch": 0.10220561457953987,
      "grad_norm": 0.08647580444812775,
      "learning_rate": 8.977943854204601e-06,
      "loss": 0.0125,
      "step": 6455
    },
    {
      "epoch": 0.10222144813718194,
      "grad_norm": 0.04366361349821091,
      "learning_rate": 8.977785518628182e-06,
      "loss": 0.0027,
      "step": 6456
    },
    {
      "epoch": 0.102237281694824,
      "grad_norm": 0.3463134765625,
      "learning_rate": 8.97762718305176e-06,
      "loss": 0.0752,
      "step": 6457
    },
    {
      "epoch": 0.10225311525246608,
      "grad_norm": 0.000671974616125226,
      "learning_rate": 8.97746884747534e-06,
      "loss": 0.0,
      "step": 6458
    },
    {
      "epoch": 0.10226894881010815,
      "grad_norm": 0.3230215311050415,
      "learning_rate": 8.977310511898919e-06,
      "loss": 0.1435,
      "step": 6459
    },
    {
      "epoch": 0.10228478236775021,
      "grad_norm": 0.3561517596244812,
      "learning_rate": 8.9771521763225e-06,
      "loss": 0.0908,
      "step": 6460
    },
    {
      "epoch": 0.10230061592539227,
      "grad_norm": 0.009253542870283127,
      "learning_rate": 8.976993840746077e-06,
      "loss": 0.0005,
      "step": 6461
    },
    {
      "epoch": 0.10231644948303434,
      "grad_norm": 0.36669689416885376,
      "learning_rate": 8.976835505169658e-06,
      "loss": 0.2136,
      "step": 6462
    },
    {
      "epoch": 0.1023322830406764,
      "grad_norm": 0.00024658182519488037,
      "learning_rate": 8.976677169593237e-06,
      "loss": 0.0,
      "step": 6463
    },
    {
      "epoch": 0.10234811659831848,
      "grad_norm": 0.5792586803436279,
      "learning_rate": 8.976518834016816e-06,
      "loss": 0.0832,
      "step": 6464
    },
    {
      "epoch": 0.10236395015596055,
      "grad_norm": 0.3248654901981354,
      "learning_rate": 8.976360498440395e-06,
      "loss": 0.2536,
      "step": 6465
    },
    {
      "epoch": 0.10237978371360261,
      "grad_norm": 0.2839621901512146,
      "learning_rate": 8.976202162863976e-06,
      "loss": 0.1054,
      "step": 6466
    },
    {
      "epoch": 0.10239561727124467,
      "grad_norm": 0.019760707393288612,
      "learning_rate": 8.976043827287553e-06,
      "loss": 0.001,
      "step": 6467
    },
    {
      "epoch": 0.10241145082888674,
      "grad_norm": 0.5095376372337341,
      "learning_rate": 8.975885491711134e-06,
      "loss": 0.5754,
      "step": 6468
    },
    {
      "epoch": 0.1024272843865288,
      "grad_norm": 0.0002904292196035385,
      "learning_rate": 8.975727156134713e-06,
      "loss": 0.0,
      "step": 6469
    },
    {
      "epoch": 0.10244311794417088,
      "grad_norm": 0.4358268082141876,
      "learning_rate": 8.975568820558292e-06,
      "loss": 0.2543,
      "step": 6470
    },
    {
      "epoch": 0.10245895150181294,
      "grad_norm": 0.9763841032981873,
      "learning_rate": 8.975410484981871e-06,
      "loss": 1.0611,
      "step": 6471
    },
    {
      "epoch": 0.10247478505945501,
      "grad_norm": 0.268185555934906,
      "learning_rate": 8.975252149405452e-06,
      "loss": 0.0703,
      "step": 6472
    },
    {
      "epoch": 0.10249061861709707,
      "grad_norm": 0.23025286197662354,
      "learning_rate": 8.97509381382903e-06,
      "loss": 0.076,
      "step": 6473
    },
    {
      "epoch": 0.10250645217473914,
      "grad_norm": 0.01738710328936577,
      "learning_rate": 8.974935478252609e-06,
      "loss": 0.001,
      "step": 6474
    },
    {
      "epoch": 0.1025222857323812,
      "grad_norm": 0.37345555424690247,
      "learning_rate": 8.97477714267619e-06,
      "loss": 0.2183,
      "step": 6475
    },
    {
      "epoch": 0.10253811929002328,
      "grad_norm": 0.29106032848358154,
      "learning_rate": 8.974618807099768e-06,
      "loss": 0.203,
      "step": 6476
    },
    {
      "epoch": 0.10255395284766534,
      "grad_norm": 0.27124345302581787,
      "learning_rate": 8.974460471523347e-06,
      "loss": 0.0893,
      "step": 6477
    },
    {
      "epoch": 0.10256978640530741,
      "grad_norm": 0.4519219994544983,
      "learning_rate": 8.974302135946927e-06,
      "loss": 0.0284,
      "step": 6478
    },
    {
      "epoch": 0.10258561996294947,
      "grad_norm": 0.1344359964132309,
      "learning_rate": 8.974143800370506e-06,
      "loss": 0.0115,
      "step": 6479
    },
    {
      "epoch": 0.10260145352059154,
      "grad_norm": 0.01625458151102066,
      "learning_rate": 8.973985464794085e-06,
      "loss": 0.0009,
      "step": 6480
    },
    {
      "epoch": 0.1026172870782336,
      "grad_norm": 6.60300866002217e-05,
      "learning_rate": 8.973827129217665e-06,
      "loss": 0.0,
      "step": 6481
    },
    {
      "epoch": 0.10263312063587568,
      "grad_norm": 0.2603486180305481,
      "learning_rate": 8.973668793641243e-06,
      "loss": 0.0527,
      "step": 6482
    },
    {
      "epoch": 0.10264895419351774,
      "grad_norm": 0.06185685098171234,
      "learning_rate": 8.973510458064824e-06,
      "loss": 0.0114,
      "step": 6483
    },
    {
      "epoch": 0.10266478775115981,
      "grad_norm": 0.9536263346672058,
      "learning_rate": 8.973352122488403e-06,
      "loss": 0.1167,
      "step": 6484
    },
    {
      "epoch": 0.10268062130880187,
      "grad_norm": 0.3276187479496002,
      "learning_rate": 8.973193786911982e-06,
      "loss": 0.3992,
      "step": 6485
    },
    {
      "epoch": 0.10269645486644394,
      "grad_norm": 0.4444882273674011,
      "learning_rate": 8.97303545133556e-06,
      "loss": 0.18,
      "step": 6486
    },
    {
      "epoch": 0.102712288424086,
      "grad_norm": 0.2451266497373581,
      "learning_rate": 8.972877115759142e-06,
      "loss": 0.1256,
      "step": 6487
    },
    {
      "epoch": 0.10272812198172808,
      "grad_norm": 0.1775689274072647,
      "learning_rate": 8.972718780182719e-06,
      "loss": 0.0123,
      "step": 6488
    },
    {
      "epoch": 0.10274395553937014,
      "grad_norm": 0.016234302893280983,
      "learning_rate": 8.9725604446063e-06,
      "loss": 0.001,
      "step": 6489
    },
    {
      "epoch": 0.10275978909701221,
      "grad_norm": 3.6071796785108745e-05,
      "learning_rate": 8.972402109029879e-06,
      "loss": 0.0,
      "step": 6490
    },
    {
      "epoch": 0.10277562265465427,
      "grad_norm": 0.0034309483598917723,
      "learning_rate": 8.972243773453458e-06,
      "loss": 0.0002,
      "step": 6491
    },
    {
      "epoch": 0.10279145621229634,
      "grad_norm": 0.49854469299316406,
      "learning_rate": 8.972085437877037e-06,
      "loss": 0.648,
      "step": 6492
    },
    {
      "epoch": 0.1028072897699384,
      "grad_norm": 0.0009933958062902093,
      "learning_rate": 8.971927102300618e-06,
      "loss": 0.0,
      "step": 6493
    },
    {
      "epoch": 0.10282312332758048,
      "grad_norm": 0.07146739214658737,
      "learning_rate": 8.971768766724195e-06,
      "loss": 0.0118,
      "step": 6494
    },
    {
      "epoch": 0.10283895688522254,
      "grad_norm": 0.33663371205329895,
      "learning_rate": 8.971610431147776e-06,
      "loss": 0.2886,
      "step": 6495
    },
    {
      "epoch": 0.10285479044286461,
      "grad_norm": 0.03622619807720184,
      "learning_rate": 8.971452095571355e-06,
      "loss": 0.0019,
      "step": 6496
    },
    {
      "epoch": 0.10287062400050667,
      "grad_norm": 0.15510597825050354,
      "learning_rate": 8.971293759994934e-06,
      "loss": 0.074,
      "step": 6497
    },
    {
      "epoch": 0.10288645755814874,
      "grad_norm": 0.386321485042572,
      "learning_rate": 8.971135424418513e-06,
      "loss": 0.6516,
      "step": 6498
    },
    {
      "epoch": 0.1029022911157908,
      "grad_norm": 0.02248428389430046,
      "learning_rate": 8.970977088842092e-06,
      "loss": 0.0014,
      "step": 6499
    },
    {
      "epoch": 0.10291812467343288,
      "grad_norm": 0.24625848233699799,
      "learning_rate": 8.970818753265671e-06,
      "loss": 0.0834,
      "step": 6500
    },
    {
      "epoch": 0.10293395823107494,
      "grad_norm": 0.3539576530456543,
      "learning_rate": 8.97066041768925e-06,
      "loss": 0.0879,
      "step": 6501
    },
    {
      "epoch": 0.10294979178871701,
      "grad_norm": 0.5146613717079163,
      "learning_rate": 8.970502082112831e-06,
      "loss": 0.0824,
      "step": 6502
    },
    {
      "epoch": 0.10296562534635907,
      "grad_norm": 0.19491150975227356,
      "learning_rate": 8.97034374653641e-06,
      "loss": 0.07,
      "step": 6503
    },
    {
      "epoch": 0.10298145890400114,
      "grad_norm": 0.04668072238564491,
      "learning_rate": 8.97018541095999e-06,
      "loss": 0.0033,
      "step": 6504
    },
    {
      "epoch": 0.1029972924616432,
      "grad_norm": 0.07526221871376038,
      "learning_rate": 8.970027075383568e-06,
      "loss": 0.0022,
      "step": 6505
    },
    {
      "epoch": 0.10301312601928528,
      "grad_norm": 0.011380262672901154,
      "learning_rate": 8.969868739807148e-06,
      "loss": 0.0005,
      "step": 6506
    },
    {
      "epoch": 0.10302895957692734,
      "grad_norm": 0.007327171973884106,
      "learning_rate": 8.969710404230727e-06,
      "loss": 0.0004,
      "step": 6507
    },
    {
      "epoch": 0.1030447931345694,
      "grad_norm": 0.25743719935417175,
      "learning_rate": 8.969552068654307e-06,
      "loss": 0.089,
      "step": 6508
    },
    {
      "epoch": 0.10306062669221147,
      "grad_norm": 1.2077900171279907,
      "learning_rate": 8.969393733077886e-06,
      "loss": 0.4642,
      "step": 6509
    },
    {
      "epoch": 0.10307646024985354,
      "grad_norm": 0.9134909510612488,
      "learning_rate": 8.969235397501466e-06,
      "loss": 0.0432,
      "step": 6510
    },
    {
      "epoch": 0.1030922938074956,
      "grad_norm": 0.3544016182422638,
      "learning_rate": 8.969077061925045e-06,
      "loss": 0.1709,
      "step": 6511
    },
    {
      "epoch": 0.10310812736513768,
      "grad_norm": 0.5072917342185974,
      "learning_rate": 8.968918726348624e-06,
      "loss": 0.6071,
      "step": 6512
    },
    {
      "epoch": 0.10312396092277974,
      "grad_norm": 0.142095148563385,
      "learning_rate": 8.968760390772203e-06,
      "loss": 0.1305,
      "step": 6513
    },
    {
      "epoch": 0.1031397944804218,
      "grad_norm": 0.013231961987912655,
      "learning_rate": 8.968602055195784e-06,
      "loss": 0.0006,
      "step": 6514
    },
    {
      "epoch": 0.10315562803806387,
      "grad_norm": 0.15662063658237457,
      "learning_rate": 8.968443719619363e-06,
      "loss": 0.0207,
      "step": 6515
    },
    {
      "epoch": 0.10317146159570593,
      "grad_norm": 0.13196097314357758,
      "learning_rate": 8.968285384042942e-06,
      "loss": 0.0055,
      "step": 6516
    },
    {
      "epoch": 0.103187295153348,
      "grad_norm": 0.29740896821022034,
      "learning_rate": 8.96812704846652e-06,
      "loss": 0.318,
      "step": 6517
    },
    {
      "epoch": 0.10320312871099008,
      "grad_norm": 0.29648342728614807,
      "learning_rate": 8.9679687128901e-06,
      "loss": 0.1517,
      "step": 6518
    },
    {
      "epoch": 0.10321896226863214,
      "grad_norm": 0.01886715181171894,
      "learning_rate": 8.967810377313679e-06,
      "loss": 0.0012,
      "step": 6519
    },
    {
      "epoch": 0.1032347958262742,
      "grad_norm": 0.029950208961963654,
      "learning_rate": 8.96765204173726e-06,
      "loss": 0.0024,
      "step": 6520
    },
    {
      "epoch": 0.10325062938391627,
      "grad_norm": 0.4363568425178528,
      "learning_rate": 8.967493706160839e-06,
      "loss": 0.1773,
      "step": 6521
    },
    {
      "epoch": 0.10326646294155833,
      "grad_norm": 0.14634743332862854,
      "learning_rate": 8.967335370584416e-06,
      "loss": 0.0568,
      "step": 6522
    },
    {
      "epoch": 0.1032822964992004,
      "grad_norm": 0.13752028346061707,
      "learning_rate": 8.967177035007997e-06,
      "loss": 0.0292,
      "step": 6523
    },
    {
      "epoch": 0.10329813005684248,
      "grad_norm": 0.0001231380010722205,
      "learning_rate": 8.967018699431576e-06,
      "loss": 0.0,
      "step": 6524
    },
    {
      "epoch": 0.10331396361448454,
      "grad_norm": 0.2087726593017578,
      "learning_rate": 8.966860363855155e-06,
      "loss": 0.0145,
      "step": 6525
    },
    {
      "epoch": 0.1033297971721266,
      "grad_norm": 0.7020038366317749,
      "learning_rate": 8.966702028278734e-06,
      "loss": 0.2601,
      "step": 6526
    },
    {
      "epoch": 0.10334563072976867,
      "grad_norm": 0.20728829503059387,
      "learning_rate": 8.966543692702315e-06,
      "loss": 0.0679,
      "step": 6527
    },
    {
      "epoch": 0.10336146428741073,
      "grad_norm": 0.21055960655212402,
      "learning_rate": 8.966385357125892e-06,
      "loss": 0.1624,
      "step": 6528
    },
    {
      "epoch": 0.1033772978450528,
      "grad_norm": 0.11639313399791718,
      "learning_rate": 8.966227021549473e-06,
      "loss": 0.062,
      "step": 6529
    },
    {
      "epoch": 0.10339313140269488,
      "grad_norm": 4.132949834456667e-05,
      "learning_rate": 8.966068685973052e-06,
      "loss": 0.0,
      "step": 6530
    },
    {
      "epoch": 0.10340896496033694,
      "grad_norm": 0.023039020597934723,
      "learning_rate": 8.965910350396631e-06,
      "loss": 0.0015,
      "step": 6531
    },
    {
      "epoch": 0.103424798517979,
      "grad_norm": 0.23623378574848175,
      "learning_rate": 8.96575201482021e-06,
      "loss": 0.1152,
      "step": 6532
    },
    {
      "epoch": 0.10344063207562107,
      "grad_norm": 8.287527452921495e-05,
      "learning_rate": 8.965593679243791e-06,
      "loss": 0.0,
      "step": 6533
    },
    {
      "epoch": 0.10345646563326313,
      "grad_norm": 0.12086256593465805,
      "learning_rate": 8.965435343667369e-06,
      "loss": 0.0495,
      "step": 6534
    },
    {
      "epoch": 0.1034722991909052,
      "grad_norm": 0.000137545692268759,
      "learning_rate": 8.96527700809095e-06,
      "loss": 0.0,
      "step": 6535
    },
    {
      "epoch": 0.10348813274854728,
      "grad_norm": 0.2929218113422394,
      "learning_rate": 8.965118672514528e-06,
      "loss": 0.191,
      "step": 6536
    },
    {
      "epoch": 0.10350396630618934,
      "grad_norm": 0.3191084861755371,
      "learning_rate": 8.964960336938107e-06,
      "loss": 0.1078,
      "step": 6537
    },
    {
      "epoch": 0.1035197998638314,
      "grad_norm": 0.3624535799026489,
      "learning_rate": 8.964802001361687e-06,
      "loss": 0.3948,
      "step": 6538
    },
    {
      "epoch": 0.10353563342147347,
      "grad_norm": 0.20157597959041595,
      "learning_rate": 8.964643665785266e-06,
      "loss": 0.1345,
      "step": 6539
    },
    {
      "epoch": 0.10355146697911553,
      "grad_norm": 0.0196556206792593,
      "learning_rate": 8.964485330208845e-06,
      "loss": 0.0011,
      "step": 6540
    },
    {
      "epoch": 0.1035673005367576,
      "grad_norm": 1.0216811895370483,
      "learning_rate": 8.964326994632425e-06,
      "loss": 0.9188,
      "step": 6541
    },
    {
      "epoch": 0.10358313409439968,
      "grad_norm": 0.25105488300323486,
      "learning_rate": 8.964168659056005e-06,
      "loss": 0.0374,
      "step": 6542
    },
    {
      "epoch": 0.10359896765204174,
      "grad_norm": 0.020749958232045174,
      "learning_rate": 8.964010323479584e-06,
      "loss": 0.0013,
      "step": 6543
    },
    {
      "epoch": 0.1036148012096838,
      "grad_norm": 0.03538209944963455,
      "learning_rate": 8.963851987903163e-06,
      "loss": 0.0028,
      "step": 6544
    },
    {
      "epoch": 0.10363063476732587,
      "grad_norm": 0.40270185470581055,
      "learning_rate": 8.963693652326742e-06,
      "loss": 0.1305,
      "step": 6545
    },
    {
      "epoch": 0.10364646832496793,
      "grad_norm": 0.00017758589820005,
      "learning_rate": 8.963535316750321e-06,
      "loss": 0.0,
      "step": 6546
    },
    {
      "epoch": 0.10366230188261,
      "grad_norm": 0.022523166611790657,
      "learning_rate": 8.9633769811739e-06,
      "loss": 0.0014,
      "step": 6547
    },
    {
      "epoch": 0.10367813544025208,
      "grad_norm": 0.4544590711593628,
      "learning_rate": 8.96321864559748e-06,
      "loss": 0.1263,
      "step": 6548
    },
    {
      "epoch": 0.10369396899789414,
      "grad_norm": 0.15784107148647308,
      "learning_rate": 8.963060310021058e-06,
      "loss": 0.0867,
      "step": 6549
    },
    {
      "epoch": 0.1037098025555362,
      "grad_norm": 0.006929965689778328,
      "learning_rate": 8.962901974444639e-06,
      "loss": 0.0005,
      "step": 6550
    },
    {
      "epoch": 0.10372563611317827,
      "grad_norm": 0.4555698037147522,
      "learning_rate": 8.962743638868218e-06,
      "loss": 0.0446,
      "step": 6551
    },
    {
      "epoch": 0.10374146967082033,
      "grad_norm": 0.23440465331077576,
      "learning_rate": 8.962585303291797e-06,
      "loss": 0.053,
      "step": 6552
    },
    {
      "epoch": 0.1037573032284624,
      "grad_norm": 0.2609785199165344,
      "learning_rate": 8.962426967715376e-06,
      "loss": 0.0507,
      "step": 6553
    },
    {
      "epoch": 0.10377313678610448,
      "grad_norm": 0.0001732787786750123,
      "learning_rate": 8.962268632138957e-06,
      "loss": 0.0,
      "step": 6554
    },
    {
      "epoch": 0.10378897034374654,
      "grad_norm": 0.22076378762722015,
      "learning_rate": 8.962110296562534e-06,
      "loss": 0.0718,
      "step": 6555
    },
    {
      "epoch": 0.1038048039013886,
      "grad_norm": 0.2794106900691986,
      "learning_rate": 8.961951960986115e-06,
      "loss": 0.3072,
      "step": 6556
    },
    {
      "epoch": 0.10382063745903067,
      "grad_norm": 0.0021816894877701998,
      "learning_rate": 8.961793625409694e-06,
      "loss": 0.0001,
      "step": 6557
    },
    {
      "epoch": 0.10383647101667273,
      "grad_norm": 0.6258739233016968,
      "learning_rate": 8.961635289833273e-06,
      "loss": 0.3511,
      "step": 6558
    },
    {
      "epoch": 0.1038523045743148,
      "grad_norm": 0.3477526009082794,
      "learning_rate": 8.961476954256852e-06,
      "loss": 0.181,
      "step": 6559
    },
    {
      "epoch": 0.10386813813195687,
      "grad_norm": 0.6135740876197815,
      "learning_rate": 8.961318618680433e-06,
      "loss": 0.2381,
      "step": 6560
    },
    {
      "epoch": 0.10388397168959894,
      "grad_norm": 0.11208371073007584,
      "learning_rate": 8.96116028310401e-06,
      "loss": 0.028,
      "step": 6561
    },
    {
      "epoch": 0.103899805247241,
      "grad_norm": 0.25865933299064636,
      "learning_rate": 8.961001947527591e-06,
      "loss": 0.036,
      "step": 6562
    },
    {
      "epoch": 0.10391563880488307,
      "grad_norm": 0.32507309317588806,
      "learning_rate": 8.96084361195117e-06,
      "loss": 0.1098,
      "step": 6563
    },
    {
      "epoch": 0.10393147236252513,
      "grad_norm": 0.28698211908340454,
      "learning_rate": 8.96068527637475e-06,
      "loss": 0.3602,
      "step": 6564
    },
    {
      "epoch": 0.1039473059201672,
      "grad_norm": 0.42743176221847534,
      "learning_rate": 8.960526940798328e-06,
      "loss": 0.4538,
      "step": 6565
    },
    {
      "epoch": 0.10396313947780927,
      "grad_norm": 0.3056522607803345,
      "learning_rate": 8.96036860522191e-06,
      "loss": 0.1491,
      "step": 6566
    },
    {
      "epoch": 0.10397897303545134,
      "grad_norm": 0.00023865335970185697,
      "learning_rate": 8.960210269645487e-06,
      "loss": 0.0,
      "step": 6567
    },
    {
      "epoch": 0.1039948065930934,
      "grad_norm": 0.21344894170761108,
      "learning_rate": 8.960051934069067e-06,
      "loss": 0.1403,
      "step": 6568
    },
    {
      "epoch": 0.10401064015073547,
      "grad_norm": 9.188883268507197e-05,
      "learning_rate": 8.959893598492646e-06,
      "loss": 0.0,
      "step": 6569
    },
    {
      "epoch": 0.10402647370837753,
      "grad_norm": 0.3303675353527069,
      "learning_rate": 8.959735262916226e-06,
      "loss": 0.064,
      "step": 6570
    },
    {
      "epoch": 0.1040423072660196,
      "grad_norm": 0.022460170090198517,
      "learning_rate": 8.959576927339805e-06,
      "loss": 0.0015,
      "step": 6571
    },
    {
      "epoch": 0.10405814082366167,
      "grad_norm": 0.015789171680808067,
      "learning_rate": 8.959418591763384e-06,
      "loss": 0.0009,
      "step": 6572
    },
    {
      "epoch": 0.10407397438130374,
      "grad_norm": 0.01912197284400463,
      "learning_rate": 8.959260256186963e-06,
      "loss": 0.0012,
      "step": 6573
    },
    {
      "epoch": 0.1040898079389458,
      "grad_norm": 2.5681986808776855,
      "learning_rate": 8.959101920610542e-06,
      "loss": 0.0669,
      "step": 6574
    },
    {
      "epoch": 0.10410564149658787,
      "grad_norm": 0.23795294761657715,
      "learning_rate": 8.958943585034123e-06,
      "loss": 0.5578,
      "step": 6575
    },
    {
      "epoch": 0.10412147505422993,
      "grad_norm": 0.9261712431907654,
      "learning_rate": 8.958785249457702e-06,
      "loss": 0.1718,
      "step": 6576
    },
    {
      "epoch": 0.104137308611872,
      "grad_norm": 0.21078228950500488,
      "learning_rate": 8.95862691388128e-06,
      "loss": 0.0542,
      "step": 6577
    },
    {
      "epoch": 0.10415314216951407,
      "grad_norm": 0.4108344316482544,
      "learning_rate": 8.95846857830486e-06,
      "loss": 0.191,
      "step": 6578
    },
    {
      "epoch": 0.10416897572715614,
      "grad_norm": 0.3787524402141571,
      "learning_rate": 8.958310242728439e-06,
      "loss": 0.4216,
      "step": 6579
    },
    {
      "epoch": 0.1041848092847982,
      "grad_norm": 0.4739779829978943,
      "learning_rate": 8.958151907152018e-06,
      "loss": 0.5675,
      "step": 6580
    },
    {
      "epoch": 0.10420064284244027,
      "grad_norm": 0.2952221632003784,
      "learning_rate": 8.957993571575599e-06,
      "loss": 0.1342,
      "step": 6581
    },
    {
      "epoch": 0.10421647640008233,
      "grad_norm": 0.0046707941219210625,
      "learning_rate": 8.957835235999178e-06,
      "loss": 0.0003,
      "step": 6582
    },
    {
      "epoch": 0.1042323099577244,
      "grad_norm": 0.16880589723587036,
      "learning_rate": 8.957676900422757e-06,
      "loss": 0.024,
      "step": 6583
    },
    {
      "epoch": 0.10424814351536647,
      "grad_norm": 0.5539256930351257,
      "learning_rate": 8.957518564846336e-06,
      "loss": 0.067,
      "step": 6584
    },
    {
      "epoch": 0.10426397707300854,
      "grad_norm": 0.6074572205543518,
      "learning_rate": 8.957360229269915e-06,
      "loss": 0.3038,
      "step": 6585
    },
    {
      "epoch": 0.1042798106306506,
      "grad_norm": 0.40886127948760986,
      "learning_rate": 8.957201893693494e-06,
      "loss": 0.1321,
      "step": 6586
    },
    {
      "epoch": 0.10429564418829267,
      "grad_norm": 0.1525154709815979,
      "learning_rate": 8.957043558117075e-06,
      "loss": 0.0387,
      "step": 6587
    },
    {
      "epoch": 0.10431147774593473,
      "grad_norm": 0.07216353714466095,
      "learning_rate": 8.956885222540654e-06,
      "loss": 0.001,
      "step": 6588
    },
    {
      "epoch": 0.1043273113035768,
      "grad_norm": 0.1756398230791092,
      "learning_rate": 8.956726886964233e-06,
      "loss": 0.0639,
      "step": 6589
    },
    {
      "epoch": 0.10434314486121887,
      "grad_norm": 0.13124452531337738,
      "learning_rate": 8.956568551387812e-06,
      "loss": 0.0634,
      "step": 6590
    },
    {
      "epoch": 0.10435897841886094,
      "grad_norm": 0.2779429256916046,
      "learning_rate": 8.956410215811391e-06,
      "loss": 0.4618,
      "step": 6591
    },
    {
      "epoch": 0.104374811976503,
      "grad_norm": 0.25706231594085693,
      "learning_rate": 8.95625188023497e-06,
      "loss": 0.1168,
      "step": 6592
    },
    {
      "epoch": 0.10439064553414507,
      "grad_norm": 0.09464842081069946,
      "learning_rate": 8.95609354465855e-06,
      "loss": 0.0012,
      "step": 6593
    },
    {
      "epoch": 0.10440647909178713,
      "grad_norm": 0.2840489447116852,
      "learning_rate": 8.95593520908213e-06,
      "loss": 0.1361,
      "step": 6594
    },
    {
      "epoch": 0.1044223126494292,
      "grad_norm": 0.011428541503846645,
      "learning_rate": 8.955776873505708e-06,
      "loss": 0.0002,
      "step": 6595
    },
    {
      "epoch": 0.10443814620707127,
      "grad_norm": 0.3095196783542633,
      "learning_rate": 8.955618537929288e-06,
      "loss": 0.3522,
      "step": 6596
    },
    {
      "epoch": 0.10445397976471334,
      "grad_norm": 0.433060884475708,
      "learning_rate": 8.955460202352867e-06,
      "loss": 0.0979,
      "step": 6597
    },
    {
      "epoch": 0.1044698133223554,
      "grad_norm": 0.4284650981426239,
      "learning_rate": 8.955301866776447e-06,
      "loss": 0.3461,
      "step": 6598
    },
    {
      "epoch": 0.10448564687999747,
      "grad_norm": 0.253397673368454,
      "learning_rate": 8.955143531200026e-06,
      "loss": 0.2042,
      "step": 6599
    },
    {
      "epoch": 0.10450148043763953,
      "grad_norm": 0.21775193512439728,
      "learning_rate": 8.954985195623606e-06,
      "loss": 0.0842,
      "step": 6600
    },
    {
      "epoch": 0.1045173139952816,
      "grad_norm": 7.285163883352652e-05,
      "learning_rate": 8.954826860047184e-06,
      "loss": 0.0,
      "step": 6601
    },
    {
      "epoch": 0.10453314755292367,
      "grad_norm": 0.46450361609458923,
      "learning_rate": 8.954668524470765e-06,
      "loss": 0.067,
      "step": 6602
    },
    {
      "epoch": 0.10454898111056574,
      "grad_norm": 0.37993210554122925,
      "learning_rate": 8.954510188894344e-06,
      "loss": 0.3625,
      "step": 6603
    },
    {
      "epoch": 0.1045648146682078,
      "grad_norm": 0.009644618257880211,
      "learning_rate": 8.954351853317923e-06,
      "loss": 0.0006,
      "step": 6604
    },
    {
      "epoch": 0.10458064822584986,
      "grad_norm": 0.4973452389240265,
      "learning_rate": 8.954193517741502e-06,
      "loss": 0.2753,
      "step": 6605
    },
    {
      "epoch": 0.10459648178349193,
      "grad_norm": 0.18718364834785461,
      "learning_rate": 8.954035182165081e-06,
      "loss": 0.072,
      "step": 6606
    },
    {
      "epoch": 0.104612315341134,
      "grad_norm": 0.7301672101020813,
      "learning_rate": 8.95387684658866e-06,
      "loss": 0.0119,
      "step": 6607
    },
    {
      "epoch": 0.10462814889877607,
      "grad_norm": 0.5570672750473022,
      "learning_rate": 8.95371851101224e-06,
      "loss": 0.2205,
      "step": 6608
    },
    {
      "epoch": 0.10464398245641814,
      "grad_norm": 0.2642788887023926,
      "learning_rate": 8.95356017543582e-06,
      "loss": 0.0939,
      "step": 6609
    },
    {
      "epoch": 0.1046598160140602,
      "grad_norm": 0.33562925457954407,
      "learning_rate": 8.953401839859399e-06,
      "loss": 0.6617,
      "step": 6610
    },
    {
      "epoch": 0.10467564957170226,
      "grad_norm": 0.18613606691360474,
      "learning_rate": 8.953243504282978e-06,
      "loss": 0.0786,
      "step": 6611
    },
    {
      "epoch": 0.10469148312934433,
      "grad_norm": 0.16554121673107147,
      "learning_rate": 8.953085168706557e-06,
      "loss": 0.0635,
      "step": 6612
    },
    {
      "epoch": 0.10470731668698639,
      "grad_norm": 0.22518447041511536,
      "learning_rate": 8.952926833130136e-06,
      "loss": 0.0533,
      "step": 6613
    },
    {
      "epoch": 0.10472315024462847,
      "grad_norm": 0.3910805881023407,
      "learning_rate": 8.952768497553717e-06,
      "loss": 0.3607,
      "step": 6614
    },
    {
      "epoch": 0.10473898380227054,
      "grad_norm": 0.25792965292930603,
      "learning_rate": 8.952610161977296e-06,
      "loss": 0.064,
      "step": 6615
    },
    {
      "epoch": 0.1047548173599126,
      "grad_norm": 0.3196820914745331,
      "learning_rate": 8.952451826400875e-06,
      "loss": 0.0493,
      "step": 6616
    },
    {
      "epoch": 0.10477065091755466,
      "grad_norm": 0.055030494928359985,
      "learning_rate": 8.952293490824454e-06,
      "loss": 0.0042,
      "step": 6617
    },
    {
      "epoch": 0.10478648447519673,
      "grad_norm": 0.4061797857284546,
      "learning_rate": 8.952135155248033e-06,
      "loss": 0.3119,
      "step": 6618
    },
    {
      "epoch": 0.10480231803283879,
      "grad_norm": 0.2671706974506378,
      "learning_rate": 8.951976819671612e-06,
      "loss": 0.0917,
      "step": 6619
    },
    {
      "epoch": 0.10481815159048087,
      "grad_norm": 0.21000570058822632,
      "learning_rate": 8.951818484095191e-06,
      "loss": 0.1326,
      "step": 6620
    },
    {
      "epoch": 0.10483398514812294,
      "grad_norm": 0.28923800587654114,
      "learning_rate": 8.951660148518772e-06,
      "loss": 0.2821,
      "step": 6621
    },
    {
      "epoch": 0.104849818705765,
      "grad_norm": 0.008272143080830574,
      "learning_rate": 8.95150181294235e-06,
      "loss": 0.0001,
      "step": 6622
    },
    {
      "epoch": 0.10486565226340706,
      "grad_norm": 0.00275671249255538,
      "learning_rate": 8.95134347736593e-06,
      "loss": 0.0001,
      "step": 6623
    },
    {
      "epoch": 0.10488148582104913,
      "grad_norm": 0.35855206847190857,
      "learning_rate": 8.95118514178951e-06,
      "loss": 0.095,
      "step": 6624
    },
    {
      "epoch": 0.10489731937869119,
      "grad_norm": 0.18302622437477112,
      "learning_rate": 8.951026806213088e-06,
      "loss": 0.0616,
      "step": 6625
    },
    {
      "epoch": 0.10491315293633327,
      "grad_norm": 0.43966835737228394,
      "learning_rate": 8.950868470636668e-06,
      "loss": 0.2392,
      "step": 6626
    },
    {
      "epoch": 0.10492898649397533,
      "grad_norm": 0.017098937183618546,
      "learning_rate": 8.950710135060248e-06,
      "loss": 0.0009,
      "step": 6627
    },
    {
      "epoch": 0.1049448200516174,
      "grad_norm": 0.7333496809005737,
      "learning_rate": 8.950551799483826e-06,
      "loss": 0.3826,
      "step": 6628
    },
    {
      "epoch": 0.10496065360925946,
      "grad_norm": 0.0007950409781187773,
      "learning_rate": 8.950393463907406e-06,
      "loss": 0.0,
      "step": 6629
    },
    {
      "epoch": 0.10497648716690153,
      "grad_norm": 0.01634349673986435,
      "learning_rate": 8.950235128330986e-06,
      "loss": 0.0009,
      "step": 6630
    },
    {
      "epoch": 0.10499232072454359,
      "grad_norm": 0.5546898245811462,
      "learning_rate": 8.950076792754565e-06,
      "loss": 0.2525,
      "step": 6631
    },
    {
      "epoch": 0.10500815428218567,
      "grad_norm": 0.1596575230360031,
      "learning_rate": 8.949918457178144e-06,
      "loss": 0.0419,
      "step": 6632
    },
    {
      "epoch": 0.10502398783982773,
      "grad_norm": 0.5245582461357117,
      "learning_rate": 8.949760121601725e-06,
      "loss": 0.5574,
      "step": 6633
    },
    {
      "epoch": 0.1050398213974698,
      "grad_norm": 0.00441468833014369,
      "learning_rate": 8.949601786025302e-06,
      "loss": 0.0002,
      "step": 6634
    },
    {
      "epoch": 0.10505565495511186,
      "grad_norm": 0.3429831266403198,
      "learning_rate": 8.949443450448883e-06,
      "loss": 0.1647,
      "step": 6635
    },
    {
      "epoch": 0.10507148851275393,
      "grad_norm": 0.00022252167400438339,
      "learning_rate": 8.949285114872462e-06,
      "loss": 0.0,
      "step": 6636
    },
    {
      "epoch": 0.10508732207039599,
      "grad_norm": 0.4724196493625641,
      "learning_rate": 8.94912677929604e-06,
      "loss": 0.2118,
      "step": 6637
    },
    {
      "epoch": 0.10510315562803807,
      "grad_norm": 0.2721337080001831,
      "learning_rate": 8.94896844371962e-06,
      "loss": 0.5766,
      "step": 6638
    },
    {
      "epoch": 0.10511898918568013,
      "grad_norm": 0.28408244252204895,
      "learning_rate": 8.9488101081432e-06,
      "loss": 0.0484,
      "step": 6639
    },
    {
      "epoch": 0.1051348227433222,
      "grad_norm": 0.22139593958854675,
      "learning_rate": 8.948651772566778e-06,
      "loss": 0.0574,
      "step": 6640
    },
    {
      "epoch": 0.10515065630096426,
      "grad_norm": 0.3248574137687683,
      "learning_rate": 8.948493436990357e-06,
      "loss": 0.0684,
      "step": 6641
    },
    {
      "epoch": 0.10516648985860633,
      "grad_norm": 0.6420885920524597,
      "learning_rate": 8.948335101413938e-06,
      "loss": 0.6071,
      "step": 6642
    },
    {
      "epoch": 0.10518232341624839,
      "grad_norm": 0.2447831630706787,
      "learning_rate": 8.948176765837517e-06,
      "loss": 0.061,
      "step": 6643
    },
    {
      "epoch": 0.10519815697389047,
      "grad_norm": 0.4411640465259552,
      "learning_rate": 8.948018430261096e-06,
      "loss": 0.1745,
      "step": 6644
    },
    {
      "epoch": 0.10521399053153253,
      "grad_norm": 0.02307569980621338,
      "learning_rate": 8.947860094684675e-06,
      "loss": 0.001,
      "step": 6645
    },
    {
      "epoch": 0.1052298240891746,
      "grad_norm": 0.02513674646615982,
      "learning_rate": 8.947701759108254e-06,
      "loss": 0.0014,
      "step": 6646
    },
    {
      "epoch": 0.10524565764681666,
      "grad_norm": 0.4618140161037445,
      "learning_rate": 8.947543423531833e-06,
      "loss": 0.6026,
      "step": 6647
    },
    {
      "epoch": 0.10526149120445873,
      "grad_norm": 0.24279719591140747,
      "learning_rate": 8.947385087955414e-06,
      "loss": 0.1526,
      "step": 6648
    },
    {
      "epoch": 0.10527732476210079,
      "grad_norm": 0.29644402861595154,
      "learning_rate": 8.947226752378993e-06,
      "loss": 0.0955,
      "step": 6649
    },
    {
      "epoch": 0.10529315831974287,
      "grad_norm": 0.28795957565307617,
      "learning_rate": 8.947068416802572e-06,
      "loss": 0.1149,
      "step": 6650
    },
    {
      "epoch": 0.10530899187738493,
      "grad_norm": 0.47112923860549927,
      "learning_rate": 8.946910081226151e-06,
      "loss": 0.3158,
      "step": 6651
    },
    {
      "epoch": 0.105324825435027,
      "grad_norm": 0.15054211020469666,
      "learning_rate": 8.94675174564973e-06,
      "loss": 0.0144,
      "step": 6652
    },
    {
      "epoch": 0.10534065899266906,
      "grad_norm": 6.268017023103312e-05,
      "learning_rate": 8.94659341007331e-06,
      "loss": 0.0,
      "step": 6653
    },
    {
      "epoch": 0.10535649255031113,
      "grad_norm": 0.004207860678434372,
      "learning_rate": 8.94643507449689e-06,
      "loss": 0.0001,
      "step": 6654
    },
    {
      "epoch": 0.10537232610795319,
      "grad_norm": 0.2026534527540207,
      "learning_rate": 8.94627673892047e-06,
      "loss": 0.0683,
      "step": 6655
    },
    {
      "epoch": 0.10538815966559527,
      "grad_norm": 0.40197280049324036,
      "learning_rate": 8.946118403344048e-06,
      "loss": 0.1148,
      "step": 6656
    },
    {
      "epoch": 0.10540399322323733,
      "grad_norm": 0.8316909670829773,
      "learning_rate": 8.945960067767627e-06,
      "loss": 0.1489,
      "step": 6657
    },
    {
      "epoch": 0.1054198267808794,
      "grad_norm": 0.02583734691143036,
      "learning_rate": 8.945801732191207e-06,
      "loss": 0.0018,
      "step": 6658
    },
    {
      "epoch": 0.10543566033852146,
      "grad_norm": 0.5558094382286072,
      "learning_rate": 8.945643396614786e-06,
      "loss": 0.0768,
      "step": 6659
    },
    {
      "epoch": 0.10545149389616353,
      "grad_norm": 0.27920371294021606,
      "learning_rate": 8.945485061038366e-06,
      "loss": 0.066,
      "step": 6660
    },
    {
      "epoch": 0.10546732745380559,
      "grad_norm": 0.8677597641944885,
      "learning_rate": 8.945326725461946e-06,
      "loss": 0.3611,
      "step": 6661
    },
    {
      "epoch": 0.10548316101144767,
      "grad_norm": 0.012287582270801067,
      "learning_rate": 8.945168389885525e-06,
      "loss": 0.0006,
      "step": 6662
    },
    {
      "epoch": 0.10549899456908973,
      "grad_norm": 0.01969277486205101,
      "learning_rate": 8.945010054309104e-06,
      "loss": 0.0008,
      "step": 6663
    },
    {
      "epoch": 0.1055148281267318,
      "grad_norm": 0.03437726944684982,
      "learning_rate": 8.944851718732683e-06,
      "loss": 0.002,
      "step": 6664
    },
    {
      "epoch": 0.10553066168437386,
      "grad_norm": 0.27719563245773315,
      "learning_rate": 8.944693383156262e-06,
      "loss": 0.0697,
      "step": 6665
    },
    {
      "epoch": 0.10554649524201593,
      "grad_norm": 0.2724049985408783,
      "learning_rate": 8.944535047579841e-06,
      "loss": 0.0555,
      "step": 6666
    },
    {
      "epoch": 0.10556232879965799,
      "grad_norm": 0.2979262173175812,
      "learning_rate": 8.944376712003422e-06,
      "loss": 0.1741,
      "step": 6667
    },
    {
      "epoch": 0.10557816235730007,
      "grad_norm": 0.32623639702796936,
      "learning_rate": 8.944218376426999e-06,
      "loss": 0.1433,
      "step": 6668
    },
    {
      "epoch": 0.10559399591494213,
      "grad_norm": 0.23222926259040833,
      "learning_rate": 8.94406004085058e-06,
      "loss": 0.1306,
      "step": 6669
    },
    {
      "epoch": 0.1056098294725842,
      "grad_norm": 0.04712998494505882,
      "learning_rate": 8.943901705274159e-06,
      "loss": 0.0023,
      "step": 6670
    },
    {
      "epoch": 0.10562566303022626,
      "grad_norm": 0.35787343978881836,
      "learning_rate": 8.943743369697738e-06,
      "loss": 0.0354,
      "step": 6671
    },
    {
      "epoch": 0.10564149658786832,
      "grad_norm": 0.33090102672576904,
      "learning_rate": 8.943585034121317e-06,
      "loss": 0.1339,
      "step": 6672
    },
    {
      "epoch": 0.10565733014551039,
      "grad_norm": 0.015677735209465027,
      "learning_rate": 8.943426698544896e-06,
      "loss": 0.0009,
      "step": 6673
    },
    {
      "epoch": 0.10567316370315247,
      "grad_norm": 0.16995474696159363,
      "learning_rate": 8.943268362968475e-06,
      "loss": 0.145,
      "step": 6674
    },
    {
      "epoch": 0.10568899726079453,
      "grad_norm": 0.21950310468673706,
      "learning_rate": 8.943110027392056e-06,
      "loss": 0.0943,
      "step": 6675
    },
    {
      "epoch": 0.1057048308184366,
      "grad_norm": 0.002412032103165984,
      "learning_rate": 8.942951691815635e-06,
      "loss": 0.0001,
      "step": 6676
    },
    {
      "epoch": 0.10572066437607866,
      "grad_norm": 1.0675426721572876,
      "learning_rate": 8.942793356239214e-06,
      "loss": 0.4429,
      "step": 6677
    },
    {
      "epoch": 0.10573649793372072,
      "grad_norm": 0.007134000305086374,
      "learning_rate": 8.942635020662793e-06,
      "loss": 0.0003,
      "step": 6678
    },
    {
      "epoch": 0.10575233149136279,
      "grad_norm": 0.00010201294207945466,
      "learning_rate": 8.942476685086372e-06,
      "loss": 0.0,
      "step": 6679
    },
    {
      "epoch": 0.10576816504900487,
      "grad_norm": 0.016332687810063362,
      "learning_rate": 8.942318349509951e-06,
      "loss": 0.0009,
      "step": 6680
    },
    {
      "epoch": 0.10578399860664693,
      "grad_norm": 0.007910153828561306,
      "learning_rate": 8.942160013933532e-06,
      "loss": 0.0001,
      "step": 6681
    },
    {
      "epoch": 0.105799832164289,
      "grad_norm": 0.29644158482551575,
      "learning_rate": 8.942001678357111e-06,
      "loss": 0.0763,
      "step": 6682
    },
    {
      "epoch": 0.10581566572193106,
      "grad_norm": 0.3604125380516052,
      "learning_rate": 8.94184334278069e-06,
      "loss": 0.0452,
      "step": 6683
    },
    {
      "epoch": 0.10583149927957312,
      "grad_norm": 0.29903244972229004,
      "learning_rate": 8.94168500720427e-06,
      "loss": 0.1202,
      "step": 6684
    },
    {
      "epoch": 0.10584733283721519,
      "grad_norm": 0.028142694383859634,
      "learning_rate": 8.941526671627848e-06,
      "loss": 0.0016,
      "step": 6685
    },
    {
      "epoch": 0.10586316639485727,
      "grad_norm": 0.3255418539047241,
      "learning_rate": 8.941368336051428e-06,
      "loss": 0.2095,
      "step": 6686
    },
    {
      "epoch": 0.10587899995249933,
      "grad_norm": 0.040250975638628006,
      "learning_rate": 8.941210000475008e-06,
      "loss": 0.0016,
      "step": 6687
    },
    {
      "epoch": 0.1058948335101414,
      "grad_norm": 0.2847473621368408,
      "learning_rate": 8.941051664898587e-06,
      "loss": 0.08,
      "step": 6688
    },
    {
      "epoch": 0.10591066706778346,
      "grad_norm": 0.24262410402297974,
      "learning_rate": 8.940893329322165e-06,
      "loss": 0.1644,
      "step": 6689
    },
    {
      "epoch": 0.10592650062542552,
      "grad_norm": 0.3818311393260956,
      "learning_rate": 8.940734993745746e-06,
      "loss": 0.1294,
      "step": 6690
    },
    {
      "epoch": 0.10594233418306759,
      "grad_norm": 0.18664100766181946,
      "learning_rate": 8.940576658169325e-06,
      "loss": 0.0357,
      "step": 6691
    },
    {
      "epoch": 0.10595816774070967,
      "grad_norm": 0.47223126888275146,
      "learning_rate": 8.940418322592904e-06,
      "loss": 0.7352,
      "step": 6692
    },
    {
      "epoch": 0.10597400129835173,
      "grad_norm": 0.14430852234363556,
      "learning_rate": 8.940259987016483e-06,
      "loss": 0.0077,
      "step": 6693
    },
    {
      "epoch": 0.1059898348559938,
      "grad_norm": 0.33130958676338196,
      "learning_rate": 8.940101651440064e-06,
      "loss": 0.2144,
      "step": 6694
    },
    {
      "epoch": 0.10600566841363586,
      "grad_norm": 0.5290124416351318,
      "learning_rate": 8.939943315863641e-06,
      "loss": 0.9573,
      "step": 6695
    },
    {
      "epoch": 0.10602150197127792,
      "grad_norm": 0.35470351576805115,
      "learning_rate": 8.939784980287222e-06,
      "loss": 0.2197,
      "step": 6696
    },
    {
      "epoch": 0.10603733552891999,
      "grad_norm": 0.1575280874967575,
      "learning_rate": 8.9396266447108e-06,
      "loss": 0.0217,
      "step": 6697
    },
    {
      "epoch": 0.10605316908656207,
      "grad_norm": 0.5085982084274292,
      "learning_rate": 8.93946830913438e-06,
      "loss": 0.6803,
      "step": 6698
    },
    {
      "epoch": 0.10606900264420413,
      "grad_norm": 0.2780337929725647,
      "learning_rate": 8.939309973557959e-06,
      "loss": 0.2176,
      "step": 6699
    },
    {
      "epoch": 0.1060848362018462,
      "grad_norm": 0.1683802455663681,
      "learning_rate": 8.93915163798154e-06,
      "loss": 0.0042,
      "step": 6700
    },
    {
      "epoch": 0.10610066975948826,
      "grad_norm": 0.21283738315105438,
      "learning_rate": 8.938993302405117e-06,
      "loss": 0.0982,
      "step": 6701
    },
    {
      "epoch": 0.10611650331713032,
      "grad_norm": 0.4303188621997833,
      "learning_rate": 8.938834966828698e-06,
      "loss": 0.4515,
      "step": 6702
    },
    {
      "epoch": 0.10613233687477239,
      "grad_norm": 0.25074079632759094,
      "learning_rate": 8.938676631252277e-06,
      "loss": 0.0983,
      "step": 6703
    },
    {
      "epoch": 0.10614817043241447,
      "grad_norm": 0.23089416325092316,
      "learning_rate": 8.938518295675856e-06,
      "loss": 0.1103,
      "step": 6704
    },
    {
      "epoch": 0.10616400399005653,
      "grad_norm": 3.8048809074098244e-05,
      "learning_rate": 8.938359960099435e-06,
      "loss": 0.0,
      "step": 6705
    },
    {
      "epoch": 0.1061798375476986,
      "grad_norm": 0.23932670056819916,
      "learning_rate": 8.938201624523016e-06,
      "loss": 0.1677,
      "step": 6706
    },
    {
      "epoch": 0.10619567110534066,
      "grad_norm": 0.24142643809318542,
      "learning_rate": 8.938043288946593e-06,
      "loss": 0.0972,
      "step": 6707
    },
    {
      "epoch": 0.10621150466298272,
      "grad_norm": 0.41334259510040283,
      "learning_rate": 8.937884953370174e-06,
      "loss": 0.4296,
      "step": 6708
    },
    {
      "epoch": 0.10622733822062479,
      "grad_norm": 0.12259159237146378,
      "learning_rate": 8.937726617793753e-06,
      "loss": 0.0341,
      "step": 6709
    },
    {
      "epoch": 0.10624317177826686,
      "grad_norm": 0.00014806042599957436,
      "learning_rate": 8.937568282217332e-06,
      "loss": 0.0,
      "step": 6710
    },
    {
      "epoch": 0.10625900533590893,
      "grad_norm": 0.00021176687732804567,
      "learning_rate": 8.937409946640911e-06,
      "loss": 0.0,
      "step": 6711
    },
    {
      "epoch": 0.106274838893551,
      "grad_norm": 0.027794091030955315,
      "learning_rate": 8.937251611064492e-06,
      "loss": 0.0013,
      "step": 6712
    },
    {
      "epoch": 0.10629067245119306,
      "grad_norm": 0.25418204069137573,
      "learning_rate": 8.93709327548807e-06,
      "loss": 0.0515,
      "step": 6713
    },
    {
      "epoch": 0.10630650600883512,
      "grad_norm": 0.8503859043121338,
      "learning_rate": 8.936934939911649e-06,
      "loss": 0.0261,
      "step": 6714
    },
    {
      "epoch": 0.10632233956647719,
      "grad_norm": 0.20703686773777008,
      "learning_rate": 8.93677660433523e-06,
      "loss": 0.0664,
      "step": 6715
    },
    {
      "epoch": 0.10633817312411926,
      "grad_norm": 0.14128802716732025,
      "learning_rate": 8.936618268758808e-06,
      "loss": 0.0346,
      "step": 6716
    },
    {
      "epoch": 0.10635400668176133,
      "grad_norm": 0.00012641315697692335,
      "learning_rate": 8.936459933182388e-06,
      "loss": 0.0,
      "step": 6717
    },
    {
      "epoch": 0.1063698402394034,
      "grad_norm": 0.2644961178302765,
      "learning_rate": 8.936301597605967e-06,
      "loss": 0.2934,
      "step": 6718
    },
    {
      "epoch": 0.10638567379704546,
      "grad_norm": 0.14351384341716766,
      "learning_rate": 8.936143262029546e-06,
      "loss": 0.0293,
      "step": 6719
    },
    {
      "epoch": 0.10640150735468752,
      "grad_norm": 0.2203962206840515,
      "learning_rate": 8.935984926453125e-06,
      "loss": 0.1332,
      "step": 6720
    },
    {
      "epoch": 0.10641734091232959,
      "grad_norm": 0.19303031265735626,
      "learning_rate": 8.935826590876706e-06,
      "loss": 0.0124,
      "step": 6721
    },
    {
      "epoch": 0.10643317446997166,
      "grad_norm": 0.000418553565395996,
      "learning_rate": 8.935668255300285e-06,
      "loss": 0.0,
      "step": 6722
    },
    {
      "epoch": 0.10644900802761373,
      "grad_norm": 0.013760445639491081,
      "learning_rate": 8.935509919723864e-06,
      "loss": 0.0006,
      "step": 6723
    },
    {
      "epoch": 0.10646484158525579,
      "grad_norm": 0.5644180774688721,
      "learning_rate": 8.935351584147443e-06,
      "loss": 0.0613,
      "step": 6724
    },
    {
      "epoch": 0.10648067514289786,
      "grad_norm": 0.5181608200073242,
      "learning_rate": 8.935193248571022e-06,
      "loss": 0.1837,
      "step": 6725
    },
    {
      "epoch": 0.10649650870053992,
      "grad_norm": 0.26818183064460754,
      "learning_rate": 8.935034912994601e-06,
      "loss": 0.0323,
      "step": 6726
    },
    {
      "epoch": 0.10651234225818199,
      "grad_norm": 0.3691476881504059,
      "learning_rate": 8.934876577418182e-06,
      "loss": 0.0773,
      "step": 6727
    },
    {
      "epoch": 0.10652817581582406,
      "grad_norm": 0.8295297622680664,
      "learning_rate": 8.93471824184176e-06,
      "loss": 0.7653,
      "step": 6728
    },
    {
      "epoch": 0.10654400937346613,
      "grad_norm": 0.45300570130348206,
      "learning_rate": 8.93455990626534e-06,
      "loss": 0.5,
      "step": 6729
    },
    {
      "epoch": 0.10655984293110819,
      "grad_norm": 7.430720143020153e-05,
      "learning_rate": 8.934401570688919e-06,
      "loss": 0.0,
      "step": 6730
    },
    {
      "epoch": 0.10657567648875026,
      "grad_norm": 0.6838234663009644,
      "learning_rate": 8.934243235112498e-06,
      "loss": 0.5789,
      "step": 6731
    },
    {
      "epoch": 0.10659151004639232,
      "grad_norm": 0.6271321177482605,
      "learning_rate": 8.934084899536077e-06,
      "loss": 0.9917,
      "step": 6732
    },
    {
      "epoch": 0.10660734360403439,
      "grad_norm": 0.005766826216131449,
      "learning_rate": 8.933926563959658e-06,
      "loss": 0.0001,
      "step": 6733
    },
    {
      "epoch": 0.10662317716167646,
      "grad_norm": 0.525950014591217,
      "learning_rate": 8.933768228383235e-06,
      "loss": 0.0073,
      "step": 6734
    },
    {
      "epoch": 0.10663901071931853,
      "grad_norm": 0.41885414719581604,
      "learning_rate": 8.933609892806816e-06,
      "loss": 0.1907,
      "step": 6735
    },
    {
      "epoch": 0.10665484427696059,
      "grad_norm": 0.015543658286333084,
      "learning_rate": 8.933451557230395e-06,
      "loss": 0.0009,
      "step": 6736
    },
    {
      "epoch": 0.10667067783460266,
      "grad_norm": 0.022539978846907616,
      "learning_rate": 8.933293221653974e-06,
      "loss": 0.0012,
      "step": 6737
    },
    {
      "epoch": 0.10668651139224472,
      "grad_norm": 0.32044652104377747,
      "learning_rate": 8.933134886077553e-06,
      "loss": 0.1168,
      "step": 6738
    },
    {
      "epoch": 0.10670234494988678,
      "grad_norm": 0.17522183060646057,
      "learning_rate": 8.932976550501132e-06,
      "loss": 0.0463,
      "step": 6739
    },
    {
      "epoch": 0.10671817850752886,
      "grad_norm": 0.40038028359413147,
      "learning_rate": 8.932818214924711e-06,
      "loss": 0.1601,
      "step": 6740
    },
    {
      "epoch": 0.10673401206517093,
      "grad_norm": 0.22117888927459717,
      "learning_rate": 8.93265987934829e-06,
      "loss": 0.1024,
      "step": 6741
    },
    {
      "epoch": 0.10674984562281299,
      "grad_norm": 0.5101818442344666,
      "learning_rate": 8.932501543771871e-06,
      "loss": 0.3511,
      "step": 6742
    },
    {
      "epoch": 0.10676567918045506,
      "grad_norm": 0.24334579706192017,
      "learning_rate": 8.93234320819545e-06,
      "loss": 0.0748,
      "step": 6743
    },
    {
      "epoch": 0.10678151273809712,
      "grad_norm": 0.39356282353401184,
      "learning_rate": 8.93218487261903e-06,
      "loss": 0.374,
      "step": 6744
    },
    {
      "epoch": 0.10679734629573918,
      "grad_norm": 0.42397740483283997,
      "learning_rate": 8.932026537042609e-06,
      "loss": 0.4599,
      "step": 6745
    },
    {
      "epoch": 0.10681317985338126,
      "grad_norm": 0.13875114917755127,
      "learning_rate": 8.931868201466188e-06,
      "loss": 0.0232,
      "step": 6746
    },
    {
      "epoch": 0.10682901341102333,
      "grad_norm": 0.030131321400403976,
      "learning_rate": 8.931709865889767e-06,
      "loss": 0.0019,
      "step": 6747
    },
    {
      "epoch": 0.10684484696866539,
      "grad_norm": 0.03645646199584007,
      "learning_rate": 8.931551530313347e-06,
      "loss": 0.0022,
      "step": 6748
    },
    {
      "epoch": 0.10686068052630746,
      "grad_norm": 9.655940812081099e-05,
      "learning_rate": 8.931393194736927e-06,
      "loss": 0.0,
      "step": 6749
    },
    {
      "epoch": 0.10687651408394952,
      "grad_norm": 0.3128759264945984,
      "learning_rate": 8.931234859160506e-06,
      "loss": 0.2801,
      "step": 6750
    },
    {
      "epoch": 0.10689234764159158,
      "grad_norm": 0.386849045753479,
      "learning_rate": 8.931076523584085e-06,
      "loss": 0.1406,
      "step": 6751
    },
    {
      "epoch": 0.10690818119923366,
      "grad_norm": 0.0007351890671998262,
      "learning_rate": 8.930918188007664e-06,
      "loss": 0.0001,
      "step": 6752
    },
    {
      "epoch": 0.10692401475687573,
      "grad_norm": 0.6122233867645264,
      "learning_rate": 8.930759852431243e-06,
      "loss": 0.3449,
      "step": 6753
    },
    {
      "epoch": 0.10693984831451779,
      "grad_norm": 0.25144392251968384,
      "learning_rate": 8.930601516854824e-06,
      "loss": 0.1624,
      "step": 6754
    },
    {
      "epoch": 0.10695568187215986,
      "grad_norm": 0.136821448802948,
      "learning_rate": 8.930443181278403e-06,
      "loss": 0.0657,
      "step": 6755
    },
    {
      "epoch": 0.10697151542980192,
      "grad_norm": 0.21691446006298065,
      "learning_rate": 8.930284845701982e-06,
      "loss": 0.1128,
      "step": 6756
    },
    {
      "epoch": 0.10698734898744398,
      "grad_norm": 0.043724823743104935,
      "learning_rate": 8.930126510125561e-06,
      "loss": 0.0022,
      "step": 6757
    },
    {
      "epoch": 0.10700318254508606,
      "grad_norm": 0.27325868606567383,
      "learning_rate": 8.92996817454914e-06,
      "loss": 0.0958,
      "step": 6758
    },
    {
      "epoch": 0.10701901610272813,
      "grad_norm": 0.5901439189910889,
      "learning_rate": 8.929809838972719e-06,
      "loss": 0.0077,
      "step": 6759
    },
    {
      "epoch": 0.10703484966037019,
      "grad_norm": 0.30793634057044983,
      "learning_rate": 8.9296515033963e-06,
      "loss": 0.1403,
      "step": 6760
    },
    {
      "epoch": 0.10705068321801225,
      "grad_norm": 0.010775490663945675,
      "learning_rate": 8.929493167819879e-06,
      "loss": 0.0003,
      "step": 6761
    },
    {
      "epoch": 0.10706651677565432,
      "grad_norm": 0.0001841911143856123,
      "learning_rate": 8.929334832243456e-06,
      "loss": 0.0,
      "step": 6762
    },
    {
      "epoch": 0.10708235033329638,
      "grad_norm": 0.2667900621891022,
      "learning_rate": 8.929176496667037e-06,
      "loss": 0.1374,
      "step": 6763
    },
    {
      "epoch": 0.10709818389093846,
      "grad_norm": 6.567583477590233e-05,
      "learning_rate": 8.929018161090616e-06,
      "loss": 0.0,
      "step": 6764
    },
    {
      "epoch": 0.10711401744858053,
      "grad_norm": 0.18892230093479156,
      "learning_rate": 8.928859825514195e-06,
      "loss": 0.0337,
      "step": 6765
    },
    {
      "epoch": 0.10712985100622259,
      "grad_norm": 0.19781553745269775,
      "learning_rate": 8.928701489937774e-06,
      "loss": 0.0461,
      "step": 6766
    },
    {
      "epoch": 0.10714568456386465,
      "grad_norm": 0.5742936730384827,
      "learning_rate": 8.928543154361355e-06,
      "loss": 0.1128,
      "step": 6767
    },
    {
      "epoch": 0.10716151812150672,
      "grad_norm": 0.2765716016292572,
      "learning_rate": 8.928384818784932e-06,
      "loss": 0.1722,
      "step": 6768
    },
    {
      "epoch": 0.10717735167914878,
      "grad_norm": 0.0007729142671450973,
      "learning_rate": 8.928226483208513e-06,
      "loss": 0.0,
      "step": 6769
    },
    {
      "epoch": 0.10719318523679086,
      "grad_norm": 0.05085207521915436,
      "learning_rate": 8.928068147632092e-06,
      "loss": 0.002,
      "step": 6770
    },
    {
      "epoch": 0.10720901879443293,
      "grad_norm": 0.009564503096044064,
      "learning_rate": 8.927909812055671e-06,
      "loss": 0.0005,
      "step": 6771
    },
    {
      "epoch": 0.10722485235207499,
      "grad_norm": 0.4008844196796417,
      "learning_rate": 8.92775147647925e-06,
      "loss": 0.2631,
      "step": 6772
    },
    {
      "epoch": 0.10724068590971705,
      "grad_norm": 0.031868431717157364,
      "learning_rate": 8.927593140902831e-06,
      "loss": 0.0018,
      "step": 6773
    },
    {
      "epoch": 0.10725651946735912,
      "grad_norm": 0.4390951097011566,
      "learning_rate": 8.927434805326409e-06,
      "loss": 0.5611,
      "step": 6774
    },
    {
      "epoch": 0.10727235302500118,
      "grad_norm": 0.20952017605304718,
      "learning_rate": 8.92727646974999e-06,
      "loss": 0.0906,
      "step": 6775
    },
    {
      "epoch": 0.10728818658264326,
      "grad_norm": 0.28282520174980164,
      "learning_rate": 8.927118134173568e-06,
      "loss": 0.6373,
      "step": 6776
    },
    {
      "epoch": 0.10730402014028532,
      "grad_norm": 2.1102703612996265e-05,
      "learning_rate": 8.926959798597148e-06,
      "loss": 0.0,
      "step": 6777
    },
    {
      "epoch": 0.10731985369792739,
      "grad_norm": 0.22667375206947327,
      "learning_rate": 8.926801463020727e-06,
      "loss": 0.007,
      "step": 6778
    },
    {
      "epoch": 0.10733568725556945,
      "grad_norm": 0.03940612077713013,
      "learning_rate": 8.926643127444307e-06,
      "loss": 0.0029,
      "step": 6779
    },
    {
      "epoch": 0.10735152081321152,
      "grad_norm": 1.3434451818466187,
      "learning_rate": 8.926484791867885e-06,
      "loss": 0.1442,
      "step": 6780
    },
    {
      "epoch": 0.10736735437085358,
      "grad_norm": 0.00887878704816103,
      "learning_rate": 8.926326456291466e-06,
      "loss": 0.0004,
      "step": 6781
    },
    {
      "epoch": 0.10738318792849566,
      "grad_norm": 0.24659770727157593,
      "learning_rate": 8.926168120715045e-06,
      "loss": 0.0075,
      "step": 6782
    },
    {
      "epoch": 0.10739902148613772,
      "grad_norm": 0.35467347502708435,
      "learning_rate": 8.926009785138624e-06,
      "loss": 0.0234,
      "step": 6783
    },
    {
      "epoch": 0.10741485504377979,
      "grad_norm": 0.6480320692062378,
      "learning_rate": 8.925851449562203e-06,
      "loss": 0.13,
      "step": 6784
    },
    {
      "epoch": 0.10743068860142185,
      "grad_norm": 0.45055675506591797,
      "learning_rate": 8.925693113985782e-06,
      "loss": 0.0795,
      "step": 6785
    },
    {
      "epoch": 0.10744652215906392,
      "grad_norm": 0.016275322064757347,
      "learning_rate": 8.925534778409361e-06,
      "loss": 0.0009,
      "step": 6786
    },
    {
      "epoch": 0.10746235571670598,
      "grad_norm": 0.17449887096881866,
      "learning_rate": 8.92537644283294e-06,
      "loss": 0.0805,
      "step": 6787
    },
    {
      "epoch": 0.10747818927434806,
      "grad_norm": 0.2703951597213745,
      "learning_rate": 8.92521810725652e-06,
      "loss": 0.0736,
      "step": 6788
    },
    {
      "epoch": 0.10749402283199012,
      "grad_norm": 0.01821259595453739,
      "learning_rate": 8.9250597716801e-06,
      "loss": 0.0009,
      "step": 6789
    },
    {
      "epoch": 0.10750985638963219,
      "grad_norm": 0.01878538355231285,
      "learning_rate": 8.924901436103679e-06,
      "loss": 0.001,
      "step": 6790
    },
    {
      "epoch": 0.10752568994727425,
      "grad_norm": 0.1587931215763092,
      "learning_rate": 8.924743100527258e-06,
      "loss": 0.046,
      "step": 6791
    },
    {
      "epoch": 0.10754152350491632,
      "grad_norm": 0.0006336323567666113,
      "learning_rate": 8.924584764950837e-06,
      "loss": 0.0,
      "step": 6792
    },
    {
      "epoch": 0.10755735706255838,
      "grad_norm": 0.2171107977628708,
      "learning_rate": 8.924426429374416e-06,
      "loss": 0.0048,
      "step": 6793
    },
    {
      "epoch": 0.10757319062020046,
      "grad_norm": 0.16589663922786713,
      "learning_rate": 8.924268093797997e-06,
      "loss": 0.1119,
      "step": 6794
    },
    {
      "epoch": 0.10758902417784252,
      "grad_norm": 0.5046569108963013,
      "learning_rate": 8.924109758221576e-06,
      "loss": 0.5851,
      "step": 6795
    },
    {
      "epoch": 0.10760485773548459,
      "grad_norm": 0.2587627172470093,
      "learning_rate": 8.923951422645155e-06,
      "loss": 0.1015,
      "step": 6796
    },
    {
      "epoch": 0.10762069129312665,
      "grad_norm": 0.39626166224479675,
      "learning_rate": 8.923793087068734e-06,
      "loss": 0.7416,
      "step": 6797
    },
    {
      "epoch": 0.10763652485076872,
      "grad_norm": 0.1390926092863083,
      "learning_rate": 8.923634751492313e-06,
      "loss": 0.0579,
      "step": 6798
    },
    {
      "epoch": 0.10765235840841078,
      "grad_norm": 0.4855715036392212,
      "learning_rate": 8.923476415915892e-06,
      "loss": 0.019,
      "step": 6799
    },
    {
      "epoch": 0.10766819196605286,
      "grad_norm": 0.00017743765783961862,
      "learning_rate": 8.923318080339473e-06,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 0.10768402552369492,
      "grad_norm": 0.30695176124572754,
      "learning_rate": 8.92315974476305e-06,
      "loss": 0.1182,
      "step": 6801
    },
    {
      "epoch": 0.10769985908133699,
      "grad_norm": 0.29050371050834656,
      "learning_rate": 8.923001409186631e-06,
      "loss": 0.3538,
      "step": 6802
    },
    {
      "epoch": 0.10771569263897905,
      "grad_norm": 0.6136249303817749,
      "learning_rate": 8.92284307361021e-06,
      "loss": 0.149,
      "step": 6803
    },
    {
      "epoch": 0.10773152619662112,
      "grad_norm": 0.29736995697021484,
      "learning_rate": 8.92268473803379e-06,
      "loss": 0.2627,
      "step": 6804
    },
    {
      "epoch": 0.10774735975426318,
      "grad_norm": 0.19315031170845032,
      "learning_rate": 8.922526402457369e-06,
      "loss": 0.0827,
      "step": 6805
    },
    {
      "epoch": 0.10776319331190526,
      "grad_norm": 0.37572869658470154,
      "learning_rate": 8.92236806688095e-06,
      "loss": 0.3886,
      "step": 6806
    },
    {
      "epoch": 0.10777902686954732,
      "grad_norm": 0.4481651484966278,
      "learning_rate": 8.922209731304527e-06,
      "loss": 0.4979,
      "step": 6807
    },
    {
      "epoch": 0.10779486042718939,
      "grad_norm": 0.3198331892490387,
      "learning_rate": 8.922051395728107e-06,
      "loss": 0.0342,
      "step": 6808
    },
    {
      "epoch": 0.10781069398483145,
      "grad_norm": 0.0199113879352808,
      "learning_rate": 8.921893060151687e-06,
      "loss": 0.001,
      "step": 6809
    },
    {
      "epoch": 0.10782652754247352,
      "grad_norm": 0.00020002310338895768,
      "learning_rate": 8.921734724575266e-06,
      "loss": 0.0,
      "step": 6810
    },
    {
      "epoch": 0.10784236110011558,
      "grad_norm": 0.015633977949619293,
      "learning_rate": 8.921576388998845e-06,
      "loss": 0.0002,
      "step": 6811
    },
    {
      "epoch": 0.10785819465775766,
      "grad_norm": 0.6311742067337036,
      "learning_rate": 8.921418053422424e-06,
      "loss": 0.2439,
      "step": 6812
    },
    {
      "epoch": 0.10787402821539972,
      "grad_norm": 0.9596884846687317,
      "learning_rate": 8.921259717846003e-06,
      "loss": 0.1137,
      "step": 6813
    },
    {
      "epoch": 0.10788986177304179,
      "grad_norm": 0.658647358417511,
      "learning_rate": 8.921101382269582e-06,
      "loss": 0.3601,
      "step": 6814
    },
    {
      "epoch": 0.10790569533068385,
      "grad_norm": 0.4997839629650116,
      "learning_rate": 8.920943046693163e-06,
      "loss": 0.4211,
      "step": 6815
    },
    {
      "epoch": 0.10792152888832592,
      "grad_norm": 0.5533300638198853,
      "learning_rate": 8.920784711116742e-06,
      "loss": 1.0122,
      "step": 6816
    },
    {
      "epoch": 0.10793736244596798,
      "grad_norm": 0.49071216583251953,
      "learning_rate": 8.920626375540321e-06,
      "loss": 0.1554,
      "step": 6817
    },
    {
      "epoch": 0.10795319600361006,
      "grad_norm": 0.22891034185886383,
      "learning_rate": 8.9204680399639e-06,
      "loss": 0.2253,
      "step": 6818
    },
    {
      "epoch": 0.10796902956125212,
      "grad_norm": 0.22431719303131104,
      "learning_rate": 8.920309704387479e-06,
      "loss": 0.1357,
      "step": 6819
    },
    {
      "epoch": 0.10798486311889419,
      "grad_norm": 0.030808407813310623,
      "learning_rate": 8.920151368811058e-06,
      "loss": 0.0018,
      "step": 6820
    },
    {
      "epoch": 0.10800069667653625,
      "grad_norm": 0.49804919958114624,
      "learning_rate": 8.919993033234639e-06,
      "loss": 0.431,
      "step": 6821
    },
    {
      "epoch": 0.10801653023417832,
      "grad_norm": 0.42335590720176697,
      "learning_rate": 8.919834697658218e-06,
      "loss": 0.0535,
      "step": 6822
    },
    {
      "epoch": 0.10803236379182038,
      "grad_norm": 0.046683184802532196,
      "learning_rate": 8.919676362081797e-06,
      "loss": 0.004,
      "step": 6823
    },
    {
      "epoch": 0.10804819734946246,
      "grad_norm": 0.48404306173324585,
      "learning_rate": 8.919518026505376e-06,
      "loss": 0.0514,
      "step": 6824
    },
    {
      "epoch": 0.10806403090710452,
      "grad_norm": 0.06842531263828278,
      "learning_rate": 8.919359690928955e-06,
      "loss": 0.0027,
      "step": 6825
    },
    {
      "epoch": 0.10807986446474659,
      "grad_norm": 9.755175415193662e-05,
      "learning_rate": 8.919201355352534e-06,
      "loss": 0.0,
      "step": 6826
    },
    {
      "epoch": 0.10809569802238865,
      "grad_norm": 0.03220377862453461,
      "learning_rate": 8.919043019776115e-06,
      "loss": 0.0018,
      "step": 6827
    },
    {
      "epoch": 0.10811153158003071,
      "grad_norm": 0.27158844470977783,
      "learning_rate": 8.918884684199694e-06,
      "loss": 0.1194,
      "step": 6828
    },
    {
      "epoch": 0.10812736513767278,
      "grad_norm": 0.3047063648700714,
      "learning_rate": 8.918726348623273e-06,
      "loss": 0.1511,
      "step": 6829
    },
    {
      "epoch": 0.10814319869531486,
      "grad_norm": 0.5574204921722412,
      "learning_rate": 8.918568013046852e-06,
      "loss": 0.0565,
      "step": 6830
    },
    {
      "epoch": 0.10815903225295692,
      "grad_norm": 0.1876642256975174,
      "learning_rate": 8.918409677470431e-06,
      "loss": 0.0674,
      "step": 6831
    },
    {
      "epoch": 0.10817486581059899,
      "grad_norm": 0.3568030595779419,
      "learning_rate": 8.91825134189401e-06,
      "loss": 0.2995,
      "step": 6832
    },
    {
      "epoch": 0.10819069936824105,
      "grad_norm": 0.19638870656490326,
      "learning_rate": 8.91809300631759e-06,
      "loss": 0.0904,
      "step": 6833
    },
    {
      "epoch": 0.10820653292588311,
      "grad_norm": 0.01728522777557373,
      "learning_rate": 8.91793467074117e-06,
      "loss": 0.0004,
      "step": 6834
    },
    {
      "epoch": 0.10822236648352518,
      "grad_norm": 0.18610481917858124,
      "learning_rate": 8.917776335164748e-06,
      "loss": 0.0708,
      "step": 6835
    },
    {
      "epoch": 0.10823820004116726,
      "grad_norm": 0.4515998363494873,
      "learning_rate": 8.917617999588328e-06,
      "loss": 0.2849,
      "step": 6836
    },
    {
      "epoch": 0.10825403359880932,
      "grad_norm": 0.22720472514629364,
      "learning_rate": 8.917459664011908e-06,
      "loss": 0.0631,
      "step": 6837
    },
    {
      "epoch": 0.10826986715645139,
      "grad_norm": 0.31792956590652466,
      "learning_rate": 8.917301328435487e-06,
      "loss": 0.5175,
      "step": 6838
    },
    {
      "epoch": 0.10828570071409345,
      "grad_norm": 0.19177104532718658,
      "learning_rate": 8.917142992859066e-06,
      "loss": 0.098,
      "step": 6839
    },
    {
      "epoch": 0.10830153427173551,
      "grad_norm": 0.00010020247282227501,
      "learning_rate": 8.916984657282646e-06,
      "loss": 0.0,
      "step": 6840
    },
    {
      "epoch": 0.10831736782937758,
      "grad_norm": 0.006795153021812439,
      "learning_rate": 8.916826321706224e-06,
      "loss": 0.0003,
      "step": 6841
    },
    {
      "epoch": 0.10833320138701964,
      "grad_norm": 0.25129401683807373,
      "learning_rate": 8.916667986129805e-06,
      "loss": 0.0478,
      "step": 6842
    },
    {
      "epoch": 0.10834903494466172,
      "grad_norm": 0.3354836106300354,
      "learning_rate": 8.916509650553384e-06,
      "loss": 0.31,
      "step": 6843
    },
    {
      "epoch": 0.10836486850230378,
      "grad_norm": 0.18960988521575928,
      "learning_rate": 8.916351314976963e-06,
      "loss": 0.0868,
      "step": 6844
    },
    {
      "epoch": 0.10838070205994585,
      "grad_norm": 0.22736811637878418,
      "learning_rate": 8.916192979400542e-06,
      "loss": 0.0114,
      "step": 6845
    },
    {
      "epoch": 0.10839653561758791,
      "grad_norm": 0.337001234292984,
      "learning_rate": 8.916034643824123e-06,
      "loss": 0.0988,
      "step": 6846
    },
    {
      "epoch": 0.10841236917522998,
      "grad_norm": 0.4524233043193817,
      "learning_rate": 8.9158763082477e-06,
      "loss": 0.081,
      "step": 6847
    },
    {
      "epoch": 0.10842820273287204,
      "grad_norm": 0.07217478007078171,
      "learning_rate": 8.91571797267128e-06,
      "loss": 0.0028,
      "step": 6848
    },
    {
      "epoch": 0.10844403629051412,
      "grad_norm": 0.028645101934671402,
      "learning_rate": 8.91555963709486e-06,
      "loss": 0.0016,
      "step": 6849
    },
    {
      "epoch": 0.10845986984815618,
      "grad_norm": 0.30065953731536865,
      "learning_rate": 8.915401301518439e-06,
      "loss": 0.1565,
      "step": 6850
    },
    {
      "epoch": 0.10847570340579825,
      "grad_norm": 0.773141086101532,
      "learning_rate": 8.915242965942018e-06,
      "loss": 0.6453,
      "step": 6851
    },
    {
      "epoch": 0.10849153696344031,
      "grad_norm": 0.6109775304794312,
      "learning_rate": 8.915084630365599e-06,
      "loss": 0.1269,
      "step": 6852
    },
    {
      "epoch": 0.10850737052108238,
      "grad_norm": 0.2028496116399765,
      "learning_rate": 8.914926294789176e-06,
      "loss": 0.0487,
      "step": 6853
    },
    {
      "epoch": 0.10852320407872444,
      "grad_norm": 0.20913143455982208,
      "learning_rate": 8.914767959212757e-06,
      "loss": 0.0645,
      "step": 6854
    },
    {
      "epoch": 0.10853903763636652,
      "grad_norm": 0.15875568985939026,
      "learning_rate": 8.914609623636336e-06,
      "loss": 0.0631,
      "step": 6855
    },
    {
      "epoch": 0.10855487119400858,
      "grad_norm": 0.45819878578186035,
      "learning_rate": 8.914451288059915e-06,
      "loss": 0.2461,
      "step": 6856
    },
    {
      "epoch": 0.10857070475165065,
      "grad_norm": 0.13873226940631866,
      "learning_rate": 8.914292952483494e-06,
      "loss": 0.0431,
      "step": 6857
    },
    {
      "epoch": 0.10858653830929271,
      "grad_norm": 0.7889082431793213,
      "learning_rate": 8.914134616907073e-06,
      "loss": 0.113,
      "step": 6858
    },
    {
      "epoch": 0.10860237186693478,
      "grad_norm": 0.02601751498878002,
      "learning_rate": 8.913976281330652e-06,
      "loss": 0.0013,
      "step": 6859
    },
    {
      "epoch": 0.10861820542457684,
      "grad_norm": 0.001089943922124803,
      "learning_rate": 8.913817945754231e-06,
      "loss": 0.0,
      "step": 6860
    },
    {
      "epoch": 0.10863403898221892,
      "grad_norm": 0.33528226613998413,
      "learning_rate": 8.913659610177812e-06,
      "loss": 0.1905,
      "step": 6861
    },
    {
      "epoch": 0.10864987253986098,
      "grad_norm": 0.1506572961807251,
      "learning_rate": 8.913501274601391e-06,
      "loss": 0.0494,
      "step": 6862
    },
    {
      "epoch": 0.10866570609750305,
      "grad_norm": 0.21827110648155212,
      "learning_rate": 8.91334293902497e-06,
      "loss": 0.0499,
      "step": 6863
    },
    {
      "epoch": 0.10868153965514511,
      "grad_norm": 0.0003351521154399961,
      "learning_rate": 8.91318460344855e-06,
      "loss": 0.0,
      "step": 6864
    },
    {
      "epoch": 0.10869737321278718,
      "grad_norm": 0.034552332013845444,
      "learning_rate": 8.913026267872129e-06,
      "loss": 0.002,
      "step": 6865
    },
    {
      "epoch": 0.10871320677042924,
      "grad_norm": 0.00013034044241067022,
      "learning_rate": 8.912867932295708e-06,
      "loss": 0.0,
      "step": 6866
    },
    {
      "epoch": 0.10872904032807132,
      "grad_norm": 0.6354120373725891,
      "learning_rate": 8.912709596719288e-06,
      "loss": 0.2487,
      "step": 6867
    },
    {
      "epoch": 0.10874487388571338,
      "grad_norm": 0.21931219100952148,
      "learning_rate": 8.912551261142866e-06,
      "loss": 0.0504,
      "step": 6868
    },
    {
      "epoch": 0.10876070744335545,
      "grad_norm": 0.31282347440719604,
      "learning_rate": 8.912392925566447e-06,
      "loss": 0.6033,
      "step": 6869
    },
    {
      "epoch": 0.10877654100099751,
      "grad_norm": 0.48124074935913086,
      "learning_rate": 8.912234589990026e-06,
      "loss": 0.3203,
      "step": 6870
    },
    {
      "epoch": 0.10879237455863958,
      "grad_norm": 1.000041127204895,
      "learning_rate": 8.912076254413605e-06,
      "loss": 0.2964,
      "step": 6871
    },
    {
      "epoch": 0.10880820811628164,
      "grad_norm": 0.0002956062962766737,
      "learning_rate": 8.911917918837184e-06,
      "loss": 0.0,
      "step": 6872
    },
    {
      "epoch": 0.10882404167392372,
      "grad_norm": 0.4929989278316498,
      "learning_rate": 8.911759583260765e-06,
      "loss": 0.2376,
      "step": 6873
    },
    {
      "epoch": 0.10883987523156578,
      "grad_norm": 0.39714232087135315,
      "learning_rate": 8.911601247684342e-06,
      "loss": 0.113,
      "step": 6874
    },
    {
      "epoch": 0.10885570878920785,
      "grad_norm": 0.2472998946905136,
      "learning_rate": 8.911442912107923e-06,
      "loss": 0.1243,
      "step": 6875
    },
    {
      "epoch": 0.10887154234684991,
      "grad_norm": 0.10099094361066818,
      "learning_rate": 8.911284576531502e-06,
      "loss": 0.0019,
      "step": 6876
    },
    {
      "epoch": 0.10888737590449198,
      "grad_norm": 0.44783392548561096,
      "learning_rate": 8.911126240955081e-06,
      "loss": 0.4572,
      "step": 6877
    },
    {
      "epoch": 0.10890320946213404,
      "grad_norm": 0.0005662132753059268,
      "learning_rate": 8.91096790537866e-06,
      "loss": 0.0,
      "step": 6878
    },
    {
      "epoch": 0.10891904301977612,
      "grad_norm": 0.2837323248386383,
      "learning_rate": 8.91080956980224e-06,
      "loss": 0.0828,
      "step": 6879
    },
    {
      "epoch": 0.10893487657741818,
      "grad_norm": 0.22285571694374084,
      "learning_rate": 8.910651234225818e-06,
      "loss": 0.0589,
      "step": 6880
    },
    {
      "epoch": 0.10895071013506025,
      "grad_norm": 0.31410637497901917,
      "learning_rate": 8.910492898649399e-06,
      "loss": 0.1455,
      "step": 6881
    },
    {
      "epoch": 0.10896654369270231,
      "grad_norm": 0.2695140540599823,
      "learning_rate": 8.910334563072978e-06,
      "loss": 0.2958,
      "step": 6882
    },
    {
      "epoch": 0.10898237725034438,
      "grad_norm": 0.19269941747188568,
      "learning_rate": 8.910176227496557e-06,
      "loss": 0.0991,
      "step": 6883
    },
    {
      "epoch": 0.10899821080798644,
      "grad_norm": 0.016251733526587486,
      "learning_rate": 8.910017891920136e-06,
      "loss": 0.0009,
      "step": 6884
    },
    {
      "epoch": 0.10901404436562852,
      "grad_norm": 0.4852226674556732,
      "learning_rate": 8.909859556343715e-06,
      "loss": 0.3601,
      "step": 6885
    },
    {
      "epoch": 0.10902987792327058,
      "grad_norm": 0.5460600852966309,
      "learning_rate": 8.909701220767294e-06,
      "loss": 0.6641,
      "step": 6886
    },
    {
      "epoch": 0.10904571148091265,
      "grad_norm": 0.12502430379390717,
      "learning_rate": 8.909542885190873e-06,
      "loss": 0.0085,
      "step": 6887
    },
    {
      "epoch": 0.10906154503855471,
      "grad_norm": 0.973433792591095,
      "learning_rate": 8.909384549614454e-06,
      "loss": 0.1624,
      "step": 6888
    },
    {
      "epoch": 0.10907737859619678,
      "grad_norm": 0.35581615567207336,
      "learning_rate": 8.909226214038033e-06,
      "loss": 0.123,
      "step": 6889
    },
    {
      "epoch": 0.10909321215383884,
      "grad_norm": 0.7620685696601868,
      "learning_rate": 8.909067878461612e-06,
      "loss": 0.3853,
      "step": 6890
    },
    {
      "epoch": 0.10910904571148092,
      "grad_norm": 0.36021193861961365,
      "learning_rate": 8.908909542885191e-06,
      "loss": 0.3322,
      "step": 6891
    },
    {
      "epoch": 0.10912487926912298,
      "grad_norm": 0.3628001809120178,
      "learning_rate": 8.90875120730877e-06,
      "loss": 0.4532,
      "step": 6892
    },
    {
      "epoch": 0.10914071282676505,
      "grad_norm": 0.18528369069099426,
      "learning_rate": 8.90859287173235e-06,
      "loss": 0.0788,
      "step": 6893
    },
    {
      "epoch": 0.10915654638440711,
      "grad_norm": 0.29989612102508545,
      "learning_rate": 8.90843453615593e-06,
      "loss": 0.2718,
      "step": 6894
    },
    {
      "epoch": 0.10917237994204917,
      "grad_norm": 0.1822485625743866,
      "learning_rate": 8.90827620057951e-06,
      "loss": 0.1435,
      "step": 6895
    },
    {
      "epoch": 0.10918821349969124,
      "grad_norm": 0.3527382016181946,
      "learning_rate": 8.908117865003088e-06,
      "loss": 0.236,
      "step": 6896
    },
    {
      "epoch": 0.10920404705733332,
      "grad_norm": 0.007853522896766663,
      "learning_rate": 8.907959529426668e-06,
      "loss": 0.0003,
      "step": 6897
    },
    {
      "epoch": 0.10921988061497538,
      "grad_norm": 0.021018540486693382,
      "learning_rate": 8.907801193850247e-06,
      "loss": 0.0012,
      "step": 6898
    },
    {
      "epoch": 0.10923571417261745,
      "grad_norm": 0.20421847701072693,
      "learning_rate": 8.907642858273826e-06,
      "loss": 0.0036,
      "step": 6899
    },
    {
      "epoch": 0.10925154773025951,
      "grad_norm": 0.0017311389092355967,
      "learning_rate": 8.907484522697407e-06,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 0.10926738128790157,
      "grad_norm": 0.22835484147071838,
      "learning_rate": 8.907326187120986e-06,
      "loss": 0.0795,
      "step": 6901
    },
    {
      "epoch": 0.10928321484554364,
      "grad_norm": 0.024142447859048843,
      "learning_rate": 8.907167851544565e-06,
      "loss": 0.0014,
      "step": 6902
    },
    {
      "epoch": 0.10929904840318572,
      "grad_norm": 0.0005558072007261217,
      "learning_rate": 8.907009515968144e-06,
      "loss": 0.0,
      "step": 6903
    },
    {
      "epoch": 0.10931488196082778,
      "grad_norm": 0.11679471284151077,
      "learning_rate": 8.906851180391723e-06,
      "loss": 0.0023,
      "step": 6904
    },
    {
      "epoch": 0.10933071551846985,
      "grad_norm": 0.23714099824428558,
      "learning_rate": 8.906692844815302e-06,
      "loss": 0.1028,
      "step": 6905
    },
    {
      "epoch": 0.10934654907611191,
      "grad_norm": 0.0002587309863884002,
      "learning_rate": 8.906534509238881e-06,
      "loss": 0.0,
      "step": 6906
    },
    {
      "epoch": 0.10936238263375397,
      "grad_norm": 0.3093526363372803,
      "learning_rate": 8.906376173662462e-06,
      "loss": 0.1937,
      "step": 6907
    },
    {
      "epoch": 0.10937821619139604,
      "grad_norm": 0.39053624868392944,
      "learning_rate": 8.906217838086039e-06,
      "loss": 0.0812,
      "step": 6908
    },
    {
      "epoch": 0.10939404974903812,
      "grad_norm": 0.20585545897483826,
      "learning_rate": 8.90605950250962e-06,
      "loss": 0.0974,
      "step": 6909
    },
    {
      "epoch": 0.10940988330668018,
      "grad_norm": 0.31127506494522095,
      "learning_rate": 8.905901166933199e-06,
      "loss": 0.1023,
      "step": 6910
    },
    {
      "epoch": 0.10942571686432224,
      "grad_norm": 0.34167230129241943,
      "learning_rate": 8.905742831356778e-06,
      "loss": 0.127,
      "step": 6911
    },
    {
      "epoch": 0.10944155042196431,
      "grad_norm": 0.4286126494407654,
      "learning_rate": 8.905584495780357e-06,
      "loss": 0.5232,
      "step": 6912
    },
    {
      "epoch": 0.10945738397960637,
      "grad_norm": 0.24816089868545532,
      "learning_rate": 8.905426160203938e-06,
      "loss": 0.0615,
      "step": 6913
    },
    {
      "epoch": 0.10947321753724844,
      "grad_norm": 0.03957192972302437,
      "learning_rate": 8.905267824627515e-06,
      "loss": 0.0023,
      "step": 6914
    },
    {
      "epoch": 0.10948905109489052,
      "grad_norm": 0.7632730603218079,
      "learning_rate": 8.905109489051096e-06,
      "loss": 0.6215,
      "step": 6915
    },
    {
      "epoch": 0.10950488465253258,
      "grad_norm": 0.4314371943473816,
      "learning_rate": 8.904951153474675e-06,
      "loss": 0.1111,
      "step": 6916
    },
    {
      "epoch": 0.10952071821017464,
      "grad_norm": 0.24503222107887268,
      "learning_rate": 8.904792817898254e-06,
      "loss": 0.118,
      "step": 6917
    },
    {
      "epoch": 0.10953655176781671,
      "grad_norm": 0.37519699335098267,
      "learning_rate": 8.904634482321833e-06,
      "loss": 0.24,
      "step": 6918
    },
    {
      "epoch": 0.10955238532545877,
      "grad_norm": 0.2644384801387787,
      "learning_rate": 8.904476146745414e-06,
      "loss": 0.1103,
      "step": 6919
    },
    {
      "epoch": 0.10956821888310084,
      "grad_norm": 0.5887815356254578,
      "learning_rate": 8.904317811168991e-06,
      "loss": 0.6517,
      "step": 6920
    },
    {
      "epoch": 0.10958405244074292,
      "grad_norm": 0.12441497296094894,
      "learning_rate": 8.904159475592572e-06,
      "loss": 0.0398,
      "step": 6921
    },
    {
      "epoch": 0.10959988599838498,
      "grad_norm": 0.410564661026001,
      "learning_rate": 8.904001140016151e-06,
      "loss": 0.2643,
      "step": 6922
    },
    {
      "epoch": 0.10961571955602704,
      "grad_norm": 0.416171669960022,
      "learning_rate": 8.90384280443973e-06,
      "loss": 0.0733,
      "step": 6923
    },
    {
      "epoch": 0.10963155311366911,
      "grad_norm": 0.00022984127281233668,
      "learning_rate": 8.90368446886331e-06,
      "loss": 0.0,
      "step": 6924
    },
    {
      "epoch": 0.10964738667131117,
      "grad_norm": 0.3698318600654602,
      "learning_rate": 8.903526133286889e-06,
      "loss": 0.1785,
      "step": 6925
    },
    {
      "epoch": 0.10966322022895324,
      "grad_norm": 0.32379353046417236,
      "learning_rate": 8.903367797710468e-06,
      "loss": 0.436,
      "step": 6926
    },
    {
      "epoch": 0.10967905378659532,
      "grad_norm": 0.021746143698692322,
      "learning_rate": 8.903209462134048e-06,
      "loss": 0.0017,
      "step": 6927
    },
    {
      "epoch": 0.10969488734423738,
      "grad_norm": 0.4286773204803467,
      "learning_rate": 8.903051126557628e-06,
      "loss": 0.07,
      "step": 6928
    },
    {
      "epoch": 0.10971072090187944,
      "grad_norm": 0.6502350568771362,
      "learning_rate": 8.902892790981207e-06,
      "loss": 0.2793,
      "step": 6929
    },
    {
      "epoch": 0.10972655445952151,
      "grad_norm": 0.3888164758682251,
      "learning_rate": 8.902734455404786e-06,
      "loss": 0.2006,
      "step": 6930
    },
    {
      "epoch": 0.10974238801716357,
      "grad_norm": 0.1971094012260437,
      "learning_rate": 8.902576119828365e-06,
      "loss": 0.0538,
      "step": 6931
    },
    {
      "epoch": 0.10975822157480564,
      "grad_norm": 0.3939545154571533,
      "learning_rate": 8.902417784251944e-06,
      "loss": 0.1552,
      "step": 6932
    },
    {
      "epoch": 0.10977405513244771,
      "grad_norm": 0.5450108647346497,
      "learning_rate": 8.902259448675523e-06,
      "loss": 0.0182,
      "step": 6933
    },
    {
      "epoch": 0.10978988869008978,
      "grad_norm": 0.2484874129295349,
      "learning_rate": 8.902101113099104e-06,
      "loss": 0.0576,
      "step": 6934
    },
    {
      "epoch": 0.10980572224773184,
      "grad_norm": 0.028535520657896996,
      "learning_rate": 8.901942777522681e-06,
      "loss": 0.0016,
      "step": 6935
    },
    {
      "epoch": 0.10982155580537391,
      "grad_norm": 0.3277340531349182,
      "learning_rate": 8.901784441946262e-06,
      "loss": 0.1799,
      "step": 6936
    },
    {
      "epoch": 0.10983738936301597,
      "grad_norm": 1.5917786359786987,
      "learning_rate": 8.901626106369841e-06,
      "loss": 0.2681,
      "step": 6937
    },
    {
      "epoch": 0.10985322292065804,
      "grad_norm": 0.0006476292619481683,
      "learning_rate": 8.90146777079342e-06,
      "loss": 0.0,
      "step": 6938
    },
    {
      "epoch": 0.10986905647830011,
      "grad_norm": 0.36246827244758606,
      "learning_rate": 8.901309435216999e-06,
      "loss": 0.4975,
      "step": 6939
    },
    {
      "epoch": 0.10988489003594218,
      "grad_norm": 0.07319879531860352,
      "learning_rate": 8.90115109964058e-06,
      "loss": 0.003,
      "step": 6940
    },
    {
      "epoch": 0.10990072359358424,
      "grad_norm": 0.21120290458202362,
      "learning_rate": 8.900992764064157e-06,
      "loss": 0.0562,
      "step": 6941
    },
    {
      "epoch": 0.10991655715122631,
      "grad_norm": 0.007535711862146854,
      "learning_rate": 8.900834428487738e-06,
      "loss": 0.0004,
      "step": 6942
    },
    {
      "epoch": 0.10993239070886837,
      "grad_norm": 0.32159966230392456,
      "learning_rate": 8.900676092911317e-06,
      "loss": 0.0432,
      "step": 6943
    },
    {
      "epoch": 0.10994822426651044,
      "grad_norm": 0.5700368881225586,
      "learning_rate": 8.900517757334896e-06,
      "loss": 0.6993,
      "step": 6944
    },
    {
      "epoch": 0.10996405782415251,
      "grad_norm": 0.3410378694534302,
      "learning_rate": 8.900359421758475e-06,
      "loss": 0.325,
      "step": 6945
    },
    {
      "epoch": 0.10997989138179458,
      "grad_norm": 0.3149202764034271,
      "learning_rate": 8.900201086182056e-06,
      "loss": 0.3582,
      "step": 6946
    },
    {
      "epoch": 0.10999572493943664,
      "grad_norm": 0.16030773520469666,
      "learning_rate": 8.900042750605633e-06,
      "loss": 0.0385,
      "step": 6947
    },
    {
      "epoch": 0.1100115584970787,
      "grad_norm": 0.6037896275520325,
      "learning_rate": 8.899884415029214e-06,
      "loss": 0.2021,
      "step": 6948
    },
    {
      "epoch": 0.11002739205472077,
      "grad_norm": 0.13030050694942474,
      "learning_rate": 8.899726079452793e-06,
      "loss": 0.0076,
      "step": 6949
    },
    {
      "epoch": 0.11004322561236284,
      "grad_norm": 0.2245105355978012,
      "learning_rate": 8.899567743876372e-06,
      "loss": 0.0246,
      "step": 6950
    },
    {
      "epoch": 0.11005905917000491,
      "grad_norm": 0.25877079367637634,
      "learning_rate": 8.899409408299951e-06,
      "loss": 0.0545,
      "step": 6951
    },
    {
      "epoch": 0.11007489272764698,
      "grad_norm": 0.23110511898994446,
      "learning_rate": 8.899251072723532e-06,
      "loss": 0.0818,
      "step": 6952
    },
    {
      "epoch": 0.11009072628528904,
      "grad_norm": 0.23018892109394073,
      "learning_rate": 8.89909273714711e-06,
      "loss": 0.0819,
      "step": 6953
    },
    {
      "epoch": 0.1101065598429311,
      "grad_norm": 0.23460781574249268,
      "learning_rate": 8.898934401570689e-06,
      "loss": 0.0476,
      "step": 6954
    },
    {
      "epoch": 0.11012239340057317,
      "grad_norm": 0.3368208408355713,
      "learning_rate": 8.89877606599427e-06,
      "loss": 0.1129,
      "step": 6955
    },
    {
      "epoch": 0.11013822695821524,
      "grad_norm": 0.2245928943157196,
      "learning_rate": 8.898617730417849e-06,
      "loss": 0.0721,
      "step": 6956
    },
    {
      "epoch": 0.11015406051585731,
      "grad_norm": 0.058581821620464325,
      "learning_rate": 8.898459394841428e-06,
      "loss": 0.0062,
      "step": 6957
    },
    {
      "epoch": 0.11016989407349938,
      "grad_norm": 0.02568196691572666,
      "learning_rate": 8.898301059265007e-06,
      "loss": 0.0016,
      "step": 6958
    },
    {
      "epoch": 0.11018572763114144,
      "grad_norm": 0.008698060177266598,
      "learning_rate": 8.898142723688586e-06,
      "loss": 0.0005,
      "step": 6959
    },
    {
      "epoch": 0.1102015611887835,
      "grad_norm": 0.2539716362953186,
      "learning_rate": 8.897984388112165e-06,
      "loss": 0.232,
      "step": 6960
    },
    {
      "epoch": 0.11021739474642557,
      "grad_norm": 0.599755048751831,
      "learning_rate": 8.897826052535746e-06,
      "loss": 0.0753,
      "step": 6961
    },
    {
      "epoch": 0.11023322830406763,
      "grad_norm": 0.0003255154879298061,
      "learning_rate": 8.897667716959325e-06,
      "loss": 0.0,
      "step": 6962
    },
    {
      "epoch": 0.11024906186170971,
      "grad_norm": 0.2788107693195343,
      "learning_rate": 8.897509381382904e-06,
      "loss": 0.0158,
      "step": 6963
    },
    {
      "epoch": 0.11026489541935178,
      "grad_norm": 12.02585220336914,
      "learning_rate": 8.897351045806483e-06,
      "loss": 0.5091,
      "step": 6964
    },
    {
      "epoch": 0.11028072897699384,
      "grad_norm": 0.2916555404663086,
      "learning_rate": 8.897192710230062e-06,
      "loss": 0.1449,
      "step": 6965
    },
    {
      "epoch": 0.1102965625346359,
      "grad_norm": 0.7883243560791016,
      "learning_rate": 8.897034374653641e-06,
      "loss": 0.4185,
      "step": 6966
    },
    {
      "epoch": 0.11031239609227797,
      "grad_norm": 0.010044741444289684,
      "learning_rate": 8.896876039077222e-06,
      "loss": 0.0005,
      "step": 6967
    },
    {
      "epoch": 0.11032822964992003,
      "grad_norm": 0.21202121675014496,
      "learning_rate": 8.896717703500801e-06,
      "loss": 0.0748,
      "step": 6968
    },
    {
      "epoch": 0.11034406320756211,
      "grad_norm": 0.016627755016088486,
      "learning_rate": 8.89655936792438e-06,
      "loss": 0.0016,
      "step": 6969
    },
    {
      "epoch": 0.11035989676520418,
      "grad_norm": 0.024920033290982246,
      "learning_rate": 8.896401032347959e-06,
      "loss": 0.0015,
      "step": 6970
    },
    {
      "epoch": 0.11037573032284624,
      "grad_norm": 0.0064788744784891605,
      "learning_rate": 8.896242696771538e-06,
      "loss": 0.0003,
      "step": 6971
    },
    {
      "epoch": 0.1103915638804883,
      "grad_norm": 0.8244412541389465,
      "learning_rate": 8.896084361195117e-06,
      "loss": 0.1568,
      "step": 6972
    },
    {
      "epoch": 0.11040739743813037,
      "grad_norm": 0.33747148513793945,
      "learning_rate": 8.895926025618698e-06,
      "loss": 0.1236,
      "step": 6973
    },
    {
      "epoch": 0.11042323099577243,
      "grad_norm": 0.028276018798351288,
      "learning_rate": 8.895767690042277e-06,
      "loss": 0.0018,
      "step": 6974
    },
    {
      "epoch": 0.11043906455341451,
      "grad_norm": 0.00935483630746603,
      "learning_rate": 8.895609354465856e-06,
      "loss": 0.0006,
      "step": 6975
    },
    {
      "epoch": 0.11045489811105658,
      "grad_norm": 0.2293916791677475,
      "learning_rate": 8.895451018889435e-06,
      "loss": 0.0035,
      "step": 6976
    },
    {
      "epoch": 0.11047073166869864,
      "grad_norm": 0.021382717415690422,
      "learning_rate": 8.895292683313014e-06,
      "loss": 0.0012,
      "step": 6977
    },
    {
      "epoch": 0.1104865652263407,
      "grad_norm": 0.2753181457519531,
      "learning_rate": 8.895134347736593e-06,
      "loss": 0.0614,
      "step": 6978
    },
    {
      "epoch": 0.11050239878398277,
      "grad_norm": 0.19066213071346283,
      "learning_rate": 8.894976012160172e-06,
      "loss": 0.0528,
      "step": 6979
    },
    {
      "epoch": 0.11051823234162483,
      "grad_norm": 1.2345954179763794,
      "learning_rate": 8.894817676583753e-06,
      "loss": 0.2714,
      "step": 6980
    },
    {
      "epoch": 0.11053406589926691,
      "grad_norm": 0.4370604455471039,
      "learning_rate": 8.89465934100733e-06,
      "loss": 0.0478,
      "step": 6981
    },
    {
      "epoch": 0.11054989945690898,
      "grad_norm": 0.00040118032484315336,
      "learning_rate": 8.894501005430911e-06,
      "loss": 0.0,
      "step": 6982
    },
    {
      "epoch": 0.11056573301455104,
      "grad_norm": 0.420086145401001,
      "learning_rate": 8.89434266985449e-06,
      "loss": 0.1601,
      "step": 6983
    },
    {
      "epoch": 0.1105815665721931,
      "grad_norm": 0.0005003801779821515,
      "learning_rate": 8.89418433427807e-06,
      "loss": 0.0,
      "step": 6984
    },
    {
      "epoch": 0.11059740012983517,
      "grad_norm": 0.1453615128993988,
      "learning_rate": 8.894025998701649e-06,
      "loss": 0.0828,
      "step": 6985
    },
    {
      "epoch": 0.11061323368747723,
      "grad_norm": 0.23724496364593506,
      "learning_rate": 8.89386766312523e-06,
      "loss": 0.0815,
      "step": 6986
    },
    {
      "epoch": 0.11062906724511931,
      "grad_norm": 0.00531930522993207,
      "learning_rate": 8.893709327548807e-06,
      "loss": 0.0003,
      "step": 6987
    },
    {
      "epoch": 0.11064490080276138,
      "grad_norm": 0.27784812450408936,
      "learning_rate": 8.893550991972388e-06,
      "loss": 0.021,
      "step": 6988
    },
    {
      "epoch": 0.11066073436040344,
      "grad_norm": 0.25785142183303833,
      "learning_rate": 8.893392656395967e-06,
      "loss": 0.438,
      "step": 6989
    },
    {
      "epoch": 0.1106765679180455,
      "grad_norm": 0.2746477425098419,
      "learning_rate": 8.893234320819546e-06,
      "loss": 0.1087,
      "step": 6990
    },
    {
      "epoch": 0.11069240147568757,
      "grad_norm": 0.3071039319038391,
      "learning_rate": 8.893075985243125e-06,
      "loss": 0.3186,
      "step": 6991
    },
    {
      "epoch": 0.11070823503332963,
      "grad_norm": 0.6217493414878845,
      "learning_rate": 8.892917649666704e-06,
      "loss": 0.4244,
      "step": 6992
    },
    {
      "epoch": 0.11072406859097171,
      "grad_norm": 0.13068632781505585,
      "learning_rate": 8.892759314090283e-06,
      "loss": 0.0459,
      "step": 6993
    },
    {
      "epoch": 0.11073990214861378,
      "grad_norm": 0.060960203409194946,
      "learning_rate": 8.892600978513864e-06,
      "loss": 0.0048,
      "step": 6994
    },
    {
      "epoch": 0.11075573570625584,
      "grad_norm": 0.001600557705387473,
      "learning_rate": 8.892442642937443e-06,
      "loss": 0.0001,
      "step": 6995
    },
    {
      "epoch": 0.1107715692638979,
      "grad_norm": 0.0025352893862873316,
      "learning_rate": 8.892284307361022e-06,
      "loss": 0.0001,
      "step": 6996
    },
    {
      "epoch": 0.11078740282153997,
      "grad_norm": 0.3715643584728241,
      "learning_rate": 8.892125971784601e-06,
      "loss": 0.0806,
      "step": 6997
    },
    {
      "epoch": 0.11080323637918203,
      "grad_norm": 0.2691090703010559,
      "learning_rate": 8.89196763620818e-06,
      "loss": 0.0894,
      "step": 6998
    },
    {
      "epoch": 0.11081906993682411,
      "grad_norm": 0.19397862255573273,
      "learning_rate": 8.891809300631759e-06,
      "loss": 0.0899,
      "step": 6999
    },
    {
      "epoch": 0.11083490349446617,
      "grad_norm": 0.5464333891868591,
      "learning_rate": 8.89165096505534e-06,
      "loss": 0.1568,
      "step": 7000
    },
    {
      "epoch": 0.11085073705210824,
      "grad_norm": 0.1589728444814682,
      "learning_rate": 8.891492629478919e-06,
      "loss": 0.0557,
      "step": 7001
    },
    {
      "epoch": 0.1108665706097503,
      "grad_norm": 1.1884936094284058,
      "learning_rate": 8.891334293902496e-06,
      "loss": 0.1017,
      "step": 7002
    },
    {
      "epoch": 0.11088240416739237,
      "grad_norm": 0.28212523460388184,
      "learning_rate": 8.891175958326077e-06,
      "loss": 0.1546,
      "step": 7003
    },
    {
      "epoch": 0.11089823772503443,
      "grad_norm": 0.0006325579597614706,
      "learning_rate": 8.891017622749656e-06,
      "loss": 0.0,
      "step": 7004
    },
    {
      "epoch": 0.11091407128267651,
      "grad_norm": 0.026037439703941345,
      "learning_rate": 8.890859287173235e-06,
      "loss": 0.0013,
      "step": 7005
    },
    {
      "epoch": 0.11092990484031857,
      "grad_norm": 0.3804605007171631,
      "learning_rate": 8.890700951596814e-06,
      "loss": 0.3792,
      "step": 7006
    },
    {
      "epoch": 0.11094573839796064,
      "grad_norm": 0.0005011238972656429,
      "learning_rate": 8.890542616020395e-06,
      "loss": 0.0,
      "step": 7007
    },
    {
      "epoch": 0.1109615719556027,
      "grad_norm": 0.17356400191783905,
      "learning_rate": 8.890384280443973e-06,
      "loss": 0.0265,
      "step": 7008
    },
    {
      "epoch": 0.11097740551324477,
      "grad_norm": 0.0003785620501730591,
      "learning_rate": 8.890225944867553e-06,
      "loss": 0.0,
      "step": 7009
    },
    {
      "epoch": 0.11099323907088683,
      "grad_norm": 0.1694219708442688,
      "learning_rate": 8.890067609291132e-06,
      "loss": 0.0637,
      "step": 7010
    },
    {
      "epoch": 0.11100907262852891,
      "grad_norm": 0.2454044222831726,
      "learning_rate": 8.889909273714711e-06,
      "loss": 0.1939,
      "step": 7011
    },
    {
      "epoch": 0.11102490618617097,
      "grad_norm": 0.3715118169784546,
      "learning_rate": 8.88975093813829e-06,
      "loss": 0.2263,
      "step": 7012
    },
    {
      "epoch": 0.11104073974381304,
      "grad_norm": 0.21878688037395477,
      "learning_rate": 8.889592602561871e-06,
      "loss": 0.0726,
      "step": 7013
    },
    {
      "epoch": 0.1110565733014551,
      "grad_norm": 0.3075765073299408,
      "learning_rate": 8.889434266985449e-06,
      "loss": 0.0599,
      "step": 7014
    },
    {
      "epoch": 0.11107240685909717,
      "grad_norm": 0.1828518956899643,
      "learning_rate": 8.88927593140903e-06,
      "loss": 0.1031,
      "step": 7015
    },
    {
      "epoch": 0.11108824041673923,
      "grad_norm": 0.4901905357837677,
      "learning_rate": 8.889117595832609e-06,
      "loss": 0.7045,
      "step": 7016
    },
    {
      "epoch": 0.11110407397438131,
      "grad_norm": 0.17768411338329315,
      "learning_rate": 8.888959260256188e-06,
      "loss": 0.0662,
      "step": 7017
    },
    {
      "epoch": 0.11111990753202337,
      "grad_norm": 0.00046313440543599427,
      "learning_rate": 8.888800924679767e-06,
      "loss": 0.0,
      "step": 7018
    },
    {
      "epoch": 0.11113574108966544,
      "grad_norm": 0.0003429871576372534,
      "learning_rate": 8.888642589103347e-06,
      "loss": 0.0,
      "step": 7019
    },
    {
      "epoch": 0.1111515746473075,
      "grad_norm": 0.344483345746994,
      "learning_rate": 8.888484253526925e-06,
      "loss": 0.0926,
      "step": 7020
    },
    {
      "epoch": 0.11116740820494957,
      "grad_norm": 0.21135376393795013,
      "learning_rate": 8.888325917950506e-06,
      "loss": 0.1366,
      "step": 7021
    },
    {
      "epoch": 0.11118324176259163,
      "grad_norm": 0.000748274615034461,
      "learning_rate": 8.888167582374085e-06,
      "loss": 0.0,
      "step": 7022
    },
    {
      "epoch": 0.11119907532023371,
      "grad_norm": 0.00552420224994421,
      "learning_rate": 8.888009246797664e-06,
      "loss": 0.0004,
      "step": 7023
    },
    {
      "epoch": 0.11121490887787577,
      "grad_norm": 0.6696069240570068,
      "learning_rate": 8.887850911221243e-06,
      "loss": 0.5013,
      "step": 7024
    },
    {
      "epoch": 0.11123074243551784,
      "grad_norm": 0.30698084831237793,
      "learning_rate": 8.887692575644824e-06,
      "loss": 0.2886,
      "step": 7025
    },
    {
      "epoch": 0.1112465759931599,
      "grad_norm": 0.3809652328491211,
      "learning_rate": 8.887534240068401e-06,
      "loss": 0.6465,
      "step": 7026
    },
    {
      "epoch": 0.11126240955080197,
      "grad_norm": 0.27350178360939026,
      "learning_rate": 8.88737590449198e-06,
      "loss": 0.0933,
      "step": 7027
    },
    {
      "epoch": 0.11127824310844403,
      "grad_norm": 0.23168940842151642,
      "learning_rate": 8.887217568915561e-06,
      "loss": 0.1102,
      "step": 7028
    },
    {
      "epoch": 0.11129407666608611,
      "grad_norm": 0.12976980209350586,
      "learning_rate": 8.88705923333914e-06,
      "loss": 0.0502,
      "step": 7029
    },
    {
      "epoch": 0.11130991022372817,
      "grad_norm": 0.1668952852487564,
      "learning_rate": 8.886900897762719e-06,
      "loss": 0.0316,
      "step": 7030
    },
    {
      "epoch": 0.11132574378137024,
      "grad_norm": 0.18409475684165955,
      "learning_rate": 8.886742562186298e-06,
      "loss": 0.0081,
      "step": 7031
    },
    {
      "epoch": 0.1113415773390123,
      "grad_norm": 0.29327595233917236,
      "learning_rate": 8.886584226609877e-06,
      "loss": 0.0822,
      "step": 7032
    },
    {
      "epoch": 0.11135741089665437,
      "grad_norm": 0.011432248167693615,
      "learning_rate": 8.886425891033456e-06,
      "loss": 0.0007,
      "step": 7033
    },
    {
      "epoch": 0.11137324445429643,
      "grad_norm": 0.1208147406578064,
      "learning_rate": 8.886267555457037e-06,
      "loss": 0.0302,
      "step": 7034
    },
    {
      "epoch": 0.11138907801193851,
      "grad_norm": 0.39330339431762695,
      "learning_rate": 8.886109219880616e-06,
      "loss": 0.62,
      "step": 7035
    },
    {
      "epoch": 0.11140491156958057,
      "grad_norm": 0.3015775680541992,
      "learning_rate": 8.885950884304195e-06,
      "loss": 0.0552,
      "step": 7036
    },
    {
      "epoch": 0.11142074512722264,
      "grad_norm": 0.4310759902000427,
      "learning_rate": 8.885792548727774e-06,
      "loss": 0.1207,
      "step": 7037
    },
    {
      "epoch": 0.1114365786848647,
      "grad_norm": 0.4784090220928192,
      "learning_rate": 8.885634213151353e-06,
      "loss": 0.5301,
      "step": 7038
    },
    {
      "epoch": 0.11145241224250677,
      "grad_norm": 0.0002506955643184483,
      "learning_rate": 8.885475877574932e-06,
      "loss": 0.0,
      "step": 7039
    },
    {
      "epoch": 0.11146824580014883,
      "grad_norm": 0.027431583032011986,
      "learning_rate": 8.885317541998513e-06,
      "loss": 0.0019,
      "step": 7040
    },
    {
      "epoch": 0.11148407935779091,
      "grad_norm": 0.14919085800647736,
      "learning_rate": 8.885159206422092e-06,
      "loss": 0.0646,
      "step": 7041
    },
    {
      "epoch": 0.11149991291543297,
      "grad_norm": 0.42998677492141724,
      "learning_rate": 8.885000870845671e-06,
      "loss": 0.3359,
      "step": 7042
    },
    {
      "epoch": 0.11151574647307504,
      "grad_norm": 0.17734427750110626,
      "learning_rate": 8.88484253526925e-06,
      "loss": 0.1613,
      "step": 7043
    },
    {
      "epoch": 0.1115315800307171,
      "grad_norm": 0.022869817912578583,
      "learning_rate": 8.88468419969283e-06,
      "loss": 0.0017,
      "step": 7044
    },
    {
      "epoch": 0.11154741358835916,
      "grad_norm": 0.010829984210431576,
      "learning_rate": 8.884525864116409e-06,
      "loss": 0.0006,
      "step": 7045
    },
    {
      "epoch": 0.11156324714600123,
      "grad_norm": 0.09481406956911087,
      "learning_rate": 8.88436752853999e-06,
      "loss": 0.0176,
      "step": 7046
    },
    {
      "epoch": 0.11157908070364331,
      "grad_norm": 0.36920782923698425,
      "learning_rate": 8.884209192963568e-06,
      "loss": 0.378,
      "step": 7047
    },
    {
      "epoch": 0.11159491426128537,
      "grad_norm": 0.313017874956131,
      "learning_rate": 8.884050857387148e-06,
      "loss": 0.0746,
      "step": 7048
    },
    {
      "epoch": 0.11161074781892744,
      "grad_norm": 0.20263703167438507,
      "learning_rate": 8.883892521810727e-06,
      "loss": 0.08,
      "step": 7049
    },
    {
      "epoch": 0.1116265813765695,
      "grad_norm": 0.3928851783275604,
      "learning_rate": 8.883734186234306e-06,
      "loss": 0.2318,
      "step": 7050
    },
    {
      "epoch": 0.11164241493421156,
      "grad_norm": 0.011815800331532955,
      "learning_rate": 8.883575850657885e-06,
      "loss": 0.0005,
      "step": 7051
    },
    {
      "epoch": 0.11165824849185363,
      "grad_norm": 8.900015382096171e-05,
      "learning_rate": 8.883417515081464e-06,
      "loss": 0.0,
      "step": 7052
    },
    {
      "epoch": 0.11167408204949571,
      "grad_norm": 0.3762110769748688,
      "learning_rate": 8.883259179505043e-06,
      "loss": 0.4622,
      "step": 7053
    },
    {
      "epoch": 0.11168991560713777,
      "grad_norm": 0.25111228227615356,
      "learning_rate": 8.883100843928622e-06,
      "loss": 0.0797,
      "step": 7054
    },
    {
      "epoch": 0.11170574916477984,
      "grad_norm": 0.6386998295783997,
      "learning_rate": 8.882942508352203e-06,
      "loss": 0.1049,
      "step": 7055
    },
    {
      "epoch": 0.1117215827224219,
      "grad_norm": 0.28007787466049194,
      "learning_rate": 8.882784172775782e-06,
      "loss": 0.2115,
      "step": 7056
    },
    {
      "epoch": 0.11173741628006396,
      "grad_norm": 0.007778991479426622,
      "learning_rate": 8.882625837199361e-06,
      "loss": 0.0003,
      "step": 7057
    },
    {
      "epoch": 0.11175324983770603,
      "grad_norm": 0.013555037789046764,
      "learning_rate": 8.88246750162294e-06,
      "loss": 0.0007,
      "step": 7058
    },
    {
      "epoch": 0.1117690833953481,
      "grad_norm": 0.32016685605049133,
      "learning_rate": 8.882309166046519e-06,
      "loss": 0.0691,
      "step": 7059
    },
    {
      "epoch": 0.11178491695299017,
      "grad_norm": 0.4818119704723358,
      "learning_rate": 8.882150830470098e-06,
      "loss": 0.0973,
      "step": 7060
    },
    {
      "epoch": 0.11180075051063224,
      "grad_norm": 0.011903275735676289,
      "learning_rate": 8.881992494893679e-06,
      "loss": 0.0008,
      "step": 7061
    },
    {
      "epoch": 0.1118165840682743,
      "grad_norm": 0.3883002996444702,
      "learning_rate": 8.881834159317258e-06,
      "loss": 0.2841,
      "step": 7062
    },
    {
      "epoch": 0.11183241762591636,
      "grad_norm": 0.01300143077969551,
      "learning_rate": 8.881675823740837e-06,
      "loss": 0.0007,
      "step": 7063
    },
    {
      "epoch": 0.11184825118355843,
      "grad_norm": 0.049108751118183136,
      "learning_rate": 8.881517488164416e-06,
      "loss": 0.003,
      "step": 7064
    },
    {
      "epoch": 0.1118640847412005,
      "grad_norm": 0.1330568492412567,
      "learning_rate": 8.881359152587995e-06,
      "loss": 0.0316,
      "step": 7065
    },
    {
      "epoch": 0.11187991829884257,
      "grad_norm": 0.0967390164732933,
      "learning_rate": 8.881200817011574e-06,
      "loss": 0.0321,
      "step": 7066
    },
    {
      "epoch": 0.11189575185648463,
      "grad_norm": 0.030386531725525856,
      "learning_rate": 8.881042481435155e-06,
      "loss": 0.0017,
      "step": 7067
    },
    {
      "epoch": 0.1119115854141267,
      "grad_norm": 0.3539581298828125,
      "learning_rate": 8.880884145858734e-06,
      "loss": 0.1266,
      "step": 7068
    },
    {
      "epoch": 0.11192741897176876,
      "grad_norm": 0.41464880108833313,
      "learning_rate": 8.880725810282313e-06,
      "loss": 0.1348,
      "step": 7069
    },
    {
      "epoch": 0.11194325252941083,
      "grad_norm": 0.3936523199081421,
      "learning_rate": 8.880567474705892e-06,
      "loss": 0.0184,
      "step": 7070
    },
    {
      "epoch": 0.1119590860870529,
      "grad_norm": 0.24021925032138824,
      "learning_rate": 8.880409139129471e-06,
      "loss": 0.102,
      "step": 7071
    },
    {
      "epoch": 0.11197491964469497,
      "grad_norm": 0.43747758865356445,
      "learning_rate": 8.88025080355305e-06,
      "loss": 0.2044,
      "step": 7072
    },
    {
      "epoch": 0.11199075320233703,
      "grad_norm": 0.005935771856456995,
      "learning_rate": 8.880092467976631e-06,
      "loss": 0.0002,
      "step": 7073
    },
    {
      "epoch": 0.1120065867599791,
      "grad_norm": 0.24555248022079468,
      "learning_rate": 8.87993413240021e-06,
      "loss": 0.0398,
      "step": 7074
    },
    {
      "epoch": 0.11202242031762116,
      "grad_norm": 0.42831575870513916,
      "learning_rate": 8.879775796823788e-06,
      "loss": 0.013,
      "step": 7075
    },
    {
      "epoch": 0.11203825387526323,
      "grad_norm": 0.23285415768623352,
      "learning_rate": 8.879617461247369e-06,
      "loss": 0.0338,
      "step": 7076
    },
    {
      "epoch": 0.1120540874329053,
      "grad_norm": 0.2322399765253067,
      "learning_rate": 8.879459125670948e-06,
      "loss": 0.0637,
      "step": 7077
    },
    {
      "epoch": 0.11206992099054737,
      "grad_norm": 0.4054013192653656,
      "learning_rate": 8.879300790094527e-06,
      "loss": 0.0823,
      "step": 7078
    },
    {
      "epoch": 0.11208575454818943,
      "grad_norm": 0.3830890655517578,
      "learning_rate": 8.879142454518106e-06,
      "loss": 0.1002,
      "step": 7079
    },
    {
      "epoch": 0.1121015881058315,
      "grad_norm": 0.747948408126831,
      "learning_rate": 8.878984118941687e-06,
      "loss": 0.2286,
      "step": 7080
    },
    {
      "epoch": 0.11211742166347356,
      "grad_norm": 0.18977370858192444,
      "learning_rate": 8.878825783365264e-06,
      "loss": 0.0607,
      "step": 7081
    },
    {
      "epoch": 0.11213325522111563,
      "grad_norm": 0.004887963645160198,
      "learning_rate": 8.878667447788845e-06,
      "loss": 0.0003,
      "step": 7082
    },
    {
      "epoch": 0.1121490887787577,
      "grad_norm": 0.13309159874916077,
      "learning_rate": 8.878509112212424e-06,
      "loss": 0.0461,
      "step": 7083
    },
    {
      "epoch": 0.11216492233639977,
      "grad_norm": 0.5297773480415344,
      "learning_rate": 8.878350776636003e-06,
      "loss": 0.2699,
      "step": 7084
    },
    {
      "epoch": 0.11218075589404183,
      "grad_norm": 0.0056137097999453545,
      "learning_rate": 8.878192441059582e-06,
      "loss": 0.0002,
      "step": 7085
    },
    {
      "epoch": 0.1121965894516839,
      "grad_norm": 0.007689402438700199,
      "learning_rate": 8.878034105483163e-06,
      "loss": 0.0004,
      "step": 7086
    },
    {
      "epoch": 0.11221242300932596,
      "grad_norm": 0.5103203654289246,
      "learning_rate": 8.87787576990674e-06,
      "loss": 0.25,
      "step": 7087
    },
    {
      "epoch": 0.11222825656696803,
      "grad_norm": 0.20252028107643127,
      "learning_rate": 8.877717434330321e-06,
      "loss": 0.0464,
      "step": 7088
    },
    {
      "epoch": 0.1122440901246101,
      "grad_norm": 0.005900022108107805,
      "learning_rate": 8.8775590987539e-06,
      "loss": 0.0003,
      "step": 7089
    },
    {
      "epoch": 0.11225992368225217,
      "grad_norm": 0.177372008562088,
      "learning_rate": 8.877400763177479e-06,
      "loss": 0.0362,
      "step": 7090
    },
    {
      "epoch": 0.11227575723989423,
      "grad_norm": 0.26688432693481445,
      "learning_rate": 8.877242427601058e-06,
      "loss": 0.1156,
      "step": 7091
    },
    {
      "epoch": 0.1122915907975363,
      "grad_norm": 0.3344757556915283,
      "learning_rate": 8.877084092024639e-06,
      "loss": 0.1466,
      "step": 7092
    },
    {
      "epoch": 0.11230742435517836,
      "grad_norm": 0.23657968640327454,
      "learning_rate": 8.876925756448216e-06,
      "loss": 0.0526,
      "step": 7093
    },
    {
      "epoch": 0.11232325791282043,
      "grad_norm": 0.02129734307527542,
      "learning_rate": 8.876767420871797e-06,
      "loss": 0.0009,
      "step": 7094
    },
    {
      "epoch": 0.1123390914704625,
      "grad_norm": 0.006493996363133192,
      "learning_rate": 8.876609085295376e-06,
      "loss": 0.0003,
      "step": 7095
    },
    {
      "epoch": 0.11235492502810457,
      "grad_norm": 0.1860923022031784,
      "learning_rate": 8.876450749718955e-06,
      "loss": 0.0609,
      "step": 7096
    },
    {
      "epoch": 0.11237075858574663,
      "grad_norm": 0.740945041179657,
      "learning_rate": 8.876292414142534e-06,
      "loss": 0.3183,
      "step": 7097
    },
    {
      "epoch": 0.1123865921433887,
      "grad_norm": 0.19507735967636108,
      "learning_rate": 8.876134078566113e-06,
      "loss": 0.0564,
      "step": 7098
    },
    {
      "epoch": 0.11240242570103076,
      "grad_norm": 0.14730416238307953,
      "learning_rate": 8.875975742989692e-06,
      "loss": 0.0464,
      "step": 7099
    },
    {
      "epoch": 0.11241825925867283,
      "grad_norm": 0.0005930543411523104,
      "learning_rate": 8.875817407413272e-06,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 0.1124340928163149,
      "grad_norm": 0.40200379490852356,
      "learning_rate": 8.875659071836852e-06,
      "loss": 0.0873,
      "step": 7101
    },
    {
      "epoch": 0.11244992637395697,
      "grad_norm": 0.3834512531757355,
      "learning_rate": 8.875500736260431e-06,
      "loss": 0.3461,
      "step": 7102
    },
    {
      "epoch": 0.11246575993159903,
      "grad_norm": 0.008894979022443295,
      "learning_rate": 8.87534240068401e-06,
      "loss": 0.0003,
      "step": 7103
    },
    {
      "epoch": 0.1124815934892411,
      "grad_norm": 0.37352293729782104,
      "learning_rate": 8.87518406510759e-06,
      "loss": 0.1952,
      "step": 7104
    },
    {
      "epoch": 0.11249742704688316,
      "grad_norm": 0.20470522344112396,
      "learning_rate": 8.875025729531169e-06,
      "loss": 0.0913,
      "step": 7105
    },
    {
      "epoch": 0.11251326060452523,
      "grad_norm": 0.19705326855182648,
      "learning_rate": 8.874867393954748e-06,
      "loss": 0.0774,
      "step": 7106
    },
    {
      "epoch": 0.1125290941621673,
      "grad_norm": 0.34886670112609863,
      "learning_rate": 8.874709058378328e-06,
      "loss": 0.1514,
      "step": 7107
    },
    {
      "epoch": 0.11254492771980937,
      "grad_norm": 0.38014617562294006,
      "learning_rate": 8.874550722801908e-06,
      "loss": 0.2057,
      "step": 7108
    },
    {
      "epoch": 0.11256076127745143,
      "grad_norm": 0.44613951444625854,
      "learning_rate": 8.874392387225487e-06,
      "loss": 0.1024,
      "step": 7109
    },
    {
      "epoch": 0.1125765948350935,
      "grad_norm": 0.003353866282850504,
      "learning_rate": 8.874234051649066e-06,
      "loss": 0.0001,
      "step": 7110
    },
    {
      "epoch": 0.11259242839273556,
      "grad_norm": 0.3291833698749542,
      "learning_rate": 8.874075716072645e-06,
      "loss": 0.0638,
      "step": 7111
    },
    {
      "epoch": 0.11260826195037762,
      "grad_norm": 0.3437000513076782,
      "learning_rate": 8.873917380496224e-06,
      "loss": 0.0901,
      "step": 7112
    },
    {
      "epoch": 0.1126240955080197,
      "grad_norm": 0.17025786638259888,
      "learning_rate": 8.873759044919805e-06,
      "loss": 0.0302,
      "step": 7113
    },
    {
      "epoch": 0.11263992906566177,
      "grad_norm": 0.5019017457962036,
      "learning_rate": 8.873600709343384e-06,
      "loss": 0.1538,
      "step": 7114
    },
    {
      "epoch": 0.11265576262330383,
      "grad_norm": 0.4174324572086334,
      "learning_rate": 8.873442373766963e-06,
      "loss": 0.0507,
      "step": 7115
    },
    {
      "epoch": 0.1126715961809459,
      "grad_norm": 0.5659021139144897,
      "learning_rate": 8.873284038190542e-06,
      "loss": 0.2856,
      "step": 7116
    },
    {
      "epoch": 0.11268742973858796,
      "grad_norm": 0.523364245891571,
      "learning_rate": 8.873125702614121e-06,
      "loss": 0.0727,
      "step": 7117
    },
    {
      "epoch": 0.11270326329623002,
      "grad_norm": 0.7173853516578674,
      "learning_rate": 8.8729673670377e-06,
      "loss": 0.2419,
      "step": 7118
    },
    {
      "epoch": 0.1127190968538721,
      "grad_norm": 0.35706743597984314,
      "learning_rate": 8.87280903146128e-06,
      "loss": 0.088,
      "step": 7119
    },
    {
      "epoch": 0.11273493041151417,
      "grad_norm": 0.006269895471632481,
      "learning_rate": 8.872650695884858e-06,
      "loss": 0.0002,
      "step": 7120
    },
    {
      "epoch": 0.11275076396915623,
      "grad_norm": 0.5764251351356506,
      "learning_rate": 8.872492360308439e-06,
      "loss": 0.6057,
      "step": 7121
    },
    {
      "epoch": 0.1127665975267983,
      "grad_norm": 0.18967671692371368,
      "learning_rate": 8.872334024732018e-06,
      "loss": 0.0332,
      "step": 7122
    },
    {
      "epoch": 0.11278243108444036,
      "grad_norm": 0.33022037148475647,
      "learning_rate": 8.872175689155597e-06,
      "loss": 0.1977,
      "step": 7123
    },
    {
      "epoch": 0.11279826464208242,
      "grad_norm": 0.3469533920288086,
      "learning_rate": 8.872017353579176e-06,
      "loss": 0.2312,
      "step": 7124
    },
    {
      "epoch": 0.1128140981997245,
      "grad_norm": 0.1422804892063141,
      "learning_rate": 8.871859018002755e-06,
      "loss": 0.0669,
      "step": 7125
    },
    {
      "epoch": 0.11282993175736657,
      "grad_norm": 0.17444688081741333,
      "learning_rate": 8.871700682426334e-06,
      "loss": 0.0393,
      "step": 7126
    },
    {
      "epoch": 0.11284576531500863,
      "grad_norm": 0.040147729218006134,
      "learning_rate": 8.871542346849913e-06,
      "loss": 0.0025,
      "step": 7127
    },
    {
      "epoch": 0.1128615988726507,
      "grad_norm": 0.36560043692588806,
      "learning_rate": 8.871384011273494e-06,
      "loss": 0.0687,
      "step": 7128
    },
    {
      "epoch": 0.11287743243029276,
      "grad_norm": 0.5019574165344238,
      "learning_rate": 8.871225675697073e-06,
      "loss": 0.6153,
      "step": 7129
    },
    {
      "epoch": 0.11289326598793482,
      "grad_norm": 0.20890069007873535,
      "learning_rate": 8.871067340120652e-06,
      "loss": 0.0884,
      "step": 7130
    },
    {
      "epoch": 0.1129090995455769,
      "grad_norm": 0.3140837848186493,
      "learning_rate": 8.870909004544231e-06,
      "loss": 0.1914,
      "step": 7131
    },
    {
      "epoch": 0.11292493310321897,
      "grad_norm": 0.315032035112381,
      "learning_rate": 8.87075066896781e-06,
      "loss": 0.0825,
      "step": 7132
    },
    {
      "epoch": 0.11294076666086103,
      "grad_norm": 0.2769836485385895,
      "learning_rate": 8.87059233339139e-06,
      "loss": 0.2028,
      "step": 7133
    },
    {
      "epoch": 0.1129566002185031,
      "grad_norm": 0.20871105790138245,
      "learning_rate": 8.87043399781497e-06,
      "loss": 0.0826,
      "step": 7134
    },
    {
      "epoch": 0.11297243377614516,
      "grad_norm": 0.24138687551021576,
      "learning_rate": 8.87027566223855e-06,
      "loss": 0.1378,
      "step": 7135
    },
    {
      "epoch": 0.11298826733378722,
      "grad_norm": 0.5809608697891235,
      "learning_rate": 8.870117326662129e-06,
      "loss": 0.8711,
      "step": 7136
    },
    {
      "epoch": 0.1130041008914293,
      "grad_norm": 0.31770825386047363,
      "learning_rate": 8.869958991085708e-06,
      "loss": 0.1792,
      "step": 7137
    },
    {
      "epoch": 0.11301993444907137,
      "grad_norm": 0.03931603208184242,
      "learning_rate": 8.869800655509287e-06,
      "loss": 0.0023,
      "step": 7138
    },
    {
      "epoch": 0.11303576800671343,
      "grad_norm": 0.46206092834472656,
      "learning_rate": 8.869642319932866e-06,
      "loss": 0.1267,
      "step": 7139
    },
    {
      "epoch": 0.1130516015643555,
      "grad_norm": 0.012237988412380219,
      "learning_rate": 8.869483984356447e-06,
      "loss": 0.0006,
      "step": 7140
    },
    {
      "epoch": 0.11306743512199756,
      "grad_norm": 0.24246183037757874,
      "learning_rate": 8.869325648780026e-06,
      "loss": 0.0151,
      "step": 7141
    },
    {
      "epoch": 0.11308326867963962,
      "grad_norm": 0.1605013757944107,
      "learning_rate": 8.869167313203605e-06,
      "loss": 0.015,
      "step": 7142
    },
    {
      "epoch": 0.1130991022372817,
      "grad_norm": 0.48450967669487,
      "learning_rate": 8.869008977627184e-06,
      "loss": 0.6367,
      "step": 7143
    },
    {
      "epoch": 0.11311493579492377,
      "grad_norm": 0.15120410919189453,
      "learning_rate": 8.868850642050763e-06,
      "loss": 0.0502,
      "step": 7144
    },
    {
      "epoch": 0.11313076935256583,
      "grad_norm": 0.0009821108542382717,
      "learning_rate": 8.868692306474342e-06,
      "loss": 0.0,
      "step": 7145
    },
    {
      "epoch": 0.1131466029102079,
      "grad_norm": 0.26130178570747375,
      "learning_rate": 8.868533970897921e-06,
      "loss": 0.0806,
      "step": 7146
    },
    {
      "epoch": 0.11316243646784996,
      "grad_norm": 0.21154829859733582,
      "learning_rate": 8.868375635321502e-06,
      "loss": 0.0458,
      "step": 7147
    },
    {
      "epoch": 0.11317827002549202,
      "grad_norm": 0.013606719672679901,
      "learning_rate": 8.86821729974508e-06,
      "loss": 0.0006,
      "step": 7148
    },
    {
      "epoch": 0.1131941035831341,
      "grad_norm": 3.153059244155884,
      "learning_rate": 8.86805896416866e-06,
      "loss": 0.1816,
      "step": 7149
    },
    {
      "epoch": 0.11320993714077617,
      "grad_norm": 0.06393267959356308,
      "learning_rate": 8.867900628592239e-06,
      "loss": 0.0074,
      "step": 7150
    },
    {
      "epoch": 0.11322577069841823,
      "grad_norm": 0.0011595258256420493,
      "learning_rate": 8.867742293015818e-06,
      "loss": 0.0,
      "step": 7151
    },
    {
      "epoch": 0.1132416042560603,
      "grad_norm": 0.15095262229442596,
      "learning_rate": 8.867583957439397e-06,
      "loss": 0.0224,
      "step": 7152
    },
    {
      "epoch": 0.11325743781370236,
      "grad_norm": 0.2055593729019165,
      "learning_rate": 8.867425621862978e-06,
      "loss": 0.0349,
      "step": 7153
    },
    {
      "epoch": 0.11327327137134442,
      "grad_norm": 0.6802806258201599,
      "learning_rate": 8.867267286286555e-06,
      "loss": 0.2451,
      "step": 7154
    },
    {
      "epoch": 0.1132891049289865,
      "grad_norm": 0.24656988680362701,
      "learning_rate": 8.867108950710136e-06,
      "loss": 0.1434,
      "step": 7155
    },
    {
      "epoch": 0.11330493848662856,
      "grad_norm": 0.40323740243911743,
      "learning_rate": 8.866950615133715e-06,
      "loss": 0.1407,
      "step": 7156
    },
    {
      "epoch": 0.11332077204427063,
      "grad_norm": 0.15205880999565125,
      "learning_rate": 8.866792279557294e-06,
      "loss": 0.0511,
      "step": 7157
    },
    {
      "epoch": 0.1133366056019127,
      "grad_norm": 0.01027846708893776,
      "learning_rate": 8.866633943980873e-06,
      "loss": 0.0006,
      "step": 7158
    },
    {
      "epoch": 0.11335243915955476,
      "grad_norm": 0.12926962971687317,
      "learning_rate": 8.866475608404454e-06,
      "loss": 0.0178,
      "step": 7159
    },
    {
      "epoch": 0.11336827271719682,
      "grad_norm": 0.011597076430916786,
      "learning_rate": 8.866317272828032e-06,
      "loss": 0.0005,
      "step": 7160
    },
    {
      "epoch": 0.1133841062748389,
      "grad_norm": 0.007539829239249229,
      "learning_rate": 8.866158937251612e-06,
      "loss": 0.0002,
      "step": 7161
    },
    {
      "epoch": 0.11339993983248096,
      "grad_norm": 0.43157073855400085,
      "learning_rate": 8.866000601675191e-06,
      "loss": 0.2739,
      "step": 7162
    },
    {
      "epoch": 0.11341577339012303,
      "grad_norm": 0.4257681369781494,
      "learning_rate": 8.86584226609877e-06,
      "loss": 0.2422,
      "step": 7163
    },
    {
      "epoch": 0.11343160694776509,
      "grad_norm": 0.6081326007843018,
      "learning_rate": 8.86568393052235e-06,
      "loss": 0.1241,
      "step": 7164
    },
    {
      "epoch": 0.11344744050540716,
      "grad_norm": 0.006478426046669483,
      "learning_rate": 8.86552559494593e-06,
      "loss": 0.0002,
      "step": 7165
    },
    {
      "epoch": 0.11346327406304922,
      "grad_norm": 0.014781909063458443,
      "learning_rate": 8.865367259369508e-06,
      "loss": 0.0008,
      "step": 7166
    },
    {
      "epoch": 0.1134791076206913,
      "grad_norm": 0.021480396389961243,
      "learning_rate": 8.865208923793089e-06,
      "loss": 0.0013,
      "step": 7167
    },
    {
      "epoch": 0.11349494117833336,
      "grad_norm": 0.25770679116249084,
      "learning_rate": 8.865050588216668e-06,
      "loss": 0.0987,
      "step": 7168
    },
    {
      "epoch": 0.11351077473597543,
      "grad_norm": 0.00448849331587553,
      "learning_rate": 8.864892252640247e-06,
      "loss": 0.0001,
      "step": 7169
    },
    {
      "epoch": 0.11352660829361749,
      "grad_norm": 0.5476671457290649,
      "learning_rate": 8.864733917063826e-06,
      "loss": 0.2365,
      "step": 7170
    },
    {
      "epoch": 0.11354244185125956,
      "grad_norm": 0.7341412901878357,
      "learning_rate": 8.864575581487405e-06,
      "loss": 0.775,
      "step": 7171
    },
    {
      "epoch": 0.11355827540890162,
      "grad_norm": 0.30548492074012756,
      "learning_rate": 8.864417245910984e-06,
      "loss": 0.124,
      "step": 7172
    },
    {
      "epoch": 0.1135741089665437,
      "grad_norm": 0.031143296509981155,
      "learning_rate": 8.864258910334563e-06,
      "loss": 0.0015,
      "step": 7173
    },
    {
      "epoch": 0.11358994252418576,
      "grad_norm": 0.3154444992542267,
      "learning_rate": 8.864100574758144e-06,
      "loss": 0.0888,
      "step": 7174
    },
    {
      "epoch": 0.11360577608182783,
      "grad_norm": 0.01773235946893692,
      "learning_rate": 8.863942239181723e-06,
      "loss": 0.0007,
      "step": 7175
    },
    {
      "epoch": 0.11362160963946989,
      "grad_norm": 0.007613332476466894,
      "learning_rate": 8.863783903605302e-06,
      "loss": 0.0004,
      "step": 7176
    },
    {
      "epoch": 0.11363744319711196,
      "grad_norm": 0.3048252761363983,
      "learning_rate": 8.863625568028881e-06,
      "loss": 0.1758,
      "step": 7177
    },
    {
      "epoch": 0.11365327675475402,
      "grad_norm": 0.0027014196384698153,
      "learning_rate": 8.86346723245246e-06,
      "loss": 0.0001,
      "step": 7178
    },
    {
      "epoch": 0.1136691103123961,
      "grad_norm": 0.04570203274488449,
      "learning_rate": 8.86330889687604e-06,
      "loss": 0.0005,
      "step": 7179
    },
    {
      "epoch": 0.11368494387003816,
      "grad_norm": 0.3737703561782837,
      "learning_rate": 8.86315056129962e-06,
      "loss": 0.1156,
      "step": 7180
    },
    {
      "epoch": 0.11370077742768023,
      "grad_norm": 0.00042571709491312504,
      "learning_rate": 8.862992225723199e-06,
      "loss": 0.0,
      "step": 7181
    },
    {
      "epoch": 0.11371661098532229,
      "grad_norm": 0.027211664244532585,
      "learning_rate": 8.862833890146778e-06,
      "loss": 0.0013,
      "step": 7182
    },
    {
      "epoch": 0.11373244454296436,
      "grad_norm": 1.587220549583435,
      "learning_rate": 8.862675554570357e-06,
      "loss": 0.233,
      "step": 7183
    },
    {
      "epoch": 0.11374827810060642,
      "grad_norm": 0.18317000567913055,
      "learning_rate": 8.862517218993936e-06,
      "loss": 0.0547,
      "step": 7184
    },
    {
      "epoch": 0.1137641116582485,
      "grad_norm": 0.2066119760274887,
      "learning_rate": 8.862358883417515e-06,
      "loss": 0.2429,
      "step": 7185
    },
    {
      "epoch": 0.11377994521589056,
      "grad_norm": 0.677924394607544,
      "learning_rate": 8.862200547841096e-06,
      "loss": 0.1782,
      "step": 7186
    },
    {
      "epoch": 0.11379577877353263,
      "grad_norm": 0.12750715017318726,
      "learning_rate": 8.862042212264673e-06,
      "loss": 0.0215,
      "step": 7187
    },
    {
      "epoch": 0.11381161233117469,
      "grad_norm": 0.029207875952124596,
      "learning_rate": 8.861883876688254e-06,
      "loss": 0.0017,
      "step": 7188
    },
    {
      "epoch": 0.11382744588881676,
      "grad_norm": 0.18063323199748993,
      "learning_rate": 8.861725541111833e-06,
      "loss": 0.0519,
      "step": 7189
    },
    {
      "epoch": 0.11384327944645882,
      "grad_norm": 0.5599538087844849,
      "learning_rate": 8.861567205535412e-06,
      "loss": 0.2181,
      "step": 7190
    },
    {
      "epoch": 0.1138591130041009,
      "grad_norm": 0.041446954011917114,
      "learning_rate": 8.861408869958992e-06,
      "loss": 0.0023,
      "step": 7191
    },
    {
      "epoch": 0.11387494656174296,
      "grad_norm": 0.000985630671493709,
      "learning_rate": 8.861250534382572e-06,
      "loss": 0.0,
      "step": 7192
    },
    {
      "epoch": 0.11389078011938503,
      "grad_norm": 0.12915919721126556,
      "learning_rate": 8.86109219880615e-06,
      "loss": 0.0019,
      "step": 7193
    },
    {
      "epoch": 0.11390661367702709,
      "grad_norm": 0.3100544512271881,
      "learning_rate": 8.860933863229729e-06,
      "loss": 0.2267,
      "step": 7194
    },
    {
      "epoch": 0.11392244723466916,
      "grad_norm": 0.2087613046169281,
      "learning_rate": 8.86077552765331e-06,
      "loss": 0.0495,
      "step": 7195
    },
    {
      "epoch": 0.11393828079231122,
      "grad_norm": 0.0024653275031596422,
      "learning_rate": 8.860617192076889e-06,
      "loss": 0.0,
      "step": 7196
    },
    {
      "epoch": 0.1139541143499533,
      "grad_norm": 0.49865540862083435,
      "learning_rate": 8.860458856500468e-06,
      "loss": 0.4257,
      "step": 7197
    },
    {
      "epoch": 0.11396994790759536,
      "grad_norm": 0.012548547238111496,
      "learning_rate": 8.860300520924047e-06,
      "loss": 0.0005,
      "step": 7198
    },
    {
      "epoch": 0.11398578146523743,
      "grad_norm": 0.0019076444441452622,
      "learning_rate": 8.860142185347626e-06,
      "loss": 0.0,
      "step": 7199
    },
    {
      "epoch": 0.11400161502287949,
      "grad_norm": 0.000606286630500108,
      "learning_rate": 8.859983849771205e-06,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 0.11401744858052155,
      "grad_norm": 0.001528946217149496,
      "learning_rate": 8.859825514194786e-06,
      "loss": 0.0,
      "step": 7201
    },
    {
      "epoch": 0.11403328213816362,
      "grad_norm": 0.3087317645549774,
      "learning_rate": 8.859667178618365e-06,
      "loss": 0.2524,
      "step": 7202
    },
    {
      "epoch": 0.1140491156958057,
      "grad_norm": 0.3147810697555542,
      "learning_rate": 8.859508843041944e-06,
      "loss": 0.1177,
      "step": 7203
    },
    {
      "epoch": 0.11406494925344776,
      "grad_norm": 0.36335447430610657,
      "learning_rate": 8.859350507465523e-06,
      "loss": 0.3719,
      "step": 7204
    },
    {
      "epoch": 0.11408078281108983,
      "grad_norm": 0.013224436901509762,
      "learning_rate": 8.859192171889102e-06,
      "loss": 0.0006,
      "step": 7205
    },
    {
      "epoch": 0.11409661636873189,
      "grad_norm": 0.05004660412669182,
      "learning_rate": 8.859033836312681e-06,
      "loss": 0.003,
      "step": 7206
    },
    {
      "epoch": 0.11411244992637395,
      "grad_norm": 0.6110788583755493,
      "learning_rate": 8.858875500736262e-06,
      "loss": 0.2404,
      "step": 7207
    },
    {
      "epoch": 0.11412828348401602,
      "grad_norm": 0.30458974838256836,
      "learning_rate": 8.858717165159841e-06,
      "loss": 0.1074,
      "step": 7208
    },
    {
      "epoch": 0.1141441170416581,
      "grad_norm": 0.23975740373134613,
      "learning_rate": 8.85855882958342e-06,
      "loss": 0.0853,
      "step": 7209
    },
    {
      "epoch": 0.11415995059930016,
      "grad_norm": 0.11336185038089752,
      "learning_rate": 8.858400494006999e-06,
      "loss": 0.0028,
      "step": 7210
    },
    {
      "epoch": 0.11417578415694223,
      "grad_norm": 0.2984966039657593,
      "learning_rate": 8.858242158430578e-06,
      "loss": 0.0692,
      "step": 7211
    },
    {
      "epoch": 0.11419161771458429,
      "grad_norm": 0.28820574283599854,
      "learning_rate": 8.858083822854157e-06,
      "loss": 0.2385,
      "step": 7212
    },
    {
      "epoch": 0.11420745127222635,
      "grad_norm": 0.21472260355949402,
      "learning_rate": 8.857925487277738e-06,
      "loss": 0.0707,
      "step": 7213
    },
    {
      "epoch": 0.11422328482986842,
      "grad_norm": 0.41894984245300293,
      "learning_rate": 8.857767151701317e-06,
      "loss": 0.2438,
      "step": 7214
    },
    {
      "epoch": 0.1142391183875105,
      "grad_norm": 0.014703329652547836,
      "learning_rate": 8.857608816124896e-06,
      "loss": 0.0007,
      "step": 7215
    },
    {
      "epoch": 0.11425495194515256,
      "grad_norm": 0.2911780774593353,
      "learning_rate": 8.857450480548475e-06,
      "loss": 0.163,
      "step": 7216
    },
    {
      "epoch": 0.11427078550279463,
      "grad_norm": 0.7569453716278076,
      "learning_rate": 8.857292144972054e-06,
      "loss": 0.1338,
      "step": 7217
    },
    {
      "epoch": 0.11428661906043669,
      "grad_norm": 0.004391780123114586,
      "learning_rate": 8.857133809395633e-06,
      "loss": 0.0001,
      "step": 7218
    },
    {
      "epoch": 0.11430245261807875,
      "grad_norm": 0.3796107769012451,
      "learning_rate": 8.856975473819213e-06,
      "loss": 0.0429,
      "step": 7219
    },
    {
      "epoch": 0.11431828617572082,
      "grad_norm": 0.588554859161377,
      "learning_rate": 8.856817138242793e-06,
      "loss": 0.486,
      "step": 7220
    },
    {
      "epoch": 0.1143341197333629,
      "grad_norm": 0.2185654193162918,
      "learning_rate": 8.85665880266637e-06,
      "loss": 0.0857,
      "step": 7221
    },
    {
      "epoch": 0.11434995329100496,
      "grad_norm": 0.5639085173606873,
      "learning_rate": 8.856500467089951e-06,
      "loss": 0.5644,
      "step": 7222
    },
    {
      "epoch": 0.11436578684864702,
      "grad_norm": 0.46864622831344604,
      "learning_rate": 8.85634213151353e-06,
      "loss": 0.1106,
      "step": 7223
    },
    {
      "epoch": 0.11438162040628909,
      "grad_norm": 0.38542449474334717,
      "learning_rate": 8.85618379593711e-06,
      "loss": 0.14,
      "step": 7224
    },
    {
      "epoch": 0.11439745396393115,
      "grad_norm": 0.41101667284965515,
      "learning_rate": 8.856025460360689e-06,
      "loss": 0.3816,
      "step": 7225
    },
    {
      "epoch": 0.11441328752157322,
      "grad_norm": 0.02049744874238968,
      "learning_rate": 8.85586712478427e-06,
      "loss": 0.001,
      "step": 7226
    },
    {
      "epoch": 0.1144291210792153,
      "grad_norm": 0.14856041967868805,
      "learning_rate": 8.855708789207847e-06,
      "loss": 0.0059,
      "step": 7227
    },
    {
      "epoch": 0.11444495463685736,
      "grad_norm": 0.5803296566009521,
      "learning_rate": 8.855550453631428e-06,
      "loss": 0.2823,
      "step": 7228
    },
    {
      "epoch": 0.11446078819449942,
      "grad_norm": 0.018382837995886803,
      "learning_rate": 8.855392118055007e-06,
      "loss": 0.0008,
      "step": 7229
    },
    {
      "epoch": 0.11447662175214149,
      "grad_norm": 0.0060724844224750996,
      "learning_rate": 8.855233782478586e-06,
      "loss": 0.0001,
      "step": 7230
    },
    {
      "epoch": 0.11449245530978355,
      "grad_norm": 0.3202911615371704,
      "learning_rate": 8.855075446902165e-06,
      "loss": 0.1122,
      "step": 7231
    },
    {
      "epoch": 0.11450828886742562,
      "grad_norm": 0.5646175742149353,
      "learning_rate": 8.854917111325746e-06,
      "loss": 0.1484,
      "step": 7232
    },
    {
      "epoch": 0.1145241224250677,
      "grad_norm": 0.21423572301864624,
      "learning_rate": 8.854758775749323e-06,
      "loss": 0.1548,
      "step": 7233
    },
    {
      "epoch": 0.11453995598270976,
      "grad_norm": 0.2652663290500641,
      "learning_rate": 8.854600440172904e-06,
      "loss": 0.0073,
      "step": 7234
    },
    {
      "epoch": 0.11455578954035182,
      "grad_norm": 0.5088845491409302,
      "learning_rate": 8.854442104596483e-06,
      "loss": 0.403,
      "step": 7235
    },
    {
      "epoch": 0.11457162309799389,
      "grad_norm": 0.2407539188861847,
      "learning_rate": 8.854283769020062e-06,
      "loss": 0.0422,
      "step": 7236
    },
    {
      "epoch": 0.11458745665563595,
      "grad_norm": 0.3897629678249359,
      "learning_rate": 8.854125433443641e-06,
      "loss": 0.3044,
      "step": 7237
    },
    {
      "epoch": 0.11460329021327802,
      "grad_norm": 0.8575767874717712,
      "learning_rate": 8.853967097867222e-06,
      "loss": 0.1568,
      "step": 7238
    },
    {
      "epoch": 0.1146191237709201,
      "grad_norm": 0.012921062298119068,
      "learning_rate": 8.8538087622908e-06,
      "loss": 0.0005,
      "step": 7239
    },
    {
      "epoch": 0.11463495732856216,
      "grad_norm": 0.31087353825569153,
      "learning_rate": 8.85365042671438e-06,
      "loss": 0.1667,
      "step": 7240
    },
    {
      "epoch": 0.11465079088620422,
      "grad_norm": 0.4714677929878235,
      "learning_rate": 8.853492091137959e-06,
      "loss": 0.5277,
      "step": 7241
    },
    {
      "epoch": 0.11466662444384629,
      "grad_norm": 0.019817987456917763,
      "learning_rate": 8.853333755561538e-06,
      "loss": 0.0007,
      "step": 7242
    },
    {
      "epoch": 0.11468245800148835,
      "grad_norm": 0.2606624364852905,
      "learning_rate": 8.853175419985117e-06,
      "loss": 0.1087,
      "step": 7243
    },
    {
      "epoch": 0.11469829155913042,
      "grad_norm": 0.030052514746785164,
      "learning_rate": 8.853017084408696e-06,
      "loss": 0.0014,
      "step": 7244
    },
    {
      "epoch": 0.11471412511677248,
      "grad_norm": 1.0817855596542358,
      "learning_rate": 8.852858748832275e-06,
      "loss": 0.1249,
      "step": 7245
    },
    {
      "epoch": 0.11472995867441456,
      "grad_norm": 0.5478289723396301,
      "learning_rate": 8.852700413255854e-06,
      "loss": 0.1122,
      "step": 7246
    },
    {
      "epoch": 0.11474579223205662,
      "grad_norm": 0.013086174614727497,
      "learning_rate": 8.852542077679435e-06,
      "loss": 0.0005,
      "step": 7247
    },
    {
      "epoch": 0.11476162578969869,
      "grad_norm": 0.018817510455846786,
      "learning_rate": 8.852383742103013e-06,
      "loss": 0.001,
      "step": 7248
    },
    {
      "epoch": 0.11477745934734075,
      "grad_norm": 0.20984788239002228,
      "learning_rate": 8.852225406526593e-06,
      "loss": 0.1026,
      "step": 7249
    },
    {
      "epoch": 0.11479329290498282,
      "grad_norm": 0.004417088348418474,
      "learning_rate": 8.852067070950172e-06,
      "loss": 0.0002,
      "step": 7250
    },
    {
      "epoch": 0.11480912646262488,
      "grad_norm": 0.014469200745224953,
      "learning_rate": 8.851908735373752e-06,
      "loss": 0.0005,
      "step": 7251
    },
    {
      "epoch": 0.11482496002026696,
      "grad_norm": 0.38233867287635803,
      "learning_rate": 8.85175039979733e-06,
      "loss": 0.0822,
      "step": 7252
    },
    {
      "epoch": 0.11484079357790902,
      "grad_norm": 0.14106883108615875,
      "learning_rate": 8.851592064220911e-06,
      "loss": 0.0162,
      "step": 7253
    },
    {
      "epoch": 0.11485662713555109,
      "grad_norm": 0.6209306120872498,
      "learning_rate": 8.851433728644489e-06,
      "loss": 0.7429,
      "step": 7254
    },
    {
      "epoch": 0.11487246069319315,
      "grad_norm": 0.013792706653475761,
      "learning_rate": 8.85127539306807e-06,
      "loss": 0.0007,
      "step": 7255
    },
    {
      "epoch": 0.11488829425083522,
      "grad_norm": 0.20561105012893677,
      "learning_rate": 8.851117057491649e-06,
      "loss": 0.5132,
      "step": 7256
    },
    {
      "epoch": 0.11490412780847728,
      "grad_norm": 0.37780335545539856,
      "learning_rate": 8.850958721915228e-06,
      "loss": 0.1995,
      "step": 7257
    },
    {
      "epoch": 0.11491996136611936,
      "grad_norm": 0.5887352228164673,
      "learning_rate": 8.850800386338807e-06,
      "loss": 0.0676,
      "step": 7258
    },
    {
      "epoch": 0.11493579492376142,
      "grad_norm": 0.2844381034374237,
      "learning_rate": 8.850642050762388e-06,
      "loss": 0.051,
      "step": 7259
    },
    {
      "epoch": 0.11495162848140349,
      "grad_norm": 0.1591930091381073,
      "learning_rate": 8.850483715185965e-06,
      "loss": 0.0622,
      "step": 7260
    },
    {
      "epoch": 0.11496746203904555,
      "grad_norm": 0.3462294936180115,
      "learning_rate": 8.850325379609546e-06,
      "loss": 0.2667,
      "step": 7261
    },
    {
      "epoch": 0.11498329559668762,
      "grad_norm": 0.659242570400238,
      "learning_rate": 8.850167044033125e-06,
      "loss": 0.1424,
      "step": 7262
    },
    {
      "epoch": 0.11499912915432968,
      "grad_norm": 0.36196279525756836,
      "learning_rate": 8.850008708456704e-06,
      "loss": 0.2425,
      "step": 7263
    },
    {
      "epoch": 0.11501496271197176,
      "grad_norm": 0.4764438569545746,
      "learning_rate": 8.849850372880283e-06,
      "loss": 0.184,
      "step": 7264
    },
    {
      "epoch": 0.11503079626961382,
      "grad_norm": 0.2851223647594452,
      "learning_rate": 8.849692037303864e-06,
      "loss": 0.111,
      "step": 7265
    },
    {
      "epoch": 0.11504662982725589,
      "grad_norm": 0.2749035954475403,
      "learning_rate": 8.849533701727441e-06,
      "loss": 0.0713,
      "step": 7266
    },
    {
      "epoch": 0.11506246338489795,
      "grad_norm": 0.016871687024831772,
      "learning_rate": 8.84937536615102e-06,
      "loss": 0.0008,
      "step": 7267
    },
    {
      "epoch": 0.11507829694254001,
      "grad_norm": 0.24463053047657013,
      "learning_rate": 8.849217030574601e-06,
      "loss": 0.0372,
      "step": 7268
    },
    {
      "epoch": 0.11509413050018208,
      "grad_norm": 0.2309246063232422,
      "learning_rate": 8.84905869499818e-06,
      "loss": 0.0813,
      "step": 7269
    },
    {
      "epoch": 0.11510996405782416,
      "grad_norm": 0.39823436737060547,
      "learning_rate": 8.848900359421759e-06,
      "loss": 0.1728,
      "step": 7270
    },
    {
      "epoch": 0.11512579761546622,
      "grad_norm": 0.5319722294807434,
      "learning_rate": 8.848742023845338e-06,
      "loss": 0.0261,
      "step": 7271
    },
    {
      "epoch": 0.11514163117310829,
      "grad_norm": 0.6076722741127014,
      "learning_rate": 8.848583688268917e-06,
      "loss": 0.602,
      "step": 7272
    },
    {
      "epoch": 0.11515746473075035,
      "grad_norm": 0.0007588771404698491,
      "learning_rate": 8.848425352692496e-06,
      "loss": 0.0,
      "step": 7273
    },
    {
      "epoch": 0.11517329828839241,
      "grad_norm": 0.7903068661689758,
      "learning_rate": 8.848267017116077e-06,
      "loss": 0.6573,
      "step": 7274
    },
    {
      "epoch": 0.11518913184603448,
      "grad_norm": 0.43975260853767395,
      "learning_rate": 8.848108681539656e-06,
      "loss": 0.297,
      "step": 7275
    },
    {
      "epoch": 0.11520496540367656,
      "grad_norm": 0.29315125942230225,
      "learning_rate": 8.847950345963235e-06,
      "loss": 0.1193,
      "step": 7276
    },
    {
      "epoch": 0.11522079896131862,
      "grad_norm": 0.43508875370025635,
      "learning_rate": 8.847792010386814e-06,
      "loss": 0.6066,
      "step": 7277
    },
    {
      "epoch": 0.11523663251896069,
      "grad_norm": 0.24763080477714539,
      "learning_rate": 8.847633674810393e-06,
      "loss": 0.0706,
      "step": 7278
    },
    {
      "epoch": 0.11525246607660275,
      "grad_norm": 0.00173779611941427,
      "learning_rate": 8.847475339233973e-06,
      "loss": 0.0,
      "step": 7279
    },
    {
      "epoch": 0.11526829963424481,
      "grad_norm": 0.24038133025169373,
      "learning_rate": 8.847317003657553e-06,
      "loss": 0.0751,
      "step": 7280
    },
    {
      "epoch": 0.11528413319188688,
      "grad_norm": 0.3611150085926056,
      "learning_rate": 8.847158668081132e-06,
      "loss": 0.0466,
      "step": 7281
    },
    {
      "epoch": 0.11529996674952896,
      "grad_norm": 0.0011871315073221922,
      "learning_rate": 8.847000332504711e-06,
      "loss": 0.0,
      "step": 7282
    },
    {
      "epoch": 0.11531580030717102,
      "grad_norm": 0.365398645401001,
      "learning_rate": 8.84684199692829e-06,
      "loss": 0.3868,
      "step": 7283
    },
    {
      "epoch": 0.11533163386481309,
      "grad_norm": 0.7663768529891968,
      "learning_rate": 8.84668366135187e-06,
      "loss": 0.2086,
      "step": 7284
    },
    {
      "epoch": 0.11534746742245515,
      "grad_norm": 0.2429913431406021,
      "learning_rate": 8.846525325775449e-06,
      "loss": 0.0136,
      "step": 7285
    },
    {
      "epoch": 0.11536330098009721,
      "grad_norm": 0.22558754682540894,
      "learning_rate": 8.84636699019903e-06,
      "loss": 0.0433,
      "step": 7286
    },
    {
      "epoch": 0.11537913453773928,
      "grad_norm": 0.14465847611427307,
      "learning_rate": 8.846208654622609e-06,
      "loss": 0.0585,
      "step": 7287
    },
    {
      "epoch": 0.11539496809538136,
      "grad_norm": 0.003358613234013319,
      "learning_rate": 8.846050319046188e-06,
      "loss": 0.0001,
      "step": 7288
    },
    {
      "epoch": 0.11541080165302342,
      "grad_norm": 0.10847435146570206,
      "learning_rate": 8.845891983469767e-06,
      "loss": 0.0034,
      "step": 7289
    },
    {
      "epoch": 0.11542663521066548,
      "grad_norm": 0.3448922038078308,
      "learning_rate": 8.845733647893346e-06,
      "loss": 0.1157,
      "step": 7290
    },
    {
      "epoch": 0.11544246876830755,
      "grad_norm": 0.5251159071922302,
      "learning_rate": 8.845575312316925e-06,
      "loss": 0.2146,
      "step": 7291
    },
    {
      "epoch": 0.11545830232594961,
      "grad_norm": 0.33740249276161194,
      "learning_rate": 8.845416976740504e-06,
      "loss": 0.4792,
      "step": 7292
    },
    {
      "epoch": 0.11547413588359168,
      "grad_norm": 0.4337749481201172,
      "learning_rate": 8.845258641164085e-06,
      "loss": 0.2079,
      "step": 7293
    },
    {
      "epoch": 0.11548996944123376,
      "grad_norm": 0.24477413296699524,
      "learning_rate": 8.845100305587662e-06,
      "loss": 0.0771,
      "step": 7294
    },
    {
      "epoch": 0.11550580299887582,
      "grad_norm": 0.24267876148223877,
      "learning_rate": 8.844941970011243e-06,
      "loss": 0.0569,
      "step": 7295
    },
    {
      "epoch": 0.11552163655651788,
      "grad_norm": 0.20410093665122986,
      "learning_rate": 8.844783634434822e-06,
      "loss": 0.0712,
      "step": 7296
    },
    {
      "epoch": 0.11553747011415995,
      "grad_norm": 0.1788853108882904,
      "learning_rate": 8.844625298858401e-06,
      "loss": 0.0608,
      "step": 7297
    },
    {
      "epoch": 0.11555330367180201,
      "grad_norm": 0.4105941355228424,
      "learning_rate": 8.84446696328198e-06,
      "loss": 0.2189,
      "step": 7298
    },
    {
      "epoch": 0.11556913722944408,
      "grad_norm": 0.023429252207279205,
      "learning_rate": 8.844308627705561e-06,
      "loss": 0.0009,
      "step": 7299
    },
    {
      "epoch": 0.11558497078708616,
      "grad_norm": 0.376675546169281,
      "learning_rate": 8.844150292129138e-06,
      "loss": 0.0436,
      "step": 7300
    },
    {
      "epoch": 0.11560080434472822,
      "grad_norm": 0.2013031542301178,
      "learning_rate": 8.843991956552719e-06,
      "loss": 0.0693,
      "step": 7301
    },
    {
      "epoch": 0.11561663790237028,
      "grad_norm": 0.0010055835591629148,
      "learning_rate": 8.843833620976298e-06,
      "loss": 0.0,
      "step": 7302
    },
    {
      "epoch": 0.11563247146001235,
      "grad_norm": 0.46924108266830444,
      "learning_rate": 8.843675285399877e-06,
      "loss": 0.2906,
      "step": 7303
    },
    {
      "epoch": 0.11564830501765441,
      "grad_norm": 0.28904613852500916,
      "learning_rate": 8.843516949823456e-06,
      "loss": 0.0656,
      "step": 7304
    },
    {
      "epoch": 0.11566413857529648,
      "grad_norm": 0.29269939661026,
      "learning_rate": 8.843358614247037e-06,
      "loss": 0.2123,
      "step": 7305
    },
    {
      "epoch": 0.11567997213293855,
      "grad_norm": 0.5242514610290527,
      "learning_rate": 8.843200278670614e-06,
      "loss": 0.1134,
      "step": 7306
    },
    {
      "epoch": 0.11569580569058062,
      "grad_norm": 0.01957886666059494,
      "learning_rate": 8.843041943094195e-06,
      "loss": 0.0007,
      "step": 7307
    },
    {
      "epoch": 0.11571163924822268,
      "grad_norm": 0.3674063980579376,
      "learning_rate": 8.842883607517774e-06,
      "loss": 0.1946,
      "step": 7308
    },
    {
      "epoch": 0.11572747280586475,
      "grad_norm": 0.19400456547737122,
      "learning_rate": 8.842725271941353e-06,
      "loss": 0.1497,
      "step": 7309
    },
    {
      "epoch": 0.11574330636350681,
      "grad_norm": 0.1699295938014984,
      "learning_rate": 8.842566936364932e-06,
      "loss": 0.1098,
      "step": 7310
    },
    {
      "epoch": 0.11575913992114888,
      "grad_norm": 0.427182674407959,
      "learning_rate": 8.842408600788512e-06,
      "loss": 0.3419,
      "step": 7311
    },
    {
      "epoch": 0.11577497347879095,
      "grad_norm": 0.3466981053352356,
      "learning_rate": 8.84225026521209e-06,
      "loss": 0.168,
      "step": 7312
    },
    {
      "epoch": 0.11579080703643302,
      "grad_norm": 0.37532839179039,
      "learning_rate": 8.842091929635671e-06,
      "loss": 0.2154,
      "step": 7313
    },
    {
      "epoch": 0.11580664059407508,
      "grad_norm": 0.20467518270015717,
      "learning_rate": 8.84193359405925e-06,
      "loss": 0.0261,
      "step": 7314
    },
    {
      "epoch": 0.11582247415171715,
      "grad_norm": 0.09881415963172913,
      "learning_rate": 8.841775258482828e-06,
      "loss": 0.0025,
      "step": 7315
    },
    {
      "epoch": 0.11583830770935921,
      "grad_norm": 0.42570292949676514,
      "learning_rate": 8.841616922906409e-06,
      "loss": 0.2189,
      "step": 7316
    },
    {
      "epoch": 0.11585414126700128,
      "grad_norm": 0.029472772032022476,
      "learning_rate": 8.841458587329988e-06,
      "loss": 0.0029,
      "step": 7317
    },
    {
      "epoch": 0.11586997482464335,
      "grad_norm": 0.005903799552470446,
      "learning_rate": 8.841300251753567e-06,
      "loss": 0.0001,
      "step": 7318
    },
    {
      "epoch": 0.11588580838228542,
      "grad_norm": 0.15126755833625793,
      "learning_rate": 8.841141916177146e-06,
      "loss": 0.0218,
      "step": 7319
    },
    {
      "epoch": 0.11590164193992748,
      "grad_norm": 0.33504992723464966,
      "learning_rate": 8.840983580600727e-06,
      "loss": 0.0538,
      "step": 7320
    },
    {
      "epoch": 0.11591747549756955,
      "grad_norm": 0.2959785461425781,
      "learning_rate": 8.840825245024304e-06,
      "loss": 0.1319,
      "step": 7321
    },
    {
      "epoch": 0.11593330905521161,
      "grad_norm": 0.3310742676258087,
      "learning_rate": 8.840666909447885e-06,
      "loss": 0.1324,
      "step": 7322
    },
    {
      "epoch": 0.11594914261285368,
      "grad_norm": 0.05148809403181076,
      "learning_rate": 8.840508573871464e-06,
      "loss": 0.0015,
      "step": 7323
    },
    {
      "epoch": 0.11596497617049575,
      "grad_norm": 0.4529828727245331,
      "learning_rate": 8.840350238295043e-06,
      "loss": 0.0562,
      "step": 7324
    },
    {
      "epoch": 0.11598080972813782,
      "grad_norm": 0.3552139103412628,
      "learning_rate": 8.840191902718622e-06,
      "loss": 0.4298,
      "step": 7325
    },
    {
      "epoch": 0.11599664328577988,
      "grad_norm": 0.3099091947078705,
      "learning_rate": 8.840033567142203e-06,
      "loss": 0.1171,
      "step": 7326
    },
    {
      "epoch": 0.11601247684342195,
      "grad_norm": 0.41574081778526306,
      "learning_rate": 8.83987523156578e-06,
      "loss": 0.3293,
      "step": 7327
    },
    {
      "epoch": 0.11602831040106401,
      "grad_norm": 0.005611363332718611,
      "learning_rate": 8.839716895989361e-06,
      "loss": 0.0001,
      "step": 7328
    },
    {
      "epoch": 0.11604414395870608,
      "grad_norm": 0.008396370336413383,
      "learning_rate": 8.83955856041294e-06,
      "loss": 0.0004,
      "step": 7329
    },
    {
      "epoch": 0.11605997751634815,
      "grad_norm": 0.005802650470286608,
      "learning_rate": 8.839400224836519e-06,
      "loss": 0.0003,
      "step": 7330
    },
    {
      "epoch": 0.11607581107399022,
      "grad_norm": 0.002811546204611659,
      "learning_rate": 8.839241889260098e-06,
      "loss": 0.0001,
      "step": 7331
    },
    {
      "epoch": 0.11609164463163228,
      "grad_norm": 0.19397437572479248,
      "learning_rate": 8.839083553683679e-06,
      "loss": 0.0701,
      "step": 7332
    },
    {
      "epoch": 0.11610747818927435,
      "grad_norm": 0.3320005536079407,
      "learning_rate": 8.838925218107256e-06,
      "loss": 0.0599,
      "step": 7333
    },
    {
      "epoch": 0.11612331174691641,
      "grad_norm": 0.4374646842479706,
      "learning_rate": 8.838766882530837e-06,
      "loss": 0.6221,
      "step": 7334
    },
    {
      "epoch": 0.11613914530455847,
      "grad_norm": 0.2456495463848114,
      "learning_rate": 8.838608546954416e-06,
      "loss": 0.0515,
      "step": 7335
    },
    {
      "epoch": 0.11615497886220055,
      "grad_norm": 0.4241921007633209,
      "learning_rate": 8.838450211377995e-06,
      "loss": 0.4238,
      "step": 7336
    },
    {
      "epoch": 0.11617081241984262,
      "grad_norm": 0.25609225034713745,
      "learning_rate": 8.838291875801574e-06,
      "loss": 0.1319,
      "step": 7337
    },
    {
      "epoch": 0.11618664597748468,
      "grad_norm": 0.020880253985524178,
      "learning_rate": 8.838133540225155e-06,
      "loss": 0.001,
      "step": 7338
    },
    {
      "epoch": 0.11620247953512675,
      "grad_norm": 0.017282066866755486,
      "learning_rate": 8.837975204648733e-06,
      "loss": 0.001,
      "step": 7339
    },
    {
      "epoch": 0.11621831309276881,
      "grad_norm": 0.5116052031517029,
      "learning_rate": 8.837816869072312e-06,
      "loss": 0.2506,
      "step": 7340
    },
    {
      "epoch": 0.11623414665041087,
      "grad_norm": 0.12346803396940231,
      "learning_rate": 8.837658533495892e-06,
      "loss": 0.0215,
      "step": 7341
    },
    {
      "epoch": 0.11624998020805295,
      "grad_norm": 0.2599189877510071,
      "learning_rate": 8.837500197919471e-06,
      "loss": 0.1672,
      "step": 7342
    },
    {
      "epoch": 0.11626581376569502,
      "grad_norm": 0.288366436958313,
      "learning_rate": 8.83734186234305e-06,
      "loss": 0.1374,
      "step": 7343
    },
    {
      "epoch": 0.11628164732333708,
      "grad_norm": 0.32777345180511475,
      "learning_rate": 8.83718352676663e-06,
      "loss": 0.1254,
      "step": 7344
    },
    {
      "epoch": 0.11629748088097915,
      "grad_norm": 0.018690014258027077,
      "learning_rate": 8.837025191190209e-06,
      "loss": 0.0008,
      "step": 7345
    },
    {
      "epoch": 0.11631331443862121,
      "grad_norm": 0.8221426606178284,
      "learning_rate": 8.836866855613788e-06,
      "loss": 0.1168,
      "step": 7346
    },
    {
      "epoch": 0.11632914799626327,
      "grad_norm": 0.2218708097934723,
      "learning_rate": 8.836708520037369e-06,
      "loss": 0.0395,
      "step": 7347
    },
    {
      "epoch": 0.11634498155390535,
      "grad_norm": 0.23347817361354828,
      "learning_rate": 8.836550184460948e-06,
      "loss": 0.137,
      "step": 7348
    },
    {
      "epoch": 0.11636081511154742,
      "grad_norm": 0.14074859023094177,
      "learning_rate": 8.836391848884527e-06,
      "loss": 0.0472,
      "step": 7349
    },
    {
      "epoch": 0.11637664866918948,
      "grad_norm": 0.5012726783752441,
      "learning_rate": 8.836233513308106e-06,
      "loss": 0.5167,
      "step": 7350
    },
    {
      "epoch": 0.11639248222683155,
      "grad_norm": 0.4393389821052551,
      "learning_rate": 8.836075177731685e-06,
      "loss": 0.006,
      "step": 7351
    },
    {
      "epoch": 0.11640831578447361,
      "grad_norm": 0.34790492057800293,
      "learning_rate": 8.835916842155264e-06,
      "loss": 0.2523,
      "step": 7352
    },
    {
      "epoch": 0.11642414934211567,
      "grad_norm": 0.44316402077674866,
      "learning_rate": 8.835758506578845e-06,
      "loss": 0.524,
      "step": 7353
    },
    {
      "epoch": 0.11643998289975775,
      "grad_norm": 0.009334612637758255,
      "learning_rate": 8.835600171002424e-06,
      "loss": 0.0005,
      "step": 7354
    },
    {
      "epoch": 0.11645581645739982,
      "grad_norm": 0.0012207641266286373,
      "learning_rate": 8.835441835426003e-06,
      "loss": 0.0,
      "step": 7355
    },
    {
      "epoch": 0.11647165001504188,
      "grad_norm": 0.14050863683223724,
      "learning_rate": 8.835283499849582e-06,
      "loss": 0.0317,
      "step": 7356
    },
    {
      "epoch": 0.11648748357268394,
      "grad_norm": 0.3942788243293762,
      "learning_rate": 8.835125164273161e-06,
      "loss": 0.0375,
      "step": 7357
    },
    {
      "epoch": 0.11650331713032601,
      "grad_norm": 0.014486316591501236,
      "learning_rate": 8.83496682869674e-06,
      "loss": 0.0003,
      "step": 7358
    },
    {
      "epoch": 0.11651915068796807,
      "grad_norm": 0.39612990617752075,
      "learning_rate": 8.834808493120321e-06,
      "loss": 0.5327,
      "step": 7359
    },
    {
      "epoch": 0.11653498424561015,
      "grad_norm": 0.013412967324256897,
      "learning_rate": 8.8346501575439e-06,
      "loss": 0.0015,
      "step": 7360
    },
    {
      "epoch": 0.11655081780325222,
      "grad_norm": 0.5861220359802246,
      "learning_rate": 8.834491821967479e-06,
      "loss": 0.3048,
      "step": 7361
    },
    {
      "epoch": 0.11656665136089428,
      "grad_norm": 0.25063714385032654,
      "learning_rate": 8.834333486391058e-06,
      "loss": 0.0923,
      "step": 7362
    },
    {
      "epoch": 0.11658248491853634,
      "grad_norm": 0.3628859519958496,
      "learning_rate": 8.834175150814637e-06,
      "loss": 0.0934,
      "step": 7363
    },
    {
      "epoch": 0.11659831847617841,
      "grad_norm": 0.4857110381126404,
      "learning_rate": 8.834016815238216e-06,
      "loss": 0.5464,
      "step": 7364
    },
    {
      "epoch": 0.11661415203382047,
      "grad_norm": 0.28787708282470703,
      "learning_rate": 8.833858479661795e-06,
      "loss": 0.239,
      "step": 7365
    },
    {
      "epoch": 0.11662998559146255,
      "grad_norm": 0.010677986778318882,
      "learning_rate": 8.833700144085376e-06,
      "loss": 0.0002,
      "step": 7366
    },
    {
      "epoch": 0.11664581914910462,
      "grad_norm": 0.540644109249115,
      "learning_rate": 8.833541808508954e-06,
      "loss": 0.0524,
      "step": 7367
    },
    {
      "epoch": 0.11666165270674668,
      "grad_norm": 0.24026797711849213,
      "learning_rate": 8.833383472932534e-06,
      "loss": 0.1809,
      "step": 7368
    },
    {
      "epoch": 0.11667748626438874,
      "grad_norm": 0.23870915174484253,
      "learning_rate": 8.833225137356113e-06,
      "loss": 0.0659,
      "step": 7369
    },
    {
      "epoch": 0.11669331982203081,
      "grad_norm": 0.19831618666648865,
      "learning_rate": 8.833066801779692e-06,
      "loss": 0.0061,
      "step": 7370
    },
    {
      "epoch": 0.11670915337967287,
      "grad_norm": 0.3866181969642639,
      "learning_rate": 8.832908466203272e-06,
      "loss": 0.2144,
      "step": 7371
    },
    {
      "epoch": 0.11672498693731495,
      "grad_norm": 0.01753411628305912,
      "learning_rate": 8.832750130626852e-06,
      "loss": 0.001,
      "step": 7372
    },
    {
      "epoch": 0.11674082049495701,
      "grad_norm": 0.006682087201625109,
      "learning_rate": 8.83259179505043e-06,
      "loss": 0.0005,
      "step": 7373
    },
    {
      "epoch": 0.11675665405259908,
      "grad_norm": 0.4290255010128021,
      "learning_rate": 8.83243345947401e-06,
      "loss": 0.3901,
      "step": 7374
    },
    {
      "epoch": 0.11677248761024114,
      "grad_norm": 0.028102731332182884,
      "learning_rate": 8.83227512389759e-06,
      "loss": 0.0011,
      "step": 7375
    },
    {
      "epoch": 0.11678832116788321,
      "grad_norm": 0.3464651107788086,
      "learning_rate": 8.832116788321169e-06,
      "loss": 0.3432,
      "step": 7376
    },
    {
      "epoch": 0.11680415472552527,
      "grad_norm": 0.2511195242404938,
      "learning_rate": 8.831958452744748e-06,
      "loss": 0.0997,
      "step": 7377
    },
    {
      "epoch": 0.11681998828316735,
      "grad_norm": 0.23811674118041992,
      "learning_rate": 8.831800117168327e-06,
      "loss": 0.1261,
      "step": 7378
    },
    {
      "epoch": 0.11683582184080941,
      "grad_norm": 0.18548962473869324,
      "learning_rate": 8.831641781591906e-06,
      "loss": 0.0513,
      "step": 7379
    },
    {
      "epoch": 0.11685165539845148,
      "grad_norm": 0.4170117974281311,
      "learning_rate": 8.831483446015487e-06,
      "loss": 0.1042,
      "step": 7380
    },
    {
      "epoch": 0.11686748895609354,
      "grad_norm": 0.22202789783477783,
      "learning_rate": 8.831325110439066e-06,
      "loss": 0.09,
      "step": 7381
    },
    {
      "epoch": 0.11688332251373561,
      "grad_norm": 0.622238278388977,
      "learning_rate": 8.831166774862645e-06,
      "loss": 0.5517,
      "step": 7382
    },
    {
      "epoch": 0.11689915607137767,
      "grad_norm": 0.302110493183136,
      "learning_rate": 8.831008439286224e-06,
      "loss": 0.0693,
      "step": 7383
    },
    {
      "epoch": 0.11691498962901975,
      "grad_norm": 0.4951505959033966,
      "learning_rate": 8.830850103709803e-06,
      "loss": 0.1657,
      "step": 7384
    },
    {
      "epoch": 0.11693082318666181,
      "grad_norm": 0.3712103068828583,
      "learning_rate": 8.830691768133382e-06,
      "loss": 0.3202,
      "step": 7385
    },
    {
      "epoch": 0.11694665674430388,
      "grad_norm": 0.2299327701330185,
      "learning_rate": 8.830533432556963e-06,
      "loss": 0.0183,
      "step": 7386
    },
    {
      "epoch": 0.11696249030194594,
      "grad_norm": 0.3284660875797272,
      "learning_rate": 8.830375096980542e-06,
      "loss": 0.0571,
      "step": 7387
    },
    {
      "epoch": 0.11697832385958801,
      "grad_norm": 0.002039814367890358,
      "learning_rate": 8.83021676140412e-06,
      "loss": 0.0001,
      "step": 7388
    },
    {
      "epoch": 0.11699415741723007,
      "grad_norm": 0.18287238478660583,
      "learning_rate": 8.8300584258277e-06,
      "loss": 0.0323,
      "step": 7389
    },
    {
      "epoch": 0.11700999097487215,
      "grad_norm": 0.6753209233283997,
      "learning_rate": 8.82990009025128e-06,
      "loss": 0.8187,
      "step": 7390
    },
    {
      "epoch": 0.11702582453251421,
      "grad_norm": 0.2296333909034729,
      "learning_rate": 8.829741754674858e-06,
      "loss": 0.1266,
      "step": 7391
    },
    {
      "epoch": 0.11704165809015628,
      "grad_norm": 0.0004183826094958931,
      "learning_rate": 8.829583419098437e-06,
      "loss": 0.0,
      "step": 7392
    },
    {
      "epoch": 0.11705749164779834,
      "grad_norm": 0.4610387980937958,
      "learning_rate": 8.829425083522018e-06,
      "loss": 0.2289,
      "step": 7393
    },
    {
      "epoch": 0.1170733252054404,
      "grad_norm": 0.6454416513442993,
      "learning_rate": 8.829266747945595e-06,
      "loss": 0.1214,
      "step": 7394
    },
    {
      "epoch": 0.11708915876308247,
      "grad_norm": 0.09608855843544006,
      "learning_rate": 8.829108412369176e-06,
      "loss": 0.0075,
      "step": 7395
    },
    {
      "epoch": 0.11710499232072455,
      "grad_norm": 0.45807892084121704,
      "learning_rate": 8.828950076792755e-06,
      "loss": 0.0708,
      "step": 7396
    },
    {
      "epoch": 0.11712082587836661,
      "grad_norm": 0.01281747780740261,
      "learning_rate": 8.828791741216334e-06,
      "loss": 0.0005,
      "step": 7397
    },
    {
      "epoch": 0.11713665943600868,
      "grad_norm": 0.0019420890603214502,
      "learning_rate": 8.828633405639913e-06,
      "loss": 0.0,
      "step": 7398
    },
    {
      "epoch": 0.11715249299365074,
      "grad_norm": 0.12436837702989578,
      "learning_rate": 8.828475070063494e-06,
      "loss": 0.0102,
      "step": 7399
    },
    {
      "epoch": 0.1171683265512928,
      "grad_norm": 0.2851964235305786,
      "learning_rate": 8.828316734487072e-06,
      "loss": 0.3043,
      "step": 7400
    },
    {
      "epoch": 0.11718416010893487,
      "grad_norm": 0.2559429705142975,
      "learning_rate": 8.828158398910652e-06,
      "loss": 0.0771,
      "step": 7401
    },
    {
      "epoch": 0.11719999366657695,
      "grad_norm": 0.49378088116645813,
      "learning_rate": 8.828000063334231e-06,
      "loss": 0.6296,
      "step": 7402
    },
    {
      "epoch": 0.11721582722421901,
      "grad_norm": 0.5564534068107605,
      "learning_rate": 8.82784172775781e-06,
      "loss": 0.0996,
      "step": 7403
    },
    {
      "epoch": 0.11723166078186108,
      "grad_norm": 0.008407814428210258,
      "learning_rate": 8.82768339218139e-06,
      "loss": 0.0003,
      "step": 7404
    },
    {
      "epoch": 0.11724749433950314,
      "grad_norm": 0.010548725724220276,
      "learning_rate": 8.82752505660497e-06,
      "loss": 0.0003,
      "step": 7405
    },
    {
      "epoch": 0.1172633278971452,
      "grad_norm": 0.022029120475053787,
      "learning_rate": 8.827366721028548e-06,
      "loss": 0.0011,
      "step": 7406
    },
    {
      "epoch": 0.11727916145478727,
      "grad_norm": 0.25935816764831543,
      "learning_rate": 8.827208385452129e-06,
      "loss": 0.2374,
      "step": 7407
    },
    {
      "epoch": 0.11729499501242935,
      "grad_norm": 0.45327675342559814,
      "learning_rate": 8.827050049875708e-06,
      "loss": 0.1247,
      "step": 7408
    },
    {
      "epoch": 0.11731082857007141,
      "grad_norm": 0.1658758670091629,
      "learning_rate": 8.826891714299287e-06,
      "loss": 0.0379,
      "step": 7409
    },
    {
      "epoch": 0.11732666212771348,
      "grad_norm": 0.2734619677066803,
      "learning_rate": 8.826733378722866e-06,
      "loss": 0.136,
      "step": 7410
    },
    {
      "epoch": 0.11734249568535554,
      "grad_norm": 0.007264258340001106,
      "learning_rate": 8.826575043146445e-06,
      "loss": 0.0002,
      "step": 7411
    },
    {
      "epoch": 0.1173583292429976,
      "grad_norm": 0.015023868530988693,
      "learning_rate": 8.826416707570024e-06,
      "loss": 0.0007,
      "step": 7412
    },
    {
      "epoch": 0.11737416280063967,
      "grad_norm": 1.042474389076233,
      "learning_rate": 8.826258371993603e-06,
      "loss": 0.9425,
      "step": 7413
    },
    {
      "epoch": 0.11738999635828175,
      "grad_norm": 0.29405900835990906,
      "learning_rate": 8.826100036417184e-06,
      "loss": 0.0717,
      "step": 7414
    },
    {
      "epoch": 0.11740582991592381,
      "grad_norm": 1.1350797414779663,
      "learning_rate": 8.825941700840763e-06,
      "loss": 0.0344,
      "step": 7415
    },
    {
      "epoch": 0.11742166347356588,
      "grad_norm": 0.9616442918777466,
      "learning_rate": 8.825783365264342e-06,
      "loss": 0.0848,
      "step": 7416
    },
    {
      "epoch": 0.11743749703120794,
      "grad_norm": 0.6037731766700745,
      "learning_rate": 8.825625029687921e-06,
      "loss": 0.076,
      "step": 7417
    },
    {
      "epoch": 0.11745333058885,
      "grad_norm": 0.19739416241645813,
      "learning_rate": 8.8254666941115e-06,
      "loss": 0.08,
      "step": 7418
    },
    {
      "epoch": 0.11746916414649207,
      "grad_norm": 0.4296334981918335,
      "learning_rate": 8.82530835853508e-06,
      "loss": 0.5848,
      "step": 7419
    },
    {
      "epoch": 0.11748499770413415,
      "grad_norm": 0.008676345460116863,
      "learning_rate": 8.82515002295866e-06,
      "loss": 0.0003,
      "step": 7420
    },
    {
      "epoch": 0.11750083126177621,
      "grad_norm": 0.005836040712893009,
      "learning_rate": 8.824991687382239e-06,
      "loss": 0.0003,
      "step": 7421
    },
    {
      "epoch": 0.11751666481941828,
      "grad_norm": 0.5624034404754639,
      "learning_rate": 8.824833351805818e-06,
      "loss": 0.0809,
      "step": 7422
    },
    {
      "epoch": 0.11753249837706034,
      "grad_norm": 0.0050887977704405785,
      "learning_rate": 8.824675016229397e-06,
      "loss": 0.0002,
      "step": 7423
    },
    {
      "epoch": 0.1175483319347024,
      "grad_norm": 0.18860305845737457,
      "learning_rate": 8.824516680652976e-06,
      "loss": 0.0354,
      "step": 7424
    },
    {
      "epoch": 0.11756416549234447,
      "grad_norm": 0.37556755542755127,
      "learning_rate": 8.824358345076555e-06,
      "loss": 0.2409,
      "step": 7425
    },
    {
      "epoch": 0.11757999904998655,
      "grad_norm": 0.13144010305404663,
      "learning_rate": 8.824200009500136e-06,
      "loss": 0.0578,
      "step": 7426
    },
    {
      "epoch": 0.11759583260762861,
      "grad_norm": 0.019702797755599022,
      "learning_rate": 8.824041673923715e-06,
      "loss": 0.0007,
      "step": 7427
    },
    {
      "epoch": 0.11761166616527068,
      "grad_norm": 0.20020464062690735,
      "learning_rate": 8.823883338347294e-06,
      "loss": 0.0369,
      "step": 7428
    },
    {
      "epoch": 0.11762749972291274,
      "grad_norm": 0.46774598956108093,
      "learning_rate": 8.823725002770873e-06,
      "loss": 0.4828,
      "step": 7429
    },
    {
      "epoch": 0.1176433332805548,
      "grad_norm": 0.1511957049369812,
      "learning_rate": 8.823566667194453e-06,
      "loss": 0.0684,
      "step": 7430
    },
    {
      "epoch": 0.11765916683819687,
      "grad_norm": 0.5966616272926331,
      "learning_rate": 8.823408331618032e-06,
      "loss": 0.6508,
      "step": 7431
    },
    {
      "epoch": 0.11767500039583895,
      "grad_norm": 0.2849491238594055,
      "learning_rate": 8.823249996041612e-06,
      "loss": 0.1323,
      "step": 7432
    },
    {
      "epoch": 0.11769083395348101,
      "grad_norm": 0.4049961566925049,
      "learning_rate": 8.823091660465191e-06,
      "loss": 0.3664,
      "step": 7433
    },
    {
      "epoch": 0.11770666751112308,
      "grad_norm": 0.2961120009422302,
      "learning_rate": 8.82293332488877e-06,
      "loss": 0.064,
      "step": 7434
    },
    {
      "epoch": 0.11772250106876514,
      "grad_norm": 0.2579551935195923,
      "learning_rate": 8.82277498931235e-06,
      "loss": 0.0896,
      "step": 7435
    },
    {
      "epoch": 0.1177383346264072,
      "grad_norm": 0.11190056800842285,
      "learning_rate": 8.822616653735929e-06,
      "loss": 0.0444,
      "step": 7436
    },
    {
      "epoch": 0.11775416818404927,
      "grad_norm": 0.13181467354297638,
      "learning_rate": 8.822458318159508e-06,
      "loss": 0.0326,
      "step": 7437
    },
    {
      "epoch": 0.11777000174169135,
      "grad_norm": 0.3270203471183777,
      "learning_rate": 8.822299982583087e-06,
      "loss": 0.4693,
      "step": 7438
    },
    {
      "epoch": 0.11778583529933341,
      "grad_norm": 0.5041112303733826,
      "learning_rate": 8.822141647006666e-06,
      "loss": 0.5839,
      "step": 7439
    },
    {
      "epoch": 0.11780166885697547,
      "grad_norm": 0.5079879760742188,
      "learning_rate": 8.821983311430245e-06,
      "loss": 0.0661,
      "step": 7440
    },
    {
      "epoch": 0.11781750241461754,
      "grad_norm": 0.23889771103858948,
      "learning_rate": 8.821824975853826e-06,
      "loss": 0.1324,
      "step": 7441
    },
    {
      "epoch": 0.1178333359722596,
      "grad_norm": 0.27818942070007324,
      "learning_rate": 8.821666640277405e-06,
      "loss": 0.1122,
      "step": 7442
    },
    {
      "epoch": 0.11784916952990167,
      "grad_norm": 0.0012068620417267084,
      "learning_rate": 8.821508304700984e-06,
      "loss": 0.0,
      "step": 7443
    },
    {
      "epoch": 0.11786500308754375,
      "grad_norm": 0.15314802527427673,
      "learning_rate": 8.821349969124563e-06,
      "loss": 0.0329,
      "step": 7444
    },
    {
      "epoch": 0.11788083664518581,
      "grad_norm": 0.03092949464917183,
      "learning_rate": 8.821191633548142e-06,
      "loss": 0.0013,
      "step": 7445
    },
    {
      "epoch": 0.11789667020282787,
      "grad_norm": 0.05785989761352539,
      "learning_rate": 8.821033297971721e-06,
      "loss": 0.001,
      "step": 7446
    },
    {
      "epoch": 0.11791250376046994,
      "grad_norm": 0.25805872678756714,
      "learning_rate": 8.820874962395302e-06,
      "loss": 0.0997,
      "step": 7447
    },
    {
      "epoch": 0.117928337318112,
      "grad_norm": 0.33848342299461365,
      "learning_rate": 8.820716626818881e-06,
      "loss": 0.1752,
      "step": 7448
    },
    {
      "epoch": 0.11794417087575407,
      "grad_norm": 0.5218943953514099,
      "learning_rate": 8.82055829124246e-06,
      "loss": 0.5124,
      "step": 7449
    },
    {
      "epoch": 0.11796000443339615,
      "grad_norm": 0.5025465488433838,
      "learning_rate": 8.82039995566604e-06,
      "loss": 0.5461,
      "step": 7450
    },
    {
      "epoch": 0.11797583799103821,
      "grad_norm": 0.389619380235672,
      "learning_rate": 8.820241620089618e-06,
      "loss": 0.3478,
      "step": 7451
    },
    {
      "epoch": 0.11799167154868027,
      "grad_norm": 0.37737834453582764,
      "learning_rate": 8.820083284513197e-06,
      "loss": 0.1411,
      "step": 7452
    },
    {
      "epoch": 0.11800750510632234,
      "grad_norm": 0.22509869933128357,
      "learning_rate": 8.819924948936778e-06,
      "loss": 0.0704,
      "step": 7453
    },
    {
      "epoch": 0.1180233386639644,
      "grad_norm": 0.004976213909685612,
      "learning_rate": 8.819766613360357e-06,
      "loss": 0.0002,
      "step": 7454
    },
    {
      "epoch": 0.11803917222160647,
      "grad_norm": 0.5201186537742615,
      "learning_rate": 8.819608277783936e-06,
      "loss": 0.3092,
      "step": 7455
    },
    {
      "epoch": 0.11805500577924855,
      "grad_norm": 0.1864526867866516,
      "learning_rate": 8.819449942207515e-06,
      "loss": 0.0427,
      "step": 7456
    },
    {
      "epoch": 0.11807083933689061,
      "grad_norm": 0.36895766854286194,
      "learning_rate": 8.819291606631094e-06,
      "loss": 0.2632,
      "step": 7457
    },
    {
      "epoch": 0.11808667289453267,
      "grad_norm": 0.45441222190856934,
      "learning_rate": 8.819133271054674e-06,
      "loss": 0.147,
      "step": 7458
    },
    {
      "epoch": 0.11810250645217474,
      "grad_norm": 0.312824010848999,
      "learning_rate": 8.818974935478253e-06,
      "loss": 0.1832,
      "step": 7459
    },
    {
      "epoch": 0.1181183400098168,
      "grad_norm": 0.2925304174423218,
      "learning_rate": 8.818816599901833e-06,
      "loss": 0.0237,
      "step": 7460
    },
    {
      "epoch": 0.11813417356745887,
      "grad_norm": 0.7459614276885986,
      "learning_rate": 8.81865826432541e-06,
      "loss": 0.0465,
      "step": 7461
    },
    {
      "epoch": 0.11815000712510094,
      "grad_norm": 0.00048699454055167735,
      "learning_rate": 8.818499928748992e-06,
      "loss": 0.0,
      "step": 7462
    },
    {
      "epoch": 0.11816584068274301,
      "grad_norm": 0.3089464604854584,
      "learning_rate": 8.81834159317257e-06,
      "loss": 0.0195,
      "step": 7463
    },
    {
      "epoch": 0.11818167424038507,
      "grad_norm": 0.46417373418807983,
      "learning_rate": 8.81818325759615e-06,
      "loss": 0.1088,
      "step": 7464
    },
    {
      "epoch": 0.11819750779802714,
      "grad_norm": 0.9480305314064026,
      "learning_rate": 8.818024922019729e-06,
      "loss": 0.2792,
      "step": 7465
    },
    {
      "epoch": 0.1182133413556692,
      "grad_norm": 0.0011448821751400828,
      "learning_rate": 8.81786658644331e-06,
      "loss": 0.0,
      "step": 7466
    },
    {
      "epoch": 0.11822917491331127,
      "grad_norm": 0.9985100626945496,
      "learning_rate": 8.817708250866887e-06,
      "loss": 0.3988,
      "step": 7467
    },
    {
      "epoch": 0.11824500847095334,
      "grad_norm": 0.43847930431365967,
      "learning_rate": 8.817549915290468e-06,
      "loss": 0.211,
      "step": 7468
    },
    {
      "epoch": 0.11826084202859541,
      "grad_norm": 0.0014173092786222696,
      "learning_rate": 8.817391579714047e-06,
      "loss": 0.0,
      "step": 7469
    },
    {
      "epoch": 0.11827667558623747,
      "grad_norm": 0.0017001025844365358,
      "learning_rate": 8.817233244137626e-06,
      "loss": 0.0,
      "step": 7470
    },
    {
      "epoch": 0.11829250914387954,
      "grad_norm": 0.5035515427589417,
      "learning_rate": 8.817074908561205e-06,
      "loss": 0.1507,
      "step": 7471
    },
    {
      "epoch": 0.1183083427015216,
      "grad_norm": 0.0026091451290994883,
      "learning_rate": 8.816916572984786e-06,
      "loss": 0.0001,
      "step": 7472
    },
    {
      "epoch": 0.11832417625916367,
      "grad_norm": 0.42212021350860596,
      "learning_rate": 8.816758237408363e-06,
      "loss": 0.0968,
      "step": 7473
    },
    {
      "epoch": 0.11834000981680574,
      "grad_norm": 0.38903820514678955,
      "learning_rate": 8.816599901831944e-06,
      "loss": 0.1443,
      "step": 7474
    },
    {
      "epoch": 0.11835584337444781,
      "grad_norm": 0.6035163402557373,
      "learning_rate": 8.816441566255523e-06,
      "loss": 0.2971,
      "step": 7475
    },
    {
      "epoch": 0.11837167693208987,
      "grad_norm": 0.0014774554874747992,
      "learning_rate": 8.816283230679102e-06,
      "loss": 0.0,
      "step": 7476
    },
    {
      "epoch": 0.11838751048973194,
      "grad_norm": 0.004793637897819281,
      "learning_rate": 8.816124895102681e-06,
      "loss": 0.0001,
      "step": 7477
    },
    {
      "epoch": 0.118403344047374,
      "grad_norm": 0.2915498614311218,
      "learning_rate": 8.815966559526262e-06,
      "loss": 0.0573,
      "step": 7478
    },
    {
      "epoch": 0.11841917760501607,
      "grad_norm": 0.3380235731601715,
      "learning_rate": 8.81580822394984e-06,
      "loss": 0.0981,
      "step": 7479
    },
    {
      "epoch": 0.11843501116265814,
      "grad_norm": 0.23467467725276947,
      "learning_rate": 8.81564988837342e-06,
      "loss": 0.1002,
      "step": 7480
    },
    {
      "epoch": 0.11845084472030021,
      "grad_norm": 0.3823685348033905,
      "learning_rate": 8.815491552796999e-06,
      "loss": 0.1754,
      "step": 7481
    },
    {
      "epoch": 0.11846667827794227,
      "grad_norm": 0.7238128185272217,
      "learning_rate": 8.815333217220578e-06,
      "loss": 0.1557,
      "step": 7482
    },
    {
      "epoch": 0.11848251183558434,
      "grad_norm": 0.7348341941833496,
      "learning_rate": 8.815174881644157e-06,
      "loss": 0.8135,
      "step": 7483
    },
    {
      "epoch": 0.1184983453932264,
      "grad_norm": 0.38418760895729065,
      "learning_rate": 8.815016546067736e-06,
      "loss": 0.1227,
      "step": 7484
    },
    {
      "epoch": 0.11851417895086847,
      "grad_norm": 0.5289455652236938,
      "learning_rate": 8.814858210491315e-06,
      "loss": 0.1345,
      "step": 7485
    },
    {
      "epoch": 0.11853001250851054,
      "grad_norm": 0.25233444571495056,
      "learning_rate": 8.814699874914895e-06,
      "loss": 0.23,
      "step": 7486
    },
    {
      "epoch": 0.11854584606615261,
      "grad_norm": 0.252802312374115,
      "learning_rate": 8.814541539338475e-06,
      "loss": 0.1336,
      "step": 7487
    },
    {
      "epoch": 0.11856167962379467,
      "grad_norm": 0.23869745433330536,
      "learning_rate": 8.814383203762054e-06,
      "loss": 0.1142,
      "step": 7488
    },
    {
      "epoch": 0.11857751318143674,
      "grad_norm": 0.32753312587738037,
      "learning_rate": 8.814224868185633e-06,
      "loss": 0.4015,
      "step": 7489
    },
    {
      "epoch": 0.1185933467390788,
      "grad_norm": 0.22659605741500854,
      "learning_rate": 8.814066532609213e-06,
      "loss": 0.0499,
      "step": 7490
    },
    {
      "epoch": 0.11860918029672086,
      "grad_norm": 0.33975037932395935,
      "learning_rate": 8.813908197032792e-06,
      "loss": 0.0857,
      "step": 7491
    },
    {
      "epoch": 0.11862501385436294,
      "grad_norm": 0.013280493207275867,
      "learning_rate": 8.81374986145637e-06,
      "loss": 0.0006,
      "step": 7492
    },
    {
      "epoch": 0.11864084741200501,
      "grad_norm": 0.012632097117602825,
      "learning_rate": 8.813591525879951e-06,
      "loss": 0.0006,
      "step": 7493
    },
    {
      "epoch": 0.11865668096964707,
      "grad_norm": 0.3073030412197113,
      "learning_rate": 8.81343319030353e-06,
      "loss": 0.1284,
      "step": 7494
    },
    {
      "epoch": 0.11867251452728914,
      "grad_norm": 0.44569358229637146,
      "learning_rate": 8.81327485472711e-06,
      "loss": 0.8568,
      "step": 7495
    },
    {
      "epoch": 0.1186883480849312,
      "grad_norm": 0.4002586603164673,
      "learning_rate": 8.813116519150689e-06,
      "loss": 0.1367,
      "step": 7496
    },
    {
      "epoch": 0.11870418164257326,
      "grad_norm": 0.27828511595726013,
      "learning_rate": 8.812958183574268e-06,
      "loss": 0.1612,
      "step": 7497
    },
    {
      "epoch": 0.11872001520021534,
      "grad_norm": 0.4520975351333618,
      "learning_rate": 8.812799847997847e-06,
      "loss": 0.4394,
      "step": 7498
    },
    {
      "epoch": 0.1187358487578574,
      "grad_norm": 0.0011708330130204558,
      "learning_rate": 8.812641512421428e-06,
      "loss": 0.0,
      "step": 7499
    },
    {
      "epoch": 0.11875168231549947,
      "grad_norm": 0.31653907895088196,
      "learning_rate": 8.812483176845007e-06,
      "loss": 0.2107,
      "step": 7500
    },
    {
      "epoch": 0.11876751587314154,
      "grad_norm": 0.1366567313671112,
      "learning_rate": 8.812324841268586e-06,
      "loss": 0.0423,
      "step": 7501
    },
    {
      "epoch": 0.1187833494307836,
      "grad_norm": 0.28098711371421814,
      "learning_rate": 8.812166505692165e-06,
      "loss": 0.0709,
      "step": 7502
    },
    {
      "epoch": 0.11879918298842566,
      "grad_norm": 0.2800966203212738,
      "learning_rate": 8.812008170115744e-06,
      "loss": 0.1766,
      "step": 7503
    },
    {
      "epoch": 0.11881501654606774,
      "grad_norm": 0.24063774943351746,
      "learning_rate": 8.811849834539323e-06,
      "loss": 0.053,
      "step": 7504
    },
    {
      "epoch": 0.1188308501037098,
      "grad_norm": 0.00549272308126092,
      "learning_rate": 8.811691498962904e-06,
      "loss": 0.0001,
      "step": 7505
    },
    {
      "epoch": 0.11884668366135187,
      "grad_norm": 0.009105686098337173,
      "learning_rate": 8.811533163386481e-06,
      "loss": 0.0003,
      "step": 7506
    },
    {
      "epoch": 0.11886251721899393,
      "grad_norm": 0.022382019087672234,
      "learning_rate": 8.81137482781006e-06,
      "loss": 0.0013,
      "step": 7507
    },
    {
      "epoch": 0.118878350776636,
      "grad_norm": 0.490327924489975,
      "learning_rate": 8.811216492233641e-06,
      "loss": 0.1933,
      "step": 7508
    },
    {
      "epoch": 0.11889418433427806,
      "grad_norm": 0.008834542706608772,
      "learning_rate": 8.81105815665722e-06,
      "loss": 0.0004,
      "step": 7509
    },
    {
      "epoch": 0.11891001789192014,
      "grad_norm": 0.34316492080688477,
      "learning_rate": 8.8108998210808e-06,
      "loss": 0.2509,
      "step": 7510
    },
    {
      "epoch": 0.1189258514495622,
      "grad_norm": 0.022479146718978882,
      "learning_rate": 8.810741485504378e-06,
      "loss": 0.0011,
      "step": 7511
    },
    {
      "epoch": 0.11894168500720427,
      "grad_norm": 0.43713054060935974,
      "learning_rate": 8.810583149927957e-06,
      "loss": 0.2079,
      "step": 7512
    },
    {
      "epoch": 0.11895751856484633,
      "grad_norm": 0.5198626518249512,
      "learning_rate": 8.810424814351536e-06,
      "loss": 0.5197,
      "step": 7513
    },
    {
      "epoch": 0.1189733521224884,
      "grad_norm": 0.37228506803512573,
      "learning_rate": 8.810266478775117e-06,
      "loss": 0.143,
      "step": 7514
    },
    {
      "epoch": 0.11898918568013046,
      "grad_norm": 0.42024385929107666,
      "learning_rate": 8.810108143198696e-06,
      "loss": 0.2364,
      "step": 7515
    },
    {
      "epoch": 0.11900501923777254,
      "grad_norm": 0.16266793012619019,
      "learning_rate": 8.809949807622275e-06,
      "loss": 0.049,
      "step": 7516
    },
    {
      "epoch": 0.1190208527954146,
      "grad_norm": 0.961854875087738,
      "learning_rate": 8.809791472045854e-06,
      "loss": 0.3209,
      "step": 7517
    },
    {
      "epoch": 0.11903668635305667,
      "grad_norm": 0.19648878276348114,
      "learning_rate": 8.809633136469434e-06,
      "loss": 0.0545,
      "step": 7518
    },
    {
      "epoch": 0.11905251991069873,
      "grad_norm": 0.7603561282157898,
      "learning_rate": 8.809474800893013e-06,
      "loss": 0.5943,
      "step": 7519
    },
    {
      "epoch": 0.1190683534683408,
      "grad_norm": 0.07506262511014938,
      "learning_rate": 8.809316465316593e-06,
      "loss": 0.0049,
      "step": 7520
    },
    {
      "epoch": 0.11908418702598286,
      "grad_norm": 0.3603043854236603,
      "learning_rate": 8.809158129740172e-06,
      "loss": 0.2764,
      "step": 7521
    },
    {
      "epoch": 0.11910002058362494,
      "grad_norm": 0.0005813822499476373,
      "learning_rate": 8.808999794163752e-06,
      "loss": 0.0,
      "step": 7522
    },
    {
      "epoch": 0.119115854141267,
      "grad_norm": 0.23818887770175934,
      "learning_rate": 8.80884145858733e-06,
      "loss": 0.1101,
      "step": 7523
    },
    {
      "epoch": 0.11913168769890907,
      "grad_norm": 0.2403673678636551,
      "learning_rate": 8.80868312301091e-06,
      "loss": 0.0914,
      "step": 7524
    },
    {
      "epoch": 0.11914752125655113,
      "grad_norm": 0.4189966022968292,
      "learning_rate": 8.808524787434489e-06,
      "loss": 0.6219,
      "step": 7525
    },
    {
      "epoch": 0.1191633548141932,
      "grad_norm": 0.026579704135656357,
      "learning_rate": 8.80836645185807e-06,
      "loss": 0.0014,
      "step": 7526
    },
    {
      "epoch": 0.11917918837183526,
      "grad_norm": 0.30680081248283386,
      "learning_rate": 8.808208116281649e-06,
      "loss": 0.1283,
      "step": 7527
    },
    {
      "epoch": 0.11919502192947734,
      "grad_norm": 0.02166471630334854,
      "learning_rate": 8.808049780705228e-06,
      "loss": 0.0011,
      "step": 7528
    },
    {
      "epoch": 0.1192108554871194,
      "grad_norm": 0.45570412278175354,
      "learning_rate": 8.807891445128807e-06,
      "loss": 0.4839,
      "step": 7529
    },
    {
      "epoch": 0.11922668904476147,
      "grad_norm": 0.1981050819158554,
      "learning_rate": 8.807733109552386e-06,
      "loss": 0.0964,
      "step": 7530
    },
    {
      "epoch": 0.11924252260240353,
      "grad_norm": 0.2510518431663513,
      "learning_rate": 8.807574773975965e-06,
      "loss": 0.0549,
      "step": 7531
    },
    {
      "epoch": 0.1192583561600456,
      "grad_norm": 0.33923712372779846,
      "learning_rate": 8.807416438399544e-06,
      "loss": 0.4049,
      "step": 7532
    },
    {
      "epoch": 0.11927418971768766,
      "grad_norm": 0.2736542522907257,
      "learning_rate": 8.807258102823125e-06,
      "loss": 0.0231,
      "step": 7533
    },
    {
      "epoch": 0.11929002327532974,
      "grad_norm": 0.21463024616241455,
      "learning_rate": 8.807099767246702e-06,
      "loss": 0.0606,
      "step": 7534
    },
    {
      "epoch": 0.1193058568329718,
      "grad_norm": 0.18437142670154572,
      "learning_rate": 8.806941431670283e-06,
      "loss": 0.0051,
      "step": 7535
    },
    {
      "epoch": 0.11932169039061387,
      "grad_norm": 0.21356086432933807,
      "learning_rate": 8.806783096093862e-06,
      "loss": 0.0966,
      "step": 7536
    },
    {
      "epoch": 0.11933752394825593,
      "grad_norm": 0.3965708017349243,
      "learning_rate": 8.806624760517441e-06,
      "loss": 0.0798,
      "step": 7537
    },
    {
      "epoch": 0.119353357505898,
      "grad_norm": 0.0005362732918001711,
      "learning_rate": 8.80646642494102e-06,
      "loss": 0.0,
      "step": 7538
    },
    {
      "epoch": 0.11936919106354006,
      "grad_norm": 0.1902133822441101,
      "learning_rate": 8.806308089364601e-06,
      "loss": 0.1245,
      "step": 7539
    },
    {
      "epoch": 0.11938502462118214,
      "grad_norm": 0.5433982014656067,
      "learning_rate": 8.806149753788178e-06,
      "loss": 0.0669,
      "step": 7540
    },
    {
      "epoch": 0.1194008581788242,
      "grad_norm": 0.06221925467252731,
      "learning_rate": 8.805991418211759e-06,
      "loss": 0.0047,
      "step": 7541
    },
    {
      "epoch": 0.11941669173646627,
      "grad_norm": 0.5213580131530762,
      "learning_rate": 8.805833082635338e-06,
      "loss": 0.5092,
      "step": 7542
    },
    {
      "epoch": 0.11943252529410833,
      "grad_norm": 0.14025640487670898,
      "learning_rate": 8.805674747058917e-06,
      "loss": 0.0445,
      "step": 7543
    },
    {
      "epoch": 0.1194483588517504,
      "grad_norm": 0.2599671185016632,
      "learning_rate": 8.805516411482496e-06,
      "loss": 0.0463,
      "step": 7544
    },
    {
      "epoch": 0.11946419240939246,
      "grad_norm": 0.661095380783081,
      "learning_rate": 8.805358075906077e-06,
      "loss": 0.6433,
      "step": 7545
    },
    {
      "epoch": 0.11948002596703454,
      "grad_norm": 0.1882474273443222,
      "learning_rate": 8.805199740329655e-06,
      "loss": 0.0765,
      "step": 7546
    },
    {
      "epoch": 0.1194958595246766,
      "grad_norm": 0.2983022630214691,
      "learning_rate": 8.805041404753235e-06,
      "loss": 0.0582,
      "step": 7547
    },
    {
      "epoch": 0.11951169308231867,
      "grad_norm": 0.22333388030529022,
      "learning_rate": 8.804883069176814e-06,
      "loss": 0.072,
      "step": 7548
    },
    {
      "epoch": 0.11952752663996073,
      "grad_norm": 0.172649085521698,
      "learning_rate": 8.804724733600393e-06,
      "loss": 0.0502,
      "step": 7549
    },
    {
      "epoch": 0.1195433601976028,
      "grad_norm": 0.4744971692562103,
      "learning_rate": 8.804566398023973e-06,
      "loss": 0.8525,
      "step": 7550
    },
    {
      "epoch": 0.11955919375524486,
      "grad_norm": 0.4026559889316559,
      "learning_rate": 8.804408062447553e-06,
      "loss": 0.0421,
      "step": 7551
    },
    {
      "epoch": 0.11957502731288694,
      "grad_norm": 0.0142636988312006,
      "learning_rate": 8.80424972687113e-06,
      "loss": 0.0007,
      "step": 7552
    },
    {
      "epoch": 0.119590860870529,
      "grad_norm": 0.6414732933044434,
      "learning_rate": 8.804091391294711e-06,
      "loss": 1.1623,
      "step": 7553
    },
    {
      "epoch": 0.11960669442817107,
      "grad_norm": 0.35328003764152527,
      "learning_rate": 8.80393305571829e-06,
      "loss": 0.1076,
      "step": 7554
    },
    {
      "epoch": 0.11962252798581313,
      "grad_norm": 0.5565827488899231,
      "learning_rate": 8.80377472014187e-06,
      "loss": 0.0788,
      "step": 7555
    },
    {
      "epoch": 0.1196383615434552,
      "grad_norm": 0.0008577796397730708,
      "learning_rate": 8.803616384565449e-06,
      "loss": 0.0,
      "step": 7556
    },
    {
      "epoch": 0.11965419510109726,
      "grad_norm": 0.3162449300289154,
      "learning_rate": 8.803458048989028e-06,
      "loss": 0.1453,
      "step": 7557
    },
    {
      "epoch": 0.11967002865873934,
      "grad_norm": 0.03079860284924507,
      "learning_rate": 8.803299713412607e-06,
      "loss": 0.0033,
      "step": 7558
    },
    {
      "epoch": 0.1196858622163814,
      "grad_norm": 0.0030278696212917566,
      "learning_rate": 8.803141377836186e-06,
      "loss": 0.0001,
      "step": 7559
    },
    {
      "epoch": 0.11970169577402347,
      "grad_norm": 0.00026783227804116905,
      "learning_rate": 8.802983042259767e-06,
      "loss": 0.0,
      "step": 7560
    },
    {
      "epoch": 0.11971752933166553,
      "grad_norm": 0.0006386410677805543,
      "learning_rate": 8.802824706683346e-06,
      "loss": 0.0,
      "step": 7561
    },
    {
      "epoch": 0.1197333628893076,
      "grad_norm": 0.21122495830059052,
      "learning_rate": 8.802666371106925e-06,
      "loss": 0.0655,
      "step": 7562
    },
    {
      "epoch": 0.11974919644694966,
      "grad_norm": 0.016055386513471603,
      "learning_rate": 8.802508035530504e-06,
      "loss": 0.0007,
      "step": 7563
    },
    {
      "epoch": 0.11976503000459174,
      "grad_norm": 0.49340710043907166,
      "learning_rate": 8.802349699954083e-06,
      "loss": 0.4366,
      "step": 7564
    },
    {
      "epoch": 0.1197808635622338,
      "grad_norm": 0.37788793444633484,
      "learning_rate": 8.802191364377662e-06,
      "loss": 0.0633,
      "step": 7565
    },
    {
      "epoch": 0.11979669711987587,
      "grad_norm": 0.36906546354293823,
      "learning_rate": 8.802033028801243e-06,
      "loss": 0.0578,
      "step": 7566
    },
    {
      "epoch": 0.11981253067751793,
      "grad_norm": 0.9346694946289062,
      "learning_rate": 8.801874693224822e-06,
      "loss": 0.8283,
      "step": 7567
    },
    {
      "epoch": 0.11982836423516,
      "grad_norm": 0.003828258952125907,
      "learning_rate": 8.801716357648401e-06,
      "loss": 0.0,
      "step": 7568
    },
    {
      "epoch": 0.11984419779280206,
      "grad_norm": 0.09851647168397903,
      "learning_rate": 8.80155802207198e-06,
      "loss": 0.0039,
      "step": 7569
    },
    {
      "epoch": 0.11986003135044414,
      "grad_norm": 0.3003438711166382,
      "learning_rate": 8.80139968649556e-06,
      "loss": 0.104,
      "step": 7570
    },
    {
      "epoch": 0.1198758649080862,
      "grad_norm": 0.16131214797496796,
      "learning_rate": 8.801241350919138e-06,
      "loss": 0.03,
      "step": 7571
    },
    {
      "epoch": 0.11989169846572827,
      "grad_norm": 0.03231295198202133,
      "learning_rate": 8.801083015342719e-06,
      "loss": 0.0017,
      "step": 7572
    },
    {
      "epoch": 0.11990753202337033,
      "grad_norm": 0.5035085082054138,
      "learning_rate": 8.800924679766296e-06,
      "loss": 0.3569,
      "step": 7573
    },
    {
      "epoch": 0.1199233655810124,
      "grad_norm": 0.19032754004001617,
      "learning_rate": 8.800766344189877e-06,
      "loss": 0.0015,
      "step": 7574
    },
    {
      "epoch": 0.11993919913865446,
      "grad_norm": 0.007677615620195866,
      "learning_rate": 8.800608008613456e-06,
      "loss": 0.0004,
      "step": 7575
    },
    {
      "epoch": 0.11995503269629654,
      "grad_norm": 0.34822070598602295,
      "learning_rate": 8.800449673037035e-06,
      "loss": 0.089,
      "step": 7576
    },
    {
      "epoch": 0.1199708662539386,
      "grad_norm": 0.00408486882224679,
      "learning_rate": 8.800291337460614e-06,
      "loss": 0.0002,
      "step": 7577
    },
    {
      "epoch": 0.11998669981158067,
      "grad_norm": 0.46505919098854065,
      "learning_rate": 8.800133001884195e-06,
      "loss": 0.5982,
      "step": 7578
    },
    {
      "epoch": 0.12000253336922273,
      "grad_norm": 0.242357537150383,
      "learning_rate": 8.799974666307773e-06,
      "loss": 0.0363,
      "step": 7579
    },
    {
      "epoch": 0.1200183669268648,
      "grad_norm": 0.5174199342727661,
      "learning_rate": 8.799816330731352e-06,
      "loss": 0.0715,
      "step": 7580
    },
    {
      "epoch": 0.12003420048450686,
      "grad_norm": 0.23926368355751038,
      "learning_rate": 8.799657995154932e-06,
      "loss": 0.0723,
      "step": 7581
    },
    {
      "epoch": 0.12005003404214894,
      "grad_norm": 0.020720496773719788,
      "learning_rate": 8.799499659578512e-06,
      "loss": 0.0011,
      "step": 7582
    },
    {
      "epoch": 0.120065867599791,
      "grad_norm": 0.0005840033991262317,
      "learning_rate": 8.79934132400209e-06,
      "loss": 0.0,
      "step": 7583
    },
    {
      "epoch": 0.12008170115743307,
      "grad_norm": 0.45367273688316345,
      "learning_rate": 8.79918298842567e-06,
      "loss": 0.4609,
      "step": 7584
    },
    {
      "epoch": 0.12009753471507513,
      "grad_norm": 1.4027217626571655,
      "learning_rate": 8.799024652849249e-06,
      "loss": 0.3111,
      "step": 7585
    },
    {
      "epoch": 0.1201133682727172,
      "grad_norm": 0.12883292138576508,
      "learning_rate": 8.798866317272828e-06,
      "loss": 0.0391,
      "step": 7586
    },
    {
      "epoch": 0.12012920183035926,
      "grad_norm": 0.011211872100830078,
      "learning_rate": 8.798707981696409e-06,
      "loss": 0.0005,
      "step": 7587
    },
    {
      "epoch": 0.12014503538800134,
      "grad_norm": 0.2264065146446228,
      "learning_rate": 8.798549646119988e-06,
      "loss": 0.044,
      "step": 7588
    },
    {
      "epoch": 0.1201608689456434,
      "grad_norm": 0.029612362384796143,
      "learning_rate": 8.798391310543567e-06,
      "loss": 0.0013,
      "step": 7589
    },
    {
      "epoch": 0.12017670250328547,
      "grad_norm": 0.01347630750387907,
      "learning_rate": 8.798232974967146e-06,
      "loss": 0.0007,
      "step": 7590
    },
    {
      "epoch": 0.12019253606092753,
      "grad_norm": 0.2959389090538025,
      "learning_rate": 8.798074639390725e-06,
      "loss": 0.0413,
      "step": 7591
    },
    {
      "epoch": 0.1202083696185696,
      "grad_norm": 0.12488703429698944,
      "learning_rate": 8.797916303814304e-06,
      "loss": 0.0374,
      "step": 7592
    },
    {
      "epoch": 0.12022420317621166,
      "grad_norm": 0.29067113995552063,
      "learning_rate": 8.797757968237885e-06,
      "loss": 0.1758,
      "step": 7593
    },
    {
      "epoch": 0.12024003673385374,
      "grad_norm": 0.45634734630584717,
      "learning_rate": 8.797599632661464e-06,
      "loss": 0.1136,
      "step": 7594
    },
    {
      "epoch": 0.1202558702914958,
      "grad_norm": 0.3749144673347473,
      "learning_rate": 8.797441297085043e-06,
      "loss": 0.3878,
      "step": 7595
    },
    {
      "epoch": 0.12027170384913786,
      "grad_norm": 0.4715641140937805,
      "learning_rate": 8.797282961508622e-06,
      "loss": 0.1709,
      "step": 7596
    },
    {
      "epoch": 0.12028753740677993,
      "grad_norm": 0.027271326631307602,
      "learning_rate": 8.797124625932201e-06,
      "loss": 0.0013,
      "step": 7597
    },
    {
      "epoch": 0.120303370964422,
      "grad_norm": 0.0012196718016639352,
      "learning_rate": 8.79696629035578e-06,
      "loss": 0.0,
      "step": 7598
    },
    {
      "epoch": 0.12031920452206406,
      "grad_norm": 0.3286363184452057,
      "learning_rate": 8.796807954779361e-06,
      "loss": 0.2522,
      "step": 7599
    },
    {
      "epoch": 0.12033503807970614,
      "grad_norm": 0.3664674460887909,
      "learning_rate": 8.79664961920294e-06,
      "loss": 0.0786,
      "step": 7600
    },
    {
      "epoch": 0.1203508716373482,
      "grad_norm": 0.0783582553267479,
      "learning_rate": 8.79649128362652e-06,
      "loss": 0.0029,
      "step": 7601
    },
    {
      "epoch": 0.12036670519499026,
      "grad_norm": 0.24688081443309784,
      "learning_rate": 8.796332948050098e-06,
      "loss": 0.1115,
      "step": 7602
    },
    {
      "epoch": 0.12038253875263233,
      "grad_norm": 0.0003727759758476168,
      "learning_rate": 8.796174612473677e-06,
      "loss": 0.0,
      "step": 7603
    },
    {
      "epoch": 0.12039837231027439,
      "grad_norm": 0.4818076491355896,
      "learning_rate": 8.796016276897256e-06,
      "loss": 0.0683,
      "step": 7604
    },
    {
      "epoch": 0.12041420586791646,
      "grad_norm": 0.05997566133737564,
      "learning_rate": 8.795857941320835e-06,
      "loss": 0.0091,
      "step": 7605
    },
    {
      "epoch": 0.12043003942555854,
      "grad_norm": 0.4215826094150543,
      "learning_rate": 8.795699605744416e-06,
      "loss": 0.2755,
      "step": 7606
    },
    {
      "epoch": 0.1204458729832006,
      "grad_norm": 0.01739581488072872,
      "learning_rate": 8.795541270167994e-06,
      "loss": 0.0008,
      "step": 7607
    },
    {
      "epoch": 0.12046170654084266,
      "grad_norm": 0.29257825016975403,
      "learning_rate": 8.795382934591574e-06,
      "loss": 0.0648,
      "step": 7608
    },
    {
      "epoch": 0.12047754009848473,
      "grad_norm": 0.44416484236717224,
      "learning_rate": 8.795224599015153e-06,
      "loss": 0.5659,
      "step": 7609
    },
    {
      "epoch": 0.12049337365612679,
      "grad_norm": 0.002364266896620393,
      "learning_rate": 8.795066263438733e-06,
      "loss": 0.0,
      "step": 7610
    },
    {
      "epoch": 0.12050920721376886,
      "grad_norm": 0.41428130865097046,
      "learning_rate": 8.794907927862312e-06,
      "loss": 0.6098,
      "step": 7611
    },
    {
      "epoch": 0.12052504077141094,
      "grad_norm": 0.7984018921852112,
      "learning_rate": 8.794749592285892e-06,
      "loss": 0.6241,
      "step": 7612
    },
    {
      "epoch": 0.120540874329053,
      "grad_norm": 0.0007864781655371189,
      "learning_rate": 8.79459125670947e-06,
      "loss": 0.0,
      "step": 7613
    },
    {
      "epoch": 0.12055670788669506,
      "grad_norm": 0.4752691388130188,
      "learning_rate": 8.79443292113305e-06,
      "loss": 0.168,
      "step": 7614
    },
    {
      "epoch": 0.12057254144433713,
      "grad_norm": 0.2895427644252777,
      "learning_rate": 8.79427458555663e-06,
      "loss": 0.0802,
      "step": 7615
    },
    {
      "epoch": 0.12058837500197919,
      "grad_norm": 0.00210465001873672,
      "learning_rate": 8.794116249980209e-06,
      "loss": 0.0001,
      "step": 7616
    },
    {
      "epoch": 0.12060420855962126,
      "grad_norm": 0.01026465930044651,
      "learning_rate": 8.793957914403788e-06,
      "loss": 0.0004,
      "step": 7617
    },
    {
      "epoch": 0.12062004211726333,
      "grad_norm": 0.012321299873292446,
      "learning_rate": 8.793799578827369e-06,
      "loss": 0.0006,
      "step": 7618
    },
    {
      "epoch": 0.1206358756749054,
      "grad_norm": 0.3843457102775574,
      "learning_rate": 8.793641243250946e-06,
      "loss": 0.3322,
      "step": 7619
    },
    {
      "epoch": 0.12065170923254746,
      "grad_norm": 0.005555605515837669,
      "learning_rate": 8.793482907674527e-06,
      "loss": 0.0003,
      "step": 7620
    },
    {
      "epoch": 0.12066754279018953,
      "grad_norm": 0.28078579902648926,
      "learning_rate": 8.793324572098106e-06,
      "loss": 0.024,
      "step": 7621
    },
    {
      "epoch": 0.12068337634783159,
      "grad_norm": 0.20150288939476013,
      "learning_rate": 8.793166236521685e-06,
      "loss": 0.0875,
      "step": 7622
    },
    {
      "epoch": 0.12069920990547366,
      "grad_norm": 0.3303714692592621,
      "learning_rate": 8.793007900945264e-06,
      "loss": 0.1239,
      "step": 7623
    },
    {
      "epoch": 0.12071504346311573,
      "grad_norm": 0.5011574029922485,
      "learning_rate": 8.792849565368845e-06,
      "loss": 0.0638,
      "step": 7624
    },
    {
      "epoch": 0.1207308770207578,
      "grad_norm": 1.9605274200439453,
      "learning_rate": 8.792691229792422e-06,
      "loss": 0.1949,
      "step": 7625
    },
    {
      "epoch": 0.12074671057839986,
      "grad_norm": 0.24551023542881012,
      "learning_rate": 8.792532894216003e-06,
      "loss": 0.0848,
      "step": 7626
    },
    {
      "epoch": 0.12076254413604193,
      "grad_norm": 0.24823835492134094,
      "learning_rate": 8.792374558639582e-06,
      "loss": 0.0551,
      "step": 7627
    },
    {
      "epoch": 0.12077837769368399,
      "grad_norm": 0.21948319673538208,
      "learning_rate": 8.792216223063161e-06,
      "loss": 0.073,
      "step": 7628
    },
    {
      "epoch": 0.12079421125132606,
      "grad_norm": 0.18618600070476532,
      "learning_rate": 8.79205788748674e-06,
      "loss": 0.1424,
      "step": 7629
    },
    {
      "epoch": 0.12081004480896813,
      "grad_norm": 0.49766895174980164,
      "learning_rate": 8.79189955191032e-06,
      "loss": 0.1886,
      "step": 7630
    },
    {
      "epoch": 0.1208258783666102,
      "grad_norm": 0.00912871491163969,
      "learning_rate": 8.791741216333898e-06,
      "loss": 0.0005,
      "step": 7631
    },
    {
      "epoch": 0.12084171192425226,
      "grad_norm": 1.634267807006836,
      "learning_rate": 8.791582880757477e-06,
      "loss": 0.4508,
      "step": 7632
    },
    {
      "epoch": 0.12085754548189433,
      "grad_norm": 0.05961909517645836,
      "learning_rate": 8.791424545181058e-06,
      "loss": 0.0045,
      "step": 7633
    },
    {
      "epoch": 0.12087337903953639,
      "grad_norm": 0.4760010838508606,
      "learning_rate": 8.791266209604636e-06,
      "loss": 0.6312,
      "step": 7634
    },
    {
      "epoch": 0.12088921259717846,
      "grad_norm": 0.2220045030117035,
      "learning_rate": 8.791107874028216e-06,
      "loss": 0.0944,
      "step": 7635
    },
    {
      "epoch": 0.12090504615482053,
      "grad_norm": 0.2543063759803772,
      "learning_rate": 8.790949538451795e-06,
      "loss": 0.0574,
      "step": 7636
    },
    {
      "epoch": 0.1209208797124626,
      "grad_norm": 0.6145641803741455,
      "learning_rate": 8.790791202875374e-06,
      "loss": 0.0673,
      "step": 7637
    },
    {
      "epoch": 0.12093671327010466,
      "grad_norm": 0.04357535019516945,
      "learning_rate": 8.790632867298954e-06,
      "loss": 0.0056,
      "step": 7638
    },
    {
      "epoch": 0.12095254682774673,
      "grad_norm": 0.8664155602455139,
      "learning_rate": 8.790474531722534e-06,
      "loss": 0.1546,
      "step": 7639
    },
    {
      "epoch": 0.12096838038538879,
      "grad_norm": 0.20355801284313202,
      "learning_rate": 8.790316196146112e-06,
      "loss": 0.0557,
      "step": 7640
    },
    {
      "epoch": 0.12098421394303085,
      "grad_norm": 0.43155938386917114,
      "learning_rate": 8.790157860569693e-06,
      "loss": 0.4858,
      "step": 7641
    },
    {
      "epoch": 0.12100004750067293,
      "grad_norm": 0.3884277045726776,
      "learning_rate": 8.789999524993272e-06,
      "loss": 0.3338,
      "step": 7642
    },
    {
      "epoch": 0.121015881058315,
      "grad_norm": 0.0006494848057627678,
      "learning_rate": 8.78984118941685e-06,
      "loss": 0.0,
      "step": 7643
    },
    {
      "epoch": 0.12103171461595706,
      "grad_norm": 0.39523354172706604,
      "learning_rate": 8.78968285384043e-06,
      "loss": 0.3054,
      "step": 7644
    },
    {
      "epoch": 0.12104754817359913,
      "grad_norm": 0.023034067824482918,
      "learning_rate": 8.78952451826401e-06,
      "loss": 0.0011,
      "step": 7645
    },
    {
      "epoch": 0.12106338173124119,
      "grad_norm": 0.2962439954280853,
      "learning_rate": 8.789366182687588e-06,
      "loss": 0.051,
      "step": 7646
    },
    {
      "epoch": 0.12107921528888325,
      "grad_norm": 0.31904691457748413,
      "learning_rate": 8.789207847111169e-06,
      "loss": 0.1946,
      "step": 7647
    },
    {
      "epoch": 0.12109504884652532,
      "grad_norm": 0.39505431056022644,
      "learning_rate": 8.789049511534748e-06,
      "loss": 0.6033,
      "step": 7648
    },
    {
      "epoch": 0.1211108824041674,
      "grad_norm": 0.1545225828886032,
      "learning_rate": 8.788891175958327e-06,
      "loss": 0.0566,
      "step": 7649
    },
    {
      "epoch": 0.12112671596180946,
      "grad_norm": 0.2741597890853882,
      "learning_rate": 8.788732840381906e-06,
      "loss": 0.3646,
      "step": 7650
    },
    {
      "epoch": 0.12114254951945153,
      "grad_norm": 0.025768952444195747,
      "learning_rate": 8.788574504805487e-06,
      "loss": 0.0019,
      "step": 7651
    },
    {
      "epoch": 0.12115838307709359,
      "grad_norm": 0.46143972873687744,
      "learning_rate": 8.788416169229064e-06,
      "loss": 0.3345,
      "step": 7652
    },
    {
      "epoch": 0.12117421663473565,
      "grad_norm": 0.21134904026985168,
      "learning_rate": 8.788257833652643e-06,
      "loss": 0.0629,
      "step": 7653
    },
    {
      "epoch": 0.12119005019237772,
      "grad_norm": 0.03571392223238945,
      "learning_rate": 8.788099498076224e-06,
      "loss": 0.0021,
      "step": 7654
    },
    {
      "epoch": 0.1212058837500198,
      "grad_norm": 0.501044511795044,
      "learning_rate": 8.787941162499803e-06,
      "loss": 0.1101,
      "step": 7655
    },
    {
      "epoch": 0.12122171730766186,
      "grad_norm": 0.007213628850877285,
      "learning_rate": 8.787782826923382e-06,
      "loss": 0.0004,
      "step": 7656
    },
    {
      "epoch": 0.12123755086530393,
      "grad_norm": 0.14955788850784302,
      "learning_rate": 8.787624491346961e-06,
      "loss": 0.0535,
      "step": 7657
    },
    {
      "epoch": 0.12125338442294599,
      "grad_norm": 0.5759254693984985,
      "learning_rate": 8.78746615577054e-06,
      "loss": 0.1168,
      "step": 7658
    },
    {
      "epoch": 0.12126921798058805,
      "grad_norm": 0.00039328919956460595,
      "learning_rate": 8.78730782019412e-06,
      "loss": 0.0,
      "step": 7659
    },
    {
      "epoch": 0.12128505153823012,
      "grad_norm": 0.288665771484375,
      "learning_rate": 8.7871494846177e-06,
      "loss": 0.0984,
      "step": 7660
    },
    {
      "epoch": 0.1213008850958722,
      "grad_norm": 0.003385473508387804,
      "learning_rate": 8.78699114904128e-06,
      "loss": 0.0001,
      "step": 7661
    },
    {
      "epoch": 0.12131671865351426,
      "grad_norm": 0.3366010785102844,
      "learning_rate": 8.786832813464858e-06,
      "loss": 0.199,
      "step": 7662
    },
    {
      "epoch": 0.12133255221115632,
      "grad_norm": 0.32521888613700867,
      "learning_rate": 8.786674477888437e-06,
      "loss": 0.1154,
      "step": 7663
    },
    {
      "epoch": 0.12134838576879839,
      "grad_norm": 0.03666415438055992,
      "learning_rate": 8.786516142312016e-06,
      "loss": 0.0021,
      "step": 7664
    },
    {
      "epoch": 0.12136421932644045,
      "grad_norm": 0.57979816198349,
      "learning_rate": 8.786357806735595e-06,
      "loss": 0.9055,
      "step": 7665
    },
    {
      "epoch": 0.12138005288408252,
      "grad_norm": 1.9987164735794067,
      "learning_rate": 8.786199471159176e-06,
      "loss": 0.0187,
      "step": 7666
    },
    {
      "epoch": 0.1213958864417246,
      "grad_norm": 0.008590967394411564,
      "learning_rate": 8.786041135582755e-06,
      "loss": 0.0004,
      "step": 7667
    },
    {
      "epoch": 0.12141171999936666,
      "grad_norm": 0.0053702606819570065,
      "learning_rate": 8.785882800006334e-06,
      "loss": 0.0002,
      "step": 7668
    },
    {
      "epoch": 0.12142755355700872,
      "grad_norm": 0.02830488234758377,
      "learning_rate": 8.785724464429914e-06,
      "loss": 0.0013,
      "step": 7669
    },
    {
      "epoch": 0.12144338711465079,
      "grad_norm": 0.9685587286949158,
      "learning_rate": 8.785566128853493e-06,
      "loss": 0.2394,
      "step": 7670
    },
    {
      "epoch": 0.12145922067229285,
      "grad_norm": 0.00028682712581939995,
      "learning_rate": 8.785407793277072e-06,
      "loss": 0.0,
      "step": 7671
    },
    {
      "epoch": 0.12147505422993492,
      "grad_norm": 0.26586687564849854,
      "learning_rate": 8.785249457700652e-06,
      "loss": 0.1395,
      "step": 7672
    },
    {
      "epoch": 0.121490887787577,
      "grad_norm": 0.030815226957201958,
      "learning_rate": 8.785091122124232e-06,
      "loss": 0.0019,
      "step": 7673
    },
    {
      "epoch": 0.12150672134521906,
      "grad_norm": 0.000590964627917856,
      "learning_rate": 8.78493278654781e-06,
      "loss": 0.0,
      "step": 7674
    },
    {
      "epoch": 0.12152255490286112,
      "grad_norm": 0.21185538172721863,
      "learning_rate": 8.78477445097139e-06,
      "loss": 0.0678,
      "step": 7675
    },
    {
      "epoch": 0.12153838846050319,
      "grad_norm": 0.39192038774490356,
      "learning_rate": 8.784616115394969e-06,
      "loss": 0.0826,
      "step": 7676
    },
    {
      "epoch": 0.12155422201814525,
      "grad_norm": 0.1345704346895218,
      "learning_rate": 8.784457779818548e-06,
      "loss": 0.0067,
      "step": 7677
    },
    {
      "epoch": 0.12157005557578732,
      "grad_norm": 0.06204405054450035,
      "learning_rate": 8.784299444242127e-06,
      "loss": 0.0013,
      "step": 7678
    },
    {
      "epoch": 0.1215858891334294,
      "grad_norm": 0.15011143684387207,
      "learning_rate": 8.784141108665708e-06,
      "loss": 0.0345,
      "step": 7679
    },
    {
      "epoch": 0.12160172269107146,
      "grad_norm": 0.022124454379081726,
      "learning_rate": 8.783982773089285e-06,
      "loss": 0.0014,
      "step": 7680
    },
    {
      "epoch": 0.12161755624871352,
      "grad_norm": 0.2575828731060028,
      "learning_rate": 8.783824437512866e-06,
      "loss": 0.1138,
      "step": 7681
    },
    {
      "epoch": 0.12163338980635559,
      "grad_norm": 0.008405923843383789,
      "learning_rate": 8.783666101936445e-06,
      "loss": 0.0003,
      "step": 7682
    },
    {
      "epoch": 0.12164922336399765,
      "grad_norm": 0.6996546387672424,
      "learning_rate": 8.783507766360024e-06,
      "loss": 0.0623,
      "step": 7683
    },
    {
      "epoch": 0.12166505692163972,
      "grad_norm": 0.20279604196548462,
      "learning_rate": 8.783349430783603e-06,
      "loss": 0.0351,
      "step": 7684
    },
    {
      "epoch": 0.1216808904792818,
      "grad_norm": 0.0033151747193187475,
      "learning_rate": 8.783191095207184e-06,
      "loss": 0.0001,
      "step": 7685
    },
    {
      "epoch": 0.12169672403692386,
      "grad_norm": 0.28634893894195557,
      "learning_rate": 8.783032759630761e-06,
      "loss": 0.2435,
      "step": 7686
    },
    {
      "epoch": 0.12171255759456592,
      "grad_norm": 0.28891628980636597,
      "learning_rate": 8.782874424054342e-06,
      "loss": 0.1885,
      "step": 7687
    },
    {
      "epoch": 0.12172839115220799,
      "grad_norm": 0.2009446918964386,
      "learning_rate": 8.782716088477921e-06,
      "loss": 0.1164,
      "step": 7688
    },
    {
      "epoch": 0.12174422470985005,
      "grad_norm": 0.29263216257095337,
      "learning_rate": 8.7825577529015e-06,
      "loss": 0.1261,
      "step": 7689
    },
    {
      "epoch": 0.12176005826749212,
      "grad_norm": 0.33223557472229004,
      "learning_rate": 8.78239941732508e-06,
      "loss": 0.0913,
      "step": 7690
    },
    {
      "epoch": 0.1217758918251342,
      "grad_norm": 0.20363228023052216,
      "learning_rate": 8.78224108174866e-06,
      "loss": 0.0784,
      "step": 7691
    },
    {
      "epoch": 0.12179172538277626,
      "grad_norm": 0.3754378855228424,
      "learning_rate": 8.782082746172237e-06,
      "loss": 0.2547,
      "step": 7692
    },
    {
      "epoch": 0.12180755894041832,
      "grad_norm": 0.32742688059806824,
      "learning_rate": 8.781924410595818e-06,
      "loss": 0.4293,
      "step": 7693
    },
    {
      "epoch": 0.12182339249806039,
      "grad_norm": 0.2019212692975998,
      "learning_rate": 8.781766075019397e-06,
      "loss": 0.0565,
      "step": 7694
    },
    {
      "epoch": 0.12183922605570245,
      "grad_norm": 0.049368053674697876,
      "learning_rate": 8.781607739442976e-06,
      "loss": 0.002,
      "step": 7695
    },
    {
      "epoch": 0.12185505961334452,
      "grad_norm": 0.2682015001773834,
      "learning_rate": 8.781449403866555e-06,
      "loss": 0.0824,
      "step": 7696
    },
    {
      "epoch": 0.1218708931709866,
      "grad_norm": 0.1925767958164215,
      "learning_rate": 8.781291068290135e-06,
      "loss": 0.0989,
      "step": 7697
    },
    {
      "epoch": 0.12188672672862866,
      "grad_norm": 0.0002267280506202951,
      "learning_rate": 8.781132732713714e-06,
      "loss": 0.0,
      "step": 7698
    },
    {
      "epoch": 0.12190256028627072,
      "grad_norm": 0.25345751643180847,
      "learning_rate": 8.780974397137294e-06,
      "loss": 0.2593,
      "step": 7699
    },
    {
      "epoch": 0.12191839384391279,
      "grad_norm": 0.01049859169870615,
      "learning_rate": 8.780816061560873e-06,
      "loss": 0.0004,
      "step": 7700
    },
    {
      "epoch": 0.12193422740155485,
      "grad_norm": 0.8734391331672668,
      "learning_rate": 8.78065772598445e-06,
      "loss": 0.1641,
      "step": 7701
    },
    {
      "epoch": 0.12195006095919692,
      "grad_norm": 0.7143464684486389,
      "learning_rate": 8.780499390408032e-06,
      "loss": 0.1182,
      "step": 7702
    },
    {
      "epoch": 0.121965894516839,
      "grad_norm": 0.31416577100753784,
      "learning_rate": 8.78034105483161e-06,
      "loss": 0.0766,
      "step": 7703
    },
    {
      "epoch": 0.12198172807448106,
      "grad_norm": 0.3106022775173187,
      "learning_rate": 8.78018271925519e-06,
      "loss": 0.1754,
      "step": 7704
    },
    {
      "epoch": 0.12199756163212312,
      "grad_norm": 0.19104787707328796,
      "learning_rate": 8.780024383678769e-06,
      "loss": 0.099,
      "step": 7705
    },
    {
      "epoch": 0.12201339518976519,
      "grad_norm": 0.4189457893371582,
      "learning_rate": 8.77986604810235e-06,
      "loss": 0.5447,
      "step": 7706
    },
    {
      "epoch": 0.12202922874740725,
      "grad_norm": 0.09279186278581619,
      "learning_rate": 8.779707712525927e-06,
      "loss": 0.0133,
      "step": 7707
    },
    {
      "epoch": 0.12204506230504931,
      "grad_norm": 0.08340416103601456,
      "learning_rate": 8.779549376949508e-06,
      "loss": 0.0122,
      "step": 7708
    },
    {
      "epoch": 0.1220608958626914,
      "grad_norm": 0.03075135126709938,
      "learning_rate": 8.779391041373087e-06,
      "loss": 0.0016,
      "step": 7709
    },
    {
      "epoch": 0.12207672942033346,
      "grad_norm": 0.40023496747016907,
      "learning_rate": 8.779232705796666e-06,
      "loss": 0.2275,
      "step": 7710
    },
    {
      "epoch": 0.12209256297797552,
      "grad_norm": 1.9819931983947754,
      "learning_rate": 8.779074370220245e-06,
      "loss": 0.0972,
      "step": 7711
    },
    {
      "epoch": 0.12210839653561759,
      "grad_norm": 0.17304550111293793,
      "learning_rate": 8.778916034643826e-06,
      "loss": 0.0427,
      "step": 7712
    },
    {
      "epoch": 0.12212423009325965,
      "grad_norm": 0.4184456765651703,
      "learning_rate": 8.778757699067403e-06,
      "loss": 0.0604,
      "step": 7713
    },
    {
      "epoch": 0.12214006365090171,
      "grad_norm": 0.19811446964740753,
      "learning_rate": 8.778599363490984e-06,
      "loss": 0.1752,
      "step": 7714
    },
    {
      "epoch": 0.12215589720854379,
      "grad_norm": 0.07287701964378357,
      "learning_rate": 8.778441027914563e-06,
      "loss": 0.0013,
      "step": 7715
    },
    {
      "epoch": 0.12217173076618586,
      "grad_norm": 0.4123254418373108,
      "learning_rate": 8.778282692338142e-06,
      "loss": 0.4098,
      "step": 7716
    },
    {
      "epoch": 0.12218756432382792,
      "grad_norm": 0.01692011207342148,
      "learning_rate": 8.778124356761721e-06,
      "loss": 0.0003,
      "step": 7717
    },
    {
      "epoch": 0.12220339788146999,
      "grad_norm": 0.40107619762420654,
      "learning_rate": 8.777966021185302e-06,
      "loss": 0.1484,
      "step": 7718
    },
    {
      "epoch": 0.12221923143911205,
      "grad_norm": 1.03362238407135,
      "learning_rate": 8.77780768560888e-06,
      "loss": 0.1119,
      "step": 7719
    },
    {
      "epoch": 0.12223506499675411,
      "grad_norm": 0.14675258100032806,
      "learning_rate": 8.77764935003246e-06,
      "loss": 0.0089,
      "step": 7720
    },
    {
      "epoch": 0.12225089855439619,
      "grad_norm": 0.7373061776161194,
      "learning_rate": 8.77749101445604e-06,
      "loss": 0.1436,
      "step": 7721
    },
    {
      "epoch": 0.12226673211203826,
      "grad_norm": 0.24357229471206665,
      "learning_rate": 8.777332678879618e-06,
      "loss": 0.0941,
      "step": 7722
    },
    {
      "epoch": 0.12228256566968032,
      "grad_norm": 0.034684814512729645,
      "learning_rate": 8.777174343303197e-06,
      "loss": 0.0021,
      "step": 7723
    },
    {
      "epoch": 0.12229839922732239,
      "grad_norm": 0.45487120747566223,
      "learning_rate": 8.777016007726776e-06,
      "loss": 0.088,
      "step": 7724
    },
    {
      "epoch": 0.12231423278496445,
      "grad_norm": 0.11410997807979584,
      "learning_rate": 8.776857672150356e-06,
      "loss": 0.0323,
      "step": 7725
    },
    {
      "epoch": 0.12233006634260651,
      "grad_norm": 1.2640841007232666,
      "learning_rate": 8.776699336573935e-06,
      "loss": 0.1189,
      "step": 7726
    },
    {
      "epoch": 0.12234589990024859,
      "grad_norm": 0.24084864556789398,
      "learning_rate": 8.776541000997515e-06,
      "loss": 0.1155,
      "step": 7727
    },
    {
      "epoch": 0.12236173345789066,
      "grad_norm": 0.15676800906658173,
      "learning_rate": 8.776382665421094e-06,
      "loss": 0.0507,
      "step": 7728
    },
    {
      "epoch": 0.12237756701553272,
      "grad_norm": 0.3592097759246826,
      "learning_rate": 8.776224329844674e-06,
      "loss": 0.079,
      "step": 7729
    },
    {
      "epoch": 0.12239340057317478,
      "grad_norm": 0.05483665689826012,
      "learning_rate": 8.776065994268253e-06,
      "loss": 0.0013,
      "step": 7730
    },
    {
      "epoch": 0.12240923413081685,
      "grad_norm": 0.34990355372428894,
      "learning_rate": 8.775907658691832e-06,
      "loss": 0.0825,
      "step": 7731
    },
    {
      "epoch": 0.12242506768845891,
      "grad_norm": 0.4391564130783081,
      "learning_rate": 8.77574932311541e-06,
      "loss": 0.1026,
      "step": 7732
    },
    {
      "epoch": 0.12244090124610099,
      "grad_norm": 0.3971727788448334,
      "learning_rate": 8.775590987538992e-06,
      "loss": 0.1959,
      "step": 7733
    },
    {
      "epoch": 0.12245673480374306,
      "grad_norm": 0.009347775019705296,
      "learning_rate": 8.77543265196257e-06,
      "loss": 0.0003,
      "step": 7734
    },
    {
      "epoch": 0.12247256836138512,
      "grad_norm": 0.6028191447257996,
      "learning_rate": 8.77527431638615e-06,
      "loss": 0.3147,
      "step": 7735
    },
    {
      "epoch": 0.12248840191902718,
      "grad_norm": 0.4308048188686371,
      "learning_rate": 8.775115980809729e-06,
      "loss": 0.2393,
      "step": 7736
    },
    {
      "epoch": 0.12250423547666925,
      "grad_norm": 0.07373487949371338,
      "learning_rate": 8.774957645233308e-06,
      "loss": 0.0059,
      "step": 7737
    },
    {
      "epoch": 0.12252006903431131,
      "grad_norm": 0.4915477931499481,
      "learning_rate": 8.774799309656887e-06,
      "loss": 0.4731,
      "step": 7738
    },
    {
      "epoch": 0.12253590259195339,
      "grad_norm": 0.27202048897743225,
      "learning_rate": 8.774640974080468e-06,
      "loss": 0.2782,
      "step": 7739
    },
    {
      "epoch": 0.12255173614959546,
      "grad_norm": 0.006965150590986013,
      "learning_rate": 8.774482638504047e-06,
      "loss": 0.0003,
      "step": 7740
    },
    {
      "epoch": 0.12256756970723752,
      "grad_norm": 0.015157287940382957,
      "learning_rate": 8.774324302927626e-06,
      "loss": 0.0008,
      "step": 7741
    },
    {
      "epoch": 0.12258340326487958,
      "grad_norm": 0.28357329964637756,
      "learning_rate": 8.774165967351205e-06,
      "loss": 0.1347,
      "step": 7742
    },
    {
      "epoch": 0.12259923682252165,
      "grad_norm": 0.30276554822921753,
      "learning_rate": 8.774007631774784e-06,
      "loss": 0.1184,
      "step": 7743
    },
    {
      "epoch": 0.12261507038016371,
      "grad_norm": 0.1824258714914322,
      "learning_rate": 8.773849296198363e-06,
      "loss": 0.0559,
      "step": 7744
    },
    {
      "epoch": 0.12263090393780579,
      "grad_norm": 0.16384200751781464,
      "learning_rate": 8.773690960621944e-06,
      "loss": 0.0101,
      "step": 7745
    },
    {
      "epoch": 0.12264673749544786,
      "grad_norm": 0.26340359449386597,
      "learning_rate": 8.773532625045523e-06,
      "loss": 0.1193,
      "step": 7746
    },
    {
      "epoch": 0.12266257105308992,
      "grad_norm": 0.0023068911395967007,
      "learning_rate": 8.773374289469102e-06,
      "loss": 0.0001,
      "step": 7747
    },
    {
      "epoch": 0.12267840461073198,
      "grad_norm": 0.0002695721632335335,
      "learning_rate": 8.773215953892681e-06,
      "loss": 0.0,
      "step": 7748
    },
    {
      "epoch": 0.12269423816837405,
      "grad_norm": 0.481433629989624,
      "learning_rate": 8.77305761831626e-06,
      "loss": 0.2045,
      "step": 7749
    },
    {
      "epoch": 0.12271007172601611,
      "grad_norm": 0.3677472472190857,
      "learning_rate": 8.77289928273984e-06,
      "loss": 0.154,
      "step": 7750
    },
    {
      "epoch": 0.12272590528365819,
      "grad_norm": 0.2317831963300705,
      "learning_rate": 8.772740947163418e-06,
      "loss": 0.0565,
      "step": 7751
    },
    {
      "epoch": 0.12274173884130025,
      "grad_norm": 0.009089844301342964,
      "learning_rate": 8.772582611586999e-06,
      "loss": 0.0005,
      "step": 7752
    },
    {
      "epoch": 0.12275757239894232,
      "grad_norm": 0.42780622839927673,
      "learning_rate": 8.772424276010577e-06,
      "loss": 0.1873,
      "step": 7753
    },
    {
      "epoch": 0.12277340595658438,
      "grad_norm": 0.2908993661403656,
      "learning_rate": 8.772265940434157e-06,
      "loss": 0.0654,
      "step": 7754
    },
    {
      "epoch": 0.12278923951422645,
      "grad_norm": 0.33486831188201904,
      "learning_rate": 8.772107604857736e-06,
      "loss": 0.1282,
      "step": 7755
    },
    {
      "epoch": 0.12280507307186851,
      "grad_norm": 0.5502244830131531,
      "learning_rate": 8.771949269281315e-06,
      "loss": 0.1524,
      "step": 7756
    },
    {
      "epoch": 0.12282090662951059,
      "grad_norm": 0.02884369157254696,
      "learning_rate": 8.771790933704895e-06,
      "loss": 0.0007,
      "step": 7757
    },
    {
      "epoch": 0.12283674018715265,
      "grad_norm": 0.5167048573493958,
      "learning_rate": 8.771632598128474e-06,
      "loss": 0.1617,
      "step": 7758
    },
    {
      "epoch": 0.12285257374479472,
      "grad_norm": 0.23188044130802155,
      "learning_rate": 8.771474262552053e-06,
      "loss": 0.0306,
      "step": 7759
    },
    {
      "epoch": 0.12286840730243678,
      "grad_norm": 0.2298249900341034,
      "learning_rate": 8.771315926975633e-06,
      "loss": 0.246,
      "step": 7760
    },
    {
      "epoch": 0.12288424086007885,
      "grad_norm": 0.15855583548545837,
      "learning_rate": 8.771157591399213e-06,
      "loss": 0.1008,
      "step": 7761
    },
    {
      "epoch": 0.12290007441772091,
      "grad_norm": 0.0007301539299078286,
      "learning_rate": 8.770999255822792e-06,
      "loss": 0.0,
      "step": 7762
    },
    {
      "epoch": 0.12291590797536299,
      "grad_norm": 0.40491512417793274,
      "learning_rate": 8.77084092024637e-06,
      "loss": 0.1967,
      "step": 7763
    },
    {
      "epoch": 0.12293174153300505,
      "grad_norm": 0.25495287775993347,
      "learning_rate": 8.77068258466995e-06,
      "loss": 0.0581,
      "step": 7764
    },
    {
      "epoch": 0.12294757509064712,
      "grad_norm": 0.002908103633671999,
      "learning_rate": 8.770524249093529e-06,
      "loss": 0.0001,
      "step": 7765
    },
    {
      "epoch": 0.12296340864828918,
      "grad_norm": 0.33694061636924744,
      "learning_rate": 8.77036591351711e-06,
      "loss": 0.0995,
      "step": 7766
    },
    {
      "epoch": 0.12297924220593125,
      "grad_norm": 0.27038007974624634,
      "learning_rate": 8.770207577940689e-06,
      "loss": 0.1714,
      "step": 7767
    },
    {
      "epoch": 0.12299507576357331,
      "grad_norm": 0.039291657507419586,
      "learning_rate": 8.770049242364268e-06,
      "loss": 0.0021,
      "step": 7768
    },
    {
      "epoch": 0.12301090932121539,
      "grad_norm": 0.40128272771835327,
      "learning_rate": 8.769890906787847e-06,
      "loss": 0.3326,
      "step": 7769
    },
    {
      "epoch": 0.12302674287885745,
      "grad_norm": 0.3459365665912628,
      "learning_rate": 8.769732571211426e-06,
      "loss": 0.2799,
      "step": 7770
    },
    {
      "epoch": 0.12304257643649952,
      "grad_norm": 0.7240477204322815,
      "learning_rate": 8.769574235635005e-06,
      "loss": 0.2228,
      "step": 7771
    },
    {
      "epoch": 0.12305840999414158,
      "grad_norm": 0.33022233843803406,
      "learning_rate": 8.769415900058584e-06,
      "loss": 0.1123,
      "step": 7772
    },
    {
      "epoch": 0.12307424355178365,
      "grad_norm": 0.5887868404388428,
      "learning_rate": 8.769257564482165e-06,
      "loss": 0.0894,
      "step": 7773
    },
    {
      "epoch": 0.12309007710942571,
      "grad_norm": 0.2890167236328125,
      "learning_rate": 8.769099228905742e-06,
      "loss": 0.1995,
      "step": 7774
    },
    {
      "epoch": 0.12310591066706779,
      "grad_norm": 0.3193072974681854,
      "learning_rate": 8.768940893329323e-06,
      "loss": 0.056,
      "step": 7775
    },
    {
      "epoch": 0.12312174422470985,
      "grad_norm": 0.00029303328483365476,
      "learning_rate": 8.768782557752902e-06,
      "loss": 0.0,
      "step": 7776
    },
    {
      "epoch": 0.12313757778235192,
      "grad_norm": 0.26963281631469727,
      "learning_rate": 8.768624222176481e-06,
      "loss": 0.1365,
      "step": 7777
    },
    {
      "epoch": 0.12315341133999398,
      "grad_norm": 0.4166487455368042,
      "learning_rate": 8.76846588660006e-06,
      "loss": 0.081,
      "step": 7778
    },
    {
      "epoch": 0.12316924489763605,
      "grad_norm": 0.3573283553123474,
      "learning_rate": 8.768307551023641e-06,
      "loss": 0.2337,
      "step": 7779
    },
    {
      "epoch": 0.12318507845527811,
      "grad_norm": 0.24203571677207947,
      "learning_rate": 8.768149215447218e-06,
      "loss": 0.2075,
      "step": 7780
    },
    {
      "epoch": 0.12320091201292019,
      "grad_norm": 0.5299738645553589,
      "learning_rate": 8.7679908798708e-06,
      "loss": 0.1588,
      "step": 7781
    },
    {
      "epoch": 0.12321674557056225,
      "grad_norm": 0.3324469327926636,
      "learning_rate": 8.767832544294378e-06,
      "loss": 0.0813,
      "step": 7782
    },
    {
      "epoch": 0.12323257912820432,
      "grad_norm": 0.09580939263105392,
      "learning_rate": 8.767674208717957e-06,
      "loss": 0.0106,
      "step": 7783
    },
    {
      "epoch": 0.12324841268584638,
      "grad_norm": 0.004284095950424671,
      "learning_rate": 8.767515873141536e-06,
      "loss": 0.0001,
      "step": 7784
    },
    {
      "epoch": 0.12326424624348845,
      "grad_norm": 0.21660460531711578,
      "learning_rate": 8.767357537565117e-06,
      "loss": 0.131,
      "step": 7785
    },
    {
      "epoch": 0.12328007980113051,
      "grad_norm": 0.0037901452742516994,
      "learning_rate": 8.767199201988695e-06,
      "loss": 0.0002,
      "step": 7786
    },
    {
      "epoch": 0.12329591335877259,
      "grad_norm": 0.2673686444759369,
      "learning_rate": 8.767040866412275e-06,
      "loss": 0.0786,
      "step": 7787
    },
    {
      "epoch": 0.12331174691641465,
      "grad_norm": 0.15959098935127258,
      "learning_rate": 8.766882530835854e-06,
      "loss": 0.0857,
      "step": 7788
    },
    {
      "epoch": 0.12332758047405672,
      "grad_norm": 0.17882730066776276,
      "learning_rate": 8.766724195259434e-06,
      "loss": 0.0387,
      "step": 7789
    },
    {
      "epoch": 0.12334341403169878,
      "grad_norm": 0.47374314069747925,
      "learning_rate": 8.766565859683013e-06,
      "loss": 0.1831,
      "step": 7790
    },
    {
      "epoch": 0.12335924758934085,
      "grad_norm": 0.38968315720558167,
      "learning_rate": 8.766407524106593e-06,
      "loss": 0.224,
      "step": 7791
    },
    {
      "epoch": 0.12337508114698291,
      "grad_norm": 0.4285637438297272,
      "learning_rate": 8.76624918853017e-06,
      "loss": 0.1463,
      "step": 7792
    },
    {
      "epoch": 0.12339091470462499,
      "grad_norm": 0.2585511803627014,
      "learning_rate": 8.766090852953752e-06,
      "loss": 0.0758,
      "step": 7793
    },
    {
      "epoch": 0.12340674826226705,
      "grad_norm": 0.5366451740264893,
      "learning_rate": 8.76593251737733e-06,
      "loss": 0.3712,
      "step": 7794
    },
    {
      "epoch": 0.12342258181990912,
      "grad_norm": 0.23754307627677917,
      "learning_rate": 8.76577418180091e-06,
      "loss": 0.0666,
      "step": 7795
    },
    {
      "epoch": 0.12343841537755118,
      "grad_norm": 0.5691354274749756,
      "learning_rate": 8.765615846224489e-06,
      "loss": 0.6373,
      "step": 7796
    },
    {
      "epoch": 0.12345424893519324,
      "grad_norm": 0.30189236998558044,
      "learning_rate": 8.765457510648068e-06,
      "loss": 0.1593,
      "step": 7797
    },
    {
      "epoch": 0.12347008249283531,
      "grad_norm": 0.46431031823158264,
      "learning_rate": 8.765299175071647e-06,
      "loss": 0.1704,
      "step": 7798
    },
    {
      "epoch": 0.12348591605047739,
      "grad_norm": 0.7936842441558838,
      "learning_rate": 8.765140839495226e-06,
      "loss": 0.1224,
      "step": 7799
    },
    {
      "epoch": 0.12350174960811945,
      "grad_norm": 0.3757667541503906,
      "learning_rate": 8.764982503918807e-06,
      "loss": 0.1273,
      "step": 7800
    },
    {
      "epoch": 0.12351758316576152,
      "grad_norm": 0.5168113708496094,
      "learning_rate": 8.764824168342386e-06,
      "loss": 0.2652,
      "step": 7801
    },
    {
      "epoch": 0.12353341672340358,
      "grad_norm": 0.5021792054176331,
      "learning_rate": 8.764665832765965e-06,
      "loss": 0.162,
      "step": 7802
    },
    {
      "epoch": 0.12354925028104564,
      "grad_norm": 0.46181055903434753,
      "learning_rate": 8.764507497189544e-06,
      "loss": 0.8728,
      "step": 7803
    },
    {
      "epoch": 0.12356508383868771,
      "grad_norm": 0.29999634623527527,
      "learning_rate": 8.764349161613123e-06,
      "loss": 0.1143,
      "step": 7804
    },
    {
      "epoch": 0.12358091739632979,
      "grad_norm": 0.34913092851638794,
      "learning_rate": 8.764190826036702e-06,
      "loss": 0.1522,
      "step": 7805
    },
    {
      "epoch": 0.12359675095397185,
      "grad_norm": 0.001464903587475419,
      "learning_rate": 8.764032490460283e-06,
      "loss": 0.0001,
      "step": 7806
    },
    {
      "epoch": 0.12361258451161392,
      "grad_norm": 0.5201112627983093,
      "learning_rate": 8.763874154883862e-06,
      "loss": 0.2845,
      "step": 7807
    },
    {
      "epoch": 0.12362841806925598,
      "grad_norm": 0.014497033320367336,
      "learning_rate": 8.763715819307441e-06,
      "loss": 0.0008,
      "step": 7808
    },
    {
      "epoch": 0.12364425162689804,
      "grad_norm": 0.22721776366233826,
      "learning_rate": 8.76355748373102e-06,
      "loss": 0.2166,
      "step": 7809
    },
    {
      "epoch": 0.12366008518454011,
      "grad_norm": 0.022561348974704742,
      "learning_rate": 8.7633991481546e-06,
      "loss": 0.0013,
      "step": 7810
    },
    {
      "epoch": 0.12367591874218219,
      "grad_norm": 0.004138201009482145,
      "learning_rate": 8.763240812578178e-06,
      "loss": 0.0002,
      "step": 7811
    },
    {
      "epoch": 0.12369175229982425,
      "grad_norm": 0.22376586496829987,
      "learning_rate": 8.763082477001759e-06,
      "loss": 0.1498,
      "step": 7812
    },
    {
      "epoch": 0.12370758585746632,
      "grad_norm": 0.4217142164707184,
      "learning_rate": 8.762924141425338e-06,
      "loss": 0.1371,
      "step": 7813
    },
    {
      "epoch": 0.12372341941510838,
      "grad_norm": 0.36760643124580383,
      "learning_rate": 8.762765805848917e-06,
      "loss": 0.3309,
      "step": 7814
    },
    {
      "epoch": 0.12373925297275044,
      "grad_norm": 0.47440406680107117,
      "learning_rate": 8.762607470272496e-06,
      "loss": 0.1066,
      "step": 7815
    },
    {
      "epoch": 0.12375508653039251,
      "grad_norm": 0.4712429642677307,
      "learning_rate": 8.762449134696075e-06,
      "loss": 0.2951,
      "step": 7816
    },
    {
      "epoch": 0.12377092008803459,
      "grad_norm": 0.11660047620534897,
      "learning_rate": 8.762290799119655e-06,
      "loss": 0.012,
      "step": 7817
    },
    {
      "epoch": 0.12378675364567665,
      "grad_norm": 0.015774093568325043,
      "learning_rate": 8.762132463543235e-06,
      "loss": 0.0005,
      "step": 7818
    },
    {
      "epoch": 0.12380258720331871,
      "grad_norm": 0.3763853907585144,
      "learning_rate": 8.761974127966814e-06,
      "loss": 0.0307,
      "step": 7819
    },
    {
      "epoch": 0.12381842076096078,
      "grad_norm": 0.22350305318832397,
      "learning_rate": 8.761815792390392e-06,
      "loss": 0.0639,
      "step": 7820
    },
    {
      "epoch": 0.12383425431860284,
      "grad_norm": 0.6677566170692444,
      "learning_rate": 8.761657456813973e-06,
      "loss": 1.0208,
      "step": 7821
    },
    {
      "epoch": 0.12385008787624491,
      "grad_norm": 0.4335014522075653,
      "learning_rate": 8.761499121237552e-06,
      "loss": 0.0757,
      "step": 7822
    },
    {
      "epoch": 0.12386592143388699,
      "grad_norm": 0.15787652134895325,
      "learning_rate": 8.76134078566113e-06,
      "loss": 0.0036,
      "step": 7823
    },
    {
      "epoch": 0.12388175499152905,
      "grad_norm": 3.7797627449035645,
      "learning_rate": 8.76118245008471e-06,
      "loss": 1.2986,
      "step": 7824
    },
    {
      "epoch": 0.12389758854917111,
      "grad_norm": 0.021433798596262932,
      "learning_rate": 8.761024114508289e-06,
      "loss": 0.0011,
      "step": 7825
    },
    {
      "epoch": 0.12391342210681318,
      "grad_norm": 0.0255600456148386,
      "learning_rate": 8.760865778931868e-06,
      "loss": 0.0015,
      "step": 7826
    },
    {
      "epoch": 0.12392925566445524,
      "grad_norm": 0.13123451173305511,
      "learning_rate": 8.760707443355449e-06,
      "loss": 0.054,
      "step": 7827
    },
    {
      "epoch": 0.12394508922209731,
      "grad_norm": 0.016389718279242516,
      "learning_rate": 8.760549107779028e-06,
      "loss": 0.0008,
      "step": 7828
    },
    {
      "epoch": 0.12396092277973939,
      "grad_norm": 0.013379978947341442,
      "learning_rate": 8.760390772202607e-06,
      "loss": 0.0007,
      "step": 7829
    },
    {
      "epoch": 0.12397675633738145,
      "grad_norm": 0.2978709042072296,
      "learning_rate": 8.760232436626186e-06,
      "loss": 0.1274,
      "step": 7830
    },
    {
      "epoch": 0.12399258989502351,
      "grad_norm": 0.0007090867147780955,
      "learning_rate": 8.760074101049765e-06,
      "loss": 0.0,
      "step": 7831
    },
    {
      "epoch": 0.12400842345266558,
      "grad_norm": 0.0002163834433304146,
      "learning_rate": 8.759915765473344e-06,
      "loss": 0.0,
      "step": 7832
    },
    {
      "epoch": 0.12402425701030764,
      "grad_norm": 0.004055938217788935,
      "learning_rate": 8.759757429896925e-06,
      "loss": 0.0001,
      "step": 7833
    },
    {
      "epoch": 0.1240400905679497,
      "grad_norm": 0.03168219327926636,
      "learning_rate": 8.759599094320504e-06,
      "loss": 0.002,
      "step": 7834
    },
    {
      "epoch": 0.12405592412559178,
      "grad_norm": 0.4778050482273102,
      "learning_rate": 8.759440758744083e-06,
      "loss": 0.3963,
      "step": 7835
    },
    {
      "epoch": 0.12407175768323385,
      "grad_norm": 0.5866037011146545,
      "learning_rate": 8.759282423167662e-06,
      "loss": 0.0931,
      "step": 7836
    },
    {
      "epoch": 0.12408759124087591,
      "grad_norm": 0.4054797887802124,
      "learning_rate": 8.759124087591241e-06,
      "loss": 0.3648,
      "step": 7837
    },
    {
      "epoch": 0.12410342479851798,
      "grad_norm": 0.21230973303318024,
      "learning_rate": 8.75896575201482e-06,
      "loss": 0.1243,
      "step": 7838
    },
    {
      "epoch": 0.12411925835616004,
      "grad_norm": 0.18609718978405,
      "learning_rate": 8.758807416438401e-06,
      "loss": 0.0862,
      "step": 7839
    },
    {
      "epoch": 0.1241350919138021,
      "grad_norm": 0.35280755162239075,
      "learning_rate": 8.75864908086198e-06,
      "loss": 0.1062,
      "step": 7840
    },
    {
      "epoch": 0.12415092547144418,
      "grad_norm": 0.001119876280426979,
      "learning_rate": 8.75849074528556e-06,
      "loss": 0.0,
      "step": 7841
    },
    {
      "epoch": 0.12416675902908625,
      "grad_norm": 0.13926242291927338,
      "learning_rate": 8.758332409709138e-06,
      "loss": 0.0333,
      "step": 7842
    },
    {
      "epoch": 0.12418259258672831,
      "grad_norm": 0.7067343592643738,
      "learning_rate": 8.758174074132717e-06,
      "loss": 0.1409,
      "step": 7843
    },
    {
      "epoch": 0.12419842614437038,
      "grad_norm": 0.3177104592323303,
      "learning_rate": 8.758015738556296e-06,
      "loss": 0.0653,
      "step": 7844
    },
    {
      "epoch": 0.12421425970201244,
      "grad_norm": 0.5070948004722595,
      "learning_rate": 8.757857402979876e-06,
      "loss": 0.8492,
      "step": 7845
    },
    {
      "epoch": 0.1242300932596545,
      "grad_norm": 0.21041271090507507,
      "learning_rate": 8.757699067403456e-06,
      "loss": 0.1369,
      "step": 7846
    },
    {
      "epoch": 0.12424592681729658,
      "grad_norm": 0.023025993257761,
      "learning_rate": 8.757540731827034e-06,
      "loss": 0.0013,
      "step": 7847
    },
    {
      "epoch": 0.12426176037493865,
      "grad_norm": 0.16804897785186768,
      "learning_rate": 8.757382396250614e-06,
      "loss": 0.0617,
      "step": 7848
    },
    {
      "epoch": 0.12427759393258071,
      "grad_norm": 0.17113973200321198,
      "learning_rate": 8.757224060674194e-06,
      "loss": 0.0858,
      "step": 7849
    },
    {
      "epoch": 0.12429342749022278,
      "grad_norm": 0.33171364665031433,
      "learning_rate": 8.757065725097773e-06,
      "loss": 0.1565,
      "step": 7850
    },
    {
      "epoch": 0.12430926104786484,
      "grad_norm": 0.23357844352722168,
      "learning_rate": 8.756907389521352e-06,
      "loss": 0.0966,
      "step": 7851
    },
    {
      "epoch": 0.1243250946055069,
      "grad_norm": 0.5808621644973755,
      "learning_rate": 8.756749053944932e-06,
      "loss": 0.7656,
      "step": 7852
    },
    {
      "epoch": 0.12434092816314898,
      "grad_norm": 0.28179317712783813,
      "learning_rate": 8.75659071836851e-06,
      "loss": 0.1581,
      "step": 7853
    },
    {
      "epoch": 0.12435676172079105,
      "grad_norm": 0.47802165150642395,
      "learning_rate": 8.75643238279209e-06,
      "loss": 0.3219,
      "step": 7854
    },
    {
      "epoch": 0.12437259527843311,
      "grad_norm": 0.6865314841270447,
      "learning_rate": 8.75627404721567e-06,
      "loss": 0.1051,
      "step": 7855
    },
    {
      "epoch": 0.12438842883607518,
      "grad_norm": 0.2955970764160156,
      "learning_rate": 8.756115711639249e-06,
      "loss": 0.1837,
      "step": 7856
    },
    {
      "epoch": 0.12440426239371724,
      "grad_norm": 0.17169499397277832,
      "learning_rate": 8.755957376062828e-06,
      "loss": 0.0584,
      "step": 7857
    },
    {
      "epoch": 0.1244200959513593,
      "grad_norm": 0.01839565485715866,
      "learning_rate": 8.755799040486409e-06,
      "loss": 0.0011,
      "step": 7858
    },
    {
      "epoch": 0.12443592950900138,
      "grad_norm": 0.012007810175418854,
      "learning_rate": 8.755640704909986e-06,
      "loss": 0.0002,
      "step": 7859
    },
    {
      "epoch": 0.12445176306664345,
      "grad_norm": 0.4057391285896301,
      "learning_rate": 8.755482369333567e-06,
      "loss": 0.6067,
      "step": 7860
    },
    {
      "epoch": 0.12446759662428551,
      "grad_norm": 0.20783746242523193,
      "learning_rate": 8.755324033757146e-06,
      "loss": 0.0105,
      "step": 7861
    },
    {
      "epoch": 0.12448343018192758,
      "grad_norm": 0.47036877274513245,
      "learning_rate": 8.755165698180725e-06,
      "loss": 0.1923,
      "step": 7862
    },
    {
      "epoch": 0.12449926373956964,
      "grad_norm": 0.43993470072746277,
      "learning_rate": 8.755007362604304e-06,
      "loss": 0.2,
      "step": 7863
    },
    {
      "epoch": 0.1245150972972117,
      "grad_norm": 0.5716586112976074,
      "learning_rate": 8.754849027027885e-06,
      "loss": 0.0108,
      "step": 7864
    },
    {
      "epoch": 0.12453093085485378,
      "grad_norm": 0.2552909851074219,
      "learning_rate": 8.754690691451462e-06,
      "loss": 0.0412,
      "step": 7865
    },
    {
      "epoch": 0.12454676441249585,
      "grad_norm": 0.28397026658058167,
      "learning_rate": 8.754532355875043e-06,
      "loss": 0.1007,
      "step": 7866
    },
    {
      "epoch": 0.12456259797013791,
      "grad_norm": 0.024573246017098427,
      "learning_rate": 8.754374020298622e-06,
      "loss": 0.0012,
      "step": 7867
    },
    {
      "epoch": 0.12457843152777998,
      "grad_norm": 0.2336779683828354,
      "learning_rate": 8.754215684722201e-06,
      "loss": 0.1257,
      "step": 7868
    },
    {
      "epoch": 0.12459426508542204,
      "grad_norm": 0.00039360442315228283,
      "learning_rate": 8.75405734914578e-06,
      "loss": 0.0,
      "step": 7869
    },
    {
      "epoch": 0.1246100986430641,
      "grad_norm": 0.1375560313463211,
      "learning_rate": 8.75389901356936e-06,
      "loss": 0.0389,
      "step": 7870
    },
    {
      "epoch": 0.12462593220070618,
      "grad_norm": 0.0003684025432448834,
      "learning_rate": 8.753740677992938e-06,
      "loss": 0.0,
      "step": 7871
    },
    {
      "epoch": 0.12464176575834825,
      "grad_norm": 0.1775071769952774,
      "learning_rate": 8.753582342416517e-06,
      "loss": 0.0659,
      "step": 7872
    },
    {
      "epoch": 0.12465759931599031,
      "grad_norm": 0.5617572665214539,
      "learning_rate": 8.753424006840098e-06,
      "loss": 0.1859,
      "step": 7873
    },
    {
      "epoch": 0.12467343287363238,
      "grad_norm": 0.31663015484809875,
      "learning_rate": 8.753265671263677e-06,
      "loss": 0.2542,
      "step": 7874
    },
    {
      "epoch": 0.12468926643127444,
      "grad_norm": 0.013519392348825932,
      "learning_rate": 8.753107335687256e-06,
      "loss": 0.0006,
      "step": 7875
    },
    {
      "epoch": 0.1247050999889165,
      "grad_norm": 0.412239134311676,
      "learning_rate": 8.752949000110835e-06,
      "loss": 0.2266,
      "step": 7876
    },
    {
      "epoch": 0.12472093354655858,
      "grad_norm": 0.31756213307380676,
      "learning_rate": 8.752790664534415e-06,
      "loss": 0.0883,
      "step": 7877
    },
    {
      "epoch": 0.12473676710420065,
      "grad_norm": 0.003395538544282317,
      "learning_rate": 8.752632328957994e-06,
      "loss": 0.0001,
      "step": 7878
    },
    {
      "epoch": 0.12475260066184271,
      "grad_norm": 0.21620497107505798,
      "learning_rate": 8.752473993381574e-06,
      "loss": 0.0819,
      "step": 7879
    },
    {
      "epoch": 0.12476843421948478,
      "grad_norm": 0.3367249369621277,
      "learning_rate": 8.752315657805154e-06,
      "loss": 0.0607,
      "step": 7880
    },
    {
      "epoch": 0.12478426777712684,
      "grad_norm": 0.6073775291442871,
      "learning_rate": 8.752157322228733e-06,
      "loss": 0.858,
      "step": 7881
    },
    {
      "epoch": 0.1248001013347689,
      "grad_norm": 0.23008565604686737,
      "learning_rate": 8.751998986652312e-06,
      "loss": 0.0382,
      "step": 7882
    },
    {
      "epoch": 0.12481593489241098,
      "grad_norm": 0.31353288888931274,
      "learning_rate": 8.75184065107589e-06,
      "loss": 0.6119,
      "step": 7883
    },
    {
      "epoch": 0.12483176845005305,
      "grad_norm": 0.49698421359062195,
      "learning_rate": 8.75168231549947e-06,
      "loss": 0.0255,
      "step": 7884
    },
    {
      "epoch": 0.12484760200769511,
      "grad_norm": 0.37328580021858215,
      "learning_rate": 8.75152397992305e-06,
      "loss": 0.323,
      "step": 7885
    },
    {
      "epoch": 0.12486343556533717,
      "grad_norm": 0.3873628079891205,
      "learning_rate": 8.75136564434663e-06,
      "loss": 0.0822,
      "step": 7886
    },
    {
      "epoch": 0.12487926912297924,
      "grad_norm": 0.0021974160335958004,
      "learning_rate": 8.751207308770209e-06,
      "loss": 0.0,
      "step": 7887
    },
    {
      "epoch": 0.1248951026806213,
      "grad_norm": 0.013011950999498367,
      "learning_rate": 8.751048973193788e-06,
      "loss": 0.0005,
      "step": 7888
    },
    {
      "epoch": 0.12491093623826338,
      "grad_norm": 0.40870264172554016,
      "learning_rate": 8.750890637617367e-06,
      "loss": 0.1259,
      "step": 7889
    },
    {
      "epoch": 0.12492676979590545,
      "grad_norm": 0.6304326057434082,
      "learning_rate": 8.750732302040946e-06,
      "loss": 0.2368,
      "step": 7890
    },
    {
      "epoch": 0.12494260335354751,
      "grad_norm": 0.00015116168651729822,
      "learning_rate": 8.750573966464527e-06,
      "loss": 0.0,
      "step": 7891
    },
    {
      "epoch": 0.12495843691118957,
      "grad_norm": 0.5836857557296753,
      "learning_rate": 8.750415630888104e-06,
      "loss": 0.0489,
      "step": 7892
    },
    {
      "epoch": 0.12497427046883164,
      "grad_norm": 0.0323668047785759,
      "learning_rate": 8.750257295311683e-06,
      "loss": 0.0016,
      "step": 7893
    },
    {
      "epoch": 0.1249901040264737,
      "grad_norm": 0.004952958784997463,
      "learning_rate": 8.750098959735264e-06,
      "loss": 0.0001,
      "step": 7894
    },
    {
      "epoch": 0.12500593758411577,
      "grad_norm": 0.2643182873725891,
      "learning_rate": 8.749940624158843e-06,
      "loss": 0.1103,
      "step": 7895
    },
    {
      "epoch": 0.12502177114175783,
      "grad_norm": 0.15359637141227722,
      "learning_rate": 8.749782288582422e-06,
      "loss": 0.0405,
      "step": 7896
    },
    {
      "epoch": 0.1250376046993999,
      "grad_norm": 0.3282984495162964,
      "learning_rate": 8.749623953006001e-06,
      "loss": 0.1978,
      "step": 7897
    },
    {
      "epoch": 0.125053438257042,
      "grad_norm": 0.4381406009197235,
      "learning_rate": 8.74946561742958e-06,
      "loss": 0.146,
      "step": 7898
    },
    {
      "epoch": 0.12506927181468405,
      "grad_norm": 0.5359471440315247,
      "learning_rate": 8.74930728185316e-06,
      "loss": 0.1718,
      "step": 7899
    },
    {
      "epoch": 0.12508510537232612,
      "grad_norm": 0.1749984472990036,
      "learning_rate": 8.74914894627674e-06,
      "loss": 0.0541,
      "step": 7900
    },
    {
      "epoch": 0.12510093892996818,
      "grad_norm": 0.006235682871192694,
      "learning_rate": 8.74899061070032e-06,
      "loss": 0.0002,
      "step": 7901
    },
    {
      "epoch": 0.12511677248761024,
      "grad_norm": 0.0005304870428517461,
      "learning_rate": 8.748832275123898e-06,
      "loss": 0.0,
      "step": 7902
    },
    {
      "epoch": 0.1251326060452523,
      "grad_norm": 0.22244316339492798,
      "learning_rate": 8.748673939547477e-06,
      "loss": 0.0519,
      "step": 7903
    },
    {
      "epoch": 0.12514843960289437,
      "grad_norm": 0.3845677971839905,
      "learning_rate": 8.748515603971056e-06,
      "loss": 0.1001,
      "step": 7904
    },
    {
      "epoch": 0.12516427316053644,
      "grad_norm": 0.36368295550346375,
      "learning_rate": 8.748357268394636e-06,
      "loss": 0.1454,
      "step": 7905
    },
    {
      "epoch": 0.1251801067181785,
      "grad_norm": 0.5322925448417664,
      "learning_rate": 8.748198932818216e-06,
      "loss": 0.1858,
      "step": 7906
    },
    {
      "epoch": 0.12519594027582057,
      "grad_norm": 0.5473551750183105,
      "learning_rate": 8.748040597241795e-06,
      "loss": 0.4456,
      "step": 7907
    },
    {
      "epoch": 0.12521177383346263,
      "grad_norm": 0.24215024709701538,
      "learning_rate": 8.747882261665375e-06,
      "loss": 0.0779,
      "step": 7908
    },
    {
      "epoch": 0.1252276073911047,
      "grad_norm": 0.6576984524726868,
      "learning_rate": 8.747723926088954e-06,
      "loss": 0.0754,
      "step": 7909
    },
    {
      "epoch": 0.1252434409487468,
      "grad_norm": 1.2719827890396118,
      "learning_rate": 8.747565590512533e-06,
      "loss": 0.5938,
      "step": 7910
    },
    {
      "epoch": 0.12525927450638885,
      "grad_norm": 0.2251168042421341,
      "learning_rate": 8.747407254936112e-06,
      "loss": 0.1047,
      "step": 7911
    },
    {
      "epoch": 0.12527510806403092,
      "grad_norm": 0.2882445156574249,
      "learning_rate": 8.747248919359693e-06,
      "loss": 0.0911,
      "step": 7912
    },
    {
      "epoch": 0.12529094162167298,
      "grad_norm": 0.1463584005832672,
      "learning_rate": 8.747090583783272e-06,
      "loss": 0.0637,
      "step": 7913
    },
    {
      "epoch": 0.12530677517931504,
      "grad_norm": 0.3625599145889282,
      "learning_rate": 8.74693224820685e-06,
      "loss": 0.0376,
      "step": 7914
    },
    {
      "epoch": 0.1253226087369571,
      "grad_norm": 0.5951473712921143,
      "learning_rate": 8.74677391263043e-06,
      "loss": 0.628,
      "step": 7915
    },
    {
      "epoch": 0.12533844229459917,
      "grad_norm": 0.3288695216178894,
      "learning_rate": 8.746615577054009e-06,
      "loss": 0.052,
      "step": 7916
    },
    {
      "epoch": 0.12535427585224124,
      "grad_norm": 0.45590081810951233,
      "learning_rate": 8.746457241477588e-06,
      "loss": 0.0749,
      "step": 7917
    },
    {
      "epoch": 0.1253701094098833,
      "grad_norm": 0.7534515261650085,
      "learning_rate": 8.746298905901167e-06,
      "loss": 0.3544,
      "step": 7918
    },
    {
      "epoch": 0.12538594296752537,
      "grad_norm": 0.2498766928911209,
      "learning_rate": 8.746140570324748e-06,
      "loss": 0.0481,
      "step": 7919
    },
    {
      "epoch": 0.12540177652516743,
      "grad_norm": 0.626910388469696,
      "learning_rate": 8.745982234748325e-06,
      "loss": 0.0536,
      "step": 7920
    },
    {
      "epoch": 0.1254176100828095,
      "grad_norm": 0.3710100054740906,
      "learning_rate": 8.745823899171906e-06,
      "loss": 0.2708,
      "step": 7921
    },
    {
      "epoch": 0.1254334436404516,
      "grad_norm": 0.041845474392175674,
      "learning_rate": 8.745665563595485e-06,
      "loss": 0.0021,
      "step": 7922
    },
    {
      "epoch": 0.12544927719809365,
      "grad_norm": 0.47753092646598816,
      "learning_rate": 8.745507228019064e-06,
      "loss": 0.1573,
      "step": 7923
    },
    {
      "epoch": 0.12546511075573571,
      "grad_norm": 0.23879018425941467,
      "learning_rate": 8.745348892442643e-06,
      "loss": 0.0417,
      "step": 7924
    },
    {
      "epoch": 0.12548094431337778,
      "grad_norm": 0.2386355698108673,
      "learning_rate": 8.745190556866224e-06,
      "loss": 0.0991,
      "step": 7925
    },
    {
      "epoch": 0.12549677787101984,
      "grad_norm": 0.3983123004436493,
      "learning_rate": 8.745032221289801e-06,
      "loss": 0.1093,
      "step": 7926
    },
    {
      "epoch": 0.1255126114286619,
      "grad_norm": 0.23869097232818604,
      "learning_rate": 8.744873885713382e-06,
      "loss": 0.1078,
      "step": 7927
    },
    {
      "epoch": 0.12552844498630397,
      "grad_norm": 0.5975512266159058,
      "learning_rate": 8.744715550136961e-06,
      "loss": 0.5153,
      "step": 7928
    },
    {
      "epoch": 0.12554427854394604,
      "grad_norm": 0.38025790452957153,
      "learning_rate": 8.74455721456054e-06,
      "loss": 0.0907,
      "step": 7929
    },
    {
      "epoch": 0.1255601121015881,
      "grad_norm": 0.48237088322639465,
      "learning_rate": 8.74439887898412e-06,
      "loss": 0.1662,
      "step": 7930
    },
    {
      "epoch": 0.12557594565923016,
      "grad_norm": 0.005517873447388411,
      "learning_rate": 8.7442405434077e-06,
      "loss": 0.0002,
      "step": 7931
    },
    {
      "epoch": 0.12559177921687223,
      "grad_norm": 0.002894426928833127,
      "learning_rate": 8.744082207831277e-06,
      "loss": 0.0001,
      "step": 7932
    },
    {
      "epoch": 0.1256076127745143,
      "grad_norm": 0.3933607041835785,
      "learning_rate": 8.743923872254858e-06,
      "loss": 0.5778,
      "step": 7933
    },
    {
      "epoch": 0.12562344633215639,
      "grad_norm": 0.5612041354179382,
      "learning_rate": 8.743765536678437e-06,
      "loss": 0.5722,
      "step": 7934
    },
    {
      "epoch": 0.12563927988979845,
      "grad_norm": 0.036923643201589584,
      "learning_rate": 8.743607201102016e-06,
      "loss": 0.0027,
      "step": 7935
    },
    {
      "epoch": 0.12565511344744051,
      "grad_norm": 0.008599583990871906,
      "learning_rate": 8.743448865525596e-06,
      "loss": 0.0004,
      "step": 7936
    },
    {
      "epoch": 0.12567094700508258,
      "grad_norm": 0.038502369076013565,
      "learning_rate": 8.743290529949176e-06,
      "loss": 0.0064,
      "step": 7937
    },
    {
      "epoch": 0.12568678056272464,
      "grad_norm": 0.4376431107521057,
      "learning_rate": 8.743132194372754e-06,
      "loss": 0.4867,
      "step": 7938
    },
    {
      "epoch": 0.1257026141203667,
      "grad_norm": 0.013049354776740074,
      "learning_rate": 8.742973858796334e-06,
      "loss": 0.0006,
      "step": 7939
    },
    {
      "epoch": 0.12571844767800877,
      "grad_norm": 0.28756460547447205,
      "learning_rate": 8.742815523219914e-06,
      "loss": 0.0881,
      "step": 7940
    },
    {
      "epoch": 0.12573428123565084,
      "grad_norm": 0.2527984082698822,
      "learning_rate": 8.742657187643493e-06,
      "loss": 0.0885,
      "step": 7941
    },
    {
      "epoch": 0.1257501147932929,
      "grad_norm": 0.5240026116371155,
      "learning_rate": 8.742498852067072e-06,
      "loss": 0.7137,
      "step": 7942
    },
    {
      "epoch": 0.12576594835093496,
      "grad_norm": 0.013607527129352093,
      "learning_rate": 8.74234051649065e-06,
      "loss": 0.0006,
      "step": 7943
    },
    {
      "epoch": 0.12578178190857703,
      "grad_norm": 0.2425018846988678,
      "learning_rate": 8.74218218091423e-06,
      "loss": 0.2128,
      "step": 7944
    },
    {
      "epoch": 0.1257976154662191,
      "grad_norm": 0.4733317494392395,
      "learning_rate": 8.742023845337809e-06,
      "loss": 0.1048,
      "step": 7945
    },
    {
      "epoch": 0.12581344902386118,
      "grad_norm": 0.4595417380332947,
      "learning_rate": 8.74186550976139e-06,
      "loss": 0.45,
      "step": 7946
    },
    {
      "epoch": 0.12582928258150325,
      "grad_norm": 0.5972611308097839,
      "learning_rate": 8.741707174184969e-06,
      "loss": 0.8259,
      "step": 7947
    },
    {
      "epoch": 0.1258451161391453,
      "grad_norm": 0.23088747262954712,
      "learning_rate": 8.741548838608548e-06,
      "loss": 0.1094,
      "step": 7948
    },
    {
      "epoch": 0.12586094969678738,
      "grad_norm": 0.007205337751656771,
      "learning_rate": 8.741390503032127e-06,
      "loss": 0.0002,
      "step": 7949
    },
    {
      "epoch": 0.12587678325442944,
      "grad_norm": 0.22254939377307892,
      "learning_rate": 8.741232167455706e-06,
      "loss": 0.0799,
      "step": 7950
    },
    {
      "epoch": 0.1258926168120715,
      "grad_norm": 0.4066106081008911,
      "learning_rate": 8.741073831879285e-06,
      "loss": 0.1176,
      "step": 7951
    },
    {
      "epoch": 0.12590845036971357,
      "grad_norm": 0.13519331812858582,
      "learning_rate": 8.740915496302866e-06,
      "loss": 0.0286,
      "step": 7952
    },
    {
      "epoch": 0.12592428392735563,
      "grad_norm": 0.10933724045753479,
      "learning_rate": 8.740757160726443e-06,
      "loss": 0.0176,
      "step": 7953
    },
    {
      "epoch": 0.1259401174849977,
      "grad_norm": 0.00637168250977993,
      "learning_rate": 8.740598825150024e-06,
      "loss": 0.0003,
      "step": 7954
    },
    {
      "epoch": 0.12595595104263976,
      "grad_norm": 0.25859543681144714,
      "learning_rate": 8.740440489573603e-06,
      "loss": 0.193,
      "step": 7955
    },
    {
      "epoch": 0.12597178460028183,
      "grad_norm": 0.16164472699165344,
      "learning_rate": 8.740282153997182e-06,
      "loss": 0.0025,
      "step": 7956
    },
    {
      "epoch": 0.1259876181579239,
      "grad_norm": 0.35715872049331665,
      "learning_rate": 8.740123818420761e-06,
      "loss": 0.0702,
      "step": 7957
    },
    {
      "epoch": 0.12600345171556598,
      "grad_norm": 0.5742789506912231,
      "learning_rate": 8.739965482844342e-06,
      "loss": 0.1943,
      "step": 7958
    },
    {
      "epoch": 0.12601928527320805,
      "grad_norm": 0.0075265346094965935,
      "learning_rate": 8.73980714726792e-06,
      "loss": 0.0004,
      "step": 7959
    },
    {
      "epoch": 0.1260351188308501,
      "grad_norm": 0.37974902987480164,
      "learning_rate": 8.7396488116915e-06,
      "loss": 0.0425,
      "step": 7960
    },
    {
      "epoch": 0.12605095238849218,
      "grad_norm": 0.1997140496969223,
      "learning_rate": 8.73949047611508e-06,
      "loss": 0.1012,
      "step": 7961
    },
    {
      "epoch": 0.12606678594613424,
      "grad_norm": 0.18801195919513702,
      "learning_rate": 8.739332140538658e-06,
      "loss": 0.0323,
      "step": 7962
    },
    {
      "epoch": 0.1260826195037763,
      "grad_norm": 0.346659392118454,
      "learning_rate": 8.739173804962237e-06,
      "loss": 0.1258,
      "step": 7963
    },
    {
      "epoch": 0.12609845306141837,
      "grad_norm": 0.3562510013580322,
      "learning_rate": 8.739015469385817e-06,
      "loss": 0.0526,
      "step": 7964
    },
    {
      "epoch": 0.12611428661906043,
      "grad_norm": 0.32113662362098694,
      "learning_rate": 8.738857133809396e-06,
      "loss": 0.0922,
      "step": 7965
    },
    {
      "epoch": 0.1261301201767025,
      "grad_norm": 0.49378135800361633,
      "learning_rate": 8.738698798232975e-06,
      "loss": 0.1326,
      "step": 7966
    },
    {
      "epoch": 0.12614595373434456,
      "grad_norm": 0.3450739085674286,
      "learning_rate": 8.738540462656555e-06,
      "loss": 0.1954,
      "step": 7967
    },
    {
      "epoch": 0.12616178729198663,
      "grad_norm": 0.18794837594032288,
      "learning_rate": 8.738382127080135e-06,
      "loss": 0.0492,
      "step": 7968
    },
    {
      "epoch": 0.1261776208496287,
      "grad_norm": 0.021794691681861877,
      "learning_rate": 8.738223791503714e-06,
      "loss": 0.0011,
      "step": 7969
    },
    {
      "epoch": 0.12619345440727078,
      "grad_norm": 0.2967912256717682,
      "learning_rate": 8.738065455927293e-06,
      "loss": 0.0453,
      "step": 7970
    },
    {
      "epoch": 0.12620928796491285,
      "grad_norm": 0.49246475100517273,
      "learning_rate": 8.737907120350872e-06,
      "loss": 0.1968,
      "step": 7971
    },
    {
      "epoch": 0.1262251215225549,
      "grad_norm": 0.3884626030921936,
      "learning_rate": 8.73774878477445e-06,
      "loss": 0.3791,
      "step": 7972
    },
    {
      "epoch": 0.12624095508019698,
      "grad_norm": 0.522734522819519,
      "learning_rate": 8.737590449198032e-06,
      "loss": 0.2056,
      "step": 7973
    },
    {
      "epoch": 0.12625678863783904,
      "grad_norm": 0.41615667939186096,
      "learning_rate": 8.73743211362161e-06,
      "loss": 0.1921,
      "step": 7974
    },
    {
      "epoch": 0.1262726221954811,
      "grad_norm": 0.26553627848625183,
      "learning_rate": 8.73727377804519e-06,
      "loss": 0.126,
      "step": 7975
    },
    {
      "epoch": 0.12628845575312317,
      "grad_norm": 0.022609949111938477,
      "learning_rate": 8.737115442468769e-06,
      "loss": 0.0013,
      "step": 7976
    },
    {
      "epoch": 0.12630428931076523,
      "grad_norm": 0.0002575686085037887,
      "learning_rate": 8.736957106892348e-06,
      "loss": 0.0,
      "step": 7977
    },
    {
      "epoch": 0.1263201228684073,
      "grad_norm": 0.41797196865081787,
      "learning_rate": 8.736798771315927e-06,
      "loss": 0.0157,
      "step": 7978
    },
    {
      "epoch": 0.12633595642604936,
      "grad_norm": 0.0006283850525505841,
      "learning_rate": 8.736640435739508e-06,
      "loss": 0.0,
      "step": 7979
    },
    {
      "epoch": 0.12635178998369143,
      "grad_norm": 0.16597937047481537,
      "learning_rate": 8.736482100163087e-06,
      "loss": 0.0332,
      "step": 7980
    },
    {
      "epoch": 0.1263676235413335,
      "grad_norm": 0.42392754554748535,
      "learning_rate": 8.736323764586666e-06,
      "loss": 0.2399,
      "step": 7981
    },
    {
      "epoch": 0.12638345709897558,
      "grad_norm": 0.5039827227592468,
      "learning_rate": 8.736165429010245e-06,
      "loss": 0.1701,
      "step": 7982
    },
    {
      "epoch": 0.12639929065661765,
      "grad_norm": 0.40334397554397583,
      "learning_rate": 8.736007093433824e-06,
      "loss": 0.1596,
      "step": 7983
    },
    {
      "epoch": 0.1264151242142597,
      "grad_norm": 0.3628562390804291,
      "learning_rate": 8.735848757857403e-06,
      "loss": 0.1665,
      "step": 7984
    },
    {
      "epoch": 0.12643095777190178,
      "grad_norm": 0.21992312371730804,
      "learning_rate": 8.735690422280984e-06,
      "loss": 0.0666,
      "step": 7985
    },
    {
      "epoch": 0.12644679132954384,
      "grad_norm": 0.18355250358581543,
      "learning_rate": 8.735532086704563e-06,
      "loss": 0.0727,
      "step": 7986
    },
    {
      "epoch": 0.1264626248871859,
      "grad_norm": 0.022519707679748535,
      "learning_rate": 8.735373751128142e-06,
      "loss": 0.0014,
      "step": 7987
    },
    {
      "epoch": 0.12647845844482797,
      "grad_norm": 0.4509735405445099,
      "learning_rate": 8.735215415551721e-06,
      "loss": 0.0862,
      "step": 7988
    },
    {
      "epoch": 0.12649429200247003,
      "grad_norm": 0.005014858674257994,
      "learning_rate": 8.7350570799753e-06,
      "loss": 0.0002,
      "step": 7989
    },
    {
      "epoch": 0.1265101255601121,
      "grad_norm": 0.00829064566642046,
      "learning_rate": 8.73489874439888e-06,
      "loss": 0.0002,
      "step": 7990
    },
    {
      "epoch": 0.12652595911775416,
      "grad_norm": 0.34695953130722046,
      "learning_rate": 8.734740408822458e-06,
      "loss": 0.1557,
      "step": 7991
    },
    {
      "epoch": 0.12654179267539623,
      "grad_norm": 2.1403403282165527,
      "learning_rate": 8.73458207324604e-06,
      "loss": 0.1081,
      "step": 7992
    },
    {
      "epoch": 0.1265576262330383,
      "grad_norm": 0.4215499460697174,
      "learning_rate": 8.734423737669617e-06,
      "loss": 0.3144,
      "step": 7993
    },
    {
      "epoch": 0.12657345979068038,
      "grad_norm": 0.3838723301887512,
      "learning_rate": 8.734265402093197e-06,
      "loss": 0.1528,
      "step": 7994
    },
    {
      "epoch": 0.12658929334832245,
      "grad_norm": 0.9104094505310059,
      "learning_rate": 8.734107066516776e-06,
      "loss": 0.4438,
      "step": 7995
    },
    {
      "epoch": 0.1266051269059645,
      "grad_norm": 0.7524694800376892,
      "learning_rate": 8.733948730940356e-06,
      "loss": 0.5763,
      "step": 7996
    },
    {
      "epoch": 0.12662096046360657,
      "grad_norm": 0.08441824465990067,
      "learning_rate": 8.733790395363935e-06,
      "loss": 0.0053,
      "step": 7997
    },
    {
      "epoch": 0.12663679402124864,
      "grad_norm": 0.0003394899540580809,
      "learning_rate": 8.733632059787515e-06,
      "loss": 0.0,
      "step": 7998
    },
    {
      "epoch": 0.1266526275788907,
      "grad_norm": 0.657279908657074,
      "learning_rate": 8.733473724211093e-06,
      "loss": 0.9472,
      "step": 7999
    },
    {
      "epoch": 0.12666846113653277,
      "grad_norm": 0.5373344421386719,
      "learning_rate": 8.733315388634674e-06,
      "loss": 0.5758,
      "step": 8000
    },
    {
      "epoch": 0.12668429469417483,
      "grad_norm": 0.020630979910492897,
      "learning_rate": 8.733157053058253e-06,
      "loss": 0.0009,
      "step": 8001
    },
    {
      "epoch": 0.1267001282518169,
      "grad_norm": 0.29724565148353577,
      "learning_rate": 8.732998717481832e-06,
      "loss": 0.058,
      "step": 8002
    },
    {
      "epoch": 0.12671596180945896,
      "grad_norm": 0.010476353578269482,
      "learning_rate": 8.73284038190541e-06,
      "loss": 0.0006,
      "step": 8003
    },
    {
      "epoch": 0.12673179536710102,
      "grad_norm": 0.01166723482310772,
      "learning_rate": 8.732682046328992e-06,
      "loss": 0.0005,
      "step": 8004
    },
    {
      "epoch": 0.1267476289247431,
      "grad_norm": 0.41675645112991333,
      "learning_rate": 8.732523710752569e-06,
      "loss": 0.2603,
      "step": 8005
    },
    {
      "epoch": 0.12676346248238518,
      "grad_norm": 0.24653935432434082,
      "learning_rate": 8.73236537517615e-06,
      "loss": 0.0693,
      "step": 8006
    },
    {
      "epoch": 0.12677929604002725,
      "grad_norm": 1.6609809398651123,
      "learning_rate": 8.732207039599729e-06,
      "loss": 0.2333,
      "step": 8007
    },
    {
      "epoch": 0.1267951295976693,
      "grad_norm": 0.0031258531380444765,
      "learning_rate": 8.732048704023308e-06,
      "loss": 0.0001,
      "step": 8008
    },
    {
      "epoch": 0.12681096315531137,
      "grad_norm": 0.21910665929317474,
      "learning_rate": 8.731890368446887e-06,
      "loss": 0.0701,
      "step": 8009
    },
    {
      "epoch": 0.12682679671295344,
      "grad_norm": 0.6135678887367249,
      "learning_rate": 8.731732032870468e-06,
      "loss": 0.0482,
      "step": 8010
    },
    {
      "epoch": 0.1268426302705955,
      "grad_norm": 0.02585877664387226,
      "learning_rate": 8.731573697294045e-06,
      "loss": 0.0018,
      "step": 8011
    },
    {
      "epoch": 0.12685846382823757,
      "grad_norm": 0.5304602384567261,
      "learning_rate": 8.731415361717624e-06,
      "loss": 0.1413,
      "step": 8012
    },
    {
      "epoch": 0.12687429738587963,
      "grad_norm": 0.6521150469779968,
      "learning_rate": 8.731257026141205e-06,
      "loss": 0.2518,
      "step": 8013
    },
    {
      "epoch": 0.1268901309435217,
      "grad_norm": 0.2077641487121582,
      "learning_rate": 8.731098690564784e-06,
      "loss": 0.1923,
      "step": 8014
    },
    {
      "epoch": 0.12690596450116376,
      "grad_norm": 0.4572408199310303,
      "learning_rate": 8.730940354988363e-06,
      "loss": 0.2689,
      "step": 8015
    },
    {
      "epoch": 0.12692179805880582,
      "grad_norm": 0.21852385997772217,
      "learning_rate": 8.730782019411942e-06,
      "loss": 0.1204,
      "step": 8016
    },
    {
      "epoch": 0.1269376316164479,
      "grad_norm": 0.6011595726013184,
      "learning_rate": 8.730623683835521e-06,
      "loss": 0.9403,
      "step": 8017
    },
    {
      "epoch": 0.12695346517408998,
      "grad_norm": 0.3169472813606262,
      "learning_rate": 8.7304653482591e-06,
      "loss": 0.0849,
      "step": 8018
    },
    {
      "epoch": 0.12696929873173204,
      "grad_norm": 1.1469320058822632,
      "learning_rate": 8.730307012682681e-06,
      "loss": 0.0681,
      "step": 8019
    },
    {
      "epoch": 0.1269851322893741,
      "grad_norm": 0.33849355578422546,
      "learning_rate": 8.730148677106259e-06,
      "loss": 0.3286,
      "step": 8020
    },
    {
      "epoch": 0.12700096584701617,
      "grad_norm": 0.0756680965423584,
      "learning_rate": 8.72999034152984e-06,
      "loss": 0.0037,
      "step": 8021
    },
    {
      "epoch": 0.12701679940465824,
      "grad_norm": 0.4369211196899414,
      "learning_rate": 8.729832005953418e-06,
      "loss": 0.3264,
      "step": 8022
    },
    {
      "epoch": 0.1270326329623003,
      "grad_norm": 0.5724565386772156,
      "learning_rate": 8.729673670376997e-06,
      "loss": 0.1874,
      "step": 8023
    },
    {
      "epoch": 0.12704846651994237,
      "grad_norm": 0.5297031998634338,
      "learning_rate": 8.729515334800577e-06,
      "loss": 0.1484,
      "step": 8024
    },
    {
      "epoch": 0.12706430007758443,
      "grad_norm": 0.84964519739151,
      "learning_rate": 8.729356999224157e-06,
      "loss": 0.0507,
      "step": 8025
    },
    {
      "epoch": 0.1270801336352265,
      "grad_norm": 0.19892781972885132,
      "learning_rate": 8.729198663647735e-06,
      "loss": 0.1162,
      "step": 8026
    },
    {
      "epoch": 0.12709596719286856,
      "grad_norm": 0.3692832291126251,
      "learning_rate": 8.729040328071315e-06,
      "loss": 0.1481,
      "step": 8027
    },
    {
      "epoch": 0.12711180075051062,
      "grad_norm": 0.16973695158958435,
      "learning_rate": 8.728881992494895e-06,
      "loss": 0.0857,
      "step": 8028
    },
    {
      "epoch": 0.1271276343081527,
      "grad_norm": 0.5176761746406555,
      "learning_rate": 8.728723656918474e-06,
      "loss": 0.5261,
      "step": 8029
    },
    {
      "epoch": 0.12714346786579478,
      "grad_norm": 1.1196008920669556,
      "learning_rate": 8.728565321342053e-06,
      "loss": 0.4033,
      "step": 8030
    },
    {
      "epoch": 0.12715930142343684,
      "grad_norm": 0.004335158038884401,
      "learning_rate": 8.728406985765633e-06,
      "loss": 0.0002,
      "step": 8031
    },
    {
      "epoch": 0.1271751349810789,
      "grad_norm": 0.017957178875803947,
      "learning_rate": 8.728248650189211e-06,
      "loss": 0.0011,
      "step": 8032
    },
    {
      "epoch": 0.12719096853872097,
      "grad_norm": 0.41535189747810364,
      "learning_rate": 8.728090314612792e-06,
      "loss": 0.5377,
      "step": 8033
    },
    {
      "epoch": 0.12720680209636304,
      "grad_norm": 0.0027302922680974007,
      "learning_rate": 8.72793197903637e-06,
      "loss": 0.0001,
      "step": 8034
    },
    {
      "epoch": 0.1272226356540051,
      "grad_norm": 0.5898780822753906,
      "learning_rate": 8.72777364345995e-06,
      "loss": 0.4249,
      "step": 8035
    },
    {
      "epoch": 0.12723846921164716,
      "grad_norm": 0.023604797199368477,
      "learning_rate": 8.727615307883529e-06,
      "loss": 0.0003,
      "step": 8036
    },
    {
      "epoch": 0.12725430276928923,
      "grad_norm": 0.5435915589332581,
      "learning_rate": 8.727456972307108e-06,
      "loss": 0.6916,
      "step": 8037
    },
    {
      "epoch": 0.1272701363269313,
      "grad_norm": 0.3355911076068878,
      "learning_rate": 8.727298636730687e-06,
      "loss": 0.1085,
      "step": 8038
    },
    {
      "epoch": 0.12728596988457336,
      "grad_norm": 0.04194860905408859,
      "learning_rate": 8.727140301154266e-06,
      "loss": 0.0024,
      "step": 8039
    },
    {
      "epoch": 0.12730180344221542,
      "grad_norm": 0.3100157678127289,
      "learning_rate": 8.726981965577847e-06,
      "loss": 0.1911,
      "step": 8040
    },
    {
      "epoch": 0.1273176369998575,
      "grad_norm": 0.2745993435382843,
      "learning_rate": 8.726823630001426e-06,
      "loss": 0.2235,
      "step": 8041
    },
    {
      "epoch": 0.12733347055749958,
      "grad_norm": 0.2520812749862671,
      "learning_rate": 8.726665294425005e-06,
      "loss": 0.2467,
      "step": 8042
    },
    {
      "epoch": 0.12734930411514164,
      "grad_norm": 0.15980927646160126,
      "learning_rate": 8.726506958848584e-06,
      "loss": 0.0454,
      "step": 8043
    },
    {
      "epoch": 0.1273651376727837,
      "grad_norm": 0.10400982201099396,
      "learning_rate": 8.726348623272163e-06,
      "loss": 0.0513,
      "step": 8044
    },
    {
      "epoch": 0.12738097123042577,
      "grad_norm": 0.5111856460571289,
      "learning_rate": 8.726190287695742e-06,
      "loss": 0.7394,
      "step": 8045
    },
    {
      "epoch": 0.12739680478806784,
      "grad_norm": 0.010503842495381832,
      "learning_rate": 8.726031952119323e-06,
      "loss": 0.0006,
      "step": 8046
    },
    {
      "epoch": 0.1274126383457099,
      "grad_norm": 0.27836960554122925,
      "learning_rate": 8.725873616542902e-06,
      "loss": 0.1178,
      "step": 8047
    },
    {
      "epoch": 0.12742847190335196,
      "grad_norm": 0.6474708318710327,
      "learning_rate": 8.725715280966481e-06,
      "loss": 0.0621,
      "step": 8048
    },
    {
      "epoch": 0.12744430546099403,
      "grad_norm": 0.17553137242794037,
      "learning_rate": 8.72555694539006e-06,
      "loss": 0.0634,
      "step": 8049
    },
    {
      "epoch": 0.1274601390186361,
      "grad_norm": 0.26936060190200806,
      "learning_rate": 8.72539860981364e-06,
      "loss": 0.2484,
      "step": 8050
    },
    {
      "epoch": 0.12747597257627816,
      "grad_norm": 0.0004269867204129696,
      "learning_rate": 8.725240274237218e-06,
      "loss": 0.0,
      "step": 8051
    },
    {
      "epoch": 0.12749180613392022,
      "grad_norm": 0.14797092974185944,
      "learning_rate": 8.7250819386608e-06,
      "loss": 0.0559,
      "step": 8052
    },
    {
      "epoch": 0.12750763969156229,
      "grad_norm": 0.01919187419116497,
      "learning_rate": 8.724923603084378e-06,
      "loss": 0.0008,
      "step": 8053
    },
    {
      "epoch": 0.12752347324920435,
      "grad_norm": 0.42630496621131897,
      "learning_rate": 8.724765267507957e-06,
      "loss": 0.1726,
      "step": 8054
    },
    {
      "epoch": 0.12753930680684644,
      "grad_norm": 0.34537288546562195,
      "learning_rate": 8.724606931931536e-06,
      "loss": 0.0606,
      "step": 8055
    },
    {
      "epoch": 0.1275551403644885,
      "grad_norm": 0.02118079923093319,
      "learning_rate": 8.724448596355116e-06,
      "loss": 0.001,
      "step": 8056
    },
    {
      "epoch": 0.12757097392213057,
      "grad_norm": 0.39701470732688904,
      "learning_rate": 8.724290260778695e-06,
      "loss": 0.1092,
      "step": 8057
    },
    {
      "epoch": 0.12758680747977263,
      "grad_norm": 0.21218006312847137,
      "learning_rate": 8.724131925202275e-06,
      "loss": 0.0925,
      "step": 8058
    },
    {
      "epoch": 0.1276026410374147,
      "grad_norm": 0.43042662739753723,
      "learning_rate": 8.723973589625854e-06,
      "loss": 0.6052,
      "step": 8059
    },
    {
      "epoch": 0.12761847459505676,
      "grad_norm": 0.6675362586975098,
      "learning_rate": 8.723815254049434e-06,
      "loss": 0.3481,
      "step": 8060
    },
    {
      "epoch": 0.12763430815269883,
      "grad_norm": 0.3184407949447632,
      "learning_rate": 8.723656918473013e-06,
      "loss": 0.1334,
      "step": 8061
    },
    {
      "epoch": 0.1276501417103409,
      "grad_norm": 0.4223078787326813,
      "learning_rate": 8.723498582896592e-06,
      "loss": 0.1562,
      "step": 8062
    },
    {
      "epoch": 0.12766597526798296,
      "grad_norm": 0.1491900086402893,
      "learning_rate": 8.72334024732017e-06,
      "loss": 0.0602,
      "step": 8063
    },
    {
      "epoch": 0.12768180882562502,
      "grad_norm": 0.39069873094558716,
      "learning_rate": 8.72318191174375e-06,
      "loss": 0.1906,
      "step": 8064
    },
    {
      "epoch": 0.12769764238326708,
      "grad_norm": 0.41259193420410156,
      "learning_rate": 8.72302357616733e-06,
      "loss": 0.5912,
      "step": 8065
    },
    {
      "epoch": 0.12771347594090915,
      "grad_norm": 0.19467765092849731,
      "learning_rate": 8.722865240590908e-06,
      "loss": 0.0311,
      "step": 8066
    },
    {
      "epoch": 0.12772930949855124,
      "grad_norm": 0.009191298857331276,
      "learning_rate": 8.722706905014489e-06,
      "loss": 0.0005,
      "step": 8067
    },
    {
      "epoch": 0.1277451430561933,
      "grad_norm": 0.000252052879659459,
      "learning_rate": 8.722548569438068e-06,
      "loss": 0.0,
      "step": 8068
    },
    {
      "epoch": 0.12776097661383537,
      "grad_norm": 0.05655127763748169,
      "learning_rate": 8.722390233861647e-06,
      "loss": 0.0031,
      "step": 8069
    },
    {
      "epoch": 0.12777681017147743,
      "grad_norm": 0.19822576642036438,
      "learning_rate": 8.722231898285226e-06,
      "loss": 0.1114,
      "step": 8070
    },
    {
      "epoch": 0.1277926437291195,
      "grad_norm": 0.3503980040550232,
      "learning_rate": 8.722073562708807e-06,
      "loss": 0.0235,
      "step": 8071
    },
    {
      "epoch": 0.12780847728676156,
      "grad_norm": 0.022769803181290627,
      "learning_rate": 8.721915227132384e-06,
      "loss": 0.0012,
      "step": 8072
    },
    {
      "epoch": 0.12782431084440363,
      "grad_norm": 0.22115862369537354,
      "learning_rate": 8.721756891555965e-06,
      "loss": 0.0379,
      "step": 8073
    },
    {
      "epoch": 0.1278401444020457,
      "grad_norm": 0.0418558269739151,
      "learning_rate": 8.721598555979544e-06,
      "loss": 0.0021,
      "step": 8074
    },
    {
      "epoch": 0.12785597795968776,
      "grad_norm": 0.3695933520793915,
      "learning_rate": 8.721440220403123e-06,
      "loss": 0.2379,
      "step": 8075
    },
    {
      "epoch": 0.12787181151732982,
      "grad_norm": 0.23128020763397217,
      "learning_rate": 8.721281884826702e-06,
      "loss": 0.1502,
      "step": 8076
    },
    {
      "epoch": 0.12788764507497188,
      "grad_norm": 0.0004336647398304194,
      "learning_rate": 8.721123549250283e-06,
      "loss": 0.0,
      "step": 8077
    },
    {
      "epoch": 0.12790347863261395,
      "grad_norm": 0.0008009672746993601,
      "learning_rate": 8.72096521367386e-06,
      "loss": 0.0,
      "step": 8078
    },
    {
      "epoch": 0.12791931219025604,
      "grad_norm": 0.45581352710723877,
      "learning_rate": 8.720806878097441e-06,
      "loss": 0.2758,
      "step": 8079
    },
    {
      "epoch": 0.1279351457478981,
      "grad_norm": 0.13950702548027039,
      "learning_rate": 8.72064854252102e-06,
      "loss": 0.0581,
      "step": 8080
    },
    {
      "epoch": 0.12795097930554017,
      "grad_norm": 0.008455499075353146,
      "learning_rate": 8.7204902069446e-06,
      "loss": 0.0005,
      "step": 8081
    },
    {
      "epoch": 0.12796681286318223,
      "grad_norm": 0.19034959375858307,
      "learning_rate": 8.720331871368178e-06,
      "loss": 0.0175,
      "step": 8082
    },
    {
      "epoch": 0.1279826464208243,
      "grad_norm": 0.011086209677159786,
      "learning_rate": 8.720173535791757e-06,
      "loss": 0.0009,
      "step": 8083
    },
    {
      "epoch": 0.12799847997846636,
      "grad_norm": 0.40554946660995483,
      "learning_rate": 8.720015200215337e-06,
      "loss": 0.7012,
      "step": 8084
    },
    {
      "epoch": 0.12801431353610843,
      "grad_norm": 0.26857900619506836,
      "learning_rate": 8.719856864638916e-06,
      "loss": 0.1058,
      "step": 8085
    },
    {
      "epoch": 0.1280301470937505,
      "grad_norm": 0.4748172163963318,
      "learning_rate": 8.719698529062496e-06,
      "loss": 0.3443,
      "step": 8086
    },
    {
      "epoch": 0.12804598065139255,
      "grad_norm": 0.46971315145492554,
      "learning_rate": 8.719540193486074e-06,
      "loss": 1.7715,
      "step": 8087
    },
    {
      "epoch": 0.12806181420903462,
      "grad_norm": 0.34992218017578125,
      "learning_rate": 8.719381857909655e-06,
      "loss": 0.0628,
      "step": 8088
    },
    {
      "epoch": 0.12807764776667668,
      "grad_norm": 0.26165276765823364,
      "learning_rate": 8.719223522333234e-06,
      "loss": 0.0722,
      "step": 8089
    },
    {
      "epoch": 0.12809348132431875,
      "grad_norm": 0.22069653868675232,
      "learning_rate": 8.719065186756813e-06,
      "loss": 0.071,
      "step": 8090
    },
    {
      "epoch": 0.12810931488196084,
      "grad_norm": 0.012042790651321411,
      "learning_rate": 8.718906851180392e-06,
      "loss": 0.0005,
      "step": 8091
    },
    {
      "epoch": 0.1281251484396029,
      "grad_norm": 0.41968509554862976,
      "learning_rate": 8.718748515603973e-06,
      "loss": 0.0381,
      "step": 8092
    },
    {
      "epoch": 0.12814098199724497,
      "grad_norm": 0.18889611959457397,
      "learning_rate": 8.71859018002755e-06,
      "loss": 0.0438,
      "step": 8093
    },
    {
      "epoch": 0.12815681555488703,
      "grad_norm": 0.48097875714302063,
      "learning_rate": 8.71843184445113e-06,
      "loss": 0.4653,
      "step": 8094
    },
    {
      "epoch": 0.1281726491125291,
      "grad_norm": 0.032122060656547546,
      "learning_rate": 8.71827350887471e-06,
      "loss": 0.0016,
      "step": 8095
    },
    {
      "epoch": 0.12818848267017116,
      "grad_norm": 0.049280766397714615,
      "learning_rate": 8.718115173298289e-06,
      "loss": 0.003,
      "step": 8096
    },
    {
      "epoch": 0.12820431622781323,
      "grad_norm": 0.2691045105457306,
      "learning_rate": 8.717956837721868e-06,
      "loss": 0.1484,
      "step": 8097
    },
    {
      "epoch": 0.1282201497854553,
      "grad_norm": 0.016868339851498604,
      "learning_rate": 8.717798502145449e-06,
      "loss": 0.0009,
      "step": 8098
    },
    {
      "epoch": 0.12823598334309735,
      "grad_norm": 0.26694056391716003,
      "learning_rate": 8.717640166569026e-06,
      "loss": 0.1103,
      "step": 8099
    },
    {
      "epoch": 0.12825181690073942,
      "grad_norm": 0.2520312964916229,
      "learning_rate": 8.717481830992607e-06,
      "loss": 0.0923,
      "step": 8100
    },
    {
      "epoch": 0.12826765045838148,
      "grad_norm": 0.07959068566560745,
      "learning_rate": 8.717323495416186e-06,
      "loss": 0.0066,
      "step": 8101
    },
    {
      "epoch": 0.12828348401602355,
      "grad_norm": 0.925503134727478,
      "learning_rate": 8.717165159839765e-06,
      "loss": 0.1134,
      "step": 8102
    },
    {
      "epoch": 0.12829931757366564,
      "grad_norm": 0.11562829464673996,
      "learning_rate": 8.717006824263344e-06,
      "loss": 0.0187,
      "step": 8103
    },
    {
      "epoch": 0.1283151511313077,
      "grad_norm": 1.0564039945602417,
      "learning_rate": 8.716848488686925e-06,
      "loss": 0.6465,
      "step": 8104
    },
    {
      "epoch": 0.12833098468894977,
      "grad_norm": 0.036525189876556396,
      "learning_rate": 8.716690153110502e-06,
      "loss": 0.0022,
      "step": 8105
    },
    {
      "epoch": 0.12834681824659183,
      "grad_norm": 0.4032560884952545,
      "learning_rate": 8.716531817534083e-06,
      "loss": 0.1531,
      "step": 8106
    },
    {
      "epoch": 0.1283626518042339,
      "grad_norm": 0.0004431887937244028,
      "learning_rate": 8.716373481957662e-06,
      "loss": 0.0,
      "step": 8107
    },
    {
      "epoch": 0.12837848536187596,
      "grad_norm": 0.27033066749572754,
      "learning_rate": 8.716215146381241e-06,
      "loss": 0.1495,
      "step": 8108
    },
    {
      "epoch": 0.12839431891951802,
      "grad_norm": 1.5451264381408691,
      "learning_rate": 8.71605681080482e-06,
      "loss": 0.1508,
      "step": 8109
    },
    {
      "epoch": 0.1284101524771601,
      "grad_norm": 0.00025157027994282544,
      "learning_rate": 8.7158984752284e-06,
      "loss": 0.0,
      "step": 8110
    },
    {
      "epoch": 0.12842598603480215,
      "grad_norm": 0.24269257485866547,
      "learning_rate": 8.715740139651978e-06,
      "loss": 0.0937,
      "step": 8111
    },
    {
      "epoch": 0.12844181959244422,
      "grad_norm": 0.2918584942817688,
      "learning_rate": 8.715581804075558e-06,
      "loss": 0.1314,
      "step": 8112
    },
    {
      "epoch": 0.12845765315008628,
      "grad_norm": 0.3423955738544464,
      "learning_rate": 8.715423468499138e-06,
      "loss": 0.6365,
      "step": 8113
    },
    {
      "epoch": 0.12847348670772835,
      "grad_norm": 0.0018547407817095518,
      "learning_rate": 8.715265132922717e-06,
      "loss": 0.0001,
      "step": 8114
    },
    {
      "epoch": 0.12848932026537044,
      "grad_norm": 0.004975601099431515,
      "learning_rate": 8.715106797346296e-06,
      "loss": 0.0002,
      "step": 8115
    },
    {
      "epoch": 0.1285051538230125,
      "grad_norm": 0.2939964532852173,
      "learning_rate": 8.714948461769876e-06,
      "loss": 0.0944,
      "step": 8116
    },
    {
      "epoch": 0.12852098738065457,
      "grad_norm": 0.03659690544009209,
      "learning_rate": 8.714790126193455e-06,
      "loss": 0.0018,
      "step": 8117
    },
    {
      "epoch": 0.12853682093829663,
      "grad_norm": 0.29358774423599243,
      "learning_rate": 8.714631790617034e-06,
      "loss": 0.0873,
      "step": 8118
    },
    {
      "epoch": 0.1285526544959387,
      "grad_norm": 0.41123437881469727,
      "learning_rate": 8.714473455040615e-06,
      "loss": 0.5257,
      "step": 8119
    },
    {
      "epoch": 0.12856848805358076,
      "grad_norm": 0.5591293573379517,
      "learning_rate": 8.714315119464194e-06,
      "loss": 0.103,
      "step": 8120
    },
    {
      "epoch": 0.12858432161122282,
      "grad_norm": 0.8291918039321899,
      "learning_rate": 8.714156783887773e-06,
      "loss": 0.2041,
      "step": 8121
    },
    {
      "epoch": 0.1286001551688649,
      "grad_norm": 0.10519535094499588,
      "learning_rate": 8.713998448311352e-06,
      "loss": 0.0024,
      "step": 8122
    },
    {
      "epoch": 0.12861598872650695,
      "grad_norm": 0.0005712659913115203,
      "learning_rate": 8.71384011273493e-06,
      "loss": 0.0,
      "step": 8123
    },
    {
      "epoch": 0.12863182228414902,
      "grad_norm": 0.6624022126197815,
      "learning_rate": 8.71368177715851e-06,
      "loss": 0.6597,
      "step": 8124
    },
    {
      "epoch": 0.12864765584179108,
      "grad_norm": 0.2945932447910309,
      "learning_rate": 8.71352344158209e-06,
      "loss": 0.2463,
      "step": 8125
    },
    {
      "epoch": 0.12866348939943315,
      "grad_norm": 0.382303923368454,
      "learning_rate": 8.71336510600567e-06,
      "loss": 0.2791,
      "step": 8126
    },
    {
      "epoch": 0.12867932295707524,
      "grad_norm": 0.19318410754203796,
      "learning_rate": 8.713206770429249e-06,
      "loss": 0.0983,
      "step": 8127
    },
    {
      "epoch": 0.1286951565147173,
      "grad_norm": 0.504589319229126,
      "learning_rate": 8.713048434852828e-06,
      "loss": 0.303,
      "step": 8128
    },
    {
      "epoch": 0.12871099007235937,
      "grad_norm": 0.3857075273990631,
      "learning_rate": 8.712890099276407e-06,
      "loss": 0.1033,
      "step": 8129
    },
    {
      "epoch": 0.12872682363000143,
      "grad_norm": 0.35067155957221985,
      "learning_rate": 8.712731763699986e-06,
      "loss": 0.0434,
      "step": 8130
    },
    {
      "epoch": 0.1287426571876435,
      "grad_norm": 0.013275613076984882,
      "learning_rate": 8.712573428123567e-06,
      "loss": 0.0006,
      "step": 8131
    },
    {
      "epoch": 0.12875849074528556,
      "grad_norm": 0.3132549226284027,
      "learning_rate": 8.712415092547146e-06,
      "loss": 0.0455,
      "step": 8132
    },
    {
      "epoch": 0.12877432430292762,
      "grad_norm": 0.30885401368141174,
      "learning_rate": 8.712256756970723e-06,
      "loss": 0.065,
      "step": 8133
    },
    {
      "epoch": 0.1287901578605697,
      "grad_norm": 0.40413278341293335,
      "learning_rate": 8.712098421394304e-06,
      "loss": 0.4655,
      "step": 8134
    },
    {
      "epoch": 0.12880599141821175,
      "grad_norm": 0.02586263231933117,
      "learning_rate": 8.711940085817883e-06,
      "loss": 0.0014,
      "step": 8135
    },
    {
      "epoch": 0.12882182497585382,
      "grad_norm": 0.2529999911785126,
      "learning_rate": 8.711781750241462e-06,
      "loss": 0.0916,
      "step": 8136
    },
    {
      "epoch": 0.12883765853349588,
      "grad_norm": 0.37067899107933044,
      "learning_rate": 8.711623414665041e-06,
      "loss": 0.1372,
      "step": 8137
    },
    {
      "epoch": 0.12885349209113794,
      "grad_norm": 0.40158236026763916,
      "learning_rate": 8.711465079088622e-06,
      "loss": 0.0832,
      "step": 8138
    },
    {
      "epoch": 0.12886932564878004,
      "grad_norm": 0.04556212201714516,
      "learning_rate": 8.7113067435122e-06,
      "loss": 0.0023,
      "step": 8139
    },
    {
      "epoch": 0.1288851592064221,
      "grad_norm": 0.29464367032051086,
      "learning_rate": 8.71114840793578e-06,
      "loss": 0.0679,
      "step": 8140
    },
    {
      "epoch": 0.12890099276406417,
      "grad_norm": 0.3210592269897461,
      "learning_rate": 8.71099007235936e-06,
      "loss": 0.035,
      "step": 8141
    },
    {
      "epoch": 0.12891682632170623,
      "grad_norm": 0.32624703645706177,
      "learning_rate": 8.710831736782938e-06,
      "loss": 0.0419,
      "step": 8142
    },
    {
      "epoch": 0.1289326598793483,
      "grad_norm": 0.017311278730630875,
      "learning_rate": 8.710673401206517e-06,
      "loss": 0.0004,
      "step": 8143
    },
    {
      "epoch": 0.12894849343699036,
      "grad_norm": 0.3510203957557678,
      "learning_rate": 8.710515065630097e-06,
      "loss": 0.1439,
      "step": 8144
    },
    {
      "epoch": 0.12896432699463242,
      "grad_norm": 0.0005384460091590881,
      "learning_rate": 8.710356730053676e-06,
      "loss": 0.0,
      "step": 8145
    },
    {
      "epoch": 0.1289801605522745,
      "grad_norm": 0.21001292765140533,
      "learning_rate": 8.710198394477256e-06,
      "loss": 0.0579,
      "step": 8146
    },
    {
      "epoch": 0.12899599410991655,
      "grad_norm": 0.0005143408779986203,
      "learning_rate": 8.710040058900836e-06,
      "loss": 0.0,
      "step": 8147
    },
    {
      "epoch": 0.12901182766755862,
      "grad_norm": 0.06735381484031677,
      "learning_rate": 8.709881723324415e-06,
      "loss": 0.0038,
      "step": 8148
    },
    {
      "epoch": 0.12902766122520068,
      "grad_norm": 0.4024451673030853,
      "learning_rate": 8.709723387747994e-06,
      "loss": 0.0982,
      "step": 8149
    },
    {
      "epoch": 0.12904349478284274,
      "grad_norm": 0.2537369430065155,
      "learning_rate": 8.709565052171573e-06,
      "loss": 0.0717,
      "step": 8150
    },
    {
      "epoch": 0.12905932834048484,
      "grad_norm": 0.34274375438690186,
      "learning_rate": 8.709406716595152e-06,
      "loss": 0.0532,
      "step": 8151
    },
    {
      "epoch": 0.1290751618981269,
      "grad_norm": 0.206265389919281,
      "learning_rate": 8.709248381018733e-06,
      "loss": 0.0595,
      "step": 8152
    },
    {
      "epoch": 0.12909099545576896,
      "grad_norm": 0.0004881555214524269,
      "learning_rate": 8.709090045442312e-06,
      "loss": 0.0,
      "step": 8153
    },
    {
      "epoch": 0.12910682901341103,
      "grad_norm": 0.5761194229125977,
      "learning_rate": 8.70893170986589e-06,
      "loss": 0.3703,
      "step": 8154
    },
    {
      "epoch": 0.1291226625710531,
      "grad_norm": 0.019040515646338463,
      "learning_rate": 8.70877337428947e-06,
      "loss": 0.0006,
      "step": 8155
    },
    {
      "epoch": 0.12913849612869516,
      "grad_norm": 0.574821412563324,
      "learning_rate": 8.708615038713049e-06,
      "loss": 0.8496,
      "step": 8156
    },
    {
      "epoch": 0.12915432968633722,
      "grad_norm": 0.014234231784939766,
      "learning_rate": 8.708456703136628e-06,
      "loss": 0.0006,
      "step": 8157
    },
    {
      "epoch": 0.12917016324397929,
      "grad_norm": 0.6089038252830505,
      "learning_rate": 8.708298367560207e-06,
      "loss": 0.1521,
      "step": 8158
    },
    {
      "epoch": 0.12918599680162135,
      "grad_norm": 0.011424481868743896,
      "learning_rate": 8.708140031983788e-06,
      "loss": 0.0003,
      "step": 8159
    },
    {
      "epoch": 0.12920183035926341,
      "grad_norm": 0.23320813477039337,
      "learning_rate": 8.707981696407365e-06,
      "loss": 0.0631,
      "step": 8160
    },
    {
      "epoch": 0.12921766391690548,
      "grad_norm": 0.009851345792412758,
      "learning_rate": 8.707823360830946e-06,
      "loss": 0.0005,
      "step": 8161
    },
    {
      "epoch": 0.12923349747454754,
      "grad_norm": 0.00562779838219285,
      "learning_rate": 8.707665025254525e-06,
      "loss": 0.0002,
      "step": 8162
    },
    {
      "epoch": 0.12924933103218963,
      "grad_norm": 0.009580009616911411,
      "learning_rate": 8.707506689678104e-06,
      "loss": 0.0004,
      "step": 8163
    },
    {
      "epoch": 0.1292651645898317,
      "grad_norm": 0.4931986629962921,
      "learning_rate": 8.707348354101683e-06,
      "loss": 0.205,
      "step": 8164
    },
    {
      "epoch": 0.12928099814747376,
      "grad_norm": 0.1774183064699173,
      "learning_rate": 8.707190018525264e-06,
      "loss": 0.0648,
      "step": 8165
    },
    {
      "epoch": 0.12929683170511583,
      "grad_norm": 0.0015656913165003061,
      "learning_rate": 8.707031682948841e-06,
      "loss": 0.0001,
      "step": 8166
    },
    {
      "epoch": 0.1293126652627579,
      "grad_norm": 0.264517605304718,
      "learning_rate": 8.706873347372422e-06,
      "loss": 0.1333,
      "step": 8167
    },
    {
      "epoch": 0.12932849882039996,
      "grad_norm": 0.2546463906764984,
      "learning_rate": 8.706715011796001e-06,
      "loss": 0.0575,
      "step": 8168
    },
    {
      "epoch": 0.12934433237804202,
      "grad_norm": 0.03677321597933769,
      "learning_rate": 8.70655667621958e-06,
      "loss": 0.0018,
      "step": 8169
    },
    {
      "epoch": 0.12936016593568408,
      "grad_norm": 0.0003204178938176483,
      "learning_rate": 8.70639834064316e-06,
      "loss": 0.0,
      "step": 8170
    },
    {
      "epoch": 0.12937599949332615,
      "grad_norm": 0.5185298323631287,
      "learning_rate": 8.70624000506674e-06,
      "loss": 0.3764,
      "step": 8171
    },
    {
      "epoch": 0.1293918330509682,
      "grad_norm": 0.02595514990389347,
      "learning_rate": 8.706081669490318e-06,
      "loss": 0.0013,
      "step": 8172
    },
    {
      "epoch": 0.12940766660861028,
      "grad_norm": 0.011586342938244343,
      "learning_rate": 8.705923333913898e-06,
      "loss": 0.0005,
      "step": 8173
    },
    {
      "epoch": 0.12942350016625234,
      "grad_norm": 0.478120893239975,
      "learning_rate": 8.705764998337477e-06,
      "loss": 0.1718,
      "step": 8174
    },
    {
      "epoch": 0.12943933372389443,
      "grad_norm": 0.8627516627311707,
      "learning_rate": 8.705606662761057e-06,
      "loss": 0.0295,
      "step": 8175
    },
    {
      "epoch": 0.1294551672815365,
      "grad_norm": 0.3046315312385559,
      "learning_rate": 8.705448327184636e-06,
      "loss": 0.0408,
      "step": 8176
    },
    {
      "epoch": 0.12947100083917856,
      "grad_norm": 0.0005327247781679034,
      "learning_rate": 8.705289991608216e-06,
      "loss": 0.0,
      "step": 8177
    },
    {
      "epoch": 0.12948683439682063,
      "grad_norm": 0.0020608766935765743,
      "learning_rate": 8.705131656031794e-06,
      "loss": 0.0,
      "step": 8178
    },
    {
      "epoch": 0.1295026679544627,
      "grad_norm": 0.3709407150745392,
      "learning_rate": 8.704973320455375e-06,
      "loss": 0.1141,
      "step": 8179
    },
    {
      "epoch": 0.12951850151210476,
      "grad_norm": 0.05666010081768036,
      "learning_rate": 8.704814984878954e-06,
      "loss": 0.0035,
      "step": 8180
    },
    {
      "epoch": 0.12953433506974682,
      "grad_norm": 0.29386618733406067,
      "learning_rate": 8.704656649302533e-06,
      "loss": 0.1184,
      "step": 8181
    },
    {
      "epoch": 0.12955016862738888,
      "grad_norm": 1.041406273841858,
      "learning_rate": 8.704498313726112e-06,
      "loss": 1.1231,
      "step": 8182
    },
    {
      "epoch": 0.12956600218503095,
      "grad_norm": 0.008404480293393135,
      "learning_rate": 8.70433997814969e-06,
      "loss": 0.0004,
      "step": 8183
    },
    {
      "epoch": 0.129581835742673,
      "grad_norm": 0.5865883231163025,
      "learning_rate": 8.70418164257327e-06,
      "loss": 0.0879,
      "step": 8184
    },
    {
      "epoch": 0.12959766930031508,
      "grad_norm": 0.32479995489120483,
      "learning_rate": 8.704023306996849e-06,
      "loss": 0.0763,
      "step": 8185
    },
    {
      "epoch": 0.12961350285795714,
      "grad_norm": 0.4859764575958252,
      "learning_rate": 8.70386497142043e-06,
      "loss": 0.2047,
      "step": 8186
    },
    {
      "epoch": 0.12962933641559923,
      "grad_norm": 0.28386640548706055,
      "learning_rate": 8.703706635844009e-06,
      "loss": 0.1639,
      "step": 8187
    },
    {
      "epoch": 0.1296451699732413,
      "grad_norm": 0.012989085167646408,
      "learning_rate": 8.703548300267588e-06,
      "loss": 0.0005,
      "step": 8188
    },
    {
      "epoch": 0.12966100353088336,
      "grad_norm": 0.6346915364265442,
      "learning_rate": 8.703389964691167e-06,
      "loss": 0.1123,
      "step": 8189
    },
    {
      "epoch": 0.12967683708852543,
      "grad_norm": 0.0002437382354401052,
      "learning_rate": 8.703231629114746e-06,
      "loss": 0.0,
      "step": 8190
    },
    {
      "epoch": 0.1296926706461675,
      "grad_norm": 0.693610429763794,
      "learning_rate": 8.703073293538325e-06,
      "loss": 0.5365,
      "step": 8191
    },
    {
      "epoch": 0.12970850420380955,
      "grad_norm": 0.2629503309726715,
      "learning_rate": 8.702914957961906e-06,
      "loss": 0.1142,
      "step": 8192
    },
    {
      "epoch": 0.12972433776145162,
      "grad_norm": 0.47893449664115906,
      "learning_rate": 8.702756622385485e-06,
      "loss": 0.0874,
      "step": 8193
    },
    {
      "epoch": 0.12974017131909368,
      "grad_norm": 0.24193109571933746,
      "learning_rate": 8.702598286809064e-06,
      "loss": 0.0564,
      "step": 8194
    },
    {
      "epoch": 0.12975600487673575,
      "grad_norm": 0.0040212771855294704,
      "learning_rate": 8.702439951232643e-06,
      "loss": 0.0002,
      "step": 8195
    },
    {
      "epoch": 0.1297718384343778,
      "grad_norm": 0.016616927459836006,
      "learning_rate": 8.702281615656222e-06,
      "loss": 0.0009,
      "step": 8196
    },
    {
      "epoch": 0.12978767199201988,
      "grad_norm": 0.3176177144050598,
      "learning_rate": 8.702123280079801e-06,
      "loss": 0.308,
      "step": 8197
    },
    {
      "epoch": 0.12980350554966194,
      "grad_norm": 1.0689115524291992,
      "learning_rate": 8.701964944503382e-06,
      "loss": 0.0052,
      "step": 8198
    },
    {
      "epoch": 0.12981933910730403,
      "grad_norm": 0.5639280080795288,
      "learning_rate": 8.701806608926961e-06,
      "loss": 0.2347,
      "step": 8199
    },
    {
      "epoch": 0.1298351726649461,
      "grad_norm": 0.4146757125854492,
      "learning_rate": 8.70164827335054e-06,
      "loss": 0.2496,
      "step": 8200
    },
    {
      "epoch": 0.12985100622258816,
      "grad_norm": 0.6264491677284241,
      "learning_rate": 8.70148993777412e-06,
      "loss": 0.1403,
      "step": 8201
    },
    {
      "epoch": 0.12986683978023023,
      "grad_norm": 0.6404018402099609,
      "learning_rate": 8.701331602197698e-06,
      "loss": 0.4081,
      "step": 8202
    },
    {
      "epoch": 0.1298826733378723,
      "grad_norm": 0.4231736660003662,
      "learning_rate": 8.701173266621278e-06,
      "loss": 0.2368,
      "step": 8203
    },
    {
      "epoch": 0.12989850689551435,
      "grad_norm": 0.1941346824169159,
      "learning_rate": 8.701014931044858e-06,
      "loss": 0.0477,
      "step": 8204
    },
    {
      "epoch": 0.12991434045315642,
      "grad_norm": 0.48144546151161194,
      "learning_rate": 8.700856595468437e-06,
      "loss": 0.5789,
      "step": 8205
    },
    {
      "epoch": 0.12993017401079848,
      "grad_norm": 0.00013681130076292902,
      "learning_rate": 8.700698259892015e-06,
      "loss": 0.0,
      "step": 8206
    },
    {
      "epoch": 0.12994600756844055,
      "grad_norm": 0.3344416916370392,
      "learning_rate": 8.700539924315596e-06,
      "loss": 0.1949,
      "step": 8207
    },
    {
      "epoch": 0.1299618411260826,
      "grad_norm": 0.30045583844184875,
      "learning_rate": 8.700381588739175e-06,
      "loss": 0.0843,
      "step": 8208
    },
    {
      "epoch": 0.12997767468372468,
      "grad_norm": 0.0067877029068768024,
      "learning_rate": 8.700223253162754e-06,
      "loss": 0.0002,
      "step": 8209
    },
    {
      "epoch": 0.12999350824136674,
      "grad_norm": 0.40400686860084534,
      "learning_rate": 8.700064917586333e-06,
      "loss": 0.5092,
      "step": 8210
    },
    {
      "epoch": 0.13000934179900883,
      "grad_norm": 0.6913201808929443,
      "learning_rate": 8.699906582009912e-06,
      "loss": 0.8555,
      "step": 8211
    },
    {
      "epoch": 0.1300251753566509,
      "grad_norm": 0.2223215401172638,
      "learning_rate": 8.699748246433491e-06,
      "loss": 0.0698,
      "step": 8212
    },
    {
      "epoch": 0.13004100891429296,
      "grad_norm": 0.019936079159379005,
      "learning_rate": 8.699589910857072e-06,
      "loss": 0.0009,
      "step": 8213
    },
    {
      "epoch": 0.13005684247193502,
      "grad_norm": 0.6361702084541321,
      "learning_rate": 8.69943157528065e-06,
      "loss": 0.0343,
      "step": 8214
    },
    {
      "epoch": 0.1300726760295771,
      "grad_norm": 0.2827419340610504,
      "learning_rate": 8.69927323970423e-06,
      "loss": 0.0051,
      "step": 8215
    },
    {
      "epoch": 0.13008850958721915,
      "grad_norm": 0.26118990778923035,
      "learning_rate": 8.699114904127809e-06,
      "loss": 0.3472,
      "step": 8216
    },
    {
      "epoch": 0.13010434314486122,
      "grad_norm": 0.14774174988269806,
      "learning_rate": 8.698956568551388e-06,
      "loss": 0.0333,
      "step": 8217
    },
    {
      "epoch": 0.13012017670250328,
      "grad_norm": 0.0013324877945706248,
      "learning_rate": 8.698798232974967e-06,
      "loss": 0.0,
      "step": 8218
    },
    {
      "epoch": 0.13013601026014535,
      "grad_norm": 0.6756018400192261,
      "learning_rate": 8.698639897398548e-06,
      "loss": 0.2602,
      "step": 8219
    },
    {
      "epoch": 0.1301518438177874,
      "grad_norm": 0.6752921938896179,
      "learning_rate": 8.698481561822127e-06,
      "loss": 0.0567,
      "step": 8220
    },
    {
      "epoch": 0.13016767737542947,
      "grad_norm": 0.25800731778144836,
      "learning_rate": 8.698323226245706e-06,
      "loss": 0.1585,
      "step": 8221
    },
    {
      "epoch": 0.13018351093307154,
      "grad_norm": 0.2608742117881775,
      "learning_rate": 8.698164890669285e-06,
      "loss": 0.1045,
      "step": 8222
    },
    {
      "epoch": 0.13019934449071363,
      "grad_norm": 2.7208139896392822,
      "learning_rate": 8.698006555092864e-06,
      "loss": 0.1497,
      "step": 8223
    },
    {
      "epoch": 0.1302151780483557,
      "grad_norm": 0.002125507453456521,
      "learning_rate": 8.697848219516443e-06,
      "loss": 0.0,
      "step": 8224
    },
    {
      "epoch": 0.13023101160599776,
      "grad_norm": 0.00033412480843253434,
      "learning_rate": 8.697689883940024e-06,
      "loss": 0.0,
      "step": 8225
    },
    {
      "epoch": 0.13024684516363982,
      "grad_norm": 0.25255534052848816,
      "learning_rate": 8.697531548363603e-06,
      "loss": 0.0652,
      "step": 8226
    },
    {
      "epoch": 0.1302626787212819,
      "grad_norm": 0.7349052429199219,
      "learning_rate": 8.697373212787182e-06,
      "loss": 0.1628,
      "step": 8227
    },
    {
      "epoch": 0.13027851227892395,
      "grad_norm": 0.5144540667533875,
      "learning_rate": 8.697214877210761e-06,
      "loss": 0.2899,
      "step": 8228
    },
    {
      "epoch": 0.13029434583656602,
      "grad_norm": 0.5598294138908386,
      "learning_rate": 8.69705654163434e-06,
      "loss": 0.1323,
      "step": 8229
    },
    {
      "epoch": 0.13031017939420808,
      "grad_norm": 0.4150261878967285,
      "learning_rate": 8.69689820605792e-06,
      "loss": 0.3464,
      "step": 8230
    },
    {
      "epoch": 0.13032601295185015,
      "grad_norm": 0.09514741599559784,
      "learning_rate": 8.696739870481499e-06,
      "loss": 0.0081,
      "step": 8231
    },
    {
      "epoch": 0.1303418465094922,
      "grad_norm": 0.4954863488674164,
      "learning_rate": 8.69658153490508e-06,
      "loss": 0.5175,
      "step": 8232
    },
    {
      "epoch": 0.13035768006713427,
      "grad_norm": 0.009521601721644402,
      "learning_rate": 8.696423199328657e-06,
      "loss": 0.0003,
      "step": 8233
    },
    {
      "epoch": 0.13037351362477634,
      "grad_norm": 0.01841340772807598,
      "learning_rate": 8.696264863752237e-06,
      "loss": 0.001,
      "step": 8234
    },
    {
      "epoch": 0.13038934718241843,
      "grad_norm": 0.016952699050307274,
      "learning_rate": 8.696106528175817e-06,
      "loss": 0.0007,
      "step": 8235
    },
    {
      "epoch": 0.1304051807400605,
      "grad_norm": 0.6772618889808655,
      "learning_rate": 8.695948192599396e-06,
      "loss": 1.0121,
      "step": 8236
    },
    {
      "epoch": 0.13042101429770256,
      "grad_norm": 0.3086591362953186,
      "learning_rate": 8.695789857022975e-06,
      "loss": 0.0947,
      "step": 8237
    },
    {
      "epoch": 0.13043684785534462,
      "grad_norm": 0.5907362699508667,
      "learning_rate": 8.695631521446555e-06,
      "loss": 0.5338,
      "step": 8238
    },
    {
      "epoch": 0.1304526814129867,
      "grad_norm": 0.2567349076271057,
      "learning_rate": 8.695473185870133e-06,
      "loss": 0.1407,
      "step": 8239
    },
    {
      "epoch": 0.13046851497062875,
      "grad_norm": 0.2697027027606964,
      "learning_rate": 8.695314850293714e-06,
      "loss": 0.1214,
      "step": 8240
    },
    {
      "epoch": 0.13048434852827082,
      "grad_norm": 0.9207455515861511,
      "learning_rate": 8.695156514717293e-06,
      "loss": 0.0438,
      "step": 8241
    },
    {
      "epoch": 0.13050018208591288,
      "grad_norm": 0.2505856454372406,
      "learning_rate": 8.694998179140872e-06,
      "loss": 0.0769,
      "step": 8242
    },
    {
      "epoch": 0.13051601564355494,
      "grad_norm": 3.657839059829712,
      "learning_rate": 8.694839843564451e-06,
      "loss": 0.5404,
      "step": 8243
    },
    {
      "epoch": 0.130531849201197,
      "grad_norm": 0.3862842917442322,
      "learning_rate": 8.694681507988032e-06,
      "loss": 0.4107,
      "step": 8244
    },
    {
      "epoch": 0.13054768275883907,
      "grad_norm": 0.1620383858680725,
      "learning_rate": 8.694523172411609e-06,
      "loss": 0.0837,
      "step": 8245
    },
    {
      "epoch": 0.13056351631648114,
      "grad_norm": 0.329311728477478,
      "learning_rate": 8.69436483683519e-06,
      "loss": 0.4726,
      "step": 8246
    },
    {
      "epoch": 0.13057934987412323,
      "grad_norm": 0.44652795791625977,
      "learning_rate": 8.694206501258769e-06,
      "loss": 0.3132,
      "step": 8247
    },
    {
      "epoch": 0.1305951834317653,
      "grad_norm": 0.000849859497975558,
      "learning_rate": 8.694048165682348e-06,
      "loss": 0.0,
      "step": 8248
    },
    {
      "epoch": 0.13061101698940736,
      "grad_norm": 0.004109095316380262,
      "learning_rate": 8.693889830105927e-06,
      "loss": 0.0001,
      "step": 8249
    },
    {
      "epoch": 0.13062685054704942,
      "grad_norm": 0.20365455746650696,
      "learning_rate": 8.693731494529508e-06,
      "loss": 0.0376,
      "step": 8250
    },
    {
      "epoch": 0.1306426841046915,
      "grad_norm": 0.005958567373454571,
      "learning_rate": 8.693573158953085e-06,
      "loss": 0.0002,
      "step": 8251
    },
    {
      "epoch": 0.13065851766233355,
      "grad_norm": 0.5964998602867126,
      "learning_rate": 8.693414823376666e-06,
      "loss": 0.332,
      "step": 8252
    },
    {
      "epoch": 0.13067435121997562,
      "grad_norm": 0.25557002425193787,
      "learning_rate": 8.693256487800245e-06,
      "loss": 0.0802,
      "step": 8253
    },
    {
      "epoch": 0.13069018477761768,
      "grad_norm": 0.2241477221250534,
      "learning_rate": 8.693098152223824e-06,
      "loss": 0.0208,
      "step": 8254
    },
    {
      "epoch": 0.13070601833525974,
      "grad_norm": 0.39837488532066345,
      "learning_rate": 8.692939816647403e-06,
      "loss": 0.5491,
      "step": 8255
    },
    {
      "epoch": 0.1307218518929018,
      "grad_norm": 0.0007808181690052152,
      "learning_rate": 8.692781481070982e-06,
      "loss": 0.0,
      "step": 8256
    },
    {
      "epoch": 0.13073768545054387,
      "grad_norm": 0.8491278886795044,
      "learning_rate": 8.692623145494561e-06,
      "loss": 0.0945,
      "step": 8257
    },
    {
      "epoch": 0.13075351900818594,
      "grad_norm": 0.3354746401309967,
      "learning_rate": 8.69246480991814e-06,
      "loss": 0.0756,
      "step": 8258
    },
    {
      "epoch": 0.13076935256582803,
      "grad_norm": 0.4875522553920746,
      "learning_rate": 8.692306474341721e-06,
      "loss": 0.1961,
      "step": 8259
    },
    {
      "epoch": 0.1307851861234701,
      "grad_norm": 0.01117466576397419,
      "learning_rate": 8.6921481387653e-06,
      "loss": 0.0005,
      "step": 8260
    },
    {
      "epoch": 0.13080101968111216,
      "grad_norm": 0.26092514395713806,
      "learning_rate": 8.69198980318888e-06,
      "loss": 0.0293,
      "step": 8261
    },
    {
      "epoch": 0.13081685323875422,
      "grad_norm": 0.5475245118141174,
      "learning_rate": 8.691831467612458e-06,
      "loss": 0.4358,
      "step": 8262
    },
    {
      "epoch": 0.13083268679639629,
      "grad_norm": 0.43254101276397705,
      "learning_rate": 8.691673132036038e-06,
      "loss": 0.0422,
      "step": 8263
    },
    {
      "epoch": 0.13084852035403835,
      "grad_norm": 0.03611087054014206,
      "learning_rate": 8.691514796459617e-06,
      "loss": 0.0014,
      "step": 8264
    },
    {
      "epoch": 0.13086435391168041,
      "grad_norm": 0.6791473627090454,
      "learning_rate": 8.691356460883197e-06,
      "loss": 0.0181,
      "step": 8265
    },
    {
      "epoch": 0.13088018746932248,
      "grad_norm": 0.005575196817517281,
      "learning_rate": 8.691198125306776e-06,
      "loss": 0.0003,
      "step": 8266
    },
    {
      "epoch": 0.13089602102696454,
      "grad_norm": 0.23657172918319702,
      "learning_rate": 8.691039789730356e-06,
      "loss": 0.1086,
      "step": 8267
    },
    {
      "epoch": 0.1309118545846066,
      "grad_norm": 0.44128885865211487,
      "learning_rate": 8.690881454153935e-06,
      "loss": 0.3185,
      "step": 8268
    },
    {
      "epoch": 0.13092768814224867,
      "grad_norm": 0.5313898324966431,
      "learning_rate": 8.690723118577514e-06,
      "loss": 0.3247,
      "step": 8269
    },
    {
      "epoch": 0.13094352169989074,
      "grad_norm": 0.6273871660232544,
      "learning_rate": 8.690564783001093e-06,
      "loss": 0.1728,
      "step": 8270
    },
    {
      "epoch": 0.13095935525753283,
      "grad_norm": 0.5341108441352844,
      "learning_rate": 8.690406447424674e-06,
      "loss": 0.0481,
      "step": 8271
    },
    {
      "epoch": 0.1309751888151749,
      "grad_norm": 0.2654759883880615,
      "learning_rate": 8.690248111848251e-06,
      "loss": 0.1453,
      "step": 8272
    },
    {
      "epoch": 0.13099102237281696,
      "grad_norm": 0.34947654604911804,
      "learning_rate": 8.690089776271832e-06,
      "loss": 0.0821,
      "step": 8273
    },
    {
      "epoch": 0.13100685593045902,
      "grad_norm": 0.43860167264938354,
      "learning_rate": 8.68993144069541e-06,
      "loss": 0.1256,
      "step": 8274
    },
    {
      "epoch": 0.13102268948810109,
      "grad_norm": 0.5055347084999084,
      "learning_rate": 8.68977310511899e-06,
      "loss": 0.0905,
      "step": 8275
    },
    {
      "epoch": 0.13103852304574315,
      "grad_norm": 0.3089953064918518,
      "learning_rate": 8.689614769542569e-06,
      "loss": 0.0877,
      "step": 8276
    },
    {
      "epoch": 0.1310543566033852,
      "grad_norm": 1.090539813041687,
      "learning_rate": 8.689456433966148e-06,
      "loss": 0.5509,
      "step": 8277
    },
    {
      "epoch": 0.13107019016102728,
      "grad_norm": 0.014906550757586956,
      "learning_rate": 8.689298098389727e-06,
      "loss": 0.0006,
      "step": 8278
    },
    {
      "epoch": 0.13108602371866934,
      "grad_norm": 0.5294075608253479,
      "learning_rate": 8.689139762813306e-06,
      "loss": 0.2401,
      "step": 8279
    },
    {
      "epoch": 0.1311018572763114,
      "grad_norm": 0.3303259611129761,
      "learning_rate": 8.688981427236887e-06,
      "loss": 0.3946,
      "step": 8280
    },
    {
      "epoch": 0.13111769083395347,
      "grad_norm": 0.01792065240442753,
      "learning_rate": 8.688823091660466e-06,
      "loss": 0.001,
      "step": 8281
    },
    {
      "epoch": 0.13113352439159554,
      "grad_norm": 0.1500418335199356,
      "learning_rate": 8.688664756084045e-06,
      "loss": 0.0482,
      "step": 8282
    },
    {
      "epoch": 0.13114935794923763,
      "grad_norm": 0.2920500934123993,
      "learning_rate": 8.688506420507624e-06,
      "loss": 0.1771,
      "step": 8283
    },
    {
      "epoch": 0.1311651915068797,
      "grad_norm": 0.20679567754268646,
      "learning_rate": 8.688348084931203e-06,
      "loss": 0.0314,
      "step": 8284
    },
    {
      "epoch": 0.13118102506452176,
      "grad_norm": 0.13508696854114532,
      "learning_rate": 8.688189749354782e-06,
      "loss": 0.0101,
      "step": 8285
    },
    {
      "epoch": 0.13119685862216382,
      "grad_norm": 0.006392191629856825,
      "learning_rate": 8.688031413778363e-06,
      "loss": 0.0003,
      "step": 8286
    },
    {
      "epoch": 0.13121269217980588,
      "grad_norm": 0.42408376932144165,
      "learning_rate": 8.687873078201942e-06,
      "loss": 0.6817,
      "step": 8287
    },
    {
      "epoch": 0.13122852573744795,
      "grad_norm": 0.14901019632816315,
      "learning_rate": 8.687714742625521e-06,
      "loss": 0.0711,
      "step": 8288
    },
    {
      "epoch": 0.13124435929509,
      "grad_norm": 0.677651584148407,
      "learning_rate": 8.6875564070491e-06,
      "loss": 0.2053,
      "step": 8289
    },
    {
      "epoch": 0.13126019285273208,
      "grad_norm": 0.3227796256542206,
      "learning_rate": 8.68739807147268e-06,
      "loss": 0.0976,
      "step": 8290
    },
    {
      "epoch": 0.13127602641037414,
      "grad_norm": 0.27871009707450867,
      "learning_rate": 8.687239735896259e-06,
      "loss": 0.2911,
      "step": 8291
    },
    {
      "epoch": 0.1312918599680162,
      "grad_norm": 0.4065690338611603,
      "learning_rate": 8.68708140031984e-06,
      "loss": 0.0527,
      "step": 8292
    },
    {
      "epoch": 0.13130769352565827,
      "grad_norm": 0.29829737544059753,
      "learning_rate": 8.686923064743418e-06,
      "loss": 0.2178,
      "step": 8293
    },
    {
      "epoch": 0.13132352708330033,
      "grad_norm": 0.004868974443525076,
      "learning_rate": 8.686764729166997e-06,
      "loss": 0.0001,
      "step": 8294
    },
    {
      "epoch": 0.13133936064094243,
      "grad_norm": 0.4170897901058197,
      "learning_rate": 8.686606393590577e-06,
      "loss": 0.5433,
      "step": 8295
    },
    {
      "epoch": 0.1313551941985845,
      "grad_norm": 0.38927310705184937,
      "learning_rate": 8.686448058014156e-06,
      "loss": 0.0907,
      "step": 8296
    },
    {
      "epoch": 0.13137102775622655,
      "grad_norm": 0.26551732420921326,
      "learning_rate": 8.686289722437735e-06,
      "loss": 0.1305,
      "step": 8297
    },
    {
      "epoch": 0.13138686131386862,
      "grad_norm": 0.009937414899468422,
      "learning_rate": 8.686131386861315e-06,
      "loss": 0.0005,
      "step": 8298
    },
    {
      "epoch": 0.13140269487151068,
      "grad_norm": 0.24602943658828735,
      "learning_rate": 8.685973051284895e-06,
      "loss": 0.1344,
      "step": 8299
    },
    {
      "epoch": 0.13141852842915275,
      "grad_norm": 0.0006130696274340153,
      "learning_rate": 8.685814715708474e-06,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 0.1314343619867948,
      "grad_norm": 0.5804966688156128,
      "learning_rate": 8.685656380132053e-06,
      "loss": 0.4216,
      "step": 8301
    },
    {
      "epoch": 0.13145019554443688,
      "grad_norm": 0.37834247946739197,
      "learning_rate": 8.685498044555632e-06,
      "loss": 0.1828,
      "step": 8302
    },
    {
      "epoch": 0.13146602910207894,
      "grad_norm": 0.4557780623435974,
      "learning_rate": 8.685339708979211e-06,
      "loss": 0.1788,
      "step": 8303
    },
    {
      "epoch": 0.131481862659721,
      "grad_norm": 0.2999153733253479,
      "learning_rate": 8.68518137340279e-06,
      "loss": 0.1297,
      "step": 8304
    },
    {
      "epoch": 0.13149769621736307,
      "grad_norm": 0.5391750931739807,
      "learning_rate": 8.68502303782637e-06,
      "loss": 0.1504,
      "step": 8305
    },
    {
      "epoch": 0.13151352977500513,
      "grad_norm": 0.3387605845928192,
      "learning_rate": 8.684864702249948e-06,
      "loss": 0.0883,
      "step": 8306
    },
    {
      "epoch": 0.13152936333264723,
      "grad_norm": 0.4628494381904602,
      "learning_rate": 8.684706366673529e-06,
      "loss": 0.1407,
      "step": 8307
    },
    {
      "epoch": 0.1315451968902893,
      "grad_norm": 0.05680805817246437,
      "learning_rate": 8.684548031097108e-06,
      "loss": 0.0032,
      "step": 8308
    },
    {
      "epoch": 0.13156103044793135,
      "grad_norm": 0.41441482305526733,
      "learning_rate": 8.684389695520687e-06,
      "loss": 0.7216,
      "step": 8309
    },
    {
      "epoch": 0.13157686400557342,
      "grad_norm": 0.0004958556382916868,
      "learning_rate": 8.684231359944266e-06,
      "loss": 0.0,
      "step": 8310
    },
    {
      "epoch": 0.13159269756321548,
      "grad_norm": 0.25903695821762085,
      "learning_rate": 8.684073024367847e-06,
      "loss": 0.0106,
      "step": 8311
    },
    {
      "epoch": 0.13160853112085755,
      "grad_norm": 0.5926883220672607,
      "learning_rate": 8.683914688791424e-06,
      "loss": 0.9152,
      "step": 8312
    },
    {
      "epoch": 0.1316243646784996,
      "grad_norm": 0.003500570310279727,
      "learning_rate": 8.683756353215005e-06,
      "loss": 0.0001,
      "step": 8313
    },
    {
      "epoch": 0.13164019823614168,
      "grad_norm": 0.019059862941503525,
      "learning_rate": 8.683598017638584e-06,
      "loss": 0.0011,
      "step": 8314
    },
    {
      "epoch": 0.13165603179378374,
      "grad_norm": 0.5905865430831909,
      "learning_rate": 8.683439682062163e-06,
      "loss": 0.2759,
      "step": 8315
    },
    {
      "epoch": 0.1316718653514258,
      "grad_norm": 0.2831220030784607,
      "learning_rate": 8.683281346485742e-06,
      "loss": 0.1565,
      "step": 8316
    },
    {
      "epoch": 0.13168769890906787,
      "grad_norm": 0.24517634510993958,
      "learning_rate": 8.683123010909323e-06,
      "loss": 0.0956,
      "step": 8317
    },
    {
      "epoch": 0.13170353246670993,
      "grad_norm": 0.06387946754693985,
      "learning_rate": 8.6829646753329e-06,
      "loss": 0.0027,
      "step": 8318
    },
    {
      "epoch": 0.13171936602435202,
      "grad_norm": 0.0710483267903328,
      "learning_rate": 8.682806339756481e-06,
      "loss": 0.0056,
      "step": 8319
    },
    {
      "epoch": 0.1317351995819941,
      "grad_norm": 0.3476846516132355,
      "learning_rate": 8.68264800418006e-06,
      "loss": 0.0382,
      "step": 8320
    },
    {
      "epoch": 0.13175103313963615,
      "grad_norm": 0.009625674225389957,
      "learning_rate": 8.68248966860364e-06,
      "loss": 0.0004,
      "step": 8321
    },
    {
      "epoch": 0.13176686669727822,
      "grad_norm": 0.29481709003448486,
      "learning_rate": 8.682331333027218e-06,
      "loss": 0.104,
      "step": 8322
    },
    {
      "epoch": 0.13178270025492028,
      "grad_norm": 0.4695683717727661,
      "learning_rate": 8.6821729974508e-06,
      "loss": 0.2155,
      "step": 8323
    },
    {
      "epoch": 0.13179853381256235,
      "grad_norm": 0.28325316309928894,
      "learning_rate": 8.682014661874377e-06,
      "loss": 0.0904,
      "step": 8324
    },
    {
      "epoch": 0.1318143673702044,
      "grad_norm": 0.47016867995262146,
      "learning_rate": 8.681856326297956e-06,
      "loss": 0.0714,
      "step": 8325
    },
    {
      "epoch": 0.13183020092784647,
      "grad_norm": 0.8834402561187744,
      "learning_rate": 8.681697990721536e-06,
      "loss": 0.1166,
      "step": 8326
    },
    {
      "epoch": 0.13184603448548854,
      "grad_norm": 0.17531520128250122,
      "learning_rate": 8.681539655145116e-06,
      "loss": 0.0558,
      "step": 8327
    },
    {
      "epoch": 0.1318618680431306,
      "grad_norm": 0.21117077767848969,
      "learning_rate": 8.681381319568695e-06,
      "loss": 0.1668,
      "step": 8328
    },
    {
      "epoch": 0.13187770160077267,
      "grad_norm": 0.3399542272090912,
      "learning_rate": 8.681222983992274e-06,
      "loss": 0.1642,
      "step": 8329
    },
    {
      "epoch": 0.13189353515841473,
      "grad_norm": 0.37444764375686646,
      "learning_rate": 8.681064648415853e-06,
      "loss": 0.1018,
      "step": 8330
    },
    {
      "epoch": 0.13190936871605682,
      "grad_norm": 0.003975181840360165,
      "learning_rate": 8.680906312839432e-06,
      "loss": 0.0002,
      "step": 8331
    },
    {
      "epoch": 0.1319252022736989,
      "grad_norm": 9.208969277096912e-05,
      "learning_rate": 8.680747977263013e-06,
      "loss": 0.0,
      "step": 8332
    },
    {
      "epoch": 0.13194103583134095,
      "grad_norm": 0.46660640835762024,
      "learning_rate": 8.680589641686592e-06,
      "loss": 0.0757,
      "step": 8333
    },
    {
      "epoch": 0.13195686938898302,
      "grad_norm": 0.00022605010599363595,
      "learning_rate": 8.68043130611017e-06,
      "loss": 0.0,
      "step": 8334
    },
    {
      "epoch": 0.13197270294662508,
      "grad_norm": 0.2733934223651886,
      "learning_rate": 8.68027297053375e-06,
      "loss": 0.0863,
      "step": 8335
    },
    {
      "epoch": 0.13198853650426715,
      "grad_norm": 0.7941942811012268,
      "learning_rate": 8.680114634957329e-06,
      "loss": 0.4099,
      "step": 8336
    },
    {
      "epoch": 0.1320043700619092,
      "grad_norm": 0.2671813666820526,
      "learning_rate": 8.679956299380908e-06,
      "loss": 0.2909,
      "step": 8337
    },
    {
      "epoch": 0.13202020361955127,
      "grad_norm": 0.49181637167930603,
      "learning_rate": 8.679797963804489e-06,
      "loss": 0.4246,
      "step": 8338
    },
    {
      "epoch": 0.13203603717719334,
      "grad_norm": 0.4220915138721466,
      "learning_rate": 8.679639628228066e-06,
      "loss": 0.0857,
      "step": 8339
    },
    {
      "epoch": 0.1320518707348354,
      "grad_norm": 0.0022095104213804007,
      "learning_rate": 8.679481292651647e-06,
      "loss": 0.0001,
      "step": 8340
    },
    {
      "epoch": 0.13206770429247747,
      "grad_norm": 0.28208649158477783,
      "learning_rate": 8.679322957075226e-06,
      "loss": 0.0657,
      "step": 8341
    },
    {
      "epoch": 0.13208353785011953,
      "grad_norm": 0.35923150181770325,
      "learning_rate": 8.679164621498805e-06,
      "loss": 0.1911,
      "step": 8342
    },
    {
      "epoch": 0.13209937140776162,
      "grad_norm": 0.000419404124841094,
      "learning_rate": 8.679006285922384e-06,
      "loss": 0.0,
      "step": 8343
    },
    {
      "epoch": 0.1321152049654037,
      "grad_norm": 0.42216745018959045,
      "learning_rate": 8.678847950345965e-06,
      "loss": 0.2498,
      "step": 8344
    },
    {
      "epoch": 0.13213103852304575,
      "grad_norm": 0.981109082698822,
      "learning_rate": 8.678689614769542e-06,
      "loss": 0.6406,
      "step": 8345
    },
    {
      "epoch": 0.13214687208068782,
      "grad_norm": 0.012202826328575611,
      "learning_rate": 8.678531279193123e-06,
      "loss": 0.0005,
      "step": 8346
    },
    {
      "epoch": 0.13216270563832988,
      "grad_norm": 0.1420363336801529,
      "learning_rate": 8.678372943616702e-06,
      "loss": 0.0417,
      "step": 8347
    },
    {
      "epoch": 0.13217853919597194,
      "grad_norm": 0.18038766086101532,
      "learning_rate": 8.678214608040281e-06,
      "loss": 0.0828,
      "step": 8348
    },
    {
      "epoch": 0.132194372753614,
      "grad_norm": 0.18979506194591522,
      "learning_rate": 8.67805627246386e-06,
      "loss": 0.0489,
      "step": 8349
    },
    {
      "epoch": 0.13221020631125607,
      "grad_norm": 0.7440815567970276,
      "learning_rate": 8.67789793688744e-06,
      "loss": 0.284,
      "step": 8350
    },
    {
      "epoch": 0.13222603986889814,
      "grad_norm": 0.37414732575416565,
      "learning_rate": 8.677739601311019e-06,
      "loss": 0.117,
      "step": 8351
    },
    {
      "epoch": 0.1322418734265402,
      "grad_norm": 0.2871374189853668,
      "learning_rate": 8.677581265734598e-06,
      "loss": 0.0741,
      "step": 8352
    },
    {
      "epoch": 0.13225770698418227,
      "grad_norm": 0.42084911465644836,
      "learning_rate": 8.677422930158178e-06,
      "loss": 0.1152,
      "step": 8353
    },
    {
      "epoch": 0.13227354054182433,
      "grad_norm": 0.5795340538024902,
      "learning_rate": 8.677264594581757e-06,
      "loss": 0.2351,
      "step": 8354
    },
    {
      "epoch": 0.13228937409946642,
      "grad_norm": 1.234002947807312,
      "learning_rate": 8.677106259005337e-06,
      "loss": 0.024,
      "step": 8355
    },
    {
      "epoch": 0.1323052076571085,
      "grad_norm": 0.00021341527462936938,
      "learning_rate": 8.676947923428916e-06,
      "loss": 0.0,
      "step": 8356
    },
    {
      "epoch": 0.13232104121475055,
      "grad_norm": 0.4032639265060425,
      "learning_rate": 8.676789587852495e-06,
      "loss": 0.4702,
      "step": 8357
    },
    {
      "epoch": 0.13233687477239262,
      "grad_norm": 0.3219579756259918,
      "learning_rate": 8.676631252276074e-06,
      "loss": 0.6059,
      "step": 8358
    },
    {
      "epoch": 0.13235270833003468,
      "grad_norm": 0.12513898313045502,
      "learning_rate": 8.676472916699655e-06,
      "loss": 0.0539,
      "step": 8359
    },
    {
      "epoch": 0.13236854188767674,
      "grad_norm": 0.31451985239982605,
      "learning_rate": 8.676314581123234e-06,
      "loss": 0.0804,
      "step": 8360
    },
    {
      "epoch": 0.1323843754453188,
      "grad_norm": 0.0013950193533673882,
      "learning_rate": 8.676156245546813e-06,
      "loss": 0.0,
      "step": 8361
    },
    {
      "epoch": 0.13240020900296087,
      "grad_norm": 0.3358851969242096,
      "learning_rate": 8.675997909970392e-06,
      "loss": 0.1107,
      "step": 8362
    },
    {
      "epoch": 0.13241604256060294,
      "grad_norm": 0.2280903160572052,
      "learning_rate": 8.675839574393971e-06,
      "loss": 0.0375,
      "step": 8363
    },
    {
      "epoch": 0.132431876118245,
      "grad_norm": 0.021371375769376755,
      "learning_rate": 8.67568123881755e-06,
      "loss": 0.0011,
      "step": 8364
    },
    {
      "epoch": 0.13244770967588707,
      "grad_norm": 0.24987514317035675,
      "learning_rate": 8.67552290324113e-06,
      "loss": 0.0944,
      "step": 8365
    },
    {
      "epoch": 0.13246354323352913,
      "grad_norm": 0.006018944550305605,
      "learning_rate": 8.67536456766471e-06,
      "loss": 0.0002,
      "step": 8366
    },
    {
      "epoch": 0.13247937679117122,
      "grad_norm": 0.301201730966568,
      "learning_rate": 8.675206232088289e-06,
      "loss": 0.1663,
      "step": 8367
    },
    {
      "epoch": 0.13249521034881329,
      "grad_norm": 0.28344497084617615,
      "learning_rate": 8.675047896511868e-06,
      "loss": 0.0473,
      "step": 8368
    },
    {
      "epoch": 0.13251104390645535,
      "grad_norm": 0.3942604959011078,
      "learning_rate": 8.674889560935447e-06,
      "loss": 0.109,
      "step": 8369
    },
    {
      "epoch": 0.13252687746409741,
      "grad_norm": 0.2517523765563965,
      "learning_rate": 8.674731225359026e-06,
      "loss": 0.061,
      "step": 8370
    },
    {
      "epoch": 0.13254271102173948,
      "grad_norm": 0.04541116952896118,
      "learning_rate": 8.674572889782607e-06,
      "loss": 0.0012,
      "step": 8371
    },
    {
      "epoch": 0.13255854457938154,
      "grad_norm": 0.3289043605327606,
      "learning_rate": 8.674414554206186e-06,
      "loss": 0.0957,
      "step": 8372
    },
    {
      "epoch": 0.1325743781370236,
      "grad_norm": 0.273896187543869,
      "learning_rate": 8.674256218629763e-06,
      "loss": 0.0952,
      "step": 8373
    },
    {
      "epoch": 0.13259021169466567,
      "grad_norm": 0.5652058720588684,
      "learning_rate": 8.674097883053344e-06,
      "loss": 0.1641,
      "step": 8374
    },
    {
      "epoch": 0.13260604525230774,
      "grad_norm": 0.012005507946014404,
      "learning_rate": 8.673939547476923e-06,
      "loss": 0.0006,
      "step": 8375
    },
    {
      "epoch": 0.1326218788099498,
      "grad_norm": 0.297638863325119,
      "learning_rate": 8.673781211900502e-06,
      "loss": 0.219,
      "step": 8376
    },
    {
      "epoch": 0.13263771236759186,
      "grad_norm": 0.46323710680007935,
      "learning_rate": 8.673622876324081e-06,
      "loss": 0.3218,
      "step": 8377
    },
    {
      "epoch": 0.13265354592523393,
      "grad_norm": 0.22567133605480194,
      "learning_rate": 8.673464540747662e-06,
      "loss": 0.0786,
      "step": 8378
    },
    {
      "epoch": 0.13266937948287602,
      "grad_norm": 0.01961652562022209,
      "learning_rate": 8.67330620517124e-06,
      "loss": 0.0008,
      "step": 8379
    },
    {
      "epoch": 0.13268521304051809,
      "grad_norm": 0.12816369533538818,
      "learning_rate": 8.67314786959482e-06,
      "loss": 0.0288,
      "step": 8380
    },
    {
      "epoch": 0.13270104659816015,
      "grad_norm": 0.26546770334243774,
      "learning_rate": 8.6729895340184e-06,
      "loss": 0.077,
      "step": 8381
    },
    {
      "epoch": 0.1327168801558022,
      "grad_norm": 0.012953403405845165,
      "learning_rate": 8.672831198441978e-06,
      "loss": 0.0006,
      "step": 8382
    },
    {
      "epoch": 0.13273271371344428,
      "grad_norm": 0.27251896262168884,
      "learning_rate": 8.672672862865558e-06,
      "loss": 0.1138,
      "step": 8383
    },
    {
      "epoch": 0.13274854727108634,
      "grad_norm": 0.6559261679649353,
      "learning_rate": 8.672514527289138e-06,
      "loss": 0.2158,
      "step": 8384
    },
    {
      "epoch": 0.1327643808287284,
      "grad_norm": 0.36684855818748474,
      "learning_rate": 8.672356191712716e-06,
      "loss": 0.2011,
      "step": 8385
    },
    {
      "epoch": 0.13278021438637047,
      "grad_norm": 0.48745158314704895,
      "learning_rate": 8.672197856136297e-06,
      "loss": 0.0995,
      "step": 8386
    },
    {
      "epoch": 0.13279604794401254,
      "grad_norm": 0.31995484232902527,
      "learning_rate": 8.672039520559876e-06,
      "loss": 0.1521,
      "step": 8387
    },
    {
      "epoch": 0.1328118815016546,
      "grad_norm": 0.0006752106128260493,
      "learning_rate": 8.671881184983455e-06,
      "loss": 0.0,
      "step": 8388
    },
    {
      "epoch": 0.13282771505929666,
      "grad_norm": 1.1682586669921875,
      "learning_rate": 8.671722849407034e-06,
      "loss": 0.1277,
      "step": 8389
    },
    {
      "epoch": 0.13284354861693873,
      "grad_norm": 0.37886425852775574,
      "learning_rate": 8.671564513830615e-06,
      "loss": 0.1832,
      "step": 8390
    },
    {
      "epoch": 0.13285938217458082,
      "grad_norm": 0.10977549105882645,
      "learning_rate": 8.671406178254192e-06,
      "loss": 0.014,
      "step": 8391
    },
    {
      "epoch": 0.13287521573222288,
      "grad_norm": 0.7688464522361755,
      "learning_rate": 8.671247842677773e-06,
      "loss": 0.2095,
      "step": 8392
    },
    {
      "epoch": 0.13289104928986495,
      "grad_norm": 0.30313459038734436,
      "learning_rate": 8.671089507101352e-06,
      "loss": 0.1223,
      "step": 8393
    },
    {
      "epoch": 0.132906882847507,
      "grad_norm": 0.3843415081501007,
      "learning_rate": 8.67093117152493e-06,
      "loss": 0.2631,
      "step": 8394
    },
    {
      "epoch": 0.13292271640514908,
      "grad_norm": 0.2596156895160675,
      "learning_rate": 8.67077283594851e-06,
      "loss": 0.0694,
      "step": 8395
    },
    {
      "epoch": 0.13293854996279114,
      "grad_norm": 0.36100369691848755,
      "learning_rate": 8.67061450037209e-06,
      "loss": 0.1929,
      "step": 8396
    },
    {
      "epoch": 0.1329543835204332,
      "grad_norm": 0.07046383619308472,
      "learning_rate": 8.670456164795668e-06,
      "loss": 0.0032,
      "step": 8397
    },
    {
      "epoch": 0.13297021707807527,
      "grad_norm": 0.1851537674665451,
      "learning_rate": 8.670297829219247e-06,
      "loss": 0.0261,
      "step": 8398
    },
    {
      "epoch": 0.13298605063571733,
      "grad_norm": 0.5510131120681763,
      "learning_rate": 8.670139493642828e-06,
      "loss": 0.8809,
      "step": 8399
    },
    {
      "epoch": 0.1330018841933594,
      "grad_norm": 0.36010169982910156,
      "learning_rate": 8.669981158066407e-06,
      "loss": 0.1245,
      "step": 8400
    },
    {
      "epoch": 0.13301771775100146,
      "grad_norm": 0.019044620916247368,
      "learning_rate": 8.669822822489986e-06,
      "loss": 0.0008,
      "step": 8401
    },
    {
      "epoch": 0.13303355130864353,
      "grad_norm": 0.2945345640182495,
      "learning_rate": 8.669664486913565e-06,
      "loss": 0.0779,
      "step": 8402
    },
    {
      "epoch": 0.13304938486628562,
      "grad_norm": 0.2641146779060364,
      "learning_rate": 8.669506151337144e-06,
      "loss": 0.0956,
      "step": 8403
    },
    {
      "epoch": 0.13306521842392768,
      "grad_norm": 0.1987462341785431,
      "learning_rate": 8.669347815760723e-06,
      "loss": 0.0421,
      "step": 8404
    },
    {
      "epoch": 0.13308105198156975,
      "grad_norm": 0.15684694051742554,
      "learning_rate": 8.669189480184304e-06,
      "loss": 0.039,
      "step": 8405
    },
    {
      "epoch": 0.1330968855392118,
      "grad_norm": 0.6791397929191589,
      "learning_rate": 8.669031144607881e-06,
      "loss": 0.0789,
      "step": 8406
    },
    {
      "epoch": 0.13311271909685388,
      "grad_norm": 0.5383045673370361,
      "learning_rate": 8.668872809031462e-06,
      "loss": 0.425,
      "step": 8407
    },
    {
      "epoch": 0.13312855265449594,
      "grad_norm": 0.5510823130607605,
      "learning_rate": 8.668714473455041e-06,
      "loss": 0.6812,
      "step": 8408
    },
    {
      "epoch": 0.133144386212138,
      "grad_norm": 0.31691619753837585,
      "learning_rate": 8.66855613787862e-06,
      "loss": 0.1527,
      "step": 8409
    },
    {
      "epoch": 0.13316021976978007,
      "grad_norm": 0.37060073018074036,
      "learning_rate": 8.6683978023022e-06,
      "loss": 0.2277,
      "step": 8410
    },
    {
      "epoch": 0.13317605332742213,
      "grad_norm": 6.719498634338379,
      "learning_rate": 8.66823946672578e-06,
      "loss": 0.3352,
      "step": 8411
    },
    {
      "epoch": 0.1331918868850642,
      "grad_norm": 0.6462041139602661,
      "learning_rate": 8.668081131149358e-06,
      "loss": 0.099,
      "step": 8412
    },
    {
      "epoch": 0.13320772044270626,
      "grad_norm": 0.46986865997314453,
      "learning_rate": 8.667922795572938e-06,
      "loss": 0.1948,
      "step": 8413
    },
    {
      "epoch": 0.13322355400034833,
      "grad_norm": 0.008970316499471664,
      "learning_rate": 8.667764459996518e-06,
      "loss": 0.0003,
      "step": 8414
    },
    {
      "epoch": 0.13323938755799042,
      "grad_norm": 0.45639127492904663,
      "learning_rate": 8.667606124420097e-06,
      "loss": 0.261,
      "step": 8415
    },
    {
      "epoch": 0.13325522111563248,
      "grad_norm": 0.44514426589012146,
      "learning_rate": 8.667447788843676e-06,
      "loss": 0.1507,
      "step": 8416
    },
    {
      "epoch": 0.13327105467327455,
      "grad_norm": 0.2852851450443268,
      "learning_rate": 8.667289453267256e-06,
      "loss": 0.0477,
      "step": 8417
    },
    {
      "epoch": 0.1332868882309166,
      "grad_norm": 0.13529108464717865,
      "learning_rate": 8.667131117690834e-06,
      "loss": 0.0502,
      "step": 8418
    },
    {
      "epoch": 0.13330272178855868,
      "grad_norm": 0.30116283893585205,
      "learning_rate": 8.666972782114415e-06,
      "loss": 0.1596,
      "step": 8419
    },
    {
      "epoch": 0.13331855534620074,
      "grad_norm": 0.04156512767076492,
      "learning_rate": 8.666814446537994e-06,
      "loss": 0.0008,
      "step": 8420
    },
    {
      "epoch": 0.1333343889038428,
      "grad_norm": 0.5235193371772766,
      "learning_rate": 8.666656110961573e-06,
      "loss": 0.4997,
      "step": 8421
    },
    {
      "epoch": 0.13335022246148487,
      "grad_norm": 0.30481433868408203,
      "learning_rate": 8.666497775385152e-06,
      "loss": 0.2401,
      "step": 8422
    },
    {
      "epoch": 0.13336605601912693,
      "grad_norm": 0.0003799562400672585,
      "learning_rate": 8.666339439808731e-06,
      "loss": 0.0,
      "step": 8423
    },
    {
      "epoch": 0.133381889576769,
      "grad_norm": 0.2762567400932312,
      "learning_rate": 8.66618110423231e-06,
      "loss": 0.0877,
      "step": 8424
    },
    {
      "epoch": 0.13339772313441106,
      "grad_norm": 0.411482036113739,
      "learning_rate": 8.666022768655889e-06,
      "loss": 0.0554,
      "step": 8425
    },
    {
      "epoch": 0.13341355669205313,
      "grad_norm": 0.38808730244636536,
      "learning_rate": 8.66586443307947e-06,
      "loss": 0.083,
      "step": 8426
    },
    {
      "epoch": 0.13342939024969522,
      "grad_norm": 0.022349972277879715,
      "learning_rate": 8.665706097503049e-06,
      "loss": 0.0011,
      "step": 8427
    },
    {
      "epoch": 0.13344522380733728,
      "grad_norm": 0.09236765652894974,
      "learning_rate": 8.665547761926628e-06,
      "loss": 0.0095,
      "step": 8428
    },
    {
      "epoch": 0.13346105736497935,
      "grad_norm": 0.6435990929603577,
      "learning_rate": 8.665389426350207e-06,
      "loss": 0.313,
      "step": 8429
    },
    {
      "epoch": 0.1334768909226214,
      "grad_norm": 0.0004498787166085094,
      "learning_rate": 8.665231090773786e-06,
      "loss": 0.0,
      "step": 8430
    },
    {
      "epoch": 0.13349272448026347,
      "grad_norm": 0.840199887752533,
      "learning_rate": 8.665072755197365e-06,
      "loss": 0.184,
      "step": 8431
    },
    {
      "epoch": 0.13350855803790554,
      "grad_norm": 0.547723114490509,
      "learning_rate": 8.664914419620946e-06,
      "loss": 0.1574,
      "step": 8432
    },
    {
      "epoch": 0.1335243915955476,
      "grad_norm": 0.23850221931934357,
      "learning_rate": 8.664756084044525e-06,
      "loss": 0.1064,
      "step": 8433
    },
    {
      "epoch": 0.13354022515318967,
      "grad_norm": 0.29495498538017273,
      "learning_rate": 8.664597748468104e-06,
      "loss": 0.1425,
      "step": 8434
    },
    {
      "epoch": 0.13355605871083173,
      "grad_norm": 0.19465021789073944,
      "learning_rate": 8.664439412891683e-06,
      "loss": 0.012,
      "step": 8435
    },
    {
      "epoch": 0.1335718922684738,
      "grad_norm": 0.30937787890434265,
      "learning_rate": 8.664281077315262e-06,
      "loss": 0.1876,
      "step": 8436
    },
    {
      "epoch": 0.13358772582611586,
      "grad_norm": 0.3374907076358795,
      "learning_rate": 8.664122741738841e-06,
      "loss": 0.0311,
      "step": 8437
    },
    {
      "epoch": 0.13360355938375792,
      "grad_norm": 0.4766077697277069,
      "learning_rate": 8.663964406162422e-06,
      "loss": 0.3264,
      "step": 8438
    },
    {
      "epoch": 0.13361939294140002,
      "grad_norm": 0.016064515337347984,
      "learning_rate": 8.663806070586001e-06,
      "loss": 0.001,
      "step": 8439
    },
    {
      "epoch": 0.13363522649904208,
      "grad_norm": 0.4151016175746918,
      "learning_rate": 8.66364773500958e-06,
      "loss": 0.1248,
      "step": 8440
    },
    {
      "epoch": 0.13365106005668415,
      "grad_norm": 0.1351788192987442,
      "learning_rate": 8.66348939943316e-06,
      "loss": 0.0326,
      "step": 8441
    },
    {
      "epoch": 0.1336668936143262,
      "grad_norm": 1.2041229009628296,
      "learning_rate": 8.663331063856739e-06,
      "loss": 0.0144,
      "step": 8442
    },
    {
      "epoch": 0.13368272717196827,
      "grad_norm": 0.199617400765419,
      "learning_rate": 8.663172728280318e-06,
      "loss": 0.0416,
      "step": 8443
    },
    {
      "epoch": 0.13369856072961034,
      "grad_norm": 0.021004298701882362,
      "learning_rate": 8.663014392703898e-06,
      "loss": 0.0011,
      "step": 8444
    },
    {
      "epoch": 0.1337143942872524,
      "grad_norm": 0.547562837600708,
      "learning_rate": 8.662856057127477e-06,
      "loss": 0.1443,
      "step": 8445
    },
    {
      "epoch": 0.13373022784489447,
      "grad_norm": 0.016236357390880585,
      "learning_rate": 8.662697721551055e-06,
      "loss": 0.0008,
      "step": 8446
    },
    {
      "epoch": 0.13374606140253653,
      "grad_norm": 0.4803644120693207,
      "learning_rate": 8.662539385974636e-06,
      "loss": 0.1708,
      "step": 8447
    },
    {
      "epoch": 0.1337618949601786,
      "grad_norm": 0.542343258857727,
      "learning_rate": 8.662381050398215e-06,
      "loss": 0.245,
      "step": 8448
    },
    {
      "epoch": 0.13377772851782066,
      "grad_norm": 0.0006958332960493863,
      "learning_rate": 8.662222714821794e-06,
      "loss": 0.0,
      "step": 8449
    },
    {
      "epoch": 0.13379356207546272,
      "grad_norm": 0.3186657726764679,
      "learning_rate": 8.662064379245373e-06,
      "loss": 0.13,
      "step": 8450
    },
    {
      "epoch": 0.1338093956331048,
      "grad_norm": 0.08145496994256973,
      "learning_rate": 8.661906043668954e-06,
      "loss": 0.0022,
      "step": 8451
    },
    {
      "epoch": 0.13382522919074688,
      "grad_norm": 0.33391690254211426,
      "learning_rate": 8.661747708092531e-06,
      "loss": 0.6945,
      "step": 8452
    },
    {
      "epoch": 0.13384106274838894,
      "grad_norm": 0.3944331407546997,
      "learning_rate": 8.661589372516112e-06,
      "loss": 0.2027,
      "step": 8453
    },
    {
      "epoch": 0.133856896306031,
      "grad_norm": 0.43767616152763367,
      "learning_rate": 8.661431036939691e-06,
      "loss": 0.2048,
      "step": 8454
    },
    {
      "epoch": 0.13387272986367307,
      "grad_norm": 0.431027352809906,
      "learning_rate": 8.66127270136327e-06,
      "loss": 0.362,
      "step": 8455
    },
    {
      "epoch": 0.13388856342131514,
      "grad_norm": 1.128892183303833,
      "learning_rate": 8.661114365786849e-06,
      "loss": 0.384,
      "step": 8456
    },
    {
      "epoch": 0.1339043969789572,
      "grad_norm": 0.4133719205856323,
      "learning_rate": 8.66095603021043e-06,
      "loss": 0.1103,
      "step": 8457
    },
    {
      "epoch": 0.13392023053659927,
      "grad_norm": 0.34233200550079346,
      "learning_rate": 8.660797694634007e-06,
      "loss": 0.1287,
      "step": 8458
    },
    {
      "epoch": 0.13393606409424133,
      "grad_norm": 0.2485070824623108,
      "learning_rate": 8.660639359057588e-06,
      "loss": 0.0295,
      "step": 8459
    },
    {
      "epoch": 0.1339518976518834,
      "grad_norm": 0.23747694492340088,
      "learning_rate": 8.660481023481167e-06,
      "loss": 0.0252,
      "step": 8460
    },
    {
      "epoch": 0.13396773120952546,
      "grad_norm": 0.30729353427886963,
      "learning_rate": 8.660322687904746e-06,
      "loss": 0.0233,
      "step": 8461
    },
    {
      "epoch": 0.13398356476716752,
      "grad_norm": 0.5325820446014404,
      "learning_rate": 8.660164352328325e-06,
      "loss": 0.3956,
      "step": 8462
    },
    {
      "epoch": 0.1339993983248096,
      "grad_norm": 0.17272426187992096,
      "learning_rate": 8.660006016751904e-06,
      "loss": 0.0535,
      "step": 8463
    },
    {
      "epoch": 0.13401523188245168,
      "grad_norm": 0.30405503511428833,
      "learning_rate": 8.659847681175483e-06,
      "loss": 0.0544,
      "step": 8464
    },
    {
      "epoch": 0.13403106544009374,
      "grad_norm": 0.3081548511981964,
      "learning_rate": 8.659689345599064e-06,
      "loss": 0.1663,
      "step": 8465
    },
    {
      "epoch": 0.1340468989977358,
      "grad_norm": 0.2814043164253235,
      "learning_rate": 8.659531010022643e-06,
      "loss": 0.2523,
      "step": 8466
    },
    {
      "epoch": 0.13406273255537787,
      "grad_norm": 0.004546895157545805,
      "learning_rate": 8.659372674446222e-06,
      "loss": 0.0001,
      "step": 8467
    },
    {
      "epoch": 0.13407856611301994,
      "grad_norm": 0.24031966924667358,
      "learning_rate": 8.659214338869801e-06,
      "loss": 0.0728,
      "step": 8468
    },
    {
      "epoch": 0.134094399670662,
      "grad_norm": 0.030250413343310356,
      "learning_rate": 8.65905600329338e-06,
      "loss": 0.0013,
      "step": 8469
    },
    {
      "epoch": 0.13411023322830407,
      "grad_norm": 0.024872377514839172,
      "learning_rate": 8.65889766771696e-06,
      "loss": 0.0013,
      "step": 8470
    },
    {
      "epoch": 0.13412606678594613,
      "grad_norm": 0.38494935631752014,
      "learning_rate": 8.658739332140539e-06,
      "loss": 0.1582,
      "step": 8471
    },
    {
      "epoch": 0.1341419003435882,
      "grad_norm": 0.2923087477684021,
      "learning_rate": 8.65858099656412e-06,
      "loss": 0.1985,
      "step": 8472
    },
    {
      "epoch": 0.13415773390123026,
      "grad_norm": 0.0003647278936114162,
      "learning_rate": 8.658422660987697e-06,
      "loss": 0.0,
      "step": 8473
    },
    {
      "epoch": 0.13417356745887232,
      "grad_norm": 0.29336434602737427,
      "learning_rate": 8.658264325411278e-06,
      "loss": 0.3628,
      "step": 8474
    },
    {
      "epoch": 0.1341894010165144,
      "grad_norm": 0.37626099586486816,
      "learning_rate": 8.658105989834857e-06,
      "loss": 0.2301,
      "step": 8475
    },
    {
      "epoch": 0.13420523457415648,
      "grad_norm": 0.4328480362892151,
      "learning_rate": 8.657947654258436e-06,
      "loss": 0.3125,
      "step": 8476
    },
    {
      "epoch": 0.13422106813179854,
      "grad_norm": 0.6151220798492432,
      "learning_rate": 8.657789318682015e-06,
      "loss": 0.1556,
      "step": 8477
    },
    {
      "epoch": 0.1342369016894406,
      "grad_norm": 0.2823752164840698,
      "learning_rate": 8.657630983105596e-06,
      "loss": 0.2365,
      "step": 8478
    },
    {
      "epoch": 0.13425273524708267,
      "grad_norm": 0.00046659293002448976,
      "learning_rate": 8.657472647529173e-06,
      "loss": 0.0,
      "step": 8479
    },
    {
      "epoch": 0.13426856880472474,
      "grad_norm": 0.5665479302406311,
      "learning_rate": 8.657314311952754e-06,
      "loss": 0.6551,
      "step": 8480
    },
    {
      "epoch": 0.1342844023623668,
      "grad_norm": 0.5174292325973511,
      "learning_rate": 8.657155976376333e-06,
      "loss": 0.6397,
      "step": 8481
    },
    {
      "epoch": 0.13430023592000886,
      "grad_norm": 1.6812975406646729,
      "learning_rate": 8.656997640799912e-06,
      "loss": 0.2403,
      "step": 8482
    },
    {
      "epoch": 0.13431606947765093,
      "grad_norm": 0.3092089891433716,
      "learning_rate": 8.656839305223491e-06,
      "loss": 0.2018,
      "step": 8483
    },
    {
      "epoch": 0.134331903035293,
      "grad_norm": 0.013334342278540134,
      "learning_rate": 8.656680969647072e-06,
      "loss": 0.0008,
      "step": 8484
    },
    {
      "epoch": 0.13434773659293506,
      "grad_norm": 0.2878175973892212,
      "learning_rate": 8.656522634070649e-06,
      "loss": 0.0365,
      "step": 8485
    },
    {
      "epoch": 0.13436357015057712,
      "grad_norm": 0.36156609654426575,
      "learning_rate": 8.65636429849423e-06,
      "loss": 0.2005,
      "step": 8486
    },
    {
      "epoch": 0.13437940370821919,
      "grad_norm": 0.2142702043056488,
      "learning_rate": 8.656205962917809e-06,
      "loss": 0.0423,
      "step": 8487
    },
    {
      "epoch": 0.13439523726586128,
      "grad_norm": 0.6081252098083496,
      "learning_rate": 8.656047627341388e-06,
      "loss": 0.5258,
      "step": 8488
    },
    {
      "epoch": 0.13441107082350334,
      "grad_norm": 0.30133384466171265,
      "learning_rate": 8.655889291764967e-06,
      "loss": 0.1533,
      "step": 8489
    },
    {
      "epoch": 0.1344269043811454,
      "grad_norm": 0.03638528287410736,
      "learning_rate": 8.655730956188548e-06,
      "loss": 0.0021,
      "step": 8490
    },
    {
      "epoch": 0.13444273793878747,
      "grad_norm": 0.03811738267540932,
      "learning_rate": 8.655572620612125e-06,
      "loss": 0.0027,
      "step": 8491
    },
    {
      "epoch": 0.13445857149642954,
      "grad_norm": 0.32657960057258606,
      "learning_rate": 8.655414285035706e-06,
      "loss": 0.1113,
      "step": 8492
    },
    {
      "epoch": 0.1344744050540716,
      "grad_norm": 0.36931443214416504,
      "learning_rate": 8.655255949459285e-06,
      "loss": 0.3997,
      "step": 8493
    },
    {
      "epoch": 0.13449023861171366,
      "grad_norm": 0.0003795971570070833,
      "learning_rate": 8.655097613882864e-06,
      "loss": 0.0,
      "step": 8494
    },
    {
      "epoch": 0.13450607216935573,
      "grad_norm": 0.4730840027332306,
      "learning_rate": 8.654939278306443e-06,
      "loss": 0.5311,
      "step": 8495
    },
    {
      "epoch": 0.1345219057269978,
      "grad_norm": 0.24040533602237701,
      "learning_rate": 8.654780942730022e-06,
      "loss": 0.2557,
      "step": 8496
    },
    {
      "epoch": 0.13453773928463986,
      "grad_norm": 1.2880921363830566,
      "learning_rate": 8.654622607153601e-06,
      "loss": 0.1866,
      "step": 8497
    },
    {
      "epoch": 0.13455357284228192,
      "grad_norm": 0.02054169587790966,
      "learning_rate": 8.65446427157718e-06,
      "loss": 0.0011,
      "step": 8498
    },
    {
      "epoch": 0.13456940639992399,
      "grad_norm": 0.24773816764354706,
      "learning_rate": 8.654305936000761e-06,
      "loss": 0.0323,
      "step": 8499
    },
    {
      "epoch": 0.13458523995756608,
      "grad_norm": 0.46130236983299255,
      "learning_rate": 8.65414760042434e-06,
      "loss": 0.0909,
      "step": 8500
    },
    {
      "epoch": 0.13460107351520814,
      "grad_norm": 0.013149849139153957,
      "learning_rate": 8.65398926484792e-06,
      "loss": 0.0005,
      "step": 8501
    },
    {
      "epoch": 0.1346169070728502,
      "grad_norm": 0.0002893266500905156,
      "learning_rate": 8.653830929271499e-06,
      "loss": 0.0,
      "step": 8502
    },
    {
      "epoch": 0.13463274063049227,
      "grad_norm": 0.0005979527486488223,
      "learning_rate": 8.653672593695078e-06,
      "loss": 0.0,
      "step": 8503
    },
    {
      "epoch": 0.13464857418813433,
      "grad_norm": 0.5117812156677246,
      "learning_rate": 8.653514258118657e-06,
      "loss": 0.5076,
      "step": 8504
    },
    {
      "epoch": 0.1346644077457764,
      "grad_norm": 0.033715806901454926,
      "learning_rate": 8.653355922542237e-06,
      "loss": 0.0006,
      "step": 8505
    },
    {
      "epoch": 0.13468024130341846,
      "grad_norm": 0.4063294529914856,
      "learning_rate": 8.653197586965817e-06,
      "loss": 0.1049,
      "step": 8506
    },
    {
      "epoch": 0.13469607486106053,
      "grad_norm": 0.2248060256242752,
      "learning_rate": 8.653039251389396e-06,
      "loss": 0.104,
      "step": 8507
    },
    {
      "epoch": 0.1347119084187026,
      "grad_norm": 0.16645650565624237,
      "learning_rate": 8.652880915812975e-06,
      "loss": 0.056,
      "step": 8508
    },
    {
      "epoch": 0.13472774197634466,
      "grad_norm": 0.0034683288540691137,
      "learning_rate": 8.652722580236554e-06,
      "loss": 0.0002,
      "step": 8509
    },
    {
      "epoch": 0.13474357553398672,
      "grad_norm": 0.0003173853037878871,
      "learning_rate": 8.652564244660133e-06,
      "loss": 0.0,
      "step": 8510
    },
    {
      "epoch": 0.13475940909162878,
      "grad_norm": 0.42327019572257996,
      "learning_rate": 8.652405909083714e-06,
      "loss": 0.1601,
      "step": 8511
    },
    {
      "epoch": 0.13477524264927088,
      "grad_norm": 0.3280664086341858,
      "learning_rate": 8.652247573507293e-06,
      "loss": 0.17,
      "step": 8512
    },
    {
      "epoch": 0.13479107620691294,
      "grad_norm": 0.2922542989253998,
      "learning_rate": 8.652089237930872e-06,
      "loss": 0.1379,
      "step": 8513
    },
    {
      "epoch": 0.134806909764555,
      "grad_norm": 0.005637906026095152,
      "learning_rate": 8.651930902354451e-06,
      "loss": 0.0002,
      "step": 8514
    },
    {
      "epoch": 0.13482274332219707,
      "grad_norm": 0.21817900240421295,
      "learning_rate": 8.65177256677803e-06,
      "loss": 0.2653,
      "step": 8515
    },
    {
      "epoch": 0.13483857687983913,
      "grad_norm": 0.46603623032569885,
      "learning_rate": 8.651614231201609e-06,
      "loss": 0.3736,
      "step": 8516
    },
    {
      "epoch": 0.1348544104374812,
      "grad_norm": 0.01924273557960987,
      "learning_rate": 8.65145589562519e-06,
      "loss": 0.0009,
      "step": 8517
    },
    {
      "epoch": 0.13487024399512326,
      "grad_norm": 0.28341975808143616,
      "learning_rate": 8.651297560048769e-06,
      "loss": 0.0752,
      "step": 8518
    },
    {
      "epoch": 0.13488607755276533,
      "grad_norm": 0.24328923225402832,
      "learning_rate": 8.651139224472346e-06,
      "loss": 0.1313,
      "step": 8519
    },
    {
      "epoch": 0.1349019111104074,
      "grad_norm": 0.5859659910202026,
      "learning_rate": 8.650980888895927e-06,
      "loss": 0.1954,
      "step": 8520
    },
    {
      "epoch": 0.13491774466804946,
      "grad_norm": 0.0005327541148290038,
      "learning_rate": 8.650822553319506e-06,
      "loss": 0.0,
      "step": 8521
    },
    {
      "epoch": 0.13493357822569152,
      "grad_norm": 0.42310258746147156,
      "learning_rate": 8.650664217743085e-06,
      "loss": 0.1658,
      "step": 8522
    },
    {
      "epoch": 0.13494941178333358,
      "grad_norm": 0.0011261089239269495,
      "learning_rate": 8.650505882166664e-06,
      "loss": 0.0,
      "step": 8523
    },
    {
      "epoch": 0.13496524534097568,
      "grad_norm": 0.2701151967048645,
      "learning_rate": 8.650347546590245e-06,
      "loss": 0.1003,
      "step": 8524
    },
    {
      "epoch": 0.13498107889861774,
      "grad_norm": 0.1136142686009407,
      "learning_rate": 8.650189211013822e-06,
      "loss": 0.002,
      "step": 8525
    },
    {
      "epoch": 0.1349969124562598,
      "grad_norm": 0.26299798488616943,
      "learning_rate": 8.650030875437403e-06,
      "loss": 0.0865,
      "step": 8526
    },
    {
      "epoch": 0.13501274601390187,
      "grad_norm": 0.43704524636268616,
      "learning_rate": 8.649872539860982e-06,
      "loss": 0.1631,
      "step": 8527
    },
    {
      "epoch": 0.13502857957154393,
      "grad_norm": 0.35352468490600586,
      "learning_rate": 8.649714204284561e-06,
      "loss": 0.1111,
      "step": 8528
    },
    {
      "epoch": 0.135044413129186,
      "grad_norm": 0.48987600207328796,
      "learning_rate": 8.64955586870814e-06,
      "loss": 0.2374,
      "step": 8529
    },
    {
      "epoch": 0.13506024668682806,
      "grad_norm": 0.23369677364826202,
      "learning_rate": 8.64939753313172e-06,
      "loss": 0.099,
      "step": 8530
    },
    {
      "epoch": 0.13507608024447013,
      "grad_norm": 0.1541951447725296,
      "learning_rate": 8.649239197555299e-06,
      "loss": 0.0041,
      "step": 8531
    },
    {
      "epoch": 0.1350919138021122,
      "grad_norm": 1.3452668190002441,
      "learning_rate": 8.64908086197888e-06,
      "loss": 1.0875,
      "step": 8532
    },
    {
      "epoch": 0.13510774735975425,
      "grad_norm": 0.0003233336901757866,
      "learning_rate": 8.648922526402458e-06,
      "loss": 0.0,
      "step": 8533
    },
    {
      "epoch": 0.13512358091739632,
      "grad_norm": 0.3871762752532959,
      "learning_rate": 8.648764190826038e-06,
      "loss": 0.3147,
      "step": 8534
    },
    {
      "epoch": 0.13513941447503838,
      "grad_norm": 0.39145582914352417,
      "learning_rate": 8.648605855249617e-06,
      "loss": 0.3275,
      "step": 8535
    },
    {
      "epoch": 0.13515524803268048,
      "grad_norm": 0.00044495565816760063,
      "learning_rate": 8.648447519673196e-06,
      "loss": 0.0,
      "step": 8536
    },
    {
      "epoch": 0.13517108159032254,
      "grad_norm": 1.260294795036316,
      "learning_rate": 8.648289184096775e-06,
      "loss": 0.0461,
      "step": 8537
    },
    {
      "epoch": 0.1351869151479646,
      "grad_norm": 0.548442542552948,
      "learning_rate": 8.648130848520356e-06,
      "loss": 0.2331,
      "step": 8538
    },
    {
      "epoch": 0.13520274870560667,
      "grad_norm": 0.6965072751045227,
      "learning_rate": 8.647972512943935e-06,
      "loss": 0.2669,
      "step": 8539
    },
    {
      "epoch": 0.13521858226324873,
      "grad_norm": 0.223317950963974,
      "learning_rate": 8.647814177367514e-06,
      "loss": 0.0078,
      "step": 8540
    },
    {
      "epoch": 0.1352344158208908,
      "grad_norm": 0.6654508113861084,
      "learning_rate": 8.647655841791093e-06,
      "loss": 0.439,
      "step": 8541
    },
    {
      "epoch": 0.13525024937853286,
      "grad_norm": 0.00020679316367022693,
      "learning_rate": 8.647497506214672e-06,
      "loss": 0.0,
      "step": 8542
    },
    {
      "epoch": 0.13526608293617493,
      "grad_norm": 0.3111797571182251,
      "learning_rate": 8.647339170638251e-06,
      "loss": 0.1521,
      "step": 8543
    },
    {
      "epoch": 0.135281916493817,
      "grad_norm": 0.4768936336040497,
      "learning_rate": 8.64718083506183e-06,
      "loss": 0.3687,
      "step": 8544
    },
    {
      "epoch": 0.13529775005145905,
      "grad_norm": 0.21864517033100128,
      "learning_rate": 8.64702249948541e-06,
      "loss": 0.0297,
      "step": 8545
    },
    {
      "epoch": 0.13531358360910112,
      "grad_norm": 0.0201974269002676,
      "learning_rate": 8.646864163908988e-06,
      "loss": 0.0011,
      "step": 8546
    },
    {
      "epoch": 0.13532941716674318,
      "grad_norm": 0.239124596118927,
      "learning_rate": 8.646705828332569e-06,
      "loss": 0.1483,
      "step": 8547
    },
    {
      "epoch": 0.13534525072438527,
      "grad_norm": 0.38464978337287903,
      "learning_rate": 8.646547492756148e-06,
      "loss": 0.1821,
      "step": 8548
    },
    {
      "epoch": 0.13536108428202734,
      "grad_norm": 0.2509256899356842,
      "learning_rate": 8.646389157179727e-06,
      "loss": 0.1106,
      "step": 8549
    },
    {
      "epoch": 0.1353769178396694,
      "grad_norm": 0.014097110368311405,
      "learning_rate": 8.646230821603306e-06,
      "loss": 0.0007,
      "step": 8550
    },
    {
      "epoch": 0.13539275139731147,
      "grad_norm": 0.3964630961418152,
      "learning_rate": 8.646072486026887e-06,
      "loss": 0.0573,
      "step": 8551
    },
    {
      "epoch": 0.13540858495495353,
      "grad_norm": 0.05665111541748047,
      "learning_rate": 8.645914150450464e-06,
      "loss": 0.0024,
      "step": 8552
    },
    {
      "epoch": 0.1354244185125956,
      "grad_norm": 0.41958099603652954,
      "learning_rate": 8.645755814874045e-06,
      "loss": 0.1176,
      "step": 8553
    },
    {
      "epoch": 0.13544025207023766,
      "grad_norm": 0.0001816922886064276,
      "learning_rate": 8.645597479297624e-06,
      "loss": 0.0,
      "step": 8554
    },
    {
      "epoch": 0.13545608562787972,
      "grad_norm": 0.2280651330947876,
      "learning_rate": 8.645439143721203e-06,
      "loss": 0.0169,
      "step": 8555
    },
    {
      "epoch": 0.1354719191855218,
      "grad_norm": 0.16472913324832916,
      "learning_rate": 8.645280808144782e-06,
      "loss": 0.0532,
      "step": 8556
    },
    {
      "epoch": 0.13548775274316385,
      "grad_norm": 0.002558330073952675,
      "learning_rate": 8.645122472568363e-06,
      "loss": 0.0001,
      "step": 8557
    },
    {
      "epoch": 0.13550358630080592,
      "grad_norm": 0.24736681580543518,
      "learning_rate": 8.64496413699194e-06,
      "loss": 0.0821,
      "step": 8558
    },
    {
      "epoch": 0.13551941985844798,
      "grad_norm": 0.6670584082603455,
      "learning_rate": 8.644805801415521e-06,
      "loss": 0.2739,
      "step": 8559
    },
    {
      "epoch": 0.13553525341609007,
      "grad_norm": 0.7518883347511292,
      "learning_rate": 8.6446474658391e-06,
      "loss": 0.3776,
      "step": 8560
    },
    {
      "epoch": 0.13555108697373214,
      "grad_norm": 0.40364742279052734,
      "learning_rate": 8.64448913026268e-06,
      "loss": 0.121,
      "step": 8561
    },
    {
      "epoch": 0.1355669205313742,
      "grad_norm": 0.2319086790084839,
      "learning_rate": 8.644330794686259e-06,
      "loss": 0.1019,
      "step": 8562
    },
    {
      "epoch": 0.13558275408901627,
      "grad_norm": 0.6082508563995361,
      "learning_rate": 8.64417245910984e-06,
      "loss": 0.0667,
      "step": 8563
    },
    {
      "epoch": 0.13559858764665833,
      "grad_norm": 0.13507047295570374,
      "learning_rate": 8.644014123533417e-06,
      "loss": 0.0374,
      "step": 8564
    },
    {
      "epoch": 0.1356144212043004,
      "grad_norm": 0.5703637003898621,
      "learning_rate": 8.643855787956997e-06,
      "loss": 0.0801,
      "step": 8565
    },
    {
      "epoch": 0.13563025476194246,
      "grad_norm": 0.024529991671442986,
      "learning_rate": 8.643697452380577e-06,
      "loss": 0.0018,
      "step": 8566
    },
    {
      "epoch": 0.13564608831958452,
      "grad_norm": 0.599640965461731,
      "learning_rate": 8.643539116804156e-06,
      "loss": 0.7553,
      "step": 8567
    },
    {
      "epoch": 0.1356619218772266,
      "grad_norm": 0.0518852174282074,
      "learning_rate": 8.643380781227735e-06,
      "loss": 0.0009,
      "step": 8568
    },
    {
      "epoch": 0.13567775543486865,
      "grad_norm": 0.3795678913593292,
      "learning_rate": 8.643222445651314e-06,
      "loss": 0.128,
      "step": 8569
    },
    {
      "epoch": 0.13569358899251072,
      "grad_norm": 0.4934593141078949,
      "learning_rate": 8.643064110074893e-06,
      "loss": 0.739,
      "step": 8570
    },
    {
      "epoch": 0.13570942255015278,
      "grad_norm": 0.3141469657421112,
      "learning_rate": 8.642905774498472e-06,
      "loss": 0.119,
      "step": 8571
    },
    {
      "epoch": 0.13572525610779487,
      "grad_norm": 0.24123579263687134,
      "learning_rate": 8.642747438922053e-06,
      "loss": 0.0637,
      "step": 8572
    },
    {
      "epoch": 0.13574108966543694,
      "grad_norm": 0.3417268991470337,
      "learning_rate": 8.642589103345632e-06,
      "loss": 0.1139,
      "step": 8573
    },
    {
      "epoch": 0.135756923223079,
      "grad_norm": 0.27214786410331726,
      "learning_rate": 8.642430767769211e-06,
      "loss": 0.172,
      "step": 8574
    },
    {
      "epoch": 0.13577275678072107,
      "grad_norm": 0.003390665864571929,
      "learning_rate": 8.64227243219279e-06,
      "loss": 0.0001,
      "step": 8575
    },
    {
      "epoch": 0.13578859033836313,
      "grad_norm": 0.26987066864967346,
      "learning_rate": 8.642114096616369e-06,
      "loss": 0.1276,
      "step": 8576
    },
    {
      "epoch": 0.1358044238960052,
      "grad_norm": 0.37288838624954224,
      "learning_rate": 8.641955761039948e-06,
      "loss": 0.1483,
      "step": 8577
    },
    {
      "epoch": 0.13582025745364726,
      "grad_norm": 0.5325227379798889,
      "learning_rate": 8.641797425463529e-06,
      "loss": 0.2912,
      "step": 8578
    },
    {
      "epoch": 0.13583609101128932,
      "grad_norm": 0.11332806199789047,
      "learning_rate": 8.641639089887108e-06,
      "loss": 0.0395,
      "step": 8579
    },
    {
      "epoch": 0.1358519245689314,
      "grad_norm": 0.2357998788356781,
      "learning_rate": 8.641480754310687e-06,
      "loss": 0.1248,
      "step": 8580
    },
    {
      "epoch": 0.13586775812657345,
      "grad_norm": 1.7228896617889404,
      "learning_rate": 8.641322418734266e-06,
      "loss": 0.6487,
      "step": 8581
    },
    {
      "epoch": 0.13588359168421552,
      "grad_norm": 1.0392117500305176,
      "learning_rate": 8.641164083157845e-06,
      "loss": 0.5891,
      "step": 8582
    },
    {
      "epoch": 0.13589942524185758,
      "grad_norm": 0.0001831991976359859,
      "learning_rate": 8.641005747581424e-06,
      "loss": 0.0,
      "step": 8583
    },
    {
      "epoch": 0.13591525879949967,
      "grad_norm": 0.42035236954689026,
      "learning_rate": 8.640847412005005e-06,
      "loss": 0.4272,
      "step": 8584
    },
    {
      "epoch": 0.13593109235714174,
      "grad_norm": 0.18162688612937927,
      "learning_rate": 8.640689076428584e-06,
      "loss": 0.0165,
      "step": 8585
    },
    {
      "epoch": 0.1359469259147838,
      "grad_norm": 0.024545656517148018,
      "learning_rate": 8.640530740852163e-06,
      "loss": 0.0015,
      "step": 8586
    },
    {
      "epoch": 0.13596275947242586,
      "grad_norm": 1.5188926458358765,
      "learning_rate": 8.640372405275742e-06,
      "loss": 0.2494,
      "step": 8587
    },
    {
      "epoch": 0.13597859303006793,
      "grad_norm": 0.2938869297504425,
      "learning_rate": 8.640214069699321e-06,
      "loss": 0.1329,
      "step": 8588
    },
    {
      "epoch": 0.13599442658771,
      "grad_norm": 1.227275013923645,
      "learning_rate": 8.6400557341229e-06,
      "loss": 0.2059,
      "step": 8589
    },
    {
      "epoch": 0.13601026014535206,
      "grad_norm": 0.010976018384099007,
      "learning_rate": 8.63989739854648e-06,
      "loss": 0.0006,
      "step": 8590
    },
    {
      "epoch": 0.13602609370299412,
      "grad_norm": 0.0008553987718187273,
      "learning_rate": 8.63973906297006e-06,
      "loss": 0.0,
      "step": 8591
    },
    {
      "epoch": 0.1360419272606362,
      "grad_norm": 0.29276517033576965,
      "learning_rate": 8.639580727393638e-06,
      "loss": 0.0697,
      "step": 8592
    },
    {
      "epoch": 0.13605776081827825,
      "grad_norm": 0.011802825145423412,
      "learning_rate": 8.639422391817218e-06,
      "loss": 0.0003,
      "step": 8593
    },
    {
      "epoch": 0.13607359437592031,
      "grad_norm": 0.37253233790397644,
      "learning_rate": 8.639264056240798e-06,
      "loss": 0.1223,
      "step": 8594
    },
    {
      "epoch": 0.13608942793356238,
      "grad_norm": 0.22157400846481323,
      "learning_rate": 8.639105720664377e-06,
      "loss": 0.0861,
      "step": 8595
    },
    {
      "epoch": 0.13610526149120447,
      "grad_norm": 0.208885058760643,
      "learning_rate": 8.638947385087956e-06,
      "loss": 0.0615,
      "step": 8596
    },
    {
      "epoch": 0.13612109504884654,
      "grad_norm": 0.14158226549625397,
      "learning_rate": 8.638789049511535e-06,
      "loss": 0.0216,
      "step": 8597
    },
    {
      "epoch": 0.1361369286064886,
      "grad_norm": 0.23462529480457306,
      "learning_rate": 8.638630713935114e-06,
      "loss": 0.0367,
      "step": 8598
    },
    {
      "epoch": 0.13615276216413066,
      "grad_norm": 0.22122682631015778,
      "learning_rate": 8.638472378358695e-06,
      "loss": 0.1329,
      "step": 8599
    },
    {
      "epoch": 0.13616859572177273,
      "grad_norm": 0.18738499283790588,
      "learning_rate": 8.638314042782274e-06,
      "loss": 0.0379,
      "step": 8600
    },
    {
      "epoch": 0.1361844292794148,
      "grad_norm": 0.5963304042816162,
      "learning_rate": 8.638155707205853e-06,
      "loss": 0.5851,
      "step": 8601
    },
    {
      "epoch": 0.13620026283705686,
      "grad_norm": 0.460359662771225,
      "learning_rate": 8.637997371629432e-06,
      "loss": 0.1411,
      "step": 8602
    },
    {
      "epoch": 0.13621609639469892,
      "grad_norm": 0.5056143999099731,
      "learning_rate": 8.637839036053011e-06,
      "loss": 0.2975,
      "step": 8603
    },
    {
      "epoch": 0.13623192995234099,
      "grad_norm": 0.17063607275485992,
      "learning_rate": 8.63768070047659e-06,
      "loss": 0.0572,
      "step": 8604
    },
    {
      "epoch": 0.13624776350998305,
      "grad_norm": 0.0002052785421255976,
      "learning_rate": 8.63752236490017e-06,
      "loss": 0.0,
      "step": 8605
    },
    {
      "epoch": 0.13626359706762511,
      "grad_norm": 1.814904808998108,
      "learning_rate": 8.63736402932375e-06,
      "loss": 0.3617,
      "step": 8606
    },
    {
      "epoch": 0.13627943062526718,
      "grad_norm": 0.09361723810434341,
      "learning_rate": 8.637205693747329e-06,
      "loss": 0.0261,
      "step": 8607
    },
    {
      "epoch": 0.13629526418290927,
      "grad_norm": 0.47745281457901,
      "learning_rate": 8.637047358170908e-06,
      "loss": 0.1692,
      "step": 8608
    },
    {
      "epoch": 0.13631109774055133,
      "grad_norm": 0.05411485955119133,
      "learning_rate": 8.636889022594487e-06,
      "loss": 0.0104,
      "step": 8609
    },
    {
      "epoch": 0.1363269312981934,
      "grad_norm": 0.17987461388111115,
      "learning_rate": 8.636730687018066e-06,
      "loss": 0.071,
      "step": 8610
    },
    {
      "epoch": 0.13634276485583546,
      "grad_norm": 0.31056156754493713,
      "learning_rate": 8.636572351441647e-06,
      "loss": 0.0418,
      "step": 8611
    },
    {
      "epoch": 0.13635859841347753,
      "grad_norm": 0.008798176422715187,
      "learning_rate": 8.636414015865226e-06,
      "loss": 0.0006,
      "step": 8612
    },
    {
      "epoch": 0.1363744319711196,
      "grad_norm": 0.6828254461288452,
      "learning_rate": 8.636255680288805e-06,
      "loss": 0.0808,
      "step": 8613
    },
    {
      "epoch": 0.13639026552876166,
      "grad_norm": 0.1597651243209839,
      "learning_rate": 8.636097344712384e-06,
      "loss": 0.0829,
      "step": 8614
    },
    {
      "epoch": 0.13640609908640372,
      "grad_norm": 0.39510995149612427,
      "learning_rate": 8.635939009135963e-06,
      "loss": 0.0735,
      "step": 8615
    },
    {
      "epoch": 0.13642193264404578,
      "grad_norm": 0.009816857054829597,
      "learning_rate": 8.635780673559542e-06,
      "loss": 0.0004,
      "step": 8616
    },
    {
      "epoch": 0.13643776620168785,
      "grad_norm": 0.3995703458786011,
      "learning_rate": 8.635622337983121e-06,
      "loss": 0.5927,
      "step": 8617
    },
    {
      "epoch": 0.1364535997593299,
      "grad_norm": 0.10913755744695663,
      "learning_rate": 8.635464002406702e-06,
      "loss": 0.0031,
      "step": 8618
    },
    {
      "epoch": 0.13646943331697198,
      "grad_norm": 0.545768141746521,
      "learning_rate": 8.63530566683028e-06,
      "loss": 0.4047,
      "step": 8619
    },
    {
      "epoch": 0.13648526687461407,
      "grad_norm": 0.1644592434167862,
      "learning_rate": 8.63514733125386e-06,
      "loss": 0.0637,
      "step": 8620
    },
    {
      "epoch": 0.13650110043225613,
      "grad_norm": 0.39023470878601074,
      "learning_rate": 8.63498899567744e-06,
      "loss": 0.5239,
      "step": 8621
    },
    {
      "epoch": 0.1365169339898982,
      "grad_norm": 0.3085736930370331,
      "learning_rate": 8.634830660101019e-06,
      "loss": 0.4589,
      "step": 8622
    },
    {
      "epoch": 0.13653276754754026,
      "grad_norm": 0.24036060273647308,
      "learning_rate": 8.634672324524598e-06,
      "loss": 0.118,
      "step": 8623
    },
    {
      "epoch": 0.13654860110518233,
      "grad_norm": 0.2959577441215515,
      "learning_rate": 8.634513988948178e-06,
      "loss": 0.0753,
      "step": 8624
    },
    {
      "epoch": 0.1365644346628244,
      "grad_norm": 0.00021779767121188343,
      "learning_rate": 8.634355653371756e-06,
      "loss": 0.0,
      "step": 8625
    },
    {
      "epoch": 0.13658026822046646,
      "grad_norm": 0.1380268931388855,
      "learning_rate": 8.634197317795337e-06,
      "loss": 0.0281,
      "step": 8626
    },
    {
      "epoch": 0.13659610177810852,
      "grad_norm": 0.000536867999471724,
      "learning_rate": 8.634038982218916e-06,
      "loss": 0.0,
      "step": 8627
    },
    {
      "epoch": 0.13661193533575058,
      "grad_norm": 0.8891377449035645,
      "learning_rate": 8.633880646642495e-06,
      "loss": 0.1091,
      "step": 8628
    },
    {
      "epoch": 0.13662776889339265,
      "grad_norm": 0.3344951868057251,
      "learning_rate": 8.633722311066074e-06,
      "loss": 0.187,
      "step": 8629
    },
    {
      "epoch": 0.1366436024510347,
      "grad_norm": 0.042269282042980194,
      "learning_rate": 8.633563975489655e-06,
      "loss": 0.0036,
      "step": 8630
    },
    {
      "epoch": 0.13665943600867678,
      "grad_norm": 0.3042638599872589,
      "learning_rate": 8.633405639913232e-06,
      "loss": 0.0952,
      "step": 8631
    },
    {
      "epoch": 0.13667526956631887,
      "grad_norm": 0.5695451498031616,
      "learning_rate": 8.633247304336813e-06,
      "loss": 0.386,
      "step": 8632
    },
    {
      "epoch": 0.13669110312396093,
      "grad_norm": 0.3923526406288147,
      "learning_rate": 8.633088968760392e-06,
      "loss": 0.1393,
      "step": 8633
    },
    {
      "epoch": 0.136706936681603,
      "grad_norm": 0.03174334019422531,
      "learning_rate": 8.632930633183971e-06,
      "loss": 0.0012,
      "step": 8634
    },
    {
      "epoch": 0.13672277023924506,
      "grad_norm": 0.33915579319000244,
      "learning_rate": 8.63277229760755e-06,
      "loss": 0.2797,
      "step": 8635
    },
    {
      "epoch": 0.13673860379688713,
      "grad_norm": 0.2216511070728302,
      "learning_rate": 8.63261396203113e-06,
      "loss": 0.0456,
      "step": 8636
    },
    {
      "epoch": 0.1367544373545292,
      "grad_norm": 0.01316782832145691,
      "learning_rate": 8.632455626454708e-06,
      "loss": 0.0009,
      "step": 8637
    },
    {
      "epoch": 0.13677027091217125,
      "grad_norm": 0.31518590450286865,
      "learning_rate": 8.632297290878287e-06,
      "loss": 0.1687,
      "step": 8638
    },
    {
      "epoch": 0.13678610446981332,
      "grad_norm": 0.509845495223999,
      "learning_rate": 8.632138955301868e-06,
      "loss": 0.1574,
      "step": 8639
    },
    {
      "epoch": 0.13680193802745538,
      "grad_norm": 0.016254572197794914,
      "learning_rate": 8.631980619725447e-06,
      "loss": 0.001,
      "step": 8640
    },
    {
      "epoch": 0.13681777158509745,
      "grad_norm": 0.010228813625872135,
      "learning_rate": 8.631822284149026e-06,
      "loss": 0.0006,
      "step": 8641
    },
    {
      "epoch": 0.1368336051427395,
      "grad_norm": 0.6347423195838928,
      "learning_rate": 8.631663948572605e-06,
      "loss": 0.2985,
      "step": 8642
    },
    {
      "epoch": 0.13684943870038158,
      "grad_norm": 0.1411145031452179,
      "learning_rate": 8.631505612996184e-06,
      "loss": 0.0072,
      "step": 8643
    },
    {
      "epoch": 0.13686527225802367,
      "grad_norm": 0.1568709909915924,
      "learning_rate": 8.631347277419763e-06,
      "loss": 0.075,
      "step": 8644
    },
    {
      "epoch": 0.13688110581566573,
      "grad_norm": 0.23105652630329132,
      "learning_rate": 8.631188941843344e-06,
      "loss": 0.0783,
      "step": 8645
    },
    {
      "epoch": 0.1368969393733078,
      "grad_norm": 0.030112892389297485,
      "learning_rate": 8.631030606266923e-06,
      "loss": 0.0018,
      "step": 8646
    },
    {
      "epoch": 0.13691277293094986,
      "grad_norm": 0.5533607006072998,
      "learning_rate": 8.630872270690502e-06,
      "loss": 0.1689,
      "step": 8647
    },
    {
      "epoch": 0.13692860648859193,
      "grad_norm": 0.01711033657193184,
      "learning_rate": 8.630713935114081e-06,
      "loss": 0.0009,
      "step": 8648
    },
    {
      "epoch": 0.136944440046234,
      "grad_norm": 0.4919010102748871,
      "learning_rate": 8.63055559953766e-06,
      "loss": 0.6494,
      "step": 8649
    },
    {
      "epoch": 0.13696027360387605,
      "grad_norm": 0.27407321333885193,
      "learning_rate": 8.63039726396124e-06,
      "loss": 0.0711,
      "step": 8650
    },
    {
      "epoch": 0.13697610716151812,
      "grad_norm": 0.47276997566223145,
      "learning_rate": 8.63023892838482e-06,
      "loss": 0.3545,
      "step": 8651
    },
    {
      "epoch": 0.13699194071916018,
      "grad_norm": 0.00029752322006970644,
      "learning_rate": 8.6300805928084e-06,
      "loss": 0.0,
      "step": 8652
    },
    {
      "epoch": 0.13700777427680225,
      "grad_norm": 0.2987159490585327,
      "learning_rate": 8.629922257231979e-06,
      "loss": 0.0595,
      "step": 8653
    },
    {
      "epoch": 0.1370236078344443,
      "grad_norm": 0.09019706398248672,
      "learning_rate": 8.629763921655558e-06,
      "loss": 0.01,
      "step": 8654
    },
    {
      "epoch": 0.13703944139208638,
      "grad_norm": 0.3067123293876648,
      "learning_rate": 8.629605586079137e-06,
      "loss": 0.1253,
      "step": 8655
    },
    {
      "epoch": 0.13705527494972847,
      "grad_norm": 0.53310626745224,
      "learning_rate": 8.629447250502716e-06,
      "loss": 0.5472,
      "step": 8656
    },
    {
      "epoch": 0.13707110850737053,
      "grad_norm": 0.8669619560241699,
      "learning_rate": 8.629288914926297e-06,
      "loss": 0.2454,
      "step": 8657
    },
    {
      "epoch": 0.1370869420650126,
      "grad_norm": 0.00025963186635635793,
      "learning_rate": 8.629130579349874e-06,
      "loss": 0.0,
      "step": 8658
    },
    {
      "epoch": 0.13710277562265466,
      "grad_norm": 0.18237103521823883,
      "learning_rate": 8.628972243773455e-06,
      "loss": 0.0457,
      "step": 8659
    },
    {
      "epoch": 0.13711860918029672,
      "grad_norm": 0.45787227153778076,
      "learning_rate": 8.628813908197034e-06,
      "loss": 0.219,
      "step": 8660
    },
    {
      "epoch": 0.1371344427379388,
      "grad_norm": 0.5125414729118347,
      "learning_rate": 8.628655572620613e-06,
      "loss": 0.105,
      "step": 8661
    },
    {
      "epoch": 0.13715027629558085,
      "grad_norm": 1.7739611864089966,
      "learning_rate": 8.628497237044192e-06,
      "loss": 0.0201,
      "step": 8662
    },
    {
      "epoch": 0.13716610985322292,
      "grad_norm": 0.5702723264694214,
      "learning_rate": 8.628338901467771e-06,
      "loss": 0.5201,
      "step": 8663
    },
    {
      "epoch": 0.13718194341086498,
      "grad_norm": 0.29441359639167786,
      "learning_rate": 8.62818056589135e-06,
      "loss": 0.1191,
      "step": 8664
    },
    {
      "epoch": 0.13719777696850705,
      "grad_norm": 0.30990052223205566,
      "learning_rate": 8.62802223031493e-06,
      "loss": 0.2215,
      "step": 8665
    },
    {
      "epoch": 0.1372136105261491,
      "grad_norm": 0.014705387875437737,
      "learning_rate": 8.62786389473851e-06,
      "loss": 0.0007,
      "step": 8666
    },
    {
      "epoch": 0.13722944408379117,
      "grad_norm": 0.179090678691864,
      "learning_rate": 8.627705559162089e-06,
      "loss": 0.0808,
      "step": 8667
    },
    {
      "epoch": 0.13724527764143327,
      "grad_norm": 0.38554292917251587,
      "learning_rate": 8.627547223585668e-06,
      "loss": 0.5951,
      "step": 8668
    },
    {
      "epoch": 0.13726111119907533,
      "grad_norm": 0.4714651107788086,
      "learning_rate": 8.627388888009247e-06,
      "loss": 0.0969,
      "step": 8669
    },
    {
      "epoch": 0.1372769447567174,
      "grad_norm": 0.24049979448318481,
      "learning_rate": 8.627230552432826e-06,
      "loss": 0.0599,
      "step": 8670
    },
    {
      "epoch": 0.13729277831435946,
      "grad_norm": 0.3562980890274048,
      "learning_rate": 8.627072216856405e-06,
      "loss": 0.0605,
      "step": 8671
    },
    {
      "epoch": 0.13730861187200152,
      "grad_norm": 0.2125360369682312,
      "learning_rate": 8.626913881279986e-06,
      "loss": 0.1429,
      "step": 8672
    },
    {
      "epoch": 0.1373244454296436,
      "grad_norm": 0.00019445622456260026,
      "learning_rate": 8.626755545703565e-06,
      "loss": 0.0,
      "step": 8673
    },
    {
      "epoch": 0.13734027898728565,
      "grad_norm": 0.00011320496560074389,
      "learning_rate": 8.626597210127144e-06,
      "loss": 0.0,
      "step": 8674
    },
    {
      "epoch": 0.13735611254492772,
      "grad_norm": 0.2520928382873535,
      "learning_rate": 8.626438874550723e-06,
      "loss": 0.142,
      "step": 8675
    },
    {
      "epoch": 0.13737194610256978,
      "grad_norm": 0.32339155673980713,
      "learning_rate": 8.626280538974302e-06,
      "loss": 0.2542,
      "step": 8676
    },
    {
      "epoch": 0.13738777966021185,
      "grad_norm": 0.2348894625902176,
      "learning_rate": 8.626122203397882e-06,
      "loss": 0.0623,
      "step": 8677
    },
    {
      "epoch": 0.1374036132178539,
      "grad_norm": 0.7297148704528809,
      "learning_rate": 8.625963867821462e-06,
      "loss": 0.4287,
      "step": 8678
    },
    {
      "epoch": 0.13741944677549597,
      "grad_norm": 0.021735331043601036,
      "learning_rate": 8.625805532245041e-06,
      "loss": 0.0013,
      "step": 8679
    },
    {
      "epoch": 0.13743528033313807,
      "grad_norm": 0.24279026687145233,
      "learning_rate": 8.62564719666862e-06,
      "loss": 0.1232,
      "step": 8680
    },
    {
      "epoch": 0.13745111389078013,
      "grad_norm": 0.1644848734140396,
      "learning_rate": 8.6254888610922e-06,
      "loss": 0.0277,
      "step": 8681
    },
    {
      "epoch": 0.1374669474484222,
      "grad_norm": 0.5717608332633972,
      "learning_rate": 8.625330525515779e-06,
      "loss": 0.2597,
      "step": 8682
    },
    {
      "epoch": 0.13748278100606426,
      "grad_norm": 0.7770843505859375,
      "learning_rate": 8.625172189939358e-06,
      "loss": 0.2045,
      "step": 8683
    },
    {
      "epoch": 0.13749861456370632,
      "grad_norm": 0.474761962890625,
      "learning_rate": 8.625013854362938e-06,
      "loss": 0.194,
      "step": 8684
    },
    {
      "epoch": 0.1375144481213484,
      "grad_norm": 0.011217364110052586,
      "learning_rate": 8.624855518786518e-06,
      "loss": 0.0007,
      "step": 8685
    },
    {
      "epoch": 0.13753028167899045,
      "grad_norm": 0.15449897944927216,
      "learning_rate": 8.624697183210095e-06,
      "loss": 0.0086,
      "step": 8686
    },
    {
      "epoch": 0.13754611523663252,
      "grad_norm": 0.14574407041072845,
      "learning_rate": 8.624538847633676e-06,
      "loss": 0.0376,
      "step": 8687
    },
    {
      "epoch": 0.13756194879427458,
      "grad_norm": 0.00018259913485962898,
      "learning_rate": 8.624380512057255e-06,
      "loss": 0.0,
      "step": 8688
    },
    {
      "epoch": 0.13757778235191664,
      "grad_norm": 0.00017440412193536758,
      "learning_rate": 8.624222176480834e-06,
      "loss": 0.0,
      "step": 8689
    },
    {
      "epoch": 0.1375936159095587,
      "grad_norm": 1.8677171468734741,
      "learning_rate": 8.624063840904413e-06,
      "loss": 0.5501,
      "step": 8690
    },
    {
      "epoch": 0.13760944946720077,
      "grad_norm": 0.3098827004432678,
      "learning_rate": 8.623905505327994e-06,
      "loss": 0.0772,
      "step": 8691
    },
    {
      "epoch": 0.13762528302484286,
      "grad_norm": 0.00044406286906450987,
      "learning_rate": 8.623747169751571e-06,
      "loss": 0.0,
      "step": 8692
    },
    {
      "epoch": 0.13764111658248493,
      "grad_norm": 0.3093807101249695,
      "learning_rate": 8.623588834175152e-06,
      "loss": 0.1095,
      "step": 8693
    },
    {
      "epoch": 0.137656950140127,
      "grad_norm": 0.30976179242134094,
      "learning_rate": 8.623430498598731e-06,
      "loss": 0.2092,
      "step": 8694
    },
    {
      "epoch": 0.13767278369776906,
      "grad_norm": 0.35502588748931885,
      "learning_rate": 8.62327216302231e-06,
      "loss": 0.2321,
      "step": 8695
    },
    {
      "epoch": 0.13768861725541112,
      "grad_norm": 0.01624998450279236,
      "learning_rate": 8.623113827445889e-06,
      "loss": 0.0007,
      "step": 8696
    },
    {
      "epoch": 0.1377044508130532,
      "grad_norm": 0.34951505064964294,
      "learning_rate": 8.62295549186947e-06,
      "loss": 0.2314,
      "step": 8697
    },
    {
      "epoch": 0.13772028437069525,
      "grad_norm": 0.2661706805229187,
      "learning_rate": 8.622797156293047e-06,
      "loss": 0.1142,
      "step": 8698
    },
    {
      "epoch": 0.13773611792833731,
      "grad_norm": 0.004835218656808138,
      "learning_rate": 8.622638820716628e-06,
      "loss": 0.0002,
      "step": 8699
    },
    {
      "epoch": 0.13775195148597938,
      "grad_norm": 0.015860967338085175,
      "learning_rate": 8.622480485140207e-06,
      "loss": 0.0008,
      "step": 8700
    },
    {
      "epoch": 0.13776778504362144,
      "grad_norm": 0.007326868362724781,
      "learning_rate": 8.622322149563786e-06,
      "loss": 0.0004,
      "step": 8701
    },
    {
      "epoch": 0.1377836186012635,
      "grad_norm": 0.04625860974192619,
      "learning_rate": 8.622163813987365e-06,
      "loss": 0.0024,
      "step": 8702
    },
    {
      "epoch": 0.13779945215890557,
      "grad_norm": 0.0006211731233634055,
      "learning_rate": 8.622005478410946e-06,
      "loss": 0.0,
      "step": 8703
    },
    {
      "epoch": 0.13781528571654766,
      "grad_norm": 0.35369718074798584,
      "learning_rate": 8.621847142834523e-06,
      "loss": 0.2196,
      "step": 8704
    },
    {
      "epoch": 0.13783111927418973,
      "grad_norm": 0.1710488647222519,
      "learning_rate": 8.621688807258104e-06,
      "loss": 0.1579,
      "step": 8705
    },
    {
      "epoch": 0.1378469528318318,
      "grad_norm": 0.23590543866157532,
      "learning_rate": 8.621530471681683e-06,
      "loss": 0.0904,
      "step": 8706
    },
    {
      "epoch": 0.13786278638947386,
      "grad_norm": 0.27247947454452515,
      "learning_rate": 8.621372136105262e-06,
      "loss": 0.0757,
      "step": 8707
    },
    {
      "epoch": 0.13787861994711592,
      "grad_norm": 0.4581224322319031,
      "learning_rate": 8.621213800528841e-06,
      "loss": 0.2763,
      "step": 8708
    },
    {
      "epoch": 0.13789445350475799,
      "grad_norm": 0.030878541991114616,
      "learning_rate": 8.621055464952422e-06,
      "loss": 0.0017,
      "step": 8709
    },
    {
      "epoch": 0.13791028706240005,
      "grad_norm": 0.6007600426673889,
      "learning_rate": 8.620897129376e-06,
      "loss": 0.3327,
      "step": 8710
    },
    {
      "epoch": 0.13792612062004211,
      "grad_norm": 0.20837995409965515,
      "learning_rate": 8.620738793799579e-06,
      "loss": 0.0896,
      "step": 8711
    },
    {
      "epoch": 0.13794195417768418,
      "grad_norm": 0.9034695625305176,
      "learning_rate": 8.62058045822316e-06,
      "loss": 0.4135,
      "step": 8712
    },
    {
      "epoch": 0.13795778773532624,
      "grad_norm": 0.2982417047023773,
      "learning_rate": 8.620422122646739e-06,
      "loss": 0.1912,
      "step": 8713
    },
    {
      "epoch": 0.1379736212929683,
      "grad_norm": 0.0014601506991311908,
      "learning_rate": 8.620263787070318e-06,
      "loss": 0.0,
      "step": 8714
    },
    {
      "epoch": 0.13798945485061037,
      "grad_norm": 0.42931827902793884,
      "learning_rate": 8.620105451493897e-06,
      "loss": 0.0291,
      "step": 8715
    },
    {
      "epoch": 0.13800528840825246,
      "grad_norm": 0.4637133777141571,
      "learning_rate": 8.619947115917476e-06,
      "loss": 0.417,
      "step": 8716
    },
    {
      "epoch": 0.13802112196589453,
      "grad_norm": 0.15865325927734375,
      "learning_rate": 8.619788780341055e-06,
      "loss": 0.0133,
      "step": 8717
    },
    {
      "epoch": 0.1380369555235366,
      "grad_norm": 0.00026882035308517516,
      "learning_rate": 8.619630444764636e-06,
      "loss": 0.0,
      "step": 8718
    },
    {
      "epoch": 0.13805278908117866,
      "grad_norm": 0.08906380087137222,
      "learning_rate": 8.619472109188215e-06,
      "loss": 0.0163,
      "step": 8719
    },
    {
      "epoch": 0.13806862263882072,
      "grad_norm": 0.017072070389986038,
      "learning_rate": 8.619313773611794e-06,
      "loss": 0.0005,
      "step": 8720
    },
    {
      "epoch": 0.13808445619646278,
      "grad_norm": 0.17005594074726105,
      "learning_rate": 8.619155438035373e-06,
      "loss": 0.0577,
      "step": 8721
    },
    {
      "epoch": 0.13810028975410485,
      "grad_norm": 0.36165568232536316,
      "learning_rate": 8.618997102458952e-06,
      "loss": 0.3051,
      "step": 8722
    },
    {
      "epoch": 0.1381161233117469,
      "grad_norm": 0.035216446965932846,
      "learning_rate": 8.618838766882531e-06,
      "loss": 0.002,
      "step": 8723
    },
    {
      "epoch": 0.13813195686938898,
      "grad_norm": 0.4375019371509552,
      "learning_rate": 8.618680431306112e-06,
      "loss": 0.2162,
      "step": 8724
    },
    {
      "epoch": 0.13814779042703104,
      "grad_norm": 0.5981873869895935,
      "learning_rate": 8.61852209572969e-06,
      "loss": 0.0463,
      "step": 8725
    },
    {
      "epoch": 0.1381636239846731,
      "grad_norm": 0.2551928460597992,
      "learning_rate": 8.61836376015327e-06,
      "loss": 0.0914,
      "step": 8726
    },
    {
      "epoch": 0.13817945754231517,
      "grad_norm": 0.4900088608264923,
      "learning_rate": 8.618205424576849e-06,
      "loss": 0.3091,
      "step": 8727
    },
    {
      "epoch": 0.13819529109995726,
      "grad_norm": 0.18027614057064056,
      "learning_rate": 8.618047089000428e-06,
      "loss": 0.0101,
      "step": 8728
    },
    {
      "epoch": 0.13821112465759933,
      "grad_norm": 0.43178537487983704,
      "learning_rate": 8.617888753424007e-06,
      "loss": 0.4101,
      "step": 8729
    },
    {
      "epoch": 0.1382269582152414,
      "grad_norm": 0.038890812546014786,
      "learning_rate": 8.617730417847588e-06,
      "loss": 0.0022,
      "step": 8730
    },
    {
      "epoch": 0.13824279177288346,
      "grad_norm": 0.012239313684403896,
      "learning_rate": 8.617572082271165e-06,
      "loss": 0.0006,
      "step": 8731
    },
    {
      "epoch": 0.13825862533052552,
      "grad_norm": 0.28041568398475647,
      "learning_rate": 8.617413746694746e-06,
      "loss": 0.1048,
      "step": 8732
    },
    {
      "epoch": 0.13827445888816758,
      "grad_norm": 0.36231541633605957,
      "learning_rate": 8.617255411118325e-06,
      "loss": 0.0061,
      "step": 8733
    },
    {
      "epoch": 0.13829029244580965,
      "grad_norm": 7.840820762794465e-05,
      "learning_rate": 8.617097075541904e-06,
      "loss": 0.0,
      "step": 8734
    },
    {
      "epoch": 0.1383061260034517,
      "grad_norm": 0.17276854813098907,
      "learning_rate": 8.616938739965483e-06,
      "loss": 0.0588,
      "step": 8735
    },
    {
      "epoch": 0.13832195956109378,
      "grad_norm": 0.30403608083724976,
      "learning_rate": 8.616780404389062e-06,
      "loss": 0.0378,
      "step": 8736
    },
    {
      "epoch": 0.13833779311873584,
      "grad_norm": 0.00035979965468868613,
      "learning_rate": 8.616622068812642e-06,
      "loss": 0.0,
      "step": 8737
    },
    {
      "epoch": 0.1383536266763779,
      "grad_norm": 0.235409215092659,
      "learning_rate": 8.61646373323622e-06,
      "loss": 0.0877,
      "step": 8738
    },
    {
      "epoch": 0.13836946023401997,
      "grad_norm": 0.00034934081486426294,
      "learning_rate": 8.616305397659801e-06,
      "loss": 0.0,
      "step": 8739
    },
    {
      "epoch": 0.13838529379166206,
      "grad_norm": 0.015935778617858887,
      "learning_rate": 8.61614706208338e-06,
      "loss": 0.0006,
      "step": 8740
    },
    {
      "epoch": 0.13840112734930413,
      "grad_norm": 0.26518821716308594,
      "learning_rate": 8.61598872650696e-06,
      "loss": 0.0505,
      "step": 8741
    },
    {
      "epoch": 0.1384169609069462,
      "grad_norm": 0.24317848682403564,
      "learning_rate": 8.615830390930539e-06,
      "loss": 0.0889,
      "step": 8742
    },
    {
      "epoch": 0.13843279446458825,
      "grad_norm": 0.3496777415275574,
      "learning_rate": 8.615672055354118e-06,
      "loss": 0.1253,
      "step": 8743
    },
    {
      "epoch": 0.13844862802223032,
      "grad_norm": 0.3649355173110962,
      "learning_rate": 8.615513719777697e-06,
      "loss": 0.1873,
      "step": 8744
    },
    {
      "epoch": 0.13846446157987238,
      "grad_norm": 0.20091669261455536,
      "learning_rate": 8.615355384201278e-06,
      "loss": 0.0528,
      "step": 8745
    },
    {
      "epoch": 0.13848029513751445,
      "grad_norm": 0.22723925113677979,
      "learning_rate": 8.615197048624857e-06,
      "loss": 0.0507,
      "step": 8746
    },
    {
      "epoch": 0.1384961286951565,
      "grad_norm": 0.8367419242858887,
      "learning_rate": 8.615038713048436e-06,
      "loss": 0.5083,
      "step": 8747
    },
    {
      "epoch": 0.13851196225279858,
      "grad_norm": 0.27229464054107666,
      "learning_rate": 8.614880377472015e-06,
      "loss": 0.0467,
      "step": 8748
    },
    {
      "epoch": 0.13852779581044064,
      "grad_norm": 0.37164872884750366,
      "learning_rate": 8.614722041895594e-06,
      "loss": 0.3585,
      "step": 8749
    },
    {
      "epoch": 0.1385436293680827,
      "grad_norm": 0.6228930950164795,
      "learning_rate": 8.614563706319173e-06,
      "loss": 0.676,
      "step": 8750
    },
    {
      "epoch": 0.13855946292572477,
      "grad_norm": 0.2564541697502136,
      "learning_rate": 8.614405370742754e-06,
      "loss": 0.0935,
      "step": 8751
    },
    {
      "epoch": 0.13857529648336686,
      "grad_norm": 0.1434788554906845,
      "learning_rate": 8.614247035166333e-06,
      "loss": 0.0052,
      "step": 8752
    },
    {
      "epoch": 0.13859113004100893,
      "grad_norm": 0.46649742126464844,
      "learning_rate": 8.614088699589912e-06,
      "loss": 0.2177,
      "step": 8753
    },
    {
      "epoch": 0.138606963598651,
      "grad_norm": 0.5480311512947083,
      "learning_rate": 8.613930364013491e-06,
      "loss": 0.21,
      "step": 8754
    },
    {
      "epoch": 0.13862279715629305,
      "grad_norm": 0.2176605761051178,
      "learning_rate": 8.61377202843707e-06,
      "loss": 0.061,
      "step": 8755
    },
    {
      "epoch": 0.13863863071393512,
      "grad_norm": 0.5400980114936829,
      "learning_rate": 8.613613692860649e-06,
      "loss": 0.5925,
      "step": 8756
    },
    {
      "epoch": 0.13865446427157718,
      "grad_norm": 0.8812183141708374,
      "learning_rate": 8.61345535728423e-06,
      "loss": 0.1809,
      "step": 8757
    },
    {
      "epoch": 0.13867029782921925,
      "grad_norm": 0.3318640887737274,
      "learning_rate": 8.613297021707809e-06,
      "loss": 0.4815,
      "step": 8758
    },
    {
      "epoch": 0.1386861313868613,
      "grad_norm": 0.5187178254127502,
      "learning_rate": 8.613138686131386e-06,
      "loss": 0.0724,
      "step": 8759
    },
    {
      "epoch": 0.13870196494450338,
      "grad_norm": 0.6830779910087585,
      "learning_rate": 8.612980350554967e-06,
      "loss": 0.0513,
      "step": 8760
    },
    {
      "epoch": 0.13871779850214544,
      "grad_norm": 0.017306948080658913,
      "learning_rate": 8.612822014978546e-06,
      "loss": 0.0008,
      "step": 8761
    },
    {
      "epoch": 0.1387336320597875,
      "grad_norm": 0.004225871060043573,
      "learning_rate": 8.612663679402125e-06,
      "loss": 0.0002,
      "step": 8762
    },
    {
      "epoch": 0.13874946561742957,
      "grad_norm": 0.40283888578414917,
      "learning_rate": 8.612505343825704e-06,
      "loss": 0.1344,
      "step": 8763
    },
    {
      "epoch": 0.13876529917507166,
      "grad_norm": 0.5899559855461121,
      "learning_rate": 8.612347008249285e-06,
      "loss": 0.7278,
      "step": 8764
    },
    {
      "epoch": 0.13878113273271372,
      "grad_norm": 0.0369250513613224,
      "learning_rate": 8.612188672672863e-06,
      "loss": 0.0032,
      "step": 8765
    },
    {
      "epoch": 0.1387969662903558,
      "grad_norm": 0.2684032618999481,
      "learning_rate": 8.612030337096443e-06,
      "loss": 0.1002,
      "step": 8766
    },
    {
      "epoch": 0.13881279984799785,
      "grad_norm": 0.5154104828834534,
      "learning_rate": 8.611872001520022e-06,
      "loss": 0.4491,
      "step": 8767
    },
    {
      "epoch": 0.13882863340563992,
      "grad_norm": 0.13048283755779266,
      "learning_rate": 8.611713665943601e-06,
      "loss": 0.0123,
      "step": 8768
    },
    {
      "epoch": 0.13884446696328198,
      "grad_norm": 0.39563876390457153,
      "learning_rate": 8.61155533036718e-06,
      "loss": 0.1661,
      "step": 8769
    },
    {
      "epoch": 0.13886030052092405,
      "grad_norm": 0.4019738435745239,
      "learning_rate": 8.611396994790761e-06,
      "loss": 0.1471,
      "step": 8770
    },
    {
      "epoch": 0.1388761340785661,
      "grad_norm": 0.08544126152992249,
      "learning_rate": 8.611238659214339e-06,
      "loss": 0.0295,
      "step": 8771
    },
    {
      "epoch": 0.13889196763620817,
      "grad_norm": 0.0055703530088067055,
      "learning_rate": 8.61108032363792e-06,
      "loss": 0.0002,
      "step": 8772
    },
    {
      "epoch": 0.13890780119385024,
      "grad_norm": 0.46982958912849426,
      "learning_rate": 8.610921988061499e-06,
      "loss": 0.1382,
      "step": 8773
    },
    {
      "epoch": 0.1389236347514923,
      "grad_norm": 0.04374348372220993,
      "learning_rate": 8.610763652485078e-06,
      "loss": 0.003,
      "step": 8774
    },
    {
      "epoch": 0.13893946830913437,
      "grad_norm": 0.19893082976341248,
      "learning_rate": 8.610605316908657e-06,
      "loss": 0.0886,
      "step": 8775
    },
    {
      "epoch": 0.13895530186677646,
      "grad_norm": 0.36202189326286316,
      "learning_rate": 8.610446981332237e-06,
      "loss": 0.1438,
      "step": 8776
    },
    {
      "epoch": 0.13897113542441852,
      "grad_norm": 0.5844693183898926,
      "learning_rate": 8.610288645755815e-06,
      "loss": 0.5286,
      "step": 8777
    },
    {
      "epoch": 0.1389869689820606,
      "grad_norm": 0.9439413547515869,
      "learning_rate": 8.610130310179396e-06,
      "loss": 0.3036,
      "step": 8778
    },
    {
      "epoch": 0.13900280253970265,
      "grad_norm": 0.5623286962509155,
      "learning_rate": 8.609971974602975e-06,
      "loss": 0.4422,
      "step": 8779
    },
    {
      "epoch": 0.13901863609734472,
      "grad_norm": 0.5689572691917419,
      "learning_rate": 8.609813639026554e-06,
      "loss": 0.2121,
      "step": 8780
    },
    {
      "epoch": 0.13903446965498678,
      "grad_norm": 0.32823294401168823,
      "learning_rate": 8.609655303450133e-06,
      "loss": 0.1048,
      "step": 8781
    },
    {
      "epoch": 0.13905030321262885,
      "grad_norm": 0.3708394169807434,
      "learning_rate": 8.609496967873712e-06,
      "loss": 0.0511,
      "step": 8782
    },
    {
      "epoch": 0.1390661367702709,
      "grad_norm": 0.03896556422114372,
      "learning_rate": 8.609338632297291e-06,
      "loss": 0.0055,
      "step": 8783
    },
    {
      "epoch": 0.13908197032791297,
      "grad_norm": 0.36657196283340454,
      "learning_rate": 8.60918029672087e-06,
      "loss": 0.0859,
      "step": 8784
    },
    {
      "epoch": 0.13909780388555504,
      "grad_norm": 0.3128112554550171,
      "learning_rate": 8.609021961144451e-06,
      "loss": 0.0578,
      "step": 8785
    },
    {
      "epoch": 0.1391136374431971,
      "grad_norm": 0.43630656599998474,
      "learning_rate": 8.60886362556803e-06,
      "loss": 0.1709,
      "step": 8786
    },
    {
      "epoch": 0.13912947100083917,
      "grad_norm": 0.019627006724476814,
      "learning_rate": 8.608705289991609e-06,
      "loss": 0.001,
      "step": 8787
    },
    {
      "epoch": 0.13914530455848126,
      "grad_norm": 0.43779534101486206,
      "learning_rate": 8.608546954415188e-06,
      "loss": 0.2811,
      "step": 8788
    },
    {
      "epoch": 0.13916113811612332,
      "grad_norm": 0.4529789686203003,
      "learning_rate": 8.608388618838767e-06,
      "loss": 0.3575,
      "step": 8789
    },
    {
      "epoch": 0.1391769716737654,
      "grad_norm": 0.007283409591764212,
      "learning_rate": 8.608230283262346e-06,
      "loss": 0.0003,
      "step": 8790
    },
    {
      "epoch": 0.13919280523140745,
      "grad_norm": 1.5502508878707886,
      "learning_rate": 8.608071947685927e-06,
      "loss": 0.1033,
      "step": 8791
    },
    {
      "epoch": 0.13920863878904952,
      "grad_norm": 0.1218913197517395,
      "learning_rate": 8.607913612109504e-06,
      "loss": 0.0446,
      "step": 8792
    },
    {
      "epoch": 0.13922447234669158,
      "grad_norm": 0.3092484772205353,
      "learning_rate": 8.607755276533085e-06,
      "loss": 0.1772,
      "step": 8793
    },
    {
      "epoch": 0.13924030590433364,
      "grad_norm": 0.17336741089820862,
      "learning_rate": 8.607596940956664e-06,
      "loss": 0.0585,
      "step": 8794
    },
    {
      "epoch": 0.1392561394619757,
      "grad_norm": 0.42861345410346985,
      "learning_rate": 8.607438605380243e-06,
      "loss": 0.1371,
      "step": 8795
    },
    {
      "epoch": 0.13927197301961777,
      "grad_norm": 0.5489407777786255,
      "learning_rate": 8.607280269803822e-06,
      "loss": 0.7671,
      "step": 8796
    },
    {
      "epoch": 0.13928780657725984,
      "grad_norm": 0.0005925446166656911,
      "learning_rate": 8.607121934227403e-06,
      "loss": 0.0,
      "step": 8797
    },
    {
      "epoch": 0.1393036401349019,
      "grad_norm": 0.44733738899230957,
      "learning_rate": 8.60696359865098e-06,
      "loss": 0.1327,
      "step": 8798
    },
    {
      "epoch": 0.13931947369254397,
      "grad_norm": 0.629722535610199,
      "learning_rate": 8.606805263074561e-06,
      "loss": 0.313,
      "step": 8799
    },
    {
      "epoch": 0.13933530725018606,
      "grad_norm": 0.008756672032177448,
      "learning_rate": 8.60664692749814e-06,
      "loss": 0.0005,
      "step": 8800
    },
    {
      "epoch": 0.13935114080782812,
      "grad_norm": 0.0008047302253544331,
      "learning_rate": 8.60648859192172e-06,
      "loss": 0.0,
      "step": 8801
    },
    {
      "epoch": 0.1393669743654702,
      "grad_norm": 0.3902841806411743,
      "learning_rate": 8.606330256345299e-06,
      "loss": 0.3247,
      "step": 8802
    },
    {
      "epoch": 0.13938280792311225,
      "grad_norm": 0.019165243953466415,
      "learning_rate": 8.60617192076888e-06,
      "loss": 0.0005,
      "step": 8803
    },
    {
      "epoch": 0.13939864148075432,
      "grad_norm": 0.45163631439208984,
      "learning_rate": 8.606013585192457e-06,
      "loss": 0.3179,
      "step": 8804
    },
    {
      "epoch": 0.13941447503839638,
      "grad_norm": 0.01965365558862686,
      "learning_rate": 8.605855249616038e-06,
      "loss": 0.0011,
      "step": 8805
    },
    {
      "epoch": 0.13943030859603844,
      "grad_norm": 0.25059670209884644,
      "learning_rate": 8.605696914039617e-06,
      "loss": 0.1066,
      "step": 8806
    },
    {
      "epoch": 0.1394461421536805,
      "grad_norm": 0.6834216713905334,
      "learning_rate": 8.605538578463196e-06,
      "loss": 0.9804,
      "step": 8807
    },
    {
      "epoch": 0.13946197571132257,
      "grad_norm": 0.019127678126096725,
      "learning_rate": 8.605380242886775e-06,
      "loss": 0.0015,
      "step": 8808
    },
    {
      "epoch": 0.13947780926896464,
      "grad_norm": 0.0813407450914383,
      "learning_rate": 8.605221907310354e-06,
      "loss": 0.0013,
      "step": 8809
    },
    {
      "epoch": 0.1394936428266067,
      "grad_norm": 0.4257424473762512,
      "learning_rate": 8.605063571733933e-06,
      "loss": 0.2831,
      "step": 8810
    },
    {
      "epoch": 0.13950947638424877,
      "grad_norm": 0.4843013882637024,
      "learning_rate": 8.604905236157512e-06,
      "loss": 0.6664,
      "step": 8811
    },
    {
      "epoch": 0.13952530994189086,
      "grad_norm": 0.4014061689376831,
      "learning_rate": 8.604746900581093e-06,
      "loss": 0.1556,
      "step": 8812
    },
    {
      "epoch": 0.13954114349953292,
      "grad_norm": 0.3190624713897705,
      "learning_rate": 8.604588565004672e-06,
      "loss": 0.1551,
      "step": 8813
    },
    {
      "epoch": 0.13955697705717499,
      "grad_norm": 0.25157925486564636,
      "learning_rate": 8.604430229428251e-06,
      "loss": 0.169,
      "step": 8814
    },
    {
      "epoch": 0.13957281061481705,
      "grad_norm": 0.022013399749994278,
      "learning_rate": 8.60427189385183e-06,
      "loss": 0.0013,
      "step": 8815
    },
    {
      "epoch": 0.13958864417245911,
      "grad_norm": 0.004897803999483585,
      "learning_rate": 8.604113558275409e-06,
      "loss": 0.0002,
      "step": 8816
    },
    {
      "epoch": 0.13960447773010118,
      "grad_norm": 0.3797513246536255,
      "learning_rate": 8.603955222698988e-06,
      "loss": 0.0915,
      "step": 8817
    },
    {
      "epoch": 0.13962031128774324,
      "grad_norm": 0.0032603468280285597,
      "learning_rate": 8.603796887122569e-06,
      "loss": 0.0002,
      "step": 8818
    },
    {
      "epoch": 0.1396361448453853,
      "grad_norm": 0.20704008638858795,
      "learning_rate": 8.603638551546148e-06,
      "loss": 0.0249,
      "step": 8819
    },
    {
      "epoch": 0.13965197840302737,
      "grad_norm": 0.07610630244016647,
      "learning_rate": 8.603480215969727e-06,
      "loss": 0.0033,
      "step": 8820
    },
    {
      "epoch": 0.13966781196066944,
      "grad_norm": 0.2868069112300873,
      "learning_rate": 8.603321880393306e-06,
      "loss": 0.2479,
      "step": 8821
    },
    {
      "epoch": 0.1396836455183115,
      "grad_norm": 0.14212539792060852,
      "learning_rate": 8.603163544816885e-06,
      "loss": 0.0031,
      "step": 8822
    },
    {
      "epoch": 0.13969947907595356,
      "grad_norm": 0.6524120569229126,
      "learning_rate": 8.603005209240464e-06,
      "loss": 0.1329,
      "step": 8823
    },
    {
      "epoch": 0.13971531263359566,
      "grad_norm": 0.3967336118221283,
      "learning_rate": 8.602846873664045e-06,
      "loss": 0.0773,
      "step": 8824
    },
    {
      "epoch": 0.13973114619123772,
      "grad_norm": 0.205335795879364,
      "learning_rate": 8.602688538087624e-06,
      "loss": 0.0697,
      "step": 8825
    },
    {
      "epoch": 0.13974697974887978,
      "grad_norm": 0.002584730042144656,
      "learning_rate": 8.602530202511203e-06,
      "loss": 0.0001,
      "step": 8826
    },
    {
      "epoch": 0.13976281330652185,
      "grad_norm": 0.14797092974185944,
      "learning_rate": 8.602371866934782e-06,
      "loss": 0.0551,
      "step": 8827
    },
    {
      "epoch": 0.1397786468641639,
      "grad_norm": 0.014909864403307438,
      "learning_rate": 8.602213531358361e-06,
      "loss": 0.0008,
      "step": 8828
    },
    {
      "epoch": 0.13979448042180598,
      "grad_norm": 0.007634492591023445,
      "learning_rate": 8.60205519578194e-06,
      "loss": 0.0004,
      "step": 8829
    },
    {
      "epoch": 0.13981031397944804,
      "grad_norm": 0.00021327545982785523,
      "learning_rate": 8.60189686020552e-06,
      "loss": 0.0,
      "step": 8830
    },
    {
      "epoch": 0.1398261475370901,
      "grad_norm": 0.5392312407493591,
      "learning_rate": 8.6017385246291e-06,
      "loss": 0.8206,
      "step": 8831
    },
    {
      "epoch": 0.13984198109473217,
      "grad_norm": 0.0002909528266172856,
      "learning_rate": 8.601580189052678e-06,
      "loss": 0.0,
      "step": 8832
    },
    {
      "epoch": 0.13985781465237423,
      "grad_norm": 0.12929195165634155,
      "learning_rate": 8.601421853476259e-06,
      "loss": 0.0029,
      "step": 8833
    },
    {
      "epoch": 0.1398736482100163,
      "grad_norm": 0.5368341207504272,
      "learning_rate": 8.601263517899838e-06,
      "loss": 0.1104,
      "step": 8834
    },
    {
      "epoch": 0.13988948176765836,
      "grad_norm": 0.4211227595806122,
      "learning_rate": 8.601105182323417e-06,
      "loss": 0.2251,
      "step": 8835
    },
    {
      "epoch": 0.13990531532530046,
      "grad_norm": 0.008943610824644566,
      "learning_rate": 8.600946846746996e-06,
      "loss": 0.0005,
      "step": 8836
    },
    {
      "epoch": 0.13992114888294252,
      "grad_norm": 0.2762909233570099,
      "learning_rate": 8.600788511170577e-06,
      "loss": 0.158,
      "step": 8837
    },
    {
      "epoch": 0.13993698244058458,
      "grad_norm": 0.17901740968227386,
      "learning_rate": 8.600630175594154e-06,
      "loss": 0.0364,
      "step": 8838
    },
    {
      "epoch": 0.13995281599822665,
      "grad_norm": 0.2331129014492035,
      "learning_rate": 8.600471840017735e-06,
      "loss": 0.1061,
      "step": 8839
    },
    {
      "epoch": 0.1399686495558687,
      "grad_norm": 0.010557626374065876,
      "learning_rate": 8.600313504441314e-06,
      "loss": 0.0006,
      "step": 8840
    },
    {
      "epoch": 0.13998448311351078,
      "grad_norm": 0.04058276116847992,
      "learning_rate": 8.600155168864893e-06,
      "loss": 0.0018,
      "step": 8841
    },
    {
      "epoch": 0.14000031667115284,
      "grad_norm": 0.31861019134521484,
      "learning_rate": 8.599996833288472e-06,
      "loss": 0.1248,
      "step": 8842
    },
    {
      "epoch": 0.1400161502287949,
      "grad_norm": 1.0043591260910034,
      "learning_rate": 8.599838497712053e-06,
      "loss": 0.1434,
      "step": 8843
    },
    {
      "epoch": 0.14003198378643697,
      "grad_norm": 0.137888103723526,
      "learning_rate": 8.59968016213563e-06,
      "loss": 0.0606,
      "step": 8844
    },
    {
      "epoch": 0.14004781734407903,
      "grad_norm": 0.013838118873536587,
      "learning_rate": 8.599521826559211e-06,
      "loss": 0.0008,
      "step": 8845
    },
    {
      "epoch": 0.1400636509017211,
      "grad_norm": 0.3083392083644867,
      "learning_rate": 8.59936349098279e-06,
      "loss": 0.1123,
      "step": 8846
    },
    {
      "epoch": 0.14007948445936316,
      "grad_norm": 1.1087363958358765,
      "learning_rate": 8.599205155406369e-06,
      "loss": 0.5014,
      "step": 8847
    },
    {
      "epoch": 0.14009531801700525,
      "grad_norm": 0.2927679419517517,
      "learning_rate": 8.599046819829948e-06,
      "loss": 0.1946,
      "step": 8848
    },
    {
      "epoch": 0.14011115157464732,
      "grad_norm": 0.28831055760383606,
      "learning_rate": 8.598888484253527e-06,
      "loss": 0.2768,
      "step": 8849
    },
    {
      "epoch": 0.14012698513228938,
      "grad_norm": 0.013122113421559334,
      "learning_rate": 8.598730148677106e-06,
      "loss": 0.0006,
      "step": 8850
    },
    {
      "epoch": 0.14014281868993145,
      "grad_norm": 0.11864005774259567,
      "learning_rate": 8.598571813100687e-06,
      "loss": 0.0434,
      "step": 8851
    },
    {
      "epoch": 0.1401586522475735,
      "grad_norm": 0.49263083934783936,
      "learning_rate": 8.598413477524266e-06,
      "loss": 0.2832,
      "step": 8852
    },
    {
      "epoch": 0.14017448580521558,
      "grad_norm": 0.3027053475379944,
      "learning_rate": 8.598255141947845e-06,
      "loss": 0.4127,
      "step": 8853
    },
    {
      "epoch": 0.14019031936285764,
      "grad_norm": 0.2513045370578766,
      "learning_rate": 8.598096806371424e-06,
      "loss": 0.0909,
      "step": 8854
    },
    {
      "epoch": 0.1402061529204997,
      "grad_norm": 0.40322956442832947,
      "learning_rate": 8.597938470795003e-06,
      "loss": 0.1435,
      "step": 8855
    },
    {
      "epoch": 0.14022198647814177,
      "grad_norm": 0.015394925139844418,
      "learning_rate": 8.597780135218582e-06,
      "loss": 0.0008,
      "step": 8856
    },
    {
      "epoch": 0.14023782003578383,
      "grad_norm": 0.44487088918685913,
      "learning_rate": 8.597621799642162e-06,
      "loss": 0.1653,
      "step": 8857
    },
    {
      "epoch": 0.1402536535934259,
      "grad_norm": 0.20886869728565216,
      "learning_rate": 8.597463464065742e-06,
      "loss": 0.068,
      "step": 8858
    },
    {
      "epoch": 0.14026948715106796,
      "grad_norm": 0.5017836093902588,
      "learning_rate": 8.59730512848932e-06,
      "loss": 0.0156,
      "step": 8859
    },
    {
      "epoch": 0.14028532070871003,
      "grad_norm": 0.013756189495325089,
      "learning_rate": 8.5971467929129e-06,
      "loss": 0.0005,
      "step": 8860
    },
    {
      "epoch": 0.14030115426635212,
      "grad_norm": 0.013511153869330883,
      "learning_rate": 8.59698845733648e-06,
      "loss": 0.0008,
      "step": 8861
    },
    {
      "epoch": 0.14031698782399418,
      "grad_norm": 0.4372520446777344,
      "learning_rate": 8.596830121760059e-06,
      "loss": 0.6045,
      "step": 8862
    },
    {
      "epoch": 0.14033282138163625,
      "grad_norm": 0.27309516072273254,
      "learning_rate": 8.596671786183638e-06,
      "loss": 0.0863,
      "step": 8863
    },
    {
      "epoch": 0.1403486549392783,
      "grad_norm": 0.7239201068878174,
      "learning_rate": 8.596513450607219e-06,
      "loss": 0.3875,
      "step": 8864
    },
    {
      "epoch": 0.14036448849692038,
      "grad_norm": 0.10163477063179016,
      "learning_rate": 8.596355115030796e-06,
      "loss": 0.0288,
      "step": 8865
    },
    {
      "epoch": 0.14038032205456244,
      "grad_norm": 0.19693472981452942,
      "learning_rate": 8.596196779454377e-06,
      "loss": 0.0488,
      "step": 8866
    },
    {
      "epoch": 0.1403961556122045,
      "grad_norm": 0.2844347059726715,
      "learning_rate": 8.596038443877956e-06,
      "loss": 0.1885,
      "step": 8867
    },
    {
      "epoch": 0.14041198916984657,
      "grad_norm": 0.13633809983730316,
      "learning_rate": 8.595880108301535e-06,
      "loss": 0.0044,
      "step": 8868
    },
    {
      "epoch": 0.14042782272748863,
      "grad_norm": 0.23543870449066162,
      "learning_rate": 8.595721772725114e-06,
      "loss": 0.2108,
      "step": 8869
    },
    {
      "epoch": 0.1404436562851307,
      "grad_norm": 0.2555110454559326,
      "learning_rate": 8.595563437148695e-06,
      "loss": 0.0531,
      "step": 8870
    },
    {
      "epoch": 0.14045948984277276,
      "grad_norm": 0.015227193012833595,
      "learning_rate": 8.595405101572272e-06,
      "loss": 0.0009,
      "step": 8871
    },
    {
      "epoch": 0.14047532340041483,
      "grad_norm": 0.2590082585811615,
      "learning_rate": 8.595246765995853e-06,
      "loss": 0.1085,
      "step": 8872
    },
    {
      "epoch": 0.14049115695805692,
      "grad_norm": 0.0004862738132942468,
      "learning_rate": 8.595088430419432e-06,
      "loss": 0.0,
      "step": 8873
    },
    {
      "epoch": 0.14050699051569898,
      "grad_norm": 0.4389602839946747,
      "learning_rate": 8.594930094843011e-06,
      "loss": 0.1358,
      "step": 8874
    },
    {
      "epoch": 0.14052282407334105,
      "grad_norm": 0.013878731057047844,
      "learning_rate": 8.59477175926659e-06,
      "loss": 0.0007,
      "step": 8875
    },
    {
      "epoch": 0.1405386576309831,
      "grad_norm": 0.10970591753721237,
      "learning_rate": 8.594613423690171e-06,
      "loss": 0.0539,
      "step": 8876
    },
    {
      "epoch": 0.14055449118862517,
      "grad_norm": 0.4145166575908661,
      "learning_rate": 8.594455088113748e-06,
      "loss": 0.4988,
      "step": 8877
    },
    {
      "epoch": 0.14057032474626724,
      "grad_norm": 0.000698457530234009,
      "learning_rate": 8.594296752537329e-06,
      "loss": 0.0,
      "step": 8878
    },
    {
      "epoch": 0.1405861583039093,
      "grad_norm": 0.005410115700215101,
      "learning_rate": 8.594138416960908e-06,
      "loss": 0.0003,
      "step": 8879
    },
    {
      "epoch": 0.14060199186155137,
      "grad_norm": 0.33100005984306335,
      "learning_rate": 8.593980081384487e-06,
      "loss": 0.2458,
      "step": 8880
    },
    {
      "epoch": 0.14061782541919343,
      "grad_norm": 0.6293632984161377,
      "learning_rate": 8.593821745808066e-06,
      "loss": 0.0901,
      "step": 8881
    },
    {
      "epoch": 0.1406336589768355,
      "grad_norm": 0.00018742184329312295,
      "learning_rate": 8.593663410231645e-06,
      "loss": 0.0,
      "step": 8882
    },
    {
      "epoch": 0.14064949253447756,
      "grad_norm": 0.35883623361587524,
      "learning_rate": 8.593505074655224e-06,
      "loss": 0.0952,
      "step": 8883
    },
    {
      "epoch": 0.14066532609211962,
      "grad_norm": 0.5826972126960754,
      "learning_rate": 8.593346739078803e-06,
      "loss": 0.3256,
      "step": 8884
    },
    {
      "epoch": 0.14068115964976172,
      "grad_norm": 0.4413972795009613,
      "learning_rate": 8.593188403502384e-06,
      "loss": 0.4889,
      "step": 8885
    },
    {
      "epoch": 0.14069699320740378,
      "grad_norm": 0.00020998381660319865,
      "learning_rate": 8.593030067925963e-06,
      "loss": 0.0,
      "step": 8886
    },
    {
      "epoch": 0.14071282676504585,
      "grad_norm": 0.6382533311843872,
      "learning_rate": 8.592871732349542e-06,
      "loss": 0.4167,
      "step": 8887
    },
    {
      "epoch": 0.1407286603226879,
      "grad_norm": 6.438461423385888e-05,
      "learning_rate": 8.592713396773121e-06,
      "loss": 0.0,
      "step": 8888
    },
    {
      "epoch": 0.14074449388032997,
      "grad_norm": 0.27407118678092957,
      "learning_rate": 8.5925550611967e-06,
      "loss": 0.0744,
      "step": 8889
    },
    {
      "epoch": 0.14076032743797204,
      "grad_norm": 0.4462887942790985,
      "learning_rate": 8.59239672562028e-06,
      "loss": 0.3135,
      "step": 8890
    },
    {
      "epoch": 0.1407761609956141,
      "grad_norm": 0.0006717865471728146,
      "learning_rate": 8.59223839004386e-06,
      "loss": 0.0,
      "step": 8891
    },
    {
      "epoch": 0.14079199455325617,
      "grad_norm": 0.19751177728176117,
      "learning_rate": 8.59208005446744e-06,
      "loss": 0.093,
      "step": 8892
    },
    {
      "epoch": 0.14080782811089823,
      "grad_norm": 0.607703685760498,
      "learning_rate": 8.591921718891019e-06,
      "loss": 0.7816,
      "step": 8893
    },
    {
      "epoch": 0.1408236616685403,
      "grad_norm": 0.13126806914806366,
      "learning_rate": 8.591763383314598e-06,
      "loss": 0.0464,
      "step": 8894
    },
    {
      "epoch": 0.14083949522618236,
      "grad_norm": 0.0004115485935471952,
      "learning_rate": 8.591605047738177e-06,
      "loss": 0.0,
      "step": 8895
    },
    {
      "epoch": 0.14085532878382442,
      "grad_norm": 0.5315563678741455,
      "learning_rate": 8.591446712161756e-06,
      "loss": 0.1371,
      "step": 8896
    },
    {
      "epoch": 0.14087116234146652,
      "grad_norm": 0.0008221992757171392,
      "learning_rate": 8.591288376585337e-06,
      "loss": 0.0,
      "step": 8897
    },
    {
      "epoch": 0.14088699589910858,
      "grad_norm": 0.22473683953285217,
      "learning_rate": 8.591130041008916e-06,
      "loss": 0.1366,
      "step": 8898
    },
    {
      "epoch": 0.14090282945675064,
      "grad_norm": 0.40324869751930237,
      "learning_rate": 8.590971705432495e-06,
      "loss": 0.6727,
      "step": 8899
    },
    {
      "epoch": 0.1409186630143927,
      "grad_norm": 0.009394871070981026,
      "learning_rate": 8.590813369856074e-06,
      "loss": 0.0005,
      "step": 8900
    },
    {
      "epoch": 0.14093449657203477,
      "grad_norm": 0.16511447727680206,
      "learning_rate": 8.590655034279653e-06,
      "loss": 0.0393,
      "step": 8901
    },
    {
      "epoch": 0.14095033012967684,
      "grad_norm": 0.00044672549120150506,
      "learning_rate": 8.590496698703232e-06,
      "loss": 0.0,
      "step": 8902
    },
    {
      "epoch": 0.1409661636873189,
      "grad_norm": 0.01817169040441513,
      "learning_rate": 8.590338363126811e-06,
      "loss": 0.001,
      "step": 8903
    },
    {
      "epoch": 0.14098199724496097,
      "grad_norm": 0.5017858743667603,
      "learning_rate": 8.590180027550392e-06,
      "loss": 0.6185,
      "step": 8904
    },
    {
      "epoch": 0.14099783080260303,
      "grad_norm": 0.0001402688940288499,
      "learning_rate": 8.59002169197397e-06,
      "loss": 0.0,
      "step": 8905
    },
    {
      "epoch": 0.1410136643602451,
      "grad_norm": 0.5299234986305237,
      "learning_rate": 8.58986335639755e-06,
      "loss": 0.534,
      "step": 8906
    },
    {
      "epoch": 0.14102949791788716,
      "grad_norm": 0.01712328940629959,
      "learning_rate": 8.589705020821129e-06,
      "loss": 0.001,
      "step": 8907
    },
    {
      "epoch": 0.14104533147552922,
      "grad_norm": 0.44512850046157837,
      "learning_rate": 8.589546685244708e-06,
      "loss": 0.1993,
      "step": 8908
    },
    {
      "epoch": 0.14106116503317132,
      "grad_norm": 0.25939062237739563,
      "learning_rate": 8.589388349668287e-06,
      "loss": 0.0751,
      "step": 8909
    },
    {
      "epoch": 0.14107699859081338,
      "grad_norm": 0.44248679280281067,
      "learning_rate": 8.589230014091868e-06,
      "loss": 0.1334,
      "step": 8910
    },
    {
      "epoch": 0.14109283214845544,
      "grad_norm": 0.48052871227264404,
      "learning_rate": 8.589071678515445e-06,
      "loss": 0.5113,
      "step": 8911
    },
    {
      "epoch": 0.1411086657060975,
      "grad_norm": 0.16664165258407593,
      "learning_rate": 8.588913342939026e-06,
      "loss": 0.0239,
      "step": 8912
    },
    {
      "epoch": 0.14112449926373957,
      "grad_norm": 0.0006397883989848197,
      "learning_rate": 8.588755007362605e-06,
      "loss": 0.0,
      "step": 8913
    },
    {
      "epoch": 0.14114033282138164,
      "grad_norm": 0.35101184248924255,
      "learning_rate": 8.588596671786184e-06,
      "loss": 0.121,
      "step": 8914
    },
    {
      "epoch": 0.1411561663790237,
      "grad_norm": 0.6127483248710632,
      "learning_rate": 8.588438336209763e-06,
      "loss": 0.374,
      "step": 8915
    },
    {
      "epoch": 0.14117199993666577,
      "grad_norm": 0.46622082591056824,
      "learning_rate": 8.588280000633343e-06,
      "loss": 0.517,
      "step": 8916
    },
    {
      "epoch": 0.14118783349430783,
      "grad_norm": 0.013702617026865482,
      "learning_rate": 8.588121665056922e-06,
      "loss": 0.0008,
      "step": 8917
    },
    {
      "epoch": 0.1412036670519499,
      "grad_norm": 0.00021829291654285043,
      "learning_rate": 8.587963329480502e-06,
      "loss": 0.0,
      "step": 8918
    },
    {
      "epoch": 0.14121950060959196,
      "grad_norm": 0.24873115122318268,
      "learning_rate": 8.587804993904081e-06,
      "loss": 0.1172,
      "step": 8919
    },
    {
      "epoch": 0.14123533416723402,
      "grad_norm": 0.005055421497672796,
      "learning_rate": 8.58764665832766e-06,
      "loss": 0.0002,
      "step": 8920
    },
    {
      "epoch": 0.14125116772487611,
      "grad_norm": 0.2293744683265686,
      "learning_rate": 8.58748832275124e-06,
      "loss": 0.0354,
      "step": 8921
    },
    {
      "epoch": 0.14126700128251818,
      "grad_norm": 0.20699594914913177,
      "learning_rate": 8.587329987174819e-06,
      "loss": 0.0933,
      "step": 8922
    },
    {
      "epoch": 0.14128283484016024,
      "grad_norm": 0.06857883185148239,
      "learning_rate": 8.587171651598398e-06,
      "loss": 0.0027,
      "step": 8923
    },
    {
      "epoch": 0.1412986683978023,
      "grad_norm": 0.17744362354278564,
      "learning_rate": 8.587013316021979e-06,
      "loss": 0.0416,
      "step": 8924
    },
    {
      "epoch": 0.14131450195544437,
      "grad_norm": 0.7087235450744629,
      "learning_rate": 8.586854980445558e-06,
      "loss": 0.6101,
      "step": 8925
    },
    {
      "epoch": 0.14133033551308644,
      "grad_norm": 0.05585214123129845,
      "learning_rate": 8.586696644869137e-06,
      "loss": 0.0013,
      "step": 8926
    },
    {
      "epoch": 0.1413461690707285,
      "grad_norm": 0.013930387794971466,
      "learning_rate": 8.586538309292716e-06,
      "loss": 0.0007,
      "step": 8927
    },
    {
      "epoch": 0.14136200262837056,
      "grad_norm": 0.4688136875629425,
      "learning_rate": 8.586379973716295e-06,
      "loss": 0.2072,
      "step": 8928
    },
    {
      "epoch": 0.14137783618601263,
      "grad_norm": 0.005334367044270039,
      "learning_rate": 8.586221638139874e-06,
      "loss": 0.0002,
      "step": 8929
    },
    {
      "epoch": 0.1413936697436547,
      "grad_norm": 0.3639076352119446,
      "learning_rate": 8.586063302563453e-06,
      "loss": 0.0681,
      "step": 8930
    },
    {
      "epoch": 0.14140950330129676,
      "grad_norm": 0.19474905729293823,
      "learning_rate": 8.585904966987034e-06,
      "loss": 0.0927,
      "step": 8931
    },
    {
      "epoch": 0.14142533685893882,
      "grad_norm": 0.015342471189796925,
      "learning_rate": 8.585746631410611e-06,
      "loss": 0.0007,
      "step": 8932
    },
    {
      "epoch": 0.1414411704165809,
      "grad_norm": 0.004305244889110327,
      "learning_rate": 8.585588295834192e-06,
      "loss": 0.0002,
      "step": 8933
    },
    {
      "epoch": 0.14145700397422298,
      "grad_norm": 0.39506444334983826,
      "learning_rate": 8.585429960257771e-06,
      "loss": 0.041,
      "step": 8934
    },
    {
      "epoch": 0.14147283753186504,
      "grad_norm": 0.48901820182800293,
      "learning_rate": 8.58527162468135e-06,
      "loss": 0.6023,
      "step": 8935
    },
    {
      "epoch": 0.1414886710895071,
      "grad_norm": 0.006797450594604015,
      "learning_rate": 8.58511328910493e-06,
      "loss": 0.0003,
      "step": 8936
    },
    {
      "epoch": 0.14150450464714917,
      "grad_norm": 0.40486910939216614,
      "learning_rate": 8.58495495352851e-06,
      "loss": 0.3958,
      "step": 8937
    },
    {
      "epoch": 0.14152033820479124,
      "grad_norm": 0.8393898010253906,
      "learning_rate": 8.584796617952087e-06,
      "loss": 0.1206,
      "step": 8938
    },
    {
      "epoch": 0.1415361717624333,
      "grad_norm": 0.366513729095459,
      "learning_rate": 8.584638282375668e-06,
      "loss": 0.2135,
      "step": 8939
    },
    {
      "epoch": 0.14155200532007536,
      "grad_norm": 0.41082844138145447,
      "learning_rate": 8.584479946799247e-06,
      "loss": 0.0094,
      "step": 8940
    },
    {
      "epoch": 0.14156783887771743,
      "grad_norm": 0.006027926690876484,
      "learning_rate": 8.584321611222826e-06,
      "loss": 0.0003,
      "step": 8941
    },
    {
      "epoch": 0.1415836724353595,
      "grad_norm": 0.46243590116500854,
      "learning_rate": 8.584163275646405e-06,
      "loss": 0.3673,
      "step": 8942
    },
    {
      "epoch": 0.14159950599300156,
      "grad_norm": 0.2143658995628357,
      "learning_rate": 8.584004940069986e-06,
      "loss": 0.1645,
      "step": 8943
    },
    {
      "epoch": 0.14161533955064362,
      "grad_norm": 0.016303258016705513,
      "learning_rate": 8.583846604493564e-06,
      "loss": 0.0006,
      "step": 8944
    },
    {
      "epoch": 0.1416311731082857,
      "grad_norm": 0.43334484100341797,
      "learning_rate": 8.583688268917144e-06,
      "loss": 0.1575,
      "step": 8945
    },
    {
      "epoch": 0.14164700666592778,
      "grad_norm": 0.5572533011436462,
      "learning_rate": 8.583529933340723e-06,
      "loss": 0.2184,
      "step": 8946
    },
    {
      "epoch": 0.14166284022356984,
      "grad_norm": 0.2034037560224533,
      "learning_rate": 8.583371597764302e-06,
      "loss": 0.0688,
      "step": 8947
    },
    {
      "epoch": 0.1416786737812119,
      "grad_norm": 0.39020833373069763,
      "learning_rate": 8.583213262187882e-06,
      "loss": 0.0823,
      "step": 8948
    },
    {
      "epoch": 0.14169450733885397,
      "grad_norm": 0.259515643119812,
      "learning_rate": 8.583054926611462e-06,
      "loss": 0.1157,
      "step": 8949
    },
    {
      "epoch": 0.14171034089649603,
      "grad_norm": 0.36132100224494934,
      "learning_rate": 8.58289659103504e-06,
      "loss": 0.191,
      "step": 8950
    },
    {
      "epoch": 0.1417261744541381,
      "grad_norm": 0.00013085566752124578,
      "learning_rate": 8.582738255458619e-06,
      "loss": 0.0,
      "step": 8951
    },
    {
      "epoch": 0.14174200801178016,
      "grad_norm": 0.43774649500846863,
      "learning_rate": 8.5825799198822e-06,
      "loss": 0.103,
      "step": 8952
    },
    {
      "epoch": 0.14175784156942223,
      "grad_norm": 0.011854210868477821,
      "learning_rate": 8.582421584305779e-06,
      "loss": 0.0007,
      "step": 8953
    },
    {
      "epoch": 0.1417736751270643,
      "grad_norm": 0.33158305287361145,
      "learning_rate": 8.582263248729358e-06,
      "loss": 0.1969,
      "step": 8954
    },
    {
      "epoch": 0.14178950868470636,
      "grad_norm": 0.01582466810941696,
      "learning_rate": 8.582104913152937e-06,
      "loss": 0.0002,
      "step": 8955
    },
    {
      "epoch": 0.14180534224234842,
      "grad_norm": 0.30669689178466797,
      "learning_rate": 8.581946577576516e-06,
      "loss": 0.1633,
      "step": 8956
    },
    {
      "epoch": 0.1418211757999905,
      "grad_norm": 0.41559967398643494,
      "learning_rate": 8.581788242000095e-06,
      "loss": 0.2664,
      "step": 8957
    },
    {
      "epoch": 0.14183700935763258,
      "grad_norm": 0.174236461520195,
      "learning_rate": 8.581629906423676e-06,
      "loss": 0.0242,
      "step": 8958
    },
    {
      "epoch": 0.14185284291527464,
      "grad_norm": 0.15202312171459198,
      "learning_rate": 8.581471570847255e-06,
      "loss": 0.0355,
      "step": 8959
    },
    {
      "epoch": 0.1418686764729167,
      "grad_norm": 0.16853031516075134,
      "learning_rate": 8.581313235270834e-06,
      "loss": 0.0543,
      "step": 8960
    },
    {
      "epoch": 0.14188451003055877,
      "grad_norm": 0.7613052725791931,
      "learning_rate": 8.581154899694413e-06,
      "loss": 0.0898,
      "step": 8961
    },
    {
      "epoch": 0.14190034358820083,
      "grad_norm": 0.4991030991077423,
      "learning_rate": 8.580996564117992e-06,
      "loss": 0.2915,
      "step": 8962
    },
    {
      "epoch": 0.1419161771458429,
      "grad_norm": 0.01674067974090576,
      "learning_rate": 8.580838228541571e-06,
      "loss": 0.0009,
      "step": 8963
    },
    {
      "epoch": 0.14193201070348496,
      "grad_norm": 0.5018807053565979,
      "learning_rate": 8.580679892965152e-06,
      "loss": 0.1311,
      "step": 8964
    },
    {
      "epoch": 0.14194784426112703,
      "grad_norm": 0.3274681866168976,
      "learning_rate": 8.580521557388731e-06,
      "loss": 0.272,
      "step": 8965
    },
    {
      "epoch": 0.1419636778187691,
      "grad_norm": 0.00927154440432787,
      "learning_rate": 8.58036322181231e-06,
      "loss": 0.0004,
      "step": 8966
    },
    {
      "epoch": 0.14197951137641115,
      "grad_norm": 0.3471481204032898,
      "learning_rate": 8.580204886235889e-06,
      "loss": 0.0688,
      "step": 8967
    },
    {
      "epoch": 0.14199534493405322,
      "grad_norm": 0.36039018630981445,
      "learning_rate": 8.580046550659468e-06,
      "loss": 0.1551,
      "step": 8968
    },
    {
      "epoch": 0.1420111784916953,
      "grad_norm": 0.02185782976448536,
      "learning_rate": 8.579888215083047e-06,
      "loss": 0.0014,
      "step": 8969
    },
    {
      "epoch": 0.14202701204933738,
      "grad_norm": 0.0001398510066792369,
      "learning_rate": 8.579729879506628e-06,
      "loss": 0.0,
      "step": 8970
    },
    {
      "epoch": 0.14204284560697944,
      "grad_norm": 0.3901238739490509,
      "learning_rate": 8.579571543930207e-06,
      "loss": 0.1347,
      "step": 8971
    },
    {
      "epoch": 0.1420586791646215,
      "grad_norm": 0.1950656920671463,
      "learning_rate": 8.579413208353786e-06,
      "loss": 0.0607,
      "step": 8972
    },
    {
      "epoch": 0.14207451272226357,
      "grad_norm": 0.14330936968326569,
      "learning_rate": 8.579254872777365e-06,
      "loss": 0.0738,
      "step": 8973
    },
    {
      "epoch": 0.14209034627990563,
      "grad_norm": 0.28229665756225586,
      "learning_rate": 8.579096537200944e-06,
      "loss": 0.0463,
      "step": 8974
    },
    {
      "epoch": 0.1421061798375477,
      "grad_norm": 0.24225017428398132,
      "learning_rate": 8.578938201624523e-06,
      "loss": 0.1748,
      "step": 8975
    },
    {
      "epoch": 0.14212201339518976,
      "grad_norm": 0.1593901365995407,
      "learning_rate": 8.578779866048103e-06,
      "loss": 0.0579,
      "step": 8976
    },
    {
      "epoch": 0.14213784695283183,
      "grad_norm": 0.2203378826379776,
      "learning_rate": 8.578621530471682e-06,
      "loss": 0.1119,
      "step": 8977
    },
    {
      "epoch": 0.1421536805104739,
      "grad_norm": 0.13545618951320648,
      "learning_rate": 8.57846319489526e-06,
      "loss": 0.0674,
      "step": 8978
    },
    {
      "epoch": 0.14216951406811595,
      "grad_norm": 0.5117617249488831,
      "learning_rate": 8.578304859318841e-06,
      "loss": 0.097,
      "step": 8979
    },
    {
      "epoch": 0.14218534762575802,
      "grad_norm": 0.10668209940195084,
      "learning_rate": 8.57814652374242e-06,
      "loss": 0.061,
      "step": 8980
    },
    {
      "epoch": 0.1422011811834001,
      "grad_norm": 0.25940752029418945,
      "learning_rate": 8.577988188166e-06,
      "loss": 0.0902,
      "step": 8981
    },
    {
      "epoch": 0.14221701474104217,
      "grad_norm": 0.21036069095134735,
      "learning_rate": 8.577829852589579e-06,
      "loss": 0.0805,
      "step": 8982
    },
    {
      "epoch": 0.14223284829868424,
      "grad_norm": 0.0002300424821441993,
      "learning_rate": 8.577671517013158e-06,
      "loss": 0.0,
      "step": 8983
    },
    {
      "epoch": 0.1422486818563263,
      "grad_norm": 0.5002239346504211,
      "learning_rate": 8.577513181436737e-06,
      "loss": 0.0804,
      "step": 8984
    },
    {
      "epoch": 0.14226451541396837,
      "grad_norm": 0.2501427233219147,
      "learning_rate": 8.577354845860318e-06,
      "loss": 0.0718,
      "step": 8985
    },
    {
      "epoch": 0.14228034897161043,
      "grad_norm": 0.4501730501651764,
      "learning_rate": 8.577196510283897e-06,
      "loss": 0.1244,
      "step": 8986
    },
    {
      "epoch": 0.1422961825292525,
      "grad_norm": 0.1233256533741951,
      "learning_rate": 8.577038174707476e-06,
      "loss": 0.0396,
      "step": 8987
    },
    {
      "epoch": 0.14231201608689456,
      "grad_norm": 0.3657739758491516,
      "learning_rate": 8.576879839131055e-06,
      "loss": 0.0892,
      "step": 8988
    },
    {
      "epoch": 0.14232784964453662,
      "grad_norm": 0.2168339341878891,
      "learning_rate": 8.576721503554634e-06,
      "loss": 0.0601,
      "step": 8989
    },
    {
      "epoch": 0.1423436832021787,
      "grad_norm": 8.043389243539423e-05,
      "learning_rate": 8.576563167978213e-06,
      "loss": 0.0,
      "step": 8990
    },
    {
      "epoch": 0.14235951675982075,
      "grad_norm": 0.5102462768554688,
      "learning_rate": 8.576404832401794e-06,
      "loss": 0.8267,
      "step": 8991
    },
    {
      "epoch": 0.14237535031746282,
      "grad_norm": 0.4845048785209656,
      "learning_rate": 8.576246496825373e-06,
      "loss": 0.2091,
      "step": 8992
    },
    {
      "epoch": 0.1423911838751049,
      "grad_norm": 0.43960773944854736,
      "learning_rate": 8.576088161248952e-06,
      "loss": 0.1818,
      "step": 8993
    },
    {
      "epoch": 0.14240701743274697,
      "grad_norm": 0.5131067633628845,
      "learning_rate": 8.575929825672531e-06,
      "loss": 0.3348,
      "step": 8994
    },
    {
      "epoch": 0.14242285099038904,
      "grad_norm": 0.4366549551486969,
      "learning_rate": 8.57577149009611e-06,
      "loss": 0.0352,
      "step": 8995
    },
    {
      "epoch": 0.1424386845480311,
      "grad_norm": 0.5047526359558105,
      "learning_rate": 8.57561315451969e-06,
      "loss": 0.6764,
      "step": 8996
    },
    {
      "epoch": 0.14245451810567317,
      "grad_norm": 0.22484295070171356,
      "learning_rate": 8.57545481894327e-06,
      "loss": 0.0959,
      "step": 8997
    },
    {
      "epoch": 0.14247035166331523,
      "grad_norm": 0.12775443494319916,
      "learning_rate": 8.575296483366849e-06,
      "loss": 0.0218,
      "step": 8998
    },
    {
      "epoch": 0.1424861852209573,
      "grad_norm": 0.5330497026443481,
      "learning_rate": 8.575138147790426e-06,
      "loss": 0.094,
      "step": 8999
    },
    {
      "epoch": 0.14250201877859936,
      "grad_norm": 0.0022780706640332937,
      "learning_rate": 8.574979812214007e-06,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 0.14251785233624142,
      "grad_norm": 0.35227566957473755,
      "learning_rate": 8.574821476637586e-06,
      "loss": 0.0922,
      "step": 9001
    },
    {
      "epoch": 0.1425336858938835,
      "grad_norm": 0.5343432426452637,
      "learning_rate": 8.574663141061165e-06,
      "loss": 0.4778,
      "step": 9002
    },
    {
      "epoch": 0.14254951945152555,
      "grad_norm": 0.602097749710083,
      "learning_rate": 8.574504805484744e-06,
      "loss": 0.0592,
      "step": 9003
    },
    {
      "epoch": 0.14256535300916762,
      "grad_norm": 0.3735736012458801,
      "learning_rate": 8.574346469908325e-06,
      "loss": 0.1191,
      "step": 9004
    },
    {
      "epoch": 0.1425811865668097,
      "grad_norm": 0.22633445262908936,
      "learning_rate": 8.574188134331903e-06,
      "loss": 0.2088,
      "step": 9005
    },
    {
      "epoch": 0.14259702012445177,
      "grad_norm": 0.007974158972501755,
      "learning_rate": 8.574029798755483e-06,
      "loss": 0.0003,
      "step": 9006
    },
    {
      "epoch": 0.14261285368209384,
      "grad_norm": 0.5751082897186279,
      "learning_rate": 8.573871463179062e-06,
      "loss": 0.2492,
      "step": 9007
    },
    {
      "epoch": 0.1426286872397359,
      "grad_norm": 0.022848697379231453,
      "learning_rate": 8.573713127602642e-06,
      "loss": 0.0013,
      "step": 9008
    },
    {
      "epoch": 0.14264452079737797,
      "grad_norm": 0.4547296166419983,
      "learning_rate": 8.57355479202622e-06,
      "loss": 0.2969,
      "step": 9009
    },
    {
      "epoch": 0.14266035435502003,
      "grad_norm": 0.22422192990779877,
      "learning_rate": 8.573396456449801e-06,
      "loss": 0.0798,
      "step": 9010
    },
    {
      "epoch": 0.1426761879126621,
      "grad_norm": 0.6405558586120605,
      "learning_rate": 8.573238120873379e-06,
      "loss": 0.3929,
      "step": 9011
    },
    {
      "epoch": 0.14269202147030416,
      "grad_norm": 0.01894262060523033,
      "learning_rate": 8.57307978529696e-06,
      "loss": 0.0009,
      "step": 9012
    },
    {
      "epoch": 0.14270785502794622,
      "grad_norm": 0.3946975767612457,
      "learning_rate": 8.572921449720539e-06,
      "loss": 0.5645,
      "step": 9013
    },
    {
      "epoch": 0.1427236885855883,
      "grad_norm": 0.3511946201324463,
      "learning_rate": 8.572763114144118e-06,
      "loss": 0.1328,
      "step": 9014
    },
    {
      "epoch": 0.14273952214323035,
      "grad_norm": 0.020237987861037254,
      "learning_rate": 8.572604778567697e-06,
      "loss": 0.001,
      "step": 9015
    },
    {
      "epoch": 0.14275535570087242,
      "grad_norm": 0.0013464675284922123,
      "learning_rate": 8.572446442991278e-06,
      "loss": 0.0,
      "step": 9016
    },
    {
      "epoch": 0.1427711892585145,
      "grad_norm": 0.1159273236989975,
      "learning_rate": 8.572288107414855e-06,
      "loss": 0.0311,
      "step": 9017
    },
    {
      "epoch": 0.14278702281615657,
      "grad_norm": 0.20400911569595337,
      "learning_rate": 8.572129771838436e-06,
      "loss": 0.0653,
      "step": 9018
    },
    {
      "epoch": 0.14280285637379864,
      "grad_norm": 0.6261057257652283,
      "learning_rate": 8.571971436262015e-06,
      "loss": 0.3135,
      "step": 9019
    },
    {
      "epoch": 0.1428186899314407,
      "grad_norm": 0.2600972652435303,
      "learning_rate": 8.571813100685594e-06,
      "loss": 0.1239,
      "step": 9020
    },
    {
      "epoch": 0.14283452348908277,
      "grad_norm": 0.4098531901836395,
      "learning_rate": 8.571654765109173e-06,
      "loss": 0.6327,
      "step": 9021
    },
    {
      "epoch": 0.14285035704672483,
      "grad_norm": 0.352954626083374,
      "learning_rate": 8.571496429532754e-06,
      "loss": 0.2266,
      "step": 9022
    },
    {
      "epoch": 0.1428661906043669,
      "grad_norm": 0.25811511278152466,
      "learning_rate": 8.571338093956331e-06,
      "loss": 0.0997,
      "step": 9023
    },
    {
      "epoch": 0.14288202416200896,
      "grad_norm": 0.38992318511009216,
      "learning_rate": 8.57117975837991e-06,
      "loss": 0.0877,
      "step": 9024
    },
    {
      "epoch": 0.14289785771965102,
      "grad_norm": 0.35556092858314514,
      "learning_rate": 8.571021422803491e-06,
      "loss": 0.0996,
      "step": 9025
    },
    {
      "epoch": 0.1429136912772931,
      "grad_norm": 0.4842482805252075,
      "learning_rate": 8.57086308722707e-06,
      "loss": 0.4437,
      "step": 9026
    },
    {
      "epoch": 0.14292952483493515,
      "grad_norm": 0.2580583095550537,
      "learning_rate": 8.570704751650649e-06,
      "loss": 0.1073,
      "step": 9027
    },
    {
      "epoch": 0.14294535839257722,
      "grad_norm": 0.23926742374897003,
      "learning_rate": 8.570546416074228e-06,
      "loss": 0.1242,
      "step": 9028
    },
    {
      "epoch": 0.1429611919502193,
      "grad_norm": 0.05871017277240753,
      "learning_rate": 8.570388080497807e-06,
      "loss": 0.0106,
      "step": 9029
    },
    {
      "epoch": 0.14297702550786137,
      "grad_norm": 0.00029043934773653746,
      "learning_rate": 8.570229744921386e-06,
      "loss": 0.0,
      "step": 9030
    },
    {
      "epoch": 0.14299285906550344,
      "grad_norm": 0.13548079133033752,
      "learning_rate": 8.570071409344967e-06,
      "loss": 0.012,
      "step": 9031
    },
    {
      "epoch": 0.1430086926231455,
      "grad_norm": 0.24622724950313568,
      "learning_rate": 8.569913073768546e-06,
      "loss": 0.1181,
      "step": 9032
    },
    {
      "epoch": 0.14302452618078756,
      "grad_norm": 0.3601384460926056,
      "learning_rate": 8.569754738192125e-06,
      "loss": 0.0315,
      "step": 9033
    },
    {
      "epoch": 0.14304035973842963,
      "grad_norm": 0.25486308336257935,
      "learning_rate": 8.569596402615704e-06,
      "loss": 0.0732,
      "step": 9034
    },
    {
      "epoch": 0.1430561932960717,
      "grad_norm": 0.5335816144943237,
      "learning_rate": 8.569438067039283e-06,
      "loss": 0.6098,
      "step": 9035
    },
    {
      "epoch": 0.14307202685371376,
      "grad_norm": 0.1579471379518509,
      "learning_rate": 8.569279731462863e-06,
      "loss": 0.0621,
      "step": 9036
    },
    {
      "epoch": 0.14308786041135582,
      "grad_norm": 0.00023164201411418617,
      "learning_rate": 8.569121395886443e-06,
      "loss": 0.0,
      "step": 9037
    },
    {
      "epoch": 0.14310369396899789,
      "grad_norm": 1.267210841178894,
      "learning_rate": 8.568963060310022e-06,
      "loss": 0.4573,
      "step": 9038
    },
    {
      "epoch": 0.14311952752663995,
      "grad_norm": 0.26482272148132324,
      "learning_rate": 8.568804724733601e-06,
      "loss": 0.1063,
      "step": 9039
    },
    {
      "epoch": 0.14313536108428201,
      "grad_norm": 0.24120467901229858,
      "learning_rate": 8.56864638915718e-06,
      "loss": 0.0508,
      "step": 9040
    },
    {
      "epoch": 0.1431511946419241,
      "grad_norm": 0.8291908502578735,
      "learning_rate": 8.56848805358076e-06,
      "loss": 0.1674,
      "step": 9041
    },
    {
      "epoch": 0.14316702819956617,
      "grad_norm": 0.2943938672542572,
      "learning_rate": 8.568329718004339e-06,
      "loss": 0.0564,
      "step": 9042
    },
    {
      "epoch": 0.14318286175720824,
      "grad_norm": 0.6758292317390442,
      "learning_rate": 8.56817138242792e-06,
      "loss": 0.0716,
      "step": 9043
    },
    {
      "epoch": 0.1431986953148503,
      "grad_norm": 0.2737504541873932,
      "learning_rate": 8.568013046851497e-06,
      "loss": 0.0553,
      "step": 9044
    },
    {
      "epoch": 0.14321452887249236,
      "grad_norm": 0.11980413645505905,
      "learning_rate": 8.567854711275078e-06,
      "loss": 0.0151,
      "step": 9045
    },
    {
      "epoch": 0.14323036243013443,
      "grad_norm": 3.7908570766448975,
      "learning_rate": 8.567696375698657e-06,
      "loss": 0.2017,
      "step": 9046
    },
    {
      "epoch": 0.1432461959877765,
      "grad_norm": 0.5772420763969421,
      "learning_rate": 8.567538040122236e-06,
      "loss": 0.5892,
      "step": 9047
    },
    {
      "epoch": 0.14326202954541856,
      "grad_norm": 0.051224347203969955,
      "learning_rate": 8.567379704545815e-06,
      "loss": 0.0072,
      "step": 9048
    },
    {
      "epoch": 0.14327786310306062,
      "grad_norm": 0.34464168548583984,
      "learning_rate": 8.567221368969394e-06,
      "loss": 0.2932,
      "step": 9049
    },
    {
      "epoch": 0.14329369666070269,
      "grad_norm": 0.14485079050064087,
      "learning_rate": 8.567063033392973e-06,
      "loss": 0.0392,
      "step": 9050
    },
    {
      "epoch": 0.14330953021834475,
      "grad_norm": 0.04132755473256111,
      "learning_rate": 8.566904697816552e-06,
      "loss": 0.0023,
      "step": 9051
    },
    {
      "epoch": 0.1433253637759868,
      "grad_norm": 0.009936532936990261,
      "learning_rate": 8.566746362240133e-06,
      "loss": 0.0006,
      "step": 9052
    },
    {
      "epoch": 0.1433411973336289,
      "grad_norm": 0.32277658581733704,
      "learning_rate": 8.566588026663712e-06,
      "loss": 0.2908,
      "step": 9053
    },
    {
      "epoch": 0.14335703089127097,
      "grad_norm": 0.2959024906158447,
      "learning_rate": 8.566429691087291e-06,
      "loss": 0.2144,
      "step": 9054
    },
    {
      "epoch": 0.14337286444891303,
      "grad_norm": 0.06681567430496216,
      "learning_rate": 8.56627135551087e-06,
      "loss": 0.0013,
      "step": 9055
    },
    {
      "epoch": 0.1433886980065551,
      "grad_norm": 0.13649138808250427,
      "learning_rate": 8.56611301993445e-06,
      "loss": 0.0501,
      "step": 9056
    },
    {
      "epoch": 0.14340453156419716,
      "grad_norm": 0.15384069085121155,
      "learning_rate": 8.565954684358028e-06,
      "loss": 0.0613,
      "step": 9057
    },
    {
      "epoch": 0.14342036512183923,
      "grad_norm": 0.4399792551994324,
      "learning_rate": 8.565796348781609e-06,
      "loss": 0.1637,
      "step": 9058
    },
    {
      "epoch": 0.1434361986794813,
      "grad_norm": 0.35369694232940674,
      "learning_rate": 8.565638013205188e-06,
      "loss": 0.0087,
      "step": 9059
    },
    {
      "epoch": 0.14345203223712336,
      "grad_norm": 0.2636660039424896,
      "learning_rate": 8.565479677628767e-06,
      "loss": 0.0628,
      "step": 9060
    },
    {
      "epoch": 0.14346786579476542,
      "grad_norm": 0.602445662021637,
      "learning_rate": 8.565321342052346e-06,
      "loss": 0.7023,
      "step": 9061
    },
    {
      "epoch": 0.14348369935240748,
      "grad_norm": 0.0004767525242641568,
      "learning_rate": 8.565163006475925e-06,
      "loss": 0.0,
      "step": 9062
    },
    {
      "epoch": 0.14349953291004955,
      "grad_norm": 0.298739492893219,
      "learning_rate": 8.565004670899504e-06,
      "loss": 0.1649,
      "step": 9063
    },
    {
      "epoch": 0.1435153664676916,
      "grad_norm": 0.18324211239814758,
      "learning_rate": 8.564846335323085e-06,
      "loss": 0.0496,
      "step": 9064
    },
    {
      "epoch": 0.1435312000253337,
      "grad_norm": 0.8452017903327942,
      "learning_rate": 8.564687999746664e-06,
      "loss": 0.3647,
      "step": 9065
    },
    {
      "epoch": 0.14354703358297577,
      "grad_norm": 0.41865605115890503,
      "learning_rate": 8.564529664170243e-06,
      "loss": 0.1289,
      "step": 9066
    },
    {
      "epoch": 0.14356286714061783,
      "grad_norm": 0.003623059019446373,
      "learning_rate": 8.564371328593822e-06,
      "loss": 0.0002,
      "step": 9067
    },
    {
      "epoch": 0.1435787006982599,
      "grad_norm": 0.2767201066017151,
      "learning_rate": 8.564212993017402e-06,
      "loss": 0.1055,
      "step": 9068
    },
    {
      "epoch": 0.14359453425590196,
      "grad_norm": 0.00814078375697136,
      "learning_rate": 8.56405465744098e-06,
      "loss": 0.0004,
      "step": 9069
    },
    {
      "epoch": 0.14361036781354403,
      "grad_norm": 0.28305062651634216,
      "learning_rate": 8.563896321864561e-06,
      "loss": 0.2153,
      "step": 9070
    },
    {
      "epoch": 0.1436262013711861,
      "grad_norm": 0.20675289630889893,
      "learning_rate": 8.56373798628814e-06,
      "loss": 0.0666,
      "step": 9071
    },
    {
      "epoch": 0.14364203492882816,
      "grad_norm": 0.44445809721946716,
      "learning_rate": 8.563579650711718e-06,
      "loss": 0.1721,
      "step": 9072
    },
    {
      "epoch": 0.14365786848647022,
      "grad_norm": 0.22634312510490417,
      "learning_rate": 8.563421315135299e-06,
      "loss": 0.1712,
      "step": 9073
    },
    {
      "epoch": 0.14367370204411228,
      "grad_norm": 0.21388380229473114,
      "learning_rate": 8.563262979558878e-06,
      "loss": 0.0879,
      "step": 9074
    },
    {
      "epoch": 0.14368953560175435,
      "grad_norm": 0.33153271675109863,
      "learning_rate": 8.563104643982457e-06,
      "loss": 0.1214,
      "step": 9075
    },
    {
      "epoch": 0.1437053691593964,
      "grad_norm": 0.21150371432304382,
      "learning_rate": 8.562946308406036e-06,
      "loss": 0.1731,
      "step": 9076
    },
    {
      "epoch": 0.1437212027170385,
      "grad_norm": 0.3292035460472107,
      "learning_rate": 8.562787972829617e-06,
      "loss": 0.0536,
      "step": 9077
    },
    {
      "epoch": 0.14373703627468057,
      "grad_norm": 0.5941116809844971,
      "learning_rate": 8.562629637253194e-06,
      "loss": 0.2867,
      "step": 9078
    },
    {
      "epoch": 0.14375286983232263,
      "grad_norm": 0.3414331078529358,
      "learning_rate": 8.562471301676775e-06,
      "loss": 0.2232,
      "step": 9079
    },
    {
      "epoch": 0.1437687033899647,
      "grad_norm": 0.022987861186265945,
      "learning_rate": 8.562312966100354e-06,
      "loss": 0.0013,
      "step": 9080
    },
    {
      "epoch": 0.14378453694760676,
      "grad_norm": 0.003485739231109619,
      "learning_rate": 8.562154630523933e-06,
      "loss": 0.0002,
      "step": 9081
    },
    {
      "epoch": 0.14380037050524883,
      "grad_norm": 0.030208464711904526,
      "learning_rate": 8.561996294947512e-06,
      "loss": 0.0015,
      "step": 9082
    },
    {
      "epoch": 0.1438162040628909,
      "grad_norm": 0.3514728248119354,
      "learning_rate": 8.561837959371093e-06,
      "loss": 0.1269,
      "step": 9083
    },
    {
      "epoch": 0.14383203762053295,
      "grad_norm": 0.0001075031395885162,
      "learning_rate": 8.56167962379467e-06,
      "loss": 0.0,
      "step": 9084
    },
    {
      "epoch": 0.14384787117817502,
      "grad_norm": 0.2915615141391754,
      "learning_rate": 8.561521288218251e-06,
      "loss": 0.0777,
      "step": 9085
    },
    {
      "epoch": 0.14386370473581708,
      "grad_norm": 0.011532379314303398,
      "learning_rate": 8.56136295264183e-06,
      "loss": 0.0013,
      "step": 9086
    },
    {
      "epoch": 0.14387953829345915,
      "grad_norm": 0.00032135529909282923,
      "learning_rate": 8.561204617065409e-06,
      "loss": 0.0,
      "step": 9087
    },
    {
      "epoch": 0.1438953718511012,
      "grad_norm": 0.3142266571521759,
      "learning_rate": 8.561046281488988e-06,
      "loss": 0.2324,
      "step": 9088
    },
    {
      "epoch": 0.1439112054087433,
      "grad_norm": 0.4431076645851135,
      "learning_rate": 8.560887945912569e-06,
      "loss": 0.1547,
      "step": 9089
    },
    {
      "epoch": 0.14392703896638537,
      "grad_norm": 0.545826256275177,
      "learning_rate": 8.560729610336146e-06,
      "loss": 0.0654,
      "step": 9090
    },
    {
      "epoch": 0.14394287252402743,
      "grad_norm": 0.242864727973938,
      "learning_rate": 8.560571274759727e-06,
      "loss": 0.103,
      "step": 9091
    },
    {
      "epoch": 0.1439587060816695,
      "grad_norm": 0.21195046603679657,
      "learning_rate": 8.560412939183306e-06,
      "loss": 0.0998,
      "step": 9092
    },
    {
      "epoch": 0.14397453963931156,
      "grad_norm": 0.32847997546195984,
      "learning_rate": 8.560254603606885e-06,
      "loss": 0.0762,
      "step": 9093
    },
    {
      "epoch": 0.14399037319695362,
      "grad_norm": 0.0418599471449852,
      "learning_rate": 8.560096268030464e-06,
      "loss": 0.0024,
      "step": 9094
    },
    {
      "epoch": 0.1440062067545957,
      "grad_norm": 0.16685153543949127,
      "learning_rate": 8.559937932454043e-06,
      "loss": 0.0559,
      "step": 9095
    },
    {
      "epoch": 0.14402204031223775,
      "grad_norm": 0.38710400462150574,
      "learning_rate": 8.559779596877623e-06,
      "loss": 0.2813,
      "step": 9096
    },
    {
      "epoch": 0.14403787386987982,
      "grad_norm": 0.1773800104856491,
      "learning_rate": 8.559621261301202e-06,
      "loss": 0.0952,
      "step": 9097
    },
    {
      "epoch": 0.14405370742752188,
      "grad_norm": 0.27248939871788025,
      "learning_rate": 8.559462925724782e-06,
      "loss": 0.0063,
      "step": 9098
    },
    {
      "epoch": 0.14406954098516395,
      "grad_norm": 0.542416512966156,
      "learning_rate": 8.559304590148361e-06,
      "loss": 0.2254,
      "step": 9099
    },
    {
      "epoch": 0.144085374542806,
      "grad_norm": 0.23801934719085693,
      "learning_rate": 8.55914625457194e-06,
      "loss": 0.0285,
      "step": 9100
    },
    {
      "epoch": 0.1441012081004481,
      "grad_norm": 0.09942405670881271,
      "learning_rate": 8.55898791899552e-06,
      "loss": 0.0105,
      "step": 9101
    },
    {
      "epoch": 0.14411704165809017,
      "grad_norm": 0.19762010872364044,
      "learning_rate": 8.558829583419099e-06,
      "loss": 0.0758,
      "step": 9102
    },
    {
      "epoch": 0.14413287521573223,
      "grad_norm": 0.21117104589939117,
      "learning_rate": 8.558671247842678e-06,
      "loss": 0.0953,
      "step": 9103
    },
    {
      "epoch": 0.1441487087733743,
      "grad_norm": 0.004847430624067783,
      "learning_rate": 8.558512912266259e-06,
      "loss": 0.0002,
      "step": 9104
    },
    {
      "epoch": 0.14416454233101636,
      "grad_norm": 0.2940448820590973,
      "learning_rate": 8.558354576689838e-06,
      "loss": 0.1236,
      "step": 9105
    },
    {
      "epoch": 0.14418037588865842,
      "grad_norm": 0.005267065949738026,
      "learning_rate": 8.558196241113417e-06,
      "loss": 0.0002,
      "step": 9106
    },
    {
      "epoch": 0.1441962094463005,
      "grad_norm": 0.44917264580726624,
      "learning_rate": 8.558037905536996e-06,
      "loss": 0.545,
      "step": 9107
    },
    {
      "epoch": 0.14421204300394255,
      "grad_norm": 0.40233027935028076,
      "learning_rate": 8.557879569960575e-06,
      "loss": 0.1238,
      "step": 9108
    },
    {
      "epoch": 0.14422787656158462,
      "grad_norm": 0.10592494159936905,
      "learning_rate": 8.557721234384154e-06,
      "loss": 0.0027,
      "step": 9109
    },
    {
      "epoch": 0.14424371011922668,
      "grad_norm": 0.0007715059909969568,
      "learning_rate": 8.557562898807735e-06,
      "loss": 0.0,
      "step": 9110
    },
    {
      "epoch": 0.14425954367686875,
      "grad_norm": 0.5923798084259033,
      "learning_rate": 8.557404563231312e-06,
      "loss": 0.1378,
      "step": 9111
    },
    {
      "epoch": 0.1442753772345108,
      "grad_norm": 0.10588692128658295,
      "learning_rate": 8.557246227654893e-06,
      "loss": 0.0509,
      "step": 9112
    },
    {
      "epoch": 0.1442912107921529,
      "grad_norm": 0.00015757034998387098,
      "learning_rate": 8.557087892078472e-06,
      "loss": 0.0,
      "step": 9113
    },
    {
      "epoch": 0.14430704434979497,
      "grad_norm": 0.4759478271007538,
      "learning_rate": 8.556929556502051e-06,
      "loss": 0.1351,
      "step": 9114
    },
    {
      "epoch": 0.14432287790743703,
      "grad_norm": 0.009098079986870289,
      "learning_rate": 8.55677122092563e-06,
      "loss": 0.0004,
      "step": 9115
    },
    {
      "epoch": 0.1443387114650791,
      "grad_norm": 0.27032479643821716,
      "learning_rate": 8.556612885349211e-06,
      "loss": 0.064,
      "step": 9116
    },
    {
      "epoch": 0.14435454502272116,
      "grad_norm": 0.26407894492149353,
      "learning_rate": 8.556454549772788e-06,
      "loss": 0.0357,
      "step": 9117
    },
    {
      "epoch": 0.14437037858036322,
      "grad_norm": 0.2702498435974121,
      "learning_rate": 8.556296214196369e-06,
      "loss": 0.1731,
      "step": 9118
    },
    {
      "epoch": 0.1443862121380053,
      "grad_norm": 0.8445292711257935,
      "learning_rate": 8.556137878619948e-06,
      "loss": 0.2849,
      "step": 9119
    },
    {
      "epoch": 0.14440204569564735,
      "grad_norm": 0.22369761765003204,
      "learning_rate": 8.555979543043527e-06,
      "loss": 0.0263,
      "step": 9120
    },
    {
      "epoch": 0.14441787925328942,
      "grad_norm": 0.19739362597465515,
      "learning_rate": 8.555821207467106e-06,
      "loss": 0.0419,
      "step": 9121
    },
    {
      "epoch": 0.14443371281093148,
      "grad_norm": 0.3917427062988281,
      "learning_rate": 8.555662871890685e-06,
      "loss": 0.0204,
      "step": 9122
    },
    {
      "epoch": 0.14444954636857354,
      "grad_norm": 0.16138510406017303,
      "learning_rate": 8.555504536314264e-06,
      "loss": 0.0093,
      "step": 9123
    },
    {
      "epoch": 0.1444653799262156,
      "grad_norm": 0.333842009305954,
      "learning_rate": 8.555346200737844e-06,
      "loss": 0.1113,
      "step": 9124
    },
    {
      "epoch": 0.1444812134838577,
      "grad_norm": 0.0001232958456967026,
      "learning_rate": 8.555187865161424e-06,
      "loss": 0.0,
      "step": 9125
    },
    {
      "epoch": 0.14449704704149977,
      "grad_norm": 0.2498587667942047,
      "learning_rate": 8.555029529585003e-06,
      "loss": 0.1082,
      "step": 9126
    },
    {
      "epoch": 0.14451288059914183,
      "grad_norm": 0.2862333655357361,
      "learning_rate": 8.554871194008582e-06,
      "loss": 0.0665,
      "step": 9127
    },
    {
      "epoch": 0.1445287141567839,
      "grad_norm": 0.2034682035446167,
      "learning_rate": 8.554712858432162e-06,
      "loss": 0.085,
      "step": 9128
    },
    {
      "epoch": 0.14454454771442596,
      "grad_norm": 0.005167702678591013,
      "learning_rate": 8.55455452285574e-06,
      "loss": 0.0002,
      "step": 9129
    },
    {
      "epoch": 0.14456038127206802,
      "grad_norm": 0.2627027630805969,
      "learning_rate": 8.55439618727932e-06,
      "loss": 0.0494,
      "step": 9130
    },
    {
      "epoch": 0.1445762148297101,
      "grad_norm": 0.4729270040988922,
      "learning_rate": 8.5542378517029e-06,
      "loss": 0.4907,
      "step": 9131
    },
    {
      "epoch": 0.14459204838735215,
      "grad_norm": 0.7211268544197083,
      "learning_rate": 8.55407951612648e-06,
      "loss": 0.9044,
      "step": 9132
    },
    {
      "epoch": 0.14460788194499422,
      "grad_norm": 0.4027007222175598,
      "learning_rate": 8.553921180550059e-06,
      "loss": 0.0652,
      "step": 9133
    },
    {
      "epoch": 0.14462371550263628,
      "grad_norm": 0.45274972915649414,
      "learning_rate": 8.553762844973638e-06,
      "loss": 0.3018,
      "step": 9134
    },
    {
      "epoch": 0.14463954906027834,
      "grad_norm": 0.2939439117908478,
      "learning_rate": 8.553604509397217e-06,
      "loss": 0.5827,
      "step": 9135
    },
    {
      "epoch": 0.1446553826179204,
      "grad_norm": 0.5244138240814209,
      "learning_rate": 8.553446173820796e-06,
      "loss": 0.103,
      "step": 9136
    },
    {
      "epoch": 0.1446712161755625,
      "grad_norm": 0.3139064311981201,
      "learning_rate": 8.553287838244377e-06,
      "loss": 0.0877,
      "step": 9137
    },
    {
      "epoch": 0.14468704973320456,
      "grad_norm": 0.5052341222763062,
      "learning_rate": 8.553129502667956e-06,
      "loss": 0.5573,
      "step": 9138
    },
    {
      "epoch": 0.14470288329084663,
      "grad_norm": 0.020023135468363762,
      "learning_rate": 8.552971167091535e-06,
      "loss": 0.0011,
      "step": 9139
    },
    {
      "epoch": 0.1447187168484887,
      "grad_norm": 0.864043116569519,
      "learning_rate": 8.552812831515114e-06,
      "loss": 0.6575,
      "step": 9140
    },
    {
      "epoch": 0.14473455040613076,
      "grad_norm": 0.48516881465911865,
      "learning_rate": 8.552654495938693e-06,
      "loss": 0.1305,
      "step": 9141
    },
    {
      "epoch": 0.14475038396377282,
      "grad_norm": 0.24016468226909637,
      "learning_rate": 8.552496160362272e-06,
      "loss": 0.0783,
      "step": 9142
    },
    {
      "epoch": 0.14476621752141489,
      "grad_norm": 0.3376823663711548,
      "learning_rate": 8.552337824785851e-06,
      "loss": 0.0108,
      "step": 9143
    },
    {
      "epoch": 0.14478205107905695,
      "grad_norm": 0.32054048776626587,
      "learning_rate": 8.552179489209432e-06,
      "loss": 0.1686,
      "step": 9144
    },
    {
      "epoch": 0.14479788463669901,
      "grad_norm": 0.7867344617843628,
      "learning_rate": 8.55202115363301e-06,
      "loss": 0.8746,
      "step": 9145
    },
    {
      "epoch": 0.14481371819434108,
      "grad_norm": 0.6210843920707703,
      "learning_rate": 8.55186281805659e-06,
      "loss": 0.042,
      "step": 9146
    },
    {
      "epoch": 0.14482955175198314,
      "grad_norm": 0.17543545365333557,
      "learning_rate": 8.55170448248017e-06,
      "loss": 0.0578,
      "step": 9147
    },
    {
      "epoch": 0.1448453853096252,
      "grad_norm": 0.3243313431739807,
      "learning_rate": 8.551546146903748e-06,
      "loss": 0.113,
      "step": 9148
    },
    {
      "epoch": 0.1448612188672673,
      "grad_norm": 0.5577926635742188,
      "learning_rate": 8.551387811327327e-06,
      "loss": 0.1648,
      "step": 9149
    },
    {
      "epoch": 0.14487705242490936,
      "grad_norm": 0.4884726405143738,
      "learning_rate": 8.551229475750908e-06,
      "loss": 0.725,
      "step": 9150
    },
    {
      "epoch": 0.14489288598255143,
      "grad_norm": 0.007212457712739706,
      "learning_rate": 8.551071140174485e-06,
      "loss": 0.0004,
      "step": 9151
    },
    {
      "epoch": 0.1449087195401935,
      "grad_norm": 0.18431849777698517,
      "learning_rate": 8.550912804598066e-06,
      "loss": 0.0797,
      "step": 9152
    },
    {
      "epoch": 0.14492455309783556,
      "grad_norm": 0.009813662618398666,
      "learning_rate": 8.550754469021645e-06,
      "loss": 0.0006,
      "step": 9153
    },
    {
      "epoch": 0.14494038665547762,
      "grad_norm": 0.2032822072505951,
      "learning_rate": 8.550596133445224e-06,
      "loss": 0.0749,
      "step": 9154
    },
    {
      "epoch": 0.14495622021311969,
      "grad_norm": 0.271708607673645,
      "learning_rate": 8.550437797868804e-06,
      "loss": 0.1674,
      "step": 9155
    },
    {
      "epoch": 0.14497205377076175,
      "grad_norm": 0.2050294429063797,
      "learning_rate": 8.550279462292384e-06,
      "loss": 0.0728,
      "step": 9156
    },
    {
      "epoch": 0.14498788732840381,
      "grad_norm": 0.0038331956602633,
      "learning_rate": 8.550121126715962e-06,
      "loss": 0.0002,
      "step": 9157
    },
    {
      "epoch": 0.14500372088604588,
      "grad_norm": 0.2448558658361435,
      "learning_rate": 8.549962791139542e-06,
      "loss": 0.1565,
      "step": 9158
    },
    {
      "epoch": 0.14501955444368794,
      "grad_norm": 0.28270721435546875,
      "learning_rate": 8.549804455563122e-06,
      "loss": 0.3398,
      "step": 9159
    },
    {
      "epoch": 0.14503538800133,
      "grad_norm": 0.22829094529151917,
      "learning_rate": 8.5496461199867e-06,
      "loss": 0.0128,
      "step": 9160
    },
    {
      "epoch": 0.1450512215589721,
      "grad_norm": 0.20590248703956604,
      "learning_rate": 8.54948778441028e-06,
      "loss": 0.0073,
      "step": 9161
    },
    {
      "epoch": 0.14506705511661416,
      "grad_norm": 0.44203072786331177,
      "learning_rate": 8.54932944883386e-06,
      "loss": 0.59,
      "step": 9162
    },
    {
      "epoch": 0.14508288867425623,
      "grad_norm": 0.15885378420352936,
      "learning_rate": 8.549171113257438e-06,
      "loss": 0.0203,
      "step": 9163
    },
    {
      "epoch": 0.1450987222318983,
      "grad_norm": 0.19035638868808746,
      "learning_rate": 8.549012777681019e-06,
      "loss": 0.0756,
      "step": 9164
    },
    {
      "epoch": 0.14511455578954036,
      "grad_norm": 0.43025779724121094,
      "learning_rate": 8.548854442104598e-06,
      "loss": 0.132,
      "step": 9165
    },
    {
      "epoch": 0.14513038934718242,
      "grad_norm": 0.0311154592782259,
      "learning_rate": 8.548696106528177e-06,
      "loss": 0.0022,
      "step": 9166
    },
    {
      "epoch": 0.14514622290482448,
      "grad_norm": 0.26188376545906067,
      "learning_rate": 8.548537770951756e-06,
      "loss": 0.0601,
      "step": 9167
    },
    {
      "epoch": 0.14516205646246655,
      "grad_norm": 0.27403679490089417,
      "learning_rate": 8.548379435375335e-06,
      "loss": 0.0411,
      "step": 9168
    },
    {
      "epoch": 0.1451778900201086,
      "grad_norm": 0.3835780620574951,
      "learning_rate": 8.548221099798914e-06,
      "loss": 0.1723,
      "step": 9169
    },
    {
      "epoch": 0.14519372357775068,
      "grad_norm": 0.01594562456011772,
      "learning_rate": 8.548062764222493e-06,
      "loss": 0.001,
      "step": 9170
    },
    {
      "epoch": 0.14520955713539274,
      "grad_norm": 0.017912106588482857,
      "learning_rate": 8.547904428646074e-06,
      "loss": 0.001,
      "step": 9171
    },
    {
      "epoch": 0.1452253906930348,
      "grad_norm": 0.23436230421066284,
      "learning_rate": 8.547746093069651e-06,
      "loss": 0.0827,
      "step": 9172
    },
    {
      "epoch": 0.1452412242506769,
      "grad_norm": 0.35215938091278076,
      "learning_rate": 8.547587757493232e-06,
      "loss": 0.1986,
      "step": 9173
    },
    {
      "epoch": 0.14525705780831896,
      "grad_norm": 0.31817254424095154,
      "learning_rate": 8.547429421916811e-06,
      "loss": 0.2141,
      "step": 9174
    },
    {
      "epoch": 0.14527289136596103,
      "grad_norm": 0.3363484740257263,
      "learning_rate": 8.54727108634039e-06,
      "loss": 0.4795,
      "step": 9175
    },
    {
      "epoch": 0.1452887249236031,
      "grad_norm": 0.000732608197722584,
      "learning_rate": 8.54711275076397e-06,
      "loss": 0.0,
      "step": 9176
    },
    {
      "epoch": 0.14530455848124516,
      "grad_norm": 0.28481364250183105,
      "learning_rate": 8.54695441518755e-06,
      "loss": 0.0736,
      "step": 9177
    },
    {
      "epoch": 0.14532039203888722,
      "grad_norm": 0.2016993910074234,
      "learning_rate": 8.546796079611127e-06,
      "loss": 0.0735,
      "step": 9178
    },
    {
      "epoch": 0.14533622559652928,
      "grad_norm": 0.4254591763019562,
      "learning_rate": 8.546637744034708e-06,
      "loss": 0.3697,
      "step": 9179
    },
    {
      "epoch": 0.14535205915417135,
      "grad_norm": 0.4533807933330536,
      "learning_rate": 8.546479408458287e-06,
      "loss": 0.329,
      "step": 9180
    },
    {
      "epoch": 0.1453678927118134,
      "grad_norm": 0.3206149637699127,
      "learning_rate": 8.546321072881866e-06,
      "loss": 0.1218,
      "step": 9181
    },
    {
      "epoch": 0.14538372626945548,
      "grad_norm": 0.2110709697008133,
      "learning_rate": 8.546162737305445e-06,
      "loss": 0.1204,
      "step": 9182
    },
    {
      "epoch": 0.14539955982709754,
      "grad_norm": 0.528695285320282,
      "learning_rate": 8.546004401729026e-06,
      "loss": 0.0181,
      "step": 9183
    },
    {
      "epoch": 0.1454153933847396,
      "grad_norm": 0.37736254930496216,
      "learning_rate": 8.545846066152604e-06,
      "loss": 0.1493,
      "step": 9184
    },
    {
      "epoch": 0.1454312269423817,
      "grad_norm": 0.008181310258805752,
      "learning_rate": 8.545687730576184e-06,
      "loss": 0.0009,
      "step": 9185
    },
    {
      "epoch": 0.14544706050002376,
      "grad_norm": 0.4600367546081543,
      "learning_rate": 8.545529394999763e-06,
      "loss": 0.1964,
      "step": 9186
    },
    {
      "epoch": 0.14546289405766583,
      "grad_norm": 0.21180421113967896,
      "learning_rate": 8.545371059423343e-06,
      "loss": 0.0302,
      "step": 9187
    },
    {
      "epoch": 0.1454787276153079,
      "grad_norm": 0.47827616333961487,
      "learning_rate": 8.545212723846922e-06,
      "loss": 0.568,
      "step": 9188
    },
    {
      "epoch": 0.14549456117294995,
      "grad_norm": 0.5112835764884949,
      "learning_rate": 8.545054388270502e-06,
      "loss": 0.1593,
      "step": 9189
    },
    {
      "epoch": 0.14551039473059202,
      "grad_norm": 0.36287474632263184,
      "learning_rate": 8.54489605269408e-06,
      "loss": 0.5046,
      "step": 9190
    },
    {
      "epoch": 0.14552622828823408,
      "grad_norm": 0.2806762754917145,
      "learning_rate": 8.544737717117659e-06,
      "loss": 0.1282,
      "step": 9191
    },
    {
      "epoch": 0.14554206184587615,
      "grad_norm": 0.16884878277778625,
      "learning_rate": 8.54457938154124e-06,
      "loss": 0.0588,
      "step": 9192
    },
    {
      "epoch": 0.1455578954035182,
      "grad_norm": 0.1542900800704956,
      "learning_rate": 8.544421045964819e-06,
      "loss": 0.0309,
      "step": 9193
    },
    {
      "epoch": 0.14557372896116028,
      "grad_norm": 0.3302308917045593,
      "learning_rate": 8.544262710388398e-06,
      "loss": 0.1161,
      "step": 9194
    },
    {
      "epoch": 0.14558956251880234,
      "grad_norm": 0.2472769021987915,
      "learning_rate": 8.544104374811977e-06,
      "loss": 0.0858,
      "step": 9195
    },
    {
      "epoch": 0.1456053960764444,
      "grad_norm": 0.0023770048283040524,
      "learning_rate": 8.543946039235556e-06,
      "loss": 0.0,
      "step": 9196
    },
    {
      "epoch": 0.1456212296340865,
      "grad_norm": 0.01337000634521246,
      "learning_rate": 8.543787703659135e-06,
      "loss": 0.0009,
      "step": 9197
    },
    {
      "epoch": 0.14563706319172856,
      "grad_norm": 0.17838622629642487,
      "learning_rate": 8.543629368082716e-06,
      "loss": 0.0364,
      "step": 9198
    },
    {
      "epoch": 0.14565289674937063,
      "grad_norm": 0.009460347704589367,
      "learning_rate": 8.543471032506295e-06,
      "loss": 0.0005,
      "step": 9199
    },
    {
      "epoch": 0.1456687303070127,
      "grad_norm": 0.00015198119217529893,
      "learning_rate": 8.543312696929874e-06,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 0.14568456386465475,
      "grad_norm": 0.4443223476409912,
      "learning_rate": 8.543154361353453e-06,
      "loss": 0.064,
      "step": 9201
    },
    {
      "epoch": 0.14570039742229682,
      "grad_norm": 0.2106798142194748,
      "learning_rate": 8.542996025777032e-06,
      "loss": 0.0614,
      "step": 9202
    },
    {
      "epoch": 0.14571623097993888,
      "grad_norm": 0.41566917300224304,
      "learning_rate": 8.542837690200611e-06,
      "loss": 0.1612,
      "step": 9203
    },
    {
      "epoch": 0.14573206453758095,
      "grad_norm": 0.004266907926648855,
      "learning_rate": 8.542679354624192e-06,
      "loss": 0.0002,
      "step": 9204
    },
    {
      "epoch": 0.145747898095223,
      "grad_norm": 0.14082922041416168,
      "learning_rate": 8.542521019047771e-06,
      "loss": 0.073,
      "step": 9205
    },
    {
      "epoch": 0.14576373165286508,
      "grad_norm": 0.27795878052711487,
      "learning_rate": 8.54236268347135e-06,
      "loss": 0.2649,
      "step": 9206
    },
    {
      "epoch": 0.14577956521050714,
      "grad_norm": 0.3525439500808716,
      "learning_rate": 8.54220434789493e-06,
      "loss": 0.2308,
      "step": 9207
    },
    {
      "epoch": 0.1457953987681492,
      "grad_norm": 0.30768123269081116,
      "learning_rate": 8.542046012318508e-06,
      "loss": 0.106,
      "step": 9208
    },
    {
      "epoch": 0.1458112323257913,
      "grad_norm": 0.4885304570198059,
      "learning_rate": 8.541887676742087e-06,
      "loss": 0.1574,
      "step": 9209
    },
    {
      "epoch": 0.14582706588343336,
      "grad_norm": 0.297366201877594,
      "learning_rate": 8.541729341165668e-06,
      "loss": 0.3875,
      "step": 9210
    },
    {
      "epoch": 0.14584289944107542,
      "grad_norm": 4.215587615966797,
      "learning_rate": 8.541571005589247e-06,
      "loss": 0.3279,
      "step": 9211
    },
    {
      "epoch": 0.1458587329987175,
      "grad_norm": 0.6494393348693848,
      "learning_rate": 8.541412670012826e-06,
      "loss": 0.4406,
      "step": 9212
    },
    {
      "epoch": 0.14587456655635955,
      "grad_norm": 0.00027687876718118787,
      "learning_rate": 8.541254334436405e-06,
      "loss": 0.0,
      "step": 9213
    },
    {
      "epoch": 0.14589040011400162,
      "grad_norm": 0.13146059215068817,
      "learning_rate": 8.541095998859984e-06,
      "loss": 0.026,
      "step": 9214
    },
    {
      "epoch": 0.14590623367164368,
      "grad_norm": 0.0002068928733933717,
      "learning_rate": 8.540937663283564e-06,
      "loss": 0.0,
      "step": 9215
    },
    {
      "epoch": 0.14592206722928575,
      "grad_norm": 0.28604206442832947,
      "learning_rate": 8.540779327707143e-06,
      "loss": 0.115,
      "step": 9216
    },
    {
      "epoch": 0.1459379007869278,
      "grad_norm": 0.0007969794678501785,
      "learning_rate": 8.540620992130723e-06,
      "loss": 0.0,
      "step": 9217
    },
    {
      "epoch": 0.14595373434456987,
      "grad_norm": 0.01585329696536064,
      "learning_rate": 8.5404626565543e-06,
      "loss": 0.0009,
      "step": 9218
    },
    {
      "epoch": 0.14596956790221194,
      "grad_norm": 0.4374774694442749,
      "learning_rate": 8.540304320977882e-06,
      "loss": 0.2639,
      "step": 9219
    },
    {
      "epoch": 0.145985401459854,
      "grad_norm": 0.428268700838089,
      "learning_rate": 8.54014598540146e-06,
      "loss": 0.206,
      "step": 9220
    },
    {
      "epoch": 0.1460012350174961,
      "grad_norm": 0.4604741930961609,
      "learning_rate": 8.53998764982504e-06,
      "loss": 0.2243,
      "step": 9221
    },
    {
      "epoch": 0.14601706857513816,
      "grad_norm": 0.34845924377441406,
      "learning_rate": 8.539829314248619e-06,
      "loss": 0.3333,
      "step": 9222
    },
    {
      "epoch": 0.14603290213278022,
      "grad_norm": 0.0031805280596017838,
      "learning_rate": 8.5396709786722e-06,
      "loss": 0.0001,
      "step": 9223
    },
    {
      "epoch": 0.1460487356904223,
      "grad_norm": 0.270304411649704,
      "learning_rate": 8.539512643095777e-06,
      "loss": 0.0889,
      "step": 9224
    },
    {
      "epoch": 0.14606456924806435,
      "grad_norm": 0.33509591221809387,
      "learning_rate": 8.539354307519358e-06,
      "loss": 0.6538,
      "step": 9225
    },
    {
      "epoch": 0.14608040280570642,
      "grad_norm": 0.36470285058021545,
      "learning_rate": 8.539195971942937e-06,
      "loss": 0.1073,
      "step": 9226
    },
    {
      "epoch": 0.14609623636334848,
      "grad_norm": 0.22888311743736267,
      "learning_rate": 8.539037636366516e-06,
      "loss": 0.0603,
      "step": 9227
    },
    {
      "epoch": 0.14611206992099054,
      "grad_norm": 0.00014577257388737053,
      "learning_rate": 8.538879300790095e-06,
      "loss": 0.0,
      "step": 9228
    },
    {
      "epoch": 0.1461279034786326,
      "grad_norm": 0.10399933159351349,
      "learning_rate": 8.538720965213676e-06,
      "loss": 0.0011,
      "step": 9229
    },
    {
      "epoch": 0.14614373703627467,
      "grad_norm": 0.004027603659778833,
      "learning_rate": 8.538562629637253e-06,
      "loss": 0.0002,
      "step": 9230
    },
    {
      "epoch": 0.14615957059391674,
      "grad_norm": 0.16703352332115173,
      "learning_rate": 8.538404294060834e-06,
      "loss": 0.0275,
      "step": 9231
    },
    {
      "epoch": 0.1461754041515588,
      "grad_norm": 0.29989093542099,
      "learning_rate": 8.538245958484413e-06,
      "loss": 0.0826,
      "step": 9232
    },
    {
      "epoch": 0.1461912377092009,
      "grad_norm": 0.5669390559196472,
      "learning_rate": 8.538087622907992e-06,
      "loss": 0.0635,
      "step": 9233
    },
    {
      "epoch": 0.14620707126684296,
      "grad_norm": 0.46953970193862915,
      "learning_rate": 8.537929287331571e-06,
      "loss": 0.1512,
      "step": 9234
    },
    {
      "epoch": 0.14622290482448502,
      "grad_norm": 0.00031951250275596976,
      "learning_rate": 8.53777095175515e-06,
      "loss": 0.0,
      "step": 9235
    },
    {
      "epoch": 0.1462387383821271,
      "grad_norm": 0.00015788206655997783,
      "learning_rate": 8.53761261617873e-06,
      "loss": 0.0,
      "step": 9236
    },
    {
      "epoch": 0.14625457193976915,
      "grad_norm": 0.00018621129856910557,
      "learning_rate": 8.53745428060231e-06,
      "loss": 0.0,
      "step": 9237
    },
    {
      "epoch": 0.14627040549741122,
      "grad_norm": 0.2916978895664215,
      "learning_rate": 8.537295945025889e-06,
      "loss": 0.3367,
      "step": 9238
    },
    {
      "epoch": 0.14628623905505328,
      "grad_norm": 0.42223912477493286,
      "learning_rate": 8.537137609449467e-06,
      "loss": 0.1786,
      "step": 9239
    },
    {
      "epoch": 0.14630207261269534,
      "grad_norm": 1.0151183605194092,
      "learning_rate": 8.536979273873047e-06,
      "loss": 0.4474,
      "step": 9240
    },
    {
      "epoch": 0.1463179061703374,
      "grad_norm": 0.30684801936149597,
      "learning_rate": 8.536820938296626e-06,
      "loss": 0.0444,
      "step": 9241
    },
    {
      "epoch": 0.14633373972797947,
      "grad_norm": 0.5874526500701904,
      "learning_rate": 8.536662602720205e-06,
      "loss": 0.6094,
      "step": 9242
    },
    {
      "epoch": 0.14634957328562154,
      "grad_norm": 0.47395944595336914,
      "learning_rate": 8.536504267143785e-06,
      "loss": 0.1248,
      "step": 9243
    },
    {
      "epoch": 0.1463654068432636,
      "grad_norm": 0.42605748772621155,
      "learning_rate": 8.536345931567365e-06,
      "loss": 0.0725,
      "step": 9244
    },
    {
      "epoch": 0.1463812404009057,
      "grad_norm": 0.3022406995296478,
      "learning_rate": 8.536187595990943e-06,
      "loss": 0.1854,
      "step": 9245
    },
    {
      "epoch": 0.14639707395854776,
      "grad_norm": 0.024388112127780914,
      "learning_rate": 8.536029260414523e-06,
      "loss": 0.0016,
      "step": 9246
    },
    {
      "epoch": 0.14641290751618982,
      "grad_norm": 0.36162275075912476,
      "learning_rate": 8.535870924838103e-06,
      "loss": 0.2053,
      "step": 9247
    },
    {
      "epoch": 0.1464287410738319,
      "grad_norm": 0.19540727138519287,
      "learning_rate": 8.535712589261682e-06,
      "loss": 0.0817,
      "step": 9248
    },
    {
      "epoch": 0.14644457463147395,
      "grad_norm": 0.6352049112319946,
      "learning_rate": 8.53555425368526e-06,
      "loss": 0.809,
      "step": 9249
    },
    {
      "epoch": 0.14646040818911601,
      "grad_norm": 0.022122956812381744,
      "learning_rate": 8.535395918108841e-06,
      "loss": 0.0011,
      "step": 9250
    },
    {
      "epoch": 0.14647624174675808,
      "grad_norm": 0.4705062508583069,
      "learning_rate": 8.535237582532419e-06,
      "loss": 0.0827,
      "step": 9251
    },
    {
      "epoch": 0.14649207530440014,
      "grad_norm": 0.5066726803779602,
      "learning_rate": 8.535079246956e-06,
      "loss": 0.5275,
      "step": 9252
    },
    {
      "epoch": 0.1465079088620422,
      "grad_norm": 0.00014570532948710024,
      "learning_rate": 8.534920911379579e-06,
      "loss": 0.0,
      "step": 9253
    },
    {
      "epoch": 0.14652374241968427,
      "grad_norm": 0.004036732483655214,
      "learning_rate": 8.534762575803158e-06,
      "loss": 0.0002,
      "step": 9254
    },
    {
      "epoch": 0.14653957597732634,
      "grad_norm": 0.0017801738576963544,
      "learning_rate": 8.534604240226737e-06,
      "loss": 0.0,
      "step": 9255
    },
    {
      "epoch": 0.1465554095349684,
      "grad_norm": 0.007895593531429768,
      "learning_rate": 8.534445904650318e-06,
      "loss": 0.0003,
      "step": 9256
    },
    {
      "epoch": 0.14657124309261046,
      "grad_norm": 0.3920479714870453,
      "learning_rate": 8.534287569073895e-06,
      "loss": 0.1269,
      "step": 9257
    },
    {
      "epoch": 0.14658707665025256,
      "grad_norm": 0.5730164647102356,
      "learning_rate": 8.534129233497476e-06,
      "loss": 0.676,
      "step": 9258
    },
    {
      "epoch": 0.14660291020789462,
      "grad_norm": 0.17530880868434906,
      "learning_rate": 8.533970897921055e-06,
      "loss": 0.0807,
      "step": 9259
    },
    {
      "epoch": 0.14661874376553669,
      "grad_norm": 0.6245999336242676,
      "learning_rate": 8.533812562344634e-06,
      "loss": 0.9788,
      "step": 9260
    },
    {
      "epoch": 0.14663457732317875,
      "grad_norm": 0.6758704781532288,
      "learning_rate": 8.533654226768213e-06,
      "loss": 0.39,
      "step": 9261
    },
    {
      "epoch": 0.14665041088082081,
      "grad_norm": 0.03919687867164612,
      "learning_rate": 8.533495891191794e-06,
      "loss": 0.0057,
      "step": 9262
    },
    {
      "epoch": 0.14666624443846288,
      "grad_norm": 0.9017934799194336,
      "learning_rate": 8.533337555615371e-06,
      "loss": 0.0906,
      "step": 9263
    },
    {
      "epoch": 0.14668207799610494,
      "grad_norm": 0.44843146204948425,
      "learning_rate": 8.53317922003895e-06,
      "loss": 0.3738,
      "step": 9264
    },
    {
      "epoch": 0.146697911553747,
      "grad_norm": 0.376693457365036,
      "learning_rate": 8.533020884462531e-06,
      "loss": 0.0809,
      "step": 9265
    },
    {
      "epoch": 0.14671374511138907,
      "grad_norm": 0.31851980090141296,
      "learning_rate": 8.53286254888611e-06,
      "loss": 0.2504,
      "step": 9266
    },
    {
      "epoch": 0.14672957866903114,
      "grad_norm": 0.8561971783638,
      "learning_rate": 8.53270421330969e-06,
      "loss": 0.3548,
      "step": 9267
    },
    {
      "epoch": 0.1467454122266732,
      "grad_norm": 0.30709245800971985,
      "learning_rate": 8.532545877733268e-06,
      "loss": 0.1081,
      "step": 9268
    },
    {
      "epoch": 0.14676124578431526,
      "grad_norm": 0.3553861677646637,
      "learning_rate": 8.532387542156847e-06,
      "loss": 0.188,
      "step": 9269
    },
    {
      "epoch": 0.14677707934195736,
      "grad_norm": 0.2650049328804016,
      "learning_rate": 8.532229206580426e-06,
      "loss": 0.0702,
      "step": 9270
    },
    {
      "epoch": 0.14679291289959942,
      "grad_norm": 0.00011424611147958785,
      "learning_rate": 8.532070871004007e-06,
      "loss": 0.0,
      "step": 9271
    },
    {
      "epoch": 0.14680874645724148,
      "grad_norm": 0.26355987787246704,
      "learning_rate": 8.531912535427586e-06,
      "loss": 0.0215,
      "step": 9272
    },
    {
      "epoch": 0.14682458001488355,
      "grad_norm": 0.34779730439186096,
      "learning_rate": 8.531754199851165e-06,
      "loss": 0.156,
      "step": 9273
    },
    {
      "epoch": 0.1468404135725256,
      "grad_norm": 0.43695858120918274,
      "learning_rate": 8.531595864274744e-06,
      "loss": 0.2517,
      "step": 9274
    },
    {
      "epoch": 0.14685624713016768,
      "grad_norm": 0.7023575901985168,
      "learning_rate": 8.531437528698324e-06,
      "loss": 0.3398,
      "step": 9275
    },
    {
      "epoch": 0.14687208068780974,
      "grad_norm": 0.4729529023170471,
      "learning_rate": 8.531279193121903e-06,
      "loss": 0.5758,
      "step": 9276
    },
    {
      "epoch": 0.1468879142454518,
      "grad_norm": 0.010227545164525509,
      "learning_rate": 8.531120857545483e-06,
      "loss": 0.0004,
      "step": 9277
    },
    {
      "epoch": 0.14690374780309387,
      "grad_norm": 0.00020367470278870314,
      "learning_rate": 8.530962521969062e-06,
      "loss": 0.0,
      "step": 9278
    },
    {
      "epoch": 0.14691958136073593,
      "grad_norm": 0.38522136211395264,
      "learning_rate": 8.530804186392642e-06,
      "loss": 0.4708,
      "step": 9279
    },
    {
      "epoch": 0.146935414918378,
      "grad_norm": 6.2206519942265e-05,
      "learning_rate": 8.53064585081622e-06,
      "loss": 0.0,
      "step": 9280
    },
    {
      "epoch": 0.14695124847602006,
      "grad_norm": 0.024963224306702614,
      "learning_rate": 8.5304875152398e-06,
      "loss": 0.0018,
      "step": 9281
    },
    {
      "epoch": 0.14696708203366216,
      "grad_norm": 0.00011543637083377689,
      "learning_rate": 8.530329179663379e-06,
      "loss": 0.0,
      "step": 9282
    },
    {
      "epoch": 0.14698291559130422,
      "grad_norm": 0.4953942894935608,
      "learning_rate": 8.53017084408696e-06,
      "loss": 0.0737,
      "step": 9283
    },
    {
      "epoch": 0.14699874914894628,
      "grad_norm": 0.16455133259296417,
      "learning_rate": 8.530012508510539e-06,
      "loss": 0.0539,
      "step": 9284
    },
    {
      "epoch": 0.14701458270658835,
      "grad_norm": 0.1527927815914154,
      "learning_rate": 8.529854172934118e-06,
      "loss": 0.0736,
      "step": 9285
    },
    {
      "epoch": 0.1470304162642304,
      "grad_norm": 0.012182584963738918,
      "learning_rate": 8.529695837357697e-06,
      "loss": 0.0007,
      "step": 9286
    },
    {
      "epoch": 0.14704624982187248,
      "grad_norm": 0.34984251856803894,
      "learning_rate": 8.529537501781276e-06,
      "loss": 0.1044,
      "step": 9287
    },
    {
      "epoch": 0.14706208337951454,
      "grad_norm": 0.017878646031022072,
      "learning_rate": 8.529379166204855e-06,
      "loss": 0.0009,
      "step": 9288
    },
    {
      "epoch": 0.1470779169371566,
      "grad_norm": 0.1766636222600937,
      "learning_rate": 8.529220830628434e-06,
      "loss": 0.0958,
      "step": 9289
    },
    {
      "epoch": 0.14709375049479867,
      "grad_norm": 0.1422424614429474,
      "learning_rate": 8.529062495052015e-06,
      "loss": 0.0436,
      "step": 9290
    },
    {
      "epoch": 0.14710958405244073,
      "grad_norm": 0.3463476598262787,
      "learning_rate": 8.528904159475592e-06,
      "loss": 0.0963,
      "step": 9291
    },
    {
      "epoch": 0.1471254176100828,
      "grad_norm": 0.17959950864315033,
      "learning_rate": 8.528745823899173e-06,
      "loss": 0.069,
      "step": 9292
    },
    {
      "epoch": 0.14714125116772486,
      "grad_norm": 0.4836551249027252,
      "learning_rate": 8.528587488322752e-06,
      "loss": 0.7447,
      "step": 9293
    },
    {
      "epoch": 0.14715708472536695,
      "grad_norm": 0.5840476751327515,
      "learning_rate": 8.528429152746331e-06,
      "loss": 0.4699,
      "step": 9294
    },
    {
      "epoch": 0.14717291828300902,
      "grad_norm": 0.30948686599731445,
      "learning_rate": 8.52827081716991e-06,
      "loss": 0.1512,
      "step": 9295
    },
    {
      "epoch": 0.14718875184065108,
      "grad_norm": 0.00042706989916041493,
      "learning_rate": 8.528112481593491e-06,
      "loss": 0.0,
      "step": 9296
    },
    {
      "epoch": 0.14720458539829315,
      "grad_norm": 0.11605749279260635,
      "learning_rate": 8.527954146017068e-06,
      "loss": 0.016,
      "step": 9297
    },
    {
      "epoch": 0.1472204189559352,
      "grad_norm": 0.44223350286483765,
      "learning_rate": 8.527795810440649e-06,
      "loss": 0.1524,
      "step": 9298
    },
    {
      "epoch": 0.14723625251357728,
      "grad_norm": 0.5644991397857666,
      "learning_rate": 8.527637474864228e-06,
      "loss": 0.1715,
      "step": 9299
    },
    {
      "epoch": 0.14725208607121934,
      "grad_norm": 0.057059500366449356,
      "learning_rate": 8.527479139287807e-06,
      "loss": 0.0041,
      "step": 9300
    },
    {
      "epoch": 0.1472679196288614,
      "grad_norm": 0.013095634989440441,
      "learning_rate": 8.527320803711386e-06,
      "loss": 0.0008,
      "step": 9301
    },
    {
      "epoch": 0.14728375318650347,
      "grad_norm": 0.4750117063522339,
      "learning_rate": 8.527162468134965e-06,
      "loss": 0.1701,
      "step": 9302
    },
    {
      "epoch": 0.14729958674414553,
      "grad_norm": 0.025904763489961624,
      "learning_rate": 8.527004132558545e-06,
      "loss": 0.0016,
      "step": 9303
    },
    {
      "epoch": 0.1473154203017876,
      "grad_norm": 0.34684330224990845,
      "learning_rate": 8.526845796982125e-06,
      "loss": 0.2728,
      "step": 9304
    },
    {
      "epoch": 0.14733125385942966,
      "grad_norm": 0.11837448924779892,
      "learning_rate": 8.526687461405704e-06,
      "loss": 0.0364,
      "step": 9305
    },
    {
      "epoch": 0.14734708741707175,
      "grad_norm": 0.01240354310721159,
      "learning_rate": 8.526529125829283e-06,
      "loss": 0.0007,
      "step": 9306
    },
    {
      "epoch": 0.14736292097471382,
      "grad_norm": 0.6136541366577148,
      "learning_rate": 8.526370790252863e-06,
      "loss": 0.1558,
      "step": 9307
    },
    {
      "epoch": 0.14737875453235588,
      "grad_norm": 0.2534060776233673,
      "learning_rate": 8.526212454676442e-06,
      "loss": 0.0664,
      "step": 9308
    },
    {
      "epoch": 0.14739458808999795,
      "grad_norm": 0.019126279279589653,
      "learning_rate": 8.52605411910002e-06,
      "loss": 0.0018,
      "step": 9309
    },
    {
      "epoch": 0.14741042164764,
      "grad_norm": 0.3313104212284088,
      "learning_rate": 8.525895783523601e-06,
      "loss": 0.2394,
      "step": 9310
    },
    {
      "epoch": 0.14742625520528208,
      "grad_norm": 0.6360530853271484,
      "learning_rate": 8.52573744794718e-06,
      "loss": 0.1877,
      "step": 9311
    },
    {
      "epoch": 0.14744208876292414,
      "grad_norm": 0.45387861132621765,
      "learning_rate": 8.525579112370758e-06,
      "loss": 0.0739,
      "step": 9312
    },
    {
      "epoch": 0.1474579223205662,
      "grad_norm": 0.784163236618042,
      "learning_rate": 8.525420776794339e-06,
      "loss": 0.1882,
      "step": 9313
    },
    {
      "epoch": 0.14747375587820827,
      "grad_norm": 0.32380199432373047,
      "learning_rate": 8.525262441217918e-06,
      "loss": 0.2169,
      "step": 9314
    },
    {
      "epoch": 0.14748958943585033,
      "grad_norm": 0.00016967715055216104,
      "learning_rate": 8.525104105641497e-06,
      "loss": 0.0,
      "step": 9315
    },
    {
      "epoch": 0.1475054229934924,
      "grad_norm": 3.4228971004486084,
      "learning_rate": 8.524945770065076e-06,
      "loss": 0.0443,
      "step": 9316
    },
    {
      "epoch": 0.14752125655113446,
      "grad_norm": 0.39192134141921997,
      "learning_rate": 8.524787434488657e-06,
      "loss": 0.1556,
      "step": 9317
    },
    {
      "epoch": 0.14753709010877655,
      "grad_norm": 0.012310739606618881,
      "learning_rate": 8.524629098912234e-06,
      "loss": 0.0005,
      "step": 9318
    },
    {
      "epoch": 0.14755292366641862,
      "grad_norm": 0.26970168948173523,
      "learning_rate": 8.524470763335815e-06,
      "loss": 0.1538,
      "step": 9319
    },
    {
      "epoch": 0.14756875722406068,
      "grad_norm": 0.0015425195451825857,
      "learning_rate": 8.524312427759394e-06,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 0.14758459078170275,
      "grad_norm": 0.0003106785879936069,
      "learning_rate": 8.524154092182973e-06,
      "loss": 0.0,
      "step": 9321
    },
    {
      "epoch": 0.1476004243393448,
      "grad_norm": 0.9096407294273376,
      "learning_rate": 8.523995756606552e-06,
      "loss": 0.4585,
      "step": 9322
    },
    {
      "epoch": 0.14761625789698687,
      "grad_norm": 0.3924899101257324,
      "learning_rate": 8.523837421030133e-06,
      "loss": 0.5858,
      "step": 9323
    },
    {
      "epoch": 0.14763209145462894,
      "grad_norm": 0.17042912542819977,
      "learning_rate": 8.52367908545371e-06,
      "loss": 0.0614,
      "step": 9324
    },
    {
      "epoch": 0.147647925012271,
      "grad_norm": 0.007233386393636465,
      "learning_rate": 8.523520749877291e-06,
      "loss": 0.0003,
      "step": 9325
    },
    {
      "epoch": 0.14766375856991307,
      "grad_norm": 0.008520866744220257,
      "learning_rate": 8.52336241430087e-06,
      "loss": 0.0004,
      "step": 9326
    },
    {
      "epoch": 0.14767959212755513,
      "grad_norm": 0.5173506736755371,
      "learning_rate": 8.52320407872445e-06,
      "loss": 0.1074,
      "step": 9327
    },
    {
      "epoch": 0.1476954256851972,
      "grad_norm": 0.5284673571586609,
      "learning_rate": 8.523045743148028e-06,
      "loss": 0.1769,
      "step": 9328
    },
    {
      "epoch": 0.14771125924283926,
      "grad_norm": 0.17405064404010773,
      "learning_rate": 8.522887407571609e-06,
      "loss": 0.0701,
      "step": 9329
    },
    {
      "epoch": 0.14772709280048135,
      "grad_norm": 0.26236099004745483,
      "learning_rate": 8.522729071995186e-06,
      "loss": 0.0925,
      "step": 9330
    },
    {
      "epoch": 0.14774292635812342,
      "grad_norm": 0.6050006151199341,
      "learning_rate": 8.522570736418767e-06,
      "loss": 0.1408,
      "step": 9331
    },
    {
      "epoch": 0.14775875991576548,
      "grad_norm": 0.0062418244779109955,
      "learning_rate": 8.522412400842346e-06,
      "loss": 0.0003,
      "step": 9332
    },
    {
      "epoch": 0.14777459347340755,
      "grad_norm": 0.03038126975297928,
      "learning_rate": 8.522254065265925e-06,
      "loss": 0.0006,
      "step": 9333
    },
    {
      "epoch": 0.1477904270310496,
      "grad_norm": 0.2816833555698395,
      "learning_rate": 8.522095729689504e-06,
      "loss": 0.1727,
      "step": 9334
    },
    {
      "epoch": 0.14780626058869167,
      "grad_norm": 0.24738924205303192,
      "learning_rate": 8.521937394113085e-06,
      "loss": 0.1024,
      "step": 9335
    },
    {
      "epoch": 0.14782209414633374,
      "grad_norm": 0.011304027400910854,
      "learning_rate": 8.521779058536663e-06,
      "loss": 0.0005,
      "step": 9336
    },
    {
      "epoch": 0.1478379277039758,
      "grad_norm": 0.679411768913269,
      "learning_rate": 8.521620722960242e-06,
      "loss": 0.1461,
      "step": 9337
    },
    {
      "epoch": 0.14785376126161787,
      "grad_norm": 0.014142312109470367,
      "learning_rate": 8.521462387383822e-06,
      "loss": 0.0006,
      "step": 9338
    },
    {
      "epoch": 0.14786959481925993,
      "grad_norm": 0.8558640480041504,
      "learning_rate": 8.521304051807402e-06,
      "loss": 0.2918,
      "step": 9339
    },
    {
      "epoch": 0.147885428376902,
      "grad_norm": 0.511439323425293,
      "learning_rate": 8.52114571623098e-06,
      "loss": 0.5512,
      "step": 9340
    },
    {
      "epoch": 0.14790126193454406,
      "grad_norm": 0.41486236453056335,
      "learning_rate": 8.52098738065456e-06,
      "loss": 0.1383,
      "step": 9341
    },
    {
      "epoch": 0.14791709549218615,
      "grad_norm": 0.0011767663527280092,
      "learning_rate": 8.520829045078139e-06,
      "loss": 0.0,
      "step": 9342
    },
    {
      "epoch": 0.14793292904982822,
      "grad_norm": 0.03375423699617386,
      "learning_rate": 8.520670709501718e-06,
      "loss": 0.0021,
      "step": 9343
    },
    {
      "epoch": 0.14794876260747028,
      "grad_norm": 0.00959243904799223,
      "learning_rate": 8.520512373925299e-06,
      "loss": 0.0005,
      "step": 9344
    },
    {
      "epoch": 0.14796459616511234,
      "grad_norm": 0.00051031110342592,
      "learning_rate": 8.520354038348878e-06,
      "loss": 0.0,
      "step": 9345
    },
    {
      "epoch": 0.1479804297227544,
      "grad_norm": 0.6344172358512878,
      "learning_rate": 8.520195702772457e-06,
      "loss": 0.3783,
      "step": 9346
    },
    {
      "epoch": 0.14799626328039647,
      "grad_norm": 0.019347980618476868,
      "learning_rate": 8.520037367196036e-06,
      "loss": 0.001,
      "step": 9347
    },
    {
      "epoch": 0.14801209683803854,
      "grad_norm": 0.4780244827270508,
      "learning_rate": 8.519879031619615e-06,
      "loss": 0.309,
      "step": 9348
    },
    {
      "epoch": 0.1480279303956806,
      "grad_norm": 0.40628400444984436,
      "learning_rate": 8.519720696043194e-06,
      "loss": 0.1917,
      "step": 9349
    },
    {
      "epoch": 0.14804376395332267,
      "grad_norm": 0.4622343182563782,
      "learning_rate": 8.519562360466775e-06,
      "loss": 0.167,
      "step": 9350
    },
    {
      "epoch": 0.14805959751096473,
      "grad_norm": 0.1353146731853485,
      "learning_rate": 8.519404024890354e-06,
      "loss": 0.0586,
      "step": 9351
    },
    {
      "epoch": 0.1480754310686068,
      "grad_norm": 0.004486498422920704,
      "learning_rate": 8.519245689313933e-06,
      "loss": 0.0001,
      "step": 9352
    },
    {
      "epoch": 0.14809126462624886,
      "grad_norm": 0.032860662788152695,
      "learning_rate": 8.519087353737512e-06,
      "loss": 0.0018,
      "step": 9353
    },
    {
      "epoch": 0.14810709818389095,
      "grad_norm": 0.00023164924641605467,
      "learning_rate": 8.518929018161091e-06,
      "loss": 0.0,
      "step": 9354
    },
    {
      "epoch": 0.14812293174153301,
      "grad_norm": 0.3805120289325714,
      "learning_rate": 8.51877068258467e-06,
      "loss": 0.133,
      "step": 9355
    },
    {
      "epoch": 0.14813876529917508,
      "grad_norm": 0.3117881417274475,
      "learning_rate": 8.518612347008251e-06,
      "loss": 0.0224,
      "step": 9356
    },
    {
      "epoch": 0.14815459885681714,
      "grad_norm": 0.37610089778900146,
      "learning_rate": 8.51845401143183e-06,
      "loss": 0.2338,
      "step": 9357
    },
    {
      "epoch": 0.1481704324144592,
      "grad_norm": 0.03490167856216431,
      "learning_rate": 8.51829567585541e-06,
      "loss": 0.002,
      "step": 9358
    },
    {
      "epoch": 0.14818626597210127,
      "grad_norm": 0.3543477952480316,
      "learning_rate": 8.518137340278988e-06,
      "loss": 0.2492,
      "step": 9359
    },
    {
      "epoch": 0.14820209952974334,
      "grad_norm": 0.0009655928006395698,
      "learning_rate": 8.517979004702567e-06,
      "loss": 0.0,
      "step": 9360
    },
    {
      "epoch": 0.1482179330873854,
      "grad_norm": 0.00014818577619735152,
      "learning_rate": 8.517820669126146e-06,
      "loss": 0.0,
      "step": 9361
    },
    {
      "epoch": 0.14823376664502746,
      "grad_norm": 0.22013643383979797,
      "learning_rate": 8.517662333549725e-06,
      "loss": 0.0676,
      "step": 9362
    },
    {
      "epoch": 0.14824960020266953,
      "grad_norm": 0.00023939103994052857,
      "learning_rate": 8.517503997973305e-06,
      "loss": 0.0,
      "step": 9363
    },
    {
      "epoch": 0.1482654337603116,
      "grad_norm": 0.04987252503633499,
      "learning_rate": 8.517345662396884e-06,
      "loss": 0.0025,
      "step": 9364
    },
    {
      "epoch": 0.14828126731795366,
      "grad_norm": 0.26091256737709045,
      "learning_rate": 8.517187326820464e-06,
      "loss": 0.0717,
      "step": 9365
    },
    {
      "epoch": 0.14829710087559575,
      "grad_norm": 0.3704603612422943,
      "learning_rate": 8.517028991244043e-06,
      "loss": 0.0732,
      "step": 9366
    },
    {
      "epoch": 0.14831293443323781,
      "grad_norm": 0.5662407875061035,
      "learning_rate": 8.516870655667623e-06,
      "loss": 0.4649,
      "step": 9367
    },
    {
      "epoch": 0.14832876799087988,
      "grad_norm": 0.023898668587207794,
      "learning_rate": 8.516712320091202e-06,
      "loss": 0.0012,
      "step": 9368
    },
    {
      "epoch": 0.14834460154852194,
      "grad_norm": 0.2318316549062729,
      "learning_rate": 8.51655398451478e-06,
      "loss": 0.0352,
      "step": 9369
    },
    {
      "epoch": 0.148360435106164,
      "grad_norm": 0.41641008853912354,
      "learning_rate": 8.51639564893836e-06,
      "loss": 0.1338,
      "step": 9370
    },
    {
      "epoch": 0.14837626866380607,
      "grad_norm": 0.007396467495709658,
      "learning_rate": 8.51623731336194e-06,
      "loss": 0.0003,
      "step": 9371
    },
    {
      "epoch": 0.14839210222144814,
      "grad_norm": 0.641728937625885,
      "learning_rate": 8.51607897778552e-06,
      "loss": 0.197,
      "step": 9372
    },
    {
      "epoch": 0.1484079357790902,
      "grad_norm": 0.8596197962760925,
      "learning_rate": 8.515920642209099e-06,
      "loss": 0.0399,
      "step": 9373
    },
    {
      "epoch": 0.14842376933673226,
      "grad_norm": 0.3956787586212158,
      "learning_rate": 8.515762306632678e-06,
      "loss": 0.119,
      "step": 9374
    },
    {
      "epoch": 0.14843960289437433,
      "grad_norm": 0.18308986723423004,
      "learning_rate": 8.515603971056257e-06,
      "loss": 0.0788,
      "step": 9375
    },
    {
      "epoch": 0.1484554364520164,
      "grad_norm": 0.13060730695724487,
      "learning_rate": 8.515445635479836e-06,
      "loss": 0.0113,
      "step": 9376
    },
    {
      "epoch": 0.14847127000965846,
      "grad_norm": 0.28695905208587646,
      "learning_rate": 8.515287299903417e-06,
      "loss": 0.1533,
      "step": 9377
    },
    {
      "epoch": 0.14848710356730055,
      "grad_norm": 0.3394550085067749,
      "learning_rate": 8.515128964326996e-06,
      "loss": 0.0839,
      "step": 9378
    },
    {
      "epoch": 0.1485029371249426,
      "grad_norm": 0.21741080284118652,
      "learning_rate": 8.514970628750575e-06,
      "loss": 0.0493,
      "step": 9379
    },
    {
      "epoch": 0.14851877068258468,
      "grad_norm": 0.18535739183425903,
      "learning_rate": 8.514812293174154e-06,
      "loss": 0.0577,
      "step": 9380
    },
    {
      "epoch": 0.14853460424022674,
      "grad_norm": 0.7850260734558105,
      "learning_rate": 8.514653957597733e-06,
      "loss": 0.2946,
      "step": 9381
    },
    {
      "epoch": 0.1485504377978688,
      "grad_norm": 0.6341562271118164,
      "learning_rate": 8.514495622021312e-06,
      "loss": 0.152,
      "step": 9382
    },
    {
      "epoch": 0.14856627135551087,
      "grad_norm": 0.4117468595504761,
      "learning_rate": 8.514337286444893e-06,
      "loss": 0.0457,
      "step": 9383
    },
    {
      "epoch": 0.14858210491315293,
      "grad_norm": 0.0008256106521002948,
      "learning_rate": 8.514178950868472e-06,
      "loss": 0.0,
      "step": 9384
    },
    {
      "epoch": 0.148597938470795,
      "grad_norm": 0.0257013700902462,
      "learning_rate": 8.51402061529205e-06,
      "loss": 0.001,
      "step": 9385
    },
    {
      "epoch": 0.14861377202843706,
      "grad_norm": 0.009878771379590034,
      "learning_rate": 8.51386227971563e-06,
      "loss": 0.0001,
      "step": 9386
    },
    {
      "epoch": 0.14862960558607913,
      "grad_norm": 0.22867703437805176,
      "learning_rate": 8.51370394413921e-06,
      "loss": 0.108,
      "step": 9387
    },
    {
      "epoch": 0.1486454391437212,
      "grad_norm": 0.00029655551770702004,
      "learning_rate": 8.513545608562788e-06,
      "loss": 0.0,
      "step": 9388
    },
    {
      "epoch": 0.14866127270136326,
      "grad_norm": 0.4095357358455658,
      "learning_rate": 8.513387272986367e-06,
      "loss": 0.0937,
      "step": 9389
    },
    {
      "epoch": 0.14867710625900535,
      "grad_norm": 0.2900632917881012,
      "learning_rate": 8.513228937409948e-06,
      "loss": 0.1433,
      "step": 9390
    },
    {
      "epoch": 0.1486929398166474,
      "grad_norm": 0.2889857590198517,
      "learning_rate": 8.513070601833526e-06,
      "loss": 0.1268,
      "step": 9391
    },
    {
      "epoch": 0.14870877337428948,
      "grad_norm": 0.274372935295105,
      "learning_rate": 8.512912266257106e-06,
      "loss": 0.1215,
      "step": 9392
    },
    {
      "epoch": 0.14872460693193154,
      "grad_norm": 0.1921267807483673,
      "learning_rate": 8.512753930680685e-06,
      "loss": 0.0764,
      "step": 9393
    },
    {
      "epoch": 0.1487404404895736,
      "grad_norm": 0.025440474972128868,
      "learning_rate": 8.512595595104265e-06,
      "loss": 0.0011,
      "step": 9394
    },
    {
      "epoch": 0.14875627404721567,
      "grad_norm": 0.37727564573287964,
      "learning_rate": 8.512437259527844e-06,
      "loss": 0.1597,
      "step": 9395
    },
    {
      "epoch": 0.14877210760485773,
      "grad_norm": 0.18324841558933258,
      "learning_rate": 8.512278923951424e-06,
      "loss": 0.057,
      "step": 9396
    },
    {
      "epoch": 0.1487879411624998,
      "grad_norm": 0.29294005036354065,
      "learning_rate": 8.512120588375002e-06,
      "loss": 0.034,
      "step": 9397
    },
    {
      "epoch": 0.14880377472014186,
      "grad_norm": 0.1721583604812622,
      "learning_rate": 8.511962252798583e-06,
      "loss": 0.1203,
      "step": 9398
    },
    {
      "epoch": 0.14881960827778393,
      "grad_norm": 0.38561782240867615,
      "learning_rate": 8.511803917222162e-06,
      "loss": 0.2139,
      "step": 9399
    },
    {
      "epoch": 0.148835441835426,
      "grad_norm": 0.33955442905426025,
      "learning_rate": 8.51164558164574e-06,
      "loss": 0.214,
      "step": 9400
    },
    {
      "epoch": 0.14885127539306806,
      "grad_norm": 0.602039098739624,
      "learning_rate": 8.51148724606932e-06,
      "loss": 0.1034,
      "step": 9401
    },
    {
      "epoch": 0.14886710895071015,
      "grad_norm": 0.22567224502563477,
      "learning_rate": 8.5113289104929e-06,
      "loss": 0.0453,
      "step": 9402
    },
    {
      "epoch": 0.1488829425083522,
      "grad_norm": 0.0022781393490731716,
      "learning_rate": 8.511170574916478e-06,
      "loss": 0.0001,
      "step": 9403
    },
    {
      "epoch": 0.14889877606599428,
      "grad_norm": 0.15512551367282867,
      "learning_rate": 8.511012239340059e-06,
      "loss": 0.092,
      "step": 9404
    },
    {
      "epoch": 0.14891460962363634,
      "grad_norm": 0.02059190534055233,
      "learning_rate": 8.510853903763638e-06,
      "loss": 0.001,
      "step": 9405
    },
    {
      "epoch": 0.1489304431812784,
      "grad_norm": 0.5690739750862122,
      "learning_rate": 8.510695568187217e-06,
      "loss": 0.097,
      "step": 9406
    },
    {
      "epoch": 0.14894627673892047,
      "grad_norm": 0.6627881526947021,
      "learning_rate": 8.510537232610796e-06,
      "loss": 0.4815,
      "step": 9407
    },
    {
      "epoch": 0.14896211029656253,
      "grad_norm": 0.22801566123962402,
      "learning_rate": 8.510378897034375e-06,
      "loss": 0.068,
      "step": 9408
    },
    {
      "epoch": 0.1489779438542046,
      "grad_norm": 0.007181995082646608,
      "learning_rate": 8.510220561457954e-06,
      "loss": 0.0004,
      "step": 9409
    },
    {
      "epoch": 0.14899377741184666,
      "grad_norm": 0.02429276891052723,
      "learning_rate": 8.510062225881533e-06,
      "loss": 0.0014,
      "step": 9410
    },
    {
      "epoch": 0.14900961096948873,
      "grad_norm": 0.16312620043754578,
      "learning_rate": 8.509903890305114e-06,
      "loss": 0.0328,
      "step": 9411
    },
    {
      "epoch": 0.1490254445271308,
      "grad_norm": 0.32223889231681824,
      "learning_rate": 8.509745554728693e-06,
      "loss": 0.1816,
      "step": 9412
    },
    {
      "epoch": 0.14904127808477285,
      "grad_norm": 1.086424469947815,
      "learning_rate": 8.509587219152272e-06,
      "loss": 0.5158,
      "step": 9413
    },
    {
      "epoch": 0.14905711164241495,
      "grad_norm": 0.25464993715286255,
      "learning_rate": 8.509428883575851e-06,
      "loss": 0.0657,
      "step": 9414
    },
    {
      "epoch": 0.149072945200057,
      "grad_norm": 0.4300641119480133,
      "learning_rate": 8.50927054799943e-06,
      "loss": 0.2227,
      "step": 9415
    },
    {
      "epoch": 0.14908877875769908,
      "grad_norm": 0.19802094995975494,
      "learning_rate": 8.50911221242301e-06,
      "loss": 0.0284,
      "step": 9416
    },
    {
      "epoch": 0.14910461231534114,
      "grad_norm": 0.38296616077423096,
      "learning_rate": 8.50895387684659e-06,
      "loss": 0.11,
      "step": 9417
    },
    {
      "epoch": 0.1491204458729832,
      "grad_norm": 0.2904609739780426,
      "learning_rate": 8.50879554127017e-06,
      "loss": 0.0155,
      "step": 9418
    },
    {
      "epoch": 0.14913627943062527,
      "grad_norm": 0.002312907250598073,
      "learning_rate": 8.508637205693748e-06,
      "loss": 0.0,
      "step": 9419
    },
    {
      "epoch": 0.14915211298826733,
      "grad_norm": 0.0250649806112051,
      "learning_rate": 8.508478870117327e-06,
      "loss": 0.0017,
      "step": 9420
    },
    {
      "epoch": 0.1491679465459094,
      "grad_norm": 0.00019120675278827548,
      "learning_rate": 8.508320534540906e-06,
      "loss": 0.0,
      "step": 9421
    },
    {
      "epoch": 0.14918378010355146,
      "grad_norm": 0.00335290958173573,
      "learning_rate": 8.508162198964486e-06,
      "loss": 0.0001,
      "step": 9422
    },
    {
      "epoch": 0.14919961366119353,
      "grad_norm": 0.2598072588443756,
      "learning_rate": 8.508003863388066e-06,
      "loss": 0.0667,
      "step": 9423
    },
    {
      "epoch": 0.1492154472188356,
      "grad_norm": 0.503280520439148,
      "learning_rate": 8.507845527811645e-06,
      "loss": 0.2715,
      "step": 9424
    },
    {
      "epoch": 0.14923128077647765,
      "grad_norm": 0.01140754297375679,
      "learning_rate": 8.507687192235224e-06,
      "loss": 0.0006,
      "step": 9425
    },
    {
      "epoch": 0.14924711433411975,
      "grad_norm": 0.6933935880661011,
      "learning_rate": 8.507528856658804e-06,
      "loss": 0.2082,
      "step": 9426
    },
    {
      "epoch": 0.1492629478917618,
      "grad_norm": 0.32314473390579224,
      "learning_rate": 8.507370521082383e-06,
      "loss": 0.2248,
      "step": 9427
    },
    {
      "epoch": 0.14927878144940387,
      "grad_norm": 0.6587781310081482,
      "learning_rate": 8.507212185505962e-06,
      "loss": 0.1003,
      "step": 9428
    },
    {
      "epoch": 0.14929461500704594,
      "grad_norm": 0.00023205090838018805,
      "learning_rate": 8.507053849929542e-06,
      "loss": 0.0,
      "step": 9429
    },
    {
      "epoch": 0.149310448564688,
      "grad_norm": 0.03732365369796753,
      "learning_rate": 8.50689551435312e-06,
      "loss": 0.0018,
      "step": 9430
    },
    {
      "epoch": 0.14932628212233007,
      "grad_norm": 0.00038743947516195476,
      "learning_rate": 8.5067371787767e-06,
      "loss": 0.0,
      "step": 9431
    },
    {
      "epoch": 0.14934211567997213,
      "grad_norm": 0.18513600528240204,
      "learning_rate": 8.50657884320028e-06,
      "loss": 0.0748,
      "step": 9432
    },
    {
      "epoch": 0.1493579492376142,
      "grad_norm": 0.5992252826690674,
      "learning_rate": 8.506420507623859e-06,
      "loss": 0.27,
      "step": 9433
    },
    {
      "epoch": 0.14937378279525626,
      "grad_norm": 0.7233476042747498,
      "learning_rate": 8.506262172047438e-06,
      "loss": 0.0355,
      "step": 9434
    },
    {
      "epoch": 0.14938961635289832,
      "grad_norm": 0.2037525326013565,
      "learning_rate": 8.506103836471017e-06,
      "loss": 0.0475,
      "step": 9435
    },
    {
      "epoch": 0.1494054499105404,
      "grad_norm": 0.019280070438981056,
      "learning_rate": 8.505945500894596e-06,
      "loss": 0.0008,
      "step": 9436
    },
    {
      "epoch": 0.14942128346818245,
      "grad_norm": 0.002407533349469304,
      "learning_rate": 8.505787165318175e-06,
      "loss": 0.0,
      "step": 9437
    },
    {
      "epoch": 0.14943711702582455,
      "grad_norm": 0.021458804607391357,
      "learning_rate": 8.505628829741756e-06,
      "loss": 0.0014,
      "step": 9438
    },
    {
      "epoch": 0.1494529505834666,
      "grad_norm": 0.2959284484386444,
      "learning_rate": 8.505470494165335e-06,
      "loss": 0.0762,
      "step": 9439
    },
    {
      "epoch": 0.14946878414110867,
      "grad_norm": 0.022693494334816933,
      "learning_rate": 8.505312158588914e-06,
      "loss": 0.0013,
      "step": 9440
    },
    {
      "epoch": 0.14948461769875074,
      "grad_norm": 0.03201661258935928,
      "learning_rate": 8.505153823012493e-06,
      "loss": 0.0023,
      "step": 9441
    },
    {
      "epoch": 0.1495004512563928,
      "grad_norm": 0.33100205659866333,
      "learning_rate": 8.504995487436072e-06,
      "loss": 0.1539,
      "step": 9442
    },
    {
      "epoch": 0.14951628481403487,
      "grad_norm": 0.35839536786079407,
      "learning_rate": 8.504837151859651e-06,
      "loss": 0.2027,
      "step": 9443
    },
    {
      "epoch": 0.14953211837167693,
      "grad_norm": 0.5353114604949951,
      "learning_rate": 8.504678816283232e-06,
      "loss": 0.1802,
      "step": 9444
    },
    {
      "epoch": 0.149547951929319,
      "grad_norm": 0.003764854744076729,
      "learning_rate": 8.504520480706811e-06,
      "loss": 0.0001,
      "step": 9445
    },
    {
      "epoch": 0.14956378548696106,
      "grad_norm": 0.8252601623535156,
      "learning_rate": 8.50436214513039e-06,
      "loss": 0.3854,
      "step": 9446
    },
    {
      "epoch": 0.14957961904460312,
      "grad_norm": 0.5877201557159424,
      "learning_rate": 8.50420380955397e-06,
      "loss": 1.0502,
      "step": 9447
    },
    {
      "epoch": 0.1495954526022452,
      "grad_norm": 0.17185194790363312,
      "learning_rate": 8.504045473977548e-06,
      "loss": 0.0363,
      "step": 9448
    },
    {
      "epoch": 0.14961128615988725,
      "grad_norm": 7.127920252969489e-05,
      "learning_rate": 8.503887138401127e-06,
      "loss": 0.0,
      "step": 9449
    },
    {
      "epoch": 0.14962711971752934,
      "grad_norm": 0.14104992151260376,
      "learning_rate": 8.503728802824708e-06,
      "loss": 0.0339,
      "step": 9450
    },
    {
      "epoch": 0.1496429532751714,
      "grad_norm": 0.48004186153411865,
      "learning_rate": 8.503570467248287e-06,
      "loss": 0.0745,
      "step": 9451
    },
    {
      "epoch": 0.14965878683281347,
      "grad_norm": 0.00011912447371287271,
      "learning_rate": 8.503412131671866e-06,
      "loss": 0.0,
      "step": 9452
    },
    {
      "epoch": 0.14967462039045554,
      "grad_norm": 0.3715016543865204,
      "learning_rate": 8.503253796095445e-06,
      "loss": 0.2979,
      "step": 9453
    },
    {
      "epoch": 0.1496904539480976,
      "grad_norm": 0.5644612908363342,
      "learning_rate": 8.503095460519025e-06,
      "loss": 0.9287,
      "step": 9454
    },
    {
      "epoch": 0.14970628750573967,
      "grad_norm": 1.7937123775482178,
      "learning_rate": 8.502937124942604e-06,
      "loss": 0.1853,
      "step": 9455
    },
    {
      "epoch": 0.14972212106338173,
      "grad_norm": 0.6597639322280884,
      "learning_rate": 8.502778789366183e-06,
      "loss": 0.2224,
      "step": 9456
    },
    {
      "epoch": 0.1497379546210238,
      "grad_norm": 0.0007885944796726108,
      "learning_rate": 8.502620453789763e-06,
      "loss": 0.0,
      "step": 9457
    },
    {
      "epoch": 0.14975378817866586,
      "grad_norm": 0.6193569898605347,
      "learning_rate": 8.50246211821334e-06,
      "loss": 0.1069,
      "step": 9458
    },
    {
      "epoch": 0.14976962173630792,
      "grad_norm": 0.1759524643421173,
      "learning_rate": 8.502303782636922e-06,
      "loss": 0.0828,
      "step": 9459
    },
    {
      "epoch": 0.14978545529395,
      "grad_norm": 0.4588935971260071,
      "learning_rate": 8.5021454470605e-06,
      "loss": 0.1697,
      "step": 9460
    },
    {
      "epoch": 0.14980128885159205,
      "grad_norm": 0.23714672029018402,
      "learning_rate": 8.50198711148408e-06,
      "loss": 0.0446,
      "step": 9461
    },
    {
      "epoch": 0.14981712240923414,
      "grad_norm": 0.31217578053474426,
      "learning_rate": 8.501828775907659e-06,
      "loss": 0.132,
      "step": 9462
    },
    {
      "epoch": 0.1498329559668762,
      "grad_norm": 0.35309335589408875,
      "learning_rate": 8.50167044033124e-06,
      "loss": 0.2102,
      "step": 9463
    },
    {
      "epoch": 0.14984878952451827,
      "grad_norm": 0.13919471204280853,
      "learning_rate": 8.501512104754817e-06,
      "loss": 0.0107,
      "step": 9464
    },
    {
      "epoch": 0.14986462308216034,
      "grad_norm": 0.5164101123809814,
      "learning_rate": 8.501353769178398e-06,
      "loss": 0.0977,
      "step": 9465
    },
    {
      "epoch": 0.1498804566398024,
      "grad_norm": 0.0072993021458387375,
      "learning_rate": 8.501195433601977e-06,
      "loss": 0.0004,
      "step": 9466
    },
    {
      "epoch": 0.14989629019744447,
      "grad_norm": 0.5739914774894714,
      "learning_rate": 8.501037098025556e-06,
      "loss": 0.2603,
      "step": 9467
    },
    {
      "epoch": 0.14991212375508653,
      "grad_norm": 0.025109831243753433,
      "learning_rate": 8.500878762449135e-06,
      "loss": 0.0014,
      "step": 9468
    },
    {
      "epoch": 0.1499279573127286,
      "grad_norm": 0.08807282894849777,
      "learning_rate": 8.500720426872716e-06,
      "loss": 0.0138,
      "step": 9469
    },
    {
      "epoch": 0.14994379087037066,
      "grad_norm": 0.05200788378715515,
      "learning_rate": 8.500562091296293e-06,
      "loss": 0.0029,
      "step": 9470
    },
    {
      "epoch": 0.14995962442801272,
      "grad_norm": 8.835227345116436e-05,
      "learning_rate": 8.500403755719874e-06,
      "loss": 0.0,
      "step": 9471
    },
    {
      "epoch": 0.1499754579856548,
      "grad_norm": 0.6443670988082886,
      "learning_rate": 8.500245420143453e-06,
      "loss": 0.1742,
      "step": 9472
    },
    {
      "epoch": 0.14999129154329685,
      "grad_norm": 0.1460525393486023,
      "learning_rate": 8.500087084567032e-06,
      "loss": 0.0297,
      "step": 9473
    },
    {
      "epoch": 0.15000712510093894,
      "grad_norm": 0.00017543746798764914,
      "learning_rate": 8.499928748990611e-06,
      "loss": 0.0,
      "step": 9474
    },
    {
      "epoch": 0.150022958658581,
      "grad_norm": 3.47283673286438,
      "learning_rate": 8.499770413414192e-06,
      "loss": 0.4382,
      "step": 9475
    },
    {
      "epoch": 0.15003879221622307,
      "grad_norm": 0.24071119725704193,
      "learning_rate": 8.49961207783777e-06,
      "loss": 0.1103,
      "step": 9476
    },
    {
      "epoch": 0.15005462577386514,
      "grad_norm": 0.3005521595478058,
      "learning_rate": 8.49945374226135e-06,
      "loss": 0.1248,
      "step": 9477
    },
    {
      "epoch": 0.1500704593315072,
      "grad_norm": 0.3370949625968933,
      "learning_rate": 8.49929540668493e-06,
      "loss": 0.0659,
      "step": 9478
    },
    {
      "epoch": 0.15008629288914926,
      "grad_norm": 0.24440902471542358,
      "learning_rate": 8.499137071108508e-06,
      "loss": 0.2772,
      "step": 9479
    },
    {
      "epoch": 0.15010212644679133,
      "grad_norm": 0.02384112775325775,
      "learning_rate": 8.498978735532087e-06,
      "loss": 0.0015,
      "step": 9480
    },
    {
      "epoch": 0.1501179600044334,
      "grad_norm": 0.8246471285820007,
      "learning_rate": 8.498820399955666e-06,
      "loss": 0.3979,
      "step": 9481
    },
    {
      "epoch": 0.15013379356207546,
      "grad_norm": 0.0158368106931448,
      "learning_rate": 8.498662064379246e-06,
      "loss": 0.0014,
      "step": 9482
    },
    {
      "epoch": 0.15014962711971752,
      "grad_norm": 0.3859270513057709,
      "learning_rate": 8.498503728802825e-06,
      "loss": 0.3541,
      "step": 9483
    },
    {
      "epoch": 0.15016546067735959,
      "grad_norm": 0.34232571721076965,
      "learning_rate": 8.498345393226405e-06,
      "loss": 0.146,
      "step": 9484
    },
    {
      "epoch": 0.15018129423500165,
      "grad_norm": 0.21744126081466675,
      "learning_rate": 8.498187057649984e-06,
      "loss": 0.0548,
      "step": 9485
    },
    {
      "epoch": 0.15019712779264374,
      "grad_norm": 0.16445696353912354,
      "learning_rate": 8.498028722073564e-06,
      "loss": 0.0167,
      "step": 9486
    },
    {
      "epoch": 0.1502129613502858,
      "grad_norm": 0.3094627261161804,
      "learning_rate": 8.497870386497143e-06,
      "loss": 0.0688,
      "step": 9487
    },
    {
      "epoch": 0.15022879490792787,
      "grad_norm": 0.26210635900497437,
      "learning_rate": 8.497712050920722e-06,
      "loss": 0.1489,
      "step": 9488
    },
    {
      "epoch": 0.15024462846556993,
      "grad_norm": 0.778006911277771,
      "learning_rate": 8.4975537153443e-06,
      "loss": 0.1643,
      "step": 9489
    },
    {
      "epoch": 0.150260462023212,
      "grad_norm": 0.08300693333148956,
      "learning_rate": 8.497395379767882e-06,
      "loss": 0.0064,
      "step": 9490
    },
    {
      "epoch": 0.15027629558085406,
      "grad_norm": 0.3806183934211731,
      "learning_rate": 8.497237044191459e-06,
      "loss": 0.0672,
      "step": 9491
    },
    {
      "epoch": 0.15029212913849613,
      "grad_norm": 0.000354410003637895,
      "learning_rate": 8.49707870861504e-06,
      "loss": 0.0,
      "step": 9492
    },
    {
      "epoch": 0.1503079626961382,
      "grad_norm": 0.5140767693519592,
      "learning_rate": 8.496920373038619e-06,
      "loss": 0.5894,
      "step": 9493
    },
    {
      "epoch": 0.15032379625378026,
      "grad_norm": 0.6675236225128174,
      "learning_rate": 8.496762037462198e-06,
      "loss": 0.8147,
      "step": 9494
    },
    {
      "epoch": 0.15033962981142232,
      "grad_norm": 0.26947617530822754,
      "learning_rate": 8.496603701885777e-06,
      "loss": 0.153,
      "step": 9495
    },
    {
      "epoch": 0.15035546336906438,
      "grad_norm": 0.20186591148376465,
      "learning_rate": 8.496445366309358e-06,
      "loss": 0.0487,
      "step": 9496
    },
    {
      "epoch": 0.15037129692670645,
      "grad_norm": 0.2702745199203491,
      "learning_rate": 8.496287030732935e-06,
      "loss": 0.3253,
      "step": 9497
    },
    {
      "epoch": 0.15038713048434854,
      "grad_norm": 0.7433911561965942,
      "learning_rate": 8.496128695156516e-06,
      "loss": 0.5061,
      "step": 9498
    },
    {
      "epoch": 0.1504029640419906,
      "grad_norm": 0.35144978761672974,
      "learning_rate": 8.495970359580095e-06,
      "loss": 0.1106,
      "step": 9499
    },
    {
      "epoch": 0.15041879759963267,
      "grad_norm": 0.2236345112323761,
      "learning_rate": 8.495812024003674e-06,
      "loss": 0.1141,
      "step": 9500
    },
    {
      "epoch": 0.15043463115727473,
      "grad_norm": 0.01520149689167738,
      "learning_rate": 8.495653688427253e-06,
      "loss": 0.0011,
      "step": 9501
    },
    {
      "epoch": 0.1504504647149168,
      "grad_norm": 0.34629055857658386,
      "learning_rate": 8.495495352850834e-06,
      "loss": 0.2381,
      "step": 9502
    },
    {
      "epoch": 0.15046629827255886,
      "grad_norm": 0.3651061952114105,
      "learning_rate": 8.495337017274411e-06,
      "loss": 0.2158,
      "step": 9503
    },
    {
      "epoch": 0.15048213183020093,
      "grad_norm": 0.013111740350723267,
      "learning_rate": 8.49517868169799e-06,
      "loss": 0.0009,
      "step": 9504
    },
    {
      "epoch": 0.150497965387843,
      "grad_norm": 0.23454377055168152,
      "learning_rate": 8.495020346121571e-06,
      "loss": 0.1394,
      "step": 9505
    },
    {
      "epoch": 0.15051379894548506,
      "grad_norm": 0.40739282965660095,
      "learning_rate": 8.49486201054515e-06,
      "loss": 0.1173,
      "step": 9506
    },
    {
      "epoch": 0.15052963250312712,
      "grad_norm": 0.26364803314208984,
      "learning_rate": 8.49470367496873e-06,
      "loss": 0.059,
      "step": 9507
    },
    {
      "epoch": 0.15054546606076918,
      "grad_norm": 0.39638620615005493,
      "learning_rate": 8.494545339392308e-06,
      "loss": 0.149,
      "step": 9508
    },
    {
      "epoch": 0.15056129961841125,
      "grad_norm": 0.24701586365699768,
      "learning_rate": 8.494387003815887e-06,
      "loss": 0.0761,
      "step": 9509
    },
    {
      "epoch": 0.15057713317605334,
      "grad_norm": 0.32100391387939453,
      "learning_rate": 8.494228668239467e-06,
      "loss": 0.1204,
      "step": 9510
    },
    {
      "epoch": 0.1505929667336954,
      "grad_norm": 0.3399296700954437,
      "learning_rate": 8.494070332663047e-06,
      "loss": 0.5546,
      "step": 9511
    },
    {
      "epoch": 0.15060880029133747,
      "grad_norm": 0.38327428698539734,
      "learning_rate": 8.493911997086626e-06,
      "loss": 0.5485,
      "step": 9512
    },
    {
      "epoch": 0.15062463384897953,
      "grad_norm": 7.070427091093734e-05,
      "learning_rate": 8.493753661510205e-06,
      "loss": 0.0,
      "step": 9513
    },
    {
      "epoch": 0.1506404674066216,
      "grad_norm": 0.5331323742866516,
      "learning_rate": 8.493595325933785e-06,
      "loss": 0.2877,
      "step": 9514
    },
    {
      "epoch": 0.15065630096426366,
      "grad_norm": 0.19303283095359802,
      "learning_rate": 8.493436990357364e-06,
      "loss": 0.0125,
      "step": 9515
    },
    {
      "epoch": 0.15067213452190573,
      "grad_norm": 0.3311147391796112,
      "learning_rate": 8.493278654780943e-06,
      "loss": 0.0934,
      "step": 9516
    },
    {
      "epoch": 0.1506879680795478,
      "grad_norm": 0.004586956929415464,
      "learning_rate": 8.493120319204523e-06,
      "loss": 0.0002,
      "step": 9517
    },
    {
      "epoch": 0.15070380163718985,
      "grad_norm": 0.6352107524871826,
      "learning_rate": 8.492961983628103e-06,
      "loss": 0.4505,
      "step": 9518
    },
    {
      "epoch": 0.15071963519483192,
      "grad_norm": 0.002695862902328372,
      "learning_rate": 8.492803648051682e-06,
      "loss": 0.0,
      "step": 9519
    },
    {
      "epoch": 0.15073546875247398,
      "grad_norm": 0.43588584661483765,
      "learning_rate": 8.49264531247526e-06,
      "loss": 0.1383,
      "step": 9520
    },
    {
      "epoch": 0.15075130231011605,
      "grad_norm": 0.22404137253761292,
      "learning_rate": 8.49248697689884e-06,
      "loss": 0.0614,
      "step": 9521
    },
    {
      "epoch": 0.15076713586775814,
      "grad_norm": 0.5992966890335083,
      "learning_rate": 8.492328641322419e-06,
      "loss": 1.2815,
      "step": 9522
    },
    {
      "epoch": 0.1507829694254002,
      "grad_norm": 0.3682016134262085,
      "learning_rate": 8.492170305746e-06,
      "loss": 0.132,
      "step": 9523
    },
    {
      "epoch": 0.15079880298304227,
      "grad_norm": 0.2580341398715973,
      "learning_rate": 8.492011970169579e-06,
      "loss": 0.0644,
      "step": 9524
    },
    {
      "epoch": 0.15081463654068433,
      "grad_norm": 0.38510218262672424,
      "learning_rate": 8.491853634593158e-06,
      "loss": 0.1459,
      "step": 9525
    },
    {
      "epoch": 0.1508304700983264,
      "grad_norm": 0.009783822111785412,
      "learning_rate": 8.491695299016737e-06,
      "loss": 0.0005,
      "step": 9526
    },
    {
      "epoch": 0.15084630365596846,
      "grad_norm": 0.14323057234287262,
      "learning_rate": 8.491536963440316e-06,
      "loss": 0.0762,
      "step": 9527
    },
    {
      "epoch": 0.15086213721361053,
      "grad_norm": 0.21743835508823395,
      "learning_rate": 8.491378627863895e-06,
      "loss": 0.0316,
      "step": 9528
    },
    {
      "epoch": 0.1508779707712526,
      "grad_norm": 0.4760313034057617,
      "learning_rate": 8.491220292287474e-06,
      "loss": 0.3475,
      "step": 9529
    },
    {
      "epoch": 0.15089380432889465,
      "grad_norm": 0.4091399013996124,
      "learning_rate": 8.491061956711055e-06,
      "loss": 0.0933,
      "step": 9530
    },
    {
      "epoch": 0.15090963788653672,
      "grad_norm": 0.5111390352249146,
      "learning_rate": 8.490903621134632e-06,
      "loss": 0.5077,
      "step": 9531
    },
    {
      "epoch": 0.15092547144417878,
      "grad_norm": 0.0002104094746755436,
      "learning_rate": 8.490745285558213e-06,
      "loss": 0.0,
      "step": 9532
    },
    {
      "epoch": 0.15094130500182085,
      "grad_norm": 0.02864290587604046,
      "learning_rate": 8.490586949981792e-06,
      "loss": 0.0017,
      "step": 9533
    },
    {
      "epoch": 0.15095713855946294,
      "grad_norm": 0.01535010989755392,
      "learning_rate": 8.490428614405371e-06,
      "loss": 0.0007,
      "step": 9534
    },
    {
      "epoch": 0.150972972117105,
      "grad_norm": 0.5986906290054321,
      "learning_rate": 8.49027027882895e-06,
      "loss": 0.3636,
      "step": 9535
    },
    {
      "epoch": 0.15098880567474707,
      "grad_norm": 0.010234744288027287,
      "learning_rate": 8.490111943252531e-06,
      "loss": 0.0006,
      "step": 9536
    },
    {
      "epoch": 0.15100463923238913,
      "grad_norm": 0.33404597640037537,
      "learning_rate": 8.489953607676108e-06,
      "loss": 0.0846,
      "step": 9537
    },
    {
      "epoch": 0.1510204727900312,
      "grad_norm": 0.6107345819473267,
      "learning_rate": 8.48979527209969e-06,
      "loss": 0.4663,
      "step": 9538
    },
    {
      "epoch": 0.15103630634767326,
      "grad_norm": 0.01200248021632433,
      "learning_rate": 8.489636936523268e-06,
      "loss": 0.0006,
      "step": 9539
    },
    {
      "epoch": 0.15105213990531532,
      "grad_norm": 0.37813347578048706,
      "learning_rate": 8.489478600946847e-06,
      "loss": 0.297,
      "step": 9540
    },
    {
      "epoch": 0.1510679734629574,
      "grad_norm": 0.6130335330963135,
      "learning_rate": 8.489320265370426e-06,
      "loss": 0.3247,
      "step": 9541
    },
    {
      "epoch": 0.15108380702059945,
      "grad_norm": 0.012694939970970154,
      "learning_rate": 8.489161929794007e-06,
      "loss": 0.0006,
      "step": 9542
    },
    {
      "epoch": 0.15109964057824152,
      "grad_norm": 0.010777702555060387,
      "learning_rate": 8.489003594217585e-06,
      "loss": 0.0006,
      "step": 9543
    },
    {
      "epoch": 0.15111547413588358,
      "grad_norm": 0.30476269125938416,
      "learning_rate": 8.488845258641165e-06,
      "loss": 0.1944,
      "step": 9544
    },
    {
      "epoch": 0.15113130769352565,
      "grad_norm": 0.7849368453025818,
      "learning_rate": 8.488686923064744e-06,
      "loss": 0.1193,
      "step": 9545
    },
    {
      "epoch": 0.15114714125116774,
      "grad_norm": 0.7041598558425903,
      "learning_rate": 8.488528587488324e-06,
      "loss": 0.183,
      "step": 9546
    },
    {
      "epoch": 0.1511629748088098,
      "grad_norm": 0.00800313800573349,
      "learning_rate": 8.488370251911903e-06,
      "loss": 0.0004,
      "step": 9547
    },
    {
      "epoch": 0.15117880836645187,
      "grad_norm": 0.2500567138195038,
      "learning_rate": 8.488211916335483e-06,
      "loss": 0.2087,
      "step": 9548
    },
    {
      "epoch": 0.15119464192409393,
      "grad_norm": 0.4682133197784424,
      "learning_rate": 8.48805358075906e-06,
      "loss": 0.1219,
      "step": 9549
    },
    {
      "epoch": 0.151210475481736,
      "grad_norm": 0.0001783423504093662,
      "learning_rate": 8.487895245182642e-06,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 0.15122630903937806,
      "grad_norm": 0.0779932364821434,
      "learning_rate": 8.48773690960622e-06,
      "loss": 0.0254,
      "step": 9551
    },
    {
      "epoch": 0.15124214259702012,
      "grad_norm": 0.34964364767074585,
      "learning_rate": 8.4875785740298e-06,
      "loss": 0.1056,
      "step": 9552
    },
    {
      "epoch": 0.1512579761546622,
      "grad_norm": 0.05913541465997696,
      "learning_rate": 8.487420238453379e-06,
      "loss": 0.0034,
      "step": 9553
    },
    {
      "epoch": 0.15127380971230425,
      "grad_norm": 0.0003922542091459036,
      "learning_rate": 8.487261902876958e-06,
      "loss": 0.0,
      "step": 9554
    },
    {
      "epoch": 0.15128964326994632,
      "grad_norm": 0.04388275370001793,
      "learning_rate": 8.487103567300537e-06,
      "loss": 0.0023,
      "step": 9555
    },
    {
      "epoch": 0.15130547682758838,
      "grad_norm": 0.019246231764554977,
      "learning_rate": 8.486945231724116e-06,
      "loss": 0.0013,
      "step": 9556
    },
    {
      "epoch": 0.15132131038523045,
      "grad_norm": 0.005095474887639284,
      "learning_rate": 8.486786896147697e-06,
      "loss": 0.0003,
      "step": 9557
    },
    {
      "epoch": 0.15133714394287254,
      "grad_norm": 0.22458817064762115,
      "learning_rate": 8.486628560571274e-06,
      "loss": 0.1197,
      "step": 9558
    },
    {
      "epoch": 0.1513529775005146,
      "grad_norm": 0.6228164434432983,
      "learning_rate": 8.486470224994855e-06,
      "loss": 0.1838,
      "step": 9559
    },
    {
      "epoch": 0.15136881105815667,
      "grad_norm": 1.6065130233764648,
      "learning_rate": 8.486311889418434e-06,
      "loss": 0.7528,
      "step": 9560
    },
    {
      "epoch": 0.15138464461579873,
      "grad_norm": 0.8079283833503723,
      "learning_rate": 8.486153553842013e-06,
      "loss": 0.1464,
      "step": 9561
    },
    {
      "epoch": 0.1514004781734408,
      "grad_norm": 0.17925621569156647,
      "learning_rate": 8.485995218265592e-06,
      "loss": 0.0636,
      "step": 9562
    },
    {
      "epoch": 0.15141631173108286,
      "grad_norm": 0.3452248275279999,
      "learning_rate": 8.485836882689173e-06,
      "loss": 0.1802,
      "step": 9563
    },
    {
      "epoch": 0.15143214528872492,
      "grad_norm": 0.00832070130854845,
      "learning_rate": 8.48567854711275e-06,
      "loss": 0.0005,
      "step": 9564
    },
    {
      "epoch": 0.151447978846367,
      "grad_norm": 0.0002075886441161856,
      "learning_rate": 8.485520211536331e-06,
      "loss": 0.0,
      "step": 9565
    },
    {
      "epoch": 0.15146381240400905,
      "grad_norm": 0.4162595272064209,
      "learning_rate": 8.48536187595991e-06,
      "loss": 0.2447,
      "step": 9566
    },
    {
      "epoch": 0.15147964596165112,
      "grad_norm": 0.30925458669662476,
      "learning_rate": 8.48520354038349e-06,
      "loss": 0.0098,
      "step": 9567
    },
    {
      "epoch": 0.15149547951929318,
      "grad_norm": 0.04435628280043602,
      "learning_rate": 8.485045204807068e-06,
      "loss": 0.0031,
      "step": 9568
    },
    {
      "epoch": 0.15151131307693524,
      "grad_norm": 0.005022815894335508,
      "learning_rate": 8.48488686923065e-06,
      "loss": 0.0003,
      "step": 9569
    },
    {
      "epoch": 0.15152714663457734,
      "grad_norm": 0.07800406962633133,
      "learning_rate": 8.484728533654227e-06,
      "loss": 0.0073,
      "step": 9570
    },
    {
      "epoch": 0.1515429801922194,
      "grad_norm": 0.010288010351359844,
      "learning_rate": 8.484570198077807e-06,
      "loss": 0.0008,
      "step": 9571
    },
    {
      "epoch": 0.15155881374986147,
      "grad_norm": 0.3900465965270996,
      "learning_rate": 8.484411862501386e-06,
      "loss": 0.2031,
      "step": 9572
    },
    {
      "epoch": 0.15157464730750353,
      "grad_norm": 0.00036369398003444076,
      "learning_rate": 8.484253526924965e-06,
      "loss": 0.0,
      "step": 9573
    },
    {
      "epoch": 0.1515904808651456,
      "grad_norm": 0.5978354811668396,
      "learning_rate": 8.484095191348545e-06,
      "loss": 0.4653,
      "step": 9574
    },
    {
      "epoch": 0.15160631442278766,
      "grad_norm": 0.28448790311813354,
      "learning_rate": 8.483936855772125e-06,
      "loss": 0.2422,
      "step": 9575
    },
    {
      "epoch": 0.15162214798042972,
      "grad_norm": 0.0035493061877787113,
      "learning_rate": 8.483778520195703e-06,
      "loss": 0.0001,
      "step": 9576
    },
    {
      "epoch": 0.1516379815380718,
      "grad_norm": 0.15603221952915192,
      "learning_rate": 8.483620184619282e-06,
      "loss": 0.0553,
      "step": 9577
    },
    {
      "epoch": 0.15165381509571385,
      "grad_norm": 0.2197318971157074,
      "learning_rate": 8.483461849042863e-06,
      "loss": 0.0829,
      "step": 9578
    },
    {
      "epoch": 0.15166964865335592,
      "grad_norm": 0.0003646193945314735,
      "learning_rate": 8.483303513466442e-06,
      "loss": 0.0,
      "step": 9579
    },
    {
      "epoch": 0.15168548221099798,
      "grad_norm": 0.32697364687919617,
      "learning_rate": 8.48314517789002e-06,
      "loss": 0.0637,
      "step": 9580
    },
    {
      "epoch": 0.15170131576864004,
      "grad_norm": 0.41231417655944824,
      "learning_rate": 8.4829868423136e-06,
      "loss": 0.1815,
      "step": 9581
    },
    {
      "epoch": 0.15171714932628214,
      "grad_norm": 0.2644643783569336,
      "learning_rate": 8.482828506737179e-06,
      "loss": 0.0726,
      "step": 9582
    },
    {
      "epoch": 0.1517329828839242,
      "grad_norm": 0.4475284218788147,
      "learning_rate": 8.482670171160758e-06,
      "loss": 0.4043,
      "step": 9583
    },
    {
      "epoch": 0.15174881644156626,
      "grad_norm": 0.4665374755859375,
      "learning_rate": 8.482511835584339e-06,
      "loss": 0.5311,
      "step": 9584
    },
    {
      "epoch": 0.15176464999920833,
      "grad_norm": 0.26462069153785706,
      "learning_rate": 8.482353500007918e-06,
      "loss": 0.2303,
      "step": 9585
    },
    {
      "epoch": 0.1517804835568504,
      "grad_norm": 0.34963303804397583,
      "learning_rate": 8.482195164431497e-06,
      "loss": 0.1218,
      "step": 9586
    },
    {
      "epoch": 0.15179631711449246,
      "grad_norm": 0.2551138401031494,
      "learning_rate": 8.482036828855076e-06,
      "loss": 0.1013,
      "step": 9587
    },
    {
      "epoch": 0.15181215067213452,
      "grad_norm": 0.007466974202543497,
      "learning_rate": 8.481878493278655e-06,
      "loss": 0.0005,
      "step": 9588
    },
    {
      "epoch": 0.15182798422977659,
      "grad_norm": 0.0042232973501086235,
      "learning_rate": 8.481720157702234e-06,
      "loss": 0.0003,
      "step": 9589
    },
    {
      "epoch": 0.15184381778741865,
      "grad_norm": 0.40746256709098816,
      "learning_rate": 8.481561822125815e-06,
      "loss": 0.3742,
      "step": 9590
    },
    {
      "epoch": 0.15185965134506071,
      "grad_norm": 0.17943622171878815,
      "learning_rate": 8.481403486549394e-06,
      "loss": 0.0886,
      "step": 9591
    },
    {
      "epoch": 0.15187548490270278,
      "grad_norm": 0.03189383074641228,
      "learning_rate": 8.481245150972973e-06,
      "loss": 0.0024,
      "step": 9592
    },
    {
      "epoch": 0.15189131846034484,
      "grad_norm": 0.002369835739955306,
      "learning_rate": 8.481086815396552e-06,
      "loss": 0.0001,
      "step": 9593
    },
    {
      "epoch": 0.15190715201798694,
      "grad_norm": 0.04963565245270729,
      "learning_rate": 8.480928479820131e-06,
      "loss": 0.0025,
      "step": 9594
    },
    {
      "epoch": 0.151922985575629,
      "grad_norm": 0.0647817850112915,
      "learning_rate": 8.48077014424371e-06,
      "loss": 0.0057,
      "step": 9595
    },
    {
      "epoch": 0.15193881913327106,
      "grad_norm": 0.3334895372390747,
      "learning_rate": 8.480611808667291e-06,
      "loss": 0.1548,
      "step": 9596
    },
    {
      "epoch": 0.15195465269091313,
      "grad_norm": 0.1723627746105194,
      "learning_rate": 8.48045347309087e-06,
      "loss": 0.0132,
      "step": 9597
    },
    {
      "epoch": 0.1519704862485552,
      "grad_norm": 0.001188051188364625,
      "learning_rate": 8.48029513751445e-06,
      "loss": 0.0,
      "step": 9598
    },
    {
      "epoch": 0.15198631980619726,
      "grad_norm": 0.1788022369146347,
      "learning_rate": 8.480136801938028e-06,
      "loss": 0.1119,
      "step": 9599
    },
    {
      "epoch": 0.15200215336383932,
      "grad_norm": 0.01562479604035616,
      "learning_rate": 8.479978466361607e-06,
      "loss": 0.0009,
      "step": 9600
    },
    {
      "epoch": 0.15201798692148139,
      "grad_norm": 0.2260909378528595,
      "learning_rate": 8.479820130785186e-06,
      "loss": 0.0291,
      "step": 9601
    },
    {
      "epoch": 0.15203382047912345,
      "grad_norm": 0.00030519848223775625,
      "learning_rate": 8.479661795208766e-06,
      "loss": 0.0,
      "step": 9602
    },
    {
      "epoch": 0.1520496540367655,
      "grad_norm": 0.28340739011764526,
      "learning_rate": 8.479503459632346e-06,
      "loss": 0.0457,
      "step": 9603
    },
    {
      "epoch": 0.15206548759440758,
      "grad_norm": 0.00047720741713419557,
      "learning_rate": 8.479345124055924e-06,
      "loss": 0.0,
      "step": 9604
    },
    {
      "epoch": 0.15208132115204964,
      "grad_norm": 0.21777194738388062,
      "learning_rate": 8.479186788479504e-06,
      "loss": 0.0212,
      "step": 9605
    },
    {
      "epoch": 0.15209715470969173,
      "grad_norm": 0.00437580281868577,
      "learning_rate": 8.479028452903084e-06,
      "loss": 0.0002,
      "step": 9606
    },
    {
      "epoch": 0.1521129882673338,
      "grad_norm": 0.5520715117454529,
      "learning_rate": 8.478870117326663e-06,
      "loss": 0.4403,
      "step": 9607
    },
    {
      "epoch": 0.15212882182497586,
      "grad_norm": 0.22999097406864166,
      "learning_rate": 8.478711781750242e-06,
      "loss": 0.0782,
      "step": 9608
    },
    {
      "epoch": 0.15214465538261793,
      "grad_norm": 0.04049261659383774,
      "learning_rate": 8.478553446173823e-06,
      "loss": 0.0014,
      "step": 9609
    },
    {
      "epoch": 0.15216048894026,
      "grad_norm": 0.0003371053608134389,
      "learning_rate": 8.4783951105974e-06,
      "loss": 0.0,
      "step": 9610
    },
    {
      "epoch": 0.15217632249790206,
      "grad_norm": 0.9993274211883545,
      "learning_rate": 8.47823677502098e-06,
      "loss": 0.2562,
      "step": 9611
    },
    {
      "epoch": 0.15219215605554412,
      "grad_norm": 0.07667092233896255,
      "learning_rate": 8.47807843944456e-06,
      "loss": 0.0039,
      "step": 9612
    },
    {
      "epoch": 0.15220798961318618,
      "grad_norm": 0.5343232750892639,
      "learning_rate": 8.477920103868139e-06,
      "loss": 0.0995,
      "step": 9613
    },
    {
      "epoch": 0.15222382317082825,
      "grad_norm": 0.7316151261329651,
      "learning_rate": 8.477761768291718e-06,
      "loss": 0.3819,
      "step": 9614
    },
    {
      "epoch": 0.1522396567284703,
      "grad_norm": 0.010252140462398529,
      "learning_rate": 8.477603432715299e-06,
      "loss": 0.0006,
      "step": 9615
    },
    {
      "epoch": 0.15225549028611238,
      "grad_norm": 0.018114259466528893,
      "learning_rate": 8.477445097138876e-06,
      "loss": 0.0012,
      "step": 9616
    },
    {
      "epoch": 0.15227132384375444,
      "grad_norm": 0.01769999787211418,
      "learning_rate": 8.477286761562457e-06,
      "loss": 0.0007,
      "step": 9617
    },
    {
      "epoch": 0.15228715740139653,
      "grad_norm": 0.006579088978469372,
      "learning_rate": 8.477128425986036e-06,
      "loss": 0.0003,
      "step": 9618
    },
    {
      "epoch": 0.1523029909590386,
      "grad_norm": 0.0035772654227912426,
      "learning_rate": 8.476970090409615e-06,
      "loss": 0.0002,
      "step": 9619
    },
    {
      "epoch": 0.15231882451668066,
      "grad_norm": 0.5443078279495239,
      "learning_rate": 8.476811754833194e-06,
      "loss": 0.4423,
      "step": 9620
    },
    {
      "epoch": 0.15233465807432273,
      "grad_norm": 0.31835252046585083,
      "learning_rate": 8.476653419256773e-06,
      "loss": 0.0771,
      "step": 9621
    },
    {
      "epoch": 0.1523504916319648,
      "grad_norm": 0.5312141180038452,
      "learning_rate": 8.476495083680352e-06,
      "loss": 0.092,
      "step": 9622
    },
    {
      "epoch": 0.15236632518960685,
      "grad_norm": 0.5032494068145752,
      "learning_rate": 8.476336748103933e-06,
      "loss": 0.0436,
      "step": 9623
    },
    {
      "epoch": 0.15238215874724892,
      "grad_norm": 0.01894727535545826,
      "learning_rate": 8.476178412527512e-06,
      "loss": 0.0012,
      "step": 9624
    },
    {
      "epoch": 0.15239799230489098,
      "grad_norm": 0.6730527281761169,
      "learning_rate": 8.47602007695109e-06,
      "loss": 0.0822,
      "step": 9625
    },
    {
      "epoch": 0.15241382586253305,
      "grad_norm": 0.0016771841328591108,
      "learning_rate": 8.47586174137467e-06,
      "loss": 0.0,
      "step": 9626
    },
    {
      "epoch": 0.1524296594201751,
      "grad_norm": 0.41247162222862244,
      "learning_rate": 8.47570340579825e-06,
      "loss": 0.0584,
      "step": 9627
    },
    {
      "epoch": 0.15244549297781718,
      "grad_norm": 0.012098681181669235,
      "learning_rate": 8.475545070221828e-06,
      "loss": 0.0007,
      "step": 9628
    },
    {
      "epoch": 0.15246132653545924,
      "grad_norm": 0.011118194088339806,
      "learning_rate": 8.475386734645407e-06,
      "loss": 0.0006,
      "step": 9629
    },
    {
      "epoch": 0.15247716009310133,
      "grad_norm": 0.5009342432022095,
      "learning_rate": 8.475228399068988e-06,
      "loss": 0.0483,
      "step": 9630
    },
    {
      "epoch": 0.1524929936507434,
      "grad_norm": 0.25322723388671875,
      "learning_rate": 8.475070063492566e-06,
      "loss": 0.1672,
      "step": 9631
    },
    {
      "epoch": 0.15250882720838546,
      "grad_norm": 0.41265082359313965,
      "learning_rate": 8.474911727916146e-06,
      "loss": 0.4472,
      "step": 9632
    },
    {
      "epoch": 0.15252466076602753,
      "grad_norm": 0.30165916681289673,
      "learning_rate": 8.474753392339726e-06,
      "loss": 0.1539,
      "step": 9633
    },
    {
      "epoch": 0.1525404943236696,
      "grad_norm": 0.3481177091598511,
      "learning_rate": 8.474595056763305e-06,
      "loss": 0.0825,
      "step": 9634
    },
    {
      "epoch": 0.15255632788131165,
      "grad_norm": 0.016491180285811424,
      "learning_rate": 8.474436721186884e-06,
      "loss": 0.0009,
      "step": 9635
    },
    {
      "epoch": 0.15257216143895372,
      "grad_norm": 0.030443478375673294,
      "learning_rate": 8.474278385610464e-06,
      "loss": 0.0016,
      "step": 9636
    },
    {
      "epoch": 0.15258799499659578,
      "grad_norm": 0.2965905964374542,
      "learning_rate": 8.474120050034042e-06,
      "loss": 0.0845,
      "step": 9637
    },
    {
      "epoch": 0.15260382855423785,
      "grad_norm": 0.21210600435733795,
      "learning_rate": 8.473961714457623e-06,
      "loss": 0.0592,
      "step": 9638
    },
    {
      "epoch": 0.1526196621118799,
      "grad_norm": 0.319655179977417,
      "learning_rate": 8.473803378881202e-06,
      "loss": 0.165,
      "step": 9639
    },
    {
      "epoch": 0.15263549566952198,
      "grad_norm": 0.26868104934692383,
      "learning_rate": 8.47364504330478e-06,
      "loss": 0.1009,
      "step": 9640
    },
    {
      "epoch": 0.15265132922716404,
      "grad_norm": 0.22119848430156708,
      "learning_rate": 8.47348670772836e-06,
      "loss": 0.049,
      "step": 9641
    },
    {
      "epoch": 0.15266716278480613,
      "grad_norm": 0.3789654076099396,
      "learning_rate": 8.47332837215194e-06,
      "loss": 0.1959,
      "step": 9642
    },
    {
      "epoch": 0.1526829963424482,
      "grad_norm": 0.26049014925956726,
      "learning_rate": 8.473170036575518e-06,
      "loss": 0.2401,
      "step": 9643
    },
    {
      "epoch": 0.15269882990009026,
      "grad_norm": 0.21836751699447632,
      "learning_rate": 8.473011700999099e-06,
      "loss": 0.0544,
      "step": 9644
    },
    {
      "epoch": 0.15271466345773232,
      "grad_norm": 0.4534026086330414,
      "learning_rate": 8.472853365422678e-06,
      "loss": 0.2088,
      "step": 9645
    },
    {
      "epoch": 0.1527304970153744,
      "grad_norm": 0.22783301770687103,
      "learning_rate": 8.472695029846257e-06,
      "loss": 0.0879,
      "step": 9646
    },
    {
      "epoch": 0.15274633057301645,
      "grad_norm": 0.9268385171890259,
      "learning_rate": 8.472536694269836e-06,
      "loss": 0.2612,
      "step": 9647
    },
    {
      "epoch": 0.15276216413065852,
      "grad_norm": 0.010092124342918396,
      "learning_rate": 8.472378358693415e-06,
      "loss": 0.0005,
      "step": 9648
    },
    {
      "epoch": 0.15277799768830058,
      "grad_norm": 0.016285503283143044,
      "learning_rate": 8.472220023116994e-06,
      "loss": 0.0008,
      "step": 9649
    },
    {
      "epoch": 0.15279383124594265,
      "grad_norm": 0.3474585711956024,
      "learning_rate": 8.472061687540573e-06,
      "loss": 0.0428,
      "step": 9650
    },
    {
      "epoch": 0.1528096648035847,
      "grad_norm": 0.2144274115562439,
      "learning_rate": 8.471903351964154e-06,
      "loss": 0.101,
      "step": 9651
    },
    {
      "epoch": 0.15282549836122677,
      "grad_norm": 0.0025238445959985256,
      "learning_rate": 8.471745016387733e-06,
      "loss": 0.0001,
      "step": 9652
    },
    {
      "epoch": 0.15284133191886884,
      "grad_norm": 0.3152289092540741,
      "learning_rate": 8.471586680811312e-06,
      "loss": 0.0397,
      "step": 9653
    },
    {
      "epoch": 0.15285716547651093,
      "grad_norm": 0.42487210035324097,
      "learning_rate": 8.471428345234891e-06,
      "loss": 0.0744,
      "step": 9654
    },
    {
      "epoch": 0.152872999034153,
      "grad_norm": 0.3365195095539093,
      "learning_rate": 8.47127000965847e-06,
      "loss": 0.0324,
      "step": 9655
    },
    {
      "epoch": 0.15288883259179506,
      "grad_norm": 0.46278005838394165,
      "learning_rate": 8.47111167408205e-06,
      "loss": 0.438,
      "step": 9656
    },
    {
      "epoch": 0.15290466614943712,
      "grad_norm": 0.1833161860704422,
      "learning_rate": 8.47095333850563e-06,
      "loss": 0.0635,
      "step": 9657
    },
    {
      "epoch": 0.1529204997070792,
      "grad_norm": 0.658686637878418,
      "learning_rate": 8.47079500292921e-06,
      "loss": 0.074,
      "step": 9658
    },
    {
      "epoch": 0.15293633326472125,
      "grad_norm": 0.13013319671154022,
      "learning_rate": 8.470636667352788e-06,
      "loss": 0.0415,
      "step": 9659
    },
    {
      "epoch": 0.15295216682236332,
      "grad_norm": 0.1458083540201187,
      "learning_rate": 8.470478331776367e-06,
      "loss": 0.0404,
      "step": 9660
    },
    {
      "epoch": 0.15296800038000538,
      "grad_norm": 0.00025341511354781687,
      "learning_rate": 8.470319996199947e-06,
      "loss": 0.0,
      "step": 9661
    },
    {
      "epoch": 0.15298383393764745,
      "grad_norm": 0.0004988922155462205,
      "learning_rate": 8.470161660623526e-06,
      "loss": 0.0,
      "step": 9662
    },
    {
      "epoch": 0.1529996674952895,
      "grad_norm": 0.6963195204734802,
      "learning_rate": 8.470003325047106e-06,
      "loss": 0.5635,
      "step": 9663
    },
    {
      "epoch": 0.15301550105293157,
      "grad_norm": 0.36135709285736084,
      "learning_rate": 8.469844989470685e-06,
      "loss": 0.076,
      "step": 9664
    },
    {
      "epoch": 0.15303133461057364,
      "grad_norm": 0.27629122138023376,
      "learning_rate": 8.469686653894265e-06,
      "loss": 0.0538,
      "step": 9665
    },
    {
      "epoch": 0.1530471681682157,
      "grad_norm": 0.16766208410263062,
      "learning_rate": 8.469528318317844e-06,
      "loss": 0.0974,
      "step": 9666
    },
    {
      "epoch": 0.1530630017258578,
      "grad_norm": 0.05121355503797531,
      "learning_rate": 8.469369982741423e-06,
      "loss": 0.0022,
      "step": 9667
    },
    {
      "epoch": 0.15307883528349986,
      "grad_norm": 0.05476577579975128,
      "learning_rate": 8.469211647165002e-06,
      "loss": 0.0026,
      "step": 9668
    },
    {
      "epoch": 0.15309466884114192,
      "grad_norm": 0.15604491531848907,
      "learning_rate": 8.469053311588583e-06,
      "loss": 0.0586,
      "step": 9669
    },
    {
      "epoch": 0.153110502398784,
      "grad_norm": 0.12713703513145447,
      "learning_rate": 8.468894976012162e-06,
      "loss": 0.0445,
      "step": 9670
    },
    {
      "epoch": 0.15312633595642605,
      "grad_norm": 0.00015835583326406777,
      "learning_rate": 8.46873664043574e-06,
      "loss": 0.0,
      "step": 9671
    },
    {
      "epoch": 0.15314216951406812,
      "grad_norm": 0.4327852129936218,
      "learning_rate": 8.46857830485932e-06,
      "loss": 0.1124,
      "step": 9672
    },
    {
      "epoch": 0.15315800307171018,
      "grad_norm": 0.00045390755985863507,
      "learning_rate": 8.468419969282899e-06,
      "loss": 0.0,
      "step": 9673
    },
    {
      "epoch": 0.15317383662935224,
      "grad_norm": 0.42529061436653137,
      "learning_rate": 8.468261633706478e-06,
      "loss": 0.2687,
      "step": 9674
    },
    {
      "epoch": 0.1531896701869943,
      "grad_norm": 0.5261991024017334,
      "learning_rate": 8.468103298130057e-06,
      "loss": 0.8845,
      "step": 9675
    },
    {
      "epoch": 0.15320550374463637,
      "grad_norm": 0.012903044000267982,
      "learning_rate": 8.467944962553638e-06,
      "loss": 0.0006,
      "step": 9676
    },
    {
      "epoch": 0.15322133730227844,
      "grad_norm": 0.3324134051799774,
      "learning_rate": 8.467786626977215e-06,
      "loss": 0.1563,
      "step": 9677
    },
    {
      "epoch": 0.1532371708599205,
      "grad_norm": 0.45775339007377625,
      "learning_rate": 8.467628291400796e-06,
      "loss": 0.083,
      "step": 9678
    },
    {
      "epoch": 0.1532530044175626,
      "grad_norm": 0.46898147463798523,
      "learning_rate": 8.467469955824375e-06,
      "loss": 0.4952,
      "step": 9679
    },
    {
      "epoch": 0.15326883797520466,
      "grad_norm": 0.0008610107470303774,
      "learning_rate": 8.467311620247954e-06,
      "loss": 0.0,
      "step": 9680
    },
    {
      "epoch": 0.15328467153284672,
      "grad_norm": 0.15081146359443665,
      "learning_rate": 8.467153284671533e-06,
      "loss": 0.0392,
      "step": 9681
    },
    {
      "epoch": 0.1533005050904888,
      "grad_norm": 0.3564354479312897,
      "learning_rate": 8.466994949095112e-06,
      "loss": 0.1151,
      "step": 9682
    },
    {
      "epoch": 0.15331633864813085,
      "grad_norm": 0.1065881997346878,
      "learning_rate": 8.466836613518691e-06,
      "loss": 0.0332,
      "step": 9683
    },
    {
      "epoch": 0.15333217220577292,
      "grad_norm": 0.39315497875213623,
      "learning_rate": 8.466678277942272e-06,
      "loss": 0.0212,
      "step": 9684
    },
    {
      "epoch": 0.15334800576341498,
      "grad_norm": 0.5962719321250916,
      "learning_rate": 8.466519942365851e-06,
      "loss": 0.2499,
      "step": 9685
    },
    {
      "epoch": 0.15336383932105704,
      "grad_norm": 0.21688660979270935,
      "learning_rate": 8.46636160678943e-06,
      "loss": 0.0427,
      "step": 9686
    },
    {
      "epoch": 0.1533796728786991,
      "grad_norm": 0.24952258169651031,
      "learning_rate": 8.46620327121301e-06,
      "loss": 0.1581,
      "step": 9687
    },
    {
      "epoch": 0.15339550643634117,
      "grad_norm": 0.46951693296432495,
      "learning_rate": 8.466044935636588e-06,
      "loss": 0.1105,
      "step": 9688
    },
    {
      "epoch": 0.15341133999398324,
      "grad_norm": 0.2601688802242279,
      "learning_rate": 8.465886600060168e-06,
      "loss": 0.0638,
      "step": 9689
    },
    {
      "epoch": 0.1534271735516253,
      "grad_norm": 0.15318945050239563,
      "learning_rate": 8.465728264483748e-06,
      "loss": 0.0296,
      "step": 9690
    },
    {
      "epoch": 0.1534430071092674,
      "grad_norm": 0.7613785862922668,
      "learning_rate": 8.465569928907327e-06,
      "loss": 0.0898,
      "step": 9691
    },
    {
      "epoch": 0.15345884066690946,
      "grad_norm": 0.1993861198425293,
      "learning_rate": 8.465411593330906e-06,
      "loss": 0.0701,
      "step": 9692
    },
    {
      "epoch": 0.15347467422455152,
      "grad_norm": 0.00017691391985863447,
      "learning_rate": 8.465253257754486e-06,
      "loss": 0.0,
      "step": 9693
    },
    {
      "epoch": 0.15349050778219359,
      "grad_norm": 0.017609769478440285,
      "learning_rate": 8.465094922178065e-06,
      "loss": 0.0014,
      "step": 9694
    },
    {
      "epoch": 0.15350634133983565,
      "grad_norm": 0.34271737933158875,
      "learning_rate": 8.464936586601644e-06,
      "loss": 0.2491,
      "step": 9695
    },
    {
      "epoch": 0.15352217489747771,
      "grad_norm": 0.12431448698043823,
      "learning_rate": 8.464778251025224e-06,
      "loss": 0.0255,
      "step": 9696
    },
    {
      "epoch": 0.15353800845511978,
      "grad_norm": 0.15591517090797424,
      "learning_rate": 8.464619915448804e-06,
      "loss": 0.0604,
      "step": 9697
    },
    {
      "epoch": 0.15355384201276184,
      "grad_norm": 0.3850872218608856,
      "learning_rate": 8.464461579872381e-06,
      "loss": 0.1018,
      "step": 9698
    },
    {
      "epoch": 0.1535696755704039,
      "grad_norm": 0.11520593613386154,
      "learning_rate": 8.464303244295962e-06,
      "loss": 0.0548,
      "step": 9699
    },
    {
      "epoch": 0.15358550912804597,
      "grad_norm": 0.9805887341499329,
      "learning_rate": 8.46414490871954e-06,
      "loss": 0.2116,
      "step": 9700
    },
    {
      "epoch": 0.15360134268568804,
      "grad_norm": 0.21133491396903992,
      "learning_rate": 8.46398657314312e-06,
      "loss": 0.0547,
      "step": 9701
    },
    {
      "epoch": 0.1536171762433301,
      "grad_norm": 0.012397261336445808,
      "learning_rate": 8.463828237566699e-06,
      "loss": 0.0007,
      "step": 9702
    },
    {
      "epoch": 0.1536330098009722,
      "grad_norm": 0.5713045001029968,
      "learning_rate": 8.46366990199028e-06,
      "loss": 0.1504,
      "step": 9703
    },
    {
      "epoch": 0.15364884335861426,
      "grad_norm": 0.14912883937358856,
      "learning_rate": 8.463511566413857e-06,
      "loss": 0.0782,
      "step": 9704
    },
    {
      "epoch": 0.15366467691625632,
      "grad_norm": 0.7074523568153381,
      "learning_rate": 8.463353230837438e-06,
      "loss": 0.3487,
      "step": 9705
    },
    {
      "epoch": 0.15368051047389839,
      "grad_norm": 0.008241981267929077,
      "learning_rate": 8.463194895261017e-06,
      "loss": 0.0005,
      "step": 9706
    },
    {
      "epoch": 0.15369634403154045,
      "grad_norm": 0.43789950013160706,
      "learning_rate": 8.463036559684596e-06,
      "loss": 0.0959,
      "step": 9707
    },
    {
      "epoch": 0.1537121775891825,
      "grad_norm": 0.017687011510133743,
      "learning_rate": 8.462878224108175e-06,
      "loss": 0.001,
      "step": 9708
    },
    {
      "epoch": 0.15372801114682458,
      "grad_norm": 0.011184281669557095,
      "learning_rate": 8.462719888531756e-06,
      "loss": 0.0006,
      "step": 9709
    },
    {
      "epoch": 0.15374384470446664,
      "grad_norm": 0.8175572752952576,
      "learning_rate": 8.462561552955333e-06,
      "loss": 0.5108,
      "step": 9710
    },
    {
      "epoch": 0.1537596782621087,
      "grad_norm": 0.012594816274940968,
      "learning_rate": 8.462403217378914e-06,
      "loss": 0.0009,
      "step": 9711
    },
    {
      "epoch": 0.15377551181975077,
      "grad_norm": 0.508488655090332,
      "learning_rate": 8.462244881802493e-06,
      "loss": 0.8442,
      "step": 9712
    },
    {
      "epoch": 0.15379134537739284,
      "grad_norm": 0.3013730049133301,
      "learning_rate": 8.462086546226072e-06,
      "loss": 0.1467,
      "step": 9713
    },
    {
      "epoch": 0.1538071789350349,
      "grad_norm": 0.496573269367218,
      "learning_rate": 8.461928210649651e-06,
      "loss": 0.2002,
      "step": 9714
    },
    {
      "epoch": 0.153823012492677,
      "grad_norm": 0.014215131290256977,
      "learning_rate": 8.461769875073232e-06,
      "loss": 0.0014,
      "step": 9715
    },
    {
      "epoch": 0.15383884605031906,
      "grad_norm": 0.34953635931015015,
      "learning_rate": 8.46161153949681e-06,
      "loss": 0.2572,
      "step": 9716
    },
    {
      "epoch": 0.15385467960796112,
      "grad_norm": 0.34480488300323486,
      "learning_rate": 8.46145320392039e-06,
      "loss": 0.344,
      "step": 9717
    },
    {
      "epoch": 0.15387051316560318,
      "grad_norm": 0.6443595886230469,
      "learning_rate": 8.46129486834397e-06,
      "loss": 0.2796,
      "step": 9718
    },
    {
      "epoch": 0.15388634672324525,
      "grad_norm": 0.4201720356941223,
      "learning_rate": 8.461136532767548e-06,
      "loss": 0.1157,
      "step": 9719
    },
    {
      "epoch": 0.1539021802808873,
      "grad_norm": 0.8176178932189941,
      "learning_rate": 8.460978197191127e-06,
      "loss": 0.3289,
      "step": 9720
    },
    {
      "epoch": 0.15391801383852938,
      "grad_norm": 0.5465248823165894,
      "learning_rate": 8.460819861614707e-06,
      "loss": 0.4613,
      "step": 9721
    },
    {
      "epoch": 0.15393384739617144,
      "grad_norm": 0.0386819913983345,
      "learning_rate": 8.460661526038286e-06,
      "loss": 0.0026,
      "step": 9722
    },
    {
      "epoch": 0.1539496809538135,
      "grad_norm": 0.1815599799156189,
      "learning_rate": 8.460503190461865e-06,
      "loss": 0.0069,
      "step": 9723
    },
    {
      "epoch": 0.15396551451145557,
      "grad_norm": 0.03217129409313202,
      "learning_rate": 8.460344854885445e-06,
      "loss": 0.0021,
      "step": 9724
    },
    {
      "epoch": 0.15398134806909763,
      "grad_norm": 0.000521624693647027,
      "learning_rate": 8.460186519309025e-06,
      "loss": 0.0,
      "step": 9725
    },
    {
      "epoch": 0.1539971816267397,
      "grad_norm": 1.3452839851379395,
      "learning_rate": 8.460028183732604e-06,
      "loss": 0.2253,
      "step": 9726
    },
    {
      "epoch": 0.1540130151843818,
      "grad_norm": 0.33766573667526245,
      "learning_rate": 8.459869848156183e-06,
      "loss": 0.2588,
      "step": 9727
    },
    {
      "epoch": 0.15402884874202386,
      "grad_norm": 0.30615952610969543,
      "learning_rate": 8.459711512579762e-06,
      "loss": 0.1505,
      "step": 9728
    },
    {
      "epoch": 0.15404468229966592,
      "grad_norm": 0.5030099749565125,
      "learning_rate": 8.459553177003341e-06,
      "loss": 0.8651,
      "step": 9729
    },
    {
      "epoch": 0.15406051585730798,
      "grad_norm": 0.3450224697589874,
      "learning_rate": 8.459394841426922e-06,
      "loss": 0.1393,
      "step": 9730
    },
    {
      "epoch": 0.15407634941495005,
      "grad_norm": 0.24391640722751617,
      "learning_rate": 8.4592365058505e-06,
      "loss": 0.1367,
      "step": 9731
    },
    {
      "epoch": 0.1540921829725921,
      "grad_norm": 0.3306795358657837,
      "learning_rate": 8.45907817027408e-06,
      "loss": 0.1703,
      "step": 9732
    },
    {
      "epoch": 0.15410801653023418,
      "grad_norm": 0.0095926932990551,
      "learning_rate": 8.458919834697659e-06,
      "loss": 0.0006,
      "step": 9733
    },
    {
      "epoch": 0.15412385008787624,
      "grad_norm": 0.475481241941452,
      "learning_rate": 8.458761499121238e-06,
      "loss": 0.7036,
      "step": 9734
    },
    {
      "epoch": 0.1541396836455183,
      "grad_norm": 0.35031014680862427,
      "learning_rate": 8.458603163544817e-06,
      "loss": 0.0962,
      "step": 9735
    },
    {
      "epoch": 0.15415551720316037,
      "grad_norm": 0.37793079018592834,
      "learning_rate": 8.458444827968398e-06,
      "loss": 0.2831,
      "step": 9736
    },
    {
      "epoch": 0.15417135076080243,
      "grad_norm": 0.02366246096789837,
      "learning_rate": 8.458286492391977e-06,
      "loss": 0.0013,
      "step": 9737
    },
    {
      "epoch": 0.1541871843184445,
      "grad_norm": 0.607745349407196,
      "learning_rate": 8.458128156815556e-06,
      "loss": 0.206,
      "step": 9738
    },
    {
      "epoch": 0.1542030178760866,
      "grad_norm": 0.5446941256523132,
      "learning_rate": 8.457969821239135e-06,
      "loss": 0.3376,
      "step": 9739
    },
    {
      "epoch": 0.15421885143372865,
      "grad_norm": 0.3815706968307495,
      "learning_rate": 8.457811485662714e-06,
      "loss": 0.1109,
      "step": 9740
    },
    {
      "epoch": 0.15423468499137072,
      "grad_norm": 0.2816147208213806,
      "learning_rate": 8.457653150086293e-06,
      "loss": 0.1563,
      "step": 9741
    },
    {
      "epoch": 0.15425051854901278,
      "grad_norm": 0.6370174288749695,
      "learning_rate": 8.457494814509874e-06,
      "loss": 0.8865,
      "step": 9742
    },
    {
      "epoch": 0.15426635210665485,
      "grad_norm": 0.39696016907691956,
      "learning_rate": 8.457336478933453e-06,
      "loss": 0.2841,
      "step": 9743
    },
    {
      "epoch": 0.1542821856642969,
      "grad_norm": 0.0014377464540302753,
      "learning_rate": 8.457178143357032e-06,
      "loss": 0.0,
      "step": 9744
    },
    {
      "epoch": 0.15429801922193898,
      "grad_norm": 0.32926762104034424,
      "learning_rate": 8.457019807780611e-06,
      "loss": 0.1663,
      "step": 9745
    },
    {
      "epoch": 0.15431385277958104,
      "grad_norm": 0.23693950474262238,
      "learning_rate": 8.45686147220419e-06,
      "loss": 0.1071,
      "step": 9746
    },
    {
      "epoch": 0.1543296863372231,
      "grad_norm": 0.4425146281719208,
      "learning_rate": 8.45670313662777e-06,
      "loss": 0.0862,
      "step": 9747
    },
    {
      "epoch": 0.15434551989486517,
      "grad_norm": 0.0005763611407019198,
      "learning_rate": 8.456544801051348e-06,
      "loss": 0.0,
      "step": 9748
    },
    {
      "epoch": 0.15436135345250723,
      "grad_norm": 0.4524645209312439,
      "learning_rate": 8.456386465474928e-06,
      "loss": 0.4035,
      "step": 9749
    },
    {
      "epoch": 0.1543771870101493,
      "grad_norm": 0.3907000720500946,
      "learning_rate": 8.456228129898507e-06,
      "loss": 0.1496,
      "step": 9750
    },
    {
      "epoch": 0.1543930205677914,
      "grad_norm": 0.3858616054058075,
      "learning_rate": 8.456069794322087e-06,
      "loss": 0.0972,
      "step": 9751
    },
    {
      "epoch": 0.15440885412543345,
      "grad_norm": 0.35759034752845764,
      "learning_rate": 8.455911458745666e-06,
      "loss": 0.2027,
      "step": 9752
    },
    {
      "epoch": 0.15442468768307552,
      "grad_norm": 0.002649590838700533,
      "learning_rate": 8.455753123169246e-06,
      "loss": 0.0001,
      "step": 9753
    },
    {
      "epoch": 0.15444052124071758,
      "grad_norm": 0.7740461230278015,
      "learning_rate": 8.455594787592825e-06,
      "loss": 0.5578,
      "step": 9754
    },
    {
      "epoch": 0.15445635479835965,
      "grad_norm": 0.4727817475795746,
      "learning_rate": 8.455436452016404e-06,
      "loss": 0.1531,
      "step": 9755
    },
    {
      "epoch": 0.1544721883560017,
      "grad_norm": 0.433728963136673,
      "learning_rate": 8.455278116439983e-06,
      "loss": 0.5651,
      "step": 9756
    },
    {
      "epoch": 0.15448802191364377,
      "grad_norm": 0.3321579098701477,
      "learning_rate": 8.455119780863564e-06,
      "loss": 0.0903,
      "step": 9757
    },
    {
      "epoch": 0.15450385547128584,
      "grad_norm": 0.5781434178352356,
      "learning_rate": 8.454961445287143e-06,
      "loss": 0.0137,
      "step": 9758
    },
    {
      "epoch": 0.1545196890289279,
      "grad_norm": 0.11784680932760239,
      "learning_rate": 8.454803109710722e-06,
      "loss": 0.0067,
      "step": 9759
    },
    {
      "epoch": 0.15453552258656997,
      "grad_norm": 0.1327228546142578,
      "learning_rate": 8.4546447741343e-06,
      "loss": 0.0515,
      "step": 9760
    },
    {
      "epoch": 0.15455135614421203,
      "grad_norm": 0.0016550063155591488,
      "learning_rate": 8.45448643855788e-06,
      "loss": 0.0,
      "step": 9761
    },
    {
      "epoch": 0.1545671897018541,
      "grad_norm": 0.22198697924613953,
      "learning_rate": 8.454328102981459e-06,
      "loss": 0.0701,
      "step": 9762
    },
    {
      "epoch": 0.1545830232594962,
      "grad_norm": 0.4115927517414093,
      "learning_rate": 8.45416976740504e-06,
      "loss": 0.1547,
      "step": 9763
    },
    {
      "epoch": 0.15459885681713825,
      "grad_norm": 0.25173959136009216,
      "learning_rate": 8.454011431828619e-06,
      "loss": 0.1234,
      "step": 9764
    },
    {
      "epoch": 0.15461469037478032,
      "grad_norm": 0.8176897764205933,
      "learning_rate": 8.453853096252198e-06,
      "loss": 0.1695,
      "step": 9765
    },
    {
      "epoch": 0.15463052393242238,
      "grad_norm": 0.3639891445636749,
      "learning_rate": 8.453694760675777e-06,
      "loss": 0.0848,
      "step": 9766
    },
    {
      "epoch": 0.15464635749006445,
      "grad_norm": 0.3024521768093109,
      "learning_rate": 8.453536425099356e-06,
      "loss": 0.1594,
      "step": 9767
    },
    {
      "epoch": 0.1546621910477065,
      "grad_norm": 0.2349650263786316,
      "learning_rate": 8.453378089522935e-06,
      "loss": 0.0274,
      "step": 9768
    },
    {
      "epoch": 0.15467802460534857,
      "grad_norm": 0.021028656512498856,
      "learning_rate": 8.453219753946514e-06,
      "loss": 0.0011,
      "step": 9769
    },
    {
      "epoch": 0.15469385816299064,
      "grad_norm": 0.014656934887170792,
      "learning_rate": 8.453061418370095e-06,
      "loss": 0.0004,
      "step": 9770
    },
    {
      "epoch": 0.1547096917206327,
      "grad_norm": 0.21238219738006592,
      "learning_rate": 8.452903082793672e-06,
      "loss": 0.0602,
      "step": 9771
    },
    {
      "epoch": 0.15472552527827477,
      "grad_norm": 0.4090563654899597,
      "learning_rate": 8.452744747217253e-06,
      "loss": 0.1355,
      "step": 9772
    },
    {
      "epoch": 0.15474135883591683,
      "grad_norm": 0.0006550585967488587,
      "learning_rate": 8.452586411640832e-06,
      "loss": 0.0,
      "step": 9773
    },
    {
      "epoch": 0.1547571923935589,
      "grad_norm": 0.2409363090991974,
      "learning_rate": 8.452428076064411e-06,
      "loss": 0.0835,
      "step": 9774
    },
    {
      "epoch": 0.154773025951201,
      "grad_norm": 1.1476976871490479,
      "learning_rate": 8.45226974048799e-06,
      "loss": 0.0854,
      "step": 9775
    },
    {
      "epoch": 0.15478885950884305,
      "grad_norm": 0.3895599842071533,
      "learning_rate": 8.452111404911571e-06,
      "loss": 0.2762,
      "step": 9776
    },
    {
      "epoch": 0.15480469306648512,
      "grad_norm": 0.024380462244153023,
      "learning_rate": 8.451953069335149e-06,
      "loss": 0.0011,
      "step": 9777
    },
    {
      "epoch": 0.15482052662412718,
      "grad_norm": 0.49871551990509033,
      "learning_rate": 8.45179473375873e-06,
      "loss": 0.4355,
      "step": 9778
    },
    {
      "epoch": 0.15483636018176924,
      "grad_norm": 0.0029128058813512325,
      "learning_rate": 8.451636398182308e-06,
      "loss": 0.0001,
      "step": 9779
    },
    {
      "epoch": 0.1548521937394113,
      "grad_norm": 0.8378847241401672,
      "learning_rate": 8.451478062605887e-06,
      "loss": 0.2734,
      "step": 9780
    },
    {
      "epoch": 0.15486802729705337,
      "grad_norm": 0.3400830626487732,
      "learning_rate": 8.451319727029467e-06,
      "loss": 0.1283,
      "step": 9781
    },
    {
      "epoch": 0.15488386085469544,
      "grad_norm": 0.16732476651668549,
      "learning_rate": 8.451161391453047e-06,
      "loss": 0.0057,
      "step": 9782
    },
    {
      "epoch": 0.1548996944123375,
      "grad_norm": 0.1449066400527954,
      "learning_rate": 8.451003055876625e-06,
      "loss": 0.0648,
      "step": 9783
    },
    {
      "epoch": 0.15491552796997957,
      "grad_norm": 0.23244605958461761,
      "learning_rate": 8.450844720300205e-06,
      "loss": 0.18,
      "step": 9784
    },
    {
      "epoch": 0.15493136152762163,
      "grad_norm": 0.8544503450393677,
      "learning_rate": 8.450686384723785e-06,
      "loss": 0.8968,
      "step": 9785
    },
    {
      "epoch": 0.1549471950852637,
      "grad_norm": 0.2418254017829895,
      "learning_rate": 8.450528049147364e-06,
      "loss": 0.0252,
      "step": 9786
    },
    {
      "epoch": 0.1549630286429058,
      "grad_norm": 0.21105501055717468,
      "learning_rate": 8.450369713570943e-06,
      "loss": 0.062,
      "step": 9787
    },
    {
      "epoch": 0.15497886220054785,
      "grad_norm": 0.0011783139780163765,
      "learning_rate": 8.450211377994523e-06,
      "loss": 0.0,
      "step": 9788
    },
    {
      "epoch": 0.15499469575818992,
      "grad_norm": 0.43516743183135986,
      "learning_rate": 8.450053042418101e-06,
      "loss": 0.0332,
      "step": 9789
    },
    {
      "epoch": 0.15501052931583198,
      "grad_norm": 0.35769233107566833,
      "learning_rate": 8.449894706841682e-06,
      "loss": 0.0089,
      "step": 9790
    },
    {
      "epoch": 0.15502636287347404,
      "grad_norm": 0.37594813108444214,
      "learning_rate": 8.44973637126526e-06,
      "loss": 0.1256,
      "step": 9791
    },
    {
      "epoch": 0.1550421964311161,
      "grad_norm": 0.27309271693229675,
      "learning_rate": 8.44957803568884e-06,
      "loss": 0.1787,
      "step": 9792
    },
    {
      "epoch": 0.15505802998875817,
      "grad_norm": 0.18522320687770844,
      "learning_rate": 8.449419700112419e-06,
      "loss": 0.0674,
      "step": 9793
    },
    {
      "epoch": 0.15507386354640024,
      "grad_norm": 0.3456309735774994,
      "learning_rate": 8.449261364535998e-06,
      "loss": 0.0712,
      "step": 9794
    },
    {
      "epoch": 0.1550896971040423,
      "grad_norm": 0.046394772827625275,
      "learning_rate": 8.449103028959577e-06,
      "loss": 0.0031,
      "step": 9795
    },
    {
      "epoch": 0.15510553066168437,
      "grad_norm": 0.9425063729286194,
      "learning_rate": 8.448944693383156e-06,
      "loss": 0.1314,
      "step": 9796
    },
    {
      "epoch": 0.15512136421932643,
      "grad_norm": 0.0008093225187622011,
      "learning_rate": 8.448786357806737e-06,
      "loss": 0.0,
      "step": 9797
    },
    {
      "epoch": 0.1551371977769685,
      "grad_norm": 0.18233272433280945,
      "learning_rate": 8.448628022230316e-06,
      "loss": 0.0671,
      "step": 9798
    },
    {
      "epoch": 0.15515303133461059,
      "grad_norm": 0.012342757545411587,
      "learning_rate": 8.448469686653895e-06,
      "loss": 0.0007,
      "step": 9799
    },
    {
      "epoch": 0.15516886489225265,
      "grad_norm": 0.0008760430500842631,
      "learning_rate": 8.448311351077474e-06,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 0.15518469844989471,
      "grad_norm": 0.10836564004421234,
      "learning_rate": 8.448153015501053e-06,
      "loss": 0.0041,
      "step": 9801
    },
    {
      "epoch": 0.15520053200753678,
      "grad_norm": 0.175336092710495,
      "learning_rate": 8.447994679924632e-06,
      "loss": 0.0517,
      "step": 9802
    },
    {
      "epoch": 0.15521636556517884,
      "grad_norm": 0.0034597860649228096,
      "learning_rate": 8.447836344348213e-06,
      "loss": 0.0001,
      "step": 9803
    },
    {
      "epoch": 0.1552321991228209,
      "grad_norm": 0.27750977873802185,
      "learning_rate": 8.447678008771792e-06,
      "loss": 0.0248,
      "step": 9804
    },
    {
      "epoch": 0.15524803268046297,
      "grad_norm": 0.0019438249291852117,
      "learning_rate": 8.447519673195371e-06,
      "loss": 0.0,
      "step": 9805
    },
    {
      "epoch": 0.15526386623810504,
      "grad_norm": 0.25363627076148987,
      "learning_rate": 8.44736133761895e-06,
      "loss": 0.1139,
      "step": 9806
    },
    {
      "epoch": 0.1552796997957471,
      "grad_norm": 0.014044192619621754,
      "learning_rate": 8.44720300204253e-06,
      "loss": 0.0007,
      "step": 9807
    },
    {
      "epoch": 0.15529553335338916,
      "grad_norm": 0.10616223514080048,
      "learning_rate": 8.447044666466108e-06,
      "loss": 0.0183,
      "step": 9808
    },
    {
      "epoch": 0.15531136691103123,
      "grad_norm": 0.017949245870113373,
      "learning_rate": 8.44688633088969e-06,
      "loss": 0.001,
      "step": 9809
    },
    {
      "epoch": 0.1553272004686733,
      "grad_norm": 0.3295343518257141,
      "learning_rate": 8.446727995313268e-06,
      "loss": 0.1884,
      "step": 9810
    },
    {
      "epoch": 0.15534303402631539,
      "grad_norm": 0.4615184962749481,
      "learning_rate": 8.446569659736847e-06,
      "loss": 0.188,
      "step": 9811
    },
    {
      "epoch": 0.15535886758395745,
      "grad_norm": 0.3681599795818329,
      "learning_rate": 8.446411324160426e-06,
      "loss": 0.2575,
      "step": 9812
    },
    {
      "epoch": 0.1553747011415995,
      "grad_norm": 0.5784664154052734,
      "learning_rate": 8.446252988584006e-06,
      "loss": 0.7328,
      "step": 9813
    },
    {
      "epoch": 0.15539053469924158,
      "grad_norm": 0.26603469252586365,
      "learning_rate": 8.446094653007585e-06,
      "loss": 0.0614,
      "step": 9814
    },
    {
      "epoch": 0.15540636825688364,
      "grad_norm": 0.5437546968460083,
      "learning_rate": 8.445936317431165e-06,
      "loss": 0.2159,
      "step": 9815
    },
    {
      "epoch": 0.1554222018145257,
      "grad_norm": 0.4280186593532562,
      "learning_rate": 8.445777981854743e-06,
      "loss": 0.3316,
      "step": 9816
    },
    {
      "epoch": 0.15543803537216777,
      "grad_norm": 0.6877373456954956,
      "learning_rate": 8.445619646278322e-06,
      "loss": 0.7389,
      "step": 9817
    },
    {
      "epoch": 0.15545386892980984,
      "grad_norm": 0.2495090365409851,
      "learning_rate": 8.445461310701903e-06,
      "loss": 0.2096,
      "step": 9818
    },
    {
      "epoch": 0.1554697024874519,
      "grad_norm": 0.3602297306060791,
      "learning_rate": 8.445302975125482e-06,
      "loss": 0.0066,
      "step": 9819
    },
    {
      "epoch": 0.15548553604509396,
      "grad_norm": 0.22476452589035034,
      "learning_rate": 8.44514463954906e-06,
      "loss": 0.0379,
      "step": 9820
    },
    {
      "epoch": 0.15550136960273603,
      "grad_norm": 0.2376774549484253,
      "learning_rate": 8.44498630397264e-06,
      "loss": 0.008,
      "step": 9821
    },
    {
      "epoch": 0.1555172031603781,
      "grad_norm": 0.15423214435577393,
      "learning_rate": 8.444827968396219e-06,
      "loss": 0.054,
      "step": 9822
    },
    {
      "epoch": 0.15553303671802018,
      "grad_norm": 0.29851797223091125,
      "learning_rate": 8.444669632819798e-06,
      "loss": 0.1927,
      "step": 9823
    },
    {
      "epoch": 0.15554887027566225,
      "grad_norm": 0.4919227361679077,
      "learning_rate": 8.444511297243379e-06,
      "loss": 0.0795,
      "step": 9824
    },
    {
      "epoch": 0.1555647038333043,
      "grad_norm": 0.2926434278488159,
      "learning_rate": 8.444352961666958e-06,
      "loss": 0.0722,
      "step": 9825
    },
    {
      "epoch": 0.15558053739094638,
      "grad_norm": 0.0010615438222885132,
      "learning_rate": 8.444194626090537e-06,
      "loss": 0.0,
      "step": 9826
    },
    {
      "epoch": 0.15559637094858844,
      "grad_norm": 0.4502362608909607,
      "learning_rate": 8.444036290514116e-06,
      "loss": 0.4609,
      "step": 9827
    },
    {
      "epoch": 0.1556122045062305,
      "grad_norm": 0.000465723016532138,
      "learning_rate": 8.443877954937695e-06,
      "loss": 0.0,
      "step": 9828
    },
    {
      "epoch": 0.15562803806387257,
      "grad_norm": 0.00043258050573058426,
      "learning_rate": 8.443719619361274e-06,
      "loss": 0.0,
      "step": 9829
    },
    {
      "epoch": 0.15564387162151463,
      "grad_norm": 0.013686049729585648,
      "learning_rate": 8.443561283784855e-06,
      "loss": 0.0007,
      "step": 9830
    },
    {
      "epoch": 0.1556597051791567,
      "grad_norm": 0.40252065658569336,
      "learning_rate": 8.443402948208434e-06,
      "loss": 0.2758,
      "step": 9831
    },
    {
      "epoch": 0.15567553873679876,
      "grad_norm": 0.38819360733032227,
      "learning_rate": 8.443244612632013e-06,
      "loss": 0.0817,
      "step": 9832
    },
    {
      "epoch": 0.15569137229444083,
      "grad_norm": 0.4159333109855652,
      "learning_rate": 8.443086277055592e-06,
      "loss": 0.1293,
      "step": 9833
    },
    {
      "epoch": 0.1557072058520829,
      "grad_norm": 0.3099590837955475,
      "learning_rate": 8.442927941479171e-06,
      "loss": 0.1786,
      "step": 9834
    },
    {
      "epoch": 0.15572303940972498,
      "grad_norm": 0.01833336614072323,
      "learning_rate": 8.44276960590275e-06,
      "loss": 0.0011,
      "step": 9835
    },
    {
      "epoch": 0.15573887296736705,
      "grad_norm": 0.006390003487467766,
      "learning_rate": 8.442611270326331e-06,
      "loss": 0.0004,
      "step": 9836
    },
    {
      "epoch": 0.1557547065250091,
      "grad_norm": 0.27589619159698486,
      "learning_rate": 8.44245293474991e-06,
      "loss": 0.1472,
      "step": 9837
    },
    {
      "epoch": 0.15577054008265118,
      "grad_norm": 0.6083425879478455,
      "learning_rate": 8.44229459917349e-06,
      "loss": 0.1174,
      "step": 9838
    },
    {
      "epoch": 0.15578637364029324,
      "grad_norm": 0.2534751892089844,
      "learning_rate": 8.442136263597068e-06,
      "loss": 0.047,
      "step": 9839
    },
    {
      "epoch": 0.1558022071979353,
      "grad_norm": 0.2385634332895279,
      "learning_rate": 8.441977928020647e-06,
      "loss": 0.0579,
      "step": 9840
    },
    {
      "epoch": 0.15581804075557737,
      "grad_norm": 0.07805988192558289,
      "learning_rate": 8.441819592444227e-06,
      "loss": 0.003,
      "step": 9841
    },
    {
      "epoch": 0.15583387431321943,
      "grad_norm": 0.06857676059007645,
      "learning_rate": 8.441661256867806e-06,
      "loss": 0.0049,
      "step": 9842
    },
    {
      "epoch": 0.1558497078708615,
      "grad_norm": 0.04162859544157982,
      "learning_rate": 8.441502921291386e-06,
      "loss": 0.0019,
      "step": 9843
    },
    {
      "epoch": 0.15586554142850356,
      "grad_norm": 0.37919801473617554,
      "learning_rate": 8.441344585714964e-06,
      "loss": 0.0637,
      "step": 9844
    },
    {
      "epoch": 0.15588137498614563,
      "grad_norm": 0.5341718196868896,
      "learning_rate": 8.441186250138545e-06,
      "loss": 0.0561,
      "step": 9845
    },
    {
      "epoch": 0.1558972085437877,
      "grad_norm": 0.014738818630576134,
      "learning_rate": 8.441027914562124e-06,
      "loss": 0.001,
      "step": 9846
    },
    {
      "epoch": 0.15591304210142978,
      "grad_norm": 0.14973360300064087,
      "learning_rate": 8.440869578985703e-06,
      "loss": 0.0224,
      "step": 9847
    },
    {
      "epoch": 0.15592887565907185,
      "grad_norm": 0.7798945307731628,
      "learning_rate": 8.440711243409282e-06,
      "loss": 0.0761,
      "step": 9848
    },
    {
      "epoch": 0.1559447092167139,
      "grad_norm": 0.4624551236629486,
      "learning_rate": 8.440552907832863e-06,
      "loss": 0.4557,
      "step": 9849
    },
    {
      "epoch": 0.15596054277435598,
      "grad_norm": 0.000559887383133173,
      "learning_rate": 8.44039457225644e-06,
      "loss": 0.0,
      "step": 9850
    },
    {
      "epoch": 0.15597637633199804,
      "grad_norm": 0.030990691855549812,
      "learning_rate": 8.44023623668002e-06,
      "loss": 0.0047,
      "step": 9851
    },
    {
      "epoch": 0.1559922098896401,
      "grad_norm": 0.0002767904952634126,
      "learning_rate": 8.4400779011036e-06,
      "loss": 0.0,
      "step": 9852
    },
    {
      "epoch": 0.15600804344728217,
      "grad_norm": 0.20458318293094635,
      "learning_rate": 8.439919565527179e-06,
      "loss": 0.0457,
      "step": 9853
    },
    {
      "epoch": 0.15602387700492423,
      "grad_norm": 0.00021765148267149925,
      "learning_rate": 8.439761229950758e-06,
      "loss": 0.0,
      "step": 9854
    },
    {
      "epoch": 0.1560397105625663,
      "grad_norm": 0.02234380878508091,
      "learning_rate": 8.439602894374339e-06,
      "loss": 0.0003,
      "step": 9855
    },
    {
      "epoch": 0.15605554412020836,
      "grad_norm": 0.49666568636894226,
      "learning_rate": 8.439444558797916e-06,
      "loss": 0.1916,
      "step": 9856
    },
    {
      "epoch": 0.15607137767785043,
      "grad_norm": 0.43779024481773376,
      "learning_rate": 8.439286223221497e-06,
      "loss": 0.4842,
      "step": 9857
    },
    {
      "epoch": 0.1560872112354925,
      "grad_norm": 0.0051167551428079605,
      "learning_rate": 8.439127887645076e-06,
      "loss": 0.0001,
      "step": 9858
    },
    {
      "epoch": 0.15610304479313458,
      "grad_norm": 0.005047385115176439,
      "learning_rate": 8.438969552068655e-06,
      "loss": 0.0003,
      "step": 9859
    },
    {
      "epoch": 0.15611887835077665,
      "grad_norm": 0.6509031057357788,
      "learning_rate": 8.438811216492234e-06,
      "loss": 0.1108,
      "step": 9860
    },
    {
      "epoch": 0.1561347119084187,
      "grad_norm": 0.17794570326805115,
      "learning_rate": 8.438652880915815e-06,
      "loss": 0.0841,
      "step": 9861
    },
    {
      "epoch": 0.15615054546606078,
      "grad_norm": 0.2914249300956726,
      "learning_rate": 8.438494545339392e-06,
      "loss": 0.1405,
      "step": 9862
    },
    {
      "epoch": 0.15616637902370284,
      "grad_norm": 0.00023510545725002885,
      "learning_rate": 8.438336209762973e-06,
      "loss": 0.0,
      "step": 9863
    },
    {
      "epoch": 0.1561822125813449,
      "grad_norm": 0.0007010509143583477,
      "learning_rate": 8.438177874186552e-06,
      "loss": 0.0,
      "step": 9864
    },
    {
      "epoch": 0.15619804613898697,
      "grad_norm": 0.296377956867218,
      "learning_rate": 8.438019538610131e-06,
      "loss": 0.1876,
      "step": 9865
    },
    {
      "epoch": 0.15621387969662903,
      "grad_norm": 0.3471231162548065,
      "learning_rate": 8.43786120303371e-06,
      "loss": 0.0691,
      "step": 9866
    },
    {
      "epoch": 0.1562297132542711,
      "grad_norm": 0.4021585285663605,
      "learning_rate": 8.43770286745729e-06,
      "loss": 0.1099,
      "step": 9867
    },
    {
      "epoch": 0.15624554681191316,
      "grad_norm": 0.1919202357530594,
      "learning_rate": 8.437544531880868e-06,
      "loss": 0.0741,
      "step": 9868
    },
    {
      "epoch": 0.15626138036955523,
      "grad_norm": 0.00019827218784485012,
      "learning_rate": 8.437386196304448e-06,
      "loss": 0.0,
      "step": 9869
    },
    {
      "epoch": 0.1562772139271973,
      "grad_norm": 0.3841840624809265,
      "learning_rate": 8.437227860728028e-06,
      "loss": 0.3261,
      "step": 9870
    },
    {
      "epoch": 0.15629304748483938,
      "grad_norm": 0.17308850586414337,
      "learning_rate": 8.437069525151607e-06,
      "loss": 0.0471,
      "step": 9871
    },
    {
      "epoch": 0.15630888104248145,
      "grad_norm": 0.25457340478897095,
      "learning_rate": 8.436911189575187e-06,
      "loss": 0.0543,
      "step": 9872
    },
    {
      "epoch": 0.1563247146001235,
      "grad_norm": 0.2075560986995697,
      "learning_rate": 8.436752853998766e-06,
      "loss": 0.0534,
      "step": 9873
    },
    {
      "epoch": 0.15634054815776557,
      "grad_norm": 0.35580235719680786,
      "learning_rate": 8.436594518422345e-06,
      "loss": 0.2194,
      "step": 9874
    },
    {
      "epoch": 0.15635638171540764,
      "grad_norm": 0.4052042067050934,
      "learning_rate": 8.436436182845924e-06,
      "loss": 0.1508,
      "step": 9875
    },
    {
      "epoch": 0.1563722152730497,
      "grad_norm": 0.025463657453656197,
      "learning_rate": 8.436277847269505e-06,
      "loss": 0.0014,
      "step": 9876
    },
    {
      "epoch": 0.15638804883069177,
      "grad_norm": 0.5407986044883728,
      "learning_rate": 8.436119511693082e-06,
      "loss": 0.1796,
      "step": 9877
    },
    {
      "epoch": 0.15640388238833383,
      "grad_norm": 0.25871431827545166,
      "learning_rate": 8.435961176116663e-06,
      "loss": 0.0975,
      "step": 9878
    },
    {
      "epoch": 0.1564197159459759,
      "grad_norm": 0.013849081471562386,
      "learning_rate": 8.435802840540242e-06,
      "loss": 0.0007,
      "step": 9879
    },
    {
      "epoch": 0.15643554950361796,
      "grad_norm": 0.23763519525527954,
      "learning_rate": 8.43564450496382e-06,
      "loss": 0.0716,
      "step": 9880
    },
    {
      "epoch": 0.15645138306126002,
      "grad_norm": 0.01612008549273014,
      "learning_rate": 8.4354861693874e-06,
      "loss": 0.0011,
      "step": 9881
    },
    {
      "epoch": 0.1564672166189021,
      "grad_norm": 0.1522173285484314,
      "learning_rate": 8.43532783381098e-06,
      "loss": 0.0592,
      "step": 9882
    },
    {
      "epoch": 0.15648305017654418,
      "grad_norm": 0.3794674873352051,
      "learning_rate": 8.435169498234558e-06,
      "loss": 0.1744,
      "step": 9883
    },
    {
      "epoch": 0.15649888373418624,
      "grad_norm": 0.2649516761302948,
      "learning_rate": 8.435011162658139e-06,
      "loss": 0.0465,
      "step": 9884
    },
    {
      "epoch": 0.1565147172918283,
      "grad_norm": 0.5091006755828857,
      "learning_rate": 8.434852827081718e-06,
      "loss": 0.3525,
      "step": 9885
    },
    {
      "epoch": 0.15653055084947037,
      "grad_norm": 0.01198292151093483,
      "learning_rate": 8.434694491505297e-06,
      "loss": 0.0006,
      "step": 9886
    },
    {
      "epoch": 0.15654638440711244,
      "grad_norm": 0.48106908798217773,
      "learning_rate": 8.434536155928876e-06,
      "loss": 0.0317,
      "step": 9887
    },
    {
      "epoch": 0.1565622179647545,
      "grad_norm": 0.5641463994979858,
      "learning_rate": 8.434377820352457e-06,
      "loss": 0.1755,
      "step": 9888
    },
    {
      "epoch": 0.15657805152239657,
      "grad_norm": 0.5659754872322083,
      "learning_rate": 8.434219484776034e-06,
      "loss": 0.2051,
      "step": 9889
    },
    {
      "epoch": 0.15659388508003863,
      "grad_norm": 0.424893319606781,
      "learning_rate": 8.434061149199613e-06,
      "loss": 0.0589,
      "step": 9890
    },
    {
      "epoch": 0.1566097186376807,
      "grad_norm": 0.3703862130641937,
      "learning_rate": 8.433902813623194e-06,
      "loss": 0.0841,
      "step": 9891
    },
    {
      "epoch": 0.15662555219532276,
      "grad_norm": 0.5728724002838135,
      "learning_rate": 8.433744478046773e-06,
      "loss": 0.0214,
      "step": 9892
    },
    {
      "epoch": 0.15664138575296482,
      "grad_norm": 0.2555430233478546,
      "learning_rate": 8.433586142470352e-06,
      "loss": 0.2485,
      "step": 9893
    },
    {
      "epoch": 0.1566572193106069,
      "grad_norm": 0.5723063349723816,
      "learning_rate": 8.433427806893931e-06,
      "loss": 0.5504,
      "step": 9894
    },
    {
      "epoch": 0.15667305286824898,
      "grad_norm": 0.2773657739162445,
      "learning_rate": 8.43326947131751e-06,
      "loss": 0.0591,
      "step": 9895
    },
    {
      "epoch": 0.15668888642589104,
      "grad_norm": 0.4859875738620758,
      "learning_rate": 8.43311113574109e-06,
      "loss": 0.3174,
      "step": 9896
    },
    {
      "epoch": 0.1567047199835331,
      "grad_norm": 0.005897343158721924,
      "learning_rate": 8.43295280016467e-06,
      "loss": 0.0004,
      "step": 9897
    },
    {
      "epoch": 0.15672055354117517,
      "grad_norm": 0.7406895160675049,
      "learning_rate": 8.43279446458825e-06,
      "loss": 0.7954,
      "step": 9898
    },
    {
      "epoch": 0.15673638709881724,
      "grad_norm": 0.2628939747810364,
      "learning_rate": 8.432636129011828e-06,
      "loss": 0.0771,
      "step": 9899
    },
    {
      "epoch": 0.1567522206564593,
      "grad_norm": 0.006494998000562191,
      "learning_rate": 8.432477793435408e-06,
      "loss": 0.0003,
      "step": 9900
    },
    {
      "epoch": 0.15676805421410137,
      "grad_norm": 0.6069614291191101,
      "learning_rate": 8.432319457858987e-06,
      "loss": 0.2059,
      "step": 9901
    },
    {
      "epoch": 0.15678388777174343,
      "grad_norm": 0.3650919497013092,
      "learning_rate": 8.432161122282566e-06,
      "loss": 0.1819,
      "step": 9902
    },
    {
      "epoch": 0.1567997213293855,
      "grad_norm": 0.4029443562030792,
      "learning_rate": 8.432002786706146e-06,
      "loss": 0.1487,
      "step": 9903
    },
    {
      "epoch": 0.15681555488702756,
      "grad_norm": 0.5386479496955872,
      "learning_rate": 8.431844451129726e-06,
      "loss": 0.3459,
      "step": 9904
    },
    {
      "epoch": 0.15683138844466962,
      "grad_norm": 0.10595601052045822,
      "learning_rate": 8.431686115553305e-06,
      "loss": 0.029,
      "step": 9905
    },
    {
      "epoch": 0.1568472220023117,
      "grad_norm": 0.26590779423713684,
      "learning_rate": 8.431527779976884e-06,
      "loss": 0.1157,
      "step": 9906
    },
    {
      "epoch": 0.15686305555995378,
      "grad_norm": 0.2102133184671402,
      "learning_rate": 8.431369444400463e-06,
      "loss": 0.015,
      "step": 9907
    },
    {
      "epoch": 0.15687888911759584,
      "grad_norm": 0.127646803855896,
      "learning_rate": 8.431211108824042e-06,
      "loss": 0.0518,
      "step": 9908
    },
    {
      "epoch": 0.1568947226752379,
      "grad_norm": 0.017381878569722176,
      "learning_rate": 8.431052773247623e-06,
      "loss": 0.0011,
      "step": 9909
    },
    {
      "epoch": 0.15691055623287997,
      "grad_norm": 0.29469093680381775,
      "learning_rate": 8.430894437671202e-06,
      "loss": 0.1041,
      "step": 9910
    },
    {
      "epoch": 0.15692638979052204,
      "grad_norm": 0.0073930430226027966,
      "learning_rate": 8.43073610209478e-06,
      "loss": 0.0004,
      "step": 9911
    },
    {
      "epoch": 0.1569422233481641,
      "grad_norm": 0.8512885570526123,
      "learning_rate": 8.43057776651836e-06,
      "loss": 0.9126,
      "step": 9912
    },
    {
      "epoch": 0.15695805690580616,
      "grad_norm": 0.40567871928215027,
      "learning_rate": 8.430419430941939e-06,
      "loss": 0.2463,
      "step": 9913
    },
    {
      "epoch": 0.15697389046344823,
      "grad_norm": 0.21218302845954895,
      "learning_rate": 8.430261095365518e-06,
      "loss": 0.0806,
      "step": 9914
    },
    {
      "epoch": 0.1569897240210903,
      "grad_norm": 0.022819019854068756,
      "learning_rate": 8.430102759789097e-06,
      "loss": 0.001,
      "step": 9915
    },
    {
      "epoch": 0.15700555757873236,
      "grad_norm": 0.29298871755599976,
      "learning_rate": 8.429944424212678e-06,
      "loss": 0.0979,
      "step": 9916
    },
    {
      "epoch": 0.15702139113637442,
      "grad_norm": 0.41244813799858093,
      "learning_rate": 8.429786088636255e-06,
      "loss": 0.4192,
      "step": 9917
    },
    {
      "epoch": 0.1570372246940165,
      "grad_norm": 0.9564440846443176,
      "learning_rate": 8.429627753059836e-06,
      "loss": 0.5849,
      "step": 9918
    },
    {
      "epoch": 0.15705305825165858,
      "grad_norm": 0.1667669266462326,
      "learning_rate": 8.429469417483415e-06,
      "loss": 0.0776,
      "step": 9919
    },
    {
      "epoch": 0.15706889180930064,
      "grad_norm": 0.5418466329574585,
      "learning_rate": 8.429311081906994e-06,
      "loss": 0.0273,
      "step": 9920
    },
    {
      "epoch": 0.1570847253669427,
      "grad_norm": 0.3428983688354492,
      "learning_rate": 8.429152746330573e-06,
      "loss": 0.1274,
      "step": 9921
    },
    {
      "epoch": 0.15710055892458477,
      "grad_norm": 0.037051524966955185,
      "learning_rate": 8.428994410754154e-06,
      "loss": 0.0027,
      "step": 9922
    },
    {
      "epoch": 0.15711639248222684,
      "grad_norm": 0.2808062434196472,
      "learning_rate": 8.428836075177731e-06,
      "loss": 0.0847,
      "step": 9923
    },
    {
      "epoch": 0.1571322260398689,
      "grad_norm": 0.0016860660398378968,
      "learning_rate": 8.428677739601312e-06,
      "loss": 0.0,
      "step": 9924
    },
    {
      "epoch": 0.15714805959751096,
      "grad_norm": 0.01734958030283451,
      "learning_rate": 8.428519404024891e-06,
      "loss": 0.0013,
      "step": 9925
    },
    {
      "epoch": 0.15716389315515303,
      "grad_norm": 0.5507087707519531,
      "learning_rate": 8.42836106844847e-06,
      "loss": 0.4883,
      "step": 9926
    },
    {
      "epoch": 0.1571797267127951,
      "grad_norm": 0.012836204841732979,
      "learning_rate": 8.42820273287205e-06,
      "loss": 0.0008,
      "step": 9927
    },
    {
      "epoch": 0.15719556027043716,
      "grad_norm": 0.0009317831136286259,
      "learning_rate": 8.42804439729563e-06,
      "loss": 0.0,
      "step": 9928
    },
    {
      "epoch": 0.15721139382807922,
      "grad_norm": 0.47850891947746277,
      "learning_rate": 8.427886061719208e-06,
      "loss": 0.3233,
      "step": 9929
    },
    {
      "epoch": 0.15722722738572129,
      "grad_norm": 0.129011869430542,
      "learning_rate": 8.427727726142788e-06,
      "loss": 0.0041,
      "step": 9930
    },
    {
      "epoch": 0.15724306094336338,
      "grad_norm": 0.9638670682907104,
      "learning_rate": 8.427569390566367e-06,
      "loss": 0.4746,
      "step": 9931
    },
    {
      "epoch": 0.15725889450100544,
      "grad_norm": 0.19495180249214172,
      "learning_rate": 8.427411054989947e-06,
      "loss": 0.0133,
      "step": 9932
    },
    {
      "epoch": 0.1572747280586475,
      "grad_norm": 0.18188969790935516,
      "learning_rate": 8.427252719413526e-06,
      "loss": 0.0064,
      "step": 9933
    },
    {
      "epoch": 0.15729056161628957,
      "grad_norm": 0.009762361645698547,
      "learning_rate": 8.427094383837106e-06,
      "loss": 0.0004,
      "step": 9934
    },
    {
      "epoch": 0.15730639517393163,
      "grad_norm": 0.01743246056139469,
      "learning_rate": 8.426936048260684e-06,
      "loss": 0.0011,
      "step": 9935
    },
    {
      "epoch": 0.1573222287315737,
      "grad_norm": 0.018524043262004852,
      "learning_rate": 8.426777712684265e-06,
      "loss": 0.0011,
      "step": 9936
    },
    {
      "epoch": 0.15733806228921576,
      "grad_norm": 0.005688373930752277,
      "learning_rate": 8.426619377107844e-06,
      "loss": 0.0001,
      "step": 9937
    },
    {
      "epoch": 0.15735389584685783,
      "grad_norm": 0.27637580037117004,
      "learning_rate": 8.426461041531423e-06,
      "loss": 0.2126,
      "step": 9938
    },
    {
      "epoch": 0.1573697294044999,
      "grad_norm": 0.38870155811309814,
      "learning_rate": 8.426302705955002e-06,
      "loss": 0.4924,
      "step": 9939
    },
    {
      "epoch": 0.15738556296214196,
      "grad_norm": 0.41224008798599243,
      "learning_rate": 8.426144370378581e-06,
      "loss": 0.0669,
      "step": 9940
    },
    {
      "epoch": 0.15740139651978402,
      "grad_norm": 0.021261468529701233,
      "learning_rate": 8.42598603480216e-06,
      "loss": 0.0014,
      "step": 9941
    },
    {
      "epoch": 0.15741723007742608,
      "grad_norm": 0.001675744540989399,
      "learning_rate": 8.425827699225739e-06,
      "loss": 0.0,
      "step": 9942
    },
    {
      "epoch": 0.15743306363506818,
      "grad_norm": 0.38675445318222046,
      "learning_rate": 8.42566936364932e-06,
      "loss": 0.0427,
      "step": 9943
    },
    {
      "epoch": 0.15744889719271024,
      "grad_norm": 0.27121853828430176,
      "learning_rate": 8.425511028072897e-06,
      "loss": 0.0486,
      "step": 9944
    },
    {
      "epoch": 0.1574647307503523,
      "grad_norm": 0.2615119218826294,
      "learning_rate": 8.425352692496478e-06,
      "loss": 0.0445,
      "step": 9945
    },
    {
      "epoch": 0.15748056430799437,
      "grad_norm": 0.1718808114528656,
      "learning_rate": 8.425194356920057e-06,
      "loss": 0.0677,
      "step": 9946
    },
    {
      "epoch": 0.15749639786563643,
      "grad_norm": 0.528438150882721,
      "learning_rate": 8.425036021343636e-06,
      "loss": 0.5222,
      "step": 9947
    },
    {
      "epoch": 0.1575122314232785,
      "grad_norm": 0.17856262624263763,
      "learning_rate": 8.424877685767215e-06,
      "loss": 0.0333,
      "step": 9948
    },
    {
      "epoch": 0.15752806498092056,
      "grad_norm": 2.2473626136779785,
      "learning_rate": 8.424719350190796e-06,
      "loss": 0.2563,
      "step": 9949
    },
    {
      "epoch": 0.15754389853856263,
      "grad_norm": 0.3252948224544525,
      "learning_rate": 8.424561014614373e-06,
      "loss": 0.0477,
      "step": 9950
    },
    {
      "epoch": 0.1575597320962047,
      "grad_norm": 0.24281050264835358,
      "learning_rate": 8.424402679037954e-06,
      "loss": 0.0372,
      "step": 9951
    },
    {
      "epoch": 0.15757556565384676,
      "grad_norm": 0.007273425813764334,
      "learning_rate": 8.424244343461533e-06,
      "loss": 0.0001,
      "step": 9952
    },
    {
      "epoch": 0.15759139921148882,
      "grad_norm": 0.3761703372001648,
      "learning_rate": 8.424086007885112e-06,
      "loss": 0.1332,
      "step": 9953
    },
    {
      "epoch": 0.15760723276913088,
      "grad_norm": 0.5246371626853943,
      "learning_rate": 8.423927672308691e-06,
      "loss": 0.1153,
      "step": 9954
    },
    {
      "epoch": 0.15762306632677298,
      "grad_norm": 0.5375024676322937,
      "learning_rate": 8.423769336732272e-06,
      "loss": 0.3526,
      "step": 9955
    },
    {
      "epoch": 0.15763889988441504,
      "grad_norm": 0.007854900322854519,
      "learning_rate": 8.42361100115585e-06,
      "loss": 0.0005,
      "step": 9956
    },
    {
      "epoch": 0.1576547334420571,
      "grad_norm": 0.27239251136779785,
      "learning_rate": 8.42345266557943e-06,
      "loss": 0.142,
      "step": 9957
    },
    {
      "epoch": 0.15767056699969917,
      "grad_norm": 0.0011070212349295616,
      "learning_rate": 8.42329433000301e-06,
      "loss": 0.0,
      "step": 9958
    },
    {
      "epoch": 0.15768640055734123,
      "grad_norm": 0.008271228522062302,
      "learning_rate": 8.423135994426588e-06,
      "loss": 0.0004,
      "step": 9959
    },
    {
      "epoch": 0.1577022341149833,
      "grad_norm": 0.00025326781906187534,
      "learning_rate": 8.422977658850168e-06,
      "loss": 0.0,
      "step": 9960
    },
    {
      "epoch": 0.15771806767262536,
      "grad_norm": 0.9306044578552246,
      "learning_rate": 8.422819323273747e-06,
      "loss": 1.0022,
      "step": 9961
    },
    {
      "epoch": 0.15773390123026743,
      "grad_norm": 0.28705674409866333,
      "learning_rate": 8.422660987697326e-06,
      "loss": 0.0093,
      "step": 9962
    },
    {
      "epoch": 0.1577497347879095,
      "grad_norm": 0.0030157575383782387,
      "learning_rate": 8.422502652120905e-06,
      "loss": 0.0001,
      "step": 9963
    },
    {
      "epoch": 0.15776556834555155,
      "grad_norm": 0.40512439608573914,
      "learning_rate": 8.422344316544486e-06,
      "loss": 0.0397,
      "step": 9964
    },
    {
      "epoch": 0.15778140190319362,
      "grad_norm": 0.318766325712204,
      "learning_rate": 8.422185980968065e-06,
      "loss": 0.1397,
      "step": 9965
    },
    {
      "epoch": 0.15779723546083568,
      "grad_norm": 0.1689634770154953,
      "learning_rate": 8.422027645391644e-06,
      "loss": 0.0568,
      "step": 9966
    },
    {
      "epoch": 0.15781306901847778,
      "grad_norm": 0.011517344042658806,
      "learning_rate": 8.421869309815223e-06,
      "loss": 0.0006,
      "step": 9967
    },
    {
      "epoch": 0.15782890257611984,
      "grad_norm": 0.020170442759990692,
      "learning_rate": 8.421710974238802e-06,
      "loss": 0.0012,
      "step": 9968
    },
    {
      "epoch": 0.1578447361337619,
      "grad_norm": 0.3982236385345459,
      "learning_rate": 8.421552638662381e-06,
      "loss": 0.1178,
      "step": 9969
    },
    {
      "epoch": 0.15786056969140397,
      "grad_norm": 0.014537501148879528,
      "learning_rate": 8.421394303085962e-06,
      "loss": 0.0005,
      "step": 9970
    },
    {
      "epoch": 0.15787640324904603,
      "grad_norm": 0.0003264055703766644,
      "learning_rate": 8.42123596750954e-06,
      "loss": 0.0,
      "step": 9971
    },
    {
      "epoch": 0.1578922368066881,
      "grad_norm": 0.38151490688323975,
      "learning_rate": 8.42107763193312e-06,
      "loss": 0.0901,
      "step": 9972
    },
    {
      "epoch": 0.15790807036433016,
      "grad_norm": 0.6659144163131714,
      "learning_rate": 8.420919296356699e-06,
      "loss": 0.8084,
      "step": 9973
    },
    {
      "epoch": 0.15792390392197223,
      "grad_norm": 0.05446859821677208,
      "learning_rate": 8.420760960780278e-06,
      "loss": 0.0023,
      "step": 9974
    },
    {
      "epoch": 0.1579397374796143,
      "grad_norm": 0.0002639802114572376,
      "learning_rate": 8.420602625203857e-06,
      "loss": 0.0,
      "step": 9975
    },
    {
      "epoch": 0.15795557103725635,
      "grad_norm": 0.1813594251871109,
      "learning_rate": 8.420444289627438e-06,
      "loss": 0.0781,
      "step": 9976
    },
    {
      "epoch": 0.15797140459489842,
      "grad_norm": 0.3069310486316681,
      "learning_rate": 8.420285954051017e-06,
      "loss": 0.1962,
      "step": 9977
    },
    {
      "epoch": 0.15798723815254048,
      "grad_norm": 0.27228403091430664,
      "learning_rate": 8.420127618474596e-06,
      "loss": 0.1167,
      "step": 9978
    },
    {
      "epoch": 0.15800307171018257,
      "grad_norm": 0.0020303393248468637,
      "learning_rate": 8.419969282898175e-06,
      "loss": 0.0001,
      "step": 9979
    },
    {
      "epoch": 0.15801890526782464,
      "grad_norm": 0.7545685172080994,
      "learning_rate": 8.419810947321754e-06,
      "loss": 0.2547,
      "step": 9980
    },
    {
      "epoch": 0.1580347388254667,
      "grad_norm": 1.3075549602508545,
      "learning_rate": 8.419652611745333e-06,
      "loss": 0.1475,
      "step": 9981
    },
    {
      "epoch": 0.15805057238310877,
      "grad_norm": 0.676214337348938,
      "learning_rate": 8.419494276168914e-06,
      "loss": 0.164,
      "step": 9982
    },
    {
      "epoch": 0.15806640594075083,
      "grad_norm": 0.2888876497745514,
      "learning_rate": 8.419335940592493e-06,
      "loss": 0.0545,
      "step": 9983
    },
    {
      "epoch": 0.1580822394983929,
      "grad_norm": 0.24011391401290894,
      "learning_rate": 8.419177605016072e-06,
      "loss": 0.077,
      "step": 9984
    },
    {
      "epoch": 0.15809807305603496,
      "grad_norm": 0.3575229048728943,
      "learning_rate": 8.419019269439651e-06,
      "loss": 0.0836,
      "step": 9985
    },
    {
      "epoch": 0.15811390661367702,
      "grad_norm": 0.26584112644195557,
      "learning_rate": 8.41886093386323e-06,
      "loss": 0.0562,
      "step": 9986
    },
    {
      "epoch": 0.1581297401713191,
      "grad_norm": 0.43743592500686646,
      "learning_rate": 8.41870259828681e-06,
      "loss": 0.1695,
      "step": 9987
    },
    {
      "epoch": 0.15814557372896115,
      "grad_norm": 0.32242435216903687,
      "learning_rate": 8.418544262710389e-06,
      "loss": 0.1526,
      "step": 9988
    },
    {
      "epoch": 0.15816140728660322,
      "grad_norm": 0.21449469029903412,
      "learning_rate": 8.41838592713397e-06,
      "loss": 0.06,
      "step": 9989
    },
    {
      "epoch": 0.15817724084424528,
      "grad_norm": 0.41854995489120483,
      "learning_rate": 8.418227591557547e-06,
      "loss": 0.2301,
      "step": 9990
    },
    {
      "epoch": 0.15819307440188737,
      "grad_norm": 0.0009469608194194734,
      "learning_rate": 8.418069255981127e-06,
      "loss": 0.0,
      "step": 9991
    },
    {
      "epoch": 0.15820890795952944,
      "grad_norm": 0.023222286254167557,
      "learning_rate": 8.417910920404707e-06,
      "loss": 0.0016,
      "step": 9992
    },
    {
      "epoch": 0.1582247415171715,
      "grad_norm": 0.021994205191731453,
      "learning_rate": 8.417752584828286e-06,
      "loss": 0.0008,
      "step": 9993
    },
    {
      "epoch": 0.15824057507481357,
      "grad_norm": 0.23040913045406342,
      "learning_rate": 8.417594249251865e-06,
      "loss": 0.0354,
      "step": 9994
    },
    {
      "epoch": 0.15825640863245563,
      "grad_norm": 0.5555822849273682,
      "learning_rate": 8.417435913675445e-06,
      "loss": 0.0904,
      "step": 9995
    },
    {
      "epoch": 0.1582722421900977,
      "grad_norm": 0.6248970627784729,
      "learning_rate": 8.417277578099023e-06,
      "loss": 0.058,
      "step": 9996
    },
    {
      "epoch": 0.15828807574773976,
      "grad_norm": 0.6212313771247864,
      "learning_rate": 8.417119242522604e-06,
      "loss": 0.5597,
      "step": 9997
    },
    {
      "epoch": 0.15830390930538182,
      "grad_norm": 0.18291451036930084,
      "learning_rate": 8.416960906946183e-06,
      "loss": 0.0603,
      "step": 9998
    },
    {
      "epoch": 0.1583197428630239,
      "grad_norm": 0.3708023130893707,
      "learning_rate": 8.416802571369762e-06,
      "loss": 0.381,
      "step": 9999
    },
    {
      "epoch": 0.15833557642066595,
      "grad_norm": 0.2167213261127472,
      "learning_rate": 8.416644235793341e-06,
      "loss": 0.0624,
      "step": 10000
    },
    {
      "epoch": 0.15835140997830802,
      "grad_norm": 0.41413331031799316,
      "learning_rate": 8.416485900216922e-06,
      "loss": 0.1909,
      "step": 10001
    },
    {
      "epoch": 0.15836724353595008,
      "grad_norm": 0.03148382902145386,
      "learning_rate": 8.416327564640499e-06,
      "loss": 0.0018,
      "step": 10002
    },
    {
      "epoch": 0.15838307709359217,
      "grad_norm": 0.2566019296646118,
      "learning_rate": 8.41616922906408e-06,
      "loss": 0.0593,
      "step": 10003
    },
    {
      "epoch": 0.15839891065123424,
      "grad_norm": 0.41710686683654785,
      "learning_rate": 8.416010893487659e-06,
      "loss": 0.22,
      "step": 10004
    },
    {
      "epoch": 0.1584147442088763,
      "grad_norm": 0.010729138739407063,
      "learning_rate": 8.415852557911238e-06,
      "loss": 0.0005,
      "step": 10005
    },
    {
      "epoch": 0.15843057776651837,
      "grad_norm": 0.017650434747338295,
      "learning_rate": 8.415694222334817e-06,
      "loss": 0.0008,
      "step": 10006
    },
    {
      "epoch": 0.15844641132416043,
      "grad_norm": 2.2444169521331787,
      "learning_rate": 8.415535886758396e-06,
      "loss": 0.0657,
      "step": 10007
    },
    {
      "epoch": 0.1584622448818025,
      "grad_norm": 0.00037949264515191317,
      "learning_rate": 8.415377551181975e-06,
      "loss": 0.0,
      "step": 10008
    },
    {
      "epoch": 0.15847807843944456,
      "grad_norm": 0.0026287955697625875,
      "learning_rate": 8.415219215605554e-06,
      "loss": 0.0001,
      "step": 10009
    },
    {
      "epoch": 0.15849391199708662,
      "grad_norm": 0.0005147120100446045,
      "learning_rate": 8.415060880029135e-06,
      "loss": 0.0,
      "step": 10010
    },
    {
      "epoch": 0.1585097455547287,
      "grad_norm": 0.06849734485149384,
      "learning_rate": 8.414902544452712e-06,
      "loss": 0.0048,
      "step": 10011
    },
    {
      "epoch": 0.15852557911237075,
      "grad_norm": 0.4979901909828186,
      "learning_rate": 8.414744208876293e-06,
      "loss": 0.1992,
      "step": 10012
    },
    {
      "epoch": 0.15854141267001282,
      "grad_norm": 0.30014005303382874,
      "learning_rate": 8.414585873299872e-06,
      "loss": 0.0965,
      "step": 10013
    },
    {
      "epoch": 0.15855724622765488,
      "grad_norm": 0.04065468907356262,
      "learning_rate": 8.414427537723451e-06,
      "loss": 0.0027,
      "step": 10014
    },
    {
      "epoch": 0.15857307978529697,
      "grad_norm": 0.7011892199516296,
      "learning_rate": 8.41426920214703e-06,
      "loss": 0.0916,
      "step": 10015
    },
    {
      "epoch": 0.15858891334293904,
      "grad_norm": 0.40464723110198975,
      "learning_rate": 8.414110866570611e-06,
      "loss": 0.4885,
      "step": 10016
    },
    {
      "epoch": 0.1586047469005811,
      "grad_norm": 0.2697664201259613,
      "learning_rate": 8.413952530994189e-06,
      "loss": 0.1707,
      "step": 10017
    },
    {
      "epoch": 0.15862058045822316,
      "grad_norm": 0.0201324000954628,
      "learning_rate": 8.41379419541777e-06,
      "loss": 0.0013,
      "step": 10018
    },
    {
      "epoch": 0.15863641401586523,
      "grad_norm": 0.6693772673606873,
      "learning_rate": 8.413635859841348e-06,
      "loss": 0.2009,
      "step": 10019
    },
    {
      "epoch": 0.1586522475735073,
      "grad_norm": 0.4587015211582184,
      "learning_rate": 8.413477524264928e-06,
      "loss": 0.7001,
      "step": 10020
    },
    {
      "epoch": 0.15866808113114936,
      "grad_norm": 0.0006336596561595798,
      "learning_rate": 8.413319188688507e-06,
      "loss": 0.0,
      "step": 10021
    },
    {
      "epoch": 0.15868391468879142,
      "grad_norm": 0.24810871481895447,
      "learning_rate": 8.413160853112087e-06,
      "loss": 0.1539,
      "step": 10022
    },
    {
      "epoch": 0.1586997482464335,
      "grad_norm": 0.2989541292190552,
      "learning_rate": 8.413002517535665e-06,
      "loss": 0.0458,
      "step": 10023
    },
    {
      "epoch": 0.15871558180407555,
      "grad_norm": 0.008766819722950459,
      "learning_rate": 8.412844181959246e-06,
      "loss": 0.0004,
      "step": 10024
    },
    {
      "epoch": 0.15873141536171761,
      "grad_norm": 0.37861186265945435,
      "learning_rate": 8.412685846382825e-06,
      "loss": 0.0709,
      "step": 10025
    },
    {
      "epoch": 0.15874724891935968,
      "grad_norm": 0.469340056180954,
      "learning_rate": 8.412527510806404e-06,
      "loss": 0.1086,
      "step": 10026
    },
    {
      "epoch": 0.15876308247700177,
      "grad_norm": 0.00029668319621123374,
      "learning_rate": 8.412369175229983e-06,
      "loss": 0.0,
      "step": 10027
    },
    {
      "epoch": 0.15877891603464384,
      "grad_norm": 0.5472672581672668,
      "learning_rate": 8.412210839653564e-06,
      "loss": 0.1289,
      "step": 10028
    },
    {
      "epoch": 0.1587947495922859,
      "grad_norm": 0.03799006715416908,
      "learning_rate": 8.412052504077141e-06,
      "loss": 0.0024,
      "step": 10029
    },
    {
      "epoch": 0.15881058314992796,
      "grad_norm": 0.278346985578537,
      "learning_rate": 8.411894168500722e-06,
      "loss": 0.1047,
      "step": 10030
    },
    {
      "epoch": 0.15882641670757003,
      "grad_norm": 0.510169267654419,
      "learning_rate": 8.4117358329243e-06,
      "loss": 0.1576,
      "step": 10031
    },
    {
      "epoch": 0.1588422502652121,
      "grad_norm": 0.02969966270029545,
      "learning_rate": 8.41157749734788e-06,
      "loss": 0.0018,
      "step": 10032
    },
    {
      "epoch": 0.15885808382285416,
      "grad_norm": 0.5082983374595642,
      "learning_rate": 8.411419161771459e-06,
      "loss": 0.5768,
      "step": 10033
    },
    {
      "epoch": 0.15887391738049622,
      "grad_norm": 0.022566696628928185,
      "learning_rate": 8.411260826195038e-06,
      "loss": 0.0014,
      "step": 10034
    },
    {
      "epoch": 0.15888975093813829,
      "grad_norm": 0.020998304709792137,
      "learning_rate": 8.411102490618617e-06,
      "loss": 0.0011,
      "step": 10035
    },
    {
      "epoch": 0.15890558449578035,
      "grad_norm": 0.028801443055272102,
      "learning_rate": 8.410944155042196e-06,
      "loss": 0.0017,
      "step": 10036
    },
    {
      "epoch": 0.15892141805342241,
      "grad_norm": 0.2882235050201416,
      "learning_rate": 8.410785819465777e-06,
      "loss": 0.0735,
      "step": 10037
    },
    {
      "epoch": 0.15893725161106448,
      "grad_norm": 0.3105555474758148,
      "learning_rate": 8.410627483889356e-06,
      "loss": 0.0528,
      "step": 10038
    },
    {
      "epoch": 0.15895308516870657,
      "grad_norm": 0.5107025504112244,
      "learning_rate": 8.410469148312935e-06,
      "loss": 1.2566,
      "step": 10039
    },
    {
      "epoch": 0.15896891872634863,
      "grad_norm": 0.006417266558855772,
      "learning_rate": 8.410310812736514e-06,
      "loss": 0.0003,
      "step": 10040
    },
    {
      "epoch": 0.1589847522839907,
      "grad_norm": 0.19049106538295746,
      "learning_rate": 8.410152477160093e-06,
      "loss": 0.0194,
      "step": 10041
    },
    {
      "epoch": 0.15900058584163276,
      "grad_norm": 0.9044610857963562,
      "learning_rate": 8.409994141583672e-06,
      "loss": 0.2468,
      "step": 10042
    },
    {
      "epoch": 0.15901641939927483,
      "grad_norm": 0.74163419008255,
      "learning_rate": 8.409835806007253e-06,
      "loss": 0.0402,
      "step": 10043
    },
    {
      "epoch": 0.1590322529569169,
      "grad_norm": 0.0002440590033074841,
      "learning_rate": 8.409677470430832e-06,
      "loss": 0.0,
      "step": 10044
    },
    {
      "epoch": 0.15904808651455896,
      "grad_norm": 0.05820572003722191,
      "learning_rate": 8.409519134854411e-06,
      "loss": 0.0044,
      "step": 10045
    },
    {
      "epoch": 0.15906392007220102,
      "grad_norm": 0.02594875544309616,
      "learning_rate": 8.40936079927799e-06,
      "loss": 0.0014,
      "step": 10046
    },
    {
      "epoch": 0.15907975362984308,
      "grad_norm": 0.0001618730166228488,
      "learning_rate": 8.40920246370157e-06,
      "loss": 0.0,
      "step": 10047
    },
    {
      "epoch": 0.15909558718748515,
      "grad_norm": 0.7521458864212036,
      "learning_rate": 8.409044128125149e-06,
      "loss": 0.2153,
      "step": 10048
    },
    {
      "epoch": 0.1591114207451272,
      "grad_norm": 0.01587253250181675,
      "learning_rate": 8.40888579254873e-06,
      "loss": 0.0007,
      "step": 10049
    },
    {
      "epoch": 0.15912725430276928,
      "grad_norm": 0.20900936424732208,
      "learning_rate": 8.408727456972308e-06,
      "loss": 0.0776,
      "step": 10050
    },
    {
      "epoch": 0.15914308786041137,
      "grad_norm": 0.0142426248639822,
      "learning_rate": 8.408569121395887e-06,
      "loss": 0.0008,
      "step": 10051
    },
    {
      "epoch": 0.15915892141805343,
      "grad_norm": 0.1454198807477951,
      "learning_rate": 8.408410785819467e-06,
      "loss": 0.0336,
      "step": 10052
    },
    {
      "epoch": 0.1591747549756955,
      "grad_norm": 0.42075636982917786,
      "learning_rate": 8.408252450243046e-06,
      "loss": 0.2136,
      "step": 10053
    },
    {
      "epoch": 0.15919058853333756,
      "grad_norm": 0.8750831484794617,
      "learning_rate": 8.408094114666625e-06,
      "loss": 0.4651,
      "step": 10054
    },
    {
      "epoch": 0.15920642209097963,
      "grad_norm": 0.45368248224258423,
      "learning_rate": 8.407935779090205e-06,
      "loss": 0.1945,
      "step": 10055
    },
    {
      "epoch": 0.1592222556486217,
      "grad_norm": 0.20777344703674316,
      "learning_rate": 8.407777443513785e-06,
      "loss": 0.0852,
      "step": 10056
    },
    {
      "epoch": 0.15923808920626376,
      "grad_norm": 0.03525440767407417,
      "learning_rate": 8.407619107937364e-06,
      "loss": 0.0024,
      "step": 10057
    },
    {
      "epoch": 0.15925392276390582,
      "grad_norm": 0.06451043486595154,
      "learning_rate": 8.407460772360943e-06,
      "loss": 0.003,
      "step": 10058
    },
    {
      "epoch": 0.15926975632154788,
      "grad_norm": 0.21066060662269592,
      "learning_rate": 8.407302436784522e-06,
      "loss": 0.0766,
      "step": 10059
    },
    {
      "epoch": 0.15928558987918995,
      "grad_norm": 0.43565109372138977,
      "learning_rate": 8.407144101208101e-06,
      "loss": 0.1133,
      "step": 10060
    },
    {
      "epoch": 0.159301423436832,
      "grad_norm": 0.2413032352924347,
      "learning_rate": 8.40698576563168e-06,
      "loss": 0.1668,
      "step": 10061
    },
    {
      "epoch": 0.15931725699447408,
      "grad_norm": 0.28180113434791565,
      "learning_rate": 8.40682743005526e-06,
      "loss": 0.0584,
      "step": 10062
    },
    {
      "epoch": 0.15933309055211614,
      "grad_norm": 0.20330029726028442,
      "learning_rate": 8.406669094478838e-06,
      "loss": 0.1019,
      "step": 10063
    },
    {
      "epoch": 0.15934892410975823,
      "grad_norm": 0.00036951282527297735,
      "learning_rate": 8.406510758902419e-06,
      "loss": 0.0,
      "step": 10064
    },
    {
      "epoch": 0.1593647576674003,
      "grad_norm": 0.4930685758590698,
      "learning_rate": 8.406352423325998e-06,
      "loss": 0.315,
      "step": 10065
    },
    {
      "epoch": 0.15938059122504236,
      "grad_norm": 0.24655044078826904,
      "learning_rate": 8.406194087749577e-06,
      "loss": 0.1577,
      "step": 10066
    },
    {
      "epoch": 0.15939642478268443,
      "grad_norm": 0.0006086263456381857,
      "learning_rate": 8.406035752173156e-06,
      "loss": 0.0,
      "step": 10067
    },
    {
      "epoch": 0.1594122583403265,
      "grad_norm": 0.38976937532424927,
      "learning_rate": 8.405877416596735e-06,
      "loss": 0.0571,
      "step": 10068
    },
    {
      "epoch": 0.15942809189796855,
      "grad_norm": 0.6078270077705383,
      "learning_rate": 8.405719081020314e-06,
      "loss": 0.485,
      "step": 10069
    },
    {
      "epoch": 0.15944392545561062,
      "grad_norm": 0.0004648726899176836,
      "learning_rate": 8.405560745443895e-06,
      "loss": 0.0,
      "step": 10070
    },
    {
      "epoch": 0.15945975901325268,
      "grad_norm": 0.14173004031181335,
      "learning_rate": 8.405402409867474e-06,
      "loss": 0.0542,
      "step": 10071
    },
    {
      "epoch": 0.15947559257089475,
      "grad_norm": 0.6111646294593811,
      "learning_rate": 8.405244074291053e-06,
      "loss": 0.3171,
      "step": 10072
    },
    {
      "epoch": 0.1594914261285368,
      "grad_norm": 0.820282518863678,
      "learning_rate": 8.405085738714632e-06,
      "loss": 0.3802,
      "step": 10073
    },
    {
      "epoch": 0.15950725968617888,
      "grad_norm": 0.23713645339012146,
      "learning_rate": 8.404927403138211e-06,
      "loss": 0.0994,
      "step": 10074
    },
    {
      "epoch": 0.15952309324382094,
      "grad_norm": 0.3957892656326294,
      "learning_rate": 8.40476906756179e-06,
      "loss": 0.3523,
      "step": 10075
    },
    {
      "epoch": 0.15953892680146303,
      "grad_norm": 0.30258965492248535,
      "learning_rate": 8.404610731985371e-06,
      "loss": 0.1241,
      "step": 10076
    },
    {
      "epoch": 0.1595547603591051,
      "grad_norm": 0.5359548926353455,
      "learning_rate": 8.40445239640895e-06,
      "loss": 0.3194,
      "step": 10077
    },
    {
      "epoch": 0.15957059391674716,
      "grad_norm": 0.22989995777606964,
      "learning_rate": 8.40429406083253e-06,
      "loss": 0.0748,
      "step": 10078
    },
    {
      "epoch": 0.15958642747438923,
      "grad_norm": 0.5704056024551392,
      "learning_rate": 8.404135725256108e-06,
      "loss": 0.4723,
      "step": 10079
    },
    {
      "epoch": 0.1596022610320313,
      "grad_norm": 0.1853834092617035,
      "learning_rate": 8.403977389679688e-06,
      "loss": 0.0866,
      "step": 10080
    },
    {
      "epoch": 0.15961809458967335,
      "grad_norm": 0.020164022222161293,
      "learning_rate": 8.403819054103267e-06,
      "loss": 0.0013,
      "step": 10081
    },
    {
      "epoch": 0.15963392814731542,
      "grad_norm": 0.6506763100624084,
      "learning_rate": 8.403660718526846e-06,
      "loss": 0.4026,
      "step": 10082
    },
    {
      "epoch": 0.15964976170495748,
      "grad_norm": 0.3931819200515747,
      "learning_rate": 8.403502382950427e-06,
      "loss": 0.2892,
      "step": 10083
    },
    {
      "epoch": 0.15966559526259955,
      "grad_norm": 0.0004171155742369592,
      "learning_rate": 8.403344047374004e-06,
      "loss": 0.0,
      "step": 10084
    },
    {
      "epoch": 0.1596814288202416,
      "grad_norm": 0.014772552996873856,
      "learning_rate": 8.403185711797585e-06,
      "loss": 0.0007,
      "step": 10085
    },
    {
      "epoch": 0.15969726237788368,
      "grad_norm": 0.4358038008213043,
      "learning_rate": 8.403027376221164e-06,
      "loss": 0.0109,
      "step": 10086
    },
    {
      "epoch": 0.15971309593552574,
      "grad_norm": 1.0384447574615479,
      "learning_rate": 8.402869040644743e-06,
      "loss": 0.3338,
      "step": 10087
    },
    {
      "epoch": 0.15972892949316783,
      "grad_norm": 0.3799617290496826,
      "learning_rate": 8.402710705068322e-06,
      "loss": 0.1778,
      "step": 10088
    },
    {
      "epoch": 0.1597447630508099,
      "grad_norm": 1.0034867525100708,
      "learning_rate": 8.402552369491903e-06,
      "loss": 0.2187,
      "step": 10089
    },
    {
      "epoch": 0.15976059660845196,
      "grad_norm": 0.32894131541252136,
      "learning_rate": 8.40239403391548e-06,
      "loss": 0.2314,
      "step": 10090
    },
    {
      "epoch": 0.15977643016609402,
      "grad_norm": 0.24669206142425537,
      "learning_rate": 8.40223569833906e-06,
      "loss": 0.1115,
      "step": 10091
    },
    {
      "epoch": 0.1597922637237361,
      "grad_norm": 0.3343035876750946,
      "learning_rate": 8.40207736276264e-06,
      "loss": 0.1619,
      "step": 10092
    },
    {
      "epoch": 0.15980809728137815,
      "grad_norm": 0.4040222465991974,
      "learning_rate": 8.401919027186219e-06,
      "loss": 0.2181,
      "step": 10093
    },
    {
      "epoch": 0.15982393083902022,
      "grad_norm": 0.21325553953647614,
      "learning_rate": 8.401760691609798e-06,
      "loss": 0.0068,
      "step": 10094
    },
    {
      "epoch": 0.15983976439666228,
      "grad_norm": 0.00023413484450429678,
      "learning_rate": 8.401602356033379e-06,
      "loss": 0.0,
      "step": 10095
    },
    {
      "epoch": 0.15985559795430435,
      "grad_norm": 0.3307407796382904,
      "learning_rate": 8.401444020456956e-06,
      "loss": 0.1809,
      "step": 10096
    },
    {
      "epoch": 0.1598714315119464,
      "grad_norm": 0.19518618285655975,
      "learning_rate": 8.401285684880537e-06,
      "loss": 0.0846,
      "step": 10097
    },
    {
      "epoch": 0.15988726506958847,
      "grad_norm": 0.27456584572792053,
      "learning_rate": 8.401127349304116e-06,
      "loss": 0.16,
      "step": 10098
    },
    {
      "epoch": 0.15990309862723054,
      "grad_norm": 0.2714956998825073,
      "learning_rate": 8.400969013727695e-06,
      "loss": 0.041,
      "step": 10099
    },
    {
      "epoch": 0.15991893218487263,
      "grad_norm": 0.4807172119617462,
      "learning_rate": 8.400810678151274e-06,
      "loss": 0.1624,
      "step": 10100
    },
    {
      "epoch": 0.1599347657425147,
      "grad_norm": 0.7525898218154907,
      "learning_rate": 8.400652342574855e-06,
      "loss": 0.3397,
      "step": 10101
    },
    {
      "epoch": 0.15995059930015676,
      "grad_norm": 0.5971457362174988,
      "learning_rate": 8.400494006998432e-06,
      "loss": 0.043,
      "step": 10102
    },
    {
      "epoch": 0.15996643285779882,
      "grad_norm": 0.4106118083000183,
      "learning_rate": 8.400335671422013e-06,
      "loss": 0.1702,
      "step": 10103
    },
    {
      "epoch": 0.1599822664154409,
      "grad_norm": 0.011016802862286568,
      "learning_rate": 8.400177335845592e-06,
      "loss": 0.0005,
      "step": 10104
    },
    {
      "epoch": 0.15999809997308295,
      "grad_norm": 0.7100253105163574,
      "learning_rate": 8.400019000269171e-06,
      "loss": 0.3038,
      "step": 10105
    },
    {
      "epoch": 0.16001393353072502,
      "grad_norm": 0.010524570941925049,
      "learning_rate": 8.39986066469275e-06,
      "loss": 0.0007,
      "step": 10106
    },
    {
      "epoch": 0.16002976708836708,
      "grad_norm": 0.7283508777618408,
      "learning_rate": 8.39970232911633e-06,
      "loss": 0.1663,
      "step": 10107
    },
    {
      "epoch": 0.16004560064600915,
      "grad_norm": 0.3357083797454834,
      "learning_rate": 8.399543993539909e-06,
      "loss": 0.108,
      "step": 10108
    },
    {
      "epoch": 0.1600614342036512,
      "grad_norm": 0.007692408282309771,
      "learning_rate": 8.399385657963488e-06,
      "loss": 0.0005,
      "step": 10109
    },
    {
      "epoch": 0.16007726776129327,
      "grad_norm": 0.27116677165031433,
      "learning_rate": 8.399227322387068e-06,
      "loss": 0.1509,
      "step": 10110
    },
    {
      "epoch": 0.16009310131893534,
      "grad_norm": 0.3269442915916443,
      "learning_rate": 8.399068986810648e-06,
      "loss": 0.1024,
      "step": 10111
    },
    {
      "epoch": 0.16010893487657743,
      "grad_norm": 0.23021315038204193,
      "learning_rate": 8.398910651234227e-06,
      "loss": 0.1609,
      "step": 10112
    },
    {
      "epoch": 0.1601247684342195,
      "grad_norm": 0.3791852593421936,
      "learning_rate": 8.398752315657806e-06,
      "loss": 0.1782,
      "step": 10113
    },
    {
      "epoch": 0.16014060199186156,
      "grad_norm": 0.5616613030433655,
      "learning_rate": 8.398593980081385e-06,
      "loss": 0.3612,
      "step": 10114
    },
    {
      "epoch": 0.16015643554950362,
      "grad_norm": 0.8677629828453064,
      "learning_rate": 8.398435644504964e-06,
      "loss": 0.2677,
      "step": 10115
    },
    {
      "epoch": 0.1601722691071457,
      "grad_norm": 0.6207011938095093,
      "learning_rate": 8.398277308928545e-06,
      "loss": 0.5076,
      "step": 10116
    },
    {
      "epoch": 0.16018810266478775,
      "grad_norm": 0.3253139555454254,
      "learning_rate": 8.398118973352124e-06,
      "loss": 0.1075,
      "step": 10117
    },
    {
      "epoch": 0.16020393622242982,
      "grad_norm": 0.001974590355530381,
      "learning_rate": 8.397960637775703e-06,
      "loss": 0.0,
      "step": 10118
    },
    {
      "epoch": 0.16021976978007188,
      "grad_norm": 0.3387308716773987,
      "learning_rate": 8.397802302199282e-06,
      "loss": 0.0617,
      "step": 10119
    },
    {
      "epoch": 0.16023560333771394,
      "grad_norm": 0.4221237003803253,
      "learning_rate": 8.397643966622861e-06,
      "loss": 0.245,
      "step": 10120
    },
    {
      "epoch": 0.160251436895356,
      "grad_norm": 0.4211997985839844,
      "learning_rate": 8.39748563104644e-06,
      "loss": 0.5102,
      "step": 10121
    },
    {
      "epoch": 0.16026727045299807,
      "grad_norm": 0.3309721350669861,
      "learning_rate": 8.39732729547002e-06,
      "loss": 0.2748,
      "step": 10122
    },
    {
      "epoch": 0.16028310401064014,
      "grad_norm": 0.0005953545914962888,
      "learning_rate": 8.3971689598936e-06,
      "loss": 0.0,
      "step": 10123
    },
    {
      "epoch": 0.16029893756828223,
      "grad_norm": 0.0041724867187440395,
      "learning_rate": 8.397010624317179e-06,
      "loss": 0.0002,
      "step": 10124
    },
    {
      "epoch": 0.1603147711259243,
      "grad_norm": 0.36866146326065063,
      "learning_rate": 8.396852288740758e-06,
      "loss": 0.2817,
      "step": 10125
    },
    {
      "epoch": 0.16033060468356636,
      "grad_norm": 0.005924598313868046,
      "learning_rate": 8.396693953164337e-06,
      "loss": 0.0003,
      "step": 10126
    },
    {
      "epoch": 0.16034643824120842,
      "grad_norm": 0.017730683088302612,
      "learning_rate": 8.396535617587916e-06,
      "loss": 0.001,
      "step": 10127
    },
    {
      "epoch": 0.1603622717988505,
      "grad_norm": 0.8405359983444214,
      "learning_rate": 8.396377282011497e-06,
      "loss": 0.1866,
      "step": 10128
    },
    {
      "epoch": 0.16037810535649255,
      "grad_norm": 0.20216530561447144,
      "learning_rate": 8.396218946435076e-06,
      "loss": 0.0644,
      "step": 10129
    },
    {
      "epoch": 0.16039393891413462,
      "grad_norm": 0.2423093169927597,
      "learning_rate": 8.396060610858653e-06,
      "loss": 0.0389,
      "step": 10130
    },
    {
      "epoch": 0.16040977247177668,
      "grad_norm": 0.657965898513794,
      "learning_rate": 8.395902275282234e-06,
      "loss": 0.8997,
      "step": 10131
    },
    {
      "epoch": 0.16042560602941874,
      "grad_norm": 1.001717448234558,
      "learning_rate": 8.395743939705813e-06,
      "loss": 0.3294,
      "step": 10132
    },
    {
      "epoch": 0.1604414395870608,
      "grad_norm": 0.4747636318206787,
      "learning_rate": 8.395585604129392e-06,
      "loss": 0.0146,
      "step": 10133
    },
    {
      "epoch": 0.16045727314470287,
      "grad_norm": 0.2434682846069336,
      "learning_rate": 8.395427268552971e-06,
      "loss": 0.0455,
      "step": 10134
    },
    {
      "epoch": 0.16047310670234494,
      "grad_norm": 0.01964065246284008,
      "learning_rate": 8.39526893297655e-06,
      "loss": 0.0011,
      "step": 10135
    },
    {
      "epoch": 0.16048894025998703,
      "grad_norm": 0.03304017335176468,
      "learning_rate": 8.39511059740013e-06,
      "loss": 0.002,
      "step": 10136
    },
    {
      "epoch": 0.1605047738176291,
      "grad_norm": 0.21369530260562897,
      "learning_rate": 8.39495226182371e-06,
      "loss": 0.0643,
      "step": 10137
    },
    {
      "epoch": 0.16052060737527116,
      "grad_norm": 0.2556341290473938,
      "learning_rate": 8.39479392624729e-06,
      "loss": 0.1517,
      "step": 10138
    },
    {
      "epoch": 0.16053644093291322,
      "grad_norm": 0.44849467277526855,
      "learning_rate": 8.394635590670869e-06,
      "loss": 0.235,
      "step": 10139
    },
    {
      "epoch": 0.16055227449055529,
      "grad_norm": 0.0080754728987813,
      "learning_rate": 8.394477255094448e-06,
      "loss": 0.0004,
      "step": 10140
    },
    {
      "epoch": 0.16056810804819735,
      "grad_norm": 0.6191719770431519,
      "learning_rate": 8.394318919518027e-06,
      "loss": 0.2498,
      "step": 10141
    },
    {
      "epoch": 0.16058394160583941,
      "grad_norm": 0.2875462472438812,
      "learning_rate": 8.394160583941606e-06,
      "loss": 0.1014,
      "step": 10142
    },
    {
      "epoch": 0.16059977516348148,
      "grad_norm": 0.6921409368515015,
      "learning_rate": 8.394002248365187e-06,
      "loss": 0.6225,
      "step": 10143
    },
    {
      "epoch": 0.16061560872112354,
      "grad_norm": 0.19645912945270538,
      "learning_rate": 8.393843912788766e-06,
      "loss": 0.0778,
      "step": 10144
    },
    {
      "epoch": 0.1606314422787656,
      "grad_norm": 0.00020364183001220226,
      "learning_rate": 8.393685577212345e-06,
      "loss": 0.0,
      "step": 10145
    },
    {
      "epoch": 0.16064727583640767,
      "grad_norm": 0.448406457901001,
      "learning_rate": 8.393527241635924e-06,
      "loss": 0.1527,
      "step": 10146
    },
    {
      "epoch": 0.16066310939404974,
      "grad_norm": 0.016143513843417168,
      "learning_rate": 8.393368906059503e-06,
      "loss": 0.001,
      "step": 10147
    },
    {
      "epoch": 0.16067894295169183,
      "grad_norm": 0.35148885846138,
      "learning_rate": 8.393210570483082e-06,
      "loss": 0.2031,
      "step": 10148
    },
    {
      "epoch": 0.1606947765093339,
      "grad_norm": 0.0006801359122619033,
      "learning_rate": 8.393052234906663e-06,
      "loss": 0.0,
      "step": 10149
    },
    {
      "epoch": 0.16071061006697596,
      "grad_norm": 0.04028039798140526,
      "learning_rate": 8.392893899330242e-06,
      "loss": 0.0024,
      "step": 10150
    },
    {
      "epoch": 0.16072644362461802,
      "grad_norm": 0.18889115750789642,
      "learning_rate": 8.392735563753821e-06,
      "loss": 0.1617,
      "step": 10151
    },
    {
      "epoch": 0.16074227718226008,
      "grad_norm": 0.3719137907028198,
      "learning_rate": 8.3925772281774e-06,
      "loss": 0.2756,
      "step": 10152
    },
    {
      "epoch": 0.16075811073990215,
      "grad_norm": 0.014503170736134052,
      "learning_rate": 8.392418892600979e-06,
      "loss": 0.0006,
      "step": 10153
    },
    {
      "epoch": 0.1607739442975442,
      "grad_norm": 0.22038543224334717,
      "learning_rate": 8.392260557024558e-06,
      "loss": 0.0548,
      "step": 10154
    },
    {
      "epoch": 0.16078977785518628,
      "grad_norm": 0.2139550745487213,
      "learning_rate": 8.392102221448137e-06,
      "loss": 0.0827,
      "step": 10155
    },
    {
      "epoch": 0.16080561141282834,
      "grad_norm": 0.06977006047964096,
      "learning_rate": 8.391943885871718e-06,
      "loss": 0.0048,
      "step": 10156
    },
    {
      "epoch": 0.1608214449704704,
      "grad_norm": 0.5781189799308777,
      "learning_rate": 8.391785550295295e-06,
      "loss": 0.2741,
      "step": 10157
    },
    {
      "epoch": 0.16083727852811247,
      "grad_norm": 0.5999245047569275,
      "learning_rate": 8.391627214718876e-06,
      "loss": 0.1073,
      "step": 10158
    },
    {
      "epoch": 0.16085311208575453,
      "grad_norm": 0.005081950221210718,
      "learning_rate": 8.391468879142455e-06,
      "loss": 0.0002,
      "step": 10159
    },
    {
      "epoch": 0.16086894564339663,
      "grad_norm": 0.5716004371643066,
      "learning_rate": 8.391310543566034e-06,
      "loss": 0.0775,
      "step": 10160
    },
    {
      "epoch": 0.1608847792010387,
      "grad_norm": 0.4272308647632599,
      "learning_rate": 8.391152207989613e-06,
      "loss": 0.2041,
      "step": 10161
    },
    {
      "epoch": 0.16090061275868076,
      "grad_norm": 0.3585623502731323,
      "learning_rate": 8.390993872413194e-06,
      "loss": 0.0524,
      "step": 10162
    },
    {
      "epoch": 0.16091644631632282,
      "grad_norm": 0.5905850529670715,
      "learning_rate": 8.390835536836771e-06,
      "loss": 0.0778,
      "step": 10163
    },
    {
      "epoch": 0.16093227987396488,
      "grad_norm": 0.024687258526682854,
      "learning_rate": 8.390677201260352e-06,
      "loss": 0.0012,
      "step": 10164
    },
    {
      "epoch": 0.16094811343160695,
      "grad_norm": 0.29682859778404236,
      "learning_rate": 8.390518865683931e-06,
      "loss": 0.106,
      "step": 10165
    },
    {
      "epoch": 0.160963946989249,
      "grad_norm": 0.0011869551381096244,
      "learning_rate": 8.39036053010751e-06,
      "loss": 0.0,
      "step": 10166
    },
    {
      "epoch": 0.16097978054689108,
      "grad_norm": 0.3086790442466736,
      "learning_rate": 8.39020219453109e-06,
      "loss": 0.0654,
      "step": 10167
    },
    {
      "epoch": 0.16099561410453314,
      "grad_norm": 0.022892780601978302,
      "learning_rate": 8.39004385895467e-06,
      "loss": 0.0012,
      "step": 10168
    },
    {
      "epoch": 0.1610114476621752,
      "grad_norm": 0.31851857900619507,
      "learning_rate": 8.389885523378248e-06,
      "loss": 0.1438,
      "step": 10169
    },
    {
      "epoch": 0.16102728121981727,
      "grad_norm": 0.40559035539627075,
      "learning_rate": 8.389727187801828e-06,
      "loss": 0.2274,
      "step": 10170
    },
    {
      "epoch": 0.16104311477745933,
      "grad_norm": 0.6996600031852722,
      "learning_rate": 8.389568852225408e-06,
      "loss": 0.06,
      "step": 10171
    },
    {
      "epoch": 0.16105894833510143,
      "grad_norm": 0.0003463492030277848,
      "learning_rate": 8.389410516648987e-06,
      "loss": 0.0,
      "step": 10172
    },
    {
      "epoch": 0.1610747818927435,
      "grad_norm": 0.24451595544815063,
      "learning_rate": 8.389252181072566e-06,
      "loss": 0.0184,
      "step": 10173
    },
    {
      "epoch": 0.16109061545038555,
      "grad_norm": 0.008494744077324867,
      "learning_rate": 8.389093845496146e-06,
      "loss": 0.0005,
      "step": 10174
    },
    {
      "epoch": 0.16110644900802762,
      "grad_norm": 0.0010440271580591798,
      "learning_rate": 8.388935509919724e-06,
      "loss": 0.0,
      "step": 10175
    },
    {
      "epoch": 0.16112228256566968,
      "grad_norm": 0.5961553454399109,
      "learning_rate": 8.388777174343305e-06,
      "loss": 0.026,
      "step": 10176
    },
    {
      "epoch": 0.16113811612331175,
      "grad_norm": 0.48124462366104126,
      "learning_rate": 8.388618838766884e-06,
      "loss": 0.1277,
      "step": 10177
    },
    {
      "epoch": 0.1611539496809538,
      "grad_norm": 0.49138981103897095,
      "learning_rate": 8.388460503190463e-06,
      "loss": 0.0171,
      "step": 10178
    },
    {
      "epoch": 0.16116978323859588,
      "grad_norm": 0.0003359051770530641,
      "learning_rate": 8.388302167614042e-06,
      "loss": 0.0,
      "step": 10179
    },
    {
      "epoch": 0.16118561679623794,
      "grad_norm": 0.46519479155540466,
      "learning_rate": 8.388143832037621e-06,
      "loss": 0.133,
      "step": 10180
    },
    {
      "epoch": 0.16120145035388,
      "grad_norm": 0.33566802740097046,
      "learning_rate": 8.3879854964612e-06,
      "loss": 0.0645,
      "step": 10181
    },
    {
      "epoch": 0.16121728391152207,
      "grad_norm": 0.21114739775657654,
      "learning_rate": 8.387827160884779e-06,
      "loss": 0.0344,
      "step": 10182
    },
    {
      "epoch": 0.16123311746916413,
      "grad_norm": 0.5627200603485107,
      "learning_rate": 8.38766882530836e-06,
      "loss": 0.4427,
      "step": 10183
    },
    {
      "epoch": 0.16124895102680623,
      "grad_norm": 0.006972786504775286,
      "learning_rate": 8.387510489731939e-06,
      "loss": 0.0004,
      "step": 10184
    },
    {
      "epoch": 0.1612647845844483,
      "grad_norm": 0.25948566198349,
      "learning_rate": 8.387352154155518e-06,
      "loss": 0.1114,
      "step": 10185
    },
    {
      "epoch": 0.16128061814209035,
      "grad_norm": 0.3007400929927826,
      "learning_rate": 8.387193818579097e-06,
      "loss": 0.2116,
      "step": 10186
    },
    {
      "epoch": 0.16129645169973242,
      "grad_norm": 0.25336334109306335,
      "learning_rate": 8.387035483002676e-06,
      "loss": 0.0979,
      "step": 10187
    },
    {
      "epoch": 0.16131228525737448,
      "grad_norm": 0.5526562333106995,
      "learning_rate": 8.386877147426255e-06,
      "loss": 0.3776,
      "step": 10188
    },
    {
      "epoch": 0.16132811881501655,
      "grad_norm": 0.16645674407482147,
      "learning_rate": 8.386718811849836e-06,
      "loss": 0.0535,
      "step": 10189
    },
    {
      "epoch": 0.1613439523726586,
      "grad_norm": 0.13108421862125397,
      "learning_rate": 8.386560476273415e-06,
      "loss": 0.0459,
      "step": 10190
    },
    {
      "epoch": 0.16135978593030068,
      "grad_norm": 0.6794431805610657,
      "learning_rate": 8.386402140696994e-06,
      "loss": 0.0641,
      "step": 10191
    },
    {
      "epoch": 0.16137561948794274,
      "grad_norm": 0.35884565114974976,
      "learning_rate": 8.386243805120573e-06,
      "loss": 0.1374,
      "step": 10192
    },
    {
      "epoch": 0.1613914530455848,
      "grad_norm": 0.1918867826461792,
      "learning_rate": 8.386085469544152e-06,
      "loss": 0.0204,
      "step": 10193
    },
    {
      "epoch": 0.16140728660322687,
      "grad_norm": 0.2033851146697998,
      "learning_rate": 8.385927133967731e-06,
      "loss": 0.0951,
      "step": 10194
    },
    {
      "epoch": 0.16142312016086893,
      "grad_norm": 0.4949144423007965,
      "learning_rate": 8.385768798391312e-06,
      "loss": 0.121,
      "step": 10195
    },
    {
      "epoch": 0.16143895371851102,
      "grad_norm": 0.09235498309135437,
      "learning_rate": 8.38561046281489e-06,
      "loss": 0.0045,
      "step": 10196
    },
    {
      "epoch": 0.1614547872761531,
      "grad_norm": 0.9401842355728149,
      "learning_rate": 8.38545212723847e-06,
      "loss": 0.6424,
      "step": 10197
    },
    {
      "epoch": 0.16147062083379515,
      "grad_norm": 0.3975403606891632,
      "learning_rate": 8.38529379166205e-06,
      "loss": 0.2637,
      "step": 10198
    },
    {
      "epoch": 0.16148645439143722,
      "grad_norm": 0.3266373872756958,
      "learning_rate": 8.385135456085629e-06,
      "loss": 0.1864,
      "step": 10199
    },
    {
      "epoch": 0.16150228794907928,
      "grad_norm": 0.3788262605667114,
      "learning_rate": 8.384977120509208e-06,
      "loss": 0.2934,
      "step": 10200
    },
    {
      "epoch": 0.16151812150672135,
      "grad_norm": 0.0013552895979955792,
      "learning_rate": 8.384818784932788e-06,
      "loss": 0.0,
      "step": 10201
    },
    {
      "epoch": 0.1615339550643634,
      "grad_norm": 0.4781267046928406,
      "learning_rate": 8.384660449356366e-06,
      "loss": 0.2448,
      "step": 10202
    },
    {
      "epoch": 0.16154978862200547,
      "grad_norm": 0.4613475501537323,
      "learning_rate": 8.384502113779945e-06,
      "loss": 0.3531,
      "step": 10203
    },
    {
      "epoch": 0.16156562217964754,
      "grad_norm": 0.4842594861984253,
      "learning_rate": 8.384343778203526e-06,
      "loss": 0.149,
      "step": 10204
    },
    {
      "epoch": 0.1615814557372896,
      "grad_norm": 0.41222283244132996,
      "learning_rate": 8.384185442627105e-06,
      "loss": 0.2085,
      "step": 10205
    },
    {
      "epoch": 0.16159728929493167,
      "grad_norm": 0.34771206974983215,
      "learning_rate": 8.384027107050684e-06,
      "loss": 0.1206,
      "step": 10206
    },
    {
      "epoch": 0.16161312285257373,
      "grad_norm": 0.3966362178325653,
      "learning_rate": 8.383868771474263e-06,
      "loss": 0.135,
      "step": 10207
    },
    {
      "epoch": 0.16162895641021582,
      "grad_norm": 0.12700369954109192,
      "learning_rate": 8.383710435897842e-06,
      "loss": 0.0621,
      "step": 10208
    },
    {
      "epoch": 0.1616447899678579,
      "grad_norm": 0.0011791153810918331,
      "learning_rate": 8.383552100321421e-06,
      "loss": 0.0,
      "step": 10209
    },
    {
      "epoch": 0.16166062352549995,
      "grad_norm": 0.3153824210166931,
      "learning_rate": 8.383393764745002e-06,
      "loss": 0.1033,
      "step": 10210
    },
    {
      "epoch": 0.16167645708314202,
      "grad_norm": 0.01889656111598015,
      "learning_rate": 8.383235429168581e-06,
      "loss": 0.001,
      "step": 10211
    },
    {
      "epoch": 0.16169229064078408,
      "grad_norm": 0.4013775885105133,
      "learning_rate": 8.38307709359216e-06,
      "loss": 0.4978,
      "step": 10212
    },
    {
      "epoch": 0.16170812419842615,
      "grad_norm": 0.9364562630653381,
      "learning_rate": 8.382918758015739e-06,
      "loss": 0.1171,
      "step": 10213
    },
    {
      "epoch": 0.1617239577560682,
      "grad_norm": 0.19435328245162964,
      "learning_rate": 8.382760422439318e-06,
      "loss": 0.0669,
      "step": 10214
    },
    {
      "epoch": 0.16173979131371027,
      "grad_norm": 0.5161387920379639,
      "learning_rate": 8.382602086862897e-06,
      "loss": 0.1964,
      "step": 10215
    },
    {
      "epoch": 0.16175562487135234,
      "grad_norm": 0.027552559971809387,
      "learning_rate": 8.382443751286478e-06,
      "loss": 0.0003,
      "step": 10216
    },
    {
      "epoch": 0.1617714584289944,
      "grad_norm": 0.5134634375572205,
      "learning_rate": 8.382285415710057e-06,
      "loss": 0.2071,
      "step": 10217
    },
    {
      "epoch": 0.16178729198663647,
      "grad_norm": 0.07074146717786789,
      "learning_rate": 8.382127080133636e-06,
      "loss": 0.0082,
      "step": 10218
    },
    {
      "epoch": 0.16180312554427853,
      "grad_norm": 0.40648287534713745,
      "learning_rate": 8.381968744557215e-06,
      "loss": 0.2457,
      "step": 10219
    },
    {
      "epoch": 0.16181895910192062,
      "grad_norm": 0.02178049087524414,
      "learning_rate": 8.381810408980794e-06,
      "loss": 0.0012,
      "step": 10220
    },
    {
      "epoch": 0.1618347926595627,
      "grad_norm": 0.003928930498659611,
      "learning_rate": 8.381652073404373e-06,
      "loss": 0.0002,
      "step": 10221
    },
    {
      "epoch": 0.16185062621720475,
      "grad_norm": 0.2770056426525116,
      "learning_rate": 8.381493737827954e-06,
      "loss": 0.1169,
      "step": 10222
    },
    {
      "epoch": 0.16186645977484682,
      "grad_norm": 0.14587965607643127,
      "learning_rate": 8.381335402251533e-06,
      "loss": 0.0893,
      "step": 10223
    },
    {
      "epoch": 0.16188229333248888,
      "grad_norm": 0.2531142830848694,
      "learning_rate": 8.381177066675112e-06,
      "loss": 0.0729,
      "step": 10224
    },
    {
      "epoch": 0.16189812689013094,
      "grad_norm": 0.0007402916671708226,
      "learning_rate": 8.381018731098691e-06,
      "loss": 0.0,
      "step": 10225
    },
    {
      "epoch": 0.161913960447773,
      "grad_norm": 0.0006853883387520909,
      "learning_rate": 8.38086039552227e-06,
      "loss": 0.0,
      "step": 10226
    },
    {
      "epoch": 0.16192979400541507,
      "grad_norm": 0.6229109168052673,
      "learning_rate": 8.38070205994585e-06,
      "loss": 0.2699,
      "step": 10227
    },
    {
      "epoch": 0.16194562756305714,
      "grad_norm": 0.4438032805919647,
      "learning_rate": 8.380543724369429e-06,
      "loss": 0.4759,
      "step": 10228
    },
    {
      "epoch": 0.1619614611206992,
      "grad_norm": 0.2720530927181244,
      "learning_rate": 8.38038538879301e-06,
      "loss": 0.1554,
      "step": 10229
    },
    {
      "epoch": 0.16197729467834127,
      "grad_norm": 0.0004771131498273462,
      "learning_rate": 8.380227053216587e-06,
      "loss": 0.0,
      "step": 10230
    },
    {
      "epoch": 0.16199312823598333,
      "grad_norm": 0.3200972378253937,
      "learning_rate": 8.380068717640168e-06,
      "loss": 0.0746,
      "step": 10231
    },
    {
      "epoch": 0.16200896179362542,
      "grad_norm": 0.7109807133674622,
      "learning_rate": 8.379910382063747e-06,
      "loss": 0.0694,
      "step": 10232
    },
    {
      "epoch": 0.1620247953512675,
      "grad_norm": 0.23319019377231598,
      "learning_rate": 8.379752046487326e-06,
      "loss": 0.054,
      "step": 10233
    },
    {
      "epoch": 0.16204062890890955,
      "grad_norm": 0.43088218569755554,
      "learning_rate": 8.379593710910905e-06,
      "loss": 0.204,
      "step": 10234
    },
    {
      "epoch": 0.16205646246655162,
      "grad_norm": 0.33184948563575745,
      "learning_rate": 8.379435375334486e-06,
      "loss": 0.1128,
      "step": 10235
    },
    {
      "epoch": 0.16207229602419368,
      "grad_norm": 0.13471180200576782,
      "learning_rate": 8.379277039758063e-06,
      "loss": 0.0428,
      "step": 10236
    },
    {
      "epoch": 0.16208812958183574,
      "grad_norm": 0.4049378037452698,
      "learning_rate": 8.379118704181644e-06,
      "loss": 0.2056,
      "step": 10237
    },
    {
      "epoch": 0.1621039631394778,
      "grad_norm": 0.002280564745888114,
      "learning_rate": 8.378960368605223e-06,
      "loss": 0.0,
      "step": 10238
    },
    {
      "epoch": 0.16211979669711987,
      "grad_norm": 1.7157050371170044,
      "learning_rate": 8.378802033028802e-06,
      "loss": 0.1344,
      "step": 10239
    },
    {
      "epoch": 0.16213563025476194,
      "grad_norm": 0.3376345932483673,
      "learning_rate": 8.378643697452381e-06,
      "loss": 0.3059,
      "step": 10240
    },
    {
      "epoch": 0.162151463812404,
      "grad_norm": 0.3296029567718506,
      "learning_rate": 8.378485361875962e-06,
      "loss": 0.5065,
      "step": 10241
    },
    {
      "epoch": 0.16216729737004607,
      "grad_norm": 0.4398757219314575,
      "learning_rate": 8.378327026299539e-06,
      "loss": 0.1446,
      "step": 10242
    },
    {
      "epoch": 0.16218313092768813,
      "grad_norm": 0.18043801188468933,
      "learning_rate": 8.37816869072312e-06,
      "loss": 0.0863,
      "step": 10243
    },
    {
      "epoch": 0.16219896448533022,
      "grad_norm": 0.08163092285394669,
      "learning_rate": 8.378010355146699e-06,
      "loss": 0.0048,
      "step": 10244
    },
    {
      "epoch": 0.16221479804297229,
      "grad_norm": 0.0313432440161705,
      "learning_rate": 8.377852019570278e-06,
      "loss": 0.0009,
      "step": 10245
    },
    {
      "epoch": 0.16223063160061435,
      "grad_norm": 0.2621521055698395,
      "learning_rate": 8.377693683993857e-06,
      "loss": 0.021,
      "step": 10246
    },
    {
      "epoch": 0.16224646515825641,
      "grad_norm": 0.18385227024555206,
      "learning_rate": 8.377535348417438e-06,
      "loss": 0.0326,
      "step": 10247
    },
    {
      "epoch": 0.16226229871589848,
      "grad_norm": 0.19688603281974792,
      "learning_rate": 8.377377012841015e-06,
      "loss": 0.0593,
      "step": 10248
    },
    {
      "epoch": 0.16227813227354054,
      "grad_norm": 0.43199363350868225,
      "learning_rate": 8.377218677264596e-06,
      "loss": 0.1211,
      "step": 10249
    },
    {
      "epoch": 0.1622939658311826,
      "grad_norm": 0.38977792859077454,
      "learning_rate": 8.377060341688175e-06,
      "loss": 0.1497,
      "step": 10250
    },
    {
      "epoch": 0.16230979938882467,
      "grad_norm": 0.17463085055351257,
      "learning_rate": 8.376902006111754e-06,
      "loss": 0.0778,
      "step": 10251
    },
    {
      "epoch": 0.16232563294646674,
      "grad_norm": 0.17064730823040009,
      "learning_rate": 8.376743670535333e-06,
      "loss": 0.005,
      "step": 10252
    },
    {
      "epoch": 0.1623414665041088,
      "grad_norm": 0.02182137407362461,
      "learning_rate": 8.376585334958912e-06,
      "loss": 0.0011,
      "step": 10253
    },
    {
      "epoch": 0.16235730006175086,
      "grad_norm": 0.40661194920539856,
      "learning_rate": 8.376426999382491e-06,
      "loss": 0.0119,
      "step": 10254
    },
    {
      "epoch": 0.16237313361939293,
      "grad_norm": 0.2579673230648041,
      "learning_rate": 8.37626866380607e-06,
      "loss": 0.0854,
      "step": 10255
    },
    {
      "epoch": 0.16238896717703502,
      "grad_norm": 0.7258300185203552,
      "learning_rate": 8.376110328229651e-06,
      "loss": 0.1978,
      "step": 10256
    },
    {
      "epoch": 0.16240480073467708,
      "grad_norm": 0.3573491871356964,
      "learning_rate": 8.37595199265323e-06,
      "loss": 0.0792,
      "step": 10257
    },
    {
      "epoch": 0.16242063429231915,
      "grad_norm": 0.4759654998779297,
      "learning_rate": 8.37579365707681e-06,
      "loss": 0.2658,
      "step": 10258
    },
    {
      "epoch": 0.1624364678499612,
      "grad_norm": 0.029804930090904236,
      "learning_rate": 8.375635321500389e-06,
      "loss": 0.0018,
      "step": 10259
    },
    {
      "epoch": 0.16245230140760328,
      "grad_norm": 0.0006001455476507545,
      "learning_rate": 8.375476985923968e-06,
      "loss": 0.0,
      "step": 10260
    },
    {
      "epoch": 0.16246813496524534,
      "grad_norm": 0.005406132899224758,
      "learning_rate": 8.375318650347547e-06,
      "loss": 0.0001,
      "step": 10261
    },
    {
      "epoch": 0.1624839685228874,
      "grad_norm": 0.9162530303001404,
      "learning_rate": 8.375160314771127e-06,
      "loss": 0.9429,
      "step": 10262
    },
    {
      "epoch": 0.16249980208052947,
      "grad_norm": 0.6583996415138245,
      "learning_rate": 8.375001979194705e-06,
      "loss": 0.1294,
      "step": 10263
    },
    {
      "epoch": 0.16251563563817154,
      "grad_norm": 8.300510671688244e-05,
      "learning_rate": 8.374843643618286e-06,
      "loss": 0.0,
      "step": 10264
    },
    {
      "epoch": 0.1625314691958136,
      "grad_norm": 0.525798499584198,
      "learning_rate": 8.374685308041865e-06,
      "loss": 0.2753,
      "step": 10265
    },
    {
      "epoch": 0.16254730275345566,
      "grad_norm": 0.5250034928321838,
      "learning_rate": 8.374526972465444e-06,
      "loss": 0.1384,
      "step": 10266
    },
    {
      "epoch": 0.16256313631109773,
      "grad_norm": 0.24630670249462128,
      "learning_rate": 8.374368636889023e-06,
      "loss": 0.0814,
      "step": 10267
    },
    {
      "epoch": 0.16257896986873982,
      "grad_norm": 0.1401427984237671,
      "learning_rate": 8.374210301312604e-06,
      "loss": 0.0222,
      "step": 10268
    },
    {
      "epoch": 0.16259480342638188,
      "grad_norm": 0.1549038589000702,
      "learning_rate": 8.374051965736181e-06,
      "loss": 0.0065,
      "step": 10269
    },
    {
      "epoch": 0.16261063698402395,
      "grad_norm": 0.6676093935966492,
      "learning_rate": 8.373893630159762e-06,
      "loss": 0.1243,
      "step": 10270
    },
    {
      "epoch": 0.162626470541666,
      "grad_norm": 0.2625519037246704,
      "learning_rate": 8.373735294583341e-06,
      "loss": 0.0883,
      "step": 10271
    },
    {
      "epoch": 0.16264230409930808,
      "grad_norm": 0.00029244396137073636,
      "learning_rate": 8.37357695900692e-06,
      "loss": 0.0,
      "step": 10272
    },
    {
      "epoch": 0.16265813765695014,
      "grad_norm": 0.8644127249717712,
      "learning_rate": 8.373418623430499e-06,
      "loss": 0.1661,
      "step": 10273
    },
    {
      "epoch": 0.1626739712145922,
      "grad_norm": 0.4788609445095062,
      "learning_rate": 8.373260287854078e-06,
      "loss": 0.3168,
      "step": 10274
    },
    {
      "epoch": 0.16268980477223427,
      "grad_norm": 0.3314240574836731,
      "learning_rate": 8.373101952277657e-06,
      "loss": 0.1958,
      "step": 10275
    },
    {
      "epoch": 0.16270563832987633,
      "grad_norm": 0.38183584809303284,
      "learning_rate": 8.372943616701236e-06,
      "loss": 0.0139,
      "step": 10276
    },
    {
      "epoch": 0.1627214718875184,
      "grad_norm": 0.0092426473274827,
      "learning_rate": 8.372785281124817e-06,
      "loss": 0.0005,
      "step": 10277
    },
    {
      "epoch": 0.16273730544516046,
      "grad_norm": 0.3263881504535675,
      "learning_rate": 8.372626945548396e-06,
      "loss": 0.1351,
      "step": 10278
    },
    {
      "epoch": 0.16275313900280253,
      "grad_norm": 0.6754976511001587,
      "learning_rate": 8.372468609971975e-06,
      "loss": 0.1444,
      "step": 10279
    },
    {
      "epoch": 0.16276897256044462,
      "grad_norm": 0.3255158066749573,
      "learning_rate": 8.372310274395554e-06,
      "loss": 0.1036,
      "step": 10280
    },
    {
      "epoch": 0.16278480611808668,
      "grad_norm": 0.008918560110032558,
      "learning_rate": 8.372151938819133e-06,
      "loss": 0.0002,
      "step": 10281
    },
    {
      "epoch": 0.16280063967572875,
      "grad_norm": 0.4857216477394104,
      "learning_rate": 8.371993603242712e-06,
      "loss": 0.2581,
      "step": 10282
    },
    {
      "epoch": 0.1628164732333708,
      "grad_norm": 0.9707632660865784,
      "learning_rate": 8.371835267666293e-06,
      "loss": 0.3621,
      "step": 10283
    },
    {
      "epoch": 0.16283230679101288,
      "grad_norm": 0.36779338121414185,
      "learning_rate": 8.371676932089872e-06,
      "loss": 0.1529,
      "step": 10284
    },
    {
      "epoch": 0.16284814034865494,
      "grad_norm": 0.23346517980098724,
      "learning_rate": 8.371518596513451e-06,
      "loss": 0.0646,
      "step": 10285
    },
    {
      "epoch": 0.162863973906297,
      "grad_norm": 0.39401429891586304,
      "learning_rate": 8.37136026093703e-06,
      "loss": 0.1522,
      "step": 10286
    },
    {
      "epoch": 0.16287980746393907,
      "grad_norm": 0.03184972330927849,
      "learning_rate": 8.37120192536061e-06,
      "loss": 0.0015,
      "step": 10287
    },
    {
      "epoch": 0.16289564102158113,
      "grad_norm": 0.2124830186367035,
      "learning_rate": 8.371043589784189e-06,
      "loss": 0.079,
      "step": 10288
    },
    {
      "epoch": 0.1629114745792232,
      "grad_norm": 0.015693819150328636,
      "learning_rate": 8.37088525420777e-06,
      "loss": 0.0007,
      "step": 10289
    },
    {
      "epoch": 0.16292730813686526,
      "grad_norm": 0.24843916296958923,
      "learning_rate": 8.370726918631348e-06,
      "loss": 0.0877,
      "step": 10290
    },
    {
      "epoch": 0.16294314169450733,
      "grad_norm": 0.6525678634643555,
      "learning_rate": 8.370568583054928e-06,
      "loss": 0.1974,
      "step": 10291
    },
    {
      "epoch": 0.16295897525214942,
      "grad_norm": 0.14268293976783752,
      "learning_rate": 8.370410247478507e-06,
      "loss": 0.063,
      "step": 10292
    },
    {
      "epoch": 0.16297480880979148,
      "grad_norm": 0.0019764527678489685,
      "learning_rate": 8.370251911902086e-06,
      "loss": 0.0001,
      "step": 10293
    },
    {
      "epoch": 0.16299064236743355,
      "grad_norm": 1.0472320318222046,
      "learning_rate": 8.370093576325665e-06,
      "loss": 0.1467,
      "step": 10294
    },
    {
      "epoch": 0.1630064759250756,
      "grad_norm": 0.024048741906881332,
      "learning_rate": 8.369935240749246e-06,
      "loss": 0.0011,
      "step": 10295
    },
    {
      "epoch": 0.16302230948271768,
      "grad_norm": 0.5679568648338318,
      "learning_rate": 8.369776905172825e-06,
      "loss": 0.3144,
      "step": 10296
    },
    {
      "epoch": 0.16303814304035974,
      "grad_norm": 0.4411211609840393,
      "learning_rate": 8.369618569596404e-06,
      "loss": 0.6057,
      "step": 10297
    },
    {
      "epoch": 0.1630539765980018,
      "grad_norm": 0.01201123371720314,
      "learning_rate": 8.369460234019983e-06,
      "loss": 0.0007,
      "step": 10298
    },
    {
      "epoch": 0.16306981015564387,
      "grad_norm": 0.22921977937221527,
      "learning_rate": 8.369301898443562e-06,
      "loss": 0.0484,
      "step": 10299
    },
    {
      "epoch": 0.16308564371328593,
      "grad_norm": 0.4376648962497711,
      "learning_rate": 8.369143562867141e-06,
      "loss": 0.1264,
      "step": 10300
    },
    {
      "epoch": 0.163101477270928,
      "grad_norm": 0.0005840196972712874,
      "learning_rate": 8.36898522729072e-06,
      "loss": 0.0,
      "step": 10301
    },
    {
      "epoch": 0.16311731082857006,
      "grad_norm": 0.022840315476059914,
      "learning_rate": 8.3688268917143e-06,
      "loss": 0.0013,
      "step": 10302
    },
    {
      "epoch": 0.16313314438621213,
      "grad_norm": 0.4574822783470154,
      "learning_rate": 8.368668556137878e-06,
      "loss": 0.3601,
      "step": 10303
    },
    {
      "epoch": 0.16314897794385422,
      "grad_norm": 0.00029964683926664293,
      "learning_rate": 8.368510220561459e-06,
      "loss": 0.0,
      "step": 10304
    },
    {
      "epoch": 0.16316481150149628,
      "grad_norm": 0.21822302043437958,
      "learning_rate": 8.368351884985038e-06,
      "loss": 0.0225,
      "step": 10305
    },
    {
      "epoch": 0.16318064505913835,
      "grad_norm": 0.4156784415245056,
      "learning_rate": 8.368193549408617e-06,
      "loss": 0.2116,
      "step": 10306
    },
    {
      "epoch": 0.1631964786167804,
      "grad_norm": 0.15198655426502228,
      "learning_rate": 8.368035213832196e-06,
      "loss": 0.0317,
      "step": 10307
    },
    {
      "epoch": 0.16321231217442247,
      "grad_norm": 0.6741867661476135,
      "learning_rate": 8.367876878255777e-06,
      "loss": 0.3025,
      "step": 10308
    },
    {
      "epoch": 0.16322814573206454,
      "grad_norm": 0.008909803815186024,
      "learning_rate": 8.367718542679354e-06,
      "loss": 0.0005,
      "step": 10309
    },
    {
      "epoch": 0.1632439792897066,
      "grad_norm": 0.07294227182865143,
      "learning_rate": 8.367560207102935e-06,
      "loss": 0.0014,
      "step": 10310
    },
    {
      "epoch": 0.16325981284734867,
      "grad_norm": 0.20361776649951935,
      "learning_rate": 8.367401871526514e-06,
      "loss": 0.0587,
      "step": 10311
    },
    {
      "epoch": 0.16327564640499073,
      "grad_norm": 0.016578394919633865,
      "learning_rate": 8.367243535950093e-06,
      "loss": 0.0012,
      "step": 10312
    },
    {
      "epoch": 0.1632914799626328,
      "grad_norm": 0.5394341349601746,
      "learning_rate": 8.367085200373672e-06,
      "loss": 0.5003,
      "step": 10313
    },
    {
      "epoch": 0.16330731352027486,
      "grad_norm": 0.5173748731613159,
      "learning_rate": 8.366926864797253e-06,
      "loss": 0.0931,
      "step": 10314
    },
    {
      "epoch": 0.16332314707791692,
      "grad_norm": 0.2564432621002197,
      "learning_rate": 8.36676852922083e-06,
      "loss": 0.0826,
      "step": 10315
    },
    {
      "epoch": 0.16333898063555902,
      "grad_norm": 0.054937705397605896,
      "learning_rate": 8.366610193644411e-06,
      "loss": 0.0027,
      "step": 10316
    },
    {
      "epoch": 0.16335481419320108,
      "grad_norm": 0.353864848613739,
      "learning_rate": 8.36645185806799e-06,
      "loss": 0.098,
      "step": 10317
    },
    {
      "epoch": 0.16337064775084315,
      "grad_norm": 0.5679168701171875,
      "learning_rate": 8.36629352249157e-06,
      "loss": 0.3258,
      "step": 10318
    },
    {
      "epoch": 0.1633864813084852,
      "grad_norm": 0.018199188634753227,
      "learning_rate": 8.366135186915149e-06,
      "loss": 0.0007,
      "step": 10319
    },
    {
      "epoch": 0.16340231486612727,
      "grad_norm": 0.36757075786590576,
      "learning_rate": 8.36597685133873e-06,
      "loss": 0.2274,
      "step": 10320
    },
    {
      "epoch": 0.16341814842376934,
      "grad_norm": 0.3640485107898712,
      "learning_rate": 8.365818515762307e-06,
      "loss": 0.1145,
      "step": 10321
    },
    {
      "epoch": 0.1634339819814114,
      "grad_norm": 0.44704657793045044,
      "learning_rate": 8.365660180185886e-06,
      "loss": 0.1907,
      "step": 10322
    },
    {
      "epoch": 0.16344981553905347,
      "grad_norm": 0.000882943975739181,
      "learning_rate": 8.365501844609467e-06,
      "loss": 0.0,
      "step": 10323
    },
    {
      "epoch": 0.16346564909669553,
      "grad_norm": 0.4044440686702728,
      "learning_rate": 8.365343509033046e-06,
      "loss": 0.5575,
      "step": 10324
    },
    {
      "epoch": 0.1634814826543376,
      "grad_norm": 0.0008477892260998487,
      "learning_rate": 8.365185173456625e-06,
      "loss": 0.0,
      "step": 10325
    },
    {
      "epoch": 0.16349731621197966,
      "grad_norm": 0.1243022009730339,
      "learning_rate": 8.365026837880204e-06,
      "loss": 0.0464,
      "step": 10326
    },
    {
      "epoch": 0.16351314976962172,
      "grad_norm": 0.3412613272666931,
      "learning_rate": 8.364868502303783e-06,
      "loss": 0.2529,
      "step": 10327
    },
    {
      "epoch": 0.16352898332726382,
      "grad_norm": 0.2481490671634674,
      "learning_rate": 8.364710166727362e-06,
      "loss": 0.0594,
      "step": 10328
    },
    {
      "epoch": 0.16354481688490588,
      "grad_norm": 0.19930687546730042,
      "learning_rate": 8.364551831150943e-06,
      "loss": 0.1374,
      "step": 10329
    },
    {
      "epoch": 0.16356065044254794,
      "grad_norm": 0.24463874101638794,
      "learning_rate": 8.36439349557452e-06,
      "loss": 0.0989,
      "step": 10330
    },
    {
      "epoch": 0.16357648400019,
      "grad_norm": 0.23480693995952606,
      "learning_rate": 8.364235159998101e-06,
      "loss": 0.0571,
      "step": 10331
    },
    {
      "epoch": 0.16359231755783207,
      "grad_norm": 0.38786908984184265,
      "learning_rate": 8.36407682442168e-06,
      "loss": 0.091,
      "step": 10332
    },
    {
      "epoch": 0.16360815111547414,
      "grad_norm": 1.7728275060653687,
      "learning_rate": 8.363918488845259e-06,
      "loss": 1.5748,
      "step": 10333
    },
    {
      "epoch": 0.1636239846731162,
      "grad_norm": 0.0069835069589316845,
      "learning_rate": 8.363760153268838e-06,
      "loss": 0.0004,
      "step": 10334
    },
    {
      "epoch": 0.16363981823075827,
      "grad_norm": 0.2821447253227234,
      "learning_rate": 8.363601817692419e-06,
      "loss": 0.1088,
      "step": 10335
    },
    {
      "epoch": 0.16365565178840033,
      "grad_norm": 0.7295007705688477,
      "learning_rate": 8.363443482115996e-06,
      "loss": 0.473,
      "step": 10336
    },
    {
      "epoch": 0.1636714853460424,
      "grad_norm": 0.2842141091823578,
      "learning_rate": 8.363285146539577e-06,
      "loss": 0.1416,
      "step": 10337
    },
    {
      "epoch": 0.16368731890368446,
      "grad_norm": 0.014367369003593922,
      "learning_rate": 8.363126810963156e-06,
      "loss": 0.0007,
      "step": 10338
    },
    {
      "epoch": 0.16370315246132652,
      "grad_norm": 0.26028937101364136,
      "learning_rate": 8.362968475386735e-06,
      "loss": 0.0802,
      "step": 10339
    },
    {
      "epoch": 0.16371898601896862,
      "grad_norm": 1.002859354019165,
      "learning_rate": 8.362810139810314e-06,
      "loss": 0.2271,
      "step": 10340
    },
    {
      "epoch": 0.16373481957661068,
      "grad_norm": 0.16868935525417328,
      "learning_rate": 8.362651804233895e-06,
      "loss": 0.0513,
      "step": 10341
    },
    {
      "epoch": 0.16375065313425274,
      "grad_norm": 0.3763304054737091,
      "learning_rate": 8.362493468657472e-06,
      "loss": 0.2987,
      "step": 10342
    },
    {
      "epoch": 0.1637664866918948,
      "grad_norm": 0.02058134414255619,
      "learning_rate": 8.362335133081053e-06,
      "loss": 0.0003,
      "step": 10343
    },
    {
      "epoch": 0.16378232024953687,
      "grad_norm": 0.199583500623703,
      "learning_rate": 8.362176797504632e-06,
      "loss": 0.0748,
      "step": 10344
    },
    {
      "epoch": 0.16379815380717894,
      "grad_norm": 0.26797932386398315,
      "learning_rate": 8.362018461928211e-06,
      "loss": 0.1007,
      "step": 10345
    },
    {
      "epoch": 0.163813987364821,
      "grad_norm": 0.037017159163951874,
      "learning_rate": 8.36186012635179e-06,
      "loss": 0.0024,
      "step": 10346
    },
    {
      "epoch": 0.16382982092246307,
      "grad_norm": 0.037202853709459305,
      "learning_rate": 8.36170179077537e-06,
      "loss": 0.0022,
      "step": 10347
    },
    {
      "epoch": 0.16384565448010513,
      "grad_norm": 0.22816194593906403,
      "learning_rate": 8.361543455198949e-06,
      "loss": 0.066,
      "step": 10348
    },
    {
      "epoch": 0.1638614880377472,
      "grad_norm": 0.01862335205078125,
      "learning_rate": 8.361385119622528e-06,
      "loss": 0.0006,
      "step": 10349
    },
    {
      "epoch": 0.16387732159538926,
      "grad_norm": 0.42400074005126953,
      "learning_rate": 8.361226784046109e-06,
      "loss": 0.1664,
      "step": 10350
    },
    {
      "epoch": 0.16389315515303132,
      "grad_norm": 0.13673414289951324,
      "learning_rate": 8.361068448469688e-06,
      "loss": 0.0611,
      "step": 10351
    },
    {
      "epoch": 0.16390898871067341,
      "grad_norm": 0.047027140855789185,
      "learning_rate": 8.360910112893267e-06,
      "loss": 0.0073,
      "step": 10352
    },
    {
      "epoch": 0.16392482226831548,
      "grad_norm": 0.24751560389995575,
      "learning_rate": 8.360751777316846e-06,
      "loss": 0.0818,
      "step": 10353
    },
    {
      "epoch": 0.16394065582595754,
      "grad_norm": 0.40025991201400757,
      "learning_rate": 8.360593441740425e-06,
      "loss": 0.2609,
      "step": 10354
    },
    {
      "epoch": 0.1639564893835996,
      "grad_norm": 0.00022470502881333232,
      "learning_rate": 8.360435106164004e-06,
      "loss": 0.0,
      "step": 10355
    },
    {
      "epoch": 0.16397232294124167,
      "grad_norm": 0.32876041531562805,
      "learning_rate": 8.360276770587585e-06,
      "loss": 0.1547,
      "step": 10356
    },
    {
      "epoch": 0.16398815649888374,
      "grad_norm": 0.03837810456752777,
      "learning_rate": 8.360118435011164e-06,
      "loss": 0.0018,
      "step": 10357
    },
    {
      "epoch": 0.1640039900565258,
      "grad_norm": 0.20274120569229126,
      "learning_rate": 8.359960099434743e-06,
      "loss": 0.0085,
      "step": 10358
    },
    {
      "epoch": 0.16401982361416786,
      "grad_norm": 0.3694528341293335,
      "learning_rate": 8.359801763858322e-06,
      "loss": 0.2039,
      "step": 10359
    },
    {
      "epoch": 0.16403565717180993,
      "grad_norm": 0.0035046006087213755,
      "learning_rate": 8.359643428281901e-06,
      "loss": 0.0002,
      "step": 10360
    },
    {
      "epoch": 0.164051490729452,
      "grad_norm": 0.019649537280201912,
      "learning_rate": 8.35948509270548e-06,
      "loss": 0.0011,
      "step": 10361
    },
    {
      "epoch": 0.16406732428709406,
      "grad_norm": 0.019152222201228142,
      "learning_rate": 8.359326757129061e-06,
      "loss": 0.0009,
      "step": 10362
    },
    {
      "epoch": 0.16408315784473612,
      "grad_norm": 0.0937548503279686,
      "learning_rate": 8.35916842155264e-06,
      "loss": 0.009,
      "step": 10363
    },
    {
      "epoch": 0.1640989914023782,
      "grad_norm": 0.0033604521304368973,
      "learning_rate": 8.359010085976219e-06,
      "loss": 0.0002,
      "step": 10364
    },
    {
      "epoch": 0.16411482496002028,
      "grad_norm": 0.39825278520584106,
      "learning_rate": 8.358851750399798e-06,
      "loss": 0.2612,
      "step": 10365
    },
    {
      "epoch": 0.16413065851766234,
      "grad_norm": 0.13958331942558289,
      "learning_rate": 8.358693414823377e-06,
      "loss": 0.0598,
      "step": 10366
    },
    {
      "epoch": 0.1641464920753044,
      "grad_norm": 0.05984948202967644,
      "learning_rate": 8.358535079246956e-06,
      "loss": 0.0088,
      "step": 10367
    },
    {
      "epoch": 0.16416232563294647,
      "grad_norm": 0.2652144730091095,
      "learning_rate": 8.358376743670537e-06,
      "loss": 0.0384,
      "step": 10368
    },
    {
      "epoch": 0.16417815919058854,
      "grad_norm": 0.5192230939865112,
      "learning_rate": 8.358218408094116e-06,
      "loss": 0.6689,
      "step": 10369
    },
    {
      "epoch": 0.1641939927482306,
      "grad_norm": 0.011623752303421497,
      "learning_rate": 8.358060072517693e-06,
      "loss": 0.0006,
      "step": 10370
    },
    {
      "epoch": 0.16420982630587266,
      "grad_norm": 0.7924548387527466,
      "learning_rate": 8.357901736941274e-06,
      "loss": 0.1844,
      "step": 10371
    },
    {
      "epoch": 0.16422565986351473,
      "grad_norm": 0.012563073076307774,
      "learning_rate": 8.357743401364853e-06,
      "loss": 0.0006,
      "step": 10372
    },
    {
      "epoch": 0.1642414934211568,
      "grad_norm": 0.4318214952945709,
      "learning_rate": 8.357585065788432e-06,
      "loss": 0.3476,
      "step": 10373
    },
    {
      "epoch": 0.16425732697879886,
      "grad_norm": 0.12734417617321014,
      "learning_rate": 8.357426730212011e-06,
      "loss": 0.0499,
      "step": 10374
    },
    {
      "epoch": 0.16427316053644092,
      "grad_norm": 0.006049793213605881,
      "learning_rate": 8.357268394635592e-06,
      "loss": 0.0003,
      "step": 10375
    },
    {
      "epoch": 0.164288994094083,
      "grad_norm": 0.019281480461359024,
      "learning_rate": 8.35711005905917e-06,
      "loss": 0.0009,
      "step": 10376
    },
    {
      "epoch": 0.16430482765172508,
      "grad_norm": 0.22222568094730377,
      "learning_rate": 8.35695172348275e-06,
      "loss": 0.083,
      "step": 10377
    },
    {
      "epoch": 0.16432066120936714,
      "grad_norm": 0.02493814192712307,
      "learning_rate": 8.35679338790633e-06,
      "loss": 0.0014,
      "step": 10378
    },
    {
      "epoch": 0.1643364947670092,
      "grad_norm": 0.4529794156551361,
      "learning_rate": 8.356635052329909e-06,
      "loss": 0.4976,
      "step": 10379
    },
    {
      "epoch": 0.16435232832465127,
      "grad_norm": 0.4937226474285126,
      "learning_rate": 8.356476716753488e-06,
      "loss": 0.1488,
      "step": 10380
    },
    {
      "epoch": 0.16436816188229333,
      "grad_norm": 0.5102658867835999,
      "learning_rate": 8.356318381177068e-06,
      "loss": 0.0139,
      "step": 10381
    },
    {
      "epoch": 0.1643839954399354,
      "grad_norm": 0.9217146039009094,
      "learning_rate": 8.356160045600646e-06,
      "loss": 0.339,
      "step": 10382
    },
    {
      "epoch": 0.16439982899757746,
      "grad_norm": 0.4348985552787781,
      "learning_rate": 8.356001710024227e-06,
      "loss": 0.4351,
      "step": 10383
    },
    {
      "epoch": 0.16441566255521953,
      "grad_norm": 0.01147227268666029,
      "learning_rate": 8.355843374447806e-06,
      "loss": 0.0005,
      "step": 10384
    },
    {
      "epoch": 0.1644314961128616,
      "grad_norm": 0.06337475776672363,
      "learning_rate": 8.355685038871385e-06,
      "loss": 0.0033,
      "step": 10385
    },
    {
      "epoch": 0.16444732967050366,
      "grad_norm": 0.4998033046722412,
      "learning_rate": 8.355526703294964e-06,
      "loss": 0.148,
      "step": 10386
    },
    {
      "epoch": 0.16446316322814572,
      "grad_norm": 0.15793533623218536,
      "learning_rate": 8.355368367718543e-06,
      "loss": 0.0173,
      "step": 10387
    },
    {
      "epoch": 0.1644789967857878,
      "grad_norm": 0.24407483637332916,
      "learning_rate": 8.355210032142122e-06,
      "loss": 0.2687,
      "step": 10388
    },
    {
      "epoch": 0.16449483034342988,
      "grad_norm": 0.0015224864473566413,
      "learning_rate": 8.355051696565703e-06,
      "loss": 0.0001,
      "step": 10389
    },
    {
      "epoch": 0.16451066390107194,
      "grad_norm": 0.20319101214408875,
      "learning_rate": 8.354893360989282e-06,
      "loss": 0.0561,
      "step": 10390
    },
    {
      "epoch": 0.164526497458714,
      "grad_norm": 0.3469886779785156,
      "learning_rate": 8.354735025412861e-06,
      "loss": 0.1688,
      "step": 10391
    },
    {
      "epoch": 0.16454233101635607,
      "grad_norm": 0.30031511187553406,
      "learning_rate": 8.35457668983644e-06,
      "loss": 0.1504,
      "step": 10392
    },
    {
      "epoch": 0.16455816457399813,
      "grad_norm": 0.9852213263511658,
      "learning_rate": 8.354418354260019e-06,
      "loss": 0.2285,
      "step": 10393
    },
    {
      "epoch": 0.1645739981316402,
      "grad_norm": 0.32614845037460327,
      "learning_rate": 8.354260018683598e-06,
      "loss": 0.1194,
      "step": 10394
    },
    {
      "epoch": 0.16458983168928226,
      "grad_norm": 0.43960636854171753,
      "learning_rate": 8.354101683107177e-06,
      "loss": 0.7639,
      "step": 10395
    },
    {
      "epoch": 0.16460566524692433,
      "grad_norm": 0.31511595845222473,
      "learning_rate": 8.353943347530758e-06,
      "loss": 0.0782,
      "step": 10396
    },
    {
      "epoch": 0.1646214988045664,
      "grad_norm": 0.020566370338201523,
      "learning_rate": 8.353785011954335e-06,
      "loss": 0.001,
      "step": 10397
    },
    {
      "epoch": 0.16463733236220846,
      "grad_norm": 0.4679926633834839,
      "learning_rate": 8.353626676377916e-06,
      "loss": 0.1465,
      "step": 10398
    },
    {
      "epoch": 0.16465316591985052,
      "grad_norm": 0.34686461091041565,
      "learning_rate": 8.353468340801495e-06,
      "loss": 0.1765,
      "step": 10399
    },
    {
      "epoch": 0.1646689994774926,
      "grad_norm": 1.0156034231185913,
      "learning_rate": 8.353310005225074e-06,
      "loss": 0.0228,
      "step": 10400
    },
    {
      "epoch": 0.16468483303513468,
      "grad_norm": 0.40818488597869873,
      "learning_rate": 8.353151669648653e-06,
      "loss": 0.2726,
      "step": 10401
    },
    {
      "epoch": 0.16470066659277674,
      "grad_norm": 0.35705122351646423,
      "learning_rate": 8.352993334072234e-06,
      "loss": 0.438,
      "step": 10402
    },
    {
      "epoch": 0.1647165001504188,
      "grad_norm": 0.09251478314399719,
      "learning_rate": 8.352834998495812e-06,
      "loss": 0.0039,
      "step": 10403
    },
    {
      "epoch": 0.16473233370806087,
      "grad_norm": 0.007271359674632549,
      "learning_rate": 8.352676662919392e-06,
      "loss": 0.0004,
      "step": 10404
    },
    {
      "epoch": 0.16474816726570293,
      "grad_norm": 0.31528574228286743,
      "learning_rate": 8.352518327342971e-06,
      "loss": 0.0645,
      "step": 10405
    },
    {
      "epoch": 0.164764000823345,
      "grad_norm": 0.8916600942611694,
      "learning_rate": 8.35235999176655e-06,
      "loss": 0.1169,
      "step": 10406
    },
    {
      "epoch": 0.16477983438098706,
      "grad_norm": 0.000897914229426533,
      "learning_rate": 8.35220165619013e-06,
      "loss": 0.0,
      "step": 10407
    },
    {
      "epoch": 0.16479566793862913,
      "grad_norm": 0.0019899806939065456,
      "learning_rate": 8.35204332061371e-06,
      "loss": 0.0,
      "step": 10408
    },
    {
      "epoch": 0.1648115014962712,
      "grad_norm": 0.6429497003555298,
      "learning_rate": 8.351884985037288e-06,
      "loss": 0.3238,
      "step": 10409
    },
    {
      "epoch": 0.16482733505391325,
      "grad_norm": 0.24569280445575714,
      "learning_rate": 8.351726649460869e-06,
      "loss": 0.1726,
      "step": 10410
    },
    {
      "epoch": 0.16484316861155532,
      "grad_norm": 0.4172857403755188,
      "learning_rate": 8.351568313884448e-06,
      "loss": 0.2004,
      "step": 10411
    },
    {
      "epoch": 0.1648590021691974,
      "grad_norm": 0.06761906296014786,
      "learning_rate": 8.351409978308027e-06,
      "loss": 0.0045,
      "step": 10412
    },
    {
      "epoch": 0.16487483572683947,
      "grad_norm": 0.14670473337173462,
      "learning_rate": 8.351251642731606e-06,
      "loss": 0.0684,
      "step": 10413
    },
    {
      "epoch": 0.16489066928448154,
      "grad_norm": 0.026474762707948685,
      "learning_rate": 8.351093307155187e-06,
      "loss": 0.0016,
      "step": 10414
    },
    {
      "epoch": 0.1649065028421236,
      "grad_norm": 0.36225056648254395,
      "learning_rate": 8.350934971578764e-06,
      "loss": 0.2168,
      "step": 10415
    },
    {
      "epoch": 0.16492233639976567,
      "grad_norm": 0.24995306134223938,
      "learning_rate": 8.350776636002345e-06,
      "loss": 0.0294,
      "step": 10416
    },
    {
      "epoch": 0.16493816995740773,
      "grad_norm": 0.0013401496689766645,
      "learning_rate": 8.350618300425924e-06,
      "loss": 0.0001,
      "step": 10417
    },
    {
      "epoch": 0.1649540035150498,
      "grad_norm": 1.0656462907791138,
      "learning_rate": 8.350459964849503e-06,
      "loss": 0.2079,
      "step": 10418
    },
    {
      "epoch": 0.16496983707269186,
      "grad_norm": 0.4329201281070709,
      "learning_rate": 8.350301629273082e-06,
      "loss": 0.1476,
      "step": 10419
    },
    {
      "epoch": 0.16498567063033392,
      "grad_norm": 0.17810556292533875,
      "learning_rate": 8.350143293696661e-06,
      "loss": 0.0446,
      "step": 10420
    },
    {
      "epoch": 0.165001504187976,
      "grad_norm": 0.7639973759651184,
      "learning_rate": 8.34998495812024e-06,
      "loss": 0.3482,
      "step": 10421
    },
    {
      "epoch": 0.16501733774561805,
      "grad_norm": 0.03428412601351738,
      "learning_rate": 8.34982662254382e-06,
      "loss": 0.0016,
      "step": 10422
    },
    {
      "epoch": 0.16503317130326012,
      "grad_norm": 0.07588726282119751,
      "learning_rate": 8.3496682869674e-06,
      "loss": 0.0036,
      "step": 10423
    },
    {
      "epoch": 0.1650490048609022,
      "grad_norm": 0.012248936109244823,
      "learning_rate": 8.349509951390979e-06,
      "loss": 0.0007,
      "step": 10424
    },
    {
      "epoch": 0.16506483841854427,
      "grad_norm": 0.8508846163749695,
      "learning_rate": 8.349351615814558e-06,
      "loss": 0.1137,
      "step": 10425
    },
    {
      "epoch": 0.16508067197618634,
      "grad_norm": 0.36254367232322693,
      "learning_rate": 8.349193280238137e-06,
      "loss": 0.1798,
      "step": 10426
    },
    {
      "epoch": 0.1650965055338284,
      "grad_norm": 0.21692180633544922,
      "learning_rate": 8.349034944661716e-06,
      "loss": 0.0889,
      "step": 10427
    },
    {
      "epoch": 0.16511233909147047,
      "grad_norm": 0.34967753291130066,
      "learning_rate": 8.348876609085295e-06,
      "loss": 0.4188,
      "step": 10428
    },
    {
      "epoch": 0.16512817264911253,
      "grad_norm": 0.7630149722099304,
      "learning_rate": 8.348718273508876e-06,
      "loss": 0.5346,
      "step": 10429
    },
    {
      "epoch": 0.1651440062067546,
      "grad_norm": 0.2479570209980011,
      "learning_rate": 8.348559937932455e-06,
      "loss": 0.1587,
      "step": 10430
    },
    {
      "epoch": 0.16515983976439666,
      "grad_norm": 0.016980085521936417,
      "learning_rate": 8.348401602356034e-06,
      "loss": 0.001,
      "step": 10431
    },
    {
      "epoch": 0.16517567332203872,
      "grad_norm": 1.2990504503250122,
      "learning_rate": 8.348243266779613e-06,
      "loss": 0.6006,
      "step": 10432
    },
    {
      "epoch": 0.1651915068796808,
      "grad_norm": 0.15791933238506317,
      "learning_rate": 8.348084931203192e-06,
      "loss": 0.0557,
      "step": 10433
    },
    {
      "epoch": 0.16520734043732285,
      "grad_norm": 0.006751755718141794,
      "learning_rate": 8.347926595626772e-06,
      "loss": 0.0003,
      "step": 10434
    },
    {
      "epoch": 0.16522317399496492,
      "grad_norm": 0.3168763220310211,
      "learning_rate": 8.347768260050352e-06,
      "loss": 0.0659,
      "step": 10435
    },
    {
      "epoch": 0.165239007552607,
      "grad_norm": 0.3094692528247833,
      "learning_rate": 8.347609924473931e-06,
      "loss": 0.0264,
      "step": 10436
    },
    {
      "epoch": 0.16525484111024907,
      "grad_norm": 0.49299171566963196,
      "learning_rate": 8.34745158889751e-06,
      "loss": 0.2358,
      "step": 10437
    },
    {
      "epoch": 0.16527067466789114,
      "grad_norm": 0.2824755311012268,
      "learning_rate": 8.34729325332109e-06,
      "loss": 0.0606,
      "step": 10438
    },
    {
      "epoch": 0.1652865082255332,
      "grad_norm": 0.003124818904325366,
      "learning_rate": 8.347134917744669e-06,
      "loss": 0.0001,
      "step": 10439
    },
    {
      "epoch": 0.16530234178317527,
      "grad_norm": 0.34892264008522034,
      "learning_rate": 8.346976582168248e-06,
      "loss": 0.3876,
      "step": 10440
    },
    {
      "epoch": 0.16531817534081733,
      "grad_norm": 0.6643407940864563,
      "learning_rate": 8.346818246591828e-06,
      "loss": 0.4231,
      "step": 10441
    },
    {
      "epoch": 0.1653340088984594,
      "grad_norm": 0.4070601165294647,
      "learning_rate": 8.346659911015408e-06,
      "loss": 0.1611,
      "step": 10442
    },
    {
      "epoch": 0.16534984245610146,
      "grad_norm": 0.06125495582818985,
      "learning_rate": 8.346501575438985e-06,
      "loss": 0.0054,
      "step": 10443
    },
    {
      "epoch": 0.16536567601374352,
      "grad_norm": 0.5204525589942932,
      "learning_rate": 8.346343239862566e-06,
      "loss": 0.0986,
      "step": 10444
    },
    {
      "epoch": 0.1653815095713856,
      "grad_norm": 0.27389639616012573,
      "learning_rate": 8.346184904286145e-06,
      "loss": 0.0996,
      "step": 10445
    },
    {
      "epoch": 0.16539734312902765,
      "grad_norm": 0.28135520219802856,
      "learning_rate": 8.346026568709724e-06,
      "loss": 0.0651,
      "step": 10446
    },
    {
      "epoch": 0.16541317668666972,
      "grad_norm": 0.6290416717529297,
      "learning_rate": 8.345868233133303e-06,
      "loss": 0.1002,
      "step": 10447
    },
    {
      "epoch": 0.1654290102443118,
      "grad_norm": 0.0009306143037974834,
      "learning_rate": 8.345709897556884e-06,
      "loss": 0.0,
      "step": 10448
    },
    {
      "epoch": 0.16544484380195387,
      "grad_norm": 0.2646970748901367,
      "learning_rate": 8.345551561980461e-06,
      "loss": 0.1245,
      "step": 10449
    },
    {
      "epoch": 0.16546067735959594,
      "grad_norm": 0.37657880783081055,
      "learning_rate": 8.345393226404042e-06,
      "loss": 0.44,
      "step": 10450
    },
    {
      "epoch": 0.165476510917238,
      "grad_norm": 0.3559919595718384,
      "learning_rate": 8.345234890827621e-06,
      "loss": 0.1279,
      "step": 10451
    },
    {
      "epoch": 0.16549234447488007,
      "grad_norm": 0.30166950821876526,
      "learning_rate": 8.3450765552512e-06,
      "loss": 0.0693,
      "step": 10452
    },
    {
      "epoch": 0.16550817803252213,
      "grad_norm": 0.20984981954097748,
      "learning_rate": 8.344918219674779e-06,
      "loss": 0.0532,
      "step": 10453
    },
    {
      "epoch": 0.1655240115901642,
      "grad_norm": 0.2527977228164673,
      "learning_rate": 8.344759884098358e-06,
      "loss": 0.1096,
      "step": 10454
    },
    {
      "epoch": 0.16553984514780626,
      "grad_norm": 0.28570589423179626,
      "learning_rate": 8.344601548521937e-06,
      "loss": 0.2039,
      "step": 10455
    },
    {
      "epoch": 0.16555567870544832,
      "grad_norm": 0.006125470623373985,
      "learning_rate": 8.344443212945518e-06,
      "loss": 0.0001,
      "step": 10456
    },
    {
      "epoch": 0.1655715122630904,
      "grad_norm": 0.0009098759037442505,
      "learning_rate": 8.344284877369097e-06,
      "loss": 0.0,
      "step": 10457
    },
    {
      "epoch": 0.16558734582073245,
      "grad_norm": 0.2610708475112915,
      "learning_rate": 8.344126541792676e-06,
      "loss": 0.1293,
      "step": 10458
    },
    {
      "epoch": 0.16560317937837452,
      "grad_norm": 0.41773468255996704,
      "learning_rate": 8.343968206216255e-06,
      "loss": 0.1648,
      "step": 10459
    },
    {
      "epoch": 0.16561901293601658,
      "grad_norm": 0.7286680936813354,
      "learning_rate": 8.343809870639834e-06,
      "loss": 0.9067,
      "step": 10460
    },
    {
      "epoch": 0.16563484649365867,
      "grad_norm": 0.0006703231483697891,
      "learning_rate": 8.343651535063413e-06,
      "loss": 0.0,
      "step": 10461
    },
    {
      "epoch": 0.16565068005130074,
      "grad_norm": 0.04561452940106392,
      "learning_rate": 8.343493199486994e-06,
      "loss": 0.001,
      "step": 10462
    },
    {
      "epoch": 0.1656665136089428,
      "grad_norm": 0.16900378465652466,
      "learning_rate": 8.343334863910573e-06,
      "loss": 0.0293,
      "step": 10463
    },
    {
      "epoch": 0.16568234716658486,
      "grad_norm": 0.43806034326553345,
      "learning_rate": 8.343176528334152e-06,
      "loss": 0.4965,
      "step": 10464
    },
    {
      "epoch": 0.16569818072422693,
      "grad_norm": 0.20028647780418396,
      "learning_rate": 8.343018192757731e-06,
      "loss": 0.0387,
      "step": 10465
    },
    {
      "epoch": 0.165714014281869,
      "grad_norm": 0.5514540076255798,
      "learning_rate": 8.34285985718131e-06,
      "loss": 0.2801,
      "step": 10466
    },
    {
      "epoch": 0.16572984783951106,
      "grad_norm": 0.3722133934497833,
      "learning_rate": 8.34270152160489e-06,
      "loss": 0.0828,
      "step": 10467
    },
    {
      "epoch": 0.16574568139715312,
      "grad_norm": 0.008436760865151882,
      "learning_rate": 8.342543186028469e-06,
      "loss": 0.0005,
      "step": 10468
    },
    {
      "epoch": 0.16576151495479519,
      "grad_norm": 0.3021726608276367,
      "learning_rate": 8.34238485045205e-06,
      "loss": 0.0822,
      "step": 10469
    },
    {
      "epoch": 0.16577734851243725,
      "grad_norm": 0.015987437218427658,
      "learning_rate": 8.342226514875627e-06,
      "loss": 0.0009,
      "step": 10470
    },
    {
      "epoch": 0.16579318207007931,
      "grad_norm": 0.010712298564612865,
      "learning_rate": 8.342068179299208e-06,
      "loss": 0.0004,
      "step": 10471
    },
    {
      "epoch": 0.16580901562772138,
      "grad_norm": 0.03628157824277878,
      "learning_rate": 8.341909843722787e-06,
      "loss": 0.0023,
      "step": 10472
    },
    {
      "epoch": 0.16582484918536347,
      "grad_norm": 0.04359359294176102,
      "learning_rate": 8.341751508146366e-06,
      "loss": 0.0022,
      "step": 10473
    },
    {
      "epoch": 0.16584068274300554,
      "grad_norm": 0.014584017917513847,
      "learning_rate": 8.341593172569945e-06,
      "loss": 0.0008,
      "step": 10474
    },
    {
      "epoch": 0.1658565163006476,
      "grad_norm": 0.000193645159015432,
      "learning_rate": 8.341434836993526e-06,
      "loss": 0.0,
      "step": 10475
    },
    {
      "epoch": 0.16587234985828966,
      "grad_norm": 0.006869732402265072,
      "learning_rate": 8.341276501417103e-06,
      "loss": 0.0004,
      "step": 10476
    },
    {
      "epoch": 0.16588818341593173,
      "grad_norm": 0.20450514554977417,
      "learning_rate": 8.341118165840684e-06,
      "loss": 0.0878,
      "step": 10477
    },
    {
      "epoch": 0.1659040169735738,
      "grad_norm": 0.3852338194847107,
      "learning_rate": 8.340959830264263e-06,
      "loss": 0.0655,
      "step": 10478
    },
    {
      "epoch": 0.16591985053121586,
      "grad_norm": 0.16041840612888336,
      "learning_rate": 8.340801494687842e-06,
      "loss": 0.0565,
      "step": 10479
    },
    {
      "epoch": 0.16593568408885792,
      "grad_norm": 0.5108000636100769,
      "learning_rate": 8.340643159111421e-06,
      "loss": 0.5808,
      "step": 10480
    },
    {
      "epoch": 0.16595151764649999,
      "grad_norm": 0.6792131066322327,
      "learning_rate": 8.340484823535002e-06,
      "loss": 0.3611,
      "step": 10481
    },
    {
      "epoch": 0.16596735120414205,
      "grad_norm": 0.722829282283783,
      "learning_rate": 8.34032648795858e-06,
      "loss": 0.2132,
      "step": 10482
    },
    {
      "epoch": 0.1659831847617841,
      "grad_norm": 0.37550267577171326,
      "learning_rate": 8.34016815238216e-06,
      "loss": 0.0622,
      "step": 10483
    },
    {
      "epoch": 0.16599901831942618,
      "grad_norm": 0.17121140658855438,
      "learning_rate": 8.340009816805739e-06,
      "loss": 0.0674,
      "step": 10484
    },
    {
      "epoch": 0.16601485187706827,
      "grad_norm": 0.0009438468259759247,
      "learning_rate": 8.339851481229318e-06,
      "loss": 0.0,
      "step": 10485
    },
    {
      "epoch": 0.16603068543471033,
      "grad_norm": 0.3514306843280792,
      "learning_rate": 8.339693145652897e-06,
      "loss": 0.5357,
      "step": 10486
    },
    {
      "epoch": 0.1660465189923524,
      "grad_norm": 0.01799064874649048,
      "learning_rate": 8.339534810076478e-06,
      "loss": 0.0009,
      "step": 10487
    },
    {
      "epoch": 0.16606235254999446,
      "grad_norm": 0.0004886173992417753,
      "learning_rate": 8.339376474500055e-06,
      "loss": 0.0,
      "step": 10488
    },
    {
      "epoch": 0.16607818610763653,
      "grad_norm": 0.24826571345329285,
      "learning_rate": 8.339218138923636e-06,
      "loss": 0.0367,
      "step": 10489
    },
    {
      "epoch": 0.1660940196652786,
      "grad_norm": 0.17457331717014313,
      "learning_rate": 8.339059803347215e-06,
      "loss": 0.0833,
      "step": 10490
    },
    {
      "epoch": 0.16610985322292066,
      "grad_norm": 0.011146721430122852,
      "learning_rate": 8.338901467770794e-06,
      "loss": 0.0006,
      "step": 10491
    },
    {
      "epoch": 0.16612568678056272,
      "grad_norm": 0.0010710165370255709,
      "learning_rate": 8.338743132194373e-06,
      "loss": 0.0,
      "step": 10492
    },
    {
      "epoch": 0.16614152033820478,
      "grad_norm": 0.4369294345378876,
      "learning_rate": 8.338584796617952e-06,
      "loss": 0.1415,
      "step": 10493
    },
    {
      "epoch": 0.16615735389584685,
      "grad_norm": 0.5067132115364075,
      "learning_rate": 8.338426461041532e-06,
      "loss": 0.3701,
      "step": 10494
    },
    {
      "epoch": 0.1661731874534889,
      "grad_norm": 0.5287418961524963,
      "learning_rate": 8.33826812546511e-06,
      "loss": 0.1935,
      "step": 10495
    },
    {
      "epoch": 0.16618902101113098,
      "grad_norm": 0.5378615260124207,
      "learning_rate": 8.338109789888691e-06,
      "loss": 0.0636,
      "step": 10496
    },
    {
      "epoch": 0.16620485456877307,
      "grad_norm": 0.011555567383766174,
      "learning_rate": 8.33795145431227e-06,
      "loss": 0.0005,
      "step": 10497
    },
    {
      "epoch": 0.16622068812641513,
      "grad_norm": 0.6532920002937317,
      "learning_rate": 8.33779311873585e-06,
      "loss": 0.378,
      "step": 10498
    },
    {
      "epoch": 0.1662365216840572,
      "grad_norm": 0.763634979724884,
      "learning_rate": 8.337634783159429e-06,
      "loss": 0.6606,
      "step": 10499
    },
    {
      "epoch": 0.16625235524169926,
      "grad_norm": 0.6481503844261169,
      "learning_rate": 8.337476447583008e-06,
      "loss": 0.3676,
      "step": 10500
    },
    {
      "epoch": 0.16626818879934133,
      "grad_norm": 0.43981683254241943,
      "learning_rate": 8.337318112006587e-06,
      "loss": 0.1781,
      "step": 10501
    },
    {
      "epoch": 0.1662840223569834,
      "grad_norm": 0.6109517216682434,
      "learning_rate": 8.337159776430168e-06,
      "loss": 0.0702,
      "step": 10502
    },
    {
      "epoch": 0.16629985591462546,
      "grad_norm": 0.46880993247032166,
      "learning_rate": 8.337001440853747e-06,
      "loss": 0.1429,
      "step": 10503
    },
    {
      "epoch": 0.16631568947226752,
      "grad_norm": 0.013400022871792316,
      "learning_rate": 8.336843105277326e-06,
      "loss": 0.0006,
      "step": 10504
    },
    {
      "epoch": 0.16633152302990958,
      "grad_norm": 0.6607158184051514,
      "learning_rate": 8.336684769700905e-06,
      "loss": 0.123,
      "step": 10505
    },
    {
      "epoch": 0.16634735658755165,
      "grad_norm": 0.4196692407131195,
      "learning_rate": 8.336526434124484e-06,
      "loss": 0.0826,
      "step": 10506
    },
    {
      "epoch": 0.1663631901451937,
      "grad_norm": 0.4294033944606781,
      "learning_rate": 8.336368098548063e-06,
      "loss": 0.1866,
      "step": 10507
    },
    {
      "epoch": 0.16637902370283578,
      "grad_norm": 0.634532630443573,
      "learning_rate": 8.336209762971644e-06,
      "loss": 0.0751,
      "step": 10508
    },
    {
      "epoch": 0.16639485726047787,
      "grad_norm": 0.22444306313991547,
      "learning_rate": 8.336051427395223e-06,
      "loss": 0.1124,
      "step": 10509
    },
    {
      "epoch": 0.16641069081811993,
      "grad_norm": 0.0001779111917130649,
      "learning_rate": 8.335893091818802e-06,
      "loss": 0.0,
      "step": 10510
    },
    {
      "epoch": 0.166426524375762,
      "grad_norm": 0.7214999198913574,
      "learning_rate": 8.335734756242381e-06,
      "loss": 0.1407,
      "step": 10511
    },
    {
      "epoch": 0.16644235793340406,
      "grad_norm": 0.2822253406047821,
      "learning_rate": 8.33557642066596e-06,
      "loss": 0.1263,
      "step": 10512
    },
    {
      "epoch": 0.16645819149104613,
      "grad_norm": 0.009264853782951832,
      "learning_rate": 8.335418085089539e-06,
      "loss": 0.0005,
      "step": 10513
    },
    {
      "epoch": 0.1664740250486882,
      "grad_norm": 0.738303005695343,
      "learning_rate": 8.33525974951312e-06,
      "loss": 0.5731,
      "step": 10514
    },
    {
      "epoch": 0.16648985860633025,
      "grad_norm": 0.030090292915701866,
      "learning_rate": 8.335101413936699e-06,
      "loss": 0.002,
      "step": 10515
    },
    {
      "epoch": 0.16650569216397232,
      "grad_norm": 0.01310438197106123,
      "learning_rate": 8.334943078360276e-06,
      "loss": 0.0009,
      "step": 10516
    },
    {
      "epoch": 0.16652152572161438,
      "grad_norm": 0.001745126792229712,
      "learning_rate": 8.334784742783857e-06,
      "loss": 0.0001,
      "step": 10517
    },
    {
      "epoch": 0.16653735927925645,
      "grad_norm": 0.3729926645755768,
      "learning_rate": 8.334626407207436e-06,
      "loss": 0.2089,
      "step": 10518
    },
    {
      "epoch": 0.1665531928368985,
      "grad_norm": 0.004062876105308533,
      "learning_rate": 8.334468071631015e-06,
      "loss": 0.0002,
      "step": 10519
    },
    {
      "epoch": 0.16656902639454058,
      "grad_norm": 0.3096292316913605,
      "learning_rate": 8.334309736054594e-06,
      "loss": 0.1239,
      "step": 10520
    },
    {
      "epoch": 0.16658485995218267,
      "grad_norm": 0.34556254744529724,
      "learning_rate": 8.334151400478173e-06,
      "loss": 0.0644,
      "step": 10521
    },
    {
      "epoch": 0.16660069350982473,
      "grad_norm": 0.5613310933113098,
      "learning_rate": 8.333993064901753e-06,
      "loss": 0.5727,
      "step": 10522
    },
    {
      "epoch": 0.1666165270674668,
      "grad_norm": 0.011912857182323933,
      "learning_rate": 8.333834729325333e-06,
      "loss": 0.0004,
      "step": 10523
    },
    {
      "epoch": 0.16663236062510886,
      "grad_norm": 0.4412800967693329,
      "learning_rate": 8.333676393748912e-06,
      "loss": 0.2798,
      "step": 10524
    },
    {
      "epoch": 0.16664819418275092,
      "grad_norm": 0.00038453051820397377,
      "learning_rate": 8.333518058172491e-06,
      "loss": 0.0,
      "step": 10525
    },
    {
      "epoch": 0.166664027740393,
      "grad_norm": 0.0002749914419837296,
      "learning_rate": 8.33335972259607e-06,
      "loss": 0.0,
      "step": 10526
    },
    {
      "epoch": 0.16667986129803505,
      "grad_norm": 0.47800230979919434,
      "learning_rate": 8.33320138701965e-06,
      "loss": 0.1434,
      "step": 10527
    },
    {
      "epoch": 0.16669569485567712,
      "grad_norm": 0.37582314014434814,
      "learning_rate": 8.333043051443229e-06,
      "loss": 0.0516,
      "step": 10528
    },
    {
      "epoch": 0.16671152841331918,
      "grad_norm": 0.0037279168609529734,
      "learning_rate": 8.33288471586681e-06,
      "loss": 0.0002,
      "step": 10529
    },
    {
      "epoch": 0.16672736197096125,
      "grad_norm": 0.33058103919029236,
      "learning_rate": 8.332726380290389e-06,
      "loss": 0.112,
      "step": 10530
    },
    {
      "epoch": 0.1667431955286033,
      "grad_norm": 1.038543701171875,
      "learning_rate": 8.332568044713968e-06,
      "loss": 0.1242,
      "step": 10531
    },
    {
      "epoch": 0.16675902908624538,
      "grad_norm": 0.5000441670417786,
      "learning_rate": 8.332409709137547e-06,
      "loss": 0.1829,
      "step": 10532
    },
    {
      "epoch": 0.16677486264388747,
      "grad_norm": 0.01135390717536211,
      "learning_rate": 8.332251373561126e-06,
      "loss": 0.0006,
      "step": 10533
    },
    {
      "epoch": 0.16679069620152953,
      "grad_norm": 0.2952998876571655,
      "learning_rate": 8.332093037984705e-06,
      "loss": 0.5242,
      "step": 10534
    },
    {
      "epoch": 0.1668065297591716,
      "grad_norm": 0.500789999961853,
      "learning_rate": 8.331934702408286e-06,
      "loss": 0.1726,
      "step": 10535
    },
    {
      "epoch": 0.16682236331681366,
      "grad_norm": 0.6491092443466187,
      "learning_rate": 8.331776366831865e-06,
      "loss": 0.0235,
      "step": 10536
    },
    {
      "epoch": 0.16683819687445572,
      "grad_norm": 0.0018042030278593302,
      "learning_rate": 8.331618031255444e-06,
      "loss": 0.0,
      "step": 10537
    },
    {
      "epoch": 0.1668540304320978,
      "grad_norm": 0.695633053779602,
      "learning_rate": 8.331459695679023e-06,
      "loss": 0.647,
      "step": 10538
    },
    {
      "epoch": 0.16686986398973985,
      "grad_norm": 0.2525436282157898,
      "learning_rate": 8.331301360102602e-06,
      "loss": 0.0496,
      "step": 10539
    },
    {
      "epoch": 0.16688569754738192,
      "grad_norm": 0.19048401713371277,
      "learning_rate": 8.331143024526181e-06,
      "loss": 0.0633,
      "step": 10540
    },
    {
      "epoch": 0.16690153110502398,
      "grad_norm": 0.2638106942176819,
      "learning_rate": 8.33098468894976e-06,
      "loss": 0.1266,
      "step": 10541
    },
    {
      "epoch": 0.16691736466266605,
      "grad_norm": 0.49041566252708435,
      "learning_rate": 8.330826353373341e-06,
      "loss": 0.1788,
      "step": 10542
    },
    {
      "epoch": 0.1669331982203081,
      "grad_norm": 1.7364038228988647,
      "learning_rate": 8.330668017796918e-06,
      "loss": 0.7279,
      "step": 10543
    },
    {
      "epoch": 0.16694903177795017,
      "grad_norm": 0.33259880542755127,
      "learning_rate": 8.330509682220499e-06,
      "loss": 0.184,
      "step": 10544
    },
    {
      "epoch": 0.16696486533559227,
      "grad_norm": 0.3646732568740845,
      "learning_rate": 8.330351346644078e-06,
      "loss": 0.1257,
      "step": 10545
    },
    {
      "epoch": 0.16698069889323433,
      "grad_norm": 0.41787707805633545,
      "learning_rate": 8.330193011067657e-06,
      "loss": 0.2374,
      "step": 10546
    },
    {
      "epoch": 0.1669965324508764,
      "grad_norm": 0.39684659242630005,
      "learning_rate": 8.330034675491236e-06,
      "loss": 0.3139,
      "step": 10547
    },
    {
      "epoch": 0.16701236600851846,
      "grad_norm": 0.39397838711738586,
      "learning_rate": 8.329876339914817e-06,
      "loss": 0.4119,
      "step": 10548
    },
    {
      "epoch": 0.16702819956616052,
      "grad_norm": 0.17409572005271912,
      "learning_rate": 8.329718004338394e-06,
      "loss": 0.054,
      "step": 10549
    },
    {
      "epoch": 0.1670440331238026,
      "grad_norm": 0.4255078434944153,
      "learning_rate": 8.329559668761975e-06,
      "loss": 0.1527,
      "step": 10550
    },
    {
      "epoch": 0.16705986668144465,
      "grad_norm": 0.42100101709365845,
      "learning_rate": 8.329401333185554e-06,
      "loss": 0.0889,
      "step": 10551
    },
    {
      "epoch": 0.16707570023908672,
      "grad_norm": 0.27827024459838867,
      "learning_rate": 8.329242997609133e-06,
      "loss": 0.1787,
      "step": 10552
    },
    {
      "epoch": 0.16709153379672878,
      "grad_norm": 0.0023354121949523687,
      "learning_rate": 8.329084662032712e-06,
      "loss": 0.0001,
      "step": 10553
    },
    {
      "epoch": 0.16710736735437084,
      "grad_norm": 0.3951154053211212,
      "learning_rate": 8.328926326456293e-06,
      "loss": 0.3118,
      "step": 10554
    },
    {
      "epoch": 0.1671232009120129,
      "grad_norm": 0.0362280011177063,
      "learning_rate": 8.32876799087987e-06,
      "loss": 0.0024,
      "step": 10555
    },
    {
      "epoch": 0.16713903446965497,
      "grad_norm": 0.26416918635368347,
      "learning_rate": 8.328609655303451e-06,
      "loss": 0.0837,
      "step": 10556
    },
    {
      "epoch": 0.16715486802729707,
      "grad_norm": 0.2926957905292511,
      "learning_rate": 8.32845131972703e-06,
      "loss": 0.1287,
      "step": 10557
    },
    {
      "epoch": 0.16717070158493913,
      "grad_norm": 0.6853647828102112,
      "learning_rate": 8.32829298415061e-06,
      "loss": 0.5103,
      "step": 10558
    },
    {
      "epoch": 0.1671865351425812,
      "grad_norm": 0.007347454316914082,
      "learning_rate": 8.328134648574189e-06,
      "loss": 0.0003,
      "step": 10559
    },
    {
      "epoch": 0.16720236870022326,
      "grad_norm": 0.5753993391990662,
      "learning_rate": 8.32797631299777e-06,
      "loss": 0.5425,
      "step": 10560
    },
    {
      "epoch": 0.16721820225786532,
      "grad_norm": 0.10582087934017181,
      "learning_rate": 8.327817977421347e-06,
      "loss": 0.0024,
      "step": 10561
    },
    {
      "epoch": 0.1672340358155074,
      "grad_norm": 0.49578019976615906,
      "learning_rate": 8.327659641844928e-06,
      "loss": 0.107,
      "step": 10562
    },
    {
      "epoch": 0.16724986937314945,
      "grad_norm": 0.39600861072540283,
      "learning_rate": 8.327501306268507e-06,
      "loss": 0.1151,
      "step": 10563
    },
    {
      "epoch": 0.16726570293079152,
      "grad_norm": 0.019283205270767212,
      "learning_rate": 8.327342970692086e-06,
      "loss": 0.001,
      "step": 10564
    },
    {
      "epoch": 0.16728153648843358,
      "grad_norm": 0.7091578841209412,
      "learning_rate": 8.327184635115665e-06,
      "loss": 0.2389,
      "step": 10565
    },
    {
      "epoch": 0.16729737004607564,
      "grad_norm": 0.37074244022369385,
      "learning_rate": 8.327026299539244e-06,
      "loss": 0.13,
      "step": 10566
    },
    {
      "epoch": 0.1673132036037177,
      "grad_norm": 0.380698025226593,
      "learning_rate": 8.326867963962823e-06,
      "loss": 0.139,
      "step": 10567
    },
    {
      "epoch": 0.16732903716135977,
      "grad_norm": 0.39638155698776245,
      "learning_rate": 8.326709628386402e-06,
      "loss": 0.1726,
      "step": 10568
    },
    {
      "epoch": 0.16734487071900186,
      "grad_norm": 0.0743776261806488,
      "learning_rate": 8.326551292809983e-06,
      "loss": 0.011,
      "step": 10569
    },
    {
      "epoch": 0.16736070427664393,
      "grad_norm": 0.2083086371421814,
      "learning_rate": 8.326392957233562e-06,
      "loss": 0.0766,
      "step": 10570
    },
    {
      "epoch": 0.167376537834286,
      "grad_norm": 0.31770026683807373,
      "learning_rate": 8.326234621657141e-06,
      "loss": 0.069,
      "step": 10571
    },
    {
      "epoch": 0.16739237139192806,
      "grad_norm": 0.7594501376152039,
      "learning_rate": 8.32607628608072e-06,
      "loss": 0.428,
      "step": 10572
    },
    {
      "epoch": 0.16740820494957012,
      "grad_norm": 0.5051410794258118,
      "learning_rate": 8.325917950504299e-06,
      "loss": 0.7145,
      "step": 10573
    },
    {
      "epoch": 0.1674240385072122,
      "grad_norm": 0.5360559821128845,
      "learning_rate": 8.325759614927878e-06,
      "loss": 0.1553,
      "step": 10574
    },
    {
      "epoch": 0.16743987206485425,
      "grad_norm": 0.3784331679344177,
      "learning_rate": 8.325601279351459e-06,
      "loss": 0.1825,
      "step": 10575
    },
    {
      "epoch": 0.16745570562249631,
      "grad_norm": 0.08060694485902786,
      "learning_rate": 8.325442943775038e-06,
      "loss": 0.0075,
      "step": 10576
    },
    {
      "epoch": 0.16747153918013838,
      "grad_norm": 0.28052666783332825,
      "learning_rate": 8.325284608198617e-06,
      "loss": 0.0795,
      "step": 10577
    },
    {
      "epoch": 0.16748737273778044,
      "grad_norm": 0.32348471879959106,
      "learning_rate": 8.325126272622196e-06,
      "loss": 0.228,
      "step": 10578
    },
    {
      "epoch": 0.1675032062954225,
      "grad_norm": 0.4163583815097809,
      "learning_rate": 8.324967937045775e-06,
      "loss": 0.1514,
      "step": 10579
    },
    {
      "epoch": 0.16751903985306457,
      "grad_norm": 0.20515212416648865,
      "learning_rate": 8.324809601469354e-06,
      "loss": 0.0782,
      "step": 10580
    },
    {
      "epoch": 0.16753487341070666,
      "grad_norm": 0.5268636345863342,
      "learning_rate": 8.324651265892935e-06,
      "loss": 0.302,
      "step": 10581
    },
    {
      "epoch": 0.16755070696834873,
      "grad_norm": 0.008339917287230492,
      "learning_rate": 8.324492930316513e-06,
      "loss": 0.0004,
      "step": 10582
    },
    {
      "epoch": 0.1675665405259908,
      "grad_norm": 0.34222403168678284,
      "learning_rate": 8.324334594740093e-06,
      "loss": 0.0758,
      "step": 10583
    },
    {
      "epoch": 0.16758237408363286,
      "grad_norm": 0.015537889674305916,
      "learning_rate": 8.324176259163672e-06,
      "loss": 0.0007,
      "step": 10584
    },
    {
      "epoch": 0.16759820764127492,
      "grad_norm": 0.30915161967277527,
      "learning_rate": 8.324017923587251e-06,
      "loss": 0.0595,
      "step": 10585
    },
    {
      "epoch": 0.16761404119891699,
      "grad_norm": 0.5816541910171509,
      "learning_rate": 8.32385958801083e-06,
      "loss": 0.4862,
      "step": 10586
    },
    {
      "epoch": 0.16762987475655905,
      "grad_norm": 0.4569474160671234,
      "learning_rate": 8.32370125243441e-06,
      "loss": 0.1995,
      "step": 10587
    },
    {
      "epoch": 0.16764570831420111,
      "grad_norm": 0.31852951645851135,
      "learning_rate": 8.323542916857989e-06,
      "loss": 0.1595,
      "step": 10588
    },
    {
      "epoch": 0.16766154187184318,
      "grad_norm": 0.24761931598186493,
      "learning_rate": 8.323384581281568e-06,
      "loss": 0.0421,
      "step": 10589
    },
    {
      "epoch": 0.16767737542948524,
      "grad_norm": 0.11332924664020538,
      "learning_rate": 8.323226245705149e-06,
      "loss": 0.0699,
      "step": 10590
    },
    {
      "epoch": 0.1676932089871273,
      "grad_norm": 0.6631458401679993,
      "learning_rate": 8.323067910128728e-06,
      "loss": 0.6017,
      "step": 10591
    },
    {
      "epoch": 0.16770904254476937,
      "grad_norm": 0.49584677815437317,
      "learning_rate": 8.322909574552307e-06,
      "loss": 0.1384,
      "step": 10592
    },
    {
      "epoch": 0.16772487610241146,
      "grad_norm": 0.02234019711613655,
      "learning_rate": 8.322751238975886e-06,
      "loss": 0.0014,
      "step": 10593
    },
    {
      "epoch": 0.16774070966005353,
      "grad_norm": 0.00036904215812683105,
      "learning_rate": 8.322592903399465e-06,
      "loss": 0.0,
      "step": 10594
    },
    {
      "epoch": 0.1677565432176956,
      "grad_norm": 0.20574717223644257,
      "learning_rate": 8.322434567823044e-06,
      "loss": 0.0697,
      "step": 10595
    },
    {
      "epoch": 0.16777237677533766,
      "grad_norm": 0.16217666864395142,
      "learning_rate": 8.322276232246625e-06,
      "loss": 0.0469,
      "step": 10596
    },
    {
      "epoch": 0.16778821033297972,
      "grad_norm": 0.0006383438594639301,
      "learning_rate": 8.322117896670204e-06,
      "loss": 0.0,
      "step": 10597
    },
    {
      "epoch": 0.16780404389062178,
      "grad_norm": 0.4221574068069458,
      "learning_rate": 8.321959561093783e-06,
      "loss": 0.091,
      "step": 10598
    },
    {
      "epoch": 0.16781987744826385,
      "grad_norm": 0.19657041132450104,
      "learning_rate": 8.321801225517362e-06,
      "loss": 0.0303,
      "step": 10599
    },
    {
      "epoch": 0.1678357110059059,
      "grad_norm": 0.28405746817588806,
      "learning_rate": 8.321642889940941e-06,
      "loss": 0.0572,
      "step": 10600
    },
    {
      "epoch": 0.16785154456354798,
      "grad_norm": 0.1625501960515976,
      "learning_rate": 8.32148455436452e-06,
      "loss": 0.039,
      "step": 10601
    },
    {
      "epoch": 0.16786737812119004,
      "grad_norm": 0.45764702558517456,
      "learning_rate": 8.321326218788101e-06,
      "loss": 0.0976,
      "step": 10602
    },
    {
      "epoch": 0.1678832116788321,
      "grad_norm": 0.03122982755303383,
      "learning_rate": 8.32116788321168e-06,
      "loss": 0.0022,
      "step": 10603
    },
    {
      "epoch": 0.16789904523647417,
      "grad_norm": 0.545251190662384,
      "learning_rate": 8.321009547635259e-06,
      "loss": 0.4497,
      "step": 10604
    },
    {
      "epoch": 0.16791487879411626,
      "grad_norm": 0.1206790879368782,
      "learning_rate": 8.320851212058838e-06,
      "loss": 0.06,
      "step": 10605
    },
    {
      "epoch": 0.16793071235175833,
      "grad_norm": 0.35011377930641174,
      "learning_rate": 8.320692876482417e-06,
      "loss": 0.2681,
      "step": 10606
    },
    {
      "epoch": 0.1679465459094004,
      "grad_norm": 0.06641868501901627,
      "learning_rate": 8.320534540905996e-06,
      "loss": 0.0099,
      "step": 10607
    },
    {
      "epoch": 0.16796237946704246,
      "grad_norm": 0.34628888964653015,
      "learning_rate": 8.320376205329577e-06,
      "loss": 0.116,
      "step": 10608
    },
    {
      "epoch": 0.16797821302468452,
      "grad_norm": 0.63141268491745,
      "learning_rate": 8.320217869753156e-06,
      "loss": 0.2116,
      "step": 10609
    },
    {
      "epoch": 0.16799404658232658,
      "grad_norm": 0.3013665974140167,
      "learning_rate": 8.320059534176735e-06,
      "loss": 0.076,
      "step": 10610
    },
    {
      "epoch": 0.16800988013996865,
      "grad_norm": 0.2280232459306717,
      "learning_rate": 8.319901198600314e-06,
      "loss": 0.0529,
      "step": 10611
    },
    {
      "epoch": 0.1680257136976107,
      "grad_norm": 0.2422071248292923,
      "learning_rate": 8.319742863023893e-06,
      "loss": 0.0621,
      "step": 10612
    },
    {
      "epoch": 0.16804154725525278,
      "grad_norm": 0.7441918849945068,
      "learning_rate": 8.319584527447472e-06,
      "loss": 1.0207,
      "step": 10613
    },
    {
      "epoch": 0.16805738081289484,
      "grad_norm": 0.7889814376831055,
      "learning_rate": 8.319426191871052e-06,
      "loss": 0.0159,
      "step": 10614
    },
    {
      "epoch": 0.1680732143705369,
      "grad_norm": 0.5309867858886719,
      "learning_rate": 8.319267856294632e-06,
      "loss": 0.598,
      "step": 10615
    },
    {
      "epoch": 0.16808904792817897,
      "grad_norm": 0.3053569793701172,
      "learning_rate": 8.31910952071821e-06,
      "loss": 0.1188,
      "step": 10616
    },
    {
      "epoch": 0.16810488148582106,
      "grad_norm": 0.5448797941207886,
      "learning_rate": 8.31895118514179e-06,
      "loss": 0.093,
      "step": 10617
    },
    {
      "epoch": 0.16812071504346313,
      "grad_norm": 0.2228589951992035,
      "learning_rate": 8.31879284956537e-06,
      "loss": 0.0534,
      "step": 10618
    },
    {
      "epoch": 0.1681365486011052,
      "grad_norm": 0.5060606002807617,
      "learning_rate": 8.318634513988949e-06,
      "loss": 0.0711,
      "step": 10619
    },
    {
      "epoch": 0.16815238215874725,
      "grad_norm": 0.10198656469583511,
      "learning_rate": 8.318476178412528e-06,
      "loss": 0.0371,
      "step": 10620
    },
    {
      "epoch": 0.16816821571638932,
      "grad_norm": 0.45673462748527527,
      "learning_rate": 8.318317842836109e-06,
      "loss": 0.1476,
      "step": 10621
    },
    {
      "epoch": 0.16818404927403138,
      "grad_norm": 0.29943522810935974,
      "learning_rate": 8.318159507259686e-06,
      "loss": 0.1199,
      "step": 10622
    },
    {
      "epoch": 0.16819988283167345,
      "grad_norm": 0.10058116912841797,
      "learning_rate": 8.318001171683267e-06,
      "loss": 0.0054,
      "step": 10623
    },
    {
      "epoch": 0.1682157163893155,
      "grad_norm": 0.3365069627761841,
      "learning_rate": 8.317842836106846e-06,
      "loss": 0.0682,
      "step": 10624
    },
    {
      "epoch": 0.16823154994695758,
      "grad_norm": 0.5596085786819458,
      "learning_rate": 8.317684500530425e-06,
      "loss": 0.0987,
      "step": 10625
    },
    {
      "epoch": 0.16824738350459964,
      "grad_norm": 0.0001485195680288598,
      "learning_rate": 8.317526164954004e-06,
      "loss": 0.0,
      "step": 10626
    },
    {
      "epoch": 0.1682632170622417,
      "grad_norm": 0.24511326849460602,
      "learning_rate": 8.317367829377585e-06,
      "loss": 0.0772,
      "step": 10627
    },
    {
      "epoch": 0.16827905061988377,
      "grad_norm": 0.1955079585313797,
      "learning_rate": 8.317209493801162e-06,
      "loss": 0.0673,
      "step": 10628
    },
    {
      "epoch": 0.16829488417752586,
      "grad_norm": 0.4900016188621521,
      "learning_rate": 8.317051158224743e-06,
      "loss": 0.2632,
      "step": 10629
    },
    {
      "epoch": 0.16831071773516793,
      "grad_norm": 0.03396570309996605,
      "learning_rate": 8.316892822648322e-06,
      "loss": 0.0019,
      "step": 10630
    },
    {
      "epoch": 0.16832655129281,
      "grad_norm": 0.001482728635892272,
      "learning_rate": 8.316734487071901e-06,
      "loss": 0.0,
      "step": 10631
    },
    {
      "epoch": 0.16834238485045205,
      "grad_norm": 0.013295360840857029,
      "learning_rate": 8.31657615149548e-06,
      "loss": 0.0006,
      "step": 10632
    },
    {
      "epoch": 0.16835821840809412,
      "grad_norm": 0.3321666717529297,
      "learning_rate": 8.316417815919061e-06,
      "loss": 0.3226,
      "step": 10633
    },
    {
      "epoch": 0.16837405196573618,
      "grad_norm": 0.2327498346567154,
      "learning_rate": 8.316259480342638e-06,
      "loss": 0.0498,
      "step": 10634
    },
    {
      "epoch": 0.16838988552337825,
      "grad_norm": 0.017888912931084633,
      "learning_rate": 8.316101144766217e-06,
      "loss": 0.0009,
      "step": 10635
    },
    {
      "epoch": 0.1684057190810203,
      "grad_norm": 0.1661161333322525,
      "learning_rate": 8.315942809189798e-06,
      "loss": 0.034,
      "step": 10636
    },
    {
      "epoch": 0.16842155263866238,
      "grad_norm": 0.25664710998535156,
      "learning_rate": 8.315784473613377e-06,
      "loss": 0.0808,
      "step": 10637
    },
    {
      "epoch": 0.16843738619630444,
      "grad_norm": 0.2894866466522217,
      "learning_rate": 8.315626138036956e-06,
      "loss": 0.0846,
      "step": 10638
    },
    {
      "epoch": 0.1684532197539465,
      "grad_norm": 0.27100902795791626,
      "learning_rate": 8.315467802460535e-06,
      "loss": 0.1475,
      "step": 10639
    },
    {
      "epoch": 0.16846905331158857,
      "grad_norm": 1.5192681550979614,
      "learning_rate": 8.315309466884114e-06,
      "loss": 0.495,
      "step": 10640
    },
    {
      "epoch": 0.16848488686923066,
      "grad_norm": 0.2350124567747116,
      "learning_rate": 8.315151131307694e-06,
      "loss": 0.0501,
      "step": 10641
    },
    {
      "epoch": 0.16850072042687272,
      "grad_norm": 0.36749929189682007,
      "learning_rate": 8.314992795731274e-06,
      "loss": 0.41,
      "step": 10642
    },
    {
      "epoch": 0.1685165539845148,
      "grad_norm": 0.18302658200263977,
      "learning_rate": 8.314834460154853e-06,
      "loss": 0.0529,
      "step": 10643
    },
    {
      "epoch": 0.16853238754215685,
      "grad_norm": 0.41328027844429016,
      "learning_rate": 8.314676124578432e-06,
      "loss": 0.3714,
      "step": 10644
    },
    {
      "epoch": 0.16854822109979892,
      "grad_norm": 0.08859693259000778,
      "learning_rate": 8.314517789002012e-06,
      "loss": 0.0077,
      "step": 10645
    },
    {
      "epoch": 0.16856405465744098,
      "grad_norm": 1.3226710557937622,
      "learning_rate": 8.31435945342559e-06,
      "loss": 0.6344,
      "step": 10646
    },
    {
      "epoch": 0.16857988821508305,
      "grad_norm": 0.3456677198410034,
      "learning_rate": 8.31420111784917e-06,
      "loss": 0.0502,
      "step": 10647
    },
    {
      "epoch": 0.1685957217727251,
      "grad_norm": 0.18439741432666779,
      "learning_rate": 8.31404278227275e-06,
      "loss": 0.0553,
      "step": 10648
    },
    {
      "epoch": 0.16861155533036717,
      "grad_norm": 0.23667849600315094,
      "learning_rate": 8.313884446696328e-06,
      "loss": 0.0705,
      "step": 10649
    },
    {
      "epoch": 0.16862738888800924,
      "grad_norm": 0.1955217719078064,
      "learning_rate": 8.313726111119909e-06,
      "loss": 0.067,
      "step": 10650
    },
    {
      "epoch": 0.1686432224456513,
      "grad_norm": 0.5739108324050903,
      "learning_rate": 8.313567775543488e-06,
      "loss": 0.6138,
      "step": 10651
    },
    {
      "epoch": 0.16865905600329337,
      "grad_norm": 0.6299844980239868,
      "learning_rate": 8.313409439967067e-06,
      "loss": 0.8074,
      "step": 10652
    },
    {
      "epoch": 0.16867488956093546,
      "grad_norm": 0.6047890782356262,
      "learning_rate": 8.313251104390646e-06,
      "loss": 0.7449,
      "step": 10653
    },
    {
      "epoch": 0.16869072311857752,
      "grad_norm": 0.1981668472290039,
      "learning_rate": 8.313092768814227e-06,
      "loss": 0.0251,
      "step": 10654
    },
    {
      "epoch": 0.1687065566762196,
      "grad_norm": 0.44575899839401245,
      "learning_rate": 8.312934433237804e-06,
      "loss": 0.0699,
      "step": 10655
    },
    {
      "epoch": 0.16872239023386165,
      "grad_norm": 0.2925051748752594,
      "learning_rate": 8.312776097661385e-06,
      "loss": 0.0967,
      "step": 10656
    },
    {
      "epoch": 0.16873822379150372,
      "grad_norm": 0.20571617782115936,
      "learning_rate": 8.312617762084964e-06,
      "loss": 0.089,
      "step": 10657
    },
    {
      "epoch": 0.16875405734914578,
      "grad_norm": 0.15311609208583832,
      "learning_rate": 8.312459426508543e-06,
      "loss": 0.0608,
      "step": 10658
    },
    {
      "epoch": 0.16876989090678784,
      "grad_norm": 0.23882825672626495,
      "learning_rate": 8.312301090932122e-06,
      "loss": 0.1055,
      "step": 10659
    },
    {
      "epoch": 0.1687857244644299,
      "grad_norm": 0.4511818587779999,
      "learning_rate": 8.312142755355701e-06,
      "loss": 0.0622,
      "step": 10660
    },
    {
      "epoch": 0.16880155802207197,
      "grad_norm": 0.007797362748533487,
      "learning_rate": 8.31198441977928e-06,
      "loss": 0.0004,
      "step": 10661
    },
    {
      "epoch": 0.16881739157971404,
      "grad_norm": 0.3081394135951996,
      "learning_rate": 8.31182608420286e-06,
      "loss": 0.1125,
      "step": 10662
    },
    {
      "epoch": 0.1688332251373561,
      "grad_norm": 0.40027520060539246,
      "learning_rate": 8.31166774862644e-06,
      "loss": 0.1084,
      "step": 10663
    },
    {
      "epoch": 0.16884905869499817,
      "grad_norm": 0.2493187040090561,
      "learning_rate": 8.311509413050019e-06,
      "loss": 0.045,
      "step": 10664
    },
    {
      "epoch": 0.16886489225264026,
      "grad_norm": 0.010249599814414978,
      "learning_rate": 8.311351077473598e-06,
      "loss": 0.0005,
      "step": 10665
    },
    {
      "epoch": 0.16888072581028232,
      "grad_norm": 0.22440220415592194,
      "learning_rate": 8.311192741897177e-06,
      "loss": 0.0875,
      "step": 10666
    },
    {
      "epoch": 0.1688965593679244,
      "grad_norm": 0.39640945196151733,
      "learning_rate": 8.311034406320756e-06,
      "loss": 0.153,
      "step": 10667
    },
    {
      "epoch": 0.16891239292556645,
      "grad_norm": 0.6539674997329712,
      "learning_rate": 8.310876070744335e-06,
      "loss": 0.1836,
      "step": 10668
    },
    {
      "epoch": 0.16892822648320852,
      "grad_norm": 0.112925224006176,
      "learning_rate": 8.310717735167916e-06,
      "loss": 0.046,
      "step": 10669
    },
    {
      "epoch": 0.16894406004085058,
      "grad_norm": 0.4985121488571167,
      "learning_rate": 8.310559399591495e-06,
      "loss": 0.2303,
      "step": 10670
    },
    {
      "epoch": 0.16895989359849264,
      "grad_norm": 0.768521785736084,
      "learning_rate": 8.310401064015074e-06,
      "loss": 0.9471,
      "step": 10671
    },
    {
      "epoch": 0.1689757271561347,
      "grad_norm": 0.06849546730518341,
      "learning_rate": 8.310242728438653e-06,
      "loss": 0.0064,
      "step": 10672
    },
    {
      "epoch": 0.16899156071377677,
      "grad_norm": 0.015699556097388268,
      "learning_rate": 8.310084392862233e-06,
      "loss": 0.0012,
      "step": 10673
    },
    {
      "epoch": 0.16900739427141884,
      "grad_norm": 0.2107081562280655,
      "learning_rate": 8.309926057285812e-06,
      "loss": 0.0549,
      "step": 10674
    },
    {
      "epoch": 0.1690232278290609,
      "grad_norm": 0.1908283680677414,
      "learning_rate": 8.309767721709392e-06,
      "loss": 0.0704,
      "step": 10675
    },
    {
      "epoch": 0.16903906138670297,
      "grad_norm": 6.28244670224376e-05,
      "learning_rate": 8.309609386132971e-06,
      "loss": 0.0,
      "step": 10676
    },
    {
      "epoch": 0.16905489494434506,
      "grad_norm": 0.0002483275893609971,
      "learning_rate": 8.30945105055655e-06,
      "loss": 0.0,
      "step": 10677
    },
    {
      "epoch": 0.16907072850198712,
      "grad_norm": 0.4928578734397888,
      "learning_rate": 8.30929271498013e-06,
      "loss": 0.0758,
      "step": 10678
    },
    {
      "epoch": 0.1690865620596292,
      "grad_norm": 0.3657958507537842,
      "learning_rate": 8.309134379403709e-06,
      "loss": 0.0156,
      "step": 10679
    },
    {
      "epoch": 0.16910239561727125,
      "grad_norm": 0.05061039701104164,
      "learning_rate": 8.308976043827288e-06,
      "loss": 0.0012,
      "step": 10680
    },
    {
      "epoch": 0.16911822917491331,
      "grad_norm": 0.6244924664497375,
      "learning_rate": 8.308817708250869e-06,
      "loss": 0.2086,
      "step": 10681
    },
    {
      "epoch": 0.16913406273255538,
      "grad_norm": 0.0006587167736142874,
      "learning_rate": 8.308659372674448e-06,
      "loss": 0.0,
      "step": 10682
    },
    {
      "epoch": 0.16914989629019744,
      "grad_norm": 0.44818830490112305,
      "learning_rate": 8.308501037098025e-06,
      "loss": 0.0089,
      "step": 10683
    },
    {
      "epoch": 0.1691657298478395,
      "grad_norm": 0.5467138886451721,
      "learning_rate": 8.308342701521606e-06,
      "loss": 0.3427,
      "step": 10684
    },
    {
      "epoch": 0.16918156340548157,
      "grad_norm": 0.10867685824632645,
      "learning_rate": 8.308184365945185e-06,
      "loss": 0.0018,
      "step": 10685
    },
    {
      "epoch": 0.16919739696312364,
      "grad_norm": 0.19654199481010437,
      "learning_rate": 8.308026030368764e-06,
      "loss": 0.0854,
      "step": 10686
    },
    {
      "epoch": 0.1692132305207657,
      "grad_norm": 0.5698803067207336,
      "learning_rate": 8.307867694792343e-06,
      "loss": 0.2938,
      "step": 10687
    },
    {
      "epoch": 0.16922906407840776,
      "grad_norm": 0.005250860471278429,
      "learning_rate": 8.307709359215924e-06,
      "loss": 0.0002,
      "step": 10688
    },
    {
      "epoch": 0.16924489763604986,
      "grad_norm": 0.21676337718963623,
      "learning_rate": 8.307551023639501e-06,
      "loss": 0.0791,
      "step": 10689
    },
    {
      "epoch": 0.16926073119369192,
      "grad_norm": 0.008333205245435238,
      "learning_rate": 8.307392688063082e-06,
      "loss": 0.0002,
      "step": 10690
    },
    {
      "epoch": 0.16927656475133399,
      "grad_norm": 0.00014542632561642677,
      "learning_rate": 8.307234352486661e-06,
      "loss": 0.0,
      "step": 10691
    },
    {
      "epoch": 0.16929239830897605,
      "grad_norm": 0.3151859641075134,
      "learning_rate": 8.30707601691024e-06,
      "loss": 0.1685,
      "step": 10692
    },
    {
      "epoch": 0.16930823186661811,
      "grad_norm": 0.7385494709014893,
      "learning_rate": 8.30691768133382e-06,
      "loss": 0.2084,
      "step": 10693
    },
    {
      "epoch": 0.16932406542426018,
      "grad_norm": 0.318832665681839,
      "learning_rate": 8.3067593457574e-06,
      "loss": 0.077,
      "step": 10694
    },
    {
      "epoch": 0.16933989898190224,
      "grad_norm": 0.27506905794143677,
      "learning_rate": 8.306601010180977e-06,
      "loss": 0.1408,
      "step": 10695
    },
    {
      "epoch": 0.1693557325395443,
      "grad_norm": 0.4784518778324127,
      "learning_rate": 8.306442674604558e-06,
      "loss": 0.0719,
      "step": 10696
    },
    {
      "epoch": 0.16937156609718637,
      "grad_norm": 0.18787072598934174,
      "learning_rate": 8.306284339028137e-06,
      "loss": 0.073,
      "step": 10697
    },
    {
      "epoch": 0.16938739965482844,
      "grad_norm": 0.5041976571083069,
      "learning_rate": 8.306126003451716e-06,
      "loss": 0.2771,
      "step": 10698
    },
    {
      "epoch": 0.1694032332124705,
      "grad_norm": 0.4051356613636017,
      "learning_rate": 8.305967667875295e-06,
      "loss": 0.0537,
      "step": 10699
    },
    {
      "epoch": 0.16941906677011256,
      "grad_norm": 0.553525984287262,
      "learning_rate": 8.305809332298876e-06,
      "loss": 0.2772,
      "step": 10700
    },
    {
      "epoch": 0.16943490032775466,
      "grad_norm": 0.36003103852272034,
      "learning_rate": 8.305650996722454e-06,
      "loss": 0.2316,
      "step": 10701
    },
    {
      "epoch": 0.16945073388539672,
      "grad_norm": 0.5591634511947632,
      "learning_rate": 8.305492661146034e-06,
      "loss": 0.4683,
      "step": 10702
    },
    {
      "epoch": 0.16946656744303878,
      "grad_norm": 0.6626269221305847,
      "learning_rate": 8.305334325569613e-06,
      "loss": 0.5966,
      "step": 10703
    },
    {
      "epoch": 0.16948240100068085,
      "grad_norm": 0.26859426498413086,
      "learning_rate": 8.305175989993192e-06,
      "loss": 0.1965,
      "step": 10704
    },
    {
      "epoch": 0.1694982345583229,
      "grad_norm": 0.02799268253147602,
      "learning_rate": 8.305017654416772e-06,
      "loss": 0.0016,
      "step": 10705
    },
    {
      "epoch": 0.16951406811596498,
      "grad_norm": 0.6780909895896912,
      "learning_rate": 8.30485931884035e-06,
      "loss": 0.5716,
      "step": 10706
    },
    {
      "epoch": 0.16952990167360704,
      "grad_norm": 4.13717794418335,
      "learning_rate": 8.30470098326393e-06,
      "loss": 0.2804,
      "step": 10707
    },
    {
      "epoch": 0.1695457352312491,
      "grad_norm": 0.385842889547348,
      "learning_rate": 8.304542647687509e-06,
      "loss": 0.0646,
      "step": 10708
    },
    {
      "epoch": 0.16956156878889117,
      "grad_norm": 0.1425628364086151,
      "learning_rate": 8.30438431211109e-06,
      "loss": 0.0583,
      "step": 10709
    },
    {
      "epoch": 0.16957740234653323,
      "grad_norm": 0.5839348435401917,
      "learning_rate": 8.304225976534667e-06,
      "loss": 0.1137,
      "step": 10710
    },
    {
      "epoch": 0.1695932359041753,
      "grad_norm": 0.038293298333883286,
      "learning_rate": 8.304067640958248e-06,
      "loss": 0.0024,
      "step": 10711
    },
    {
      "epoch": 0.16960906946181736,
      "grad_norm": 0.0696982890367508,
      "learning_rate": 8.303909305381827e-06,
      "loss": 0.0027,
      "step": 10712
    },
    {
      "epoch": 0.16962490301945946,
      "grad_norm": 0.8866006135940552,
      "learning_rate": 8.303750969805406e-06,
      "loss": 0.1317,
      "step": 10713
    },
    {
      "epoch": 0.16964073657710152,
      "grad_norm": 0.39801082015037537,
      "learning_rate": 8.303592634228985e-06,
      "loss": 0.0365,
      "step": 10714
    },
    {
      "epoch": 0.16965657013474358,
      "grad_norm": 0.37104490399360657,
      "learning_rate": 8.303434298652566e-06,
      "loss": 0.0628,
      "step": 10715
    },
    {
      "epoch": 0.16967240369238565,
      "grad_norm": 0.5361679196357727,
      "learning_rate": 8.303275963076143e-06,
      "loss": 0.3759,
      "step": 10716
    },
    {
      "epoch": 0.1696882372500277,
      "grad_norm": 0.01125984825193882,
      "learning_rate": 8.303117627499724e-06,
      "loss": 0.0006,
      "step": 10717
    },
    {
      "epoch": 0.16970407080766978,
      "grad_norm": 0.38948434591293335,
      "learning_rate": 8.302959291923303e-06,
      "loss": 0.0677,
      "step": 10718
    },
    {
      "epoch": 0.16971990436531184,
      "grad_norm": 0.3238294720649719,
      "learning_rate": 8.302800956346882e-06,
      "loss": 0.1465,
      "step": 10719
    },
    {
      "epoch": 0.1697357379229539,
      "grad_norm": 0.0002868328883778304,
      "learning_rate": 8.302642620770461e-06,
      "loss": 0.0,
      "step": 10720
    },
    {
      "epoch": 0.16975157148059597,
      "grad_norm": 0.20073197782039642,
      "learning_rate": 8.302484285194042e-06,
      "loss": 0.0608,
      "step": 10721
    },
    {
      "epoch": 0.16976740503823803,
      "grad_norm": 0.3907774090766907,
      "learning_rate": 8.30232594961762e-06,
      "loss": 0.0375,
      "step": 10722
    },
    {
      "epoch": 0.1697832385958801,
      "grad_norm": 0.00021562384790740907,
      "learning_rate": 8.3021676140412e-06,
      "loss": 0.0,
      "step": 10723
    },
    {
      "epoch": 0.16979907215352216,
      "grad_norm": 0.5844886898994446,
      "learning_rate": 8.302009278464779e-06,
      "loss": 0.2569,
      "step": 10724
    },
    {
      "epoch": 0.16981490571116425,
      "grad_norm": 0.5542237758636475,
      "learning_rate": 8.301850942888358e-06,
      "loss": 0.1501,
      "step": 10725
    },
    {
      "epoch": 0.16983073926880632,
      "grad_norm": 0.24668298661708832,
      "learning_rate": 8.301692607311937e-06,
      "loss": 0.0639,
      "step": 10726
    },
    {
      "epoch": 0.16984657282644838,
      "grad_norm": 0.025852855294942856,
      "learning_rate": 8.301534271735518e-06,
      "loss": 0.0011,
      "step": 10727
    },
    {
      "epoch": 0.16986240638409045,
      "grad_norm": 0.011705761775374413,
      "learning_rate": 8.301375936159095e-06,
      "loss": 0.0006,
      "step": 10728
    },
    {
      "epoch": 0.1698782399417325,
      "grad_norm": 0.02333785966038704,
      "learning_rate": 8.301217600582676e-06,
      "loss": 0.0016,
      "step": 10729
    },
    {
      "epoch": 0.16989407349937458,
      "grad_norm": 0.42996060848236084,
      "learning_rate": 8.301059265006255e-06,
      "loss": 0.1175,
      "step": 10730
    },
    {
      "epoch": 0.16990990705701664,
      "grad_norm": 0.6768944263458252,
      "learning_rate": 8.300900929429834e-06,
      "loss": 0.2524,
      "step": 10731
    },
    {
      "epoch": 0.1699257406146587,
      "grad_norm": 0.24982799589633942,
      "learning_rate": 8.300742593853413e-06,
      "loss": 0.0948,
      "step": 10732
    },
    {
      "epoch": 0.16994157417230077,
      "grad_norm": 0.3071821928024292,
      "learning_rate": 8.300584258276993e-06,
      "loss": 0.077,
      "step": 10733
    },
    {
      "epoch": 0.16995740772994283,
      "grad_norm": 0.00023335646255873144,
      "learning_rate": 8.300425922700572e-06,
      "loss": 0.0,
      "step": 10734
    },
    {
      "epoch": 0.1699732412875849,
      "grad_norm": 0.0022794408723711967,
      "learning_rate": 8.30026758712415e-06,
      "loss": 0.0001,
      "step": 10735
    },
    {
      "epoch": 0.16998907484522696,
      "grad_norm": 0.20257095992565155,
      "learning_rate": 8.300109251547731e-06,
      "loss": 0.0734,
      "step": 10736
    },
    {
      "epoch": 0.17000490840286905,
      "grad_norm": 0.1470230221748352,
      "learning_rate": 8.29995091597131e-06,
      "loss": 0.0139,
      "step": 10737
    },
    {
      "epoch": 0.17002074196051112,
      "grad_norm": 0.346829354763031,
      "learning_rate": 8.29979258039489e-06,
      "loss": 0.108,
      "step": 10738
    },
    {
      "epoch": 0.17003657551815318,
      "grad_norm": 0.30681878328323364,
      "learning_rate": 8.299634244818469e-06,
      "loss": 0.3506,
      "step": 10739
    },
    {
      "epoch": 0.17005240907579525,
      "grad_norm": 0.0002214580017607659,
      "learning_rate": 8.299475909242048e-06,
      "loss": 0.0,
      "step": 10740
    },
    {
      "epoch": 0.1700682426334373,
      "grad_norm": 0.49680665135383606,
      "learning_rate": 8.299317573665627e-06,
      "loss": 0.3405,
      "step": 10741
    },
    {
      "epoch": 0.17008407619107938,
      "grad_norm": 0.3511437773704529,
      "learning_rate": 8.299159238089208e-06,
      "loss": 0.2003,
      "step": 10742
    },
    {
      "epoch": 0.17009990974872144,
      "grad_norm": 0.006433446891605854,
      "learning_rate": 8.299000902512787e-06,
      "loss": 0.0003,
      "step": 10743
    },
    {
      "epoch": 0.1701157433063635,
      "grad_norm": 0.02309875562787056,
      "learning_rate": 8.298842566936366e-06,
      "loss": 0.0013,
      "step": 10744
    },
    {
      "epoch": 0.17013157686400557,
      "grad_norm": 0.5972853899002075,
      "learning_rate": 8.298684231359945e-06,
      "loss": 0.0593,
      "step": 10745
    },
    {
      "epoch": 0.17014741042164763,
      "grad_norm": 0.2955623269081116,
      "learning_rate": 8.298525895783524e-06,
      "loss": 0.0566,
      "step": 10746
    },
    {
      "epoch": 0.1701632439792897,
      "grad_norm": 0.15948887169361115,
      "learning_rate": 8.298367560207103e-06,
      "loss": 0.0383,
      "step": 10747
    },
    {
      "epoch": 0.17017907753693176,
      "grad_norm": 0.3921843469142914,
      "learning_rate": 8.298209224630684e-06,
      "loss": 0.0139,
      "step": 10748
    },
    {
      "epoch": 0.17019491109457385,
      "grad_norm": 0.033947091549634933,
      "learning_rate": 8.298050889054263e-06,
      "loss": 0.0028,
      "step": 10749
    },
    {
      "epoch": 0.17021074465221592,
      "grad_norm": 0.5394880175590515,
      "learning_rate": 8.297892553477842e-06,
      "loss": 0.2605,
      "step": 10750
    },
    {
      "epoch": 0.17022657820985798,
      "grad_norm": 0.20497442781925201,
      "learning_rate": 8.297734217901421e-06,
      "loss": 0.0121,
      "step": 10751
    },
    {
      "epoch": 0.17024241176750005,
      "grad_norm": 0.3213317096233368,
      "learning_rate": 8.297575882325e-06,
      "loss": 0.084,
      "step": 10752
    },
    {
      "epoch": 0.1702582453251421,
      "grad_norm": 0.134378120303154,
      "learning_rate": 8.29741754674858e-06,
      "loss": 0.0363,
      "step": 10753
    },
    {
      "epoch": 0.17027407888278417,
      "grad_norm": 0.2291220873594284,
      "learning_rate": 8.29725921117216e-06,
      "loss": 0.0318,
      "step": 10754
    },
    {
      "epoch": 0.17028991244042624,
      "grad_norm": 0.24486689269542694,
      "learning_rate": 8.297100875595739e-06,
      "loss": 0.1127,
      "step": 10755
    },
    {
      "epoch": 0.1703057459980683,
      "grad_norm": 0.2996480464935303,
      "learning_rate": 8.296942540019316e-06,
      "loss": 0.0344,
      "step": 10756
    },
    {
      "epoch": 0.17032157955571037,
      "grad_norm": 0.01005315687507391,
      "learning_rate": 8.296784204442897e-06,
      "loss": 0.0005,
      "step": 10757
    },
    {
      "epoch": 0.17033741311335243,
      "grad_norm": 0.2677510678768158,
      "learning_rate": 8.296625868866476e-06,
      "loss": 0.0548,
      "step": 10758
    },
    {
      "epoch": 0.1703532466709945,
      "grad_norm": 0.35867080092430115,
      "learning_rate": 8.296467533290055e-06,
      "loss": 0.0962,
      "step": 10759
    },
    {
      "epoch": 0.17036908022863656,
      "grad_norm": 0.015689190477132797,
      "learning_rate": 8.296309197713634e-06,
      "loss": 0.0007,
      "step": 10760
    },
    {
      "epoch": 0.17038491378627865,
      "grad_norm": 0.008576000109314919,
      "learning_rate": 8.296150862137215e-06,
      "loss": 0.0004,
      "step": 10761
    },
    {
      "epoch": 0.17040074734392072,
      "grad_norm": 0.5879505276679993,
      "learning_rate": 8.295992526560793e-06,
      "loss": 0.8246,
      "step": 10762
    },
    {
      "epoch": 0.17041658090156278,
      "grad_norm": 0.026531556621193886,
      "learning_rate": 8.295834190984373e-06,
      "loss": 0.0007,
      "step": 10763
    },
    {
      "epoch": 0.17043241445920485,
      "grad_norm": 0.35465964674949646,
      "learning_rate": 8.295675855407952e-06,
      "loss": 0.123,
      "step": 10764
    },
    {
      "epoch": 0.1704482480168469,
      "grad_norm": 0.4822675287723541,
      "learning_rate": 8.295517519831532e-06,
      "loss": 0.3359,
      "step": 10765
    },
    {
      "epoch": 0.17046408157448897,
      "grad_norm": 0.6153180599212646,
      "learning_rate": 8.29535918425511e-06,
      "loss": 0.0154,
      "step": 10766
    },
    {
      "epoch": 0.17047991513213104,
      "grad_norm": 0.2336614727973938,
      "learning_rate": 8.295200848678691e-06,
      "loss": 0.0767,
      "step": 10767
    },
    {
      "epoch": 0.1704957486897731,
      "grad_norm": 0.300149142742157,
      "learning_rate": 8.295042513102269e-06,
      "loss": 0.0603,
      "step": 10768
    },
    {
      "epoch": 0.17051158224741517,
      "grad_norm": 0.19341665506362915,
      "learning_rate": 8.29488417752585e-06,
      "loss": 0.0599,
      "step": 10769
    },
    {
      "epoch": 0.17052741580505723,
      "grad_norm": 0.3628707826137543,
      "learning_rate": 8.294725841949429e-06,
      "loss": 0.1881,
      "step": 10770
    },
    {
      "epoch": 0.1705432493626993,
      "grad_norm": 0.00016050202248152345,
      "learning_rate": 8.294567506373008e-06,
      "loss": 0.0,
      "step": 10771
    },
    {
      "epoch": 0.17055908292034136,
      "grad_norm": 0.024951091036200523,
      "learning_rate": 8.294409170796587e-06,
      "loss": 0.0013,
      "step": 10772
    },
    {
      "epoch": 0.17057491647798345,
      "grad_norm": 0.34751376509666443,
      "learning_rate": 8.294250835220166e-06,
      "loss": 0.0607,
      "step": 10773
    },
    {
      "epoch": 0.17059075003562552,
      "grad_norm": 0.5481522083282471,
      "learning_rate": 8.294092499643745e-06,
      "loss": 0.1518,
      "step": 10774
    },
    {
      "epoch": 0.17060658359326758,
      "grad_norm": 0.7179147601127625,
      "learning_rate": 8.293934164067326e-06,
      "loss": 0.1869,
      "step": 10775
    },
    {
      "epoch": 0.17062241715090964,
      "grad_norm": 0.3404945433139801,
      "learning_rate": 8.293775828490905e-06,
      "loss": 0.0718,
      "step": 10776
    },
    {
      "epoch": 0.1706382507085517,
      "grad_norm": 0.0004643763822969049,
      "learning_rate": 8.293617492914484e-06,
      "loss": 0.0,
      "step": 10777
    },
    {
      "epoch": 0.17065408426619377,
      "grad_norm": 0.3800849914550781,
      "learning_rate": 8.293459157338063e-06,
      "loss": 0.0927,
      "step": 10778
    },
    {
      "epoch": 0.17066991782383584,
      "grad_norm": 0.0016526755644008517,
      "learning_rate": 8.293300821761642e-06,
      "loss": 0.0,
      "step": 10779
    },
    {
      "epoch": 0.1706857513814779,
      "grad_norm": 0.3026316463947296,
      "learning_rate": 8.293142486185221e-06,
      "loss": 0.0567,
      "step": 10780
    },
    {
      "epoch": 0.17070158493911997,
      "grad_norm": 0.03643115237355232,
      "learning_rate": 8.2929841506088e-06,
      "loss": 0.0019,
      "step": 10781
    },
    {
      "epoch": 0.17071741849676203,
      "grad_norm": 0.4300979673862457,
      "learning_rate": 8.292825815032381e-06,
      "loss": 0.0737,
      "step": 10782
    },
    {
      "epoch": 0.1707332520544041,
      "grad_norm": 0.39140233397483826,
      "learning_rate": 8.292667479455958e-06,
      "loss": 0.196,
      "step": 10783
    },
    {
      "epoch": 0.17074908561204616,
      "grad_norm": 0.4387391209602356,
      "learning_rate": 8.292509143879539e-06,
      "loss": 0.2246,
      "step": 10784
    },
    {
      "epoch": 0.17076491916968825,
      "grad_norm": 0.0320417694747448,
      "learning_rate": 8.292350808303118e-06,
      "loss": 0.0019,
      "step": 10785
    },
    {
      "epoch": 0.17078075272733031,
      "grad_norm": 0.00033769779838621616,
      "learning_rate": 8.292192472726697e-06,
      "loss": 0.0,
      "step": 10786
    },
    {
      "epoch": 0.17079658628497238,
      "grad_norm": 0.6467718482017517,
      "learning_rate": 8.292034137150276e-06,
      "loss": 0.1525,
      "step": 10787
    },
    {
      "epoch": 0.17081241984261444,
      "grad_norm": 0.3770582973957062,
      "learning_rate": 8.291875801573857e-06,
      "loss": 0.1522,
      "step": 10788
    },
    {
      "epoch": 0.1708282534002565,
      "grad_norm": 0.25477901101112366,
      "learning_rate": 8.291717465997435e-06,
      "loss": 0.1432,
      "step": 10789
    },
    {
      "epoch": 0.17084408695789857,
      "grad_norm": 0.06847551465034485,
      "learning_rate": 8.291559130421015e-06,
      "loss": 0.0033,
      "step": 10790
    },
    {
      "epoch": 0.17085992051554064,
      "grad_norm": 0.8216091394424438,
      "learning_rate": 8.291400794844594e-06,
      "loss": 0.4707,
      "step": 10791
    },
    {
      "epoch": 0.1708757540731827,
      "grad_norm": 0.30094051361083984,
      "learning_rate": 8.291242459268173e-06,
      "loss": 0.0927,
      "step": 10792
    },
    {
      "epoch": 0.17089158763082476,
      "grad_norm": 0.2862206995487213,
      "learning_rate": 8.291084123691753e-06,
      "loss": 0.0364,
      "step": 10793
    },
    {
      "epoch": 0.17090742118846683,
      "grad_norm": 0.3697025179862976,
      "learning_rate": 8.290925788115333e-06,
      "loss": 0.0133,
      "step": 10794
    },
    {
      "epoch": 0.1709232547461089,
      "grad_norm": 0.47084301710128784,
      "learning_rate": 8.29076745253891e-06,
      "loss": 0.1741,
      "step": 10795
    },
    {
      "epoch": 0.17093908830375096,
      "grad_norm": 0.28763705492019653,
      "learning_rate": 8.290609116962491e-06,
      "loss": 0.079,
      "step": 10796
    },
    {
      "epoch": 0.17095492186139305,
      "grad_norm": 0.5072208046913147,
      "learning_rate": 8.29045078138607e-06,
      "loss": 0.0686,
      "step": 10797
    },
    {
      "epoch": 0.17097075541903511,
      "grad_norm": 0.5877740979194641,
      "learning_rate": 8.29029244580965e-06,
      "loss": 0.2911,
      "step": 10798
    },
    {
      "epoch": 0.17098658897667718,
      "grad_norm": 0.6509687900543213,
      "learning_rate": 8.290134110233229e-06,
      "loss": 0.1785,
      "step": 10799
    },
    {
      "epoch": 0.17100242253431924,
      "grad_norm": 0.4166848659515381,
      "learning_rate": 8.28997577465681e-06,
      "loss": 0.2612,
      "step": 10800
    },
    {
      "epoch": 0.1710182560919613,
      "grad_norm": 0.032666921615600586,
      "learning_rate": 8.289817439080387e-06,
      "loss": 0.0005,
      "step": 10801
    },
    {
      "epoch": 0.17103408964960337,
      "grad_norm": 1.2649893760681152,
      "learning_rate": 8.289659103503968e-06,
      "loss": 0.1181,
      "step": 10802
    },
    {
      "epoch": 0.17104992320724544,
      "grad_norm": 0.2526089549064636,
      "learning_rate": 8.289500767927547e-06,
      "loss": 0.1022,
      "step": 10803
    },
    {
      "epoch": 0.1710657567648875,
      "grad_norm": 0.09630201756954193,
      "learning_rate": 8.289342432351126e-06,
      "loss": 0.0141,
      "step": 10804
    },
    {
      "epoch": 0.17108159032252956,
      "grad_norm": 0.018415013328194618,
      "learning_rate": 8.289184096774705e-06,
      "loss": 0.0009,
      "step": 10805
    },
    {
      "epoch": 0.17109742388017163,
      "grad_norm": 0.43385523557662964,
      "learning_rate": 8.289025761198284e-06,
      "loss": 0.0716,
      "step": 10806
    },
    {
      "epoch": 0.1711132574378137,
      "grad_norm": 0.6264767050743103,
      "learning_rate": 8.288867425621863e-06,
      "loss": 0.0774,
      "step": 10807
    },
    {
      "epoch": 0.17112909099545576,
      "grad_norm": 0.506093442440033,
      "learning_rate": 8.288709090045442e-06,
      "loss": 0.3242,
      "step": 10808
    },
    {
      "epoch": 0.17114492455309785,
      "grad_norm": 0.19933858513832092,
      "learning_rate": 8.288550754469023e-06,
      "loss": 0.027,
      "step": 10809
    },
    {
      "epoch": 0.1711607581107399,
      "grad_norm": 1.024448275566101,
      "learning_rate": 8.288392418892602e-06,
      "loss": 0.0869,
      "step": 10810
    },
    {
      "epoch": 0.17117659166838198,
      "grad_norm": 0.32967832684516907,
      "learning_rate": 8.288234083316181e-06,
      "loss": 0.0668,
      "step": 10811
    },
    {
      "epoch": 0.17119242522602404,
      "grad_norm": 0.09146878868341446,
      "learning_rate": 8.28807574773976e-06,
      "loss": 0.0061,
      "step": 10812
    },
    {
      "epoch": 0.1712082587836661,
      "grad_norm": 0.3523889482021332,
      "learning_rate": 8.28791741216334e-06,
      "loss": 0.1339,
      "step": 10813
    },
    {
      "epoch": 0.17122409234130817,
      "grad_norm": 1.0245100259780884,
      "learning_rate": 8.287759076586918e-06,
      "loss": 0.0925,
      "step": 10814
    },
    {
      "epoch": 0.17123992589895023,
      "grad_norm": 0.0004317277926020324,
      "learning_rate": 8.287600741010499e-06,
      "loss": 0.0,
      "step": 10815
    },
    {
      "epoch": 0.1712557594565923,
      "grad_norm": 0.3795213997364044,
      "learning_rate": 8.287442405434078e-06,
      "loss": 0.1036,
      "step": 10816
    },
    {
      "epoch": 0.17127159301423436,
      "grad_norm": 0.8375402688980103,
      "learning_rate": 8.287284069857657e-06,
      "loss": 0.1993,
      "step": 10817
    },
    {
      "epoch": 0.17128742657187643,
      "grad_norm": 0.3700481653213501,
      "learning_rate": 8.287125734281236e-06,
      "loss": 0.4336,
      "step": 10818
    },
    {
      "epoch": 0.1713032601295185,
      "grad_norm": 0.02420048601925373,
      "learning_rate": 8.286967398704815e-06,
      "loss": 0.0011,
      "step": 10819
    },
    {
      "epoch": 0.17131909368716056,
      "grad_norm": 0.0231254231184721,
      "learning_rate": 8.286809063128394e-06,
      "loss": 0.001,
      "step": 10820
    },
    {
      "epoch": 0.17133492724480265,
      "grad_norm": 0.662354588508606,
      "learning_rate": 8.286650727551975e-06,
      "loss": 0.261,
      "step": 10821
    },
    {
      "epoch": 0.1713507608024447,
      "grad_norm": 0.16426537930965424,
      "learning_rate": 8.286492391975554e-06,
      "loss": 0.0537,
      "step": 10822
    },
    {
      "epoch": 0.17136659436008678,
      "grad_norm": 0.3337080478668213,
      "learning_rate": 8.286334056399133e-06,
      "loss": 0.0988,
      "step": 10823
    },
    {
      "epoch": 0.17138242791772884,
      "grad_norm": 0.032390858978033066,
      "learning_rate": 8.286175720822712e-06,
      "loss": 0.0019,
      "step": 10824
    },
    {
      "epoch": 0.1713982614753709,
      "grad_norm": 0.41432756185531616,
      "learning_rate": 8.286017385246292e-06,
      "loss": 0.1518,
      "step": 10825
    },
    {
      "epoch": 0.17141409503301297,
      "grad_norm": 0.2773447334766388,
      "learning_rate": 8.28585904966987e-06,
      "loss": 0.0762,
      "step": 10826
    },
    {
      "epoch": 0.17142992859065503,
      "grad_norm": 0.02059909887611866,
      "learning_rate": 8.28570071409345e-06,
      "loss": 0.0009,
      "step": 10827
    },
    {
      "epoch": 0.1714457621482971,
      "grad_norm": 0.35924825072288513,
      "learning_rate": 8.28554237851703e-06,
      "loss": 0.1857,
      "step": 10828
    },
    {
      "epoch": 0.17146159570593916,
      "grad_norm": 0.621367871761322,
      "learning_rate": 8.285384042940608e-06,
      "loss": 0.1507,
      "step": 10829
    },
    {
      "epoch": 0.17147742926358123,
      "grad_norm": 0.04368814080953598,
      "learning_rate": 8.285225707364189e-06,
      "loss": 0.0025,
      "step": 10830
    },
    {
      "epoch": 0.1714932628212233,
      "grad_norm": 0.11989249289035797,
      "learning_rate": 8.285067371787768e-06,
      "loss": 0.0626,
      "step": 10831
    },
    {
      "epoch": 0.17150909637886536,
      "grad_norm": 0.45126813650131226,
      "learning_rate": 8.284909036211347e-06,
      "loss": 0.3006,
      "step": 10832
    },
    {
      "epoch": 0.17152492993650745,
      "grad_norm": 0.020694725215435028,
      "learning_rate": 8.284750700634926e-06,
      "loss": 0.0012,
      "step": 10833
    },
    {
      "epoch": 0.1715407634941495,
      "grad_norm": 0.4210521876811981,
      "learning_rate": 8.284592365058507e-06,
      "loss": 0.0776,
      "step": 10834
    },
    {
      "epoch": 0.17155659705179158,
      "grad_norm": 0.45758217573165894,
      "learning_rate": 8.284434029482084e-06,
      "loss": 0.1548,
      "step": 10835
    },
    {
      "epoch": 0.17157243060943364,
      "grad_norm": 1.2610729932785034,
      "learning_rate": 8.284275693905665e-06,
      "loss": 0.7607,
      "step": 10836
    },
    {
      "epoch": 0.1715882641670757,
      "grad_norm": 0.06514448672533035,
      "learning_rate": 8.284117358329244e-06,
      "loss": 0.0052,
      "step": 10837
    },
    {
      "epoch": 0.17160409772471777,
      "grad_norm": 0.22120292484760284,
      "learning_rate": 8.283959022752823e-06,
      "loss": 0.0589,
      "step": 10838
    },
    {
      "epoch": 0.17161993128235983,
      "grad_norm": 0.20370575785636902,
      "learning_rate": 8.283800687176402e-06,
      "loss": 0.0522,
      "step": 10839
    },
    {
      "epoch": 0.1716357648400019,
      "grad_norm": 0.037009112536907196,
      "learning_rate": 8.283642351599981e-06,
      "loss": 0.0011,
      "step": 10840
    },
    {
      "epoch": 0.17165159839764396,
      "grad_norm": 0.3876572251319885,
      "learning_rate": 8.28348401602356e-06,
      "loss": 0.1621,
      "step": 10841
    },
    {
      "epoch": 0.17166743195528603,
      "grad_norm": 0.47058916091918945,
      "learning_rate": 8.283325680447141e-06,
      "loss": 0.3576,
      "step": 10842
    },
    {
      "epoch": 0.1716832655129281,
      "grad_norm": 0.39689216017723083,
      "learning_rate": 8.28316734487072e-06,
      "loss": 0.0254,
      "step": 10843
    },
    {
      "epoch": 0.17169909907057015,
      "grad_norm": 0.16757358610630035,
      "learning_rate": 8.2830090092943e-06,
      "loss": 0.0699,
      "step": 10844
    },
    {
      "epoch": 0.17171493262821225,
      "grad_norm": 0.005175072234123945,
      "learning_rate": 8.282850673717878e-06,
      "loss": 0.0003,
      "step": 10845
    },
    {
      "epoch": 0.1717307661858543,
      "grad_norm": 0.17454399168491364,
      "learning_rate": 8.282692338141457e-06,
      "loss": 0.0587,
      "step": 10846
    },
    {
      "epoch": 0.17174659974349638,
      "grad_norm": 0.32409292459487915,
      "learning_rate": 8.282534002565036e-06,
      "loss": 0.3459,
      "step": 10847
    },
    {
      "epoch": 0.17176243330113844,
      "grad_norm": 0.0007679541013203561,
      "learning_rate": 8.282375666988617e-06,
      "loss": 0.0,
      "step": 10848
    },
    {
      "epoch": 0.1717782668587805,
      "grad_norm": 0.22506414353847504,
      "learning_rate": 8.282217331412196e-06,
      "loss": 0.0914,
      "step": 10849
    },
    {
      "epoch": 0.17179410041642257,
      "grad_norm": 0.7781355977058411,
      "learning_rate": 8.282058995835775e-06,
      "loss": 0.0378,
      "step": 10850
    },
    {
      "epoch": 0.17180993397406463,
      "grad_norm": 0.0029202422592788935,
      "learning_rate": 8.281900660259354e-06,
      "loss": 0.0001,
      "step": 10851
    },
    {
      "epoch": 0.1718257675317067,
      "grad_norm": 0.14371447265148163,
      "learning_rate": 8.281742324682933e-06,
      "loss": 0.0447,
      "step": 10852
    },
    {
      "epoch": 0.17184160108934876,
      "grad_norm": 0.005648091901093721,
      "learning_rate": 8.281583989106513e-06,
      "loss": 0.0003,
      "step": 10853
    },
    {
      "epoch": 0.17185743464699083,
      "grad_norm": 0.5198797583580017,
      "learning_rate": 8.281425653530092e-06,
      "loss": 0.3503,
      "step": 10854
    },
    {
      "epoch": 0.1718732682046329,
      "grad_norm": 0.2689177691936493,
      "learning_rate": 8.281267317953672e-06,
      "loss": 0.0646,
      "step": 10855
    },
    {
      "epoch": 0.17188910176227495,
      "grad_norm": 0.3946983516216278,
      "learning_rate": 8.28110898237725e-06,
      "loss": 0.2469,
      "step": 10856
    },
    {
      "epoch": 0.17190493531991705,
      "grad_norm": 0.3520987033843994,
      "learning_rate": 8.28095064680083e-06,
      "loss": 0.1259,
      "step": 10857
    },
    {
      "epoch": 0.1719207688775591,
      "grad_norm": 0.2874504029750824,
      "learning_rate": 8.28079231122441e-06,
      "loss": 0.167,
      "step": 10858
    },
    {
      "epoch": 0.17193660243520117,
      "grad_norm": 0.4471307098865509,
      "learning_rate": 8.280633975647989e-06,
      "loss": 0.2649,
      "step": 10859
    },
    {
      "epoch": 0.17195243599284324,
      "grad_norm": 0.4151725172996521,
      "learning_rate": 8.280475640071568e-06,
      "loss": 0.3226,
      "step": 10860
    },
    {
      "epoch": 0.1719682695504853,
      "grad_norm": 0.38977372646331787,
      "learning_rate": 8.280317304495149e-06,
      "loss": 0.1494,
      "step": 10861
    },
    {
      "epoch": 0.17198410310812737,
      "grad_norm": 0.4969983994960785,
      "learning_rate": 8.280158968918726e-06,
      "loss": 0.2032,
      "step": 10862
    },
    {
      "epoch": 0.17199993666576943,
      "grad_norm": 0.45162326097488403,
      "learning_rate": 8.280000633342307e-06,
      "loss": 0.2298,
      "step": 10863
    },
    {
      "epoch": 0.1720157702234115,
      "grad_norm": 0.44088900089263916,
      "learning_rate": 8.279842297765886e-06,
      "loss": 0.2055,
      "step": 10864
    },
    {
      "epoch": 0.17203160378105356,
      "grad_norm": 0.4326387345790863,
      "learning_rate": 8.279683962189465e-06,
      "loss": 0.1651,
      "step": 10865
    },
    {
      "epoch": 0.17204743733869562,
      "grad_norm": 0.3312196731567383,
      "learning_rate": 8.279525626613044e-06,
      "loss": 0.1117,
      "step": 10866
    },
    {
      "epoch": 0.1720632708963377,
      "grad_norm": 0.011982510797679424,
      "learning_rate": 8.279367291036625e-06,
      "loss": 0.0005,
      "step": 10867
    },
    {
      "epoch": 0.17207910445397975,
      "grad_norm": 0.2850666046142578,
      "learning_rate": 8.279208955460202e-06,
      "loss": 0.0907,
      "step": 10868
    },
    {
      "epoch": 0.17209493801162182,
      "grad_norm": 0.001273337984457612,
      "learning_rate": 8.279050619883783e-06,
      "loss": 0.0,
      "step": 10869
    },
    {
      "epoch": 0.1721107715692639,
      "grad_norm": 0.26016494631767273,
      "learning_rate": 8.278892284307362e-06,
      "loss": 0.0489,
      "step": 10870
    },
    {
      "epoch": 0.17212660512690597,
      "grad_norm": 0.2248763144016266,
      "learning_rate": 8.278733948730941e-06,
      "loss": 0.0204,
      "step": 10871
    },
    {
      "epoch": 0.17214243868454804,
      "grad_norm": 0.2258637547492981,
      "learning_rate": 8.27857561315452e-06,
      "loss": 0.061,
      "step": 10872
    },
    {
      "epoch": 0.1721582722421901,
      "grad_norm": 0.0034529617987573147,
      "learning_rate": 8.278417277578101e-06,
      "loss": 0.0001,
      "step": 10873
    },
    {
      "epoch": 0.17217410579983217,
      "grad_norm": 0.3032798767089844,
      "learning_rate": 8.278258942001678e-06,
      "loss": 0.2202,
      "step": 10874
    },
    {
      "epoch": 0.17218993935747423,
      "grad_norm": 0.034987032413482666,
      "learning_rate": 8.278100606425259e-06,
      "loss": 0.0019,
      "step": 10875
    },
    {
      "epoch": 0.1722057729151163,
      "grad_norm": 0.3390675485134125,
      "learning_rate": 8.277942270848838e-06,
      "loss": 0.296,
      "step": 10876
    },
    {
      "epoch": 0.17222160647275836,
      "grad_norm": 0.4234239161014557,
      "learning_rate": 8.277783935272417e-06,
      "loss": 0.2916,
      "step": 10877
    },
    {
      "epoch": 0.17223744003040042,
      "grad_norm": 0.4314393103122711,
      "learning_rate": 8.277625599695996e-06,
      "loss": 0.2294,
      "step": 10878
    },
    {
      "epoch": 0.1722532735880425,
      "grad_norm": 0.029230866581201553,
      "learning_rate": 8.277467264119575e-06,
      "loss": 0.0014,
      "step": 10879
    },
    {
      "epoch": 0.17226910714568455,
      "grad_norm": 0.015506214462220669,
      "learning_rate": 8.277308928543155e-06,
      "loss": 0.0007,
      "step": 10880
    },
    {
      "epoch": 0.17228494070332662,
      "grad_norm": 0.3041464686393738,
      "learning_rate": 8.277150592966734e-06,
      "loss": 0.1186,
      "step": 10881
    },
    {
      "epoch": 0.1723007742609687,
      "grad_norm": 0.5742649435997009,
      "learning_rate": 8.276992257390314e-06,
      "loss": 0.0952,
      "step": 10882
    },
    {
      "epoch": 0.17231660781861077,
      "grad_norm": 0.555752158164978,
      "learning_rate": 8.276833921813893e-06,
      "loss": 0.173,
      "step": 10883
    },
    {
      "epoch": 0.17233244137625284,
      "grad_norm": 0.6152624487876892,
      "learning_rate": 8.276675586237473e-06,
      "loss": 0.8154,
      "step": 10884
    },
    {
      "epoch": 0.1723482749338949,
      "grad_norm": 0.02994624152779579,
      "learning_rate": 8.276517250661052e-06,
      "loss": 0.0017,
      "step": 10885
    },
    {
      "epoch": 0.17236410849153697,
      "grad_norm": 0.3939599394798279,
      "learning_rate": 8.27635891508463e-06,
      "loss": 0.0584,
      "step": 10886
    },
    {
      "epoch": 0.17237994204917903,
      "grad_norm": 0.00021992648544255644,
      "learning_rate": 8.27620057950821e-06,
      "loss": 0.0,
      "step": 10887
    },
    {
      "epoch": 0.1723957756068211,
      "grad_norm": 0.5170848965644836,
      "learning_rate": 8.27604224393179e-06,
      "loss": 0.317,
      "step": 10888
    },
    {
      "epoch": 0.17241160916446316,
      "grad_norm": 0.24260231852531433,
      "learning_rate": 8.27588390835537e-06,
      "loss": 0.0927,
      "step": 10889
    },
    {
      "epoch": 0.17242744272210522,
      "grad_norm": 0.9904034733772278,
      "learning_rate": 8.275725572778949e-06,
      "loss": 0.0787,
      "step": 10890
    },
    {
      "epoch": 0.1724432762797473,
      "grad_norm": 0.2801734209060669,
      "learning_rate": 8.275567237202528e-06,
      "loss": 0.1021,
      "step": 10891
    },
    {
      "epoch": 0.17245910983738935,
      "grad_norm": 0.0003243166138418019,
      "learning_rate": 8.275408901626107e-06,
      "loss": 0.0,
      "step": 10892
    },
    {
      "epoch": 0.17247494339503142,
      "grad_norm": 0.0032722523901611567,
      "learning_rate": 8.275250566049686e-06,
      "loss": 0.0001,
      "step": 10893
    },
    {
      "epoch": 0.1724907769526735,
      "grad_norm": 0.536602795124054,
      "learning_rate": 8.275092230473267e-06,
      "loss": 0.186,
      "step": 10894
    },
    {
      "epoch": 0.17250661051031557,
      "grad_norm": 0.05749163404107094,
      "learning_rate": 8.274933894896846e-06,
      "loss": 0.0024,
      "step": 10895
    },
    {
      "epoch": 0.17252244406795764,
      "grad_norm": 0.23006905615329742,
      "learning_rate": 8.274775559320425e-06,
      "loss": 0.053,
      "step": 10896
    },
    {
      "epoch": 0.1725382776255997,
      "grad_norm": 0.19106824696063995,
      "learning_rate": 8.274617223744004e-06,
      "loss": 0.0205,
      "step": 10897
    },
    {
      "epoch": 0.17255411118324177,
      "grad_norm": 0.3789748549461365,
      "learning_rate": 8.274458888167583e-06,
      "loss": 0.1239,
      "step": 10898
    },
    {
      "epoch": 0.17256994474088383,
      "grad_norm": 0.1911611109972,
      "learning_rate": 8.274300552591162e-06,
      "loss": 0.0809,
      "step": 10899
    },
    {
      "epoch": 0.1725857782985259,
      "grad_norm": 0.11264850944280624,
      "learning_rate": 8.274142217014741e-06,
      "loss": 0.0081,
      "step": 10900
    },
    {
      "epoch": 0.17260161185616796,
      "grad_norm": 0.5468355417251587,
      "learning_rate": 8.27398388143832e-06,
      "loss": 0.3191,
      "step": 10901
    },
    {
      "epoch": 0.17261744541381002,
      "grad_norm": 0.7866134643554688,
      "learning_rate": 8.2738255458619e-06,
      "loss": 0.7712,
      "step": 10902
    },
    {
      "epoch": 0.1726332789714521,
      "grad_norm": 0.521828293800354,
      "learning_rate": 8.27366721028548e-06,
      "loss": 0.2245,
      "step": 10903
    },
    {
      "epoch": 0.17264911252909415,
      "grad_norm": 0.5263925790786743,
      "learning_rate": 8.27350887470906e-06,
      "loss": 0.3973,
      "step": 10904
    },
    {
      "epoch": 0.17266494608673622,
      "grad_norm": 0.21158425509929657,
      "learning_rate": 8.273350539132638e-06,
      "loss": 0.0796,
      "step": 10905
    },
    {
      "epoch": 0.1726807796443783,
      "grad_norm": 0.3433043658733368,
      "learning_rate": 8.273192203556217e-06,
      "loss": 0.0714,
      "step": 10906
    },
    {
      "epoch": 0.17269661320202037,
      "grad_norm": 0.23821212351322174,
      "learning_rate": 8.273033867979796e-06,
      "loss": 0.1191,
      "step": 10907
    },
    {
      "epoch": 0.17271244675966244,
      "grad_norm": 0.2542651295661926,
      "learning_rate": 8.272875532403376e-06,
      "loss": 0.1707,
      "step": 10908
    },
    {
      "epoch": 0.1727282803173045,
      "grad_norm": 0.4005142152309418,
      "learning_rate": 8.272717196826956e-06,
      "loss": 0.483,
      "step": 10909
    },
    {
      "epoch": 0.17274411387494656,
      "grad_norm": 0.3416881859302521,
      "learning_rate": 8.272558861250535e-06,
      "loss": 0.1471,
      "step": 10910
    },
    {
      "epoch": 0.17275994743258863,
      "grad_norm": 0.04777306690812111,
      "learning_rate": 8.272400525674114e-06,
      "loss": 0.0022,
      "step": 10911
    },
    {
      "epoch": 0.1727757809902307,
      "grad_norm": 0.09189734607934952,
      "learning_rate": 8.272242190097694e-06,
      "loss": 0.0061,
      "step": 10912
    },
    {
      "epoch": 0.17279161454787276,
      "grad_norm": 0.38107654452323914,
      "learning_rate": 8.272083854521273e-06,
      "loss": 0.064,
      "step": 10913
    },
    {
      "epoch": 0.17280744810551482,
      "grad_norm": 0.04603372514247894,
      "learning_rate": 8.271925518944852e-06,
      "loss": 0.0021,
      "step": 10914
    },
    {
      "epoch": 0.17282328166315689,
      "grad_norm": 0.5741007924079895,
      "learning_rate": 8.271767183368432e-06,
      "loss": 0.3162,
      "step": 10915
    },
    {
      "epoch": 0.17283911522079895,
      "grad_norm": 0.36768484115600586,
      "learning_rate": 8.271608847792012e-06,
      "loss": 0.213,
      "step": 10916
    },
    {
      "epoch": 0.17285494877844101,
      "grad_norm": 0.1779247522354126,
      "learning_rate": 8.27145051221559e-06,
      "loss": 0.0705,
      "step": 10917
    },
    {
      "epoch": 0.1728707823360831,
      "grad_norm": 0.20028267800807953,
      "learning_rate": 8.27129217663917e-06,
      "loss": 0.0455,
      "step": 10918
    },
    {
      "epoch": 0.17288661589372517,
      "grad_norm": 0.2721724808216095,
      "learning_rate": 8.271133841062749e-06,
      "loss": 0.0399,
      "step": 10919
    },
    {
      "epoch": 0.17290244945136723,
      "grad_norm": 0.01675344444811344,
      "learning_rate": 8.270975505486328e-06,
      "loss": 0.0007,
      "step": 10920
    },
    {
      "epoch": 0.1729182830090093,
      "grad_norm": 0.3425370752811432,
      "learning_rate": 8.270817169909909e-06,
      "loss": 0.1574,
      "step": 10921
    },
    {
      "epoch": 0.17293411656665136,
      "grad_norm": 0.6806669235229492,
      "learning_rate": 8.270658834333488e-06,
      "loss": 0.6675,
      "step": 10922
    },
    {
      "epoch": 0.17294995012429343,
      "grad_norm": 0.5942386388778687,
      "learning_rate": 8.270500498757067e-06,
      "loss": 0.6319,
      "step": 10923
    },
    {
      "epoch": 0.1729657836819355,
      "grad_norm": 0.1130051389336586,
      "learning_rate": 8.270342163180646e-06,
      "loss": 0.0144,
      "step": 10924
    },
    {
      "epoch": 0.17298161723957756,
      "grad_norm": 0.2775003910064697,
      "learning_rate": 8.270183827604225e-06,
      "loss": 0.1445,
      "step": 10925
    },
    {
      "epoch": 0.17299745079721962,
      "grad_norm": 0.009669842198491096,
      "learning_rate": 8.270025492027804e-06,
      "loss": 0.0004,
      "step": 10926
    },
    {
      "epoch": 0.17301328435486168,
      "grad_norm": 0.5446286201477051,
      "learning_rate": 8.269867156451383e-06,
      "loss": 0.2764,
      "step": 10927
    },
    {
      "epoch": 0.17302911791250375,
      "grad_norm": 0.6607191562652588,
      "learning_rate": 8.269708820874964e-06,
      "loss": 0.1124,
      "step": 10928
    },
    {
      "epoch": 0.1730449514701458,
      "grad_norm": 0.44739773869514465,
      "learning_rate": 8.269550485298541e-06,
      "loss": 0.1476,
      "step": 10929
    },
    {
      "epoch": 0.1730607850277879,
      "grad_norm": 0.7877390384674072,
      "learning_rate": 8.269392149722122e-06,
      "loss": 0.1076,
      "step": 10930
    },
    {
      "epoch": 0.17307661858542997,
      "grad_norm": 0.3463679254055023,
      "learning_rate": 8.269233814145701e-06,
      "loss": 0.1675,
      "step": 10931
    },
    {
      "epoch": 0.17309245214307203,
      "grad_norm": 0.17713281512260437,
      "learning_rate": 8.26907547856928e-06,
      "loss": 0.0246,
      "step": 10932
    },
    {
      "epoch": 0.1731082857007141,
      "grad_norm": 0.12222129106521606,
      "learning_rate": 8.26891714299286e-06,
      "loss": 0.0042,
      "step": 10933
    },
    {
      "epoch": 0.17312411925835616,
      "grad_norm": 1.1234592199325562,
      "learning_rate": 8.26875880741644e-06,
      "loss": 0.7238,
      "step": 10934
    },
    {
      "epoch": 0.17313995281599823,
      "grad_norm": 0.27425867319107056,
      "learning_rate": 8.268600471840017e-06,
      "loss": 0.0996,
      "step": 10935
    },
    {
      "epoch": 0.1731557863736403,
      "grad_norm": 0.36803188920021057,
      "learning_rate": 8.268442136263598e-06,
      "loss": 0.1512,
      "step": 10936
    },
    {
      "epoch": 0.17317161993128236,
      "grad_norm": 0.10082564502954483,
      "learning_rate": 8.268283800687177e-06,
      "loss": 0.0068,
      "step": 10937
    },
    {
      "epoch": 0.17318745348892442,
      "grad_norm": 0.9799138307571411,
      "learning_rate": 8.268125465110756e-06,
      "loss": 0.0854,
      "step": 10938
    },
    {
      "epoch": 0.17320328704656648,
      "grad_norm": 0.5063450932502747,
      "learning_rate": 8.267967129534335e-06,
      "loss": 0.162,
      "step": 10939
    },
    {
      "epoch": 0.17321912060420855,
      "grad_norm": 0.8741100430488586,
      "learning_rate": 8.267808793957916e-06,
      "loss": 0.176,
      "step": 10940
    },
    {
      "epoch": 0.1732349541618506,
      "grad_norm": 0.27087604999542236,
      "learning_rate": 8.267650458381494e-06,
      "loss": 0.1294,
      "step": 10941
    },
    {
      "epoch": 0.1732507877194927,
      "grad_norm": 0.21265017986297607,
      "learning_rate": 8.267492122805074e-06,
      "loss": 0.0585,
      "step": 10942
    },
    {
      "epoch": 0.17326662127713477,
      "grad_norm": 0.591223418712616,
      "learning_rate": 8.267333787228653e-06,
      "loss": 0.191,
      "step": 10943
    },
    {
      "epoch": 0.17328245483477683,
      "grad_norm": 0.40194305777549744,
      "learning_rate": 8.267175451652233e-06,
      "loss": 0.3797,
      "step": 10944
    },
    {
      "epoch": 0.1732982883924189,
      "grad_norm": 0.0008691946277394891,
      "learning_rate": 8.267017116075812e-06,
      "loss": 0.0,
      "step": 10945
    },
    {
      "epoch": 0.17331412195006096,
      "grad_norm": 0.01365281455218792,
      "learning_rate": 8.266858780499392e-06,
      "loss": 0.0005,
      "step": 10946
    },
    {
      "epoch": 0.17332995550770303,
      "grad_norm": 0.030142998322844505,
      "learning_rate": 8.26670044492297e-06,
      "loss": 0.0013,
      "step": 10947
    },
    {
      "epoch": 0.1733457890653451,
      "grad_norm": 0.44940298795700073,
      "learning_rate": 8.266542109346549e-06,
      "loss": 0.1131,
      "step": 10948
    },
    {
      "epoch": 0.17336162262298715,
      "grad_norm": 0.5743178725242615,
      "learning_rate": 8.26638377377013e-06,
      "loss": 0.0652,
      "step": 10949
    },
    {
      "epoch": 0.17337745618062922,
      "grad_norm": 0.03612368553876877,
      "learning_rate": 8.266225438193709e-06,
      "loss": 0.0025,
      "step": 10950
    },
    {
      "epoch": 0.17339328973827128,
      "grad_norm": 0.472182959318161,
      "learning_rate": 8.266067102617288e-06,
      "loss": 0.1651,
      "step": 10951
    },
    {
      "epoch": 0.17340912329591335,
      "grad_norm": 0.00021156146249268204,
      "learning_rate": 8.265908767040867e-06,
      "loss": 0.0,
      "step": 10952
    },
    {
      "epoch": 0.1734249568535554,
      "grad_norm": 0.022431666031479836,
      "learning_rate": 8.265750431464446e-06,
      "loss": 0.001,
      "step": 10953
    },
    {
      "epoch": 0.1734407904111975,
      "grad_norm": 0.2039562165737152,
      "learning_rate": 8.265592095888025e-06,
      "loss": 0.0419,
      "step": 10954
    },
    {
      "epoch": 0.17345662396883957,
      "grad_norm": 0.17842711508274078,
      "learning_rate": 8.265433760311606e-06,
      "loss": 0.0639,
      "step": 10955
    },
    {
      "epoch": 0.17347245752648163,
      "grad_norm": 0.33805206418037415,
      "learning_rate": 8.265275424735185e-06,
      "loss": 0.0862,
      "step": 10956
    },
    {
      "epoch": 0.1734882910841237,
      "grad_norm": 0.5594174265861511,
      "learning_rate": 8.265117089158764e-06,
      "loss": 0.3654,
      "step": 10957
    },
    {
      "epoch": 0.17350412464176576,
      "grad_norm": 0.19486844539642334,
      "learning_rate": 8.264958753582343e-06,
      "loss": 0.1325,
      "step": 10958
    },
    {
      "epoch": 0.17351995819940783,
      "grad_norm": 0.2609558403491974,
      "learning_rate": 8.264800418005922e-06,
      "loss": 0.0624,
      "step": 10959
    },
    {
      "epoch": 0.1735357917570499,
      "grad_norm": 0.40743082761764526,
      "learning_rate": 8.264642082429501e-06,
      "loss": 0.2186,
      "step": 10960
    },
    {
      "epoch": 0.17355162531469195,
      "grad_norm": 0.5533987879753113,
      "learning_rate": 8.264483746853082e-06,
      "loss": 0.0347,
      "step": 10961
    },
    {
      "epoch": 0.17356745887233402,
      "grad_norm": 0.5052951574325562,
      "learning_rate": 8.264325411276661e-06,
      "loss": 0.4007,
      "step": 10962
    },
    {
      "epoch": 0.17358329242997608,
      "grad_norm": 0.02482505328953266,
      "learning_rate": 8.26416707570024e-06,
      "loss": 0.0012,
      "step": 10963
    },
    {
      "epoch": 0.17359912598761815,
      "grad_norm": 0.42287760972976685,
      "learning_rate": 8.26400874012382e-06,
      "loss": 0.1069,
      "step": 10964
    },
    {
      "epoch": 0.1736149595452602,
      "grad_norm": 0.012645311653614044,
      "learning_rate": 8.263850404547398e-06,
      "loss": 0.0008,
      "step": 10965
    },
    {
      "epoch": 0.1736307931029023,
      "grad_norm": 0.3035983145236969,
      "learning_rate": 8.263692068970977e-06,
      "loss": 0.0745,
      "step": 10966
    },
    {
      "epoch": 0.17364662666054437,
      "grad_norm": 0.27388638257980347,
      "learning_rate": 8.263533733394558e-06,
      "loss": 0.1013,
      "step": 10967
    },
    {
      "epoch": 0.17366246021818643,
      "grad_norm": 0.005594564136117697,
      "learning_rate": 8.263375397818136e-06,
      "loss": 0.0003,
      "step": 10968
    },
    {
      "epoch": 0.1736782937758285,
      "grad_norm": 0.12066690623760223,
      "learning_rate": 8.263217062241716e-06,
      "loss": 0.0072,
      "step": 10969
    },
    {
      "epoch": 0.17369412733347056,
      "grad_norm": 0.000324332679156214,
      "learning_rate": 8.263058726665295e-06,
      "loss": 0.0,
      "step": 10970
    },
    {
      "epoch": 0.17370996089111262,
      "grad_norm": 0.19541506469249725,
      "learning_rate": 8.262900391088874e-06,
      "loss": 0.1307,
      "step": 10971
    },
    {
      "epoch": 0.1737257944487547,
      "grad_norm": 0.039655666798353195,
      "learning_rate": 8.262742055512454e-06,
      "loss": 0.0066,
      "step": 10972
    },
    {
      "epoch": 0.17374162800639675,
      "grad_norm": 0.34538164734840393,
      "learning_rate": 8.262583719936033e-06,
      "loss": 0.018,
      "step": 10973
    },
    {
      "epoch": 0.17375746156403882,
      "grad_norm": 0.2660159468650818,
      "learning_rate": 8.262425384359612e-06,
      "loss": 0.0802,
      "step": 10974
    },
    {
      "epoch": 0.17377329512168088,
      "grad_norm": 0.005214048083871603,
      "learning_rate": 8.26226704878319e-06,
      "loss": 0.0002,
      "step": 10975
    },
    {
      "epoch": 0.17378912867932295,
      "grad_norm": 0.16441893577575684,
      "learning_rate": 8.262108713206772e-06,
      "loss": 0.0512,
      "step": 10976
    },
    {
      "epoch": 0.173804962236965,
      "grad_norm": 0.05672544613480568,
      "learning_rate": 8.26195037763035e-06,
      "loss": 0.0027,
      "step": 10977
    },
    {
      "epoch": 0.1738207957946071,
      "grad_norm": 0.551768958568573,
      "learning_rate": 8.26179204205393e-06,
      "loss": 0.2182,
      "step": 10978
    },
    {
      "epoch": 0.17383662935224917,
      "grad_norm": 0.2690998315811157,
      "learning_rate": 8.261633706477509e-06,
      "loss": 0.0571,
      "step": 10979
    },
    {
      "epoch": 0.17385246290989123,
      "grad_norm": 0.23519478738307953,
      "learning_rate": 8.261475370901088e-06,
      "loss": 0.0757,
      "step": 10980
    },
    {
      "epoch": 0.1738682964675333,
      "grad_norm": 0.3980938494205475,
      "learning_rate": 8.261317035324667e-06,
      "loss": 0.1584,
      "step": 10981
    },
    {
      "epoch": 0.17388413002517536,
      "grad_norm": 0.17022015154361725,
      "learning_rate": 8.261158699748248e-06,
      "loss": 0.0217,
      "step": 10982
    },
    {
      "epoch": 0.17389996358281742,
      "grad_norm": 0.00014252838445827365,
      "learning_rate": 8.261000364171827e-06,
      "loss": 0.0,
      "step": 10983
    },
    {
      "epoch": 0.1739157971404595,
      "grad_norm": 0.0939098447561264,
      "learning_rate": 8.260842028595406e-06,
      "loss": 0.0045,
      "step": 10984
    },
    {
      "epoch": 0.17393163069810155,
      "grad_norm": 0.38676005601882935,
      "learning_rate": 8.260683693018985e-06,
      "loss": 0.0634,
      "step": 10985
    },
    {
      "epoch": 0.17394746425574362,
      "grad_norm": 0.18137244880199432,
      "learning_rate": 8.260525357442564e-06,
      "loss": 0.0158,
      "step": 10986
    },
    {
      "epoch": 0.17396329781338568,
      "grad_norm": 0.39635130763053894,
      "learning_rate": 8.260367021866143e-06,
      "loss": 0.2928,
      "step": 10987
    },
    {
      "epoch": 0.17397913137102775,
      "grad_norm": 0.019002186134457588,
      "learning_rate": 8.260208686289724e-06,
      "loss": 0.0013,
      "step": 10988
    },
    {
      "epoch": 0.1739949649286698,
      "grad_norm": 0.00012910123041365296,
      "learning_rate": 8.260050350713303e-06,
      "loss": 0.0,
      "step": 10989
    },
    {
      "epoch": 0.1740107984863119,
      "grad_norm": 0.7002973556518555,
      "learning_rate": 8.259892015136882e-06,
      "loss": 0.076,
      "step": 10990
    },
    {
      "epoch": 0.17402663204395397,
      "grad_norm": 0.8699883818626404,
      "learning_rate": 8.259733679560461e-06,
      "loss": 0.571,
      "step": 10991
    },
    {
      "epoch": 0.17404246560159603,
      "grad_norm": 0.43757519125938416,
      "learning_rate": 8.25957534398404e-06,
      "loss": 0.0473,
      "step": 10992
    },
    {
      "epoch": 0.1740582991592381,
      "grad_norm": 0.4391978085041046,
      "learning_rate": 8.25941700840762e-06,
      "loss": 0.1741,
      "step": 10993
    },
    {
      "epoch": 0.17407413271688016,
      "grad_norm": 0.2567327320575714,
      "learning_rate": 8.2592586728312e-06,
      "loss": 0.0755,
      "step": 10994
    },
    {
      "epoch": 0.17408996627452222,
      "grad_norm": 0.0007526981644332409,
      "learning_rate": 8.259100337254779e-06,
      "loss": 0.0,
      "step": 10995
    },
    {
      "epoch": 0.1741057998321643,
      "grad_norm": 0.3526918888092041,
      "learning_rate": 8.258942001678357e-06,
      "loss": 0.0997,
      "step": 10996
    },
    {
      "epoch": 0.17412163338980635,
      "grad_norm": 0.6998530626296997,
      "learning_rate": 8.258783666101937e-06,
      "loss": 1.238,
      "step": 10997
    },
    {
      "epoch": 0.17413746694744842,
      "grad_norm": 0.1540180742740631,
      "learning_rate": 8.258625330525516e-06,
      "loss": 0.0324,
      "step": 10998
    },
    {
      "epoch": 0.17415330050509048,
      "grad_norm": 0.39664244651794434,
      "learning_rate": 8.258466994949095e-06,
      "loss": 0.2327,
      "step": 10999
    },
    {
      "epoch": 0.17416913406273254,
      "grad_norm": 0.5959035754203796,
      "learning_rate": 8.258308659372675e-06,
      "loss": 0.0159,
      "step": 11000
    },
    {
      "epoch": 0.1741849676203746,
      "grad_norm": 0.0151126803830266,
      "learning_rate": 8.258150323796255e-06,
      "loss": 0.0007,
      "step": 11001
    },
    {
      "epoch": 0.1742008011780167,
      "grad_norm": 0.18556085228919983,
      "learning_rate": 8.257991988219833e-06,
      "loss": 0.0265,
      "step": 11002
    },
    {
      "epoch": 0.17421663473565877,
      "grad_norm": 0.012783761136233807,
      "learning_rate": 8.257833652643413e-06,
      "loss": 0.0004,
      "step": 11003
    },
    {
      "epoch": 0.17423246829330083,
      "grad_norm": 0.3514038920402527,
      "learning_rate": 8.257675317066993e-06,
      "loss": 0.0846,
      "step": 11004
    },
    {
      "epoch": 0.1742483018509429,
      "grad_norm": 0.2756965756416321,
      "learning_rate": 8.257516981490572e-06,
      "loss": 0.0935,
      "step": 11005
    },
    {
      "epoch": 0.17426413540858496,
      "grad_norm": 1.321108102798462,
      "learning_rate": 8.25735864591415e-06,
      "loss": 0.0393,
      "step": 11006
    },
    {
      "epoch": 0.17427996896622702,
      "grad_norm": 0.47655048966407776,
      "learning_rate": 8.257200310337731e-06,
      "loss": 0.418,
      "step": 11007
    },
    {
      "epoch": 0.1742958025238691,
      "grad_norm": 0.6811583638191223,
      "learning_rate": 8.257041974761309e-06,
      "loss": 0.3098,
      "step": 11008
    },
    {
      "epoch": 0.17431163608151115,
      "grad_norm": 0.010311237536370754,
      "learning_rate": 8.25688363918489e-06,
      "loss": 0.0004,
      "step": 11009
    },
    {
      "epoch": 0.17432746963915322,
      "grad_norm": 0.00014718937745783478,
      "learning_rate": 8.256725303608469e-06,
      "loss": 0.0,
      "step": 11010
    },
    {
      "epoch": 0.17434330319679528,
      "grad_norm": 0.013791280798614025,
      "learning_rate": 8.256566968032048e-06,
      "loss": 0.0006,
      "step": 11011
    },
    {
      "epoch": 0.17435913675443734,
      "grad_norm": 0.39109230041503906,
      "learning_rate": 8.256408632455627e-06,
      "loss": 0.2289,
      "step": 11012
    },
    {
      "epoch": 0.1743749703120794,
      "grad_norm": 0.3116368055343628,
      "learning_rate": 8.256250296879208e-06,
      "loss": 0.1169,
      "step": 11013
    },
    {
      "epoch": 0.1743908038697215,
      "grad_norm": 0.2259795069694519,
      "learning_rate": 8.256091961302785e-06,
      "loss": 0.0474,
      "step": 11014
    },
    {
      "epoch": 0.17440663742736356,
      "grad_norm": 0.6543232202529907,
      "learning_rate": 8.255933625726366e-06,
      "loss": 0.3796,
      "step": 11015
    },
    {
      "epoch": 0.17442247098500563,
      "grad_norm": 0.38560786843299866,
      "learning_rate": 8.255775290149945e-06,
      "loss": 0.1047,
      "step": 11016
    },
    {
      "epoch": 0.1744383045426477,
      "grad_norm": 0.11065977811813354,
      "learning_rate": 8.255616954573524e-06,
      "loss": 0.0054,
      "step": 11017
    },
    {
      "epoch": 0.17445413810028976,
      "grad_norm": 0.364041805267334,
      "learning_rate": 8.255458618997103e-06,
      "loss": 0.1559,
      "step": 11018
    },
    {
      "epoch": 0.17446997165793182,
      "grad_norm": 0.692714273929596,
      "learning_rate": 8.255300283420684e-06,
      "loss": 0.0637,
      "step": 11019
    },
    {
      "epoch": 0.17448580521557389,
      "grad_norm": 0.03233175352215767,
      "learning_rate": 8.255141947844261e-06,
      "loss": 0.0019,
      "step": 11020
    },
    {
      "epoch": 0.17450163877321595,
      "grad_norm": 0.08157064765691757,
      "learning_rate": 8.25498361226784e-06,
      "loss": 0.0045,
      "step": 11021
    },
    {
      "epoch": 0.17451747233085801,
      "grad_norm": 0.4071918725967407,
      "learning_rate": 8.254825276691421e-06,
      "loss": 0.2618,
      "step": 11022
    },
    {
      "epoch": 0.17453330588850008,
      "grad_norm": 0.25708144903182983,
      "learning_rate": 8.254666941115e-06,
      "loss": 0.0271,
      "step": 11023
    },
    {
      "epoch": 0.17454913944614214,
      "grad_norm": 0.0003521276521496475,
      "learning_rate": 8.25450860553858e-06,
      "loss": 0.0,
      "step": 11024
    },
    {
      "epoch": 0.1745649730037842,
      "grad_norm": 0.308298259973526,
      "learning_rate": 8.254350269962158e-06,
      "loss": 0.076,
      "step": 11025
    },
    {
      "epoch": 0.1745808065614263,
      "grad_norm": 0.007802340667694807,
      "learning_rate": 8.254191934385737e-06,
      "loss": 0.0003,
      "step": 11026
    },
    {
      "epoch": 0.17459664011906836,
      "grad_norm": 0.7553139328956604,
      "learning_rate": 8.254033598809316e-06,
      "loss": 0.1862,
      "step": 11027
    },
    {
      "epoch": 0.17461247367671043,
      "grad_norm": 0.36600831151008606,
      "learning_rate": 8.253875263232897e-06,
      "loss": 0.2784,
      "step": 11028
    },
    {
      "epoch": 0.1746283072343525,
      "grad_norm": 0.20797815918922424,
      "learning_rate": 8.253716927656476e-06,
      "loss": 0.1085,
      "step": 11029
    },
    {
      "epoch": 0.17464414079199456,
      "grad_norm": 0.39095667004585266,
      "learning_rate": 8.253558592080055e-06,
      "loss": 0.1076,
      "step": 11030
    },
    {
      "epoch": 0.17465997434963662,
      "grad_norm": 0.348178893327713,
      "learning_rate": 8.253400256503634e-06,
      "loss": 0.0456,
      "step": 11031
    },
    {
      "epoch": 0.17467580790727869,
      "grad_norm": 0.19313523173332214,
      "learning_rate": 8.253241920927214e-06,
      "loss": 0.0378,
      "step": 11032
    },
    {
      "epoch": 0.17469164146492075,
      "grad_norm": 0.6874770522117615,
      "learning_rate": 8.253083585350793e-06,
      "loss": 0.242,
      "step": 11033
    },
    {
      "epoch": 0.1747074750225628,
      "grad_norm": 0.008182908408343792,
      "learning_rate": 8.252925249774373e-06,
      "loss": 0.0002,
      "step": 11034
    },
    {
      "epoch": 0.17472330858020488,
      "grad_norm": 0.0028587032575160265,
      "learning_rate": 8.25276691419795e-06,
      "loss": 0.0001,
      "step": 11035
    },
    {
      "epoch": 0.17473914213784694,
      "grad_norm": 0.00014423407264985144,
      "learning_rate": 8.252608578621532e-06,
      "loss": 0.0,
      "step": 11036
    },
    {
      "epoch": 0.174754975695489,
      "grad_norm": 0.7292148470878601,
      "learning_rate": 8.25245024304511e-06,
      "loss": 0.4533,
      "step": 11037
    },
    {
      "epoch": 0.1747708092531311,
      "grad_norm": 0.0004541287198662758,
      "learning_rate": 8.25229190746869e-06,
      "loss": 0.0,
      "step": 11038
    },
    {
      "epoch": 0.17478664281077316,
      "grad_norm": 0.395796000957489,
      "learning_rate": 8.252133571892269e-06,
      "loss": 0.2512,
      "step": 11039
    },
    {
      "epoch": 0.17480247636841523,
      "grad_norm": 0.046239472925662994,
      "learning_rate": 8.25197523631585e-06,
      "loss": 0.0057,
      "step": 11040
    },
    {
      "epoch": 0.1748183099260573,
      "grad_norm": 0.48202288150787354,
      "learning_rate": 8.251816900739427e-06,
      "loss": 0.3522,
      "step": 11041
    },
    {
      "epoch": 0.17483414348369936,
      "grad_norm": 0.2475050389766693,
      "learning_rate": 8.251658565163008e-06,
      "loss": 0.0369,
      "step": 11042
    },
    {
      "epoch": 0.17484997704134142,
      "grad_norm": 0.006242747884243727,
      "learning_rate": 8.251500229586587e-06,
      "loss": 0.0003,
      "step": 11043
    },
    {
      "epoch": 0.17486581059898348,
      "grad_norm": 0.14815962314605713,
      "learning_rate": 8.251341894010166e-06,
      "loss": 0.003,
      "step": 11044
    },
    {
      "epoch": 0.17488164415662555,
      "grad_norm": 0.21868690848350525,
      "learning_rate": 8.251183558433745e-06,
      "loss": 0.0643,
      "step": 11045
    },
    {
      "epoch": 0.1748974777142676,
      "grad_norm": 0.22691601514816284,
      "learning_rate": 8.251025222857324e-06,
      "loss": 0.1132,
      "step": 11046
    },
    {
      "epoch": 0.17491331127190968,
      "grad_norm": 0.2583460807800293,
      "learning_rate": 8.250866887280903e-06,
      "loss": 0.0855,
      "step": 11047
    },
    {
      "epoch": 0.17492914482955174,
      "grad_norm": 0.16074636578559875,
      "learning_rate": 8.250708551704482e-06,
      "loss": 0.0677,
      "step": 11048
    },
    {
      "epoch": 0.1749449783871938,
      "grad_norm": 0.2285050004720688,
      "learning_rate": 8.250550216128063e-06,
      "loss": 0.0732,
      "step": 11049
    },
    {
      "epoch": 0.1749608119448359,
      "grad_norm": 0.28583046793937683,
      "learning_rate": 8.250391880551642e-06,
      "loss": 0.1361,
      "step": 11050
    },
    {
      "epoch": 0.17497664550247796,
      "grad_norm": 2.7199954986572266,
      "learning_rate": 8.250233544975221e-06,
      "loss": 0.1703,
      "step": 11051
    },
    {
      "epoch": 0.17499247906012003,
      "grad_norm": 0.2661527991294861,
      "learning_rate": 8.2500752093988e-06,
      "loss": 0.4156,
      "step": 11052
    },
    {
      "epoch": 0.1750083126177621,
      "grad_norm": 0.7044807076454163,
      "learning_rate": 8.24991687382238e-06,
      "loss": 0.3643,
      "step": 11053
    },
    {
      "epoch": 0.17502414617540415,
      "grad_norm": 0.47556573152542114,
      "learning_rate": 8.249758538245958e-06,
      "loss": 0.0182,
      "step": 11054
    },
    {
      "epoch": 0.17503997973304622,
      "grad_norm": 0.010895594023168087,
      "learning_rate": 8.24960020266954e-06,
      "loss": 0.0006,
      "step": 11055
    },
    {
      "epoch": 0.17505581329068828,
      "grad_norm": 0.513641893863678,
      "learning_rate": 8.249441867093118e-06,
      "loss": 0.3928,
      "step": 11056
    },
    {
      "epoch": 0.17507164684833035,
      "grad_norm": 0.03321397304534912,
      "learning_rate": 8.249283531516697e-06,
      "loss": 0.002,
      "step": 11057
    },
    {
      "epoch": 0.1750874804059724,
      "grad_norm": 0.5039191246032715,
      "learning_rate": 8.249125195940276e-06,
      "loss": 0.3574,
      "step": 11058
    },
    {
      "epoch": 0.17510331396361448,
      "grad_norm": 0.5356826186180115,
      "learning_rate": 8.248966860363855e-06,
      "loss": 0.6012,
      "step": 11059
    },
    {
      "epoch": 0.17511914752125654,
      "grad_norm": 0.5588309168815613,
      "learning_rate": 8.248808524787435e-06,
      "loss": 0.2871,
      "step": 11060
    },
    {
      "epoch": 0.1751349810788986,
      "grad_norm": 1.2607253789901733,
      "learning_rate": 8.248650189211015e-06,
      "loss": 0.0282,
      "step": 11061
    },
    {
      "epoch": 0.1751508146365407,
      "grad_norm": 0.00020668547949753702,
      "learning_rate": 8.248491853634594e-06,
      "loss": 0.0,
      "step": 11062
    },
    {
      "epoch": 0.17516664819418276,
      "grad_norm": 0.22921960055828094,
      "learning_rate": 8.248333518058173e-06,
      "loss": 0.0388,
      "step": 11063
    },
    {
      "epoch": 0.17518248175182483,
      "grad_norm": 7.835239375708625e-05,
      "learning_rate": 8.248175182481753e-06,
      "loss": 0.0,
      "step": 11064
    },
    {
      "epoch": 0.1751983153094669,
      "grad_norm": 0.5773679614067078,
      "learning_rate": 8.248016846905332e-06,
      "loss": 0.2598,
      "step": 11065
    },
    {
      "epoch": 0.17521414886710895,
      "grad_norm": 0.27243027091026306,
      "learning_rate": 8.24785851132891e-06,
      "loss": 0.0326,
      "step": 11066
    },
    {
      "epoch": 0.17522998242475102,
      "grad_norm": 0.2654935419559479,
      "learning_rate": 8.247700175752492e-06,
      "loss": 0.087,
      "step": 11067
    },
    {
      "epoch": 0.17524581598239308,
      "grad_norm": 0.9956017732620239,
      "learning_rate": 8.24754184017607e-06,
      "loss": 0.4404,
      "step": 11068
    },
    {
      "epoch": 0.17526164954003515,
      "grad_norm": 0.1994476467370987,
      "learning_rate": 8.247383504599648e-06,
      "loss": 0.106,
      "step": 11069
    },
    {
      "epoch": 0.1752774830976772,
      "grad_norm": 0.5911104679107666,
      "learning_rate": 8.247225169023229e-06,
      "loss": 0.0954,
      "step": 11070
    },
    {
      "epoch": 0.17529331665531928,
      "grad_norm": 0.0037402245216071606,
      "learning_rate": 8.247066833446808e-06,
      "loss": 0.0002,
      "step": 11071
    },
    {
      "epoch": 0.17530915021296134,
      "grad_norm": 0.44827789068222046,
      "learning_rate": 8.246908497870387e-06,
      "loss": 0.2882,
      "step": 11072
    },
    {
      "epoch": 0.1753249837706034,
      "grad_norm": 0.33226755261421204,
      "learning_rate": 8.246750162293966e-06,
      "loss": 0.1929,
      "step": 11073
    },
    {
      "epoch": 0.1753408173282455,
      "grad_norm": 0.4637269675731659,
      "learning_rate": 8.246591826717547e-06,
      "loss": 0.4192,
      "step": 11074
    },
    {
      "epoch": 0.17535665088588756,
      "grad_norm": 0.2507385015487671,
      "learning_rate": 8.246433491141124e-06,
      "loss": 0.053,
      "step": 11075
    },
    {
      "epoch": 0.17537248444352962,
      "grad_norm": 0.49385231733322144,
      "learning_rate": 8.246275155564705e-06,
      "loss": 0.1934,
      "step": 11076
    },
    {
      "epoch": 0.1753883180011717,
      "grad_norm": 0.22376686334609985,
      "learning_rate": 8.246116819988284e-06,
      "loss": 0.0625,
      "step": 11077
    },
    {
      "epoch": 0.17540415155881375,
      "grad_norm": 0.025113733485341072,
      "learning_rate": 8.245958484411863e-06,
      "loss": 0.0014,
      "step": 11078
    },
    {
      "epoch": 0.17541998511645582,
      "grad_norm": 0.4835812747478485,
      "learning_rate": 8.245800148835442e-06,
      "loss": 0.2097,
      "step": 11079
    },
    {
      "epoch": 0.17543581867409788,
      "grad_norm": 0.01120650116354227,
      "learning_rate": 8.245641813259023e-06,
      "loss": 0.0006,
      "step": 11080
    },
    {
      "epoch": 0.17545165223173995,
      "grad_norm": 1.1391315460205078,
      "learning_rate": 8.2454834776826e-06,
      "loss": 0.0647,
      "step": 11081
    },
    {
      "epoch": 0.175467485789382,
      "grad_norm": 0.591717004776001,
      "learning_rate": 8.245325142106181e-06,
      "loss": 0.1988,
      "step": 11082
    },
    {
      "epoch": 0.17548331934702407,
      "grad_norm": 0.4852310121059418,
      "learning_rate": 8.24516680652976e-06,
      "loss": 0.3342,
      "step": 11083
    },
    {
      "epoch": 0.17549915290466614,
      "grad_norm": 0.5021288990974426,
      "learning_rate": 8.24500847095334e-06,
      "loss": 0.4103,
      "step": 11084
    },
    {
      "epoch": 0.1755149864623082,
      "grad_norm": 0.04512089863419533,
      "learning_rate": 8.244850135376918e-06,
      "loss": 0.0009,
      "step": 11085
    },
    {
      "epoch": 0.1755308200199503,
      "grad_norm": 0.24060189723968506,
      "learning_rate": 8.244691799800499e-06,
      "loss": 0.0974,
      "step": 11086
    },
    {
      "epoch": 0.17554665357759236,
      "grad_norm": 0.5434028506278992,
      "learning_rate": 8.244533464224076e-06,
      "loss": 0.0757,
      "step": 11087
    },
    {
      "epoch": 0.17556248713523442,
      "grad_norm": 0.17702876031398773,
      "learning_rate": 8.244375128647657e-06,
      "loss": 0.0329,
      "step": 11088
    },
    {
      "epoch": 0.1755783206928765,
      "grad_norm": 0.5497651696205139,
      "learning_rate": 8.244216793071236e-06,
      "loss": 0.2125,
      "step": 11089
    },
    {
      "epoch": 0.17559415425051855,
      "grad_norm": 0.0008255214779637754,
      "learning_rate": 8.244058457494815e-06,
      "loss": 0.0,
      "step": 11090
    },
    {
      "epoch": 0.17560998780816062,
      "grad_norm": 0.3984948992729187,
      "learning_rate": 8.243900121918394e-06,
      "loss": 0.1305,
      "step": 11091
    },
    {
      "epoch": 0.17562582136580268,
      "grad_norm": 0.016872389242053032,
      "learning_rate": 8.243741786341974e-06,
      "loss": 0.0008,
      "step": 11092
    },
    {
      "epoch": 0.17564165492344475,
      "grad_norm": 0.1538705676794052,
      "learning_rate": 8.243583450765553e-06,
      "loss": 0.0415,
      "step": 11093
    },
    {
      "epoch": 0.1756574884810868,
      "grad_norm": 0.5880372524261475,
      "learning_rate": 8.243425115189132e-06,
      "loss": 0.0767,
      "step": 11094
    },
    {
      "epoch": 0.17567332203872887,
      "grad_norm": 1.2892073392868042,
      "learning_rate": 8.243266779612713e-06,
      "loss": 0.6384,
      "step": 11095
    },
    {
      "epoch": 0.17568915559637094,
      "grad_norm": 0.0002153388923034072,
      "learning_rate": 8.24310844403629e-06,
      "loss": 0.0,
      "step": 11096
    },
    {
      "epoch": 0.175704989154013,
      "grad_norm": 0.37094423174858093,
      "learning_rate": 8.24295010845987e-06,
      "loss": 0.0665,
      "step": 11097
    },
    {
      "epoch": 0.1757208227116551,
      "grad_norm": 0.6851773262023926,
      "learning_rate": 8.24279177288345e-06,
      "loss": 0.826,
      "step": 11098
    },
    {
      "epoch": 0.17573665626929716,
      "grad_norm": 0.0005586951156146824,
      "learning_rate": 8.242633437307029e-06,
      "loss": 0.0,
      "step": 11099
    },
    {
      "epoch": 0.17575248982693922,
      "grad_norm": 0.7947566509246826,
      "learning_rate": 8.242475101730608e-06,
      "loss": 0.1149,
      "step": 11100
    },
    {
      "epoch": 0.1757683233845813,
      "grad_norm": 0.4108665883541107,
      "learning_rate": 8.242316766154189e-06,
      "loss": 0.0905,
      "step": 11101
    },
    {
      "epoch": 0.17578415694222335,
      "grad_norm": 0.07655748724937439,
      "learning_rate": 8.242158430577766e-06,
      "loss": 0.0041,
      "step": 11102
    },
    {
      "epoch": 0.17579999049986542,
      "grad_norm": 0.2941838800907135,
      "learning_rate": 8.242000095001347e-06,
      "loss": 0.0337,
      "step": 11103
    },
    {
      "epoch": 0.17581582405750748,
      "grad_norm": 0.9002472758293152,
      "learning_rate": 8.241841759424926e-06,
      "loss": 0.1191,
      "step": 11104
    },
    {
      "epoch": 0.17583165761514954,
      "grad_norm": 0.017597327008843422,
      "learning_rate": 8.241683423848505e-06,
      "loss": 0.0008,
      "step": 11105
    },
    {
      "epoch": 0.1758474911727916,
      "grad_norm": 0.4997771680355072,
      "learning_rate": 8.241525088272084e-06,
      "loss": 0.416,
      "step": 11106
    },
    {
      "epoch": 0.17586332473043367,
      "grad_norm": 0.4745925962924957,
      "learning_rate": 8.241366752695665e-06,
      "loss": 0.0496,
      "step": 11107
    },
    {
      "epoch": 0.17587915828807574,
      "grad_norm": 0.3486187756061554,
      "learning_rate": 8.241208417119242e-06,
      "loss": 0.2368,
      "step": 11108
    },
    {
      "epoch": 0.1758949918457178,
      "grad_norm": 0.024874361231923103,
      "learning_rate": 8.241050081542823e-06,
      "loss": 0.0009,
      "step": 11109
    },
    {
      "epoch": 0.1759108254033599,
      "grad_norm": 0.008556145243346691,
      "learning_rate": 8.240891745966402e-06,
      "loss": 0.0003,
      "step": 11110
    },
    {
      "epoch": 0.17592665896100196,
      "grad_norm": 0.47687509655952454,
      "learning_rate": 8.240733410389981e-06,
      "loss": 0.3205,
      "step": 11111
    },
    {
      "epoch": 0.17594249251864402,
      "grad_norm": 0.21804501116275787,
      "learning_rate": 8.24057507481356e-06,
      "loss": 0.0888,
      "step": 11112
    },
    {
      "epoch": 0.1759583260762861,
      "grad_norm": 0.5120064616203308,
      "learning_rate": 8.240416739237141e-06,
      "loss": 0.0735,
      "step": 11113
    },
    {
      "epoch": 0.17597415963392815,
      "grad_norm": 0.560131847858429,
      "learning_rate": 8.240258403660718e-06,
      "loss": 0.1918,
      "step": 11114
    },
    {
      "epoch": 0.17598999319157022,
      "grad_norm": 0.5578964948654175,
      "learning_rate": 8.2401000680843e-06,
      "loss": 0.1249,
      "step": 11115
    },
    {
      "epoch": 0.17600582674921228,
      "grad_norm": 0.27628692984580994,
      "learning_rate": 8.239941732507878e-06,
      "loss": 0.1448,
      "step": 11116
    },
    {
      "epoch": 0.17602166030685434,
      "grad_norm": 0.8957161903381348,
      "learning_rate": 8.239783396931457e-06,
      "loss": 0.1092,
      "step": 11117
    },
    {
      "epoch": 0.1760374938644964,
      "grad_norm": 0.004989828914403915,
      "learning_rate": 8.239625061355036e-06,
      "loss": 0.0002,
      "step": 11118
    },
    {
      "epoch": 0.17605332742213847,
      "grad_norm": 1.0607266426086426,
      "learning_rate": 8.239466725778616e-06,
      "loss": 0.1307,
      "step": 11119
    },
    {
      "epoch": 0.17606916097978054,
      "grad_norm": 0.7148898839950562,
      "learning_rate": 8.239308390202195e-06,
      "loss": 0.2444,
      "step": 11120
    },
    {
      "epoch": 0.1760849945374226,
      "grad_norm": 0.019777966663241386,
      "learning_rate": 8.239150054625774e-06,
      "loss": 0.0009,
      "step": 11121
    },
    {
      "epoch": 0.1761008280950647,
      "grad_norm": 0.41807055473327637,
      "learning_rate": 8.238991719049354e-06,
      "loss": 0.0759,
      "step": 11122
    },
    {
      "epoch": 0.17611666165270676,
      "grad_norm": 0.3363814353942871,
      "learning_rate": 8.238833383472934e-06,
      "loss": 0.0358,
      "step": 11123
    },
    {
      "epoch": 0.17613249521034882,
      "grad_norm": 0.018487771973013878,
      "learning_rate": 8.238675047896513e-06,
      "loss": 0.0008,
      "step": 11124
    },
    {
      "epoch": 0.17614832876799089,
      "grad_norm": 0.4828779101371765,
      "learning_rate": 8.238516712320092e-06,
      "loss": 0.3958,
      "step": 11125
    },
    {
      "epoch": 0.17616416232563295,
      "grad_norm": 0.4688709080219269,
      "learning_rate": 8.23835837674367e-06,
      "loss": 0.2407,
      "step": 11126
    },
    {
      "epoch": 0.17617999588327501,
      "grad_norm": 0.000478619069326669,
      "learning_rate": 8.23820004116725e-06,
      "loss": 0.0,
      "step": 11127
    },
    {
      "epoch": 0.17619582944091708,
      "grad_norm": 0.46962469816207886,
      "learning_rate": 8.23804170559083e-06,
      "loss": 0.1583,
      "step": 11128
    },
    {
      "epoch": 0.17621166299855914,
      "grad_norm": 0.12919147312641144,
      "learning_rate": 8.23788337001441e-06,
      "loss": 0.054,
      "step": 11129
    },
    {
      "epoch": 0.1762274965562012,
      "grad_norm": 0.4194868505001068,
      "learning_rate": 8.237725034437989e-06,
      "loss": 0.0485,
      "step": 11130
    },
    {
      "epoch": 0.17624333011384327,
      "grad_norm": 0.015302455984055996,
      "learning_rate": 8.237566698861568e-06,
      "loss": 0.0006,
      "step": 11131
    },
    {
      "epoch": 0.17625916367148534,
      "grad_norm": 0.25050538778305054,
      "learning_rate": 8.237408363285147e-06,
      "loss": 0.0798,
      "step": 11132
    },
    {
      "epoch": 0.1762749972291274,
      "grad_norm": 0.6887140870094299,
      "learning_rate": 8.237250027708726e-06,
      "loss": 0.6681,
      "step": 11133
    },
    {
      "epoch": 0.1762908307867695,
      "grad_norm": 0.2226196527481079,
      "learning_rate": 8.237091692132307e-06,
      "loss": 0.0681,
      "step": 11134
    },
    {
      "epoch": 0.17630666434441156,
      "grad_norm": 0.03939126804471016,
      "learning_rate": 8.236933356555886e-06,
      "loss": 0.0019,
      "step": 11135
    },
    {
      "epoch": 0.17632249790205362,
      "grad_norm": 0.07120396941900253,
      "learning_rate": 8.236775020979465e-06,
      "loss": 0.0034,
      "step": 11136
    },
    {
      "epoch": 0.17633833145969569,
      "grad_norm": 0.39635735750198364,
      "learning_rate": 8.236616685403044e-06,
      "loss": 0.1219,
      "step": 11137
    },
    {
      "epoch": 0.17635416501733775,
      "grad_norm": 0.32660529017448425,
      "learning_rate": 8.236458349826623e-06,
      "loss": 0.164,
      "step": 11138
    },
    {
      "epoch": 0.1763699985749798,
      "grad_norm": 0.0065355198457837105,
      "learning_rate": 8.236300014250202e-06,
      "loss": 0.0001,
      "step": 11139
    },
    {
      "epoch": 0.17638583213262188,
      "grad_norm": 0.16217711567878723,
      "learning_rate": 8.236141678673781e-06,
      "loss": 0.0562,
      "step": 11140
    },
    {
      "epoch": 0.17640166569026394,
      "grad_norm": 0.43116098642349243,
      "learning_rate": 8.235983343097362e-06,
      "loss": 0.15,
      "step": 11141
    },
    {
      "epoch": 0.176417499247906,
      "grad_norm": 0.10713808238506317,
      "learning_rate": 8.23582500752094e-06,
      "loss": 0.0019,
      "step": 11142
    },
    {
      "epoch": 0.17643333280554807,
      "grad_norm": 0.11541160941123962,
      "learning_rate": 8.23566667194452e-06,
      "loss": 0.0076,
      "step": 11143
    },
    {
      "epoch": 0.17644916636319014,
      "grad_norm": 0.47976744174957275,
      "learning_rate": 8.2355083363681e-06,
      "loss": 0.0665,
      "step": 11144
    },
    {
      "epoch": 0.1764649999208322,
      "grad_norm": 0.4307023882865906,
      "learning_rate": 8.235350000791678e-06,
      "loss": 0.1989,
      "step": 11145
    },
    {
      "epoch": 0.1764808334784743,
      "grad_norm": 0.1561766266822815,
      "learning_rate": 8.235191665215257e-06,
      "loss": 0.0191,
      "step": 11146
    },
    {
      "epoch": 0.17649666703611636,
      "grad_norm": 0.7338096499443054,
      "learning_rate": 8.235033329638838e-06,
      "loss": 0.4199,
      "step": 11147
    },
    {
      "epoch": 0.17651250059375842,
      "grad_norm": 0.774795413017273,
      "learning_rate": 8.234874994062416e-06,
      "loss": 0.7353,
      "step": 11148
    },
    {
      "epoch": 0.17652833415140048,
      "grad_norm": 0.5452063679695129,
      "learning_rate": 8.234716658485996e-06,
      "loss": 0.2064,
      "step": 11149
    },
    {
      "epoch": 0.17654416770904255,
      "grad_norm": 0.47487592697143555,
      "learning_rate": 8.234558322909575e-06,
      "loss": 0.105,
      "step": 11150
    },
    {
      "epoch": 0.1765600012666846,
      "grad_norm": 0.2014809548854828,
      "learning_rate": 8.234399987333155e-06,
      "loss": 0.0284,
      "step": 11151
    },
    {
      "epoch": 0.17657583482432668,
      "grad_norm": 1.178571105003357,
      "learning_rate": 8.234241651756734e-06,
      "loss": 0.1091,
      "step": 11152
    },
    {
      "epoch": 0.17659166838196874,
      "grad_norm": 0.1786731630563736,
      "learning_rate": 8.234083316180314e-06,
      "loss": 0.0339,
      "step": 11153
    },
    {
      "epoch": 0.1766075019396108,
      "grad_norm": 0.0469701923429966,
      "learning_rate": 8.233924980603892e-06,
      "loss": 0.002,
      "step": 11154
    },
    {
      "epoch": 0.17662333549725287,
      "grad_norm": 0.016264213249087334,
      "learning_rate": 8.233766645027473e-06,
      "loss": 0.0007,
      "step": 11155
    },
    {
      "epoch": 0.17663916905489493,
      "grad_norm": 0.1451241672039032,
      "learning_rate": 8.233608309451052e-06,
      "loss": 0.013,
      "step": 11156
    },
    {
      "epoch": 0.176655002612537,
      "grad_norm": 0.25505194067955017,
      "learning_rate": 8.23344997387463e-06,
      "loss": 0.0827,
      "step": 11157
    },
    {
      "epoch": 0.1766708361701791,
      "grad_norm": 0.00023383420193567872,
      "learning_rate": 8.23329163829821e-06,
      "loss": 0.0,
      "step": 11158
    },
    {
      "epoch": 0.17668666972782116,
      "grad_norm": 0.02477019466459751,
      "learning_rate": 8.233133302721789e-06,
      "loss": 0.0012,
      "step": 11159
    },
    {
      "epoch": 0.17670250328546322,
      "grad_norm": 0.00020234745170455426,
      "learning_rate": 8.232974967145368e-06,
      "loss": 0.0,
      "step": 11160
    },
    {
      "epoch": 0.17671833684310528,
      "grad_norm": 0.038074854761362076,
      "learning_rate": 8.232816631568949e-06,
      "loss": 0.0015,
      "step": 11161
    },
    {
      "epoch": 0.17673417040074735,
      "grad_norm": 0.6309354305267334,
      "learning_rate": 8.232658295992528e-06,
      "loss": 0.6868,
      "step": 11162
    },
    {
      "epoch": 0.1767500039583894,
      "grad_norm": 0.35572725534439087,
      "learning_rate": 8.232499960416107e-06,
      "loss": 0.0451,
      "step": 11163
    },
    {
      "epoch": 0.17676583751603148,
      "grad_norm": 0.15250264108181,
      "learning_rate": 8.232341624839686e-06,
      "loss": 0.0568,
      "step": 11164
    },
    {
      "epoch": 0.17678167107367354,
      "grad_norm": 0.007178760599344969,
      "learning_rate": 8.232183289263265e-06,
      "loss": 0.0002,
      "step": 11165
    },
    {
      "epoch": 0.1767975046313156,
      "grad_norm": 0.03828861936926842,
      "learning_rate": 8.232024953686844e-06,
      "loss": 0.002,
      "step": 11166
    },
    {
      "epoch": 0.17681333818895767,
      "grad_norm": 0.67741858959198,
      "learning_rate": 8.231866618110423e-06,
      "loss": 0.2215,
      "step": 11167
    },
    {
      "epoch": 0.17682917174659973,
      "grad_norm": 0.27629777789115906,
      "learning_rate": 8.231708282534004e-06,
      "loss": 0.0535,
      "step": 11168
    },
    {
      "epoch": 0.1768450053042418,
      "grad_norm": 0.02904304303228855,
      "learning_rate": 8.231549946957581e-06,
      "loss": 0.0011,
      "step": 11169
    },
    {
      "epoch": 0.1768608388618839,
      "grad_norm": 0.302796870470047,
      "learning_rate": 8.231391611381162e-06,
      "loss": 0.0455,
      "step": 11170
    },
    {
      "epoch": 0.17687667241952595,
      "grad_norm": 0.22495096921920776,
      "learning_rate": 8.231233275804741e-06,
      "loss": 0.0592,
      "step": 11171
    },
    {
      "epoch": 0.17689250597716802,
      "grad_norm": 0.39306071400642395,
      "learning_rate": 8.23107494022832e-06,
      "loss": 0.3183,
      "step": 11172
    },
    {
      "epoch": 0.17690833953481008,
      "grad_norm": 0.03307722508907318,
      "learning_rate": 8.2309166046519e-06,
      "loss": 0.0017,
      "step": 11173
    },
    {
      "epoch": 0.17692417309245215,
      "grad_norm": 0.5592892169952393,
      "learning_rate": 8.23075826907548e-06,
      "loss": 0.0416,
      "step": 11174
    },
    {
      "epoch": 0.1769400066500942,
      "grad_norm": 0.06389783322811127,
      "learning_rate": 8.230599933499058e-06,
      "loss": 0.0035,
      "step": 11175
    },
    {
      "epoch": 0.17695584020773628,
      "grad_norm": 0.13572777807712555,
      "learning_rate": 8.230441597922638e-06,
      "loss": 0.065,
      "step": 11176
    },
    {
      "epoch": 0.17697167376537834,
      "grad_norm": 0.36652201414108276,
      "learning_rate": 8.230283262346217e-06,
      "loss": 0.1322,
      "step": 11177
    },
    {
      "epoch": 0.1769875073230204,
      "grad_norm": 0.34597694873809814,
      "learning_rate": 8.230124926769796e-06,
      "loss": 0.2238,
      "step": 11178
    },
    {
      "epoch": 0.17700334088066247,
      "grad_norm": 0.05870869383215904,
      "learning_rate": 8.229966591193376e-06,
      "loss": 0.0011,
      "step": 11179
    },
    {
      "epoch": 0.17701917443830453,
      "grad_norm": 0.00048628236982040107,
      "learning_rate": 8.229808255616956e-06,
      "loss": 0.0,
      "step": 11180
    },
    {
      "epoch": 0.1770350079959466,
      "grad_norm": 0.7084180116653442,
      "learning_rate": 8.229649920040534e-06,
      "loss": 0.1575,
      "step": 11181
    },
    {
      "epoch": 0.1770508415535887,
      "grad_norm": 0.27437958121299744,
      "learning_rate": 8.229491584464114e-06,
      "loss": 0.0129,
      "step": 11182
    },
    {
      "epoch": 0.17706667511123075,
      "grad_norm": 0.015161479823291302,
      "learning_rate": 8.229333248887694e-06,
      "loss": 0.0007,
      "step": 11183
    },
    {
      "epoch": 0.17708250866887282,
      "grad_norm": 0.4387064278125763,
      "learning_rate": 8.229174913311273e-06,
      "loss": 0.2964,
      "step": 11184
    },
    {
      "epoch": 0.17709834222651488,
      "grad_norm": 0.5475419759750366,
      "learning_rate": 8.229016577734852e-06,
      "loss": 0.0368,
      "step": 11185
    },
    {
      "epoch": 0.17711417578415695,
      "grad_norm": 0.5603321194648743,
      "learning_rate": 8.228858242158432e-06,
      "loss": 0.1895,
      "step": 11186
    },
    {
      "epoch": 0.177130009341799,
      "grad_norm": 0.20438823103904724,
      "learning_rate": 8.22869990658201e-06,
      "loss": 0.2825,
      "step": 11187
    },
    {
      "epoch": 0.17714584289944107,
      "grad_norm": 0.042716678231954575,
      "learning_rate": 8.228541571005589e-06,
      "loss": 0.003,
      "step": 11188
    },
    {
      "epoch": 0.17716167645708314,
      "grad_norm": 0.14444561302661896,
      "learning_rate": 8.22838323542917e-06,
      "loss": 0.0428,
      "step": 11189
    },
    {
      "epoch": 0.1771775100147252,
      "grad_norm": 0.49697649478912354,
      "learning_rate": 8.228224899852749e-06,
      "loss": 0.104,
      "step": 11190
    },
    {
      "epoch": 0.17719334357236727,
      "grad_norm": 0.3339349031448364,
      "learning_rate": 8.228066564276328e-06,
      "loss": 0.1787,
      "step": 11191
    },
    {
      "epoch": 0.17720917713000933,
      "grad_norm": 0.18534724414348602,
      "learning_rate": 8.227908228699907e-06,
      "loss": 0.0751,
      "step": 11192
    },
    {
      "epoch": 0.1772250106876514,
      "grad_norm": 0.16096307337284088,
      "learning_rate": 8.227749893123486e-06,
      "loss": 0.0687,
      "step": 11193
    },
    {
      "epoch": 0.1772408442452935,
      "grad_norm": 0.5731745958328247,
      "learning_rate": 8.227591557547065e-06,
      "loss": 0.032,
      "step": 11194
    },
    {
      "epoch": 0.17725667780293555,
      "grad_norm": 0.25947481393814087,
      "learning_rate": 8.227433221970646e-06,
      "loss": 0.1158,
      "step": 11195
    },
    {
      "epoch": 0.17727251136057762,
      "grad_norm": 0.24619357287883759,
      "learning_rate": 8.227274886394225e-06,
      "loss": 0.0266,
      "step": 11196
    },
    {
      "epoch": 0.17728834491821968,
      "grad_norm": 0.0001830538676586002,
      "learning_rate": 8.227116550817804e-06,
      "loss": 0.0,
      "step": 11197
    },
    {
      "epoch": 0.17730417847586175,
      "grad_norm": 0.17059019207954407,
      "learning_rate": 8.226958215241383e-06,
      "loss": 0.0498,
      "step": 11198
    },
    {
      "epoch": 0.1773200120335038,
      "grad_norm": 0.31112411618232727,
      "learning_rate": 8.226799879664962e-06,
      "loss": 0.0327,
      "step": 11199
    },
    {
      "epoch": 0.17733584559114587,
      "grad_norm": 0.4210542142391205,
      "learning_rate": 8.226641544088541e-06,
      "loss": 0.094,
      "step": 11200
    },
    {
      "epoch": 0.17735167914878794,
      "grad_norm": 0.9437472224235535,
      "learning_rate": 8.226483208512122e-06,
      "loss": 0.1578,
      "step": 11201
    },
    {
      "epoch": 0.17736751270643,
      "grad_norm": 0.010871338658034801,
      "learning_rate": 8.226324872935701e-06,
      "loss": 0.0005,
      "step": 11202
    },
    {
      "epoch": 0.17738334626407207,
      "grad_norm": 0.010936068370938301,
      "learning_rate": 8.22616653735928e-06,
      "loss": 0.0005,
      "step": 11203
    },
    {
      "epoch": 0.17739917982171413,
      "grad_norm": 0.4812341630458832,
      "learning_rate": 8.22600820178286e-06,
      "loss": 0.2344,
      "step": 11204
    },
    {
      "epoch": 0.1774150133793562,
      "grad_norm": 0.0988273099064827,
      "learning_rate": 8.225849866206438e-06,
      "loss": 0.0076,
      "step": 11205
    },
    {
      "epoch": 0.1774308469369983,
      "grad_norm": 0.312984824180603,
      "learning_rate": 8.225691530630017e-06,
      "loss": 0.146,
      "step": 11206
    },
    {
      "epoch": 0.17744668049464035,
      "grad_norm": 0.5099789500236511,
      "learning_rate": 8.225533195053598e-06,
      "loss": 0.0754,
      "step": 11207
    },
    {
      "epoch": 0.17746251405228242,
      "grad_norm": 0.9378582835197449,
      "learning_rate": 8.225374859477177e-06,
      "loss": 0.2152,
      "step": 11208
    },
    {
      "epoch": 0.17747834760992448,
      "grad_norm": 0.025731738656759262,
      "learning_rate": 8.225216523900756e-06,
      "loss": 0.0017,
      "step": 11209
    },
    {
      "epoch": 0.17749418116756654,
      "grad_norm": 0.13493196666240692,
      "learning_rate": 8.225058188324335e-06,
      "loss": 0.0285,
      "step": 11210
    },
    {
      "epoch": 0.1775100147252086,
      "grad_norm": 0.2726042568683624,
      "learning_rate": 8.224899852747915e-06,
      "loss": 0.0965,
      "step": 11211
    },
    {
      "epoch": 0.17752584828285067,
      "grad_norm": 0.6410747170448303,
      "learning_rate": 8.224741517171494e-06,
      "loss": 0.4163,
      "step": 11212
    },
    {
      "epoch": 0.17754168184049274,
      "grad_norm": 0.36320334672927856,
      "learning_rate": 8.224583181595073e-06,
      "loss": 0.9011,
      "step": 11213
    },
    {
      "epoch": 0.1775575153981348,
      "grad_norm": 0.5282833576202393,
      "learning_rate": 8.224424846018653e-06,
      "loss": 0.298,
      "step": 11214
    },
    {
      "epoch": 0.17757334895577687,
      "grad_norm": 0.14062294363975525,
      "learning_rate": 8.224266510442231e-06,
      "loss": 0.0351,
      "step": 11215
    },
    {
      "epoch": 0.17758918251341893,
      "grad_norm": 0.003108412493020296,
      "learning_rate": 8.224108174865812e-06,
      "loss": 0.0001,
      "step": 11216
    },
    {
      "epoch": 0.177605016071061,
      "grad_norm": 0.000494356092531234,
      "learning_rate": 8.22394983928939e-06,
      "loss": 0.0,
      "step": 11217
    },
    {
      "epoch": 0.1776208496287031,
      "grad_norm": 0.024556538090109825,
      "learning_rate": 8.22379150371297e-06,
      "loss": 0.0019,
      "step": 11218
    },
    {
      "epoch": 0.17763668318634515,
      "grad_norm": 0.5819194316864014,
      "learning_rate": 8.223633168136549e-06,
      "loss": 0.2007,
      "step": 11219
    },
    {
      "epoch": 0.17765251674398722,
      "grad_norm": 0.3255186378955841,
      "learning_rate": 8.22347483256013e-06,
      "loss": 0.0998,
      "step": 11220
    },
    {
      "epoch": 0.17766835030162928,
      "grad_norm": 0.33778882026672363,
      "learning_rate": 8.223316496983707e-06,
      "loss": 0.1641,
      "step": 11221
    },
    {
      "epoch": 0.17768418385927134,
      "grad_norm": 0.39471447467803955,
      "learning_rate": 8.223158161407288e-06,
      "loss": 0.4427,
      "step": 11222
    },
    {
      "epoch": 0.1777000174169134,
      "grad_norm": 0.03939924016594887,
      "learning_rate": 8.222999825830867e-06,
      "loss": 0.0009,
      "step": 11223
    },
    {
      "epoch": 0.17771585097455547,
      "grad_norm": 0.42263635993003845,
      "learning_rate": 8.222841490254446e-06,
      "loss": 0.0807,
      "step": 11224
    },
    {
      "epoch": 0.17773168453219754,
      "grad_norm": 0.03084246627986431,
      "learning_rate": 8.222683154678025e-06,
      "loss": 0.0017,
      "step": 11225
    },
    {
      "epoch": 0.1777475180898396,
      "grad_norm": 0.3459087014198303,
      "learning_rate": 8.222524819101604e-06,
      "loss": 0.2144,
      "step": 11226
    },
    {
      "epoch": 0.17776335164748167,
      "grad_norm": 0.5809908509254456,
      "learning_rate": 8.222366483525183e-06,
      "loss": 0.1293,
      "step": 11227
    },
    {
      "epoch": 0.17777918520512373,
      "grad_norm": 0.6829222440719604,
      "learning_rate": 8.222208147948764e-06,
      "loss": 0.1396,
      "step": 11228
    },
    {
      "epoch": 0.1777950187627658,
      "grad_norm": 0.20762811601161957,
      "learning_rate": 8.222049812372343e-06,
      "loss": 0.0753,
      "step": 11229
    },
    {
      "epoch": 0.1778108523204079,
      "grad_norm": 0.34248948097229004,
      "learning_rate": 8.221891476795922e-06,
      "loss": 0.1479,
      "step": 11230
    },
    {
      "epoch": 0.17782668587804995,
      "grad_norm": 0.6368104815483093,
      "learning_rate": 8.221733141219501e-06,
      "loss": 0.9224,
      "step": 11231
    },
    {
      "epoch": 0.17784251943569201,
      "grad_norm": 0.3720170855522156,
      "learning_rate": 8.22157480564308e-06,
      "loss": 0.0745,
      "step": 11232
    },
    {
      "epoch": 0.17785835299333408,
      "grad_norm": 0.004429639782756567,
      "learning_rate": 8.22141647006666e-06,
      "loss": 0.0002,
      "step": 11233
    },
    {
      "epoch": 0.17787418655097614,
      "grad_norm": 0.07334285229444504,
      "learning_rate": 8.22125813449024e-06,
      "loss": 0.0107,
      "step": 11234
    },
    {
      "epoch": 0.1778900201086182,
      "grad_norm": 0.00040830366197042167,
      "learning_rate": 8.22109979891382e-06,
      "loss": 0.0,
      "step": 11235
    },
    {
      "epoch": 0.17790585366626027,
      "grad_norm": 0.004045724403113127,
      "learning_rate": 8.220941463337397e-06,
      "loss": 0.0001,
      "step": 11236
    },
    {
      "epoch": 0.17792168722390234,
      "grad_norm": 0.23601950705051422,
      "learning_rate": 8.220783127760977e-06,
      "loss": 0.2684,
      "step": 11237
    },
    {
      "epoch": 0.1779375207815444,
      "grad_norm": 0.5473880171775818,
      "learning_rate": 8.220624792184556e-06,
      "loss": 0.2067,
      "step": 11238
    },
    {
      "epoch": 0.17795335433918646,
      "grad_norm": 0.0007408891688100994,
      "learning_rate": 8.220466456608136e-06,
      "loss": 0.0,
      "step": 11239
    },
    {
      "epoch": 0.17796918789682853,
      "grad_norm": 0.6268112659454346,
      "learning_rate": 8.220308121031715e-06,
      "loss": 0.5708,
      "step": 11240
    },
    {
      "epoch": 0.1779850214544706,
      "grad_norm": 0.004788522608578205,
      "learning_rate": 8.220149785455295e-06,
      "loss": 0.0001,
      "step": 11241
    },
    {
      "epoch": 0.17800085501211269,
      "grad_norm": 0.010071888566017151,
      "learning_rate": 8.219991449878873e-06,
      "loss": 0.0002,
      "step": 11242
    },
    {
      "epoch": 0.17801668856975475,
      "grad_norm": 0.3321610689163208,
      "learning_rate": 8.219833114302454e-06,
      "loss": 0.1347,
      "step": 11243
    },
    {
      "epoch": 0.17803252212739681,
      "grad_norm": 0.3328755497932434,
      "learning_rate": 8.219674778726033e-06,
      "loss": 0.1325,
      "step": 11244
    },
    {
      "epoch": 0.17804835568503888,
      "grad_norm": 1.0154786109924316,
      "learning_rate": 8.219516443149612e-06,
      "loss": 0.2104,
      "step": 11245
    },
    {
      "epoch": 0.17806418924268094,
      "grad_norm": 0.32126307487487793,
      "learning_rate": 8.21935810757319e-06,
      "loss": 0.0962,
      "step": 11246
    },
    {
      "epoch": 0.178080022800323,
      "grad_norm": 0.40739911794662476,
      "learning_rate": 8.219199771996772e-06,
      "loss": 0.4156,
      "step": 11247
    },
    {
      "epoch": 0.17809585635796507,
      "grad_norm": 0.00040461955359205604,
      "learning_rate": 8.219041436420349e-06,
      "loss": 0.0,
      "step": 11248
    },
    {
      "epoch": 0.17811168991560714,
      "grad_norm": 1.026440978050232,
      "learning_rate": 8.21888310084393e-06,
      "loss": 0.4246,
      "step": 11249
    },
    {
      "epoch": 0.1781275234732492,
      "grad_norm": 0.00011402777454350144,
      "learning_rate": 8.218724765267509e-06,
      "loss": 0.0,
      "step": 11250
    },
    {
      "epoch": 0.17814335703089126,
      "grad_norm": 0.005795150995254517,
      "learning_rate": 8.218566429691088e-06,
      "loss": 0.0003,
      "step": 11251
    },
    {
      "epoch": 0.17815919058853333,
      "grad_norm": 0.260710209608078,
      "learning_rate": 8.218408094114667e-06,
      "loss": 0.0922,
      "step": 11252
    },
    {
      "epoch": 0.1781750241461754,
      "grad_norm": 0.00025677160010673106,
      "learning_rate": 8.218249758538248e-06,
      "loss": 0.0,
      "step": 11253
    },
    {
      "epoch": 0.17819085770381748,
      "grad_norm": 0.2845862805843353,
      "learning_rate": 8.218091422961825e-06,
      "loss": 0.0454,
      "step": 11254
    },
    {
      "epoch": 0.17820669126145955,
      "grad_norm": 0.37121105194091797,
      "learning_rate": 8.217933087385406e-06,
      "loss": 0.1667,
      "step": 11255
    },
    {
      "epoch": 0.1782225248191016,
      "grad_norm": 0.014362478628754616,
      "learning_rate": 8.217774751808985e-06,
      "loss": 0.0005,
      "step": 11256
    },
    {
      "epoch": 0.17823835837674368,
      "grad_norm": 0.6166201233863831,
      "learning_rate": 8.217616416232564e-06,
      "loss": 0.105,
      "step": 11257
    },
    {
      "epoch": 0.17825419193438574,
      "grad_norm": 0.022678958252072334,
      "learning_rate": 8.217458080656143e-06,
      "loss": 0.0014,
      "step": 11258
    },
    {
      "epoch": 0.1782700254920278,
      "grad_norm": 0.16649039089679718,
      "learning_rate": 8.217299745079724e-06,
      "loss": 0.0644,
      "step": 11259
    },
    {
      "epoch": 0.17828585904966987,
      "grad_norm": 0.18006789684295654,
      "learning_rate": 8.217141409503301e-06,
      "loss": 0.0805,
      "step": 11260
    },
    {
      "epoch": 0.17830169260731193,
      "grad_norm": 0.18364694714546204,
      "learning_rate": 8.21698307392688e-06,
      "loss": 0.1192,
      "step": 11261
    },
    {
      "epoch": 0.178317526164954,
      "grad_norm": 0.28978022933006287,
      "learning_rate": 8.216824738350461e-06,
      "loss": 0.1004,
      "step": 11262
    },
    {
      "epoch": 0.17833335972259606,
      "grad_norm": 0.00027193687856197357,
      "learning_rate": 8.21666640277404e-06,
      "loss": 0.0,
      "step": 11263
    },
    {
      "epoch": 0.17834919328023813,
      "grad_norm": 0.3953157067298889,
      "learning_rate": 8.21650806719762e-06,
      "loss": 0.212,
      "step": 11264
    },
    {
      "epoch": 0.1783650268378802,
      "grad_norm": 0.3661264479160309,
      "learning_rate": 8.216349731621198e-06,
      "loss": 0.0949,
      "step": 11265
    },
    {
      "epoch": 0.17838086039552226,
      "grad_norm": 0.21958348155021667,
      "learning_rate": 8.216191396044777e-06,
      "loss": 0.0413,
      "step": 11266
    },
    {
      "epoch": 0.17839669395316435,
      "grad_norm": 0.031499285250902176,
      "learning_rate": 8.216033060468357e-06,
      "loss": 0.0015,
      "step": 11267
    },
    {
      "epoch": 0.1784125275108064,
      "grad_norm": 0.22500577569007874,
      "learning_rate": 8.215874724891937e-06,
      "loss": 0.0803,
      "step": 11268
    },
    {
      "epoch": 0.17842836106844848,
      "grad_norm": 0.2220592498779297,
      "learning_rate": 8.215716389315516e-06,
      "loss": 0.0032,
      "step": 11269
    },
    {
      "epoch": 0.17844419462609054,
      "grad_norm": 0.6687682271003723,
      "learning_rate": 8.215558053739095e-06,
      "loss": 0.0399,
      "step": 11270
    },
    {
      "epoch": 0.1784600281837326,
      "grad_norm": 0.3252086937427521,
      "learning_rate": 8.215399718162675e-06,
      "loss": 0.1198,
      "step": 11271
    },
    {
      "epoch": 0.17847586174137467,
      "grad_norm": 0.4337593913078308,
      "learning_rate": 8.215241382586254e-06,
      "loss": 0.3335,
      "step": 11272
    },
    {
      "epoch": 0.17849169529901673,
      "grad_norm": 0.390938937664032,
      "learning_rate": 8.215083047009833e-06,
      "loss": 0.1205,
      "step": 11273
    },
    {
      "epoch": 0.1785075288566588,
      "grad_norm": 0.5044808983802795,
      "learning_rate": 8.214924711433413e-06,
      "loss": 0.7156,
      "step": 11274
    },
    {
      "epoch": 0.17852336241430086,
      "grad_norm": 0.052235644310712814,
      "learning_rate": 8.214766375856993e-06,
      "loss": 0.0044,
      "step": 11275
    },
    {
      "epoch": 0.17853919597194293,
      "grad_norm": 0.727588415145874,
      "learning_rate": 8.214608040280572e-06,
      "loss": 0.3533,
      "step": 11276
    },
    {
      "epoch": 0.178555029529585,
      "grad_norm": 0.029770294204354286,
      "learning_rate": 8.21444970470415e-06,
      "loss": 0.002,
      "step": 11277
    },
    {
      "epoch": 0.17857086308722706,
      "grad_norm": 0.2317575067281723,
      "learning_rate": 8.21429136912773e-06,
      "loss": 0.0171,
      "step": 11278
    },
    {
      "epoch": 0.17858669664486915,
      "grad_norm": 0.0168339554220438,
      "learning_rate": 8.214133033551309e-06,
      "loss": 0.0009,
      "step": 11279
    },
    {
      "epoch": 0.1786025302025112,
      "grad_norm": 0.369602233171463,
      "learning_rate": 8.21397469797489e-06,
      "loss": 0.1992,
      "step": 11280
    },
    {
      "epoch": 0.17861836376015328,
      "grad_norm": 0.02995910495519638,
      "learning_rate": 8.213816362398469e-06,
      "loss": 0.0013,
      "step": 11281
    },
    {
      "epoch": 0.17863419731779534,
      "grad_norm": 0.48118409514427185,
      "learning_rate": 8.213658026822048e-06,
      "loss": 0.1324,
      "step": 11282
    },
    {
      "epoch": 0.1786500308754374,
      "grad_norm": 0.4914668798446655,
      "learning_rate": 8.213499691245627e-06,
      "loss": 0.5375,
      "step": 11283
    },
    {
      "epoch": 0.17866586443307947,
      "grad_norm": 0.00019574345787987113,
      "learning_rate": 8.213341355669206e-06,
      "loss": 0.0,
      "step": 11284
    },
    {
      "epoch": 0.17868169799072153,
      "grad_norm": 0.00027687070542015135,
      "learning_rate": 8.213183020092785e-06,
      "loss": 0.0,
      "step": 11285
    },
    {
      "epoch": 0.1786975315483636,
      "grad_norm": 0.3832322359085083,
      "learning_rate": 8.213024684516364e-06,
      "loss": 0.1356,
      "step": 11286
    },
    {
      "epoch": 0.17871336510600566,
      "grad_norm": 0.010304266586899757,
      "learning_rate": 8.212866348939943e-06,
      "loss": 0.0006,
      "step": 11287
    },
    {
      "epoch": 0.17872919866364773,
      "grad_norm": 0.3467434048652649,
      "learning_rate": 8.212708013363522e-06,
      "loss": 0.1855,
      "step": 11288
    },
    {
      "epoch": 0.1787450322212898,
      "grad_norm": 0.06802872568368912,
      "learning_rate": 8.212549677787103e-06,
      "loss": 0.0064,
      "step": 11289
    },
    {
      "epoch": 0.17876086577893185,
      "grad_norm": 0.00031776190735399723,
      "learning_rate": 8.212391342210682e-06,
      "loss": 0.0,
      "step": 11290
    },
    {
      "epoch": 0.17877669933657395,
      "grad_norm": 0.0002837199135683477,
      "learning_rate": 8.212233006634261e-06,
      "loss": 0.0,
      "step": 11291
    },
    {
      "epoch": 0.178792532894216,
      "grad_norm": 0.48866644501686096,
      "learning_rate": 8.21207467105784e-06,
      "loss": 0.2743,
      "step": 11292
    },
    {
      "epoch": 0.17880836645185808,
      "grad_norm": 0.304303914308548,
      "learning_rate": 8.21191633548142e-06,
      "loss": 0.0869,
      "step": 11293
    },
    {
      "epoch": 0.17882420000950014,
      "grad_norm": 0.159383624792099,
      "learning_rate": 8.211757999904998e-06,
      "loss": 0.0477,
      "step": 11294
    },
    {
      "epoch": 0.1788400335671422,
      "grad_norm": 0.07617083191871643,
      "learning_rate": 8.21159966432858e-06,
      "loss": 0.0065,
      "step": 11295
    },
    {
      "epoch": 0.17885586712478427,
      "grad_norm": 0.3635105490684509,
      "learning_rate": 8.211441328752158e-06,
      "loss": 0.1143,
      "step": 11296
    },
    {
      "epoch": 0.17887170068242633,
      "grad_norm": 0.525783121585846,
      "learning_rate": 8.211282993175737e-06,
      "loss": 0.1712,
      "step": 11297
    },
    {
      "epoch": 0.1788875342400684,
      "grad_norm": 0.5629623532295227,
      "learning_rate": 8.211124657599316e-06,
      "loss": 0.1232,
      "step": 11298
    },
    {
      "epoch": 0.17890336779771046,
      "grad_norm": 0.0002031180920312181,
      "learning_rate": 8.210966322022896e-06,
      "loss": 0.0,
      "step": 11299
    },
    {
      "epoch": 0.17891920135535253,
      "grad_norm": 0.25459206104278564,
      "learning_rate": 8.210807986446475e-06,
      "loss": 0.3065,
      "step": 11300
    },
    {
      "epoch": 0.1789350349129946,
      "grad_norm": 0.3913988173007965,
      "learning_rate": 8.210649650870055e-06,
      "loss": 0.1288,
      "step": 11301
    },
    {
      "epoch": 0.17895086847063665,
      "grad_norm": 0.016185877844691277,
      "learning_rate": 8.210491315293634e-06,
      "loss": 0.0007,
      "step": 11302
    },
    {
      "epoch": 0.17896670202827875,
      "grad_norm": 0.23101456463336945,
      "learning_rate": 8.210332979717214e-06,
      "loss": 0.0551,
      "step": 11303
    },
    {
      "epoch": 0.1789825355859208,
      "grad_norm": 0.0005667444202117622,
      "learning_rate": 8.210174644140793e-06,
      "loss": 0.0,
      "step": 11304
    },
    {
      "epoch": 0.17899836914356287,
      "grad_norm": 0.000464938348159194,
      "learning_rate": 8.210016308564372e-06,
      "loss": 0.0,
      "step": 11305
    },
    {
      "epoch": 0.17901420270120494,
      "grad_norm": 2.104147434234619,
      "learning_rate": 8.20985797298795e-06,
      "loss": 0.2807,
      "step": 11306
    },
    {
      "epoch": 0.179030036258847,
      "grad_norm": 0.007168351206928492,
      "learning_rate": 8.209699637411532e-06,
      "loss": 0.0003,
      "step": 11307
    },
    {
      "epoch": 0.17904586981648907,
      "grad_norm": 0.8174452185630798,
      "learning_rate": 8.20954130183511e-06,
      "loss": 0.5279,
      "step": 11308
    },
    {
      "epoch": 0.17906170337413113,
      "grad_norm": 0.31875166296958923,
      "learning_rate": 8.209382966258688e-06,
      "loss": 0.1061,
      "step": 11309
    },
    {
      "epoch": 0.1790775369317732,
      "grad_norm": 0.006211398169398308,
      "learning_rate": 8.209224630682269e-06,
      "loss": 0.0003,
      "step": 11310
    },
    {
      "epoch": 0.17909337048941526,
      "grad_norm": 0.0013684032019227743,
      "learning_rate": 8.209066295105848e-06,
      "loss": 0.0001,
      "step": 11311
    },
    {
      "epoch": 0.17910920404705732,
      "grad_norm": 0.3094150424003601,
      "learning_rate": 8.208907959529427e-06,
      "loss": 0.1718,
      "step": 11312
    },
    {
      "epoch": 0.1791250376046994,
      "grad_norm": 0.02362557128071785,
      "learning_rate": 8.208749623953006e-06,
      "loss": 0.0015,
      "step": 11313
    },
    {
      "epoch": 0.17914087116234145,
      "grad_norm": 0.33212122321128845,
      "learning_rate": 8.208591288376587e-06,
      "loss": 0.2512,
      "step": 11314
    },
    {
      "epoch": 0.17915670471998354,
      "grad_norm": 0.3049379289150238,
      "learning_rate": 8.208432952800164e-06,
      "loss": 0.1307,
      "step": 11315
    },
    {
      "epoch": 0.1791725382776256,
      "grad_norm": 0.2593350112438202,
      "learning_rate": 8.208274617223745e-06,
      "loss": 0.0869,
      "step": 11316
    },
    {
      "epoch": 0.17918837183526767,
      "grad_norm": 0.438933402299881,
      "learning_rate": 8.208116281647324e-06,
      "loss": 0.1445,
      "step": 11317
    },
    {
      "epoch": 0.17920420539290974,
      "grad_norm": 0.16549836099147797,
      "learning_rate": 8.207957946070903e-06,
      "loss": 0.0141,
      "step": 11318
    },
    {
      "epoch": 0.1792200389505518,
      "grad_norm": 0.6060800552368164,
      "learning_rate": 8.207799610494482e-06,
      "loss": 0.0704,
      "step": 11319
    },
    {
      "epoch": 0.17923587250819387,
      "grad_norm": 0.0003811105852946639,
      "learning_rate": 8.207641274918063e-06,
      "loss": 0.0,
      "step": 11320
    },
    {
      "epoch": 0.17925170606583593,
      "grad_norm": 0.8032298684120178,
      "learning_rate": 8.20748293934164e-06,
      "loss": 0.121,
      "step": 11321
    },
    {
      "epoch": 0.179267539623478,
      "grad_norm": 1.797562599182129,
      "learning_rate": 8.207324603765221e-06,
      "loss": 0.0327,
      "step": 11322
    },
    {
      "epoch": 0.17928337318112006,
      "grad_norm": 0.8241434693336487,
      "learning_rate": 8.2071662681888e-06,
      "loss": 0.166,
      "step": 11323
    },
    {
      "epoch": 0.17929920673876212,
      "grad_norm": 0.2824954688549042,
      "learning_rate": 8.20700793261238e-06,
      "loss": 0.0686,
      "step": 11324
    },
    {
      "epoch": 0.1793150402964042,
      "grad_norm": 0.6032880544662476,
      "learning_rate": 8.206849597035958e-06,
      "loss": 0.5355,
      "step": 11325
    },
    {
      "epoch": 0.17933087385404625,
      "grad_norm": 0.25045087933540344,
      "learning_rate": 8.20669126145954e-06,
      "loss": 0.1076,
      "step": 11326
    },
    {
      "epoch": 0.17934670741168834,
      "grad_norm": 0.0011644774349406362,
      "learning_rate": 8.206532925883117e-06,
      "loss": 0.0,
      "step": 11327
    },
    {
      "epoch": 0.1793625409693304,
      "grad_norm": 0.00039756123442202806,
      "learning_rate": 8.206374590306697e-06,
      "loss": 0.0,
      "step": 11328
    },
    {
      "epoch": 0.17937837452697247,
      "grad_norm": 0.6034414768218994,
      "learning_rate": 8.206216254730276e-06,
      "loss": 0.0734,
      "step": 11329
    },
    {
      "epoch": 0.17939420808461454,
      "grad_norm": 0.435575395822525,
      "learning_rate": 8.206057919153855e-06,
      "loss": 0.1419,
      "step": 11330
    },
    {
      "epoch": 0.1794100416422566,
      "grad_norm": 0.2989770472049713,
      "learning_rate": 8.205899583577435e-06,
      "loss": 0.051,
      "step": 11331
    },
    {
      "epoch": 0.17942587519989867,
      "grad_norm": 0.26732635498046875,
      "learning_rate": 8.205741248001015e-06,
      "loss": 0.0661,
      "step": 11332
    },
    {
      "epoch": 0.17944170875754073,
      "grad_norm": 0.04522577300667763,
      "learning_rate": 8.205582912424593e-06,
      "loss": 0.002,
      "step": 11333
    },
    {
      "epoch": 0.1794575423151828,
      "grad_norm": 0.33665433526039124,
      "learning_rate": 8.205424576848172e-06,
      "loss": 0.1128,
      "step": 11334
    },
    {
      "epoch": 0.17947337587282486,
      "grad_norm": 0.49923115968704224,
      "learning_rate": 8.205266241271753e-06,
      "loss": 0.2537,
      "step": 11335
    },
    {
      "epoch": 0.17948920943046692,
      "grad_norm": 0.8809025287628174,
      "learning_rate": 8.205107905695332e-06,
      "loss": 0.1226,
      "step": 11336
    },
    {
      "epoch": 0.179505042988109,
      "grad_norm": 1.446825623512268,
      "learning_rate": 8.20494957011891e-06,
      "loss": 0.3075,
      "step": 11337
    },
    {
      "epoch": 0.17952087654575105,
      "grad_norm": 0.40762966871261597,
      "learning_rate": 8.20479123454249e-06,
      "loss": 0.1441,
      "step": 11338
    },
    {
      "epoch": 0.17953671010339314,
      "grad_norm": 0.16519354283809662,
      "learning_rate": 8.204632898966069e-06,
      "loss": 0.0638,
      "step": 11339
    },
    {
      "epoch": 0.1795525436610352,
      "grad_norm": 0.5733921527862549,
      "learning_rate": 8.204474563389648e-06,
      "loss": 0.2296,
      "step": 11340
    },
    {
      "epoch": 0.17956837721867727,
      "grad_norm": 0.354892373085022,
      "learning_rate": 8.204316227813229e-06,
      "loss": 0.1094,
      "step": 11341
    },
    {
      "epoch": 0.17958421077631934,
      "grad_norm": 0.22462648153305054,
      "learning_rate": 8.204157892236808e-06,
      "loss": 0.0256,
      "step": 11342
    },
    {
      "epoch": 0.1796000443339614,
      "grad_norm": 0.3035058379173279,
      "learning_rate": 8.203999556660387e-06,
      "loss": 0.1413,
      "step": 11343
    },
    {
      "epoch": 0.17961587789160346,
      "grad_norm": 0.1644424945116043,
      "learning_rate": 8.203841221083966e-06,
      "loss": 0.0505,
      "step": 11344
    },
    {
      "epoch": 0.17963171144924553,
      "grad_norm": 0.3952533006668091,
      "learning_rate": 8.203682885507545e-06,
      "loss": 0.0739,
      "step": 11345
    },
    {
      "epoch": 0.1796475450068876,
      "grad_norm": 0.0001835879374993965,
      "learning_rate": 8.203524549931124e-06,
      "loss": 0.0,
      "step": 11346
    },
    {
      "epoch": 0.17966337856452966,
      "grad_norm": 0.2327093780040741,
      "learning_rate": 8.203366214354705e-06,
      "loss": 0.0829,
      "step": 11347
    },
    {
      "epoch": 0.17967921212217172,
      "grad_norm": 0.006088227964937687,
      "learning_rate": 8.203207878778284e-06,
      "loss": 0.0003,
      "step": 11348
    },
    {
      "epoch": 0.1796950456798138,
      "grad_norm": 0.4698009192943573,
      "learning_rate": 8.203049543201863e-06,
      "loss": 0.0609,
      "step": 11349
    },
    {
      "epoch": 0.17971087923745585,
      "grad_norm": 0.5695984959602356,
      "learning_rate": 8.202891207625442e-06,
      "loss": 0.3468,
      "step": 11350
    },
    {
      "epoch": 0.17972671279509794,
      "grad_norm": 0.4647987186908722,
      "learning_rate": 8.202732872049021e-06,
      "loss": 0.2372,
      "step": 11351
    },
    {
      "epoch": 0.17974254635274,
      "grad_norm": 0.6682230830192566,
      "learning_rate": 8.2025745364726e-06,
      "loss": 0.2793,
      "step": 11352
    },
    {
      "epoch": 0.17975837991038207,
      "grad_norm": 0.021702345460653305,
      "learning_rate": 8.202416200896181e-06,
      "loss": 0.0009,
      "step": 11353
    },
    {
      "epoch": 0.17977421346802414,
      "grad_norm": 0.9449804425239563,
      "learning_rate": 8.202257865319758e-06,
      "loss": 0.0951,
      "step": 11354
    },
    {
      "epoch": 0.1797900470256662,
      "grad_norm": 0.09572308510541916,
      "learning_rate": 8.20209952974334e-06,
      "loss": 0.0065,
      "step": 11355
    },
    {
      "epoch": 0.17980588058330826,
      "grad_norm": 0.5052561163902283,
      "learning_rate": 8.201941194166918e-06,
      "loss": 0.3304,
      "step": 11356
    },
    {
      "epoch": 0.17982171414095033,
      "grad_norm": 0.4279201030731201,
      "learning_rate": 8.201782858590497e-06,
      "loss": 0.2026,
      "step": 11357
    },
    {
      "epoch": 0.1798375476985924,
      "grad_norm": 0.22168785333633423,
      "learning_rate": 8.201624523014077e-06,
      "loss": 0.0568,
      "step": 11358
    },
    {
      "epoch": 0.17985338125623446,
      "grad_norm": 0.12101123481988907,
      "learning_rate": 8.201466187437656e-06,
      "loss": 0.0094,
      "step": 11359
    },
    {
      "epoch": 0.17986921481387652,
      "grad_norm": 0.20246517658233643,
      "learning_rate": 8.201307851861235e-06,
      "loss": 0.0812,
      "step": 11360
    },
    {
      "epoch": 0.17988504837151859,
      "grad_norm": 0.03998300060629845,
      "learning_rate": 8.201149516284814e-06,
      "loss": 0.002,
      "step": 11361
    },
    {
      "epoch": 0.17990088192916065,
      "grad_norm": 0.1738215684890747,
      "learning_rate": 8.200991180708395e-06,
      "loss": 0.0022,
      "step": 11362
    },
    {
      "epoch": 0.17991671548680274,
      "grad_norm": 0.31763628125190735,
      "learning_rate": 8.200832845131974e-06,
      "loss": 0.133,
      "step": 11363
    },
    {
      "epoch": 0.1799325490444448,
      "grad_norm": 0.2919021248817444,
      "learning_rate": 8.200674509555553e-06,
      "loss": 0.1089,
      "step": 11364
    },
    {
      "epoch": 0.17994838260208687,
      "grad_norm": 0.013073083013296127,
      "learning_rate": 8.200516173979132e-06,
      "loss": 0.0005,
      "step": 11365
    },
    {
      "epoch": 0.17996421615972893,
      "grad_norm": 0.7616589069366455,
      "learning_rate": 8.20035783840271e-06,
      "loss": 0.4956,
      "step": 11366
    },
    {
      "epoch": 0.179980049717371,
      "grad_norm": 0.4204730987548828,
      "learning_rate": 8.20019950282629e-06,
      "loss": 0.0676,
      "step": 11367
    },
    {
      "epoch": 0.17999588327501306,
      "grad_norm": 0.41239669919013977,
      "learning_rate": 8.20004116724987e-06,
      "loss": 0.1519,
      "step": 11368
    },
    {
      "epoch": 0.18001171683265513,
      "grad_norm": 0.5098392963409424,
      "learning_rate": 8.19988283167345e-06,
      "loss": 0.0735,
      "step": 11369
    },
    {
      "epoch": 0.1800275503902972,
      "grad_norm": 0.43491604924201965,
      "learning_rate": 8.199724496097029e-06,
      "loss": 0.0909,
      "step": 11370
    },
    {
      "epoch": 0.18004338394793926,
      "grad_norm": 0.0003702985413838178,
      "learning_rate": 8.199566160520608e-06,
      "loss": 0.0,
      "step": 11371
    },
    {
      "epoch": 0.18005921750558132,
      "grad_norm": 0.0037191100418567657,
      "learning_rate": 8.199407824944187e-06,
      "loss": 0.0001,
      "step": 11372
    },
    {
      "epoch": 0.18007505106322338,
      "grad_norm": 0.40946170687675476,
      "learning_rate": 8.199249489367766e-06,
      "loss": 0.2626,
      "step": 11373
    },
    {
      "epoch": 0.18009088462086545,
      "grad_norm": 0.4963700771331787,
      "learning_rate": 8.199091153791347e-06,
      "loss": 0.1999,
      "step": 11374
    },
    {
      "epoch": 0.18010671817850754,
      "grad_norm": 0.9831801056861877,
      "learning_rate": 8.198932818214926e-06,
      "loss": 0.1521,
      "step": 11375
    },
    {
      "epoch": 0.1801225517361496,
      "grad_norm": 0.00040515162982046604,
      "learning_rate": 8.198774482638505e-06,
      "loss": 0.0,
      "step": 11376
    },
    {
      "epoch": 0.18013838529379167,
      "grad_norm": 0.5160996913909912,
      "learning_rate": 8.198616147062084e-06,
      "loss": 0.097,
      "step": 11377
    },
    {
      "epoch": 0.18015421885143373,
      "grad_norm": 0.5053176879882812,
      "learning_rate": 8.198457811485663e-06,
      "loss": 0.1656,
      "step": 11378
    },
    {
      "epoch": 0.1801700524090758,
      "grad_norm": 0.3452583849430084,
      "learning_rate": 8.198299475909242e-06,
      "loss": 0.1235,
      "step": 11379
    },
    {
      "epoch": 0.18018588596671786,
      "grad_norm": 0.00019381253514438868,
      "learning_rate": 8.198141140332823e-06,
      "loss": 0.0,
      "step": 11380
    },
    {
      "epoch": 0.18020171952435993,
      "grad_norm": 0.39036813378334045,
      "learning_rate": 8.197982804756402e-06,
      "loss": 0.1019,
      "step": 11381
    },
    {
      "epoch": 0.180217553082002,
      "grad_norm": 0.5857861638069153,
      "learning_rate": 8.19782446917998e-06,
      "loss": 0.1424,
      "step": 11382
    },
    {
      "epoch": 0.18023338663964406,
      "grad_norm": 0.00019211714970879257,
      "learning_rate": 8.19766613360356e-06,
      "loss": 0.0,
      "step": 11383
    },
    {
      "epoch": 0.18024922019728612,
      "grad_norm": 0.46262869238853455,
      "learning_rate": 8.19750779802714e-06,
      "loss": 0.0568,
      "step": 11384
    },
    {
      "epoch": 0.18026505375492818,
      "grad_norm": 1.1611369848251343,
      "learning_rate": 8.197349462450718e-06,
      "loss": 0.4821,
      "step": 11385
    },
    {
      "epoch": 0.18028088731257025,
      "grad_norm": 0.5778663158416748,
      "learning_rate": 8.197191126874298e-06,
      "loss": 0.23,
      "step": 11386
    },
    {
      "epoch": 0.18029672087021234,
      "grad_norm": 0.0257149375975132,
      "learning_rate": 8.197032791297878e-06,
      "loss": 0.0015,
      "step": 11387
    },
    {
      "epoch": 0.1803125544278544,
      "grad_norm": 0.3847830295562744,
      "learning_rate": 8.196874455721456e-06,
      "loss": 0.1496,
      "step": 11388
    },
    {
      "epoch": 0.18032838798549647,
      "grad_norm": 0.6079528331756592,
      "learning_rate": 8.196716120145036e-06,
      "loss": 0.126,
      "step": 11389
    },
    {
      "epoch": 0.18034422154313853,
      "grad_norm": 0.44270312786102295,
      "learning_rate": 8.196557784568616e-06,
      "loss": 0.3778,
      "step": 11390
    },
    {
      "epoch": 0.1803600551007806,
      "grad_norm": 0.42324432730674744,
      "learning_rate": 8.196399448992195e-06,
      "loss": 0.4635,
      "step": 11391
    },
    {
      "epoch": 0.18037588865842266,
      "grad_norm": 0.3447261154651642,
      "learning_rate": 8.196241113415774e-06,
      "loss": 0.0753,
      "step": 11392
    },
    {
      "epoch": 0.18039172221606473,
      "grad_norm": 0.03880678489804268,
      "learning_rate": 8.196082777839354e-06,
      "loss": 0.0025,
      "step": 11393
    },
    {
      "epoch": 0.1804075557737068,
      "grad_norm": 0.795408308506012,
      "learning_rate": 8.195924442262932e-06,
      "loss": 0.1872,
      "step": 11394
    },
    {
      "epoch": 0.18042338933134885,
      "grad_norm": 0.008940690197050571,
      "learning_rate": 8.195766106686513e-06,
      "loss": 0.0004,
      "step": 11395
    },
    {
      "epoch": 0.18043922288899092,
      "grad_norm": 0.18370813131332397,
      "learning_rate": 8.195607771110092e-06,
      "loss": 0.0576,
      "step": 11396
    },
    {
      "epoch": 0.18045505644663298,
      "grad_norm": 0.017815615981817245,
      "learning_rate": 8.19544943553367e-06,
      "loss": 0.0009,
      "step": 11397
    },
    {
      "epoch": 0.18047089000427505,
      "grad_norm": 0.1306796371936798,
      "learning_rate": 8.19529109995725e-06,
      "loss": 0.0279,
      "step": 11398
    },
    {
      "epoch": 0.18048672356191714,
      "grad_norm": 0.23148223757743835,
      "learning_rate": 8.19513276438083e-06,
      "loss": 0.092,
      "step": 11399
    },
    {
      "epoch": 0.1805025571195592,
      "grad_norm": 0.5371712446212769,
      "learning_rate": 8.194974428804408e-06,
      "loss": 0.3124,
      "step": 11400
    },
    {
      "epoch": 0.18051839067720127,
      "grad_norm": 0.14758853614330292,
      "learning_rate": 8.194816093227989e-06,
      "loss": 0.0259,
      "step": 11401
    },
    {
      "epoch": 0.18053422423484333,
      "grad_norm": 1.428174376487732,
      "learning_rate": 8.194657757651568e-06,
      "loss": 0.0407,
      "step": 11402
    },
    {
      "epoch": 0.1805500577924854,
      "grad_norm": 0.7820538878440857,
      "learning_rate": 8.194499422075147e-06,
      "loss": 0.6384,
      "step": 11403
    },
    {
      "epoch": 0.18056589135012746,
      "grad_norm": 0.16384604573249817,
      "learning_rate": 8.194341086498726e-06,
      "loss": 0.0541,
      "step": 11404
    },
    {
      "epoch": 0.18058172490776953,
      "grad_norm": 0.17676031589508057,
      "learning_rate": 8.194182750922305e-06,
      "loss": 0.085,
      "step": 11405
    },
    {
      "epoch": 0.1805975584654116,
      "grad_norm": 5.8453315432416275e-05,
      "learning_rate": 8.194024415345884e-06,
      "loss": 0.0,
      "step": 11406
    },
    {
      "epoch": 0.18061339202305365,
      "grad_norm": 0.3301081657409668,
      "learning_rate": 8.193866079769463e-06,
      "loss": 0.1677,
      "step": 11407
    },
    {
      "epoch": 0.18062922558069572,
      "grad_norm": 0.33149194717407227,
      "learning_rate": 8.193707744193044e-06,
      "loss": 0.117,
      "step": 11408
    },
    {
      "epoch": 0.18064505913833778,
      "grad_norm": 0.549138605594635,
      "learning_rate": 8.193549408616623e-06,
      "loss": 0.2302,
      "step": 11409
    },
    {
      "epoch": 0.18066089269597985,
      "grad_norm": 0.2967280447483063,
      "learning_rate": 8.193391073040202e-06,
      "loss": 0.0366,
      "step": 11410
    },
    {
      "epoch": 0.18067672625362194,
      "grad_norm": 0.00012813066132366657,
      "learning_rate": 8.193232737463781e-06,
      "loss": 0.0,
      "step": 11411
    },
    {
      "epoch": 0.180692559811264,
      "grad_norm": 0.291718065738678,
      "learning_rate": 8.19307440188736e-06,
      "loss": 0.1501,
      "step": 11412
    },
    {
      "epoch": 0.18070839336890607,
      "grad_norm": 0.20445308089256287,
      "learning_rate": 8.19291606631094e-06,
      "loss": 0.0958,
      "step": 11413
    },
    {
      "epoch": 0.18072422692654813,
      "grad_norm": 1.493094801902771,
      "learning_rate": 8.19275773073452e-06,
      "loss": 0.0606,
      "step": 11414
    },
    {
      "epoch": 0.1807400604841902,
      "grad_norm": 0.20188817381858826,
      "learning_rate": 8.192599395158098e-06,
      "loss": 0.0175,
      "step": 11415
    },
    {
      "epoch": 0.18075589404183226,
      "grad_norm": 0.4565848410129547,
      "learning_rate": 8.192441059581678e-06,
      "loss": 0.0922,
      "step": 11416
    },
    {
      "epoch": 0.18077172759947432,
      "grad_norm": 0.6922794580459595,
      "learning_rate": 8.192282724005257e-06,
      "loss": 0.1705,
      "step": 11417
    },
    {
      "epoch": 0.1807875611571164,
      "grad_norm": 0.8220910429954529,
      "learning_rate": 8.192124388428837e-06,
      "loss": 0.0305,
      "step": 11418
    },
    {
      "epoch": 0.18080339471475845,
      "grad_norm": 0.27266445755958557,
      "learning_rate": 8.191966052852416e-06,
      "loss": 0.0982,
      "step": 11419
    },
    {
      "epoch": 0.18081922827240052,
      "grad_norm": 0.5412828326225281,
      "learning_rate": 8.191807717275996e-06,
      "loss": 0.5881,
      "step": 11420
    },
    {
      "epoch": 0.18083506183004258,
      "grad_norm": 0.44586798548698425,
      "learning_rate": 8.191649381699574e-06,
      "loss": 0.2001,
      "step": 11421
    },
    {
      "epoch": 0.18085089538768465,
      "grad_norm": 0.7529545426368713,
      "learning_rate": 8.191491046123155e-06,
      "loss": 0.9239,
      "step": 11422
    },
    {
      "epoch": 0.18086672894532674,
      "grad_norm": 0.0017124592559412122,
      "learning_rate": 8.191332710546734e-06,
      "loss": 0.0,
      "step": 11423
    },
    {
      "epoch": 0.1808825625029688,
      "grad_norm": 0.22969429194927216,
      "learning_rate": 8.191174374970313e-06,
      "loss": 0.0537,
      "step": 11424
    },
    {
      "epoch": 0.18089839606061087,
      "grad_norm": 0.3736165165901184,
      "learning_rate": 8.191016039393892e-06,
      "loss": 0.0724,
      "step": 11425
    },
    {
      "epoch": 0.18091422961825293,
      "grad_norm": 0.32082799077033997,
      "learning_rate": 8.190857703817473e-06,
      "loss": 0.1413,
      "step": 11426
    },
    {
      "epoch": 0.180930063175895,
      "grad_norm": 0.39336109161376953,
      "learning_rate": 8.19069936824105e-06,
      "loss": 0.1699,
      "step": 11427
    },
    {
      "epoch": 0.18094589673353706,
      "grad_norm": 0.1488640308380127,
      "learning_rate": 8.19054103266463e-06,
      "loss": 0.0348,
      "step": 11428
    },
    {
      "epoch": 0.18096173029117912,
      "grad_norm": 0.004872697871178389,
      "learning_rate": 8.19038269708821e-06,
      "loss": 0.0002,
      "step": 11429
    },
    {
      "epoch": 0.1809775638488212,
      "grad_norm": 0.019399555400013924,
      "learning_rate": 8.190224361511789e-06,
      "loss": 0.0009,
      "step": 11430
    },
    {
      "epoch": 0.18099339740646325,
      "grad_norm": 0.3513890504837036,
      "learning_rate": 8.190066025935368e-06,
      "loss": 0.1754,
      "step": 11431
    },
    {
      "epoch": 0.18100923096410532,
      "grad_norm": 0.018731622025370598,
      "learning_rate": 8.189907690358947e-06,
      "loss": 0.0006,
      "step": 11432
    },
    {
      "epoch": 0.18102506452174738,
      "grad_norm": 0.3739819824695587,
      "learning_rate": 8.189749354782526e-06,
      "loss": 0.0254,
      "step": 11433
    },
    {
      "epoch": 0.18104089807938945,
      "grad_norm": 0.42454636096954346,
      "learning_rate": 8.189591019206105e-06,
      "loss": 0.1926,
      "step": 11434
    },
    {
      "epoch": 0.18105673163703154,
      "grad_norm": 1.1546552181243896,
      "learning_rate": 8.189432683629686e-06,
      "loss": 0.0422,
      "step": 11435
    },
    {
      "epoch": 0.1810725651946736,
      "grad_norm": 0.3427085280418396,
      "learning_rate": 8.189274348053265e-06,
      "loss": 0.0874,
      "step": 11436
    },
    {
      "epoch": 0.18108839875231567,
      "grad_norm": 0.5081138610839844,
      "learning_rate": 8.189116012476844e-06,
      "loss": 0.1193,
      "step": 11437
    },
    {
      "epoch": 0.18110423230995773,
      "grad_norm": 8.64859321154654e-05,
      "learning_rate": 8.188957676900423e-06,
      "loss": 0.0,
      "step": 11438
    },
    {
      "epoch": 0.1811200658675998,
      "grad_norm": 0.5944721698760986,
      "learning_rate": 8.188799341324002e-06,
      "loss": 0.0783,
      "step": 11439
    },
    {
      "epoch": 0.18113589942524186,
      "grad_norm": 0.9099174737930298,
      "learning_rate": 8.188641005747581e-06,
      "loss": 0.1618,
      "step": 11440
    },
    {
      "epoch": 0.18115173298288392,
      "grad_norm": 1.2408771514892578,
      "learning_rate": 8.188482670171162e-06,
      "loss": 0.161,
      "step": 11441
    },
    {
      "epoch": 0.181167566540526,
      "grad_norm": 0.039932165294885635,
      "learning_rate": 8.188324334594741e-06,
      "loss": 0.0021,
      "step": 11442
    },
    {
      "epoch": 0.18118340009816805,
      "grad_norm": 0.7668707966804504,
      "learning_rate": 8.18816599901832e-06,
      "loss": 0.3515,
      "step": 11443
    },
    {
      "epoch": 0.18119923365581012,
      "grad_norm": 0.15430320799350739,
      "learning_rate": 8.1880076634419e-06,
      "loss": 0.0833,
      "step": 11444
    },
    {
      "epoch": 0.18121506721345218,
      "grad_norm": 0.7792059183120728,
      "learning_rate": 8.187849327865478e-06,
      "loss": 0.0888,
      "step": 11445
    },
    {
      "epoch": 0.18123090077109424,
      "grad_norm": 0.36190739274024963,
      "learning_rate": 8.187690992289058e-06,
      "loss": 0.0964,
      "step": 11446
    },
    {
      "epoch": 0.18124673432873634,
      "grad_norm": 0.0039579556323587894,
      "learning_rate": 8.187532656712638e-06,
      "loss": 0.0002,
      "step": 11447
    },
    {
      "epoch": 0.1812625678863784,
      "grad_norm": 0.47068843245506287,
      "learning_rate": 8.187374321136217e-06,
      "loss": 0.0943,
      "step": 11448
    },
    {
      "epoch": 0.18127840144402046,
      "grad_norm": 0.4305768311023712,
      "learning_rate": 8.187215985559796e-06,
      "loss": 0.4237,
      "step": 11449
    },
    {
      "epoch": 0.18129423500166253,
      "grad_norm": 0.32959359884262085,
      "learning_rate": 8.187057649983376e-06,
      "loss": 0.0721,
      "step": 11450
    },
    {
      "epoch": 0.1813100685593046,
      "grad_norm": 2.330239772796631,
      "learning_rate": 8.186899314406955e-06,
      "loss": 0.1287,
      "step": 11451
    },
    {
      "epoch": 0.18132590211694666,
      "grad_norm": 0.8742448687553406,
      "learning_rate": 8.186740978830534e-06,
      "loss": 0.1654,
      "step": 11452
    },
    {
      "epoch": 0.18134173567458872,
      "grad_norm": 0.5521384477615356,
      "learning_rate": 8.186582643254113e-06,
      "loss": 0.2715,
      "step": 11453
    },
    {
      "epoch": 0.1813575692322308,
      "grad_norm": 0.1267637014389038,
      "learning_rate": 8.186424307677694e-06,
      "loss": 0.0122,
      "step": 11454
    },
    {
      "epoch": 0.18137340278987285,
      "grad_norm": 0.4526764452457428,
      "learning_rate": 8.186265972101271e-06,
      "loss": 0.2839,
      "step": 11455
    },
    {
      "epoch": 0.18138923634751491,
      "grad_norm": 0.8394869565963745,
      "learning_rate": 8.186107636524852e-06,
      "loss": 0.2366,
      "step": 11456
    },
    {
      "epoch": 0.18140506990515698,
      "grad_norm": 0.5303989052772522,
      "learning_rate": 8.18594930094843e-06,
      "loss": 0.1122,
      "step": 11457
    },
    {
      "epoch": 0.18142090346279904,
      "grad_norm": 0.5740213990211487,
      "learning_rate": 8.18579096537201e-06,
      "loss": 0.1902,
      "step": 11458
    },
    {
      "epoch": 0.18143673702044114,
      "grad_norm": 0.4850902259349823,
      "learning_rate": 8.185632629795589e-06,
      "loss": 0.0158,
      "step": 11459
    },
    {
      "epoch": 0.1814525705780832,
      "grad_norm": 0.3968198597431183,
      "learning_rate": 8.18547429421917e-06,
      "loss": 0.2109,
      "step": 11460
    },
    {
      "epoch": 0.18146840413572526,
      "grad_norm": 0.3853641450405121,
      "learning_rate": 8.185315958642747e-06,
      "loss": 0.0959,
      "step": 11461
    },
    {
      "epoch": 0.18148423769336733,
      "grad_norm": 0.21522893011569977,
      "learning_rate": 8.185157623066328e-06,
      "loss": 0.0846,
      "step": 11462
    },
    {
      "epoch": 0.1815000712510094,
      "grad_norm": 0.4603630304336548,
      "learning_rate": 8.184999287489907e-06,
      "loss": 0.1305,
      "step": 11463
    },
    {
      "epoch": 0.18151590480865146,
      "grad_norm": 0.00017272178956773132,
      "learning_rate": 8.184840951913486e-06,
      "loss": 0.0,
      "step": 11464
    },
    {
      "epoch": 0.18153173836629352,
      "grad_norm": 0.7378212213516235,
      "learning_rate": 8.184682616337065e-06,
      "loss": 0.3006,
      "step": 11465
    },
    {
      "epoch": 0.18154757192393559,
      "grad_norm": 0.3175862729549408,
      "learning_rate": 8.184524280760646e-06,
      "loss": 0.0714,
      "step": 11466
    },
    {
      "epoch": 0.18156340548157765,
      "grad_norm": 1.2595151662826538,
      "learning_rate": 8.184365945184223e-06,
      "loss": 0.7588,
      "step": 11467
    },
    {
      "epoch": 0.18157923903921971,
      "grad_norm": 0.3284076452255249,
      "learning_rate": 8.184207609607804e-06,
      "loss": 0.0605,
      "step": 11468
    },
    {
      "epoch": 0.18159507259686178,
      "grad_norm": 0.3882468640804291,
      "learning_rate": 8.184049274031383e-06,
      "loss": 0.1162,
      "step": 11469
    },
    {
      "epoch": 0.18161090615450384,
      "grad_norm": 0.00021317372738849372,
      "learning_rate": 8.183890938454962e-06,
      "loss": 0.0,
      "step": 11470
    },
    {
      "epoch": 0.18162673971214593,
      "grad_norm": 0.6257752776145935,
      "learning_rate": 8.183732602878541e-06,
      "loss": 0.1317,
      "step": 11471
    },
    {
      "epoch": 0.181642573269788,
      "grad_norm": 0.25315091013908386,
      "learning_rate": 8.183574267302122e-06,
      "loss": 0.089,
      "step": 11472
    },
    {
      "epoch": 0.18165840682743006,
      "grad_norm": 0.4193969964981079,
      "learning_rate": 8.1834159317257e-06,
      "loss": 0.0425,
      "step": 11473
    },
    {
      "epoch": 0.18167424038507213,
      "grad_norm": 0.0006459879223257303,
      "learning_rate": 8.18325759614928e-06,
      "loss": 0.0,
      "step": 11474
    },
    {
      "epoch": 0.1816900739427142,
      "grad_norm": 0.02152213826775551,
      "learning_rate": 8.18309926057286e-06,
      "loss": 0.0008,
      "step": 11475
    },
    {
      "epoch": 0.18170590750035626,
      "grad_norm": 0.00011128913320135325,
      "learning_rate": 8.182940924996438e-06,
      "loss": 0.0,
      "step": 11476
    },
    {
      "epoch": 0.18172174105799832,
      "grad_norm": 0.6831973791122437,
      "learning_rate": 8.182782589420017e-06,
      "loss": 0.8929,
      "step": 11477
    },
    {
      "epoch": 0.18173757461564038,
      "grad_norm": 0.36254367232322693,
      "learning_rate": 8.182624253843597e-06,
      "loss": 0.208,
      "step": 11478
    },
    {
      "epoch": 0.18175340817328245,
      "grad_norm": 0.33953967690467834,
      "learning_rate": 8.182465918267176e-06,
      "loss": 0.2735,
      "step": 11479
    },
    {
      "epoch": 0.1817692417309245,
      "grad_norm": 0.18499889969825745,
      "learning_rate": 8.182307582690755e-06,
      "loss": 0.0273,
      "step": 11480
    },
    {
      "epoch": 0.18178507528856658,
      "grad_norm": 0.3796577751636505,
      "learning_rate": 8.182149247114335e-06,
      "loss": 0.2466,
      "step": 11481
    },
    {
      "epoch": 0.18180090884620864,
      "grad_norm": 0.5787628889083862,
      "learning_rate": 8.181990911537913e-06,
      "loss": 0.1468,
      "step": 11482
    },
    {
      "epoch": 0.18181674240385073,
      "grad_norm": 0.042217813432216644,
      "learning_rate": 8.181832575961494e-06,
      "loss": 0.001,
      "step": 11483
    },
    {
      "epoch": 0.1818325759614928,
      "grad_norm": 0.8885308504104614,
      "learning_rate": 8.181674240385073e-06,
      "loss": 0.5629,
      "step": 11484
    },
    {
      "epoch": 0.18184840951913486,
      "grad_norm": 0.47768935561180115,
      "learning_rate": 8.181515904808652e-06,
      "loss": 0.2995,
      "step": 11485
    },
    {
      "epoch": 0.18186424307677693,
      "grad_norm": 0.7823653817176819,
      "learning_rate": 8.181357569232231e-06,
      "loss": 0.1515,
      "step": 11486
    },
    {
      "epoch": 0.181880076634419,
      "grad_norm": 0.00047101863310672343,
      "learning_rate": 8.181199233655812e-06,
      "loss": 0.0,
      "step": 11487
    },
    {
      "epoch": 0.18189591019206106,
      "grad_norm": 0.22863109409809113,
      "learning_rate": 8.181040898079389e-06,
      "loss": 0.0671,
      "step": 11488
    },
    {
      "epoch": 0.18191174374970312,
      "grad_norm": 0.5374069213867188,
      "learning_rate": 8.18088256250297e-06,
      "loss": 0.7451,
      "step": 11489
    },
    {
      "epoch": 0.18192757730734518,
      "grad_norm": 0.37507015466690063,
      "learning_rate": 8.180724226926549e-06,
      "loss": 0.2918,
      "step": 11490
    },
    {
      "epoch": 0.18194341086498725,
      "grad_norm": 0.14316660165786743,
      "learning_rate": 8.180565891350128e-06,
      "loss": 0.0093,
      "step": 11491
    },
    {
      "epoch": 0.1819592444226293,
      "grad_norm": 0.38490965962409973,
      "learning_rate": 8.180407555773707e-06,
      "loss": 0.1639,
      "step": 11492
    },
    {
      "epoch": 0.18197507798027138,
      "grad_norm": 0.10964209586381912,
      "learning_rate": 8.180249220197288e-06,
      "loss": 0.0059,
      "step": 11493
    },
    {
      "epoch": 0.18199091153791344,
      "grad_norm": 0.3120465576648712,
      "learning_rate": 8.180090884620865e-06,
      "loss": 0.0349,
      "step": 11494
    },
    {
      "epoch": 0.18200674509555553,
      "grad_norm": 0.29362112283706665,
      "learning_rate": 8.179932549044446e-06,
      "loss": 0.2402,
      "step": 11495
    },
    {
      "epoch": 0.1820225786531976,
      "grad_norm": 0.06385662406682968,
      "learning_rate": 8.179774213468025e-06,
      "loss": 0.0021,
      "step": 11496
    },
    {
      "epoch": 0.18203841221083966,
      "grad_norm": 0.3227926790714264,
      "learning_rate": 8.179615877891604e-06,
      "loss": 0.1548,
      "step": 11497
    },
    {
      "epoch": 0.18205424576848173,
      "grad_norm": 0.418047696352005,
      "learning_rate": 8.179457542315183e-06,
      "loss": 0.019,
      "step": 11498
    },
    {
      "epoch": 0.1820700793261238,
      "grad_norm": 0.223199263215065,
      "learning_rate": 8.179299206738764e-06,
      "loss": 0.0637,
      "step": 11499
    },
    {
      "epoch": 0.18208591288376585,
      "grad_norm": 0.6080377101898193,
      "learning_rate": 8.179140871162341e-06,
      "loss": 0.2974,
      "step": 11500
    },
    {
      "epoch": 0.18210174644140792,
      "grad_norm": 0.03428446501493454,
      "learning_rate": 8.17898253558592e-06,
      "loss": 0.0015,
      "step": 11501
    },
    {
      "epoch": 0.18211757999904998,
      "grad_norm": 0.7078913450241089,
      "learning_rate": 8.178824200009501e-06,
      "loss": 0.3291,
      "step": 11502
    },
    {
      "epoch": 0.18213341355669205,
      "grad_norm": 0.4604838788509369,
      "learning_rate": 8.17866586443308e-06,
      "loss": 0.2231,
      "step": 11503
    },
    {
      "epoch": 0.1821492471143341,
      "grad_norm": 0.0018384992145001888,
      "learning_rate": 8.17850752885666e-06,
      "loss": 0.0001,
      "step": 11504
    },
    {
      "epoch": 0.18216508067197618,
      "grad_norm": 0.4435446262359619,
      "learning_rate": 8.178349193280238e-06,
      "loss": 0.091,
      "step": 11505
    },
    {
      "epoch": 0.18218091422961824,
      "grad_norm": 0.4452173411846161,
      "learning_rate": 8.178190857703818e-06,
      "loss": 0.289,
      "step": 11506
    },
    {
      "epoch": 0.18219674778726033,
      "grad_norm": 0.29038551449775696,
      "learning_rate": 8.178032522127397e-06,
      "loss": 0.0411,
      "step": 11507
    },
    {
      "epoch": 0.1822125813449024,
      "grad_norm": 0.33096325397491455,
      "learning_rate": 8.177874186550977e-06,
      "loss": 0.1275,
      "step": 11508
    },
    {
      "epoch": 0.18222841490254446,
      "grad_norm": 0.8687466382980347,
      "learning_rate": 8.177715850974556e-06,
      "loss": 0.3814,
      "step": 11509
    },
    {
      "epoch": 0.18224424846018653,
      "grad_norm": 0.39731618762016296,
      "learning_rate": 8.177557515398136e-06,
      "loss": 0.4369,
      "step": 11510
    },
    {
      "epoch": 0.1822600820178286,
      "grad_norm": 0.00015263889508787543,
      "learning_rate": 8.177399179821715e-06,
      "loss": 0.0,
      "step": 11511
    },
    {
      "epoch": 0.18227591557547065,
      "grad_norm": 0.04165748134255409,
      "learning_rate": 8.177240844245294e-06,
      "loss": 0.0015,
      "step": 11512
    },
    {
      "epoch": 0.18229174913311272,
      "grad_norm": 0.00941800232976675,
      "learning_rate": 8.177082508668873e-06,
      "loss": 0.0001,
      "step": 11513
    },
    {
      "epoch": 0.18230758269075478,
      "grad_norm": 0.5587126016616821,
      "learning_rate": 8.176924173092454e-06,
      "loss": 0.2882,
      "step": 11514
    },
    {
      "epoch": 0.18232341624839685,
      "grad_norm": 0.5218611359596252,
      "learning_rate": 8.176765837516033e-06,
      "loss": 0.6318,
      "step": 11515
    },
    {
      "epoch": 0.1823392498060389,
      "grad_norm": 0.00026016728952527046,
      "learning_rate": 8.176607501939612e-06,
      "loss": 0.0,
      "step": 11516
    },
    {
      "epoch": 0.18235508336368098,
      "grad_norm": 0.8120447993278503,
      "learning_rate": 8.17644916636319e-06,
      "loss": 0.1068,
      "step": 11517
    },
    {
      "epoch": 0.18237091692132304,
      "grad_norm": 0.2965979278087616,
      "learning_rate": 8.17629083078677e-06,
      "loss": 0.1503,
      "step": 11518
    },
    {
      "epoch": 0.18238675047896513,
      "grad_norm": 0.08835747838020325,
      "learning_rate": 8.176132495210349e-06,
      "loss": 0.0074,
      "step": 11519
    },
    {
      "epoch": 0.1824025840366072,
      "grad_norm": 0.269191712141037,
      "learning_rate": 8.17597415963393e-06,
      "loss": 0.0991,
      "step": 11520
    },
    {
      "epoch": 0.18241841759424926,
      "grad_norm": 0.1960810422897339,
      "learning_rate": 8.175815824057509e-06,
      "loss": 0.0186,
      "step": 11521
    },
    {
      "epoch": 0.18243425115189132,
      "grad_norm": 0.5305840373039246,
      "learning_rate": 8.175657488481088e-06,
      "loss": 0.4734,
      "step": 11522
    },
    {
      "epoch": 0.1824500847095334,
      "grad_norm": 0.4229133725166321,
      "learning_rate": 8.175499152904667e-06,
      "loss": 0.1271,
      "step": 11523
    },
    {
      "epoch": 0.18246591826717545,
      "grad_norm": 0.4955001771450043,
      "learning_rate": 8.175340817328246e-06,
      "loss": 0.1541,
      "step": 11524
    },
    {
      "epoch": 0.18248175182481752,
      "grad_norm": 0.4097285568714142,
      "learning_rate": 8.175182481751825e-06,
      "loss": 0.1285,
      "step": 11525
    },
    {
      "epoch": 0.18249758538245958,
      "grad_norm": 0.27246999740600586,
      "learning_rate": 8.175024146175404e-06,
      "loss": 0.107,
      "step": 11526
    },
    {
      "epoch": 0.18251341894010165,
      "grad_norm": 0.00013853338896296918,
      "learning_rate": 8.174865810598985e-06,
      "loss": 0.0,
      "step": 11527
    },
    {
      "epoch": 0.1825292524977437,
      "grad_norm": 1.8096973896026611,
      "learning_rate": 8.174707475022562e-06,
      "loss": 0.8126,
      "step": 11528
    },
    {
      "epoch": 0.18254508605538577,
      "grad_norm": 0.19023874402046204,
      "learning_rate": 8.174549139446143e-06,
      "loss": 0.0421,
      "step": 11529
    },
    {
      "epoch": 0.18256091961302784,
      "grad_norm": 0.013131195679306984,
      "learning_rate": 8.174390803869722e-06,
      "loss": 0.0005,
      "step": 11530
    },
    {
      "epoch": 0.18257675317066993,
      "grad_norm": 0.33770620822906494,
      "learning_rate": 8.174232468293301e-06,
      "loss": 0.1121,
      "step": 11531
    },
    {
      "epoch": 0.182592586728312,
      "grad_norm": 0.28101739287376404,
      "learning_rate": 8.17407413271688e-06,
      "loss": 0.1052,
      "step": 11532
    },
    {
      "epoch": 0.18260842028595406,
      "grad_norm": 0.023346276953816414,
      "learning_rate": 8.173915797140461e-06,
      "loss": 0.0012,
      "step": 11533
    },
    {
      "epoch": 0.18262425384359612,
      "grad_norm": 0.004874106030911207,
      "learning_rate": 8.173757461564039e-06,
      "loss": 0.0002,
      "step": 11534
    },
    {
      "epoch": 0.1826400874012382,
      "grad_norm": 0.47303974628448486,
      "learning_rate": 8.17359912598762e-06,
      "loss": 0.1605,
      "step": 11535
    },
    {
      "epoch": 0.18265592095888025,
      "grad_norm": 0.006559513509273529,
      "learning_rate": 8.173440790411198e-06,
      "loss": 0.0003,
      "step": 11536
    },
    {
      "epoch": 0.18267175451652232,
      "grad_norm": 0.16349680721759796,
      "learning_rate": 8.173282454834777e-06,
      "loss": 0.0614,
      "step": 11537
    },
    {
      "epoch": 0.18268758807416438,
      "grad_norm": 0.30370214581489563,
      "learning_rate": 8.173124119258357e-06,
      "loss": 0.1754,
      "step": 11538
    },
    {
      "epoch": 0.18270342163180645,
      "grad_norm": 0.00043963309144601226,
      "learning_rate": 8.172965783681937e-06,
      "loss": 0.0,
      "step": 11539
    },
    {
      "epoch": 0.1827192551894485,
      "grad_norm": 0.4051496684551239,
      "learning_rate": 8.172807448105515e-06,
      "loss": 0.0721,
      "step": 11540
    },
    {
      "epoch": 0.18273508874709057,
      "grad_norm": 0.2955292761325836,
      "learning_rate": 8.172649112529095e-06,
      "loss": 0.1004,
      "step": 11541
    },
    {
      "epoch": 0.18275092230473264,
      "grad_norm": 0.1603560894727707,
      "learning_rate": 8.172490776952675e-06,
      "loss": 0.0577,
      "step": 11542
    },
    {
      "epoch": 0.18276675586237473,
      "grad_norm": 0.0012215920723974705,
      "learning_rate": 8.172332441376254e-06,
      "loss": 0.0,
      "step": 11543
    },
    {
      "epoch": 0.1827825894200168,
      "grad_norm": 0.13268022239208221,
      "learning_rate": 8.172174105799833e-06,
      "loss": 0.0138,
      "step": 11544
    },
    {
      "epoch": 0.18279842297765886,
      "grad_norm": 0.3332451581954956,
      "learning_rate": 8.172015770223412e-06,
      "loss": 0.1242,
      "step": 11545
    },
    {
      "epoch": 0.18281425653530092,
      "grad_norm": 0.9679821133613586,
      "learning_rate": 8.171857434646991e-06,
      "loss": 0.8742,
      "step": 11546
    },
    {
      "epoch": 0.182830090092943,
      "grad_norm": 0.5100637674331665,
      "learning_rate": 8.171699099070572e-06,
      "loss": 0.1224,
      "step": 11547
    },
    {
      "epoch": 0.18284592365058505,
      "grad_norm": 0.3221127986907959,
      "learning_rate": 8.17154076349415e-06,
      "loss": 0.1173,
      "step": 11548
    },
    {
      "epoch": 0.18286175720822712,
      "grad_norm": 0.28088319301605225,
      "learning_rate": 8.171382427917728e-06,
      "loss": 0.1825,
      "step": 11549
    },
    {
      "epoch": 0.18287759076586918,
      "grad_norm": 2.0497682094573975,
      "learning_rate": 8.171224092341309e-06,
      "loss": 0.1231,
      "step": 11550
    },
    {
      "epoch": 0.18289342432351124,
      "grad_norm": 0.32931965589523315,
      "learning_rate": 8.171065756764888e-06,
      "loss": 0.1479,
      "step": 11551
    },
    {
      "epoch": 0.1829092578811533,
      "grad_norm": 0.14832662045955658,
      "learning_rate": 8.170907421188467e-06,
      "loss": 0.0707,
      "step": 11552
    },
    {
      "epoch": 0.18292509143879537,
      "grad_norm": 0.2818770110607147,
      "learning_rate": 8.170749085612046e-06,
      "loss": 0.1073,
      "step": 11553
    },
    {
      "epoch": 0.18294092499643744,
      "grad_norm": 0.5780758261680603,
      "learning_rate": 8.170590750035627e-06,
      "loss": 0.2615,
      "step": 11554
    },
    {
      "epoch": 0.18295675855407953,
      "grad_norm": 0.1709221452474594,
      "learning_rate": 8.170432414459204e-06,
      "loss": 0.0797,
      "step": 11555
    },
    {
      "epoch": 0.1829725921117216,
      "grad_norm": 0.01830250769853592,
      "learning_rate": 8.170274078882785e-06,
      "loss": 0.0007,
      "step": 11556
    },
    {
      "epoch": 0.18298842566936366,
      "grad_norm": 0.39531049132347107,
      "learning_rate": 8.170115743306364e-06,
      "loss": 0.049,
      "step": 11557
    },
    {
      "epoch": 0.18300425922700572,
      "grad_norm": 0.008247149176895618,
      "learning_rate": 8.169957407729943e-06,
      "loss": 0.0003,
      "step": 11558
    },
    {
      "epoch": 0.1830200927846478,
      "grad_norm": 0.01867356151342392,
      "learning_rate": 8.169799072153522e-06,
      "loss": 0.0007,
      "step": 11559
    },
    {
      "epoch": 0.18303592634228985,
      "grad_norm": 0.12402501702308655,
      "learning_rate": 8.169640736577103e-06,
      "loss": 0.0536,
      "step": 11560
    },
    {
      "epoch": 0.18305175989993192,
      "grad_norm": 0.41008952260017395,
      "learning_rate": 8.16948240100068e-06,
      "loss": 0.2888,
      "step": 11561
    },
    {
      "epoch": 0.18306759345757398,
      "grad_norm": 0.24176573753356934,
      "learning_rate": 8.169324065424261e-06,
      "loss": 0.061,
      "step": 11562
    },
    {
      "epoch": 0.18308342701521604,
      "grad_norm": 0.018345506861805916,
      "learning_rate": 8.16916572984784e-06,
      "loss": 0.0009,
      "step": 11563
    },
    {
      "epoch": 0.1830992605728581,
      "grad_norm": 0.19047687947750092,
      "learning_rate": 8.16900739427142e-06,
      "loss": 0.0678,
      "step": 11564
    },
    {
      "epoch": 0.18311509413050017,
      "grad_norm": 0.3297586441040039,
      "learning_rate": 8.168849058694998e-06,
      "loss": 0.0697,
      "step": 11565
    },
    {
      "epoch": 0.18313092768814224,
      "grad_norm": 0.06565850973129272,
      "learning_rate": 8.16869072311858e-06,
      "loss": 0.0027,
      "step": 11566
    },
    {
      "epoch": 0.18314676124578433,
      "grad_norm": 0.010469991713762283,
      "learning_rate": 8.168532387542157e-06,
      "loss": 0.0004,
      "step": 11567
    },
    {
      "epoch": 0.1831625948034264,
      "grad_norm": 0.2605842053890228,
      "learning_rate": 8.168374051965737e-06,
      "loss": 0.0974,
      "step": 11568
    },
    {
      "epoch": 0.18317842836106846,
      "grad_norm": 0.3555244505405426,
      "learning_rate": 8.168215716389316e-06,
      "loss": 0.1744,
      "step": 11569
    },
    {
      "epoch": 0.18319426191871052,
      "grad_norm": 0.5652647614479065,
      "learning_rate": 8.168057380812896e-06,
      "loss": 0.0901,
      "step": 11570
    },
    {
      "epoch": 0.18321009547635259,
      "grad_norm": 0.0030143512412905693,
      "learning_rate": 8.167899045236475e-06,
      "loss": 0.0,
      "step": 11571
    },
    {
      "epoch": 0.18322592903399465,
      "grad_norm": 0.0006700524827465415,
      "learning_rate": 8.167740709660055e-06,
      "loss": 0.0,
      "step": 11572
    },
    {
      "epoch": 0.18324176259163671,
      "grad_norm": 0.47418299317359924,
      "learning_rate": 8.167582374083633e-06,
      "loss": 0.5319,
      "step": 11573
    },
    {
      "epoch": 0.18325759614927878,
      "grad_norm": 0.5166174173355103,
      "learning_rate": 8.167424038507212e-06,
      "loss": 0.5212,
      "step": 11574
    },
    {
      "epoch": 0.18327342970692084,
      "grad_norm": 0.3127952814102173,
      "learning_rate": 8.167265702930793e-06,
      "loss": 0.1306,
      "step": 11575
    },
    {
      "epoch": 0.1832892632645629,
      "grad_norm": 0.2956380546092987,
      "learning_rate": 8.167107367354372e-06,
      "loss": 0.0327,
      "step": 11576
    },
    {
      "epoch": 0.18330509682220497,
      "grad_norm": 0.39348602294921875,
      "learning_rate": 8.16694903177795e-06,
      "loss": 0.1061,
      "step": 11577
    },
    {
      "epoch": 0.18332093037984704,
      "grad_norm": 0.47297540307044983,
      "learning_rate": 8.16679069620153e-06,
      "loss": 0.0861,
      "step": 11578
    },
    {
      "epoch": 0.18333676393748913,
      "grad_norm": 0.00011167107004439458,
      "learning_rate": 8.166632360625109e-06,
      "loss": 0.0,
      "step": 11579
    },
    {
      "epoch": 0.1833525974951312,
      "grad_norm": 0.3791182041168213,
      "learning_rate": 8.166474025048688e-06,
      "loss": 0.2339,
      "step": 11580
    },
    {
      "epoch": 0.18336843105277326,
      "grad_norm": 1.086713433265686,
      "learning_rate": 8.166315689472269e-06,
      "loss": 0.0546,
      "step": 11581
    },
    {
      "epoch": 0.18338426461041532,
      "grad_norm": 0.00012706444249488413,
      "learning_rate": 8.166157353895848e-06,
      "loss": 0.0,
      "step": 11582
    },
    {
      "epoch": 0.18340009816805738,
      "grad_norm": 1.2920691967010498,
      "learning_rate": 8.165999018319427e-06,
      "loss": 0.3399,
      "step": 11583
    },
    {
      "epoch": 0.18341593172569945,
      "grad_norm": 0.08412472903728485,
      "learning_rate": 8.165840682743006e-06,
      "loss": 0.0323,
      "step": 11584
    },
    {
      "epoch": 0.1834317652833415,
      "grad_norm": 0.14756882190704346,
      "learning_rate": 8.165682347166585e-06,
      "loss": 0.0375,
      "step": 11585
    },
    {
      "epoch": 0.18344759884098358,
      "grad_norm": 0.41714420914649963,
      "learning_rate": 8.165524011590164e-06,
      "loss": 0.2127,
      "step": 11586
    },
    {
      "epoch": 0.18346343239862564,
      "grad_norm": 0.0032683706376701593,
      "learning_rate": 8.165365676013745e-06,
      "loss": 0.0001,
      "step": 11587
    },
    {
      "epoch": 0.1834792659562677,
      "grad_norm": 0.16817736625671387,
      "learning_rate": 8.165207340437324e-06,
      "loss": 0.0118,
      "step": 11588
    },
    {
      "epoch": 0.18349509951390977,
      "grad_norm": 0.35369908809661865,
      "learning_rate": 8.165049004860903e-06,
      "loss": 0.1008,
      "step": 11589
    },
    {
      "epoch": 0.18351093307155183,
      "grad_norm": 0.20501850545406342,
      "learning_rate": 8.164890669284482e-06,
      "loss": 0.0449,
      "step": 11590
    },
    {
      "epoch": 0.18352676662919393,
      "grad_norm": 0.38054877519607544,
      "learning_rate": 8.164732333708061e-06,
      "loss": 0.2886,
      "step": 11591
    },
    {
      "epoch": 0.183542600186836,
      "grad_norm": 0.36740586161613464,
      "learning_rate": 8.16457399813164e-06,
      "loss": 0.3264,
      "step": 11592
    },
    {
      "epoch": 0.18355843374447806,
      "grad_norm": 0.1736198514699936,
      "learning_rate": 8.164415662555221e-06,
      "loss": 0.0159,
      "step": 11593
    },
    {
      "epoch": 0.18357426730212012,
      "grad_norm": 0.6439805030822754,
      "learning_rate": 8.1642573269788e-06,
      "loss": 0.3887,
      "step": 11594
    },
    {
      "epoch": 0.18359010085976218,
      "grad_norm": 0.01593482308089733,
      "learning_rate": 8.16409899140238e-06,
      "loss": 0.0005,
      "step": 11595
    },
    {
      "epoch": 0.18360593441740425,
      "grad_norm": 0.18724223971366882,
      "learning_rate": 8.163940655825958e-06,
      "loss": 0.0752,
      "step": 11596
    },
    {
      "epoch": 0.1836217679750463,
      "grad_norm": 0.21532820165157318,
      "learning_rate": 8.163782320249538e-06,
      "loss": 0.0448,
      "step": 11597
    },
    {
      "epoch": 0.18363760153268838,
      "grad_norm": 5.833755130879581e-05,
      "learning_rate": 8.163623984673117e-06,
      "loss": 0.0,
      "step": 11598
    },
    {
      "epoch": 0.18365343509033044,
      "grad_norm": 0.05011073127388954,
      "learning_rate": 8.163465649096696e-06,
      "loss": 0.0015,
      "step": 11599
    },
    {
      "epoch": 0.1836692686479725,
      "grad_norm": 0.2255854457616806,
      "learning_rate": 8.163307313520276e-06,
      "loss": 0.0401,
      "step": 11600
    },
    {
      "epoch": 0.18368510220561457,
      "grad_norm": 0.02335156686604023,
      "learning_rate": 8.163148977943854e-06,
      "loss": 0.0009,
      "step": 11601
    },
    {
      "epoch": 0.18370093576325663,
      "grad_norm": 0.00011870158778037876,
      "learning_rate": 8.162990642367435e-06,
      "loss": 0.0,
      "step": 11602
    },
    {
      "epoch": 0.18371676932089873,
      "grad_norm": 0.37288278341293335,
      "learning_rate": 8.162832306791014e-06,
      "loss": 0.062,
      "step": 11603
    },
    {
      "epoch": 0.1837326028785408,
      "grad_norm": 0.6987862586975098,
      "learning_rate": 8.162673971214593e-06,
      "loss": 0.918,
      "step": 11604
    },
    {
      "epoch": 0.18374843643618285,
      "grad_norm": 0.7869736552238464,
      "learning_rate": 8.162515635638172e-06,
      "loss": 0.1658,
      "step": 11605
    },
    {
      "epoch": 0.18376426999382492,
      "grad_norm": 0.31877386569976807,
      "learning_rate": 8.162357300061751e-06,
      "loss": 0.1442,
      "step": 11606
    },
    {
      "epoch": 0.18378010355146698,
      "grad_norm": 0.3856462836265564,
      "learning_rate": 8.16219896448533e-06,
      "loss": 0.095,
      "step": 11607
    },
    {
      "epoch": 0.18379593710910905,
      "grad_norm": 0.016552379354834557,
      "learning_rate": 8.16204062890891e-06,
      "loss": 0.0006,
      "step": 11608
    },
    {
      "epoch": 0.1838117706667511,
      "grad_norm": 0.39125537872314453,
      "learning_rate": 8.16188229333249e-06,
      "loss": 0.1851,
      "step": 11609
    },
    {
      "epoch": 0.18382760422439318,
      "grad_norm": 1.057308316230774,
      "learning_rate": 8.161723957756069e-06,
      "loss": 0.524,
      "step": 11610
    },
    {
      "epoch": 0.18384343778203524,
      "grad_norm": 0.44572973251342773,
      "learning_rate": 8.161565622179648e-06,
      "loss": 0.1922,
      "step": 11611
    },
    {
      "epoch": 0.1838592713396773,
      "grad_norm": 0.4393160045146942,
      "learning_rate": 8.161407286603227e-06,
      "loss": 0.0871,
      "step": 11612
    },
    {
      "epoch": 0.18387510489731937,
      "grad_norm": 0.3246760964393616,
      "learning_rate": 8.161248951026806e-06,
      "loss": 0.1462,
      "step": 11613
    },
    {
      "epoch": 0.18389093845496143,
      "grad_norm": 0.25302520394325256,
      "learning_rate": 8.161090615450387e-06,
      "loss": 0.0318,
      "step": 11614
    },
    {
      "epoch": 0.18390677201260353,
      "grad_norm": 0.40310606360435486,
      "learning_rate": 8.160932279873966e-06,
      "loss": 0.2168,
      "step": 11615
    },
    {
      "epoch": 0.1839226055702456,
      "grad_norm": 0.1762225329875946,
      "learning_rate": 8.160773944297545e-06,
      "loss": 0.0397,
      "step": 11616
    },
    {
      "epoch": 0.18393843912788765,
      "grad_norm": 0.18433962762355804,
      "learning_rate": 8.160615608721124e-06,
      "loss": 0.052,
      "step": 11617
    },
    {
      "epoch": 0.18395427268552972,
      "grad_norm": 0.536790668964386,
      "learning_rate": 8.160457273144703e-06,
      "loss": 0.1177,
      "step": 11618
    },
    {
      "epoch": 0.18397010624317178,
      "grad_norm": 0.7402573823928833,
      "learning_rate": 8.160298937568282e-06,
      "loss": 0.485,
      "step": 11619
    },
    {
      "epoch": 0.18398593980081385,
      "grad_norm": 0.4307660758495331,
      "learning_rate": 8.160140601991863e-06,
      "loss": 0.0956,
      "step": 11620
    },
    {
      "epoch": 0.1840017733584559,
      "grad_norm": 0.251247376203537,
      "learning_rate": 8.159982266415442e-06,
      "loss": 0.1011,
      "step": 11621
    },
    {
      "epoch": 0.18401760691609798,
      "grad_norm": 0.6583631038665771,
      "learning_rate": 8.15982393083902e-06,
      "loss": 0.3871,
      "step": 11622
    },
    {
      "epoch": 0.18403344047374004,
      "grad_norm": 0.2621731758117676,
      "learning_rate": 8.1596655952626e-06,
      "loss": 0.1157,
      "step": 11623
    },
    {
      "epoch": 0.1840492740313821,
      "grad_norm": 0.3547966182231903,
      "learning_rate": 8.15950725968618e-06,
      "loss": 0.2132,
      "step": 11624
    },
    {
      "epoch": 0.18406510758902417,
      "grad_norm": 0.2633885443210602,
      "learning_rate": 8.159348924109759e-06,
      "loss": 0.1807,
      "step": 11625
    },
    {
      "epoch": 0.18408094114666623,
      "grad_norm": 0.36142516136169434,
      "learning_rate": 8.159190588533338e-06,
      "loss": 0.1004,
      "step": 11626
    },
    {
      "epoch": 0.18409677470430832,
      "grad_norm": 0.27603641152381897,
      "learning_rate": 8.159032252956918e-06,
      "loss": 0.0872,
      "step": 11627
    },
    {
      "epoch": 0.1841126082619504,
      "grad_norm": 0.34161967039108276,
      "learning_rate": 8.158873917380496e-06,
      "loss": 0.0077,
      "step": 11628
    },
    {
      "epoch": 0.18412844181959245,
      "grad_norm": 2.1892871856689453,
      "learning_rate": 8.158715581804077e-06,
      "loss": 0.9224,
      "step": 11629
    },
    {
      "epoch": 0.18414427537723452,
      "grad_norm": 0.31648075580596924,
      "learning_rate": 8.158557246227656e-06,
      "loss": 0.0875,
      "step": 11630
    },
    {
      "epoch": 0.18416010893487658,
      "grad_norm": 0.007558646611869335,
      "learning_rate": 8.158398910651235e-06,
      "loss": 0.0002,
      "step": 11631
    },
    {
      "epoch": 0.18417594249251865,
      "grad_norm": 0.1880994737148285,
      "learning_rate": 8.158240575074814e-06,
      "loss": 0.0365,
      "step": 11632
    },
    {
      "epoch": 0.1841917760501607,
      "grad_norm": 0.010231789201498032,
      "learning_rate": 8.158082239498395e-06,
      "loss": 0.0004,
      "step": 11633
    },
    {
      "epoch": 0.18420760960780277,
      "grad_norm": 0.00013045922969467938,
      "learning_rate": 8.157923903921972e-06,
      "loss": 0.0,
      "step": 11634
    },
    {
      "epoch": 0.18422344316544484,
      "grad_norm": 0.3069758713245392,
      "learning_rate": 8.157765568345553e-06,
      "loss": 0.0713,
      "step": 11635
    },
    {
      "epoch": 0.1842392767230869,
      "grad_norm": 0.058416832238435745,
      "learning_rate": 8.157607232769132e-06,
      "loss": 0.0015,
      "step": 11636
    },
    {
      "epoch": 0.18425511028072897,
      "grad_norm": 0.42456603050231934,
      "learning_rate": 8.157448897192711e-06,
      "loss": 0.1453,
      "step": 11637
    },
    {
      "epoch": 0.18427094383837103,
      "grad_norm": 0.33178311586380005,
      "learning_rate": 8.15729056161629e-06,
      "loss": 0.0897,
      "step": 11638
    },
    {
      "epoch": 0.18428677739601312,
      "grad_norm": 0.006600049324333668,
      "learning_rate": 8.15713222603987e-06,
      "loss": 0.0001,
      "step": 11639
    },
    {
      "epoch": 0.1843026109536552,
      "grad_norm": 0.4263046681880951,
      "learning_rate": 8.156973890463448e-06,
      "loss": 0.2527,
      "step": 11640
    },
    {
      "epoch": 0.18431844451129725,
      "grad_norm": 0.5515180826187134,
      "learning_rate": 8.156815554887029e-06,
      "loss": 0.0233,
      "step": 11641
    },
    {
      "epoch": 0.18433427806893932,
      "grad_norm": 0.8014606833457947,
      "learning_rate": 8.156657219310608e-06,
      "loss": 0.095,
      "step": 11642
    },
    {
      "epoch": 0.18435011162658138,
      "grad_norm": 0.052369941025972366,
      "learning_rate": 8.156498883734187e-06,
      "loss": 0.0021,
      "step": 11643
    },
    {
      "epoch": 0.18436594518422345,
      "grad_norm": 1.0764955282211304,
      "learning_rate": 8.156340548157766e-06,
      "loss": 0.196,
      "step": 11644
    },
    {
      "epoch": 0.1843817787418655,
      "grad_norm": 0.0013085553655400872,
      "learning_rate": 8.156182212581345e-06,
      "loss": 0.0,
      "step": 11645
    },
    {
      "epoch": 0.18439761229950757,
      "grad_norm": 0.43230485916137695,
      "learning_rate": 8.156023877004924e-06,
      "loss": 0.2358,
      "step": 11646
    },
    {
      "epoch": 0.18441344585714964,
      "grad_norm": 0.622565746307373,
      "learning_rate": 8.155865541428503e-06,
      "loss": 0.6786,
      "step": 11647
    },
    {
      "epoch": 0.1844292794147917,
      "grad_norm": 0.31545308232307434,
      "learning_rate": 8.155707205852084e-06,
      "loss": 0.09,
      "step": 11648
    },
    {
      "epoch": 0.18444511297243377,
      "grad_norm": 0.7033388018608093,
      "learning_rate": 8.155548870275663e-06,
      "loss": 0.3206,
      "step": 11649
    },
    {
      "epoch": 0.18446094653007583,
      "grad_norm": 0.40778008103370667,
      "learning_rate": 8.155390534699242e-06,
      "loss": 0.101,
      "step": 11650
    },
    {
      "epoch": 0.18447678008771792,
      "grad_norm": 0.49037954211235046,
      "learning_rate": 8.155232199122821e-06,
      "loss": 0.1519,
      "step": 11651
    },
    {
      "epoch": 0.18449261364536,
      "grad_norm": 0.6943938732147217,
      "learning_rate": 8.1550738635464e-06,
      "loss": 0.4262,
      "step": 11652
    },
    {
      "epoch": 0.18450844720300205,
      "grad_norm": 6.769967149011791e-05,
      "learning_rate": 8.15491552796998e-06,
      "loss": 0.0,
      "step": 11653
    },
    {
      "epoch": 0.18452428076064412,
      "grad_norm": 0.021979916840791702,
      "learning_rate": 8.15475719239356e-06,
      "loss": 0.0011,
      "step": 11654
    },
    {
      "epoch": 0.18454011431828618,
      "grad_norm": 0.015784041956067085,
      "learning_rate": 8.15459885681714e-06,
      "loss": 0.0008,
      "step": 11655
    },
    {
      "epoch": 0.18455594787592824,
      "grad_norm": 0.8278996348381042,
      "learning_rate": 8.154440521240718e-06,
      "loss": 0.4105,
      "step": 11656
    },
    {
      "epoch": 0.1845717814335703,
      "grad_norm": 0.2037838250398636,
      "learning_rate": 8.154282185664298e-06,
      "loss": 0.0418,
      "step": 11657
    },
    {
      "epoch": 0.18458761499121237,
      "grad_norm": 0.672516405582428,
      "learning_rate": 8.154123850087877e-06,
      "loss": 0.4239,
      "step": 11658
    },
    {
      "epoch": 0.18460344854885444,
      "grad_norm": 0.07633271813392639,
      "learning_rate": 8.153965514511456e-06,
      "loss": 0.004,
      "step": 11659
    },
    {
      "epoch": 0.1846192821064965,
      "grad_norm": 2.4621002674102783,
      "learning_rate": 8.153807178935036e-06,
      "loss": 0.0918,
      "step": 11660
    },
    {
      "epoch": 0.18463511566413857,
      "grad_norm": 0.52838534116745,
      "learning_rate": 8.153648843358616e-06,
      "loss": 0.7901,
      "step": 11661
    },
    {
      "epoch": 0.18465094922178063,
      "grad_norm": 0.3028658330440521,
      "learning_rate": 8.153490507782195e-06,
      "loss": 0.2319,
      "step": 11662
    },
    {
      "epoch": 0.18466678277942272,
      "grad_norm": 1.0510503053665161,
      "learning_rate": 8.153332172205774e-06,
      "loss": 0.6379,
      "step": 11663
    },
    {
      "epoch": 0.1846826163370648,
      "grad_norm": 0.0037217901553958654,
      "learning_rate": 8.153173836629353e-06,
      "loss": 0.0002,
      "step": 11664
    },
    {
      "epoch": 0.18469844989470685,
      "grad_norm": 0.009061535820364952,
      "learning_rate": 8.153015501052932e-06,
      "loss": 0.0003,
      "step": 11665
    },
    {
      "epoch": 0.18471428345234892,
      "grad_norm": 0.6653086543083191,
      "learning_rate": 8.152857165476513e-06,
      "loss": 0.3458,
      "step": 11666
    },
    {
      "epoch": 0.18473011700999098,
      "grad_norm": 0.26945221424102783,
      "learning_rate": 8.152698829900092e-06,
      "loss": 0.0756,
      "step": 11667
    },
    {
      "epoch": 0.18474595056763304,
      "grad_norm": 0.0027687919791787863,
      "learning_rate": 8.15254049432367e-06,
      "loss": 0.0001,
      "step": 11668
    },
    {
      "epoch": 0.1847617841252751,
      "grad_norm": 0.45704376697540283,
      "learning_rate": 8.15238215874725e-06,
      "loss": 0.0601,
      "step": 11669
    },
    {
      "epoch": 0.18477761768291717,
      "grad_norm": 0.6073071956634521,
      "learning_rate": 8.152223823170829e-06,
      "loss": 0.1851,
      "step": 11670
    },
    {
      "epoch": 0.18479345124055924,
      "grad_norm": 0.4101390242576599,
      "learning_rate": 8.152065487594408e-06,
      "loss": 0.1411,
      "step": 11671
    },
    {
      "epoch": 0.1848092847982013,
      "grad_norm": 0.017343495041131973,
      "learning_rate": 8.151907152017987e-06,
      "loss": 0.0007,
      "step": 11672
    },
    {
      "epoch": 0.18482511835584337,
      "grad_norm": 0.5299403667449951,
      "learning_rate": 8.151748816441566e-06,
      "loss": 0.3983,
      "step": 11673
    },
    {
      "epoch": 0.18484095191348543,
      "grad_norm": 0.0007020320044830441,
      "learning_rate": 8.151590480865145e-06,
      "loss": 0.0,
      "step": 11674
    },
    {
      "epoch": 0.1848567854711275,
      "grad_norm": 0.6931485533714294,
      "learning_rate": 8.151432145288726e-06,
      "loss": 0.3666,
      "step": 11675
    },
    {
      "epoch": 0.18487261902876959,
      "grad_norm": 0.00978083536028862,
      "learning_rate": 8.151273809712305e-06,
      "loss": 0.0005,
      "step": 11676
    },
    {
      "epoch": 0.18488845258641165,
      "grad_norm": 0.4202931821346283,
      "learning_rate": 8.151115474135884e-06,
      "loss": 0.0877,
      "step": 11677
    },
    {
      "epoch": 0.18490428614405371,
      "grad_norm": 0.5132095217704773,
      "learning_rate": 8.150957138559463e-06,
      "loss": 0.7713,
      "step": 11678
    },
    {
      "epoch": 0.18492011970169578,
      "grad_norm": 0.00018000006093643606,
      "learning_rate": 8.150798802983042e-06,
      "loss": 0.0,
      "step": 11679
    },
    {
      "epoch": 0.18493595325933784,
      "grad_norm": 0.3233697712421417,
      "learning_rate": 8.150640467406621e-06,
      "loss": 0.1505,
      "step": 11680
    },
    {
      "epoch": 0.1849517868169799,
      "grad_norm": 0.0027457510586827993,
      "learning_rate": 8.150482131830202e-06,
      "loss": 0.0001,
      "step": 11681
    },
    {
      "epoch": 0.18496762037462197,
      "grad_norm": 0.007525148335844278,
      "learning_rate": 8.150323796253781e-06,
      "loss": 0.0003,
      "step": 11682
    },
    {
      "epoch": 0.18498345393226404,
      "grad_norm": 0.25822004675865173,
      "learning_rate": 8.15016546067736e-06,
      "loss": 0.0919,
      "step": 11683
    },
    {
      "epoch": 0.1849992874899061,
      "grad_norm": 0.5680718421936035,
      "learning_rate": 8.15000712510094e-06,
      "loss": 0.1151,
      "step": 11684
    },
    {
      "epoch": 0.18501512104754816,
      "grad_norm": 0.5753698945045471,
      "learning_rate": 8.149848789524519e-06,
      "loss": 0.1222,
      "step": 11685
    },
    {
      "epoch": 0.18503095460519023,
      "grad_norm": 0.39637473225593567,
      "learning_rate": 8.149690453948098e-06,
      "loss": 0.1355,
      "step": 11686
    },
    {
      "epoch": 0.1850467881628323,
      "grad_norm": 0.16373196244239807,
      "learning_rate": 8.149532118371678e-06,
      "loss": 0.1164,
      "step": 11687
    },
    {
      "epoch": 0.18506262172047439,
      "grad_norm": 0.4679023027420044,
      "learning_rate": 8.149373782795257e-06,
      "loss": 0.1777,
      "step": 11688
    },
    {
      "epoch": 0.18507845527811645,
      "grad_norm": 0.2642408311367035,
      "learning_rate": 8.149215447218837e-06,
      "loss": 0.1703,
      "step": 11689
    },
    {
      "epoch": 0.1850942888357585,
      "grad_norm": 0.008866299875080585,
      "learning_rate": 8.149057111642416e-06,
      "loss": 0.0004,
      "step": 11690
    },
    {
      "epoch": 0.18511012239340058,
      "grad_norm": 0.34804362058639526,
      "learning_rate": 8.148898776065995e-06,
      "loss": 0.0724,
      "step": 11691
    },
    {
      "epoch": 0.18512595595104264,
      "grad_norm": 0.43590158224105835,
      "learning_rate": 8.148740440489574e-06,
      "loss": 0.3587,
      "step": 11692
    },
    {
      "epoch": 0.1851417895086847,
      "grad_norm": 0.1256984919309616,
      "learning_rate": 8.148582104913155e-06,
      "loss": 0.0477,
      "step": 11693
    },
    {
      "epoch": 0.18515762306632677,
      "grad_norm": 0.7138510942459106,
      "learning_rate": 8.148423769336734e-06,
      "loss": 0.5996,
      "step": 11694
    },
    {
      "epoch": 0.18517345662396884,
      "grad_norm": 0.35017672181129456,
      "learning_rate": 8.148265433760311e-06,
      "loss": 0.2206,
      "step": 11695
    },
    {
      "epoch": 0.1851892901816109,
      "grad_norm": 0.21809054911136627,
      "learning_rate": 8.148107098183892e-06,
      "loss": 0.094,
      "step": 11696
    },
    {
      "epoch": 0.18520512373925296,
      "grad_norm": 0.26492929458618164,
      "learning_rate": 8.147948762607471e-06,
      "loss": 0.0511,
      "step": 11697
    },
    {
      "epoch": 0.18522095729689503,
      "grad_norm": 1.7545738220214844,
      "learning_rate": 8.14779042703105e-06,
      "loss": 0.2398,
      "step": 11698
    },
    {
      "epoch": 0.1852367908545371,
      "grad_norm": 0.2868362367153168,
      "learning_rate": 8.147632091454629e-06,
      "loss": 0.1364,
      "step": 11699
    },
    {
      "epoch": 0.18525262441217918,
      "grad_norm": 0.3624442219734192,
      "learning_rate": 8.14747375587821e-06,
      "loss": 0.0757,
      "step": 11700
    },
    {
      "epoch": 0.18526845796982125,
      "grad_norm": 0.29431650042533875,
      "learning_rate": 8.147315420301787e-06,
      "loss": 0.1565,
      "step": 11701
    },
    {
      "epoch": 0.1852842915274633,
      "grad_norm": 0.3969404399394989,
      "learning_rate": 8.147157084725368e-06,
      "loss": 0.1855,
      "step": 11702
    },
    {
      "epoch": 0.18530012508510538,
      "grad_norm": 0.19024509191513062,
      "learning_rate": 8.146998749148947e-06,
      "loss": 0.0397,
      "step": 11703
    },
    {
      "epoch": 0.18531595864274744,
      "grad_norm": 0.011697460897266865,
      "learning_rate": 8.146840413572526e-06,
      "loss": 0.0003,
      "step": 11704
    },
    {
      "epoch": 0.1853317922003895,
      "grad_norm": 0.19638344645500183,
      "learning_rate": 8.146682077996105e-06,
      "loss": 0.0621,
      "step": 11705
    },
    {
      "epoch": 0.18534762575803157,
      "grad_norm": 0.003147619077935815,
      "learning_rate": 8.146523742419686e-06,
      "loss": 0.0001,
      "step": 11706
    },
    {
      "epoch": 0.18536345931567363,
      "grad_norm": 0.003095705062150955,
      "learning_rate": 8.146365406843263e-06,
      "loss": 0.0001,
      "step": 11707
    },
    {
      "epoch": 0.1853792928733157,
      "grad_norm": 0.008828703314065933,
      "learning_rate": 8.146207071266844e-06,
      "loss": 0.0004,
      "step": 11708
    },
    {
      "epoch": 0.18539512643095776,
      "grad_norm": 0.011208879761397839,
      "learning_rate": 8.146048735690423e-06,
      "loss": 0.0005,
      "step": 11709
    },
    {
      "epoch": 0.18541095998859983,
      "grad_norm": 0.2587572932243347,
      "learning_rate": 8.145890400114002e-06,
      "loss": 0.0591,
      "step": 11710
    },
    {
      "epoch": 0.1854267935462419,
      "grad_norm": 0.17318019270896912,
      "learning_rate": 8.145732064537581e-06,
      "loss": 0.0669,
      "step": 11711
    },
    {
      "epoch": 0.18544262710388398,
      "grad_norm": 0.00019067738321609795,
      "learning_rate": 8.145573728961162e-06,
      "loss": 0.0,
      "step": 11712
    },
    {
      "epoch": 0.18545846066152605,
      "grad_norm": 0.0005578940035775304,
      "learning_rate": 8.14541539338474e-06,
      "loss": 0.0,
      "step": 11713
    },
    {
      "epoch": 0.1854742942191681,
      "grad_norm": 0.11226364225149155,
      "learning_rate": 8.14525705780832e-06,
      "loss": 0.0077,
      "step": 11714
    },
    {
      "epoch": 0.18549012777681018,
      "grad_norm": 0.47946491837501526,
      "learning_rate": 8.1450987222319e-06,
      "loss": 0.1086,
      "step": 11715
    },
    {
      "epoch": 0.18550596133445224,
      "grad_norm": 0.32211607694625854,
      "learning_rate": 8.144940386655478e-06,
      "loss": 0.1302,
      "step": 11716
    },
    {
      "epoch": 0.1855217948920943,
      "grad_norm": 0.02489764243364334,
      "learning_rate": 8.144782051079058e-06,
      "loss": 0.0009,
      "step": 11717
    },
    {
      "epoch": 0.18553762844973637,
      "grad_norm": 0.33668190240859985,
      "learning_rate": 8.144623715502637e-06,
      "loss": 0.2601,
      "step": 11718
    },
    {
      "epoch": 0.18555346200737843,
      "grad_norm": 0.6537832617759705,
      "learning_rate": 8.144465379926216e-06,
      "loss": 0.9609,
      "step": 11719
    },
    {
      "epoch": 0.1855692955650205,
      "grad_norm": 9.974231943488121e-05,
      "learning_rate": 8.144307044349795e-06,
      "loss": 0.0,
      "step": 11720
    },
    {
      "epoch": 0.18558512912266256,
      "grad_norm": 0.6506071090698242,
      "learning_rate": 8.144148708773376e-06,
      "loss": 0.5829,
      "step": 11721
    },
    {
      "epoch": 0.18560096268030463,
      "grad_norm": 0.06548997759819031,
      "learning_rate": 8.143990373196955e-06,
      "loss": 0.0018,
      "step": 11722
    },
    {
      "epoch": 0.1856167962379467,
      "grad_norm": 0.3974202275276184,
      "learning_rate": 8.143832037620534e-06,
      "loss": 0.1287,
      "step": 11723
    },
    {
      "epoch": 0.18563262979558878,
      "grad_norm": 0.2132890373468399,
      "learning_rate": 8.143673702044113e-06,
      "loss": 0.0324,
      "step": 11724
    },
    {
      "epoch": 0.18564846335323085,
      "grad_norm": 0.24892012774944305,
      "learning_rate": 8.143515366467692e-06,
      "loss": 0.0054,
      "step": 11725
    },
    {
      "epoch": 0.1856642969108729,
      "grad_norm": 0.30775728821754456,
      "learning_rate": 8.143357030891271e-06,
      "loss": 0.05,
      "step": 11726
    },
    {
      "epoch": 0.18568013046851498,
      "grad_norm": 0.01717342436313629,
      "learning_rate": 8.143198695314852e-06,
      "loss": 0.0007,
      "step": 11727
    },
    {
      "epoch": 0.18569596402615704,
      "grad_norm": 1.113418698310852,
      "learning_rate": 8.14304035973843e-06,
      "loss": 0.0947,
      "step": 11728
    },
    {
      "epoch": 0.1857117975837991,
      "grad_norm": 0.047676101326942444,
      "learning_rate": 8.14288202416201e-06,
      "loss": 0.0015,
      "step": 11729
    },
    {
      "epoch": 0.18572763114144117,
      "grad_norm": 0.3252069652080536,
      "learning_rate": 8.142723688585589e-06,
      "loss": 0.0137,
      "step": 11730
    },
    {
      "epoch": 0.18574346469908323,
      "grad_norm": 0.6380775570869446,
      "learning_rate": 8.142565353009168e-06,
      "loss": 0.6698,
      "step": 11731
    },
    {
      "epoch": 0.1857592982567253,
      "grad_norm": 0.3375970721244812,
      "learning_rate": 8.142407017432747e-06,
      "loss": 0.0701,
      "step": 11732
    },
    {
      "epoch": 0.18577513181436736,
      "grad_norm": 0.028354471549391747,
      "learning_rate": 8.142248681856328e-06,
      "loss": 0.0013,
      "step": 11733
    },
    {
      "epoch": 0.18579096537200943,
      "grad_norm": 0.13036398589611053,
      "learning_rate": 8.142090346279907e-06,
      "loss": 0.0378,
      "step": 11734
    },
    {
      "epoch": 0.1858067989296515,
      "grad_norm": 0.26256221532821655,
      "learning_rate": 8.141932010703486e-06,
      "loss": 0.0111,
      "step": 11735
    },
    {
      "epoch": 0.18582263248729358,
      "grad_norm": 0.08101552724838257,
      "learning_rate": 8.141773675127065e-06,
      "loss": 0.0091,
      "step": 11736
    },
    {
      "epoch": 0.18583846604493565,
      "grad_norm": 0.0005037515657022595,
      "learning_rate": 8.141615339550644e-06,
      "loss": 0.0,
      "step": 11737
    },
    {
      "epoch": 0.1858542996025777,
      "grad_norm": 0.34092238545417786,
      "learning_rate": 8.141457003974223e-06,
      "loss": 0.2078,
      "step": 11738
    },
    {
      "epoch": 0.18587013316021977,
      "grad_norm": 0.47857165336608887,
      "learning_rate": 8.141298668397804e-06,
      "loss": 0.1586,
      "step": 11739
    },
    {
      "epoch": 0.18588596671786184,
      "grad_norm": 0.017040181905031204,
      "learning_rate": 8.141140332821381e-06,
      "loss": 0.0007,
      "step": 11740
    },
    {
      "epoch": 0.1859018002755039,
      "grad_norm": 0.27984845638275146,
      "learning_rate": 8.140981997244962e-06,
      "loss": 0.1301,
      "step": 11741
    },
    {
      "epoch": 0.18591763383314597,
      "grad_norm": 0.8150092959403992,
      "learning_rate": 8.140823661668541e-06,
      "loss": 0.1863,
      "step": 11742
    },
    {
      "epoch": 0.18593346739078803,
      "grad_norm": 0.34089967608451843,
      "learning_rate": 8.14066532609212e-06,
      "loss": 0.1197,
      "step": 11743
    },
    {
      "epoch": 0.1859493009484301,
      "grad_norm": 0.00931607373058796,
      "learning_rate": 8.1405069905157e-06,
      "loss": 0.0003,
      "step": 11744
    },
    {
      "epoch": 0.18596513450607216,
      "grad_norm": 0.00015541839820798486,
      "learning_rate": 8.140348654939279e-06,
      "loss": 0.0,
      "step": 11745
    },
    {
      "epoch": 0.18598096806371422,
      "grad_norm": 0.16050423681735992,
      "learning_rate": 8.140190319362858e-06,
      "loss": 0.0581,
      "step": 11746
    },
    {
      "epoch": 0.1859968016213563,
      "grad_norm": 0.010379139333963394,
      "learning_rate": 8.140031983786437e-06,
      "loss": 0.0004,
      "step": 11747
    },
    {
      "epoch": 0.18601263517899838,
      "grad_norm": 0.012783285230398178,
      "learning_rate": 8.139873648210017e-06,
      "loss": 0.0005,
      "step": 11748
    },
    {
      "epoch": 0.18602846873664045,
      "grad_norm": 0.3126950263977051,
      "learning_rate": 8.139715312633597e-06,
      "loss": 0.1344,
      "step": 11749
    },
    {
      "epoch": 0.1860443022942825,
      "grad_norm": 0.5645721554756165,
      "learning_rate": 8.139556977057176e-06,
      "loss": 0.415,
      "step": 11750
    },
    {
      "epoch": 0.18606013585192457,
      "grad_norm": 0.44351592659950256,
      "learning_rate": 8.139398641480755e-06,
      "loss": 0.195,
      "step": 11751
    },
    {
      "epoch": 0.18607596940956664,
      "grad_norm": 0.3339737355709076,
      "learning_rate": 8.139240305904334e-06,
      "loss": 0.0567,
      "step": 11752
    },
    {
      "epoch": 0.1860918029672087,
      "grad_norm": 1.3090258836746216,
      "learning_rate": 8.139081970327913e-06,
      "loss": 0.2466,
      "step": 11753
    },
    {
      "epoch": 0.18610763652485077,
      "grad_norm": 0.5740189552307129,
      "learning_rate": 8.138923634751494e-06,
      "loss": 0.9105,
      "step": 11754
    },
    {
      "epoch": 0.18612347008249283,
      "grad_norm": 0.2901211082935333,
      "learning_rate": 8.138765299175073e-06,
      "loss": 0.0894,
      "step": 11755
    },
    {
      "epoch": 0.1861393036401349,
      "grad_norm": 0.5542481541633606,
      "learning_rate": 8.138606963598652e-06,
      "loss": 0.363,
      "step": 11756
    },
    {
      "epoch": 0.18615513719777696,
      "grad_norm": 0.3446073532104492,
      "learning_rate": 8.138448628022231e-06,
      "loss": 0.2848,
      "step": 11757
    },
    {
      "epoch": 0.18617097075541902,
      "grad_norm": 0.5491856336593628,
      "learning_rate": 8.13829029244581e-06,
      "loss": 0.4115,
      "step": 11758
    },
    {
      "epoch": 0.1861868043130611,
      "grad_norm": 0.26110899448394775,
      "learning_rate": 8.138131956869389e-06,
      "loss": 0.0044,
      "step": 11759
    },
    {
      "epoch": 0.18620263787070318,
      "grad_norm": 1.8772382736206055,
      "learning_rate": 8.13797362129297e-06,
      "loss": 0.195,
      "step": 11760
    },
    {
      "epoch": 0.18621847142834524,
      "grad_norm": 0.629967987537384,
      "learning_rate": 8.137815285716549e-06,
      "loss": 0.1118,
      "step": 11761
    },
    {
      "epoch": 0.1862343049859873,
      "grad_norm": 0.23129719495773315,
      "learning_rate": 8.137656950140128e-06,
      "loss": 0.0506,
      "step": 11762
    },
    {
      "epoch": 0.18625013854362937,
      "grad_norm": 0.16406109929084778,
      "learning_rate": 8.137498614563707e-06,
      "loss": 0.0847,
      "step": 11763
    },
    {
      "epoch": 0.18626597210127144,
      "grad_norm": 0.04222305491566658,
      "learning_rate": 8.137340278987286e-06,
      "loss": 0.0035,
      "step": 11764
    },
    {
      "epoch": 0.1862818056589135,
      "grad_norm": 0.0005392066086642444,
      "learning_rate": 8.137181943410865e-06,
      "loss": 0.0,
      "step": 11765
    },
    {
      "epoch": 0.18629763921655557,
      "grad_norm": 0.0005097024841234088,
      "learning_rate": 8.137023607834444e-06,
      "loss": 0.0,
      "step": 11766
    },
    {
      "epoch": 0.18631347277419763,
      "grad_norm": 0.22725838422775269,
      "learning_rate": 8.136865272258025e-06,
      "loss": 0.062,
      "step": 11767
    },
    {
      "epoch": 0.1863293063318397,
      "grad_norm": 0.2465025931596756,
      "learning_rate": 8.136706936681602e-06,
      "loss": 0.0761,
      "step": 11768
    },
    {
      "epoch": 0.18634513988948176,
      "grad_norm": 0.8143014311790466,
      "learning_rate": 8.136548601105183e-06,
      "loss": 0.2715,
      "step": 11769
    },
    {
      "epoch": 0.18636097344712382,
      "grad_norm": 0.12979432940483093,
      "learning_rate": 8.136390265528762e-06,
      "loss": 0.01,
      "step": 11770
    },
    {
      "epoch": 0.1863768070047659,
      "grad_norm": 0.8967227935791016,
      "learning_rate": 8.136231929952341e-06,
      "loss": 0.3031,
      "step": 11771
    },
    {
      "epoch": 0.18639264056240798,
      "grad_norm": 0.3134482204914093,
      "learning_rate": 8.13607359437592e-06,
      "loss": 0.0836,
      "step": 11772
    },
    {
      "epoch": 0.18640847412005004,
      "grad_norm": 0.6015442609786987,
      "learning_rate": 8.135915258799501e-06,
      "loss": 0.778,
      "step": 11773
    },
    {
      "epoch": 0.1864243076776921,
      "grad_norm": 0.39272400736808777,
      "learning_rate": 8.135756923223079e-06,
      "loss": 0.1932,
      "step": 11774
    },
    {
      "epoch": 0.18644014123533417,
      "grad_norm": 0.905937910079956,
      "learning_rate": 8.13559858764666e-06,
      "loss": 0.2532,
      "step": 11775
    },
    {
      "epoch": 0.18645597479297624,
      "grad_norm": 0.4064590334892273,
      "learning_rate": 8.135440252070238e-06,
      "loss": 0.0496,
      "step": 11776
    },
    {
      "epoch": 0.1864718083506183,
      "grad_norm": 0.009337939321994781,
      "learning_rate": 8.135281916493818e-06,
      "loss": 0.0004,
      "step": 11777
    },
    {
      "epoch": 0.18648764190826037,
      "grad_norm": 0.0621766559779644,
      "learning_rate": 8.135123580917397e-06,
      "loss": 0.0026,
      "step": 11778
    },
    {
      "epoch": 0.18650347546590243,
      "grad_norm": 0.24422405660152435,
      "learning_rate": 8.134965245340977e-06,
      "loss": 0.0959,
      "step": 11779
    },
    {
      "epoch": 0.1865193090235445,
      "grad_norm": 0.41505181789398193,
      "learning_rate": 8.134806909764555e-06,
      "loss": 0.3068,
      "step": 11780
    },
    {
      "epoch": 0.18653514258118656,
      "grad_norm": 0.0013271997449919581,
      "learning_rate": 8.134648574188136e-06,
      "loss": 0.0,
      "step": 11781
    },
    {
      "epoch": 0.18655097613882862,
      "grad_norm": 0.6260325908660889,
      "learning_rate": 8.134490238611715e-06,
      "loss": 0.2816,
      "step": 11782
    },
    {
      "epoch": 0.1865668096964707,
      "grad_norm": 0.18791022896766663,
      "learning_rate": 8.134331903035294e-06,
      "loss": 0.0626,
      "step": 11783
    },
    {
      "epoch": 0.18658264325411278,
      "grad_norm": 0.005460841581225395,
      "learning_rate": 8.134173567458873e-06,
      "loss": 0.0002,
      "step": 11784
    },
    {
      "epoch": 0.18659847681175484,
      "grad_norm": 0.0207577683031559,
      "learning_rate": 8.134015231882454e-06,
      "loss": 0.0011,
      "step": 11785
    },
    {
      "epoch": 0.1866143103693969,
      "grad_norm": 0.14665420353412628,
      "learning_rate": 8.133856896306031e-06,
      "loss": 0.0419,
      "step": 11786
    },
    {
      "epoch": 0.18663014392703897,
      "grad_norm": 0.5485436320304871,
      "learning_rate": 8.133698560729612e-06,
      "loss": 0.1385,
      "step": 11787
    },
    {
      "epoch": 0.18664597748468104,
      "grad_norm": 0.2293815314769745,
      "learning_rate": 8.13354022515319e-06,
      "loss": 0.0501,
      "step": 11788
    },
    {
      "epoch": 0.1866618110423231,
      "grad_norm": 0.43053218722343445,
      "learning_rate": 8.13338188957677e-06,
      "loss": 0.1706,
      "step": 11789
    },
    {
      "epoch": 0.18667764459996516,
      "grad_norm": 0.0018849096959456801,
      "learning_rate": 8.133223554000349e-06,
      "loss": 0.0001,
      "step": 11790
    },
    {
      "epoch": 0.18669347815760723,
      "grad_norm": 0.02165808342397213,
      "learning_rate": 8.133065218423928e-06,
      "loss": 0.0009,
      "step": 11791
    },
    {
      "epoch": 0.1867093117152493,
      "grad_norm": 0.0027763142716139555,
      "learning_rate": 8.132906882847507e-06,
      "loss": 0.0,
      "step": 11792
    },
    {
      "epoch": 0.18672514527289136,
      "grad_norm": 0.0001178746169898659,
      "learning_rate": 8.132748547271086e-06,
      "loss": 0.0,
      "step": 11793
    },
    {
      "epoch": 0.18674097883053342,
      "grad_norm": 0.12859655916690826,
      "learning_rate": 8.132590211694667e-06,
      "loss": 0.0415,
      "step": 11794
    },
    {
      "epoch": 0.18675681238817549,
      "grad_norm": 0.34512776136398315,
      "learning_rate": 8.132431876118246e-06,
      "loss": 0.1468,
      "step": 11795
    },
    {
      "epoch": 0.18677264594581758,
      "grad_norm": 0.2381027191877365,
      "learning_rate": 8.132273540541825e-06,
      "loss": 0.0587,
      "step": 11796
    },
    {
      "epoch": 0.18678847950345964,
      "grad_norm": 1.0298606157302856,
      "learning_rate": 8.132115204965404e-06,
      "loss": 0.7274,
      "step": 11797
    },
    {
      "epoch": 0.1868043130611017,
      "grad_norm": 0.4399539530277252,
      "learning_rate": 8.131956869388983e-06,
      "loss": 0.0391,
      "step": 11798
    },
    {
      "epoch": 0.18682014661874377,
      "grad_norm": 0.0003680054796859622,
      "learning_rate": 8.131798533812562e-06,
      "loss": 0.0,
      "step": 11799
    },
    {
      "epoch": 0.18683598017638584,
      "grad_norm": 0.004334497731178999,
      "learning_rate": 8.131640198236143e-06,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 0.1868518137340279,
      "grad_norm": 0.035223912447690964,
      "learning_rate": 8.13148186265972e-06,
      "loss": 0.002,
      "step": 11801
    },
    {
      "epoch": 0.18686764729166996,
      "grad_norm": 0.1773594617843628,
      "learning_rate": 8.131323527083301e-06,
      "loss": 0.0106,
      "step": 11802
    },
    {
      "epoch": 0.18688348084931203,
      "grad_norm": 0.08850617706775665,
      "learning_rate": 8.13116519150688e-06,
      "loss": 0.0159,
      "step": 11803
    },
    {
      "epoch": 0.1868993144069541,
      "grad_norm": 0.00020688149379566312,
      "learning_rate": 8.13100685593046e-06,
      "loss": 0.0,
      "step": 11804
    },
    {
      "epoch": 0.18691514796459616,
      "grad_norm": 0.017866505309939384,
      "learning_rate": 8.130848520354039e-06,
      "loss": 0.0008,
      "step": 11805
    },
    {
      "epoch": 0.18693098152223822,
      "grad_norm": 0.00698816915974021,
      "learning_rate": 8.13069018477762e-06,
      "loss": 0.0002,
      "step": 11806
    },
    {
      "epoch": 0.18694681507988029,
      "grad_norm": 0.4577295482158661,
      "learning_rate": 8.130531849201197e-06,
      "loss": 0.3727,
      "step": 11807
    },
    {
      "epoch": 0.18696264863752238,
      "grad_norm": 0.0007604528218507767,
      "learning_rate": 8.130373513624777e-06,
      "loss": 0.0,
      "step": 11808
    },
    {
      "epoch": 0.18697848219516444,
      "grad_norm": 0.5144889950752258,
      "learning_rate": 8.130215178048357e-06,
      "loss": 0.4549,
      "step": 11809
    },
    {
      "epoch": 0.1869943157528065,
      "grad_norm": 0.00021415889204945415,
      "learning_rate": 8.130056842471936e-06,
      "loss": 0.0,
      "step": 11810
    },
    {
      "epoch": 0.18701014931044857,
      "grad_norm": 0.15534786880016327,
      "learning_rate": 8.129898506895515e-06,
      "loss": 0.045,
      "step": 11811
    },
    {
      "epoch": 0.18702598286809063,
      "grad_norm": 0.213300421833992,
      "learning_rate": 8.129740171319096e-06,
      "loss": 0.2588,
      "step": 11812
    },
    {
      "epoch": 0.1870418164257327,
      "grad_norm": 0.012610221281647682,
      "learning_rate": 8.129581835742673e-06,
      "loss": 0.0005,
      "step": 11813
    },
    {
      "epoch": 0.18705764998337476,
      "grad_norm": 0.520227313041687,
      "learning_rate": 8.129423500166252e-06,
      "loss": 0.1151,
      "step": 11814
    },
    {
      "epoch": 0.18707348354101683,
      "grad_norm": 0.007217905484139919,
      "learning_rate": 8.129265164589833e-06,
      "loss": 0.0003,
      "step": 11815
    },
    {
      "epoch": 0.1870893170986589,
      "grad_norm": 0.5523261427879333,
      "learning_rate": 8.129106829013412e-06,
      "loss": 0.3823,
      "step": 11816
    },
    {
      "epoch": 0.18710515065630096,
      "grad_norm": 0.2471085637807846,
      "learning_rate": 8.128948493436991e-06,
      "loss": 0.0688,
      "step": 11817
    },
    {
      "epoch": 0.18712098421394302,
      "grad_norm": 0.29414087533950806,
      "learning_rate": 8.12879015786057e-06,
      "loss": 0.0831,
      "step": 11818
    },
    {
      "epoch": 0.18713681777158508,
      "grad_norm": 0.37398579716682434,
      "learning_rate": 8.128631822284149e-06,
      "loss": 0.1898,
      "step": 11819
    },
    {
      "epoch": 0.18715265132922718,
      "grad_norm": 0.03100266493856907,
      "learning_rate": 8.128473486707728e-06,
      "loss": 0.0017,
      "step": 11820
    },
    {
      "epoch": 0.18716848488686924,
      "grad_norm": 0.29043930768966675,
      "learning_rate": 8.128315151131309e-06,
      "loss": 0.0823,
      "step": 11821
    },
    {
      "epoch": 0.1871843184445113,
      "grad_norm": 0.36556562781333923,
      "learning_rate": 8.128156815554888e-06,
      "loss": 0.1853,
      "step": 11822
    },
    {
      "epoch": 0.18720015200215337,
      "grad_norm": 0.003577125258743763,
      "learning_rate": 8.127998479978467e-06,
      "loss": 0.0002,
      "step": 11823
    },
    {
      "epoch": 0.18721598555979543,
      "grad_norm": 0.2391325682401657,
      "learning_rate": 8.127840144402046e-06,
      "loss": 0.0744,
      "step": 11824
    },
    {
      "epoch": 0.1872318191174375,
      "grad_norm": 0.21544866263866425,
      "learning_rate": 8.127681808825625e-06,
      "loss": 0.0687,
      "step": 11825
    },
    {
      "epoch": 0.18724765267507956,
      "grad_norm": 0.39138633012771606,
      "learning_rate": 8.127523473249204e-06,
      "loss": 0.2399,
      "step": 11826
    },
    {
      "epoch": 0.18726348623272163,
      "grad_norm": 0.07770241051912308,
      "learning_rate": 8.127365137672785e-06,
      "loss": 0.0039,
      "step": 11827
    },
    {
      "epoch": 0.1872793197903637,
      "grad_norm": 0.014716795645654202,
      "learning_rate": 8.127206802096364e-06,
      "loss": 0.0007,
      "step": 11828
    },
    {
      "epoch": 0.18729515334800576,
      "grad_norm": 0.4373698830604553,
      "learning_rate": 8.127048466519943e-06,
      "loss": 0.1111,
      "step": 11829
    },
    {
      "epoch": 0.18731098690564782,
      "grad_norm": 0.23434992134571075,
      "learning_rate": 8.126890130943522e-06,
      "loss": 0.0117,
      "step": 11830
    },
    {
      "epoch": 0.18732682046328988,
      "grad_norm": 0.2869374752044678,
      "learning_rate": 8.126731795367101e-06,
      "loss": 0.0642,
      "step": 11831
    },
    {
      "epoch": 0.18734265402093198,
      "grad_norm": 0.2940329313278198,
      "learning_rate": 8.12657345979068e-06,
      "loss": 0.0872,
      "step": 11832
    },
    {
      "epoch": 0.18735848757857404,
      "grad_norm": 0.4465051293373108,
      "learning_rate": 8.126415124214261e-06,
      "loss": 0.2234,
      "step": 11833
    },
    {
      "epoch": 0.1873743211362161,
      "grad_norm": 0.6226472854614258,
      "learning_rate": 8.12625678863784e-06,
      "loss": 0.1531,
      "step": 11834
    },
    {
      "epoch": 0.18739015469385817,
      "grad_norm": 1.0955466032028198,
      "learning_rate": 8.12609845306142e-06,
      "loss": 0.5755,
      "step": 11835
    },
    {
      "epoch": 0.18740598825150023,
      "grad_norm": 0.19114913046360016,
      "learning_rate": 8.125940117484999e-06,
      "loss": 0.0705,
      "step": 11836
    },
    {
      "epoch": 0.1874218218091423,
      "grad_norm": 0.7202140092849731,
      "learning_rate": 8.125781781908578e-06,
      "loss": 0.5417,
      "step": 11837
    },
    {
      "epoch": 0.18743765536678436,
      "grad_norm": 0.003682802664116025,
      "learning_rate": 8.125623446332157e-06,
      "loss": 0.0001,
      "step": 11838
    },
    {
      "epoch": 0.18745348892442643,
      "grad_norm": 0.3340492248535156,
      "learning_rate": 8.125465110755736e-06,
      "loss": 0.1495,
      "step": 11839
    },
    {
      "epoch": 0.1874693224820685,
      "grad_norm": 0.08451416343450546,
      "learning_rate": 8.125306775179317e-06,
      "loss": 0.0112,
      "step": 11840
    },
    {
      "epoch": 0.18748515603971055,
      "grad_norm": 1.25962495803833,
      "learning_rate": 8.125148439602894e-06,
      "loss": 0.0222,
      "step": 11841
    },
    {
      "epoch": 0.18750098959735262,
      "grad_norm": 0.007388539146631956,
      "learning_rate": 8.124990104026475e-06,
      "loss": 0.0003,
      "step": 11842
    },
    {
      "epoch": 0.18751682315499468,
      "grad_norm": 0.11891929060220718,
      "learning_rate": 8.124831768450054e-06,
      "loss": 0.0047,
      "step": 11843
    },
    {
      "epoch": 0.18753265671263677,
      "grad_norm": 0.1423395872116089,
      "learning_rate": 8.124673432873633e-06,
      "loss": 0.0032,
      "step": 11844
    },
    {
      "epoch": 0.18754849027027884,
      "grad_norm": 0.37049901485443115,
      "learning_rate": 8.124515097297212e-06,
      "loss": 0.1339,
      "step": 11845
    },
    {
      "epoch": 0.1875643238279209,
      "grad_norm": 0.020372338593006134,
      "learning_rate": 8.124356761720793e-06,
      "loss": 0.0011,
      "step": 11846
    },
    {
      "epoch": 0.18758015738556297,
      "grad_norm": 0.40944620966911316,
      "learning_rate": 8.12419842614437e-06,
      "loss": 0.383,
      "step": 11847
    },
    {
      "epoch": 0.18759599094320503,
      "grad_norm": 0.5868586897850037,
      "learning_rate": 8.12404009056795e-06,
      "loss": 0.3554,
      "step": 11848
    },
    {
      "epoch": 0.1876118245008471,
      "grad_norm": 0.015624563209712505,
      "learning_rate": 8.12388175499153e-06,
      "loss": 0.0006,
      "step": 11849
    },
    {
      "epoch": 0.18762765805848916,
      "grad_norm": 0.0025236818473786116,
      "learning_rate": 8.123723419415109e-06,
      "loss": 0.0001,
      "step": 11850
    },
    {
      "epoch": 0.18764349161613122,
      "grad_norm": 1.380009412765503,
      "learning_rate": 8.123565083838688e-06,
      "loss": 0.074,
      "step": 11851
    },
    {
      "epoch": 0.1876593251737733,
      "grad_norm": 0.3832966089248657,
      "learning_rate": 8.123406748262269e-06,
      "loss": 0.0479,
      "step": 11852
    },
    {
      "epoch": 0.18767515873141535,
      "grad_norm": 0.0035681934095919132,
      "learning_rate": 8.123248412685846e-06,
      "loss": 0.0001,
      "step": 11853
    },
    {
      "epoch": 0.18769099228905742,
      "grad_norm": 0.0002148583735106513,
      "learning_rate": 8.123090077109427e-06,
      "loss": 0.0,
      "step": 11854
    },
    {
      "epoch": 0.18770682584669948,
      "grad_norm": 0.2455330193042755,
      "learning_rate": 8.122931741533006e-06,
      "loss": 0.1051,
      "step": 11855
    },
    {
      "epoch": 0.18772265940434157,
      "grad_norm": 0.6964691281318665,
      "learning_rate": 8.122773405956585e-06,
      "loss": 0.3338,
      "step": 11856
    },
    {
      "epoch": 0.18773849296198364,
      "grad_norm": 0.2615133225917816,
      "learning_rate": 8.122615070380164e-06,
      "loss": 0.0754,
      "step": 11857
    },
    {
      "epoch": 0.1877543265196257,
      "grad_norm": 0.34736526012420654,
      "learning_rate": 8.122456734803745e-06,
      "loss": 0.1074,
      "step": 11858
    },
    {
      "epoch": 0.18777016007726777,
      "grad_norm": 0.6112624406814575,
      "learning_rate": 8.122298399227322e-06,
      "loss": 0.0944,
      "step": 11859
    },
    {
      "epoch": 0.18778599363490983,
      "grad_norm": 0.02377316728234291,
      "learning_rate": 8.122140063650903e-06,
      "loss": 0.0011,
      "step": 11860
    },
    {
      "epoch": 0.1878018271925519,
      "grad_norm": 0.0192621611058712,
      "learning_rate": 8.121981728074482e-06,
      "loss": 0.0009,
      "step": 11861
    },
    {
      "epoch": 0.18781766075019396,
      "grad_norm": 0.4921312630176544,
      "learning_rate": 8.121823392498061e-06,
      "loss": 0.5623,
      "step": 11862
    },
    {
      "epoch": 0.18783349430783602,
      "grad_norm": 0.5566263198852539,
      "learning_rate": 8.12166505692164e-06,
      "loss": 0.5234,
      "step": 11863
    },
    {
      "epoch": 0.1878493278654781,
      "grad_norm": 0.27923649549484253,
      "learning_rate": 8.12150672134522e-06,
      "loss": 0.0838,
      "step": 11864
    },
    {
      "epoch": 0.18786516142312015,
      "grad_norm": 0.4079055190086365,
      "learning_rate": 8.121348385768799e-06,
      "loss": 0.1669,
      "step": 11865
    },
    {
      "epoch": 0.18788099498076222,
      "grad_norm": 0.5504253506660461,
      "learning_rate": 8.121190050192378e-06,
      "loss": 0.4778,
      "step": 11866
    },
    {
      "epoch": 0.18789682853840428,
      "grad_norm": 0.35232269763946533,
      "learning_rate": 8.121031714615958e-06,
      "loss": 0.2102,
      "step": 11867
    },
    {
      "epoch": 0.18791266209604637,
      "grad_norm": 0.044527072459459305,
      "learning_rate": 8.120873379039536e-06,
      "loss": 0.0017,
      "step": 11868
    },
    {
      "epoch": 0.18792849565368844,
      "grad_norm": 0.1958269625902176,
      "learning_rate": 8.120715043463117e-06,
      "loss": 0.0715,
      "step": 11869
    },
    {
      "epoch": 0.1879443292113305,
      "grad_norm": 0.24337612092494965,
      "learning_rate": 8.120556707886696e-06,
      "loss": 0.0556,
      "step": 11870
    },
    {
      "epoch": 0.18796016276897257,
      "grad_norm": 1.544059157371521,
      "learning_rate": 8.120398372310275e-06,
      "loss": 0.3395,
      "step": 11871
    },
    {
      "epoch": 0.18797599632661463,
      "grad_norm": 0.8646622896194458,
      "learning_rate": 8.120240036733854e-06,
      "loss": 0.6358,
      "step": 11872
    },
    {
      "epoch": 0.1879918298842567,
      "grad_norm": 0.26769426465034485,
      "learning_rate": 8.120081701157435e-06,
      "loss": 0.0579,
      "step": 11873
    },
    {
      "epoch": 0.18800766344189876,
      "grad_norm": 0.5981625318527222,
      "learning_rate": 8.119923365581012e-06,
      "loss": 0.3075,
      "step": 11874
    },
    {
      "epoch": 0.18802349699954082,
      "grad_norm": 0.017482874915003777,
      "learning_rate": 8.119765030004593e-06,
      "loss": 0.0006,
      "step": 11875
    },
    {
      "epoch": 0.1880393305571829,
      "grad_norm": 0.19690297544002533,
      "learning_rate": 8.119606694428172e-06,
      "loss": 0.0714,
      "step": 11876
    },
    {
      "epoch": 0.18805516411482495,
      "grad_norm": 0.3530968427658081,
      "learning_rate": 8.119448358851751e-06,
      "loss": 0.0961,
      "step": 11877
    },
    {
      "epoch": 0.18807099767246702,
      "grad_norm": 0.03616000711917877,
      "learning_rate": 8.11929002327533e-06,
      "loss": 0.0024,
      "step": 11878
    },
    {
      "epoch": 0.18808683123010908,
      "grad_norm": 0.5103626251220703,
      "learning_rate": 8.11913168769891e-06,
      "loss": 0.2206,
      "step": 11879
    },
    {
      "epoch": 0.18810266478775117,
      "grad_norm": 0.5925740599632263,
      "learning_rate": 8.118973352122488e-06,
      "loss": 0.3552,
      "step": 11880
    },
    {
      "epoch": 0.18811849834539324,
      "grad_norm": 0.26956912875175476,
      "learning_rate": 8.118815016546069e-06,
      "loss": 0.0644,
      "step": 11881
    },
    {
      "epoch": 0.1881343319030353,
      "grad_norm": 0.20708224177360535,
      "learning_rate": 8.118656680969648e-06,
      "loss": 0.0134,
      "step": 11882
    },
    {
      "epoch": 0.18815016546067737,
      "grad_norm": 0.02734154835343361,
      "learning_rate": 8.118498345393227e-06,
      "loss": 0.0019,
      "step": 11883
    },
    {
      "epoch": 0.18816599901831943,
      "grad_norm": 0.6280426383018494,
      "learning_rate": 8.118340009816806e-06,
      "loss": 0.2843,
      "step": 11884
    },
    {
      "epoch": 0.1881818325759615,
      "grad_norm": 0.000316377030685544,
      "learning_rate": 8.118181674240387e-06,
      "loss": 0.0,
      "step": 11885
    },
    {
      "epoch": 0.18819766613360356,
      "grad_norm": 0.0010936326580122113,
      "learning_rate": 8.118023338663964e-06,
      "loss": 0.0,
      "step": 11886
    },
    {
      "epoch": 0.18821349969124562,
      "grad_norm": 0.18376614153385162,
      "learning_rate": 8.117865003087543e-06,
      "loss": 0.0528,
      "step": 11887
    },
    {
      "epoch": 0.1882293332488877,
      "grad_norm": 0.3151884377002716,
      "learning_rate": 8.117706667511124e-06,
      "loss": 0.0799,
      "step": 11888
    },
    {
      "epoch": 0.18824516680652975,
      "grad_norm": 0.7062785029411316,
      "learning_rate": 8.117548331934703e-06,
      "loss": 0.2412,
      "step": 11889
    },
    {
      "epoch": 0.18826100036417182,
      "grad_norm": 0.025353820994496346,
      "learning_rate": 8.117389996358282e-06,
      "loss": 0.0011,
      "step": 11890
    },
    {
      "epoch": 0.18827683392181388,
      "grad_norm": 0.536331295967102,
      "learning_rate": 8.117231660781861e-06,
      "loss": 0.142,
      "step": 11891
    },
    {
      "epoch": 0.18829266747945597,
      "grad_norm": 0.2589761018753052,
      "learning_rate": 8.11707332520544e-06,
      "loss": 0.4038,
      "step": 11892
    },
    {
      "epoch": 0.18830850103709804,
      "grad_norm": 0.16802474856376648,
      "learning_rate": 8.11691498962902e-06,
      "loss": 0.031,
      "step": 11893
    },
    {
      "epoch": 0.1883243345947401,
      "grad_norm": 0.3764805495738983,
      "learning_rate": 8.1167566540526e-06,
      "loss": 0.6008,
      "step": 11894
    },
    {
      "epoch": 0.18834016815238216,
      "grad_norm": 0.15411476790905,
      "learning_rate": 8.11659831847618e-06,
      "loss": 0.0629,
      "step": 11895
    },
    {
      "epoch": 0.18835600171002423,
      "grad_norm": 0.4291154146194458,
      "learning_rate": 8.116439982899759e-06,
      "loss": 0.1148,
      "step": 11896
    },
    {
      "epoch": 0.1883718352676663,
      "grad_norm": 0.8803433775901794,
      "learning_rate": 8.116281647323338e-06,
      "loss": 0.5302,
      "step": 11897
    },
    {
      "epoch": 0.18838766882530836,
      "grad_norm": 1.1480953693389893,
      "learning_rate": 8.116123311746917e-06,
      "loss": 0.5535,
      "step": 11898
    },
    {
      "epoch": 0.18840350238295042,
      "grad_norm": 0.4336305260658264,
      "learning_rate": 8.115964976170496e-06,
      "loss": 0.1588,
      "step": 11899
    },
    {
      "epoch": 0.1884193359405925,
      "grad_norm": 0.3958183228969574,
      "learning_rate": 8.115806640594077e-06,
      "loss": 0.2952,
      "step": 11900
    },
    {
      "epoch": 0.18843516949823455,
      "grad_norm": 0.22327393293380737,
      "learning_rate": 8.115648305017656e-06,
      "loss": 0.0659,
      "step": 11901
    },
    {
      "epoch": 0.18845100305587661,
      "grad_norm": 0.5377722382545471,
      "learning_rate": 8.115489969441235e-06,
      "loss": 0.2435,
      "step": 11902
    },
    {
      "epoch": 0.18846683661351868,
      "grad_norm": 0.2763608992099762,
      "learning_rate": 8.115331633864814e-06,
      "loss": 0.1098,
      "step": 11903
    },
    {
      "epoch": 0.18848267017116077,
      "grad_norm": 0.2528201639652252,
      "learning_rate": 8.115173298288393e-06,
      "loss": 0.039,
      "step": 11904
    },
    {
      "epoch": 0.18849850372880284,
      "grad_norm": 0.13086985051631927,
      "learning_rate": 8.115014962711972e-06,
      "loss": 0.0668,
      "step": 11905
    },
    {
      "epoch": 0.1885143372864449,
      "grad_norm": 0.4473574757575989,
      "learning_rate": 8.114856627135553e-06,
      "loss": 0.1689,
      "step": 11906
    },
    {
      "epoch": 0.18853017084408696,
      "grad_norm": 0.015396036207675934,
      "learning_rate": 8.114698291559132e-06,
      "loss": 0.0007,
      "step": 11907
    },
    {
      "epoch": 0.18854600440172903,
      "grad_norm": 0.03733805567026138,
      "learning_rate": 8.114539955982711e-06,
      "loss": 0.0019,
      "step": 11908
    },
    {
      "epoch": 0.1885618379593711,
      "grad_norm": 0.3115466237068176,
      "learning_rate": 8.11438162040629e-06,
      "loss": 0.0618,
      "step": 11909
    },
    {
      "epoch": 0.18857767151701316,
      "grad_norm": 0.31609994173049927,
      "learning_rate": 8.114223284829869e-06,
      "loss": 0.0104,
      "step": 11910
    },
    {
      "epoch": 0.18859350507465522,
      "grad_norm": 0.642880380153656,
      "learning_rate": 8.114064949253448e-06,
      "loss": 0.0517,
      "step": 11911
    },
    {
      "epoch": 0.18860933863229729,
      "grad_norm": 0.3271717429161072,
      "learning_rate": 8.113906613677027e-06,
      "loss": 0.0842,
      "step": 11912
    },
    {
      "epoch": 0.18862517218993935,
      "grad_norm": 0.4452340006828308,
      "learning_rate": 8.113748278100608e-06,
      "loss": 0.0717,
      "step": 11913
    },
    {
      "epoch": 0.18864100574758141,
      "grad_norm": 0.2238226979970932,
      "learning_rate": 8.113589942524185e-06,
      "loss": 0.0366,
      "step": 11914
    },
    {
      "epoch": 0.18865683930522348,
      "grad_norm": 0.027587424963712692,
      "learning_rate": 8.113431606947766e-06,
      "loss": 0.0012,
      "step": 11915
    },
    {
      "epoch": 0.18867267286286557,
      "grad_norm": 0.04089762270450592,
      "learning_rate": 8.113273271371345e-06,
      "loss": 0.0014,
      "step": 11916
    },
    {
      "epoch": 0.18868850642050763,
      "grad_norm": 0.5505474209785461,
      "learning_rate": 8.113114935794924e-06,
      "loss": 0.062,
      "step": 11917
    },
    {
      "epoch": 0.1887043399781497,
      "grad_norm": 0.00012802152195945382,
      "learning_rate": 8.112956600218503e-06,
      "loss": 0.0,
      "step": 11918
    },
    {
      "epoch": 0.18872017353579176,
      "grad_norm": 0.019213968887925148,
      "learning_rate": 8.112798264642084e-06,
      "loss": 0.0011,
      "step": 11919
    },
    {
      "epoch": 0.18873600709343383,
      "grad_norm": 0.5252763032913208,
      "learning_rate": 8.112639929065662e-06,
      "loss": 0.1688,
      "step": 11920
    },
    {
      "epoch": 0.1887518406510759,
      "grad_norm": 0.5667957067489624,
      "learning_rate": 8.112481593489242e-06,
      "loss": 0.2169,
      "step": 11921
    },
    {
      "epoch": 0.18876767420871796,
      "grad_norm": 0.41347646713256836,
      "learning_rate": 8.112323257912821e-06,
      "loss": 0.1062,
      "step": 11922
    },
    {
      "epoch": 0.18878350776636002,
      "grad_norm": 0.6515542268753052,
      "learning_rate": 8.1121649223364e-06,
      "loss": 0.3734,
      "step": 11923
    },
    {
      "epoch": 0.18879934132400208,
      "grad_norm": 0.38336628675460815,
      "learning_rate": 8.11200658675998e-06,
      "loss": 0.0951,
      "step": 11924
    },
    {
      "epoch": 0.18881517488164415,
      "grad_norm": 0.21307092905044556,
      "learning_rate": 8.111848251183559e-06,
      "loss": 0.0484,
      "step": 11925
    },
    {
      "epoch": 0.1888310084392862,
      "grad_norm": 0.00032270996598526835,
      "learning_rate": 8.111689915607138e-06,
      "loss": 0.0,
      "step": 11926
    },
    {
      "epoch": 0.18884684199692828,
      "grad_norm": 0.32305535674095154,
      "learning_rate": 8.111531580030718e-06,
      "loss": 0.0897,
      "step": 11927
    },
    {
      "epoch": 0.18886267555457037,
      "grad_norm": 0.004884142428636551,
      "learning_rate": 8.111373244454298e-06,
      "loss": 0.0003,
      "step": 11928
    },
    {
      "epoch": 0.18887850911221243,
      "grad_norm": 0.7641923427581787,
      "learning_rate": 8.111214908877877e-06,
      "loss": 0.6126,
      "step": 11929
    },
    {
      "epoch": 0.1888943426698545,
      "grad_norm": 0.1627686619758606,
      "learning_rate": 8.111056573301456e-06,
      "loss": 0.0378,
      "step": 11930
    },
    {
      "epoch": 0.18891017622749656,
      "grad_norm": 0.19573929905891418,
      "learning_rate": 8.110898237725035e-06,
      "loss": 0.0496,
      "step": 11931
    },
    {
      "epoch": 0.18892600978513863,
      "grad_norm": 1.0260937213897705,
      "learning_rate": 8.110739902148614e-06,
      "loss": 0.6471,
      "step": 11932
    },
    {
      "epoch": 0.1889418433427807,
      "grad_norm": 0.37189069390296936,
      "learning_rate": 8.110581566572195e-06,
      "loss": 0.1027,
      "step": 11933
    },
    {
      "epoch": 0.18895767690042276,
      "grad_norm": 0.3915593922138214,
      "learning_rate": 8.110423230995774e-06,
      "loss": 0.3468,
      "step": 11934
    },
    {
      "epoch": 0.18897351045806482,
      "grad_norm": 0.33400508761405945,
      "learning_rate": 8.110264895419351e-06,
      "loss": 0.0462,
      "step": 11935
    },
    {
      "epoch": 0.18898934401570688,
      "grad_norm": 0.3878510296344757,
      "learning_rate": 8.110106559842932e-06,
      "loss": 0.2554,
      "step": 11936
    },
    {
      "epoch": 0.18900517757334895,
      "grad_norm": 0.7351545095443726,
      "learning_rate": 8.109948224266511e-06,
      "loss": 0.2786,
      "step": 11937
    },
    {
      "epoch": 0.189021011130991,
      "grad_norm": 0.38575825095176697,
      "learning_rate": 8.10978988869009e-06,
      "loss": 0.0881,
      "step": 11938
    },
    {
      "epoch": 0.18903684468863308,
      "grad_norm": 0.36680567264556885,
      "learning_rate": 8.109631553113669e-06,
      "loss": 0.213,
      "step": 11939
    },
    {
      "epoch": 0.18905267824627517,
      "grad_norm": 0.2704765498638153,
      "learning_rate": 8.10947321753725e-06,
      "loss": 0.1362,
      "step": 11940
    },
    {
      "epoch": 0.18906851180391723,
      "grad_norm": 0.42407459020614624,
      "learning_rate": 8.109314881960827e-06,
      "loss": 0.0952,
      "step": 11941
    },
    {
      "epoch": 0.1890843453615593,
      "grad_norm": 0.6750595569610596,
      "learning_rate": 8.109156546384408e-06,
      "loss": 0.0475,
      "step": 11942
    },
    {
      "epoch": 0.18910017891920136,
      "grad_norm": 0.03307672590017319,
      "learning_rate": 8.108998210807987e-06,
      "loss": 0.0019,
      "step": 11943
    },
    {
      "epoch": 0.18911601247684343,
      "grad_norm": 0.27179184556007385,
      "learning_rate": 8.108839875231566e-06,
      "loss": 0.0982,
      "step": 11944
    },
    {
      "epoch": 0.1891318460344855,
      "grad_norm": 0.08994235843420029,
      "learning_rate": 8.108681539655145e-06,
      "loss": 0.0051,
      "step": 11945
    },
    {
      "epoch": 0.18914767959212755,
      "grad_norm": 0.3286950886249542,
      "learning_rate": 8.108523204078726e-06,
      "loss": 0.0881,
      "step": 11946
    },
    {
      "epoch": 0.18916351314976962,
      "grad_norm": 0.00010648673196556047,
      "learning_rate": 8.108364868502303e-06,
      "loss": 0.0,
      "step": 11947
    },
    {
      "epoch": 0.18917934670741168,
      "grad_norm": 0.3527204692363739,
      "learning_rate": 8.108206532925884e-06,
      "loss": 0.1018,
      "step": 11948
    },
    {
      "epoch": 0.18919518026505375,
      "grad_norm": 0.25725582242012024,
      "learning_rate": 8.108048197349463e-06,
      "loss": 0.0628,
      "step": 11949
    },
    {
      "epoch": 0.1892110138226958,
      "grad_norm": 0.41313132643699646,
      "learning_rate": 8.107889861773042e-06,
      "loss": 0.1187,
      "step": 11950
    },
    {
      "epoch": 0.18922684738033788,
      "grad_norm": 0.023590203374624252,
      "learning_rate": 8.107731526196621e-06,
      "loss": 0.0008,
      "step": 11951
    },
    {
      "epoch": 0.18924268093797997,
      "grad_norm": 0.12040027976036072,
      "learning_rate": 8.107573190620202e-06,
      "loss": 0.0076,
      "step": 11952
    },
    {
      "epoch": 0.18925851449562203,
      "grad_norm": 0.3476836085319519,
      "learning_rate": 8.10741485504378e-06,
      "loss": 0.01,
      "step": 11953
    },
    {
      "epoch": 0.1892743480532641,
      "grad_norm": 0.22201575338840485,
      "learning_rate": 8.10725651946736e-06,
      "loss": 0.06,
      "step": 11954
    },
    {
      "epoch": 0.18929018161090616,
      "grad_norm": 0.00560044078156352,
      "learning_rate": 8.10709818389094e-06,
      "loss": 0.0003,
      "step": 11955
    },
    {
      "epoch": 0.18930601516854823,
      "grad_norm": 0.034194573760032654,
      "learning_rate": 8.106939848314519e-06,
      "loss": 0.0021,
      "step": 11956
    },
    {
      "epoch": 0.1893218487261903,
      "grad_norm": 0.699354887008667,
      "learning_rate": 8.106781512738098e-06,
      "loss": 0.3715,
      "step": 11957
    },
    {
      "epoch": 0.18933768228383235,
      "grad_norm": 0.4942444860935211,
      "learning_rate": 8.106623177161677e-06,
      "loss": 0.7287,
      "step": 11958
    },
    {
      "epoch": 0.18935351584147442,
      "grad_norm": 0.00030454641091637313,
      "learning_rate": 8.106464841585256e-06,
      "loss": 0.0,
      "step": 11959
    },
    {
      "epoch": 0.18936934939911648,
      "grad_norm": 0.014187175780534744,
      "learning_rate": 8.106306506008835e-06,
      "loss": 0.0006,
      "step": 11960
    },
    {
      "epoch": 0.18938518295675855,
      "grad_norm": 0.0002832194440998137,
      "learning_rate": 8.106148170432416e-06,
      "loss": 0.0,
      "step": 11961
    },
    {
      "epoch": 0.1894010165144006,
      "grad_norm": 0.018133273348212242,
      "learning_rate": 8.105989834855995e-06,
      "loss": 0.0007,
      "step": 11962
    },
    {
      "epoch": 0.18941685007204268,
      "grad_norm": 0.5191219449043274,
      "learning_rate": 8.105831499279574e-06,
      "loss": 0.5418,
      "step": 11963
    },
    {
      "epoch": 0.18943268362968477,
      "grad_norm": 0.4435364305973053,
      "learning_rate": 8.105673163703153e-06,
      "loss": 0.2814,
      "step": 11964
    },
    {
      "epoch": 0.18944851718732683,
      "grad_norm": 0.36874112486839294,
      "learning_rate": 8.105514828126732e-06,
      "loss": 0.1306,
      "step": 11965
    },
    {
      "epoch": 0.1894643507449689,
      "grad_norm": 0.30073288083076477,
      "learning_rate": 8.105356492550311e-06,
      "loss": 0.0851,
      "step": 11966
    },
    {
      "epoch": 0.18948018430261096,
      "grad_norm": 0.7072228193283081,
      "learning_rate": 8.105198156973892e-06,
      "loss": 0.2837,
      "step": 11967
    },
    {
      "epoch": 0.18949601786025302,
      "grad_norm": 0.09541560709476471,
      "learning_rate": 8.105039821397471e-06,
      "loss": 0.0039,
      "step": 11968
    },
    {
      "epoch": 0.1895118514178951,
      "grad_norm": 0.8418291211128235,
      "learning_rate": 8.10488148582105e-06,
      "loss": 0.2459,
      "step": 11969
    },
    {
      "epoch": 0.18952768497553715,
      "grad_norm": 0.6417409777641296,
      "learning_rate": 8.104723150244629e-06,
      "loss": 0.1985,
      "step": 11970
    },
    {
      "epoch": 0.18954351853317922,
      "grad_norm": 0.14203540980815887,
      "learning_rate": 8.104564814668208e-06,
      "loss": 0.0029,
      "step": 11971
    },
    {
      "epoch": 0.18955935209082128,
      "grad_norm": 0.10140188783407211,
      "learning_rate": 8.104406479091787e-06,
      "loss": 0.0084,
      "step": 11972
    },
    {
      "epoch": 0.18957518564846335,
      "grad_norm": 0.5910246968269348,
      "learning_rate": 8.104248143515368e-06,
      "loss": 0.2817,
      "step": 11973
    },
    {
      "epoch": 0.1895910192061054,
      "grad_norm": 0.45694661140441895,
      "learning_rate": 8.104089807938947e-06,
      "loss": 0.4173,
      "step": 11974
    },
    {
      "epoch": 0.18960685276374747,
      "grad_norm": 0.49200838804244995,
      "learning_rate": 8.103931472362526e-06,
      "loss": 0.2514,
      "step": 11975
    },
    {
      "epoch": 0.18962268632138957,
      "grad_norm": 0.14675062894821167,
      "learning_rate": 8.103773136786105e-06,
      "loss": 0.0498,
      "step": 11976
    },
    {
      "epoch": 0.18963851987903163,
      "grad_norm": 0.8736246228218079,
      "learning_rate": 8.103614801209684e-06,
      "loss": 0.2078,
      "step": 11977
    },
    {
      "epoch": 0.1896543534366737,
      "grad_norm": 0.0060878293588757515,
      "learning_rate": 8.103456465633263e-06,
      "loss": 0.0002,
      "step": 11978
    },
    {
      "epoch": 0.18967018699431576,
      "grad_norm": 0.3091251850128174,
      "learning_rate": 8.103298130056844e-06,
      "loss": 0.0947,
      "step": 11979
    },
    {
      "epoch": 0.18968602055195782,
      "grad_norm": 0.005783377215266228,
      "learning_rate": 8.103139794480423e-06,
      "loss": 0.0002,
      "step": 11980
    },
    {
      "epoch": 0.1897018541095999,
      "grad_norm": 0.00013546645641326904,
      "learning_rate": 8.102981458904002e-06,
      "loss": 0.0,
      "step": 11981
    },
    {
      "epoch": 0.18971768766724195,
      "grad_norm": 0.04964858293533325,
      "learning_rate": 8.102823123327581e-06,
      "loss": 0.0022,
      "step": 11982
    },
    {
      "epoch": 0.18973352122488402,
      "grad_norm": 1.2541166543960571,
      "learning_rate": 8.10266478775116e-06,
      "loss": 0.2432,
      "step": 11983
    },
    {
      "epoch": 0.18974935478252608,
      "grad_norm": 0.3315892517566681,
      "learning_rate": 8.10250645217474e-06,
      "loss": 0.1061,
      "step": 11984
    },
    {
      "epoch": 0.18976518834016814,
      "grad_norm": 0.9606180787086487,
      "learning_rate": 8.102348116598319e-06,
      "loss": 0.2491,
      "step": 11985
    },
    {
      "epoch": 0.1897810218978102,
      "grad_norm": 0.5861803889274597,
      "learning_rate": 8.1021897810219e-06,
      "loss": 0.2484,
      "step": 11986
    },
    {
      "epoch": 0.18979685545545227,
      "grad_norm": 0.30755820870399475,
      "learning_rate": 8.102031445445477e-06,
      "loss": 0.0777,
      "step": 11987
    },
    {
      "epoch": 0.18981268901309437,
      "grad_norm": 0.3603355288505554,
      "learning_rate": 8.101873109869058e-06,
      "loss": 0.1724,
      "step": 11988
    },
    {
      "epoch": 0.18982852257073643,
      "grad_norm": 0.00026074537890963256,
      "learning_rate": 8.101714774292637e-06,
      "loss": 0.0,
      "step": 11989
    },
    {
      "epoch": 0.1898443561283785,
      "grad_norm": 0.06487584859132767,
      "learning_rate": 8.101556438716216e-06,
      "loss": 0.0021,
      "step": 11990
    },
    {
      "epoch": 0.18986018968602056,
      "grad_norm": 0.00010754206596175209,
      "learning_rate": 8.101398103139795e-06,
      "loss": 0.0,
      "step": 11991
    },
    {
      "epoch": 0.18987602324366262,
      "grad_norm": 0.3044436573982239,
      "learning_rate": 8.101239767563374e-06,
      "loss": 0.0702,
      "step": 11992
    },
    {
      "epoch": 0.1898918568013047,
      "grad_norm": 0.39904314279556274,
      "learning_rate": 8.101081431986953e-06,
      "loss": 0.2302,
      "step": 11993
    },
    {
      "epoch": 0.18990769035894675,
      "grad_norm": 0.211046501994133,
      "learning_rate": 8.100923096410534e-06,
      "loss": 0.0888,
      "step": 11994
    },
    {
      "epoch": 0.18992352391658882,
      "grad_norm": 0.9264864325523376,
      "learning_rate": 8.100764760834113e-06,
      "loss": 0.2631,
      "step": 11995
    },
    {
      "epoch": 0.18993935747423088,
      "grad_norm": 0.3826822340488434,
      "learning_rate": 8.100606425257692e-06,
      "loss": 0.0711,
      "step": 11996
    },
    {
      "epoch": 0.18995519103187294,
      "grad_norm": 0.3850173056125641,
      "learning_rate": 8.100448089681271e-06,
      "loss": 0.1134,
      "step": 11997
    },
    {
      "epoch": 0.189971024589515,
      "grad_norm": 0.34389883279800415,
      "learning_rate": 8.10028975410485e-06,
      "loss": 0.2867,
      "step": 11998
    },
    {
      "epoch": 0.18998685814715707,
      "grad_norm": 0.00608005141839385,
      "learning_rate": 8.100131418528429e-06,
      "loss": 0.0003,
      "step": 11999
    },
    {
      "epoch": 0.19000269170479916,
      "grad_norm": 0.39178788661956787,
      "learning_rate": 8.09997308295201e-06,
      "loss": 0.0827,
      "step": 12000
    },
    {
      "epoch": 0.19001852526244123,
      "grad_norm": 0.4355276823043823,
      "learning_rate": 8.099814747375589e-06,
      "loss": 0.3298,
      "step": 12001
    },
    {
      "epoch": 0.1900343588200833,
      "grad_norm": 0.4966047406196594,
      "learning_rate": 8.099656411799168e-06,
      "loss": 0.3932,
      "step": 12002
    },
    {
      "epoch": 0.19005019237772536,
      "grad_norm": 0.15375564992427826,
      "learning_rate": 8.099498076222747e-06,
      "loss": 0.0056,
      "step": 12003
    },
    {
      "epoch": 0.19006602593536742,
      "grad_norm": 0.014393104240298271,
      "learning_rate": 8.099339740646326e-06,
      "loss": 0.0007,
      "step": 12004
    },
    {
      "epoch": 0.1900818594930095,
      "grad_norm": 1.0855318307876587,
      "learning_rate": 8.099181405069905e-06,
      "loss": 0.0272,
      "step": 12005
    },
    {
      "epoch": 0.19009769305065155,
      "grad_norm": 0.4082592725753784,
      "learning_rate": 8.099023069493484e-06,
      "loss": 0.1075,
      "step": 12006
    },
    {
      "epoch": 0.19011352660829361,
      "grad_norm": 0.19804884493350983,
      "learning_rate": 8.098864733917065e-06,
      "loss": 0.0475,
      "step": 12007
    },
    {
      "epoch": 0.19012936016593568,
      "grad_norm": 0.5767393708229065,
      "learning_rate": 8.098706398340643e-06,
      "loss": 0.3129,
      "step": 12008
    },
    {
      "epoch": 0.19014519372357774,
      "grad_norm": 0.36209315061569214,
      "learning_rate": 8.098548062764223e-06,
      "loss": 0.1475,
      "step": 12009
    },
    {
      "epoch": 0.1901610272812198,
      "grad_norm": 0.33837103843688965,
      "learning_rate": 8.098389727187802e-06,
      "loss": 0.0308,
      "step": 12010
    },
    {
      "epoch": 0.19017686083886187,
      "grad_norm": 0.00017215976549778134,
      "learning_rate": 8.098231391611381e-06,
      "loss": 0.0,
      "step": 12011
    },
    {
      "epoch": 0.19019269439650396,
      "grad_norm": 0.005836857482790947,
      "learning_rate": 8.09807305603496e-06,
      "loss": 0.0002,
      "step": 12012
    },
    {
      "epoch": 0.19020852795414603,
      "grad_norm": 0.0002671052061486989,
      "learning_rate": 8.097914720458541e-06,
      "loss": 0.0,
      "step": 12013
    },
    {
      "epoch": 0.1902243615117881,
      "grad_norm": 0.56730055809021,
      "learning_rate": 8.097756384882119e-06,
      "loss": 0.0581,
      "step": 12014
    },
    {
      "epoch": 0.19024019506943016,
      "grad_norm": 0.006957209203392267,
      "learning_rate": 8.0975980493057e-06,
      "loss": 0.0002,
      "step": 12015
    },
    {
      "epoch": 0.19025602862707222,
      "grad_norm": 0.40284493565559387,
      "learning_rate": 8.097439713729279e-06,
      "loss": 0.054,
      "step": 12016
    },
    {
      "epoch": 0.19027186218471429,
      "grad_norm": 0.8517327904701233,
      "learning_rate": 8.097281378152858e-06,
      "loss": 0.7002,
      "step": 12017
    },
    {
      "epoch": 0.19028769574235635,
      "grad_norm": 0.4109947383403778,
      "learning_rate": 8.097123042576437e-06,
      "loss": 0.2455,
      "step": 12018
    },
    {
      "epoch": 0.19030352929999841,
      "grad_norm": 0.7403990030288696,
      "learning_rate": 8.096964707000017e-06,
      "loss": 0.0625,
      "step": 12019
    },
    {
      "epoch": 0.19031936285764048,
      "grad_norm": 0.30022498965263367,
      "learning_rate": 8.096806371423595e-06,
      "loss": 0.1224,
      "step": 12020
    },
    {
      "epoch": 0.19033519641528254,
      "grad_norm": 0.31204530596733093,
      "learning_rate": 8.096648035847176e-06,
      "loss": 0.1334,
      "step": 12021
    },
    {
      "epoch": 0.1903510299729246,
      "grad_norm": 0.27075180411338806,
      "learning_rate": 8.096489700270755e-06,
      "loss": 0.0436,
      "step": 12022
    },
    {
      "epoch": 0.19036686353056667,
      "grad_norm": 0.3219420313835144,
      "learning_rate": 8.096331364694334e-06,
      "loss": 0.1293,
      "step": 12023
    },
    {
      "epoch": 0.19038269708820876,
      "grad_norm": 0.015246137976646423,
      "learning_rate": 8.096173029117913e-06,
      "loss": 0.0006,
      "step": 12024
    },
    {
      "epoch": 0.19039853064585083,
      "grad_norm": 3.0845258152112365e-05,
      "learning_rate": 8.096014693541494e-06,
      "loss": 0.0,
      "step": 12025
    },
    {
      "epoch": 0.1904143642034929,
      "grad_norm": 0.6490685939788818,
      "learning_rate": 8.095856357965071e-06,
      "loss": 0.3322,
      "step": 12026
    },
    {
      "epoch": 0.19043019776113496,
      "grad_norm": 0.43982958793640137,
      "learning_rate": 8.095698022388652e-06,
      "loss": 0.0458,
      "step": 12027
    },
    {
      "epoch": 0.19044603131877702,
      "grad_norm": 0.3885394334793091,
      "learning_rate": 8.095539686812231e-06,
      "loss": 0.1422,
      "step": 12028
    },
    {
      "epoch": 0.19046186487641908,
      "grad_norm": 0.3571922481060028,
      "learning_rate": 8.09538135123581e-06,
      "loss": 0.2561,
      "step": 12029
    },
    {
      "epoch": 0.19047769843406115,
      "grad_norm": 0.0010682352585718036,
      "learning_rate": 8.095223015659389e-06,
      "loss": 0.0,
      "step": 12030
    },
    {
      "epoch": 0.1904935319917032,
      "grad_norm": 0.00027858209796249866,
      "learning_rate": 8.095064680082968e-06,
      "loss": 0.0,
      "step": 12031
    },
    {
      "epoch": 0.19050936554934528,
      "grad_norm": 0.2581348419189453,
      "learning_rate": 8.094906344506547e-06,
      "loss": 0.0599,
      "step": 12032
    },
    {
      "epoch": 0.19052519910698734,
      "grad_norm": 0.5980807542800903,
      "learning_rate": 8.094748008930126e-06,
      "loss": 0.1398,
      "step": 12033
    },
    {
      "epoch": 0.1905410326646294,
      "grad_norm": 0.6620728373527527,
      "learning_rate": 8.094589673353707e-06,
      "loss": 0.102,
      "step": 12034
    },
    {
      "epoch": 0.19055686622227147,
      "grad_norm": 0.2814536988735199,
      "learning_rate": 8.094431337777286e-06,
      "loss": 0.1337,
      "step": 12035
    },
    {
      "epoch": 0.19057269977991356,
      "grad_norm": 0.3349083364009857,
      "learning_rate": 8.094273002200865e-06,
      "loss": 0.1594,
      "step": 12036
    },
    {
      "epoch": 0.19058853333755563,
      "grad_norm": 0.32079532742500305,
      "learning_rate": 8.094114666624444e-06,
      "loss": 0.1481,
      "step": 12037
    },
    {
      "epoch": 0.1906043668951977,
      "grad_norm": 0.6106022000312805,
      "learning_rate": 8.093956331048023e-06,
      "loss": 0.1112,
      "step": 12038
    },
    {
      "epoch": 0.19062020045283976,
      "grad_norm": 0.39280861616134644,
      "learning_rate": 8.093797995471602e-06,
      "loss": 0.0747,
      "step": 12039
    },
    {
      "epoch": 0.19063603401048182,
      "grad_norm": 0.01338441763073206,
      "learning_rate": 8.093639659895183e-06,
      "loss": 0.0006,
      "step": 12040
    },
    {
      "epoch": 0.19065186756812388,
      "grad_norm": 0.2852362394332886,
      "learning_rate": 8.093481324318762e-06,
      "loss": 0.0801,
      "step": 12041
    },
    {
      "epoch": 0.19066770112576595,
      "grad_norm": 0.3237342834472656,
      "learning_rate": 8.093322988742341e-06,
      "loss": 0.2104,
      "step": 12042
    },
    {
      "epoch": 0.190683534683408,
      "grad_norm": 0.06438037753105164,
      "learning_rate": 8.09316465316592e-06,
      "loss": 0.0061,
      "step": 12043
    },
    {
      "epoch": 0.19069936824105008,
      "grad_norm": 0.34809282422065735,
      "learning_rate": 8.0930063175895e-06,
      "loss": 0.0985,
      "step": 12044
    },
    {
      "epoch": 0.19071520179869214,
      "grad_norm": 0.00016621363465674222,
      "learning_rate": 8.092847982013079e-06,
      "loss": 0.0,
      "step": 12045
    },
    {
      "epoch": 0.1907310353563342,
      "grad_norm": 0.3144543468952179,
      "learning_rate": 8.09268964643666e-06,
      "loss": 0.083,
      "step": 12046
    },
    {
      "epoch": 0.19074686891397627,
      "grad_norm": 0.01581273227930069,
      "learning_rate": 8.092531310860238e-06,
      "loss": 0.0007,
      "step": 12047
    },
    {
      "epoch": 0.19076270247161836,
      "grad_norm": 0.4722379744052887,
      "learning_rate": 8.092372975283818e-06,
      "loss": 0.2514,
      "step": 12048
    },
    {
      "epoch": 0.19077853602926043,
      "grad_norm": 0.15483872592449188,
      "learning_rate": 8.092214639707397e-06,
      "loss": 0.0112,
      "step": 12049
    },
    {
      "epoch": 0.1907943695869025,
      "grad_norm": 0.19569791853427887,
      "learning_rate": 8.092056304130976e-06,
      "loss": 0.0313,
      "step": 12050
    },
    {
      "epoch": 0.19081020314454455,
      "grad_norm": 8.273126877611503e-05,
      "learning_rate": 8.091897968554555e-06,
      "loss": 0.0,
      "step": 12051
    },
    {
      "epoch": 0.19082603670218662,
      "grad_norm": 0.026340309530496597,
      "learning_rate": 8.091739632978136e-06,
      "loss": 0.0012,
      "step": 12052
    },
    {
      "epoch": 0.19084187025982868,
      "grad_norm": 0.5058301091194153,
      "learning_rate": 8.091581297401715e-06,
      "loss": 0.0636,
      "step": 12053
    },
    {
      "epoch": 0.19085770381747075,
      "grad_norm": 0.26163509488105774,
      "learning_rate": 8.091422961825292e-06,
      "loss": 0.0696,
      "step": 12054
    },
    {
      "epoch": 0.1908735373751128,
      "grad_norm": 0.043615322560071945,
      "learning_rate": 8.091264626248873e-06,
      "loss": 0.0027,
      "step": 12055
    },
    {
      "epoch": 0.19088937093275488,
      "grad_norm": 0.3616260290145874,
      "learning_rate": 8.091106290672452e-06,
      "loss": 0.1099,
      "step": 12056
    },
    {
      "epoch": 0.19090520449039694,
      "grad_norm": 0.024193627759814262,
      "learning_rate": 8.090947955096031e-06,
      "loss": 0.0014,
      "step": 12057
    },
    {
      "epoch": 0.190921038048039,
      "grad_norm": 0.4928317070007324,
      "learning_rate": 8.09078961951961e-06,
      "loss": 0.337,
      "step": 12058
    },
    {
      "epoch": 0.19093687160568107,
      "grad_norm": 0.6711698174476624,
      "learning_rate": 8.090631283943189e-06,
      "loss": 0.1159,
      "step": 12059
    },
    {
      "epoch": 0.19095270516332316,
      "grad_norm": 0.27298682928085327,
      "learning_rate": 8.090472948366768e-06,
      "loss": 0.0861,
      "step": 12060
    },
    {
      "epoch": 0.19096853872096523,
      "grad_norm": 0.4797572195529938,
      "learning_rate": 8.090314612790349e-06,
      "loss": 0.5602,
      "step": 12061
    },
    {
      "epoch": 0.1909843722786073,
      "grad_norm": 0.4375014007091522,
      "learning_rate": 8.090156277213928e-06,
      "loss": 0.0597,
      "step": 12062
    },
    {
      "epoch": 0.19100020583624935,
      "grad_norm": 0.2272357940673828,
      "learning_rate": 8.089997941637507e-06,
      "loss": 0.072,
      "step": 12063
    },
    {
      "epoch": 0.19101603939389142,
      "grad_norm": 0.3263484537601471,
      "learning_rate": 8.089839606061086e-06,
      "loss": 0.1898,
      "step": 12064
    },
    {
      "epoch": 0.19103187295153348,
      "grad_norm": 0.634925365447998,
      "learning_rate": 8.089681270484665e-06,
      "loss": 0.1304,
      "step": 12065
    },
    {
      "epoch": 0.19104770650917555,
      "grad_norm": 0.39874035120010376,
      "learning_rate": 8.089522934908244e-06,
      "loss": 0.0729,
      "step": 12066
    },
    {
      "epoch": 0.1910635400668176,
      "grad_norm": 0.009783534333109856,
      "learning_rate": 8.089364599331825e-06,
      "loss": 0.0005,
      "step": 12067
    },
    {
      "epoch": 0.19107937362445968,
      "grad_norm": 0.3191453218460083,
      "learning_rate": 8.089206263755404e-06,
      "loss": 0.1376,
      "step": 12068
    },
    {
      "epoch": 0.19109520718210174,
      "grad_norm": 0.004426626022905111,
      "learning_rate": 8.089047928178983e-06,
      "loss": 0.0002,
      "step": 12069
    },
    {
      "epoch": 0.1911110407397438,
      "grad_norm": 0.6138831377029419,
      "learning_rate": 8.088889592602562e-06,
      "loss": 0.6698,
      "step": 12070
    },
    {
      "epoch": 0.19112687429738587,
      "grad_norm": 0.5074564814567566,
      "learning_rate": 8.088731257026141e-06,
      "loss": 0.2637,
      "step": 12071
    },
    {
      "epoch": 0.19114270785502793,
      "grad_norm": 0.847014307975769,
      "learning_rate": 8.08857292144972e-06,
      "loss": 0.1059,
      "step": 12072
    },
    {
      "epoch": 0.19115854141267002,
      "grad_norm": 6.966812361497432e-05,
      "learning_rate": 8.088414585873301e-06,
      "loss": 0.0,
      "step": 12073
    },
    {
      "epoch": 0.1911743749703121,
      "grad_norm": 0.4180857539176941,
      "learning_rate": 8.08825625029688e-06,
      "loss": 0.062,
      "step": 12074
    },
    {
      "epoch": 0.19119020852795415,
      "grad_norm": 0.4808066785335541,
      "learning_rate": 8.08809791472046e-06,
      "loss": 0.051,
      "step": 12075
    },
    {
      "epoch": 0.19120604208559622,
      "grad_norm": 0.4493076205253601,
      "learning_rate": 8.087939579144039e-06,
      "loss": 0.1556,
      "step": 12076
    },
    {
      "epoch": 0.19122187564323828,
      "grad_norm": 0.8211926221847534,
      "learning_rate": 8.087781243567618e-06,
      "loss": 0.1147,
      "step": 12077
    },
    {
      "epoch": 0.19123770920088035,
      "grad_norm": 0.30582118034362793,
      "learning_rate": 8.087622907991197e-06,
      "loss": 0.0453,
      "step": 12078
    },
    {
      "epoch": 0.1912535427585224,
      "grad_norm": 0.350209504365921,
      "learning_rate": 8.087464572414776e-06,
      "loss": 0.301,
      "step": 12079
    },
    {
      "epoch": 0.19126937631616447,
      "grad_norm": 0.5176728367805481,
      "learning_rate": 8.087306236838357e-06,
      "loss": 0.1709,
      "step": 12080
    },
    {
      "epoch": 0.19128520987380654,
      "grad_norm": 0.4846093952655792,
      "learning_rate": 8.087147901261934e-06,
      "loss": 0.2744,
      "step": 12081
    },
    {
      "epoch": 0.1913010434314486,
      "grad_norm": 0.019413940608501434,
      "learning_rate": 8.086989565685515e-06,
      "loss": 0.0008,
      "step": 12082
    },
    {
      "epoch": 0.19131687698909067,
      "grad_norm": 0.4395705461502075,
      "learning_rate": 8.086831230109094e-06,
      "loss": 0.2892,
      "step": 12083
    },
    {
      "epoch": 0.19133271054673273,
      "grad_norm": 0.0016955487662926316,
      "learning_rate": 8.086672894532673e-06,
      "loss": 0.0,
      "step": 12084
    },
    {
      "epoch": 0.19134854410437482,
      "grad_norm": 0.03377094492316246,
      "learning_rate": 8.086514558956252e-06,
      "loss": 0.0006,
      "step": 12085
    },
    {
      "epoch": 0.1913643776620169,
      "grad_norm": 0.00019455341680441052,
      "learning_rate": 8.086356223379833e-06,
      "loss": 0.0,
      "step": 12086
    },
    {
      "epoch": 0.19138021121965895,
      "grad_norm": 0.6002988815307617,
      "learning_rate": 8.08619788780341e-06,
      "loss": 0.1649,
      "step": 12087
    },
    {
      "epoch": 0.19139604477730102,
      "grad_norm": 0.20239605009555817,
      "learning_rate": 8.086039552226991e-06,
      "loss": 0.0564,
      "step": 12088
    },
    {
      "epoch": 0.19141187833494308,
      "grad_norm": 0.3082485496997833,
      "learning_rate": 8.08588121665057e-06,
      "loss": 0.0457,
      "step": 12089
    },
    {
      "epoch": 0.19142771189258515,
      "grad_norm": 0.18475241959095,
      "learning_rate": 8.085722881074149e-06,
      "loss": 0.0361,
      "step": 12090
    },
    {
      "epoch": 0.1914435454502272,
      "grad_norm": 0.007642452605068684,
      "learning_rate": 8.085564545497728e-06,
      "loss": 0.0003,
      "step": 12091
    },
    {
      "epoch": 0.19145937900786927,
      "grad_norm": 0.454339861869812,
      "learning_rate": 8.085406209921309e-06,
      "loss": 0.1087,
      "step": 12092
    },
    {
      "epoch": 0.19147521256551134,
      "grad_norm": 0.5138739943504333,
      "learning_rate": 8.085247874344886e-06,
      "loss": 0.3123,
      "step": 12093
    },
    {
      "epoch": 0.1914910461231534,
      "grad_norm": 0.20714490115642548,
      "learning_rate": 8.085089538768467e-06,
      "loss": 0.0596,
      "step": 12094
    },
    {
      "epoch": 0.19150687968079547,
      "grad_norm": 0.031032584607601166,
      "learning_rate": 8.084931203192046e-06,
      "loss": 0.0013,
      "step": 12095
    },
    {
      "epoch": 0.19152271323843753,
      "grad_norm": 0.43046069145202637,
      "learning_rate": 8.084772867615625e-06,
      "loss": 0.1809,
      "step": 12096
    },
    {
      "epoch": 0.19153854679607962,
      "grad_norm": 0.6625990867614746,
      "learning_rate": 8.084614532039204e-06,
      "loss": 0.0194,
      "step": 12097
    },
    {
      "epoch": 0.1915543803537217,
      "grad_norm": 0.2657633125782013,
      "learning_rate": 8.084456196462785e-06,
      "loss": 0.1937,
      "step": 12098
    },
    {
      "epoch": 0.19157021391136375,
      "grad_norm": 0.29217880964279175,
      "learning_rate": 8.084297860886362e-06,
      "loss": 0.0996,
      "step": 12099
    },
    {
      "epoch": 0.19158604746900582,
      "grad_norm": 0.560469925403595,
      "learning_rate": 8.084139525309943e-06,
      "loss": 0.5855,
      "step": 12100
    },
    {
      "epoch": 0.19160188102664788,
      "grad_norm": 0.01866907812654972,
      "learning_rate": 8.083981189733522e-06,
      "loss": 0.0008,
      "step": 12101
    },
    {
      "epoch": 0.19161771458428994,
      "grad_norm": 0.3156908452510834,
      "learning_rate": 8.083822854157101e-06,
      "loss": 0.082,
      "step": 12102
    },
    {
      "epoch": 0.191633548141932,
      "grad_norm": 0.017320886254310608,
      "learning_rate": 8.08366451858068e-06,
      "loss": 0.0007,
      "step": 12103
    },
    {
      "epoch": 0.19164938169957407,
      "grad_norm": 0.9393236637115479,
      "learning_rate": 8.08350618300426e-06,
      "loss": 0.1029,
      "step": 12104
    },
    {
      "epoch": 0.19166521525721614,
      "grad_norm": 0.4940210282802582,
      "learning_rate": 8.083347847427839e-06,
      "loss": 0.1681,
      "step": 12105
    },
    {
      "epoch": 0.1916810488148582,
      "grad_norm": 0.9960471987724304,
      "learning_rate": 8.083189511851418e-06,
      "loss": 0.153,
      "step": 12106
    },
    {
      "epoch": 0.19169688237250027,
      "grad_norm": 0.9667202234268188,
      "learning_rate": 8.083031176274999e-06,
      "loss": 0.704,
      "step": 12107
    },
    {
      "epoch": 0.19171271593014233,
      "grad_norm": 2.6412272453308105,
      "learning_rate": 8.082872840698578e-06,
      "loss": 0.3709,
      "step": 12108
    },
    {
      "epoch": 0.19172854948778442,
      "grad_norm": 0.4442639946937561,
      "learning_rate": 8.082714505122157e-06,
      "loss": 0.0597,
      "step": 12109
    },
    {
      "epoch": 0.1917443830454265,
      "grad_norm": 0.025381317362189293,
      "learning_rate": 8.082556169545736e-06,
      "loss": 0.0015,
      "step": 12110
    },
    {
      "epoch": 0.19176021660306855,
      "grad_norm": 0.5672957897186279,
      "learning_rate": 8.082397833969315e-06,
      "loss": 0.2712,
      "step": 12111
    },
    {
      "epoch": 0.19177605016071061,
      "grad_norm": 0.2932877540588379,
      "learning_rate": 8.082239498392894e-06,
      "loss": 0.0796,
      "step": 12112
    },
    {
      "epoch": 0.19179188371835268,
      "grad_norm": 0.5728539824485779,
      "learning_rate": 8.082081162816475e-06,
      "loss": 0.204,
      "step": 12113
    },
    {
      "epoch": 0.19180771727599474,
      "grad_norm": 0.9947941303253174,
      "learning_rate": 8.081922827240054e-06,
      "loss": 0.9012,
      "step": 12114
    },
    {
      "epoch": 0.1918235508336368,
      "grad_norm": 0.14574603736400604,
      "learning_rate": 8.081764491663633e-06,
      "loss": 0.0522,
      "step": 12115
    },
    {
      "epoch": 0.19183938439127887,
      "grad_norm": 0.19541659951210022,
      "learning_rate": 8.081606156087212e-06,
      "loss": 0.0526,
      "step": 12116
    },
    {
      "epoch": 0.19185521794892094,
      "grad_norm": 0.011066758073866367,
      "learning_rate": 8.081447820510791e-06,
      "loss": 0.0005,
      "step": 12117
    },
    {
      "epoch": 0.191871051506563,
      "grad_norm": 0.3008597493171692,
      "learning_rate": 8.08128948493437e-06,
      "loss": 0.0176,
      "step": 12118
    },
    {
      "epoch": 0.19188688506420506,
      "grad_norm": 0.5394198298454285,
      "learning_rate": 8.081131149357951e-06,
      "loss": 0.6666,
      "step": 12119
    },
    {
      "epoch": 0.19190271862184713,
      "grad_norm": 0.2515118718147278,
      "learning_rate": 8.080972813781528e-06,
      "loss": 0.1126,
      "step": 12120
    },
    {
      "epoch": 0.19191855217948922,
      "grad_norm": 0.0008411856833845377,
      "learning_rate": 8.080814478205109e-06,
      "loss": 0.0,
      "step": 12121
    },
    {
      "epoch": 0.19193438573713129,
      "grad_norm": 0.4732096493244171,
      "learning_rate": 8.080656142628688e-06,
      "loss": 0.1109,
      "step": 12122
    },
    {
      "epoch": 0.19195021929477335,
      "grad_norm": 0.5766212344169617,
      "learning_rate": 8.080497807052267e-06,
      "loss": 0.253,
      "step": 12123
    },
    {
      "epoch": 0.19196605285241541,
      "grad_norm": 0.1164514422416687,
      "learning_rate": 8.080339471475846e-06,
      "loss": 0.0355,
      "step": 12124
    },
    {
      "epoch": 0.19198188641005748,
      "grad_norm": 0.05457243323326111,
      "learning_rate": 8.080181135899427e-06,
      "loss": 0.0035,
      "step": 12125
    },
    {
      "epoch": 0.19199771996769954,
      "grad_norm": 0.5451246500015259,
      "learning_rate": 8.080022800323004e-06,
      "loss": 0.1472,
      "step": 12126
    },
    {
      "epoch": 0.1920135535253416,
      "grad_norm": 1.1998255252838135,
      "learning_rate": 8.079864464746583e-06,
      "loss": 0.0523,
      "step": 12127
    },
    {
      "epoch": 0.19202938708298367,
      "grad_norm": 0.7355252504348755,
      "learning_rate": 8.079706129170164e-06,
      "loss": 0.1236,
      "step": 12128
    },
    {
      "epoch": 0.19204522064062574,
      "grad_norm": 0.0008851204765960574,
      "learning_rate": 8.079547793593743e-06,
      "loss": 0.0,
      "step": 12129
    },
    {
      "epoch": 0.1920610541982678,
      "grad_norm": 0.23024314641952515,
      "learning_rate": 8.079389458017322e-06,
      "loss": 0.0897,
      "step": 12130
    },
    {
      "epoch": 0.19207688775590986,
      "grad_norm": 0.0029935354832559824,
      "learning_rate": 8.079231122440902e-06,
      "loss": 0.0,
      "step": 12131
    },
    {
      "epoch": 0.19209272131355193,
      "grad_norm": 0.28120940923690796,
      "learning_rate": 8.07907278686448e-06,
      "loss": 0.1367,
      "step": 12132
    },
    {
      "epoch": 0.19210855487119402,
      "grad_norm": 0.6600544452667236,
      "learning_rate": 8.07891445128806e-06,
      "loss": 0.4683,
      "step": 12133
    },
    {
      "epoch": 0.19212438842883608,
      "grad_norm": 0.531469464302063,
      "learning_rate": 8.07875611571164e-06,
      "loss": 0.1044,
      "step": 12134
    },
    {
      "epoch": 0.19214022198647815,
      "grad_norm": 0.35837221145629883,
      "learning_rate": 8.07859778013522e-06,
      "loss": 0.4406,
      "step": 12135
    },
    {
      "epoch": 0.1921560555441202,
      "grad_norm": 0.3486006259918213,
      "learning_rate": 8.078439444558799e-06,
      "loss": 0.0448,
      "step": 12136
    },
    {
      "epoch": 0.19217188910176228,
      "grad_norm": 1.71564519405365,
      "learning_rate": 8.078281108982378e-06,
      "loss": 0.1912,
      "step": 12137
    },
    {
      "epoch": 0.19218772265940434,
      "grad_norm": 0.5268726348876953,
      "learning_rate": 8.078122773405957e-06,
      "loss": 0.1921,
      "step": 12138
    },
    {
      "epoch": 0.1922035562170464,
      "grad_norm": 0.3229639232158661,
      "learning_rate": 8.077964437829536e-06,
      "loss": 0.1335,
      "step": 12139
    },
    {
      "epoch": 0.19221938977468847,
      "grad_norm": 0.5357953310012817,
      "learning_rate": 8.077806102253117e-06,
      "loss": 0.3362,
      "step": 12140
    },
    {
      "epoch": 0.19223522333233053,
      "grad_norm": 0.38024935126304626,
      "learning_rate": 8.077647766676696e-06,
      "loss": 0.0772,
      "step": 12141
    },
    {
      "epoch": 0.1922510568899726,
      "grad_norm": 0.453066349029541,
      "learning_rate": 8.077489431100275e-06,
      "loss": 0.189,
      "step": 12142
    },
    {
      "epoch": 0.19226689044761466,
      "grad_norm": 0.5333476066589355,
      "learning_rate": 8.077331095523854e-06,
      "loss": 0.5637,
      "step": 12143
    },
    {
      "epoch": 0.19228272400525673,
      "grad_norm": 0.003987254109233618,
      "learning_rate": 8.077172759947433e-06,
      "loss": 0.0002,
      "step": 12144
    },
    {
      "epoch": 0.19229855756289882,
      "grad_norm": 0.3999215364456177,
      "learning_rate": 8.077014424371012e-06,
      "loss": 0.187,
      "step": 12145
    },
    {
      "epoch": 0.19231439112054088,
      "grad_norm": 0.34911906719207764,
      "learning_rate": 8.076856088794593e-06,
      "loss": 0.0808,
      "step": 12146
    },
    {
      "epoch": 0.19233022467818295,
      "grad_norm": 0.00020891193707939237,
      "learning_rate": 8.076697753218172e-06,
      "loss": 0.0,
      "step": 12147
    },
    {
      "epoch": 0.192346058235825,
      "grad_norm": 0.3810538053512573,
      "learning_rate": 8.076539417641751e-06,
      "loss": 0.162,
      "step": 12148
    },
    {
      "epoch": 0.19236189179346708,
      "grad_norm": 0.1993432343006134,
      "learning_rate": 8.07638108206533e-06,
      "loss": 0.0887,
      "step": 12149
    },
    {
      "epoch": 0.19237772535110914,
      "grad_norm": 0.3960641324520111,
      "learning_rate": 8.076222746488909e-06,
      "loss": 0.1453,
      "step": 12150
    },
    {
      "epoch": 0.1923935589087512,
      "grad_norm": 0.258321076631546,
      "learning_rate": 8.076064410912488e-06,
      "loss": 0.0533,
      "step": 12151
    },
    {
      "epoch": 0.19240939246639327,
      "grad_norm": 0.36980709433555603,
      "learning_rate": 8.075906075336067e-06,
      "loss": 0.0748,
      "step": 12152
    },
    {
      "epoch": 0.19242522602403533,
      "grad_norm": 0.014005293138325214,
      "learning_rate": 8.075747739759648e-06,
      "loss": 0.0006,
      "step": 12153
    },
    {
      "epoch": 0.1924410595816774,
      "grad_norm": 0.2852001190185547,
      "learning_rate": 8.075589404183225e-06,
      "loss": 0.1213,
      "step": 12154
    },
    {
      "epoch": 0.19245689313931946,
      "grad_norm": 0.14767351746559143,
      "learning_rate": 8.075431068606806e-06,
      "loss": 0.0467,
      "step": 12155
    },
    {
      "epoch": 0.19247272669696153,
      "grad_norm": 0.018446166068315506,
      "learning_rate": 8.075272733030385e-06,
      "loss": 0.0009,
      "step": 12156
    },
    {
      "epoch": 0.19248856025460362,
      "grad_norm": 0.502207338809967,
      "learning_rate": 8.075114397453964e-06,
      "loss": 0.3143,
      "step": 12157
    },
    {
      "epoch": 0.19250439381224568,
      "grad_norm": 0.009742187336087227,
      "learning_rate": 8.074956061877543e-06,
      "loss": 0.0004,
      "step": 12158
    },
    {
      "epoch": 0.19252022736988775,
      "grad_norm": 7.885855302447453e-05,
      "learning_rate": 8.074797726301124e-06,
      "loss": 0.0,
      "step": 12159
    },
    {
      "epoch": 0.1925360609275298,
      "grad_norm": 3.403650407562964e-05,
      "learning_rate": 8.074639390724702e-06,
      "loss": 0.0,
      "step": 12160
    },
    {
      "epoch": 0.19255189448517188,
      "grad_norm": 0.02235877327620983,
      "learning_rate": 8.074481055148282e-06,
      "loss": 0.0011,
      "step": 12161
    },
    {
      "epoch": 0.19256772804281394,
      "grad_norm": 8.21736321086064e-05,
      "learning_rate": 8.074322719571861e-06,
      "loss": 0.0,
      "step": 12162
    },
    {
      "epoch": 0.192583561600456,
      "grad_norm": 0.1908508837223053,
      "learning_rate": 8.07416438399544e-06,
      "loss": 0.042,
      "step": 12163
    },
    {
      "epoch": 0.19259939515809807,
      "grad_norm": 0.21418598294258118,
      "learning_rate": 8.07400604841902e-06,
      "loss": 0.0263,
      "step": 12164
    },
    {
      "epoch": 0.19261522871574013,
      "grad_norm": 0.47488418221473694,
      "learning_rate": 8.0738477128426e-06,
      "loss": 0.1399,
      "step": 12165
    },
    {
      "epoch": 0.1926310622733822,
      "grad_norm": 0.16505300998687744,
      "learning_rate": 8.073689377266178e-06,
      "loss": 0.0742,
      "step": 12166
    },
    {
      "epoch": 0.19264689583102426,
      "grad_norm": 0.2004198580980301,
      "learning_rate": 8.073531041689759e-06,
      "loss": 0.1153,
      "step": 12167
    },
    {
      "epoch": 0.19266272938866633,
      "grad_norm": 0.05832984670996666,
      "learning_rate": 8.073372706113338e-06,
      "loss": 0.0025,
      "step": 12168
    },
    {
      "epoch": 0.19267856294630842,
      "grad_norm": 0.03781462833285332,
      "learning_rate": 8.073214370536917e-06,
      "loss": 0.0012,
      "step": 12169
    },
    {
      "epoch": 0.19269439650395048,
      "grad_norm": 0.39021632075309753,
      "learning_rate": 8.073056034960496e-06,
      "loss": 0.1764,
      "step": 12170
    },
    {
      "epoch": 0.19271023006159255,
      "grad_norm": 0.14259231090545654,
      "learning_rate": 8.072897699384077e-06,
      "loss": 0.0082,
      "step": 12171
    },
    {
      "epoch": 0.1927260636192346,
      "grad_norm": 0.45126110315322876,
      "learning_rate": 8.072739363807654e-06,
      "loss": 0.1747,
      "step": 12172
    },
    {
      "epoch": 0.19274189717687668,
      "grad_norm": 0.006430075969547033,
      "learning_rate": 8.072581028231235e-06,
      "loss": 0.0003,
      "step": 12173
    },
    {
      "epoch": 0.19275773073451874,
      "grad_norm": 0.3583245575428009,
      "learning_rate": 8.072422692654814e-06,
      "loss": 0.2768,
      "step": 12174
    },
    {
      "epoch": 0.1927735642921608,
      "grad_norm": 0.01698969304561615,
      "learning_rate": 8.072264357078393e-06,
      "loss": 0.0007,
      "step": 12175
    },
    {
      "epoch": 0.19278939784980287,
      "grad_norm": 0.039278294891119,
      "learning_rate": 8.072106021501972e-06,
      "loss": 0.0017,
      "step": 12176
    },
    {
      "epoch": 0.19280523140744493,
      "grad_norm": 0.924575686454773,
      "learning_rate": 8.071947685925551e-06,
      "loss": 0.6509,
      "step": 12177
    },
    {
      "epoch": 0.192821064965087,
      "grad_norm": 0.2928105294704437,
      "learning_rate": 8.07178935034913e-06,
      "loss": 0.0769,
      "step": 12178
    },
    {
      "epoch": 0.19283689852272906,
      "grad_norm": 0.44321614503860474,
      "learning_rate": 8.07163101477271e-06,
      "loss": 0.1847,
      "step": 12179
    },
    {
      "epoch": 0.19285273208037113,
      "grad_norm": 0.1673637330532074,
      "learning_rate": 8.07147267919629e-06,
      "loss": 0.0577,
      "step": 12180
    },
    {
      "epoch": 0.19286856563801322,
      "grad_norm": 0.7412277460098267,
      "learning_rate": 8.071314343619869e-06,
      "loss": 0.5107,
      "step": 12181
    },
    {
      "epoch": 0.19288439919565528,
      "grad_norm": 0.0069020953960716724,
      "learning_rate": 8.071156008043448e-06,
      "loss": 0.0003,
      "step": 12182
    },
    {
      "epoch": 0.19290023275329735,
      "grad_norm": 1.1409131288528442,
      "learning_rate": 8.070997672467027e-06,
      "loss": 0.4346,
      "step": 12183
    },
    {
      "epoch": 0.1929160663109394,
      "grad_norm": 0.3864244520664215,
      "learning_rate": 8.070839336890606e-06,
      "loss": 0.3974,
      "step": 12184
    },
    {
      "epoch": 0.19293189986858147,
      "grad_norm": 0.41634082794189453,
      "learning_rate": 8.070681001314185e-06,
      "loss": 0.9906,
      "step": 12185
    },
    {
      "epoch": 0.19294773342622354,
      "grad_norm": 0.1904679834842682,
      "learning_rate": 8.070522665737766e-06,
      "loss": 0.0529,
      "step": 12186
    },
    {
      "epoch": 0.1929635669838656,
      "grad_norm": 0.6763918399810791,
      "learning_rate": 8.070364330161344e-06,
      "loss": 0.1183,
      "step": 12187
    },
    {
      "epoch": 0.19297940054150767,
      "grad_norm": 0.9933537840843201,
      "learning_rate": 8.070205994584924e-06,
      "loss": 0.0887,
      "step": 12188
    },
    {
      "epoch": 0.19299523409914973,
      "grad_norm": 0.0025432587135583162,
      "learning_rate": 8.070047659008503e-06,
      "loss": 0.0001,
      "step": 12189
    },
    {
      "epoch": 0.1930110676567918,
      "grad_norm": 0.31490573287010193,
      "learning_rate": 8.069889323432082e-06,
      "loss": 0.1572,
      "step": 12190
    },
    {
      "epoch": 0.19302690121443386,
      "grad_norm": 0.02153749018907547,
      "learning_rate": 8.069730987855662e-06,
      "loss": 0.0012,
      "step": 12191
    },
    {
      "epoch": 0.19304273477207592,
      "grad_norm": 0.26803961396217346,
      "learning_rate": 8.069572652279242e-06,
      "loss": 0.0241,
      "step": 12192
    },
    {
      "epoch": 0.19305856832971802,
      "grad_norm": 0.034711938351392746,
      "learning_rate": 8.06941431670282e-06,
      "loss": 0.0017,
      "step": 12193
    },
    {
      "epoch": 0.19307440188736008,
      "grad_norm": 0.0061550261452794075,
      "learning_rate": 8.0692559811264e-06,
      "loss": 0.0002,
      "step": 12194
    },
    {
      "epoch": 0.19309023544500215,
      "grad_norm": 0.2497105896472931,
      "learning_rate": 8.06909764554998e-06,
      "loss": 0.0265,
      "step": 12195
    },
    {
      "epoch": 0.1931060690026442,
      "grad_norm": 0.3798912465572357,
      "learning_rate": 8.068939309973559e-06,
      "loss": 0.3218,
      "step": 12196
    },
    {
      "epoch": 0.19312190256028627,
      "grad_norm": 0.01795070618391037,
      "learning_rate": 8.068780974397138e-06,
      "loss": 0.0009,
      "step": 12197
    },
    {
      "epoch": 0.19313773611792834,
      "grad_norm": 0.2761204242706299,
      "learning_rate": 8.068622638820718e-06,
      "loss": 0.1265,
      "step": 12198
    },
    {
      "epoch": 0.1931535696755704,
      "grad_norm": 0.4971052408218384,
      "learning_rate": 8.068464303244296e-06,
      "loss": 0.0287,
      "step": 12199
    },
    {
      "epoch": 0.19316940323321247,
      "grad_norm": 0.44731515645980835,
      "learning_rate": 8.068305967667875e-06,
      "loss": 0.35,
      "step": 12200
    },
    {
      "epoch": 0.19318523679085453,
      "grad_norm": 0.43780091404914856,
      "learning_rate": 8.068147632091456e-06,
      "loss": 0.3322,
      "step": 12201
    },
    {
      "epoch": 0.1932010703484966,
      "grad_norm": 0.30006474256515503,
      "learning_rate": 8.067989296515035e-06,
      "loss": 0.0742,
      "step": 12202
    },
    {
      "epoch": 0.19321690390613866,
      "grad_norm": 0.4722117483615875,
      "learning_rate": 8.067830960938614e-06,
      "loss": 0.1403,
      "step": 12203
    },
    {
      "epoch": 0.19323273746378072,
      "grad_norm": 0.6149672865867615,
      "learning_rate": 8.067672625362193e-06,
      "loss": 0.2686,
      "step": 12204
    },
    {
      "epoch": 0.19324857102142282,
      "grad_norm": 0.02144389972090721,
      "learning_rate": 8.067514289785772e-06,
      "loss": 0.0006,
      "step": 12205
    },
    {
      "epoch": 0.19326440457906488,
      "grad_norm": 0.001251067384146154,
      "learning_rate": 8.067355954209351e-06,
      "loss": 0.0,
      "step": 12206
    },
    {
      "epoch": 0.19328023813670694,
      "grad_norm": 0.004372300114482641,
      "learning_rate": 8.067197618632932e-06,
      "loss": 0.0002,
      "step": 12207
    },
    {
      "epoch": 0.193296071694349,
      "grad_norm": 0.191510871052742,
      "learning_rate": 8.067039283056511e-06,
      "loss": 0.042,
      "step": 12208
    },
    {
      "epoch": 0.19331190525199107,
      "grad_norm": 0.3793947398662567,
      "learning_rate": 8.06688094748009e-06,
      "loss": 0.1662,
      "step": 12209
    },
    {
      "epoch": 0.19332773880963314,
      "grad_norm": 0.3626631796360016,
      "learning_rate": 8.066722611903669e-06,
      "loss": 0.0731,
      "step": 12210
    },
    {
      "epoch": 0.1933435723672752,
      "grad_norm": 0.1585492491722107,
      "learning_rate": 8.066564276327248e-06,
      "loss": 0.0523,
      "step": 12211
    },
    {
      "epoch": 0.19335940592491727,
      "grad_norm": 0.02932264283299446,
      "learning_rate": 8.066405940750827e-06,
      "loss": 0.0018,
      "step": 12212
    },
    {
      "epoch": 0.19337523948255933,
      "grad_norm": 0.3475974500179291,
      "learning_rate": 8.066247605174408e-06,
      "loss": 0.1849,
      "step": 12213
    },
    {
      "epoch": 0.1933910730402014,
      "grad_norm": 0.3851131200790405,
      "learning_rate": 8.066089269597987e-06,
      "loss": 0.3497,
      "step": 12214
    },
    {
      "epoch": 0.19340690659784346,
      "grad_norm": 0.4262767732143402,
      "learning_rate": 8.065930934021566e-06,
      "loss": 0.2272,
      "step": 12215
    },
    {
      "epoch": 0.19342274015548552,
      "grad_norm": 0.0001510589208919555,
      "learning_rate": 8.065772598445145e-06,
      "loss": 0.0,
      "step": 12216
    },
    {
      "epoch": 0.19343857371312762,
      "grad_norm": 0.29506340622901917,
      "learning_rate": 8.065614262868724e-06,
      "loss": 0.0696,
      "step": 12217
    },
    {
      "epoch": 0.19345440727076968,
      "grad_norm": 0.4999586045742035,
      "learning_rate": 8.065455927292303e-06,
      "loss": 0.3381,
      "step": 12218
    },
    {
      "epoch": 0.19347024082841174,
      "grad_norm": 0.4522227346897125,
      "learning_rate": 8.065297591715884e-06,
      "loss": 0.189,
      "step": 12219
    },
    {
      "epoch": 0.1934860743860538,
      "grad_norm": 0.845120370388031,
      "learning_rate": 8.065139256139463e-06,
      "loss": 0.5602,
      "step": 12220
    },
    {
      "epoch": 0.19350190794369587,
      "grad_norm": 0.38513076305389404,
      "learning_rate": 8.064980920563042e-06,
      "loss": 0.0408,
      "step": 12221
    },
    {
      "epoch": 0.19351774150133794,
      "grad_norm": 0.2758466303348541,
      "learning_rate": 8.064822584986621e-06,
      "loss": 0.1252,
      "step": 12222
    },
    {
      "epoch": 0.19353357505898,
      "grad_norm": 0.08973277360200882,
      "learning_rate": 8.0646642494102e-06,
      "loss": 0.0208,
      "step": 12223
    },
    {
      "epoch": 0.19354940861662207,
      "grad_norm": 0.1890992671251297,
      "learning_rate": 8.06450591383378e-06,
      "loss": 0.0028,
      "step": 12224
    },
    {
      "epoch": 0.19356524217426413,
      "grad_norm": 0.5959390997886658,
      "learning_rate": 8.064347578257359e-06,
      "loss": 0.5569,
      "step": 12225
    },
    {
      "epoch": 0.1935810757319062,
      "grad_norm": 0.01729152537882328,
      "learning_rate": 8.06418924268094e-06,
      "loss": 0.0008,
      "step": 12226
    },
    {
      "epoch": 0.19359690928954826,
      "grad_norm": 0.33893662691116333,
      "learning_rate": 8.064030907104517e-06,
      "loss": 0.1388,
      "step": 12227
    },
    {
      "epoch": 0.19361274284719032,
      "grad_norm": 0.6162415742874146,
      "learning_rate": 8.063872571528098e-06,
      "loss": 0.1902,
      "step": 12228
    },
    {
      "epoch": 0.19362857640483241,
      "grad_norm": 0.45507219433784485,
      "learning_rate": 8.063714235951677e-06,
      "loss": 0.1483,
      "step": 12229
    },
    {
      "epoch": 0.19364440996247448,
      "grad_norm": 0.0001742964086588472,
      "learning_rate": 8.063555900375256e-06,
      "loss": 0.0,
      "step": 12230
    },
    {
      "epoch": 0.19366024352011654,
      "grad_norm": 0.6006483435630798,
      "learning_rate": 8.063397564798835e-06,
      "loss": 0.0891,
      "step": 12231
    },
    {
      "epoch": 0.1936760770777586,
      "grad_norm": 0.35002341866493225,
      "learning_rate": 8.063239229222416e-06,
      "loss": 0.0694,
      "step": 12232
    },
    {
      "epoch": 0.19369191063540067,
      "grad_norm": 0.6625190377235413,
      "learning_rate": 8.063080893645993e-06,
      "loss": 0.0829,
      "step": 12233
    },
    {
      "epoch": 0.19370774419304274,
      "grad_norm": 0.019434699788689613,
      "learning_rate": 8.062922558069574e-06,
      "loss": 0.001,
      "step": 12234
    },
    {
      "epoch": 0.1937235777506848,
      "grad_norm": 0.729441225528717,
      "learning_rate": 8.062764222493153e-06,
      "loss": 0.2592,
      "step": 12235
    },
    {
      "epoch": 0.19373941130832686,
      "grad_norm": 0.580655574798584,
      "learning_rate": 8.062605886916732e-06,
      "loss": 0.2349,
      "step": 12236
    },
    {
      "epoch": 0.19375524486596893,
      "grad_norm": 0.21191371977329254,
      "learning_rate": 8.062447551340311e-06,
      "loss": 0.0781,
      "step": 12237
    },
    {
      "epoch": 0.193771078423611,
      "grad_norm": 0.46890467405319214,
      "learning_rate": 8.062289215763892e-06,
      "loss": 0.4726,
      "step": 12238
    },
    {
      "epoch": 0.19378691198125306,
      "grad_norm": 0.6088157892227173,
      "learning_rate": 8.06213088018747e-06,
      "loss": 0.0967,
      "step": 12239
    },
    {
      "epoch": 0.19380274553889512,
      "grad_norm": 0.11356810480356216,
      "learning_rate": 8.06197254461105e-06,
      "loss": 0.0025,
      "step": 12240
    },
    {
      "epoch": 0.1938185790965372,
      "grad_norm": 0.4726885259151459,
      "learning_rate": 8.061814209034629e-06,
      "loss": 0.1053,
      "step": 12241
    },
    {
      "epoch": 0.19383441265417928,
      "grad_norm": 0.028608540073037148,
      "learning_rate": 8.061655873458208e-06,
      "loss": 0.0014,
      "step": 12242
    },
    {
      "epoch": 0.19385024621182134,
      "grad_norm": 0.34261372685432434,
      "learning_rate": 8.061497537881787e-06,
      "loss": 0.076,
      "step": 12243
    },
    {
      "epoch": 0.1938660797694634,
      "grad_norm": 0.5069913864135742,
      "learning_rate": 8.061339202305368e-06,
      "loss": 0.1574,
      "step": 12244
    },
    {
      "epoch": 0.19388191332710547,
      "grad_norm": 0.0002886457950808108,
      "learning_rate": 8.061180866728945e-06,
      "loss": 0.0,
      "step": 12245
    },
    {
      "epoch": 0.19389774688474753,
      "grad_norm": 0.20136509835720062,
      "learning_rate": 8.061022531152526e-06,
      "loss": 0.1143,
      "step": 12246
    },
    {
      "epoch": 0.1939135804423896,
      "grad_norm": 0.23215782642364502,
      "learning_rate": 8.060864195576105e-06,
      "loss": 0.0597,
      "step": 12247
    },
    {
      "epoch": 0.19392941400003166,
      "grad_norm": 0.3233107030391693,
      "learning_rate": 8.060705859999684e-06,
      "loss": 0.1261,
      "step": 12248
    },
    {
      "epoch": 0.19394524755767373,
      "grad_norm": 0.3870816230773926,
      "learning_rate": 8.060547524423263e-06,
      "loss": 0.1081,
      "step": 12249
    },
    {
      "epoch": 0.1939610811153158,
      "grad_norm": 0.5892719626426697,
      "learning_rate": 8.060389188846842e-06,
      "loss": 0.0835,
      "step": 12250
    },
    {
      "epoch": 0.19397691467295786,
      "grad_norm": 0.020220626145601273,
      "learning_rate": 8.060230853270422e-06,
      "loss": 0.0009,
      "step": 12251
    },
    {
      "epoch": 0.19399274823059992,
      "grad_norm": 0.1443980187177658,
      "learning_rate": 8.060072517694e-06,
      "loss": 0.0498,
      "step": 12252
    },
    {
      "epoch": 0.194008581788242,
      "grad_norm": 0.4856865704059601,
      "learning_rate": 8.059914182117581e-06,
      "loss": 0.2009,
      "step": 12253
    },
    {
      "epoch": 0.19402441534588408,
      "grad_norm": 0.43813568353652954,
      "learning_rate": 8.059755846541159e-06,
      "loss": 0.171,
      "step": 12254
    },
    {
      "epoch": 0.19404024890352614,
      "grad_norm": 0.4345630705356598,
      "learning_rate": 8.05959751096474e-06,
      "loss": 0.1775,
      "step": 12255
    },
    {
      "epoch": 0.1940560824611682,
      "grad_norm": 0.38864827156066895,
      "learning_rate": 8.059439175388319e-06,
      "loss": 0.1044,
      "step": 12256
    },
    {
      "epoch": 0.19407191601881027,
      "grad_norm": 0.19600073993206024,
      "learning_rate": 8.059280839811898e-06,
      "loss": 0.0715,
      "step": 12257
    },
    {
      "epoch": 0.19408774957645233,
      "grad_norm": 0.14495185017585754,
      "learning_rate": 8.059122504235477e-06,
      "loss": 0.0141,
      "step": 12258
    },
    {
      "epoch": 0.1941035831340944,
      "grad_norm": 0.0002490901679266244,
      "learning_rate": 8.058964168659058e-06,
      "loss": 0.0,
      "step": 12259
    },
    {
      "epoch": 0.19411941669173646,
      "grad_norm": 0.5599520802497864,
      "learning_rate": 8.058805833082635e-06,
      "loss": 0.0682,
      "step": 12260
    },
    {
      "epoch": 0.19413525024937853,
      "grad_norm": 0.46058526635169983,
      "learning_rate": 8.058647497506216e-06,
      "loss": 0.0271,
      "step": 12261
    },
    {
      "epoch": 0.1941510838070206,
      "grad_norm": 0.9954840540885925,
      "learning_rate": 8.058489161929795e-06,
      "loss": 0.0335,
      "step": 12262
    },
    {
      "epoch": 0.19416691736466266,
      "grad_norm": 0.6958920359611511,
      "learning_rate": 8.058330826353374e-06,
      "loss": 0.6409,
      "step": 12263
    },
    {
      "epoch": 0.19418275092230472,
      "grad_norm": 0.280133992433548,
      "learning_rate": 8.058172490776953e-06,
      "loss": 0.1229,
      "step": 12264
    },
    {
      "epoch": 0.1941985844799468,
      "grad_norm": 0.00017071361071430147,
      "learning_rate": 8.058014155200534e-06,
      "loss": 0.0,
      "step": 12265
    },
    {
      "epoch": 0.19421441803758888,
      "grad_norm": 1.1941845417022705,
      "learning_rate": 8.057855819624111e-06,
      "loss": 0.1437,
      "step": 12266
    },
    {
      "epoch": 0.19423025159523094,
      "grad_norm": 0.5421304702758789,
      "learning_rate": 8.057697484047692e-06,
      "loss": 0.3466,
      "step": 12267
    },
    {
      "epoch": 0.194246085152873,
      "grad_norm": 0.2597528398036957,
      "learning_rate": 8.057539148471271e-06,
      "loss": 0.0727,
      "step": 12268
    },
    {
      "epoch": 0.19426191871051507,
      "grad_norm": 0.1791367381811142,
      "learning_rate": 8.05738081289485e-06,
      "loss": 0.0244,
      "step": 12269
    },
    {
      "epoch": 0.19427775226815713,
      "grad_norm": 0.26244643330574036,
      "learning_rate": 8.057222477318429e-06,
      "loss": 0.0588,
      "step": 12270
    },
    {
      "epoch": 0.1942935858257992,
      "grad_norm": 0.548126220703125,
      "learning_rate": 8.057064141742008e-06,
      "loss": 0.2579,
      "step": 12271
    },
    {
      "epoch": 0.19430941938344126,
      "grad_norm": 0.6071828603744507,
      "learning_rate": 8.056905806165587e-06,
      "loss": 0.1422,
      "step": 12272
    },
    {
      "epoch": 0.19432525294108333,
      "grad_norm": 0.004291449207812548,
      "learning_rate": 8.056747470589166e-06,
      "loss": 0.0001,
      "step": 12273
    },
    {
      "epoch": 0.1943410864987254,
      "grad_norm": 0.41585803031921387,
      "learning_rate": 8.056589135012747e-06,
      "loss": 0.0093,
      "step": 12274
    },
    {
      "epoch": 0.19435692005636745,
      "grad_norm": 0.1806628704071045,
      "learning_rate": 8.056430799436326e-06,
      "loss": 0.0497,
      "step": 12275
    },
    {
      "epoch": 0.19437275361400952,
      "grad_norm": 5.0235685193911195e-05,
      "learning_rate": 8.056272463859905e-06,
      "loss": 0.0,
      "step": 12276
    },
    {
      "epoch": 0.1943885871716516,
      "grad_norm": 0.19135364890098572,
      "learning_rate": 8.056114128283484e-06,
      "loss": 0.0382,
      "step": 12277
    },
    {
      "epoch": 0.19440442072929368,
      "grad_norm": 0.2625162601470947,
      "learning_rate": 8.055955792707063e-06,
      "loss": 0.0446,
      "step": 12278
    },
    {
      "epoch": 0.19442025428693574,
      "grad_norm": 0.014098381623625755,
      "learning_rate": 8.055797457130643e-06,
      "loss": 0.0007,
      "step": 12279
    },
    {
      "epoch": 0.1944360878445778,
      "grad_norm": 0.42086440324783325,
      "learning_rate": 8.055639121554223e-06,
      "loss": 0.1069,
      "step": 12280
    },
    {
      "epoch": 0.19445192140221987,
      "grad_norm": 0.0034399775322526693,
      "learning_rate": 8.055480785977802e-06,
      "loss": 0.0001,
      "step": 12281
    },
    {
      "epoch": 0.19446775495986193,
      "grad_norm": 0.3083350956439972,
      "learning_rate": 8.055322450401381e-06,
      "loss": 0.1013,
      "step": 12282
    },
    {
      "epoch": 0.194483588517504,
      "grad_norm": 0.007237280253320932,
      "learning_rate": 8.05516411482496e-06,
      "loss": 0.0003,
      "step": 12283
    },
    {
      "epoch": 0.19449942207514606,
      "grad_norm": 0.3473171889781952,
      "learning_rate": 8.05500577924854e-06,
      "loss": 0.0589,
      "step": 12284
    },
    {
      "epoch": 0.19451525563278813,
      "grad_norm": 0.007393683772534132,
      "learning_rate": 8.054847443672119e-06,
      "loss": 0.0004,
      "step": 12285
    },
    {
      "epoch": 0.1945310891904302,
      "grad_norm": 0.39520594477653503,
      "learning_rate": 8.0546891080957e-06,
      "loss": 0.1535,
      "step": 12286
    },
    {
      "epoch": 0.19454692274807225,
      "grad_norm": 0.6250544786453247,
      "learning_rate": 8.054530772519279e-06,
      "loss": 0.0545,
      "step": 12287
    },
    {
      "epoch": 0.19456275630571432,
      "grad_norm": 0.510554313659668,
      "learning_rate": 8.054372436942858e-06,
      "loss": 0.0569,
      "step": 12288
    },
    {
      "epoch": 0.1945785898633564,
      "grad_norm": 0.4147647023200989,
      "learning_rate": 8.054214101366437e-06,
      "loss": 0.184,
      "step": 12289
    },
    {
      "epoch": 0.19459442342099847,
      "grad_norm": 0.0006613077130168676,
      "learning_rate": 8.054055765790016e-06,
      "loss": 0.0,
      "step": 12290
    },
    {
      "epoch": 0.19461025697864054,
      "grad_norm": 0.6737930774688721,
      "learning_rate": 8.053897430213595e-06,
      "loss": 0.2361,
      "step": 12291
    },
    {
      "epoch": 0.1946260905362826,
      "grad_norm": 0.5175091624259949,
      "learning_rate": 8.053739094637176e-06,
      "loss": 0.5093,
      "step": 12292
    },
    {
      "epoch": 0.19464192409392467,
      "grad_norm": 0.16384226083755493,
      "learning_rate": 8.053580759060755e-06,
      "loss": 0.0786,
      "step": 12293
    },
    {
      "epoch": 0.19465775765156673,
      "grad_norm": 0.6843168139457703,
      "learning_rate": 8.053422423484334e-06,
      "loss": 0.3688,
      "step": 12294
    },
    {
      "epoch": 0.1946735912092088,
      "grad_norm": 0.0003317427181173116,
      "learning_rate": 8.053264087907913e-06,
      "loss": 0.0,
      "step": 12295
    },
    {
      "epoch": 0.19468942476685086,
      "grad_norm": 0.4442196488380432,
      "learning_rate": 8.053105752331492e-06,
      "loss": 0.0629,
      "step": 12296
    },
    {
      "epoch": 0.19470525832449292,
      "grad_norm": 0.00010194002243224531,
      "learning_rate": 8.052947416755071e-06,
      "loss": 0.0,
      "step": 12297
    },
    {
      "epoch": 0.194721091882135,
      "grad_norm": 5.1673807320185006e-05,
      "learning_rate": 8.05278908117865e-06,
      "loss": 0.0,
      "step": 12298
    },
    {
      "epoch": 0.19473692543977705,
      "grad_norm": 0.011713653802871704,
      "learning_rate": 8.052630745602231e-06,
      "loss": 0.0005,
      "step": 12299
    },
    {
      "epoch": 0.19475275899741912,
      "grad_norm": 0.36930051445961,
      "learning_rate": 8.052472410025808e-06,
      "loss": 0.1105,
      "step": 12300
    },
    {
      "epoch": 0.1947685925550612,
      "grad_norm": 0.0029122570995241404,
      "learning_rate": 8.052314074449389e-06,
      "loss": 0.0001,
      "step": 12301
    },
    {
      "epoch": 0.19478442611270327,
      "grad_norm": 0.9290587306022644,
      "learning_rate": 8.052155738872968e-06,
      "loss": 0.4754,
      "step": 12302
    },
    {
      "epoch": 0.19480025967034534,
      "grad_norm": 0.12005484104156494,
      "learning_rate": 8.051997403296547e-06,
      "loss": 0.013,
      "step": 12303
    },
    {
      "epoch": 0.1948160932279874,
      "grad_norm": 0.03223515301942825,
      "learning_rate": 8.051839067720126e-06,
      "loss": 0.0017,
      "step": 12304
    },
    {
      "epoch": 0.19483192678562947,
      "grad_norm": 0.04641931876540184,
      "learning_rate": 8.051680732143707e-06,
      "loss": 0.0018,
      "step": 12305
    },
    {
      "epoch": 0.19484776034327153,
      "grad_norm": 0.021426260471343994,
      "learning_rate": 8.051522396567284e-06,
      "loss": 0.0012,
      "step": 12306
    },
    {
      "epoch": 0.1948635939009136,
      "grad_norm": 0.3770837187767029,
      "learning_rate": 8.051364060990865e-06,
      "loss": 0.166,
      "step": 12307
    },
    {
      "epoch": 0.19487942745855566,
      "grad_norm": 0.0001463427470298484,
      "learning_rate": 8.051205725414444e-06,
      "loss": 0.0,
      "step": 12308
    },
    {
      "epoch": 0.19489526101619772,
      "grad_norm": 0.23848752677440643,
      "learning_rate": 8.051047389838023e-06,
      "loss": 0.0199,
      "step": 12309
    },
    {
      "epoch": 0.1949110945738398,
      "grad_norm": 0.22520622611045837,
      "learning_rate": 8.050889054261602e-06,
      "loss": 0.037,
      "step": 12310
    },
    {
      "epoch": 0.19492692813148185,
      "grad_norm": 0.884331226348877,
      "learning_rate": 8.050730718685182e-06,
      "loss": 0.3676,
      "step": 12311
    },
    {
      "epoch": 0.19494276168912392,
      "grad_norm": 0.03179781883955002,
      "learning_rate": 8.05057238310876e-06,
      "loss": 0.0019,
      "step": 12312
    },
    {
      "epoch": 0.194958595246766,
      "grad_norm": 0.019956571981310844,
      "learning_rate": 8.050414047532341e-06,
      "loss": 0.001,
      "step": 12313
    },
    {
      "epoch": 0.19497442880440807,
      "grad_norm": 0.21706044673919678,
      "learning_rate": 8.05025571195592e-06,
      "loss": 0.1105,
      "step": 12314
    },
    {
      "epoch": 0.19499026236205014,
      "grad_norm": 1.241936445236206,
      "learning_rate": 8.0500973763795e-06,
      "loss": 0.6258,
      "step": 12315
    },
    {
      "epoch": 0.1950060959196922,
      "grad_norm": 0.01967688649892807,
      "learning_rate": 8.049939040803079e-06,
      "loss": 0.0009,
      "step": 12316
    },
    {
      "epoch": 0.19502192947733427,
      "grad_norm": 0.2777586281299591,
      "learning_rate": 8.049780705226658e-06,
      "loss": 0.1566,
      "step": 12317
    },
    {
      "epoch": 0.19503776303497633,
      "grad_norm": 0.0216213446110487,
      "learning_rate": 8.049622369650237e-06,
      "loss": 0.0009,
      "step": 12318
    },
    {
      "epoch": 0.1950535965926184,
      "grad_norm": 0.27291497588157654,
      "learning_rate": 8.049464034073816e-06,
      "loss": 0.0973,
      "step": 12319
    },
    {
      "epoch": 0.19506943015026046,
      "grad_norm": 0.26514771580696106,
      "learning_rate": 8.049305698497397e-06,
      "loss": 0.1025,
      "step": 12320
    },
    {
      "epoch": 0.19508526370790252,
      "grad_norm": 0.41314154863357544,
      "learning_rate": 8.049147362920974e-06,
      "loss": 0.1172,
      "step": 12321
    },
    {
      "epoch": 0.1951010972655446,
      "grad_norm": 0.5954104661941528,
      "learning_rate": 8.048989027344555e-06,
      "loss": 0.5559,
      "step": 12322
    },
    {
      "epoch": 0.19511693082318665,
      "grad_norm": 0.39921149611473083,
      "learning_rate": 8.048830691768134e-06,
      "loss": 0.1254,
      "step": 12323
    },
    {
      "epoch": 0.19513276438082872,
      "grad_norm": 0.3084786832332611,
      "learning_rate": 8.048672356191713e-06,
      "loss": 0.1193,
      "step": 12324
    },
    {
      "epoch": 0.1951485979384708,
      "grad_norm": 0.3041752278804779,
      "learning_rate": 8.048514020615292e-06,
      "loss": 0.0751,
      "step": 12325
    },
    {
      "epoch": 0.19516443149611287,
      "grad_norm": 0.48194876313209534,
      "learning_rate": 8.048355685038873e-06,
      "loss": 0.0682,
      "step": 12326
    },
    {
      "epoch": 0.19518026505375494,
      "grad_norm": 0.35157111287117004,
      "learning_rate": 8.04819734946245e-06,
      "loss": 0.1961,
      "step": 12327
    },
    {
      "epoch": 0.195196098611397,
      "grad_norm": 0.040849026292562485,
      "learning_rate": 8.048039013886031e-06,
      "loss": 0.0022,
      "step": 12328
    },
    {
      "epoch": 0.19521193216903907,
      "grad_norm": 0.36384761333465576,
      "learning_rate": 8.04788067830961e-06,
      "loss": 0.0662,
      "step": 12329
    },
    {
      "epoch": 0.19522776572668113,
      "grad_norm": 0.397424578666687,
      "learning_rate": 8.04772234273319e-06,
      "loss": 0.1773,
      "step": 12330
    },
    {
      "epoch": 0.1952435992843232,
      "grad_norm": 0.1637626588344574,
      "learning_rate": 8.047564007156768e-06,
      "loss": 0.0601,
      "step": 12331
    },
    {
      "epoch": 0.19525943284196526,
      "grad_norm": 0.02211019955575466,
      "learning_rate": 8.047405671580349e-06,
      "loss": 0.0012,
      "step": 12332
    },
    {
      "epoch": 0.19527526639960732,
      "grad_norm": 0.3535376489162445,
      "learning_rate": 8.047247336003926e-06,
      "loss": 0.1972,
      "step": 12333
    },
    {
      "epoch": 0.1952910999572494,
      "grad_norm": 0.37876880168914795,
      "learning_rate": 8.047089000427507e-06,
      "loss": 0.1874,
      "step": 12334
    },
    {
      "epoch": 0.19530693351489145,
      "grad_norm": 0.5608901977539062,
      "learning_rate": 8.046930664851086e-06,
      "loss": 0.2519,
      "step": 12335
    },
    {
      "epoch": 0.19532276707253352,
      "grad_norm": 0.5236502289772034,
      "learning_rate": 8.046772329274665e-06,
      "loss": 0.2509,
      "step": 12336
    },
    {
      "epoch": 0.1953386006301756,
      "grad_norm": 0.5679309368133545,
      "learning_rate": 8.046613993698244e-06,
      "loss": 0.361,
      "step": 12337
    },
    {
      "epoch": 0.19535443418781767,
      "grad_norm": 0.28963369131088257,
      "learning_rate": 8.046455658121825e-06,
      "loss": 0.133,
      "step": 12338
    },
    {
      "epoch": 0.19537026774545974,
      "grad_norm": 0.00031409916118718684,
      "learning_rate": 8.046297322545403e-06,
      "loss": 0.0,
      "step": 12339
    },
    {
      "epoch": 0.1953861013031018,
      "grad_norm": 0.003899151226505637,
      "learning_rate": 8.046138986968983e-06,
      "loss": 0.0001,
      "step": 12340
    },
    {
      "epoch": 0.19540193486074386,
      "grad_norm": 0.00021092347742523998,
      "learning_rate": 8.045980651392562e-06,
      "loss": 0.0,
      "step": 12341
    },
    {
      "epoch": 0.19541776841838593,
      "grad_norm": 0.7365037798881531,
      "learning_rate": 8.045822315816142e-06,
      "loss": 0.5721,
      "step": 12342
    },
    {
      "epoch": 0.195433601976028,
      "grad_norm": 0.0070856004022061825,
      "learning_rate": 8.04566398023972e-06,
      "loss": 0.0003,
      "step": 12343
    },
    {
      "epoch": 0.19544943553367006,
      "grad_norm": 0.3937988579273224,
      "learning_rate": 8.0455056446633e-06,
      "loss": 0.0308,
      "step": 12344
    },
    {
      "epoch": 0.19546526909131212,
      "grad_norm": 0.7511948943138123,
      "learning_rate": 8.045347309086879e-06,
      "loss": 0.1263,
      "step": 12345
    },
    {
      "epoch": 0.19548110264895419,
      "grad_norm": 0.3213285207748413,
      "learning_rate": 8.045188973510458e-06,
      "loss": 0.124,
      "step": 12346
    },
    {
      "epoch": 0.19549693620659625,
      "grad_norm": 0.1058560162782669,
      "learning_rate": 8.045030637934039e-06,
      "loss": 0.0015,
      "step": 12347
    },
    {
      "epoch": 0.19551276976423831,
      "grad_norm": 0.695577085018158,
      "learning_rate": 8.044872302357618e-06,
      "loss": 0.0474,
      "step": 12348
    },
    {
      "epoch": 0.1955286033218804,
      "grad_norm": 0.7248754501342773,
      "learning_rate": 8.044713966781197e-06,
      "loss": 0.3754,
      "step": 12349
    },
    {
      "epoch": 0.19554443687952247,
      "grad_norm": 0.19491539895534515,
      "learning_rate": 8.044555631204776e-06,
      "loss": 0.057,
      "step": 12350
    },
    {
      "epoch": 0.19556027043716454,
      "grad_norm": 0.03403390571475029,
      "learning_rate": 8.044397295628355e-06,
      "loss": 0.0015,
      "step": 12351
    },
    {
      "epoch": 0.1955761039948066,
      "grad_norm": 0.4273429811000824,
      "learning_rate": 8.044238960051934e-06,
      "loss": 0.4327,
      "step": 12352
    },
    {
      "epoch": 0.19559193755244866,
      "grad_norm": 0.023997627198696136,
      "learning_rate": 8.044080624475515e-06,
      "loss": 0.0012,
      "step": 12353
    },
    {
      "epoch": 0.19560777111009073,
      "grad_norm": 0.0001247861800948158,
      "learning_rate": 8.043922288899094e-06,
      "loss": 0.0,
      "step": 12354
    },
    {
      "epoch": 0.1956236046677328,
      "grad_norm": 0.21582742035388947,
      "learning_rate": 8.043763953322673e-06,
      "loss": 0.0676,
      "step": 12355
    },
    {
      "epoch": 0.19563943822537486,
      "grad_norm": 0.7659104466438293,
      "learning_rate": 8.043605617746252e-06,
      "loss": 0.1647,
      "step": 12356
    },
    {
      "epoch": 0.19565527178301692,
      "grad_norm": 0.438916951417923,
      "learning_rate": 8.043447282169831e-06,
      "loss": 0.5761,
      "step": 12357
    },
    {
      "epoch": 0.19567110534065899,
      "grad_norm": 0.0017515735235065222,
      "learning_rate": 8.04328894659341e-06,
      "loss": 0.0,
      "step": 12358
    },
    {
      "epoch": 0.19568693889830105,
      "grad_norm": 0.05469426140189171,
      "learning_rate": 8.043130611016991e-06,
      "loss": 0.0027,
      "step": 12359
    },
    {
      "epoch": 0.1957027724559431,
      "grad_norm": 0.46004438400268555,
      "learning_rate": 8.04297227544057e-06,
      "loss": 0.1954,
      "step": 12360
    },
    {
      "epoch": 0.1957186060135852,
      "grad_norm": 0.009703172370791435,
      "learning_rate": 8.042813939864149e-06,
      "loss": 0.0006,
      "step": 12361
    },
    {
      "epoch": 0.19573443957122727,
      "grad_norm": 0.5410031080245972,
      "learning_rate": 8.042655604287728e-06,
      "loss": 0.4387,
      "step": 12362
    },
    {
      "epoch": 0.19575027312886933,
      "grad_norm": 0.2553658187389374,
      "learning_rate": 8.042497268711307e-06,
      "loss": 0.087,
      "step": 12363
    },
    {
      "epoch": 0.1957661066865114,
      "grad_norm": 0.18409474194049835,
      "learning_rate": 8.042338933134886e-06,
      "loss": 0.0553,
      "step": 12364
    },
    {
      "epoch": 0.19578194024415346,
      "grad_norm": 0.3827779293060303,
      "learning_rate": 8.042180597558467e-06,
      "loss": 0.0907,
      "step": 12365
    },
    {
      "epoch": 0.19579777380179553,
      "grad_norm": 0.2309754490852356,
      "learning_rate": 8.042022261982046e-06,
      "loss": 0.0693,
      "step": 12366
    },
    {
      "epoch": 0.1958136073594376,
      "grad_norm": 0.2834031581878662,
      "learning_rate": 8.041863926405624e-06,
      "loss": 0.1298,
      "step": 12367
    },
    {
      "epoch": 0.19582944091707966,
      "grad_norm": 0.5863385796546936,
      "learning_rate": 8.041705590829204e-06,
      "loss": 0.246,
      "step": 12368
    },
    {
      "epoch": 0.19584527447472172,
      "grad_norm": 0.6511975526809692,
      "learning_rate": 8.041547255252783e-06,
      "loss": 0.2207,
      "step": 12369
    },
    {
      "epoch": 0.19586110803236378,
      "grad_norm": 0.02677578292787075,
      "learning_rate": 8.041388919676363e-06,
      "loss": 0.0013,
      "step": 12370
    },
    {
      "epoch": 0.19587694159000585,
      "grad_norm": 0.37036654353141785,
      "learning_rate": 8.041230584099942e-06,
      "loss": 0.1641,
      "step": 12371
    },
    {
      "epoch": 0.1958927751476479,
      "grad_norm": 0.00046157813630998135,
      "learning_rate": 8.041072248523522e-06,
      "loss": 0.0,
      "step": 12372
    },
    {
      "epoch": 0.19590860870529,
      "grad_norm": 0.2974779009819031,
      "learning_rate": 8.0409139129471e-06,
      "loss": 0.1876,
      "step": 12373
    },
    {
      "epoch": 0.19592444226293207,
      "grad_norm": 0.23445259034633636,
      "learning_rate": 8.04075557737068e-06,
      "loss": 0.1163,
      "step": 12374
    },
    {
      "epoch": 0.19594027582057413,
      "grad_norm": 0.45594361424446106,
      "learning_rate": 8.04059724179426e-06,
      "loss": 0.0954,
      "step": 12375
    },
    {
      "epoch": 0.1959561093782162,
      "grad_norm": 0.020874572917819023,
      "learning_rate": 8.040438906217839e-06,
      "loss": 0.0011,
      "step": 12376
    },
    {
      "epoch": 0.19597194293585826,
      "grad_norm": 1.4191803932189941,
      "learning_rate": 8.040280570641418e-06,
      "loss": 0.5075,
      "step": 12377
    },
    {
      "epoch": 0.19598777649350033,
      "grad_norm": 1.0783640146255493,
      "learning_rate": 8.040122235064997e-06,
      "loss": 0.5897,
      "step": 12378
    },
    {
      "epoch": 0.1960036100511424,
      "grad_norm": 0.3921201825141907,
      "learning_rate": 8.039963899488576e-06,
      "loss": 0.0276,
      "step": 12379
    },
    {
      "epoch": 0.19601944360878445,
      "grad_norm": 0.24775952100753784,
      "learning_rate": 8.039805563912157e-06,
      "loss": 0.1131,
      "step": 12380
    },
    {
      "epoch": 0.19603527716642652,
      "grad_norm": 0.4713049829006195,
      "learning_rate": 8.039647228335736e-06,
      "loss": 0.353,
      "step": 12381
    },
    {
      "epoch": 0.19605111072406858,
      "grad_norm": 0.8409610390663147,
      "learning_rate": 8.039488892759315e-06,
      "loss": 0.3534,
      "step": 12382
    },
    {
      "epoch": 0.19606694428171065,
      "grad_norm": 0.00887027382850647,
      "learning_rate": 8.039330557182894e-06,
      "loss": 0.0004,
      "step": 12383
    },
    {
      "epoch": 0.1960827778393527,
      "grad_norm": 0.32725611329078674,
      "learning_rate": 8.039172221606473e-06,
      "loss": 0.1246,
      "step": 12384
    },
    {
      "epoch": 0.1960986113969948,
      "grad_norm": 0.5385124683380127,
      "learning_rate": 8.039013886030052e-06,
      "loss": 0.1008,
      "step": 12385
    },
    {
      "epoch": 0.19611444495463687,
      "grad_norm": 0.40375909209251404,
      "learning_rate": 8.038855550453633e-06,
      "loss": 0.6162,
      "step": 12386
    },
    {
      "epoch": 0.19613027851227893,
      "grad_norm": 0.25901100039482117,
      "learning_rate": 8.038697214877212e-06,
      "loss": 0.071,
      "step": 12387
    },
    {
      "epoch": 0.196146112069921,
      "grad_norm": 0.646492600440979,
      "learning_rate": 8.038538879300791e-06,
      "loss": 0.6059,
      "step": 12388
    },
    {
      "epoch": 0.19616194562756306,
      "grad_norm": 0.47916528582572937,
      "learning_rate": 8.03838054372437e-06,
      "loss": 0.1673,
      "step": 12389
    },
    {
      "epoch": 0.19617777918520513,
      "grad_norm": 0.4662421643733978,
      "learning_rate": 8.03822220814795e-06,
      "loss": 0.0995,
      "step": 12390
    },
    {
      "epoch": 0.1961936127428472,
      "grad_norm": 0.27196604013442993,
      "learning_rate": 8.038063872571528e-06,
      "loss": 0.0473,
      "step": 12391
    },
    {
      "epoch": 0.19620944630048925,
      "grad_norm": 0.20366962254047394,
      "learning_rate": 8.037905536995107e-06,
      "loss": 0.0554,
      "step": 12392
    },
    {
      "epoch": 0.19622527985813132,
      "grad_norm": 0.40691685676574707,
      "learning_rate": 8.037747201418688e-06,
      "loss": 0.6387,
      "step": 12393
    },
    {
      "epoch": 0.19624111341577338,
      "grad_norm": 0.2812040448188782,
      "learning_rate": 8.037588865842266e-06,
      "loss": 0.179,
      "step": 12394
    },
    {
      "epoch": 0.19625694697341545,
      "grad_norm": 0.4923824369907379,
      "learning_rate": 8.037430530265846e-06,
      "loss": 0.1602,
      "step": 12395
    },
    {
      "epoch": 0.1962727805310575,
      "grad_norm": 0.011402341537177563,
      "learning_rate": 8.037272194689425e-06,
      "loss": 0.0006,
      "step": 12396
    },
    {
      "epoch": 0.1962886140886996,
      "grad_norm": 0.00836501270532608,
      "learning_rate": 8.037113859113004e-06,
      "loss": 0.0003,
      "step": 12397
    },
    {
      "epoch": 0.19630444764634167,
      "grad_norm": 0.00026364545919932425,
      "learning_rate": 8.036955523536584e-06,
      "loss": 0.0,
      "step": 12398
    },
    {
      "epoch": 0.19632028120398373,
      "grad_norm": 0.5890205502510071,
      "learning_rate": 8.036797187960164e-06,
      "loss": 0.1148,
      "step": 12399
    },
    {
      "epoch": 0.1963361147616258,
      "grad_norm": 0.5330381989479065,
      "learning_rate": 8.036638852383742e-06,
      "loss": 0.0672,
      "step": 12400
    },
    {
      "epoch": 0.19635194831926786,
      "grad_norm": 0.00015582017658744007,
      "learning_rate": 8.036480516807322e-06,
      "loss": 0.0,
      "step": 12401
    },
    {
      "epoch": 0.19636778187690992,
      "grad_norm": 0.33702948689460754,
      "learning_rate": 8.036322181230902e-06,
      "loss": 0.0509,
      "step": 12402
    },
    {
      "epoch": 0.196383615434552,
      "grad_norm": 0.3884698152542114,
      "learning_rate": 8.03616384565448e-06,
      "loss": 0.2409,
      "step": 12403
    },
    {
      "epoch": 0.19639944899219405,
      "grad_norm": 0.13575829565525055,
      "learning_rate": 8.03600551007806e-06,
      "loss": 0.0434,
      "step": 12404
    },
    {
      "epoch": 0.19641528254983612,
      "grad_norm": 0.3338501751422882,
      "learning_rate": 8.03584717450164e-06,
      "loss": 0.2622,
      "step": 12405
    },
    {
      "epoch": 0.19643111610747818,
      "grad_norm": 0.01925663650035858,
      "learning_rate": 8.035688838925218e-06,
      "loss": 0.001,
      "step": 12406
    },
    {
      "epoch": 0.19644694966512025,
      "grad_norm": 0.028500985354185104,
      "learning_rate": 8.035530503348799e-06,
      "loss": 0.0014,
      "step": 12407
    },
    {
      "epoch": 0.1964627832227623,
      "grad_norm": 0.018816132098436356,
      "learning_rate": 8.035372167772378e-06,
      "loss": 0.0011,
      "step": 12408
    },
    {
      "epoch": 0.1964786167804044,
      "grad_norm": 0.03155899420380592,
      "learning_rate": 8.035213832195957e-06,
      "loss": 0.0013,
      "step": 12409
    },
    {
      "epoch": 0.19649445033804647,
      "grad_norm": 0.01299353502690792,
      "learning_rate": 8.035055496619536e-06,
      "loss": 0.0005,
      "step": 12410
    },
    {
      "epoch": 0.19651028389568853,
      "grad_norm": 0.41710445284843445,
      "learning_rate": 8.034897161043117e-06,
      "loss": 0.0678,
      "step": 12411
    },
    {
      "epoch": 0.1965261174533306,
      "grad_norm": 0.3785552680492401,
      "learning_rate": 8.034738825466694e-06,
      "loss": 0.0465,
      "step": 12412
    },
    {
      "epoch": 0.19654195101097266,
      "grad_norm": 0.5034812092781067,
      "learning_rate": 8.034580489890275e-06,
      "loss": 0.0673,
      "step": 12413
    },
    {
      "epoch": 0.19655778456861472,
      "grad_norm": 0.3742760121822357,
      "learning_rate": 8.034422154313854e-06,
      "loss": 0.1161,
      "step": 12414
    },
    {
      "epoch": 0.1965736181262568,
      "grad_norm": 0.4286743700504303,
      "learning_rate": 8.034263818737433e-06,
      "loss": 0.126,
      "step": 12415
    },
    {
      "epoch": 0.19658945168389885,
      "grad_norm": 0.3023472726345062,
      "learning_rate": 8.034105483161012e-06,
      "loss": 0.0523,
      "step": 12416
    },
    {
      "epoch": 0.19660528524154092,
      "grad_norm": 0.6015521287918091,
      "learning_rate": 8.033947147584591e-06,
      "loss": 0.5582,
      "step": 12417
    },
    {
      "epoch": 0.19662111879918298,
      "grad_norm": 0.2862374484539032,
      "learning_rate": 8.03378881200817e-06,
      "loss": 0.1142,
      "step": 12418
    },
    {
      "epoch": 0.19663695235682505,
      "grad_norm": 0.0119654331356287,
      "learning_rate": 8.03363047643175e-06,
      "loss": 0.0006,
      "step": 12419
    },
    {
      "epoch": 0.1966527859144671,
      "grad_norm": 0.4373649060726166,
      "learning_rate": 8.03347214085533e-06,
      "loss": 0.0979,
      "step": 12420
    },
    {
      "epoch": 0.1966686194721092,
      "grad_norm": 0.31933125853538513,
      "learning_rate": 8.033313805278909e-06,
      "loss": 0.2044,
      "step": 12421
    },
    {
      "epoch": 0.19668445302975127,
      "grad_norm": 0.00964304804801941,
      "learning_rate": 8.033155469702488e-06,
      "loss": 0.0001,
      "step": 12422
    },
    {
      "epoch": 0.19670028658739333,
      "grad_norm": 0.018777994439005852,
      "learning_rate": 8.032997134126067e-06,
      "loss": 0.0009,
      "step": 12423
    },
    {
      "epoch": 0.1967161201450354,
      "grad_norm": 0.5191940069198608,
      "learning_rate": 8.032838798549646e-06,
      "loss": 0.774,
      "step": 12424
    },
    {
      "epoch": 0.19673195370267746,
      "grad_norm": 0.13630452752113342,
      "learning_rate": 8.032680462973225e-06,
      "loss": 0.0556,
      "step": 12425
    },
    {
      "epoch": 0.19674778726031952,
      "grad_norm": 0.5114381313323975,
      "learning_rate": 8.032522127396806e-06,
      "loss": 0.2476,
      "step": 12426
    },
    {
      "epoch": 0.1967636208179616,
      "grad_norm": 0.7077537178993225,
      "learning_rate": 8.032363791820385e-06,
      "loss": 0.3869,
      "step": 12427
    },
    {
      "epoch": 0.19677945437560365,
      "grad_norm": 0.41958433389663696,
      "learning_rate": 8.032205456243964e-06,
      "loss": 0.1885,
      "step": 12428
    },
    {
      "epoch": 0.19679528793324572,
      "grad_norm": 0.0001606129080755636,
      "learning_rate": 8.032047120667543e-06,
      "loss": 0.0,
      "step": 12429
    },
    {
      "epoch": 0.19681112149088778,
      "grad_norm": 0.08605737239122391,
      "learning_rate": 8.031888785091123e-06,
      "loss": 0.0047,
      "step": 12430
    },
    {
      "epoch": 0.19682695504852984,
      "grad_norm": 0.008338932879269123,
      "learning_rate": 8.031730449514702e-06,
      "loss": 0.0004,
      "step": 12431
    },
    {
      "epoch": 0.1968427886061719,
      "grad_norm": 0.44588702917099,
      "learning_rate": 8.031572113938282e-06,
      "loss": 0.1554,
      "step": 12432
    },
    {
      "epoch": 0.196858622163814,
      "grad_norm": 0.338944673538208,
      "learning_rate": 8.031413778361861e-06,
      "loss": 0.0508,
      "step": 12433
    },
    {
      "epoch": 0.19687445572145607,
      "grad_norm": 0.010992524214088917,
      "learning_rate": 8.03125544278544e-06,
      "loss": 0.0005,
      "step": 12434
    },
    {
      "epoch": 0.19689028927909813,
      "grad_norm": 0.035757385194301605,
      "learning_rate": 8.03109710720902e-06,
      "loss": 0.001,
      "step": 12435
    },
    {
      "epoch": 0.1969061228367402,
      "grad_norm": 0.5392045974731445,
      "learning_rate": 8.030938771632599e-06,
      "loss": 0.1659,
      "step": 12436
    },
    {
      "epoch": 0.19692195639438226,
      "grad_norm": 0.6684500575065613,
      "learning_rate": 8.030780436056178e-06,
      "loss": 0.2821,
      "step": 12437
    },
    {
      "epoch": 0.19693778995202432,
      "grad_norm": 0.48351117968559265,
      "learning_rate": 8.030622100479759e-06,
      "loss": 0.266,
      "step": 12438
    },
    {
      "epoch": 0.1969536235096664,
      "grad_norm": 0.180800199508667,
      "learning_rate": 8.030463764903338e-06,
      "loss": 0.0923,
      "step": 12439
    },
    {
      "epoch": 0.19696945706730845,
      "grad_norm": 0.24492083489894867,
      "learning_rate": 8.030305429326915e-06,
      "loss": 0.0701,
      "step": 12440
    },
    {
      "epoch": 0.19698529062495052,
      "grad_norm": 7.906146493041888e-05,
      "learning_rate": 8.030147093750496e-06,
      "loss": 0.0,
      "step": 12441
    },
    {
      "epoch": 0.19700112418259258,
      "grad_norm": 0.4812883138656616,
      "learning_rate": 8.029988758174075e-06,
      "loss": 0.2951,
      "step": 12442
    },
    {
      "epoch": 0.19701695774023464,
      "grad_norm": 0.33753257989883423,
      "learning_rate": 8.029830422597654e-06,
      "loss": 0.0399,
      "step": 12443
    },
    {
      "epoch": 0.1970327912978767,
      "grad_norm": 0.3563731610774994,
      "learning_rate": 8.029672087021233e-06,
      "loss": 0.1009,
      "step": 12444
    },
    {
      "epoch": 0.1970486248555188,
      "grad_norm": 0.24861855804920197,
      "learning_rate": 8.029513751444812e-06,
      "loss": 0.0441,
      "step": 12445
    },
    {
      "epoch": 0.19706445841316086,
      "grad_norm": 0.16381163895130157,
      "learning_rate": 8.029355415868391e-06,
      "loss": 0.0613,
      "step": 12446
    },
    {
      "epoch": 0.19708029197080293,
      "grad_norm": 0.6381313800811768,
      "learning_rate": 8.029197080291972e-06,
      "loss": 0.4889,
      "step": 12447
    },
    {
      "epoch": 0.197096125528445,
      "grad_norm": 0.08924712985754013,
      "learning_rate": 8.029038744715551e-06,
      "loss": 0.0028,
      "step": 12448
    },
    {
      "epoch": 0.19711195908608706,
      "grad_norm": 0.31068509817123413,
      "learning_rate": 8.02888040913913e-06,
      "loss": 0.115,
      "step": 12449
    },
    {
      "epoch": 0.19712779264372912,
      "grad_norm": 0.5771101117134094,
      "learning_rate": 8.02872207356271e-06,
      "loss": 0.2382,
      "step": 12450
    },
    {
      "epoch": 0.19714362620137119,
      "grad_norm": 0.3774109184741974,
      "learning_rate": 8.028563737986288e-06,
      "loss": 0.1535,
      "step": 12451
    },
    {
      "epoch": 0.19715945975901325,
      "grad_norm": 0.30992141366004944,
      "learning_rate": 8.028405402409867e-06,
      "loss": 0.1802,
      "step": 12452
    },
    {
      "epoch": 0.19717529331665531,
      "grad_norm": 0.14096060395240784,
      "learning_rate": 8.028247066833448e-06,
      "loss": 0.0545,
      "step": 12453
    },
    {
      "epoch": 0.19719112687429738,
      "grad_norm": 0.00011703612108249217,
      "learning_rate": 8.028088731257027e-06,
      "loss": 0.0,
      "step": 12454
    },
    {
      "epoch": 0.19720696043193944,
      "grad_norm": 0.22313477098941803,
      "learning_rate": 8.027930395680606e-06,
      "loss": 0.0454,
      "step": 12455
    },
    {
      "epoch": 0.1972227939895815,
      "grad_norm": 0.5384641289710999,
      "learning_rate": 8.027772060104185e-06,
      "loss": 0.1591,
      "step": 12456
    },
    {
      "epoch": 0.1972386275472236,
      "grad_norm": 0.4848076105117798,
      "learning_rate": 8.027613724527764e-06,
      "loss": 0.2053,
      "step": 12457
    },
    {
      "epoch": 0.19725446110486566,
      "grad_norm": 0.53115314245224,
      "learning_rate": 8.027455388951344e-06,
      "loss": 0.5706,
      "step": 12458
    },
    {
      "epoch": 0.19727029466250773,
      "grad_norm": 7.383747288258746e-05,
      "learning_rate": 8.027297053374924e-06,
      "loss": 0.0,
      "step": 12459
    },
    {
      "epoch": 0.1972861282201498,
      "grad_norm": 0.22225689888000488,
      "learning_rate": 8.027138717798503e-06,
      "loss": 0.0849,
      "step": 12460
    },
    {
      "epoch": 0.19730196177779186,
      "grad_norm": 0.6995089650154114,
      "learning_rate": 8.026980382222082e-06,
      "loss": 0.2877,
      "step": 12461
    },
    {
      "epoch": 0.19731779533543392,
      "grad_norm": 0.4776204526424408,
      "learning_rate": 8.026822046645662e-06,
      "loss": 0.1955,
      "step": 12462
    },
    {
      "epoch": 0.19733362889307599,
      "grad_norm": 0.5177587866783142,
      "learning_rate": 8.02666371106924e-06,
      "loss": 0.126,
      "step": 12463
    },
    {
      "epoch": 0.19734946245071805,
      "grad_norm": 0.03037630207836628,
      "learning_rate": 8.02650537549282e-06,
      "loss": 0.0017,
      "step": 12464
    },
    {
      "epoch": 0.1973652960083601,
      "grad_norm": 0.5434958934783936,
      "learning_rate": 8.026347039916399e-06,
      "loss": 0.3129,
      "step": 12465
    },
    {
      "epoch": 0.19738112956600218,
      "grad_norm": 0.23911575973033905,
      "learning_rate": 8.02618870433998e-06,
      "loss": 0.0179,
      "step": 12466
    },
    {
      "epoch": 0.19739696312364424,
      "grad_norm": 0.011817369610071182,
      "learning_rate": 8.026030368763557e-06,
      "loss": 0.0005,
      "step": 12467
    },
    {
      "epoch": 0.1974127966812863,
      "grad_norm": 0.08810217678546906,
      "learning_rate": 8.025872033187138e-06,
      "loss": 0.009,
      "step": 12468
    },
    {
      "epoch": 0.1974286302389284,
      "grad_norm": 0.24702580273151398,
      "learning_rate": 8.025713697610717e-06,
      "loss": 0.07,
      "step": 12469
    },
    {
      "epoch": 0.19744446379657046,
      "grad_norm": 0.17051668465137482,
      "learning_rate": 8.025555362034296e-06,
      "loss": 0.061,
      "step": 12470
    },
    {
      "epoch": 0.19746029735421253,
      "grad_norm": 0.8140047788619995,
      "learning_rate": 8.025397026457875e-06,
      "loss": 0.3494,
      "step": 12471
    },
    {
      "epoch": 0.1974761309118546,
      "grad_norm": 0.3609617054462433,
      "learning_rate": 8.025238690881456e-06,
      "loss": 0.0721,
      "step": 12472
    },
    {
      "epoch": 0.19749196446949666,
      "grad_norm": 0.2595535218715668,
      "learning_rate": 8.025080355305033e-06,
      "loss": 0.0872,
      "step": 12473
    },
    {
      "epoch": 0.19750779802713872,
      "grad_norm": 0.03470257297158241,
      "learning_rate": 8.024922019728614e-06,
      "loss": 0.0019,
      "step": 12474
    },
    {
      "epoch": 0.19752363158478078,
      "grad_norm": 0.25808820128440857,
      "learning_rate": 8.024763684152193e-06,
      "loss": 0.0584,
      "step": 12475
    },
    {
      "epoch": 0.19753946514242285,
      "grad_norm": 0.25015339255332947,
      "learning_rate": 8.024605348575772e-06,
      "loss": 0.0406,
      "step": 12476
    },
    {
      "epoch": 0.1975552987000649,
      "grad_norm": 0.37499764561653137,
      "learning_rate": 8.024447012999351e-06,
      "loss": 0.0273,
      "step": 12477
    },
    {
      "epoch": 0.19757113225770698,
      "grad_norm": 0.9771567583084106,
      "learning_rate": 8.024288677422932e-06,
      "loss": 0.1557,
      "step": 12478
    },
    {
      "epoch": 0.19758696581534904,
      "grad_norm": 0.5231778025627136,
      "learning_rate": 8.02413034184651e-06,
      "loss": 0.684,
      "step": 12479
    },
    {
      "epoch": 0.1976027993729911,
      "grad_norm": 0.6126871109008789,
      "learning_rate": 8.02397200627009e-06,
      "loss": 0.2077,
      "step": 12480
    },
    {
      "epoch": 0.19761863293063317,
      "grad_norm": 0.24995167553424835,
      "learning_rate": 8.023813670693669e-06,
      "loss": 0.0837,
      "step": 12481
    },
    {
      "epoch": 0.19763446648827526,
      "grad_norm": 0.3532615602016449,
      "learning_rate": 8.023655335117248e-06,
      "loss": 0.0298,
      "step": 12482
    },
    {
      "epoch": 0.19765030004591733,
      "grad_norm": 0.2195117324590683,
      "learning_rate": 8.023496999540827e-06,
      "loss": 0.0419,
      "step": 12483
    },
    {
      "epoch": 0.1976661336035594,
      "grad_norm": 1.1624915599822998,
      "learning_rate": 8.023338663964408e-06,
      "loss": 0.116,
      "step": 12484
    },
    {
      "epoch": 0.19768196716120146,
      "grad_norm": 6.893434328958392e-05,
      "learning_rate": 8.023180328387985e-06,
      "loss": 0.0,
      "step": 12485
    },
    {
      "epoch": 0.19769780071884352,
      "grad_norm": 0.0004609313327819109,
      "learning_rate": 8.023021992811566e-06,
      "loss": 0.0,
      "step": 12486
    },
    {
      "epoch": 0.19771363427648558,
      "grad_norm": 0.2715826630592346,
      "learning_rate": 8.022863657235145e-06,
      "loss": 0.1152,
      "step": 12487
    },
    {
      "epoch": 0.19772946783412765,
      "grad_norm": 0.10284274816513062,
      "learning_rate": 8.022705321658724e-06,
      "loss": 0.0038,
      "step": 12488
    },
    {
      "epoch": 0.1977453013917697,
      "grad_norm": 0.2464691549539566,
      "learning_rate": 8.022546986082303e-06,
      "loss": 0.0553,
      "step": 12489
    },
    {
      "epoch": 0.19776113494941178,
      "grad_norm": 0.33387690782546997,
      "learning_rate": 8.022388650505883e-06,
      "loss": 0.1234,
      "step": 12490
    },
    {
      "epoch": 0.19777696850705384,
      "grad_norm": 0.18985728919506073,
      "learning_rate": 8.022230314929462e-06,
      "loss": 0.0487,
      "step": 12491
    },
    {
      "epoch": 0.1977928020646959,
      "grad_norm": 0.24441874027252197,
      "learning_rate": 8.02207197935304e-06,
      "loss": 0.0562,
      "step": 12492
    },
    {
      "epoch": 0.19780863562233797,
      "grad_norm": 0.02883925475180149,
      "learning_rate": 8.021913643776621e-06,
      "loss": 0.0018,
      "step": 12493
    },
    {
      "epoch": 0.19782446917998006,
      "grad_norm": 1.1006500720977783,
      "learning_rate": 8.0217553082002e-06,
      "loss": 0.3115,
      "step": 12494
    },
    {
      "epoch": 0.19784030273762213,
      "grad_norm": 0.486885666847229,
      "learning_rate": 8.02159697262378e-06,
      "loss": 0.0556,
      "step": 12495
    },
    {
      "epoch": 0.1978561362952642,
      "grad_norm": 0.17499084770679474,
      "learning_rate": 8.021438637047359e-06,
      "loss": 0.1005,
      "step": 12496
    },
    {
      "epoch": 0.19787196985290625,
      "grad_norm": 0.5436748266220093,
      "learning_rate": 8.021280301470938e-06,
      "loss": 0.1198,
      "step": 12497
    },
    {
      "epoch": 0.19788780341054832,
      "grad_norm": 0.022219279780983925,
      "learning_rate": 8.021121965894517e-06,
      "loss": 0.001,
      "step": 12498
    },
    {
      "epoch": 0.19790363696819038,
      "grad_norm": 0.1586262583732605,
      "learning_rate": 8.020963630318098e-06,
      "loss": 0.0562,
      "step": 12499
    },
    {
      "epoch": 0.19791947052583245,
      "grad_norm": 0.00011091206397395581,
      "learning_rate": 8.020805294741677e-06,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 0.1979353040834745,
      "grad_norm": 0.5192793607711792,
      "learning_rate": 8.020646959165256e-06,
      "loss": 0.5202,
      "step": 12501
    },
    {
      "epoch": 0.19795113764111658,
      "grad_norm": 0.5176382660865784,
      "learning_rate": 8.020488623588835e-06,
      "loss": 0.094,
      "step": 12502
    },
    {
      "epoch": 0.19796697119875864,
      "grad_norm": 0.5957638025283813,
      "learning_rate": 8.020330288012414e-06,
      "loss": 0.2354,
      "step": 12503
    },
    {
      "epoch": 0.1979828047564007,
      "grad_norm": 0.20603910088539124,
      "learning_rate": 8.020171952435993e-06,
      "loss": 0.0588,
      "step": 12504
    },
    {
      "epoch": 0.19799863831404277,
      "grad_norm": 0.7487784624099731,
      "learning_rate": 8.020013616859574e-06,
      "loss": 0.5615,
      "step": 12505
    },
    {
      "epoch": 0.19801447187168486,
      "grad_norm": 0.6012484431266785,
      "learning_rate": 8.019855281283151e-06,
      "loss": 0.1161,
      "step": 12506
    },
    {
      "epoch": 0.19803030542932692,
      "grad_norm": 0.03799079731106758,
      "learning_rate": 8.019696945706732e-06,
      "loss": 0.0023,
      "step": 12507
    },
    {
      "epoch": 0.198046138986969,
      "grad_norm": 0.2693120837211609,
      "learning_rate": 8.019538610130311e-06,
      "loss": 0.0277,
      "step": 12508
    },
    {
      "epoch": 0.19806197254461105,
      "grad_norm": 0.015789685770869255,
      "learning_rate": 8.01938027455389e-06,
      "loss": 0.0007,
      "step": 12509
    },
    {
      "epoch": 0.19807780610225312,
      "grad_norm": 0.22333624958992004,
      "learning_rate": 8.01922193897747e-06,
      "loss": 0.0853,
      "step": 12510
    },
    {
      "epoch": 0.19809363965989518,
      "grad_norm": 0.006536929402500391,
      "learning_rate": 8.01906360340105e-06,
      "loss": 0.0003,
      "step": 12511
    },
    {
      "epoch": 0.19810947321753725,
      "grad_norm": 0.4247376620769501,
      "learning_rate": 8.018905267824627e-06,
      "loss": 0.2033,
      "step": 12512
    },
    {
      "epoch": 0.1981253067751793,
      "grad_norm": 0.37760987877845764,
      "learning_rate": 8.018746932248206e-06,
      "loss": 0.1101,
      "step": 12513
    },
    {
      "epoch": 0.19814114033282137,
      "grad_norm": 0.24975033104419708,
      "learning_rate": 8.018588596671787e-06,
      "loss": 0.0882,
      "step": 12514
    },
    {
      "epoch": 0.19815697389046344,
      "grad_norm": 0.5277266502380371,
      "learning_rate": 8.018430261095366e-06,
      "loss": 0.1993,
      "step": 12515
    },
    {
      "epoch": 0.1981728074481055,
      "grad_norm": 0.6168507933616638,
      "learning_rate": 8.018271925518945e-06,
      "loss": 0.4309,
      "step": 12516
    },
    {
      "epoch": 0.19818864100574757,
      "grad_norm": 0.00031070742988958955,
      "learning_rate": 8.018113589942524e-06,
      "loss": 0.0,
      "step": 12517
    },
    {
      "epoch": 0.19820447456338966,
      "grad_norm": 0.3996223211288452,
      "learning_rate": 8.017955254366104e-06,
      "loss": 0.0836,
      "step": 12518
    },
    {
      "epoch": 0.19822030812103172,
      "grad_norm": 0.27490559220314026,
      "learning_rate": 8.017796918789683e-06,
      "loss": 0.0279,
      "step": 12519
    },
    {
      "epoch": 0.1982361416786738,
      "grad_norm": 0.0002689406101126224,
      "learning_rate": 8.017638583213263e-06,
      "loss": 0.0,
      "step": 12520
    },
    {
      "epoch": 0.19825197523631585,
      "grad_norm": 0.43124690651893616,
      "learning_rate": 8.017480247636842e-06,
      "loss": 0.1061,
      "step": 12521
    },
    {
      "epoch": 0.19826780879395792,
      "grad_norm": 0.9202666878700256,
      "learning_rate": 8.017321912060422e-06,
      "loss": 0.1036,
      "step": 12522
    },
    {
      "epoch": 0.19828364235159998,
      "grad_norm": 0.03869374841451645,
      "learning_rate": 8.017163576484e-06,
      "loss": 0.0019,
      "step": 12523
    },
    {
      "epoch": 0.19829947590924205,
      "grad_norm": 0.16125884652137756,
      "learning_rate": 8.01700524090758e-06,
      "loss": 0.0766,
      "step": 12524
    },
    {
      "epoch": 0.1983153094668841,
      "grad_norm": 0.6709410548210144,
      "learning_rate": 8.016846905331159e-06,
      "loss": 0.1599,
      "step": 12525
    },
    {
      "epoch": 0.19833114302452617,
      "grad_norm": 0.5898815393447876,
      "learning_rate": 8.01668856975474e-06,
      "loss": 0.2816,
      "step": 12526
    },
    {
      "epoch": 0.19834697658216824,
      "grad_norm": 0.00011730784899555147,
      "learning_rate": 8.016530234178319e-06,
      "loss": 0.0,
      "step": 12527
    },
    {
      "epoch": 0.1983628101398103,
      "grad_norm": 0.1996639221906662,
      "learning_rate": 8.016371898601898e-06,
      "loss": 0.0416,
      "step": 12528
    },
    {
      "epoch": 0.19837864369745237,
      "grad_norm": 0.7974644303321838,
      "learning_rate": 8.016213563025477e-06,
      "loss": 0.6585,
      "step": 12529
    },
    {
      "epoch": 0.19839447725509446,
      "grad_norm": 0.05565277487039566,
      "learning_rate": 8.016055227449056e-06,
      "loss": 0.0031,
      "step": 12530
    },
    {
      "epoch": 0.19841031081273652,
      "grad_norm": 0.26508432626724243,
      "learning_rate": 8.015896891872635e-06,
      "loss": 0.1018,
      "step": 12531
    },
    {
      "epoch": 0.1984261443703786,
      "grad_norm": 0.26885083317756653,
      "learning_rate": 8.015738556296216e-06,
      "loss": 0.0764,
      "step": 12532
    },
    {
      "epoch": 0.19844197792802065,
      "grad_norm": 0.5279983878135681,
      "learning_rate": 8.015580220719795e-06,
      "loss": 0.3487,
      "step": 12533
    },
    {
      "epoch": 0.19845781148566272,
      "grad_norm": 0.5191007852554321,
      "learning_rate": 8.015421885143374e-06,
      "loss": 0.075,
      "step": 12534
    },
    {
      "epoch": 0.19847364504330478,
      "grad_norm": 0.22509732842445374,
      "learning_rate": 8.015263549566953e-06,
      "loss": 0.0972,
      "step": 12535
    },
    {
      "epoch": 0.19848947860094684,
      "grad_norm": 0.027516571804881096,
      "learning_rate": 8.015105213990532e-06,
      "loss": 0.0013,
      "step": 12536
    },
    {
      "epoch": 0.1985053121585889,
      "grad_norm": 0.13083651661872864,
      "learning_rate": 8.014946878414111e-06,
      "loss": 0.0514,
      "step": 12537
    },
    {
      "epoch": 0.19852114571623097,
      "grad_norm": 0.015413952060043812,
      "learning_rate": 8.01478854283769e-06,
      "loss": 0.0008,
      "step": 12538
    },
    {
      "epoch": 0.19853697927387304,
      "grad_norm": 0.19304367899894714,
      "learning_rate": 8.014630207261271e-06,
      "loss": 0.0532,
      "step": 12539
    },
    {
      "epoch": 0.1985528128315151,
      "grad_norm": 0.0002561514265835285,
      "learning_rate": 8.014471871684848e-06,
      "loss": 0.0,
      "step": 12540
    },
    {
      "epoch": 0.19856864638915717,
      "grad_norm": 0.3630482852458954,
      "learning_rate": 8.01431353610843e-06,
      "loss": 0.1484,
      "step": 12541
    },
    {
      "epoch": 0.19858447994679926,
      "grad_norm": 0.4334542453289032,
      "learning_rate": 8.014155200532008e-06,
      "loss": 0.0648,
      "step": 12542
    },
    {
      "epoch": 0.19860031350444132,
      "grad_norm": 0.320533812046051,
      "learning_rate": 8.013996864955587e-06,
      "loss": 0.0948,
      "step": 12543
    },
    {
      "epoch": 0.1986161470620834,
      "grad_norm": 0.4175666272640228,
      "learning_rate": 8.013838529379166e-06,
      "loss": 0.0754,
      "step": 12544
    },
    {
      "epoch": 0.19863198061972545,
      "grad_norm": 0.42193081974983215,
      "learning_rate": 8.013680193802747e-06,
      "loss": 0.0599,
      "step": 12545
    },
    {
      "epoch": 0.19864781417736752,
      "grad_norm": 0.022684253752231598,
      "learning_rate": 8.013521858226325e-06,
      "loss": 0.0012,
      "step": 12546
    },
    {
      "epoch": 0.19866364773500958,
      "grad_norm": 0.003806471126154065,
      "learning_rate": 8.013363522649905e-06,
      "loss": 0.0001,
      "step": 12547
    },
    {
      "epoch": 0.19867948129265164,
      "grad_norm": 0.5041794180870056,
      "learning_rate": 8.013205187073484e-06,
      "loss": 0.1855,
      "step": 12548
    },
    {
      "epoch": 0.1986953148502937,
      "grad_norm": 0.24314440786838531,
      "learning_rate": 8.013046851497063e-06,
      "loss": 0.0438,
      "step": 12549
    },
    {
      "epoch": 0.19871114840793577,
      "grad_norm": 0.5050777196884155,
      "learning_rate": 8.012888515920643e-06,
      "loss": 0.3855,
      "step": 12550
    },
    {
      "epoch": 0.19872698196557784,
      "grad_norm": 0.7701526880264282,
      "learning_rate": 8.012730180344223e-06,
      "loss": 0.1048,
      "step": 12551
    },
    {
      "epoch": 0.1987428155232199,
      "grad_norm": 0.19204220175743103,
      "learning_rate": 8.0125718447678e-06,
      "loss": 0.0492,
      "step": 12552
    },
    {
      "epoch": 0.19875864908086197,
      "grad_norm": 0.005321458913385868,
      "learning_rate": 8.012413509191382e-06,
      "loss": 0.0002,
      "step": 12553
    },
    {
      "epoch": 0.19877448263850406,
      "grad_norm": 0.27622103691101074,
      "learning_rate": 8.01225517361496e-06,
      "loss": 0.0577,
      "step": 12554
    },
    {
      "epoch": 0.19879031619614612,
      "grad_norm": 0.5398731827735901,
      "learning_rate": 8.01209683803854e-06,
      "loss": 0.4101,
      "step": 12555
    },
    {
      "epoch": 0.19880614975378819,
      "grad_norm": 0.0002147097111446783,
      "learning_rate": 8.011938502462119e-06,
      "loss": 0.0,
      "step": 12556
    },
    {
      "epoch": 0.19882198331143025,
      "grad_norm": 0.3271450102329254,
      "learning_rate": 8.0117801668857e-06,
      "loss": 0.0832,
      "step": 12557
    },
    {
      "epoch": 0.19883781686907231,
      "grad_norm": 0.36174485087394714,
      "learning_rate": 8.011621831309277e-06,
      "loss": 0.1137,
      "step": 12558
    },
    {
      "epoch": 0.19885365042671438,
      "grad_norm": 0.4022637903690338,
      "learning_rate": 8.011463495732858e-06,
      "loss": 0.1853,
      "step": 12559
    },
    {
      "epoch": 0.19886948398435644,
      "grad_norm": 0.4691407084465027,
      "learning_rate": 8.011305160156437e-06,
      "loss": 0.1558,
      "step": 12560
    },
    {
      "epoch": 0.1988853175419985,
      "grad_norm": 0.49691760540008545,
      "learning_rate": 8.011146824580016e-06,
      "loss": 0.3255,
      "step": 12561
    },
    {
      "epoch": 0.19890115109964057,
      "grad_norm": 0.22402310371398926,
      "learning_rate": 8.010988489003595e-06,
      "loss": 0.0043,
      "step": 12562
    },
    {
      "epoch": 0.19891698465728264,
      "grad_norm": 0.07886392623186111,
      "learning_rate": 8.010830153427174e-06,
      "loss": 0.0046,
      "step": 12563
    },
    {
      "epoch": 0.1989328182149247,
      "grad_norm": 0.22172173857688904,
      "learning_rate": 8.010671817850753e-06,
      "loss": 0.0851,
      "step": 12564
    },
    {
      "epoch": 0.19894865177256676,
      "grad_norm": 0.3158382475376129,
      "learning_rate": 8.010513482274332e-06,
      "loss": 0.0776,
      "step": 12565
    },
    {
      "epoch": 0.19896448533020886,
      "grad_norm": 0.28705865144729614,
      "learning_rate": 8.010355146697913e-06,
      "loss": 0.0633,
      "step": 12566
    },
    {
      "epoch": 0.19898031888785092,
      "grad_norm": 0.3181893229484558,
      "learning_rate": 8.010196811121492e-06,
      "loss": 0.1171,
      "step": 12567
    },
    {
      "epoch": 0.19899615244549299,
      "grad_norm": 7.389948586933315e-05,
      "learning_rate": 8.010038475545071e-06,
      "loss": 0.0,
      "step": 12568
    },
    {
      "epoch": 0.19901198600313505,
      "grad_norm": 0.5688302516937256,
      "learning_rate": 8.00988013996865e-06,
      "loss": 0.295,
      "step": 12569
    },
    {
      "epoch": 0.19902781956077711,
      "grad_norm": 0.2994038164615631,
      "learning_rate": 8.00972180439223e-06,
      "loss": 0.099,
      "step": 12570
    },
    {
      "epoch": 0.19904365311841918,
      "grad_norm": 0.4036913812160492,
      "learning_rate": 8.009563468815808e-06,
      "loss": 0.1049,
      "step": 12571
    },
    {
      "epoch": 0.19905948667606124,
      "grad_norm": 0.17372947931289673,
      "learning_rate": 8.009405133239389e-06,
      "loss": 0.0724,
      "step": 12572
    },
    {
      "epoch": 0.1990753202337033,
      "grad_norm": 0.0016540954820811749,
      "learning_rate": 8.009246797662966e-06,
      "loss": 0.0,
      "step": 12573
    },
    {
      "epoch": 0.19909115379134537,
      "grad_norm": 0.46160683035850525,
      "learning_rate": 8.009088462086547e-06,
      "loss": 0.1288,
      "step": 12574
    },
    {
      "epoch": 0.19910698734898744,
      "grad_norm": 0.31280818581581116,
      "learning_rate": 8.008930126510126e-06,
      "loss": 0.0783,
      "step": 12575
    },
    {
      "epoch": 0.1991228209066295,
      "grad_norm": 0.3944365382194519,
      "learning_rate": 8.008771790933705e-06,
      "loss": 0.1294,
      "step": 12576
    },
    {
      "epoch": 0.19913865446427156,
      "grad_norm": 0.42483606934547424,
      "learning_rate": 8.008613455357284e-06,
      "loss": 0.2274,
      "step": 12577
    },
    {
      "epoch": 0.19915448802191366,
      "grad_norm": 0.32158079743385315,
      "learning_rate": 8.008455119780865e-06,
      "loss": 0.0157,
      "step": 12578
    },
    {
      "epoch": 0.19917032157955572,
      "grad_norm": 0.36701342463493347,
      "learning_rate": 8.008296784204443e-06,
      "loss": 0.0295,
      "step": 12579
    },
    {
      "epoch": 0.19918615513719778,
      "grad_norm": 0.061989761888980865,
      "learning_rate": 8.008138448628023e-06,
      "loss": 0.0038,
      "step": 12580
    },
    {
      "epoch": 0.19920198869483985,
      "grad_norm": 0.3076843321323395,
      "learning_rate": 8.007980113051603e-06,
      "loss": 0.0861,
      "step": 12581
    },
    {
      "epoch": 0.1992178222524819,
      "grad_norm": 0.07751886546611786,
      "learning_rate": 8.007821777475182e-06,
      "loss": 0.0141,
      "step": 12582
    },
    {
      "epoch": 0.19923365581012398,
      "grad_norm": 0.32117143273353577,
      "learning_rate": 8.00766344189876e-06,
      "loss": 0.1006,
      "step": 12583
    },
    {
      "epoch": 0.19924948936776604,
      "grad_norm": 0.00010849440150195733,
      "learning_rate": 8.00750510632234e-06,
      "loss": 0.0,
      "step": 12584
    },
    {
      "epoch": 0.1992653229254081,
      "grad_norm": 0.18905854225158691,
      "learning_rate": 8.007346770745919e-06,
      "loss": 0.0417,
      "step": 12585
    },
    {
      "epoch": 0.19928115648305017,
      "grad_norm": 0.24837224185466766,
      "learning_rate": 8.007188435169498e-06,
      "loss": 0.0779,
      "step": 12586
    },
    {
      "epoch": 0.19929699004069223,
      "grad_norm": 0.427132785320282,
      "learning_rate": 8.007030099593079e-06,
      "loss": 0.1516,
      "step": 12587
    },
    {
      "epoch": 0.1993128235983343,
      "grad_norm": 0.5175303220748901,
      "learning_rate": 8.006871764016658e-06,
      "loss": 0.209,
      "step": 12588
    },
    {
      "epoch": 0.19932865715597636,
      "grad_norm": 0.013262424618005753,
      "learning_rate": 8.006713428440237e-06,
      "loss": 0.0007,
      "step": 12589
    },
    {
      "epoch": 0.19934449071361846,
      "grad_norm": 0.1597362756729126,
      "learning_rate": 8.006555092863816e-06,
      "loss": 0.041,
      "step": 12590
    },
    {
      "epoch": 0.19936032427126052,
      "grad_norm": 0.15856720507144928,
      "learning_rate": 8.006396757287395e-06,
      "loss": 0.0642,
      "step": 12591
    },
    {
      "epoch": 0.19937615782890258,
      "grad_norm": 0.35132119059562683,
      "learning_rate": 8.006238421710974e-06,
      "loss": 0.039,
      "step": 12592
    },
    {
      "epoch": 0.19939199138654465,
      "grad_norm": 0.1947111338376999,
      "learning_rate": 8.006080086134555e-06,
      "loss": 0.0981,
      "step": 12593
    },
    {
      "epoch": 0.1994078249441867,
      "grad_norm": 0.6797413229942322,
      "learning_rate": 8.005921750558134e-06,
      "loss": 0.6854,
      "step": 12594
    },
    {
      "epoch": 0.19942365850182878,
      "grad_norm": 0.00798582099378109,
      "learning_rate": 8.005763414981713e-06,
      "loss": 0.0004,
      "step": 12595
    },
    {
      "epoch": 0.19943949205947084,
      "grad_norm": 0.026487823575735092,
      "learning_rate": 8.005605079405292e-06,
      "loss": 0.0016,
      "step": 12596
    },
    {
      "epoch": 0.1994553256171129,
      "grad_norm": 0.0003082163748331368,
      "learning_rate": 8.005446743828871e-06,
      "loss": 0.0,
      "step": 12597
    },
    {
      "epoch": 0.19947115917475497,
      "grad_norm": 0.2235300987958908,
      "learning_rate": 8.00528840825245e-06,
      "loss": 0.0715,
      "step": 12598
    },
    {
      "epoch": 0.19948699273239703,
      "grad_norm": 0.3782122731208801,
      "learning_rate": 8.005130072676031e-06,
      "loss": 0.0449,
      "step": 12599
    },
    {
      "epoch": 0.1995028262900391,
      "grad_norm": 0.01534457691013813,
      "learning_rate": 8.00497173709961e-06,
      "loss": 0.0007,
      "step": 12600
    },
    {
      "epoch": 0.19951865984768116,
      "grad_norm": 0.00028982842923142016,
      "learning_rate": 8.00481340152319e-06,
      "loss": 0.0,
      "step": 12601
    },
    {
      "epoch": 0.19953449340532325,
      "grad_norm": 0.22671915590763092,
      "learning_rate": 8.004655065946768e-06,
      "loss": 0.0808,
      "step": 12602
    },
    {
      "epoch": 0.19955032696296532,
      "grad_norm": 0.2571454644203186,
      "learning_rate": 8.004496730370347e-06,
      "loss": 0.0701,
      "step": 12603
    },
    {
      "epoch": 0.19956616052060738,
      "grad_norm": 0.12170529365539551,
      "learning_rate": 8.004338394793926e-06,
      "loss": 0.0253,
      "step": 12604
    },
    {
      "epoch": 0.19958199407824945,
      "grad_norm": 0.3773728609085083,
      "learning_rate": 8.004180059217507e-06,
      "loss": 0.0554,
      "step": 12605
    },
    {
      "epoch": 0.1995978276358915,
      "grad_norm": 0.015198332257568836,
      "learning_rate": 8.004021723641086e-06,
      "loss": 0.0006,
      "step": 12606
    },
    {
      "epoch": 0.19961366119353358,
      "grad_norm": 0.2828182578086853,
      "learning_rate": 8.003863388064665e-06,
      "loss": 0.0612,
      "step": 12607
    },
    {
      "epoch": 0.19962949475117564,
      "grad_norm": 0.23685789108276367,
      "learning_rate": 8.003705052488244e-06,
      "loss": 0.062,
      "step": 12608
    },
    {
      "epoch": 0.1996453283088177,
      "grad_norm": 0.8326887488365173,
      "learning_rate": 8.003546716911824e-06,
      "loss": 0.2144,
      "step": 12609
    },
    {
      "epoch": 0.19966116186645977,
      "grad_norm": 0.020150788128376007,
      "learning_rate": 8.003388381335403e-06,
      "loss": 0.0009,
      "step": 12610
    },
    {
      "epoch": 0.19967699542410183,
      "grad_norm": 0.49733859300613403,
      "learning_rate": 8.003230045758982e-06,
      "loss": 0.2241,
      "step": 12611
    },
    {
      "epoch": 0.1996928289817439,
      "grad_norm": 0.2453954666852951,
      "learning_rate": 8.003071710182562e-06,
      "loss": 0.1688,
      "step": 12612
    },
    {
      "epoch": 0.19970866253938596,
      "grad_norm": 0.6635497212409973,
      "learning_rate": 8.00291337460614e-06,
      "loss": 0.0755,
      "step": 12613
    },
    {
      "epoch": 0.19972449609702805,
      "grad_norm": 0.12459997832775116,
      "learning_rate": 8.00275503902972e-06,
      "loss": 0.0096,
      "step": 12614
    },
    {
      "epoch": 0.19974032965467012,
      "grad_norm": 0.3308422863483429,
      "learning_rate": 8.0025967034533e-06,
      "loss": 0.0916,
      "step": 12615
    },
    {
      "epoch": 0.19975616321231218,
      "grad_norm": 0.5377693176269531,
      "learning_rate": 8.002438367876879e-06,
      "loss": 0.0397,
      "step": 12616
    },
    {
      "epoch": 0.19977199676995425,
      "grad_norm": 0.3533102869987488,
      "learning_rate": 8.002280032300458e-06,
      "loss": 0.1015,
      "step": 12617
    },
    {
      "epoch": 0.1997878303275963,
      "grad_norm": 0.2774277329444885,
      "learning_rate": 8.002121696724039e-06,
      "loss": 0.0677,
      "step": 12618
    },
    {
      "epoch": 0.19980366388523838,
      "grad_norm": 0.1544758379459381,
      "learning_rate": 8.001963361147616e-06,
      "loss": 0.0607,
      "step": 12619
    },
    {
      "epoch": 0.19981949744288044,
      "grad_norm": 0.520980179309845,
      "learning_rate": 8.001805025571197e-06,
      "loss": 0.4852,
      "step": 12620
    },
    {
      "epoch": 0.1998353310005225,
      "grad_norm": 0.48381832242012024,
      "learning_rate": 8.001646689994776e-06,
      "loss": 0.1439,
      "step": 12621
    },
    {
      "epoch": 0.19985116455816457,
      "grad_norm": 0.8002070784568787,
      "learning_rate": 8.001488354418355e-06,
      "loss": 0.2009,
      "step": 12622
    },
    {
      "epoch": 0.19986699811580663,
      "grad_norm": 0.17971612513065338,
      "learning_rate": 8.001330018841934e-06,
      "loss": 0.0681,
      "step": 12623
    },
    {
      "epoch": 0.1998828316734487,
      "grad_norm": 0.7146070599555969,
      "learning_rate": 8.001171683265515e-06,
      "loss": 0.2455,
      "step": 12624
    },
    {
      "epoch": 0.19989866523109076,
      "grad_norm": 0.3055405914783478,
      "learning_rate": 8.001013347689092e-06,
      "loss": 0.0643,
      "step": 12625
    },
    {
      "epoch": 0.19991449878873285,
      "grad_norm": 0.4419862627983093,
      "learning_rate": 8.000855012112673e-06,
      "loss": 0.0091,
      "step": 12626
    },
    {
      "epoch": 0.19993033234637492,
      "grad_norm": 0.005827290937304497,
      "learning_rate": 8.000696676536252e-06,
      "loss": 0.0003,
      "step": 12627
    },
    {
      "epoch": 0.19994616590401698,
      "grad_norm": 0.6089035272598267,
      "learning_rate": 8.000538340959831e-06,
      "loss": 0.1456,
      "step": 12628
    },
    {
      "epoch": 0.19996199946165905,
      "grad_norm": 0.5094760060310364,
      "learning_rate": 8.00038000538341e-06,
      "loss": 0.0443,
      "step": 12629
    },
    {
      "epoch": 0.1999778330193011,
      "grad_norm": 0.26972338557243347,
      "learning_rate": 8.00022166980699e-06,
      "loss": 0.0338,
      "step": 12630
    },
    {
      "epoch": 0.19999366657694317,
      "grad_norm": 0.632771372795105,
      "learning_rate": 8.000063334230568e-06,
      "loss": 0.0668,
      "step": 12631
    },
    {
      "epoch": 0.20000950013458524,
      "grad_norm": 0.007842804305255413,
      "learning_rate": 7.999904998654147e-06,
      "loss": 0.0004,
      "step": 12632
    },
    {
      "epoch": 0.2000253336922273,
      "grad_norm": 0.28602099418640137,
      "learning_rate": 7.999746663077728e-06,
      "loss": 0.0388,
      "step": 12633
    },
    {
      "epoch": 0.20004116724986937,
      "grad_norm": 0.14201542735099792,
      "learning_rate": 7.999588327501306e-06,
      "loss": 0.0436,
      "step": 12634
    },
    {
      "epoch": 0.20005700080751143,
      "grad_norm": 0.45726191997528076,
      "learning_rate": 7.999429991924886e-06,
      "loss": 0.0695,
      "step": 12635
    },
    {
      "epoch": 0.2000728343651535,
      "grad_norm": 0.4234005808830261,
      "learning_rate": 7.999271656348465e-06,
      "loss": 0.0437,
      "step": 12636
    },
    {
      "epoch": 0.20008866792279556,
      "grad_norm": 0.4448734223842621,
      "learning_rate": 7.999113320772045e-06,
      "loss": 0.1146,
      "step": 12637
    },
    {
      "epoch": 0.20010450148043765,
      "grad_norm": 0.8645979762077332,
      "learning_rate": 7.998954985195624e-06,
      "loss": 0.2246,
      "step": 12638
    },
    {
      "epoch": 0.20012033503807972,
      "grad_norm": 0.3919234275817871,
      "learning_rate": 7.998796649619204e-06,
      "loss": 0.0348,
      "step": 12639
    },
    {
      "epoch": 0.20013616859572178,
      "grad_norm": 0.044048748910427094,
      "learning_rate": 7.998638314042782e-06,
      "loss": 0.0027,
      "step": 12640
    },
    {
      "epoch": 0.20015200215336384,
      "grad_norm": 0.22445990145206451,
      "learning_rate": 7.998479978466363e-06,
      "loss": 0.0724,
      "step": 12641
    },
    {
      "epoch": 0.2001678357110059,
      "grad_norm": 0.28711166977882385,
      "learning_rate": 7.998321642889942e-06,
      "loss": 0.0662,
      "step": 12642
    },
    {
      "epoch": 0.20018366926864797,
      "grad_norm": 1.286601185798645,
      "learning_rate": 7.99816330731352e-06,
      "loss": 0.078,
      "step": 12643
    },
    {
      "epoch": 0.20019950282629004,
      "grad_norm": 0.34039270877838135,
      "learning_rate": 7.9980049717371e-06,
      "loss": 0.073,
      "step": 12644
    },
    {
      "epoch": 0.2002153363839321,
      "grad_norm": 0.14198164641857147,
      "learning_rate": 7.99784663616068e-06,
      "loss": 0.0361,
      "step": 12645
    },
    {
      "epoch": 0.20023116994157417,
      "grad_norm": 0.30407336354255676,
      "learning_rate": 7.997688300584258e-06,
      "loss": 0.0836,
      "step": 12646
    },
    {
      "epoch": 0.20024700349921623,
      "grad_norm": 0.5387435555458069,
      "learning_rate": 7.997529965007839e-06,
      "loss": 0.0227,
      "step": 12647
    },
    {
      "epoch": 0.2002628370568583,
      "grad_norm": 0.7144032120704651,
      "learning_rate": 7.997371629431418e-06,
      "loss": 0.0203,
      "step": 12648
    },
    {
      "epoch": 0.20027867061450036,
      "grad_norm": 0.09431076049804688,
      "learning_rate": 7.997213293854997e-06,
      "loss": 0.0043,
      "step": 12649
    },
    {
      "epoch": 0.20029450417214245,
      "grad_norm": 0.3582308888435364,
      "learning_rate": 7.997054958278576e-06,
      "loss": 0.1348,
      "step": 12650
    },
    {
      "epoch": 0.20031033772978452,
      "grad_norm": 8.083737338893116e-05,
      "learning_rate": 7.996896622702157e-06,
      "loss": 0.0,
      "step": 12651
    },
    {
      "epoch": 0.20032617128742658,
      "grad_norm": 0.00022343677119351923,
      "learning_rate": 7.996738287125734e-06,
      "loss": 0.0,
      "step": 12652
    },
    {
      "epoch": 0.20034200484506864,
      "grad_norm": 0.006437075790017843,
      "learning_rate": 7.996579951549315e-06,
      "loss": 0.0003,
      "step": 12653
    },
    {
      "epoch": 0.2003578384027107,
      "grad_norm": 0.010138988494873047,
      "learning_rate": 7.996421615972894e-06,
      "loss": 0.0004,
      "step": 12654
    },
    {
      "epoch": 0.20037367196035277,
      "grad_norm": 0.33651039004325867,
      "learning_rate": 7.996263280396473e-06,
      "loss": 0.2596,
      "step": 12655
    },
    {
      "epoch": 0.20038950551799484,
      "grad_norm": 0.33030328154563904,
      "learning_rate": 7.996104944820052e-06,
      "loss": 0.1245,
      "step": 12656
    },
    {
      "epoch": 0.2004053390756369,
      "grad_norm": 0.3348757028579712,
      "learning_rate": 7.995946609243631e-06,
      "loss": 0.0615,
      "step": 12657
    },
    {
      "epoch": 0.20042117263327897,
      "grad_norm": 0.00048772498848848045,
      "learning_rate": 7.99578827366721e-06,
      "loss": 0.0,
      "step": 12658
    },
    {
      "epoch": 0.20043700619092103,
      "grad_norm": 0.7162269949913025,
      "learning_rate": 7.99562993809079e-06,
      "loss": 0.1493,
      "step": 12659
    },
    {
      "epoch": 0.2004528397485631,
      "grad_norm": 0.5721564888954163,
      "learning_rate": 7.99547160251437e-06,
      "loss": 0.0709,
      "step": 12660
    },
    {
      "epoch": 0.20046867330620516,
      "grad_norm": 0.03614635765552521,
      "learning_rate": 7.99531326693795e-06,
      "loss": 0.0018,
      "step": 12661
    },
    {
      "epoch": 0.20048450686384725,
      "grad_norm": 0.49934783577919006,
      "learning_rate": 7.995154931361528e-06,
      "loss": 0.3103,
      "step": 12662
    },
    {
      "epoch": 0.20050034042148931,
      "grad_norm": 0.7209745049476624,
      "learning_rate": 7.994996595785107e-06,
      "loss": 0.4958,
      "step": 12663
    },
    {
      "epoch": 0.20051617397913138,
      "grad_norm": 0.49364396929740906,
      "learning_rate": 7.994838260208686e-06,
      "loss": 0.1364,
      "step": 12664
    },
    {
      "epoch": 0.20053200753677344,
      "grad_norm": 0.44104573130607605,
      "learning_rate": 7.994679924632266e-06,
      "loss": 0.1442,
      "step": 12665
    },
    {
      "epoch": 0.2005478410944155,
      "grad_norm": 0.17957483232021332,
      "learning_rate": 7.994521589055846e-06,
      "loss": 0.0159,
      "step": 12666
    },
    {
      "epoch": 0.20056367465205757,
      "grad_norm": 0.01307488139718771,
      "learning_rate": 7.994363253479425e-06,
      "loss": 0.0012,
      "step": 12667
    },
    {
      "epoch": 0.20057950820969964,
      "grad_norm": 7.246075983857736e-05,
      "learning_rate": 7.994204917903004e-06,
      "loss": 0.0,
      "step": 12668
    },
    {
      "epoch": 0.2005953417673417,
      "grad_norm": 0.6201512813568115,
      "learning_rate": 7.994046582326584e-06,
      "loss": 0.2597,
      "step": 12669
    },
    {
      "epoch": 0.20061117532498376,
      "grad_norm": 2.629670598253142e-05,
      "learning_rate": 7.993888246750163e-06,
      "loss": 0.0,
      "step": 12670
    },
    {
      "epoch": 0.20062700888262583,
      "grad_norm": 0.11997772008180618,
      "learning_rate": 7.993729911173742e-06,
      "loss": 0.0088,
      "step": 12671
    },
    {
      "epoch": 0.2006428424402679,
      "grad_norm": 0.4086983799934387,
      "learning_rate": 7.993571575597322e-06,
      "loss": 0.0191,
      "step": 12672
    },
    {
      "epoch": 0.20065867599790996,
      "grad_norm": 0.2929617166519165,
      "learning_rate": 7.993413240020902e-06,
      "loss": 0.0819,
      "step": 12673
    },
    {
      "epoch": 0.20067450955555205,
      "grad_norm": 0.31095853447914124,
      "learning_rate": 7.99325490444448e-06,
      "loss": 0.2841,
      "step": 12674
    },
    {
      "epoch": 0.20069034311319411,
      "grad_norm": 0.22153973579406738,
      "learning_rate": 7.99309656886806e-06,
      "loss": 0.0774,
      "step": 12675
    },
    {
      "epoch": 0.20070617667083618,
      "grad_norm": 0.3663260042667389,
      "learning_rate": 7.992938233291639e-06,
      "loss": 0.0259,
      "step": 12676
    },
    {
      "epoch": 0.20072201022847824,
      "grad_norm": 0.17302203178405762,
      "learning_rate": 7.992779897715218e-06,
      "loss": 0.0561,
      "step": 12677
    },
    {
      "epoch": 0.2007378437861203,
      "grad_norm": 0.19676397740840912,
      "learning_rate": 7.992621562138799e-06,
      "loss": 0.0634,
      "step": 12678
    },
    {
      "epoch": 0.20075367734376237,
      "grad_norm": 0.4044245481491089,
      "learning_rate": 7.992463226562378e-06,
      "loss": 0.1687,
      "step": 12679
    },
    {
      "epoch": 0.20076951090140444,
      "grad_norm": 0.045230932533741,
      "learning_rate": 7.992304890985955e-06,
      "loss": 0.0057,
      "step": 12680
    },
    {
      "epoch": 0.2007853444590465,
      "grad_norm": 0.2155536413192749,
      "learning_rate": 7.992146555409536e-06,
      "loss": 0.0578,
      "step": 12681
    },
    {
      "epoch": 0.20080117801668856,
      "grad_norm": 0.49275508522987366,
      "learning_rate": 7.991988219833115e-06,
      "loss": 0.3433,
      "step": 12682
    },
    {
      "epoch": 0.20081701157433063,
      "grad_norm": 0.691644549369812,
      "learning_rate": 7.991829884256694e-06,
      "loss": 0.1809,
      "step": 12683
    },
    {
      "epoch": 0.2008328451319727,
      "grad_norm": 0.33034107089042664,
      "learning_rate": 7.991671548680273e-06,
      "loss": 0.2276,
      "step": 12684
    },
    {
      "epoch": 0.20084867868961476,
      "grad_norm": 0.04490391165018082,
      "learning_rate": 7.991513213103854e-06,
      "loss": 0.0026,
      "step": 12685
    },
    {
      "epoch": 0.20086451224725685,
      "grad_norm": 0.7418544888496399,
      "learning_rate": 7.991354877527431e-06,
      "loss": 0.204,
      "step": 12686
    },
    {
      "epoch": 0.2008803458048989,
      "grad_norm": 0.02351243793964386,
      "learning_rate": 7.991196541951012e-06,
      "loss": 0.0016,
      "step": 12687
    },
    {
      "epoch": 0.20089617936254098,
      "grad_norm": 0.5240505337715149,
      "learning_rate": 7.991038206374591e-06,
      "loss": 0.0662,
      "step": 12688
    },
    {
      "epoch": 0.20091201292018304,
      "grad_norm": 0.017053762450814247,
      "learning_rate": 7.99087987079817e-06,
      "loss": 0.001,
      "step": 12689
    },
    {
      "epoch": 0.2009278464778251,
      "grad_norm": 0.34808212518692017,
      "learning_rate": 7.99072153522175e-06,
      "loss": 0.0782,
      "step": 12690
    },
    {
      "epoch": 0.20094368003546717,
      "grad_norm": 0.2913874089717865,
      "learning_rate": 7.99056319964533e-06,
      "loss": 0.1303,
      "step": 12691
    },
    {
      "epoch": 0.20095951359310923,
      "grad_norm": 0.1741909682750702,
      "learning_rate": 7.990404864068907e-06,
      "loss": 0.0349,
      "step": 12692
    },
    {
      "epoch": 0.2009753471507513,
      "grad_norm": 0.22666576504707336,
      "learning_rate": 7.990246528492488e-06,
      "loss": 0.0701,
      "step": 12693
    },
    {
      "epoch": 0.20099118070839336,
      "grad_norm": 0.29149651527404785,
      "learning_rate": 7.990088192916067e-06,
      "loss": 0.0673,
      "step": 12694
    },
    {
      "epoch": 0.20100701426603543,
      "grad_norm": 0.6444761157035828,
      "learning_rate": 7.989929857339646e-06,
      "loss": 0.2175,
      "step": 12695
    },
    {
      "epoch": 0.2010228478236775,
      "grad_norm": 0.4734565019607544,
      "learning_rate": 7.989771521763225e-06,
      "loss": 0.2203,
      "step": 12696
    },
    {
      "epoch": 0.20103868138131956,
      "grad_norm": 0.014152891002595425,
      "learning_rate": 7.989613186186805e-06,
      "loss": 0.0006,
      "step": 12697
    },
    {
      "epoch": 0.20105451493896165,
      "grad_norm": 0.6693335175514221,
      "learning_rate": 7.989454850610384e-06,
      "loss": 0.485,
      "step": 12698
    },
    {
      "epoch": 0.2010703484966037,
      "grad_norm": 0.0014604923781007528,
      "learning_rate": 7.989296515033964e-06,
      "loss": 0.0,
      "step": 12699
    },
    {
      "epoch": 0.20108618205424578,
      "grad_norm": 0.6654253602027893,
      "learning_rate": 7.989138179457543e-06,
      "loss": 0.2278,
      "step": 12700
    },
    {
      "epoch": 0.20110201561188784,
      "grad_norm": 0.4476245045661926,
      "learning_rate": 7.988979843881123e-06,
      "loss": 0.404,
      "step": 12701
    },
    {
      "epoch": 0.2011178491695299,
      "grad_norm": 0.00027161810430698097,
      "learning_rate": 7.988821508304702e-06,
      "loss": 0.0,
      "step": 12702
    },
    {
      "epoch": 0.20113368272717197,
      "grad_norm": 4.274219989776611,
      "learning_rate": 7.98866317272828e-06,
      "loss": 0.0576,
      "step": 12703
    },
    {
      "epoch": 0.20114951628481403,
      "grad_norm": 0.48923882842063904,
      "learning_rate": 7.98850483715186e-06,
      "loss": 0.4495,
      "step": 12704
    },
    {
      "epoch": 0.2011653498424561,
      "grad_norm": 0.25658994913101196,
      "learning_rate": 7.988346501575439e-06,
      "loss": 0.1247,
      "step": 12705
    },
    {
      "epoch": 0.20118118340009816,
      "grad_norm": 0.5817720293998718,
      "learning_rate": 7.98818816599902e-06,
      "loss": 0.3919,
      "step": 12706
    },
    {
      "epoch": 0.20119701695774023,
      "grad_norm": 0.03967215493321419,
      "learning_rate": 7.988029830422597e-06,
      "loss": 0.0023,
      "step": 12707
    },
    {
      "epoch": 0.2012128505153823,
      "grad_norm": 0.5653508901596069,
      "learning_rate": 7.987871494846178e-06,
      "loss": 0.168,
      "step": 12708
    },
    {
      "epoch": 0.20122868407302436,
      "grad_norm": 0.43077826499938965,
      "learning_rate": 7.987713159269757e-06,
      "loss": 0.0667,
      "step": 12709
    },
    {
      "epoch": 0.20124451763066645,
      "grad_norm": 0.022004179656505585,
      "learning_rate": 7.987554823693336e-06,
      "loss": 0.0012,
      "step": 12710
    },
    {
      "epoch": 0.2012603511883085,
      "grad_norm": 9.47364533203654e-05,
      "learning_rate": 7.987396488116915e-06,
      "loss": 0.0,
      "step": 12711
    },
    {
      "epoch": 0.20127618474595058,
      "grad_norm": 0.00016250567568931729,
      "learning_rate": 7.987238152540496e-06,
      "loss": 0.0,
      "step": 12712
    },
    {
      "epoch": 0.20129201830359264,
      "grad_norm": 0.8917686343193054,
      "learning_rate": 7.987079816964073e-06,
      "loss": 0.174,
      "step": 12713
    },
    {
      "epoch": 0.2013078518612347,
      "grad_norm": 0.43893590569496155,
      "learning_rate": 7.986921481387654e-06,
      "loss": 0.1878,
      "step": 12714
    },
    {
      "epoch": 0.20132368541887677,
      "grad_norm": 0.6485151648521423,
      "learning_rate": 7.986763145811233e-06,
      "loss": 0.4385,
      "step": 12715
    },
    {
      "epoch": 0.20133951897651883,
      "grad_norm": 0.06628825515508652,
      "learning_rate": 7.986604810234812e-06,
      "loss": 0.0033,
      "step": 12716
    },
    {
      "epoch": 0.2013553525341609,
      "grad_norm": 0.6089735627174377,
      "learning_rate": 7.986446474658391e-06,
      "loss": 0.2372,
      "step": 12717
    },
    {
      "epoch": 0.20137118609180296,
      "grad_norm": 0.19749461114406586,
      "learning_rate": 7.986288139081972e-06,
      "loss": 0.0189,
      "step": 12718
    },
    {
      "epoch": 0.20138701964944503,
      "grad_norm": 0.36468949913978577,
      "learning_rate": 7.98612980350555e-06,
      "loss": 0.0936,
      "step": 12719
    },
    {
      "epoch": 0.2014028532070871,
      "grad_norm": 0.7767823934555054,
      "learning_rate": 7.98597146792913e-06,
      "loss": 0.2181,
      "step": 12720
    },
    {
      "epoch": 0.20141868676472915,
      "grad_norm": 0.4577043950557709,
      "learning_rate": 7.98581313235271e-06,
      "loss": 0.1888,
      "step": 12721
    },
    {
      "epoch": 0.20143452032237125,
      "grad_norm": 0.0656554326415062,
      "learning_rate": 7.985654796776288e-06,
      "loss": 0.0018,
      "step": 12722
    },
    {
      "epoch": 0.2014503538800133,
      "grad_norm": 0.2192368358373642,
      "learning_rate": 7.985496461199867e-06,
      "loss": 0.0067,
      "step": 12723
    },
    {
      "epoch": 0.20146618743765538,
      "grad_norm": 0.0017555482918396592,
      "learning_rate": 7.985338125623448e-06,
      "loss": 0.0001,
      "step": 12724
    },
    {
      "epoch": 0.20148202099529744,
      "grad_norm": 0.2629118859767914,
      "learning_rate": 7.985179790047026e-06,
      "loss": 0.0638,
      "step": 12725
    },
    {
      "epoch": 0.2014978545529395,
      "grad_norm": 0.5537775754928589,
      "learning_rate": 7.985021454470606e-06,
      "loss": 0.0471,
      "step": 12726
    },
    {
      "epoch": 0.20151368811058157,
      "grad_norm": 0.22306674718856812,
      "learning_rate": 7.984863118894185e-06,
      "loss": 0.0995,
      "step": 12727
    },
    {
      "epoch": 0.20152952166822363,
      "grad_norm": 0.27946072816848755,
      "learning_rate": 7.984704783317764e-06,
      "loss": 0.0976,
      "step": 12728
    },
    {
      "epoch": 0.2015453552258657,
      "grad_norm": 0.1846281886100769,
      "learning_rate": 7.984546447741344e-06,
      "loss": 0.0648,
      "step": 12729
    },
    {
      "epoch": 0.20156118878350776,
      "grad_norm": 0.35898441076278687,
      "learning_rate": 7.984388112164923e-06,
      "loss": 0.0508,
      "step": 12730
    },
    {
      "epoch": 0.20157702234114983,
      "grad_norm": 0.3239559233188629,
      "learning_rate": 7.984229776588502e-06,
      "loss": 0.0906,
      "step": 12731
    },
    {
      "epoch": 0.2015928558987919,
      "grad_norm": 0.1473371386528015,
      "learning_rate": 7.98407144101208e-06,
      "loss": 0.0511,
      "step": 12732
    },
    {
      "epoch": 0.20160868945643395,
      "grad_norm": 0.35399770736694336,
      "learning_rate": 7.983913105435662e-06,
      "loss": 0.1176,
      "step": 12733
    },
    {
      "epoch": 0.20162452301407605,
      "grad_norm": 0.9497798085212708,
      "learning_rate": 7.98375476985924e-06,
      "loss": 0.2699,
      "step": 12734
    },
    {
      "epoch": 0.2016403565717181,
      "grad_norm": 0.5951777696609497,
      "learning_rate": 7.98359643428282e-06,
      "loss": 0.1932,
      "step": 12735
    },
    {
      "epoch": 0.20165619012936017,
      "grad_norm": 0.3498593866825104,
      "learning_rate": 7.983438098706399e-06,
      "loss": 0.0362,
      "step": 12736
    },
    {
      "epoch": 0.20167202368700224,
      "grad_norm": 0.0007633344503119588,
      "learning_rate": 7.983279763129978e-06,
      "loss": 0.0,
      "step": 12737
    },
    {
      "epoch": 0.2016878572446443,
      "grad_norm": 0.36422568559646606,
      "learning_rate": 7.983121427553557e-06,
      "loss": 0.164,
      "step": 12738
    },
    {
      "epoch": 0.20170369080228637,
      "grad_norm": 0.3600670397281647,
      "learning_rate": 7.982963091977138e-06,
      "loss": 0.2267,
      "step": 12739
    },
    {
      "epoch": 0.20171952435992843,
      "grad_norm": 0.189451202750206,
      "learning_rate": 7.982804756400717e-06,
      "loss": 0.0424,
      "step": 12740
    },
    {
      "epoch": 0.2017353579175705,
      "grad_norm": 0.2959844768047333,
      "learning_rate": 7.982646420824296e-06,
      "loss": 0.0883,
      "step": 12741
    },
    {
      "epoch": 0.20175119147521256,
      "grad_norm": 0.46725043654441833,
      "learning_rate": 7.982488085247875e-06,
      "loss": 0.0245,
      "step": 12742
    },
    {
      "epoch": 0.20176702503285462,
      "grad_norm": 1.4435906410217285,
      "learning_rate": 7.982329749671454e-06,
      "loss": 0.1675,
      "step": 12743
    },
    {
      "epoch": 0.2017828585904967,
      "grad_norm": 0.1942596584558487,
      "learning_rate": 7.982171414095033e-06,
      "loss": 0.0412,
      "step": 12744
    },
    {
      "epoch": 0.20179869214813875,
      "grad_norm": 0.44211289286613464,
      "learning_rate": 7.982013078518614e-06,
      "loss": 0.2487,
      "step": 12745
    },
    {
      "epoch": 0.20181452570578085,
      "grad_norm": 0.21503609418869019,
      "learning_rate": 7.981854742942193e-06,
      "loss": 0.0546,
      "step": 12746
    },
    {
      "epoch": 0.2018303592634229,
      "grad_norm": 0.18057167530059814,
      "learning_rate": 7.981696407365772e-06,
      "loss": 0.0327,
      "step": 12747
    },
    {
      "epoch": 0.20184619282106497,
      "grad_norm": 0.7232174277305603,
      "learning_rate": 7.981538071789351e-06,
      "loss": 0.1756,
      "step": 12748
    },
    {
      "epoch": 0.20186202637870704,
      "grad_norm": 0.4715885818004608,
      "learning_rate": 7.98137973621293e-06,
      "loss": 0.2176,
      "step": 12749
    },
    {
      "epoch": 0.2018778599363491,
      "grad_norm": 0.17020688951015472,
      "learning_rate": 7.98122140063651e-06,
      "loss": 0.0464,
      "step": 12750
    },
    {
      "epoch": 0.20189369349399117,
      "grad_norm": 0.5016847848892212,
      "learning_rate": 7.98106306506009e-06,
      "loss": 0.0213,
      "step": 12751
    },
    {
      "epoch": 0.20190952705163323,
      "grad_norm": 0.21843382716178894,
      "learning_rate": 7.98090472948367e-06,
      "loss": 0.0928,
      "step": 12752
    },
    {
      "epoch": 0.2019253606092753,
      "grad_norm": 0.12214430421590805,
      "learning_rate": 7.980746393907247e-06,
      "loss": 0.0384,
      "step": 12753
    },
    {
      "epoch": 0.20194119416691736,
      "grad_norm": 0.39499884843826294,
      "learning_rate": 7.980588058330827e-06,
      "loss": 0.1041,
      "step": 12754
    },
    {
      "epoch": 0.20195702772455942,
      "grad_norm": 0.02794729545712471,
      "learning_rate": 7.980429722754406e-06,
      "loss": 0.0015,
      "step": 12755
    },
    {
      "epoch": 0.2019728612822015,
      "grad_norm": 0.007812906987965107,
      "learning_rate": 7.980271387177985e-06,
      "loss": 0.0005,
      "step": 12756
    },
    {
      "epoch": 0.20198869483984355,
      "grad_norm": 0.022221272811293602,
      "learning_rate": 7.980113051601565e-06,
      "loss": 0.0013,
      "step": 12757
    },
    {
      "epoch": 0.20200452839748564,
      "grad_norm": 0.226831316947937,
      "learning_rate": 7.979954716025145e-06,
      "loss": 0.0878,
      "step": 12758
    },
    {
      "epoch": 0.2020203619551277,
      "grad_norm": 0.15927332639694214,
      "learning_rate": 7.979796380448723e-06,
      "loss": 0.0675,
      "step": 12759
    },
    {
      "epoch": 0.20203619551276977,
      "grad_norm": 0.013074559159576893,
      "learning_rate": 7.979638044872303e-06,
      "loss": 0.0003,
      "step": 12760
    },
    {
      "epoch": 0.20205202907041184,
      "grad_norm": 0.3011806309223175,
      "learning_rate": 7.979479709295883e-06,
      "loss": 0.0447,
      "step": 12761
    },
    {
      "epoch": 0.2020678626280539,
      "grad_norm": 0.11591491848230362,
      "learning_rate": 7.979321373719462e-06,
      "loss": 0.0092,
      "step": 12762
    },
    {
      "epoch": 0.20208369618569597,
      "grad_norm": 0.5076839327812195,
      "learning_rate": 7.97916303814304e-06,
      "loss": 0.2063,
      "step": 12763
    },
    {
      "epoch": 0.20209952974333803,
      "grad_norm": 0.04060182347893715,
      "learning_rate": 7.97900470256662e-06,
      "loss": 0.0029,
      "step": 12764
    },
    {
      "epoch": 0.2021153633009801,
      "grad_norm": 0.8304015398025513,
      "learning_rate": 7.978846366990199e-06,
      "loss": 0.8473,
      "step": 12765
    },
    {
      "epoch": 0.20213119685862216,
      "grad_norm": 0.14919082820415497,
      "learning_rate": 7.97868803141378e-06,
      "loss": 0.0037,
      "step": 12766
    },
    {
      "epoch": 0.20214703041626422,
      "grad_norm": 0.3984306752681732,
      "learning_rate": 7.978529695837359e-06,
      "loss": 0.0655,
      "step": 12767
    },
    {
      "epoch": 0.2021628639739063,
      "grad_norm": 0.13166821002960205,
      "learning_rate": 7.978371360260938e-06,
      "loss": 0.0265,
      "step": 12768
    },
    {
      "epoch": 0.20217869753154835,
      "grad_norm": 0.01810109242796898,
      "learning_rate": 7.978213024684517e-06,
      "loss": 0.0005,
      "step": 12769
    },
    {
      "epoch": 0.20219453108919044,
      "grad_norm": 0.15789461135864258,
      "learning_rate": 7.978054689108096e-06,
      "loss": 0.0447,
      "step": 12770
    },
    {
      "epoch": 0.2022103646468325,
      "grad_norm": 0.23175711929798126,
      "learning_rate": 7.977896353531675e-06,
      "loss": 0.0986,
      "step": 12771
    },
    {
      "epoch": 0.20222619820447457,
      "grad_norm": 0.07434945553541183,
      "learning_rate": 7.977738017955256e-06,
      "loss": 0.0072,
      "step": 12772
    },
    {
      "epoch": 0.20224203176211664,
      "grad_norm": 0.48934659361839294,
      "learning_rate": 7.977579682378835e-06,
      "loss": 0.144,
      "step": 12773
    },
    {
      "epoch": 0.2022578653197587,
      "grad_norm": 0.1788618117570877,
      "learning_rate": 7.977421346802414e-06,
      "loss": 0.0774,
      "step": 12774
    },
    {
      "epoch": 0.20227369887740076,
      "grad_norm": 0.002889848779886961,
      "learning_rate": 7.977263011225993e-06,
      "loss": 0.0001,
      "step": 12775
    },
    {
      "epoch": 0.20228953243504283,
      "grad_norm": 0.008715909905731678,
      "learning_rate": 7.977104675649572e-06,
      "loss": 0.0004,
      "step": 12776
    },
    {
      "epoch": 0.2023053659926849,
      "grad_norm": 0.5005403757095337,
      "learning_rate": 7.976946340073151e-06,
      "loss": 0.1308,
      "step": 12777
    },
    {
      "epoch": 0.20232119955032696,
      "grad_norm": 0.4467519521713257,
      "learning_rate": 7.97678800449673e-06,
      "loss": 0.5546,
      "step": 12778
    },
    {
      "epoch": 0.20233703310796902,
      "grad_norm": 0.654736340045929,
      "learning_rate": 7.976629668920311e-06,
      "loss": 0.4299,
      "step": 12779
    },
    {
      "epoch": 0.2023528666656111,
      "grad_norm": 0.49256831407546997,
      "learning_rate": 7.976471333343888e-06,
      "loss": 0.0898,
      "step": 12780
    },
    {
      "epoch": 0.20236870022325315,
      "grad_norm": 0.7510285973548889,
      "learning_rate": 7.97631299776747e-06,
      "loss": 0.0278,
      "step": 12781
    },
    {
      "epoch": 0.20238453378089524,
      "grad_norm": 0.0010141533566638827,
      "learning_rate": 7.976154662191048e-06,
      "loss": 0.0,
      "step": 12782
    },
    {
      "epoch": 0.2024003673385373,
      "grad_norm": 0.02410888485610485,
      "learning_rate": 7.975996326614627e-06,
      "loss": 0.0029,
      "step": 12783
    },
    {
      "epoch": 0.20241620089617937,
      "grad_norm": 0.5811492800712585,
      "learning_rate": 7.975837991038206e-06,
      "loss": 0.1689,
      "step": 12784
    },
    {
      "epoch": 0.20243203445382144,
      "grad_norm": 0.00022627311409451067,
      "learning_rate": 7.975679655461787e-06,
      "loss": 0.0,
      "step": 12785
    },
    {
      "epoch": 0.2024478680114635,
      "grad_norm": 0.4999588429927826,
      "learning_rate": 7.975521319885365e-06,
      "loss": 0.1085,
      "step": 12786
    },
    {
      "epoch": 0.20246370156910556,
      "grad_norm": 0.3287811577320099,
      "learning_rate": 7.975362984308945e-06,
      "loss": 0.0976,
      "step": 12787
    },
    {
      "epoch": 0.20247953512674763,
      "grad_norm": 0.537950336933136,
      "learning_rate": 7.975204648732524e-06,
      "loss": 0.0947,
      "step": 12788
    },
    {
      "epoch": 0.2024953686843897,
      "grad_norm": 0.4828972816467285,
      "learning_rate": 7.975046313156104e-06,
      "loss": 0.5021,
      "step": 12789
    },
    {
      "epoch": 0.20251120224203176,
      "grad_norm": 0.36219021677970886,
      "learning_rate": 7.974887977579683e-06,
      "loss": 0.0911,
      "step": 12790
    },
    {
      "epoch": 0.20252703579967382,
      "grad_norm": 0.6358479857444763,
      "learning_rate": 7.974729642003263e-06,
      "loss": 0.4599,
      "step": 12791
    },
    {
      "epoch": 0.20254286935731589,
      "grad_norm": 0.04086676239967346,
      "learning_rate": 7.97457130642684e-06,
      "loss": 0.0028,
      "step": 12792
    },
    {
      "epoch": 0.20255870291495795,
      "grad_norm": 0.03714010491967201,
      "learning_rate": 7.974412970850422e-06,
      "loss": 0.0003,
      "step": 12793
    },
    {
      "epoch": 0.20257453647260004,
      "grad_norm": 0.3402305245399475,
      "learning_rate": 7.974254635274e-06,
      "loss": 0.0921,
      "step": 12794
    },
    {
      "epoch": 0.2025903700302421,
      "grad_norm": 0.03335178270936012,
      "learning_rate": 7.97409629969758e-06,
      "loss": 0.0024,
      "step": 12795
    },
    {
      "epoch": 0.20260620358788417,
      "grad_norm": 0.05645081400871277,
      "learning_rate": 7.973937964121159e-06,
      "loss": 0.0016,
      "step": 12796
    },
    {
      "epoch": 0.20262203714552623,
      "grad_norm": 3.7356170651037246e-05,
      "learning_rate": 7.97377962854474e-06,
      "loss": 0.0,
      "step": 12797
    },
    {
      "epoch": 0.2026378707031683,
      "grad_norm": 0.31589680910110474,
      "learning_rate": 7.973621292968317e-06,
      "loss": 0.102,
      "step": 12798
    },
    {
      "epoch": 0.20265370426081036,
      "grad_norm": 0.3636447787284851,
      "learning_rate": 7.973462957391898e-06,
      "loss": 0.2276,
      "step": 12799
    },
    {
      "epoch": 0.20266953781845243,
      "grad_norm": 0.009827272035181522,
      "learning_rate": 7.973304621815477e-06,
      "loss": 0.0006,
      "step": 12800
    },
    {
      "epoch": 0.2026853713760945,
      "grad_norm": 0.1437106728553772,
      "learning_rate": 7.973146286239056e-06,
      "loss": 0.0454,
      "step": 12801
    },
    {
      "epoch": 0.20270120493373656,
      "grad_norm": 0.47658461332321167,
      "learning_rate": 7.972987950662635e-06,
      "loss": 0.4819,
      "step": 12802
    },
    {
      "epoch": 0.20271703849137862,
      "grad_norm": 4.216042725602165e-05,
      "learning_rate": 7.972829615086214e-06,
      "loss": 0.0,
      "step": 12803
    },
    {
      "epoch": 0.20273287204902068,
      "grad_norm": 0.37474867701530457,
      "learning_rate": 7.972671279509793e-06,
      "loss": 0.2158,
      "step": 12804
    },
    {
      "epoch": 0.20274870560666275,
      "grad_norm": 3.4159109592437744,
      "learning_rate": 7.972512943933372e-06,
      "loss": 0.3739,
      "step": 12805
    },
    {
      "epoch": 0.20276453916430484,
      "grad_norm": 9.881186269922182e-05,
      "learning_rate": 7.972354608356953e-06,
      "loss": 0.0,
      "step": 12806
    },
    {
      "epoch": 0.2027803727219469,
      "grad_norm": 0.008384933695197105,
      "learning_rate": 7.972196272780532e-06,
      "loss": 0.0004,
      "step": 12807
    },
    {
      "epoch": 0.20279620627958897,
      "grad_norm": 0.45014822483062744,
      "learning_rate": 7.972037937204111e-06,
      "loss": 0.1686,
      "step": 12808
    },
    {
      "epoch": 0.20281203983723103,
      "grad_norm": 0.1686975061893463,
      "learning_rate": 7.97187960162769e-06,
      "loss": 0.0542,
      "step": 12809
    },
    {
      "epoch": 0.2028278733948731,
      "grad_norm": 0.0247699823230505,
      "learning_rate": 7.97172126605127e-06,
      "loss": 0.0015,
      "step": 12810
    },
    {
      "epoch": 0.20284370695251516,
      "grad_norm": 0.7224759459495544,
      "learning_rate": 7.971562930474848e-06,
      "loss": 0.549,
      "step": 12811
    },
    {
      "epoch": 0.20285954051015723,
      "grad_norm": 0.028114888817071915,
      "learning_rate": 7.97140459489843e-06,
      "loss": 0.0007,
      "step": 12812
    },
    {
      "epoch": 0.2028753740677993,
      "grad_norm": 0.2533835768699646,
      "learning_rate": 7.971246259322008e-06,
      "loss": 0.0572,
      "step": 12813
    },
    {
      "epoch": 0.20289120762544136,
      "grad_norm": 0.00022103889205027372,
      "learning_rate": 7.971087923745587e-06,
      "loss": 0.0,
      "step": 12814
    },
    {
      "epoch": 0.20290704118308342,
      "grad_norm": 0.5592756867408752,
      "learning_rate": 7.970929588169166e-06,
      "loss": 0.3182,
      "step": 12815
    },
    {
      "epoch": 0.20292287474072548,
      "grad_norm": 0.3284436762332916,
      "learning_rate": 7.970771252592745e-06,
      "loss": 0.0958,
      "step": 12816
    },
    {
      "epoch": 0.20293870829836755,
      "grad_norm": 0.017511898651719093,
      "learning_rate": 7.970612917016325e-06,
      "loss": 0.0009,
      "step": 12817
    },
    {
      "epoch": 0.20295454185600964,
      "grad_norm": 0.29666221141815186,
      "learning_rate": 7.970454581439905e-06,
      "loss": 0.0278,
      "step": 12818
    },
    {
      "epoch": 0.2029703754136517,
      "grad_norm": 0.24172429740428925,
      "learning_rate": 7.970296245863484e-06,
      "loss": 0.0655,
      "step": 12819
    },
    {
      "epoch": 0.20298620897129377,
      "grad_norm": 0.8287225961685181,
      "learning_rate": 7.970137910287064e-06,
      "loss": 0.2003,
      "step": 12820
    },
    {
      "epoch": 0.20300204252893583,
      "grad_norm": 0.0678696408867836,
      "learning_rate": 7.969979574710643e-06,
      "loss": 0.001,
      "step": 12821
    },
    {
      "epoch": 0.2030178760865779,
      "grad_norm": 0.12477821111679077,
      "learning_rate": 7.969821239134222e-06,
      "loss": 0.0083,
      "step": 12822
    },
    {
      "epoch": 0.20303370964421996,
      "grad_norm": 0.04523603618144989,
      "learning_rate": 7.9696629035578e-06,
      "loss": 0.003,
      "step": 12823
    },
    {
      "epoch": 0.20304954320186203,
      "grad_norm": 0.3756626546382904,
      "learning_rate": 7.96950456798138e-06,
      "loss": 0.3034,
      "step": 12824
    },
    {
      "epoch": 0.2030653767595041,
      "grad_norm": 0.3077961504459381,
      "learning_rate": 7.969346232404959e-06,
      "loss": 0.0858,
      "step": 12825
    },
    {
      "epoch": 0.20308121031714615,
      "grad_norm": 0.20297779142856598,
      "learning_rate": 7.969187896828538e-06,
      "loss": 0.0688,
      "step": 12826
    },
    {
      "epoch": 0.20309704387478822,
      "grad_norm": 0.6107305884361267,
      "learning_rate": 7.969029561252119e-06,
      "loss": 0.6299,
      "step": 12827
    },
    {
      "epoch": 0.20311287743243028,
      "grad_norm": 0.0008981098653748631,
      "learning_rate": 7.968871225675698e-06,
      "loss": 0.0,
      "step": 12828
    },
    {
      "epoch": 0.20312871099007235,
      "grad_norm": 0.27174824476242065,
      "learning_rate": 7.968712890099277e-06,
      "loss": 0.0683,
      "step": 12829
    },
    {
      "epoch": 0.20314454454771444,
      "grad_norm": 0.20654480159282684,
      "learning_rate": 7.968554554522856e-06,
      "loss": 0.0616,
      "step": 12830
    },
    {
      "epoch": 0.2031603781053565,
      "grad_norm": 0.33107882738113403,
      "learning_rate": 7.968396218946435e-06,
      "loss": 0.0604,
      "step": 12831
    },
    {
      "epoch": 0.20317621166299857,
      "grad_norm": 0.27064085006713867,
      "learning_rate": 7.968237883370014e-06,
      "loss": 0.0216,
      "step": 12832
    },
    {
      "epoch": 0.20319204522064063,
      "grad_norm": 0.003974649589508772,
      "learning_rate": 7.968079547793595e-06,
      "loss": 0.0002,
      "step": 12833
    },
    {
      "epoch": 0.2032078787782827,
      "grad_norm": 0.5851515531539917,
      "learning_rate": 7.967921212217174e-06,
      "loss": 0.1959,
      "step": 12834
    },
    {
      "epoch": 0.20322371233592476,
      "grad_norm": 0.0004056371981278062,
      "learning_rate": 7.967762876640753e-06,
      "loss": 0.0,
      "step": 12835
    },
    {
      "epoch": 0.20323954589356683,
      "grad_norm": 0.009850232861936092,
      "learning_rate": 7.967604541064332e-06,
      "loss": 0.0003,
      "step": 12836
    },
    {
      "epoch": 0.2032553794512089,
      "grad_norm": 0.04297090321779251,
      "learning_rate": 7.967446205487911e-06,
      "loss": 0.0025,
      "step": 12837
    },
    {
      "epoch": 0.20327121300885095,
      "grad_norm": 0.45721644163131714,
      "learning_rate": 7.96728786991149e-06,
      "loss": 0.1824,
      "step": 12838
    },
    {
      "epoch": 0.20328704656649302,
      "grad_norm": 0.008272246457636356,
      "learning_rate": 7.967129534335071e-06,
      "loss": 0.0004,
      "step": 12839
    },
    {
      "epoch": 0.20330288012413508,
      "grad_norm": 0.019394874572753906,
      "learning_rate": 7.96697119875865e-06,
      "loss": 0.0009,
      "step": 12840
    },
    {
      "epoch": 0.20331871368177715,
      "grad_norm": 0.14855828881263733,
      "learning_rate": 7.96681286318223e-06,
      "loss": 0.0376,
      "step": 12841
    },
    {
      "epoch": 0.20333454723941924,
      "grad_norm": 0.5150550603866577,
      "learning_rate": 7.966654527605808e-06,
      "loss": 0.2511,
      "step": 12842
    },
    {
      "epoch": 0.2033503807970613,
      "grad_norm": 0.36404818296432495,
      "learning_rate": 7.966496192029387e-06,
      "loss": 0.1242,
      "step": 12843
    },
    {
      "epoch": 0.20336621435470337,
      "grad_norm": 0.008348125964403152,
      "learning_rate": 7.966337856452967e-06,
      "loss": 0.0004,
      "step": 12844
    },
    {
      "epoch": 0.20338204791234543,
      "grad_norm": 0.15918731689453125,
      "learning_rate": 7.966179520876547e-06,
      "loss": 0.0312,
      "step": 12845
    },
    {
      "epoch": 0.2033978814699875,
      "grad_norm": 0.7514798641204834,
      "learning_rate": 7.966021185300126e-06,
      "loss": 0.3049,
      "step": 12846
    },
    {
      "epoch": 0.20341371502762956,
      "grad_norm": 0.022213496267795563,
      "learning_rate": 7.965862849723705e-06,
      "loss": 0.0003,
      "step": 12847
    },
    {
      "epoch": 0.20342954858527162,
      "grad_norm": 0.4432819187641144,
      "learning_rate": 7.965704514147285e-06,
      "loss": 0.1678,
      "step": 12848
    },
    {
      "epoch": 0.2034453821429137,
      "grad_norm": 0.7136600017547607,
      "learning_rate": 7.965546178570864e-06,
      "loss": 0.4485,
      "step": 12849
    },
    {
      "epoch": 0.20346121570055575,
      "grad_norm": 0.5399697422981262,
      "learning_rate": 7.965387842994443e-06,
      "loss": 0.2294,
      "step": 12850
    },
    {
      "epoch": 0.20347704925819782,
      "grad_norm": 0.5527299046516418,
      "learning_rate": 7.965229507418022e-06,
      "loss": 0.1144,
      "step": 12851
    },
    {
      "epoch": 0.20349288281583988,
      "grad_norm": 0.010216631926596165,
      "learning_rate": 7.965071171841603e-06,
      "loss": 0.0005,
      "step": 12852
    },
    {
      "epoch": 0.20350871637348195,
      "grad_norm": 0.7822331786155701,
      "learning_rate": 7.96491283626518e-06,
      "loss": 0.4191,
      "step": 12853
    },
    {
      "epoch": 0.20352454993112404,
      "grad_norm": 0.2926887273788452,
      "learning_rate": 7.96475450068876e-06,
      "loss": 0.1323,
      "step": 12854
    },
    {
      "epoch": 0.2035403834887661,
      "grad_norm": 0.15537762641906738,
      "learning_rate": 7.96459616511234e-06,
      "loss": 0.0662,
      "step": 12855
    },
    {
      "epoch": 0.20355621704640817,
      "grad_norm": 0.17238718271255493,
      "learning_rate": 7.964437829535919e-06,
      "loss": 0.0564,
      "step": 12856
    },
    {
      "epoch": 0.20357205060405023,
      "grad_norm": 0.4246349334716797,
      "learning_rate": 7.964279493959498e-06,
      "loss": 0.2012,
      "step": 12857
    },
    {
      "epoch": 0.2035878841616923,
      "grad_norm": 0.569878101348877,
      "learning_rate": 7.964121158383079e-06,
      "loss": 0.1472,
      "step": 12858
    },
    {
      "epoch": 0.20360371771933436,
      "grad_norm": 0.6963116526603699,
      "learning_rate": 7.963962822806656e-06,
      "loss": 0.5422,
      "step": 12859
    },
    {
      "epoch": 0.20361955127697642,
      "grad_norm": 0.01323053427040577,
      "learning_rate": 7.963804487230237e-06,
      "loss": 0.0006,
      "step": 12860
    },
    {
      "epoch": 0.2036353848346185,
      "grad_norm": 0.19566456973552704,
      "learning_rate": 7.963646151653816e-06,
      "loss": 0.0264,
      "step": 12861
    },
    {
      "epoch": 0.20365121839226055,
      "grad_norm": 0.43091103434562683,
      "learning_rate": 7.963487816077395e-06,
      "loss": 0.0593,
      "step": 12862
    },
    {
      "epoch": 0.20366705194990262,
      "grad_norm": 0.3712235987186432,
      "learning_rate": 7.963329480500974e-06,
      "loss": 0.1093,
      "step": 12863
    },
    {
      "epoch": 0.20368288550754468,
      "grad_norm": 0.4519975781440735,
      "learning_rate": 7.963171144924555e-06,
      "loss": 0.0805,
      "step": 12864
    },
    {
      "epoch": 0.20369871906518675,
      "grad_norm": 0.46565747261047363,
      "learning_rate": 7.963012809348132e-06,
      "loss": 0.5127,
      "step": 12865
    },
    {
      "epoch": 0.20371455262282884,
      "grad_norm": 0.19893436133861542,
      "learning_rate": 7.962854473771713e-06,
      "loss": 0.0754,
      "step": 12866
    },
    {
      "epoch": 0.2037303861804709,
      "grad_norm": 0.6579470038414001,
      "learning_rate": 7.962696138195292e-06,
      "loss": 0.4461,
      "step": 12867
    },
    {
      "epoch": 0.20374621973811297,
      "grad_norm": 0.011461718939244747,
      "learning_rate": 7.962537802618871e-06,
      "loss": 0.0006,
      "step": 12868
    },
    {
      "epoch": 0.20376205329575503,
      "grad_norm": 0.040980029851198196,
      "learning_rate": 7.96237946704245e-06,
      "loss": 0.0021,
      "step": 12869
    },
    {
      "epoch": 0.2037778868533971,
      "grad_norm": 0.012550126761198044,
      "learning_rate": 7.962221131466031e-06,
      "loss": 0.0007,
      "step": 12870
    },
    {
      "epoch": 0.20379372041103916,
      "grad_norm": 0.615951657295227,
      "learning_rate": 7.962062795889608e-06,
      "loss": 0.119,
      "step": 12871
    },
    {
      "epoch": 0.20380955396868122,
      "grad_norm": 0.014302123337984085,
      "learning_rate": 7.961904460313188e-06,
      "loss": 0.0006,
      "step": 12872
    },
    {
      "epoch": 0.2038253875263233,
      "grad_norm": 0.18638458847999573,
      "learning_rate": 7.961746124736768e-06,
      "loss": 0.0664,
      "step": 12873
    },
    {
      "epoch": 0.20384122108396535,
      "grad_norm": 0.11977088451385498,
      "learning_rate": 7.961587789160347e-06,
      "loss": 0.0444,
      "step": 12874
    },
    {
      "epoch": 0.20385705464160742,
      "grad_norm": 0.8552792072296143,
      "learning_rate": 7.961429453583926e-06,
      "loss": 0.2998,
      "step": 12875
    },
    {
      "epoch": 0.20387288819924948,
      "grad_norm": 0.29058554768562317,
      "learning_rate": 7.961271118007506e-06,
      "loss": 0.109,
      "step": 12876
    },
    {
      "epoch": 0.20388872175689154,
      "grad_norm": 0.0001418430620105937,
      "learning_rate": 7.961112782431085e-06,
      "loss": 0.0,
      "step": 12877
    },
    {
      "epoch": 0.2039045553145336,
      "grad_norm": 0.016861649230122566,
      "learning_rate": 7.960954446854664e-06,
      "loss": 0.0008,
      "step": 12878
    },
    {
      "epoch": 0.2039203888721757,
      "grad_norm": 0.5188313126564026,
      "learning_rate": 7.960796111278244e-06,
      "loss": 0.1093,
      "step": 12879
    },
    {
      "epoch": 0.20393622242981777,
      "grad_norm": 0.2997772991657257,
      "learning_rate": 7.960637775701824e-06,
      "loss": 0.0345,
      "step": 12880
    },
    {
      "epoch": 0.20395205598745983,
      "grad_norm": 0.3499894142150879,
      "learning_rate": 7.960479440125403e-06,
      "loss": 0.0886,
      "step": 12881
    },
    {
      "epoch": 0.2039678895451019,
      "grad_norm": 0.32338839769363403,
      "learning_rate": 7.960321104548982e-06,
      "loss": 0.0873,
      "step": 12882
    },
    {
      "epoch": 0.20398372310274396,
      "grad_norm": 0.1353926807641983,
      "learning_rate": 7.96016276897256e-06,
      "loss": 0.0302,
      "step": 12883
    },
    {
      "epoch": 0.20399955666038602,
      "grad_norm": 0.2977052927017212,
      "learning_rate": 7.96000443339614e-06,
      "loss": 0.1055,
      "step": 12884
    },
    {
      "epoch": 0.2040153902180281,
      "grad_norm": 0.5408008694648743,
      "learning_rate": 7.95984609781972e-06,
      "loss": 0.1531,
      "step": 12885
    },
    {
      "epoch": 0.20403122377567015,
      "grad_norm": 0.3515123426914215,
      "learning_rate": 7.9596877622433e-06,
      "loss": 0.0995,
      "step": 12886
    },
    {
      "epoch": 0.20404705733331222,
      "grad_norm": 0.6313526630401611,
      "learning_rate": 7.959529426666879e-06,
      "loss": 0.1974,
      "step": 12887
    },
    {
      "epoch": 0.20406289089095428,
      "grad_norm": 0.00944775715470314,
      "learning_rate": 7.959371091090458e-06,
      "loss": 0.0004,
      "step": 12888
    },
    {
      "epoch": 0.20407872444859634,
      "grad_norm": 0.004573649261146784,
      "learning_rate": 7.959212755514037e-06,
      "loss": 0.0002,
      "step": 12889
    },
    {
      "epoch": 0.2040945580062384,
      "grad_norm": 0.005488248076289892,
      "learning_rate": 7.959054419937616e-06,
      "loss": 0.0003,
      "step": 12890
    },
    {
      "epoch": 0.2041103915638805,
      "grad_norm": 0.19817765057086945,
      "learning_rate": 7.958896084361197e-06,
      "loss": 0.0835,
      "step": 12891
    },
    {
      "epoch": 0.20412622512152256,
      "grad_norm": 0.19512352347373962,
      "learning_rate": 7.958737748784774e-06,
      "loss": 0.0603,
      "step": 12892
    },
    {
      "epoch": 0.20414205867916463,
      "grad_norm": 0.35406145453453064,
      "learning_rate": 7.958579413208355e-06,
      "loss": 0.2648,
      "step": 12893
    },
    {
      "epoch": 0.2041578922368067,
      "grad_norm": 0.0048010521568357944,
      "learning_rate": 7.958421077631934e-06,
      "loss": 0.0002,
      "step": 12894
    },
    {
      "epoch": 0.20417372579444876,
      "grad_norm": 0.2897499203681946,
      "learning_rate": 7.958262742055513e-06,
      "loss": 0.1533,
      "step": 12895
    },
    {
      "epoch": 0.20418955935209082,
      "grad_norm": 0.0037211058661341667,
      "learning_rate": 7.958104406479092e-06,
      "loss": 0.0002,
      "step": 12896
    },
    {
      "epoch": 0.20420539290973289,
      "grad_norm": 0.4246903359889984,
      "learning_rate": 7.957946070902671e-06,
      "loss": 0.1342,
      "step": 12897
    },
    {
      "epoch": 0.20422122646737495,
      "grad_norm": 0.14839234948158264,
      "learning_rate": 7.95778773532625e-06,
      "loss": 0.0781,
      "step": 12898
    },
    {
      "epoch": 0.20423706002501701,
      "grad_norm": 0.033262699842453,
      "learning_rate": 7.95762939974983e-06,
      "loss": 0.0022,
      "step": 12899
    },
    {
      "epoch": 0.20425289358265908,
      "grad_norm": 0.5847856402397156,
      "learning_rate": 7.95747106417341e-06,
      "loss": 0.1097,
      "step": 12900
    },
    {
      "epoch": 0.20426872714030114,
      "grad_norm": 0.7020523548126221,
      "learning_rate": 7.95731272859699e-06,
      "loss": 0.3936,
      "step": 12901
    },
    {
      "epoch": 0.2042845606979432,
      "grad_norm": 0.20736034214496613,
      "learning_rate": 7.957154393020568e-06,
      "loss": 0.0462,
      "step": 12902
    },
    {
      "epoch": 0.2043003942555853,
      "grad_norm": 0.021513406187295914,
      "learning_rate": 7.956996057444147e-06,
      "loss": 0.0013,
      "step": 12903
    },
    {
      "epoch": 0.20431622781322736,
      "grad_norm": 0.022311626002192497,
      "learning_rate": 7.956837721867727e-06,
      "loss": 0.0008,
      "step": 12904
    },
    {
      "epoch": 0.20433206137086943,
      "grad_norm": 0.009249663911759853,
      "learning_rate": 7.956679386291306e-06,
      "loss": 0.0006,
      "step": 12905
    },
    {
      "epoch": 0.2043478949285115,
      "grad_norm": 0.005626187659800053,
      "learning_rate": 7.956521050714886e-06,
      "loss": 0.0003,
      "step": 12906
    },
    {
      "epoch": 0.20436372848615356,
      "grad_norm": 0.666008472442627,
      "learning_rate": 7.956362715138465e-06,
      "loss": 0.3392,
      "step": 12907
    },
    {
      "epoch": 0.20437956204379562,
      "grad_norm": 0.47774115204811096,
      "learning_rate": 7.956204379562045e-06,
      "loss": 0.0702,
      "step": 12908
    },
    {
      "epoch": 0.20439539560143768,
      "grad_norm": 0.0017001411179080606,
      "learning_rate": 7.956046043985624e-06,
      "loss": 0.0,
      "step": 12909
    },
    {
      "epoch": 0.20441122915907975,
      "grad_norm": 0.4094228744506836,
      "learning_rate": 7.955887708409203e-06,
      "loss": 0.0928,
      "step": 12910
    },
    {
      "epoch": 0.2044270627167218,
      "grad_norm": 0.37903326749801636,
      "learning_rate": 7.955729372832782e-06,
      "loss": 0.0779,
      "step": 12911
    },
    {
      "epoch": 0.20444289627436388,
      "grad_norm": 0.36538565158843994,
      "learning_rate": 7.955571037256363e-06,
      "loss": 0.2212,
      "step": 12912
    },
    {
      "epoch": 0.20445872983200594,
      "grad_norm": 0.3535130023956299,
      "learning_rate": 7.955412701679942e-06,
      "loss": 0.0889,
      "step": 12913
    },
    {
      "epoch": 0.204474563389648,
      "grad_norm": 1.2546764612197876,
      "learning_rate": 7.95525436610352e-06,
      "loss": 0.049,
      "step": 12914
    },
    {
      "epoch": 0.2044903969472901,
      "grad_norm": 0.040375519543886185,
      "learning_rate": 7.9550960305271e-06,
      "loss": 0.0011,
      "step": 12915
    },
    {
      "epoch": 0.20450623050493216,
      "grad_norm": 0.5170644521713257,
      "learning_rate": 7.954937694950679e-06,
      "loss": 0.317,
      "step": 12916
    },
    {
      "epoch": 0.20452206406257423,
      "grad_norm": 0.003710421035066247,
      "learning_rate": 7.954779359374258e-06,
      "loss": 0.0001,
      "step": 12917
    },
    {
      "epoch": 0.2045378976202163,
      "grad_norm": 0.6521888971328735,
      "learning_rate": 7.954621023797839e-06,
      "loss": 0.6003,
      "step": 12918
    },
    {
      "epoch": 0.20455373117785836,
      "grad_norm": 0.007440460845828056,
      "learning_rate": 7.954462688221418e-06,
      "loss": 0.0002,
      "step": 12919
    },
    {
      "epoch": 0.20456956473550042,
      "grad_norm": 0.8779882788658142,
      "learning_rate": 7.954304352644997e-06,
      "loss": 0.1948,
      "step": 12920
    },
    {
      "epoch": 0.20458539829314248,
      "grad_norm": 0.27735430002212524,
      "learning_rate": 7.954146017068576e-06,
      "loss": 0.0658,
      "step": 12921
    },
    {
      "epoch": 0.20460123185078455,
      "grad_norm": 0.27323752641677856,
      "learning_rate": 7.953987681492155e-06,
      "loss": 0.0965,
      "step": 12922
    },
    {
      "epoch": 0.2046170654084266,
      "grad_norm": 0.006978104822337627,
      "learning_rate": 7.953829345915734e-06,
      "loss": 0.0003,
      "step": 12923
    },
    {
      "epoch": 0.20463289896606868,
      "grad_norm": 0.025736123323440552,
      "learning_rate": 7.953671010339313e-06,
      "loss": 0.0018,
      "step": 12924
    },
    {
      "epoch": 0.20464873252371074,
      "grad_norm": 0.004599729552865028,
      "learning_rate": 7.953512674762894e-06,
      "loss": 0.0003,
      "step": 12925
    },
    {
      "epoch": 0.2046645660813528,
      "grad_norm": 0.3094809949398041,
      "learning_rate": 7.953354339186471e-06,
      "loss": 0.4145,
      "step": 12926
    },
    {
      "epoch": 0.2046803996389949,
      "grad_norm": 0.34853556752204895,
      "learning_rate": 7.953196003610052e-06,
      "loss": 0.0155,
      "step": 12927
    },
    {
      "epoch": 0.20469623319663696,
      "grad_norm": 0.3349539637565613,
      "learning_rate": 7.953037668033631e-06,
      "loss": 0.1159,
      "step": 12928
    },
    {
      "epoch": 0.20471206675427903,
      "grad_norm": 0.0009981655748561025,
      "learning_rate": 7.95287933245721e-06,
      "loss": 0.0,
      "step": 12929
    },
    {
      "epoch": 0.2047279003119211,
      "grad_norm": 0.5213305354118347,
      "learning_rate": 7.95272099688079e-06,
      "loss": 0.2795,
      "step": 12930
    },
    {
      "epoch": 0.20474373386956315,
      "grad_norm": 0.3458661437034607,
      "learning_rate": 7.95256266130437e-06,
      "loss": 0.0598,
      "step": 12931
    },
    {
      "epoch": 0.20475956742720522,
      "grad_norm": 0.00015261878434102982,
      "learning_rate": 7.952404325727948e-06,
      "loss": 0.0,
      "step": 12932
    },
    {
      "epoch": 0.20477540098484728,
      "grad_norm": 0.21064533293247223,
      "learning_rate": 7.952245990151528e-06,
      "loss": 0.0612,
      "step": 12933
    },
    {
      "epoch": 0.20479123454248935,
      "grad_norm": 0.240652397274971,
      "learning_rate": 7.952087654575107e-06,
      "loss": 0.0702,
      "step": 12934
    },
    {
      "epoch": 0.2048070681001314,
      "grad_norm": 0.5795149207115173,
      "learning_rate": 7.951929318998686e-06,
      "loss": 0.3161,
      "step": 12935
    },
    {
      "epoch": 0.20482290165777348,
      "grad_norm": 0.28946128487586975,
      "learning_rate": 7.951770983422266e-06,
      "loss": 0.0671,
      "step": 12936
    },
    {
      "epoch": 0.20483873521541554,
      "grad_norm": 0.3074556887149811,
      "learning_rate": 7.951612647845846e-06,
      "loss": 0.2026,
      "step": 12937
    },
    {
      "epoch": 0.2048545687730576,
      "grad_norm": 0.5982517600059509,
      "learning_rate": 7.951454312269424e-06,
      "loss": 0.4299,
      "step": 12938
    },
    {
      "epoch": 0.2048704023306997,
      "grad_norm": 0.3202696144580841,
      "learning_rate": 7.951295976693004e-06,
      "loss": 0.0752,
      "step": 12939
    },
    {
      "epoch": 0.20488623588834176,
      "grad_norm": 0.2614259421825409,
      "learning_rate": 7.951137641116584e-06,
      "loss": 0.0592,
      "step": 12940
    },
    {
      "epoch": 0.20490206944598383,
      "grad_norm": 0.016460277140140533,
      "learning_rate": 7.950979305540163e-06,
      "loss": 0.0007,
      "step": 12941
    },
    {
      "epoch": 0.2049179030036259,
      "grad_norm": 0.4640512764453888,
      "learning_rate": 7.950820969963742e-06,
      "loss": 0.1314,
      "step": 12942
    },
    {
      "epoch": 0.20493373656126795,
      "grad_norm": 0.19931668043136597,
      "learning_rate": 7.950662634387322e-06,
      "loss": 0.0787,
      "step": 12943
    },
    {
      "epoch": 0.20494957011891002,
      "grad_norm": 0.06993918120861053,
      "learning_rate": 7.9505042988109e-06,
      "loss": 0.0041,
      "step": 12944
    },
    {
      "epoch": 0.20496540367655208,
      "grad_norm": 0.5072252154350281,
      "learning_rate": 7.950345963234479e-06,
      "loss": 0.017,
      "step": 12945
    },
    {
      "epoch": 0.20498123723419415,
      "grad_norm": 0.47942185401916504,
      "learning_rate": 7.95018762765806e-06,
      "loss": 0.1307,
      "step": 12946
    },
    {
      "epoch": 0.2049970707918362,
      "grad_norm": 0.13144543766975403,
      "learning_rate": 7.950029292081639e-06,
      "loss": 0.0078,
      "step": 12947
    },
    {
      "epoch": 0.20501290434947828,
      "grad_norm": 0.26175546646118164,
      "learning_rate": 7.949870956505218e-06,
      "loss": 0.0198,
      "step": 12948
    },
    {
      "epoch": 0.20502873790712034,
      "grad_norm": 0.49886566400527954,
      "learning_rate": 7.949712620928797e-06,
      "loss": 0.518,
      "step": 12949
    },
    {
      "epoch": 0.2050445714647624,
      "grad_norm": 0.4086090922355652,
      "learning_rate": 7.949554285352376e-06,
      "loss": 0.2023,
      "step": 12950
    },
    {
      "epoch": 0.2050604050224045,
      "grad_norm": 0.2916725277900696,
      "learning_rate": 7.949395949775955e-06,
      "loss": 0.1042,
      "step": 12951
    },
    {
      "epoch": 0.20507623858004656,
      "grad_norm": 0.29614847898483276,
      "learning_rate": 7.949237614199536e-06,
      "loss": 0.0221,
      "step": 12952
    },
    {
      "epoch": 0.20509207213768862,
      "grad_norm": 0.7555058598518372,
      "learning_rate": 7.949079278623115e-06,
      "loss": 0.6922,
      "step": 12953
    },
    {
      "epoch": 0.2051079056953307,
      "grad_norm": 0.5146071910858154,
      "learning_rate": 7.948920943046694e-06,
      "loss": 0.0466,
      "step": 12954
    },
    {
      "epoch": 0.20512373925297275,
      "grad_norm": 0.4793089032173157,
      "learning_rate": 7.948762607470273e-06,
      "loss": 0.1307,
      "step": 12955
    },
    {
      "epoch": 0.20513957281061482,
      "grad_norm": 0.00585377449169755,
      "learning_rate": 7.948604271893852e-06,
      "loss": 0.0003,
      "step": 12956
    },
    {
      "epoch": 0.20515540636825688,
      "grad_norm": 0.6483546495437622,
      "learning_rate": 7.948445936317431e-06,
      "loss": 0.5657,
      "step": 12957
    },
    {
      "epoch": 0.20517123992589895,
      "grad_norm": 0.019833391532301903,
      "learning_rate": 7.948287600741012e-06,
      "loss": 0.001,
      "step": 12958
    },
    {
      "epoch": 0.205187073483541,
      "grad_norm": 0.26895907521247864,
      "learning_rate": 7.94812926516459e-06,
      "loss": 0.0495,
      "step": 12959
    },
    {
      "epoch": 0.20520290704118307,
      "grad_norm": 0.24919858574867249,
      "learning_rate": 7.94797092958817e-06,
      "loss": 0.029,
      "step": 12960
    },
    {
      "epoch": 0.20521874059882514,
      "grad_norm": 0.15894007682800293,
      "learning_rate": 7.94781259401175e-06,
      "loss": 0.0308,
      "step": 12961
    },
    {
      "epoch": 0.2052345741564672,
      "grad_norm": 8.46960028866306e-05,
      "learning_rate": 7.947654258435328e-06,
      "loss": 0.0,
      "step": 12962
    },
    {
      "epoch": 0.2052504077141093,
      "grad_norm": 0.41382160782814026,
      "learning_rate": 7.947495922858907e-06,
      "loss": 0.1429,
      "step": 12963
    },
    {
      "epoch": 0.20526624127175136,
      "grad_norm": 0.3297797441482544,
      "learning_rate": 7.947337587282488e-06,
      "loss": 0.7382,
      "step": 12964
    },
    {
      "epoch": 0.20528207482939342,
      "grad_norm": 0.17799492180347443,
      "learning_rate": 7.947179251706066e-06,
      "loss": 0.0704,
      "step": 12965
    },
    {
      "epoch": 0.2052979083870355,
      "grad_norm": 0.0062172748148441315,
      "learning_rate": 7.947020916129646e-06,
      "loss": 0.0003,
      "step": 12966
    },
    {
      "epoch": 0.20531374194467755,
      "grad_norm": 0.18818408250808716,
      "learning_rate": 7.946862580553225e-06,
      "loss": 0.0397,
      "step": 12967
    },
    {
      "epoch": 0.20532957550231962,
      "grad_norm": 0.4314960539340973,
      "learning_rate": 7.946704244976805e-06,
      "loss": 0.2213,
      "step": 12968
    },
    {
      "epoch": 0.20534540905996168,
      "grad_norm": 0.41050925850868225,
      "learning_rate": 7.946545909400384e-06,
      "loss": 0.2782,
      "step": 12969
    },
    {
      "epoch": 0.20536124261760375,
      "grad_norm": 0.23033307492733002,
      "learning_rate": 7.946387573823963e-06,
      "loss": 0.0938,
      "step": 12970
    },
    {
      "epoch": 0.2053770761752458,
      "grad_norm": 1.6763302087783813,
      "learning_rate": 7.946229238247542e-06,
      "loss": 0.1484,
      "step": 12971
    },
    {
      "epoch": 0.20539290973288787,
      "grad_norm": 0.4607762098312378,
      "learning_rate": 7.946070902671121e-06,
      "loss": 0.0349,
      "step": 12972
    },
    {
      "epoch": 0.20540874329052994,
      "grad_norm": 0.05464290454983711,
      "learning_rate": 7.945912567094702e-06,
      "loss": 0.001,
      "step": 12973
    },
    {
      "epoch": 0.205424576848172,
      "grad_norm": 0.040190812200307846,
      "learning_rate": 7.94575423151828e-06,
      "loss": 0.0024,
      "step": 12974
    },
    {
      "epoch": 0.2054404104058141,
      "grad_norm": 0.006849781144410372,
      "learning_rate": 7.94559589594186e-06,
      "loss": 0.0004,
      "step": 12975
    },
    {
      "epoch": 0.20545624396345616,
      "grad_norm": 0.8300155997276306,
      "learning_rate": 7.945437560365439e-06,
      "loss": 0.2324,
      "step": 12976
    },
    {
      "epoch": 0.20547207752109822,
      "grad_norm": 0.5195295214653015,
      "learning_rate": 7.945279224789018e-06,
      "loss": 0.0795,
      "step": 12977
    },
    {
      "epoch": 0.2054879110787403,
      "grad_norm": 0.6967531442642212,
      "learning_rate": 7.945120889212597e-06,
      "loss": 0.0429,
      "step": 12978
    },
    {
      "epoch": 0.20550374463638235,
      "grad_norm": 0.5420534610748291,
      "learning_rate": 7.944962553636178e-06,
      "loss": 0.1298,
      "step": 12979
    },
    {
      "epoch": 0.20551957819402442,
      "grad_norm": 0.00025640547391958535,
      "learning_rate": 7.944804218059757e-06,
      "loss": 0.0,
      "step": 12980
    },
    {
      "epoch": 0.20553541175166648,
      "grad_norm": 0.16323083639144897,
      "learning_rate": 7.944645882483336e-06,
      "loss": 0.0608,
      "step": 12981
    },
    {
      "epoch": 0.20555124530930854,
      "grad_norm": 0.04954700171947479,
      "learning_rate": 7.944487546906915e-06,
      "loss": 0.0028,
      "step": 12982
    },
    {
      "epoch": 0.2055670788669506,
      "grad_norm": 0.30054351687431335,
      "learning_rate": 7.944329211330494e-06,
      "loss": 0.1272,
      "step": 12983
    },
    {
      "epoch": 0.20558291242459267,
      "grad_norm": 0.4454781711101532,
      "learning_rate": 7.944170875754073e-06,
      "loss": 0.4829,
      "step": 12984
    },
    {
      "epoch": 0.20559874598223474,
      "grad_norm": 0.34562310576438904,
      "learning_rate": 7.944012540177654e-06,
      "loss": 0.0652,
      "step": 12985
    },
    {
      "epoch": 0.2056145795398768,
      "grad_norm": 0.7576773762702942,
      "learning_rate": 7.943854204601233e-06,
      "loss": 0.1002,
      "step": 12986
    },
    {
      "epoch": 0.2056304130975189,
      "grad_norm": 0.00019497211906127632,
      "learning_rate": 7.943695869024812e-06,
      "loss": 0.0,
      "step": 12987
    },
    {
      "epoch": 0.20564624665516096,
      "grad_norm": 0.007624340709298849,
      "learning_rate": 7.943537533448391e-06,
      "loss": 0.0004,
      "step": 12988
    },
    {
      "epoch": 0.20566208021280302,
      "grad_norm": 0.0004988234722986817,
      "learning_rate": 7.94337919787197e-06,
      "loss": 0.0,
      "step": 12989
    },
    {
      "epoch": 0.2056779137704451,
      "grad_norm": 0.0017219637520611286,
      "learning_rate": 7.94322086229555e-06,
      "loss": 0.0,
      "step": 12990
    },
    {
      "epoch": 0.20569374732808715,
      "grad_norm": 0.4700675308704376,
      "learning_rate": 7.94306252671913e-06,
      "loss": 0.3245,
      "step": 12991
    },
    {
      "epoch": 0.20570958088572922,
      "grad_norm": 0.6283164024353027,
      "learning_rate": 7.94290419114271e-06,
      "loss": 0.2055,
      "step": 12992
    },
    {
      "epoch": 0.20572541444337128,
      "grad_norm": 0.24084560573101044,
      "learning_rate": 7.942745855566287e-06,
      "loss": 0.0856,
      "step": 12993
    },
    {
      "epoch": 0.20574124800101334,
      "grad_norm": 0.5594106912612915,
      "learning_rate": 7.942587519989867e-06,
      "loss": 0.3365,
      "step": 12994
    },
    {
      "epoch": 0.2057570815586554,
      "grad_norm": 0.171815425157547,
      "learning_rate": 7.942429184413446e-06,
      "loss": 0.0377,
      "step": 12995
    },
    {
      "epoch": 0.20577291511629747,
      "grad_norm": 0.021604008972644806,
      "learning_rate": 7.942270848837026e-06,
      "loss": 0.0012,
      "step": 12996
    },
    {
      "epoch": 0.20578874867393954,
      "grad_norm": 0.5919803380966187,
      "learning_rate": 7.942112513260605e-06,
      "loss": 0.3263,
      "step": 12997
    },
    {
      "epoch": 0.2058045822315816,
      "grad_norm": 0.14496684074401855,
      "learning_rate": 7.941954177684185e-06,
      "loss": 0.0539,
      "step": 12998
    },
    {
      "epoch": 0.2058204157892237,
      "grad_norm": 0.00422686105594039,
      "learning_rate": 7.941795842107763e-06,
      "loss": 0.0002,
      "step": 12999
    },
    {
      "epoch": 0.20583624934686576,
      "grad_norm": 0.2416452318429947,
      "learning_rate": 7.941637506531344e-06,
      "loss": 0.0977,
      "step": 13000
    },
    {
      "epoch": 0.20585208290450782,
      "grad_norm": 0.3786604702472687,
      "learning_rate": 7.941479170954923e-06,
      "loss": 0.2266,
      "step": 13001
    },
    {
      "epoch": 0.20586791646214989,
      "grad_norm": 0.41104447841644287,
      "learning_rate": 7.941320835378502e-06,
      "loss": 0.2437,
      "step": 13002
    },
    {
      "epoch": 0.20588375001979195,
      "grad_norm": 0.20242977142333984,
      "learning_rate": 7.94116249980208e-06,
      "loss": 0.0592,
      "step": 13003
    },
    {
      "epoch": 0.20589958357743401,
      "grad_norm": 0.3693249523639679,
      "learning_rate": 7.941004164225662e-06,
      "loss": 0.1251,
      "step": 13004
    },
    {
      "epoch": 0.20591541713507608,
      "grad_norm": 0.16108383238315582,
      "learning_rate": 7.940845828649239e-06,
      "loss": 0.0455,
      "step": 13005
    },
    {
      "epoch": 0.20593125069271814,
      "grad_norm": 0.0065629505552351475,
      "learning_rate": 7.94068749307282e-06,
      "loss": 0.0003,
      "step": 13006
    },
    {
      "epoch": 0.2059470842503602,
      "grad_norm": 0.48234155774116516,
      "learning_rate": 7.940529157496399e-06,
      "loss": 0.1013,
      "step": 13007
    },
    {
      "epoch": 0.20596291780800227,
      "grad_norm": 0.32393455505371094,
      "learning_rate": 7.940370821919978e-06,
      "loss": 0.0714,
      "step": 13008
    },
    {
      "epoch": 0.20597875136564434,
      "grad_norm": 0.03760051354765892,
      "learning_rate": 7.940212486343557e-06,
      "loss": 0.0021,
      "step": 13009
    },
    {
      "epoch": 0.2059945849232864,
      "grad_norm": 0.0060675791464746,
      "learning_rate": 7.940054150767138e-06,
      "loss": 0.0003,
      "step": 13010
    },
    {
      "epoch": 0.2060104184809285,
      "grad_norm": 0.3772599995136261,
      "learning_rate": 7.939895815190715e-06,
      "loss": 0.4161,
      "step": 13011
    },
    {
      "epoch": 0.20602625203857056,
      "grad_norm": 0.6573364734649658,
      "learning_rate": 7.939737479614296e-06,
      "loss": 0.3918,
      "step": 13012
    },
    {
      "epoch": 0.20604208559621262,
      "grad_norm": 0.48595762252807617,
      "learning_rate": 7.939579144037875e-06,
      "loss": 0.1752,
      "step": 13013
    },
    {
      "epoch": 0.20605791915385469,
      "grad_norm": 0.3910196125507355,
      "learning_rate": 7.939420808461454e-06,
      "loss": 0.243,
      "step": 13014
    },
    {
      "epoch": 0.20607375271149675,
      "grad_norm": 0.22044403851032257,
      "learning_rate": 7.939262472885033e-06,
      "loss": 0.0495,
      "step": 13015
    },
    {
      "epoch": 0.2060895862691388,
      "grad_norm": 0.20022734999656677,
      "learning_rate": 7.939104137308612e-06,
      "loss": 0.0999,
      "step": 13016
    },
    {
      "epoch": 0.20610541982678088,
      "grad_norm": 0.00021724765247199684,
      "learning_rate": 7.938945801732191e-06,
      "loss": 0.0,
      "step": 13017
    },
    {
      "epoch": 0.20612125338442294,
      "grad_norm": 0.25879013538360596,
      "learning_rate": 7.93878746615577e-06,
      "loss": 0.0734,
      "step": 13018
    },
    {
      "epoch": 0.206137086942065,
      "grad_norm": 0.006232135929167271,
      "learning_rate": 7.938629130579351e-06,
      "loss": 0.0003,
      "step": 13019
    },
    {
      "epoch": 0.20615292049970707,
      "grad_norm": 0.01690235547721386,
      "learning_rate": 7.938470795002929e-06,
      "loss": 0.001,
      "step": 13020
    },
    {
      "epoch": 0.20616875405734914,
      "grad_norm": 0.5119046568870544,
      "learning_rate": 7.93831245942651e-06,
      "loss": 0.1091,
      "step": 13021
    },
    {
      "epoch": 0.2061845876149912,
      "grad_norm": 0.15448950231075287,
      "learning_rate": 7.938154123850088e-06,
      "loss": 0.0478,
      "step": 13022
    },
    {
      "epoch": 0.2062004211726333,
      "grad_norm": 0.465204119682312,
      "learning_rate": 7.937995788273667e-06,
      "loss": 0.0976,
      "step": 13023
    },
    {
      "epoch": 0.20621625473027536,
      "grad_norm": 0.27128365635871887,
      "learning_rate": 7.937837452697247e-06,
      "loss": 0.0551,
      "step": 13024
    },
    {
      "epoch": 0.20623208828791742,
      "grad_norm": 0.006698605604469776,
      "learning_rate": 7.937679117120827e-06,
      "loss": 0.0002,
      "step": 13025
    },
    {
      "epoch": 0.20624792184555948,
      "grad_norm": 0.2807871997356415,
      "learning_rate": 7.937520781544405e-06,
      "loss": 0.0763,
      "step": 13026
    },
    {
      "epoch": 0.20626375540320155,
      "grad_norm": 0.14434103667736053,
      "learning_rate": 7.937362445967985e-06,
      "loss": 0.0067,
      "step": 13027
    },
    {
      "epoch": 0.2062795889608436,
      "grad_norm": 0.43543535470962524,
      "learning_rate": 7.937204110391565e-06,
      "loss": 0.2045,
      "step": 13028
    },
    {
      "epoch": 0.20629542251848568,
      "grad_norm": 0.0034893411211669445,
      "learning_rate": 7.937045774815144e-06,
      "loss": 0.0002,
      "step": 13029
    },
    {
      "epoch": 0.20631125607612774,
      "grad_norm": 0.16097736358642578,
      "learning_rate": 7.936887439238723e-06,
      "loss": 0.0856,
      "step": 13030
    },
    {
      "epoch": 0.2063270896337698,
      "grad_norm": 0.39915257692337036,
      "learning_rate": 7.936729103662304e-06,
      "loss": 0.3717,
      "step": 13031
    },
    {
      "epoch": 0.20634292319141187,
      "grad_norm": 0.31158560514450073,
      "learning_rate": 7.936570768085881e-06,
      "loss": 0.0675,
      "step": 13032
    },
    {
      "epoch": 0.20635875674905393,
      "grad_norm": 0.16624735295772552,
      "learning_rate": 7.936412432509462e-06,
      "loss": 0.0327,
      "step": 13033
    },
    {
      "epoch": 0.206374590306696,
      "grad_norm": 0.0004593219782691449,
      "learning_rate": 7.93625409693304e-06,
      "loss": 0.0,
      "step": 13034
    },
    {
      "epoch": 0.2063904238643381,
      "grad_norm": 0.31630679965019226,
      "learning_rate": 7.93609576135662e-06,
      "loss": 0.0132,
      "step": 13035
    },
    {
      "epoch": 0.20640625742198015,
      "grad_norm": 0.018429262563586235,
      "learning_rate": 7.935937425780199e-06,
      "loss": 0.001,
      "step": 13036
    },
    {
      "epoch": 0.20642209097962222,
      "grad_norm": 0.00022024603094905615,
      "learning_rate": 7.93577909020378e-06,
      "loss": 0.0,
      "step": 13037
    },
    {
      "epoch": 0.20643792453726428,
      "grad_norm": 0.0003844840102829039,
      "learning_rate": 7.935620754627357e-06,
      "loss": 0.0,
      "step": 13038
    },
    {
      "epoch": 0.20645375809490635,
      "grad_norm": 0.23684260249137878,
      "learning_rate": 7.935462419050938e-06,
      "loss": 0.0869,
      "step": 13039
    },
    {
      "epoch": 0.2064695916525484,
      "grad_norm": 0.2614583373069763,
      "learning_rate": 7.935304083474517e-06,
      "loss": 0.023,
      "step": 13040
    },
    {
      "epoch": 0.20648542521019048,
      "grad_norm": 0.5588198304176331,
      "learning_rate": 7.935145747898096e-06,
      "loss": 0.4615,
      "step": 13041
    },
    {
      "epoch": 0.20650125876783254,
      "grad_norm": 0.661902904510498,
      "learning_rate": 7.934987412321675e-06,
      "loss": 0.1058,
      "step": 13042
    },
    {
      "epoch": 0.2065170923254746,
      "grad_norm": 0.3372167944908142,
      "learning_rate": 7.934829076745254e-06,
      "loss": 0.1679,
      "step": 13043
    },
    {
      "epoch": 0.20653292588311667,
      "grad_norm": 0.3497071862220764,
      "learning_rate": 7.934670741168833e-06,
      "loss": 0.1727,
      "step": 13044
    },
    {
      "epoch": 0.20654875944075873,
      "grad_norm": 0.5156037211418152,
      "learning_rate": 7.934512405592412e-06,
      "loss": 0.3084,
      "step": 13045
    },
    {
      "epoch": 0.2065645929984008,
      "grad_norm": 0.0016110530123114586,
      "learning_rate": 7.934354070015993e-06,
      "loss": 0.0,
      "step": 13046
    },
    {
      "epoch": 0.2065804265560429,
      "grad_norm": 0.00010877445311052725,
      "learning_rate": 7.934195734439572e-06,
      "loss": 0.0,
      "step": 13047
    },
    {
      "epoch": 0.20659626011368495,
      "grad_norm": 0.08505012840032578,
      "learning_rate": 7.934037398863151e-06,
      "loss": 0.0028,
      "step": 13048
    },
    {
      "epoch": 0.20661209367132702,
      "grad_norm": 0.18190357089042664,
      "learning_rate": 7.93387906328673e-06,
      "loss": 0.0475,
      "step": 13049
    },
    {
      "epoch": 0.20662792722896908,
      "grad_norm": 0.3148862421512604,
      "learning_rate": 7.93372072771031e-06,
      "loss": 0.1199,
      "step": 13050
    },
    {
      "epoch": 0.20664376078661115,
      "grad_norm": 0.5070059895515442,
      "learning_rate": 7.933562392133888e-06,
      "loss": 0.1856,
      "step": 13051
    },
    {
      "epoch": 0.2066595943442532,
      "grad_norm": 0.3634205460548401,
      "learning_rate": 7.93340405655747e-06,
      "loss": 0.115,
      "step": 13052
    },
    {
      "epoch": 0.20667542790189528,
      "grad_norm": 0.005707837641239166,
      "learning_rate": 7.933245720981048e-06,
      "loss": 0.0001,
      "step": 13053
    },
    {
      "epoch": 0.20669126145953734,
      "grad_norm": 0.6416773796081543,
      "learning_rate": 7.933087385404627e-06,
      "loss": 0.0635,
      "step": 13054
    },
    {
      "epoch": 0.2067070950171794,
      "grad_norm": 0.0030036652460694313,
      "learning_rate": 7.932929049828206e-06,
      "loss": 0.0001,
      "step": 13055
    },
    {
      "epoch": 0.20672292857482147,
      "grad_norm": 0.33918294310569763,
      "learning_rate": 7.932770714251786e-06,
      "loss": 0.0436,
      "step": 13056
    },
    {
      "epoch": 0.20673876213246353,
      "grad_norm": 0.8950632214546204,
      "learning_rate": 7.932612378675365e-06,
      "loss": 0.1275,
      "step": 13057
    },
    {
      "epoch": 0.2067545956901056,
      "grad_norm": 0.3098992109298706,
      "learning_rate": 7.932454043098945e-06,
      "loss": 0.0321,
      "step": 13058
    },
    {
      "epoch": 0.2067704292477477,
      "grad_norm": 0.08887398988008499,
      "learning_rate": 7.932295707522525e-06,
      "loss": 0.0063,
      "step": 13059
    },
    {
      "epoch": 0.20678626280538975,
      "grad_norm": 0.0007603346602991223,
      "learning_rate": 7.932137371946104e-06,
      "loss": 0.0,
      "step": 13060
    },
    {
      "epoch": 0.20680209636303182,
      "grad_norm": 0.4825131893157959,
      "learning_rate": 7.931979036369683e-06,
      "loss": 0.2565,
      "step": 13061
    },
    {
      "epoch": 0.20681792992067388,
      "grad_norm": 0.011437403969466686,
      "learning_rate": 7.931820700793262e-06,
      "loss": 0.0006,
      "step": 13062
    },
    {
      "epoch": 0.20683376347831595,
      "grad_norm": 0.00031781510915607214,
      "learning_rate": 7.93166236521684e-06,
      "loss": 0.0,
      "step": 13063
    },
    {
      "epoch": 0.206849597035958,
      "grad_norm": 0.27510181069374084,
      "learning_rate": 7.931504029640422e-06,
      "loss": 0.0562,
      "step": 13064
    },
    {
      "epoch": 0.20686543059360007,
      "grad_norm": 0.2022959589958191,
      "learning_rate": 7.931345694064e-06,
      "loss": 0.0557,
      "step": 13065
    },
    {
      "epoch": 0.20688126415124214,
      "grad_norm": 0.6183088421821594,
      "learning_rate": 7.931187358487578e-06,
      "loss": 0.0685,
      "step": 13066
    },
    {
      "epoch": 0.2068970977088842,
      "grad_norm": 0.48629412055015564,
      "learning_rate": 7.931029022911159e-06,
      "loss": 0.0789,
      "step": 13067
    },
    {
      "epoch": 0.20691293126652627,
      "grad_norm": 0.2881850302219391,
      "learning_rate": 7.930870687334738e-06,
      "loss": 0.0625,
      "step": 13068
    },
    {
      "epoch": 0.20692876482416833,
      "grad_norm": 0.44655585289001465,
      "learning_rate": 7.930712351758317e-06,
      "loss": 0.147,
      "step": 13069
    },
    {
      "epoch": 0.2069445983818104,
      "grad_norm": 0.4518361985683441,
      "learning_rate": 7.930554016181896e-06,
      "loss": 0.1574,
      "step": 13070
    },
    {
      "epoch": 0.2069604319394525,
      "grad_norm": 0.09674417227506638,
      "learning_rate": 7.930395680605477e-06,
      "loss": 0.0066,
      "step": 13071
    },
    {
      "epoch": 0.20697626549709455,
      "grad_norm": 0.4634925425052643,
      "learning_rate": 7.930237345029054e-06,
      "loss": 0.3331,
      "step": 13072
    },
    {
      "epoch": 0.20699209905473662,
      "grad_norm": 0.4120357036590576,
      "learning_rate": 7.930079009452635e-06,
      "loss": 0.2395,
      "step": 13073
    },
    {
      "epoch": 0.20700793261237868,
      "grad_norm": 0.3281511068344116,
      "learning_rate": 7.929920673876214e-06,
      "loss": 0.0997,
      "step": 13074
    },
    {
      "epoch": 0.20702376617002075,
      "grad_norm": 0.1352735012769699,
      "learning_rate": 7.929762338299793e-06,
      "loss": 0.0609,
      "step": 13075
    },
    {
      "epoch": 0.2070395997276628,
      "grad_norm": 0.00044495423207990825,
      "learning_rate": 7.929604002723372e-06,
      "loss": 0.0,
      "step": 13076
    },
    {
      "epoch": 0.20705543328530487,
      "grad_norm": 0.5520713329315186,
      "learning_rate": 7.929445667146953e-06,
      "loss": 0.1265,
      "step": 13077
    },
    {
      "epoch": 0.20707126684294694,
      "grad_norm": 0.0004805678327102214,
      "learning_rate": 7.92928733157053e-06,
      "loss": 0.0,
      "step": 13078
    },
    {
      "epoch": 0.207087100400589,
      "grad_norm": 0.540052592754364,
      "learning_rate": 7.929128995994111e-06,
      "loss": 0.3081,
      "step": 13079
    },
    {
      "epoch": 0.20710293395823107,
      "grad_norm": 0.5352001786231995,
      "learning_rate": 7.92897066041769e-06,
      "loss": 0.188,
      "step": 13080
    },
    {
      "epoch": 0.20711876751587313,
      "grad_norm": 0.3366169035434723,
      "learning_rate": 7.92881232484127e-06,
      "loss": 0.0546,
      "step": 13081
    },
    {
      "epoch": 0.2071346010735152,
      "grad_norm": 0.2373836487531662,
      "learning_rate": 7.928653989264848e-06,
      "loss": 0.1053,
      "step": 13082
    },
    {
      "epoch": 0.2071504346311573,
      "grad_norm": 0.25574859976768494,
      "learning_rate": 7.928495653688428e-06,
      "loss": 0.0235,
      "step": 13083
    },
    {
      "epoch": 0.20716626818879935,
      "grad_norm": 0.020448680967092514,
      "learning_rate": 7.928337318112007e-06,
      "loss": 0.0009,
      "step": 13084
    },
    {
      "epoch": 0.20718210174644142,
      "grad_norm": 0.48560604453086853,
      "learning_rate": 7.928178982535587e-06,
      "loss": 0.0535,
      "step": 13085
    },
    {
      "epoch": 0.20719793530408348,
      "grad_norm": 0.3927091360092163,
      "learning_rate": 7.928020646959166e-06,
      "loss": 0.3314,
      "step": 13086
    },
    {
      "epoch": 0.20721376886172554,
      "grad_norm": 0.0034108737017959356,
      "learning_rate": 7.927862311382746e-06,
      "loss": 0.0001,
      "step": 13087
    },
    {
      "epoch": 0.2072296024193676,
      "grad_norm": 0.5842663645744324,
      "learning_rate": 7.927703975806325e-06,
      "loss": 0.7699,
      "step": 13088
    },
    {
      "epoch": 0.20724543597700967,
      "grad_norm": 0.009955566376447678,
      "learning_rate": 7.927545640229904e-06,
      "loss": 0.0005,
      "step": 13089
    },
    {
      "epoch": 0.20726126953465174,
      "grad_norm": 0.506943941116333,
      "learning_rate": 7.927387304653483e-06,
      "loss": 0.2845,
      "step": 13090
    },
    {
      "epoch": 0.2072771030922938,
      "grad_norm": 0.605019211769104,
      "learning_rate": 7.927228969077062e-06,
      "loss": 0.1853,
      "step": 13091
    },
    {
      "epoch": 0.20729293664993587,
      "grad_norm": 0.8641715049743652,
      "learning_rate": 7.927070633500643e-06,
      "loss": 0.6404,
      "step": 13092
    },
    {
      "epoch": 0.20730877020757793,
      "grad_norm": 0.6693106889724731,
      "learning_rate": 7.92691229792422e-06,
      "loss": 0.1496,
      "step": 13093
    },
    {
      "epoch": 0.20732460376522,
      "grad_norm": 0.21459288895130157,
      "learning_rate": 7.9267539623478e-06,
      "loss": 0.0422,
      "step": 13094
    },
    {
      "epoch": 0.2073404373228621,
      "grad_norm": 0.48682454228401184,
      "learning_rate": 7.92659562677138e-06,
      "loss": 0.1759,
      "step": 13095
    },
    {
      "epoch": 0.20735627088050415,
      "grad_norm": 0.37995415925979614,
      "learning_rate": 7.926437291194959e-06,
      "loss": 0.2327,
      "step": 13096
    },
    {
      "epoch": 0.20737210443814622,
      "grad_norm": 0.1922280639410019,
      "learning_rate": 7.926278955618538e-06,
      "loss": 0.0711,
      "step": 13097
    },
    {
      "epoch": 0.20738793799578828,
      "grad_norm": 0.0002319437189726159,
      "learning_rate": 7.926120620042119e-06,
      "loss": 0.0,
      "step": 13098
    },
    {
      "epoch": 0.20740377155343034,
      "grad_norm": 0.5403988361358643,
      "learning_rate": 7.925962284465696e-06,
      "loss": 0.084,
      "step": 13099
    },
    {
      "epoch": 0.2074196051110724,
      "grad_norm": 0.00906616821885109,
      "learning_rate": 7.925803948889277e-06,
      "loss": 0.0004,
      "step": 13100
    },
    {
      "epoch": 0.20743543866871447,
      "grad_norm": 0.04020547494292259,
      "learning_rate": 7.925645613312856e-06,
      "loss": 0.0015,
      "step": 13101
    },
    {
      "epoch": 0.20745127222635654,
      "grad_norm": 0.3891134262084961,
      "learning_rate": 7.925487277736435e-06,
      "loss": 0.0811,
      "step": 13102
    },
    {
      "epoch": 0.2074671057839986,
      "grad_norm": 0.5466805696487427,
      "learning_rate": 7.925328942160014e-06,
      "loss": 0.1869,
      "step": 13103
    },
    {
      "epoch": 0.20748293934164067,
      "grad_norm": 0.011772665195167065,
      "learning_rate": 7.925170606583595e-06,
      "loss": 0.0005,
      "step": 13104
    },
    {
      "epoch": 0.20749877289928273,
      "grad_norm": 0.27689823508262634,
      "learning_rate": 7.925012271007172e-06,
      "loss": 0.108,
      "step": 13105
    },
    {
      "epoch": 0.2075146064569248,
      "grad_norm": 0.01926359161734581,
      "learning_rate": 7.924853935430753e-06,
      "loss": 0.0006,
      "step": 13106
    },
    {
      "epoch": 0.20753044001456689,
      "grad_norm": 0.010432845912873745,
      "learning_rate": 7.924695599854332e-06,
      "loss": 0.0005,
      "step": 13107
    },
    {
      "epoch": 0.20754627357220895,
      "grad_norm": 1.1488484144210815,
      "learning_rate": 7.924537264277911e-06,
      "loss": 0.3882,
      "step": 13108
    },
    {
      "epoch": 0.20756210712985101,
      "grad_norm": 0.0005142852896824479,
      "learning_rate": 7.92437892870149e-06,
      "loss": 0.0,
      "step": 13109
    },
    {
      "epoch": 0.20757794068749308,
      "grad_norm": 0.6090152263641357,
      "learning_rate": 7.924220593125071e-06,
      "loss": 0.0619,
      "step": 13110
    },
    {
      "epoch": 0.20759377424513514,
      "grad_norm": 0.28889891505241394,
      "learning_rate": 7.924062257548649e-06,
      "loss": 0.2123,
      "step": 13111
    },
    {
      "epoch": 0.2076096078027772,
      "grad_norm": 0.7721061110496521,
      "learning_rate": 7.92390392197223e-06,
      "loss": 0.1867,
      "step": 13112
    },
    {
      "epoch": 0.20762544136041927,
      "grad_norm": 0.4499364197254181,
      "learning_rate": 7.923745586395808e-06,
      "loss": 0.2182,
      "step": 13113
    },
    {
      "epoch": 0.20764127491806134,
      "grad_norm": 0.501047670841217,
      "learning_rate": 7.923587250819387e-06,
      "loss": 0.0126,
      "step": 13114
    },
    {
      "epoch": 0.2076571084757034,
      "grad_norm": 0.6411303281784058,
      "learning_rate": 7.923428915242967e-06,
      "loss": 0.5382,
      "step": 13115
    },
    {
      "epoch": 0.20767294203334546,
      "grad_norm": 0.4103514850139618,
      "learning_rate": 7.923270579666546e-06,
      "loss": 0.141,
      "step": 13116
    },
    {
      "epoch": 0.20768877559098753,
      "grad_norm": 0.0005600394797511399,
      "learning_rate": 7.923112244090125e-06,
      "loss": 0.0,
      "step": 13117
    },
    {
      "epoch": 0.2077046091486296,
      "grad_norm": 0.2935590147972107,
      "learning_rate": 7.922953908513704e-06,
      "loss": 0.0654,
      "step": 13118
    },
    {
      "epoch": 0.20772044270627169,
      "grad_norm": 0.2861962616443634,
      "learning_rate": 7.922795572937285e-06,
      "loss": 0.0338,
      "step": 13119
    },
    {
      "epoch": 0.20773627626391375,
      "grad_norm": 0.1806187778711319,
      "learning_rate": 7.922637237360864e-06,
      "loss": 0.0363,
      "step": 13120
    },
    {
      "epoch": 0.2077521098215558,
      "grad_norm": 0.4195936620235443,
      "learning_rate": 7.922478901784443e-06,
      "loss": 0.1371,
      "step": 13121
    },
    {
      "epoch": 0.20776794337919788,
      "grad_norm": 0.44228023290634155,
      "learning_rate": 7.922320566208022e-06,
      "loss": 0.2391,
      "step": 13122
    },
    {
      "epoch": 0.20778377693683994,
      "grad_norm": 0.6813927292823792,
      "learning_rate": 7.922162230631601e-06,
      "loss": 0.8048,
      "step": 13123
    },
    {
      "epoch": 0.207799610494482,
      "grad_norm": 0.29688331484794617,
      "learning_rate": 7.92200389505518e-06,
      "loss": 0.1676,
      "step": 13124
    },
    {
      "epoch": 0.20781544405212407,
      "grad_norm": 0.00021343663684092462,
      "learning_rate": 7.92184555947876e-06,
      "loss": 0.0,
      "step": 13125
    },
    {
      "epoch": 0.20783127760976614,
      "grad_norm": 0.020305223762989044,
      "learning_rate": 7.92168722390234e-06,
      "loss": 0.0013,
      "step": 13126
    },
    {
      "epoch": 0.2078471111674082,
      "grad_norm": 0.5235585570335388,
      "learning_rate": 7.921528888325919e-06,
      "loss": 0.5776,
      "step": 13127
    },
    {
      "epoch": 0.20786294472505026,
      "grad_norm": 0.20279452204704285,
      "learning_rate": 7.921370552749498e-06,
      "loss": 0.0307,
      "step": 13128
    },
    {
      "epoch": 0.20787877828269233,
      "grad_norm": 0.052929166704416275,
      "learning_rate": 7.921212217173077e-06,
      "loss": 0.0014,
      "step": 13129
    },
    {
      "epoch": 0.2078946118403344,
      "grad_norm": 0.32611626386642456,
      "learning_rate": 7.921053881596656e-06,
      "loss": 0.191,
      "step": 13130
    },
    {
      "epoch": 0.20791044539797648,
      "grad_norm": 0.2712112069129944,
      "learning_rate": 7.920895546020237e-06,
      "loss": 0.131,
      "step": 13131
    },
    {
      "epoch": 0.20792627895561855,
      "grad_norm": 0.47615477442741394,
      "learning_rate": 7.920737210443816e-06,
      "loss": 0.1706,
      "step": 13132
    },
    {
      "epoch": 0.2079421125132606,
      "grad_norm": 0.0743122398853302,
      "learning_rate": 7.920578874867395e-06,
      "loss": 0.0012,
      "step": 13133
    },
    {
      "epoch": 0.20795794607090268,
      "grad_norm": 0.5342854857444763,
      "learning_rate": 7.920420539290974e-06,
      "loss": 0.5081,
      "step": 13134
    },
    {
      "epoch": 0.20797377962854474,
      "grad_norm": 0.4347023665904999,
      "learning_rate": 7.920262203714553e-06,
      "loss": 0.3761,
      "step": 13135
    },
    {
      "epoch": 0.2079896131861868,
      "grad_norm": 0.8730508089065552,
      "learning_rate": 7.920103868138132e-06,
      "loss": 0.0168,
      "step": 13136
    },
    {
      "epoch": 0.20800544674382887,
      "grad_norm": 0.01357887964695692,
      "learning_rate": 7.919945532561711e-06,
      "loss": 0.0007,
      "step": 13137
    },
    {
      "epoch": 0.20802128030147093,
      "grad_norm": 0.6808034181594849,
      "learning_rate": 7.919787196985292e-06,
      "loss": 0.6152,
      "step": 13138
    },
    {
      "epoch": 0.208037113859113,
      "grad_norm": 0.6674604415893555,
      "learning_rate": 7.91962886140887e-06,
      "loss": 0.3264,
      "step": 13139
    },
    {
      "epoch": 0.20805294741675506,
      "grad_norm": 0.1988411694765091,
      "learning_rate": 7.91947052583245e-06,
      "loss": 0.015,
      "step": 13140
    },
    {
      "epoch": 0.20806878097439713,
      "grad_norm": 1.0040512084960938,
      "learning_rate": 7.91931219025603e-06,
      "loss": 0.1363,
      "step": 13141
    },
    {
      "epoch": 0.2080846145320392,
      "grad_norm": 0.34273940324783325,
      "learning_rate": 7.919153854679608e-06,
      "loss": 0.1025,
      "step": 13142
    },
    {
      "epoch": 0.20810044808968128,
      "grad_norm": 0.0008868298027664423,
      "learning_rate": 7.918995519103188e-06,
      "loss": 0.0,
      "step": 13143
    },
    {
      "epoch": 0.20811628164732335,
      "grad_norm": 0.5199499130249023,
      "learning_rate": 7.918837183526767e-06,
      "loss": 0.5598,
      "step": 13144
    },
    {
      "epoch": 0.2081321152049654,
      "grad_norm": 0.2871254086494446,
      "learning_rate": 7.918678847950346e-06,
      "loss": 0.0435,
      "step": 13145
    },
    {
      "epoch": 0.20814794876260748,
      "grad_norm": 0.6505078077316284,
      "learning_rate": 7.918520512373926e-06,
      "loss": 0.0997,
      "step": 13146
    },
    {
      "epoch": 0.20816378232024954,
      "grad_norm": 0.30018535256385803,
      "learning_rate": 7.918362176797506e-06,
      "loss": 0.1927,
      "step": 13147
    },
    {
      "epoch": 0.2081796158778916,
      "grad_norm": 0.5603373646736145,
      "learning_rate": 7.918203841221085e-06,
      "loss": 0.1368,
      "step": 13148
    },
    {
      "epoch": 0.20819544943553367,
      "grad_norm": 0.0004321859742049128,
      "learning_rate": 7.918045505644664e-06,
      "loss": 0.0,
      "step": 13149
    },
    {
      "epoch": 0.20821128299317573,
      "grad_norm": 0.02637350559234619,
      "learning_rate": 7.917887170068243e-06,
      "loss": 0.0015,
      "step": 13150
    },
    {
      "epoch": 0.2082271165508178,
      "grad_norm": 1.7059855461120605,
      "learning_rate": 7.917728834491822e-06,
      "loss": 0.5943,
      "step": 13151
    },
    {
      "epoch": 0.20824295010845986,
      "grad_norm": 0.005150505341589451,
      "learning_rate": 7.917570498915403e-06,
      "loss": 0.0002,
      "step": 13152
    },
    {
      "epoch": 0.20825878366610193,
      "grad_norm": 2.3887932300567627,
      "learning_rate": 7.917412163338982e-06,
      "loss": 0.2226,
      "step": 13153
    },
    {
      "epoch": 0.208274617223744,
      "grad_norm": 0.2187933325767517,
      "learning_rate": 7.91725382776256e-06,
      "loss": 0.0552,
      "step": 13154
    },
    {
      "epoch": 0.20829045078138608,
      "grad_norm": 0.44662413001060486,
      "learning_rate": 7.91709549218614e-06,
      "loss": 0.1383,
      "step": 13155
    },
    {
      "epoch": 0.20830628433902815,
      "grad_norm": 0.024985594674944878,
      "learning_rate": 7.916937156609719e-06,
      "loss": 0.0013,
      "step": 13156
    },
    {
      "epoch": 0.2083221178966702,
      "grad_norm": 0.4910815954208374,
      "learning_rate": 7.916778821033298e-06,
      "loss": 0.3675,
      "step": 13157
    },
    {
      "epoch": 0.20833795145431228,
      "grad_norm": 0.00024058495182543993,
      "learning_rate": 7.916620485456879e-06,
      "loss": 0.0,
      "step": 13158
    },
    {
      "epoch": 0.20835378501195434,
      "grad_norm": 0.0006443230668082833,
      "learning_rate": 7.916462149880458e-06,
      "loss": 0.0,
      "step": 13159
    },
    {
      "epoch": 0.2083696185695964,
      "grad_norm": 0.6492120623588562,
      "learning_rate": 7.916303814304037e-06,
      "loss": 0.0102,
      "step": 13160
    },
    {
      "epoch": 0.20838545212723847,
      "grad_norm": 0.678182065486908,
      "learning_rate": 7.916145478727616e-06,
      "loss": 0.1887,
      "step": 13161
    },
    {
      "epoch": 0.20840128568488053,
      "grad_norm": 0.03709293156862259,
      "learning_rate": 7.915987143151195e-06,
      "loss": 0.0021,
      "step": 13162
    },
    {
      "epoch": 0.2084171192425226,
      "grad_norm": 0.002542896894738078,
      "learning_rate": 7.915828807574774e-06,
      "loss": 0.0001,
      "step": 13163
    },
    {
      "epoch": 0.20843295280016466,
      "grad_norm": 0.4326377213001251,
      "learning_rate": 7.915670471998353e-06,
      "loss": 0.0531,
      "step": 13164
    },
    {
      "epoch": 0.20844878635780673,
      "grad_norm": 0.3890720009803772,
      "learning_rate": 7.915512136421934e-06,
      "loss": 0.0692,
      "step": 13165
    },
    {
      "epoch": 0.2084646199154488,
      "grad_norm": 0.35265013575553894,
      "learning_rate": 7.915353800845511e-06,
      "loss": 0.0336,
      "step": 13166
    },
    {
      "epoch": 0.20848045347309088,
      "grad_norm": 0.0021812415216118097,
      "learning_rate": 7.915195465269092e-06,
      "loss": 0.0001,
      "step": 13167
    },
    {
      "epoch": 0.20849628703073295,
      "grad_norm": 0.2666528820991516,
      "learning_rate": 7.915037129692671e-06,
      "loss": 0.0843,
      "step": 13168
    },
    {
      "epoch": 0.208512120588375,
      "grad_norm": 0.19754570722579956,
      "learning_rate": 7.91487879411625e-06,
      "loss": 0.0647,
      "step": 13169
    },
    {
      "epoch": 0.20852795414601707,
      "grad_norm": 0.18154974281787872,
      "learning_rate": 7.91472045853983e-06,
      "loss": 0.0661,
      "step": 13170
    },
    {
      "epoch": 0.20854378770365914,
      "grad_norm": 0.21466995775699615,
      "learning_rate": 7.91456212296341e-06,
      "loss": 0.1266,
      "step": 13171
    },
    {
      "epoch": 0.2085596212613012,
      "grad_norm": 0.25489044189453125,
      "learning_rate": 7.914403787386988e-06,
      "loss": 0.0509,
      "step": 13172
    },
    {
      "epoch": 0.20857545481894327,
      "grad_norm": 0.5707107186317444,
      "learning_rate": 7.914245451810568e-06,
      "loss": 0.2059,
      "step": 13173
    },
    {
      "epoch": 0.20859128837658533,
      "grad_norm": 0.05321953818202019,
      "learning_rate": 7.914087116234147e-06,
      "loss": 0.0047,
      "step": 13174
    },
    {
      "epoch": 0.2086071219342274,
      "grad_norm": 0.571140706539154,
      "learning_rate": 7.913928780657727e-06,
      "loss": 0.3934,
      "step": 13175
    },
    {
      "epoch": 0.20862295549186946,
      "grad_norm": 0.00028531861607916653,
      "learning_rate": 7.913770445081306e-06,
      "loss": 0.0,
      "step": 13176
    },
    {
      "epoch": 0.20863878904951152,
      "grad_norm": 0.15871140360832214,
      "learning_rate": 7.913612109504886e-06,
      "loss": 0.0132,
      "step": 13177
    },
    {
      "epoch": 0.2086546226071536,
      "grad_norm": 0.0006875385879538953,
      "learning_rate": 7.913453773928464e-06,
      "loss": 0.0,
      "step": 13178
    },
    {
      "epoch": 0.20867045616479568,
      "grad_norm": 0.3660379648208618,
      "learning_rate": 7.913295438352045e-06,
      "loss": 0.0816,
      "step": 13179
    },
    {
      "epoch": 0.20868628972243775,
      "grad_norm": 0.0003420151479076594,
      "learning_rate": 7.913137102775624e-06,
      "loss": 0.0,
      "step": 13180
    },
    {
      "epoch": 0.2087021232800798,
      "grad_norm": 0.016397465020418167,
      "learning_rate": 7.912978767199203e-06,
      "loss": 0.001,
      "step": 13181
    },
    {
      "epoch": 0.20871795683772187,
      "grad_norm": 1.5114878416061401,
      "learning_rate": 7.912820431622782e-06,
      "loss": 0.1549,
      "step": 13182
    },
    {
      "epoch": 0.20873379039536394,
      "grad_norm": 0.6664139032363892,
      "learning_rate": 7.912662096046363e-06,
      "loss": 0.2428,
      "step": 13183
    },
    {
      "epoch": 0.208749623953006,
      "grad_norm": 0.00045846361899748445,
      "learning_rate": 7.91250376046994e-06,
      "loss": 0.0,
      "step": 13184
    },
    {
      "epoch": 0.20876545751064807,
      "grad_norm": 0.2556113600730896,
      "learning_rate": 7.912345424893519e-06,
      "loss": 0.0705,
      "step": 13185
    },
    {
      "epoch": 0.20878129106829013,
      "grad_norm": 0.0023863359820097685,
      "learning_rate": 7.9121870893171e-06,
      "loss": 0.0001,
      "step": 13186
    },
    {
      "epoch": 0.2087971246259322,
      "grad_norm": 0.5949530005455017,
      "learning_rate": 7.912028753740679e-06,
      "loss": 0.1704,
      "step": 13187
    },
    {
      "epoch": 0.20881295818357426,
      "grad_norm": 0.44327571988105774,
      "learning_rate": 7.911870418164258e-06,
      "loss": 0.7569,
      "step": 13188
    },
    {
      "epoch": 0.20882879174121632,
      "grad_norm": 0.441110223531723,
      "learning_rate": 7.911712082587837e-06,
      "loss": 0.1379,
      "step": 13189
    },
    {
      "epoch": 0.2088446252988584,
      "grad_norm": 0.017701275646686554,
      "learning_rate": 7.911553747011416e-06,
      "loss": 0.0008,
      "step": 13190
    },
    {
      "epoch": 0.20886045885650048,
      "grad_norm": 0.20314018428325653,
      "learning_rate": 7.911395411434995e-06,
      "loss": 0.074,
      "step": 13191
    },
    {
      "epoch": 0.20887629241414254,
      "grad_norm": 0.00013122423843014985,
      "learning_rate": 7.911237075858576e-06,
      "loss": 0.0,
      "step": 13192
    },
    {
      "epoch": 0.2088921259717846,
      "grad_norm": 0.6615438461303711,
      "learning_rate": 7.911078740282155e-06,
      "loss": 0.1332,
      "step": 13193
    },
    {
      "epoch": 0.20890795952942667,
      "grad_norm": 0.17849618196487427,
      "learning_rate": 7.910920404705734e-06,
      "loss": 0.036,
      "step": 13194
    },
    {
      "epoch": 0.20892379308706874,
      "grad_norm": 0.3423571288585663,
      "learning_rate": 7.910762069129313e-06,
      "loss": 0.0646,
      "step": 13195
    },
    {
      "epoch": 0.2089396266447108,
      "grad_norm": 0.3761342167854309,
      "learning_rate": 7.910603733552892e-06,
      "loss": 0.1531,
      "step": 13196
    },
    {
      "epoch": 0.20895546020235287,
      "grad_norm": 0.5025879740715027,
      "learning_rate": 7.910445397976471e-06,
      "loss": 0.1978,
      "step": 13197
    },
    {
      "epoch": 0.20897129375999493,
      "grad_norm": 0.9713029265403748,
      "learning_rate": 7.910287062400052e-06,
      "loss": 0.8007,
      "step": 13198
    },
    {
      "epoch": 0.208987127317637,
      "grad_norm": 0.5936697125434875,
      "learning_rate": 7.910128726823631e-06,
      "loss": 0.1142,
      "step": 13199
    },
    {
      "epoch": 0.20900296087527906,
      "grad_norm": 0.507929265499115,
      "learning_rate": 7.90997039124721e-06,
      "loss": 0.2769,
      "step": 13200
    },
    {
      "epoch": 0.20901879443292112,
      "grad_norm": 0.01504225842654705,
      "learning_rate": 7.90981205567079e-06,
      "loss": 0.0008,
      "step": 13201
    },
    {
      "epoch": 0.2090346279905632,
      "grad_norm": 0.6312501430511475,
      "learning_rate": 7.909653720094368e-06,
      "loss": 0.4553,
      "step": 13202
    },
    {
      "epoch": 0.20905046154820528,
      "grad_norm": 0.003771421266719699,
      "learning_rate": 7.909495384517948e-06,
      "loss": 0.0001,
      "step": 13203
    },
    {
      "epoch": 0.20906629510584734,
      "grad_norm": 0.3829665780067444,
      "learning_rate": 7.909337048941528e-06,
      "loss": 0.0475,
      "step": 13204
    },
    {
      "epoch": 0.2090821286634894,
      "grad_norm": 0.4196644425392151,
      "learning_rate": 7.909178713365107e-06,
      "loss": 0.1046,
      "step": 13205
    },
    {
      "epoch": 0.20909796222113147,
      "grad_norm": 0.3392195701599121,
      "learning_rate": 7.909020377788686e-06,
      "loss": 0.0428,
      "step": 13206
    },
    {
      "epoch": 0.20911379577877354,
      "grad_norm": 0.3754514753818512,
      "learning_rate": 7.908862042212266e-06,
      "loss": 0.0657,
      "step": 13207
    },
    {
      "epoch": 0.2091296293364156,
      "grad_norm": 0.17786306142807007,
      "learning_rate": 7.908703706635845e-06,
      "loss": 0.0427,
      "step": 13208
    },
    {
      "epoch": 0.20914546289405767,
      "grad_norm": 0.442361444234848,
      "learning_rate": 7.908545371059424e-06,
      "loss": 0.1888,
      "step": 13209
    },
    {
      "epoch": 0.20916129645169973,
      "grad_norm": 0.014586718752980232,
      "learning_rate": 7.908387035483003e-06,
      "loss": 0.0006,
      "step": 13210
    },
    {
      "epoch": 0.2091771300093418,
      "grad_norm": 0.09338419884443283,
      "learning_rate": 7.908228699906582e-06,
      "loss": 0.003,
      "step": 13211
    },
    {
      "epoch": 0.20919296356698386,
      "grad_norm": 0.4168224036693573,
      "learning_rate": 7.908070364330161e-06,
      "loss": 0.131,
      "step": 13212
    },
    {
      "epoch": 0.20920879712462592,
      "grad_norm": 0.03307456895709038,
      "learning_rate": 7.907912028753742e-06,
      "loss": 0.0017,
      "step": 13213
    },
    {
      "epoch": 0.209224630682268,
      "grad_norm": 0.0004870927077718079,
      "learning_rate": 7.90775369317732e-06,
      "loss": 0.0,
      "step": 13214
    },
    {
      "epoch": 0.20924046423991008,
      "grad_norm": 0.2899073660373688,
      "learning_rate": 7.9075953576009e-06,
      "loss": 0.0808,
      "step": 13215
    },
    {
      "epoch": 0.20925629779755214,
      "grad_norm": 0.0005598972784355283,
      "learning_rate": 7.907437022024479e-06,
      "loss": 0.0,
      "step": 13216
    },
    {
      "epoch": 0.2092721313551942,
      "grad_norm": 0.7095891833305359,
      "learning_rate": 7.907278686448058e-06,
      "loss": 0.8391,
      "step": 13217
    },
    {
      "epoch": 0.20928796491283627,
      "grad_norm": 0.3400571942329407,
      "learning_rate": 7.907120350871637e-06,
      "loss": 0.117,
      "step": 13218
    },
    {
      "epoch": 0.20930379847047834,
      "grad_norm": 0.0004126661515329033,
      "learning_rate": 7.906962015295218e-06,
      "loss": 0.0,
      "step": 13219
    },
    {
      "epoch": 0.2093196320281204,
      "grad_norm": 0.23642213642597198,
      "learning_rate": 7.906803679718797e-06,
      "loss": 0.1095,
      "step": 13220
    },
    {
      "epoch": 0.20933546558576246,
      "grad_norm": 0.2864352762699127,
      "learning_rate": 7.906645344142376e-06,
      "loss": 0.0912,
      "step": 13221
    },
    {
      "epoch": 0.20935129914340453,
      "grad_norm": 0.009129885584115982,
      "learning_rate": 7.906487008565955e-06,
      "loss": 0.0003,
      "step": 13222
    },
    {
      "epoch": 0.2093671327010466,
      "grad_norm": 0.255927175283432,
      "learning_rate": 7.906328672989534e-06,
      "loss": 0.1211,
      "step": 13223
    },
    {
      "epoch": 0.20938296625868866,
      "grad_norm": 0.14837025105953217,
      "learning_rate": 7.906170337413113e-06,
      "loss": 0.0151,
      "step": 13224
    },
    {
      "epoch": 0.20939879981633072,
      "grad_norm": 0.2237355262041092,
      "learning_rate": 7.906012001836694e-06,
      "loss": 0.0051,
      "step": 13225
    },
    {
      "epoch": 0.20941463337397279,
      "grad_norm": 0.9869150519371033,
      "learning_rate": 7.905853666260273e-06,
      "loss": 0.142,
      "step": 13226
    },
    {
      "epoch": 0.20943046693161488,
      "grad_norm": 0.3707566261291504,
      "learning_rate": 7.905695330683852e-06,
      "loss": 0.114,
      "step": 13227
    },
    {
      "epoch": 0.20944630048925694,
      "grad_norm": 0.1587461233139038,
      "learning_rate": 7.905536995107431e-06,
      "loss": 0.0342,
      "step": 13228
    },
    {
      "epoch": 0.209462134046899,
      "grad_norm": 0.3317537307739258,
      "learning_rate": 7.90537865953101e-06,
      "loss": 0.1365,
      "step": 13229
    },
    {
      "epoch": 0.20947796760454107,
      "grad_norm": 0.030222536996006966,
      "learning_rate": 7.90522032395459e-06,
      "loss": 0.0016,
      "step": 13230
    },
    {
      "epoch": 0.20949380116218314,
      "grad_norm": 0.045457374304533005,
      "learning_rate": 7.90506198837817e-06,
      "loss": 0.0016,
      "step": 13231
    },
    {
      "epoch": 0.2095096347198252,
      "grad_norm": 0.563801109790802,
      "learning_rate": 7.90490365280175e-06,
      "loss": 0.1321,
      "step": 13232
    },
    {
      "epoch": 0.20952546827746726,
      "grad_norm": 0.013401033356785774,
      "learning_rate": 7.904745317225327e-06,
      "loss": 0.0006,
      "step": 13233
    },
    {
      "epoch": 0.20954130183510933,
      "grad_norm": 0.0003022264572791755,
      "learning_rate": 7.904586981648907e-06,
      "loss": 0.0,
      "step": 13234
    },
    {
      "epoch": 0.2095571353927514,
      "grad_norm": 0.04304733872413635,
      "learning_rate": 7.904428646072487e-06,
      "loss": 0.001,
      "step": 13235
    },
    {
      "epoch": 0.20957296895039346,
      "grad_norm": 0.26122793555259705,
      "learning_rate": 7.904270310496066e-06,
      "loss": 0.285,
      "step": 13236
    },
    {
      "epoch": 0.20958880250803552,
      "grad_norm": 0.012929772026836872,
      "learning_rate": 7.904111974919645e-06,
      "loss": 0.0006,
      "step": 13237
    },
    {
      "epoch": 0.20960463606567759,
      "grad_norm": 0.0005783014348708093,
      "learning_rate": 7.903953639343225e-06,
      "loss": 0.0,
      "step": 13238
    },
    {
      "epoch": 0.20962046962331968,
      "grad_norm": 0.424185186624527,
      "learning_rate": 7.903795303766803e-06,
      "loss": 0.1938,
      "step": 13239
    },
    {
      "epoch": 0.20963630318096174,
      "grad_norm": 0.6157211065292358,
      "learning_rate": 7.903636968190384e-06,
      "loss": 0.3752,
      "step": 13240
    },
    {
      "epoch": 0.2096521367386038,
      "grad_norm": 0.5894298553466797,
      "learning_rate": 7.903478632613963e-06,
      "loss": 0.2347,
      "step": 13241
    },
    {
      "epoch": 0.20966797029624587,
      "grad_norm": 0.7394325137138367,
      "learning_rate": 7.903320297037542e-06,
      "loss": 0.6752,
      "step": 13242
    },
    {
      "epoch": 0.20968380385388793,
      "grad_norm": 0.47249650955200195,
      "learning_rate": 7.903161961461121e-06,
      "loss": 0.2289,
      "step": 13243
    },
    {
      "epoch": 0.20969963741153,
      "grad_norm": 0.0003164052322972566,
      "learning_rate": 7.903003625884702e-06,
      "loss": 0.0,
      "step": 13244
    },
    {
      "epoch": 0.20971547096917206,
      "grad_norm": 0.402150422334671,
      "learning_rate": 7.902845290308279e-06,
      "loss": 0.1277,
      "step": 13245
    },
    {
      "epoch": 0.20973130452681413,
      "grad_norm": 0.2995661795139313,
      "learning_rate": 7.90268695473186e-06,
      "loss": 0.0906,
      "step": 13246
    },
    {
      "epoch": 0.2097471380844562,
      "grad_norm": 0.011639815755188465,
      "learning_rate": 7.902528619155439e-06,
      "loss": 0.0004,
      "step": 13247
    },
    {
      "epoch": 0.20976297164209826,
      "grad_norm": 0.4847431480884552,
      "learning_rate": 7.902370283579018e-06,
      "loss": 0.2951,
      "step": 13248
    },
    {
      "epoch": 0.20977880519974032,
      "grad_norm": 0.3103913366794586,
      "learning_rate": 7.902211948002597e-06,
      "loss": 0.0305,
      "step": 13249
    },
    {
      "epoch": 0.20979463875738238,
      "grad_norm": 0.0005808199639432132,
      "learning_rate": 7.902053612426178e-06,
      "loss": 0.0,
      "step": 13250
    },
    {
      "epoch": 0.20981047231502448,
      "grad_norm": 0.05195661634206772,
      "learning_rate": 7.901895276849755e-06,
      "loss": 0.0039,
      "step": 13251
    },
    {
      "epoch": 0.20982630587266654,
      "grad_norm": 0.30690860748291016,
      "learning_rate": 7.901736941273336e-06,
      "loss": 0.1732,
      "step": 13252
    },
    {
      "epoch": 0.2098421394303086,
      "grad_norm": 1.8153557777404785,
      "learning_rate": 7.901578605696915e-06,
      "loss": 0.2867,
      "step": 13253
    },
    {
      "epoch": 0.20985797298795067,
      "grad_norm": 0.017179099842905998,
      "learning_rate": 7.901420270120494e-06,
      "loss": 0.0007,
      "step": 13254
    },
    {
      "epoch": 0.20987380654559273,
      "grad_norm": 0.44477105140686035,
      "learning_rate": 7.901261934544073e-06,
      "loss": 0.0951,
      "step": 13255
    },
    {
      "epoch": 0.2098896401032348,
      "grad_norm": 0.4083271026611328,
      "learning_rate": 7.901103598967654e-06,
      "loss": 0.1199,
      "step": 13256
    },
    {
      "epoch": 0.20990547366087686,
      "grad_norm": 0.41061729192733765,
      "learning_rate": 7.900945263391231e-06,
      "loss": 0.1423,
      "step": 13257
    },
    {
      "epoch": 0.20992130721851893,
      "grad_norm": 0.0005599498399533331,
      "learning_rate": 7.90078692781481e-06,
      "loss": 0.0,
      "step": 13258
    },
    {
      "epoch": 0.209937140776161,
      "grad_norm": 0.3015928864479065,
      "learning_rate": 7.900628592238391e-06,
      "loss": 0.0785,
      "step": 13259
    },
    {
      "epoch": 0.20995297433380306,
      "grad_norm": 0.43285104632377625,
      "learning_rate": 7.90047025666197e-06,
      "loss": 0.2893,
      "step": 13260
    },
    {
      "epoch": 0.20996880789144512,
      "grad_norm": 0.27627888321876526,
      "learning_rate": 7.90031192108555e-06,
      "loss": 0.0813,
      "step": 13261
    },
    {
      "epoch": 0.20998464144908718,
      "grad_norm": 0.01265209075063467,
      "learning_rate": 7.900153585509128e-06,
      "loss": 0.0005,
      "step": 13262
    },
    {
      "epoch": 0.21000047500672928,
      "grad_norm": 0.0989132821559906,
      "learning_rate": 7.899995249932708e-06,
      "loss": 0.0021,
      "step": 13263
    },
    {
      "epoch": 0.21001630856437134,
      "grad_norm": 0.06369119882583618,
      "learning_rate": 7.899836914356287e-06,
      "loss": 0.0024,
      "step": 13264
    },
    {
      "epoch": 0.2100321421220134,
      "grad_norm": 0.663334846496582,
      "learning_rate": 7.899678578779867e-06,
      "loss": 0.135,
      "step": 13265
    },
    {
      "epoch": 0.21004797567965547,
      "grad_norm": 0.3258734941482544,
      "learning_rate": 7.899520243203446e-06,
      "loss": 0.1537,
      "step": 13266
    },
    {
      "epoch": 0.21006380923729753,
      "grad_norm": 0.43804025650024414,
      "learning_rate": 7.899361907627026e-06,
      "loss": 0.2566,
      "step": 13267
    },
    {
      "epoch": 0.2100796427949396,
      "grad_norm": 0.11424064636230469,
      "learning_rate": 7.899203572050605e-06,
      "loss": 0.0067,
      "step": 13268
    },
    {
      "epoch": 0.21009547635258166,
      "grad_norm": 0.019105177372694016,
      "learning_rate": 7.899045236474184e-06,
      "loss": 0.0009,
      "step": 13269
    },
    {
      "epoch": 0.21011130991022373,
      "grad_norm": 1.2376182079315186,
      "learning_rate": 7.898886900897763e-06,
      "loss": 0.064,
      "step": 13270
    },
    {
      "epoch": 0.2101271434678658,
      "grad_norm": 0.4499497413635254,
      "learning_rate": 7.898728565321344e-06,
      "loss": 0.9091,
      "step": 13271
    },
    {
      "epoch": 0.21014297702550785,
      "grad_norm": 0.37849166989326477,
      "learning_rate": 7.898570229744923e-06,
      "loss": 0.1259,
      "step": 13272
    },
    {
      "epoch": 0.21015881058314992,
      "grad_norm": 0.29264041781425476,
      "learning_rate": 7.898411894168502e-06,
      "loss": 0.1444,
      "step": 13273
    },
    {
      "epoch": 0.21017464414079198,
      "grad_norm": 0.25499019026756287,
      "learning_rate": 7.89825355859208e-06,
      "loss": 0.0453,
      "step": 13274
    },
    {
      "epoch": 0.21019047769843408,
      "grad_norm": 0.3314276933670044,
      "learning_rate": 7.89809522301566e-06,
      "loss": 0.058,
      "step": 13275
    },
    {
      "epoch": 0.21020631125607614,
      "grad_norm": 0.002279767068102956,
      "learning_rate": 7.897936887439239e-06,
      "loss": 0.0,
      "step": 13276
    },
    {
      "epoch": 0.2102221448137182,
      "grad_norm": 0.3407617509365082,
      "learning_rate": 7.89777855186282e-06,
      "loss": 0.1057,
      "step": 13277
    },
    {
      "epoch": 0.21023797837136027,
      "grad_norm": 0.013540857471525669,
      "learning_rate": 7.897620216286397e-06,
      "loss": 0.0006,
      "step": 13278
    },
    {
      "epoch": 0.21025381192900233,
      "grad_norm": 0.6726828813552856,
      "learning_rate": 7.897461880709978e-06,
      "loss": 0.3048,
      "step": 13279
    },
    {
      "epoch": 0.2102696454866444,
      "grad_norm": 0.060981567949056625,
      "learning_rate": 7.897303545133557e-06,
      "loss": 0.004,
      "step": 13280
    },
    {
      "epoch": 0.21028547904428646,
      "grad_norm": 0.2983562648296356,
      "learning_rate": 7.897145209557136e-06,
      "loss": 0.2812,
      "step": 13281
    },
    {
      "epoch": 0.21030131260192853,
      "grad_norm": 0.3463112413883209,
      "learning_rate": 7.896986873980715e-06,
      "loss": 0.2705,
      "step": 13282
    },
    {
      "epoch": 0.2103171461595706,
      "grad_norm": 0.005285460501909256,
      "learning_rate": 7.896828538404294e-06,
      "loss": 0.0002,
      "step": 13283
    },
    {
      "epoch": 0.21033297971721265,
      "grad_norm": 0.11952607333660126,
      "learning_rate": 7.896670202827873e-06,
      "loss": 0.0111,
      "step": 13284
    },
    {
      "epoch": 0.21034881327485472,
      "grad_norm": 0.0002510008926037699,
      "learning_rate": 7.896511867251452e-06,
      "loss": 0.0,
      "step": 13285
    },
    {
      "epoch": 0.21036464683249678,
      "grad_norm": 0.6349148154258728,
      "learning_rate": 7.896353531675033e-06,
      "loss": 0.9113,
      "step": 13286
    },
    {
      "epoch": 0.21038048039013885,
      "grad_norm": 0.005464381072670221,
      "learning_rate": 7.896195196098612e-06,
      "loss": 0.0002,
      "step": 13287
    },
    {
      "epoch": 0.21039631394778094,
      "grad_norm": 0.4494319558143616,
      "learning_rate": 7.896036860522191e-06,
      "loss": 0.0991,
      "step": 13288
    },
    {
      "epoch": 0.210412147505423,
      "grad_norm": 0.00043059297604486346,
      "learning_rate": 7.89587852494577e-06,
      "loss": 0.0,
      "step": 13289
    },
    {
      "epoch": 0.21042798106306507,
      "grad_norm": 0.4899766147136688,
      "learning_rate": 7.89572018936935e-06,
      "loss": 0.2194,
      "step": 13290
    },
    {
      "epoch": 0.21044381462070713,
      "grad_norm": 0.46800142526626587,
      "learning_rate": 7.895561853792929e-06,
      "loss": 0.3243,
      "step": 13291
    },
    {
      "epoch": 0.2104596481783492,
      "grad_norm": 0.3602496087551117,
      "learning_rate": 7.89540351821651e-06,
      "loss": 0.2012,
      "step": 13292
    },
    {
      "epoch": 0.21047548173599126,
      "grad_norm": 0.006204587873071432,
      "learning_rate": 7.895245182640088e-06,
      "loss": 0.0002,
      "step": 13293
    },
    {
      "epoch": 0.21049131529363332,
      "grad_norm": 0.4983491003513336,
      "learning_rate": 7.895086847063667e-06,
      "loss": 0.5049,
      "step": 13294
    },
    {
      "epoch": 0.2105071488512754,
      "grad_norm": 0.3393971025943756,
      "learning_rate": 7.894928511487247e-06,
      "loss": 0.134,
      "step": 13295
    },
    {
      "epoch": 0.21052298240891745,
      "grad_norm": 0.3309714198112488,
      "learning_rate": 7.894770175910826e-06,
      "loss": 0.0749,
      "step": 13296
    },
    {
      "epoch": 0.21053881596655952,
      "grad_norm": 0.15019622445106506,
      "learning_rate": 7.894611840334405e-06,
      "loss": 0.0562,
      "step": 13297
    },
    {
      "epoch": 0.21055464952420158,
      "grad_norm": 0.014985166490077972,
      "learning_rate": 7.894453504757986e-06,
      "loss": 0.0004,
      "step": 13298
    },
    {
      "epoch": 0.21057048308184365,
      "grad_norm": 0.28834933042526245,
      "learning_rate": 7.894295169181565e-06,
      "loss": 0.1178,
      "step": 13299
    },
    {
      "epoch": 0.21058631663948574,
      "grad_norm": 0.6086418032646179,
      "learning_rate": 7.894136833605144e-06,
      "loss": 0.4712,
      "step": 13300
    },
    {
      "epoch": 0.2106021501971278,
      "grad_norm": 0.014242133125662804,
      "learning_rate": 7.893978498028723e-06,
      "loss": 0.0007,
      "step": 13301
    },
    {
      "epoch": 0.21061798375476987,
      "grad_norm": 0.8899176716804504,
      "learning_rate": 7.893820162452302e-06,
      "loss": 0.4069,
      "step": 13302
    },
    {
      "epoch": 0.21063381731241193,
      "grad_norm": 0.25834229588508606,
      "learning_rate": 7.893661826875881e-06,
      "loss": 0.1367,
      "step": 13303
    },
    {
      "epoch": 0.210649650870054,
      "grad_norm": 0.023359613493084908,
      "learning_rate": 7.893503491299462e-06,
      "loss": 0.0013,
      "step": 13304
    },
    {
      "epoch": 0.21066548442769606,
      "grad_norm": 0.41819241642951965,
      "learning_rate": 7.89334515572304e-06,
      "loss": 0.2629,
      "step": 13305
    },
    {
      "epoch": 0.21068131798533812,
      "grad_norm": 0.20096522569656372,
      "learning_rate": 7.893186820146618e-06,
      "loss": 0.042,
      "step": 13306
    },
    {
      "epoch": 0.2106971515429802,
      "grad_norm": 0.6574156284332275,
      "learning_rate": 7.893028484570199e-06,
      "loss": 0.2473,
      "step": 13307
    },
    {
      "epoch": 0.21071298510062225,
      "grad_norm": 0.26180076599121094,
      "learning_rate": 7.892870148993778e-06,
      "loss": 0.1283,
      "step": 13308
    },
    {
      "epoch": 0.21072881865826432,
      "grad_norm": 0.6167876720428467,
      "learning_rate": 7.892711813417357e-06,
      "loss": 0.3075,
      "step": 13309
    },
    {
      "epoch": 0.21074465221590638,
      "grad_norm": 0.01321135088801384,
      "learning_rate": 7.892553477840936e-06,
      "loss": 0.0006,
      "step": 13310
    },
    {
      "epoch": 0.21076048577354844,
      "grad_norm": 0.22687581181526184,
      "learning_rate": 7.892395142264517e-06,
      "loss": 0.0373,
      "step": 13311
    },
    {
      "epoch": 0.21077631933119054,
      "grad_norm": 0.8647365570068359,
      "learning_rate": 7.892236806688094e-06,
      "loss": 0.0575,
      "step": 13312
    },
    {
      "epoch": 0.2107921528888326,
      "grad_norm": 0.20105527341365814,
      "learning_rate": 7.892078471111675e-06,
      "loss": 0.0897,
      "step": 13313
    },
    {
      "epoch": 0.21080798644647467,
      "grad_norm": 0.0003663823881652206,
      "learning_rate": 7.891920135535254e-06,
      "loss": 0.0,
      "step": 13314
    },
    {
      "epoch": 0.21082382000411673,
      "grad_norm": 0.28683510422706604,
      "learning_rate": 7.891761799958833e-06,
      "loss": 0.0645,
      "step": 13315
    },
    {
      "epoch": 0.2108396535617588,
      "grad_norm": 1.3541182279586792,
      "learning_rate": 7.891603464382412e-06,
      "loss": 0.4576,
      "step": 13316
    },
    {
      "epoch": 0.21085548711940086,
      "grad_norm": 0.019595617428421974,
      "learning_rate": 7.891445128805993e-06,
      "loss": 0.001,
      "step": 13317
    },
    {
      "epoch": 0.21087132067704292,
      "grad_norm": 0.30252763628959656,
      "learning_rate": 7.89128679322957e-06,
      "loss": 0.1584,
      "step": 13318
    },
    {
      "epoch": 0.210887154234685,
      "grad_norm": 0.18681299686431885,
      "learning_rate": 7.891128457653151e-06,
      "loss": 0.0503,
      "step": 13319
    },
    {
      "epoch": 0.21090298779232705,
      "grad_norm": 0.026923013851046562,
      "learning_rate": 7.89097012207673e-06,
      "loss": 0.0014,
      "step": 13320
    },
    {
      "epoch": 0.21091882134996912,
      "grad_norm": 0.013303291983902454,
      "learning_rate": 7.89081178650031e-06,
      "loss": 0.0005,
      "step": 13321
    },
    {
      "epoch": 0.21093465490761118,
      "grad_norm": 0.5980799794197083,
      "learning_rate": 7.890653450923889e-06,
      "loss": 0.4722,
      "step": 13322
    },
    {
      "epoch": 0.21095048846525324,
      "grad_norm": 0.9625257849693298,
      "learning_rate": 7.89049511534747e-06,
      "loss": 0.1376,
      "step": 13323
    },
    {
      "epoch": 0.21096632202289534,
      "grad_norm": 0.01678197830915451,
      "learning_rate": 7.890336779771047e-06,
      "loss": 0.0009,
      "step": 13324
    },
    {
      "epoch": 0.2109821555805374,
      "grad_norm": 0.34691283106803894,
      "learning_rate": 7.890178444194627e-06,
      "loss": 0.1233,
      "step": 13325
    },
    {
      "epoch": 0.21099798913817946,
      "grad_norm": 0.46354708075523376,
      "learning_rate": 7.890020108618207e-06,
      "loss": 0.086,
      "step": 13326
    },
    {
      "epoch": 0.21101382269582153,
      "grad_norm": 0.0035944730043411255,
      "learning_rate": 7.889861773041786e-06,
      "loss": 0.0,
      "step": 13327
    },
    {
      "epoch": 0.2110296562534636,
      "grad_norm": 0.9361122846603394,
      "learning_rate": 7.889703437465365e-06,
      "loss": 0.0744,
      "step": 13328
    },
    {
      "epoch": 0.21104548981110566,
      "grad_norm": 0.00016015549772419035,
      "learning_rate": 7.889545101888945e-06,
      "loss": 0.0,
      "step": 13329
    },
    {
      "epoch": 0.21106132336874772,
      "grad_norm": 0.007883956655859947,
      "learning_rate": 7.889386766312523e-06,
      "loss": 0.0002,
      "step": 13330
    },
    {
      "epoch": 0.2110771569263898,
      "grad_norm": 0.13395504653453827,
      "learning_rate": 7.889228430736102e-06,
      "loss": 0.0223,
      "step": 13331
    },
    {
      "epoch": 0.21109299048403185,
      "grad_norm": 0.35267138481140137,
      "learning_rate": 7.889070095159683e-06,
      "loss": 0.0977,
      "step": 13332
    },
    {
      "epoch": 0.21110882404167391,
      "grad_norm": 0.3344648480415344,
      "learning_rate": 7.888911759583262e-06,
      "loss": 0.0894,
      "step": 13333
    },
    {
      "epoch": 0.21112465759931598,
      "grad_norm": 0.22682517766952515,
      "learning_rate": 7.88875342400684e-06,
      "loss": 0.0925,
      "step": 13334
    },
    {
      "epoch": 0.21114049115695804,
      "grad_norm": 0.21320128440856934,
      "learning_rate": 7.88859508843042e-06,
      "loss": 0.0542,
      "step": 13335
    },
    {
      "epoch": 0.21115632471460014,
      "grad_norm": 0.009877065196633339,
      "learning_rate": 7.888436752853999e-06,
      "loss": 0.0003,
      "step": 13336
    },
    {
      "epoch": 0.2111721582722422,
      "grad_norm": 0.5389979481697083,
      "learning_rate": 7.888278417277578e-06,
      "loss": 0.1777,
      "step": 13337
    },
    {
      "epoch": 0.21118799182988426,
      "grad_norm": 0.016176002100110054,
      "learning_rate": 7.888120081701159e-06,
      "loss": 0.0009,
      "step": 13338
    },
    {
      "epoch": 0.21120382538752633,
      "grad_norm": 0.4389398992061615,
      "learning_rate": 7.887961746124736e-06,
      "loss": 0.2294,
      "step": 13339
    },
    {
      "epoch": 0.2112196589451684,
      "grad_norm": 0.47218167781829834,
      "learning_rate": 7.887803410548317e-06,
      "loss": 0.1518,
      "step": 13340
    },
    {
      "epoch": 0.21123549250281046,
      "grad_norm": 0.3607708811759949,
      "learning_rate": 7.887645074971896e-06,
      "loss": 0.2761,
      "step": 13341
    },
    {
      "epoch": 0.21125132606045252,
      "grad_norm": 0.28994184732437134,
      "learning_rate": 7.887486739395475e-06,
      "loss": 0.1831,
      "step": 13342
    },
    {
      "epoch": 0.21126715961809459,
      "grad_norm": 0.4193851053714752,
      "learning_rate": 7.887328403819054e-06,
      "loss": 0.2921,
      "step": 13343
    },
    {
      "epoch": 0.21128299317573665,
      "grad_norm": 0.4696420133113861,
      "learning_rate": 7.887170068242635e-06,
      "loss": 0.2253,
      "step": 13344
    },
    {
      "epoch": 0.21129882673337871,
      "grad_norm": 0.28619465231895447,
      "learning_rate": 7.887011732666212e-06,
      "loss": 0.2154,
      "step": 13345
    },
    {
      "epoch": 0.21131466029102078,
      "grad_norm": 0.43483614921569824,
      "learning_rate": 7.886853397089793e-06,
      "loss": 0.1708,
      "step": 13346
    },
    {
      "epoch": 0.21133049384866284,
      "grad_norm": 0.5379589200019836,
      "learning_rate": 7.886695061513372e-06,
      "loss": 0.0181,
      "step": 13347
    },
    {
      "epoch": 0.21134632740630493,
      "grad_norm": 0.7680440545082092,
      "learning_rate": 7.886536725936951e-06,
      "loss": 0.0441,
      "step": 13348
    },
    {
      "epoch": 0.211362160963947,
      "grad_norm": 0.0004613695782609284,
      "learning_rate": 7.88637839036053e-06,
      "loss": 0.0,
      "step": 13349
    },
    {
      "epoch": 0.21137799452158906,
      "grad_norm": 0.18079493939876556,
      "learning_rate": 7.886220054784111e-06,
      "loss": 0.0664,
      "step": 13350
    },
    {
      "epoch": 0.21139382807923113,
      "grad_norm": 0.45815327763557434,
      "learning_rate": 7.886061719207689e-06,
      "loss": 0.1882,
      "step": 13351
    },
    {
      "epoch": 0.2114096616368732,
      "grad_norm": 0.6063843965530396,
      "learning_rate": 7.88590338363127e-06,
      "loss": 0.4472,
      "step": 13352
    },
    {
      "epoch": 0.21142549519451526,
      "grad_norm": 0.40413883328437805,
      "learning_rate": 7.885745048054848e-06,
      "loss": 0.1384,
      "step": 13353
    },
    {
      "epoch": 0.21144132875215732,
      "grad_norm": 0.8137599229812622,
      "learning_rate": 7.885586712478428e-06,
      "loss": 0.616,
      "step": 13354
    },
    {
      "epoch": 0.21145716230979938,
      "grad_norm": 0.3664899468421936,
      "learning_rate": 7.885428376902007e-06,
      "loss": 0.139,
      "step": 13355
    },
    {
      "epoch": 0.21147299586744145,
      "grad_norm": 0.35293224453926086,
      "learning_rate": 7.885270041325586e-06,
      "loss": 0.1458,
      "step": 13356
    },
    {
      "epoch": 0.2114888294250835,
      "grad_norm": 0.044669680297374725,
      "learning_rate": 7.885111705749165e-06,
      "loss": 0.0026,
      "step": 13357
    },
    {
      "epoch": 0.21150466298272558,
      "grad_norm": 0.005196274258196354,
      "learning_rate": 7.884953370172744e-06,
      "loss": 0.0002,
      "step": 13358
    },
    {
      "epoch": 0.21152049654036764,
      "grad_norm": 0.0009715358610264957,
      "learning_rate": 7.884795034596325e-06,
      "loss": 0.0,
      "step": 13359
    },
    {
      "epoch": 0.21153633009800973,
      "grad_norm": 0.22788599133491516,
      "learning_rate": 7.884636699019904e-06,
      "loss": 0.148,
      "step": 13360
    },
    {
      "epoch": 0.2115521636556518,
      "grad_norm": 0.015716303139925003,
      "learning_rate": 7.884478363443483e-06,
      "loss": 0.0004,
      "step": 13361
    },
    {
      "epoch": 0.21156799721329386,
      "grad_norm": 0.27483007311820984,
      "learning_rate": 7.884320027867062e-06,
      "loss": 0.0909,
      "step": 13362
    },
    {
      "epoch": 0.21158383077093593,
      "grad_norm": 0.8373423218727112,
      "learning_rate": 7.884161692290641e-06,
      "loss": 0.2748,
      "step": 13363
    },
    {
      "epoch": 0.211599664328578,
      "grad_norm": 0.018479660153388977,
      "learning_rate": 7.88400335671422e-06,
      "loss": 0.0008,
      "step": 13364
    },
    {
      "epoch": 0.21161549788622006,
      "grad_norm": 0.00025931643904186785,
      "learning_rate": 7.8838450211378e-06,
      "loss": 0.0,
      "step": 13365
    },
    {
      "epoch": 0.21163133144386212,
      "grad_norm": 0.34122440218925476,
      "learning_rate": 7.88368668556138e-06,
      "loss": 0.2257,
      "step": 13366
    },
    {
      "epoch": 0.21164716500150418,
      "grad_norm": 0.009387162514030933,
      "learning_rate": 7.883528349984959e-06,
      "loss": 0.0005,
      "step": 13367
    },
    {
      "epoch": 0.21166299855914625,
      "grad_norm": 0.33818256855010986,
      "learning_rate": 7.883370014408538e-06,
      "loss": 0.1239,
      "step": 13368
    },
    {
      "epoch": 0.2116788321167883,
      "grad_norm": 0.6876329183578491,
      "learning_rate": 7.883211678832117e-06,
      "loss": 0.1952,
      "step": 13369
    },
    {
      "epoch": 0.21169466567443038,
      "grad_norm": 0.39833399653434753,
      "learning_rate": 7.883053343255696e-06,
      "loss": 0.2206,
      "step": 13370
    },
    {
      "epoch": 0.21171049923207244,
      "grad_norm": 0.03267928212881088,
      "learning_rate": 7.882895007679277e-06,
      "loss": 0.0031,
      "step": 13371
    },
    {
      "epoch": 0.21172633278971453,
      "grad_norm": 0.025282535701990128,
      "learning_rate": 7.882736672102856e-06,
      "loss": 0.0013,
      "step": 13372
    },
    {
      "epoch": 0.2117421663473566,
      "grad_norm": 0.5560580492019653,
      "learning_rate": 7.882578336526435e-06,
      "loss": 0.4776,
      "step": 13373
    },
    {
      "epoch": 0.21175799990499866,
      "grad_norm": 0.54649418592453,
      "learning_rate": 7.882420000950014e-06,
      "loss": 0.1716,
      "step": 13374
    },
    {
      "epoch": 0.21177383346264073,
      "grad_norm": 0.2481878101825714,
      "learning_rate": 7.882261665373593e-06,
      "loss": 0.0413,
      "step": 13375
    },
    {
      "epoch": 0.2117896670202828,
      "grad_norm": 0.37430819869041443,
      "learning_rate": 7.882103329797172e-06,
      "loss": 0.2292,
      "step": 13376
    },
    {
      "epoch": 0.21180550057792485,
      "grad_norm": 0.013704990968108177,
      "learning_rate": 7.881944994220753e-06,
      "loss": 0.0005,
      "step": 13377
    },
    {
      "epoch": 0.21182133413556692,
      "grad_norm": 0.19459427893161774,
      "learning_rate": 7.881786658644332e-06,
      "loss": 0.1185,
      "step": 13378
    },
    {
      "epoch": 0.21183716769320898,
      "grad_norm": 0.0003299918898846954,
      "learning_rate": 7.88162832306791e-06,
      "loss": 0.0,
      "step": 13379
    },
    {
      "epoch": 0.21185300125085105,
      "grad_norm": 0.5588390827178955,
      "learning_rate": 7.88146998749149e-06,
      "loss": 0.4046,
      "step": 13380
    },
    {
      "epoch": 0.2118688348084931,
      "grad_norm": 0.000506166834384203,
      "learning_rate": 7.88131165191507e-06,
      "loss": 0.0,
      "step": 13381
    },
    {
      "epoch": 0.21188466836613518,
      "grad_norm": 0.011946319602429867,
      "learning_rate": 7.881153316338649e-06,
      "loss": 0.0005,
      "step": 13382
    },
    {
      "epoch": 0.21190050192377724,
      "grad_norm": 0.018695535138249397,
      "learning_rate": 7.880994980762228e-06,
      "loss": 0.0005,
      "step": 13383
    },
    {
      "epoch": 0.21191633548141933,
      "grad_norm": 0.008527620695531368,
      "learning_rate": 7.880836645185808e-06,
      "loss": 0.0004,
      "step": 13384
    },
    {
      "epoch": 0.2119321690390614,
      "grad_norm": 0.00021204703080002218,
      "learning_rate": 7.880678309609386e-06,
      "loss": 0.0,
      "step": 13385
    },
    {
      "epoch": 0.21194800259670346,
      "grad_norm": 0.01601787842810154,
      "learning_rate": 7.880519974032967e-06,
      "loss": 0.0009,
      "step": 13386
    },
    {
      "epoch": 0.21196383615434553,
      "grad_norm": 0.4099165201187134,
      "learning_rate": 7.880361638456546e-06,
      "loss": 0.6082,
      "step": 13387
    },
    {
      "epoch": 0.2119796697119876,
      "grad_norm": 0.39796704053878784,
      "learning_rate": 7.880203302880125e-06,
      "loss": 0.1564,
      "step": 13388
    },
    {
      "epoch": 0.21199550326962965,
      "grad_norm": 0.020128238946199417,
      "learning_rate": 7.880044967303704e-06,
      "loss": 0.001,
      "step": 13389
    },
    {
      "epoch": 0.21201133682727172,
      "grad_norm": 0.6434528827667236,
      "learning_rate": 7.879886631727285e-06,
      "loss": 0.2611,
      "step": 13390
    },
    {
      "epoch": 0.21202717038491378,
      "grad_norm": 0.34377342462539673,
      "learning_rate": 7.879728296150862e-06,
      "loss": 0.1737,
      "step": 13391
    },
    {
      "epoch": 0.21204300394255585,
      "grad_norm": 0.18673120439052582,
      "learning_rate": 7.879569960574443e-06,
      "loss": 0.0458,
      "step": 13392
    },
    {
      "epoch": 0.2120588375001979,
      "grad_norm": 0.28136318922042847,
      "learning_rate": 7.879411624998022e-06,
      "loss": 0.3198,
      "step": 13393
    },
    {
      "epoch": 0.21207467105783998,
      "grad_norm": 0.24478457868099213,
      "learning_rate": 7.879253289421601e-06,
      "loss": 0.1478,
      "step": 13394
    },
    {
      "epoch": 0.21209050461548204,
      "grad_norm": 0.3501996695995331,
      "learning_rate": 7.87909495384518e-06,
      "loss": 0.1468,
      "step": 13395
    },
    {
      "epoch": 0.21210633817312413,
      "grad_norm": 1.4429324865341187,
      "learning_rate": 7.87893661826876e-06,
      "loss": 0.7549,
      "step": 13396
    },
    {
      "epoch": 0.2121221717307662,
      "grad_norm": 0.48932263255119324,
      "learning_rate": 7.878778282692338e-06,
      "loss": 0.1932,
      "step": 13397
    },
    {
      "epoch": 0.21213800528840826,
      "grad_norm": 0.7111250162124634,
      "learning_rate": 7.878619947115919e-06,
      "loss": 0.1635,
      "step": 13398
    },
    {
      "epoch": 0.21215383884605032,
      "grad_norm": 0.00028360847500152886,
      "learning_rate": 7.878461611539498e-06,
      "loss": 0.0,
      "step": 13399
    },
    {
      "epoch": 0.2121696724036924,
      "grad_norm": 0.17923231422901154,
      "learning_rate": 7.878303275963077e-06,
      "loss": 0.0136,
      "step": 13400
    },
    {
      "epoch": 0.21218550596133445,
      "grad_norm": 0.9634928703308105,
      "learning_rate": 7.878144940386656e-06,
      "loss": 0.5365,
      "step": 13401
    },
    {
      "epoch": 0.21220133951897652,
      "grad_norm": 0.00042787790880538523,
      "learning_rate": 7.877986604810235e-06,
      "loss": 0.0,
      "step": 13402
    },
    {
      "epoch": 0.21221717307661858,
      "grad_norm": 0.017127100378274918,
      "learning_rate": 7.877828269233814e-06,
      "loss": 0.0006,
      "step": 13403
    },
    {
      "epoch": 0.21223300663426065,
      "grad_norm": 0.7562978267669678,
      "learning_rate": 7.877669933657393e-06,
      "loss": 0.4533,
      "step": 13404
    },
    {
      "epoch": 0.2122488401919027,
      "grad_norm": 0.26849544048309326,
      "learning_rate": 7.877511598080974e-06,
      "loss": 0.004,
      "step": 13405
    },
    {
      "epoch": 0.21226467374954477,
      "grad_norm": 1.6100934743881226,
      "learning_rate": 7.877353262504552e-06,
      "loss": 0.716,
      "step": 13406
    },
    {
      "epoch": 0.21228050730718684,
      "grad_norm": 0.7206774950027466,
      "learning_rate": 7.877194926928132e-06,
      "loss": 0.1706,
      "step": 13407
    },
    {
      "epoch": 0.21229634086482893,
      "grad_norm": 0.6510760188102722,
      "learning_rate": 7.877036591351711e-06,
      "loss": 0.1474,
      "step": 13408
    },
    {
      "epoch": 0.212312174422471,
      "grad_norm": 0.20928175747394562,
      "learning_rate": 7.87687825577529e-06,
      "loss": 0.0526,
      "step": 13409
    },
    {
      "epoch": 0.21232800798011306,
      "grad_norm": 0.00039985726471059024,
      "learning_rate": 7.87671992019887e-06,
      "loss": 0.0,
      "step": 13410
    },
    {
      "epoch": 0.21234384153775512,
      "grad_norm": 0.2389894276857376,
      "learning_rate": 7.87656158462245e-06,
      "loss": 0.0283,
      "step": 13411
    },
    {
      "epoch": 0.2123596750953972,
      "grad_norm": 0.742989182472229,
      "learning_rate": 7.876403249046028e-06,
      "loss": 0.2211,
      "step": 13412
    },
    {
      "epoch": 0.21237550865303925,
      "grad_norm": 0.35773155093193054,
      "learning_rate": 7.876244913469608e-06,
      "loss": 0.0371,
      "step": 13413
    },
    {
      "epoch": 0.21239134221068132,
      "grad_norm": 0.35072851181030273,
      "learning_rate": 7.876086577893188e-06,
      "loss": 0.0388,
      "step": 13414
    },
    {
      "epoch": 0.21240717576832338,
      "grad_norm": 0.00027007641620002687,
      "learning_rate": 7.875928242316767e-06,
      "loss": 0.0,
      "step": 13415
    },
    {
      "epoch": 0.21242300932596545,
      "grad_norm": 0.0413927398622036,
      "learning_rate": 7.875769906740346e-06,
      "loss": 0.0021,
      "step": 13416
    },
    {
      "epoch": 0.2124388428836075,
      "grad_norm": 0.01989007741212845,
      "learning_rate": 7.875611571163926e-06,
      "loss": 0.0011,
      "step": 13417
    },
    {
      "epoch": 0.21245467644124957,
      "grad_norm": 0.3235125243663788,
      "learning_rate": 7.875453235587504e-06,
      "loss": 0.1479,
      "step": 13418
    },
    {
      "epoch": 0.21247050999889164,
      "grad_norm": 0.3322630226612091,
      "learning_rate": 7.875294900011085e-06,
      "loss": 0.0082,
      "step": 13419
    },
    {
      "epoch": 0.21248634355653373,
      "grad_norm": 0.8212773203849792,
      "learning_rate": 7.875136564434664e-06,
      "loss": 0.1406,
      "step": 13420
    },
    {
      "epoch": 0.2125021771141758,
      "grad_norm": 0.4889930486679077,
      "learning_rate": 7.874978228858243e-06,
      "loss": 0.1123,
      "step": 13421
    },
    {
      "epoch": 0.21251801067181786,
      "grad_norm": 0.3802288770675659,
      "learning_rate": 7.874819893281822e-06,
      "loss": 0.1114,
      "step": 13422
    },
    {
      "epoch": 0.21253384422945992,
      "grad_norm": 0.02152263931930065,
      "learning_rate": 7.874661557705403e-06,
      "loss": 0.0009,
      "step": 13423
    },
    {
      "epoch": 0.212549677787102,
      "grad_norm": 1.190125823020935,
      "learning_rate": 7.87450322212898e-06,
      "loss": 0.0713,
      "step": 13424
    },
    {
      "epoch": 0.21256551134474405,
      "grad_norm": 0.45883530378341675,
      "learning_rate": 7.87434488655256e-06,
      "loss": 0.1114,
      "step": 13425
    },
    {
      "epoch": 0.21258134490238612,
      "grad_norm": 0.7383802533149719,
      "learning_rate": 7.87418655097614e-06,
      "loss": 0.9374,
      "step": 13426
    },
    {
      "epoch": 0.21259717846002818,
      "grad_norm": 0.32131537795066833,
      "learning_rate": 7.874028215399719e-06,
      "loss": 0.1122,
      "step": 13427
    },
    {
      "epoch": 0.21261301201767024,
      "grad_norm": 0.6114351153373718,
      "learning_rate": 7.873869879823298e-06,
      "loss": 0.4635,
      "step": 13428
    },
    {
      "epoch": 0.2126288455753123,
      "grad_norm": 0.18956021964550018,
      "learning_rate": 7.873711544246877e-06,
      "loss": 0.0783,
      "step": 13429
    },
    {
      "epoch": 0.21264467913295437,
      "grad_norm": 0.022002320736646652,
      "learning_rate": 7.873553208670456e-06,
      "loss": 0.0011,
      "step": 13430
    },
    {
      "epoch": 0.21266051269059644,
      "grad_norm": 0.010942808352410793,
      "learning_rate": 7.873394873094035e-06,
      "loss": 0.0004,
      "step": 13431
    },
    {
      "epoch": 0.21267634624823853,
      "grad_norm": 0.2492375671863556,
      "learning_rate": 7.873236537517616e-06,
      "loss": 0.0203,
      "step": 13432
    },
    {
      "epoch": 0.2126921798058806,
      "grad_norm": 0.0003981078916694969,
      "learning_rate": 7.873078201941195e-06,
      "loss": 0.0,
      "step": 13433
    },
    {
      "epoch": 0.21270801336352266,
      "grad_norm": 0.37998726963996887,
      "learning_rate": 7.872919866364774e-06,
      "loss": 0.1202,
      "step": 13434
    },
    {
      "epoch": 0.21272384692116472,
      "grad_norm": 0.444208562374115,
      "learning_rate": 7.872761530788353e-06,
      "loss": 0.3539,
      "step": 13435
    },
    {
      "epoch": 0.2127396804788068,
      "grad_norm": 0.5336521863937378,
      "learning_rate": 7.872603195211932e-06,
      "loss": 0.3075,
      "step": 13436
    },
    {
      "epoch": 0.21275551403644885,
      "grad_norm": 0.0002014072088059038,
      "learning_rate": 7.872444859635511e-06,
      "loss": 0.0,
      "step": 13437
    },
    {
      "epoch": 0.21277134759409091,
      "grad_norm": 0.43467193841934204,
      "learning_rate": 7.872286524059092e-06,
      "loss": 0.2796,
      "step": 13438
    },
    {
      "epoch": 0.21278718115173298,
      "grad_norm": 0.18949754536151886,
      "learning_rate": 7.872128188482671e-06,
      "loss": 0.057,
      "step": 13439
    },
    {
      "epoch": 0.21280301470937504,
      "grad_norm": 0.22962091863155365,
      "learning_rate": 7.87196985290625e-06,
      "loss": 0.1158,
      "step": 13440
    },
    {
      "epoch": 0.2128188482670171,
      "grad_norm": 0.20078818500041962,
      "learning_rate": 7.87181151732983e-06,
      "loss": 0.0619,
      "step": 13441
    },
    {
      "epoch": 0.21283468182465917,
      "grad_norm": 0.3305976688861847,
      "learning_rate": 7.871653181753409e-06,
      "loss": 0.0071,
      "step": 13442
    },
    {
      "epoch": 0.21285051538230124,
      "grad_norm": 0.22719663381576538,
      "learning_rate": 7.871494846176988e-06,
      "loss": 0.0548,
      "step": 13443
    },
    {
      "epoch": 0.21286634893994333,
      "grad_norm": 0.30869776010513306,
      "learning_rate": 7.871336510600568e-06,
      "loss": 0.0943,
      "step": 13444
    },
    {
      "epoch": 0.2128821824975854,
      "grad_norm": 0.0002272381680086255,
      "learning_rate": 7.871178175024147e-06,
      "loss": 0.0,
      "step": 13445
    },
    {
      "epoch": 0.21289801605522746,
      "grad_norm": 0.31828486919403076,
      "learning_rate": 7.871019839447727e-06,
      "loss": 0.1567,
      "step": 13446
    },
    {
      "epoch": 0.21291384961286952,
      "grad_norm": 0.4121965765953064,
      "learning_rate": 7.870861503871306e-06,
      "loss": 0.2416,
      "step": 13447
    },
    {
      "epoch": 0.21292968317051159,
      "grad_norm": 1.031606912612915,
      "learning_rate": 7.870703168294885e-06,
      "loss": 0.0306,
      "step": 13448
    },
    {
      "epoch": 0.21294551672815365,
      "grad_norm": 0.2669958770275116,
      "learning_rate": 7.870544832718464e-06,
      "loss": 0.0146,
      "step": 13449
    },
    {
      "epoch": 0.21296135028579571,
      "grad_norm": 0.19108183681964874,
      "learning_rate": 7.870386497142043e-06,
      "loss": 0.0226,
      "step": 13450
    },
    {
      "epoch": 0.21297718384343778,
      "grad_norm": 0.04123218357563019,
      "learning_rate": 7.870228161565624e-06,
      "loss": 0.0018,
      "step": 13451
    },
    {
      "epoch": 0.21299301740107984,
      "grad_norm": 0.2268465906381607,
      "learning_rate": 7.870069825989201e-06,
      "loss": 0.0867,
      "step": 13452
    },
    {
      "epoch": 0.2130088509587219,
      "grad_norm": 0.03447873890399933,
      "learning_rate": 7.869911490412782e-06,
      "loss": 0.0011,
      "step": 13453
    },
    {
      "epoch": 0.21302468451636397,
      "grad_norm": 0.0005326028913259506,
      "learning_rate": 7.869753154836361e-06,
      "loss": 0.0,
      "step": 13454
    },
    {
      "epoch": 0.21304051807400604,
      "grad_norm": 2.728822946548462,
      "learning_rate": 7.86959481925994e-06,
      "loss": 0.1899,
      "step": 13455
    },
    {
      "epoch": 0.21305635163164813,
      "grad_norm": 0.18547622859477997,
      "learning_rate": 7.869436483683519e-06,
      "loss": 0.0382,
      "step": 13456
    },
    {
      "epoch": 0.2130721851892902,
      "grad_norm": 0.1707402616739273,
      "learning_rate": 7.8692781481071e-06,
      "loss": 0.0499,
      "step": 13457
    },
    {
      "epoch": 0.21308801874693226,
      "grad_norm": 0.007912199012935162,
      "learning_rate": 7.869119812530677e-06,
      "loss": 0.0004,
      "step": 13458
    },
    {
      "epoch": 0.21310385230457432,
      "grad_norm": 0.4908868670463562,
      "learning_rate": 7.868961476954258e-06,
      "loss": 0.1789,
      "step": 13459
    },
    {
      "epoch": 0.21311968586221638,
      "grad_norm": 0.20447930693626404,
      "learning_rate": 7.868803141377837e-06,
      "loss": 0.116,
      "step": 13460
    },
    {
      "epoch": 0.21313551941985845,
      "grad_norm": 0.22969090938568115,
      "learning_rate": 7.868644805801416e-06,
      "loss": 0.055,
      "step": 13461
    },
    {
      "epoch": 0.2131513529775005,
      "grad_norm": 0.6109814047813416,
      "learning_rate": 7.868486470224995e-06,
      "loss": 0.4838,
      "step": 13462
    },
    {
      "epoch": 0.21316718653514258,
      "grad_norm": 0.7223448157310486,
      "learning_rate": 7.868328134648576e-06,
      "loss": 0.2154,
      "step": 13463
    },
    {
      "epoch": 0.21318302009278464,
      "grad_norm": 0.3308790624141693,
      "learning_rate": 7.868169799072153e-06,
      "loss": 0.1292,
      "step": 13464
    },
    {
      "epoch": 0.2131988536504267,
      "grad_norm": 0.3561911880970001,
      "learning_rate": 7.868011463495734e-06,
      "loss": 0.101,
      "step": 13465
    },
    {
      "epoch": 0.21321468720806877,
      "grad_norm": 0.3089970350265503,
      "learning_rate": 7.867853127919313e-06,
      "loss": 0.264,
      "step": 13466
    },
    {
      "epoch": 0.21323052076571083,
      "grad_norm": 0.5037330389022827,
      "learning_rate": 7.867694792342892e-06,
      "loss": 0.3722,
      "step": 13467
    },
    {
      "epoch": 0.21324635432335293,
      "grad_norm": 0.6837175488471985,
      "learning_rate": 7.867536456766471e-06,
      "loss": 0.8947,
      "step": 13468
    },
    {
      "epoch": 0.213262187880995,
      "grad_norm": 0.3912769854068756,
      "learning_rate": 7.86737812119005e-06,
      "loss": 0.1178,
      "step": 13469
    },
    {
      "epoch": 0.21327802143863706,
      "grad_norm": 0.19522203505039215,
      "learning_rate": 7.86721978561363e-06,
      "loss": 0.0903,
      "step": 13470
    },
    {
      "epoch": 0.21329385499627912,
      "grad_norm": 0.5423792600631714,
      "learning_rate": 7.86706145003721e-06,
      "loss": 0.0574,
      "step": 13471
    },
    {
      "epoch": 0.21330968855392118,
      "grad_norm": 0.44442108273506165,
      "learning_rate": 7.86690311446079e-06,
      "loss": 0.4252,
      "step": 13472
    },
    {
      "epoch": 0.21332552211156325,
      "grad_norm": 2.371816635131836,
      "learning_rate": 7.866744778884368e-06,
      "loss": 0.3616,
      "step": 13473
    },
    {
      "epoch": 0.2133413556692053,
      "grad_norm": 0.05923319235444069,
      "learning_rate": 7.866586443307948e-06,
      "loss": 0.0019,
      "step": 13474
    },
    {
      "epoch": 0.21335718922684738,
      "grad_norm": 0.6025694608688354,
      "learning_rate": 7.866428107731527e-06,
      "loss": 0.4013,
      "step": 13475
    },
    {
      "epoch": 0.21337302278448944,
      "grad_norm": 0.33507654070854187,
      "learning_rate": 7.866269772155106e-06,
      "loss": 0.8991,
      "step": 13476
    },
    {
      "epoch": 0.2133888563421315,
      "grad_norm": 0.34674885869026184,
      "learning_rate": 7.866111436578685e-06,
      "loss": 0.0496,
      "step": 13477
    },
    {
      "epoch": 0.21340468989977357,
      "grad_norm": 0.0005375848268158734,
      "learning_rate": 7.865953101002266e-06,
      "loss": 0.0,
      "step": 13478
    },
    {
      "epoch": 0.21342052345741563,
      "grad_norm": 0.2039940506219864,
      "learning_rate": 7.865794765425843e-06,
      "loss": 0.0399,
      "step": 13479
    },
    {
      "epoch": 0.21343635701505773,
      "grad_norm": 0.7458152770996094,
      "learning_rate": 7.865636429849424e-06,
      "loss": 0.2946,
      "step": 13480
    },
    {
      "epoch": 0.2134521905726998,
      "grad_norm": 0.41105759143829346,
      "learning_rate": 7.865478094273003e-06,
      "loss": 0.1202,
      "step": 13481
    },
    {
      "epoch": 0.21346802413034185,
      "grad_norm": 0.0004290337674319744,
      "learning_rate": 7.865319758696582e-06,
      "loss": 0.0,
      "step": 13482
    },
    {
      "epoch": 0.21348385768798392,
      "grad_norm": 0.00019605095440056175,
      "learning_rate": 7.865161423120161e-06,
      "loss": 0.0,
      "step": 13483
    },
    {
      "epoch": 0.21349969124562598,
      "grad_norm": 0.561999499797821,
      "learning_rate": 7.865003087543742e-06,
      "loss": 0.5743,
      "step": 13484
    },
    {
      "epoch": 0.21351552480326805,
      "grad_norm": 1.0271586179733276,
      "learning_rate": 7.864844751967319e-06,
      "loss": 0.4878,
      "step": 13485
    },
    {
      "epoch": 0.2135313583609101,
      "grad_norm": 0.5296825170516968,
      "learning_rate": 7.8646864163909e-06,
      "loss": 0.2676,
      "step": 13486
    },
    {
      "epoch": 0.21354719191855218,
      "grad_norm": 0.5000890493392944,
      "learning_rate": 7.864528080814479e-06,
      "loss": 0.3611,
      "step": 13487
    },
    {
      "epoch": 0.21356302547619424,
      "grad_norm": 0.2137213498353958,
      "learning_rate": 7.864369745238058e-06,
      "loss": 0.0381,
      "step": 13488
    },
    {
      "epoch": 0.2135788590338363,
      "grad_norm": 0.41068753600120544,
      "learning_rate": 7.864211409661637e-06,
      "loss": 0.3477,
      "step": 13489
    },
    {
      "epoch": 0.21359469259147837,
      "grad_norm": 0.6474025249481201,
      "learning_rate": 7.864053074085218e-06,
      "loss": 0.1254,
      "step": 13490
    },
    {
      "epoch": 0.21361052614912043,
      "grad_norm": 0.16855768859386444,
      "learning_rate": 7.863894738508795e-06,
      "loss": 0.0735,
      "step": 13491
    },
    {
      "epoch": 0.21362635970676253,
      "grad_norm": 0.6256810426712036,
      "learning_rate": 7.863736402932376e-06,
      "loss": 0.0917,
      "step": 13492
    },
    {
      "epoch": 0.2136421932644046,
      "grad_norm": 0.5846006274223328,
      "learning_rate": 7.863578067355955e-06,
      "loss": 0.2089,
      "step": 13493
    },
    {
      "epoch": 0.21365802682204665,
      "grad_norm": 0.3445967435836792,
      "learning_rate": 7.863419731779534e-06,
      "loss": 0.1636,
      "step": 13494
    },
    {
      "epoch": 0.21367386037968872,
      "grad_norm": 0.5996257066726685,
      "learning_rate": 7.863261396203113e-06,
      "loss": 0.27,
      "step": 13495
    },
    {
      "epoch": 0.21368969393733078,
      "grad_norm": 0.2045898139476776,
      "learning_rate": 7.863103060626694e-06,
      "loss": 0.0423,
      "step": 13496
    },
    {
      "epoch": 0.21370552749497285,
      "grad_norm": 0.0003154792939312756,
      "learning_rate": 7.862944725050271e-06,
      "loss": 0.0,
      "step": 13497
    },
    {
      "epoch": 0.2137213610526149,
      "grad_norm": 0.4610987603664398,
      "learning_rate": 7.86278638947385e-06,
      "loss": 0.1855,
      "step": 13498
    },
    {
      "epoch": 0.21373719461025698,
      "grad_norm": 0.007463651709258556,
      "learning_rate": 7.862628053897431e-06,
      "loss": 0.0003,
      "step": 13499
    },
    {
      "epoch": 0.21375302816789904,
      "grad_norm": 0.2233555167913437,
      "learning_rate": 7.86246971832101e-06,
      "loss": 0.0434,
      "step": 13500
    },
    {
      "epoch": 0.2137688617255411,
      "grad_norm": 0.6473827958106995,
      "learning_rate": 7.86231138274459e-06,
      "loss": 0.1502,
      "step": 13501
    },
    {
      "epoch": 0.21378469528318317,
      "grad_norm": 0.24261558055877686,
      "learning_rate": 7.862153047168169e-06,
      "loss": 0.0664,
      "step": 13502
    },
    {
      "epoch": 0.21380052884082523,
      "grad_norm": 0.47207406163215637,
      "learning_rate": 7.861994711591748e-06,
      "loss": 0.1159,
      "step": 13503
    },
    {
      "epoch": 0.21381636239846732,
      "grad_norm": 0.4179324209690094,
      "learning_rate": 7.861836376015327e-06,
      "loss": 0.5835,
      "step": 13504
    },
    {
      "epoch": 0.2138321959561094,
      "grad_norm": 0.0031956203747540712,
      "learning_rate": 7.861678040438907e-06,
      "loss": 0.0,
      "step": 13505
    },
    {
      "epoch": 0.21384802951375145,
      "grad_norm": 0.028679385781288147,
      "learning_rate": 7.861519704862487e-06,
      "loss": 0.0015,
      "step": 13506
    },
    {
      "epoch": 0.21386386307139352,
      "grad_norm": 0.13090813159942627,
      "learning_rate": 7.861361369286066e-06,
      "loss": 0.0157,
      "step": 13507
    },
    {
      "epoch": 0.21387969662903558,
      "grad_norm": 0.44923919439315796,
      "learning_rate": 7.861203033709645e-06,
      "loss": 0.333,
      "step": 13508
    },
    {
      "epoch": 0.21389553018667765,
      "grad_norm": 0.00017511611804366112,
      "learning_rate": 7.861044698133224e-06,
      "loss": 0.0,
      "step": 13509
    },
    {
      "epoch": 0.2139113637443197,
      "grad_norm": 0.0008749081753194332,
      "learning_rate": 7.860886362556803e-06,
      "loss": 0.0,
      "step": 13510
    },
    {
      "epoch": 0.21392719730196177,
      "grad_norm": 0.00030088392668403685,
      "learning_rate": 7.860728026980384e-06,
      "loss": 0.0,
      "step": 13511
    },
    {
      "epoch": 0.21394303085960384,
      "grad_norm": 0.0006634750170633197,
      "learning_rate": 7.860569691403963e-06,
      "loss": 0.0,
      "step": 13512
    },
    {
      "epoch": 0.2139588644172459,
      "grad_norm": 0.24885329604148865,
      "learning_rate": 7.860411355827542e-06,
      "loss": 0.0949,
      "step": 13513
    },
    {
      "epoch": 0.21397469797488797,
      "grad_norm": 0.404248982667923,
      "learning_rate": 7.860253020251121e-06,
      "loss": 0.0107,
      "step": 13514
    },
    {
      "epoch": 0.21399053153253003,
      "grad_norm": 0.24645960330963135,
      "learning_rate": 7.8600946846747e-06,
      "loss": 0.0641,
      "step": 13515
    },
    {
      "epoch": 0.21400636509017212,
      "grad_norm": 0.2384229451417923,
      "learning_rate": 7.859936349098279e-06,
      "loss": 0.0783,
      "step": 13516
    },
    {
      "epoch": 0.2140221986478142,
      "grad_norm": 0.0004920794162899256,
      "learning_rate": 7.85977801352186e-06,
      "loss": 0.0,
      "step": 13517
    },
    {
      "epoch": 0.21403803220545625,
      "grad_norm": 0.008604157716035843,
      "learning_rate": 7.859619677945439e-06,
      "loss": 0.0004,
      "step": 13518
    },
    {
      "epoch": 0.21405386576309832,
      "grad_norm": 1.008931279182434,
      "learning_rate": 7.859461342369018e-06,
      "loss": 0.5248,
      "step": 13519
    },
    {
      "epoch": 0.21406969932074038,
      "grad_norm": 0.5184038877487183,
      "learning_rate": 7.859303006792597e-06,
      "loss": 0.1668,
      "step": 13520
    },
    {
      "epoch": 0.21408553287838245,
      "grad_norm": 0.2239316701889038,
      "learning_rate": 7.859144671216176e-06,
      "loss": 0.0369,
      "step": 13521
    },
    {
      "epoch": 0.2141013664360245,
      "grad_norm": 0.7844935655593872,
      "learning_rate": 7.858986335639755e-06,
      "loss": 0.3929,
      "step": 13522
    },
    {
      "epoch": 0.21411719999366657,
      "grad_norm": 0.015341666527092457,
      "learning_rate": 7.858828000063334e-06,
      "loss": 0.0007,
      "step": 13523
    },
    {
      "epoch": 0.21413303355130864,
      "grad_norm": 0.0003825821040663868,
      "learning_rate": 7.858669664486915e-06,
      "loss": 0.0,
      "step": 13524
    },
    {
      "epoch": 0.2141488671089507,
      "grad_norm": 0.00011520526459207758,
      "learning_rate": 7.858511328910492e-06,
      "loss": 0.0,
      "step": 13525
    },
    {
      "epoch": 0.21416470066659277,
      "grad_norm": 0.0002318011102033779,
      "learning_rate": 7.858352993334073e-06,
      "loss": 0.0,
      "step": 13526
    },
    {
      "epoch": 0.21418053422423483,
      "grad_norm": 0.0005467088776640594,
      "learning_rate": 7.858194657757652e-06,
      "loss": 0.0,
      "step": 13527
    },
    {
      "epoch": 0.21419636778187692,
      "grad_norm": 0.1954541951417923,
      "learning_rate": 7.858036322181231e-06,
      "loss": 0.0625,
      "step": 13528
    },
    {
      "epoch": 0.214212201339519,
      "grad_norm": 0.2756987512111664,
      "learning_rate": 7.85787798660481e-06,
      "loss": 0.0514,
      "step": 13529
    },
    {
      "epoch": 0.21422803489716105,
      "grad_norm": 0.6872860193252563,
      "learning_rate": 7.85771965102839e-06,
      "loss": 0.1192,
      "step": 13530
    },
    {
      "epoch": 0.21424386845480312,
      "grad_norm": 0.22663959860801697,
      "learning_rate": 7.857561315451969e-06,
      "loss": 0.0164,
      "step": 13531
    },
    {
      "epoch": 0.21425970201244518,
      "grad_norm": 0.5259947776794434,
      "learning_rate": 7.85740297987555e-06,
      "loss": 0.0362,
      "step": 13532
    },
    {
      "epoch": 0.21427553557008724,
      "grad_norm": 0.3925759196281433,
      "learning_rate": 7.857244644299128e-06,
      "loss": 0.1601,
      "step": 13533
    },
    {
      "epoch": 0.2142913691277293,
      "grad_norm": 0.001308754668571055,
      "learning_rate": 7.857086308722708e-06,
      "loss": 0.0,
      "step": 13534
    },
    {
      "epoch": 0.21430720268537137,
      "grad_norm": 0.016318587586283684,
      "learning_rate": 7.856927973146287e-06,
      "loss": 0.0009,
      "step": 13535
    },
    {
      "epoch": 0.21432303624301344,
      "grad_norm": 1.905970573425293,
      "learning_rate": 7.856769637569866e-06,
      "loss": 0.3191,
      "step": 13536
    },
    {
      "epoch": 0.2143388698006555,
      "grad_norm": 0.00985503476113081,
      "learning_rate": 7.856611301993445e-06,
      "loss": 0.0004,
      "step": 13537
    },
    {
      "epoch": 0.21435470335829757,
      "grad_norm": 0.01752413809299469,
      "learning_rate": 7.856452966417026e-06,
      "loss": 0.0011,
      "step": 13538
    },
    {
      "epoch": 0.21437053691593963,
      "grad_norm": 0.00023423867241945118,
      "learning_rate": 7.856294630840605e-06,
      "loss": 0.0,
      "step": 13539
    },
    {
      "epoch": 0.21438637047358172,
      "grad_norm": 0.14697015285491943,
      "learning_rate": 7.856136295264184e-06,
      "loss": 0.024,
      "step": 13540
    },
    {
      "epoch": 0.2144022040312238,
      "grad_norm": 0.5725761651992798,
      "learning_rate": 7.855977959687763e-06,
      "loss": 0.5335,
      "step": 13541
    },
    {
      "epoch": 0.21441803758886585,
      "grad_norm": 0.5290673971176147,
      "learning_rate": 7.855819624111342e-06,
      "loss": 0.3248,
      "step": 13542
    },
    {
      "epoch": 0.21443387114650792,
      "grad_norm": 0.015609187074005604,
      "learning_rate": 7.855661288534921e-06,
      "loss": 0.0008,
      "step": 13543
    },
    {
      "epoch": 0.21444970470414998,
      "grad_norm": 0.307040810585022,
      "learning_rate": 7.855502952958502e-06,
      "loss": 0.0779,
      "step": 13544
    },
    {
      "epoch": 0.21446553826179204,
      "grad_norm": 0.004509991034865379,
      "learning_rate": 7.85534461738208e-06,
      "loss": 0.0002,
      "step": 13545
    },
    {
      "epoch": 0.2144813718194341,
      "grad_norm": 0.5982952117919922,
      "learning_rate": 7.855186281805658e-06,
      "loss": 0.2038,
      "step": 13546
    },
    {
      "epoch": 0.21449720537707617,
      "grad_norm": 0.6807988882064819,
      "learning_rate": 7.855027946229239e-06,
      "loss": 0.5983,
      "step": 13547
    },
    {
      "epoch": 0.21451303893471824,
      "grad_norm": 0.0002091705537168309,
      "learning_rate": 7.854869610652818e-06,
      "loss": 0.0,
      "step": 13548
    },
    {
      "epoch": 0.2145288724923603,
      "grad_norm": 0.4980146884918213,
      "learning_rate": 7.854711275076397e-06,
      "loss": 0.1771,
      "step": 13549
    },
    {
      "epoch": 0.21454470605000237,
      "grad_norm": 0.4818044900894165,
      "learning_rate": 7.854552939499976e-06,
      "loss": 0.1793,
      "step": 13550
    },
    {
      "epoch": 0.21456053960764443,
      "grad_norm": 0.39355263113975525,
      "learning_rate": 7.854394603923557e-06,
      "loss": 0.1884,
      "step": 13551
    },
    {
      "epoch": 0.21457637316528652,
      "grad_norm": 0.18949531018733978,
      "learning_rate": 7.854236268347134e-06,
      "loss": 0.0501,
      "step": 13552
    },
    {
      "epoch": 0.21459220672292859,
      "grad_norm": 0.35067468881607056,
      "learning_rate": 7.854077932770715e-06,
      "loss": 0.1236,
      "step": 13553
    },
    {
      "epoch": 0.21460804028057065,
      "grad_norm": 0.05302245542407036,
      "learning_rate": 7.853919597194294e-06,
      "loss": 0.0033,
      "step": 13554
    },
    {
      "epoch": 0.21462387383821271,
      "grad_norm": 0.2712601125240326,
      "learning_rate": 7.853761261617873e-06,
      "loss": 0.1217,
      "step": 13555
    },
    {
      "epoch": 0.21463970739585478,
      "grad_norm": 0.4298660457134247,
      "learning_rate": 7.853602926041452e-06,
      "loss": 0.3326,
      "step": 13556
    },
    {
      "epoch": 0.21465554095349684,
      "grad_norm": 0.024212917312979698,
      "learning_rate": 7.853444590465033e-06,
      "loss": 0.0014,
      "step": 13557
    },
    {
      "epoch": 0.2146713745111389,
      "grad_norm": 0.00019516024622134864,
      "learning_rate": 7.85328625488861e-06,
      "loss": 0.0,
      "step": 13558
    },
    {
      "epoch": 0.21468720806878097,
      "grad_norm": 0.5318852066993713,
      "learning_rate": 7.853127919312191e-06,
      "loss": 0.6398,
      "step": 13559
    },
    {
      "epoch": 0.21470304162642304,
      "grad_norm": 0.280695378780365,
      "learning_rate": 7.85296958373577e-06,
      "loss": 0.143,
      "step": 13560
    },
    {
      "epoch": 0.2147188751840651,
      "grad_norm": 0.2982379198074341,
      "learning_rate": 7.85281124815935e-06,
      "loss": 0.048,
      "step": 13561
    },
    {
      "epoch": 0.21473470874170716,
      "grad_norm": 1.5919429063796997,
      "learning_rate": 7.852652912582929e-06,
      "loss": 0.9798,
      "step": 13562
    },
    {
      "epoch": 0.21475054229934923,
      "grad_norm": 0.6171838045120239,
      "learning_rate": 7.85249457700651e-06,
      "loss": 0.8352,
      "step": 13563
    },
    {
      "epoch": 0.21476637585699132,
      "grad_norm": 0.6056410670280457,
      "learning_rate": 7.852336241430087e-06,
      "loss": 0.306,
      "step": 13564
    },
    {
      "epoch": 0.21478220941463338,
      "grad_norm": 0.16805966198444366,
      "learning_rate": 7.852177905853668e-06,
      "loss": 0.0036,
      "step": 13565
    },
    {
      "epoch": 0.21479804297227545,
      "grad_norm": 0.36293479800224304,
      "learning_rate": 7.852019570277247e-06,
      "loss": 0.102,
      "step": 13566
    },
    {
      "epoch": 0.2148138765299175,
      "grad_norm": 0.29030734300613403,
      "learning_rate": 7.851861234700826e-06,
      "loss": 0.1174,
      "step": 13567
    },
    {
      "epoch": 0.21482971008755958,
      "grad_norm": 0.0002445794816594571,
      "learning_rate": 7.851702899124405e-06,
      "loss": 0.0,
      "step": 13568
    },
    {
      "epoch": 0.21484554364520164,
      "grad_norm": 0.00031438382575288415,
      "learning_rate": 7.851544563547986e-06,
      "loss": 0.0,
      "step": 13569
    },
    {
      "epoch": 0.2148613772028437,
      "grad_norm": 0.4703485667705536,
      "learning_rate": 7.851386227971563e-06,
      "loss": 0.089,
      "step": 13570
    },
    {
      "epoch": 0.21487721076048577,
      "grad_norm": 0.004467891529202461,
      "learning_rate": 7.851227892395142e-06,
      "loss": 0.0002,
      "step": 13571
    },
    {
      "epoch": 0.21489304431812783,
      "grad_norm": 0.002217987086623907,
      "learning_rate": 7.851069556818723e-06,
      "loss": 0.0,
      "step": 13572
    },
    {
      "epoch": 0.2149088778757699,
      "grad_norm": 0.009595212526619434,
      "learning_rate": 7.850911221242302e-06,
      "loss": 0.0003,
      "step": 13573
    },
    {
      "epoch": 0.21492471143341196,
      "grad_norm": 0.5240573287010193,
      "learning_rate": 7.850752885665881e-06,
      "loss": 0.0486,
      "step": 13574
    },
    {
      "epoch": 0.21494054499105403,
      "grad_norm": 0.26484572887420654,
      "learning_rate": 7.85059455008946e-06,
      "loss": 0.079,
      "step": 13575
    },
    {
      "epoch": 0.21495637854869612,
      "grad_norm": 0.38054314255714417,
      "learning_rate": 7.850436214513039e-06,
      "loss": 0.1115,
      "step": 13576
    },
    {
      "epoch": 0.21497221210633818,
      "grad_norm": 0.4829730987548828,
      "learning_rate": 7.850277878936618e-06,
      "loss": 0.0591,
      "step": 13577
    },
    {
      "epoch": 0.21498804566398025,
      "grad_norm": 0.004524067044258118,
      "learning_rate": 7.850119543360199e-06,
      "loss": 0.0002,
      "step": 13578
    },
    {
      "epoch": 0.2150038792216223,
      "grad_norm": 0.40904203057289124,
      "learning_rate": 7.849961207783778e-06,
      "loss": 0.0659,
      "step": 13579
    },
    {
      "epoch": 0.21501971277926438,
      "grad_norm": 0.4419398903846741,
      "learning_rate": 7.849802872207357e-06,
      "loss": 0.0592,
      "step": 13580
    },
    {
      "epoch": 0.21503554633690644,
      "grad_norm": 0.3275747299194336,
      "learning_rate": 7.849644536630936e-06,
      "loss": 0.1028,
      "step": 13581
    },
    {
      "epoch": 0.2150513798945485,
      "grad_norm": 0.0003893160028383136,
      "learning_rate": 7.849486201054515e-06,
      "loss": 0.0,
      "step": 13582
    },
    {
      "epoch": 0.21506721345219057,
      "grad_norm": 0.25693997740745544,
      "learning_rate": 7.849327865478094e-06,
      "loss": 0.1126,
      "step": 13583
    },
    {
      "epoch": 0.21508304700983263,
      "grad_norm": 0.38955363631248474,
      "learning_rate": 7.849169529901675e-06,
      "loss": 0.2028,
      "step": 13584
    },
    {
      "epoch": 0.2150988805674747,
      "grad_norm": 0.8374720215797424,
      "learning_rate": 7.849011194325254e-06,
      "loss": 0.1704,
      "step": 13585
    },
    {
      "epoch": 0.21511471412511676,
      "grad_norm": 1.226694107055664,
      "learning_rate": 7.848852858748833e-06,
      "loss": 0.4685,
      "step": 13586
    },
    {
      "epoch": 0.21513054768275883,
      "grad_norm": 0.3089921474456787,
      "learning_rate": 7.848694523172412e-06,
      "loss": 0.1287,
      "step": 13587
    },
    {
      "epoch": 0.21514638124040092,
      "grad_norm": 0.5599237084388733,
      "learning_rate": 7.848536187595991e-06,
      "loss": 0.4159,
      "step": 13588
    },
    {
      "epoch": 0.21516221479804298,
      "grad_norm": 0.5458871722221375,
      "learning_rate": 7.84837785201957e-06,
      "loss": 0.7554,
      "step": 13589
    },
    {
      "epoch": 0.21517804835568505,
      "grad_norm": 0.38957297801971436,
      "learning_rate": 7.848219516443151e-06,
      "loss": 0.305,
      "step": 13590
    },
    {
      "epoch": 0.2151938819133271,
      "grad_norm": 0.3568500876426697,
      "learning_rate": 7.84806118086673e-06,
      "loss": 0.1404,
      "step": 13591
    },
    {
      "epoch": 0.21520971547096918,
      "grad_norm": 0.017859529703855515,
      "learning_rate": 7.84790284529031e-06,
      "loss": 0.001,
      "step": 13592
    },
    {
      "epoch": 0.21522554902861124,
      "grad_norm": 0.09514403343200684,
      "learning_rate": 7.847744509713889e-06,
      "loss": 0.0207,
      "step": 13593
    },
    {
      "epoch": 0.2152413825862533,
      "grad_norm": 0.5620332956314087,
      "learning_rate": 7.847586174137468e-06,
      "loss": 0.7458,
      "step": 13594
    },
    {
      "epoch": 0.21525721614389537,
      "grad_norm": 0.00042066266178153455,
      "learning_rate": 7.847427838561047e-06,
      "loss": 0.0,
      "step": 13595
    },
    {
      "epoch": 0.21527304970153743,
      "grad_norm": 0.4029434323310852,
      "learning_rate": 7.847269502984626e-06,
      "loss": 0.0409,
      "step": 13596
    },
    {
      "epoch": 0.2152888832591795,
      "grad_norm": 0.32956662774086,
      "learning_rate": 7.847111167408205e-06,
      "loss": 0.1135,
      "step": 13597
    },
    {
      "epoch": 0.21530471681682156,
      "grad_norm": 0.0002668445522431284,
      "learning_rate": 7.846952831831784e-06,
      "loss": 0.0,
      "step": 13598
    },
    {
      "epoch": 0.21532055037446363,
      "grad_norm": 0.11036980897188187,
      "learning_rate": 7.846794496255365e-06,
      "loss": 0.0306,
      "step": 13599
    },
    {
      "epoch": 0.21533638393210572,
      "grad_norm": 1.1009385585784912,
      "learning_rate": 7.846636160678944e-06,
      "loss": 0.4814,
      "step": 13600
    },
    {
      "epoch": 0.21535221748974778,
      "grad_norm": 0.2991619408130646,
      "learning_rate": 7.846477825102523e-06,
      "loss": 0.1232,
      "step": 13601
    },
    {
      "epoch": 0.21536805104738985,
      "grad_norm": 0.0006751623586751521,
      "learning_rate": 7.846319489526102e-06,
      "loss": 0.0,
      "step": 13602
    },
    {
      "epoch": 0.2153838846050319,
      "grad_norm": 0.5432937145233154,
      "learning_rate": 7.846161153949681e-06,
      "loss": 0.1314,
      "step": 13603
    },
    {
      "epoch": 0.21539971816267398,
      "grad_norm": 0.765222430229187,
      "learning_rate": 7.84600281837326e-06,
      "loss": 0.7005,
      "step": 13604
    },
    {
      "epoch": 0.21541555172031604,
      "grad_norm": 0.0068355221301317215,
      "learning_rate": 7.845844482796841e-06,
      "loss": 0.0002,
      "step": 13605
    },
    {
      "epoch": 0.2154313852779581,
      "grad_norm": 0.42493486404418945,
      "learning_rate": 7.84568614722042e-06,
      "loss": 0.192,
      "step": 13606
    },
    {
      "epoch": 0.21544721883560017,
      "grad_norm": 0.36911869049072266,
      "learning_rate": 7.845527811643999e-06,
      "loss": 0.1828,
      "step": 13607
    },
    {
      "epoch": 0.21546305239324223,
      "grad_norm": 0.002806777600198984,
      "learning_rate": 7.845369476067578e-06,
      "loss": 0.0001,
      "step": 13608
    },
    {
      "epoch": 0.2154788859508843,
      "grad_norm": 0.0030380121897906065,
      "learning_rate": 7.845211140491157e-06,
      "loss": 0.0002,
      "step": 13609
    },
    {
      "epoch": 0.21549471950852636,
      "grad_norm": 0.2741653323173523,
      "learning_rate": 7.845052804914736e-06,
      "loss": 0.0235,
      "step": 13610
    },
    {
      "epoch": 0.21551055306616843,
      "grad_norm": 0.004937763791531324,
      "learning_rate": 7.844894469338317e-06,
      "loss": 0.0001,
      "step": 13611
    },
    {
      "epoch": 0.21552638662381052,
      "grad_norm": 0.006364667322486639,
      "learning_rate": 7.844736133761896e-06,
      "loss": 0.0003,
      "step": 13612
    },
    {
      "epoch": 0.21554222018145258,
      "grad_norm": 0.00020278358715586364,
      "learning_rate": 7.844577798185475e-06,
      "loss": 0.0,
      "step": 13613
    },
    {
      "epoch": 0.21555805373909465,
      "grad_norm": 0.34580013155937195,
      "learning_rate": 7.844419462609054e-06,
      "loss": 0.1046,
      "step": 13614
    },
    {
      "epoch": 0.2155738872967367,
      "grad_norm": 0.02611568197607994,
      "learning_rate": 7.844261127032633e-06,
      "loss": 0.001,
      "step": 13615
    },
    {
      "epoch": 0.21558972085437877,
      "grad_norm": 0.2933111786842346,
      "learning_rate": 7.844102791456212e-06,
      "loss": 0.2643,
      "step": 13616
    },
    {
      "epoch": 0.21560555441202084,
      "grad_norm": 0.5767040252685547,
      "learning_rate": 7.843944455879793e-06,
      "loss": 0.4533,
      "step": 13617
    },
    {
      "epoch": 0.2156213879696629,
      "grad_norm": 0.009042002260684967,
      "learning_rate": 7.843786120303372e-06,
      "loss": 0.0004,
      "step": 13618
    },
    {
      "epoch": 0.21563722152730497,
      "grad_norm": 0.32401537895202637,
      "learning_rate": 7.84362778472695e-06,
      "loss": 0.162,
      "step": 13619
    },
    {
      "epoch": 0.21565305508494703,
      "grad_norm": 0.40795817971229553,
      "learning_rate": 7.84346944915053e-06,
      "loss": 0.0728,
      "step": 13620
    },
    {
      "epoch": 0.2156688886425891,
      "grad_norm": 0.5973675847053528,
      "learning_rate": 7.84331111357411e-06,
      "loss": 0.4044,
      "step": 13621
    },
    {
      "epoch": 0.21568472220023116,
      "grad_norm": 0.28335094451904297,
      "learning_rate": 7.843152777997689e-06,
      "loss": 0.0499,
      "step": 13622
    },
    {
      "epoch": 0.21570055575787322,
      "grad_norm": 0.9699763059616089,
      "learning_rate": 7.842994442421268e-06,
      "loss": 0.1264,
      "step": 13623
    },
    {
      "epoch": 0.21571638931551532,
      "grad_norm": 0.10191834717988968,
      "learning_rate": 7.842836106844848e-06,
      "loss": 0.006,
      "step": 13624
    },
    {
      "epoch": 0.21573222287315738,
      "grad_norm": 0.000218741872231476,
      "learning_rate": 7.842677771268426e-06,
      "loss": 0.0,
      "step": 13625
    },
    {
      "epoch": 0.21574805643079945,
      "grad_norm": 0.0016316460678353906,
      "learning_rate": 7.842519435692007e-06,
      "loss": 0.0,
      "step": 13626
    },
    {
      "epoch": 0.2157638899884415,
      "grad_norm": 0.22888094186782837,
      "learning_rate": 7.842361100115586e-06,
      "loss": 0.0414,
      "step": 13627
    },
    {
      "epoch": 0.21577972354608357,
      "grad_norm": 0.5013688206672668,
      "learning_rate": 7.842202764539165e-06,
      "loss": 0.5276,
      "step": 13628
    },
    {
      "epoch": 0.21579555710372564,
      "grad_norm": 0.18227770924568176,
      "learning_rate": 7.842044428962744e-06,
      "loss": 0.0088,
      "step": 13629
    },
    {
      "epoch": 0.2158113906613677,
      "grad_norm": 0.9974690675735474,
      "learning_rate": 7.841886093386325e-06,
      "loss": 0.0317,
      "step": 13630
    },
    {
      "epoch": 0.21582722421900977,
      "grad_norm": 0.36558809876441956,
      "learning_rate": 7.841727757809902e-06,
      "loss": 0.2098,
      "step": 13631
    },
    {
      "epoch": 0.21584305777665183,
      "grad_norm": 0.591697633266449,
      "learning_rate": 7.841569422233483e-06,
      "loss": 0.6369,
      "step": 13632
    },
    {
      "epoch": 0.2158588913342939,
      "grad_norm": 0.007774952799081802,
      "learning_rate": 7.841411086657062e-06,
      "loss": 0.0004,
      "step": 13633
    },
    {
      "epoch": 0.21587472489193596,
      "grad_norm": 0.1858755499124527,
      "learning_rate": 7.841252751080641e-06,
      "loss": 0.035,
      "step": 13634
    },
    {
      "epoch": 0.21589055844957802,
      "grad_norm": 0.32513555884361267,
      "learning_rate": 7.84109441550422e-06,
      "loss": 0.0562,
      "step": 13635
    },
    {
      "epoch": 0.21590639200722012,
      "grad_norm": 0.03312191739678383,
      "learning_rate": 7.8409360799278e-06,
      "loss": 0.0016,
      "step": 13636
    },
    {
      "epoch": 0.21592222556486218,
      "grad_norm": 0.011932718567550182,
      "learning_rate": 7.840777744351378e-06,
      "loss": 0.0004,
      "step": 13637
    },
    {
      "epoch": 0.21593805912250424,
      "grad_norm": 0.017539601773023605,
      "learning_rate": 7.840619408774959e-06,
      "loss": 0.0006,
      "step": 13638
    },
    {
      "epoch": 0.2159538926801463,
      "grad_norm": 0.009502849541604519,
      "learning_rate": 7.840461073198538e-06,
      "loss": 0.0004,
      "step": 13639
    },
    {
      "epoch": 0.21596972623778837,
      "grad_norm": 0.7168451547622681,
      "learning_rate": 7.840302737622117e-06,
      "loss": 0.324,
      "step": 13640
    },
    {
      "epoch": 0.21598555979543044,
      "grad_norm": 0.9059852361679077,
      "learning_rate": 7.840144402045696e-06,
      "loss": 0.1525,
      "step": 13641
    },
    {
      "epoch": 0.2160013933530725,
      "grad_norm": 0.27639955282211304,
      "learning_rate": 7.839986066469275e-06,
      "loss": 0.1046,
      "step": 13642
    },
    {
      "epoch": 0.21601722691071457,
      "grad_norm": 0.058277759701013565,
      "learning_rate": 7.839827730892854e-06,
      "loss": 0.0032,
      "step": 13643
    },
    {
      "epoch": 0.21603306046835663,
      "grad_norm": 0.0640931949019432,
      "learning_rate": 7.839669395316433e-06,
      "loss": 0.0012,
      "step": 13644
    },
    {
      "epoch": 0.2160488940259987,
      "grad_norm": 0.5326230525970459,
      "learning_rate": 7.839511059740014e-06,
      "loss": 0.083,
      "step": 13645
    },
    {
      "epoch": 0.21606472758364076,
      "grad_norm": 0.005768763832747936,
      "learning_rate": 7.839352724163593e-06,
      "loss": 0.0002,
      "step": 13646
    },
    {
      "epoch": 0.21608056114128282,
      "grad_norm": 0.2954326272010803,
      "learning_rate": 7.839194388587172e-06,
      "loss": 0.0554,
      "step": 13647
    },
    {
      "epoch": 0.21609639469892492,
      "grad_norm": 0.6982994079589844,
      "learning_rate": 7.839036053010751e-06,
      "loss": 0.1264,
      "step": 13648
    },
    {
      "epoch": 0.21611222825656698,
      "grad_norm": 0.7543443441390991,
      "learning_rate": 7.83887771743433e-06,
      "loss": 0.9349,
      "step": 13649
    },
    {
      "epoch": 0.21612806181420904,
      "grad_norm": 0.29174643754959106,
      "learning_rate": 7.83871938185791e-06,
      "loss": 0.0544,
      "step": 13650
    },
    {
      "epoch": 0.2161438953718511,
      "grad_norm": 0.4213321805000305,
      "learning_rate": 7.83856104628149e-06,
      "loss": 0.3078,
      "step": 13651
    },
    {
      "epoch": 0.21615972892949317,
      "grad_norm": 3.5681066513061523,
      "learning_rate": 7.83840271070507e-06,
      "loss": 0.4629,
      "step": 13652
    },
    {
      "epoch": 0.21617556248713524,
      "grad_norm": 0.3825377821922302,
      "learning_rate": 7.838244375128649e-06,
      "loss": 0.1815,
      "step": 13653
    },
    {
      "epoch": 0.2161913960447773,
      "grad_norm": 0.25914034247398376,
      "learning_rate": 7.838086039552228e-06,
      "loss": 0.0996,
      "step": 13654
    },
    {
      "epoch": 0.21620722960241937,
      "grad_norm": 0.3326050639152527,
      "learning_rate": 7.837927703975807e-06,
      "loss": 0.1422,
      "step": 13655
    },
    {
      "epoch": 0.21622306316006143,
      "grad_norm": 0.6941884756088257,
      "learning_rate": 7.837769368399386e-06,
      "loss": 0.351,
      "step": 13656
    },
    {
      "epoch": 0.2162388967177035,
      "grad_norm": 0.42237353324890137,
      "learning_rate": 7.837611032822967e-06,
      "loss": 0.0968,
      "step": 13657
    },
    {
      "epoch": 0.21625473027534556,
      "grad_norm": 0.49928751587867737,
      "learning_rate": 7.837452697246546e-06,
      "loss": 0.3275,
      "step": 13658
    },
    {
      "epoch": 0.21627056383298762,
      "grad_norm": 0.04525485634803772,
      "learning_rate": 7.837294361670125e-06,
      "loss": 0.001,
      "step": 13659
    },
    {
      "epoch": 0.21628639739062971,
      "grad_norm": 0.6527780294418335,
      "learning_rate": 7.837136026093704e-06,
      "loss": 0.5033,
      "step": 13660
    },
    {
      "epoch": 0.21630223094827178,
      "grad_norm": 0.004434163682162762,
      "learning_rate": 7.836977690517283e-06,
      "loss": 0.0002,
      "step": 13661
    },
    {
      "epoch": 0.21631806450591384,
      "grad_norm": 0.40033888816833496,
      "learning_rate": 7.836819354940862e-06,
      "loss": 0.4519,
      "step": 13662
    },
    {
      "epoch": 0.2163338980635559,
      "grad_norm": 0.19213062524795532,
      "learning_rate": 7.836661019364443e-06,
      "loss": 0.0666,
      "step": 13663
    },
    {
      "epoch": 0.21634973162119797,
      "grad_norm": 0.016220003366470337,
      "learning_rate": 7.83650268378802e-06,
      "loss": 0.0008,
      "step": 13664
    },
    {
      "epoch": 0.21636556517884004,
      "grad_norm": 1.356937289237976,
      "learning_rate": 7.836344348211601e-06,
      "loss": 0.514,
      "step": 13665
    },
    {
      "epoch": 0.2163813987364821,
      "grad_norm": 0.3613332509994507,
      "learning_rate": 7.83618601263518e-06,
      "loss": 0.0675,
      "step": 13666
    },
    {
      "epoch": 0.21639723229412416,
      "grad_norm": 0.1346491128206253,
      "learning_rate": 7.836027677058759e-06,
      "loss": 0.0213,
      "step": 13667
    },
    {
      "epoch": 0.21641306585176623,
      "grad_norm": 0.652813732624054,
      "learning_rate": 7.835869341482338e-06,
      "loss": 0.0989,
      "step": 13668
    },
    {
      "epoch": 0.2164288994094083,
      "grad_norm": 0.04099937528371811,
      "learning_rate": 7.835711005905917e-06,
      "loss": 0.0006,
      "step": 13669
    },
    {
      "epoch": 0.21644473296705036,
      "grad_norm": 0.027446184307336807,
      "learning_rate": 7.835552670329496e-06,
      "loss": 0.0005,
      "step": 13670
    },
    {
      "epoch": 0.21646056652469242,
      "grad_norm": 0.2920978367328644,
      "learning_rate": 7.835394334753075e-06,
      "loss": 0.0975,
      "step": 13671
    },
    {
      "epoch": 0.2164764000823345,
      "grad_norm": 0.37056833505630493,
      "learning_rate": 7.835235999176656e-06,
      "loss": 0.1468,
      "step": 13672
    },
    {
      "epoch": 0.21649223363997658,
      "grad_norm": 0.03770463913679123,
      "learning_rate": 7.835077663600235e-06,
      "loss": 0.0011,
      "step": 13673
    },
    {
      "epoch": 0.21650806719761864,
      "grad_norm": 0.41280269622802734,
      "learning_rate": 7.834919328023814e-06,
      "loss": 0.1544,
      "step": 13674
    },
    {
      "epoch": 0.2165239007552607,
      "grad_norm": 0.0001704215828794986,
      "learning_rate": 7.834760992447393e-06,
      "loss": 0.0,
      "step": 13675
    },
    {
      "epoch": 0.21653973431290277,
      "grad_norm": 0.7090717554092407,
      "learning_rate": 7.834602656870972e-06,
      "loss": 0.8157,
      "step": 13676
    },
    {
      "epoch": 0.21655556787054484,
      "grad_norm": 0.48854854702949524,
      "learning_rate": 7.834444321294552e-06,
      "loss": 0.1329,
      "step": 13677
    },
    {
      "epoch": 0.2165714014281869,
      "grad_norm": 0.3826592266559601,
      "learning_rate": 7.834285985718132e-06,
      "loss": 0.0732,
      "step": 13678
    },
    {
      "epoch": 0.21658723498582896,
      "grad_norm": 0.40842193365097046,
      "learning_rate": 7.834127650141711e-06,
      "loss": 0.0691,
      "step": 13679
    },
    {
      "epoch": 0.21660306854347103,
      "grad_norm": 0.4834829866886139,
      "learning_rate": 7.83396931456529e-06,
      "loss": 0.3189,
      "step": 13680
    },
    {
      "epoch": 0.2166189021011131,
      "grad_norm": 0.6017246246337891,
      "learning_rate": 7.83381097898887e-06,
      "loss": 0.2998,
      "step": 13681
    },
    {
      "epoch": 0.21663473565875516,
      "grad_norm": 0.01519177295267582,
      "learning_rate": 7.833652643412449e-06,
      "loss": 0.0007,
      "step": 13682
    },
    {
      "epoch": 0.21665056921639722,
      "grad_norm": 0.0078066312707960606,
      "learning_rate": 7.833494307836028e-06,
      "loss": 0.0004,
      "step": 13683
    },
    {
      "epoch": 0.21666640277403929,
      "grad_norm": 0.04996709153056145,
      "learning_rate": 7.833335972259608e-06,
      "loss": 0.0028,
      "step": 13684
    },
    {
      "epoch": 0.21668223633168138,
      "grad_norm": 0.6459243297576904,
      "learning_rate": 7.833177636683188e-06,
      "loss": 0.2995,
      "step": 13685
    },
    {
      "epoch": 0.21669806988932344,
      "grad_norm": 0.000354023213731125,
      "learning_rate": 7.833019301106767e-06,
      "loss": 0.0,
      "step": 13686
    },
    {
      "epoch": 0.2167139034469655,
      "grad_norm": 0.02685476467013359,
      "learning_rate": 7.832860965530346e-06,
      "loss": 0.0015,
      "step": 13687
    },
    {
      "epoch": 0.21672973700460757,
      "grad_norm": 0.18582408130168915,
      "learning_rate": 7.832702629953925e-06,
      "loss": 0.0426,
      "step": 13688
    },
    {
      "epoch": 0.21674557056224963,
      "grad_norm": 0.3310908079147339,
      "learning_rate": 7.832544294377504e-06,
      "loss": 0.0573,
      "step": 13689
    },
    {
      "epoch": 0.2167614041198917,
      "grad_norm": 0.5066787004470825,
      "learning_rate": 7.832385958801085e-06,
      "loss": 0.2472,
      "step": 13690
    },
    {
      "epoch": 0.21677723767753376,
      "grad_norm": 0.2025803029537201,
      "learning_rate": 7.832227623224664e-06,
      "loss": 0.0184,
      "step": 13691
    },
    {
      "epoch": 0.21679307123517583,
      "grad_norm": 0.4236452579498291,
      "learning_rate": 7.832069287648241e-06,
      "loss": 0.0673,
      "step": 13692
    },
    {
      "epoch": 0.2168089047928179,
      "grad_norm": 0.010177860967814922,
      "learning_rate": 7.831910952071822e-06,
      "loss": 0.0005,
      "step": 13693
    },
    {
      "epoch": 0.21682473835045996,
      "grad_norm": 0.36440956592559814,
      "learning_rate": 7.831752616495401e-06,
      "loss": 0.0647,
      "step": 13694
    },
    {
      "epoch": 0.21684057190810202,
      "grad_norm": 0.25737035274505615,
      "learning_rate": 7.83159428091898e-06,
      "loss": 0.0418,
      "step": 13695
    },
    {
      "epoch": 0.21685640546574408,
      "grad_norm": 0.4861060082912445,
      "learning_rate": 7.831435945342559e-06,
      "loss": 0.0791,
      "step": 13696
    },
    {
      "epoch": 0.21687223902338618,
      "grad_norm": 0.40233737230300903,
      "learning_rate": 7.83127760976614e-06,
      "loss": 0.1729,
      "step": 13697
    },
    {
      "epoch": 0.21688807258102824,
      "grad_norm": 0.33612072467803955,
      "learning_rate": 7.831119274189717e-06,
      "loss": 0.2114,
      "step": 13698
    },
    {
      "epoch": 0.2169039061386703,
      "grad_norm": 0.07485102117061615,
      "learning_rate": 7.830960938613298e-06,
      "loss": 0.0084,
      "step": 13699
    },
    {
      "epoch": 0.21691973969631237,
      "grad_norm": 0.772520899772644,
      "learning_rate": 7.830802603036877e-06,
      "loss": 0.3829,
      "step": 13700
    },
    {
      "epoch": 0.21693557325395443,
      "grad_norm": 0.19362181425094604,
      "learning_rate": 7.830644267460456e-06,
      "loss": 0.059,
      "step": 13701
    },
    {
      "epoch": 0.2169514068115965,
      "grad_norm": 0.35221579670906067,
      "learning_rate": 7.830485931884035e-06,
      "loss": 0.1214,
      "step": 13702
    },
    {
      "epoch": 0.21696724036923856,
      "grad_norm": 0.42778411507606506,
      "learning_rate": 7.830327596307616e-06,
      "loss": 0.12,
      "step": 13703
    },
    {
      "epoch": 0.21698307392688063,
      "grad_norm": 0.010546823032200336,
      "learning_rate": 7.830169260731193e-06,
      "loss": 0.0005,
      "step": 13704
    },
    {
      "epoch": 0.2169989074845227,
      "grad_norm": 0.791685938835144,
      "learning_rate": 7.830010925154774e-06,
      "loss": 0.0324,
      "step": 13705
    },
    {
      "epoch": 0.21701474104216475,
      "grad_norm": 0.4120931327342987,
      "learning_rate": 7.829852589578353e-06,
      "loss": 0.045,
      "step": 13706
    },
    {
      "epoch": 0.21703057459980682,
      "grad_norm": 0.3043386936187744,
      "learning_rate": 7.829694254001932e-06,
      "loss": 0.1166,
      "step": 13707
    },
    {
      "epoch": 0.21704640815744888,
      "grad_norm": 0.06192631274461746,
      "learning_rate": 7.829535918425511e-06,
      "loss": 0.0018,
      "step": 13708
    },
    {
      "epoch": 0.21706224171509098,
      "grad_norm": 0.32148435711860657,
      "learning_rate": 7.829377582849092e-06,
      "loss": 0.0527,
      "step": 13709
    },
    {
      "epoch": 0.21707807527273304,
      "grad_norm": 0.014679796993732452,
      "learning_rate": 7.82921924727267e-06,
      "loss": 0.0005,
      "step": 13710
    },
    {
      "epoch": 0.2170939088303751,
      "grad_norm": 0.027941476553678513,
      "learning_rate": 7.82906091169625e-06,
      "loss": 0.0015,
      "step": 13711
    },
    {
      "epoch": 0.21710974238801717,
      "grad_norm": 0.058619361370801926,
      "learning_rate": 7.82890257611983e-06,
      "loss": 0.0041,
      "step": 13712
    },
    {
      "epoch": 0.21712557594565923,
      "grad_norm": 0.43499916791915894,
      "learning_rate": 7.828744240543409e-06,
      "loss": 0.1371,
      "step": 13713
    },
    {
      "epoch": 0.2171414095033013,
      "grad_norm": 0.025414446368813515,
      "learning_rate": 7.828585904966988e-06,
      "loss": 0.0016,
      "step": 13714
    },
    {
      "epoch": 0.21715724306094336,
      "grad_norm": 0.20056554675102234,
      "learning_rate": 7.828427569390567e-06,
      "loss": 0.0796,
      "step": 13715
    },
    {
      "epoch": 0.21717307661858543,
      "grad_norm": 0.42763274908065796,
      "learning_rate": 7.828269233814146e-06,
      "loss": 0.3168,
      "step": 13716
    },
    {
      "epoch": 0.2171889101762275,
      "grad_norm": 0.37956082820892334,
      "learning_rate": 7.828110898237725e-06,
      "loss": 0.127,
      "step": 13717
    },
    {
      "epoch": 0.21720474373386955,
      "grad_norm": 0.9058472514152527,
      "learning_rate": 7.827952562661306e-06,
      "loss": 0.2375,
      "step": 13718
    },
    {
      "epoch": 0.21722057729151162,
      "grad_norm": 0.47236698865890503,
      "learning_rate": 7.827794227084885e-06,
      "loss": 0.1794,
      "step": 13719
    },
    {
      "epoch": 0.21723641084915368,
      "grad_norm": 0.0016975600738078356,
      "learning_rate": 7.827635891508464e-06,
      "loss": 0.0,
      "step": 13720
    },
    {
      "epoch": 0.21725224440679577,
      "grad_norm": 0.528522253036499,
      "learning_rate": 7.827477555932043e-06,
      "loss": 0.2448,
      "step": 13721
    },
    {
      "epoch": 0.21726807796443784,
      "grad_norm": 0.06784471869468689,
      "learning_rate": 7.827319220355622e-06,
      "loss": 0.015,
      "step": 13722
    },
    {
      "epoch": 0.2172839115220799,
      "grad_norm": 0.007759799715131521,
      "learning_rate": 7.827160884779201e-06,
      "loss": 0.0003,
      "step": 13723
    },
    {
      "epoch": 0.21729974507972197,
      "grad_norm": 0.3561524450778961,
      "learning_rate": 7.827002549202782e-06,
      "loss": 0.0601,
      "step": 13724
    },
    {
      "epoch": 0.21731557863736403,
      "grad_norm": 0.4058208465576172,
      "learning_rate": 7.82684421362636e-06,
      "loss": 0.1346,
      "step": 13725
    },
    {
      "epoch": 0.2173314121950061,
      "grad_norm": 0.7285031676292419,
      "learning_rate": 7.82668587804994e-06,
      "loss": 0.6013,
      "step": 13726
    },
    {
      "epoch": 0.21734724575264816,
      "grad_norm": 0.6245827674865723,
      "learning_rate": 7.826527542473519e-06,
      "loss": 0.3639,
      "step": 13727
    },
    {
      "epoch": 0.21736307931029022,
      "grad_norm": 0.3125193119049072,
      "learning_rate": 7.826369206897098e-06,
      "loss": 0.1464,
      "step": 13728
    },
    {
      "epoch": 0.2173789128679323,
      "grad_norm": 0.17847351729869843,
      "learning_rate": 7.826210871320677e-06,
      "loss": 0.0188,
      "step": 13729
    },
    {
      "epoch": 0.21739474642557435,
      "grad_norm": 0.29384157061576843,
      "learning_rate": 7.826052535744258e-06,
      "loss": 0.131,
      "step": 13730
    },
    {
      "epoch": 0.21741057998321642,
      "grad_norm": 0.582065761089325,
      "learning_rate": 7.825894200167835e-06,
      "loss": 0.3063,
      "step": 13731
    },
    {
      "epoch": 0.21742641354085848,
      "grad_norm": 0.23753096163272858,
      "learning_rate": 7.825735864591416e-06,
      "loss": 0.1584,
      "step": 13732
    },
    {
      "epoch": 0.21744224709850057,
      "grad_norm": 0.37734171748161316,
      "learning_rate": 7.825577529014995e-06,
      "loss": 0.0744,
      "step": 13733
    },
    {
      "epoch": 0.21745808065614264,
      "grad_norm": 0.0007603190024383366,
      "learning_rate": 7.825419193438574e-06,
      "loss": 0.0,
      "step": 13734
    },
    {
      "epoch": 0.2174739142137847,
      "grad_norm": 0.174352765083313,
      "learning_rate": 7.825260857862153e-06,
      "loss": 0.0198,
      "step": 13735
    },
    {
      "epoch": 0.21748974777142677,
      "grad_norm": 0.0003248406865168363,
      "learning_rate": 7.825102522285734e-06,
      "loss": 0.0,
      "step": 13736
    },
    {
      "epoch": 0.21750558132906883,
      "grad_norm": 0.6342630982398987,
      "learning_rate": 7.824944186709312e-06,
      "loss": 0.6342,
      "step": 13737
    },
    {
      "epoch": 0.2175214148867109,
      "grad_norm": 0.425550252199173,
      "learning_rate": 7.824785851132892e-06,
      "loss": 0.2475,
      "step": 13738
    },
    {
      "epoch": 0.21753724844435296,
      "grad_norm": 0.5707849860191345,
      "learning_rate": 7.824627515556471e-06,
      "loss": 0.1781,
      "step": 13739
    },
    {
      "epoch": 0.21755308200199502,
      "grad_norm": 0.5106824636459351,
      "learning_rate": 7.82446917998005e-06,
      "loss": 0.1783,
      "step": 13740
    },
    {
      "epoch": 0.2175689155596371,
      "grad_norm": 0.0004902557120658457,
      "learning_rate": 7.82431084440363e-06,
      "loss": 0.0,
      "step": 13741
    },
    {
      "epoch": 0.21758474911727915,
      "grad_norm": 0.2591206729412079,
      "learning_rate": 7.824152508827209e-06,
      "loss": 0.0906,
      "step": 13742
    },
    {
      "epoch": 0.21760058267492122,
      "grad_norm": 0.023460114374756813,
      "learning_rate": 7.823994173250788e-06,
      "loss": 0.0012,
      "step": 13743
    },
    {
      "epoch": 0.21761641623256328,
      "grad_norm": 0.47694531083106995,
      "learning_rate": 7.823835837674367e-06,
      "loss": 0.6478,
      "step": 13744
    },
    {
      "epoch": 0.21763224979020537,
      "grad_norm": 0.27628281712532043,
      "learning_rate": 7.823677502097948e-06,
      "loss": 0.0838,
      "step": 13745
    },
    {
      "epoch": 0.21764808334784744,
      "grad_norm": 0.21365119516849518,
      "learning_rate": 7.823519166521527e-06,
      "loss": 0.058,
      "step": 13746
    },
    {
      "epoch": 0.2176639169054895,
      "grad_norm": 0.00039510917849838734,
      "learning_rate": 7.823360830945106e-06,
      "loss": 0.0,
      "step": 13747
    },
    {
      "epoch": 0.21767975046313157,
      "grad_norm": 0.29341670870780945,
      "learning_rate": 7.823202495368685e-06,
      "loss": 0.1201,
      "step": 13748
    },
    {
      "epoch": 0.21769558402077363,
      "grad_norm": 0.3022594749927521,
      "learning_rate": 7.823044159792264e-06,
      "loss": 0.0528,
      "step": 13749
    },
    {
      "epoch": 0.2177114175784157,
      "grad_norm": 0.5778803825378418,
      "learning_rate": 7.822885824215843e-06,
      "loss": 0.2846,
      "step": 13750
    },
    {
      "epoch": 0.21772725113605776,
      "grad_norm": 0.25428885221481323,
      "learning_rate": 7.822727488639424e-06,
      "loss": 0.0456,
      "step": 13751
    },
    {
      "epoch": 0.21774308469369982,
      "grad_norm": 0.8270378708839417,
      "learning_rate": 7.822569153063003e-06,
      "loss": 0.7551,
      "step": 13752
    },
    {
      "epoch": 0.2177589182513419,
      "grad_norm": 0.6045733690261841,
      "learning_rate": 7.822410817486582e-06,
      "loss": 0.1211,
      "step": 13753
    },
    {
      "epoch": 0.21777475180898395,
      "grad_norm": 0.5367024540901184,
      "learning_rate": 7.822252481910161e-06,
      "loss": 0.3427,
      "step": 13754
    },
    {
      "epoch": 0.21779058536662602,
      "grad_norm": 0.3243158161640167,
      "learning_rate": 7.82209414633374e-06,
      "loss": 0.1408,
      "step": 13755
    },
    {
      "epoch": 0.21780641892426808,
      "grad_norm": 0.020989304408431053,
      "learning_rate": 7.821935810757319e-06,
      "loss": 0.0011,
      "step": 13756
    },
    {
      "epoch": 0.21782225248191017,
      "grad_norm": 0.005218360107392073,
      "learning_rate": 7.8217774751809e-06,
      "loss": 0.0002,
      "step": 13757
    },
    {
      "epoch": 0.21783808603955224,
      "grad_norm": 0.39967846870422363,
      "learning_rate": 7.821619139604479e-06,
      "loss": 0.0369,
      "step": 13758
    },
    {
      "epoch": 0.2178539195971943,
      "grad_norm": 0.35576194524765015,
      "learning_rate": 7.821460804028058e-06,
      "loss": 0.0763,
      "step": 13759
    },
    {
      "epoch": 0.21786975315483637,
      "grad_norm": 0.2793605923652649,
      "learning_rate": 7.821302468451637e-06,
      "loss": 0.0532,
      "step": 13760
    },
    {
      "epoch": 0.21788558671247843,
      "grad_norm": 0.0006514699198305607,
      "learning_rate": 7.821144132875216e-06,
      "loss": 0.0,
      "step": 13761
    },
    {
      "epoch": 0.2179014202701205,
      "grad_norm": 0.0006446813931688666,
      "learning_rate": 7.820985797298795e-06,
      "loss": 0.0,
      "step": 13762
    },
    {
      "epoch": 0.21791725382776256,
      "grad_norm": 0.2094307541847229,
      "learning_rate": 7.820827461722374e-06,
      "loss": 0.0344,
      "step": 13763
    },
    {
      "epoch": 0.21793308738540462,
      "grad_norm": 0.020817343145608902,
      "learning_rate": 7.820669126145955e-06,
      "loss": 0.0011,
      "step": 13764
    },
    {
      "epoch": 0.2179489209430467,
      "grad_norm": 0.00437896978110075,
      "learning_rate": 7.820510790569533e-06,
      "loss": 0.0002,
      "step": 13765
    },
    {
      "epoch": 0.21796475450068875,
      "grad_norm": 0.3019024431705475,
      "learning_rate": 7.820352454993113e-06,
      "loss": 0.0764,
      "step": 13766
    },
    {
      "epoch": 0.21798058805833082,
      "grad_norm": 0.00027918306295759976,
      "learning_rate": 7.820194119416692e-06,
      "loss": 0.0,
      "step": 13767
    },
    {
      "epoch": 0.21799642161597288,
      "grad_norm": 0.3996233642101288,
      "learning_rate": 7.820035783840271e-06,
      "loss": 0.1268,
      "step": 13768
    },
    {
      "epoch": 0.21801225517361497,
      "grad_norm": 0.008964856155216694,
      "learning_rate": 7.81987744826385e-06,
      "loss": 0.0004,
      "step": 13769
    },
    {
      "epoch": 0.21802808873125704,
      "grad_norm": 0.20066243410110474,
      "learning_rate": 7.819719112687431e-06,
      "loss": 0.0504,
      "step": 13770
    },
    {
      "epoch": 0.2180439222888991,
      "grad_norm": 0.4197308123111725,
      "learning_rate": 7.819560777111009e-06,
      "loss": 0.0707,
      "step": 13771
    },
    {
      "epoch": 0.21805975584654116,
      "grad_norm": 0.00022045579680707306,
      "learning_rate": 7.81940244153459e-06,
      "loss": 0.0,
      "step": 13772
    },
    {
      "epoch": 0.21807558940418323,
      "grad_norm": 0.6193750500679016,
      "learning_rate": 7.819244105958169e-06,
      "loss": 0.2385,
      "step": 13773
    },
    {
      "epoch": 0.2180914229618253,
      "grad_norm": 0.005422825459390879,
      "learning_rate": 7.819085770381748e-06,
      "loss": 0.0001,
      "step": 13774
    },
    {
      "epoch": 0.21810725651946736,
      "grad_norm": 0.1681908220052719,
      "learning_rate": 7.818927434805327e-06,
      "loss": 0.0312,
      "step": 13775
    },
    {
      "epoch": 0.21812309007710942,
      "grad_norm": 0.0009199577616527677,
      "learning_rate": 7.818769099228908e-06,
      "loss": 0.0,
      "step": 13776
    },
    {
      "epoch": 0.21813892363475149,
      "grad_norm": 0.845609188079834,
      "learning_rate": 7.818610763652485e-06,
      "loss": 0.0285,
      "step": 13777
    },
    {
      "epoch": 0.21815475719239355,
      "grad_norm": 0.003735120175406337,
      "learning_rate": 7.818452428076066e-06,
      "loss": 0.0,
      "step": 13778
    },
    {
      "epoch": 0.21817059075003561,
      "grad_norm": 0.3521837592124939,
      "learning_rate": 7.818294092499645e-06,
      "loss": 0.1203,
      "step": 13779
    },
    {
      "epoch": 0.21818642430767768,
      "grad_norm": 0.011052499525249004,
      "learning_rate": 7.818135756923224e-06,
      "loss": 0.0004,
      "step": 13780
    },
    {
      "epoch": 0.21820225786531977,
      "grad_norm": 0.47744083404541016,
      "learning_rate": 7.817977421346803e-06,
      "loss": 0.0581,
      "step": 13781
    },
    {
      "epoch": 0.21821809142296184,
      "grad_norm": 0.010004575364291668,
      "learning_rate": 7.817819085770384e-06,
      "loss": 0.0002,
      "step": 13782
    },
    {
      "epoch": 0.2182339249806039,
      "grad_norm": 0.0006103767082095146,
      "learning_rate": 7.817660750193961e-06,
      "loss": 0.0,
      "step": 13783
    },
    {
      "epoch": 0.21824975853824596,
      "grad_norm": 0.3733637034893036,
      "learning_rate": 7.817502414617542e-06,
      "loss": 0.0653,
      "step": 13784
    },
    {
      "epoch": 0.21826559209588803,
      "grad_norm": 0.01465658750385046,
      "learning_rate": 7.817344079041121e-06,
      "loss": 0.0006,
      "step": 13785
    },
    {
      "epoch": 0.2182814256535301,
      "grad_norm": 0.03341556340456009,
      "learning_rate": 7.8171857434647e-06,
      "loss": 0.0024,
      "step": 13786
    },
    {
      "epoch": 0.21829725921117216,
      "grad_norm": 0.3598504960536957,
      "learning_rate": 7.817027407888279e-06,
      "loss": 0.0807,
      "step": 13787
    },
    {
      "epoch": 0.21831309276881422,
      "grad_norm": 0.3270796835422516,
      "learning_rate": 7.816869072311858e-06,
      "loss": 0.0402,
      "step": 13788
    },
    {
      "epoch": 0.21832892632645629,
      "grad_norm": 0.19103018939495087,
      "learning_rate": 7.816710736735437e-06,
      "loss": 0.047,
      "step": 13789
    },
    {
      "epoch": 0.21834475988409835,
      "grad_norm": 0.5415936708450317,
      "learning_rate": 7.816552401159016e-06,
      "loss": 0.3959,
      "step": 13790
    },
    {
      "epoch": 0.2183605934417404,
      "grad_norm": 0.5968494415283203,
      "learning_rate": 7.816394065582597e-06,
      "loss": 0.4028,
      "step": 13791
    },
    {
      "epoch": 0.21837642699938248,
      "grad_norm": 0.22518979012966156,
      "learning_rate": 7.816235730006174e-06,
      "loss": 0.1353,
      "step": 13792
    },
    {
      "epoch": 0.21839226055702457,
      "grad_norm": 0.5402674078941345,
      "learning_rate": 7.816077394429755e-06,
      "loss": 0.1557,
      "step": 13793
    },
    {
      "epoch": 0.21840809411466663,
      "grad_norm": 0.2702181935310364,
      "learning_rate": 7.815919058853334e-06,
      "loss": 0.0325,
      "step": 13794
    },
    {
      "epoch": 0.2184239276723087,
      "grad_norm": 0.5123695135116577,
      "learning_rate": 7.815760723276913e-06,
      "loss": 0.3103,
      "step": 13795
    },
    {
      "epoch": 0.21843976122995076,
      "grad_norm": 0.022295666858553886,
      "learning_rate": 7.815602387700492e-06,
      "loss": 0.0011,
      "step": 13796
    },
    {
      "epoch": 0.21845559478759283,
      "grad_norm": 0.32579267024993896,
      "learning_rate": 7.815444052124073e-06,
      "loss": 0.0583,
      "step": 13797
    },
    {
      "epoch": 0.2184714283452349,
      "grad_norm": 0.3808298408985138,
      "learning_rate": 7.81528571654765e-06,
      "loss": 0.0605,
      "step": 13798
    },
    {
      "epoch": 0.21848726190287696,
      "grad_norm": 0.018001720309257507,
      "learning_rate": 7.815127380971231e-06,
      "loss": 0.0006,
      "step": 13799
    },
    {
      "epoch": 0.21850309546051902,
      "grad_norm": 0.27730342745780945,
      "learning_rate": 7.81496904539481e-06,
      "loss": 0.035,
      "step": 13800
    },
    {
      "epoch": 0.21851892901816108,
      "grad_norm": 0.00029377953615039587,
      "learning_rate": 7.81481070981839e-06,
      "loss": 0.0,
      "step": 13801
    },
    {
      "epoch": 0.21853476257580315,
      "grad_norm": 0.4652317464351654,
      "learning_rate": 7.814652374241969e-06,
      "loss": 0.0665,
      "step": 13802
    },
    {
      "epoch": 0.2185505961334452,
      "grad_norm": 0.007186342030763626,
      "learning_rate": 7.81449403866555e-06,
      "loss": 0.0003,
      "step": 13803
    },
    {
      "epoch": 0.21856642969108728,
      "grad_norm": 0.1806052029132843,
      "learning_rate": 7.814335703089127e-06,
      "loss": 0.0458,
      "step": 13804
    },
    {
      "epoch": 0.21858226324872937,
      "grad_norm": 0.028952136635780334,
      "learning_rate": 7.814177367512708e-06,
      "loss": 0.0013,
      "step": 13805
    },
    {
      "epoch": 0.21859809680637143,
      "grad_norm": 0.416819304227829,
      "learning_rate": 7.814019031936287e-06,
      "loss": 0.142,
      "step": 13806
    },
    {
      "epoch": 0.2186139303640135,
      "grad_norm": 0.2667780816555023,
      "learning_rate": 7.813860696359866e-06,
      "loss": 0.1204,
      "step": 13807
    },
    {
      "epoch": 0.21862976392165556,
      "grad_norm": 0.012240132316946983,
      "learning_rate": 7.813702360783445e-06,
      "loss": 0.0005,
      "step": 13808
    },
    {
      "epoch": 0.21864559747929763,
      "grad_norm": 0.033313602209091187,
      "learning_rate": 7.813544025207026e-06,
      "loss": 0.0013,
      "step": 13809
    },
    {
      "epoch": 0.2186614310369397,
      "grad_norm": 0.3504598140716553,
      "learning_rate": 7.813385689630603e-06,
      "loss": 0.0613,
      "step": 13810
    },
    {
      "epoch": 0.21867726459458176,
      "grad_norm": 0.3611135184764862,
      "learning_rate": 7.813227354054182e-06,
      "loss": 0.1092,
      "step": 13811
    },
    {
      "epoch": 0.21869309815222382,
      "grad_norm": 0.6098232269287109,
      "learning_rate": 7.813069018477763e-06,
      "loss": 0.5587,
      "step": 13812
    },
    {
      "epoch": 0.21870893170986588,
      "grad_norm": 0.39887863397598267,
      "learning_rate": 7.812910682901342e-06,
      "loss": 0.0662,
      "step": 13813
    },
    {
      "epoch": 0.21872476526750795,
      "grad_norm": 0.4203222393989563,
      "learning_rate": 7.812752347324921e-06,
      "loss": 0.0846,
      "step": 13814
    },
    {
      "epoch": 0.21874059882515,
      "grad_norm": 0.33694320917129517,
      "learning_rate": 7.8125940117485e-06,
      "loss": 0.0506,
      "step": 13815
    },
    {
      "epoch": 0.21875643238279208,
      "grad_norm": 0.22420351207256317,
      "learning_rate": 7.81243567617208e-06,
      "loss": 0.0346,
      "step": 13816
    },
    {
      "epoch": 0.21877226594043417,
      "grad_norm": 0.009337359108030796,
      "learning_rate": 7.812277340595658e-06,
      "loss": 0.0002,
      "step": 13817
    },
    {
      "epoch": 0.21878809949807623,
      "grad_norm": 0.4012726843357086,
      "learning_rate": 7.812119005019239e-06,
      "loss": 0.1976,
      "step": 13818
    },
    {
      "epoch": 0.2188039330557183,
      "grad_norm": 0.6736156940460205,
      "learning_rate": 7.811960669442818e-06,
      "loss": 0.9326,
      "step": 13819
    },
    {
      "epoch": 0.21881976661336036,
      "grad_norm": 0.23577581346035004,
      "learning_rate": 7.811802333866397e-06,
      "loss": 0.0665,
      "step": 13820
    },
    {
      "epoch": 0.21883560017100243,
      "grad_norm": 0.23148778080940247,
      "learning_rate": 7.811643998289976e-06,
      "loss": 0.1037,
      "step": 13821
    },
    {
      "epoch": 0.2188514337286445,
      "grad_norm": 0.01629522629082203,
      "learning_rate": 7.811485662713555e-06,
      "loss": 0.0006,
      "step": 13822
    },
    {
      "epoch": 0.21886726728628655,
      "grad_norm": 0.37207698822021484,
      "learning_rate": 7.811327327137134e-06,
      "loss": 0.0998,
      "step": 13823
    },
    {
      "epoch": 0.21888310084392862,
      "grad_norm": 0.2925422489643097,
      "learning_rate": 7.811168991560715e-06,
      "loss": 0.0616,
      "step": 13824
    },
    {
      "epoch": 0.21889893440157068,
      "grad_norm": 0.010818320326507092,
      "learning_rate": 7.811010655984294e-06,
      "loss": 0.0004,
      "step": 13825
    },
    {
      "epoch": 0.21891476795921275,
      "grad_norm": 0.6168443560600281,
      "learning_rate": 7.810852320407873e-06,
      "loss": 0.2318,
      "step": 13826
    },
    {
      "epoch": 0.2189306015168548,
      "grad_norm": 0.5125814080238342,
      "learning_rate": 7.810693984831452e-06,
      "loss": 0.0686,
      "step": 13827
    },
    {
      "epoch": 0.21894643507449688,
      "grad_norm": 0.019571799784898758,
      "learning_rate": 7.810535649255032e-06,
      "loss": 0.0011,
      "step": 13828
    },
    {
      "epoch": 0.21896226863213897,
      "grad_norm": 0.2181679755449295,
      "learning_rate": 7.81037731367861e-06,
      "loss": 0.046,
      "step": 13829
    },
    {
      "epoch": 0.21897810218978103,
      "grad_norm": 0.005143322516232729,
      "learning_rate": 7.810218978102191e-06,
      "loss": 0.0002,
      "step": 13830
    },
    {
      "epoch": 0.2189939357474231,
      "grad_norm": 0.020451033487915993,
      "learning_rate": 7.81006064252577e-06,
      "loss": 0.0008,
      "step": 13831
    },
    {
      "epoch": 0.21900976930506516,
      "grad_norm": 0.25836774706840515,
      "learning_rate": 7.80990230694935e-06,
      "loss": 0.0716,
      "step": 13832
    },
    {
      "epoch": 0.21902560286270722,
      "grad_norm": 0.015076718293130398,
      "learning_rate": 7.809743971372929e-06,
      "loss": 0.0007,
      "step": 13833
    },
    {
      "epoch": 0.2190414364203493,
      "grad_norm": 0.508416473865509,
      "learning_rate": 7.809585635796508e-06,
      "loss": 0.1654,
      "step": 13834
    },
    {
      "epoch": 0.21905726997799135,
      "grad_norm": 0.3786046802997589,
      "learning_rate": 7.809427300220087e-06,
      "loss": 0.0272,
      "step": 13835
    },
    {
      "epoch": 0.21907310353563342,
      "grad_norm": 0.03275565430521965,
      "learning_rate": 7.809268964643666e-06,
      "loss": 0.0015,
      "step": 13836
    },
    {
      "epoch": 0.21908893709327548,
      "grad_norm": 0.7221534252166748,
      "learning_rate": 7.809110629067247e-06,
      "loss": 0.2032,
      "step": 13837
    },
    {
      "epoch": 0.21910477065091755,
      "grad_norm": 0.017023906111717224,
      "learning_rate": 7.808952293490824e-06,
      "loss": 0.0009,
      "step": 13838
    },
    {
      "epoch": 0.2191206042085596,
      "grad_norm": 0.1254381537437439,
      "learning_rate": 7.808793957914405e-06,
      "loss": 0.0268,
      "step": 13839
    },
    {
      "epoch": 0.21913643776620167,
      "grad_norm": 0.21578018367290497,
      "learning_rate": 7.808635622337984e-06,
      "loss": 0.0247,
      "step": 13840
    },
    {
      "epoch": 0.21915227132384377,
      "grad_norm": 7.106812699930742e-05,
      "learning_rate": 7.808477286761563e-06,
      "loss": 0.0,
      "step": 13841
    },
    {
      "epoch": 0.21916810488148583,
      "grad_norm": 0.23383177816867828,
      "learning_rate": 7.808318951185142e-06,
      "loss": 0.1217,
      "step": 13842
    },
    {
      "epoch": 0.2191839384391279,
      "grad_norm": 0.32110071182250977,
      "learning_rate": 7.808160615608723e-06,
      "loss": 0.0696,
      "step": 13843
    },
    {
      "epoch": 0.21919977199676996,
      "grad_norm": 0.5119738578796387,
      "learning_rate": 7.8080022800323e-06,
      "loss": 0.1264,
      "step": 13844
    },
    {
      "epoch": 0.21921560555441202,
      "grad_norm": 0.2681833505630493,
      "learning_rate": 7.807843944455881e-06,
      "loss": 0.0837,
      "step": 13845
    },
    {
      "epoch": 0.2192314391120541,
      "grad_norm": 1.113647699356079,
      "learning_rate": 7.80768560887946e-06,
      "loss": 0.0691,
      "step": 13846
    },
    {
      "epoch": 0.21924727266969615,
      "grad_norm": 0.025488948449492455,
      "learning_rate": 7.807527273303039e-06,
      "loss": 0.0012,
      "step": 13847
    },
    {
      "epoch": 0.21926310622733822,
      "grad_norm": 0.009848365560173988,
      "learning_rate": 7.807368937726618e-06,
      "loss": 0.0005,
      "step": 13848
    },
    {
      "epoch": 0.21927893978498028,
      "grad_norm": 0.48529261350631714,
      "learning_rate": 7.807210602150197e-06,
      "loss": 0.4025,
      "step": 13849
    },
    {
      "epoch": 0.21929477334262235,
      "grad_norm": 0.4751763343811035,
      "learning_rate": 7.807052266573776e-06,
      "loss": 0.314,
      "step": 13850
    },
    {
      "epoch": 0.2193106069002644,
      "grad_norm": 0.01170363835990429,
      "learning_rate": 7.806893930997357e-06,
      "loss": 0.0003,
      "step": 13851
    },
    {
      "epoch": 0.21932644045790647,
      "grad_norm": 0.5521264672279358,
      "learning_rate": 7.806735595420936e-06,
      "loss": 0.1025,
      "step": 13852
    },
    {
      "epoch": 0.21934227401554857,
      "grad_norm": 0.6079316139221191,
      "learning_rate": 7.806577259844515e-06,
      "loss": 0.4688,
      "step": 13853
    },
    {
      "epoch": 0.21935810757319063,
      "grad_norm": 0.018884506076574326,
      "learning_rate": 7.806418924268094e-06,
      "loss": 0.001,
      "step": 13854
    },
    {
      "epoch": 0.2193739411308327,
      "grad_norm": 0.0354270339012146,
      "learning_rate": 7.806260588691673e-06,
      "loss": 0.0011,
      "step": 13855
    },
    {
      "epoch": 0.21938977468847476,
      "grad_norm": 0.2327442318201065,
      "learning_rate": 7.806102253115253e-06,
      "loss": 0.0629,
      "step": 13856
    },
    {
      "epoch": 0.21940560824611682,
      "grad_norm": 0.00024384142307098955,
      "learning_rate": 7.805943917538833e-06,
      "loss": 0.0,
      "step": 13857
    },
    {
      "epoch": 0.2194214418037589,
      "grad_norm": 0.6010702252388,
      "learning_rate": 7.805785581962412e-06,
      "loss": 0.0949,
      "step": 13858
    },
    {
      "epoch": 0.21943727536140095,
      "grad_norm": 0.4863106310367584,
      "learning_rate": 7.80562724638599e-06,
      "loss": 0.1208,
      "step": 13859
    },
    {
      "epoch": 0.21945310891904302,
      "grad_norm": 0.2578662931919098,
      "learning_rate": 7.80546891080957e-06,
      "loss": 0.0514,
      "step": 13860
    },
    {
      "epoch": 0.21946894247668508,
      "grad_norm": 0.21453949809074402,
      "learning_rate": 7.80531057523315e-06,
      "loss": 0.13,
      "step": 13861
    },
    {
      "epoch": 0.21948477603432714,
      "grad_norm": 0.01526737492531538,
      "learning_rate": 7.805152239656729e-06,
      "loss": 0.0006,
      "step": 13862
    },
    {
      "epoch": 0.2195006095919692,
      "grad_norm": 0.3526245057582855,
      "learning_rate": 7.804993904080308e-06,
      "loss": 0.1665,
      "step": 13863
    },
    {
      "epoch": 0.21951644314961127,
      "grad_norm": 0.9651808142662048,
      "learning_rate": 7.804835568503889e-06,
      "loss": 0.7795,
      "step": 13864
    },
    {
      "epoch": 0.21953227670725337,
      "grad_norm": 0.4928491711616516,
      "learning_rate": 7.804677232927466e-06,
      "loss": 0.1239,
      "step": 13865
    },
    {
      "epoch": 0.21954811026489543,
      "grad_norm": 0.4084041118621826,
      "learning_rate": 7.804518897351047e-06,
      "loss": 0.5304,
      "step": 13866
    },
    {
      "epoch": 0.2195639438225375,
      "grad_norm": 0.2580694854259491,
      "learning_rate": 7.804360561774626e-06,
      "loss": 0.0705,
      "step": 13867
    },
    {
      "epoch": 0.21957977738017956,
      "grad_norm": 0.30108270049095154,
      "learning_rate": 7.804202226198205e-06,
      "loss": 0.1073,
      "step": 13868
    },
    {
      "epoch": 0.21959561093782162,
      "grad_norm": 0.04639287292957306,
      "learning_rate": 7.804043890621784e-06,
      "loss": 0.0026,
      "step": 13869
    },
    {
      "epoch": 0.2196114444954637,
      "grad_norm": 0.5762805938720703,
      "learning_rate": 7.803885555045365e-06,
      "loss": 0.1425,
      "step": 13870
    },
    {
      "epoch": 0.21962727805310575,
      "grad_norm": 0.3901158571243286,
      "learning_rate": 7.803727219468942e-06,
      "loss": 0.1459,
      "step": 13871
    },
    {
      "epoch": 0.21964311161074782,
      "grad_norm": 0.18800272047519684,
      "learning_rate": 7.803568883892523e-06,
      "loss": 0.0584,
      "step": 13872
    },
    {
      "epoch": 0.21965894516838988,
      "grad_norm": 0.27407413721084595,
      "learning_rate": 7.803410548316102e-06,
      "loss": 0.0505,
      "step": 13873
    },
    {
      "epoch": 0.21967477872603194,
      "grad_norm": 0.04591500386595726,
      "learning_rate": 7.803252212739681e-06,
      "loss": 0.0014,
      "step": 13874
    },
    {
      "epoch": 0.219690612283674,
      "grad_norm": 0.0022499889601022005,
      "learning_rate": 7.80309387716326e-06,
      "loss": 0.0,
      "step": 13875
    },
    {
      "epoch": 0.21970644584131607,
      "grad_norm": 0.33249643445014954,
      "learning_rate": 7.802935541586841e-06,
      "loss": 0.0665,
      "step": 13876
    },
    {
      "epoch": 0.21972227939895816,
      "grad_norm": 0.005469075869768858,
      "learning_rate": 7.802777206010418e-06,
      "loss": 0.0001,
      "step": 13877
    },
    {
      "epoch": 0.21973811295660023,
      "grad_norm": 0.0488923154771328,
      "learning_rate": 7.802618870433999e-06,
      "loss": 0.0012,
      "step": 13878
    },
    {
      "epoch": 0.2197539465142423,
      "grad_norm": 0.3659834563732147,
      "learning_rate": 7.802460534857578e-06,
      "loss": 0.0987,
      "step": 13879
    },
    {
      "epoch": 0.21976978007188436,
      "grad_norm": 0.6017483472824097,
      "learning_rate": 7.802302199281157e-06,
      "loss": 0.3526,
      "step": 13880
    },
    {
      "epoch": 0.21978561362952642,
      "grad_norm": 0.11492086946964264,
      "learning_rate": 7.802143863704736e-06,
      "loss": 0.0228,
      "step": 13881
    },
    {
      "epoch": 0.21980144718716849,
      "grad_norm": 0.2889765202999115,
      "learning_rate": 7.801985528128317e-06,
      "loss": 0.109,
      "step": 13882
    },
    {
      "epoch": 0.21981728074481055,
      "grad_norm": 0.4397589862346649,
      "learning_rate": 7.801827192551894e-06,
      "loss": 0.0785,
      "step": 13883
    },
    {
      "epoch": 0.21983311430245261,
      "grad_norm": 0.0036215786822140217,
      "learning_rate": 7.801668856975474e-06,
      "loss": 0.0001,
      "step": 13884
    },
    {
      "epoch": 0.21984894786009468,
      "grad_norm": 0.4178384840488434,
      "learning_rate": 7.801510521399054e-06,
      "loss": 0.2168,
      "step": 13885
    },
    {
      "epoch": 0.21986478141773674,
      "grad_norm": 0.3045002520084381,
      "learning_rate": 7.801352185822633e-06,
      "loss": 0.096,
      "step": 13886
    },
    {
      "epoch": 0.2198806149753788,
      "grad_norm": 0.2757869362831116,
      "learning_rate": 7.801193850246212e-06,
      "loss": 0.0762,
      "step": 13887
    },
    {
      "epoch": 0.21989644853302087,
      "grad_norm": 0.013486145995557308,
      "learning_rate": 7.801035514669792e-06,
      "loss": 0.0006,
      "step": 13888
    },
    {
      "epoch": 0.21991228209066296,
      "grad_norm": 0.49918225407600403,
      "learning_rate": 7.80087717909337e-06,
      "loss": 0.0673,
      "step": 13889
    },
    {
      "epoch": 0.21992811564830503,
      "grad_norm": 0.4606536626815796,
      "learning_rate": 7.80071884351695e-06,
      "loss": 0.0833,
      "step": 13890
    },
    {
      "epoch": 0.2199439492059471,
      "grad_norm": 0.8660338521003723,
      "learning_rate": 7.80056050794053e-06,
      "loss": 0.1948,
      "step": 13891
    },
    {
      "epoch": 0.21995978276358916,
      "grad_norm": 0.23431773483753204,
      "learning_rate": 7.80040217236411e-06,
      "loss": 0.0932,
      "step": 13892
    },
    {
      "epoch": 0.21997561632123122,
      "grad_norm": 0.025915278121829033,
      "learning_rate": 7.800243836787689e-06,
      "loss": 0.0006,
      "step": 13893
    },
    {
      "epoch": 0.21999144987887329,
      "grad_norm": 0.6041380167007446,
      "learning_rate": 7.800085501211268e-06,
      "loss": 0.1205,
      "step": 13894
    },
    {
      "epoch": 0.22000728343651535,
      "grad_norm": 0.4847448766231537,
      "learning_rate": 7.799927165634847e-06,
      "loss": 0.0857,
      "step": 13895
    },
    {
      "epoch": 0.2200231169941574,
      "grad_norm": 0.22616823017597198,
      "learning_rate": 7.799768830058426e-06,
      "loss": 0.0754,
      "step": 13896
    },
    {
      "epoch": 0.22003895055179948,
      "grad_norm": 0.6580474376678467,
      "learning_rate": 7.799610494482007e-06,
      "loss": 0.2365,
      "step": 13897
    },
    {
      "epoch": 0.22005478410944154,
      "grad_norm": 0.48519167304039,
      "learning_rate": 7.799452158905586e-06,
      "loss": 0.0982,
      "step": 13898
    },
    {
      "epoch": 0.2200706176670836,
      "grad_norm": 0.4960482120513916,
      "learning_rate": 7.799293823329165e-06,
      "loss": 0.02,
      "step": 13899
    },
    {
      "epoch": 0.22008645122472567,
      "grad_norm": 0.26312047243118286,
      "learning_rate": 7.799135487752744e-06,
      "loss": 0.1346,
      "step": 13900
    },
    {
      "epoch": 0.22010228478236776,
      "grad_norm": 0.40652185678482056,
      "learning_rate": 7.798977152176323e-06,
      "loss": 0.1371,
      "step": 13901
    },
    {
      "epoch": 0.22011811834000983,
      "grad_norm": 0.32488375902175903,
      "learning_rate": 7.798818816599902e-06,
      "loss": 0.2377,
      "step": 13902
    },
    {
      "epoch": 0.2201339518976519,
      "grad_norm": 0.20838038623332977,
      "learning_rate": 7.798660481023483e-06,
      "loss": 0.0782,
      "step": 13903
    },
    {
      "epoch": 0.22014978545529396,
      "grad_norm": 0.34957069158554077,
      "learning_rate": 7.798502145447062e-06,
      "loss": 0.0793,
      "step": 13904
    },
    {
      "epoch": 0.22016561901293602,
      "grad_norm": 0.20746693015098572,
      "learning_rate": 7.798343809870641e-06,
      "loss": 0.0385,
      "step": 13905
    },
    {
      "epoch": 0.22018145257057808,
      "grad_norm": 0.019429074600338936,
      "learning_rate": 7.79818547429422e-06,
      "loss": 0.0007,
      "step": 13906
    },
    {
      "epoch": 0.22019728612822015,
      "grad_norm": 0.5809239149093628,
      "learning_rate": 7.798027138717799e-06,
      "loss": 0.0372,
      "step": 13907
    },
    {
      "epoch": 0.2202131196858622,
      "grad_norm": 0.025656986981630325,
      "learning_rate": 7.797868803141378e-06,
      "loss": 0.0002,
      "step": 13908
    },
    {
      "epoch": 0.22022895324350428,
      "grad_norm": 1.1870359182357788,
      "learning_rate": 7.797710467564957e-06,
      "loss": 0.2621,
      "step": 13909
    },
    {
      "epoch": 0.22024478680114634,
      "grad_norm": 0.6606020927429199,
      "learning_rate": 7.797552131988538e-06,
      "loss": 0.0682,
      "step": 13910
    },
    {
      "epoch": 0.2202606203587884,
      "grad_norm": 0.4594016373157501,
      "learning_rate": 7.797393796412115e-06,
      "loss": 0.0647,
      "step": 13911
    },
    {
      "epoch": 0.22027645391643047,
      "grad_norm": 0.004485830664634705,
      "learning_rate": 7.797235460835696e-06,
      "loss": 0.0002,
      "step": 13912
    },
    {
      "epoch": 0.22029228747407256,
      "grad_norm": 0.00035378235043026507,
      "learning_rate": 7.797077125259275e-06,
      "loss": 0.0,
      "step": 13913
    },
    {
      "epoch": 0.22030812103171463,
      "grad_norm": 0.45058131217956543,
      "learning_rate": 7.796918789682854e-06,
      "loss": 0.0883,
      "step": 13914
    },
    {
      "epoch": 0.2203239545893567,
      "grad_norm": 0.30545008182525635,
      "learning_rate": 7.796760454106433e-06,
      "loss": 0.097,
      "step": 13915
    },
    {
      "epoch": 0.22033978814699876,
      "grad_norm": 0.747494637966156,
      "learning_rate": 7.796602118530013e-06,
      "loss": 0.1633,
      "step": 13916
    },
    {
      "epoch": 0.22035562170464082,
      "grad_norm": 0.3080812394618988,
      "learning_rate": 7.796443782953592e-06,
      "loss": 0.197,
      "step": 13917
    },
    {
      "epoch": 0.22037145526228288,
      "grad_norm": 0.7117193937301636,
      "learning_rate": 7.796285447377172e-06,
      "loss": 0.147,
      "step": 13918
    },
    {
      "epoch": 0.22038728881992495,
      "grad_norm": 0.017946377396583557,
      "learning_rate": 7.796127111800751e-06,
      "loss": 0.0008,
      "step": 13919
    },
    {
      "epoch": 0.220403122377567,
      "grad_norm": 0.7837308645248413,
      "learning_rate": 7.79596877622433e-06,
      "loss": 0.757,
      "step": 13920
    },
    {
      "epoch": 0.22041895593520908,
      "grad_norm": 0.4623350203037262,
      "learning_rate": 7.79581044064791e-06,
      "loss": 0.2254,
      "step": 13921
    },
    {
      "epoch": 0.22043478949285114,
      "grad_norm": 0.004848214332014322,
      "learning_rate": 7.795652105071489e-06,
      "loss": 0.0002,
      "step": 13922
    },
    {
      "epoch": 0.2204506230504932,
      "grad_norm": 0.4577270746231079,
      "learning_rate": 7.795493769495068e-06,
      "loss": 0.3982,
      "step": 13923
    },
    {
      "epoch": 0.22046645660813527,
      "grad_norm": 0.49389639496803284,
      "learning_rate": 7.795335433918649e-06,
      "loss": 0.1551,
      "step": 13924
    },
    {
      "epoch": 0.22048229016577736,
      "grad_norm": 0.18256588280200958,
      "learning_rate": 7.795177098342228e-06,
      "loss": 0.043,
      "step": 13925
    },
    {
      "epoch": 0.22049812372341943,
      "grad_norm": 0.21958740055561066,
      "learning_rate": 7.795018762765807e-06,
      "loss": 0.0467,
      "step": 13926
    },
    {
      "epoch": 0.2205139572810615,
      "grad_norm": 0.27326807379722595,
      "learning_rate": 7.794860427189386e-06,
      "loss": 0.0715,
      "step": 13927
    },
    {
      "epoch": 0.22052979083870355,
      "grad_norm": 0.5608763694763184,
      "learning_rate": 7.794702091612965e-06,
      "loss": 0.9348,
      "step": 13928
    },
    {
      "epoch": 0.22054562439634562,
      "grad_norm": 0.5491989850997925,
      "learning_rate": 7.794543756036544e-06,
      "loss": 0.3194,
      "step": 13929
    },
    {
      "epoch": 0.22056145795398768,
      "grad_norm": 0.447832852602005,
      "learning_rate": 7.794385420460125e-06,
      "loss": 0.097,
      "step": 13930
    },
    {
      "epoch": 0.22057729151162975,
      "grad_norm": 0.0018230167916044593,
      "learning_rate": 7.794227084883704e-06,
      "loss": 0.0001,
      "step": 13931
    },
    {
      "epoch": 0.2205931250692718,
      "grad_norm": 0.3771609365940094,
      "learning_rate": 7.794068749307281e-06,
      "loss": 0.1115,
      "step": 13932
    },
    {
      "epoch": 0.22060895862691388,
      "grad_norm": 0.2228320688009262,
      "learning_rate": 7.793910413730862e-06,
      "loss": 0.1385,
      "step": 13933
    },
    {
      "epoch": 0.22062479218455594,
      "grad_norm": 0.6886501908302307,
      "learning_rate": 7.793752078154441e-06,
      "loss": 0.2359,
      "step": 13934
    },
    {
      "epoch": 0.220640625742198,
      "grad_norm": 0.3306851089000702,
      "learning_rate": 7.79359374257802e-06,
      "loss": 0.1042,
      "step": 13935
    },
    {
      "epoch": 0.22065645929984007,
      "grad_norm": 0.00012343267735559493,
      "learning_rate": 7.7934354070016e-06,
      "loss": 0.0,
      "step": 13936
    },
    {
      "epoch": 0.22067229285748216,
      "grad_norm": 0.02228296734392643,
      "learning_rate": 7.79327707142518e-06,
      "loss": 0.0007,
      "step": 13937
    },
    {
      "epoch": 0.22068812641512423,
      "grad_norm": 0.15222705900669098,
      "learning_rate": 7.793118735848757e-06,
      "loss": 0.0564,
      "step": 13938
    },
    {
      "epoch": 0.2207039599727663,
      "grad_norm": 0.44146445393562317,
      "learning_rate": 7.792960400272338e-06,
      "loss": 0.4422,
      "step": 13939
    },
    {
      "epoch": 0.22071979353040835,
      "grad_norm": 0.1502312570810318,
      "learning_rate": 7.792802064695917e-06,
      "loss": 0.0402,
      "step": 13940
    },
    {
      "epoch": 0.22073562708805042,
      "grad_norm": 0.018575306981801987,
      "learning_rate": 7.792643729119496e-06,
      "loss": 0.0008,
      "step": 13941
    },
    {
      "epoch": 0.22075146064569248,
      "grad_norm": 0.5588603019714355,
      "learning_rate": 7.792485393543075e-06,
      "loss": 0.2078,
      "step": 13942
    },
    {
      "epoch": 0.22076729420333455,
      "grad_norm": 0.0017822266090661287,
      "learning_rate": 7.792327057966656e-06,
      "loss": 0.0,
      "step": 13943
    },
    {
      "epoch": 0.2207831277609766,
      "grad_norm": 0.025770336389541626,
      "learning_rate": 7.792168722390234e-06,
      "loss": 0.0005,
      "step": 13944
    },
    {
      "epoch": 0.22079896131861868,
      "grad_norm": 0.20666269958019257,
      "learning_rate": 7.792010386813814e-06,
      "loss": 0.0811,
      "step": 13945
    },
    {
      "epoch": 0.22081479487626074,
      "grad_norm": 0.3165578246116638,
      "learning_rate": 7.791852051237393e-06,
      "loss": 0.0917,
      "step": 13946
    },
    {
      "epoch": 0.2208306284339028,
      "grad_norm": 0.002422458492219448,
      "learning_rate": 7.791693715660972e-06,
      "loss": 0.0001,
      "step": 13947
    },
    {
      "epoch": 0.22084646199154487,
      "grad_norm": 0.008924097754061222,
      "learning_rate": 7.791535380084552e-06,
      "loss": 0.0003,
      "step": 13948
    },
    {
      "epoch": 0.22086229554918696,
      "grad_norm": 0.29969677329063416,
      "learning_rate": 7.791377044508132e-06,
      "loss": 0.0377,
      "step": 13949
    },
    {
      "epoch": 0.22087812910682902,
      "grad_norm": 0.5462522506713867,
      "learning_rate": 7.79121870893171e-06,
      "loss": 0.1443,
      "step": 13950
    },
    {
      "epoch": 0.2208939626644711,
      "grad_norm": 0.699607253074646,
      "learning_rate": 7.79106037335529e-06,
      "loss": 0.0885,
      "step": 13951
    },
    {
      "epoch": 0.22090979622211315,
      "grad_norm": 0.00986533798277378,
      "learning_rate": 7.79090203777887e-06,
      "loss": 0.0004,
      "step": 13952
    },
    {
      "epoch": 0.22092562977975522,
      "grad_norm": 0.7317633628845215,
      "learning_rate": 7.790743702202449e-06,
      "loss": 0.5397,
      "step": 13953
    },
    {
      "epoch": 0.22094146333739728,
      "grad_norm": 0.5933656692504883,
      "learning_rate": 7.790585366626028e-06,
      "loss": 0.5057,
      "step": 13954
    },
    {
      "epoch": 0.22095729689503935,
      "grad_norm": 0.0001391926925862208,
      "learning_rate": 7.790427031049607e-06,
      "loss": 0.0,
      "step": 13955
    },
    {
      "epoch": 0.2209731304526814,
      "grad_norm": 0.4803476631641388,
      "learning_rate": 7.790268695473186e-06,
      "loss": 0.1072,
      "step": 13956
    },
    {
      "epoch": 0.22098896401032347,
      "grad_norm": 0.3113129436969757,
      "learning_rate": 7.790110359896765e-06,
      "loss": 0.1005,
      "step": 13957
    },
    {
      "epoch": 0.22100479756796554,
      "grad_norm": 0.01095263659954071,
      "learning_rate": 7.789952024320346e-06,
      "loss": 0.0004,
      "step": 13958
    },
    {
      "epoch": 0.2210206311256076,
      "grad_norm": 0.0362577922642231,
      "learning_rate": 7.789793688743925e-06,
      "loss": 0.0021,
      "step": 13959
    },
    {
      "epoch": 0.22103646468324967,
      "grad_norm": 0.473766028881073,
      "learning_rate": 7.789635353167504e-06,
      "loss": 0.3772,
      "step": 13960
    },
    {
      "epoch": 0.22105229824089176,
      "grad_norm": 0.009428414516150951,
      "learning_rate": 7.789477017591083e-06,
      "loss": 0.0004,
      "step": 13961
    },
    {
      "epoch": 0.22106813179853382,
      "grad_norm": 0.034559499472379684,
      "learning_rate": 7.789318682014662e-06,
      "loss": 0.0021,
      "step": 13962
    },
    {
      "epoch": 0.2210839653561759,
      "grad_norm": 9.060998854693025e-05,
      "learning_rate": 7.789160346438241e-06,
      "loss": 0.0,
      "step": 13963
    },
    {
      "epoch": 0.22109979891381795,
      "grad_norm": 0.2899406850337982,
      "learning_rate": 7.789002010861822e-06,
      "loss": 0.0484,
      "step": 13964
    },
    {
      "epoch": 0.22111563247146002,
      "grad_norm": 0.0007075509638525546,
      "learning_rate": 7.788843675285401e-06,
      "loss": 0.0,
      "step": 13965
    },
    {
      "epoch": 0.22113146602910208,
      "grad_norm": 0.027497608214616776,
      "learning_rate": 7.78868533970898e-06,
      "loss": 0.0012,
      "step": 13966
    },
    {
      "epoch": 0.22114729958674414,
      "grad_norm": 0.3695438802242279,
      "learning_rate": 7.788527004132559e-06,
      "loss": 0.1687,
      "step": 13967
    },
    {
      "epoch": 0.2211631331443862,
      "grad_norm": 0.28800785541534424,
      "learning_rate": 7.788368668556138e-06,
      "loss": 0.0548,
      "step": 13968
    },
    {
      "epoch": 0.22117896670202827,
      "grad_norm": 0.4871762692928314,
      "learning_rate": 7.788210332979717e-06,
      "loss": 0.1195,
      "step": 13969
    },
    {
      "epoch": 0.22119480025967034,
      "grad_norm": 0.057836614549160004,
      "learning_rate": 7.788051997403298e-06,
      "loss": 0.0032,
      "step": 13970
    },
    {
      "epoch": 0.2212106338173124,
      "grad_norm": 0.2097359150648117,
      "learning_rate": 7.787893661826877e-06,
      "loss": 0.0647,
      "step": 13971
    },
    {
      "epoch": 0.22122646737495447,
      "grad_norm": 0.20087623596191406,
      "learning_rate": 7.787735326250456e-06,
      "loss": 0.0132,
      "step": 13972
    },
    {
      "epoch": 0.22124230093259656,
      "grad_norm": 0.5565516352653503,
      "learning_rate": 7.787576990674035e-06,
      "loss": 0.1452,
      "step": 13973
    },
    {
      "epoch": 0.22125813449023862,
      "grad_norm": 0.4359579086303711,
      "learning_rate": 7.787418655097614e-06,
      "loss": 0.1267,
      "step": 13974
    },
    {
      "epoch": 0.2212739680478807,
      "grad_norm": 0.4606800675392151,
      "learning_rate": 7.787260319521193e-06,
      "loss": 0.132,
      "step": 13975
    },
    {
      "epoch": 0.22128980160552275,
      "grad_norm": 0.3698311150074005,
      "learning_rate": 7.787101983944774e-06,
      "loss": 0.1479,
      "step": 13976
    },
    {
      "epoch": 0.22130563516316482,
      "grad_norm": 0.3730059862136841,
      "learning_rate": 7.786943648368353e-06,
      "loss": 0.1351,
      "step": 13977
    },
    {
      "epoch": 0.22132146872080688,
      "grad_norm": 0.36259523034095764,
      "learning_rate": 7.786785312791932e-06,
      "loss": 0.1748,
      "step": 13978
    },
    {
      "epoch": 0.22133730227844894,
      "grad_norm": 0.7655957341194153,
      "learning_rate": 7.786626977215511e-06,
      "loss": 0.254,
      "step": 13979
    },
    {
      "epoch": 0.221353135836091,
      "grad_norm": 0.017720147967338562,
      "learning_rate": 7.78646864163909e-06,
      "loss": 0.0006,
      "step": 13980
    },
    {
      "epoch": 0.22136896939373307,
      "grad_norm": 0.3914668560028076,
      "learning_rate": 7.78631030606267e-06,
      "loss": 0.0793,
      "step": 13981
    },
    {
      "epoch": 0.22138480295137514,
      "grad_norm": 0.009939435869455338,
      "learning_rate": 7.786151970486249e-06,
      "loss": 0.0005,
      "step": 13982
    },
    {
      "epoch": 0.2214006365090172,
      "grad_norm": 0.8218772411346436,
      "learning_rate": 7.785993634909828e-06,
      "loss": 0.599,
      "step": 13983
    },
    {
      "epoch": 0.22141647006665927,
      "grad_norm": 0.03326571360230446,
      "learning_rate": 7.785835299333407e-06,
      "loss": 0.0016,
      "step": 13984
    },
    {
      "epoch": 0.22143230362430136,
      "grad_norm": 0.2312299609184265,
      "learning_rate": 7.785676963756988e-06,
      "loss": 0.0834,
      "step": 13985
    },
    {
      "epoch": 0.22144813718194342,
      "grad_norm": 0.9382904171943665,
      "learning_rate": 7.785518628180567e-06,
      "loss": 0.8771,
      "step": 13986
    },
    {
      "epoch": 0.2214639707395855,
      "grad_norm": 0.3090384304523468,
      "learning_rate": 7.785360292604146e-06,
      "loss": 0.2264,
      "step": 13987
    },
    {
      "epoch": 0.22147980429722755,
      "grad_norm": 0.28263208270072937,
      "learning_rate": 7.785201957027725e-06,
      "loss": 0.1108,
      "step": 13988
    },
    {
      "epoch": 0.22149563785486961,
      "grad_norm": 0.3128477931022644,
      "learning_rate": 7.785043621451304e-06,
      "loss": 0.1418,
      "step": 13989
    },
    {
      "epoch": 0.22151147141251168,
      "grad_norm": 0.0001382878836011514,
      "learning_rate": 7.784885285874883e-06,
      "loss": 0.0,
      "step": 13990
    },
    {
      "epoch": 0.22152730497015374,
      "grad_norm": 0.7907653450965881,
      "learning_rate": 7.784726950298464e-06,
      "loss": 0.2089,
      "step": 13991
    },
    {
      "epoch": 0.2215431385277958,
      "grad_norm": 0.49166610836982727,
      "learning_rate": 7.784568614722043e-06,
      "loss": 0.1611,
      "step": 13992
    },
    {
      "epoch": 0.22155897208543787,
      "grad_norm": 0.766093373298645,
      "learning_rate": 7.784410279145622e-06,
      "loss": 0.0656,
      "step": 13993
    },
    {
      "epoch": 0.22157480564307994,
      "grad_norm": 0.25809094309806824,
      "learning_rate": 7.784251943569201e-06,
      "loss": 0.1112,
      "step": 13994
    },
    {
      "epoch": 0.221590639200722,
      "grad_norm": 1.052700161933899,
      "learning_rate": 7.78409360799278e-06,
      "loss": 0.2438,
      "step": 13995
    },
    {
      "epoch": 0.22160647275836406,
      "grad_norm": 0.0007414087885990739,
      "learning_rate": 7.78393527241636e-06,
      "loss": 0.0,
      "step": 13996
    },
    {
      "epoch": 0.22162230631600616,
      "grad_norm": 0.0030293413437902927,
      "learning_rate": 7.78377693683994e-06,
      "loss": 0.0001,
      "step": 13997
    },
    {
      "epoch": 0.22163813987364822,
      "grad_norm": 0.699089765548706,
      "learning_rate": 7.783618601263519e-06,
      "loss": 0.1449,
      "step": 13998
    },
    {
      "epoch": 0.22165397343129029,
      "grad_norm": 0.6660938262939453,
      "learning_rate": 7.783460265687098e-06,
      "loss": 0.8532,
      "step": 13999
    },
    {
      "epoch": 0.22166980698893235,
      "grad_norm": 0.0028507497627288103,
      "learning_rate": 7.783301930110677e-06,
      "loss": 0.0001,
      "step": 14000
    },
    {
      "epoch": 0.22168564054657441,
      "grad_norm": 8.973537478595972e-05,
      "learning_rate": 7.783143594534256e-06,
      "loss": 0.0,
      "step": 14001
    },
    {
      "epoch": 0.22170147410421648,
      "grad_norm": 0.007366047240793705,
      "learning_rate": 7.782985258957835e-06,
      "loss": 0.0003,
      "step": 14002
    },
    {
      "epoch": 0.22171730766185854,
      "grad_norm": 0.3728031814098358,
      "learning_rate": 7.782826923381414e-06,
      "loss": 0.3214,
      "step": 14003
    },
    {
      "epoch": 0.2217331412195006,
      "grad_norm": 0.2037196308374405,
      "learning_rate": 7.782668587804995e-06,
      "loss": 0.0538,
      "step": 14004
    },
    {
      "epoch": 0.22174897477714267,
      "grad_norm": 0.021617600694298744,
      "learning_rate": 7.782510252228573e-06,
      "loss": 0.0011,
      "step": 14005
    },
    {
      "epoch": 0.22176480833478474,
      "grad_norm": 0.5562549829483032,
      "learning_rate": 7.782351916652153e-06,
      "loss": 0.4208,
      "step": 14006
    },
    {
      "epoch": 0.2217806418924268,
      "grad_norm": 0.4042578637599945,
      "learning_rate": 7.782193581075732e-06,
      "loss": 0.0419,
      "step": 14007
    },
    {
      "epoch": 0.22179647545006886,
      "grad_norm": 0.18213346600532532,
      "learning_rate": 7.782035245499312e-06,
      "loss": 0.0043,
      "step": 14008
    },
    {
      "epoch": 0.22181230900771096,
      "grad_norm": 0.35205405950546265,
      "learning_rate": 7.78187690992289e-06,
      "loss": 0.0399,
      "step": 14009
    },
    {
      "epoch": 0.22182814256535302,
      "grad_norm": 0.5063204169273376,
      "learning_rate": 7.781718574346471e-06,
      "loss": 0.0233,
      "step": 14010
    },
    {
      "epoch": 0.22184397612299508,
      "grad_norm": 0.07564519345760345,
      "learning_rate": 7.781560238770049e-06,
      "loss": 0.0038,
      "step": 14011
    },
    {
      "epoch": 0.22185980968063715,
      "grad_norm": 0.00737800495699048,
      "learning_rate": 7.78140190319363e-06,
      "loss": 0.0003,
      "step": 14012
    },
    {
      "epoch": 0.2218756432382792,
      "grad_norm": 0.10050952434539795,
      "learning_rate": 7.781243567617209e-06,
      "loss": 0.0062,
      "step": 14013
    },
    {
      "epoch": 0.22189147679592128,
      "grad_norm": 0.4322291314601898,
      "learning_rate": 7.781085232040788e-06,
      "loss": 0.106,
      "step": 14014
    },
    {
      "epoch": 0.22190731035356334,
      "grad_norm": 0.46730324625968933,
      "learning_rate": 7.780926896464367e-06,
      "loss": 0.0731,
      "step": 14015
    },
    {
      "epoch": 0.2219231439112054,
      "grad_norm": 0.3158356845378876,
      "learning_rate": 7.780768560887948e-06,
      "loss": 0.1629,
      "step": 14016
    },
    {
      "epoch": 0.22193897746884747,
      "grad_norm": 0.010135234333574772,
      "learning_rate": 7.780610225311525e-06,
      "loss": 0.0005,
      "step": 14017
    },
    {
      "epoch": 0.22195481102648953,
      "grad_norm": 0.5270156264305115,
      "learning_rate": 7.780451889735106e-06,
      "loss": 0.0662,
      "step": 14018
    },
    {
      "epoch": 0.2219706445841316,
      "grad_norm": 0.35522714257240295,
      "learning_rate": 7.780293554158685e-06,
      "loss": 0.1241,
      "step": 14019
    },
    {
      "epoch": 0.22198647814177366,
      "grad_norm": 0.3373887538909912,
      "learning_rate": 7.780135218582264e-06,
      "loss": 0.2325,
      "step": 14020
    },
    {
      "epoch": 0.22200231169941576,
      "grad_norm": 0.5770066380500793,
      "learning_rate": 7.779976883005843e-06,
      "loss": 0.6841,
      "step": 14021
    },
    {
      "epoch": 0.22201814525705782,
      "grad_norm": 0.25606897473335266,
      "learning_rate": 7.779818547429424e-06,
      "loss": 0.0768,
      "step": 14022
    },
    {
      "epoch": 0.22203397881469988,
      "grad_norm": 0.14846427738666534,
      "learning_rate": 7.779660211853001e-06,
      "loss": 0.0257,
      "step": 14023
    },
    {
      "epoch": 0.22204981237234195,
      "grad_norm": 0.005315858870744705,
      "learning_rate": 7.779501876276582e-06,
      "loss": 0.0002,
      "step": 14024
    },
    {
      "epoch": 0.222065645929984,
      "grad_norm": 0.22100621461868286,
      "learning_rate": 7.779343540700161e-06,
      "loss": 0.0432,
      "step": 14025
    },
    {
      "epoch": 0.22208147948762608,
      "grad_norm": 0.0453631617128849,
      "learning_rate": 7.77918520512374e-06,
      "loss": 0.002,
      "step": 14026
    },
    {
      "epoch": 0.22209731304526814,
      "grad_norm": 0.5561124086380005,
      "learning_rate": 7.77902686954732e-06,
      "loss": 0.0903,
      "step": 14027
    },
    {
      "epoch": 0.2221131466029102,
      "grad_norm": 0.2175445556640625,
      "learning_rate": 7.778868533970898e-06,
      "loss": 0.0774,
      "step": 14028
    },
    {
      "epoch": 0.22212898016055227,
      "grad_norm": 0.3653930425643921,
      "learning_rate": 7.778710198394477e-06,
      "loss": 0.0981,
      "step": 14029
    },
    {
      "epoch": 0.22214481371819433,
      "grad_norm": 0.4053765833377838,
      "learning_rate": 7.778551862818056e-06,
      "loss": 0.1483,
      "step": 14030
    },
    {
      "epoch": 0.2221606472758364,
      "grad_norm": 0.5446498990058899,
      "learning_rate": 7.778393527241637e-06,
      "loss": 0.0448,
      "step": 14031
    },
    {
      "epoch": 0.22217648083347846,
      "grad_norm": 0.6473712921142578,
      "learning_rate": 7.778235191665216e-06,
      "loss": 0.331,
      "step": 14032
    },
    {
      "epoch": 0.22219231439112055,
      "grad_norm": 0.2541395127773285,
      "learning_rate": 7.778076856088795e-06,
      "loss": 0.0772,
      "step": 14033
    },
    {
      "epoch": 0.22220814794876262,
      "grad_norm": 0.6202847361564636,
      "learning_rate": 7.777918520512374e-06,
      "loss": 0.8018,
      "step": 14034
    },
    {
      "epoch": 0.22222398150640468,
      "grad_norm": 0.2442694753408432,
      "learning_rate": 7.777760184935953e-06,
      "loss": 0.0661,
      "step": 14035
    },
    {
      "epoch": 0.22223981506404675,
      "grad_norm": 0.42838048934936523,
      "learning_rate": 7.777601849359533e-06,
      "loss": 0.1092,
      "step": 14036
    },
    {
      "epoch": 0.2222556486216888,
      "grad_norm": 0.3047765791416168,
      "learning_rate": 7.777443513783113e-06,
      "loss": 0.0063,
      "step": 14037
    },
    {
      "epoch": 0.22227148217933088,
      "grad_norm": 0.6288145780563354,
      "learning_rate": 7.777285178206692e-06,
      "loss": 0.3435,
      "step": 14038
    },
    {
      "epoch": 0.22228731573697294,
      "grad_norm": 0.45420554280281067,
      "learning_rate": 7.777126842630272e-06,
      "loss": 0.0928,
      "step": 14039
    },
    {
      "epoch": 0.222303149294615,
      "grad_norm": 0.09577561914920807,
      "learning_rate": 7.77696850705385e-06,
      "loss": 0.0015,
      "step": 14040
    },
    {
      "epoch": 0.22231898285225707,
      "grad_norm": 0.28294989466667175,
      "learning_rate": 7.77681017147743e-06,
      "loss": 0.0143,
      "step": 14041
    },
    {
      "epoch": 0.22233481640989913,
      "grad_norm": 0.2808386981487274,
      "learning_rate": 7.776651835901009e-06,
      "loss": 0.0477,
      "step": 14042
    },
    {
      "epoch": 0.2223506499675412,
      "grad_norm": 0.1781066507101059,
      "learning_rate": 7.77649350032459e-06,
      "loss": 0.0588,
      "step": 14043
    },
    {
      "epoch": 0.22236648352518326,
      "grad_norm": 0.5981312990188599,
      "learning_rate": 7.776335164748167e-06,
      "loss": 0.4253,
      "step": 14044
    },
    {
      "epoch": 0.22238231708282535,
      "grad_norm": 0.2195531576871872,
      "learning_rate": 7.776176829171748e-06,
      "loss": 0.051,
      "step": 14045
    },
    {
      "epoch": 0.22239815064046742,
      "grad_norm": 0.3543233275413513,
      "learning_rate": 7.776018493595327e-06,
      "loss": 0.0842,
      "step": 14046
    },
    {
      "epoch": 0.22241398419810948,
      "grad_norm": 0.32570740580558777,
      "learning_rate": 7.775860158018906e-06,
      "loss": 0.0979,
      "step": 14047
    },
    {
      "epoch": 0.22242981775575155,
      "grad_norm": 0.29210829734802246,
      "learning_rate": 7.775701822442485e-06,
      "loss": 0.075,
      "step": 14048
    },
    {
      "epoch": 0.2224456513133936,
      "grad_norm": 0.7672680020332336,
      "learning_rate": 7.775543486866066e-06,
      "loss": 0.4369,
      "step": 14049
    },
    {
      "epoch": 0.22246148487103568,
      "grad_norm": 0.16038420796394348,
      "learning_rate": 7.775385151289643e-06,
      "loss": 0.0585,
      "step": 14050
    },
    {
      "epoch": 0.22247731842867774,
      "grad_norm": 0.3710343837738037,
      "learning_rate": 7.775226815713222e-06,
      "loss": 0.1576,
      "step": 14051
    },
    {
      "epoch": 0.2224931519863198,
      "grad_norm": 0.4763433039188385,
      "learning_rate": 7.775068480136803e-06,
      "loss": 0.1663,
      "step": 14052
    },
    {
      "epoch": 0.22250898554396187,
      "grad_norm": 0.036675918847322464,
      "learning_rate": 7.774910144560382e-06,
      "loss": 0.0017,
      "step": 14053
    },
    {
      "epoch": 0.22252481910160393,
      "grad_norm": 0.21634024381637573,
      "learning_rate": 7.774751808983961e-06,
      "loss": 0.0758,
      "step": 14054
    },
    {
      "epoch": 0.222540652659246,
      "grad_norm": 0.30373355746269226,
      "learning_rate": 7.77459347340754e-06,
      "loss": 0.0985,
      "step": 14055
    },
    {
      "epoch": 0.22255648621688806,
      "grad_norm": 0.4204290807247162,
      "learning_rate": 7.77443513783112e-06,
      "loss": 0.5417,
      "step": 14056
    },
    {
      "epoch": 0.22257231977453015,
      "grad_norm": 0.2930818498134613,
      "learning_rate": 7.774276802254698e-06,
      "loss": 0.0362,
      "step": 14057
    },
    {
      "epoch": 0.22258815333217222,
      "grad_norm": 0.7635977268218994,
      "learning_rate": 7.774118466678279e-06,
      "loss": 0.1654,
      "step": 14058
    },
    {
      "epoch": 0.22260398688981428,
      "grad_norm": 0.4262533485889435,
      "learning_rate": 7.773960131101858e-06,
      "loss": 0.0756,
      "step": 14059
    },
    {
      "epoch": 0.22261982044745635,
      "grad_norm": 0.1516362726688385,
      "learning_rate": 7.773801795525437e-06,
      "loss": 0.0307,
      "step": 14060
    },
    {
      "epoch": 0.2226356540050984,
      "grad_norm": 0.024619627743959427,
      "learning_rate": 7.773643459949016e-06,
      "loss": 0.0008,
      "step": 14061
    },
    {
      "epoch": 0.22265148756274047,
      "grad_norm": 0.4649530351161957,
      "learning_rate": 7.773485124372595e-06,
      "loss": 0.0107,
      "step": 14062
    },
    {
      "epoch": 0.22266732112038254,
      "grad_norm": 0.3353377878665924,
      "learning_rate": 7.773326788796174e-06,
      "loss": 0.0333,
      "step": 14063
    },
    {
      "epoch": 0.2226831546780246,
      "grad_norm": 0.006302247289568186,
      "learning_rate": 7.773168453219755e-06,
      "loss": 0.0002,
      "step": 14064
    },
    {
      "epoch": 0.22269898823566667,
      "grad_norm": 0.2740786671638489,
      "learning_rate": 7.773010117643334e-06,
      "loss": 0.0849,
      "step": 14065
    },
    {
      "epoch": 0.22271482179330873,
      "grad_norm": 0.016485942527651787,
      "learning_rate": 7.772851782066913e-06,
      "loss": 0.0005,
      "step": 14066
    },
    {
      "epoch": 0.2227306553509508,
      "grad_norm": 0.3938021957874298,
      "learning_rate": 7.772693446490493e-06,
      "loss": 0.2048,
      "step": 14067
    },
    {
      "epoch": 0.22274648890859286,
      "grad_norm": 0.016249172389507294,
      "learning_rate": 7.772535110914072e-06,
      "loss": 0.0006,
      "step": 14068
    },
    {
      "epoch": 0.22276232246623495,
      "grad_norm": 0.01747528836131096,
      "learning_rate": 7.77237677533765e-06,
      "loss": 0.0005,
      "step": 14069
    },
    {
      "epoch": 0.22277815602387702,
      "grad_norm": 0.08471411466598511,
      "learning_rate": 7.772218439761231e-06,
      "loss": 0.0012,
      "step": 14070
    },
    {
      "epoch": 0.22279398958151908,
      "grad_norm": 0.5585851669311523,
      "learning_rate": 7.77206010418481e-06,
      "loss": 0.0515,
      "step": 14071
    },
    {
      "epoch": 0.22280982313916115,
      "grad_norm": 0.1993463784456253,
      "learning_rate": 7.77190176860839e-06,
      "loss": 0.0833,
      "step": 14072
    },
    {
      "epoch": 0.2228256566968032,
      "grad_norm": 0.24637606739997864,
      "learning_rate": 7.771743433031969e-06,
      "loss": 0.0377,
      "step": 14073
    },
    {
      "epoch": 0.22284149025444527,
      "grad_norm": 0.20656666159629822,
      "learning_rate": 7.771585097455548e-06,
      "loss": 0.0888,
      "step": 14074
    },
    {
      "epoch": 0.22285732381208734,
      "grad_norm": 0.00015783229900989681,
      "learning_rate": 7.771426761879127e-06,
      "loss": 0.0,
      "step": 14075
    },
    {
      "epoch": 0.2228731573697294,
      "grad_norm": 0.24704135954380035,
      "learning_rate": 7.771268426302706e-06,
      "loss": 0.0691,
      "step": 14076
    },
    {
      "epoch": 0.22288899092737147,
      "grad_norm": 0.3922399580478668,
      "learning_rate": 7.771110090726287e-06,
      "loss": 0.0923,
      "step": 14077
    },
    {
      "epoch": 0.22290482448501353,
      "grad_norm": 0.311771959066391,
      "learning_rate": 7.770951755149864e-06,
      "loss": 0.1201,
      "step": 14078
    },
    {
      "epoch": 0.2229206580426556,
      "grad_norm": 0.3500198423862457,
      "learning_rate": 7.770793419573445e-06,
      "loss": 0.2496,
      "step": 14079
    },
    {
      "epoch": 0.22293649160029766,
      "grad_norm": 0.03793463483452797,
      "learning_rate": 7.770635083997024e-06,
      "loss": 0.0016,
      "step": 14080
    },
    {
      "epoch": 0.22295232515793972,
      "grad_norm": 0.5985443592071533,
      "learning_rate": 7.770476748420603e-06,
      "loss": 0.1743,
      "step": 14081
    },
    {
      "epoch": 0.22296815871558182,
      "grad_norm": 0.3933905065059662,
      "learning_rate": 7.770318412844182e-06,
      "loss": 0.1184,
      "step": 14082
    },
    {
      "epoch": 0.22298399227322388,
      "grad_norm": 0.4727078080177307,
      "learning_rate": 7.770160077267763e-06,
      "loss": 0.2948,
      "step": 14083
    },
    {
      "epoch": 0.22299982583086594,
      "grad_norm": 1.9335622787475586,
      "learning_rate": 7.77000174169134e-06,
      "loss": 0.3494,
      "step": 14084
    },
    {
      "epoch": 0.223015659388508,
      "grad_norm": 0.012969514355063438,
      "learning_rate": 7.769843406114921e-06,
      "loss": 0.0007,
      "step": 14085
    },
    {
      "epoch": 0.22303149294615007,
      "grad_norm": 0.013652021065354347,
      "learning_rate": 7.7696850705385e-06,
      "loss": 0.0006,
      "step": 14086
    },
    {
      "epoch": 0.22304732650379214,
      "grad_norm": 0.2672668695449829,
      "learning_rate": 7.76952673496208e-06,
      "loss": 0.0083,
      "step": 14087
    },
    {
      "epoch": 0.2230631600614342,
      "grad_norm": 0.32793569564819336,
      "learning_rate": 7.769368399385658e-06,
      "loss": 0.1361,
      "step": 14088
    },
    {
      "epoch": 0.22307899361907627,
      "grad_norm": 0.0021086623892188072,
      "learning_rate": 7.769210063809239e-06,
      "loss": 0.0001,
      "step": 14089
    },
    {
      "epoch": 0.22309482717671833,
      "grad_norm": 0.6723477244377136,
      "learning_rate": 7.769051728232816e-06,
      "loss": 0.0601,
      "step": 14090
    },
    {
      "epoch": 0.2231106607343604,
      "grad_norm": 0.32119086384773254,
      "learning_rate": 7.768893392656397e-06,
      "loss": 0.0416,
      "step": 14091
    },
    {
      "epoch": 0.22312649429200246,
      "grad_norm": 0.00029345430084504187,
      "learning_rate": 7.768735057079976e-06,
      "loss": 0.0,
      "step": 14092
    },
    {
      "epoch": 0.22314232784964452,
      "grad_norm": 0.47461292147636414,
      "learning_rate": 7.768576721503555e-06,
      "loss": 0.5272,
      "step": 14093
    },
    {
      "epoch": 0.22315816140728661,
      "grad_norm": 0.05598057433962822,
      "learning_rate": 7.768418385927134e-06,
      "loss": 0.0029,
      "step": 14094
    },
    {
      "epoch": 0.22317399496492868,
      "grad_norm": 0.7372021079063416,
      "learning_rate": 7.768260050350715e-06,
      "loss": 0.203,
      "step": 14095
    },
    {
      "epoch": 0.22318982852257074,
      "grad_norm": 0.3528951108455658,
      "learning_rate": 7.768101714774293e-06,
      "loss": 0.1326,
      "step": 14096
    },
    {
      "epoch": 0.2232056620802128,
      "grad_norm": 0.09513457119464874,
      "learning_rate": 7.767943379197873e-06,
      "loss": 0.0033,
      "step": 14097
    },
    {
      "epoch": 0.22322149563785487,
      "grad_norm": 0.4278787076473236,
      "learning_rate": 7.767785043621452e-06,
      "loss": 0.2148,
      "step": 14098
    },
    {
      "epoch": 0.22323732919549694,
      "grad_norm": 0.3597758114337921,
      "learning_rate": 7.767626708045032e-06,
      "loss": 0.2617,
      "step": 14099
    },
    {
      "epoch": 0.223253162753139,
      "grad_norm": 0.6526500582695007,
      "learning_rate": 7.76746837246861e-06,
      "loss": 0.2259,
      "step": 14100
    },
    {
      "epoch": 0.22326899631078106,
      "grad_norm": 0.30676040053367615,
      "learning_rate": 7.76731003689219e-06,
      "loss": 0.0356,
      "step": 14101
    },
    {
      "epoch": 0.22328482986842313,
      "grad_norm": 0.0002991850196849555,
      "learning_rate": 7.767151701315769e-06,
      "loss": 0.0,
      "step": 14102
    },
    {
      "epoch": 0.2233006634260652,
      "grad_norm": 0.355589896440506,
      "learning_rate": 7.766993365739348e-06,
      "loss": 0.0473,
      "step": 14103
    },
    {
      "epoch": 0.22331649698370726,
      "grad_norm": 0.6571696996688843,
      "learning_rate": 7.766835030162929e-06,
      "loss": 0.7369,
      "step": 14104
    },
    {
      "epoch": 0.22333233054134932,
      "grad_norm": 0.5772483944892883,
      "learning_rate": 7.766676694586508e-06,
      "loss": 0.1488,
      "step": 14105
    },
    {
      "epoch": 0.22334816409899141,
      "grad_norm": 0.26232513785362244,
      "learning_rate": 7.766518359010087e-06,
      "loss": 0.0454,
      "step": 14106
    },
    {
      "epoch": 0.22336399765663348,
      "grad_norm": 0.2596170902252197,
      "learning_rate": 7.766360023433666e-06,
      "loss": 0.1022,
      "step": 14107
    },
    {
      "epoch": 0.22337983121427554,
      "grad_norm": 0.45732393860816956,
      "learning_rate": 7.766201687857245e-06,
      "loss": 0.1856,
      "step": 14108
    },
    {
      "epoch": 0.2233956647719176,
      "grad_norm": 0.021603157743811607,
      "learning_rate": 7.766043352280824e-06,
      "loss": 0.0009,
      "step": 14109
    },
    {
      "epoch": 0.22341149832955967,
      "grad_norm": 0.8404256701469421,
      "learning_rate": 7.765885016704405e-06,
      "loss": 0.1414,
      "step": 14110
    },
    {
      "epoch": 0.22342733188720174,
      "grad_norm": 0.2957722544670105,
      "learning_rate": 7.765726681127982e-06,
      "loss": 0.12,
      "step": 14111
    },
    {
      "epoch": 0.2234431654448438,
      "grad_norm": 0.5869224071502686,
      "learning_rate": 7.765568345551563e-06,
      "loss": 0.8222,
      "step": 14112
    },
    {
      "epoch": 0.22345899900248586,
      "grad_norm": 0.4148314893245697,
      "learning_rate": 7.765410009975142e-06,
      "loss": 0.1485,
      "step": 14113
    },
    {
      "epoch": 0.22347483256012793,
      "grad_norm": 0.002539088949561119,
      "learning_rate": 7.765251674398721e-06,
      "loss": 0.0001,
      "step": 14114
    },
    {
      "epoch": 0.22349066611777,
      "grad_norm": 0.4050542414188385,
      "learning_rate": 7.7650933388223e-06,
      "loss": 0.0977,
      "step": 14115
    },
    {
      "epoch": 0.22350649967541206,
      "grad_norm": 0.37402889132499695,
      "learning_rate": 7.764935003245881e-06,
      "loss": 0.1012,
      "step": 14116
    },
    {
      "epoch": 0.22352233323305412,
      "grad_norm": 0.5207096934318542,
      "learning_rate": 7.764776667669458e-06,
      "loss": 0.496,
      "step": 14117
    },
    {
      "epoch": 0.2235381667906962,
      "grad_norm": 0.17863161861896515,
      "learning_rate": 7.764618332093039e-06,
      "loss": 0.0525,
      "step": 14118
    },
    {
      "epoch": 0.22355400034833828,
      "grad_norm": 0.8465890288352966,
      "learning_rate": 7.764459996516618e-06,
      "loss": 0.8961,
      "step": 14119
    },
    {
      "epoch": 0.22356983390598034,
      "grad_norm": 0.2612009644508362,
      "learning_rate": 7.764301660940197e-06,
      "loss": 0.1196,
      "step": 14120
    },
    {
      "epoch": 0.2235856674636224,
      "grad_norm": 0.3568507134914398,
      "learning_rate": 7.764143325363776e-06,
      "loss": 0.0287,
      "step": 14121
    },
    {
      "epoch": 0.22360150102126447,
      "grad_norm": 0.9132314920425415,
      "learning_rate": 7.763984989787357e-06,
      "loss": 0.0598,
      "step": 14122
    },
    {
      "epoch": 0.22361733457890653,
      "grad_norm": 0.4735664427280426,
      "learning_rate": 7.763826654210935e-06,
      "loss": 0.088,
      "step": 14123
    },
    {
      "epoch": 0.2236331681365486,
      "grad_norm": 0.03875802084803581,
      "learning_rate": 7.763668318634514e-06,
      "loss": 0.0028,
      "step": 14124
    },
    {
      "epoch": 0.22364900169419066,
      "grad_norm": 0.03184985741972923,
      "learning_rate": 7.763509983058094e-06,
      "loss": 0.0016,
      "step": 14125
    },
    {
      "epoch": 0.22366483525183273,
      "grad_norm": 0.4843589961528778,
      "learning_rate": 7.763351647481673e-06,
      "loss": 0.159,
      "step": 14126
    },
    {
      "epoch": 0.2236806688094748,
      "grad_norm": 0.4567721486091614,
      "learning_rate": 7.763193311905253e-06,
      "loss": 0.0713,
      "step": 14127
    },
    {
      "epoch": 0.22369650236711686,
      "grad_norm": 0.02546224184334278,
      "learning_rate": 7.763034976328832e-06,
      "loss": 0.0011,
      "step": 14128
    },
    {
      "epoch": 0.22371233592475892,
      "grad_norm": 0.003395183477550745,
      "learning_rate": 7.76287664075241e-06,
      "loss": 0.0001,
      "step": 14129
    },
    {
      "epoch": 0.223728169482401,
      "grad_norm": 0.33672231435775757,
      "learning_rate": 7.76271830517599e-06,
      "loss": 0.0845,
      "step": 14130
    },
    {
      "epoch": 0.22374400304004308,
      "grad_norm": 0.3029778003692627,
      "learning_rate": 7.76255996959957e-06,
      "loss": 0.1678,
      "step": 14131
    },
    {
      "epoch": 0.22375983659768514,
      "grad_norm": 0.0011698390590026975,
      "learning_rate": 7.76240163402315e-06,
      "loss": 0.0,
      "step": 14132
    },
    {
      "epoch": 0.2237756701553272,
      "grad_norm": 0.293368399143219,
      "learning_rate": 7.762243298446729e-06,
      "loss": 0.1067,
      "step": 14133
    },
    {
      "epoch": 0.22379150371296927,
      "grad_norm": 0.04555558040738106,
      "learning_rate": 7.762084962870308e-06,
      "loss": 0.0022,
      "step": 14134
    },
    {
      "epoch": 0.22380733727061133,
      "grad_norm": 0.715324878692627,
      "learning_rate": 7.761926627293887e-06,
      "loss": 0.5475,
      "step": 14135
    },
    {
      "epoch": 0.2238231708282534,
      "grad_norm": 0.002020596992224455,
      "learning_rate": 7.761768291717466e-06,
      "loss": 0.0,
      "step": 14136
    },
    {
      "epoch": 0.22383900438589546,
      "grad_norm": 0.615298867225647,
      "learning_rate": 7.761609956141047e-06,
      "loss": 0.1697,
      "step": 14137
    },
    {
      "epoch": 0.22385483794353753,
      "grad_norm": 0.8385858535766602,
      "learning_rate": 7.761451620564626e-06,
      "loss": 0.1253,
      "step": 14138
    },
    {
      "epoch": 0.2238706715011796,
      "grad_norm": 0.4906352758407593,
      "learning_rate": 7.761293284988205e-06,
      "loss": 0.1055,
      "step": 14139
    },
    {
      "epoch": 0.22388650505882166,
      "grad_norm": 0.008107328787446022,
      "learning_rate": 7.761134949411784e-06,
      "loss": 0.0003,
      "step": 14140
    },
    {
      "epoch": 0.22390233861646372,
      "grad_norm": 0.5344164967536926,
      "learning_rate": 7.760976613835363e-06,
      "loss": 0.1136,
      "step": 14141
    },
    {
      "epoch": 0.2239181721741058,
      "grad_norm": 0.25028669834136963,
      "learning_rate": 7.760818278258942e-06,
      "loss": 0.1152,
      "step": 14142
    },
    {
      "epoch": 0.22393400573174788,
      "grad_norm": 0.7001121640205383,
      "learning_rate": 7.760659942682523e-06,
      "loss": 0.0695,
      "step": 14143
    },
    {
      "epoch": 0.22394983928938994,
      "grad_norm": 0.2324897199869156,
      "learning_rate": 7.760501607106102e-06,
      "loss": 0.0611,
      "step": 14144
    },
    {
      "epoch": 0.223965672847032,
      "grad_norm": 0.21619492769241333,
      "learning_rate": 7.760343271529681e-06,
      "loss": 0.0602,
      "step": 14145
    },
    {
      "epoch": 0.22398150640467407,
      "grad_norm": 0.2944246530532837,
      "learning_rate": 7.76018493595326e-06,
      "loss": 0.2132,
      "step": 14146
    },
    {
      "epoch": 0.22399733996231613,
      "grad_norm": 0.11344807595014572,
      "learning_rate": 7.76002660037684e-06,
      "loss": 0.0016,
      "step": 14147
    },
    {
      "epoch": 0.2240131735199582,
      "grad_norm": 0.002556834602728486,
      "learning_rate": 7.759868264800418e-06,
      "loss": 0.0001,
      "step": 14148
    },
    {
      "epoch": 0.22402900707760026,
      "grad_norm": 0.1798323094844818,
      "learning_rate": 7.759709929223997e-06,
      "loss": 0.0425,
      "step": 14149
    },
    {
      "epoch": 0.22404484063524233,
      "grad_norm": 0.00283672078512609,
      "learning_rate": 7.759551593647578e-06,
      "loss": 0.0001,
      "step": 14150
    },
    {
      "epoch": 0.2240606741928844,
      "grad_norm": 0.12269061803817749,
      "learning_rate": 7.759393258071156e-06,
      "loss": 0.0355,
      "step": 14151
    },
    {
      "epoch": 0.22407650775052645,
      "grad_norm": 0.35242512822151184,
      "learning_rate": 7.759234922494736e-06,
      "loss": 0.0914,
      "step": 14152
    },
    {
      "epoch": 0.22409234130816852,
      "grad_norm": 0.17765051126480103,
      "learning_rate": 7.759076586918315e-06,
      "loss": 0.0396,
      "step": 14153
    },
    {
      "epoch": 0.2241081748658106,
      "grad_norm": 0.8653419613838196,
      "learning_rate": 7.758918251341894e-06,
      "loss": 0.7623,
      "step": 14154
    },
    {
      "epoch": 0.22412400842345268,
      "grad_norm": 0.8327251076698303,
      "learning_rate": 7.758759915765474e-06,
      "loss": 0.4557,
      "step": 14155
    },
    {
      "epoch": 0.22413984198109474,
      "grad_norm": 0.36709919571876526,
      "learning_rate": 7.758601580189054e-06,
      "loss": 0.0801,
      "step": 14156
    },
    {
      "epoch": 0.2241556755387368,
      "grad_norm": 0.05779857188463211,
      "learning_rate": 7.758443244612632e-06,
      "loss": 0.0024,
      "step": 14157
    },
    {
      "epoch": 0.22417150909637887,
      "grad_norm": 0.014102421700954437,
      "learning_rate": 7.758284909036212e-06,
      "loss": 0.0005,
      "step": 14158
    },
    {
      "epoch": 0.22418734265402093,
      "grad_norm": 0.27312198281288147,
      "learning_rate": 7.758126573459792e-06,
      "loss": 0.105,
      "step": 14159
    },
    {
      "epoch": 0.224203176211663,
      "grad_norm": 0.8972662687301636,
      "learning_rate": 7.75796823788337e-06,
      "loss": 0.2055,
      "step": 14160
    },
    {
      "epoch": 0.22421900976930506,
      "grad_norm": 1.7975144386291504,
      "learning_rate": 7.75780990230695e-06,
      "loss": 0.6156,
      "step": 14161
    },
    {
      "epoch": 0.22423484332694713,
      "grad_norm": 0.01086098700761795,
      "learning_rate": 7.75765156673053e-06,
      "loss": 0.0005,
      "step": 14162
    },
    {
      "epoch": 0.2242506768845892,
      "grad_norm": 0.3177263140678406,
      "learning_rate": 7.757493231154108e-06,
      "loss": 0.1139,
      "step": 14163
    },
    {
      "epoch": 0.22426651044223125,
      "grad_norm": 0.6407285332679749,
      "learning_rate": 7.757334895577689e-06,
      "loss": 0.3141,
      "step": 14164
    },
    {
      "epoch": 0.22428234399987332,
      "grad_norm": 0.547448456287384,
      "learning_rate": 7.757176560001268e-06,
      "loss": 0.2566,
      "step": 14165
    },
    {
      "epoch": 0.2242981775575154,
      "grad_norm": 0.02584538422524929,
      "learning_rate": 7.757018224424847e-06,
      "loss": 0.0015,
      "step": 14166
    },
    {
      "epoch": 0.22431401111515747,
      "grad_norm": 0.3971855640411377,
      "learning_rate": 7.756859888848426e-06,
      "loss": 0.1079,
      "step": 14167
    },
    {
      "epoch": 0.22432984467279954,
      "grad_norm": 0.27059105038642883,
      "learning_rate": 7.756701553272007e-06,
      "loss": 0.0915,
      "step": 14168
    },
    {
      "epoch": 0.2243456782304416,
      "grad_norm": 0.05215134099125862,
      "learning_rate": 7.756543217695584e-06,
      "loss": 0.0019,
      "step": 14169
    },
    {
      "epoch": 0.22436151178808367,
      "grad_norm": 0.5705298185348511,
      "learning_rate": 7.756384882119165e-06,
      "loss": 0.8163,
      "step": 14170
    },
    {
      "epoch": 0.22437734534572573,
      "grad_norm": 0.0002383826213190332,
      "learning_rate": 7.756226546542744e-06,
      "loss": 0.0,
      "step": 14171
    },
    {
      "epoch": 0.2243931789033678,
      "grad_norm": 0.5537770986557007,
      "learning_rate": 7.756068210966323e-06,
      "loss": 0.6723,
      "step": 14172
    },
    {
      "epoch": 0.22440901246100986,
      "grad_norm": 0.0002023179695243016,
      "learning_rate": 7.755909875389902e-06,
      "loss": 0.0,
      "step": 14173
    },
    {
      "epoch": 0.22442484601865192,
      "grad_norm": 0.28211987018585205,
      "learning_rate": 7.755751539813481e-06,
      "loss": 0.0827,
      "step": 14174
    },
    {
      "epoch": 0.224440679576294,
      "grad_norm": 0.5542187094688416,
      "learning_rate": 7.75559320423706e-06,
      "loss": 0.1439,
      "step": 14175
    },
    {
      "epoch": 0.22445651313393605,
      "grad_norm": 0.001426895847544074,
      "learning_rate": 7.75543486866064e-06,
      "loss": 0.0001,
      "step": 14176
    },
    {
      "epoch": 0.22447234669157812,
      "grad_norm": 0.34862735867500305,
      "learning_rate": 7.75527653308422e-06,
      "loss": 0.0654,
      "step": 14177
    },
    {
      "epoch": 0.2244881802492202,
      "grad_norm": 0.3276113271713257,
      "learning_rate": 7.755118197507797e-06,
      "loss": 0.1532,
      "step": 14178
    },
    {
      "epoch": 0.22450401380686227,
      "grad_norm": 0.7727275490760803,
      "learning_rate": 7.754959861931378e-06,
      "loss": 0.2398,
      "step": 14179
    },
    {
      "epoch": 0.22451984736450434,
      "grad_norm": 0.5652807354927063,
      "learning_rate": 7.754801526354957e-06,
      "loss": 0.0372,
      "step": 14180
    },
    {
      "epoch": 0.2245356809221464,
      "grad_norm": 0.12040606141090393,
      "learning_rate": 7.754643190778536e-06,
      "loss": 0.0034,
      "step": 14181
    },
    {
      "epoch": 0.22455151447978847,
      "grad_norm": 0.3238925635814667,
      "learning_rate": 7.754484855202115e-06,
      "loss": 0.209,
      "step": 14182
    },
    {
      "epoch": 0.22456734803743053,
      "grad_norm": 0.6142323017120361,
      "learning_rate": 7.754326519625696e-06,
      "loss": 0.1567,
      "step": 14183
    },
    {
      "epoch": 0.2245831815950726,
      "grad_norm": 0.00042530577047728,
      "learning_rate": 7.754168184049274e-06,
      "loss": 0.0,
      "step": 14184
    },
    {
      "epoch": 0.22459901515271466,
      "grad_norm": 0.5427626967430115,
      "learning_rate": 7.754009848472854e-06,
      "loss": 0.1305,
      "step": 14185
    },
    {
      "epoch": 0.22461484871035672,
      "grad_norm": 0.2334955483675003,
      "learning_rate": 7.753851512896433e-06,
      "loss": 0.0942,
      "step": 14186
    },
    {
      "epoch": 0.2246306822679988,
      "grad_norm": 0.3802688419818878,
      "learning_rate": 7.753693177320013e-06,
      "loss": 0.0892,
      "step": 14187
    },
    {
      "epoch": 0.22464651582564085,
      "grad_norm": 0.010714106261730194,
      "learning_rate": 7.753534841743592e-06,
      "loss": 0.0006,
      "step": 14188
    },
    {
      "epoch": 0.22466234938328292,
      "grad_norm": 0.00022874223941471428,
      "learning_rate": 7.753376506167172e-06,
      "loss": 0.0,
      "step": 14189
    },
    {
      "epoch": 0.224678182940925,
      "grad_norm": 0.605472981929779,
      "learning_rate": 7.75321817059075e-06,
      "loss": 0.13,
      "step": 14190
    },
    {
      "epoch": 0.22469401649856707,
      "grad_norm": 0.41242456436157227,
      "learning_rate": 7.75305983501433e-06,
      "loss": 0.3405,
      "step": 14191
    },
    {
      "epoch": 0.22470985005620914,
      "grad_norm": 0.011496789753437042,
      "learning_rate": 7.75290149943791e-06,
      "loss": 0.0003,
      "step": 14192
    },
    {
      "epoch": 0.2247256836138512,
      "grad_norm": 0.5493915677070618,
      "learning_rate": 7.752743163861489e-06,
      "loss": 0.1584,
      "step": 14193
    },
    {
      "epoch": 0.22474151717149327,
      "grad_norm": 0.17834585905075073,
      "learning_rate": 7.752584828285068e-06,
      "loss": 0.0678,
      "step": 14194
    },
    {
      "epoch": 0.22475735072913533,
      "grad_norm": 0.5458912253379822,
      "learning_rate": 7.752426492708649e-06,
      "loss": 0.1136,
      "step": 14195
    },
    {
      "epoch": 0.2247731842867774,
      "grad_norm": 0.3582904040813446,
      "learning_rate": 7.752268157132226e-06,
      "loss": 0.0546,
      "step": 14196
    },
    {
      "epoch": 0.22478901784441946,
      "grad_norm": 0.4045259952545166,
      "learning_rate": 7.752109821555805e-06,
      "loss": 0.611,
      "step": 14197
    },
    {
      "epoch": 0.22480485140206152,
      "grad_norm": 0.00023870619770605117,
      "learning_rate": 7.751951485979386e-06,
      "loss": 0.0,
      "step": 14198
    },
    {
      "epoch": 0.2248206849597036,
      "grad_norm": 0.06292388588190079,
      "learning_rate": 7.751793150402965e-06,
      "loss": 0.0036,
      "step": 14199
    },
    {
      "epoch": 0.22483651851734565,
      "grad_norm": 0.6023478507995605,
      "learning_rate": 7.751634814826544e-06,
      "loss": 0.2471,
      "step": 14200
    },
    {
      "epoch": 0.22485235207498772,
      "grad_norm": 0.4269029498100281,
      "learning_rate": 7.751476479250123e-06,
      "loss": 0.0866,
      "step": 14201
    },
    {
      "epoch": 0.2248681856326298,
      "grad_norm": 0.4011093080043793,
      "learning_rate": 7.751318143673702e-06,
      "loss": 0.1992,
      "step": 14202
    },
    {
      "epoch": 0.22488401919027187,
      "grad_norm": 0.2915574610233307,
      "learning_rate": 7.751159808097281e-06,
      "loss": 0.1029,
      "step": 14203
    },
    {
      "epoch": 0.22489985274791394,
      "grad_norm": 2.7949599825660698e-05,
      "learning_rate": 7.751001472520862e-06,
      "loss": 0.0,
      "step": 14204
    },
    {
      "epoch": 0.224915686305556,
      "grad_norm": 0.0005369227146729827,
      "learning_rate": 7.750843136944441e-06,
      "loss": 0.0,
      "step": 14205
    },
    {
      "epoch": 0.22493151986319807,
      "grad_norm": 0.13905160129070282,
      "learning_rate": 7.75068480136802e-06,
      "loss": 0.0033,
      "step": 14206
    },
    {
      "epoch": 0.22494735342084013,
      "grad_norm": 0.028256498277187347,
      "learning_rate": 7.7505264657916e-06,
      "loss": 0.0016,
      "step": 14207
    },
    {
      "epoch": 0.2249631869784822,
      "grad_norm": 0.3851585388183594,
      "learning_rate": 7.750368130215178e-06,
      "loss": 0.008,
      "step": 14208
    },
    {
      "epoch": 0.22497902053612426,
      "grad_norm": 0.00037175932084210217,
      "learning_rate": 7.750209794638757e-06,
      "loss": 0.0,
      "step": 14209
    },
    {
      "epoch": 0.22499485409376632,
      "grad_norm": 0.16825254261493683,
      "learning_rate": 7.750051459062338e-06,
      "loss": 0.0448,
      "step": 14210
    },
    {
      "epoch": 0.2250106876514084,
      "grad_norm": 0.012051759287714958,
      "learning_rate": 7.749893123485917e-06,
      "loss": 0.0007,
      "step": 14211
    },
    {
      "epoch": 0.22502652120905045,
      "grad_norm": 0.16932258009910583,
      "learning_rate": 7.749734787909496e-06,
      "loss": 0.0468,
      "step": 14212
    },
    {
      "epoch": 0.22504235476669252,
      "grad_norm": 0.036762308329343796,
      "learning_rate": 7.749576452333075e-06,
      "loss": 0.0023,
      "step": 14213
    },
    {
      "epoch": 0.2250581883243346,
      "grad_norm": 0.4096216559410095,
      "learning_rate": 7.749418116756654e-06,
      "loss": 0.2302,
      "step": 14214
    },
    {
      "epoch": 0.22507402188197667,
      "grad_norm": 0.3728015422821045,
      "learning_rate": 7.749259781180234e-06,
      "loss": 0.0982,
      "step": 14215
    },
    {
      "epoch": 0.22508985543961874,
      "grad_norm": 0.013561652041971684,
      "learning_rate": 7.749101445603814e-06,
      "loss": 0.0006,
      "step": 14216
    },
    {
      "epoch": 0.2251056889972608,
      "grad_norm": 0.3491908609867096,
      "learning_rate": 7.748943110027393e-06,
      "loss": 0.0644,
      "step": 14217
    },
    {
      "epoch": 0.22512152255490286,
      "grad_norm": 0.019176732748746872,
      "learning_rate": 7.748784774450972e-06,
      "loss": 0.0011,
      "step": 14218
    },
    {
      "epoch": 0.22513735611254493,
      "grad_norm": 0.27790358662605286,
      "learning_rate": 7.748626438874552e-06,
      "loss": 0.075,
      "step": 14219
    },
    {
      "epoch": 0.225153189670187,
      "grad_norm": 6.940148159628734e-05,
      "learning_rate": 7.74846810329813e-06,
      "loss": 0.0,
      "step": 14220
    },
    {
      "epoch": 0.22516902322782906,
      "grad_norm": 0.35618194937705994,
      "learning_rate": 7.74830976772171e-06,
      "loss": 0.6813,
      "step": 14221
    },
    {
      "epoch": 0.22518485678547112,
      "grad_norm": 0.00019170978339388967,
      "learning_rate": 7.748151432145289e-06,
      "loss": 0.0,
      "step": 14222
    },
    {
      "epoch": 0.22520069034311319,
      "grad_norm": 0.5800120234489441,
      "learning_rate": 7.74799309656887e-06,
      "loss": 0.1672,
      "step": 14223
    },
    {
      "epoch": 0.22521652390075525,
      "grad_norm": 0.6837528347969055,
      "learning_rate": 7.747834760992447e-06,
      "loss": 0.2194,
      "step": 14224
    },
    {
      "epoch": 0.22523235745839731,
      "grad_norm": 0.3812378942966461,
      "learning_rate": 7.747676425416028e-06,
      "loss": 0.0946,
      "step": 14225
    },
    {
      "epoch": 0.2252481910160394,
      "grad_norm": 0.2365877330303192,
      "learning_rate": 7.747518089839607e-06,
      "loss": 0.0598,
      "step": 14226
    },
    {
      "epoch": 0.22526402457368147,
      "grad_norm": 0.19039303064346313,
      "learning_rate": 7.747359754263186e-06,
      "loss": 0.0626,
      "step": 14227
    },
    {
      "epoch": 0.22527985813132353,
      "grad_norm": 0.7890567779541016,
      "learning_rate": 7.747201418686765e-06,
      "loss": 0.6766,
      "step": 14228
    },
    {
      "epoch": 0.2252956916889656,
      "grad_norm": 0.5831692814826965,
      "learning_rate": 7.747043083110346e-06,
      "loss": 0.0959,
      "step": 14229
    },
    {
      "epoch": 0.22531152524660766,
      "grad_norm": 0.021824341267347336,
      "learning_rate": 7.746884747533923e-06,
      "loss": 0.0011,
      "step": 14230
    },
    {
      "epoch": 0.22532735880424973,
      "grad_norm": 0.3629068434238434,
      "learning_rate": 7.746726411957504e-06,
      "loss": 0.1561,
      "step": 14231
    },
    {
      "epoch": 0.2253431923618918,
      "grad_norm": 0.3761080801486969,
      "learning_rate": 7.746568076381083e-06,
      "loss": 0.0932,
      "step": 14232
    },
    {
      "epoch": 0.22535902591953386,
      "grad_norm": 0.5509874820709229,
      "learning_rate": 7.746409740804662e-06,
      "loss": 0.3334,
      "step": 14233
    },
    {
      "epoch": 0.22537485947717592,
      "grad_norm": 0.36418479681015015,
      "learning_rate": 7.746251405228241e-06,
      "loss": 0.0317,
      "step": 14234
    },
    {
      "epoch": 0.22539069303481798,
      "grad_norm": 0.0668715313076973,
      "learning_rate": 7.74609306965182e-06,
      "loss": 0.0035,
      "step": 14235
    },
    {
      "epoch": 0.22540652659246005,
      "grad_norm": 0.017077263444662094,
      "learning_rate": 7.7459347340754e-06,
      "loss": 0.0007,
      "step": 14236
    },
    {
      "epoch": 0.2254223601501021,
      "grad_norm": 0.03011888451874256,
      "learning_rate": 7.74577639849898e-06,
      "loss": 0.0014,
      "step": 14237
    },
    {
      "epoch": 0.2254381937077442,
      "grad_norm": 0.48828399181365967,
      "learning_rate": 7.74561806292256e-06,
      "loss": 0.2435,
      "step": 14238
    },
    {
      "epoch": 0.22545402726538627,
      "grad_norm": 0.50905841588974,
      "learning_rate": 7.745459727346138e-06,
      "loss": 0.4225,
      "step": 14239
    },
    {
      "epoch": 0.22546986082302833,
      "grad_norm": 0.02339320257306099,
      "learning_rate": 7.745301391769717e-06,
      "loss": 0.0014,
      "step": 14240
    },
    {
      "epoch": 0.2254856943806704,
      "grad_norm": 0.008231909945607185,
      "learning_rate": 7.745143056193296e-06,
      "loss": 0.0004,
      "step": 14241
    },
    {
      "epoch": 0.22550152793831246,
      "grad_norm": 0.037748198956251144,
      "learning_rate": 7.744984720616875e-06,
      "loss": 0.0026,
      "step": 14242
    },
    {
      "epoch": 0.22551736149595453,
      "grad_norm": 0.014180300757288933,
      "learning_rate": 7.744826385040456e-06,
      "loss": 0.0005,
      "step": 14243
    },
    {
      "epoch": 0.2255331950535966,
      "grad_norm": 0.29049304127693176,
      "learning_rate": 7.744668049464035e-06,
      "loss": 0.0778,
      "step": 14244
    },
    {
      "epoch": 0.22554902861123866,
      "grad_norm": 0.4579017460346222,
      "learning_rate": 7.744509713887613e-06,
      "loss": 0.3843,
      "step": 14245
    },
    {
      "epoch": 0.22556486216888072,
      "grad_norm": 0.29611676931381226,
      "learning_rate": 7.744351378311193e-06,
      "loss": 0.0249,
      "step": 14246
    },
    {
      "epoch": 0.22558069572652278,
      "grad_norm": 0.6379826664924622,
      "learning_rate": 7.744193042734773e-06,
      "loss": 0.3712,
      "step": 14247
    },
    {
      "epoch": 0.22559652928416485,
      "grad_norm": 0.553618848323822,
      "learning_rate": 7.744034707158352e-06,
      "loss": 0.2822,
      "step": 14248
    },
    {
      "epoch": 0.2256123628418069,
      "grad_norm": 0.012210838496685028,
      "learning_rate": 7.74387637158193e-06,
      "loss": 0.0005,
      "step": 14249
    },
    {
      "epoch": 0.225628196399449,
      "grad_norm": 0.5626245737075806,
      "learning_rate": 7.743718036005511e-06,
      "loss": 0.7925,
      "step": 14250
    },
    {
      "epoch": 0.22564402995709107,
      "grad_norm": 0.022504568099975586,
      "learning_rate": 7.743559700429089e-06,
      "loss": 0.0011,
      "step": 14251
    },
    {
      "epoch": 0.22565986351473313,
      "grad_norm": 0.18013502657413483,
      "learning_rate": 7.74340136485267e-06,
      "loss": 0.0507,
      "step": 14252
    },
    {
      "epoch": 0.2256756970723752,
      "grad_norm": 0.29373231530189514,
      "learning_rate": 7.743243029276249e-06,
      "loss": 0.1269,
      "step": 14253
    },
    {
      "epoch": 0.22569153063001726,
      "grad_norm": 0.02733783610165119,
      "learning_rate": 7.743084693699828e-06,
      "loss": 0.0013,
      "step": 14254
    },
    {
      "epoch": 0.22570736418765933,
      "grad_norm": 0.18217994272708893,
      "learning_rate": 7.742926358123407e-06,
      "loss": 0.0077,
      "step": 14255
    },
    {
      "epoch": 0.2257231977453014,
      "grad_norm": 0.0003202554362360388,
      "learning_rate": 7.742768022546988e-06,
      "loss": 0.0,
      "step": 14256
    },
    {
      "epoch": 0.22573903130294345,
      "grad_norm": 0.5394130945205688,
      "learning_rate": 7.742609686970565e-06,
      "loss": 0.1604,
      "step": 14257
    },
    {
      "epoch": 0.22575486486058552,
      "grad_norm": 0.1833888292312622,
      "learning_rate": 7.742451351394146e-06,
      "loss": 0.0506,
      "step": 14258
    },
    {
      "epoch": 0.22577069841822758,
      "grad_norm": 0.01339584868401289,
      "learning_rate": 7.742293015817725e-06,
      "loss": 0.0005,
      "step": 14259
    },
    {
      "epoch": 0.22578653197586965,
      "grad_norm": 0.0158710740506649,
      "learning_rate": 7.742134680241304e-06,
      "loss": 0.0008,
      "step": 14260
    },
    {
      "epoch": 0.2258023655335117,
      "grad_norm": 0.15657329559326172,
      "learning_rate": 7.741976344664883e-06,
      "loss": 0.0593,
      "step": 14261
    },
    {
      "epoch": 0.2258181990911538,
      "grad_norm": 0.45244187116622925,
      "learning_rate": 7.741818009088464e-06,
      "loss": 0.1325,
      "step": 14262
    },
    {
      "epoch": 0.22583403264879587,
      "grad_norm": 0.45293688774108887,
      "learning_rate": 7.741659673512041e-06,
      "loss": 0.2617,
      "step": 14263
    },
    {
      "epoch": 0.22584986620643793,
      "grad_norm": 0.536501407623291,
      "learning_rate": 7.741501337935622e-06,
      "loss": 0.1404,
      "step": 14264
    },
    {
      "epoch": 0.22586569976408,
      "grad_norm": 0.24216970801353455,
      "learning_rate": 7.741343002359201e-06,
      "loss": 0.1411,
      "step": 14265
    },
    {
      "epoch": 0.22588153332172206,
      "grad_norm": 0.25185874104499817,
      "learning_rate": 7.74118466678278e-06,
      "loss": 0.0632,
      "step": 14266
    },
    {
      "epoch": 0.22589736687936413,
      "grad_norm": 0.541973888874054,
      "learning_rate": 7.74102633120636e-06,
      "loss": 0.3166,
      "step": 14267
    },
    {
      "epoch": 0.2259132004370062,
      "grad_norm": 0.006571568548679352,
      "learning_rate": 7.740867995629938e-06,
      "loss": 0.0002,
      "step": 14268
    },
    {
      "epoch": 0.22592903399464825,
      "grad_norm": 0.00011464923591120169,
      "learning_rate": 7.740709660053517e-06,
      "loss": 0.0,
      "step": 14269
    },
    {
      "epoch": 0.22594486755229032,
      "grad_norm": 0.416026771068573,
      "learning_rate": 7.740551324477096e-06,
      "loss": 0.0973,
      "step": 14270
    },
    {
      "epoch": 0.22596070110993238,
      "grad_norm": 0.7542818188667297,
      "learning_rate": 7.740392988900677e-06,
      "loss": 0.1015,
      "step": 14271
    },
    {
      "epoch": 0.22597653466757445,
      "grad_norm": 0.3056764006614685,
      "learning_rate": 7.740234653324256e-06,
      "loss": 0.0924,
      "step": 14272
    },
    {
      "epoch": 0.2259923682252165,
      "grad_norm": 0.019292378798127174,
      "learning_rate": 7.740076317747835e-06,
      "loss": 0.001,
      "step": 14273
    },
    {
      "epoch": 0.2260082017828586,
      "grad_norm": 0.07778239250183105,
      "learning_rate": 7.739917982171414e-06,
      "loss": 0.0017,
      "step": 14274
    },
    {
      "epoch": 0.22602403534050067,
      "grad_norm": 0.2575894892215729,
      "learning_rate": 7.739759646594994e-06,
      "loss": 0.0341,
      "step": 14275
    },
    {
      "epoch": 0.22603986889814273,
      "grad_norm": 0.33226513862609863,
      "learning_rate": 7.739601311018573e-06,
      "loss": 0.1097,
      "step": 14276
    },
    {
      "epoch": 0.2260557024557848,
      "grad_norm": 0.34627723693847656,
      "learning_rate": 7.739442975442153e-06,
      "loss": 0.1678,
      "step": 14277
    },
    {
      "epoch": 0.22607153601342686,
      "grad_norm": 0.3983013927936554,
      "learning_rate": 7.739284639865733e-06,
      "loss": 0.147,
      "step": 14278
    },
    {
      "epoch": 0.22608736957106892,
      "grad_norm": 0.5711849331855774,
      "learning_rate": 7.739126304289312e-06,
      "loss": 0.429,
      "step": 14279
    },
    {
      "epoch": 0.226103203128711,
      "grad_norm": 0.001193268341012299,
      "learning_rate": 7.73896796871289e-06,
      "loss": 0.0,
      "step": 14280
    },
    {
      "epoch": 0.22611903668635305,
      "grad_norm": 4.869601616519503e-05,
      "learning_rate": 7.73880963313647e-06,
      "loss": 0.0,
      "step": 14281
    },
    {
      "epoch": 0.22613487024399512,
      "grad_norm": 0.013527820818126202,
      "learning_rate": 7.738651297560049e-06,
      "loss": 0.0006,
      "step": 14282
    },
    {
      "epoch": 0.22615070380163718,
      "grad_norm": 0.2362186312675476,
      "learning_rate": 7.73849296198363e-06,
      "loss": 0.0816,
      "step": 14283
    },
    {
      "epoch": 0.22616653735927925,
      "grad_norm": 0.2241261899471283,
      "learning_rate": 7.738334626407209e-06,
      "loss": 0.0721,
      "step": 14284
    },
    {
      "epoch": 0.2261823709169213,
      "grad_norm": 0.2243792712688446,
      "learning_rate": 7.738176290830788e-06,
      "loss": 0.0634,
      "step": 14285
    },
    {
      "epoch": 0.2261982044745634,
      "grad_norm": 0.45968908071517944,
      "learning_rate": 7.738017955254367e-06,
      "loss": 0.2543,
      "step": 14286
    },
    {
      "epoch": 0.22621403803220547,
      "grad_norm": 0.6821354031562805,
      "learning_rate": 7.737859619677946e-06,
      "loss": 0.2945,
      "step": 14287
    },
    {
      "epoch": 0.22622987158984753,
      "grad_norm": 0.4797632396221161,
      "learning_rate": 7.737701284101525e-06,
      "loss": 0.2005,
      "step": 14288
    },
    {
      "epoch": 0.2262457051474896,
      "grad_norm": 0.45510348677635193,
      "learning_rate": 7.737542948525106e-06,
      "loss": 0.4096,
      "step": 14289
    },
    {
      "epoch": 0.22626153870513166,
      "grad_norm": 9.705996490083635e-05,
      "learning_rate": 7.737384612948685e-06,
      "loss": 0.0,
      "step": 14290
    },
    {
      "epoch": 0.22627737226277372,
      "grad_norm": 0.3890874683856964,
      "learning_rate": 7.737226277372264e-06,
      "loss": 0.2208,
      "step": 14291
    },
    {
      "epoch": 0.2262932058204158,
      "grad_norm": 3.265001058578491,
      "learning_rate": 7.737067941795843e-06,
      "loss": 0.0994,
      "step": 14292
    },
    {
      "epoch": 0.22630903937805785,
      "grad_norm": 0.01604846492409706,
      "learning_rate": 7.736909606219422e-06,
      "loss": 0.0008,
      "step": 14293
    },
    {
      "epoch": 0.22632487293569992,
      "grad_norm": 0.20001618564128876,
      "learning_rate": 7.736751270643001e-06,
      "loss": 0.0538,
      "step": 14294
    },
    {
      "epoch": 0.22634070649334198,
      "grad_norm": 1.139554500579834,
      "learning_rate": 7.73659293506658e-06,
      "loss": 0.2148,
      "step": 14295
    },
    {
      "epoch": 0.22635654005098405,
      "grad_norm": 0.009506267495453358,
      "learning_rate": 7.736434599490161e-06,
      "loss": 0.0002,
      "step": 14296
    },
    {
      "epoch": 0.2263723736086261,
      "grad_norm": 0.6124186515808105,
      "learning_rate": 7.736276263913738e-06,
      "loss": 0.2741,
      "step": 14297
    },
    {
      "epoch": 0.2263882071662682,
      "grad_norm": 0.6519483327865601,
      "learning_rate": 7.73611792833732e-06,
      "loss": 0.1014,
      "step": 14298
    },
    {
      "epoch": 0.22640404072391027,
      "grad_norm": 0.0008265887736342847,
      "learning_rate": 7.735959592760898e-06,
      "loss": 0.0,
      "step": 14299
    },
    {
      "epoch": 0.22641987428155233,
      "grad_norm": 0.016079669818282127,
      "learning_rate": 7.735801257184477e-06,
      "loss": 0.0004,
      "step": 14300
    },
    {
      "epoch": 0.2264357078391944,
      "grad_norm": 0.0009348327293992043,
      "learning_rate": 7.735642921608056e-06,
      "loss": 0.0,
      "step": 14301
    },
    {
      "epoch": 0.22645154139683646,
      "grad_norm": 0.5754906535148621,
      "learning_rate": 7.735484586031635e-06,
      "loss": 0.171,
      "step": 14302
    },
    {
      "epoch": 0.22646737495447852,
      "grad_norm": 0.0004456796741578728,
      "learning_rate": 7.735326250455215e-06,
      "loss": 0.0,
      "step": 14303
    },
    {
      "epoch": 0.2264832085121206,
      "grad_norm": 0.0021638988982886076,
      "learning_rate": 7.735167914878795e-06,
      "loss": 0.0001,
      "step": 14304
    },
    {
      "epoch": 0.22649904206976265,
      "grad_norm": 0.6696562170982361,
      "learning_rate": 7.735009579302374e-06,
      "loss": 0.8492,
      "step": 14305
    },
    {
      "epoch": 0.22651487562740472,
      "grad_norm": 0.5113303661346436,
      "learning_rate": 7.734851243725954e-06,
      "loss": 0.2613,
      "step": 14306
    },
    {
      "epoch": 0.22653070918504678,
      "grad_norm": 0.005556157324463129,
      "learning_rate": 7.734692908149533e-06,
      "loss": 0.0002,
      "step": 14307
    },
    {
      "epoch": 0.22654654274268884,
      "grad_norm": 0.0024730178993195295,
      "learning_rate": 7.734534572573112e-06,
      "loss": 0.0001,
      "step": 14308
    },
    {
      "epoch": 0.2265623763003309,
      "grad_norm": 0.0010165739804506302,
      "learning_rate": 7.73437623699669e-06,
      "loss": 0.0,
      "step": 14309
    },
    {
      "epoch": 0.226578209857973,
      "grad_norm": 0.00444578193128109,
      "learning_rate": 7.734217901420272e-06,
      "loss": 0.0001,
      "step": 14310
    },
    {
      "epoch": 0.22659404341561507,
      "grad_norm": 0.021659288555383682,
      "learning_rate": 7.73405956584385e-06,
      "loss": 0.001,
      "step": 14311
    },
    {
      "epoch": 0.22660987697325713,
      "grad_norm": 0.21656404435634613,
      "learning_rate": 7.73390123026743e-06,
      "loss": 0.0326,
      "step": 14312
    },
    {
      "epoch": 0.2266257105308992,
      "grad_norm": 0.24532388150691986,
      "learning_rate": 7.733742894691009e-06,
      "loss": 0.0914,
      "step": 14313
    },
    {
      "epoch": 0.22664154408854126,
      "grad_norm": 0.4626692235469818,
      "learning_rate": 7.733584559114588e-06,
      "loss": 0.1465,
      "step": 14314
    },
    {
      "epoch": 0.22665737764618332,
      "grad_norm": 0.00019650447939056903,
      "learning_rate": 7.733426223538167e-06,
      "loss": 0.0,
      "step": 14315
    },
    {
      "epoch": 0.2266732112038254,
      "grad_norm": 0.03264233469963074,
      "learning_rate": 7.733267887961746e-06,
      "loss": 0.0013,
      "step": 14316
    },
    {
      "epoch": 0.22668904476146745,
      "grad_norm": 0.3545210659503937,
      "learning_rate": 7.733109552385327e-06,
      "loss": 0.0332,
      "step": 14317
    },
    {
      "epoch": 0.22670487831910952,
      "grad_norm": 0.4723147451877594,
      "learning_rate": 7.732951216808904e-06,
      "loss": 0.1876,
      "step": 14318
    },
    {
      "epoch": 0.22672071187675158,
      "grad_norm": 0.4510645568370819,
      "learning_rate": 7.732792881232485e-06,
      "loss": 0.0846,
      "step": 14319
    },
    {
      "epoch": 0.22673654543439364,
      "grad_norm": 0.3310335576534271,
      "learning_rate": 7.732634545656064e-06,
      "loss": 0.0768,
      "step": 14320
    },
    {
      "epoch": 0.2267523789920357,
      "grad_norm": 0.7234790325164795,
      "learning_rate": 7.732476210079643e-06,
      "loss": 0.3457,
      "step": 14321
    },
    {
      "epoch": 0.2267682125496778,
      "grad_norm": 0.32718101143836975,
      "learning_rate": 7.732317874503222e-06,
      "loss": 0.1128,
      "step": 14322
    },
    {
      "epoch": 0.22678404610731986,
      "grad_norm": 0.27732643485069275,
      "learning_rate": 7.732159538926803e-06,
      "loss": 0.0997,
      "step": 14323
    },
    {
      "epoch": 0.22679987966496193,
      "grad_norm": 0.8369795083999634,
      "learning_rate": 7.73200120335038e-06,
      "loss": 0.5091,
      "step": 14324
    },
    {
      "epoch": 0.226815713222604,
      "grad_norm": 0.41186219453811646,
      "learning_rate": 7.731842867773961e-06,
      "loss": 0.1353,
      "step": 14325
    },
    {
      "epoch": 0.22683154678024606,
      "grad_norm": 0.477823406457901,
      "learning_rate": 7.73168453219754e-06,
      "loss": 0.1458,
      "step": 14326
    },
    {
      "epoch": 0.22684738033788812,
      "grad_norm": 0.29825568199157715,
      "learning_rate": 7.73152619662112e-06,
      "loss": 0.1366,
      "step": 14327
    },
    {
      "epoch": 0.22686321389553019,
      "grad_norm": 0.4097851812839508,
      "learning_rate": 7.731367861044698e-06,
      "loss": 0.0811,
      "step": 14328
    },
    {
      "epoch": 0.22687904745317225,
      "grad_norm": 0.44882115721702576,
      "learning_rate": 7.731209525468279e-06,
      "loss": 0.0782,
      "step": 14329
    },
    {
      "epoch": 0.22689488101081431,
      "grad_norm": 0.2860473692417145,
      "learning_rate": 7.731051189891856e-06,
      "loss": 0.0758,
      "step": 14330
    },
    {
      "epoch": 0.22691071456845638,
      "grad_norm": 0.03224077820777893,
      "learning_rate": 7.730892854315437e-06,
      "loss": 0.0012,
      "step": 14331
    },
    {
      "epoch": 0.22692654812609844,
      "grad_norm": 0.009519879706203938,
      "learning_rate": 7.730734518739016e-06,
      "loss": 0.0004,
      "step": 14332
    },
    {
      "epoch": 0.2269423816837405,
      "grad_norm": 0.21270215511322021,
      "learning_rate": 7.730576183162595e-06,
      "loss": 0.0683,
      "step": 14333
    },
    {
      "epoch": 0.2269582152413826,
      "grad_norm": 0.6085385084152222,
      "learning_rate": 7.730417847586175e-06,
      "loss": 0.3632,
      "step": 14334
    },
    {
      "epoch": 0.22697404879902466,
      "grad_norm": 0.030239131301641464,
      "learning_rate": 7.730259512009755e-06,
      "loss": 0.0014,
      "step": 14335
    },
    {
      "epoch": 0.22698988235666673,
      "grad_norm": 0.8858377933502197,
      "learning_rate": 7.730101176433333e-06,
      "loss": 0.1731,
      "step": 14336
    },
    {
      "epoch": 0.2270057159143088,
      "grad_norm": 0.6122621297836304,
      "learning_rate": 7.729942840856913e-06,
      "loss": 0.1769,
      "step": 14337
    },
    {
      "epoch": 0.22702154947195086,
      "grad_norm": 0.0015990863321349025,
      "learning_rate": 7.729784505280493e-06,
      "loss": 0.0,
      "step": 14338
    },
    {
      "epoch": 0.22703738302959292,
      "grad_norm": 0.3408166468143463,
      "learning_rate": 7.729626169704072e-06,
      "loss": 0.069,
      "step": 14339
    },
    {
      "epoch": 0.22705321658723499,
      "grad_norm": 0.7071221470832825,
      "learning_rate": 7.72946783412765e-06,
      "loss": 0.1846,
      "step": 14340
    },
    {
      "epoch": 0.22706905014487705,
      "grad_norm": 0.22814849019050598,
      "learning_rate": 7.72930949855123e-06,
      "loss": 0.0598,
      "step": 14341
    },
    {
      "epoch": 0.2270848837025191,
      "grad_norm": 0.022155385464429855,
      "learning_rate": 7.729151162974809e-06,
      "loss": 0.0008,
      "step": 14342
    },
    {
      "epoch": 0.22710071726016118,
      "grad_norm": 0.3650011420249939,
      "learning_rate": 7.728992827398388e-06,
      "loss": 0.1282,
      "step": 14343
    },
    {
      "epoch": 0.22711655081780324,
      "grad_norm": 0.5608522295951843,
      "learning_rate": 7.728834491821969e-06,
      "loss": 0.1755,
      "step": 14344
    },
    {
      "epoch": 0.2271323843754453,
      "grad_norm": 0.5673936605453491,
      "learning_rate": 7.728676156245548e-06,
      "loss": 0.2299,
      "step": 14345
    },
    {
      "epoch": 0.2271482179330874,
      "grad_norm": 0.0016292089130729437,
      "learning_rate": 7.728517820669127e-06,
      "loss": 0.0,
      "step": 14346
    },
    {
      "epoch": 0.22716405149072946,
      "grad_norm": 0.013133613392710686,
      "learning_rate": 7.728359485092706e-06,
      "loss": 0.0006,
      "step": 14347
    },
    {
      "epoch": 0.22717988504837153,
      "grad_norm": 0.0001504121901234612,
      "learning_rate": 7.728201149516285e-06,
      "loss": 0.0,
      "step": 14348
    },
    {
      "epoch": 0.2271957186060136,
      "grad_norm": 0.5476755499839783,
      "learning_rate": 7.728042813939864e-06,
      "loss": 0.2685,
      "step": 14349
    },
    {
      "epoch": 0.22721155216365566,
      "grad_norm": 0.008456538431346416,
      "learning_rate": 7.727884478363445e-06,
      "loss": 0.0003,
      "step": 14350
    },
    {
      "epoch": 0.22722738572129772,
      "grad_norm": 0.5184112787246704,
      "learning_rate": 7.727726142787024e-06,
      "loss": 0.0531,
      "step": 14351
    },
    {
      "epoch": 0.22724321927893978,
      "grad_norm": 0.00011753212311305106,
      "learning_rate": 7.727567807210603e-06,
      "loss": 0.0,
      "step": 14352
    },
    {
      "epoch": 0.22725905283658185,
      "grad_norm": 0.412619024515152,
      "learning_rate": 7.727409471634182e-06,
      "loss": 0.0558,
      "step": 14353
    },
    {
      "epoch": 0.2272748863942239,
      "grad_norm": 0.0015484909527003765,
      "learning_rate": 7.727251136057761e-06,
      "loss": 0.0,
      "step": 14354
    },
    {
      "epoch": 0.22729071995186598,
      "grad_norm": 0.23049502074718475,
      "learning_rate": 7.72709280048134e-06,
      "loss": 0.0305,
      "step": 14355
    },
    {
      "epoch": 0.22730655350950804,
      "grad_norm": 0.3743375241756439,
      "learning_rate": 7.726934464904921e-06,
      "loss": 0.0377,
      "step": 14356
    },
    {
      "epoch": 0.2273223870671501,
      "grad_norm": 0.01928720809519291,
      "learning_rate": 7.7267761293285e-06,
      "loss": 0.0008,
      "step": 14357
    },
    {
      "epoch": 0.2273382206247922,
      "grad_norm": 0.4364493191242218,
      "learning_rate": 7.72661779375208e-06,
      "loss": 0.0612,
      "step": 14358
    },
    {
      "epoch": 0.22735405418243426,
      "grad_norm": 0.4305952787399292,
      "learning_rate": 7.726459458175658e-06,
      "loss": 0.264,
      "step": 14359
    },
    {
      "epoch": 0.22736988774007633,
      "grad_norm": 0.025409191846847534,
      "learning_rate": 7.726301122599237e-06,
      "loss": 0.001,
      "step": 14360
    },
    {
      "epoch": 0.2273857212977184,
      "grad_norm": 0.22830231487751007,
      "learning_rate": 7.726142787022816e-06,
      "loss": 0.0696,
      "step": 14361
    },
    {
      "epoch": 0.22740155485536045,
      "grad_norm": 1.7652089595794678,
      "learning_rate": 7.725984451446397e-06,
      "loss": 0.805,
      "step": 14362
    },
    {
      "epoch": 0.22741738841300252,
      "grad_norm": 0.5588212013244629,
      "learning_rate": 7.725826115869975e-06,
      "loss": 0.0734,
      "step": 14363
    },
    {
      "epoch": 0.22743322197064458,
      "grad_norm": 0.3175757825374603,
      "learning_rate": 7.725667780293554e-06,
      "loss": 0.1412,
      "step": 14364
    },
    {
      "epoch": 0.22744905552828665,
      "grad_norm": 0.0016485871747136116,
      "learning_rate": 7.725509444717134e-06,
      "loss": 0.0,
      "step": 14365
    },
    {
      "epoch": 0.2274648890859287,
      "grad_norm": 0.5307510495185852,
      "learning_rate": 7.725351109140714e-06,
      "loss": 0.4499,
      "step": 14366
    },
    {
      "epoch": 0.22748072264357078,
      "grad_norm": 0.01391654647886753,
      "learning_rate": 7.725192773564293e-06,
      "loss": 0.0006,
      "step": 14367
    },
    {
      "epoch": 0.22749655620121284,
      "grad_norm": 0.5202668309211731,
      "learning_rate": 7.725034437987872e-06,
      "loss": 0.1805,
      "step": 14368
    },
    {
      "epoch": 0.2275123897588549,
      "grad_norm": 0.7937756776809692,
      "learning_rate": 7.72487610241145e-06,
      "loss": 0.545,
      "step": 14369
    },
    {
      "epoch": 0.227528223316497,
      "grad_norm": 0.015556856989860535,
      "learning_rate": 7.72471776683503e-06,
      "loss": 0.0007,
      "step": 14370
    },
    {
      "epoch": 0.22754405687413906,
      "grad_norm": 0.03879817575216293,
      "learning_rate": 7.72455943125861e-06,
      "loss": 0.0019,
      "step": 14371
    },
    {
      "epoch": 0.22755989043178113,
      "grad_norm": 0.4016786515712738,
      "learning_rate": 7.72440109568219e-06,
      "loss": 0.1646,
      "step": 14372
    },
    {
      "epoch": 0.2275757239894232,
      "grad_norm": 0.2292858213186264,
      "learning_rate": 7.724242760105769e-06,
      "loss": 0.064,
      "step": 14373
    },
    {
      "epoch": 0.22759155754706525,
      "grad_norm": 0.4700521230697632,
      "learning_rate": 7.724084424529348e-06,
      "loss": 0.2728,
      "step": 14374
    },
    {
      "epoch": 0.22760739110470732,
      "grad_norm": 0.5507776141166687,
      "learning_rate": 7.723926088952927e-06,
      "loss": 1.0395,
      "step": 14375
    },
    {
      "epoch": 0.22762322466234938,
      "grad_norm": 0.07855121791362762,
      "learning_rate": 7.723767753376506e-06,
      "loss": 0.0036,
      "step": 14376
    },
    {
      "epoch": 0.22763905821999145,
      "grad_norm": 0.043555282056331635,
      "learning_rate": 7.723609417800087e-06,
      "loss": 0.0024,
      "step": 14377
    },
    {
      "epoch": 0.2276548917776335,
      "grad_norm": 0.3300635814666748,
      "learning_rate": 7.723451082223666e-06,
      "loss": 0.0078,
      "step": 14378
    },
    {
      "epoch": 0.22767072533527558,
      "grad_norm": 2.2860348224639893,
      "learning_rate": 7.723292746647245e-06,
      "loss": 0.3163,
      "step": 14379
    },
    {
      "epoch": 0.22768655889291764,
      "grad_norm": 0.318843811750412,
      "learning_rate": 7.723134411070824e-06,
      "loss": 0.0676,
      "step": 14380
    },
    {
      "epoch": 0.2277023924505597,
      "grad_norm": 0.020660722628235817,
      "learning_rate": 7.722976075494403e-06,
      "loss": 0.0007,
      "step": 14381
    },
    {
      "epoch": 0.2277182260082018,
      "grad_norm": 0.6305140256881714,
      "learning_rate": 7.722817739917982e-06,
      "loss": 0.6055,
      "step": 14382
    },
    {
      "epoch": 0.22773405956584386,
      "grad_norm": 0.4913340210914612,
      "learning_rate": 7.722659404341563e-06,
      "loss": 0.0431,
      "step": 14383
    },
    {
      "epoch": 0.22774989312348592,
      "grad_norm": 0.053001757711172104,
      "learning_rate": 7.722501068765142e-06,
      "loss": 0.0016,
      "step": 14384
    },
    {
      "epoch": 0.227765726681128,
      "grad_norm": 0.011025646701455116,
      "learning_rate": 7.722342733188721e-06,
      "loss": 0.0005,
      "step": 14385
    },
    {
      "epoch": 0.22778156023877005,
      "grad_norm": 0.2782532572746277,
      "learning_rate": 7.7221843976123e-06,
      "loss": 0.0519,
      "step": 14386
    },
    {
      "epoch": 0.22779739379641212,
      "grad_norm": 0.010723129846155643,
      "learning_rate": 7.72202606203588e-06,
      "loss": 0.0004,
      "step": 14387
    },
    {
      "epoch": 0.22781322735405418,
      "grad_norm": 0.5890909433364868,
      "learning_rate": 7.721867726459458e-06,
      "loss": 0.0593,
      "step": 14388
    },
    {
      "epoch": 0.22782906091169625,
      "grad_norm": 0.4258594512939453,
      "learning_rate": 7.721709390883037e-06,
      "loss": 0.2727,
      "step": 14389
    },
    {
      "epoch": 0.2278448944693383,
      "grad_norm": 0.0346437506377697,
      "learning_rate": 7.721551055306618e-06,
      "loss": 0.0005,
      "step": 14390
    },
    {
      "epoch": 0.22786072802698037,
      "grad_norm": 0.03205909579992294,
      "learning_rate": 7.721392719730196e-06,
      "loss": 0.0016,
      "step": 14391
    },
    {
      "epoch": 0.22787656158462244,
      "grad_norm": 0.4872361421585083,
      "learning_rate": 7.721234384153776e-06,
      "loss": 0.1253,
      "step": 14392
    },
    {
      "epoch": 0.2278923951422645,
      "grad_norm": 0.22365692257881165,
      "learning_rate": 7.721076048577355e-06,
      "loss": 0.0538,
      "step": 14393
    },
    {
      "epoch": 0.2279082286999066,
      "grad_norm": 0.2958417534828186,
      "learning_rate": 7.720917713000935e-06,
      "loss": 0.1009,
      "step": 14394
    },
    {
      "epoch": 0.22792406225754866,
      "grad_norm": 0.1947704553604126,
      "learning_rate": 7.720759377424514e-06,
      "loss": 0.0421,
      "step": 14395
    },
    {
      "epoch": 0.22793989581519072,
      "grad_norm": 0.39978915452957153,
      "learning_rate": 7.720601041848094e-06,
      "loss": 0.1664,
      "step": 14396
    },
    {
      "epoch": 0.2279557293728328,
      "grad_norm": 0.3419610559940338,
      "learning_rate": 7.720442706271672e-06,
      "loss": 0.1893,
      "step": 14397
    },
    {
      "epoch": 0.22797156293047485,
      "grad_norm": 0.04099855571985245,
      "learning_rate": 7.720284370695253e-06,
      "loss": 0.0015,
      "step": 14398
    },
    {
      "epoch": 0.22798739648811692,
      "grad_norm": 0.5426949262619019,
      "learning_rate": 7.720126035118832e-06,
      "loss": 0.2407,
      "step": 14399
    },
    {
      "epoch": 0.22800323004575898,
      "grad_norm": 0.5249114036560059,
      "learning_rate": 7.71996769954241e-06,
      "loss": 0.2568,
      "step": 14400
    },
    {
      "epoch": 0.22801906360340105,
      "grad_norm": 0.06959390640258789,
      "learning_rate": 7.71980936396599e-06,
      "loss": 0.0025,
      "step": 14401
    },
    {
      "epoch": 0.2280348971610431,
      "grad_norm": 0.28321531414985657,
      "learning_rate": 7.71965102838957e-06,
      "loss": 0.0138,
      "step": 14402
    },
    {
      "epoch": 0.22805073071868517,
      "grad_norm": 0.3522682785987854,
      "learning_rate": 7.719492692813148e-06,
      "loss": 0.1122,
      "step": 14403
    },
    {
      "epoch": 0.22806656427632724,
      "grad_norm": 0.7859890460968018,
      "learning_rate": 7.719334357236729e-06,
      "loss": 0.2709,
      "step": 14404
    },
    {
      "epoch": 0.2280823978339693,
      "grad_norm": 0.4947946071624756,
      "learning_rate": 7.719176021660308e-06,
      "loss": 0.2932,
      "step": 14405
    },
    {
      "epoch": 0.2280982313916114,
      "grad_norm": 0.5088294744491577,
      "learning_rate": 7.719017686083887e-06,
      "loss": 0.0348,
      "step": 14406
    },
    {
      "epoch": 0.22811406494925346,
      "grad_norm": 1.2051302194595337,
      "learning_rate": 7.718859350507466e-06,
      "loss": 0.2293,
      "step": 14407
    },
    {
      "epoch": 0.22812989850689552,
      "grad_norm": 0.030572131276130676,
      "learning_rate": 7.718701014931047e-06,
      "loss": 0.0051,
      "step": 14408
    },
    {
      "epoch": 0.2281457320645376,
      "grad_norm": 0.43939608335494995,
      "learning_rate": 7.718542679354624e-06,
      "loss": 0.0734,
      "step": 14409
    },
    {
      "epoch": 0.22816156562217965,
      "grad_norm": 0.5082554817199707,
      "learning_rate": 7.718384343778205e-06,
      "loss": 0.0763,
      "step": 14410
    },
    {
      "epoch": 0.22817739917982172,
      "grad_norm": 0.8656089901924133,
      "learning_rate": 7.718226008201784e-06,
      "loss": 0.4506,
      "step": 14411
    },
    {
      "epoch": 0.22819323273746378,
      "grad_norm": 1.1650856733322144,
      "learning_rate": 7.718067672625363e-06,
      "loss": 0.2753,
      "step": 14412
    },
    {
      "epoch": 0.22820906629510584,
      "grad_norm": 0.27199694514274597,
      "learning_rate": 7.717909337048942e-06,
      "loss": 0.048,
      "step": 14413
    },
    {
      "epoch": 0.2282248998527479,
      "grad_norm": 0.006438850425183773,
      "learning_rate": 7.717751001472521e-06,
      "loss": 0.0002,
      "step": 14414
    },
    {
      "epoch": 0.22824073341038997,
      "grad_norm": 0.6686333417892456,
      "learning_rate": 7.7175926658961e-06,
      "loss": 0.3638,
      "step": 14415
    },
    {
      "epoch": 0.22825656696803204,
      "grad_norm": 0.354720801115036,
      "learning_rate": 7.71743433031968e-06,
      "loss": 0.084,
      "step": 14416
    },
    {
      "epoch": 0.2282724005256741,
      "grad_norm": 0.35222700238227844,
      "learning_rate": 7.71727599474326e-06,
      "loss": 0.1535,
      "step": 14417
    },
    {
      "epoch": 0.2282882340833162,
      "grad_norm": 0.11037395894527435,
      "learning_rate": 7.71711765916684e-06,
      "loss": 0.0095,
      "step": 14418
    },
    {
      "epoch": 0.22830406764095826,
      "grad_norm": 0.30336111783981323,
      "learning_rate": 7.716959323590418e-06,
      "loss": 0.0537,
      "step": 14419
    },
    {
      "epoch": 0.22831990119860032,
      "grad_norm": 0.2494702935218811,
      "learning_rate": 7.716800988013997e-06,
      "loss": 0.0867,
      "step": 14420
    },
    {
      "epoch": 0.2283357347562424,
      "grad_norm": 0.002499525435268879,
      "learning_rate": 7.716642652437576e-06,
      "loss": 0.0001,
      "step": 14421
    },
    {
      "epoch": 0.22835156831388445,
      "grad_norm": 0.3877115249633789,
      "learning_rate": 7.716484316861156e-06,
      "loss": 0.2683,
      "step": 14422
    },
    {
      "epoch": 0.22836740187152652,
      "grad_norm": 0.00018278203788213432,
      "learning_rate": 7.716325981284736e-06,
      "loss": 0.0,
      "step": 14423
    },
    {
      "epoch": 0.22838323542916858,
      "grad_norm": 0.0010250260820612311,
      "learning_rate": 7.716167645708315e-06,
      "loss": 0.0,
      "step": 14424
    },
    {
      "epoch": 0.22839906898681064,
      "grad_norm": 0.3734396696090698,
      "learning_rate": 7.716009310131894e-06,
      "loss": 0.1205,
      "step": 14425
    },
    {
      "epoch": 0.2284149025444527,
      "grad_norm": 0.0001778851728886366,
      "learning_rate": 7.715850974555474e-06,
      "loss": 0.0,
      "step": 14426
    },
    {
      "epoch": 0.22843073610209477,
      "grad_norm": 0.24345499277114868,
      "learning_rate": 7.715692638979053e-06,
      "loss": 0.0853,
      "step": 14427
    },
    {
      "epoch": 0.22844656965973684,
      "grad_norm": 0.43456265330314636,
      "learning_rate": 7.715534303402632e-06,
      "loss": 0.0671,
      "step": 14428
    },
    {
      "epoch": 0.2284624032173789,
      "grad_norm": 0.1981223076581955,
      "learning_rate": 7.715375967826212e-06,
      "loss": 0.0102,
      "step": 14429
    },
    {
      "epoch": 0.228478236775021,
      "grad_norm": 0.45564988255500793,
      "learning_rate": 7.71521763224979e-06,
      "loss": 0.0683,
      "step": 14430
    },
    {
      "epoch": 0.22849407033266306,
      "grad_norm": 0.49569275975227356,
      "learning_rate": 7.71505929667337e-06,
      "loss": 0.1524,
      "step": 14431
    },
    {
      "epoch": 0.22850990389030512,
      "grad_norm": 0.2477329671382904,
      "learning_rate": 7.71490096109695e-06,
      "loss": 0.0071,
      "step": 14432
    },
    {
      "epoch": 0.22852573744794719,
      "grad_norm": 0.2827020287513733,
      "learning_rate": 7.714742625520529e-06,
      "loss": 0.088,
      "step": 14433
    },
    {
      "epoch": 0.22854157100558925,
      "grad_norm": 0.3749588429927826,
      "learning_rate": 7.714584289944108e-06,
      "loss": 0.1809,
      "step": 14434
    },
    {
      "epoch": 0.22855740456323131,
      "grad_norm": 0.6162064671516418,
      "learning_rate": 7.714425954367689e-06,
      "loss": 0.4337,
      "step": 14435
    },
    {
      "epoch": 0.22857323812087338,
      "grad_norm": 0.16649845242500305,
      "learning_rate": 7.714267618791266e-06,
      "loss": 0.0077,
      "step": 14436
    },
    {
      "epoch": 0.22858907167851544,
      "grad_norm": 0.009437792003154755,
      "learning_rate": 7.714109283214845e-06,
      "loss": 0.0004,
      "step": 14437
    },
    {
      "epoch": 0.2286049052361575,
      "grad_norm": 0.015903061255812645,
      "learning_rate": 7.713950947638426e-06,
      "loss": 0.0008,
      "step": 14438
    },
    {
      "epoch": 0.22862073879379957,
      "grad_norm": 0.6813088655471802,
      "learning_rate": 7.713792612062005e-06,
      "loss": 0.3913,
      "step": 14439
    },
    {
      "epoch": 0.22863657235144164,
      "grad_norm": 0.21429646015167236,
      "learning_rate": 7.713634276485584e-06,
      "loss": 0.0315,
      "step": 14440
    },
    {
      "epoch": 0.2286524059090837,
      "grad_norm": 0.642646849155426,
      "learning_rate": 7.713475940909163e-06,
      "loss": 0.2871,
      "step": 14441
    },
    {
      "epoch": 0.2286682394667258,
      "grad_norm": 0.4370870292186737,
      "learning_rate": 7.713317605332742e-06,
      "loss": 0.2655,
      "step": 14442
    },
    {
      "epoch": 0.22868407302436786,
      "grad_norm": 0.00021422398276627064,
      "learning_rate": 7.713159269756321e-06,
      "loss": 0.0,
      "step": 14443
    },
    {
      "epoch": 0.22869990658200992,
      "grad_norm": 0.3891708552837372,
      "learning_rate": 7.713000934179902e-06,
      "loss": 0.0793,
      "step": 14444
    },
    {
      "epoch": 0.22871574013965199,
      "grad_norm": 0.06579037755727768,
      "learning_rate": 7.712842598603481e-06,
      "loss": 0.0031,
      "step": 14445
    },
    {
      "epoch": 0.22873157369729405,
      "grad_norm": 0.5205150842666626,
      "learning_rate": 7.71268426302706e-06,
      "loss": 0.1612,
      "step": 14446
    },
    {
      "epoch": 0.2287474072549361,
      "grad_norm": 0.008885846473276615,
      "learning_rate": 7.71252592745064e-06,
      "loss": 0.0003,
      "step": 14447
    },
    {
      "epoch": 0.22876324081257818,
      "grad_norm": 0.5752711892127991,
      "learning_rate": 7.712367591874218e-06,
      "loss": 0.0302,
      "step": 14448
    },
    {
      "epoch": 0.22877907437022024,
      "grad_norm": 0.005013208370655775,
      "learning_rate": 7.712209256297797e-06,
      "loss": 0.0001,
      "step": 14449
    },
    {
      "epoch": 0.2287949079278623,
      "grad_norm": 0.2946629822254181,
      "learning_rate": 7.712050920721378e-06,
      "loss": 0.0917,
      "step": 14450
    },
    {
      "epoch": 0.22881074148550437,
      "grad_norm": 0.0015563807683065534,
      "learning_rate": 7.711892585144957e-06,
      "loss": 0.0001,
      "step": 14451
    },
    {
      "epoch": 0.22882657504314644,
      "grad_norm": 0.3218919038772583,
      "learning_rate": 7.711734249568536e-06,
      "loss": 0.2338,
      "step": 14452
    },
    {
      "epoch": 0.2288424086007885,
      "grad_norm": 0.2565693259239197,
      "learning_rate": 7.711575913992115e-06,
      "loss": 0.1008,
      "step": 14453
    },
    {
      "epoch": 0.2288582421584306,
      "grad_norm": 0.45104122161865234,
      "learning_rate": 7.711417578415695e-06,
      "loss": 0.1288,
      "step": 14454
    },
    {
      "epoch": 0.22887407571607266,
      "grad_norm": 0.12008189409971237,
      "learning_rate": 7.711259242839274e-06,
      "loss": 0.0189,
      "step": 14455
    },
    {
      "epoch": 0.22888990927371472,
      "grad_norm": 0.13873064517974854,
      "learning_rate": 7.711100907262854e-06,
      "loss": 0.0106,
      "step": 14456
    },
    {
      "epoch": 0.22890574283135678,
      "grad_norm": 0.01876841112971306,
      "learning_rate": 7.710942571686433e-06,
      "loss": 0.0008,
      "step": 14457
    },
    {
      "epoch": 0.22892157638899885,
      "grad_norm": 0.01102161593735218,
      "learning_rate": 7.710784236110013e-06,
      "loss": 0.0004,
      "step": 14458
    },
    {
      "epoch": 0.2289374099466409,
      "grad_norm": 0.44658440351486206,
      "learning_rate": 7.710625900533592e-06,
      "loss": 0.1001,
      "step": 14459
    },
    {
      "epoch": 0.22895324350428298,
      "grad_norm": 0.03448554873466492,
      "learning_rate": 7.71046756495717e-06,
      "loss": 0.0021,
      "step": 14460
    },
    {
      "epoch": 0.22896907706192504,
      "grad_norm": 0.7625927925109863,
      "learning_rate": 7.71030922938075e-06,
      "loss": 0.093,
      "step": 14461
    },
    {
      "epoch": 0.2289849106195671,
      "grad_norm": 0.20484711229801178,
      "learning_rate": 7.710150893804329e-06,
      "loss": 0.0693,
      "step": 14462
    },
    {
      "epoch": 0.22900074417720917,
      "grad_norm": 0.17349869012832642,
      "learning_rate": 7.70999255822791e-06,
      "loss": 0.0449,
      "step": 14463
    },
    {
      "epoch": 0.22901657773485123,
      "grad_norm": 0.005264907609671354,
      "learning_rate": 7.709834222651487e-06,
      "loss": 0.0002,
      "step": 14464
    },
    {
      "epoch": 0.2290324112924933,
      "grad_norm": 0.33329451084136963,
      "learning_rate": 7.709675887075068e-06,
      "loss": 0.0348,
      "step": 14465
    },
    {
      "epoch": 0.2290482448501354,
      "grad_norm": 1.0173989534378052,
      "learning_rate": 7.709517551498647e-06,
      "loss": 0.8261,
      "step": 14466
    },
    {
      "epoch": 0.22906407840777745,
      "grad_norm": 0.5717329978942871,
      "learning_rate": 7.709359215922226e-06,
      "loss": 0.1297,
      "step": 14467
    },
    {
      "epoch": 0.22907991196541952,
      "grad_norm": 0.28688639402389526,
      "learning_rate": 7.709200880345805e-06,
      "loss": 0.121,
      "step": 14468
    },
    {
      "epoch": 0.22909574552306158,
      "grad_norm": 0.4578213691711426,
      "learning_rate": 7.709042544769386e-06,
      "loss": 0.1556,
      "step": 14469
    },
    {
      "epoch": 0.22911157908070365,
      "grad_norm": 0.4756893515586853,
      "learning_rate": 7.708884209192963e-06,
      "loss": 0.0716,
      "step": 14470
    },
    {
      "epoch": 0.2291274126383457,
      "grad_norm": 0.006200715433806181,
      "learning_rate": 7.708725873616544e-06,
      "loss": 0.0003,
      "step": 14471
    },
    {
      "epoch": 0.22914324619598778,
      "grad_norm": 0.4433284401893616,
      "learning_rate": 7.708567538040123e-06,
      "loss": 0.1277,
      "step": 14472
    },
    {
      "epoch": 0.22915907975362984,
      "grad_norm": 0.020881781354546547,
      "learning_rate": 7.708409202463702e-06,
      "loss": 0.001,
      "step": 14473
    },
    {
      "epoch": 0.2291749133112719,
      "grad_norm": 0.00013348700304049999,
      "learning_rate": 7.708250866887281e-06,
      "loss": 0.0,
      "step": 14474
    },
    {
      "epoch": 0.22919074686891397,
      "grad_norm": 0.364952951669693,
      "learning_rate": 7.708092531310862e-06,
      "loss": 0.2413,
      "step": 14475
    },
    {
      "epoch": 0.22920658042655603,
      "grad_norm": 0.7062147855758667,
      "learning_rate": 7.70793419573444e-06,
      "loss": 0.1182,
      "step": 14476
    },
    {
      "epoch": 0.2292224139841981,
      "grad_norm": 0.4579346477985382,
      "learning_rate": 7.70777586015802e-06,
      "loss": 0.1034,
      "step": 14477
    },
    {
      "epoch": 0.2292382475418402,
      "grad_norm": 0.07819363474845886,
      "learning_rate": 7.7076175245816e-06,
      "loss": 0.0032,
      "step": 14478
    },
    {
      "epoch": 0.22925408109948225,
      "grad_norm": 0.03397468477487564,
      "learning_rate": 7.707459189005178e-06,
      "loss": 0.0007,
      "step": 14479
    },
    {
      "epoch": 0.22926991465712432,
      "grad_norm": 0.3017667829990387,
      "learning_rate": 7.707300853428757e-06,
      "loss": 0.0753,
      "step": 14480
    },
    {
      "epoch": 0.22928574821476638,
      "grad_norm": 0.4563371241092682,
      "learning_rate": 7.707142517852338e-06,
      "loss": 0.2971,
      "step": 14481
    },
    {
      "epoch": 0.22930158177240845,
      "grad_norm": 0.015185536816716194,
      "learning_rate": 7.706984182275916e-06,
      "loss": 0.0008,
      "step": 14482
    },
    {
      "epoch": 0.2293174153300505,
      "grad_norm": 0.51606285572052,
      "learning_rate": 7.706825846699496e-06,
      "loss": 0.4874,
      "step": 14483
    },
    {
      "epoch": 0.22933324888769258,
      "grad_norm": 0.04415864869952202,
      "learning_rate": 7.706667511123075e-06,
      "loss": 0.0026,
      "step": 14484
    },
    {
      "epoch": 0.22934908244533464,
      "grad_norm": 0.003767139744013548,
      "learning_rate": 7.706509175546654e-06,
      "loss": 0.0001,
      "step": 14485
    },
    {
      "epoch": 0.2293649160029767,
      "grad_norm": 0.6595973372459412,
      "learning_rate": 7.706350839970234e-06,
      "loss": 0.4172,
      "step": 14486
    },
    {
      "epoch": 0.22938074956061877,
      "grad_norm": 0.05058008432388306,
      "learning_rate": 7.706192504393813e-06,
      "loss": 0.0032,
      "step": 14487
    },
    {
      "epoch": 0.22939658311826083,
      "grad_norm": 0.5791606903076172,
      "learning_rate": 7.706034168817392e-06,
      "loss": 0.486,
      "step": 14488
    },
    {
      "epoch": 0.2294124166759029,
      "grad_norm": 0.00477897422388196,
      "learning_rate": 7.70587583324097e-06,
      "loss": 0.0002,
      "step": 14489
    },
    {
      "epoch": 0.22942825023354496,
      "grad_norm": 0.24840806424617767,
      "learning_rate": 7.705717497664552e-06,
      "loss": 0.0605,
      "step": 14490
    },
    {
      "epoch": 0.22944408379118705,
      "grad_norm": 0.25308752059936523,
      "learning_rate": 7.70555916208813e-06,
      "loss": 0.1319,
      "step": 14491
    },
    {
      "epoch": 0.22945991734882912,
      "grad_norm": 0.4800473749637604,
      "learning_rate": 7.70540082651171e-06,
      "loss": 0.1622,
      "step": 14492
    },
    {
      "epoch": 0.22947575090647118,
      "grad_norm": 0.4894457459449768,
      "learning_rate": 7.705242490935289e-06,
      "loss": 0.1815,
      "step": 14493
    },
    {
      "epoch": 0.22949158446411325,
      "grad_norm": 0.3038748502731323,
      "learning_rate": 7.705084155358868e-06,
      "loss": 0.0775,
      "step": 14494
    },
    {
      "epoch": 0.2295074180217553,
      "grad_norm": 0.4108845591545105,
      "learning_rate": 7.704925819782447e-06,
      "loss": 0.1345,
      "step": 14495
    },
    {
      "epoch": 0.22952325157939737,
      "grad_norm": 0.021024052053689957,
      "learning_rate": 7.704767484206028e-06,
      "loss": 0.001,
      "step": 14496
    },
    {
      "epoch": 0.22953908513703944,
      "grad_norm": 0.33372247219085693,
      "learning_rate": 7.704609148629605e-06,
      "loss": 0.0643,
      "step": 14497
    },
    {
      "epoch": 0.2295549186946815,
      "grad_norm": 0.012053972110152245,
      "learning_rate": 7.704450813053186e-06,
      "loss": 0.0004,
      "step": 14498
    },
    {
      "epoch": 0.22957075225232357,
      "grad_norm": 0.42856118083000183,
      "learning_rate": 7.704292477476765e-06,
      "loss": 0.171,
      "step": 14499
    },
    {
      "epoch": 0.22958658580996563,
      "grad_norm": 0.25902116298675537,
      "learning_rate": 7.704134141900344e-06,
      "loss": 0.0915,
      "step": 14500
    },
    {
      "epoch": 0.2296024193676077,
      "grad_norm": 0.2900983691215515,
      "learning_rate": 7.703975806323923e-06,
      "loss": 0.0304,
      "step": 14501
    },
    {
      "epoch": 0.22961825292524976,
      "grad_norm": 0.019844768568873405,
      "learning_rate": 7.703817470747504e-06,
      "loss": 0.0003,
      "step": 14502
    },
    {
      "epoch": 0.22963408648289185,
      "grad_norm": 0.48870283365249634,
      "learning_rate": 7.703659135171081e-06,
      "loss": 0.0121,
      "step": 14503
    },
    {
      "epoch": 0.22964992004053392,
      "grad_norm": 0.2668747901916504,
      "learning_rate": 7.703500799594662e-06,
      "loss": 0.0686,
      "step": 14504
    },
    {
      "epoch": 0.22966575359817598,
      "grad_norm": 0.1603548377752304,
      "learning_rate": 7.703342464018241e-06,
      "loss": 0.0286,
      "step": 14505
    },
    {
      "epoch": 0.22968158715581805,
      "grad_norm": 0.3312145471572876,
      "learning_rate": 7.70318412844182e-06,
      "loss": 0.1177,
      "step": 14506
    },
    {
      "epoch": 0.2296974207134601,
      "grad_norm": 0.29910391569137573,
      "learning_rate": 7.7030257928654e-06,
      "loss": 0.2047,
      "step": 14507
    },
    {
      "epoch": 0.22971325427110217,
      "grad_norm": 0.029133593663573265,
      "learning_rate": 7.70286745728898e-06,
      "loss": 0.0016,
      "step": 14508
    },
    {
      "epoch": 0.22972908782874424,
      "grad_norm": 0.17367711663246155,
      "learning_rate": 7.702709121712557e-06,
      "loss": 0.046,
      "step": 14509
    },
    {
      "epoch": 0.2297449213863863,
      "grad_norm": 0.19726383686065674,
      "learning_rate": 7.702550786136137e-06,
      "loss": 0.0115,
      "step": 14510
    },
    {
      "epoch": 0.22976075494402837,
      "grad_norm": 0.0044792951084673405,
      "learning_rate": 7.702392450559717e-06,
      "loss": 0.0002,
      "step": 14511
    },
    {
      "epoch": 0.22977658850167043,
      "grad_norm": 0.27623477578163147,
      "learning_rate": 7.702234114983296e-06,
      "loss": 0.0067,
      "step": 14512
    },
    {
      "epoch": 0.2297924220593125,
      "grad_norm": 0.5551061034202576,
      "learning_rate": 7.702075779406875e-06,
      "loss": 0.1015,
      "step": 14513
    },
    {
      "epoch": 0.22980825561695456,
      "grad_norm": 0.00018050556536763906,
      "learning_rate": 7.701917443830455e-06,
      "loss": 0.0,
      "step": 14514
    },
    {
      "epoch": 0.22982408917459665,
      "grad_norm": 0.2299119383096695,
      "learning_rate": 7.701759108254034e-06,
      "loss": 0.1413,
      "step": 14515
    },
    {
      "epoch": 0.22983992273223872,
      "grad_norm": 0.00033625727519392967,
      "learning_rate": 7.701600772677613e-06,
      "loss": 0.0,
      "step": 14516
    },
    {
      "epoch": 0.22985575628988078,
      "grad_norm": 0.13551411032676697,
      "learning_rate": 7.701442437101194e-06,
      "loss": 0.046,
      "step": 14517
    },
    {
      "epoch": 0.22987158984752284,
      "grad_norm": 0.24871757626533508,
      "learning_rate": 7.701284101524773e-06,
      "loss": 0.0892,
      "step": 14518
    },
    {
      "epoch": 0.2298874234051649,
      "grad_norm": 0.6603453159332275,
      "learning_rate": 7.701125765948352e-06,
      "loss": 0.1275,
      "step": 14519
    },
    {
      "epoch": 0.22990325696280697,
      "grad_norm": 1.0657504796981812,
      "learning_rate": 7.70096743037193e-06,
      "loss": 0.5017,
      "step": 14520
    },
    {
      "epoch": 0.22991909052044904,
      "grad_norm": 0.3393913805484772,
      "learning_rate": 7.70080909479551e-06,
      "loss": 0.1728,
      "step": 14521
    },
    {
      "epoch": 0.2299349240780911,
      "grad_norm": 0.0035777485463768244,
      "learning_rate": 7.700650759219089e-06,
      "loss": 0.0001,
      "step": 14522
    },
    {
      "epoch": 0.22995075763573317,
      "grad_norm": 0.2238551676273346,
      "learning_rate": 7.70049242364267e-06,
      "loss": 0.0459,
      "step": 14523
    },
    {
      "epoch": 0.22996659119337523,
      "grad_norm": 0.2930227220058441,
      "learning_rate": 7.700334088066249e-06,
      "loss": 0.1428,
      "step": 14524
    },
    {
      "epoch": 0.2299824247510173,
      "grad_norm": 0.5766473412513733,
      "learning_rate": 7.700175752489828e-06,
      "loss": 0.29,
      "step": 14525
    },
    {
      "epoch": 0.22999825830865936,
      "grad_norm": 0.32297584414482117,
      "learning_rate": 7.700017416913407e-06,
      "loss": 0.0731,
      "step": 14526
    },
    {
      "epoch": 0.23001409186630145,
      "grad_norm": 0.0004919368657283485,
      "learning_rate": 7.699859081336986e-06,
      "loss": 0.0,
      "step": 14527
    },
    {
      "epoch": 0.23002992542394352,
      "grad_norm": 0.6066309213638306,
      "learning_rate": 7.699700745760565e-06,
      "loss": 0.0468,
      "step": 14528
    },
    {
      "epoch": 0.23004575898158558,
      "grad_norm": 0.0019094264134764671,
      "learning_rate": 7.699542410184146e-06,
      "loss": 0.0001,
      "step": 14529
    },
    {
      "epoch": 0.23006159253922764,
      "grad_norm": 0.326030969619751,
      "learning_rate": 7.699384074607725e-06,
      "loss": 0.0466,
      "step": 14530
    },
    {
      "epoch": 0.2300774260968697,
      "grad_norm": 0.5111664533615112,
      "learning_rate": 7.699225739031304e-06,
      "loss": 0.5215,
      "step": 14531
    },
    {
      "epoch": 0.23009325965451177,
      "grad_norm": 0.008203515782952309,
      "learning_rate": 7.699067403454883e-06,
      "loss": 0.0004,
      "step": 14532
    },
    {
      "epoch": 0.23010909321215384,
      "grad_norm": 0.09966080635786057,
      "learning_rate": 7.698909067878462e-06,
      "loss": 0.0022,
      "step": 14533
    },
    {
      "epoch": 0.2301249267697959,
      "grad_norm": 0.05446247383952141,
      "learning_rate": 7.698750732302041e-06,
      "loss": 0.0023,
      "step": 14534
    },
    {
      "epoch": 0.23014076032743797,
      "grad_norm": 0.8573433756828308,
      "learning_rate": 7.69859239672562e-06,
      "loss": 0.1477,
      "step": 14535
    },
    {
      "epoch": 0.23015659388508003,
      "grad_norm": 0.21320731937885284,
      "learning_rate": 7.698434061149201e-06,
      "loss": 0.0123,
      "step": 14536
    },
    {
      "epoch": 0.2301724274427221,
      "grad_norm": 0.5659024715423584,
      "learning_rate": 7.698275725572778e-06,
      "loss": 0.3845,
      "step": 14537
    },
    {
      "epoch": 0.23018826100036416,
      "grad_norm": 0.5061435699462891,
      "learning_rate": 7.69811738999636e-06,
      "loss": 0.1494,
      "step": 14538
    },
    {
      "epoch": 0.23020409455800625,
      "grad_norm": 0.30964377522468567,
      "learning_rate": 7.697959054419938e-06,
      "loss": 0.0359,
      "step": 14539
    },
    {
      "epoch": 0.23021992811564831,
      "grad_norm": 0.00040015802369453013,
      "learning_rate": 7.697800718843517e-06,
      "loss": 0.0,
      "step": 14540
    },
    {
      "epoch": 0.23023576167329038,
      "grad_norm": 0.5508007407188416,
      "learning_rate": 7.697642383267096e-06,
      "loss": 0.3791,
      "step": 14541
    },
    {
      "epoch": 0.23025159523093244,
      "grad_norm": 0.06425134837627411,
      "learning_rate": 7.697484047690677e-06,
      "loss": 0.008,
      "step": 14542
    },
    {
      "epoch": 0.2302674287885745,
      "grad_norm": 0.004163157194852829,
      "learning_rate": 7.697325712114255e-06,
      "loss": 0.0001,
      "step": 14543
    },
    {
      "epoch": 0.23028326234621657,
      "grad_norm": 0.006851317826658487,
      "learning_rate": 7.697167376537835e-06,
      "loss": 0.0003,
      "step": 14544
    },
    {
      "epoch": 0.23029909590385864,
      "grad_norm": 0.03319665417075157,
      "learning_rate": 7.697009040961415e-06,
      "loss": 0.0019,
      "step": 14545
    },
    {
      "epoch": 0.2303149294615007,
      "grad_norm": 0.5017996430397034,
      "learning_rate": 7.696850705384994e-06,
      "loss": 0.1496,
      "step": 14546
    },
    {
      "epoch": 0.23033076301914276,
      "grad_norm": 0.002146841259673238,
      "learning_rate": 7.696692369808573e-06,
      "loss": 0.0,
      "step": 14547
    },
    {
      "epoch": 0.23034659657678483,
      "grad_norm": 0.14065496623516083,
      "learning_rate": 7.696534034232153e-06,
      "loss": 0.0375,
      "step": 14548
    },
    {
      "epoch": 0.2303624301344269,
      "grad_norm": 0.2963944375514984,
      "learning_rate": 7.69637569865573e-06,
      "loss": 0.0673,
      "step": 14549
    },
    {
      "epoch": 0.23037826369206896,
      "grad_norm": 0.015138483606278896,
      "learning_rate": 7.696217363079312e-06,
      "loss": 0.0007,
      "step": 14550
    },
    {
      "epoch": 0.23039409724971105,
      "grad_norm": 0.030538350343704224,
      "learning_rate": 7.69605902750289e-06,
      "loss": 0.0017,
      "step": 14551
    },
    {
      "epoch": 0.2304099308073531,
      "grad_norm": 0.02912314608693123,
      "learning_rate": 7.69590069192647e-06,
      "loss": 0.0016,
      "step": 14552
    },
    {
      "epoch": 0.23042576436499518,
      "grad_norm": 0.5551506876945496,
      "learning_rate": 7.695742356350049e-06,
      "loss": 0.2109,
      "step": 14553
    },
    {
      "epoch": 0.23044159792263724,
      "grad_norm": 0.38465556502342224,
      "learning_rate": 7.695584020773628e-06,
      "loss": 0.0977,
      "step": 14554
    },
    {
      "epoch": 0.2304574314802793,
      "grad_norm": 0.22638829052448273,
      "learning_rate": 7.695425685197207e-06,
      "loss": 0.051,
      "step": 14555
    },
    {
      "epoch": 0.23047326503792137,
      "grad_norm": 0.45292696356773376,
      "learning_rate": 7.695267349620788e-06,
      "loss": 0.0803,
      "step": 14556
    },
    {
      "epoch": 0.23048909859556344,
      "grad_norm": 0.42865416407585144,
      "learning_rate": 7.695109014044367e-06,
      "loss": 0.1157,
      "step": 14557
    },
    {
      "epoch": 0.2305049321532055,
      "grad_norm": 0.4234425723552704,
      "learning_rate": 7.694950678467944e-06,
      "loss": 0.6799,
      "step": 14558
    },
    {
      "epoch": 0.23052076571084756,
      "grad_norm": 0.00031488353852182627,
      "learning_rate": 7.694792342891525e-06,
      "loss": 0.0,
      "step": 14559
    },
    {
      "epoch": 0.23053659926848963,
      "grad_norm": 0.5115216970443726,
      "learning_rate": 7.694634007315104e-06,
      "loss": 0.2584,
      "step": 14560
    },
    {
      "epoch": 0.2305524328261317,
      "grad_norm": 0.26612430810928345,
      "learning_rate": 7.694475671738683e-06,
      "loss": 0.1457,
      "step": 14561
    },
    {
      "epoch": 0.23056826638377376,
      "grad_norm": 0.4154183268547058,
      "learning_rate": 7.694317336162262e-06,
      "loss": 0.1411,
      "step": 14562
    },
    {
      "epoch": 0.23058409994141585,
      "grad_norm": 0.005174880847334862,
      "learning_rate": 7.694159000585843e-06,
      "loss": 0.0002,
      "step": 14563
    },
    {
      "epoch": 0.2305999334990579,
      "grad_norm": 0.43249255418777466,
      "learning_rate": 7.69400066500942e-06,
      "loss": 0.062,
      "step": 14564
    },
    {
      "epoch": 0.23061576705669998,
      "grad_norm": 0.30729514360427856,
      "learning_rate": 7.693842329433001e-06,
      "loss": 0.1011,
      "step": 14565
    },
    {
      "epoch": 0.23063160061434204,
      "grad_norm": 0.2558111846446991,
      "learning_rate": 7.69368399385658e-06,
      "loss": 0.0289,
      "step": 14566
    },
    {
      "epoch": 0.2306474341719841,
      "grad_norm": 0.3614020049571991,
      "learning_rate": 7.69352565828016e-06,
      "loss": 0.1109,
      "step": 14567
    },
    {
      "epoch": 0.23066326772962617,
      "grad_norm": 0.24647623300552368,
      "learning_rate": 7.693367322703738e-06,
      "loss": 0.0845,
      "step": 14568
    },
    {
      "epoch": 0.23067910128726823,
      "grad_norm": 0.00020250304078217596,
      "learning_rate": 7.69320898712732e-06,
      "loss": 0.0,
      "step": 14569
    },
    {
      "epoch": 0.2306949348449103,
      "grad_norm": 0.47311022877693176,
      "learning_rate": 7.693050651550897e-06,
      "loss": 0.4357,
      "step": 14570
    },
    {
      "epoch": 0.23071076840255236,
      "grad_norm": 0.2932330369949341,
      "learning_rate": 7.692892315974477e-06,
      "loss": 0.0965,
      "step": 14571
    },
    {
      "epoch": 0.23072660196019443,
      "grad_norm": 9.71702829701826e-05,
      "learning_rate": 7.692733980398056e-06,
      "loss": 0.0,
      "step": 14572
    },
    {
      "epoch": 0.2307424355178365,
      "grad_norm": 0.391202837228775,
      "learning_rate": 7.692575644821636e-06,
      "loss": 0.1093,
      "step": 14573
    },
    {
      "epoch": 0.23075826907547856,
      "grad_norm": 0.027900338172912598,
      "learning_rate": 7.692417309245215e-06,
      "loss": 0.0014,
      "step": 14574
    },
    {
      "epoch": 0.23077410263312065,
      "grad_norm": 0.005030639469623566,
      "learning_rate": 7.692258973668795e-06,
      "loss": 0.0001,
      "step": 14575
    },
    {
      "epoch": 0.2307899361907627,
      "grad_norm": 0.34590139985084534,
      "learning_rate": 7.692100638092373e-06,
      "loss": 0.0478,
      "step": 14576
    },
    {
      "epoch": 0.23080576974840478,
      "grad_norm": 0.6753826141357422,
      "learning_rate": 7.691942302515954e-06,
      "loss": 0.1185,
      "step": 14577
    },
    {
      "epoch": 0.23082160330604684,
      "grad_norm": 4.2028186726383865e-05,
      "learning_rate": 7.691783966939533e-06,
      "loss": 0.0,
      "step": 14578
    },
    {
      "epoch": 0.2308374368636889,
      "grad_norm": 0.3457830548286438,
      "learning_rate": 7.691625631363112e-06,
      "loss": 0.5807,
      "step": 14579
    },
    {
      "epoch": 0.23085327042133097,
      "grad_norm": 0.008997420780360699,
      "learning_rate": 7.69146729578669e-06,
      "loss": 0.0005,
      "step": 14580
    },
    {
      "epoch": 0.23086910397897303,
      "grad_norm": 0.0001033222652040422,
      "learning_rate": 7.69130896021027e-06,
      "loss": 0.0,
      "step": 14581
    },
    {
      "epoch": 0.2308849375366151,
      "grad_norm": 0.4841943085193634,
      "learning_rate": 7.691150624633849e-06,
      "loss": 0.038,
      "step": 14582
    },
    {
      "epoch": 0.23090077109425716,
      "grad_norm": 0.45811423659324646,
      "learning_rate": 7.690992289057428e-06,
      "loss": 0.3395,
      "step": 14583
    },
    {
      "epoch": 0.23091660465189923,
      "grad_norm": 0.649806797504425,
      "learning_rate": 7.690833953481009e-06,
      "loss": 0.1492,
      "step": 14584
    },
    {
      "epoch": 0.2309324382095413,
      "grad_norm": 0.02141246199607849,
      "learning_rate": 7.690675617904588e-06,
      "loss": 0.0011,
      "step": 14585
    },
    {
      "epoch": 0.23094827176718336,
      "grad_norm": 0.12615379691123962,
      "learning_rate": 7.690517282328167e-06,
      "loss": 0.0052,
      "step": 14586
    },
    {
      "epoch": 0.23096410532482545,
      "grad_norm": 0.18377794325351715,
      "learning_rate": 7.690358946751746e-06,
      "loss": 0.0496,
      "step": 14587
    },
    {
      "epoch": 0.2309799388824675,
      "grad_norm": 0.3419873118400574,
      "learning_rate": 7.690200611175325e-06,
      "loss": 0.0646,
      "step": 14588
    },
    {
      "epoch": 0.23099577244010958,
      "grad_norm": 0.03726772218942642,
      "learning_rate": 7.690042275598904e-06,
      "loss": 0.0016,
      "step": 14589
    },
    {
      "epoch": 0.23101160599775164,
      "grad_norm": 0.024134287610650063,
      "learning_rate": 7.689883940022485e-06,
      "loss": 0.001,
      "step": 14590
    },
    {
      "epoch": 0.2310274395553937,
      "grad_norm": 0.309113472700119,
      "learning_rate": 7.689725604446064e-06,
      "loss": 0.062,
      "step": 14591
    },
    {
      "epoch": 0.23104327311303577,
      "grad_norm": 0.5818095207214355,
      "learning_rate": 7.689567268869643e-06,
      "loss": 0.1321,
      "step": 14592
    },
    {
      "epoch": 0.23105910667067783,
      "grad_norm": 0.00016939851047936827,
      "learning_rate": 7.689408933293222e-06,
      "loss": 0.0,
      "step": 14593
    },
    {
      "epoch": 0.2310749402283199,
      "grad_norm": 0.014673209749162197,
      "learning_rate": 7.689250597716801e-06,
      "loss": 0.0004,
      "step": 14594
    },
    {
      "epoch": 0.23109077378596196,
      "grad_norm": 0.440527081489563,
      "learning_rate": 7.68909226214038e-06,
      "loss": 0.1091,
      "step": 14595
    },
    {
      "epoch": 0.23110660734360403,
      "grad_norm": 1.5032683610916138,
      "learning_rate": 7.688933926563961e-06,
      "loss": 0.6053,
      "step": 14596
    },
    {
      "epoch": 0.2311224409012461,
      "grad_norm": 0.7457184791564941,
      "learning_rate": 7.68877559098754e-06,
      "loss": 0.0366,
      "step": 14597
    },
    {
      "epoch": 0.23113827445888815,
      "grad_norm": 0.06829360127449036,
      "learning_rate": 7.68861725541112e-06,
      "loss": 0.0038,
      "step": 14598
    },
    {
      "epoch": 0.23115410801653025,
      "grad_norm": 0.40043923258781433,
      "learning_rate": 7.688458919834698e-06,
      "loss": 0.1906,
      "step": 14599
    },
    {
      "epoch": 0.2311699415741723,
      "grad_norm": 0.4745955169200897,
      "learning_rate": 7.688300584258277e-06,
      "loss": 0.3473,
      "step": 14600
    },
    {
      "epoch": 0.23118577513181437,
      "grad_norm": 0.5021023154258728,
      "learning_rate": 7.688142248681857e-06,
      "loss": 0.2643,
      "step": 14601
    },
    {
      "epoch": 0.23120160868945644,
      "grad_norm": 0.27071890234947205,
      "learning_rate": 7.687983913105437e-06,
      "loss": 0.1069,
      "step": 14602
    },
    {
      "epoch": 0.2312174422470985,
      "grad_norm": 0.6041901707649231,
      "learning_rate": 7.687825577529016e-06,
      "loss": 0.5538,
      "step": 14603
    },
    {
      "epoch": 0.23123327580474057,
      "grad_norm": 0.372760534286499,
      "learning_rate": 7.687667241952595e-06,
      "loss": 0.2066,
      "step": 14604
    },
    {
      "epoch": 0.23124910936238263,
      "grad_norm": 0.2620108723640442,
      "learning_rate": 7.687508906376175e-06,
      "loss": 0.0098,
      "step": 14605
    },
    {
      "epoch": 0.2312649429200247,
      "grad_norm": 0.22784648835659027,
      "learning_rate": 7.687350570799754e-06,
      "loss": 0.0432,
      "step": 14606
    },
    {
      "epoch": 0.23128077647766676,
      "grad_norm": 0.06386508792638779,
      "learning_rate": 7.687192235223333e-06,
      "loss": 0.0033,
      "step": 14607
    },
    {
      "epoch": 0.23129661003530883,
      "grad_norm": 0.5890051126480103,
      "learning_rate": 7.687033899646912e-06,
      "loss": 0.7105,
      "step": 14608
    },
    {
      "epoch": 0.2313124435929509,
      "grad_norm": 0.42372605204582214,
      "learning_rate": 7.686875564070493e-06,
      "loss": 0.2046,
      "step": 14609
    },
    {
      "epoch": 0.23132827715059295,
      "grad_norm": 0.3334215581417084,
      "learning_rate": 7.68671722849407e-06,
      "loss": 0.1374,
      "step": 14610
    },
    {
      "epoch": 0.23134411070823505,
      "grad_norm": 0.4208889603614807,
      "learning_rate": 7.68655889291765e-06,
      "loss": 0.2448,
      "step": 14611
    },
    {
      "epoch": 0.2313599442658771,
      "grad_norm": 0.5679824948310852,
      "learning_rate": 7.68640055734123e-06,
      "loss": 0.131,
      "step": 14612
    },
    {
      "epoch": 0.23137577782351917,
      "grad_norm": 0.20049090683460236,
      "learning_rate": 7.686242221764809e-06,
      "loss": 0.0499,
      "step": 14613
    },
    {
      "epoch": 0.23139161138116124,
      "grad_norm": 0.0007290576468221843,
      "learning_rate": 7.686083886188388e-06,
      "loss": 0.0,
      "step": 14614
    },
    {
      "epoch": 0.2314074449388033,
      "grad_norm": 0.24781277775764465,
      "learning_rate": 7.685925550611969e-06,
      "loss": 0.1079,
      "step": 14615
    },
    {
      "epoch": 0.23142327849644537,
      "grad_norm": 0.1618843525648117,
      "learning_rate": 7.685767215035546e-06,
      "loss": 0.0707,
      "step": 14616
    },
    {
      "epoch": 0.23143911205408743,
      "grad_norm": 0.1695181429386139,
      "learning_rate": 7.685608879459127e-06,
      "loss": 0.0283,
      "step": 14617
    },
    {
      "epoch": 0.2314549456117295,
      "grad_norm": 0.008825828321278095,
      "learning_rate": 7.685450543882706e-06,
      "loss": 0.0004,
      "step": 14618
    },
    {
      "epoch": 0.23147077916937156,
      "grad_norm": 0.2967679798603058,
      "learning_rate": 7.685292208306285e-06,
      "loss": 0.0477,
      "step": 14619
    },
    {
      "epoch": 0.23148661272701362,
      "grad_norm": 0.21960589289665222,
      "learning_rate": 7.685133872729864e-06,
      "loss": 0.0887,
      "step": 14620
    },
    {
      "epoch": 0.2315024462846557,
      "grad_norm": 0.00018366935546509922,
      "learning_rate": 7.684975537153443e-06,
      "loss": 0.0,
      "step": 14621
    },
    {
      "epoch": 0.23151827984229775,
      "grad_norm": 0.43753165006637573,
      "learning_rate": 7.684817201577022e-06,
      "loss": 0.0906,
      "step": 14622
    },
    {
      "epoch": 0.23153411339993984,
      "grad_norm": 0.0070325941778719425,
      "learning_rate": 7.684658866000603e-06,
      "loss": 0.0002,
      "step": 14623
    },
    {
      "epoch": 0.2315499469575819,
      "grad_norm": 0.014667695388197899,
      "learning_rate": 7.684500530424182e-06,
      "loss": 0.0006,
      "step": 14624
    },
    {
      "epoch": 0.23156578051522397,
      "grad_norm": 0.4892367124557495,
      "learning_rate": 7.684342194847761e-06,
      "loss": 0.1781,
      "step": 14625
    },
    {
      "epoch": 0.23158161407286604,
      "grad_norm": 0.01004810445010662,
      "learning_rate": 7.68418385927134e-06,
      "loss": 0.0004,
      "step": 14626
    },
    {
      "epoch": 0.2315974476305081,
      "grad_norm": 0.000126088663819246,
      "learning_rate": 7.68402552369492e-06,
      "loss": 0.0,
      "step": 14627
    },
    {
      "epoch": 0.23161328118815017,
      "grad_norm": 0.5664237141609192,
      "learning_rate": 7.683867188118498e-06,
      "loss": 0.2225,
      "step": 14628
    },
    {
      "epoch": 0.23162911474579223,
      "grad_norm": 0.6884543895721436,
      "learning_rate": 7.683708852542078e-06,
      "loss": 0.1262,
      "step": 14629
    },
    {
      "epoch": 0.2316449483034343,
      "grad_norm": 0.5382288098335266,
      "learning_rate": 7.683550516965658e-06,
      "loss": 0.0764,
      "step": 14630
    },
    {
      "epoch": 0.23166078186107636,
      "grad_norm": 0.017799897119402885,
      "learning_rate": 7.683392181389236e-06,
      "loss": 0.0008,
      "step": 14631
    },
    {
      "epoch": 0.23167661541871842,
      "grad_norm": 0.4349207878112793,
      "learning_rate": 7.683233845812816e-06,
      "loss": 0.0979,
      "step": 14632
    },
    {
      "epoch": 0.2316924489763605,
      "grad_norm": 0.2628622055053711,
      "learning_rate": 7.683075510236396e-06,
      "loss": 0.0899,
      "step": 14633
    },
    {
      "epoch": 0.23170828253400255,
      "grad_norm": 0.00741222407668829,
      "learning_rate": 7.682917174659975e-06,
      "loss": 0.0003,
      "step": 14634
    },
    {
      "epoch": 0.23172411609164464,
      "grad_norm": 0.008766264654695988,
      "learning_rate": 7.682758839083554e-06,
      "loss": 0.0003,
      "step": 14635
    },
    {
      "epoch": 0.2317399496492867,
      "grad_norm": 0.0024886068422347307,
      "learning_rate": 7.682600503507134e-06,
      "loss": 0.0001,
      "step": 14636
    },
    {
      "epoch": 0.23175578320692877,
      "grad_norm": 0.46309712529182434,
      "learning_rate": 7.682442167930712e-06,
      "loss": 0.1495,
      "step": 14637
    },
    {
      "epoch": 0.23177161676457084,
      "grad_norm": 0.0004369291418697685,
      "learning_rate": 7.682283832354293e-06,
      "loss": 0.0,
      "step": 14638
    },
    {
      "epoch": 0.2317874503222129,
      "grad_norm": 0.8512335419654846,
      "learning_rate": 7.682125496777872e-06,
      "loss": 0.5108,
      "step": 14639
    },
    {
      "epoch": 0.23180328387985497,
      "grad_norm": 0.6244151592254639,
      "learning_rate": 7.68196716120145e-06,
      "loss": 0.1062,
      "step": 14640
    },
    {
      "epoch": 0.23181911743749703,
      "grad_norm": 0.3149977922439575,
      "learning_rate": 7.68180882562503e-06,
      "loss": 0.0856,
      "step": 14641
    },
    {
      "epoch": 0.2318349509951391,
      "grad_norm": 0.3318967819213867,
      "learning_rate": 7.68165049004861e-06,
      "loss": 0.0063,
      "step": 14642
    },
    {
      "epoch": 0.23185078455278116,
      "grad_norm": 0.2519305944442749,
      "learning_rate": 7.681492154472188e-06,
      "loss": 0.0963,
      "step": 14643
    },
    {
      "epoch": 0.23186661811042322,
      "grad_norm": 0.31405335664749146,
      "learning_rate": 7.681333818895769e-06,
      "loss": 0.0249,
      "step": 14644
    },
    {
      "epoch": 0.2318824516680653,
      "grad_norm": 0.02015887387096882,
      "learning_rate": 7.681175483319348e-06,
      "loss": 0.0008,
      "step": 14645
    },
    {
      "epoch": 0.23189828522570735,
      "grad_norm": 0.5182158946990967,
      "learning_rate": 7.681017147742927e-06,
      "loss": 0.2,
      "step": 14646
    },
    {
      "epoch": 0.23191411878334944,
      "grad_norm": 0.47302567958831787,
      "learning_rate": 7.680858812166506e-06,
      "loss": 0.243,
      "step": 14647
    },
    {
      "epoch": 0.2319299523409915,
      "grad_norm": 0.3648489713668823,
      "learning_rate": 7.680700476590087e-06,
      "loss": 0.1388,
      "step": 14648
    },
    {
      "epoch": 0.23194578589863357,
      "grad_norm": 0.003926819656044245,
      "learning_rate": 7.680542141013664e-06,
      "loss": 0.0001,
      "step": 14649
    },
    {
      "epoch": 0.23196161945627564,
      "grad_norm": 0.655012309551239,
      "learning_rate": 7.680383805437245e-06,
      "loss": 0.22,
      "step": 14650
    },
    {
      "epoch": 0.2319774530139177,
      "grad_norm": 0.7443441152572632,
      "learning_rate": 7.680225469860824e-06,
      "loss": 0.1385,
      "step": 14651
    },
    {
      "epoch": 0.23199328657155976,
      "grad_norm": 0.3147733211517334,
      "learning_rate": 7.680067134284403e-06,
      "loss": 0.0985,
      "step": 14652
    },
    {
      "epoch": 0.23200912012920183,
      "grad_norm": 0.35158097743988037,
      "learning_rate": 7.679908798707982e-06,
      "loss": 0.0291,
      "step": 14653
    },
    {
      "epoch": 0.2320249536868439,
      "grad_norm": 0.3420799672603607,
      "learning_rate": 7.679750463131561e-06,
      "loss": 0.0764,
      "step": 14654
    },
    {
      "epoch": 0.23204078724448596,
      "grad_norm": 0.00047688980703242123,
      "learning_rate": 7.67959212755514e-06,
      "loss": 0.0,
      "step": 14655
    },
    {
      "epoch": 0.23205662080212802,
      "grad_norm": 0.01316528208553791,
      "learning_rate": 7.67943379197872e-06,
      "loss": 0.0006,
      "step": 14656
    },
    {
      "epoch": 0.2320724543597701,
      "grad_norm": 1.3627504110336304,
      "learning_rate": 7.6792754564023e-06,
      "loss": 0.545,
      "step": 14657
    },
    {
      "epoch": 0.23208828791741215,
      "grad_norm": 0.37459251284599304,
      "learning_rate": 7.67911712082588e-06,
      "loss": 0.071,
      "step": 14658
    },
    {
      "epoch": 0.23210412147505424,
      "grad_norm": 0.011527330614626408,
      "learning_rate": 7.678958785249458e-06,
      "loss": 0.0005,
      "step": 14659
    },
    {
      "epoch": 0.2321199550326963,
      "grad_norm": 0.5390298962593079,
      "learning_rate": 7.678800449673037e-06,
      "loss": 0.1904,
      "step": 14660
    },
    {
      "epoch": 0.23213578859033837,
      "grad_norm": 0.32736489176750183,
      "learning_rate": 7.678642114096617e-06,
      "loss": 0.1372,
      "step": 14661
    },
    {
      "epoch": 0.23215162214798044,
      "grad_norm": 0.005840275436639786,
      "learning_rate": 7.678483778520196e-06,
      "loss": 0.0002,
      "step": 14662
    },
    {
      "epoch": 0.2321674557056225,
      "grad_norm": 0.24403180181980133,
      "learning_rate": 7.678325442943776e-06,
      "loss": 0.0318,
      "step": 14663
    },
    {
      "epoch": 0.23218328926326456,
      "grad_norm": 0.36791014671325684,
      "learning_rate": 7.678167107367355e-06,
      "loss": 0.0774,
      "step": 14664
    },
    {
      "epoch": 0.23219912282090663,
      "grad_norm": 0.40587347745895386,
      "learning_rate": 7.678008771790935e-06,
      "loss": 0.2082,
      "step": 14665
    },
    {
      "epoch": 0.2322149563785487,
      "grad_norm": 7.78104440541938e-05,
      "learning_rate": 7.677850436214514e-06,
      "loss": 0.0,
      "step": 14666
    },
    {
      "epoch": 0.23223078993619076,
      "grad_norm": 0.33779096603393555,
      "learning_rate": 7.677692100638093e-06,
      "loss": 0.0962,
      "step": 14667
    },
    {
      "epoch": 0.23224662349383282,
      "grad_norm": 0.021292008459568024,
      "learning_rate": 7.677533765061672e-06,
      "loss": 0.0009,
      "step": 14668
    },
    {
      "epoch": 0.23226245705147489,
      "grad_norm": 3.0269095077528618e-05,
      "learning_rate": 7.677375429485253e-06,
      "loss": 0.0,
      "step": 14669
    },
    {
      "epoch": 0.23227829060911695,
      "grad_norm": 0.020157400518655777,
      "learning_rate": 7.677217093908832e-06,
      "loss": 0.0005,
      "step": 14670
    },
    {
      "epoch": 0.23229412416675904,
      "grad_norm": 0.2854779064655304,
      "learning_rate": 7.67705875833241e-06,
      "loss": 0.0499,
      "step": 14671
    },
    {
      "epoch": 0.2323099577244011,
      "grad_norm": 1.5160627365112305,
      "learning_rate": 7.67690042275599e-06,
      "loss": 0.745,
      "step": 14672
    },
    {
      "epoch": 0.23232579128204317,
      "grad_norm": 0.028671804815530777,
      "learning_rate": 7.676742087179569e-06,
      "loss": 0.0013,
      "step": 14673
    },
    {
      "epoch": 0.23234162483968523,
      "grad_norm": 0.3196394443511963,
      "learning_rate": 7.676583751603148e-06,
      "loss": 0.1116,
      "step": 14674
    },
    {
      "epoch": 0.2323574583973273,
      "grad_norm": 0.45226016640663147,
      "learning_rate": 7.676425416026729e-06,
      "loss": 0.1856,
      "step": 14675
    },
    {
      "epoch": 0.23237329195496936,
      "grad_norm": 0.44576704502105713,
      "learning_rate": 7.676267080450308e-06,
      "loss": 0.2317,
      "step": 14676
    },
    {
      "epoch": 0.23238912551261143,
      "grad_norm": 0.10670682042837143,
      "learning_rate": 7.676108744873885e-06,
      "loss": 0.022,
      "step": 14677
    },
    {
      "epoch": 0.2324049590702535,
      "grad_norm": 0.6641978621482849,
      "learning_rate": 7.675950409297466e-06,
      "loss": 0.1201,
      "step": 14678
    },
    {
      "epoch": 0.23242079262789556,
      "grad_norm": 0.43511074781417847,
      "learning_rate": 7.675792073721045e-06,
      "loss": 0.0242,
      "step": 14679
    },
    {
      "epoch": 0.23243662618553762,
      "grad_norm": 0.01941240020096302,
      "learning_rate": 7.675633738144624e-06,
      "loss": 0.0009,
      "step": 14680
    },
    {
      "epoch": 0.23245245974317968,
      "grad_norm": 0.6735246777534485,
      "learning_rate": 7.675475402568203e-06,
      "loss": 0.5886,
      "step": 14681
    },
    {
      "epoch": 0.23246829330082175,
      "grad_norm": 0.00010820144962053746,
      "learning_rate": 7.675317066991784e-06,
      "loss": 0.0,
      "step": 14682
    },
    {
      "epoch": 0.23248412685846384,
      "grad_norm": 0.16947486996650696,
      "learning_rate": 7.675158731415361e-06,
      "loss": 0.047,
      "step": 14683
    },
    {
      "epoch": 0.2324999604161059,
      "grad_norm": 0.00013153802137821913,
      "learning_rate": 7.675000395838942e-06,
      "loss": 0.0,
      "step": 14684
    },
    {
      "epoch": 0.23251579397374797,
      "grad_norm": 0.1687832921743393,
      "learning_rate": 7.674842060262521e-06,
      "loss": 0.0027,
      "step": 14685
    },
    {
      "epoch": 0.23253162753139003,
      "grad_norm": 0.2630295157432556,
      "learning_rate": 7.6746837246861e-06,
      "loss": 0.0338,
      "step": 14686
    },
    {
      "epoch": 0.2325474610890321,
      "grad_norm": 0.5187987089157104,
      "learning_rate": 7.67452538910968e-06,
      "loss": 0.3686,
      "step": 14687
    },
    {
      "epoch": 0.23256329464667416,
      "grad_norm": 0.023050010204315186,
      "learning_rate": 7.674367053533258e-06,
      "loss": 0.0012,
      "step": 14688
    },
    {
      "epoch": 0.23257912820431623,
      "grad_norm": 0.3456583023071289,
      "learning_rate": 7.674208717956838e-06,
      "loss": 0.0762,
      "step": 14689
    },
    {
      "epoch": 0.2325949617619583,
      "grad_norm": 0.47974371910095215,
      "learning_rate": 7.674050382380418e-06,
      "loss": 0.3781,
      "step": 14690
    },
    {
      "epoch": 0.23261079531960036,
      "grad_norm": 0.6640522480010986,
      "learning_rate": 7.673892046803997e-06,
      "loss": 0.1775,
      "step": 14691
    },
    {
      "epoch": 0.23262662887724242,
      "grad_norm": 0.46651971340179443,
      "learning_rate": 7.673733711227576e-06,
      "loss": 0.1644,
      "step": 14692
    },
    {
      "epoch": 0.23264246243488448,
      "grad_norm": 0.40644001960754395,
      "learning_rate": 7.673575375651156e-06,
      "loss": 0.0776,
      "step": 14693
    },
    {
      "epoch": 0.23265829599252655,
      "grad_norm": 0.3944852948188782,
      "learning_rate": 7.673417040074735e-06,
      "loss": 0.1972,
      "step": 14694
    },
    {
      "epoch": 0.23267412955016864,
      "grad_norm": 0.2482045739889145,
      "learning_rate": 7.673258704498314e-06,
      "loss": 0.0527,
      "step": 14695
    },
    {
      "epoch": 0.2326899631078107,
      "grad_norm": 0.015457289293408394,
      "learning_rate": 7.673100368921894e-06,
      "loss": 0.0007,
      "step": 14696
    },
    {
      "epoch": 0.23270579666545277,
      "grad_norm": 0.19884967803955078,
      "learning_rate": 7.672942033345474e-06,
      "loss": 0.0704,
      "step": 14697
    },
    {
      "epoch": 0.23272163022309483,
      "grad_norm": 0.2615867555141449,
      "learning_rate": 7.672783697769053e-06,
      "loss": 0.0592,
      "step": 14698
    },
    {
      "epoch": 0.2327374637807369,
      "grad_norm": 0.14962513744831085,
      "learning_rate": 7.672625362192632e-06,
      "loss": 0.0088,
      "step": 14699
    },
    {
      "epoch": 0.23275329733837896,
      "grad_norm": 0.39450040459632874,
      "learning_rate": 7.67246702661621e-06,
      "loss": 0.137,
      "step": 14700
    },
    {
      "epoch": 0.23276913089602103,
      "grad_norm": 0.24836844205856323,
      "learning_rate": 7.67230869103979e-06,
      "loss": 0.0453,
      "step": 14701
    },
    {
      "epoch": 0.2327849644536631,
      "grad_norm": 0.0001241387944901362,
      "learning_rate": 7.672150355463369e-06,
      "loss": 0.0,
      "step": 14702
    },
    {
      "epoch": 0.23280079801130515,
      "grad_norm": 0.28868216276168823,
      "learning_rate": 7.67199201988695e-06,
      "loss": 0.0731,
      "step": 14703
    },
    {
      "epoch": 0.23281663156894722,
      "grad_norm": 0.0001451147982152179,
      "learning_rate": 7.671833684310527e-06,
      "loss": 0.0,
      "step": 14704
    },
    {
      "epoch": 0.23283246512658928,
      "grad_norm": 0.23747320473194122,
      "learning_rate": 7.671675348734108e-06,
      "loss": 0.0723,
      "step": 14705
    },
    {
      "epoch": 0.23284829868423135,
      "grad_norm": 0.004570454359054565,
      "learning_rate": 7.671517013157687e-06,
      "loss": 0.0002,
      "step": 14706
    },
    {
      "epoch": 0.23286413224187344,
      "grad_norm": 0.7115928530693054,
      "learning_rate": 7.671358677581266e-06,
      "loss": 0.2372,
      "step": 14707
    },
    {
      "epoch": 0.2328799657995155,
      "grad_norm": 0.5201079249382019,
      "learning_rate": 7.671200342004845e-06,
      "loss": 0.0613,
      "step": 14708
    },
    {
      "epoch": 0.23289579935715757,
      "grad_norm": 0.062489911913871765,
      "learning_rate": 7.671042006428426e-06,
      "loss": 0.0013,
      "step": 14709
    },
    {
      "epoch": 0.23291163291479963,
      "grad_norm": 0.2699328660964966,
      "learning_rate": 7.670883670852003e-06,
      "loss": 0.0668,
      "step": 14710
    },
    {
      "epoch": 0.2329274664724417,
      "grad_norm": 3.773662683670409e-05,
      "learning_rate": 7.670725335275584e-06,
      "loss": 0.0,
      "step": 14711
    },
    {
      "epoch": 0.23294330003008376,
      "grad_norm": 0.06417694687843323,
      "learning_rate": 7.670566999699163e-06,
      "loss": 0.0028,
      "step": 14712
    },
    {
      "epoch": 0.23295913358772583,
      "grad_norm": 0.3373141586780548,
      "learning_rate": 7.670408664122742e-06,
      "loss": 0.1293,
      "step": 14713
    },
    {
      "epoch": 0.2329749671453679,
      "grad_norm": 0.7122641205787659,
      "learning_rate": 7.670250328546321e-06,
      "loss": 0.0874,
      "step": 14714
    },
    {
      "epoch": 0.23299080070300995,
      "grad_norm": 0.4015403389930725,
      "learning_rate": 7.670091992969902e-06,
      "loss": 0.1403,
      "step": 14715
    },
    {
      "epoch": 0.23300663426065202,
      "grad_norm": 0.22713814675807953,
      "learning_rate": 7.66993365739348e-06,
      "loss": 0.0518,
      "step": 14716
    },
    {
      "epoch": 0.23302246781829408,
      "grad_norm": 0.16232024133205414,
      "learning_rate": 7.66977532181706e-06,
      "loss": 0.0364,
      "step": 14717
    },
    {
      "epoch": 0.23303830137593615,
      "grad_norm": 0.7631142139434814,
      "learning_rate": 7.66961698624064e-06,
      "loss": 0.612,
      "step": 14718
    },
    {
      "epoch": 0.23305413493357824,
      "grad_norm": 0.4340105950832367,
      "learning_rate": 7.669458650664218e-06,
      "loss": 0.0267,
      "step": 14719
    },
    {
      "epoch": 0.2330699684912203,
      "grad_norm": 0.2713935077190399,
      "learning_rate": 7.669300315087797e-06,
      "loss": 0.1547,
      "step": 14720
    },
    {
      "epoch": 0.23308580204886237,
      "grad_norm": 0.4401338994503021,
      "learning_rate": 7.669141979511378e-06,
      "loss": 0.1488,
      "step": 14721
    },
    {
      "epoch": 0.23310163560650443,
      "grad_norm": 0.3735099732875824,
      "learning_rate": 7.668983643934956e-06,
      "loss": 0.1229,
      "step": 14722
    },
    {
      "epoch": 0.2331174691641465,
      "grad_norm": 0.22674500942230225,
      "learning_rate": 7.668825308358536e-06,
      "loss": 0.0671,
      "step": 14723
    },
    {
      "epoch": 0.23313330272178856,
      "grad_norm": 0.37602895498275757,
      "learning_rate": 7.668666972782115e-06,
      "loss": 0.1959,
      "step": 14724
    },
    {
      "epoch": 0.23314913627943062,
      "grad_norm": 0.18345730006694794,
      "learning_rate": 7.668508637205695e-06,
      "loss": 0.0515,
      "step": 14725
    },
    {
      "epoch": 0.2331649698370727,
      "grad_norm": 0.05818340927362442,
      "learning_rate": 7.668350301629274e-06,
      "loss": 0.0028,
      "step": 14726
    },
    {
      "epoch": 0.23318080339471475,
      "grad_norm": 0.5375469923019409,
      "learning_rate": 7.668191966052853e-06,
      "loss": 0.3658,
      "step": 14727
    },
    {
      "epoch": 0.23319663695235682,
      "grad_norm": 0.281474769115448,
      "learning_rate": 7.668033630476432e-06,
      "loss": 0.0742,
      "step": 14728
    },
    {
      "epoch": 0.23321247050999888,
      "grad_norm": 0.347011536359787,
      "learning_rate": 7.667875294900011e-06,
      "loss": 0.0487,
      "step": 14729
    },
    {
      "epoch": 0.23322830406764095,
      "grad_norm": 0.01188449002802372,
      "learning_rate": 7.667716959323592e-06,
      "loss": 0.0006,
      "step": 14730
    },
    {
      "epoch": 0.23324413762528304,
      "grad_norm": 0.3895121216773987,
      "learning_rate": 7.66755862374717e-06,
      "loss": 0.2554,
      "step": 14731
    },
    {
      "epoch": 0.2332599711829251,
      "grad_norm": 0.2648221254348755,
      "learning_rate": 7.66740028817075e-06,
      "loss": 0.1314,
      "step": 14732
    },
    {
      "epoch": 0.23327580474056717,
      "grad_norm": 3.863950490951538,
      "learning_rate": 7.667241952594329e-06,
      "loss": 0.0768,
      "step": 14733
    },
    {
      "epoch": 0.23329163829820923,
      "grad_norm": 0.43355825543403625,
      "learning_rate": 7.667083617017908e-06,
      "loss": 0.266,
      "step": 14734
    },
    {
      "epoch": 0.2333074718558513,
      "grad_norm": 0.021810846403241158,
      "learning_rate": 7.666925281441487e-06,
      "loss": 0.0011,
      "step": 14735
    },
    {
      "epoch": 0.23332330541349336,
      "grad_norm": 0.01761743240058422,
      "learning_rate": 7.666766945865068e-06,
      "loss": 0.0008,
      "step": 14736
    },
    {
      "epoch": 0.23333913897113542,
      "grad_norm": 0.23615747690200806,
      "learning_rate": 7.666608610288647e-06,
      "loss": 0.0912,
      "step": 14737
    },
    {
      "epoch": 0.2333549725287775,
      "grad_norm": 0.9606073498725891,
      "learning_rate": 7.666450274712226e-06,
      "loss": 0.3289,
      "step": 14738
    },
    {
      "epoch": 0.23337080608641955,
      "grad_norm": 0.29211312532424927,
      "learning_rate": 7.666291939135805e-06,
      "loss": 0.1323,
      "step": 14739
    },
    {
      "epoch": 0.23338663964406162,
      "grad_norm": 0.4720607399940491,
      "learning_rate": 7.666133603559384e-06,
      "loss": 0.3342,
      "step": 14740
    },
    {
      "epoch": 0.23340247320170368,
      "grad_norm": 0.4892857074737549,
      "learning_rate": 7.665975267982963e-06,
      "loss": 0.2651,
      "step": 14741
    },
    {
      "epoch": 0.23341830675934575,
      "grad_norm": 0.02807614766061306,
      "learning_rate": 7.665816932406544e-06,
      "loss": 0.0014,
      "step": 14742
    },
    {
      "epoch": 0.23343414031698784,
      "grad_norm": 0.048393793404102325,
      "learning_rate": 7.665658596830123e-06,
      "loss": 0.0033,
      "step": 14743
    },
    {
      "epoch": 0.2334499738746299,
      "grad_norm": 0.2297464907169342,
      "learning_rate": 7.665500261253702e-06,
      "loss": 0.0535,
      "step": 14744
    },
    {
      "epoch": 0.23346580743227197,
      "grad_norm": 0.3429986238479614,
      "learning_rate": 7.665341925677281e-06,
      "loss": 0.0395,
      "step": 14745
    },
    {
      "epoch": 0.23348164098991403,
      "grad_norm": 0.00021340644161682576,
      "learning_rate": 7.66518359010086e-06,
      "loss": 0.0,
      "step": 14746
    },
    {
      "epoch": 0.2334974745475561,
      "grad_norm": 0.02351064421236515,
      "learning_rate": 7.66502525452444e-06,
      "loss": 0.0014,
      "step": 14747
    },
    {
      "epoch": 0.23351330810519816,
      "grad_norm": 0.24696849286556244,
      "learning_rate": 7.66486691894802e-06,
      "loss": 0.0777,
      "step": 14748
    },
    {
      "epoch": 0.23352914166284022,
      "grad_norm": 0.7262648344039917,
      "learning_rate": 7.664708583371598e-06,
      "loss": 0.1418,
      "step": 14749
    },
    {
      "epoch": 0.2335449752204823,
      "grad_norm": 0.017238425090909004,
      "learning_rate": 7.664550247795177e-06,
      "loss": 0.0008,
      "step": 14750
    },
    {
      "epoch": 0.23356080877812435,
      "grad_norm": 0.5161179304122925,
      "learning_rate": 7.664391912218757e-06,
      "loss": 0.8792,
      "step": 14751
    },
    {
      "epoch": 0.23357664233576642,
      "grad_norm": 0.004442164208739996,
      "learning_rate": 7.664233576642336e-06,
      "loss": 0.0003,
      "step": 14752
    },
    {
      "epoch": 0.23359247589340848,
      "grad_norm": 0.09388384968042374,
      "learning_rate": 7.664075241065916e-06,
      "loss": 0.0039,
      "step": 14753
    },
    {
      "epoch": 0.23360830945105054,
      "grad_norm": 0.4140983521938324,
      "learning_rate": 7.663916905489495e-06,
      "loss": 0.2136,
      "step": 14754
    },
    {
      "epoch": 0.23362414300869264,
      "grad_norm": 0.010021996684372425,
      "learning_rate": 7.663758569913074e-06,
      "loss": 0.0003,
      "step": 14755
    },
    {
      "epoch": 0.2336399765663347,
      "grad_norm": 0.38784950971603394,
      "learning_rate": 7.663600234336653e-06,
      "loss": 0.0589,
      "step": 14756
    },
    {
      "epoch": 0.23365581012397676,
      "grad_norm": 0.30362948775291443,
      "learning_rate": 7.663441898760234e-06,
      "loss": 0.2226,
      "step": 14757
    },
    {
      "epoch": 0.23367164368161883,
      "grad_norm": 0.0037808658089488745,
      "learning_rate": 7.663283563183813e-06,
      "loss": 0.0002,
      "step": 14758
    },
    {
      "epoch": 0.2336874772392609,
      "grad_norm": 0.5652527809143066,
      "learning_rate": 7.663125227607392e-06,
      "loss": 0.4497,
      "step": 14759
    },
    {
      "epoch": 0.23370331079690296,
      "grad_norm": 0.47217750549316406,
      "learning_rate": 7.66296689203097e-06,
      "loss": 0.5413,
      "step": 14760
    },
    {
      "epoch": 0.23371914435454502,
      "grad_norm": 0.1824079304933548,
      "learning_rate": 7.66280855645455e-06,
      "loss": 0.04,
      "step": 14761
    },
    {
      "epoch": 0.2337349779121871,
      "grad_norm": 0.4037133753299713,
      "learning_rate": 7.662650220878129e-06,
      "loss": 0.114,
      "step": 14762
    },
    {
      "epoch": 0.23375081146982915,
      "grad_norm": 0.967559278011322,
      "learning_rate": 7.66249188530171e-06,
      "loss": 0.3032,
      "step": 14763
    },
    {
      "epoch": 0.23376664502747121,
      "grad_norm": 0.39380669593811035,
      "learning_rate": 7.662333549725289e-06,
      "loss": 0.1003,
      "step": 14764
    },
    {
      "epoch": 0.23378247858511328,
      "grad_norm": 0.013323647901415825,
      "learning_rate": 7.662175214148868e-06,
      "loss": 0.0007,
      "step": 14765
    },
    {
      "epoch": 0.23379831214275534,
      "grad_norm": 0.20970551669597626,
      "learning_rate": 7.662016878572447e-06,
      "loss": 0.0678,
      "step": 14766
    },
    {
      "epoch": 0.23381414570039744,
      "grad_norm": 0.001265062135644257,
      "learning_rate": 7.661858542996026e-06,
      "loss": 0.0,
      "step": 14767
    },
    {
      "epoch": 0.2338299792580395,
      "grad_norm": 0.00040184956742450595,
      "learning_rate": 7.661700207419605e-06,
      "loss": 0.0,
      "step": 14768
    },
    {
      "epoch": 0.23384581281568156,
      "grad_norm": 0.1465953141450882,
      "learning_rate": 7.661541871843186e-06,
      "loss": 0.0198,
      "step": 14769
    },
    {
      "epoch": 0.23386164637332363,
      "grad_norm": 0.18441462516784668,
      "learning_rate": 7.661383536266765e-06,
      "loss": 0.048,
      "step": 14770
    },
    {
      "epoch": 0.2338774799309657,
      "grad_norm": 0.6490203142166138,
      "learning_rate": 7.661225200690344e-06,
      "loss": 0.7122,
      "step": 14771
    },
    {
      "epoch": 0.23389331348860776,
      "grad_norm": 0.5987754464149475,
      "learning_rate": 7.661066865113923e-06,
      "loss": 0.0807,
      "step": 14772
    },
    {
      "epoch": 0.23390914704624982,
      "grad_norm": 0.6891946196556091,
      "learning_rate": 7.660908529537502e-06,
      "loss": 0.2589,
      "step": 14773
    },
    {
      "epoch": 0.23392498060389189,
      "grad_norm": 0.4687362611293793,
      "learning_rate": 7.660750193961081e-06,
      "loss": 0.1638,
      "step": 14774
    },
    {
      "epoch": 0.23394081416153395,
      "grad_norm": 0.2524819076061249,
      "learning_rate": 7.66059185838466e-06,
      "loss": 0.0296,
      "step": 14775
    },
    {
      "epoch": 0.23395664771917601,
      "grad_norm": 0.8036811351776123,
      "learning_rate": 7.660433522808241e-06,
      "loss": 0.0309,
      "step": 14776
    },
    {
      "epoch": 0.23397248127681808,
      "grad_norm": 0.023524470627307892,
      "learning_rate": 7.660275187231819e-06,
      "loss": 0.0011,
      "step": 14777
    },
    {
      "epoch": 0.23398831483446014,
      "grad_norm": 0.30358242988586426,
      "learning_rate": 7.6601168516554e-06,
      "loss": 0.1266,
      "step": 14778
    },
    {
      "epoch": 0.23400414839210223,
      "grad_norm": 0.0003035665722563863,
      "learning_rate": 7.659958516078978e-06,
      "loss": 0.0,
      "step": 14779
    },
    {
      "epoch": 0.2340199819497443,
      "grad_norm": 0.007351980544626713,
      "learning_rate": 7.659800180502557e-06,
      "loss": 0.0002,
      "step": 14780
    },
    {
      "epoch": 0.23403581550738636,
      "grad_norm": 4.803883712156676e-05,
      "learning_rate": 7.659641844926137e-06,
      "loss": 0.0,
      "step": 14781
    },
    {
      "epoch": 0.23405164906502843,
      "grad_norm": 0.33669328689575195,
      "learning_rate": 7.659483509349717e-06,
      "loss": 0.0689,
      "step": 14782
    },
    {
      "epoch": 0.2340674826226705,
      "grad_norm": 0.517130434513092,
      "learning_rate": 7.659325173773295e-06,
      "loss": 0.3172,
      "step": 14783
    },
    {
      "epoch": 0.23408331618031256,
      "grad_norm": 0.04434352368116379,
      "learning_rate": 7.659166838196876e-06,
      "loss": 0.0048,
      "step": 14784
    },
    {
      "epoch": 0.23409914973795462,
      "grad_norm": 0.2323867827653885,
      "learning_rate": 7.659008502620455e-06,
      "loss": 0.0031,
      "step": 14785
    },
    {
      "epoch": 0.23411498329559668,
      "grad_norm": 0.08714167028665543,
      "learning_rate": 7.658850167044034e-06,
      "loss": 0.0057,
      "step": 14786
    },
    {
      "epoch": 0.23413081685323875,
      "grad_norm": 1.4241673946380615,
      "learning_rate": 7.658691831467613e-06,
      "loss": 0.0947,
      "step": 14787
    },
    {
      "epoch": 0.2341466504108808,
      "grad_norm": 0.23012390732765198,
      "learning_rate": 7.658533495891194e-06,
      "loss": 0.0778,
      "step": 14788
    },
    {
      "epoch": 0.23416248396852288,
      "grad_norm": 0.05555512011051178,
      "learning_rate": 7.658375160314771e-06,
      "loss": 0.0036,
      "step": 14789
    },
    {
      "epoch": 0.23417831752616494,
      "grad_norm": 0.0005351532599888742,
      "learning_rate": 7.658216824738352e-06,
      "loss": 0.0,
      "step": 14790
    },
    {
      "epoch": 0.23419415108380703,
      "grad_norm": 0.795746386051178,
      "learning_rate": 7.65805848916193e-06,
      "loss": 0.5589,
      "step": 14791
    },
    {
      "epoch": 0.2342099846414491,
      "grad_norm": 0.2511965334415436,
      "learning_rate": 7.65790015358551e-06,
      "loss": 0.0715,
      "step": 14792
    },
    {
      "epoch": 0.23422581819909116,
      "grad_norm": 0.8170173168182373,
      "learning_rate": 7.657741818009089e-06,
      "loss": 0.1936,
      "step": 14793
    },
    {
      "epoch": 0.23424165175673323,
      "grad_norm": 0.4287113547325134,
      "learning_rate": 7.65758348243267e-06,
      "loss": 0.1071,
      "step": 14794
    },
    {
      "epoch": 0.2342574853143753,
      "grad_norm": 0.33040696382522583,
      "learning_rate": 7.657425146856247e-06,
      "loss": 0.128,
      "step": 14795
    },
    {
      "epoch": 0.23427331887201736,
      "grad_norm": 0.002293204190209508,
      "learning_rate": 7.657266811279828e-06,
      "loss": 0.0001,
      "step": 14796
    },
    {
      "epoch": 0.23428915242965942,
      "grad_norm": 0.42608869075775146,
      "learning_rate": 7.657108475703407e-06,
      "loss": 0.1086,
      "step": 14797
    },
    {
      "epoch": 0.23430498598730148,
      "grad_norm": 0.01805122382938862,
      "learning_rate": 7.656950140126986e-06,
      "loss": 0.0007,
      "step": 14798
    },
    {
      "epoch": 0.23432081954494355,
      "grad_norm": 0.45440277457237244,
      "learning_rate": 7.656791804550565e-06,
      "loss": 0.0988,
      "step": 14799
    },
    {
      "epoch": 0.2343366531025856,
      "grad_norm": 0.0003109451790805906,
      "learning_rate": 7.656633468974144e-06,
      "loss": 0.0,
      "step": 14800
    },
    {
      "epoch": 0.23435248666022768,
      "grad_norm": 0.0006471788510680199,
      "learning_rate": 7.656475133397723e-06,
      "loss": 0.0,
      "step": 14801
    },
    {
      "epoch": 0.23436832021786974,
      "grad_norm": 0.0002613927936181426,
      "learning_rate": 7.656316797821302e-06,
      "loss": 0.0,
      "step": 14802
    },
    {
      "epoch": 0.23438415377551183,
      "grad_norm": 0.01462975051254034,
      "learning_rate": 7.656158462244883e-06,
      "loss": 0.0007,
      "step": 14803
    },
    {
      "epoch": 0.2343999873331539,
      "grad_norm": 0.023502357304096222,
      "learning_rate": 7.656000126668462e-06,
      "loss": 0.0011,
      "step": 14804
    },
    {
      "epoch": 0.23441582089079596,
      "grad_norm": 0.7897162437438965,
      "learning_rate": 7.655841791092041e-06,
      "loss": 0.5312,
      "step": 14805
    },
    {
      "epoch": 0.23443165444843803,
      "grad_norm": 0.32272592186927795,
      "learning_rate": 7.65568345551562e-06,
      "loss": 0.0538,
      "step": 14806
    },
    {
      "epoch": 0.2344474880060801,
      "grad_norm": 0.2608592212200165,
      "learning_rate": 7.6555251199392e-06,
      "loss": 0.0232,
      "step": 14807
    },
    {
      "epoch": 0.23446332156372215,
      "grad_norm": 0.700077474117279,
      "learning_rate": 7.655366784362779e-06,
      "loss": 0.2642,
      "step": 14808
    },
    {
      "epoch": 0.23447915512136422,
      "grad_norm": 0.5539650917053223,
      "learning_rate": 7.65520844878636e-06,
      "loss": 0.1934,
      "step": 14809
    },
    {
      "epoch": 0.23449498867900628,
      "grad_norm": 0.2856317460536957,
      "learning_rate": 7.655050113209938e-06,
      "loss": 0.042,
      "step": 14810
    },
    {
      "epoch": 0.23451082223664835,
      "grad_norm": 0.13661152124404907,
      "learning_rate": 7.654891777633517e-06,
      "loss": 0.0608,
      "step": 14811
    },
    {
      "epoch": 0.2345266557942904,
      "grad_norm": 0.33950352668762207,
      "learning_rate": 7.654733442057097e-06,
      "loss": 0.1152,
      "step": 14812
    },
    {
      "epoch": 0.23454248935193248,
      "grad_norm": 0.023707319051027298,
      "learning_rate": 7.654575106480676e-06,
      "loss": 0.0012,
      "step": 14813
    },
    {
      "epoch": 0.23455832290957454,
      "grad_norm": 0.34812429547309875,
      "learning_rate": 7.654416770904255e-06,
      "loss": 0.0566,
      "step": 14814
    },
    {
      "epoch": 0.23457415646721663,
      "grad_norm": 0.26725631952285767,
      "learning_rate": 7.654258435327835e-06,
      "loss": 0.0589,
      "step": 14815
    },
    {
      "epoch": 0.2345899900248587,
      "grad_norm": 0.03763836622238159,
      "learning_rate": 7.654100099751413e-06,
      "loss": 0.0019,
      "step": 14816
    },
    {
      "epoch": 0.23460582358250076,
      "grad_norm": 0.058072660118341446,
      "learning_rate": 7.653941764174994e-06,
      "loss": 0.0083,
      "step": 14817
    },
    {
      "epoch": 0.23462165714014283,
      "grad_norm": 0.23764224350452423,
      "learning_rate": 7.653783428598573e-06,
      "loss": 0.0561,
      "step": 14818
    },
    {
      "epoch": 0.2346374906977849,
      "grad_norm": 0.04005337134003639,
      "learning_rate": 7.653625093022152e-06,
      "loss": 0.0018,
      "step": 14819
    },
    {
      "epoch": 0.23465332425542695,
      "grad_norm": 0.08019082993268967,
      "learning_rate": 7.65346675744573e-06,
      "loss": 0.0014,
      "step": 14820
    },
    {
      "epoch": 0.23466915781306902,
      "grad_norm": 0.011295951902866364,
      "learning_rate": 7.65330842186931e-06,
      "loss": 0.0005,
      "step": 14821
    },
    {
      "epoch": 0.23468499137071108,
      "grad_norm": 0.5258419513702393,
      "learning_rate": 7.653150086292889e-06,
      "loss": 0.1315,
      "step": 14822
    },
    {
      "epoch": 0.23470082492835315,
      "grad_norm": 0.29911139607429504,
      "learning_rate": 7.652991750716468e-06,
      "loss": 0.0462,
      "step": 14823
    },
    {
      "epoch": 0.2347166584859952,
      "grad_norm": 0.03718782216310501,
      "learning_rate": 7.652833415140049e-06,
      "loss": 0.0018,
      "step": 14824
    },
    {
      "epoch": 0.23473249204363728,
      "grad_norm": 0.04887615516781807,
      "learning_rate": 7.652675079563628e-06,
      "loss": 0.0024,
      "step": 14825
    },
    {
      "epoch": 0.23474832560127934,
      "grad_norm": 0.7825295329093933,
      "learning_rate": 7.652516743987207e-06,
      "loss": 0.5639,
      "step": 14826
    },
    {
      "epoch": 0.23476415915892143,
      "grad_norm": 0.38285550475120544,
      "learning_rate": 7.652358408410786e-06,
      "loss": 0.218,
      "step": 14827
    },
    {
      "epoch": 0.2347799927165635,
      "grad_norm": 0.01131152268499136,
      "learning_rate": 7.652200072834365e-06,
      "loss": 0.0002,
      "step": 14828
    },
    {
      "epoch": 0.23479582627420556,
      "grad_norm": 0.009674571454524994,
      "learning_rate": 7.652041737257944e-06,
      "loss": 0.0004,
      "step": 14829
    },
    {
      "epoch": 0.23481165983184762,
      "grad_norm": 0.49238142371177673,
      "learning_rate": 7.651883401681525e-06,
      "loss": 0.0632,
      "step": 14830
    },
    {
      "epoch": 0.2348274933894897,
      "grad_norm": 0.014774071052670479,
      "learning_rate": 7.651725066105104e-06,
      "loss": 0.0006,
      "step": 14831
    },
    {
      "epoch": 0.23484332694713175,
      "grad_norm": 0.39599618315696716,
      "learning_rate": 7.651566730528683e-06,
      "loss": 0.2097,
      "step": 14832
    },
    {
      "epoch": 0.23485916050477382,
      "grad_norm": 0.7058604955673218,
      "learning_rate": 7.651408394952262e-06,
      "loss": 0.2151,
      "step": 14833
    },
    {
      "epoch": 0.23487499406241588,
      "grad_norm": 0.08016640692949295,
      "learning_rate": 7.651250059375841e-06,
      "loss": 0.004,
      "step": 14834
    },
    {
      "epoch": 0.23489082762005795,
      "grad_norm": 0.8424955010414124,
      "learning_rate": 7.65109172379942e-06,
      "loss": 0.4026,
      "step": 14835
    },
    {
      "epoch": 0.2349066611777,
      "grad_norm": 0.272159218788147,
      "learning_rate": 7.650933388223001e-06,
      "loss": 0.0986,
      "step": 14836
    },
    {
      "epoch": 0.23492249473534207,
      "grad_norm": 0.9455773830413818,
      "learning_rate": 7.65077505264658e-06,
      "loss": 0.1055,
      "step": 14837
    },
    {
      "epoch": 0.23493832829298414,
      "grad_norm": 0.018497010692954063,
      "learning_rate": 7.65061671707016e-06,
      "loss": 0.0009,
      "step": 14838
    },
    {
      "epoch": 0.23495416185062623,
      "grad_norm": 0.34597644209861755,
      "learning_rate": 7.650458381493738e-06,
      "loss": 0.1738,
      "step": 14839
    },
    {
      "epoch": 0.2349699954082683,
      "grad_norm": 0.42534059286117554,
      "learning_rate": 7.650300045917318e-06,
      "loss": 0.1212,
      "step": 14840
    },
    {
      "epoch": 0.23498582896591036,
      "grad_norm": 0.06366248428821564,
      "learning_rate": 7.650141710340897e-06,
      "loss": 0.0031,
      "step": 14841
    },
    {
      "epoch": 0.23500166252355242,
      "grad_norm": 0.1705692559480667,
      "learning_rate": 7.649983374764477e-06,
      "loss": 0.0448,
      "step": 14842
    },
    {
      "epoch": 0.2350174960811945,
      "grad_norm": 0.6027137637138367,
      "learning_rate": 7.649825039188056e-06,
      "loss": 0.1428,
      "step": 14843
    },
    {
      "epoch": 0.23503332963883655,
      "grad_norm": 0.4789884686470032,
      "learning_rate": 7.649666703611636e-06,
      "loss": 0.1257,
      "step": 14844
    },
    {
      "epoch": 0.23504916319647862,
      "grad_norm": 0.7541300654411316,
      "learning_rate": 7.649508368035215e-06,
      "loss": 0.6946,
      "step": 14845
    },
    {
      "epoch": 0.23506499675412068,
      "grad_norm": 1.4641231298446655,
      "learning_rate": 7.649350032458794e-06,
      "loss": 0.1337,
      "step": 14846
    },
    {
      "epoch": 0.23508083031176275,
      "grad_norm": 0.7079957127571106,
      "learning_rate": 7.649191696882373e-06,
      "loss": 0.0767,
      "step": 14847
    },
    {
      "epoch": 0.2350966638694048,
      "grad_norm": 0.44388023018836975,
      "learning_rate": 7.649033361305952e-06,
      "loss": 0.063,
      "step": 14848
    },
    {
      "epoch": 0.23511249742704687,
      "grad_norm": 0.5586547255516052,
      "learning_rate": 7.648875025729533e-06,
      "loss": 0.1966,
      "step": 14849
    },
    {
      "epoch": 0.23512833098468894,
      "grad_norm": 0.014199482277035713,
      "learning_rate": 7.64871669015311e-06,
      "loss": 0.0006,
      "step": 14850
    },
    {
      "epoch": 0.23514416454233103,
      "grad_norm": 0.33171990513801575,
      "learning_rate": 7.64855835457669e-06,
      "loss": 0.0741,
      "step": 14851
    },
    {
      "epoch": 0.2351599980999731,
      "grad_norm": 0.5437563061714172,
      "learning_rate": 7.64840001900027e-06,
      "loss": 0.2587,
      "step": 14852
    },
    {
      "epoch": 0.23517583165761516,
      "grad_norm": 0.5180178284645081,
      "learning_rate": 7.648241683423849e-06,
      "loss": 0.2917,
      "step": 14853
    },
    {
      "epoch": 0.23519166521525722,
      "grad_norm": 0.00023515890643466264,
      "learning_rate": 7.648083347847428e-06,
      "loss": 0.0,
      "step": 14854
    },
    {
      "epoch": 0.2352074987728993,
      "grad_norm": 0.19907261431217194,
      "learning_rate": 7.647925012271009e-06,
      "loss": 0.0687,
      "step": 14855
    },
    {
      "epoch": 0.23522333233054135,
      "grad_norm": 0.2617531716823578,
      "learning_rate": 7.647766676694586e-06,
      "loss": 0.1096,
      "step": 14856
    },
    {
      "epoch": 0.23523916588818342,
      "grad_norm": 0.4417995512485504,
      "learning_rate": 7.647608341118167e-06,
      "loss": 0.2377,
      "step": 14857
    },
    {
      "epoch": 0.23525499944582548,
      "grad_norm": 0.14423058927059174,
      "learning_rate": 7.647450005541746e-06,
      "loss": 0.0066,
      "step": 14858
    },
    {
      "epoch": 0.23527083300346754,
      "grad_norm": 0.21125437319278717,
      "learning_rate": 7.647291669965325e-06,
      "loss": 0.086,
      "step": 14859
    },
    {
      "epoch": 0.2352866665611096,
      "grad_norm": 0.39920344948768616,
      "learning_rate": 7.647133334388904e-06,
      "loss": 0.1758,
      "step": 14860
    },
    {
      "epoch": 0.23530250011875167,
      "grad_norm": 0.07272200286388397,
      "learning_rate": 7.646974998812485e-06,
      "loss": 0.0038,
      "step": 14861
    },
    {
      "epoch": 0.23531833367639374,
      "grad_norm": 0.4670185446739197,
      "learning_rate": 7.646816663236062e-06,
      "loss": 0.2976,
      "step": 14862
    },
    {
      "epoch": 0.23533416723403583,
      "grad_norm": 0.0011859770165756345,
      "learning_rate": 7.646658327659643e-06,
      "loss": 0.0,
      "step": 14863
    },
    {
      "epoch": 0.2353500007916779,
      "grad_norm": 0.01710362359881401,
      "learning_rate": 7.646499992083222e-06,
      "loss": 0.0009,
      "step": 14864
    },
    {
      "epoch": 0.23536583434931996,
      "grad_norm": 0.5052493810653687,
      "learning_rate": 7.646341656506801e-06,
      "loss": 0.3327,
      "step": 14865
    },
    {
      "epoch": 0.23538166790696202,
      "grad_norm": 0.2586020827293396,
      "learning_rate": 7.64618332093038e-06,
      "loss": 0.3153,
      "step": 14866
    },
    {
      "epoch": 0.2353975014646041,
      "grad_norm": 0.6878771781921387,
      "learning_rate": 7.646024985353961e-06,
      "loss": 0.3081,
      "step": 14867
    },
    {
      "epoch": 0.23541333502224615,
      "grad_norm": 0.10850781947374344,
      "learning_rate": 7.645866649777539e-06,
      "loss": 0.0151,
      "step": 14868
    },
    {
      "epoch": 0.23542916857988821,
      "grad_norm": 0.47588324546813965,
      "learning_rate": 7.645708314201118e-06,
      "loss": 0.1646,
      "step": 14869
    },
    {
      "epoch": 0.23544500213753028,
      "grad_norm": 0.9013087749481201,
      "learning_rate": 7.645549978624698e-06,
      "loss": 0.181,
      "step": 14870
    },
    {
      "epoch": 0.23546083569517234,
      "grad_norm": 0.3190428614616394,
      "learning_rate": 7.645391643048277e-06,
      "loss": 0.0474,
      "step": 14871
    },
    {
      "epoch": 0.2354766692528144,
      "grad_norm": 0.19158634543418884,
      "learning_rate": 7.645233307471857e-06,
      "loss": 0.0586,
      "step": 14872
    },
    {
      "epoch": 0.23549250281045647,
      "grad_norm": 0.5345546007156372,
      "learning_rate": 7.645074971895436e-06,
      "loss": 0.1633,
      "step": 14873
    },
    {
      "epoch": 0.23550833636809854,
      "grad_norm": 0.651124119758606,
      "learning_rate": 7.644916636319015e-06,
      "loss": 0.2451,
      "step": 14874
    },
    {
      "epoch": 0.23552416992574063,
      "grad_norm": 0.3467091917991638,
      "learning_rate": 7.644758300742594e-06,
      "loss": 0.098,
      "step": 14875
    },
    {
      "epoch": 0.2355400034833827,
      "grad_norm": 0.25433966517448425,
      "learning_rate": 7.644599965166175e-06,
      "loss": 0.0829,
      "step": 14876
    },
    {
      "epoch": 0.23555583704102476,
      "grad_norm": 0.0001495182077633217,
      "learning_rate": 7.644441629589754e-06,
      "loss": 0.0,
      "step": 14877
    },
    {
      "epoch": 0.23557167059866682,
      "grad_norm": 0.25648295879364014,
      "learning_rate": 7.644283294013333e-06,
      "loss": 0.0814,
      "step": 14878
    },
    {
      "epoch": 0.23558750415630889,
      "grad_norm": 0.0003488705842755735,
      "learning_rate": 7.644124958436912e-06,
      "loss": 0.0,
      "step": 14879
    },
    {
      "epoch": 0.23560333771395095,
      "grad_norm": 0.14115072786808014,
      "learning_rate": 7.643966622860491e-06,
      "loss": 0.0392,
      "step": 14880
    },
    {
      "epoch": 0.23561917127159301,
      "grad_norm": 0.5274280309677124,
      "learning_rate": 7.64380828728407e-06,
      "loss": 0.1199,
      "step": 14881
    },
    {
      "epoch": 0.23563500482923508,
      "grad_norm": 0.2967173457145691,
      "learning_rate": 7.64364995170765e-06,
      "loss": 0.2464,
      "step": 14882
    },
    {
      "epoch": 0.23565083838687714,
      "grad_norm": 0.07777619361877441,
      "learning_rate": 7.643491616131228e-06,
      "loss": 0.0065,
      "step": 14883
    },
    {
      "epoch": 0.2356666719445192,
      "grad_norm": 0.26893913745880127,
      "learning_rate": 7.643333280554809e-06,
      "loss": 0.1832,
      "step": 14884
    },
    {
      "epoch": 0.23568250550216127,
      "grad_norm": 0.39890778064727783,
      "learning_rate": 7.643174944978388e-06,
      "loss": 0.046,
      "step": 14885
    },
    {
      "epoch": 0.23569833905980334,
      "grad_norm": 0.2890327572822571,
      "learning_rate": 7.643016609401967e-06,
      "loss": 0.0892,
      "step": 14886
    },
    {
      "epoch": 0.2357141726174454,
      "grad_norm": 0.5271227359771729,
      "learning_rate": 7.642858273825546e-06,
      "loss": 0.2174,
      "step": 14887
    },
    {
      "epoch": 0.2357300061750875,
      "grad_norm": 0.3018483519554138,
      "learning_rate": 7.642699938249127e-06,
      "loss": 0.1054,
      "step": 14888
    },
    {
      "epoch": 0.23574583973272956,
      "grad_norm": 0.4390094578266144,
      "learning_rate": 7.642541602672704e-06,
      "loss": 0.0547,
      "step": 14889
    },
    {
      "epoch": 0.23576167329037162,
      "grad_norm": 0.21108843386173248,
      "learning_rate": 7.642383267096285e-06,
      "loss": 0.1449,
      "step": 14890
    },
    {
      "epoch": 0.23577750684801368,
      "grad_norm": 0.3850477635860443,
      "learning_rate": 7.642224931519864e-06,
      "loss": 0.1354,
      "step": 14891
    },
    {
      "epoch": 0.23579334040565575,
      "grad_norm": 0.27345046401023865,
      "learning_rate": 7.642066595943443e-06,
      "loss": 0.2426,
      "step": 14892
    },
    {
      "epoch": 0.2358091739632978,
      "grad_norm": 0.00021352760086301714,
      "learning_rate": 7.641908260367022e-06,
      "loss": 0.0,
      "step": 14893
    },
    {
      "epoch": 0.23582500752093988,
      "grad_norm": 0.38056835532188416,
      "learning_rate": 7.641749924790601e-06,
      "loss": 0.1265,
      "step": 14894
    },
    {
      "epoch": 0.23584084107858194,
      "grad_norm": 0.5131731033325195,
      "learning_rate": 7.64159158921418e-06,
      "loss": 0.1693,
      "step": 14895
    },
    {
      "epoch": 0.235856674636224,
      "grad_norm": 0.1825643628835678,
      "learning_rate": 7.64143325363776e-06,
      "loss": 0.0644,
      "step": 14896
    },
    {
      "epoch": 0.23587250819386607,
      "grad_norm": 0.48865339159965515,
      "learning_rate": 7.64127491806134e-06,
      "loss": 0.1128,
      "step": 14897
    },
    {
      "epoch": 0.23588834175150813,
      "grad_norm": 0.21974517405033112,
      "learning_rate": 7.64111658248492e-06,
      "loss": 0.0406,
      "step": 14898
    },
    {
      "epoch": 0.2359041753091502,
      "grad_norm": 0.36276355385780334,
      "learning_rate": 7.640958246908498e-06,
      "loss": 0.1072,
      "step": 14899
    },
    {
      "epoch": 0.2359200088667923,
      "grad_norm": 0.5306277871131897,
      "learning_rate": 7.640799911332078e-06,
      "loss": 0.2987,
      "step": 14900
    },
    {
      "epoch": 0.23593584242443436,
      "grad_norm": 0.4791640341281891,
      "learning_rate": 7.640641575755657e-06,
      "loss": 0.1319,
      "step": 14901
    },
    {
      "epoch": 0.23595167598207642,
      "grad_norm": 0.000214272178709507,
      "learning_rate": 7.640483240179236e-06,
      "loss": 0.0,
      "step": 14902
    },
    {
      "epoch": 0.23596750953971848,
      "grad_norm": 0.9363312721252441,
      "learning_rate": 7.640324904602816e-06,
      "loss": 1.0132,
      "step": 14903
    },
    {
      "epoch": 0.23598334309736055,
      "grad_norm": 0.5954725742340088,
      "learning_rate": 7.640166569026396e-06,
      "loss": 0.2401,
      "step": 14904
    },
    {
      "epoch": 0.2359991766550026,
      "grad_norm": 0.6152644157409668,
      "learning_rate": 7.640008233449975e-06,
      "loss": 0.2512,
      "step": 14905
    },
    {
      "epoch": 0.23601501021264468,
      "grad_norm": 0.824889600276947,
      "learning_rate": 7.639849897873554e-06,
      "loss": 0.3146,
      "step": 14906
    },
    {
      "epoch": 0.23603084377028674,
      "grad_norm": 0.2491340935230255,
      "learning_rate": 7.639691562297133e-06,
      "loss": 0.1187,
      "step": 14907
    },
    {
      "epoch": 0.2360466773279288,
      "grad_norm": 0.008073038421571255,
      "learning_rate": 7.639533226720712e-06,
      "loss": 0.0004,
      "step": 14908
    },
    {
      "epoch": 0.23606251088557087,
      "grad_norm": 0.5875640511512756,
      "learning_rate": 7.639374891144293e-06,
      "loss": 0.1401,
      "step": 14909
    },
    {
      "epoch": 0.23607834444321293,
      "grad_norm": 0.41921931505203247,
      "learning_rate": 7.639216555567872e-06,
      "loss": 0.1572,
      "step": 14910
    },
    {
      "epoch": 0.236094178000855,
      "grad_norm": 0.003792304079979658,
      "learning_rate": 7.63905821999145e-06,
      "loss": 0.0002,
      "step": 14911
    },
    {
      "epoch": 0.2361100115584971,
      "grad_norm": 0.02767808362841606,
      "learning_rate": 7.63889988441503e-06,
      "loss": 0.0017,
      "step": 14912
    },
    {
      "epoch": 0.23612584511613915,
      "grad_norm": 0.6327540278434753,
      "learning_rate": 7.638741548838609e-06,
      "loss": 0.2874,
      "step": 14913
    },
    {
      "epoch": 0.23614167867378122,
      "grad_norm": 0.40263551473617554,
      "learning_rate": 7.638583213262188e-06,
      "loss": 0.1715,
      "step": 14914
    },
    {
      "epoch": 0.23615751223142328,
      "grad_norm": 0.509336531162262,
      "learning_rate": 7.638424877685769e-06,
      "loss": 0.291,
      "step": 14915
    },
    {
      "epoch": 0.23617334578906535,
      "grad_norm": 1.1845072507858276,
      "learning_rate": 7.638266542109348e-06,
      "loss": 0.0643,
      "step": 14916
    },
    {
      "epoch": 0.2361891793467074,
      "grad_norm": 0.8712047338485718,
      "learning_rate": 7.638108206532927e-06,
      "loss": 0.2899,
      "step": 14917
    },
    {
      "epoch": 0.23620501290434948,
      "grad_norm": 0.37205660343170166,
      "learning_rate": 7.637949870956506e-06,
      "loss": 0.099,
      "step": 14918
    },
    {
      "epoch": 0.23622084646199154,
      "grad_norm": 0.32493358850479126,
      "learning_rate": 7.637791535380085e-06,
      "loss": 0.1785,
      "step": 14919
    },
    {
      "epoch": 0.2362366800196336,
      "grad_norm": 0.00018715228361543268,
      "learning_rate": 7.637633199803664e-06,
      "loss": 0.0,
      "step": 14920
    },
    {
      "epoch": 0.23625251357727567,
      "grad_norm": 0.6547236442565918,
      "learning_rate": 7.637474864227243e-06,
      "loss": 0.2485,
      "step": 14921
    },
    {
      "epoch": 0.23626834713491773,
      "grad_norm": 0.3396924138069153,
      "learning_rate": 7.637316528650824e-06,
      "loss": 0.138,
      "step": 14922
    },
    {
      "epoch": 0.2362841806925598,
      "grad_norm": 0.2516334652900696,
      "learning_rate": 7.637158193074401e-06,
      "loss": 0.0551,
      "step": 14923
    },
    {
      "epoch": 0.2363000142502019,
      "grad_norm": 0.19172684848308563,
      "learning_rate": 7.636999857497982e-06,
      "loss": 0.053,
      "step": 14924
    },
    {
      "epoch": 0.23631584780784395,
      "grad_norm": 0.1804322749376297,
      "learning_rate": 7.636841521921561e-06,
      "loss": 0.0495,
      "step": 14925
    },
    {
      "epoch": 0.23633168136548602,
      "grad_norm": 0.2640869617462158,
      "learning_rate": 7.63668318634514e-06,
      "loss": 0.0368,
      "step": 14926
    },
    {
      "epoch": 0.23634751492312808,
      "grad_norm": 0.19601081311702728,
      "learning_rate": 7.63652485076872e-06,
      "loss": 0.0426,
      "step": 14927
    },
    {
      "epoch": 0.23636334848077015,
      "grad_norm": 0.5364039540290833,
      "learning_rate": 7.6363665151923e-06,
      "loss": 0.3015,
      "step": 14928
    },
    {
      "epoch": 0.2363791820384122,
      "grad_norm": 0.2179647833108902,
      "learning_rate": 7.636208179615878e-06,
      "loss": 0.0316,
      "step": 14929
    },
    {
      "epoch": 0.23639501559605428,
      "grad_norm": 0.9938596487045288,
      "learning_rate": 7.636049844039458e-06,
      "loss": 0.543,
      "step": 14930
    },
    {
      "epoch": 0.23641084915369634,
      "grad_norm": 0.5079591274261475,
      "learning_rate": 7.635891508463037e-06,
      "loss": 0.0483,
      "step": 14931
    },
    {
      "epoch": 0.2364266827113384,
      "grad_norm": 0.8616175651550293,
      "learning_rate": 7.635733172886617e-06,
      "loss": 0.6161,
      "step": 14932
    },
    {
      "epoch": 0.23644251626898047,
      "grad_norm": 0.4770526587963104,
      "learning_rate": 7.635574837310196e-06,
      "loss": 0.2157,
      "step": 14933
    },
    {
      "epoch": 0.23645834982662253,
      "grad_norm": 0.020592816174030304,
      "learning_rate": 7.635416501733776e-06,
      "loss": 0.0011,
      "step": 14934
    },
    {
      "epoch": 0.2364741833842646,
      "grad_norm": 0.5583503842353821,
      "learning_rate": 7.635258166157354e-06,
      "loss": 0.1536,
      "step": 14935
    },
    {
      "epoch": 0.2364900169419067,
      "grad_norm": 0.7491409778594971,
      "learning_rate": 7.635099830580935e-06,
      "loss": 0.0803,
      "step": 14936
    },
    {
      "epoch": 0.23650585049954875,
      "grad_norm": 0.017983123660087585,
      "learning_rate": 7.634941495004514e-06,
      "loss": 0.001,
      "step": 14937
    },
    {
      "epoch": 0.23652168405719082,
      "grad_norm": 0.12406840920448303,
      "learning_rate": 7.634783159428093e-06,
      "loss": 0.0168,
      "step": 14938
    },
    {
      "epoch": 0.23653751761483288,
      "grad_norm": 0.4520580470561981,
      "learning_rate": 7.634624823851672e-06,
      "loss": 0.1727,
      "step": 14939
    },
    {
      "epoch": 0.23655335117247495,
      "grad_norm": 0.5923671126365662,
      "learning_rate": 7.634466488275251e-06,
      "loss": 0.8541,
      "step": 14940
    },
    {
      "epoch": 0.236569184730117,
      "grad_norm": 0.3690161406993866,
      "learning_rate": 7.63430815269883e-06,
      "loss": 0.0528,
      "step": 14941
    },
    {
      "epoch": 0.23658501828775907,
      "grad_norm": 0.5463107824325562,
      "learning_rate": 7.634149817122409e-06,
      "loss": 0.1144,
      "step": 14942
    },
    {
      "epoch": 0.23660085184540114,
      "grad_norm": 0.08277807384729385,
      "learning_rate": 7.63399148154599e-06,
      "loss": 0.004,
      "step": 14943
    },
    {
      "epoch": 0.2366166854030432,
      "grad_norm": 0.0003085887001361698,
      "learning_rate": 7.633833145969567e-06,
      "loss": 0.0,
      "step": 14944
    },
    {
      "epoch": 0.23663251896068527,
      "grad_norm": 0.5407462120056152,
      "learning_rate": 7.633674810393148e-06,
      "loss": 0.4371,
      "step": 14945
    },
    {
      "epoch": 0.23664835251832733,
      "grad_norm": 0.2597649395465851,
      "learning_rate": 7.633516474816727e-06,
      "loss": 0.0434,
      "step": 14946
    },
    {
      "epoch": 0.2366641860759694,
      "grad_norm": 0.23946300148963928,
      "learning_rate": 7.633358139240306e-06,
      "loss": 0.0627,
      "step": 14947
    },
    {
      "epoch": 0.2366800196336115,
      "grad_norm": 0.42517200112342834,
      "learning_rate": 7.633199803663885e-06,
      "loss": 0.2587,
      "step": 14948
    },
    {
      "epoch": 0.23669585319125355,
      "grad_norm": 0.6572248935699463,
      "learning_rate": 7.633041468087466e-06,
      "loss": 0.2073,
      "step": 14949
    },
    {
      "epoch": 0.23671168674889562,
      "grad_norm": 0.00034592641168273985,
      "learning_rate": 7.632883132511043e-06,
      "loss": 0.0,
      "step": 14950
    },
    {
      "epoch": 0.23672752030653768,
      "grad_norm": 0.00011990965867880732,
      "learning_rate": 7.632724796934624e-06,
      "loss": 0.0,
      "step": 14951
    },
    {
      "epoch": 0.23674335386417975,
      "grad_norm": 0.8205925822257996,
      "learning_rate": 7.632566461358203e-06,
      "loss": 0.297,
      "step": 14952
    },
    {
      "epoch": 0.2367591874218218,
      "grad_norm": 0.00027421244885772467,
      "learning_rate": 7.632408125781782e-06,
      "loss": 0.0,
      "step": 14953
    },
    {
      "epoch": 0.23677502097946387,
      "grad_norm": 0.29992249608039856,
      "learning_rate": 7.632249790205361e-06,
      "loss": 0.0704,
      "step": 14954
    },
    {
      "epoch": 0.23679085453710594,
      "grad_norm": 0.17923115193843842,
      "learning_rate": 7.632091454628942e-06,
      "loss": 0.0725,
      "step": 14955
    },
    {
      "epoch": 0.236806688094748,
      "grad_norm": 0.27647125720977783,
      "learning_rate": 7.63193311905252e-06,
      "loss": 0.0346,
      "step": 14956
    },
    {
      "epoch": 0.23682252165239007,
      "grad_norm": 0.3356893062591553,
      "learning_rate": 7.6317747834761e-06,
      "loss": 0.0976,
      "step": 14957
    },
    {
      "epoch": 0.23683835521003213,
      "grad_norm": 0.3450234532356262,
      "learning_rate": 7.63161644789968e-06,
      "loss": 0.0499,
      "step": 14958
    },
    {
      "epoch": 0.2368541887676742,
      "grad_norm": 0.24797523021697998,
      "learning_rate": 7.631458112323258e-06,
      "loss": 0.0845,
      "step": 14959
    },
    {
      "epoch": 0.2368700223253163,
      "grad_norm": 0.024495957419276237,
      "learning_rate": 7.631299776746838e-06,
      "loss": 0.0011,
      "step": 14960
    },
    {
      "epoch": 0.23688585588295835,
      "grad_norm": 0.0278518944978714,
      "learning_rate": 7.631141441170418e-06,
      "loss": 0.0015,
      "step": 14961
    },
    {
      "epoch": 0.23690168944060042,
      "grad_norm": 0.004046326968818903,
      "learning_rate": 7.630983105593996e-06,
      "loss": 0.0002,
      "step": 14962
    },
    {
      "epoch": 0.23691752299824248,
      "grad_norm": 0.2461753487586975,
      "learning_rate": 7.630824770017576e-06,
      "loss": 0.0586,
      "step": 14963
    },
    {
      "epoch": 0.23693335655588454,
      "grad_norm": 0.6904903650283813,
      "learning_rate": 7.630666434441156e-06,
      "loss": 0.2255,
      "step": 14964
    },
    {
      "epoch": 0.2369491901135266,
      "grad_norm": 0.4763649106025696,
      "learning_rate": 7.630508098864735e-06,
      "loss": 0.087,
      "step": 14965
    },
    {
      "epoch": 0.23696502367116867,
      "grad_norm": 0.42173659801483154,
      "learning_rate": 7.630349763288314e-06,
      "loss": 0.2162,
      "step": 14966
    },
    {
      "epoch": 0.23698085722881074,
      "grad_norm": 0.35368409752845764,
      "learning_rate": 7.630191427711893e-06,
      "loss": 0.0568,
      "step": 14967
    },
    {
      "epoch": 0.2369966907864528,
      "grad_norm": 0.2993220090866089,
      "learning_rate": 7.630033092135472e-06,
      "loss": 0.0224,
      "step": 14968
    },
    {
      "epoch": 0.23701252434409487,
      "grad_norm": 0.5599980354309082,
      "learning_rate": 7.629874756559051e-06,
      "loss": 0.1956,
      "step": 14969
    },
    {
      "epoch": 0.23702835790173693,
      "grad_norm": 1.017062783241272,
      "learning_rate": 7.629716420982632e-06,
      "loss": 0.5038,
      "step": 14970
    },
    {
      "epoch": 0.237044191459379,
      "grad_norm": 0.004147141240537167,
      "learning_rate": 7.62955808540621e-06,
      "loss": 0.0002,
      "step": 14971
    },
    {
      "epoch": 0.2370600250170211,
      "grad_norm": 0.46107739210128784,
      "learning_rate": 7.62939974982979e-06,
      "loss": 0.4797,
      "step": 14972
    },
    {
      "epoch": 0.23707585857466315,
      "grad_norm": 0.25852859020233154,
      "learning_rate": 7.629241414253369e-06,
      "loss": 0.0522,
      "step": 14973
    },
    {
      "epoch": 0.23709169213230522,
      "grad_norm": 0.3459739685058594,
      "learning_rate": 7.629083078676949e-06,
      "loss": 0.0999,
      "step": 14974
    },
    {
      "epoch": 0.23710752568994728,
      "grad_norm": 8.658489969093353e-05,
      "learning_rate": 7.628924743100527e-06,
      "loss": 0.0,
      "step": 14975
    },
    {
      "epoch": 0.23712335924758934,
      "grad_norm": 0.24405105412006378,
      "learning_rate": 7.628766407524107e-06,
      "loss": 0.0846,
      "step": 14976
    },
    {
      "epoch": 0.2371391928052314,
      "grad_norm": 0.7679468393325806,
      "learning_rate": 7.628608071947686e-06,
      "loss": 0.3689,
      "step": 14977
    },
    {
      "epoch": 0.23715502636287347,
      "grad_norm": 0.6232654452323914,
      "learning_rate": 7.628449736371266e-06,
      "loss": 0.1354,
      "step": 14978
    },
    {
      "epoch": 0.23717085992051554,
      "grad_norm": 0.2975888252258301,
      "learning_rate": 7.628291400794845e-06,
      "loss": 0.062,
      "step": 14979
    },
    {
      "epoch": 0.2371866934781576,
      "grad_norm": 0.6199013590812683,
      "learning_rate": 7.628133065218425e-06,
      "loss": 0.1734,
      "step": 14980
    },
    {
      "epoch": 0.23720252703579967,
      "grad_norm": 0.0023645227774977684,
      "learning_rate": 7.627974729642003e-06,
      "loss": 0.0001,
      "step": 14981
    },
    {
      "epoch": 0.23721836059344173,
      "grad_norm": 1.259063720703125,
      "learning_rate": 7.627816394065583e-06,
      "loss": 0.2039,
      "step": 14982
    },
    {
      "epoch": 0.2372341941510838,
      "grad_norm": 0.29827624559402466,
      "learning_rate": 7.627658058489162e-06,
      "loss": 0.0932,
      "step": 14983
    },
    {
      "epoch": 0.23725002770872589,
      "grad_norm": 0.3493012487888336,
      "learning_rate": 7.627499722912742e-06,
      "loss": 0.1181,
      "step": 14984
    },
    {
      "epoch": 0.23726586126636795,
      "grad_norm": 0.46153512597084045,
      "learning_rate": 7.627341387336321e-06,
      "loss": 0.0987,
      "step": 14985
    },
    {
      "epoch": 0.23728169482401001,
      "grad_norm": 0.3761683404445648,
      "learning_rate": 7.627183051759901e-06,
      "loss": 0.0101,
      "step": 14986
    },
    {
      "epoch": 0.23729752838165208,
      "grad_norm": 0.38536444306373596,
      "learning_rate": 7.6270247161834795e-06,
      "loss": 0.1055,
      "step": 14987
    },
    {
      "epoch": 0.23731336193929414,
      "grad_norm": 0.0008378494530916214,
      "learning_rate": 7.626866380607059e-06,
      "loss": 0.0,
      "step": 14988
    },
    {
      "epoch": 0.2373291954969362,
      "grad_norm": 0.2521205544471741,
      "learning_rate": 7.6267080450306385e-06,
      "loss": 0.0422,
      "step": 14989
    },
    {
      "epoch": 0.23734502905457827,
      "grad_norm": 0.03549666702747345,
      "learning_rate": 7.6265497094542176e-06,
      "loss": 0.002,
      "step": 14990
    },
    {
      "epoch": 0.23736086261222034,
      "grad_norm": 0.010784861631691456,
      "learning_rate": 7.6263913738777975e-06,
      "loss": 0.0004,
      "step": 14991
    },
    {
      "epoch": 0.2373766961698624,
      "grad_norm": 0.39756739139556885,
      "learning_rate": 7.626233038301376e-06,
      "loss": 0.0872,
      "step": 14992
    },
    {
      "epoch": 0.23739252972750446,
      "grad_norm": 0.47415485978126526,
      "learning_rate": 7.626074702724956e-06,
      "loss": 0.1878,
      "step": 14993
    },
    {
      "epoch": 0.23740836328514653,
      "grad_norm": 0.24043594300746918,
      "learning_rate": 7.625916367148535e-06,
      "loss": 0.0656,
      "step": 14994
    },
    {
      "epoch": 0.2374241968427886,
      "grad_norm": 0.18720102310180664,
      "learning_rate": 7.625758031572115e-06,
      "loss": 0.0459,
      "step": 14995
    },
    {
      "epoch": 0.23744003040043068,
      "grad_norm": 0.004788383841514587,
      "learning_rate": 7.625599695995694e-06,
      "loss": 0.0002,
      "step": 14996
    },
    {
      "epoch": 0.23745586395807275,
      "grad_norm": 0.750827968120575,
      "learning_rate": 7.625441360419274e-06,
      "loss": 0.0318,
      "step": 14997
    },
    {
      "epoch": 0.2374716975157148,
      "grad_norm": 0.4505389630794525,
      "learning_rate": 7.625283024842852e-06,
      "loss": 0.3097,
      "step": 14998
    },
    {
      "epoch": 0.23748753107335688,
      "grad_norm": 0.824661910533905,
      "learning_rate": 7.625124689266432e-06,
      "loss": 0.0348,
      "step": 14999
    },
    {
      "epoch": 0.23750336463099894,
      "grad_norm": 0.012213042937219143,
      "learning_rate": 7.624966353690011e-06,
      "loss": 0.0003,
      "step": 15000
    },
    {
      "epoch": 0.237519198188641,
      "grad_norm": 0.12622833251953125,
      "learning_rate": 7.624808018113591e-06,
      "loss": 0.0212,
      "step": 15001
    },
    {
      "epoch": 0.23753503174628307,
      "grad_norm": 0.2894973158836365,
      "learning_rate": 7.62464968253717e-06,
      "loss": 0.135,
      "step": 15002
    },
    {
      "epoch": 0.23755086530392513,
      "grad_norm": 0.03023579716682434,
      "learning_rate": 7.62449134696075e-06,
      "loss": 0.0016,
      "step": 15003
    },
    {
      "epoch": 0.2375666988615672,
      "grad_norm": 0.43144771456718445,
      "learning_rate": 7.624333011384328e-06,
      "loss": 0.1836,
      "step": 15004
    },
    {
      "epoch": 0.23758253241920926,
      "grad_norm": 0.2091178447008133,
      "learning_rate": 7.624174675807908e-06,
      "loss": 0.0654,
      "step": 15005
    },
    {
      "epoch": 0.23759836597685133,
      "grad_norm": 0.29544195532798767,
      "learning_rate": 7.624016340231487e-06,
      "loss": 0.0732,
      "step": 15006
    },
    {
      "epoch": 0.2376141995344934,
      "grad_norm": 0.043580640107393265,
      "learning_rate": 7.623858004655067e-06,
      "loss": 0.002,
      "step": 15007
    },
    {
      "epoch": 0.23763003309213548,
      "grad_norm": 0.4161812663078308,
      "learning_rate": 7.623699669078646e-06,
      "loss": 0.0692,
      "step": 15008
    },
    {
      "epoch": 0.23764586664977755,
      "grad_norm": 0.00017246023344341666,
      "learning_rate": 7.623541333502226e-06,
      "loss": 0.0,
      "step": 15009
    },
    {
      "epoch": 0.2376617002074196,
      "grad_norm": 0.7700463533401489,
      "learning_rate": 7.623382997925804e-06,
      "loss": 0.1064,
      "step": 15010
    },
    {
      "epoch": 0.23767753376506168,
      "grad_norm": 0.29040685296058655,
      "learning_rate": 7.623224662349384e-06,
      "loss": 0.0477,
      "step": 15011
    },
    {
      "epoch": 0.23769336732270374,
      "grad_norm": 0.47278130054473877,
      "learning_rate": 7.623066326772963e-06,
      "loss": 0.1725,
      "step": 15012
    },
    {
      "epoch": 0.2377092008803458,
      "grad_norm": 0.597825288772583,
      "learning_rate": 7.622907991196543e-06,
      "loss": 0.4973,
      "step": 15013
    },
    {
      "epoch": 0.23772503443798787,
      "grad_norm": 0.03613175451755524,
      "learning_rate": 7.622749655620122e-06,
      "loss": 0.0013,
      "step": 15014
    },
    {
      "epoch": 0.23774086799562993,
      "grad_norm": 0.045667048543691635,
      "learning_rate": 7.6225913200437005e-06,
      "loss": 0.0018,
      "step": 15015
    },
    {
      "epoch": 0.237756701553272,
      "grad_norm": 0.705244243144989,
      "learning_rate": 7.62243298446728e-06,
      "loss": 0.1853,
      "step": 15016
    },
    {
      "epoch": 0.23777253511091406,
      "grad_norm": 0.4058983027935028,
      "learning_rate": 7.6222746488908595e-06,
      "loss": 0.0965,
      "step": 15017
    },
    {
      "epoch": 0.23778836866855613,
      "grad_norm": 0.013365481048822403,
      "learning_rate": 7.622116313314439e-06,
      "loss": 0.0007,
      "step": 15018
    },
    {
      "epoch": 0.2378042022261982,
      "grad_norm": 0.0006585289374925196,
      "learning_rate": 7.6219579777380185e-06,
      "loss": 0.0,
      "step": 15019
    },
    {
      "epoch": 0.23782003578384028,
      "grad_norm": 0.00011163535236846656,
      "learning_rate": 7.621799642161598e-06,
      "loss": 0.0,
      "step": 15020
    },
    {
      "epoch": 0.23783586934148235,
      "grad_norm": 0.4142811596393585,
      "learning_rate": 7.621641306585177e-06,
      "loss": 0.2584,
      "step": 15021
    },
    {
      "epoch": 0.2378517028991244,
      "grad_norm": 0.5569613575935364,
      "learning_rate": 7.621482971008757e-06,
      "loss": 0.5248,
      "step": 15022
    },
    {
      "epoch": 0.23786753645676648,
      "grad_norm": 0.0007713030208833516,
      "learning_rate": 7.621324635432336e-06,
      "loss": 0.0,
      "step": 15023
    },
    {
      "epoch": 0.23788337001440854,
      "grad_norm": 1.0160574913024902,
      "learning_rate": 7.621166299855916e-06,
      "loss": 0.7507,
      "step": 15024
    },
    {
      "epoch": 0.2378992035720506,
      "grad_norm": 0.37000080943107605,
      "learning_rate": 7.621007964279495e-06,
      "loss": 0.0858,
      "step": 15025
    },
    {
      "epoch": 0.23791503712969267,
      "grad_norm": 0.6697618365287781,
      "learning_rate": 7.620849628703075e-06,
      "loss": 0.2779,
      "step": 15026
    },
    {
      "epoch": 0.23793087068733473,
      "grad_norm": 0.2536669969558716,
      "learning_rate": 7.620691293126653e-06,
      "loss": 0.0944,
      "step": 15027
    },
    {
      "epoch": 0.2379467042449768,
      "grad_norm": 0.004311226774007082,
      "learning_rate": 7.620532957550233e-06,
      "loss": 0.0001,
      "step": 15028
    },
    {
      "epoch": 0.23796253780261886,
      "grad_norm": 0.23851700127124786,
      "learning_rate": 7.620374621973812e-06,
      "loss": 0.0271,
      "step": 15029
    },
    {
      "epoch": 0.23797837136026093,
      "grad_norm": 0.5242841243743896,
      "learning_rate": 7.620216286397392e-06,
      "loss": 0.3403,
      "step": 15030
    },
    {
      "epoch": 0.237994204917903,
      "grad_norm": 0.03753887116909027,
      "learning_rate": 7.620057950820971e-06,
      "loss": 0.0019,
      "step": 15031
    },
    {
      "epoch": 0.23801003847554508,
      "grad_norm": 1.018268346786499,
      "learning_rate": 7.619899615244551e-06,
      "loss": 0.5259,
      "step": 15032
    },
    {
      "epoch": 0.23802587203318715,
      "grad_norm": 0.23335561156272888,
      "learning_rate": 7.619741279668129e-06,
      "loss": 0.0307,
      "step": 15033
    },
    {
      "epoch": 0.2380417055908292,
      "grad_norm": 0.5637486577033997,
      "learning_rate": 7.619582944091709e-06,
      "loss": 0.0449,
      "step": 15034
    },
    {
      "epoch": 0.23805753914847128,
      "grad_norm": 0.3043690621852875,
      "learning_rate": 7.619424608515288e-06,
      "loss": 0.1149,
      "step": 15035
    },
    {
      "epoch": 0.23807337270611334,
      "grad_norm": 0.0014563925797119737,
      "learning_rate": 7.619266272938868e-06,
      "loss": 0.0,
      "step": 15036
    },
    {
      "epoch": 0.2380892062637554,
      "grad_norm": 0.3643043339252472,
      "learning_rate": 7.619107937362446e-06,
      "loss": 0.116,
      "step": 15037
    },
    {
      "epoch": 0.23810503982139747,
      "grad_norm": 0.0004854444705415517,
      "learning_rate": 7.618949601786025e-06,
      "loss": 0.0,
      "step": 15038
    },
    {
      "epoch": 0.23812087337903953,
      "grad_norm": 0.4684732258319855,
      "learning_rate": 7.618791266209605e-06,
      "loss": 0.1789,
      "step": 15039
    },
    {
      "epoch": 0.2381367069366816,
      "grad_norm": 0.5847116708755493,
      "learning_rate": 7.618632930633184e-06,
      "loss": 0.6533,
      "step": 15040
    },
    {
      "epoch": 0.23815254049432366,
      "grad_norm": 0.33781012892723083,
      "learning_rate": 7.618474595056764e-06,
      "loss": 0.0332,
      "step": 15041
    },
    {
      "epoch": 0.23816837405196573,
      "grad_norm": 0.20418281853199005,
      "learning_rate": 7.618316259480342e-06,
      "loss": 0.0522,
      "step": 15042
    },
    {
      "epoch": 0.2381842076096078,
      "grad_norm": 0.4623382091522217,
      "learning_rate": 7.618157923903922e-06,
      "loss": 0.0979,
      "step": 15043
    },
    {
      "epoch": 0.23820004116724988,
      "grad_norm": 0.4271157681941986,
      "learning_rate": 7.617999588327501e-06,
      "loss": 0.1256,
      "step": 15044
    },
    {
      "epoch": 0.23821587472489195,
      "grad_norm": 0.632757306098938,
      "learning_rate": 7.617841252751081e-06,
      "loss": 0.1872,
      "step": 15045
    },
    {
      "epoch": 0.238231708282534,
      "grad_norm": 0.28046438097953796,
      "learning_rate": 7.61768291717466e-06,
      "loss": 0.0434,
      "step": 15046
    },
    {
      "epoch": 0.23824754184017607,
      "grad_norm": 0.237940713763237,
      "learning_rate": 7.61752458159824e-06,
      "loss": 0.0659,
      "step": 15047
    },
    {
      "epoch": 0.23826337539781814,
      "grad_norm": 0.3021259605884552,
      "learning_rate": 7.617366246021819e-06,
      "loss": 0.0324,
      "step": 15048
    },
    {
      "epoch": 0.2382792089554602,
      "grad_norm": 0.0028521225322037935,
      "learning_rate": 7.6172079104453985e-06,
      "loss": 0.0001,
      "step": 15049
    },
    {
      "epoch": 0.23829504251310227,
      "grad_norm": 0.6525731682777405,
      "learning_rate": 7.617049574868978e-06,
      "loss": 0.1236,
      "step": 15050
    },
    {
      "epoch": 0.23831087607074433,
      "grad_norm": 0.0006287905271165073,
      "learning_rate": 7.6168912392925575e-06,
      "loss": 0.0,
      "step": 15051
    },
    {
      "epoch": 0.2383267096283864,
      "grad_norm": 0.002210797742009163,
      "learning_rate": 7.616732903716137e-06,
      "loss": 0.0001,
      "step": 15052
    },
    {
      "epoch": 0.23834254318602846,
      "grad_norm": 0.5918998122215271,
      "learning_rate": 7.6165745681397165e-06,
      "loss": 0.1102,
      "step": 15053
    },
    {
      "epoch": 0.23835837674367052,
      "grad_norm": 0.010945834219455719,
      "learning_rate": 7.616416232563295e-06,
      "loss": 0.0005,
      "step": 15054
    },
    {
      "epoch": 0.2383742103013126,
      "grad_norm": 0.9351900815963745,
      "learning_rate": 7.616257896986875e-06,
      "loss": 0.4198,
      "step": 15055
    },
    {
      "epoch": 0.23839004385895468,
      "grad_norm": 0.2793528139591217,
      "learning_rate": 7.616099561410454e-06,
      "loss": 0.0588,
      "step": 15056
    },
    {
      "epoch": 0.23840587741659675,
      "grad_norm": 0.5541427135467529,
      "learning_rate": 7.615941225834034e-06,
      "loss": 0.3812,
      "step": 15057
    },
    {
      "epoch": 0.2384217109742388,
      "grad_norm": 0.4802219271659851,
      "learning_rate": 7.615782890257613e-06,
      "loss": 0.2461,
      "step": 15058
    },
    {
      "epoch": 0.23843754453188087,
      "grad_norm": 0.442378431558609,
      "learning_rate": 7.615624554681193e-06,
      "loss": 0.0555,
      "step": 15059
    },
    {
      "epoch": 0.23845337808952294,
      "grad_norm": 0.23161566257476807,
      "learning_rate": 7.615466219104771e-06,
      "loss": 0.0333,
      "step": 15060
    },
    {
      "epoch": 0.238469211647165,
      "grad_norm": 0.22810114920139313,
      "learning_rate": 7.615307883528351e-06,
      "loss": 0.0432,
      "step": 15061
    },
    {
      "epoch": 0.23848504520480707,
      "grad_norm": 0.29735881090164185,
      "learning_rate": 7.61514954795193e-06,
      "loss": 0.0501,
      "step": 15062
    },
    {
      "epoch": 0.23850087876244913,
      "grad_norm": 0.3879055976867676,
      "learning_rate": 7.614991212375509e-06,
      "loss": 0.0788,
      "step": 15063
    },
    {
      "epoch": 0.2385167123200912,
      "grad_norm": 0.29082927107810974,
      "learning_rate": 7.614832876799089e-06,
      "loss": 0.029,
      "step": 15064
    },
    {
      "epoch": 0.23853254587773326,
      "grad_norm": 0.02544558234512806,
      "learning_rate": 7.614674541222667e-06,
      "loss": 0.0003,
      "step": 15065
    },
    {
      "epoch": 0.23854837943537532,
      "grad_norm": 0.35235172510147095,
      "learning_rate": 7.614516205646247e-06,
      "loss": 0.1006,
      "step": 15066
    },
    {
      "epoch": 0.2385642129930174,
      "grad_norm": 0.2495570033788681,
      "learning_rate": 7.614357870069826e-06,
      "loss": 0.0751,
      "step": 15067
    },
    {
      "epoch": 0.23858004655065948,
      "grad_norm": 0.8793739676475525,
      "learning_rate": 7.614199534493406e-06,
      "loss": 0.2293,
      "step": 15068
    },
    {
      "epoch": 0.23859588010830154,
      "grad_norm": 0.3776327073574066,
      "learning_rate": 7.614041198916985e-06,
      "loss": 0.0767,
      "step": 15069
    },
    {
      "epoch": 0.2386117136659436,
      "grad_norm": 0.31700411438941956,
      "learning_rate": 7.613882863340565e-06,
      "loss": 0.0262,
      "step": 15070
    },
    {
      "epoch": 0.23862754722358567,
      "grad_norm": 0.03605513274669647,
      "learning_rate": 7.613724527764143e-06,
      "loss": 0.0019,
      "step": 15071
    },
    {
      "epoch": 0.23864338078122774,
      "grad_norm": 0.4542064964771271,
      "learning_rate": 7.613566192187723e-06,
      "loss": 0.2246,
      "step": 15072
    },
    {
      "epoch": 0.2386592143388698,
      "grad_norm": 0.02944071590900421,
      "learning_rate": 7.613407856611302e-06,
      "loss": 0.0014,
      "step": 15073
    },
    {
      "epoch": 0.23867504789651187,
      "grad_norm": 0.6478143930435181,
      "learning_rate": 7.613249521034882e-06,
      "loss": 0.0777,
      "step": 15074
    },
    {
      "epoch": 0.23869088145415393,
      "grad_norm": 0.07188373059034348,
      "learning_rate": 7.613091185458461e-06,
      "loss": 0.0022,
      "step": 15075
    },
    {
      "epoch": 0.238706715011796,
      "grad_norm": 0.7278759479522705,
      "learning_rate": 7.612932849882041e-06,
      "loss": 0.2878,
      "step": 15076
    },
    {
      "epoch": 0.23872254856943806,
      "grad_norm": 0.6280562281608582,
      "learning_rate": 7.6127745143056195e-06,
      "loss": 0.8737,
      "step": 15077
    },
    {
      "epoch": 0.23873838212708012,
      "grad_norm": 0.05388825014233589,
      "learning_rate": 7.6126161787291994e-06,
      "loss": 0.0023,
      "step": 15078
    },
    {
      "epoch": 0.2387542156847222,
      "grad_norm": 0.03295883163809776,
      "learning_rate": 7.6124578431527785e-06,
      "loss": 0.0016,
      "step": 15079
    },
    {
      "epoch": 0.23877004924236428,
      "grad_norm": 0.8267542123794556,
      "learning_rate": 7.6122995075763584e-06,
      "loss": 0.0423,
      "step": 15080
    },
    {
      "epoch": 0.23878588280000634,
      "grad_norm": 0.4519886374473572,
      "learning_rate": 7.6121411719999375e-06,
      "loss": 0.2175,
      "step": 15081
    },
    {
      "epoch": 0.2388017163576484,
      "grad_norm": 7.291866495506838e-05,
      "learning_rate": 7.6119828364235174e-06,
      "loss": 0.0,
      "step": 15082
    },
    {
      "epoch": 0.23881754991529047,
      "grad_norm": 0.342965692281723,
      "learning_rate": 7.611824500847096e-06,
      "loss": 0.1191,
      "step": 15083
    },
    {
      "epoch": 0.23883338347293254,
      "grad_norm": 0.22537340223789215,
      "learning_rate": 7.611666165270676e-06,
      "loss": 0.0189,
      "step": 15084
    },
    {
      "epoch": 0.2388492170305746,
      "grad_norm": 0.46273213624954224,
      "learning_rate": 7.611507829694255e-06,
      "loss": 0.1258,
      "step": 15085
    },
    {
      "epoch": 0.23886505058821667,
      "grad_norm": 0.29864031076431274,
      "learning_rate": 7.611349494117834e-06,
      "loss": 0.0212,
      "step": 15086
    },
    {
      "epoch": 0.23888088414585873,
      "grad_norm": 0.6133700013160706,
      "learning_rate": 7.611191158541414e-06,
      "loss": 0.2333,
      "step": 15087
    },
    {
      "epoch": 0.2388967177035008,
      "grad_norm": 7.970233127707615e-05,
      "learning_rate": 7.611032822964992e-06,
      "loss": 0.0,
      "step": 15088
    },
    {
      "epoch": 0.23891255126114286,
      "grad_norm": 0.35099300742149353,
      "learning_rate": 7.610874487388572e-06,
      "loss": 0.1207,
      "step": 15089
    },
    {
      "epoch": 0.23892838481878492,
      "grad_norm": 0.17383864521980286,
      "learning_rate": 7.610716151812151e-06,
      "loss": 0.0694,
      "step": 15090
    },
    {
      "epoch": 0.238944218376427,
      "grad_norm": 0.1781795620918274,
      "learning_rate": 7.610557816235731e-06,
      "loss": 0.0513,
      "step": 15091
    },
    {
      "epoch": 0.23896005193406908,
      "grad_norm": 0.24330966174602509,
      "learning_rate": 7.61039948065931e-06,
      "loss": 0.0306,
      "step": 15092
    },
    {
      "epoch": 0.23897588549171114,
      "grad_norm": 0.5106979012489319,
      "learning_rate": 7.61024114508289e-06,
      "loss": 0.1802,
      "step": 15093
    },
    {
      "epoch": 0.2389917190493532,
      "grad_norm": 1.0931906700134277,
      "learning_rate": 7.610082809506468e-06,
      "loss": 0.6656,
      "step": 15094
    },
    {
      "epoch": 0.23900755260699527,
      "grad_norm": 0.6731064915657043,
      "learning_rate": 7.609924473930048e-06,
      "loss": 0.1587,
      "step": 15095
    },
    {
      "epoch": 0.23902338616463734,
      "grad_norm": 1.4008244276046753,
      "learning_rate": 7.609766138353627e-06,
      "loss": 0.2172,
      "step": 15096
    },
    {
      "epoch": 0.2390392197222794,
      "grad_norm": 0.2836298942565918,
      "learning_rate": 7.609607802777207e-06,
      "loss": 0.1356,
      "step": 15097
    },
    {
      "epoch": 0.23905505327992146,
      "grad_norm": 0.31056612730026245,
      "learning_rate": 7.609449467200786e-06,
      "loss": 0.0992,
      "step": 15098
    },
    {
      "epoch": 0.23907088683756353,
      "grad_norm": 0.576972484588623,
      "learning_rate": 7.609291131624365e-06,
      "loss": 0.6535,
      "step": 15099
    },
    {
      "epoch": 0.2390867203952056,
      "grad_norm": 0.6199889183044434,
      "learning_rate": 7.609132796047944e-06,
      "loss": 0.2972,
      "step": 15100
    },
    {
      "epoch": 0.23910255395284766,
      "grad_norm": 0.2223205268383026,
      "learning_rate": 7.608974460471524e-06,
      "loss": 0.0584,
      "step": 15101
    },
    {
      "epoch": 0.23911838751048972,
      "grad_norm": 0.9735410213470459,
      "learning_rate": 7.608816124895103e-06,
      "loss": 0.2289,
      "step": 15102
    },
    {
      "epoch": 0.23913422106813179,
      "grad_norm": 0.22306545078754425,
      "learning_rate": 7.608657789318683e-06,
      "loss": 0.0492,
      "step": 15103
    },
    {
      "epoch": 0.23915005462577388,
      "grad_norm": 0.2657468318939209,
      "learning_rate": 7.6084994537422614e-06,
      "loss": 0.0533,
      "step": 15104
    },
    {
      "epoch": 0.23916588818341594,
      "grad_norm": 0.01539624109864235,
      "learning_rate": 7.608341118165841e-06,
      "loss": 0.0007,
      "step": 15105
    },
    {
      "epoch": 0.239181721741058,
      "grad_norm": 0.33941134810447693,
      "learning_rate": 7.6081827825894204e-06,
      "loss": 0.3365,
      "step": 15106
    },
    {
      "epoch": 0.23919755529870007,
      "grad_norm": 0.20300783216953278,
      "learning_rate": 7.608024447013e-06,
      "loss": 0.0087,
      "step": 15107
    },
    {
      "epoch": 0.23921338885634214,
      "grad_norm": 1.673901081085205,
      "learning_rate": 7.6078661114365794e-06,
      "loss": 0.1055,
      "step": 15108
    },
    {
      "epoch": 0.2392292224139842,
      "grad_norm": 7.43693090043962e-05,
      "learning_rate": 7.607707775860159e-06,
      "loss": 0.0,
      "step": 15109
    },
    {
      "epoch": 0.23924505597162626,
      "grad_norm": 0.3475421965122223,
      "learning_rate": 7.607549440283738e-06,
      "loss": 0.1241,
      "step": 15110
    },
    {
      "epoch": 0.23926088952926833,
      "grad_norm": 0.7182836532592773,
      "learning_rate": 7.607391104707317e-06,
      "loss": 0.1262,
      "step": 15111
    },
    {
      "epoch": 0.2392767230869104,
      "grad_norm": 0.03421637415885925,
      "learning_rate": 7.607232769130897e-06,
      "loss": 0.0021,
      "step": 15112
    },
    {
      "epoch": 0.23929255664455246,
      "grad_norm": 0.1682322472333908,
      "learning_rate": 7.607074433554476e-06,
      "loss": 0.0339,
      "step": 15113
    },
    {
      "epoch": 0.23930839020219452,
      "grad_norm": 0.5087487101554871,
      "learning_rate": 7.606916097978056e-06,
      "loss": 0.0751,
      "step": 15114
    },
    {
      "epoch": 0.23932422375983659,
      "grad_norm": 0.19853703677654266,
      "learning_rate": 7.606757762401634e-06,
      "loss": 0.0794,
      "step": 15115
    },
    {
      "epoch": 0.23934005731747868,
      "grad_norm": 0.5133812427520752,
      "learning_rate": 7.606599426825214e-06,
      "loss": 0.2304,
      "step": 15116
    },
    {
      "epoch": 0.23935589087512074,
      "grad_norm": 0.6836775541305542,
      "learning_rate": 7.606441091248793e-06,
      "loss": 0.1427,
      "step": 15117
    },
    {
      "epoch": 0.2393717244327628,
      "grad_norm": 0.47043031454086304,
      "learning_rate": 7.606282755672373e-06,
      "loss": 0.0602,
      "step": 15118
    },
    {
      "epoch": 0.23938755799040487,
      "grad_norm": 1.2063798904418945,
      "learning_rate": 7.606124420095952e-06,
      "loss": 0.2348,
      "step": 15119
    },
    {
      "epoch": 0.23940339154804693,
      "grad_norm": 0.6696681380271912,
      "learning_rate": 7.605966084519532e-06,
      "loss": 0.9536,
      "step": 15120
    },
    {
      "epoch": 0.239419225105689,
      "grad_norm": 0.028771428391337395,
      "learning_rate": 7.60580774894311e-06,
      "loss": 0.0005,
      "step": 15121
    },
    {
      "epoch": 0.23943505866333106,
      "grad_norm": 0.019129280000925064,
      "learning_rate": 7.60564941336669e-06,
      "loss": 0.0011,
      "step": 15122
    },
    {
      "epoch": 0.23945089222097313,
      "grad_norm": 0.3137720227241516,
      "learning_rate": 7.605491077790269e-06,
      "loss": 0.0992,
      "step": 15123
    },
    {
      "epoch": 0.2394667257786152,
      "grad_norm": 0.46831539273262024,
      "learning_rate": 7.605332742213849e-06,
      "loss": 0.1601,
      "step": 15124
    },
    {
      "epoch": 0.23948255933625726,
      "grad_norm": 0.5575827360153198,
      "learning_rate": 7.605174406637428e-06,
      "loss": 0.1691,
      "step": 15125
    },
    {
      "epoch": 0.23949839289389932,
      "grad_norm": 0.6101008057594299,
      "learning_rate": 7.605016071061008e-06,
      "loss": 0.1765,
      "step": 15126
    },
    {
      "epoch": 0.23951422645154138,
      "grad_norm": 0.2685505747795105,
      "learning_rate": 7.604857735484586e-06,
      "loss": 0.1,
      "step": 15127
    },
    {
      "epoch": 0.23953006000918348,
      "grad_norm": 0.5209991931915283,
      "learning_rate": 7.604699399908166e-06,
      "loss": 0.1119,
      "step": 15128
    },
    {
      "epoch": 0.23954589356682554,
      "grad_norm": 0.5304797887802124,
      "learning_rate": 7.604541064331745e-06,
      "loss": 0.2915,
      "step": 15129
    },
    {
      "epoch": 0.2395617271244676,
      "grad_norm": 0.19300144910812378,
      "learning_rate": 7.604382728755325e-06,
      "loss": 0.0493,
      "step": 15130
    },
    {
      "epoch": 0.23957756068210967,
      "grad_norm": 0.6130717396736145,
      "learning_rate": 7.604224393178904e-06,
      "loss": 0.3844,
      "step": 15131
    },
    {
      "epoch": 0.23959339423975173,
      "grad_norm": 0.48522233963012695,
      "learning_rate": 7.604066057602484e-06,
      "loss": 0.1473,
      "step": 15132
    },
    {
      "epoch": 0.2396092277973938,
      "grad_norm": 0.30532127618789673,
      "learning_rate": 7.603907722026062e-06,
      "loss": 0.1354,
      "step": 15133
    },
    {
      "epoch": 0.23962506135503586,
      "grad_norm": 0.39542731642723083,
      "learning_rate": 7.6037493864496414e-06,
      "loss": 0.1688,
      "step": 15134
    },
    {
      "epoch": 0.23964089491267793,
      "grad_norm": 0.4758135676383972,
      "learning_rate": 7.603591050873221e-06,
      "loss": 0.1319,
      "step": 15135
    },
    {
      "epoch": 0.23965672847032,
      "grad_norm": 0.03115370124578476,
      "learning_rate": 7.6034327152968005e-06,
      "loss": 0.0013,
      "step": 15136
    },
    {
      "epoch": 0.23967256202796205,
      "grad_norm": 0.1325138956308365,
      "learning_rate": 7.60327437972038e-06,
      "loss": 0.0121,
      "step": 15137
    },
    {
      "epoch": 0.23968839558560412,
      "grad_norm": 0.024969791993498802,
      "learning_rate": 7.603116044143959e-06,
      "loss": 0.0012,
      "step": 15138
    },
    {
      "epoch": 0.23970422914324618,
      "grad_norm": 0.4471880793571472,
      "learning_rate": 7.6029577085675385e-06,
      "loss": 0.1504,
      "step": 15139
    },
    {
      "epoch": 0.23972006270088828,
      "grad_norm": 0.0385262593626976,
      "learning_rate": 7.602799372991118e-06,
      "loss": 0.0022,
      "step": 15140
    },
    {
      "epoch": 0.23973589625853034,
      "grad_norm": 0.08865878731012344,
      "learning_rate": 7.6026410374146975e-06,
      "loss": 0.0061,
      "step": 15141
    },
    {
      "epoch": 0.2397517298161724,
      "grad_norm": 0.44933292269706726,
      "learning_rate": 7.602482701838277e-06,
      "loss": 0.1225,
      "step": 15142
    },
    {
      "epoch": 0.23976756337381447,
      "grad_norm": 0.10342443734407425,
      "learning_rate": 7.6023243662618565e-06,
      "loss": 0.0078,
      "step": 15143
    },
    {
      "epoch": 0.23978339693145653,
      "grad_norm": 0.3232234716415405,
      "learning_rate": 7.602166030685435e-06,
      "loss": 0.0485,
      "step": 15144
    },
    {
      "epoch": 0.2397992304890986,
      "grad_norm": 0.4691385328769684,
      "learning_rate": 7.602007695109015e-06,
      "loss": 0.1453,
      "step": 15145
    },
    {
      "epoch": 0.23981506404674066,
      "grad_norm": 0.27588218450546265,
      "learning_rate": 7.601849359532594e-06,
      "loss": 0.0401,
      "step": 15146
    },
    {
      "epoch": 0.23983089760438273,
      "grad_norm": 0.047633104026317596,
      "learning_rate": 7.601691023956174e-06,
      "loss": 0.0032,
      "step": 15147
    },
    {
      "epoch": 0.2398467311620248,
      "grad_norm": 0.5655129551887512,
      "learning_rate": 7.601532688379753e-06,
      "loss": 0.1267,
      "step": 15148
    },
    {
      "epoch": 0.23986256471966685,
      "grad_norm": 0.009943884797394276,
      "learning_rate": 7.601374352803333e-06,
      "loss": 0.0005,
      "step": 15149
    },
    {
      "epoch": 0.23987839827730892,
      "grad_norm": 0.6175166368484497,
      "learning_rate": 7.601216017226911e-06,
      "loss": 0.5549,
      "step": 15150
    },
    {
      "epoch": 0.23989423183495098,
      "grad_norm": 0.18223872780799866,
      "learning_rate": 7.601057681650491e-06,
      "loss": 0.0116,
      "step": 15151
    },
    {
      "epoch": 0.23991006539259307,
      "grad_norm": 0.6303882598876953,
      "learning_rate": 7.60089934607407e-06,
      "loss": 0.0921,
      "step": 15152
    },
    {
      "epoch": 0.23992589895023514,
      "grad_norm": 0.601233720779419,
      "learning_rate": 7.60074101049765e-06,
      "loss": 0.179,
      "step": 15153
    },
    {
      "epoch": 0.2399417325078772,
      "grad_norm": 0.7288166880607605,
      "learning_rate": 7.600582674921229e-06,
      "loss": 0.0341,
      "step": 15154
    },
    {
      "epoch": 0.23995756606551927,
      "grad_norm": 0.24976736307144165,
      "learning_rate": 7.600424339344809e-06,
      "loss": 0.0882,
      "step": 15155
    },
    {
      "epoch": 0.23997339962316133,
      "grad_norm": 0.04239579662680626,
      "learning_rate": 7.600266003768387e-06,
      "loss": 0.0021,
      "step": 15156
    },
    {
      "epoch": 0.2399892331808034,
      "grad_norm": 0.49634990096092224,
      "learning_rate": 7.600107668191967e-06,
      "loss": 0.1888,
      "step": 15157
    },
    {
      "epoch": 0.24000506673844546,
      "grad_norm": 0.32548579573631287,
      "learning_rate": 7.599949332615546e-06,
      "loss": 0.1822,
      "step": 15158
    },
    {
      "epoch": 0.24002090029608752,
      "grad_norm": 0.35364460945129395,
      "learning_rate": 7.599790997039125e-06,
      "loss": 0.039,
      "step": 15159
    },
    {
      "epoch": 0.2400367338537296,
      "grad_norm": 0.36359483003616333,
      "learning_rate": 7.599632661462705e-06,
      "loss": 0.0952,
      "step": 15160
    },
    {
      "epoch": 0.24005256741137165,
      "grad_norm": 0.0039047750178724527,
      "learning_rate": 7.599474325886283e-06,
      "loss": 0.0001,
      "step": 15161
    },
    {
      "epoch": 0.24006840096901372,
      "grad_norm": 0.5857563018798828,
      "learning_rate": 7.599315990309863e-06,
      "loss": 0.3308,
      "step": 15162
    },
    {
      "epoch": 0.24008423452665578,
      "grad_norm": 0.00028892807313241065,
      "learning_rate": 7.599157654733442e-06,
      "loss": 0.0,
      "step": 15163
    },
    {
      "epoch": 0.24010006808429787,
      "grad_norm": 0.36716774106025696,
      "learning_rate": 7.598999319157022e-06,
      "loss": 0.0615,
      "step": 15164
    },
    {
      "epoch": 0.24011590164193994,
      "grad_norm": 0.306003600358963,
      "learning_rate": 7.598840983580601e-06,
      "loss": 0.1235,
      "step": 15165
    },
    {
      "epoch": 0.240131735199582,
      "grad_norm": 0.3687858581542969,
      "learning_rate": 7.5986826480041805e-06,
      "loss": 0.1569,
      "step": 15166
    },
    {
      "epoch": 0.24014756875722407,
      "grad_norm": 0.03334614634513855,
      "learning_rate": 7.5985243124277595e-06,
      "loss": 0.0019,
      "step": 15167
    },
    {
      "epoch": 0.24016340231486613,
      "grad_norm": 0.42418813705444336,
      "learning_rate": 7.5983659768513395e-06,
      "loss": 0.2166,
      "step": 15168
    },
    {
      "epoch": 0.2401792358725082,
      "grad_norm": 0.38243064284324646,
      "learning_rate": 7.5982076412749185e-06,
      "loss": 0.0682,
      "step": 15169
    },
    {
      "epoch": 0.24019506943015026,
      "grad_norm": 0.36999180912971497,
      "learning_rate": 7.5980493056984985e-06,
      "loss": 0.0899,
      "step": 15170
    },
    {
      "epoch": 0.24021090298779232,
      "grad_norm": 0.03656642511487007,
      "learning_rate": 7.597890970122077e-06,
      "loss": 0.0014,
      "step": 15171
    },
    {
      "epoch": 0.2402267365454344,
      "grad_norm": 0.3395928144454956,
      "learning_rate": 7.597732634545657e-06,
      "loss": 0.1391,
      "step": 15172
    },
    {
      "epoch": 0.24024257010307645,
      "grad_norm": 0.009063176810741425,
      "learning_rate": 7.597574298969236e-06,
      "loss": 0.0004,
      "step": 15173
    },
    {
      "epoch": 0.24025840366071852,
      "grad_norm": 0.7863674163818359,
      "learning_rate": 7.597415963392816e-06,
      "loss": 0.6624,
      "step": 15174
    },
    {
      "epoch": 0.24027423721836058,
      "grad_norm": 0.20838040113449097,
      "learning_rate": 7.597257627816395e-06,
      "loss": 0.066,
      "step": 15175
    },
    {
      "epoch": 0.24029007077600267,
      "grad_norm": 0.7754243612289429,
      "learning_rate": 7.597099292239975e-06,
      "loss": 0.1452,
      "step": 15176
    },
    {
      "epoch": 0.24030590433364474,
      "grad_norm": 0.7286627888679504,
      "learning_rate": 7.596940956663553e-06,
      "loss": 0.8201,
      "step": 15177
    },
    {
      "epoch": 0.2403217378912868,
      "grad_norm": 0.5107545852661133,
      "learning_rate": 7.596782621087133e-06,
      "loss": 0.2907,
      "step": 15178
    },
    {
      "epoch": 0.24033757144892887,
      "grad_norm": 0.3628564178943634,
      "learning_rate": 7.596624285510712e-06,
      "loss": 0.1325,
      "step": 15179
    },
    {
      "epoch": 0.24035340500657093,
      "grad_norm": 0.3648968040943146,
      "learning_rate": 7.596465949934292e-06,
      "loss": 0.1103,
      "step": 15180
    },
    {
      "epoch": 0.240369238564213,
      "grad_norm": 0.05400920659303665,
      "learning_rate": 7.596307614357871e-06,
      "loss": 0.0044,
      "step": 15181
    },
    {
      "epoch": 0.24038507212185506,
      "grad_norm": 0.7143906950950623,
      "learning_rate": 7.596149278781449e-06,
      "loss": 0.4888,
      "step": 15182
    },
    {
      "epoch": 0.24040090567949712,
      "grad_norm": 0.0423816554248333,
      "learning_rate": 7.595990943205029e-06,
      "loss": 0.0025,
      "step": 15183
    },
    {
      "epoch": 0.2404167392371392,
      "grad_norm": 0.23573660850524902,
      "learning_rate": 7.595832607628608e-06,
      "loss": 0.0658,
      "step": 15184
    },
    {
      "epoch": 0.24043257279478125,
      "grad_norm": 0.28082016110420227,
      "learning_rate": 7.595674272052188e-06,
      "loss": 0.1223,
      "step": 15185
    },
    {
      "epoch": 0.24044840635242332,
      "grad_norm": 0.4003555476665497,
      "learning_rate": 7.595515936475767e-06,
      "loss": 0.052,
      "step": 15186
    },
    {
      "epoch": 0.24046423991006538,
      "grad_norm": 0.5111110210418701,
      "learning_rate": 7.595357600899347e-06,
      "loss": 0.1371,
      "step": 15187
    },
    {
      "epoch": 0.24048007346770747,
      "grad_norm": 0.2657584249973297,
      "learning_rate": 7.595199265322925e-06,
      "loss": 0.1248,
      "step": 15188
    },
    {
      "epoch": 0.24049590702534954,
      "grad_norm": 0.4265199899673462,
      "learning_rate": 7.595040929746505e-06,
      "loss": 0.3237,
      "step": 15189
    },
    {
      "epoch": 0.2405117405829916,
      "grad_norm": 0.41533708572387695,
      "learning_rate": 7.594882594170084e-06,
      "loss": 0.1919,
      "step": 15190
    },
    {
      "epoch": 0.24052757414063367,
      "grad_norm": 0.16778910160064697,
      "learning_rate": 7.594724258593664e-06,
      "loss": 0.0778,
      "step": 15191
    },
    {
      "epoch": 0.24054340769827573,
      "grad_norm": 0.015653586015105247,
      "learning_rate": 7.594565923017243e-06,
      "loss": 0.0006,
      "step": 15192
    },
    {
      "epoch": 0.2405592412559178,
      "grad_norm": 0.5982625484466553,
      "learning_rate": 7.594407587440823e-06,
      "loss": 0.5803,
      "step": 15193
    },
    {
      "epoch": 0.24057507481355986,
      "grad_norm": 0.399840384721756,
      "learning_rate": 7.5942492518644015e-06,
      "loss": 0.2484,
      "step": 15194
    },
    {
      "epoch": 0.24059090837120192,
      "grad_norm": 0.6700929999351501,
      "learning_rate": 7.594090916287981e-06,
      "loss": 0.0693,
      "step": 15195
    },
    {
      "epoch": 0.240606741928844,
      "grad_norm": 0.7633494138717651,
      "learning_rate": 7.5939325807115605e-06,
      "loss": 0.2113,
      "step": 15196
    },
    {
      "epoch": 0.24062257548648605,
      "grad_norm": 0.011300334706902504,
      "learning_rate": 7.59377424513514e-06,
      "loss": 0.0005,
      "step": 15197
    },
    {
      "epoch": 0.24063840904412812,
      "grad_norm": 0.6915082335472107,
      "learning_rate": 7.5936159095587195e-06,
      "loss": 0.1091,
      "step": 15198
    },
    {
      "epoch": 0.24065424260177018,
      "grad_norm": 0.2831476926803589,
      "learning_rate": 7.593457573982299e-06,
      "loss": 0.1293,
      "step": 15199
    },
    {
      "epoch": 0.24067007615941227,
      "grad_norm": 0.4578079283237457,
      "learning_rate": 7.593299238405878e-06,
      "loss": 0.0873,
      "step": 15200
    },
    {
      "epoch": 0.24068590971705434,
      "grad_norm": 0.8444731831550598,
      "learning_rate": 7.5931409028294576e-06,
      "loss": 0.2752,
      "step": 15201
    },
    {
      "epoch": 0.2407017432746964,
      "grad_norm": 0.5359466075897217,
      "learning_rate": 7.592982567253037e-06,
      "loss": 0.1119,
      "step": 15202
    },
    {
      "epoch": 0.24071757683233846,
      "grad_norm": 0.0841587632894516,
      "learning_rate": 7.5928242316766166e-06,
      "loss": 0.0053,
      "step": 15203
    },
    {
      "epoch": 0.24073341038998053,
      "grad_norm": 0.00035534403286874294,
      "learning_rate": 7.592665896100196e-06,
      "loss": 0.0,
      "step": 15204
    },
    {
      "epoch": 0.2407492439476226,
      "grad_norm": 0.00012712545867543668,
      "learning_rate": 7.5925075605237756e-06,
      "loss": 0.0,
      "step": 15205
    },
    {
      "epoch": 0.24076507750526466,
      "grad_norm": 0.7680400609970093,
      "learning_rate": 7.592349224947354e-06,
      "loss": 0.349,
      "step": 15206
    },
    {
      "epoch": 0.24078091106290672,
      "grad_norm": 0.05467795953154564,
      "learning_rate": 7.592190889370933e-06,
      "loss": 0.0027,
      "step": 15207
    },
    {
      "epoch": 0.24079674462054879,
      "grad_norm": 0.02520039863884449,
      "learning_rate": 7.592032553794513e-06,
      "loss": 0.0014,
      "step": 15208
    },
    {
      "epoch": 0.24081257817819085,
      "grad_norm": 0.4734175503253937,
      "learning_rate": 7.591874218218092e-06,
      "loss": 0.0955,
      "step": 15209
    },
    {
      "epoch": 0.24082841173583291,
      "grad_norm": 0.3715803027153015,
      "learning_rate": 7.591715882641672e-06,
      "loss": 0.1036,
      "step": 15210
    },
    {
      "epoch": 0.24084424529347498,
      "grad_norm": 0.31662389636039734,
      "learning_rate": 7.59155754706525e-06,
      "loss": 0.0909,
      "step": 15211
    },
    {
      "epoch": 0.24086007885111707,
      "grad_norm": 0.0006167664541862905,
      "learning_rate": 7.59139921148883e-06,
      "loss": 0.0,
      "step": 15212
    },
    {
      "epoch": 0.24087591240875914,
      "grad_norm": 0.4222032129764557,
      "learning_rate": 7.591240875912409e-06,
      "loss": 0.1169,
      "step": 15213
    },
    {
      "epoch": 0.2408917459664012,
      "grad_norm": 0.20734073221683502,
      "learning_rate": 7.591082540335989e-06,
      "loss": 0.0761,
      "step": 15214
    },
    {
      "epoch": 0.24090757952404326,
      "grad_norm": 0.30479833483695984,
      "learning_rate": 7.590924204759568e-06,
      "loss": 0.0611,
      "step": 15215
    },
    {
      "epoch": 0.24092341308168533,
      "grad_norm": 0.05374722555279732,
      "learning_rate": 7.590765869183148e-06,
      "loss": 0.0028,
      "step": 15216
    },
    {
      "epoch": 0.2409392466393274,
      "grad_norm": 0.4494517743587494,
      "learning_rate": 7.590607533606726e-06,
      "loss": 0.1232,
      "step": 15217
    },
    {
      "epoch": 0.24095508019696946,
      "grad_norm": 0.02006739191710949,
      "learning_rate": 7.590449198030306e-06,
      "loss": 0.0011,
      "step": 15218
    },
    {
      "epoch": 0.24097091375461152,
      "grad_norm": 0.05907071754336357,
      "learning_rate": 7.590290862453885e-06,
      "loss": 0.0033,
      "step": 15219
    },
    {
      "epoch": 0.24098674731225359,
      "grad_norm": 0.000780545815359801,
      "learning_rate": 7.590132526877465e-06,
      "loss": 0.0,
      "step": 15220
    },
    {
      "epoch": 0.24100258086989565,
      "grad_norm": 0.3068746328353882,
      "learning_rate": 7.589974191301044e-06,
      "loss": 0.0753,
      "step": 15221
    },
    {
      "epoch": 0.2410184144275377,
      "grad_norm": 0.00014474157069344074,
      "learning_rate": 7.589815855724624e-06,
      "loss": 0.0,
      "step": 15222
    },
    {
      "epoch": 0.24103424798517978,
      "grad_norm": 0.405061811208725,
      "learning_rate": 7.589657520148202e-06,
      "loss": 0.2017,
      "step": 15223
    },
    {
      "epoch": 0.24105008154282187,
      "grad_norm": 0.6232470273971558,
      "learning_rate": 7.589499184571782e-06,
      "loss": 0.3449,
      "step": 15224
    },
    {
      "epoch": 0.24106591510046393,
      "grad_norm": 0.020895052701234818,
      "learning_rate": 7.589340848995361e-06,
      "loss": 0.0012,
      "step": 15225
    },
    {
      "epoch": 0.241081748658106,
      "grad_norm": 0.4470577836036682,
      "learning_rate": 7.589182513418941e-06,
      "loss": 0.2517,
      "step": 15226
    },
    {
      "epoch": 0.24109758221574806,
      "grad_norm": 0.007971382699906826,
      "learning_rate": 7.58902417784252e-06,
      "loss": 0.0004,
      "step": 15227
    },
    {
      "epoch": 0.24111341577339013,
      "grad_norm": 0.20460925996303558,
      "learning_rate": 7.5888658422660995e-06,
      "loss": 0.0822,
      "step": 15228
    },
    {
      "epoch": 0.2411292493310322,
      "grad_norm": 0.2149149775505066,
      "learning_rate": 7.5887075066896786e-06,
      "loss": 0.0756,
      "step": 15229
    },
    {
      "epoch": 0.24114508288867426,
      "grad_norm": 0.00030553454416804016,
      "learning_rate": 7.588549171113258e-06,
      "loss": 0.0,
      "step": 15230
    },
    {
      "epoch": 0.24116091644631632,
      "grad_norm": 0.4044395685195923,
      "learning_rate": 7.5883908355368376e-06,
      "loss": 0.0904,
      "step": 15231
    },
    {
      "epoch": 0.24117675000395838,
      "grad_norm": 0.4128498435020447,
      "learning_rate": 7.588232499960416e-06,
      "loss": 0.1266,
      "step": 15232
    },
    {
      "epoch": 0.24119258356160045,
      "grad_norm": 0.2426643818616867,
      "learning_rate": 7.588074164383996e-06,
      "loss": 0.15,
      "step": 15233
    },
    {
      "epoch": 0.2412084171192425,
      "grad_norm": 0.5229077935218811,
      "learning_rate": 7.587915828807575e-06,
      "loss": 0.1615,
      "step": 15234
    },
    {
      "epoch": 0.24122425067688458,
      "grad_norm": 0.3639262616634369,
      "learning_rate": 7.587757493231155e-06,
      "loss": 0.1344,
      "step": 15235
    },
    {
      "epoch": 0.24124008423452667,
      "grad_norm": 0.8784621357917786,
      "learning_rate": 7.587599157654734e-06,
      "loss": 0.2826,
      "step": 15236
    },
    {
      "epoch": 0.24125591779216873,
      "grad_norm": 0.42782288789749146,
      "learning_rate": 7.587440822078314e-06,
      "loss": 0.1804,
      "step": 15237
    },
    {
      "epoch": 0.2412717513498108,
      "grad_norm": 0.7230179309844971,
      "learning_rate": 7.587282486501892e-06,
      "loss": 0.514,
      "step": 15238
    },
    {
      "epoch": 0.24128758490745286,
      "grad_norm": 0.4480852782726288,
      "learning_rate": 7.587124150925472e-06,
      "loss": 0.1297,
      "step": 15239
    },
    {
      "epoch": 0.24130341846509493,
      "grad_norm": 0.18645411729812622,
      "learning_rate": 7.586965815349051e-06,
      "loss": 0.0608,
      "step": 15240
    },
    {
      "epoch": 0.241319252022737,
      "grad_norm": 0.052386753261089325,
      "learning_rate": 7.586807479772631e-06,
      "loss": 0.0033,
      "step": 15241
    },
    {
      "epoch": 0.24133508558037906,
      "grad_norm": 0.42862749099731445,
      "learning_rate": 7.58664914419621e-06,
      "loss": 0.1943,
      "step": 15242
    },
    {
      "epoch": 0.24135091913802112,
      "grad_norm": 0.011167800985276699,
      "learning_rate": 7.58649080861979e-06,
      "loss": 0.0006,
      "step": 15243
    },
    {
      "epoch": 0.24136675269566318,
      "grad_norm": 0.8076202273368835,
      "learning_rate": 7.586332473043368e-06,
      "loss": 0.288,
      "step": 15244
    },
    {
      "epoch": 0.24138258625330525,
      "grad_norm": 0.04464335739612579,
      "learning_rate": 7.586174137466948e-06,
      "loss": 0.001,
      "step": 15245
    },
    {
      "epoch": 0.2413984198109473,
      "grad_norm": 0.4163503646850586,
      "learning_rate": 7.586015801890527e-06,
      "loss": 0.2179,
      "step": 15246
    },
    {
      "epoch": 0.24141425336858938,
      "grad_norm": 0.01619182527065277,
      "learning_rate": 7.585857466314107e-06,
      "loss": 0.0007,
      "step": 15247
    },
    {
      "epoch": 0.24143008692623147,
      "grad_norm": 0.2199283242225647,
      "learning_rate": 7.585699130737686e-06,
      "loss": 0.0541,
      "step": 15248
    },
    {
      "epoch": 0.24144592048387353,
      "grad_norm": 0.5658923983573914,
      "learning_rate": 7.585540795161266e-06,
      "loss": 0.3163,
      "step": 15249
    },
    {
      "epoch": 0.2414617540415156,
      "grad_norm": 0.3478887379169464,
      "learning_rate": 7.585382459584844e-06,
      "loss": 0.1607,
      "step": 15250
    },
    {
      "epoch": 0.24147758759915766,
      "grad_norm": 0.19429302215576172,
      "learning_rate": 7.585224124008424e-06,
      "loss": 0.0065,
      "step": 15251
    },
    {
      "epoch": 0.24149342115679973,
      "grad_norm": 0.00034842599416151643,
      "learning_rate": 7.585065788432003e-06,
      "loss": 0.0,
      "step": 15252
    },
    {
      "epoch": 0.2415092547144418,
      "grad_norm": 0.3452158272266388,
      "learning_rate": 7.584907452855583e-06,
      "loss": 0.0459,
      "step": 15253
    },
    {
      "epoch": 0.24152508827208385,
      "grad_norm": 0.5594624280929565,
      "learning_rate": 7.584749117279162e-06,
      "loss": 0.2235,
      "step": 15254
    },
    {
      "epoch": 0.24154092182972592,
      "grad_norm": 0.010415807366371155,
      "learning_rate": 7.5845907817027406e-06,
      "loss": 0.0005,
      "step": 15255
    },
    {
      "epoch": 0.24155675538736798,
      "grad_norm": 0.016298072412610054,
      "learning_rate": 7.5844324461263205e-06,
      "loss": 0.0008,
      "step": 15256
    },
    {
      "epoch": 0.24157258894501005,
      "grad_norm": 0.5175940990447998,
      "learning_rate": 7.5842741105498996e-06,
      "loss": 0.0806,
      "step": 15257
    },
    {
      "epoch": 0.2415884225026521,
      "grad_norm": 0.5691310167312622,
      "learning_rate": 7.5841157749734795e-06,
      "loss": 0.5251,
      "step": 15258
    },
    {
      "epoch": 0.24160425606029418,
      "grad_norm": 0.2929726243019104,
      "learning_rate": 7.583957439397059e-06,
      "loss": 0.0988,
      "step": 15259
    },
    {
      "epoch": 0.24162008961793627,
      "grad_norm": 0.7474441528320312,
      "learning_rate": 7.5837991038206385e-06,
      "loss": 0.154,
      "step": 15260
    },
    {
      "epoch": 0.24163592317557833,
      "grad_norm": 0.20493394136428833,
      "learning_rate": 7.583640768244217e-06,
      "loss": 0.0244,
      "step": 15261
    },
    {
      "epoch": 0.2416517567332204,
      "grad_norm": 0.6001008152961731,
      "learning_rate": 7.583482432667797e-06,
      "loss": 0.2738,
      "step": 15262
    },
    {
      "epoch": 0.24166759029086246,
      "grad_norm": 0.24189256131649017,
      "learning_rate": 7.583324097091376e-06,
      "loss": 0.0569,
      "step": 15263
    },
    {
      "epoch": 0.24168342384850452,
      "grad_norm": 0.3963484764099121,
      "learning_rate": 7.583165761514956e-06,
      "loss": 0.0703,
      "step": 15264
    },
    {
      "epoch": 0.2416992574061466,
      "grad_norm": 1.3024224042892456,
      "learning_rate": 7.583007425938535e-06,
      "loss": 0.2282,
      "step": 15265
    },
    {
      "epoch": 0.24171509096378865,
      "grad_norm": 0.6090091466903687,
      "learning_rate": 7.582849090362115e-06,
      "loss": 0.1462,
      "step": 15266
    },
    {
      "epoch": 0.24173092452143072,
      "grad_norm": 0.011441681534051895,
      "learning_rate": 7.582690754785693e-06,
      "loss": 0.0006,
      "step": 15267
    },
    {
      "epoch": 0.24174675807907278,
      "grad_norm": 0.32219237089157104,
      "learning_rate": 7.582532419209273e-06,
      "loss": 0.0503,
      "step": 15268
    },
    {
      "epoch": 0.24176259163671485,
      "grad_norm": 0.5039817094802856,
      "learning_rate": 7.582374083632852e-06,
      "loss": 0.2764,
      "step": 15269
    },
    {
      "epoch": 0.2417784251943569,
      "grad_norm": 0.3837624192237854,
      "learning_rate": 7.582215748056432e-06,
      "loss": 0.1419,
      "step": 15270
    },
    {
      "epoch": 0.24179425875199897,
      "grad_norm": 0.29675722122192383,
      "learning_rate": 7.582057412480011e-06,
      "loss": 0.1389,
      "step": 15271
    },
    {
      "epoch": 0.24181009230964107,
      "grad_norm": 0.7184722423553467,
      "learning_rate": 7.581899076903591e-06,
      "loss": 0.3068,
      "step": 15272
    },
    {
      "epoch": 0.24182592586728313,
      "grad_norm": 0.21859271824359894,
      "learning_rate": 7.581740741327169e-06,
      "loss": 0.0427,
      "step": 15273
    },
    {
      "epoch": 0.2418417594249252,
      "grad_norm": 0.26959264278411865,
      "learning_rate": 7.581582405750749e-06,
      "loss": 0.0482,
      "step": 15274
    },
    {
      "epoch": 0.24185759298256726,
      "grad_norm": 0.0004216080124024302,
      "learning_rate": 7.581424070174328e-06,
      "loss": 0.0,
      "step": 15275
    },
    {
      "epoch": 0.24187342654020932,
      "grad_norm": 0.23161792755126953,
      "learning_rate": 7.581265734597908e-06,
      "loss": 0.0623,
      "step": 15276
    },
    {
      "epoch": 0.2418892600978514,
      "grad_norm": 0.1672227829694748,
      "learning_rate": 7.581107399021487e-06,
      "loss": 0.0471,
      "step": 15277
    },
    {
      "epoch": 0.24190509365549345,
      "grad_norm": 4.884098962065764e-05,
      "learning_rate": 7.580949063445065e-06,
      "loss": 0.0,
      "step": 15278
    },
    {
      "epoch": 0.24192092721313552,
      "grad_norm": 0.032922666519880295,
      "learning_rate": 7.580790727868645e-06,
      "loss": 0.0017,
      "step": 15279
    },
    {
      "epoch": 0.24193676077077758,
      "grad_norm": 0.13911977410316467,
      "learning_rate": 7.580632392292224e-06,
      "loss": 0.0035,
      "step": 15280
    },
    {
      "epoch": 0.24195259432841965,
      "grad_norm": 0.6446255445480347,
      "learning_rate": 7.580474056715804e-06,
      "loss": 0.2538,
      "step": 15281
    },
    {
      "epoch": 0.2419684278860617,
      "grad_norm": 0.014112272299826145,
      "learning_rate": 7.580315721139383e-06,
      "loss": 0.0006,
      "step": 15282
    },
    {
      "epoch": 0.24198426144370377,
      "grad_norm": 0.37759989500045776,
      "learning_rate": 7.580157385562963e-06,
      "loss": 0.0393,
      "step": 15283
    },
    {
      "epoch": 0.24200009500134587,
      "grad_norm": 0.013583742082118988,
      "learning_rate": 7.5799990499865415e-06,
      "loss": 0.0007,
      "step": 15284
    },
    {
      "epoch": 0.24201592855898793,
      "grad_norm": 0.012997932732105255,
      "learning_rate": 7.579840714410121e-06,
      "loss": 0.0006,
      "step": 15285
    },
    {
      "epoch": 0.24203176211663,
      "grad_norm": 0.28045928478240967,
      "learning_rate": 7.5796823788337005e-06,
      "loss": 0.013,
      "step": 15286
    },
    {
      "epoch": 0.24204759567427206,
      "grad_norm": 0.018245572224259377,
      "learning_rate": 7.5795240432572804e-06,
      "loss": 0.0008,
      "step": 15287
    },
    {
      "epoch": 0.24206342923191412,
      "grad_norm": 0.35170698165893555,
      "learning_rate": 7.5793657076808595e-06,
      "loss": 0.1191,
      "step": 15288
    },
    {
      "epoch": 0.2420792627895562,
      "grad_norm": 0.7338278889656067,
      "learning_rate": 7.5792073721044394e-06,
      "loss": 0.3129,
      "step": 15289
    },
    {
      "epoch": 0.24209509634719825,
      "grad_norm": 0.6077765226364136,
      "learning_rate": 7.579049036528018e-06,
      "loss": 0.1776,
      "step": 15290
    },
    {
      "epoch": 0.24211092990484032,
      "grad_norm": 0.29951485991477966,
      "learning_rate": 7.578890700951598e-06,
      "loss": 0.0995,
      "step": 15291
    },
    {
      "epoch": 0.24212676346248238,
      "grad_norm": 0.29934656620025635,
      "learning_rate": 7.578732365375177e-06,
      "loss": 0.0299,
      "step": 15292
    },
    {
      "epoch": 0.24214259702012444,
      "grad_norm": 0.3766060769557953,
      "learning_rate": 7.578574029798757e-06,
      "loss": 0.0996,
      "step": 15293
    },
    {
      "epoch": 0.2421584305777665,
      "grad_norm": 0.17574754357337952,
      "learning_rate": 7.578415694222335e-06,
      "loss": 0.0182,
      "step": 15294
    },
    {
      "epoch": 0.24217426413540857,
      "grad_norm": 0.3077890872955322,
      "learning_rate": 7.578257358645915e-06,
      "loss": 0.1414,
      "step": 15295
    },
    {
      "epoch": 0.24219009769305064,
      "grad_norm": 0.4449918866157532,
      "learning_rate": 7.578099023069494e-06,
      "loss": 0.059,
      "step": 15296
    },
    {
      "epoch": 0.24220593125069273,
      "grad_norm": 0.48155152797698975,
      "learning_rate": 7.577940687493074e-06,
      "loss": 0.2952,
      "step": 15297
    },
    {
      "epoch": 0.2422217648083348,
      "grad_norm": 0.2654883563518524,
      "learning_rate": 7.577782351916653e-06,
      "loss": 0.1293,
      "step": 15298
    },
    {
      "epoch": 0.24223759836597686,
      "grad_norm": 0.7136006951332092,
      "learning_rate": 7.577624016340233e-06,
      "loss": 0.4384,
      "step": 15299
    },
    {
      "epoch": 0.24225343192361892,
      "grad_norm": 0.557888925075531,
      "learning_rate": 7.577465680763811e-06,
      "loss": 0.3106,
      "step": 15300
    },
    {
      "epoch": 0.242269265481261,
      "grad_norm": 0.7464903593063354,
      "learning_rate": 7.577307345187391e-06,
      "loss": 0.1794,
      "step": 15301
    },
    {
      "epoch": 0.24228509903890305,
      "grad_norm": 0.613860547542572,
      "learning_rate": 7.57714900961097e-06,
      "loss": 0.1175,
      "step": 15302
    },
    {
      "epoch": 0.24230093259654512,
      "grad_norm": 0.14966325461864471,
      "learning_rate": 7.576990674034549e-06,
      "loss": 0.0447,
      "step": 15303
    },
    {
      "epoch": 0.24231676615418718,
      "grad_norm": 0.010352483950555325,
      "learning_rate": 7.576832338458129e-06,
      "loss": 0.0005,
      "step": 15304
    },
    {
      "epoch": 0.24233259971182924,
      "grad_norm": 0.7212911248207092,
      "learning_rate": 7.576674002881707e-06,
      "loss": 0.2581,
      "step": 15305
    },
    {
      "epoch": 0.2423484332694713,
      "grad_norm": 0.016002407297492027,
      "learning_rate": 7.576515667305287e-06,
      "loss": 0.0008,
      "step": 15306
    },
    {
      "epoch": 0.24236426682711337,
      "grad_norm": 0.315000981092453,
      "learning_rate": 7.576357331728866e-06,
      "loss": 0.1474,
      "step": 15307
    },
    {
      "epoch": 0.24238010038475544,
      "grad_norm": 0.48201367259025574,
      "learning_rate": 7.576198996152446e-06,
      "loss": 0.0861,
      "step": 15308
    },
    {
      "epoch": 0.24239593394239753,
      "grad_norm": 0.13484720885753632,
      "learning_rate": 7.576040660576025e-06,
      "loss": 0.0055,
      "step": 15309
    },
    {
      "epoch": 0.2424117675000396,
      "grad_norm": 0.23301562666893005,
      "learning_rate": 7.575882324999605e-06,
      "loss": 0.0628,
      "step": 15310
    },
    {
      "epoch": 0.24242760105768166,
      "grad_norm": 0.6193905472755432,
      "learning_rate": 7.575723989423183e-06,
      "loss": 0.1077,
      "step": 15311
    },
    {
      "epoch": 0.24244343461532372,
      "grad_norm": 0.010055966675281525,
      "learning_rate": 7.575565653846763e-06,
      "loss": 0.0004,
      "step": 15312
    },
    {
      "epoch": 0.2424592681729658,
      "grad_norm": 0.00015719732618890703,
      "learning_rate": 7.5754073182703424e-06,
      "loss": 0.0,
      "step": 15313
    },
    {
      "epoch": 0.24247510173060785,
      "grad_norm": 0.3471004068851471,
      "learning_rate": 7.575248982693922e-06,
      "loss": 0.0305,
      "step": 15314
    },
    {
      "epoch": 0.24249093528824991,
      "grad_norm": 0.3668655753135681,
      "learning_rate": 7.5750906471175014e-06,
      "loss": 0.1708,
      "step": 15315
    },
    {
      "epoch": 0.24250676884589198,
      "grad_norm": 0.0668991208076477,
      "learning_rate": 7.574932311541081e-06,
      "loss": 0.0047,
      "step": 15316
    },
    {
      "epoch": 0.24252260240353404,
      "grad_norm": 0.297075092792511,
      "learning_rate": 7.57477397596466e-06,
      "loss": 0.1472,
      "step": 15317
    },
    {
      "epoch": 0.2425384359611761,
      "grad_norm": 0.362637460231781,
      "learning_rate": 7.5746156403882395e-06,
      "loss": 0.0374,
      "step": 15318
    },
    {
      "epoch": 0.24255426951881817,
      "grad_norm": 0.3453267216682434,
      "learning_rate": 7.574457304811819e-06,
      "loss": 0.1419,
      "step": 15319
    },
    {
      "epoch": 0.24257010307646024,
      "grad_norm": 0.6918618679046631,
      "learning_rate": 7.5742989692353985e-06,
      "loss": 0.1015,
      "step": 15320
    },
    {
      "epoch": 0.24258593663410233,
      "grad_norm": 0.24754443764686584,
      "learning_rate": 7.574140633658978e-06,
      "loss": 0.0164,
      "step": 15321
    },
    {
      "epoch": 0.2426017701917444,
      "grad_norm": 0.0007544877007603645,
      "learning_rate": 7.5739822980825575e-06,
      "loss": 0.0,
      "step": 15322
    },
    {
      "epoch": 0.24261760374938646,
      "grad_norm": 0.5577454566955566,
      "learning_rate": 7.573823962506136e-06,
      "loss": 0.5431,
      "step": 15323
    },
    {
      "epoch": 0.24263343730702852,
      "grad_norm": 0.00011166609328938648,
      "learning_rate": 7.573665626929716e-06,
      "loss": 0.0,
      "step": 15324
    },
    {
      "epoch": 0.24264927086467059,
      "grad_norm": 0.43560341000556946,
      "learning_rate": 7.573507291353295e-06,
      "loss": 0.3105,
      "step": 15325
    },
    {
      "epoch": 0.24266510442231265,
      "grad_norm": 0.1449871063232422,
      "learning_rate": 7.573348955776875e-06,
      "loss": 0.041,
      "step": 15326
    },
    {
      "epoch": 0.24268093797995471,
      "grad_norm": 0.4747788608074188,
      "learning_rate": 7.573190620200454e-06,
      "loss": 0.1677,
      "step": 15327
    },
    {
      "epoch": 0.24269677153759678,
      "grad_norm": 0.4986463487148285,
      "learning_rate": 7.573032284624032e-06,
      "loss": 0.1654,
      "step": 15328
    },
    {
      "epoch": 0.24271260509523884,
      "grad_norm": 0.16020365059375763,
      "learning_rate": 7.572873949047612e-06,
      "loss": 0.0382,
      "step": 15329
    },
    {
      "epoch": 0.2427284386528809,
      "grad_norm": 9.911367669701576e-05,
      "learning_rate": 7.572715613471191e-06,
      "loss": 0.0,
      "step": 15330
    },
    {
      "epoch": 0.24274427221052297,
      "grad_norm": 0.021573370322585106,
      "learning_rate": 7.572557277894771e-06,
      "loss": 0.001,
      "step": 15331
    },
    {
      "epoch": 0.24276010576816504,
      "grad_norm": 0.7343423962593079,
      "learning_rate": 7.57239894231835e-06,
      "loss": 0.1124,
      "step": 15332
    },
    {
      "epoch": 0.24277593932580713,
      "grad_norm": 0.005530512426048517,
      "learning_rate": 7.57224060674193e-06,
      "loss": 0.0002,
      "step": 15333
    },
    {
      "epoch": 0.2427917728834492,
      "grad_norm": 0.35066574811935425,
      "learning_rate": 7.572082271165508e-06,
      "loss": 0.0432,
      "step": 15334
    },
    {
      "epoch": 0.24280760644109126,
      "grad_norm": 0.2891697585582733,
      "learning_rate": 7.571923935589088e-06,
      "loss": 0.0465,
      "step": 15335
    },
    {
      "epoch": 0.24282343999873332,
      "grad_norm": 0.6473274827003479,
      "learning_rate": 7.571765600012667e-06,
      "loss": 0.206,
      "step": 15336
    },
    {
      "epoch": 0.24283927355637538,
      "grad_norm": 0.02246398665010929,
      "learning_rate": 7.571607264436247e-06,
      "loss": 0.0009,
      "step": 15337
    },
    {
      "epoch": 0.24285510711401745,
      "grad_norm": 0.008563731797039509,
      "learning_rate": 7.571448928859826e-06,
      "loss": 0.0004,
      "step": 15338
    },
    {
      "epoch": 0.2428709406716595,
      "grad_norm": 0.40815606713294983,
      "learning_rate": 7.571290593283406e-06,
      "loss": 0.1159,
      "step": 15339
    },
    {
      "epoch": 0.24288677422930158,
      "grad_norm": 0.32749536633491516,
      "learning_rate": 7.571132257706984e-06,
      "loss": 0.1208,
      "step": 15340
    },
    {
      "epoch": 0.24290260778694364,
      "grad_norm": 3.615302193793468e-05,
      "learning_rate": 7.570973922130564e-06,
      "loss": 0.0,
      "step": 15341
    },
    {
      "epoch": 0.2429184413445857,
      "grad_norm": 0.5236282348632812,
      "learning_rate": 7.570815586554143e-06,
      "loss": 0.3336,
      "step": 15342
    },
    {
      "epoch": 0.24293427490222777,
      "grad_norm": 0.5944282412528992,
      "learning_rate": 7.570657250977723e-06,
      "loss": 0.1873,
      "step": 15343
    },
    {
      "epoch": 0.24295010845986983,
      "grad_norm": 0.3395809829235077,
      "learning_rate": 7.570498915401302e-06,
      "loss": 0.2161,
      "step": 15344
    },
    {
      "epoch": 0.24296594201751193,
      "grad_norm": 4.4618551328312606e-05,
      "learning_rate": 7.570340579824882e-06,
      "loss": 0.0,
      "step": 15345
    },
    {
      "epoch": 0.242981775575154,
      "grad_norm": 0.3744261860847473,
      "learning_rate": 7.5701822442484605e-06,
      "loss": 0.08,
      "step": 15346
    },
    {
      "epoch": 0.24299760913279606,
      "grad_norm": 0.41195085644721985,
      "learning_rate": 7.5700239086720404e-06,
      "loss": 0.064,
      "step": 15347
    },
    {
      "epoch": 0.24301344269043812,
      "grad_norm": 0.16410326957702637,
      "learning_rate": 7.5698655730956195e-06,
      "loss": 0.0357,
      "step": 15348
    },
    {
      "epoch": 0.24302927624808018,
      "grad_norm": 0.6242709159851074,
      "learning_rate": 7.5697072375191995e-06,
      "loss": 0.1306,
      "step": 15349
    },
    {
      "epoch": 0.24304510980572225,
      "grad_norm": 1.0933104753494263,
      "learning_rate": 7.5695489019427785e-06,
      "loss": 0.4556,
      "step": 15350
    },
    {
      "epoch": 0.2430609433633643,
      "grad_norm": 0.29926741123199463,
      "learning_rate": 7.569390566366357e-06,
      "loss": 0.1345,
      "step": 15351
    },
    {
      "epoch": 0.24307677692100638,
      "grad_norm": 0.9748278260231018,
      "learning_rate": 7.569232230789937e-06,
      "loss": 0.3058,
      "step": 15352
    },
    {
      "epoch": 0.24309261047864844,
      "grad_norm": 0.642185628414154,
      "learning_rate": 7.569073895213516e-06,
      "loss": 0.276,
      "step": 15353
    },
    {
      "epoch": 0.2431084440362905,
      "grad_norm": 0.0004571382887661457,
      "learning_rate": 7.568915559637096e-06,
      "loss": 0.0,
      "step": 15354
    },
    {
      "epoch": 0.24312427759393257,
      "grad_norm": 0.35304325819015503,
      "learning_rate": 7.568757224060675e-06,
      "loss": 0.0866,
      "step": 15355
    },
    {
      "epoch": 0.24314011115157463,
      "grad_norm": 0.010702786035835743,
      "learning_rate": 7.568598888484254e-06,
      "loss": 0.0005,
      "step": 15356
    },
    {
      "epoch": 0.24315594470921673,
      "grad_norm": 0.04425795003771782,
      "learning_rate": 7.568440552907833e-06,
      "loss": 0.0025,
      "step": 15357
    },
    {
      "epoch": 0.2431717782668588,
      "grad_norm": 0.011546219699084759,
      "learning_rate": 7.568282217331413e-06,
      "loss": 0.0006,
      "step": 15358
    },
    {
      "epoch": 0.24318761182450085,
      "grad_norm": 0.487480103969574,
      "learning_rate": 7.568123881754992e-06,
      "loss": 0.0951,
      "step": 15359
    },
    {
      "epoch": 0.24320344538214292,
      "grad_norm": 0.429535835981369,
      "learning_rate": 7.567965546178572e-06,
      "loss": 0.15,
      "step": 15360
    },
    {
      "epoch": 0.24321927893978498,
      "grad_norm": 0.4714168310165405,
      "learning_rate": 7.56780721060215e-06,
      "loss": 0.2509,
      "step": 15361
    },
    {
      "epoch": 0.24323511249742705,
      "grad_norm": 0.0003579886397346854,
      "learning_rate": 7.56764887502573e-06,
      "loss": 0.0,
      "step": 15362
    },
    {
      "epoch": 0.2432509460550691,
      "grad_norm": 0.005234398413449526,
      "learning_rate": 7.567490539449309e-06,
      "loss": 0.0002,
      "step": 15363
    },
    {
      "epoch": 0.24326677961271118,
      "grad_norm": 0.49212324619293213,
      "learning_rate": 7.567332203872889e-06,
      "loss": 0.4311,
      "step": 15364
    },
    {
      "epoch": 0.24328261317035324,
      "grad_norm": 0.2616897225379944,
      "learning_rate": 7.567173868296468e-06,
      "loss": 0.0695,
      "step": 15365
    },
    {
      "epoch": 0.2432984467279953,
      "grad_norm": 0.23661921918392181,
      "learning_rate": 7.567015532720048e-06,
      "loss": 0.1692,
      "step": 15366
    },
    {
      "epoch": 0.24331428028563737,
      "grad_norm": 0.35561954975128174,
      "learning_rate": 7.566857197143626e-06,
      "loss": 0.128,
      "step": 15367
    },
    {
      "epoch": 0.24333011384327943,
      "grad_norm": 0.45569583773612976,
      "learning_rate": 7.566698861567206e-06,
      "loss": 0.1062,
      "step": 15368
    },
    {
      "epoch": 0.24334594740092153,
      "grad_norm": 0.29492250084877014,
      "learning_rate": 7.566540525990785e-06,
      "loss": 0.0906,
      "step": 15369
    },
    {
      "epoch": 0.2433617809585636,
      "grad_norm": 0.36283132433891296,
      "learning_rate": 7.566382190414365e-06,
      "loss": 0.0898,
      "step": 15370
    },
    {
      "epoch": 0.24337761451620565,
      "grad_norm": 0.0129874087870121,
      "learning_rate": 7.566223854837944e-06,
      "loss": 0.0005,
      "step": 15371
    },
    {
      "epoch": 0.24339344807384772,
      "grad_norm": 0.47038882970809937,
      "learning_rate": 7.566065519261524e-06,
      "loss": 0.0298,
      "step": 15372
    },
    {
      "epoch": 0.24340928163148978,
      "grad_norm": 0.517255425453186,
      "learning_rate": 7.5659071836851024e-06,
      "loss": 0.6049,
      "step": 15373
    },
    {
      "epoch": 0.24342511518913185,
      "grad_norm": 0.0019419316668063402,
      "learning_rate": 7.565748848108682e-06,
      "loss": 0.0,
      "step": 15374
    },
    {
      "epoch": 0.2434409487467739,
      "grad_norm": 0.318105012178421,
      "learning_rate": 7.5655905125322615e-06,
      "loss": 0.1314,
      "step": 15375
    },
    {
      "epoch": 0.24345678230441598,
      "grad_norm": 0.8741920590400696,
      "learning_rate": 7.5654321769558405e-06,
      "loss": 0.1427,
      "step": 15376
    },
    {
      "epoch": 0.24347261586205804,
      "grad_norm": 0.22657981514930725,
      "learning_rate": 7.5652738413794205e-06,
      "loss": 0.0175,
      "step": 15377
    },
    {
      "epoch": 0.2434884494197001,
      "grad_norm": 1.1140350103378296,
      "learning_rate": 7.565115505802999e-06,
      "loss": 0.0491,
      "step": 15378
    },
    {
      "epoch": 0.24350428297734217,
      "grad_norm": 0.009271460585296154,
      "learning_rate": 7.564957170226579e-06,
      "loss": 0.0005,
      "step": 15379
    },
    {
      "epoch": 0.24352011653498423,
      "grad_norm": 0.14204880595207214,
      "learning_rate": 7.564798834650158e-06,
      "loss": 0.0237,
      "step": 15380
    },
    {
      "epoch": 0.24353595009262632,
      "grad_norm": 4.844071008847095e-05,
      "learning_rate": 7.564640499073738e-06,
      "loss": 0.0,
      "step": 15381
    },
    {
      "epoch": 0.2435517836502684,
      "grad_norm": 0.00034575993777252734,
      "learning_rate": 7.564482163497317e-06,
      "loss": 0.0,
      "step": 15382
    },
    {
      "epoch": 0.24356761720791045,
      "grad_norm": 0.5217795372009277,
      "learning_rate": 7.564323827920897e-06,
      "loss": 0.1088,
      "step": 15383
    },
    {
      "epoch": 0.24358345076555252,
      "grad_norm": 0.35940980911254883,
      "learning_rate": 7.564165492344475e-06,
      "loss": 0.1044,
      "step": 15384
    },
    {
      "epoch": 0.24359928432319458,
      "grad_norm": 0.25439685583114624,
      "learning_rate": 7.564007156768055e-06,
      "loss": 0.0943,
      "step": 15385
    },
    {
      "epoch": 0.24361511788083665,
      "grad_norm": 0.045648518949747086,
      "learning_rate": 7.563848821191634e-06,
      "loss": 0.0026,
      "step": 15386
    },
    {
      "epoch": 0.2436309514384787,
      "grad_norm": 0.028094548732042313,
      "learning_rate": 7.563690485615214e-06,
      "loss": 0.001,
      "step": 15387
    },
    {
      "epoch": 0.24364678499612077,
      "grad_norm": 0.0001946346601471305,
      "learning_rate": 7.563532150038793e-06,
      "loss": 0.0,
      "step": 15388
    },
    {
      "epoch": 0.24366261855376284,
      "grad_norm": 0.28339964151382446,
      "learning_rate": 7.563373814462373e-06,
      "loss": 0.114,
      "step": 15389
    },
    {
      "epoch": 0.2436784521114049,
      "grad_norm": 0.21213045716285706,
      "learning_rate": 7.563215478885951e-06,
      "loss": 0.0592,
      "step": 15390
    },
    {
      "epoch": 0.24369428566904697,
      "grad_norm": 0.2825268507003784,
      "learning_rate": 7.563057143309531e-06,
      "loss": 0.0932,
      "step": 15391
    },
    {
      "epoch": 0.24371011922668903,
      "grad_norm": 0.47398507595062256,
      "learning_rate": 7.56289880773311e-06,
      "loss": 0.1455,
      "step": 15392
    },
    {
      "epoch": 0.24372595278433112,
      "grad_norm": 0.5406200885772705,
      "learning_rate": 7.56274047215669e-06,
      "loss": 0.1033,
      "step": 15393
    },
    {
      "epoch": 0.2437417863419732,
      "grad_norm": 0.010084476321935654,
      "learning_rate": 7.562582136580269e-06,
      "loss": 0.0004,
      "step": 15394
    },
    {
      "epoch": 0.24375761989961525,
      "grad_norm": 5.61918641324155e-05,
      "learning_rate": 7.562423801003849e-06,
      "loss": 0.0,
      "step": 15395
    },
    {
      "epoch": 0.24377345345725732,
      "grad_norm": 0.732053279876709,
      "learning_rate": 7.562265465427427e-06,
      "loss": 0.1248,
      "step": 15396
    },
    {
      "epoch": 0.24378928701489938,
      "grad_norm": 0.0006587441312149167,
      "learning_rate": 7.562107129851007e-06,
      "loss": 0.0,
      "step": 15397
    },
    {
      "epoch": 0.24380512057254144,
      "grad_norm": 0.010555431246757507,
      "learning_rate": 7.561948794274586e-06,
      "loss": 0.0004,
      "step": 15398
    },
    {
      "epoch": 0.2438209541301835,
      "grad_norm": 0.8011795282363892,
      "learning_rate": 7.561790458698165e-06,
      "loss": 0.1416,
      "step": 15399
    },
    {
      "epoch": 0.24383678768782557,
      "grad_norm": 0.43887588381767273,
      "learning_rate": 7.561632123121745e-06,
      "loss": 0.0754,
      "step": 15400
    },
    {
      "epoch": 0.24385262124546764,
      "grad_norm": 0.14895957708358765,
      "learning_rate": 7.5614737875453234e-06,
      "loss": 0.0448,
      "step": 15401
    },
    {
      "epoch": 0.2438684548031097,
      "grad_norm": 1.22600519657135,
      "learning_rate": 7.561315451968903e-06,
      "loss": 0.304,
      "step": 15402
    },
    {
      "epoch": 0.24388428836075177,
      "grad_norm": 0.4814441502094269,
      "learning_rate": 7.5611571163924825e-06,
      "loss": 0.1161,
      "step": 15403
    },
    {
      "epoch": 0.24390012191839383,
      "grad_norm": 0.03463293984532356,
      "learning_rate": 7.560998780816062e-06,
      "loss": 0.0018,
      "step": 15404
    },
    {
      "epoch": 0.24391595547603592,
      "grad_norm": 0.052208635956048965,
      "learning_rate": 7.5608404452396415e-06,
      "loss": 0.0028,
      "step": 15405
    },
    {
      "epoch": 0.243931789033678,
      "grad_norm": 0.20850728452205658,
      "learning_rate": 7.560682109663221e-06,
      "loss": 0.0689,
      "step": 15406
    },
    {
      "epoch": 0.24394762259132005,
      "grad_norm": 0.2854897975921631,
      "learning_rate": 7.5605237740868e-06,
      "loss": 0.0661,
      "step": 15407
    },
    {
      "epoch": 0.24396345614896212,
      "grad_norm": 0.4419056475162506,
      "learning_rate": 7.5603654385103795e-06,
      "loss": 0.0948,
      "step": 15408
    },
    {
      "epoch": 0.24397928970660418,
      "grad_norm": 0.022356506437063217,
      "learning_rate": 7.560207102933959e-06,
      "loss": 0.0009,
      "step": 15409
    },
    {
      "epoch": 0.24399512326424624,
      "grad_norm": 0.9407526850700378,
      "learning_rate": 7.5600487673575386e-06,
      "loss": 0.2807,
      "step": 15410
    },
    {
      "epoch": 0.2440109568218883,
      "grad_norm": 0.7284165620803833,
      "learning_rate": 7.559890431781118e-06,
      "loss": 0.4992,
      "step": 15411
    },
    {
      "epoch": 0.24402679037953037,
      "grad_norm": 0.5295896530151367,
      "learning_rate": 7.5597320962046976e-06,
      "loss": 0.0789,
      "step": 15412
    },
    {
      "epoch": 0.24404262393717244,
      "grad_norm": 0.710771918296814,
      "learning_rate": 7.559573760628276e-06,
      "loss": 0.1759,
      "step": 15413
    },
    {
      "epoch": 0.2440584574948145,
      "grad_norm": 0.00825639721006155,
      "learning_rate": 7.559415425051856e-06,
      "loss": 0.0003,
      "step": 15414
    },
    {
      "epoch": 0.24407429105245657,
      "grad_norm": 0.0271421130746603,
      "learning_rate": 7.559257089475435e-06,
      "loss": 0.0014,
      "step": 15415
    },
    {
      "epoch": 0.24409012461009863,
      "grad_norm": 0.2789791226387024,
      "learning_rate": 7.559098753899015e-06,
      "loss": 0.1078,
      "step": 15416
    },
    {
      "epoch": 0.24410595816774072,
      "grad_norm": 1.3635116815567017,
      "learning_rate": 7.558940418322594e-06,
      "loss": 0.0967,
      "step": 15417
    },
    {
      "epoch": 0.2441217917253828,
      "grad_norm": 0.019219759851694107,
      "learning_rate": 7.558782082746174e-06,
      "loss": 0.0005,
      "step": 15418
    },
    {
      "epoch": 0.24413762528302485,
      "grad_norm": 0.29701507091522217,
      "learning_rate": 7.558623747169752e-06,
      "loss": 0.1203,
      "step": 15419
    },
    {
      "epoch": 0.24415345884066691,
      "grad_norm": 0.2979215681552887,
      "learning_rate": 7.558465411593332e-06,
      "loss": 0.1413,
      "step": 15420
    },
    {
      "epoch": 0.24416929239830898,
      "grad_norm": 0.019930340349674225,
      "learning_rate": 7.558307076016911e-06,
      "loss": 0.0009,
      "step": 15421
    },
    {
      "epoch": 0.24418512595595104,
      "grad_norm": 0.4664578139781952,
      "learning_rate": 7.558148740440491e-06,
      "loss": 0.1073,
      "step": 15422
    },
    {
      "epoch": 0.2442009595135931,
      "grad_norm": 0.0503881610929966,
      "learning_rate": 7.557990404864069e-06,
      "loss": 0.0019,
      "step": 15423
    },
    {
      "epoch": 0.24421679307123517,
      "grad_norm": 0.8283489346504211,
      "learning_rate": 7.557832069287648e-06,
      "loss": 0.1619,
      "step": 15424
    },
    {
      "epoch": 0.24423262662887724,
      "grad_norm": 0.49956029653549194,
      "learning_rate": 7.557673733711228e-06,
      "loss": 0.3122,
      "step": 15425
    },
    {
      "epoch": 0.2442484601865193,
      "grad_norm": 0.09326303005218506,
      "learning_rate": 7.557515398134807e-06,
      "loss": 0.0125,
      "step": 15426
    },
    {
      "epoch": 0.24426429374416136,
      "grad_norm": 0.02997191622853279,
      "learning_rate": 7.557357062558387e-06,
      "loss": 0.0015,
      "step": 15427
    },
    {
      "epoch": 0.24428012730180343,
      "grad_norm": 0.10165618360042572,
      "learning_rate": 7.557198726981965e-06,
      "loss": 0.0087,
      "step": 15428
    },
    {
      "epoch": 0.24429596085944552,
      "grad_norm": 0.028087502345442772,
      "learning_rate": 7.557040391405545e-06,
      "loss": 0.0011,
      "step": 15429
    },
    {
      "epoch": 0.24431179441708759,
      "grad_norm": 1.379015564918518,
      "learning_rate": 7.556882055829124e-06,
      "loss": 0.0572,
      "step": 15430
    },
    {
      "epoch": 0.24432762797472965,
      "grad_norm": 0.004391881171613932,
      "learning_rate": 7.556723720252704e-06,
      "loss": 0.0001,
      "step": 15431
    },
    {
      "epoch": 0.24434346153237171,
      "grad_norm": 0.17317767441272736,
      "learning_rate": 7.556565384676283e-06,
      "loss": 0.0419,
      "step": 15432
    },
    {
      "epoch": 0.24435929509001378,
      "grad_norm": 0.38858762383461,
      "learning_rate": 7.556407049099863e-06,
      "loss": 0.1063,
      "step": 15433
    },
    {
      "epoch": 0.24437512864765584,
      "grad_norm": 0.5579537749290466,
      "learning_rate": 7.5562487135234415e-06,
      "loss": 0.0278,
      "step": 15434
    },
    {
      "epoch": 0.2443909622052979,
      "grad_norm": 0.17856337130069733,
      "learning_rate": 7.5560903779470215e-06,
      "loss": 0.0695,
      "step": 15435
    },
    {
      "epoch": 0.24440679576293997,
      "grad_norm": 0.6044495105743408,
      "learning_rate": 7.5559320423706006e-06,
      "loss": 0.3575,
      "step": 15436
    },
    {
      "epoch": 0.24442262932058204,
      "grad_norm": 0.012980091385543346,
      "learning_rate": 7.5557737067941805e-06,
      "loss": 0.0005,
      "step": 15437
    },
    {
      "epoch": 0.2444384628782241,
      "grad_norm": 0.0036658102180808783,
      "learning_rate": 7.5556153712177596e-06,
      "loss": 0.0001,
      "step": 15438
    },
    {
      "epoch": 0.24445429643586616,
      "grad_norm": 0.4528250992298126,
      "learning_rate": 7.5554570356413395e-06,
      "loss": 0.1467,
      "step": 15439
    },
    {
      "epoch": 0.24447012999350823,
      "grad_norm": 0.008487950079143047,
      "learning_rate": 7.555298700064918e-06,
      "loss": 0.0002,
      "step": 15440
    },
    {
      "epoch": 0.24448596355115032,
      "grad_norm": 0.9379879236221313,
      "learning_rate": 7.555140364488498e-06,
      "loss": 0.1035,
      "step": 15441
    },
    {
      "epoch": 0.24450179710879238,
      "grad_norm": 0.38713374733924866,
      "learning_rate": 7.554982028912077e-06,
      "loss": 0.0894,
      "step": 15442
    },
    {
      "epoch": 0.24451763066643445,
      "grad_norm": 0.8471208810806274,
      "learning_rate": 7.554823693335657e-06,
      "loss": 0.6315,
      "step": 15443
    },
    {
      "epoch": 0.2445334642240765,
      "grad_norm": 0.603883683681488,
      "learning_rate": 7.554665357759236e-06,
      "loss": 0.065,
      "step": 15444
    },
    {
      "epoch": 0.24454929778171858,
      "grad_norm": 0.04284454509615898,
      "learning_rate": 7.554507022182816e-06,
      "loss": 0.0016,
      "step": 15445
    },
    {
      "epoch": 0.24456513133936064,
      "grad_norm": 0.6487647294998169,
      "learning_rate": 7.554348686606394e-06,
      "loss": 0.2787,
      "step": 15446
    },
    {
      "epoch": 0.2445809648970027,
      "grad_norm": 0.5211018919944763,
      "learning_rate": 7.554190351029973e-06,
      "loss": 0.2628,
      "step": 15447
    },
    {
      "epoch": 0.24459679845464477,
      "grad_norm": 0.028481680899858475,
      "learning_rate": 7.554032015453553e-06,
      "loss": 0.0012,
      "step": 15448
    },
    {
      "epoch": 0.24461263201228683,
      "grad_norm": 0.741208553314209,
      "learning_rate": 7.553873679877132e-06,
      "loss": 0.4993,
      "step": 15449
    },
    {
      "epoch": 0.2446284655699289,
      "grad_norm": 0.0025589046999812126,
      "learning_rate": 7.553715344300712e-06,
      "loss": 0.0,
      "step": 15450
    },
    {
      "epoch": 0.24464429912757096,
      "grad_norm": 0.45191413164138794,
      "learning_rate": 7.55355700872429e-06,
      "loss": 0.2103,
      "step": 15451
    },
    {
      "epoch": 0.24466013268521303,
      "grad_norm": 0.3048831820487976,
      "learning_rate": 7.55339867314787e-06,
      "loss": 0.1602,
      "step": 15452
    },
    {
      "epoch": 0.24467596624285512,
      "grad_norm": 0.6504537463188171,
      "learning_rate": 7.553240337571449e-06,
      "loss": 0.0826,
      "step": 15453
    },
    {
      "epoch": 0.24469179980049718,
      "grad_norm": 0.7186468839645386,
      "learning_rate": 7.553082001995029e-06,
      "loss": 0.529,
      "step": 15454
    },
    {
      "epoch": 0.24470763335813925,
      "grad_norm": 0.0024356115609407425,
      "learning_rate": 7.552923666418608e-06,
      "loss": 0.0,
      "step": 15455
    },
    {
      "epoch": 0.2447234669157813,
      "grad_norm": 0.007106552366167307,
      "learning_rate": 7.552765330842188e-06,
      "loss": 0.0002,
      "step": 15456
    },
    {
      "epoch": 0.24473930047342338,
      "grad_norm": 0.35149624943733215,
      "learning_rate": 7.552606995265766e-06,
      "loss": 0.3286,
      "step": 15457
    },
    {
      "epoch": 0.24475513403106544,
      "grad_norm": 0.22088196873664856,
      "learning_rate": 7.552448659689346e-06,
      "loss": 0.0699,
      "step": 15458
    },
    {
      "epoch": 0.2447709675887075,
      "grad_norm": 0.92740797996521,
      "learning_rate": 7.552290324112925e-06,
      "loss": 0.928,
      "step": 15459
    },
    {
      "epoch": 0.24478680114634957,
      "grad_norm": 0.3049773871898651,
      "learning_rate": 7.552131988536505e-06,
      "loss": 0.078,
      "step": 15460
    },
    {
      "epoch": 0.24480263470399163,
      "grad_norm": 0.42464160919189453,
      "learning_rate": 7.551973652960084e-06,
      "loss": 0.0489,
      "step": 15461
    },
    {
      "epoch": 0.2448184682616337,
      "grad_norm": 0.01695985719561577,
      "learning_rate": 7.551815317383664e-06,
      "loss": 0.0006,
      "step": 15462
    },
    {
      "epoch": 0.24483430181927576,
      "grad_norm": 1.0812203884124756,
      "learning_rate": 7.5516569818072425e-06,
      "loss": 0.1735,
      "step": 15463
    },
    {
      "epoch": 0.24485013537691783,
      "grad_norm": 0.3698759973049164,
      "learning_rate": 7.551498646230822e-06,
      "loss": 0.1266,
      "step": 15464
    },
    {
      "epoch": 0.24486596893455992,
      "grad_norm": 0.3240126371383667,
      "learning_rate": 7.5513403106544015e-06,
      "loss": 0.07,
      "step": 15465
    },
    {
      "epoch": 0.24488180249220198,
      "grad_norm": 0.03338799998164177,
      "learning_rate": 7.551181975077981e-06,
      "loss": 0.0013,
      "step": 15466
    },
    {
      "epoch": 0.24489763604984405,
      "grad_norm": 0.4063488841056824,
      "learning_rate": 7.5510236395015605e-06,
      "loss": 0.1123,
      "step": 15467
    },
    {
      "epoch": 0.2449134696074861,
      "grad_norm": 0.34589025378227234,
      "learning_rate": 7.55086530392514e-06,
      "loss": 0.0324,
      "step": 15468
    },
    {
      "epoch": 0.24492930316512818,
      "grad_norm": 0.0020280194003134966,
      "learning_rate": 7.550706968348719e-06,
      "loss": 0.0001,
      "step": 15469
    },
    {
      "epoch": 0.24494513672277024,
      "grad_norm": 0.2980518043041229,
      "learning_rate": 7.5505486327722986e-06,
      "loss": 0.0771,
      "step": 15470
    },
    {
      "epoch": 0.2449609702804123,
      "grad_norm": 0.18220630288124084,
      "learning_rate": 7.550390297195878e-06,
      "loss": 0.0802,
      "step": 15471
    },
    {
      "epoch": 0.24497680383805437,
      "grad_norm": 0.18953748047351837,
      "learning_rate": 7.550231961619457e-06,
      "loss": 0.0831,
      "step": 15472
    },
    {
      "epoch": 0.24499263739569643,
      "grad_norm": 0.006528276950120926,
      "learning_rate": 7.550073626043037e-06,
      "loss": 0.0001,
      "step": 15473
    },
    {
      "epoch": 0.2450084709533385,
      "grad_norm": 0.6387022733688354,
      "learning_rate": 7.549915290466615e-06,
      "loss": 0.0394,
      "step": 15474
    },
    {
      "epoch": 0.24502430451098056,
      "grad_norm": 1.3039883375167847,
      "learning_rate": 7.549756954890195e-06,
      "loss": 0.0709,
      "step": 15475
    },
    {
      "epoch": 0.24504013806862263,
      "grad_norm": 1.0451515913009644,
      "learning_rate": 7.549598619313774e-06,
      "loss": 0.5536,
      "step": 15476
    },
    {
      "epoch": 0.24505597162626472,
      "grad_norm": 0.0017303527565672994,
      "learning_rate": 7.549440283737354e-06,
      "loss": 0.0,
      "step": 15477
    },
    {
      "epoch": 0.24507180518390678,
      "grad_norm": 0.00027782341931015253,
      "learning_rate": 7.549281948160933e-06,
      "loss": 0.0,
      "step": 15478
    },
    {
      "epoch": 0.24508763874154885,
      "grad_norm": 1.48358154296875,
      "learning_rate": 7.549123612584513e-06,
      "loss": 0.2502,
      "step": 15479
    },
    {
      "epoch": 0.2451034722991909,
      "grad_norm": 0.4354563355445862,
      "learning_rate": 7.548965277008091e-06,
      "loss": 0.2271,
      "step": 15480
    },
    {
      "epoch": 0.24511930585683298,
      "grad_norm": 0.00018872694636229426,
      "learning_rate": 7.548806941431671e-06,
      "loss": 0.0,
      "step": 15481
    },
    {
      "epoch": 0.24513513941447504,
      "grad_norm": 0.29100123047828674,
      "learning_rate": 7.54864860585525e-06,
      "loss": 0.1144,
      "step": 15482
    },
    {
      "epoch": 0.2451509729721171,
      "grad_norm": 0.5561516284942627,
      "learning_rate": 7.54849027027883e-06,
      "loss": 0.3865,
      "step": 15483
    },
    {
      "epoch": 0.24516680652975917,
      "grad_norm": 0.11532595008611679,
      "learning_rate": 7.548331934702409e-06,
      "loss": 0.0047,
      "step": 15484
    },
    {
      "epoch": 0.24518264008740123,
      "grad_norm": 0.34319788217544556,
      "learning_rate": 7.548173599125988e-06,
      "loss": 0.0805,
      "step": 15485
    },
    {
      "epoch": 0.2451984736450433,
      "grad_norm": 0.309034526348114,
      "learning_rate": 7.548015263549567e-06,
      "loss": 0.1449,
      "step": 15486
    },
    {
      "epoch": 0.24521430720268536,
      "grad_norm": 0.21446320414543152,
      "learning_rate": 7.547856927973147e-06,
      "loss": 0.0506,
      "step": 15487
    },
    {
      "epoch": 0.24523014076032743,
      "grad_norm": 0.0057320361956954,
      "learning_rate": 7.547698592396726e-06,
      "loss": 0.0002,
      "step": 15488
    },
    {
      "epoch": 0.24524597431796952,
      "grad_norm": 0.3803458511829376,
      "learning_rate": 7.547540256820306e-06,
      "loss": 0.1473,
      "step": 15489
    },
    {
      "epoch": 0.24526180787561158,
      "grad_norm": 0.5773818492889404,
      "learning_rate": 7.547381921243884e-06,
      "loss": 0.3147,
      "step": 15490
    },
    {
      "epoch": 0.24527764143325365,
      "grad_norm": 0.1509738713502884,
      "learning_rate": 7.547223585667464e-06,
      "loss": 0.0663,
      "step": 15491
    },
    {
      "epoch": 0.2452934749908957,
      "grad_norm": 0.042285218834877014,
      "learning_rate": 7.547065250091043e-06,
      "loss": 0.0015,
      "step": 15492
    },
    {
      "epoch": 0.24530930854853777,
      "grad_norm": 0.0006726835272274911,
      "learning_rate": 7.546906914514623e-06,
      "loss": 0.0,
      "step": 15493
    },
    {
      "epoch": 0.24532514210617984,
      "grad_norm": 0.9819244146347046,
      "learning_rate": 7.546748578938202e-06,
      "loss": 0.9822,
      "step": 15494
    },
    {
      "epoch": 0.2453409756638219,
      "grad_norm": 0.562061071395874,
      "learning_rate": 7.546590243361781e-06,
      "loss": 0.1363,
      "step": 15495
    },
    {
      "epoch": 0.24535680922146397,
      "grad_norm": 0.0004118443466722965,
      "learning_rate": 7.5464319077853606e-06,
      "loss": 0.0,
      "step": 15496
    },
    {
      "epoch": 0.24537264277910603,
      "grad_norm": 0.00796645600348711,
      "learning_rate": 7.54627357220894e-06,
      "loss": 0.0003,
      "step": 15497
    },
    {
      "epoch": 0.2453884763367481,
      "grad_norm": 0.8365514874458313,
      "learning_rate": 7.54611523663252e-06,
      "loss": 0.5277,
      "step": 15498
    },
    {
      "epoch": 0.24540430989439016,
      "grad_norm": 0.5829735398292542,
      "learning_rate": 7.545956901056099e-06,
      "loss": 0.0843,
      "step": 15499
    },
    {
      "epoch": 0.24542014345203222,
      "grad_norm": 0.9242963790893555,
      "learning_rate": 7.545798565479679e-06,
      "loss": 0.658,
      "step": 15500
    },
    {
      "epoch": 0.24543597700967432,
      "grad_norm": 5.649621963500977,
      "learning_rate": 7.545640229903257e-06,
      "loss": 0.3435,
      "step": 15501
    },
    {
      "epoch": 0.24545181056731638,
      "grad_norm": 4.7678367991466075e-05,
      "learning_rate": 7.545481894326837e-06,
      "loss": 0.0,
      "step": 15502
    },
    {
      "epoch": 0.24546764412495845,
      "grad_norm": 0.8694224953651428,
      "learning_rate": 7.545323558750416e-06,
      "loss": 0.9319,
      "step": 15503
    },
    {
      "epoch": 0.2454834776826005,
      "grad_norm": 0.0004990413435734808,
      "learning_rate": 7.545165223173996e-06,
      "loss": 0.0,
      "step": 15504
    },
    {
      "epoch": 0.24549931124024257,
      "grad_norm": 0.45414280891418457,
      "learning_rate": 7.545006887597575e-06,
      "loss": 0.291,
      "step": 15505
    },
    {
      "epoch": 0.24551514479788464,
      "grad_norm": 0.2620285153388977,
      "learning_rate": 7.544848552021155e-06,
      "loss": 0.0807,
      "step": 15506
    },
    {
      "epoch": 0.2455309783555267,
      "grad_norm": 0.43834346532821655,
      "learning_rate": 7.544690216444733e-06,
      "loss": 0.0383,
      "step": 15507
    },
    {
      "epoch": 0.24554681191316877,
      "grad_norm": 0.00657074386253953,
      "learning_rate": 7.544531880868313e-06,
      "loss": 0.0001,
      "step": 15508
    },
    {
      "epoch": 0.24556264547081083,
      "grad_norm": 0.4019921123981476,
      "learning_rate": 7.544373545291892e-06,
      "loss": 0.0771,
      "step": 15509
    },
    {
      "epoch": 0.2455784790284529,
      "grad_norm": 0.26230528950691223,
      "learning_rate": 7.544215209715472e-06,
      "loss": 0.0801,
      "step": 15510
    },
    {
      "epoch": 0.24559431258609496,
      "grad_norm": 0.5390259027481079,
      "learning_rate": 7.544056874139051e-06,
      "loss": 0.3389,
      "step": 15511
    },
    {
      "epoch": 0.24561014614373702,
      "grad_norm": 0.014643477275967598,
      "learning_rate": 7.543898538562631e-06,
      "loss": 0.0006,
      "step": 15512
    },
    {
      "epoch": 0.24562597970137912,
      "grad_norm": 0.5458020567893982,
      "learning_rate": 7.543740202986209e-06,
      "loss": 0.0664,
      "step": 15513
    },
    {
      "epoch": 0.24564181325902118,
      "grad_norm": 0.5463774800300598,
      "learning_rate": 7.543581867409789e-06,
      "loss": 0.1708,
      "step": 15514
    },
    {
      "epoch": 0.24565764681666324,
      "grad_norm": 0.2986021339893341,
      "learning_rate": 7.543423531833368e-06,
      "loss": 0.0558,
      "step": 15515
    },
    {
      "epoch": 0.2456734803743053,
      "grad_norm": 0.7218273878097534,
      "learning_rate": 7.543265196256948e-06,
      "loss": 0.5313,
      "step": 15516
    },
    {
      "epoch": 0.24568931393194737,
      "grad_norm": 0.0004768783110193908,
      "learning_rate": 7.543106860680527e-06,
      "loss": 0.0,
      "step": 15517
    },
    {
      "epoch": 0.24570514748958944,
      "grad_norm": 1.021552562713623,
      "learning_rate": 7.542948525104107e-06,
      "loss": 1.5484,
      "step": 15518
    },
    {
      "epoch": 0.2457209810472315,
      "grad_norm": 0.17241910099983215,
      "learning_rate": 7.542790189527685e-06,
      "loss": 0.0318,
      "step": 15519
    },
    {
      "epoch": 0.24573681460487357,
      "grad_norm": 0.5308824181556702,
      "learning_rate": 7.542631853951264e-06,
      "loss": 0.1278,
      "step": 15520
    },
    {
      "epoch": 0.24575264816251563,
      "grad_norm": 0.27975377440452576,
      "learning_rate": 7.542473518374844e-06,
      "loss": 0.0777,
      "step": 15521
    },
    {
      "epoch": 0.2457684817201577,
      "grad_norm": 0.011834771372377872,
      "learning_rate": 7.542315182798423e-06,
      "loss": 0.0004,
      "step": 15522
    },
    {
      "epoch": 0.24578431527779976,
      "grad_norm": 0.3230064809322357,
      "learning_rate": 7.542156847222003e-06,
      "loss": 0.099,
      "step": 15523
    },
    {
      "epoch": 0.24580014883544182,
      "grad_norm": 0.4597656726837158,
      "learning_rate": 7.5419985116455816e-06,
      "loss": 0.1219,
      "step": 15524
    },
    {
      "epoch": 0.24581598239308391,
      "grad_norm": 0.023263651877641678,
      "learning_rate": 7.5418401760691615e-06,
      "loss": 0.0012,
      "step": 15525
    },
    {
      "epoch": 0.24583181595072598,
      "grad_norm": 0.4064318835735321,
      "learning_rate": 7.541681840492741e-06,
      "loss": 0.0591,
      "step": 15526
    },
    {
      "epoch": 0.24584764950836804,
      "grad_norm": 0.12582765519618988,
      "learning_rate": 7.5415235049163205e-06,
      "loss": 0.0051,
      "step": 15527
    },
    {
      "epoch": 0.2458634830660101,
      "grad_norm": 0.16429327428340912,
      "learning_rate": 7.5413651693399e-06,
      "loss": 0.013,
      "step": 15528
    },
    {
      "epoch": 0.24587931662365217,
      "grad_norm": 0.6564399600028992,
      "learning_rate": 7.5412068337634795e-06,
      "loss": 0.494,
      "step": 15529
    },
    {
      "epoch": 0.24589515018129424,
      "grad_norm": 0.30237331986427307,
      "learning_rate": 7.541048498187058e-06,
      "loss": 0.0781,
      "step": 15530
    },
    {
      "epoch": 0.2459109837389363,
      "grad_norm": 0.04234938323497772,
      "learning_rate": 7.540890162610638e-06,
      "loss": 0.0023,
      "step": 15531
    },
    {
      "epoch": 0.24592681729657836,
      "grad_norm": 0.48343098163604736,
      "learning_rate": 7.540731827034217e-06,
      "loss": 0.114,
      "step": 15532
    },
    {
      "epoch": 0.24594265085422043,
      "grad_norm": 0.4373273551464081,
      "learning_rate": 7.540573491457797e-06,
      "loss": 0.1703,
      "step": 15533
    },
    {
      "epoch": 0.2459584844118625,
      "grad_norm": 0.1922597885131836,
      "learning_rate": 7.540415155881376e-06,
      "loss": 0.0765,
      "step": 15534
    },
    {
      "epoch": 0.24597431796950456,
      "grad_norm": 0.47453948855400085,
      "learning_rate": 7.540256820304956e-06,
      "loss": 0.3167,
      "step": 15535
    },
    {
      "epoch": 0.24599015152714662,
      "grad_norm": 0.5153284072875977,
      "learning_rate": 7.540098484728534e-06,
      "loss": 0.0664,
      "step": 15536
    },
    {
      "epoch": 0.24600598508478871,
      "grad_norm": 0.2145318239927292,
      "learning_rate": 7.539940149152114e-06,
      "loss": 0.0051,
      "step": 15537
    },
    {
      "epoch": 0.24602181864243078,
      "grad_norm": 0.5775745511054993,
      "learning_rate": 7.539781813575693e-06,
      "loss": 0.3224,
      "step": 15538
    },
    {
      "epoch": 0.24603765220007284,
      "grad_norm": 0.31023070216178894,
      "learning_rate": 7.539623477999273e-06,
      "loss": 0.0641,
      "step": 15539
    },
    {
      "epoch": 0.2460534857577149,
      "grad_norm": 0.0001913694868562743,
      "learning_rate": 7.539465142422852e-06,
      "loss": 0.0,
      "step": 15540
    },
    {
      "epoch": 0.24606931931535697,
      "grad_norm": 0.0001307325146626681,
      "learning_rate": 7.539306806846432e-06,
      "loss": 0.0,
      "step": 15541
    },
    {
      "epoch": 0.24608515287299904,
      "grad_norm": 0.650153636932373,
      "learning_rate": 7.53914847127001e-06,
      "loss": 0.0745,
      "step": 15542
    },
    {
      "epoch": 0.2461009864306411,
      "grad_norm": 0.7843583226203918,
      "learning_rate": 7.538990135693589e-06,
      "loss": 0.0584,
      "step": 15543
    },
    {
      "epoch": 0.24611681998828316,
      "grad_norm": 0.45708075165748596,
      "learning_rate": 7.538831800117169e-06,
      "loss": 0.3186,
      "step": 15544
    },
    {
      "epoch": 0.24613265354592523,
      "grad_norm": 4.9533617129782215e-05,
      "learning_rate": 7.538673464540748e-06,
      "loss": 0.0,
      "step": 15545
    },
    {
      "epoch": 0.2461484871035673,
      "grad_norm": 0.553082287311554,
      "learning_rate": 7.538515128964328e-06,
      "loss": 0.1528,
      "step": 15546
    },
    {
      "epoch": 0.24616432066120936,
      "grad_norm": 0.016598589718341827,
      "learning_rate": 7.538356793387906e-06,
      "loss": 0.001,
      "step": 15547
    },
    {
      "epoch": 0.24618015421885142,
      "grad_norm": 0.005276098847389221,
      "learning_rate": 7.538198457811486e-06,
      "loss": 0.0002,
      "step": 15548
    },
    {
      "epoch": 0.2461959877764935,
      "grad_norm": 0.3242345452308655,
      "learning_rate": 7.538040122235065e-06,
      "loss": 0.2752,
      "step": 15549
    },
    {
      "epoch": 0.24621182133413558,
      "grad_norm": 0.005254118703305721,
      "learning_rate": 7.537881786658645e-06,
      "loss": 0.0002,
      "step": 15550
    },
    {
      "epoch": 0.24622765489177764,
      "grad_norm": 0.16558285057544708,
      "learning_rate": 7.5377234510822235e-06,
      "loss": 0.0753,
      "step": 15551
    },
    {
      "epoch": 0.2462434884494197,
      "grad_norm": 0.1814071238040924,
      "learning_rate": 7.5375651155058034e-06,
      "loss": 0.0606,
      "step": 15552
    },
    {
      "epoch": 0.24625932200706177,
      "grad_norm": 0.7548220157623291,
      "learning_rate": 7.5374067799293825e-06,
      "loss": 0.8473,
      "step": 15553
    },
    {
      "epoch": 0.24627515556470383,
      "grad_norm": 0.32262444496154785,
      "learning_rate": 7.5372484443529624e-06,
      "loss": 0.0989,
      "step": 15554
    },
    {
      "epoch": 0.2462909891223459,
      "grad_norm": 0.252788782119751,
      "learning_rate": 7.5370901087765415e-06,
      "loss": 0.0449,
      "step": 15555
    },
    {
      "epoch": 0.24630682267998796,
      "grad_norm": 0.1810382753610611,
      "learning_rate": 7.5369317732001214e-06,
      "loss": 0.0882,
      "step": 15556
    },
    {
      "epoch": 0.24632265623763003,
      "grad_norm": 0.015713796019554138,
      "learning_rate": 7.5367734376237e-06,
      "loss": 0.0006,
      "step": 15557
    },
    {
      "epoch": 0.2463384897952721,
      "grad_norm": 0.3630671203136444,
      "learning_rate": 7.53661510204728e-06,
      "loss": 0.0952,
      "step": 15558
    },
    {
      "epoch": 0.24635432335291416,
      "grad_norm": 0.27415767312049866,
      "learning_rate": 7.536456766470859e-06,
      "loss": 0.1063,
      "step": 15559
    },
    {
      "epoch": 0.24637015691055622,
      "grad_norm": 0.29601916670799255,
      "learning_rate": 7.536298430894439e-06,
      "loss": 0.0263,
      "step": 15560
    },
    {
      "epoch": 0.2463859904681983,
      "grad_norm": 0.008157899603247643,
      "learning_rate": 7.536140095318018e-06,
      "loss": 0.0003,
      "step": 15561
    },
    {
      "epoch": 0.24640182402584038,
      "grad_norm": 1.11461341381073,
      "learning_rate": 7.535981759741598e-06,
      "loss": 0.2975,
      "step": 15562
    },
    {
      "epoch": 0.24641765758348244,
      "grad_norm": 2.218867540359497,
      "learning_rate": 7.535823424165176e-06,
      "loss": 0.108,
      "step": 15563
    },
    {
      "epoch": 0.2464334911411245,
      "grad_norm": 0.6266281604766846,
      "learning_rate": 7.535665088588756e-06,
      "loss": 0.1296,
      "step": 15564
    },
    {
      "epoch": 0.24644932469876657,
      "grad_norm": 0.14957115054130554,
      "learning_rate": 7.535506753012335e-06,
      "loss": 0.0281,
      "step": 15565
    },
    {
      "epoch": 0.24646515825640863,
      "grad_norm": 0.39590126276016235,
      "learning_rate": 7.535348417435915e-06,
      "loss": 0.2822,
      "step": 15566
    },
    {
      "epoch": 0.2464809918140507,
      "grad_norm": 0.005522942170500755,
      "learning_rate": 7.535190081859494e-06,
      "loss": 0.0002,
      "step": 15567
    },
    {
      "epoch": 0.24649682537169276,
      "grad_norm": 0.2414551079273224,
      "learning_rate": 7.535031746283072e-06,
      "loss": 0.0024,
      "step": 15568
    },
    {
      "epoch": 0.24651265892933483,
      "grad_norm": 0.23941285908222198,
      "learning_rate": 7.534873410706652e-06,
      "loss": 0.1146,
      "step": 15569
    },
    {
      "epoch": 0.2465284924869769,
      "grad_norm": 0.33252549171447754,
      "learning_rate": 7.534715075130231e-06,
      "loss": 0.1158,
      "step": 15570
    },
    {
      "epoch": 0.24654432604461896,
      "grad_norm": 0.42761242389678955,
      "learning_rate": 7.534556739553811e-06,
      "loss": 0.2778,
      "step": 15571
    },
    {
      "epoch": 0.24656015960226102,
      "grad_norm": 0.6108525991439819,
      "learning_rate": 7.53439840397739e-06,
      "loss": 0.0083,
      "step": 15572
    },
    {
      "epoch": 0.2465759931599031,
      "grad_norm": 0.12519511580467224,
      "learning_rate": 7.53424006840097e-06,
      "loss": 0.0301,
      "step": 15573
    },
    {
      "epoch": 0.24659182671754518,
      "grad_norm": 0.32423487305641174,
      "learning_rate": 7.534081732824548e-06,
      "loss": 0.1155,
      "step": 15574
    },
    {
      "epoch": 0.24660766027518724,
      "grad_norm": 0.7882195115089417,
      "learning_rate": 7.533923397248128e-06,
      "loss": 0.4059,
      "step": 15575
    },
    {
      "epoch": 0.2466234938328293,
      "grad_norm": 0.0036136440467089415,
      "learning_rate": 7.533765061671707e-06,
      "loss": 0.0001,
      "step": 15576
    },
    {
      "epoch": 0.24663932739047137,
      "grad_norm": 0.3020310401916504,
      "learning_rate": 7.533606726095287e-06,
      "loss": 0.0085,
      "step": 15577
    },
    {
      "epoch": 0.24665516094811343,
      "grad_norm": 0.645736575126648,
      "learning_rate": 7.533448390518866e-06,
      "loss": 0.162,
      "step": 15578
    },
    {
      "epoch": 0.2466709945057555,
      "grad_norm": 0.5675927996635437,
      "learning_rate": 7.533290054942446e-06,
      "loss": 0.059,
      "step": 15579
    },
    {
      "epoch": 0.24668682806339756,
      "grad_norm": 0.3935781419277191,
      "learning_rate": 7.5331317193660244e-06,
      "loss": 0.0182,
      "step": 15580
    },
    {
      "epoch": 0.24670266162103963,
      "grad_norm": 1.2106865644454956,
      "learning_rate": 7.532973383789604e-06,
      "loss": 0.2244,
      "step": 15581
    },
    {
      "epoch": 0.2467184951786817,
      "grad_norm": 0.44770878553390503,
      "learning_rate": 7.5328150482131834e-06,
      "loss": 0.1897,
      "step": 15582
    },
    {
      "epoch": 0.24673432873632375,
      "grad_norm": 0.01002439670264721,
      "learning_rate": 7.532656712636763e-06,
      "loss": 0.0004,
      "step": 15583
    },
    {
      "epoch": 0.24675016229396582,
      "grad_norm": 0.016398198902606964,
      "learning_rate": 7.5324983770603424e-06,
      "loss": 0.0008,
      "step": 15584
    },
    {
      "epoch": 0.2467659958516079,
      "grad_norm": 0.8008595705032349,
      "learning_rate": 7.532340041483922e-06,
      "loss": 0.2104,
      "step": 15585
    },
    {
      "epoch": 0.24678182940924998,
      "grad_norm": 0.39649417996406555,
      "learning_rate": 7.532181705907501e-06,
      "loss": 0.1078,
      "step": 15586
    },
    {
      "epoch": 0.24679766296689204,
      "grad_norm": 0.14971576631069183,
      "learning_rate": 7.5320233703310805e-06,
      "loss": 0.0561,
      "step": 15587
    },
    {
      "epoch": 0.2468134965245341,
      "grad_norm": 0.03366781026124954,
      "learning_rate": 7.53186503475466e-06,
      "loss": 0.0016,
      "step": 15588
    },
    {
      "epoch": 0.24682933008217617,
      "grad_norm": 1.2200379371643066,
      "learning_rate": 7.5317066991782395e-06,
      "loss": 0.9024,
      "step": 15589
    },
    {
      "epoch": 0.24684516363981823,
      "grad_norm": 0.6106616854667664,
      "learning_rate": 7.531548363601819e-06,
      "loss": 0.3027,
      "step": 15590
    },
    {
      "epoch": 0.2468609971974603,
      "grad_norm": 3.0731654167175293,
      "learning_rate": 7.531390028025397e-06,
      "loss": 0.079,
      "step": 15591
    },
    {
      "epoch": 0.24687683075510236,
      "grad_norm": 0.16515791416168213,
      "learning_rate": 7.531231692448977e-06,
      "loss": 0.0438,
      "step": 15592
    },
    {
      "epoch": 0.24689266431274443,
      "grad_norm": 0.47285112738609314,
      "learning_rate": 7.531073356872556e-06,
      "loss": 0.0967,
      "step": 15593
    },
    {
      "epoch": 0.2469084978703865,
      "grad_norm": 0.296286404132843,
      "learning_rate": 7.530915021296136e-06,
      "loss": 0.0756,
      "step": 15594
    },
    {
      "epoch": 0.24692433142802855,
      "grad_norm": 0.19941772520542145,
      "learning_rate": 7.530756685719715e-06,
      "loss": 0.0587,
      "step": 15595
    },
    {
      "epoch": 0.24694016498567062,
      "grad_norm": 0.07967333495616913,
      "learning_rate": 7.530598350143295e-06,
      "loss": 0.0051,
      "step": 15596
    },
    {
      "epoch": 0.2469559985433127,
      "grad_norm": 0.2992739975452423,
      "learning_rate": 7.530440014566873e-06,
      "loss": 0.0173,
      "step": 15597
    },
    {
      "epoch": 0.24697183210095477,
      "grad_norm": 0.7587713003158569,
      "learning_rate": 7.530281678990453e-06,
      "loss": 0.6003,
      "step": 15598
    },
    {
      "epoch": 0.24698766565859684,
      "grad_norm": 0.010617563501000404,
      "learning_rate": 7.530123343414032e-06,
      "loss": 0.0003,
      "step": 15599
    },
    {
      "epoch": 0.2470034992162389,
      "grad_norm": 0.01308347750455141,
      "learning_rate": 7.529965007837612e-06,
      "loss": 0.0007,
      "step": 15600
    },
    {
      "epoch": 0.24701933277388097,
      "grad_norm": 0.8220855593681335,
      "learning_rate": 7.529806672261191e-06,
      "loss": 0.1281,
      "step": 15601
    },
    {
      "epoch": 0.24703516633152303,
      "grad_norm": 0.6841533184051514,
      "learning_rate": 7.529648336684771e-06,
      "loss": 0.0233,
      "step": 15602
    },
    {
      "epoch": 0.2470509998891651,
      "grad_norm": 0.5441100001335144,
      "learning_rate": 7.529490001108349e-06,
      "loss": 0.1202,
      "step": 15603
    },
    {
      "epoch": 0.24706683344680716,
      "grad_norm": 0.3420671224594116,
      "learning_rate": 7.529331665531929e-06,
      "loss": 0.0071,
      "step": 15604
    },
    {
      "epoch": 0.24708266700444922,
      "grad_norm": 0.3894125521183014,
      "learning_rate": 7.529173329955508e-06,
      "loss": 0.0919,
      "step": 15605
    },
    {
      "epoch": 0.2470985005620913,
      "grad_norm": 0.032017577439546585,
      "learning_rate": 7.529014994379088e-06,
      "loss": 0.001,
      "step": 15606
    },
    {
      "epoch": 0.24711433411973335,
      "grad_norm": 0.0037323301658034325,
      "learning_rate": 7.528856658802667e-06,
      "loss": 0.0001,
      "step": 15607
    },
    {
      "epoch": 0.24713016767737542,
      "grad_norm": 0.46838945150375366,
      "learning_rate": 7.528698323226247e-06,
      "loss": 0.2806,
      "step": 15608
    },
    {
      "epoch": 0.2471460012350175,
      "grad_norm": 0.24955567717552185,
      "learning_rate": 7.528539987649825e-06,
      "loss": 0.1107,
      "step": 15609
    },
    {
      "epoch": 0.24716183479265957,
      "grad_norm": 0.2100294828414917,
      "learning_rate": 7.528381652073405e-06,
      "loss": 0.0629,
      "step": 15610
    },
    {
      "epoch": 0.24717766835030164,
      "grad_norm": 0.5818883180618286,
      "learning_rate": 7.528223316496984e-06,
      "loss": 0.4802,
      "step": 15611
    },
    {
      "epoch": 0.2471935019079437,
      "grad_norm": 0.1941348761320114,
      "learning_rate": 7.528064980920564e-06,
      "loss": 0.0582,
      "step": 15612
    },
    {
      "epoch": 0.24720933546558577,
      "grad_norm": 0.16749684512615204,
      "learning_rate": 7.527906645344143e-06,
      "loss": 0.0333,
      "step": 15613
    },
    {
      "epoch": 0.24722516902322783,
      "grad_norm": 0.5534342527389526,
      "learning_rate": 7.5277483097677225e-06,
      "loss": 0.2194,
      "step": 15614
    },
    {
      "epoch": 0.2472410025808699,
      "grad_norm": 0.2387421578168869,
      "learning_rate": 7.5275899741913015e-06,
      "loss": 0.0639,
      "step": 15615
    },
    {
      "epoch": 0.24725683613851196,
      "grad_norm": 0.16766054928302765,
      "learning_rate": 7.527431638614881e-06,
      "loss": 0.0537,
      "step": 15616
    },
    {
      "epoch": 0.24727266969615402,
      "grad_norm": 0.00010150019807042554,
      "learning_rate": 7.5272733030384605e-06,
      "loss": 0.0,
      "step": 15617
    },
    {
      "epoch": 0.2472885032537961,
      "grad_norm": 0.4904949367046356,
      "learning_rate": 7.527114967462039e-06,
      "loss": 0.0559,
      "step": 15618
    },
    {
      "epoch": 0.24730433681143815,
      "grad_norm": 0.561448872089386,
      "learning_rate": 7.526956631885619e-06,
      "loss": 0.6579,
      "step": 15619
    },
    {
      "epoch": 0.24732017036908022,
      "grad_norm": 0.40097394585609436,
      "learning_rate": 7.526798296309198e-06,
      "loss": 0.1582,
      "step": 15620
    },
    {
      "epoch": 0.2473360039267223,
      "grad_norm": 0.4720502197742462,
      "learning_rate": 7.526639960732778e-06,
      "loss": 0.0708,
      "step": 15621
    },
    {
      "epoch": 0.24735183748436437,
      "grad_norm": 0.23580700159072876,
      "learning_rate": 7.526481625156357e-06,
      "loss": 0.051,
      "step": 15622
    },
    {
      "epoch": 0.24736767104200644,
      "grad_norm": 0.6442689299583435,
      "learning_rate": 7.526323289579937e-06,
      "loss": 0.3259,
      "step": 15623
    },
    {
      "epoch": 0.2473835045996485,
      "grad_norm": 0.4741147756576538,
      "learning_rate": 7.526164954003515e-06,
      "loss": 0.5102,
      "step": 15624
    },
    {
      "epoch": 0.24739933815729057,
      "grad_norm": 0.1273019164800644,
      "learning_rate": 7.526006618427095e-06,
      "loss": 0.0073,
      "step": 15625
    },
    {
      "epoch": 0.24741517171493263,
      "grad_norm": 0.2238531857728958,
      "learning_rate": 7.525848282850674e-06,
      "loss": 0.0793,
      "step": 15626
    },
    {
      "epoch": 0.2474310052725747,
      "grad_norm": 0.48253366351127625,
      "learning_rate": 7.525689947274254e-06,
      "loss": 0.3095,
      "step": 15627
    },
    {
      "epoch": 0.24744683883021676,
      "grad_norm": 0.22736285626888275,
      "learning_rate": 7.525531611697833e-06,
      "loss": 0.0348,
      "step": 15628
    },
    {
      "epoch": 0.24746267238785882,
      "grad_norm": 0.4958683252334595,
      "learning_rate": 7.525373276121413e-06,
      "loss": 0.2519,
      "step": 15629
    },
    {
      "epoch": 0.2474785059455009,
      "grad_norm": 0.43014276027679443,
      "learning_rate": 7.525214940544991e-06,
      "loss": 0.4778,
      "step": 15630
    },
    {
      "epoch": 0.24749433950314295,
      "grad_norm": 0.8530629277229309,
      "learning_rate": 7.525056604968571e-06,
      "loss": 0.3596,
      "step": 15631
    },
    {
      "epoch": 0.24751017306078502,
      "grad_norm": 0.0001463412627344951,
      "learning_rate": 7.52489826939215e-06,
      "loss": 0.0,
      "step": 15632
    },
    {
      "epoch": 0.2475260066184271,
      "grad_norm": 2.6031973902718164e-05,
      "learning_rate": 7.52473993381573e-06,
      "loss": 0.0,
      "step": 15633
    },
    {
      "epoch": 0.24754184017606917,
      "grad_norm": 0.7847382426261902,
      "learning_rate": 7.524581598239309e-06,
      "loss": 0.2698,
      "step": 15634
    },
    {
      "epoch": 0.24755767373371124,
      "grad_norm": 1.0629292726516724,
      "learning_rate": 7.524423262662889e-06,
      "loss": 0.024,
      "step": 15635
    },
    {
      "epoch": 0.2475735072913533,
      "grad_norm": 0.20715682208538055,
      "learning_rate": 7.524264927086467e-06,
      "loss": 0.0503,
      "step": 15636
    },
    {
      "epoch": 0.24758934084899537,
      "grad_norm": 0.28516730666160583,
      "learning_rate": 7.524106591510047e-06,
      "loss": 0.0645,
      "step": 15637
    },
    {
      "epoch": 0.24760517440663743,
      "grad_norm": 0.2519536018371582,
      "learning_rate": 7.523948255933626e-06,
      "loss": 0.0294,
      "step": 15638
    },
    {
      "epoch": 0.2476210079642795,
      "grad_norm": 0.6153952479362488,
      "learning_rate": 7.523789920357205e-06,
      "loss": 0.2924,
      "step": 15639
    },
    {
      "epoch": 0.24763684152192156,
      "grad_norm": 0.8037850856781006,
      "learning_rate": 7.523631584780785e-06,
      "loss": 0.0651,
      "step": 15640
    },
    {
      "epoch": 0.24765267507956362,
      "grad_norm": 0.3543165326118469,
      "learning_rate": 7.5234732492043635e-06,
      "loss": 0.119,
      "step": 15641
    },
    {
      "epoch": 0.2476685086372057,
      "grad_norm": 0.16424570977687836,
      "learning_rate": 7.5233149136279435e-06,
      "loss": 0.0512,
      "step": 15642
    },
    {
      "epoch": 0.24768434219484775,
      "grad_norm": 0.0013033339055255055,
      "learning_rate": 7.5231565780515225e-06,
      "loss": 0.0,
      "step": 15643
    },
    {
      "epoch": 0.24770017575248982,
      "grad_norm": 0.1499047577381134,
      "learning_rate": 7.5229982424751025e-06,
      "loss": 0.0416,
      "step": 15644
    },
    {
      "epoch": 0.2477160093101319,
      "grad_norm": 0.14310906827449799,
      "learning_rate": 7.5228399068986815e-06,
      "loss": 0.0292,
      "step": 15645
    },
    {
      "epoch": 0.24773184286777397,
      "grad_norm": 0.25249072909355164,
      "learning_rate": 7.5226815713222615e-06,
      "loss": 0.1057,
      "step": 15646
    },
    {
      "epoch": 0.24774767642541604,
      "grad_norm": 0.515324592590332,
      "learning_rate": 7.52252323574584e-06,
      "loss": 0.0801,
      "step": 15647
    },
    {
      "epoch": 0.2477635099830581,
      "grad_norm": 0.2309560775756836,
      "learning_rate": 7.52236490016942e-06,
      "loss": 0.0659,
      "step": 15648
    },
    {
      "epoch": 0.24777934354070016,
      "grad_norm": 0.00010053821461042389,
      "learning_rate": 7.522206564592999e-06,
      "loss": 0.0,
      "step": 15649
    },
    {
      "epoch": 0.24779517709834223,
      "grad_norm": 0.4650527834892273,
      "learning_rate": 7.522048229016579e-06,
      "loss": 0.2433,
      "step": 15650
    },
    {
      "epoch": 0.2478110106559843,
      "grad_norm": 0.49343544244766235,
      "learning_rate": 7.521889893440158e-06,
      "loss": 0.1921,
      "step": 15651
    },
    {
      "epoch": 0.24782684421362636,
      "grad_norm": 0.15423238277435303,
      "learning_rate": 7.521731557863738e-06,
      "loss": 0.0401,
      "step": 15652
    },
    {
      "epoch": 0.24784267777126842,
      "grad_norm": 0.00021546889911405742,
      "learning_rate": 7.521573222287316e-06,
      "loss": 0.0,
      "step": 15653
    },
    {
      "epoch": 0.24785851132891049,
      "grad_norm": 0.01747545413672924,
      "learning_rate": 7.521414886710896e-06,
      "loss": 0.0005,
      "step": 15654
    },
    {
      "epoch": 0.24787434488655255,
      "grad_norm": 0.004430367611348629,
      "learning_rate": 7.521256551134475e-06,
      "loss": 0.0002,
      "step": 15655
    },
    {
      "epoch": 0.24789017844419461,
      "grad_norm": 0.2888883948326111,
      "learning_rate": 7.521098215558055e-06,
      "loss": 0.0964,
      "step": 15656
    },
    {
      "epoch": 0.2479060120018367,
      "grad_norm": 0.3387695252895355,
      "learning_rate": 7.520939879981634e-06,
      "loss": 0.0699,
      "step": 15657
    },
    {
      "epoch": 0.24792184555947877,
      "grad_norm": 0.0007611030014231801,
      "learning_rate": 7.520781544405214e-06,
      "loss": 0.0,
      "step": 15658
    },
    {
      "epoch": 0.24793767911712083,
      "grad_norm": 0.1355755776166916,
      "learning_rate": 7.520623208828792e-06,
      "loss": 0.0589,
      "step": 15659
    },
    {
      "epoch": 0.2479535126747629,
      "grad_norm": 0.12021978199481964,
      "learning_rate": 7.520464873252372e-06,
      "loss": 0.024,
      "step": 15660
    },
    {
      "epoch": 0.24796934623240496,
      "grad_norm": 0.4858259856700897,
      "learning_rate": 7.520306537675951e-06,
      "loss": 0.1974,
      "step": 15661
    },
    {
      "epoch": 0.24798517979004703,
      "grad_norm": 0.7672137022018433,
      "learning_rate": 7.520148202099531e-06,
      "loss": 0.666,
      "step": 15662
    },
    {
      "epoch": 0.2480010133476891,
      "grad_norm": 0.38913029432296753,
      "learning_rate": 7.51998986652311e-06,
      "loss": 0.081,
      "step": 15663
    },
    {
      "epoch": 0.24801684690533116,
      "grad_norm": 0.2106013298034668,
      "learning_rate": 7.519831530946688e-06,
      "loss": 0.1033,
      "step": 15664
    },
    {
      "epoch": 0.24803268046297322,
      "grad_norm": 0.6077702045440674,
      "learning_rate": 7.519673195370268e-06,
      "loss": 0.1974,
      "step": 15665
    },
    {
      "epoch": 0.24804851402061528,
      "grad_norm": 1.07992684841156,
      "learning_rate": 7.519514859793847e-06,
      "loss": 0.5794,
      "step": 15666
    },
    {
      "epoch": 0.24806434757825735,
      "grad_norm": 0.1459931582212448,
      "learning_rate": 7.519356524217427e-06,
      "loss": 0.0209,
      "step": 15667
    },
    {
      "epoch": 0.2480801811358994,
      "grad_norm": 0.698585569858551,
      "learning_rate": 7.519198188641006e-06,
      "loss": 0.3635,
      "step": 15668
    },
    {
      "epoch": 0.2480960146935415,
      "grad_norm": 0.2603079378604889,
      "learning_rate": 7.519039853064586e-06,
      "loss": 0.0797,
      "step": 15669
    },
    {
      "epoch": 0.24811184825118357,
      "grad_norm": 0.4272370934486389,
      "learning_rate": 7.5188815174881645e-06,
      "loss": 0.1009,
      "step": 15670
    },
    {
      "epoch": 0.24812768180882563,
      "grad_norm": 0.24929466843605042,
      "learning_rate": 7.518723181911744e-06,
      "loss": 0.0815,
      "step": 15671
    },
    {
      "epoch": 0.2481435153664677,
      "grad_norm": 0.7292061448097229,
      "learning_rate": 7.5185648463353235e-06,
      "loss": 0.2168,
      "step": 15672
    },
    {
      "epoch": 0.24815934892410976,
      "grad_norm": 0.009354783222079277,
      "learning_rate": 7.518406510758903e-06,
      "loss": 0.0001,
      "step": 15673
    },
    {
      "epoch": 0.24817518248175183,
      "grad_norm": 0.01343564409762621,
      "learning_rate": 7.5182481751824825e-06,
      "loss": 0.0005,
      "step": 15674
    },
    {
      "epoch": 0.2481910160393939,
      "grad_norm": 0.03841191157698631,
      "learning_rate": 7.518089839606062e-06,
      "loss": 0.0016,
      "step": 15675
    },
    {
      "epoch": 0.24820684959703596,
      "grad_norm": 0.3872902989387512,
      "learning_rate": 7.517931504029641e-06,
      "loss": 0.2999,
      "step": 15676
    },
    {
      "epoch": 0.24822268315467802,
      "grad_norm": 0.012940781190991402,
      "learning_rate": 7.5177731684532206e-06,
      "loss": 0.0005,
      "step": 15677
    },
    {
      "epoch": 0.24823851671232008,
      "grad_norm": 0.31683048605918884,
      "learning_rate": 7.5176148328768e-06,
      "loss": 0.1305,
      "step": 15678
    },
    {
      "epoch": 0.24825435026996215,
      "grad_norm": 0.25824081897735596,
      "learning_rate": 7.5174564973003796e-06,
      "loss": 0.0529,
      "step": 15679
    },
    {
      "epoch": 0.2482701838276042,
      "grad_norm": 0.023366011679172516,
      "learning_rate": 7.517298161723958e-06,
      "loss": 0.0011,
      "step": 15680
    },
    {
      "epoch": 0.2482860173852463,
      "grad_norm": 0.25300389528274536,
      "learning_rate": 7.517139826147538e-06,
      "loss": 0.0376,
      "step": 15681
    },
    {
      "epoch": 0.24830185094288837,
      "grad_norm": 0.3867145776748657,
      "learning_rate": 7.516981490571117e-06,
      "loss": 0.0529,
      "step": 15682
    },
    {
      "epoch": 0.24831768450053043,
      "grad_norm": 0.24449874460697174,
      "learning_rate": 7.516823154994697e-06,
      "loss": 0.0959,
      "step": 15683
    },
    {
      "epoch": 0.2483335180581725,
      "grad_norm": 0.14996588230133057,
      "learning_rate": 7.516664819418276e-06,
      "loss": 0.0581,
      "step": 15684
    },
    {
      "epoch": 0.24834935161581456,
      "grad_norm": 0.27095234394073486,
      "learning_rate": 7.516506483841856e-06,
      "loss": 0.0829,
      "step": 15685
    },
    {
      "epoch": 0.24836518517345663,
      "grad_norm": 0.6698721647262573,
      "learning_rate": 7.516348148265434e-06,
      "loss": 0.5446,
      "step": 15686
    },
    {
      "epoch": 0.2483810187310987,
      "grad_norm": 0.43047159910202026,
      "learning_rate": 7.516189812689013e-06,
      "loss": 0.1792,
      "step": 15687
    },
    {
      "epoch": 0.24839685228874075,
      "grad_norm": 0.5979773998260498,
      "learning_rate": 7.516031477112593e-06,
      "loss": 0.1377,
      "step": 15688
    },
    {
      "epoch": 0.24841268584638282,
      "grad_norm": 0.0009235143661499023,
      "learning_rate": 7.515873141536172e-06,
      "loss": 0.0,
      "step": 15689
    },
    {
      "epoch": 0.24842851940402488,
      "grad_norm": 0.280769020318985,
      "learning_rate": 7.515714805959752e-06,
      "loss": 0.0381,
      "step": 15690
    },
    {
      "epoch": 0.24844435296166695,
      "grad_norm": 0.17855007946491241,
      "learning_rate": 7.51555647038333e-06,
      "loss": 0.0464,
      "step": 15691
    },
    {
      "epoch": 0.248460186519309,
      "grad_norm": 0.32668429613113403,
      "learning_rate": 7.51539813480691e-06,
      "loss": 0.0839,
      "step": 15692
    },
    {
      "epoch": 0.24847602007695108,
      "grad_norm": 0.0007797136786393821,
      "learning_rate": 7.515239799230489e-06,
      "loss": 0.0,
      "step": 15693
    },
    {
      "epoch": 0.24849185363459317,
      "grad_norm": 0.00010036258026957512,
      "learning_rate": 7.515081463654069e-06,
      "loss": 0.0,
      "step": 15694
    },
    {
      "epoch": 0.24850768719223523,
      "grad_norm": 0.020344095304608345,
      "learning_rate": 7.514923128077648e-06,
      "loss": 0.001,
      "step": 15695
    },
    {
      "epoch": 0.2485235207498773,
      "grad_norm": 0.021346628665924072,
      "learning_rate": 7.514764792501228e-06,
      "loss": 0.0011,
      "step": 15696
    },
    {
      "epoch": 0.24853935430751936,
      "grad_norm": 0.03784741833806038,
      "learning_rate": 7.514606456924806e-06,
      "loss": 0.0012,
      "step": 15697
    },
    {
      "epoch": 0.24855518786516143,
      "grad_norm": 0.6509861350059509,
      "learning_rate": 7.514448121348386e-06,
      "loss": 0.5669,
      "step": 15698
    },
    {
      "epoch": 0.2485710214228035,
      "grad_norm": 0.30495572090148926,
      "learning_rate": 7.514289785771965e-06,
      "loss": 0.0783,
      "step": 15699
    },
    {
      "epoch": 0.24858685498044555,
      "grad_norm": 0.2538439929485321,
      "learning_rate": 7.514131450195545e-06,
      "loss": 0.0336,
      "step": 15700
    },
    {
      "epoch": 0.24860268853808762,
      "grad_norm": 0.5339338779449463,
      "learning_rate": 7.513973114619124e-06,
      "loss": 0.6641,
      "step": 15701
    },
    {
      "epoch": 0.24861852209572968,
      "grad_norm": 0.31753626465797424,
      "learning_rate": 7.513814779042704e-06,
      "loss": 0.1119,
      "step": 15702
    },
    {
      "epoch": 0.24863435565337175,
      "grad_norm": 0.3792516887187958,
      "learning_rate": 7.5136564434662826e-06,
      "loss": 0.0958,
      "step": 15703
    },
    {
      "epoch": 0.2486501892110138,
      "grad_norm": 1.1696953773498535,
      "learning_rate": 7.5134981078898625e-06,
      "loss": 0.5865,
      "step": 15704
    },
    {
      "epoch": 0.24866602276865588,
      "grad_norm": 0.05155491828918457,
      "learning_rate": 7.5133397723134416e-06,
      "loss": 0.0026,
      "step": 15705
    },
    {
      "epoch": 0.24868185632629797,
      "grad_norm": 0.1762162297964096,
      "learning_rate": 7.5131814367370215e-06,
      "loss": 0.0673,
      "step": 15706
    },
    {
      "epoch": 0.24869768988394003,
      "grad_norm": 0.06371291726827621,
      "learning_rate": 7.5130231011606006e-06,
      "loss": 0.0016,
      "step": 15707
    },
    {
      "epoch": 0.2487135234415821,
      "grad_norm": 0.758605420589447,
      "learning_rate": 7.5128647655841805e-06,
      "loss": 0.225,
      "step": 15708
    },
    {
      "epoch": 0.24872935699922416,
      "grad_norm": 0.30250364542007446,
      "learning_rate": 7.512706430007759e-06,
      "loss": 0.0346,
      "step": 15709
    },
    {
      "epoch": 0.24874519055686622,
      "grad_norm": 1.4129712581634521,
      "learning_rate": 7.512548094431339e-06,
      "loss": 0.3305,
      "step": 15710
    },
    {
      "epoch": 0.2487610241145083,
      "grad_norm": 0.0004735615220852196,
      "learning_rate": 7.512389758854918e-06,
      "loss": 0.0,
      "step": 15711
    },
    {
      "epoch": 0.24877685767215035,
      "grad_norm": 0.506237268447876,
      "learning_rate": 7.512231423278497e-06,
      "loss": 0.1904,
      "step": 15712
    },
    {
      "epoch": 0.24879269122979242,
      "grad_norm": 0.0022044326178729534,
      "learning_rate": 7.512073087702077e-06,
      "loss": 0.0,
      "step": 15713
    },
    {
      "epoch": 0.24880852478743448,
      "grad_norm": 0.6998423337936401,
      "learning_rate": 7.511914752125655e-06,
      "loss": 0.0441,
      "step": 15714
    },
    {
      "epoch": 0.24882435834507655,
      "grad_norm": 0.0014291685074567795,
      "learning_rate": 7.511756416549235e-06,
      "loss": 0.0,
      "step": 15715
    },
    {
      "epoch": 0.2488401919027186,
      "grad_norm": 0.0076680234633386135,
      "learning_rate": 7.511598080972814e-06,
      "loss": 0.0003,
      "step": 15716
    },
    {
      "epoch": 0.24885602546036067,
      "grad_norm": 0.010623353533446789,
      "learning_rate": 7.511439745396394e-06,
      "loss": 0.0006,
      "step": 15717
    },
    {
      "epoch": 0.24887185901800277,
      "grad_norm": 0.30998876690864563,
      "learning_rate": 7.511281409819973e-06,
      "loss": 0.0991,
      "step": 15718
    },
    {
      "epoch": 0.24888769257564483,
      "grad_norm": 0.009830794297158718,
      "learning_rate": 7.511123074243553e-06,
      "loss": 0.0003,
      "step": 15719
    },
    {
      "epoch": 0.2489035261332869,
      "grad_norm": 0.1861373484134674,
      "learning_rate": 7.510964738667131e-06,
      "loss": 0.0396,
      "step": 15720
    },
    {
      "epoch": 0.24891935969092896,
      "grad_norm": 0.6836321949958801,
      "learning_rate": 7.510806403090711e-06,
      "loss": 0.5012,
      "step": 15721
    },
    {
      "epoch": 0.24893519324857102,
      "grad_norm": 0.01735331118106842,
      "learning_rate": 7.51064806751429e-06,
      "loss": 0.0008,
      "step": 15722
    },
    {
      "epoch": 0.2489510268062131,
      "grad_norm": 5.967900506220758e-05,
      "learning_rate": 7.51048973193787e-06,
      "loss": 0.0,
      "step": 15723
    },
    {
      "epoch": 0.24896686036385515,
      "grad_norm": 0.2923831641674042,
      "learning_rate": 7.510331396361449e-06,
      "loss": 0.0811,
      "step": 15724
    },
    {
      "epoch": 0.24898269392149722,
      "grad_norm": 7.460394408553839e-05,
      "learning_rate": 7.510173060785029e-06,
      "loss": 0.0,
      "step": 15725
    },
    {
      "epoch": 0.24899852747913928,
      "grad_norm": 0.013976301066577435,
      "learning_rate": 7.510014725208607e-06,
      "loss": 0.0006,
      "step": 15726
    },
    {
      "epoch": 0.24901436103678135,
      "grad_norm": 0.35009539127349854,
      "learning_rate": 7.509856389632187e-06,
      "loss": 0.0123,
      "step": 15727
    },
    {
      "epoch": 0.2490301945944234,
      "grad_norm": 0.010696113109588623,
      "learning_rate": 7.509698054055766e-06,
      "loss": 0.0005,
      "step": 15728
    },
    {
      "epoch": 0.24904602815206547,
      "grad_norm": 0.7186160087585449,
      "learning_rate": 7.509539718479346e-06,
      "loss": 0.6105,
      "step": 15729
    },
    {
      "epoch": 0.24906186170970757,
      "grad_norm": 0.47369715571403503,
      "learning_rate": 7.509381382902925e-06,
      "loss": 0.2635,
      "step": 15730
    },
    {
      "epoch": 0.24907769526734963,
      "grad_norm": 0.3088776469230652,
      "learning_rate": 7.509223047326505e-06,
      "loss": 0.0862,
      "step": 15731
    },
    {
      "epoch": 0.2490935288249917,
      "grad_norm": 0.6224347352981567,
      "learning_rate": 7.5090647117500835e-06,
      "loss": 0.4028,
      "step": 15732
    },
    {
      "epoch": 0.24910936238263376,
      "grad_norm": 0.28586772084236145,
      "learning_rate": 7.508906376173663e-06,
      "loss": 0.1289,
      "step": 15733
    },
    {
      "epoch": 0.24912519594027582,
      "grad_norm": 0.03126826509833336,
      "learning_rate": 7.5087480405972425e-06,
      "loss": 0.0017,
      "step": 15734
    },
    {
      "epoch": 0.2491410294979179,
      "grad_norm": 2.135326623916626,
      "learning_rate": 7.508589705020822e-06,
      "loss": 0.1851,
      "step": 15735
    },
    {
      "epoch": 0.24915686305555995,
      "grad_norm": 0.4429115355014801,
      "learning_rate": 7.5084313694444015e-06,
      "loss": 0.1162,
      "step": 15736
    },
    {
      "epoch": 0.24917269661320202,
      "grad_norm": 0.7572178840637207,
      "learning_rate": 7.50827303386798e-06,
      "loss": 0.3558,
      "step": 15737
    },
    {
      "epoch": 0.24918853017084408,
      "grad_norm": 0.34730467200279236,
      "learning_rate": 7.50811469829156e-06,
      "loss": 0.0356,
      "step": 15738
    },
    {
      "epoch": 0.24920436372848614,
      "grad_norm": 0.045729100704193115,
      "learning_rate": 7.507956362715139e-06,
      "loss": 0.003,
      "step": 15739
    },
    {
      "epoch": 0.2492201972861282,
      "grad_norm": 0.004055275581777096,
      "learning_rate": 7.507798027138719e-06,
      "loss": 0.0,
      "step": 15740
    },
    {
      "epoch": 0.24923603084377027,
      "grad_norm": 0.01649995520710945,
      "learning_rate": 7.507639691562298e-06,
      "loss": 0.0005,
      "step": 15741
    },
    {
      "epoch": 0.24925186440141237,
      "grad_norm": 0.3630496859550476,
      "learning_rate": 7.507481355985877e-06,
      "loss": 0.1797,
      "step": 15742
    },
    {
      "epoch": 0.24926769795905443,
      "grad_norm": 0.34929460287094116,
      "learning_rate": 7.507323020409456e-06,
      "loss": 0.1285,
      "step": 15743
    },
    {
      "epoch": 0.2492835315166965,
      "grad_norm": 0.26909902691841125,
      "learning_rate": 7.507164684833036e-06,
      "loss": 0.0469,
      "step": 15744
    },
    {
      "epoch": 0.24929936507433856,
      "grad_norm": 0.00044955412158742547,
      "learning_rate": 7.507006349256615e-06,
      "loss": 0.0,
      "step": 15745
    },
    {
      "epoch": 0.24931519863198062,
      "grad_norm": 0.9318632483482361,
      "learning_rate": 7.506848013680195e-06,
      "loss": 0.0886,
      "step": 15746
    },
    {
      "epoch": 0.2493310321896227,
      "grad_norm": 0.7182921171188354,
      "learning_rate": 7.506689678103773e-06,
      "loss": 0.4147,
      "step": 15747
    },
    {
      "epoch": 0.24934686574726475,
      "grad_norm": 0.38264456391334534,
      "learning_rate": 7.506531342527353e-06,
      "loss": 0.0046,
      "step": 15748
    },
    {
      "epoch": 0.24936269930490682,
      "grad_norm": 0.1898387372493744,
      "learning_rate": 7.506373006950932e-06,
      "loss": 0.0384,
      "step": 15749
    },
    {
      "epoch": 0.24937853286254888,
      "grad_norm": 0.459134042263031,
      "learning_rate": 7.506214671374512e-06,
      "loss": 0.1576,
      "step": 15750
    },
    {
      "epoch": 0.24939436642019094,
      "grad_norm": 0.02037188410758972,
      "learning_rate": 7.506056335798091e-06,
      "loss": 0.0009,
      "step": 15751
    },
    {
      "epoch": 0.249410199977833,
      "grad_norm": 0.0007235949160531163,
      "learning_rate": 7.505898000221671e-06,
      "loss": 0.0,
      "step": 15752
    },
    {
      "epoch": 0.24942603353547507,
      "grad_norm": 0.4776213765144348,
      "learning_rate": 7.505739664645249e-06,
      "loss": 0.2642,
      "step": 15753
    },
    {
      "epoch": 0.24944186709311716,
      "grad_norm": 0.27163246273994446,
      "learning_rate": 7.505581329068829e-06,
      "loss": 0.0245,
      "step": 15754
    },
    {
      "epoch": 0.24945770065075923,
      "grad_norm": 0.2551906406879425,
      "learning_rate": 7.505422993492408e-06,
      "loss": 0.0481,
      "step": 15755
    },
    {
      "epoch": 0.2494735342084013,
      "grad_norm": 0.5431674718856812,
      "learning_rate": 7.505264657915988e-06,
      "loss": 0.151,
      "step": 15756
    },
    {
      "epoch": 0.24948936776604336,
      "grad_norm": 0.37978893518447876,
      "learning_rate": 7.505106322339567e-06,
      "loss": 0.0429,
      "step": 15757
    },
    {
      "epoch": 0.24950520132368542,
      "grad_norm": 0.00013257267710287124,
      "learning_rate": 7.504947986763147e-06,
      "loss": 0.0,
      "step": 15758
    },
    {
      "epoch": 0.24952103488132749,
      "grad_norm": 0.22819150984287262,
      "learning_rate": 7.504789651186725e-06,
      "loss": 0.0678,
      "step": 15759
    },
    {
      "epoch": 0.24953686843896955,
      "grad_norm": 0.01667962223291397,
      "learning_rate": 7.5046313156103045e-06,
      "loss": 0.0006,
      "step": 15760
    },
    {
      "epoch": 0.24955270199661161,
      "grad_norm": 0.010674231685698032,
      "learning_rate": 7.504472980033884e-06,
      "loss": 0.0004,
      "step": 15761
    },
    {
      "epoch": 0.24956853555425368,
      "grad_norm": 0.7773775458335876,
      "learning_rate": 7.5043146444574635e-06,
      "loss": 0.3169,
      "step": 15762
    },
    {
      "epoch": 0.24958436911189574,
      "grad_norm": 0.2655237913131714,
      "learning_rate": 7.504156308881043e-06,
      "loss": 0.0764,
      "step": 15763
    },
    {
      "epoch": 0.2496002026695378,
      "grad_norm": 1.0064151287078857,
      "learning_rate": 7.503997973304622e-06,
      "loss": 0.1791,
      "step": 15764
    },
    {
      "epoch": 0.24961603622717987,
      "grad_norm": 4.479714698391035e-05,
      "learning_rate": 7.503839637728202e-06,
      "loss": 0.0,
      "step": 15765
    },
    {
      "epoch": 0.24963186978482196,
      "grad_norm": 0.09535802900791168,
      "learning_rate": 7.503681302151781e-06,
      "loss": 0.0039,
      "step": 15766
    },
    {
      "epoch": 0.24964770334246403,
      "grad_norm": 0.45291653275489807,
      "learning_rate": 7.503522966575361e-06,
      "loss": 0.1583,
      "step": 15767
    },
    {
      "epoch": 0.2496635369001061,
      "grad_norm": 0.005314902402460575,
      "learning_rate": 7.50336463099894e-06,
      "loss": 0.0002,
      "step": 15768
    },
    {
      "epoch": 0.24967937045774816,
      "grad_norm": 0.00016112571756821126,
      "learning_rate": 7.50320629542252e-06,
      "loss": 0.0,
      "step": 15769
    },
    {
      "epoch": 0.24969520401539022,
      "grad_norm": 0.5935737490653992,
      "learning_rate": 7.503047959846098e-06,
      "loss": 0.4126,
      "step": 15770
    },
    {
      "epoch": 0.24971103757303229,
      "grad_norm": 0.6771644353866577,
      "learning_rate": 7.502889624269678e-06,
      "loss": 0.1274,
      "step": 15771
    },
    {
      "epoch": 0.24972687113067435,
      "grad_norm": 0.22945630550384521,
      "learning_rate": 7.502731288693257e-06,
      "loss": 0.0811,
      "step": 15772
    },
    {
      "epoch": 0.2497427046883164,
      "grad_norm": 0.22048497200012207,
      "learning_rate": 7.502572953116837e-06,
      "loss": 0.0791,
      "step": 15773
    },
    {
      "epoch": 0.24975853824595848,
      "grad_norm": 0.6414663791656494,
      "learning_rate": 7.502414617540416e-06,
      "loss": 0.3883,
      "step": 15774
    },
    {
      "epoch": 0.24977437180360054,
      "grad_norm": 0.40683600306510925,
      "learning_rate": 7.502256281963996e-06,
      "loss": 0.1803,
      "step": 15775
    },
    {
      "epoch": 0.2497902053612426,
      "grad_norm": 0.012883477844297886,
      "learning_rate": 7.502097946387574e-06,
      "loss": 0.0005,
      "step": 15776
    },
    {
      "epoch": 0.24980603891888467,
      "grad_norm": 0.22568094730377197,
      "learning_rate": 7.501939610811154e-06,
      "loss": 0.0561,
      "step": 15777
    },
    {
      "epoch": 0.24982187247652676,
      "grad_norm": 0.00015999063907656819,
      "learning_rate": 7.501781275234733e-06,
      "loss": 0.0,
      "step": 15778
    },
    {
      "epoch": 0.24983770603416883,
      "grad_norm": 0.1918548047542572,
      "learning_rate": 7.501622939658313e-06,
      "loss": 0.0469,
      "step": 15779
    },
    {
      "epoch": 0.2498535395918109,
      "grad_norm": 0.014238628558814526,
      "learning_rate": 7.501464604081892e-06,
      "loss": 0.0005,
      "step": 15780
    },
    {
      "epoch": 0.24986937314945296,
      "grad_norm": 0.45988553762435913,
      "learning_rate": 7.501306268505472e-06,
      "loss": 0.2243,
      "step": 15781
    },
    {
      "epoch": 0.24988520670709502,
      "grad_norm": 0.03406933322548866,
      "learning_rate": 7.50114793292905e-06,
      "loss": 0.0014,
      "step": 15782
    },
    {
      "epoch": 0.24990104026473708,
      "grad_norm": 0.372073769569397,
      "learning_rate": 7.50098959735263e-06,
      "loss": 0.09,
      "step": 15783
    },
    {
      "epoch": 0.24991687382237915,
      "grad_norm": 0.5833733081817627,
      "learning_rate": 7.500831261776209e-06,
      "loss": 0.1461,
      "step": 15784
    },
    {
      "epoch": 0.2499327073800212,
      "grad_norm": 0.6559455990791321,
      "learning_rate": 7.500672926199788e-06,
      "loss": 0.5308,
      "step": 15785
    },
    {
      "epoch": 0.24994854093766328,
      "grad_norm": 0.125823512673378,
      "learning_rate": 7.500514590623368e-06,
      "loss": 0.0096,
      "step": 15786
    },
    {
      "epoch": 0.24996437449530534,
      "grad_norm": 0.733719527721405,
      "learning_rate": 7.500356255046946e-06,
      "loss": 0.2355,
      "step": 15787
    },
    {
      "epoch": 0.2499802080529474,
      "grad_norm": 0.0001717926497804001,
      "learning_rate": 7.500197919470526e-06,
      "loss": 0.0,
      "step": 15788
    },
    {
      "epoch": 0.24999604161058947,
      "grad_norm": 0.6214925646781921,
      "learning_rate": 7.500039583894105e-06,
      "loss": 0.4116,
      "step": 15789
    },
    {
      "epoch": 0.25001187516823153,
      "grad_norm": 0.0061133489944040775,
      "learning_rate": 7.499881248317685e-06,
      "loss": 0.0002,
      "step": 15790
    },
    {
      "epoch": 0.2500277087258736,
      "grad_norm": 0.19499647617340088,
      "learning_rate": 7.4997229127412644e-06,
      "loss": 0.0911,
      "step": 15791
    },
    {
      "epoch": 0.25004354228351566,
      "grad_norm": 0.02661561220884323,
      "learning_rate": 7.499564577164844e-06,
      "loss": 0.0019,
      "step": 15792
    },
    {
      "epoch": 0.2500593758411577,
      "grad_norm": 0.42368951439857483,
      "learning_rate": 7.499406241588423e-06,
      "loss": 0.1967,
      "step": 15793
    },
    {
      "epoch": 0.2500752093987998,
      "grad_norm": 0.2816513776779175,
      "learning_rate": 7.4992479060120025e-06,
      "loss": 0.0511,
      "step": 15794
    },
    {
      "epoch": 0.25009104295644186,
      "grad_norm": 0.0035196749959141016,
      "learning_rate": 7.499089570435582e-06,
      "loss": 0.0001,
      "step": 15795
    },
    {
      "epoch": 0.250106876514084,
      "grad_norm": 0.006631918251514435,
      "learning_rate": 7.4989312348591615e-06,
      "loss": 0.0002,
      "step": 15796
    },
    {
      "epoch": 0.25012271007172604,
      "grad_norm": 0.051878854632377625,
      "learning_rate": 7.498772899282741e-06,
      "loss": 0.0036,
      "step": 15797
    },
    {
      "epoch": 0.2501385436293681,
      "grad_norm": 0.45726051926612854,
      "learning_rate": 7.4986145637063205e-06,
      "loss": 0.554,
      "step": 15798
    },
    {
      "epoch": 0.25015437718701017,
      "grad_norm": 0.23634402453899384,
      "learning_rate": 7.498456228129899e-06,
      "loss": 0.1261,
      "step": 15799
    },
    {
      "epoch": 0.25017021074465223,
      "grad_norm": 0.7423318028450012,
      "learning_rate": 7.498297892553479e-06,
      "loss": 0.2099,
      "step": 15800
    },
    {
      "epoch": 0.2501860443022943,
      "grad_norm": 4.896265029907227,
      "learning_rate": 7.498139556977058e-06,
      "loss": 0.239,
      "step": 15801
    },
    {
      "epoch": 0.25020187785993636,
      "grad_norm": 0.5516723990440369,
      "learning_rate": 7.497981221400638e-06,
      "loss": 0.1085,
      "step": 15802
    },
    {
      "epoch": 0.2502177114175784,
      "grad_norm": 0.8518638014793396,
      "learning_rate": 7.497822885824217e-06,
      "loss": 0.318,
      "step": 15803
    },
    {
      "epoch": 0.2502335449752205,
      "grad_norm": 0.7283096313476562,
      "learning_rate": 7.497664550247796e-06,
      "loss": 0.1816,
      "step": 15804
    },
    {
      "epoch": 0.25024937853286255,
      "grad_norm": 0.4207342863082886,
      "learning_rate": 7.497506214671375e-06,
      "loss": 0.1679,
      "step": 15805
    },
    {
      "epoch": 0.2502652120905046,
      "grad_norm": 0.6441196799278259,
      "learning_rate": 7.497347879094955e-06,
      "loss": 0.046,
      "step": 15806
    },
    {
      "epoch": 0.2502810456481467,
      "grad_norm": 0.28516441583633423,
      "learning_rate": 7.497189543518534e-06,
      "loss": 0.0771,
      "step": 15807
    },
    {
      "epoch": 0.25029687920578875,
      "grad_norm": 0.16575585305690765,
      "learning_rate": 7.497031207942112e-06,
      "loss": 0.0136,
      "step": 15808
    },
    {
      "epoch": 0.2503127127634308,
      "grad_norm": 0.3426130414009094,
      "learning_rate": 7.496872872365692e-06,
      "loss": 0.1307,
      "step": 15809
    },
    {
      "epoch": 0.2503285463210729,
      "grad_norm": 0.22450236976146698,
      "learning_rate": 7.496714536789271e-06,
      "loss": 0.0684,
      "step": 15810
    },
    {
      "epoch": 0.25034437987871494,
      "grad_norm": 0.013369365595281124,
      "learning_rate": 7.496556201212851e-06,
      "loss": 0.0005,
      "step": 15811
    },
    {
      "epoch": 0.250360213436357,
      "grad_norm": 0.7960742115974426,
      "learning_rate": 7.49639786563643e-06,
      "loss": 0.7703,
      "step": 15812
    },
    {
      "epoch": 0.25037604699399907,
      "grad_norm": 0.00029634361271746457,
      "learning_rate": 7.49623953006001e-06,
      "loss": 0.0,
      "step": 15813
    },
    {
      "epoch": 0.25039188055164113,
      "grad_norm": 0.19893233478069305,
      "learning_rate": 7.496081194483588e-06,
      "loss": 0.0627,
      "step": 15814
    },
    {
      "epoch": 0.2504077141092832,
      "grad_norm": 0.21045427024364471,
      "learning_rate": 7.495922858907168e-06,
      "loss": 0.0466,
      "step": 15815
    },
    {
      "epoch": 0.25042354766692526,
      "grad_norm": 0.010006175376474857,
      "learning_rate": 7.495764523330747e-06,
      "loss": 0.0001,
      "step": 15816
    },
    {
      "epoch": 0.2504393812245673,
      "grad_norm": 0.13826555013656616,
      "learning_rate": 7.495606187754327e-06,
      "loss": 0.0602,
      "step": 15817
    },
    {
      "epoch": 0.2504552147822094,
      "grad_norm": 7.603944686707109e-05,
      "learning_rate": 7.495447852177906e-06,
      "loss": 0.0,
      "step": 15818
    },
    {
      "epoch": 0.25047104833985145,
      "grad_norm": 0.6406430006027222,
      "learning_rate": 7.495289516601486e-06,
      "loss": 0.0726,
      "step": 15819
    },
    {
      "epoch": 0.2504868818974936,
      "grad_norm": 0.3696735203266144,
      "learning_rate": 7.4951311810250645e-06,
      "loss": 0.1059,
      "step": 15820
    },
    {
      "epoch": 0.25050271545513564,
      "grad_norm": 0.44204220175743103,
      "learning_rate": 7.4949728454486444e-06,
      "loss": 0.1641,
      "step": 15821
    },
    {
      "epoch": 0.2505185490127777,
      "grad_norm": 0.7104595899581909,
      "learning_rate": 7.4948145098722235e-06,
      "loss": 0.0932,
      "step": 15822
    },
    {
      "epoch": 0.25053438257041977,
      "grad_norm": 0.4636167287826538,
      "learning_rate": 7.4946561742958034e-06,
      "loss": 0.245,
      "step": 15823
    },
    {
      "epoch": 0.25055021612806183,
      "grad_norm": 0.42813944816589355,
      "learning_rate": 7.4944978387193825e-06,
      "loss": 0.2664,
      "step": 15824
    },
    {
      "epoch": 0.2505660496857039,
      "grad_norm": 0.22913233935832977,
      "learning_rate": 7.4943395031429624e-06,
      "loss": 0.0751,
      "step": 15825
    },
    {
      "epoch": 0.25058188324334596,
      "grad_norm": 0.012856675311923027,
      "learning_rate": 7.494181167566541e-06,
      "loss": 0.0004,
      "step": 15826
    },
    {
      "epoch": 0.250597716800988,
      "grad_norm": 0.43501609563827515,
      "learning_rate": 7.494022831990121e-06,
      "loss": 0.3332,
      "step": 15827
    },
    {
      "epoch": 0.2506135503586301,
      "grad_norm": 0.42901816964149475,
      "learning_rate": 7.4938644964137e-06,
      "loss": 0.3815,
      "step": 15828
    },
    {
      "epoch": 0.25062938391627215,
      "grad_norm": 0.0028091531712561846,
      "learning_rate": 7.49370616083728e-06,
      "loss": 0.0,
      "step": 15829
    },
    {
      "epoch": 0.2506452174739142,
      "grad_norm": 0.30095964670181274,
      "learning_rate": 7.493547825260859e-06,
      "loss": 0.1096,
      "step": 15830
    },
    {
      "epoch": 0.2506610510315563,
      "grad_norm": 8.608994539827108e-05,
      "learning_rate": 7.493389489684439e-06,
      "loss": 0.0,
      "step": 15831
    },
    {
      "epoch": 0.25067688458919835,
      "grad_norm": 0.34742921590805054,
      "learning_rate": 7.493231154108017e-06,
      "loss": 0.1482,
      "step": 15832
    },
    {
      "epoch": 0.2506927181468404,
      "grad_norm": 0.002239059191197157,
      "learning_rate": 7.493072818531596e-06,
      "loss": 0.0001,
      "step": 15833
    },
    {
      "epoch": 0.2507085517044825,
      "grad_norm": 0.34341803193092346,
      "learning_rate": 7.492914482955176e-06,
      "loss": 0.0942,
      "step": 15834
    },
    {
      "epoch": 0.25072438526212454,
      "grad_norm": 0.15103358030319214,
      "learning_rate": 7.492756147378755e-06,
      "loss": 0.0645,
      "step": 15835
    },
    {
      "epoch": 0.2507402188197666,
      "grad_norm": 0.9222076535224915,
      "learning_rate": 7.492597811802335e-06,
      "loss": 0.5128,
      "step": 15836
    },
    {
      "epoch": 0.25075605237740867,
      "grad_norm": 0.2606922686100006,
      "learning_rate": 7.492439476225913e-06,
      "loss": 0.0495,
      "step": 15837
    },
    {
      "epoch": 0.25077188593505073,
      "grad_norm": 0.5457923412322998,
      "learning_rate": 7.492281140649493e-06,
      "loss": 0.1704,
      "step": 15838
    },
    {
      "epoch": 0.2507877194926928,
      "grad_norm": 0.16990430653095245,
      "learning_rate": 7.492122805073072e-06,
      "loss": 0.0816,
      "step": 15839
    },
    {
      "epoch": 0.25080355305033486,
      "grad_norm": 0.00010122586536454037,
      "learning_rate": 7.491964469496652e-06,
      "loss": 0.0,
      "step": 15840
    },
    {
      "epoch": 0.2508193866079769,
      "grad_norm": 0.24674096703529358,
      "learning_rate": 7.491806133920231e-06,
      "loss": 0.1448,
      "step": 15841
    },
    {
      "epoch": 0.250835220165619,
      "grad_norm": 0.2061871588230133,
      "learning_rate": 7.491647798343811e-06,
      "loss": 0.0628,
      "step": 15842
    },
    {
      "epoch": 0.25085105372326105,
      "grad_norm": 0.2713867425918579,
      "learning_rate": 7.491489462767389e-06,
      "loss": 0.1708,
      "step": 15843
    },
    {
      "epoch": 0.2508668872809032,
      "grad_norm": 0.013609733432531357,
      "learning_rate": 7.491331127190969e-06,
      "loss": 0.0005,
      "step": 15844
    },
    {
      "epoch": 0.25088272083854524,
      "grad_norm": 0.6222548484802246,
      "learning_rate": 7.491172791614548e-06,
      "loss": 0.1917,
      "step": 15845
    },
    {
      "epoch": 0.2508985543961873,
      "grad_norm": 0.37136536836624146,
      "learning_rate": 7.491014456038128e-06,
      "loss": 0.1116,
      "step": 15846
    },
    {
      "epoch": 0.25091438795382937,
      "grad_norm": 0.4974697530269623,
      "learning_rate": 7.490856120461707e-06,
      "loss": 0.4881,
      "step": 15847
    },
    {
      "epoch": 0.25093022151147143,
      "grad_norm": 0.474323034286499,
      "learning_rate": 7.490697784885287e-06,
      "loss": 0.6844,
      "step": 15848
    },
    {
      "epoch": 0.2509460550691135,
      "grad_norm": 0.7348564863204956,
      "learning_rate": 7.4905394493088654e-06,
      "loss": 0.4258,
      "step": 15849
    },
    {
      "epoch": 0.25096188862675556,
      "grad_norm": 0.2831244468688965,
      "learning_rate": 7.490381113732445e-06,
      "loss": 0.1299,
      "step": 15850
    },
    {
      "epoch": 0.2509777221843976,
      "grad_norm": 0.01589367538690567,
      "learning_rate": 7.4902227781560244e-06,
      "loss": 0.0007,
      "step": 15851
    },
    {
      "epoch": 0.2509935557420397,
      "grad_norm": 5.557641506195068,
      "learning_rate": 7.490064442579604e-06,
      "loss": 0.4569,
      "step": 15852
    },
    {
      "epoch": 0.25100938929968175,
      "grad_norm": 0.025010501965880394,
      "learning_rate": 7.4899061070031835e-06,
      "loss": 0.0015,
      "step": 15853
    },
    {
      "epoch": 0.2510252228573238,
      "grad_norm": 0.2537577450275421,
      "learning_rate": 7.489747771426763e-06,
      "loss": 0.064,
      "step": 15854
    },
    {
      "epoch": 0.2510410564149659,
      "grad_norm": 0.3128288984298706,
      "learning_rate": 7.489589435850342e-06,
      "loss": 0.0528,
      "step": 15855
    },
    {
      "epoch": 0.25105688997260794,
      "grad_norm": 0.5550126433372498,
      "learning_rate": 7.489431100273921e-06,
      "loss": 0.0418,
      "step": 15856
    },
    {
      "epoch": 0.25107272353025,
      "grad_norm": 0.15383242070674896,
      "learning_rate": 7.489272764697501e-06,
      "loss": 0.0341,
      "step": 15857
    },
    {
      "epoch": 0.2510885570878921,
      "grad_norm": 0.0004116295895073563,
      "learning_rate": 7.48911442912108e-06,
      "loss": 0.0,
      "step": 15858
    },
    {
      "epoch": 0.25110439064553414,
      "grad_norm": 0.5927353501319885,
      "learning_rate": 7.48895609354466e-06,
      "loss": 0.3485,
      "step": 15859
    },
    {
      "epoch": 0.2511202242031762,
      "grad_norm": 0.00399392656981945,
      "learning_rate": 7.488797757968238e-06,
      "loss": 0.0002,
      "step": 15860
    },
    {
      "epoch": 0.25113605776081827,
      "grad_norm": 0.2708861827850342,
      "learning_rate": 7.488639422391818e-06,
      "loss": 0.0568,
      "step": 15861
    },
    {
      "epoch": 0.25115189131846033,
      "grad_norm": 1.5345505475997925,
      "learning_rate": 7.488481086815397e-06,
      "loss": 2.3352,
      "step": 15862
    },
    {
      "epoch": 0.2511677248761024,
      "grad_norm": 0.011574323289096355,
      "learning_rate": 7.488322751238977e-06,
      "loss": 0.0004,
      "step": 15863
    },
    {
      "epoch": 0.25118355843374446,
      "grad_norm": 1.5403079986572266,
      "learning_rate": 7.488164415662556e-06,
      "loss": 0.1182,
      "step": 15864
    },
    {
      "epoch": 0.2511993919913865,
      "grad_norm": 0.397472083568573,
      "learning_rate": 7.488006080086136e-06,
      "loss": 0.1676,
      "step": 15865
    },
    {
      "epoch": 0.2512152255490286,
      "grad_norm": 0.015823518857359886,
      "learning_rate": 7.487847744509714e-06,
      "loss": 0.0004,
      "step": 15866
    },
    {
      "epoch": 0.25123105910667065,
      "grad_norm": 3.988539934158325,
      "learning_rate": 7.487689408933294e-06,
      "loss": 0.2036,
      "step": 15867
    },
    {
      "epoch": 0.25124689266431277,
      "grad_norm": 0.6178534626960754,
      "learning_rate": 7.487531073356873e-06,
      "loss": 0.1529,
      "step": 15868
    },
    {
      "epoch": 0.25126272622195484,
      "grad_norm": 0.04909813031554222,
      "learning_rate": 7.487372737780453e-06,
      "loss": 0.0027,
      "step": 15869
    },
    {
      "epoch": 0.2512785597795969,
      "grad_norm": 0.6816542148590088,
      "learning_rate": 7.487214402204032e-06,
      "loss": 0.1581,
      "step": 15870
    },
    {
      "epoch": 0.25129439333723896,
      "grad_norm": 2.2025041580200195,
      "learning_rate": 7.487056066627611e-06,
      "loss": 0.6746,
      "step": 15871
    },
    {
      "epoch": 0.25131022689488103,
      "grad_norm": 0.0032292248215526342,
      "learning_rate": 7.48689773105119e-06,
      "loss": 0.0001,
      "step": 15872
    },
    {
      "epoch": 0.2513260604525231,
      "grad_norm": 0.376785010099411,
      "learning_rate": 7.48673939547477e-06,
      "loss": 0.1334,
      "step": 15873
    },
    {
      "epoch": 0.25134189401016516,
      "grad_norm": 0.4319171905517578,
      "learning_rate": 7.486581059898349e-06,
      "loss": 0.0799,
      "step": 15874
    },
    {
      "epoch": 0.2513577275678072,
      "grad_norm": 0.5187963843345642,
      "learning_rate": 7.486422724321929e-06,
      "loss": 0.3171,
      "step": 15875
    },
    {
      "epoch": 0.2513735611254493,
      "grad_norm": 0.5529762506484985,
      "learning_rate": 7.486264388745507e-06,
      "loss": 0.1989,
      "step": 15876
    },
    {
      "epoch": 0.25138939468309135,
      "grad_norm": 0.3956802487373352,
      "learning_rate": 7.486106053169087e-06,
      "loss": 0.1892,
      "step": 15877
    },
    {
      "epoch": 0.2514052282407334,
      "grad_norm": 0.492279052734375,
      "learning_rate": 7.485947717592666e-06,
      "loss": 0.09,
      "step": 15878
    },
    {
      "epoch": 0.2514210617983755,
      "grad_norm": 0.5453112721443176,
      "learning_rate": 7.485789382016246e-06,
      "loss": 0.2237,
      "step": 15879
    },
    {
      "epoch": 0.25143689535601754,
      "grad_norm": 0.015166448429226875,
      "learning_rate": 7.485631046439825e-06,
      "loss": 0.0006,
      "step": 15880
    },
    {
      "epoch": 0.2514527289136596,
      "grad_norm": 0.3305240869522095,
      "learning_rate": 7.485472710863404e-06,
      "loss": 0.2948,
      "step": 15881
    },
    {
      "epoch": 0.25146856247130167,
      "grad_norm": 0.4228382408618927,
      "learning_rate": 7.4853143752869835e-06,
      "loss": 0.2799,
      "step": 15882
    },
    {
      "epoch": 0.25148439602894374,
      "grad_norm": 0.5675038695335388,
      "learning_rate": 7.485156039710563e-06,
      "loss": 0.2246,
      "step": 15883
    },
    {
      "epoch": 0.2515002295865858,
      "grad_norm": 0.003379192901775241,
      "learning_rate": 7.4849977041341425e-06,
      "loss": 0.0002,
      "step": 15884
    },
    {
      "epoch": 0.25151606314422786,
      "grad_norm": 0.29997360706329346,
      "learning_rate": 7.484839368557722e-06,
      "loss": 0.0425,
      "step": 15885
    },
    {
      "epoch": 0.25153189670186993,
      "grad_norm": 0.020356247201561928,
      "learning_rate": 7.4846810329813015e-06,
      "loss": 0.0013,
      "step": 15886
    },
    {
      "epoch": 0.251547730259512,
      "grad_norm": 0.2198275476694107,
      "learning_rate": 7.48452269740488e-06,
      "loss": 0.0425,
      "step": 15887
    },
    {
      "epoch": 0.25156356381715406,
      "grad_norm": 0.5275545120239258,
      "learning_rate": 7.48436436182846e-06,
      "loss": 0.5003,
      "step": 15888
    },
    {
      "epoch": 0.2515793973747961,
      "grad_norm": 0.848054051399231,
      "learning_rate": 7.484206026252039e-06,
      "loss": 0.2732,
      "step": 15889
    },
    {
      "epoch": 0.2515952309324382,
      "grad_norm": 0.019688105210661888,
      "learning_rate": 7.484047690675619e-06,
      "loss": 0.0003,
      "step": 15890
    },
    {
      "epoch": 0.25161106449008025,
      "grad_norm": 0.6366250514984131,
      "learning_rate": 7.483889355099198e-06,
      "loss": 0.4988,
      "step": 15891
    },
    {
      "epoch": 0.25162689804772237,
      "grad_norm": 0.2883215844631195,
      "learning_rate": 7.483731019522778e-06,
      "loss": 0.098,
      "step": 15892
    },
    {
      "epoch": 0.25164273160536443,
      "grad_norm": 0.2182963788509369,
      "learning_rate": 7.483572683946356e-06,
      "loss": 0.067,
      "step": 15893
    },
    {
      "epoch": 0.2516585651630065,
      "grad_norm": 0.005954830441623926,
      "learning_rate": 7.483414348369936e-06,
      "loss": 0.0003,
      "step": 15894
    },
    {
      "epoch": 0.25167439872064856,
      "grad_norm": 0.6277967691421509,
      "learning_rate": 7.483256012793515e-06,
      "loss": 0.2901,
      "step": 15895
    },
    {
      "epoch": 0.2516902322782906,
      "grad_norm": 0.04431254789233208,
      "learning_rate": 7.483097677217095e-06,
      "loss": 0.0021,
      "step": 15896
    },
    {
      "epoch": 0.2517060658359327,
      "grad_norm": 0.3254075050354004,
      "learning_rate": 7.482939341640674e-06,
      "loss": 0.007,
      "step": 15897
    },
    {
      "epoch": 0.25172189939357476,
      "grad_norm": 0.013695601373910904,
      "learning_rate": 7.482781006064254e-06,
      "loss": 0.0007,
      "step": 15898
    },
    {
      "epoch": 0.2517377329512168,
      "grad_norm": 0.00425528921186924,
      "learning_rate": 7.482622670487832e-06,
      "loss": 0.0002,
      "step": 15899
    },
    {
      "epoch": 0.2517535665088589,
      "grad_norm": 0.19148966670036316,
      "learning_rate": 7.482464334911412e-06,
      "loss": 0.0529,
      "step": 15900
    },
    {
      "epoch": 0.25176940006650095,
      "grad_norm": 0.40032142400741577,
      "learning_rate": 7.482305999334991e-06,
      "loss": 0.0599,
      "step": 15901
    },
    {
      "epoch": 0.251785233624143,
      "grad_norm": 0.37171342968940735,
      "learning_rate": 7.482147663758571e-06,
      "loss": 0.0266,
      "step": 15902
    },
    {
      "epoch": 0.2518010671817851,
      "grad_norm": 0.026735085994005203,
      "learning_rate": 7.48198932818215e-06,
      "loss": 0.0014,
      "step": 15903
    },
    {
      "epoch": 0.25181690073942714,
      "grad_norm": 0.6667547225952148,
      "learning_rate": 7.481830992605728e-06,
      "loss": 0.1509,
      "step": 15904
    },
    {
      "epoch": 0.2518327342970692,
      "grad_norm": 0.5629845857620239,
      "learning_rate": 7.481672657029308e-06,
      "loss": 0.1281,
      "step": 15905
    },
    {
      "epoch": 0.25184856785471127,
      "grad_norm": 0.006857174914330244,
      "learning_rate": 7.481514321452887e-06,
      "loss": 0.0003,
      "step": 15906
    },
    {
      "epoch": 0.25186440141235333,
      "grad_norm": 0.457502156496048,
      "learning_rate": 7.481355985876467e-06,
      "loss": 0.0487,
      "step": 15907
    },
    {
      "epoch": 0.2518802349699954,
      "grad_norm": 0.20452314615249634,
      "learning_rate": 7.481197650300046e-06,
      "loss": 0.0508,
      "step": 15908
    },
    {
      "epoch": 0.25189606852763746,
      "grad_norm": 0.5011362433433533,
      "learning_rate": 7.481039314723626e-06,
      "loss": 0.4141,
      "step": 15909
    },
    {
      "epoch": 0.2519119020852795,
      "grad_norm": 0.4902553856372833,
      "learning_rate": 7.4808809791472045e-06,
      "loss": 0.3602,
      "step": 15910
    },
    {
      "epoch": 0.2519277356429216,
      "grad_norm": 0.3726810812950134,
      "learning_rate": 7.4807226435707845e-06,
      "loss": 0.1171,
      "step": 15911
    },
    {
      "epoch": 0.25194356920056366,
      "grad_norm": 0.9748777747154236,
      "learning_rate": 7.4805643079943635e-06,
      "loss": 0.3878,
      "step": 15912
    },
    {
      "epoch": 0.2519594027582057,
      "grad_norm": 0.28179311752319336,
      "learning_rate": 7.4804059724179435e-06,
      "loss": 0.0309,
      "step": 15913
    },
    {
      "epoch": 0.2519752363158478,
      "grad_norm": 0.24442623555660248,
      "learning_rate": 7.4802476368415226e-06,
      "loss": 0.0186,
      "step": 15914
    },
    {
      "epoch": 0.25199106987348985,
      "grad_norm": 0.22165177762508392,
      "learning_rate": 7.4800893012651025e-06,
      "loss": 0.0769,
      "step": 15915
    },
    {
      "epoch": 0.25200690343113197,
      "grad_norm": 0.0191235039383173,
      "learning_rate": 7.479930965688681e-06,
      "loss": 0.0004,
      "step": 15916
    },
    {
      "epoch": 0.25202273698877403,
      "grad_norm": 0.7217633724212646,
      "learning_rate": 7.479772630112261e-06,
      "loss": 0.1889,
      "step": 15917
    },
    {
      "epoch": 0.2520385705464161,
      "grad_norm": 0.7830039262771606,
      "learning_rate": 7.47961429453584e-06,
      "loss": 0.27,
      "step": 15918
    },
    {
      "epoch": 0.25205440410405816,
      "grad_norm": 0.4115298092365265,
      "learning_rate": 7.47945595895942e-06,
      "loss": 0.1272,
      "step": 15919
    },
    {
      "epoch": 0.2520702376617002,
      "grad_norm": 1.2931867837905884,
      "learning_rate": 7.479297623382999e-06,
      "loss": 0.784,
      "step": 15920
    },
    {
      "epoch": 0.2520860712193423,
      "grad_norm": 0.01273108646273613,
      "learning_rate": 7.479139287806579e-06,
      "loss": 0.0005,
      "step": 15921
    },
    {
      "epoch": 0.25210190477698435,
      "grad_norm": 0.2559022307395935,
      "learning_rate": 7.478980952230157e-06,
      "loss": 0.0684,
      "step": 15922
    },
    {
      "epoch": 0.2521177383346264,
      "grad_norm": 0.015939556062221527,
      "learning_rate": 7.478822616653737e-06,
      "loss": 0.0008,
      "step": 15923
    },
    {
      "epoch": 0.2521335718922685,
      "grad_norm": 0.5015729069709778,
      "learning_rate": 7.478664281077316e-06,
      "loss": 0.2825,
      "step": 15924
    },
    {
      "epoch": 0.25214940544991055,
      "grad_norm": 0.6009266376495361,
      "learning_rate": 7.478505945500896e-06,
      "loss": 0.2306,
      "step": 15925
    },
    {
      "epoch": 0.2521652390075526,
      "grad_norm": 0.0034082098864018917,
      "learning_rate": 7.478347609924475e-06,
      "loss": 0.0001,
      "step": 15926
    },
    {
      "epoch": 0.2521810725651947,
      "grad_norm": 0.6384435892105103,
      "learning_rate": 7.478189274348055e-06,
      "loss": 0.4388,
      "step": 15927
    },
    {
      "epoch": 0.25219690612283674,
      "grad_norm": 0.26384785771369934,
      "learning_rate": 7.478030938771633e-06,
      "loss": 0.0266,
      "step": 15928
    },
    {
      "epoch": 0.2522127396804788,
      "grad_norm": 0.9454010128974915,
      "learning_rate": 7.477872603195212e-06,
      "loss": 0.3715,
      "step": 15929
    },
    {
      "epoch": 0.25222857323812087,
      "grad_norm": 0.24500629305839539,
      "learning_rate": 7.477714267618792e-06,
      "loss": 0.0808,
      "step": 15930
    },
    {
      "epoch": 0.25224440679576293,
      "grad_norm": 0.0005456286016851664,
      "learning_rate": 7.477555932042371e-06,
      "loss": 0.0,
      "step": 15931
    },
    {
      "epoch": 0.252260240353405,
      "grad_norm": 0.6028624773025513,
      "learning_rate": 7.477397596465951e-06,
      "loss": 0.1561,
      "step": 15932
    },
    {
      "epoch": 0.25227607391104706,
      "grad_norm": 0.5882325768470764,
      "learning_rate": 7.477239260889529e-06,
      "loss": 0.1832,
      "step": 15933
    },
    {
      "epoch": 0.2522919074686891,
      "grad_norm": 0.02294999733567238,
      "learning_rate": 7.477080925313109e-06,
      "loss": 0.0009,
      "step": 15934
    },
    {
      "epoch": 0.2523077410263312,
      "grad_norm": 0.7425714135169983,
      "learning_rate": 7.476922589736688e-06,
      "loss": 0.6764,
      "step": 15935
    },
    {
      "epoch": 0.25232357458397325,
      "grad_norm": 0.30067408084869385,
      "learning_rate": 7.476764254160268e-06,
      "loss": 0.1043,
      "step": 15936
    },
    {
      "epoch": 0.2523394081416153,
      "grad_norm": 0.013893578201532364,
      "learning_rate": 7.4766059185838465e-06,
      "loss": 0.0007,
      "step": 15937
    },
    {
      "epoch": 0.2523552416992574,
      "grad_norm": 0.014848168008029461,
      "learning_rate": 7.476447583007426e-06,
      "loss": 0.0005,
      "step": 15938
    },
    {
      "epoch": 0.25237107525689945,
      "grad_norm": 0.008745156228542328,
      "learning_rate": 7.4762892474310055e-06,
      "loss": 0.0003,
      "step": 15939
    },
    {
      "epoch": 0.25238690881454157,
      "grad_norm": 0.21238873898983002,
      "learning_rate": 7.476130911854585e-06,
      "loss": 0.0545,
      "step": 15940
    },
    {
      "epoch": 0.25240274237218363,
      "grad_norm": 0.6199954152107239,
      "learning_rate": 7.4759725762781645e-06,
      "loss": 0.0743,
      "step": 15941
    },
    {
      "epoch": 0.2524185759298257,
      "grad_norm": 0.021297184750437737,
      "learning_rate": 7.475814240701744e-06,
      "loss": 0.0008,
      "step": 15942
    },
    {
      "epoch": 0.25243440948746776,
      "grad_norm": 0.2928018271923065,
      "learning_rate": 7.475655905125323e-06,
      "loss": 0.1347,
      "step": 15943
    },
    {
      "epoch": 0.2524502430451098,
      "grad_norm": 0.7923009991645813,
      "learning_rate": 7.4754975695489026e-06,
      "loss": 0.0633,
      "step": 15944
    },
    {
      "epoch": 0.2524660766027519,
      "grad_norm": 0.3446462154388428,
      "learning_rate": 7.475339233972482e-06,
      "loss": 0.2087,
      "step": 15945
    },
    {
      "epoch": 0.25248191016039395,
      "grad_norm": 0.2155812382698059,
      "learning_rate": 7.4751808983960616e-06,
      "loss": 0.0265,
      "step": 15946
    },
    {
      "epoch": 0.252497743718036,
      "grad_norm": 0.012699199840426445,
      "learning_rate": 7.475022562819641e-06,
      "loss": 0.0006,
      "step": 15947
    },
    {
      "epoch": 0.2525135772756781,
      "grad_norm": 0.7107772827148438,
      "learning_rate": 7.4748642272432206e-06,
      "loss": 0.1961,
      "step": 15948
    },
    {
      "epoch": 0.25252941083332014,
      "grad_norm": 0.6232480406761169,
      "learning_rate": 7.474705891666799e-06,
      "loss": 0.2979,
      "step": 15949
    },
    {
      "epoch": 0.2525452443909622,
      "grad_norm": 0.5914066433906555,
      "learning_rate": 7.474547556090379e-06,
      "loss": 0.3955,
      "step": 15950
    },
    {
      "epoch": 0.2525610779486043,
      "grad_norm": 1.181532621383667,
      "learning_rate": 7.474389220513958e-06,
      "loss": 0.2744,
      "step": 15951
    },
    {
      "epoch": 0.25257691150624634,
      "grad_norm": 0.37428003549575806,
      "learning_rate": 7.474230884937537e-06,
      "loss": 0.1052,
      "step": 15952
    },
    {
      "epoch": 0.2525927450638884,
      "grad_norm": 0.30664071440696716,
      "learning_rate": 7.474072549361117e-06,
      "loss": 0.0486,
      "step": 15953
    },
    {
      "epoch": 0.25260857862153047,
      "grad_norm": 0.44262781739234924,
      "learning_rate": 7.473914213784695e-06,
      "loss": 0.1885,
      "step": 15954
    },
    {
      "epoch": 0.25262441217917253,
      "grad_norm": 0.0013089814456179738,
      "learning_rate": 7.473755878208275e-06,
      "loss": 0.0,
      "step": 15955
    },
    {
      "epoch": 0.2526402457368146,
      "grad_norm": 0.30221566557884216,
      "learning_rate": 7.473597542631854e-06,
      "loss": 0.0578,
      "step": 15956
    },
    {
      "epoch": 0.25265607929445666,
      "grad_norm": 0.932201623916626,
      "learning_rate": 7.473439207055434e-06,
      "loss": 0.0554,
      "step": 15957
    },
    {
      "epoch": 0.2526719128520987,
      "grad_norm": 0.008754247799515724,
      "learning_rate": 7.473280871479013e-06,
      "loss": 0.0003,
      "step": 15958
    },
    {
      "epoch": 0.2526877464097408,
      "grad_norm": 0.4422294795513153,
      "learning_rate": 7.473122535902593e-06,
      "loss": 0.0734,
      "step": 15959
    },
    {
      "epoch": 0.25270357996738285,
      "grad_norm": 0.025676466524600983,
      "learning_rate": 7.472964200326171e-06,
      "loss": 0.001,
      "step": 15960
    },
    {
      "epoch": 0.2527194135250249,
      "grad_norm": 0.0022889585234224796,
      "learning_rate": 7.472805864749751e-06,
      "loss": 0.0001,
      "step": 15961
    },
    {
      "epoch": 0.252735247082667,
      "grad_norm": 0.48975151777267456,
      "learning_rate": 7.47264752917333e-06,
      "loss": 0.0566,
      "step": 15962
    },
    {
      "epoch": 0.25275108064030904,
      "grad_norm": 8.257513400167227e-05,
      "learning_rate": 7.47248919359691e-06,
      "loss": 0.0,
      "step": 15963
    },
    {
      "epoch": 0.25276691419795116,
      "grad_norm": 0.20128154754638672,
      "learning_rate": 7.472330858020489e-06,
      "loss": 0.0881,
      "step": 15964
    },
    {
      "epoch": 0.25278274775559323,
      "grad_norm": 0.29629337787628174,
      "learning_rate": 7.472172522444069e-06,
      "loss": 0.0596,
      "step": 15965
    },
    {
      "epoch": 0.2527985813132353,
      "grad_norm": 0.7798234224319458,
      "learning_rate": 7.472014186867647e-06,
      "loss": 0.3988,
      "step": 15966
    },
    {
      "epoch": 0.25281441487087736,
      "grad_norm": 0.48304489254951477,
      "learning_rate": 7.471855851291227e-06,
      "loss": 0.0627,
      "step": 15967
    },
    {
      "epoch": 0.2528302484285194,
      "grad_norm": 0.00029022363014519215,
      "learning_rate": 7.471697515714806e-06,
      "loss": 0.0,
      "step": 15968
    },
    {
      "epoch": 0.2528460819861615,
      "grad_norm": 0.2725495398044586,
      "learning_rate": 7.471539180138386e-06,
      "loss": 0.0093,
      "step": 15969
    },
    {
      "epoch": 0.25286191554380355,
      "grad_norm": 0.6253147721290588,
      "learning_rate": 7.471380844561965e-06,
      "loss": 0.092,
      "step": 15970
    },
    {
      "epoch": 0.2528777491014456,
      "grad_norm": 0.008908435702323914,
      "learning_rate": 7.471222508985545e-06,
      "loss": 0.0003,
      "step": 15971
    },
    {
      "epoch": 0.2528935826590877,
      "grad_norm": 0.5574468374252319,
      "learning_rate": 7.4710641734091236e-06,
      "loss": 0.3912,
      "step": 15972
    },
    {
      "epoch": 0.25290941621672974,
      "grad_norm": 0.24827145040035248,
      "learning_rate": 7.4709058378327035e-06,
      "loss": 0.0597,
      "step": 15973
    },
    {
      "epoch": 0.2529252497743718,
      "grad_norm": 0.6241735219955444,
      "learning_rate": 7.4707475022562826e-06,
      "loss": 0.2577,
      "step": 15974
    },
    {
      "epoch": 0.25294108333201387,
      "grad_norm": 0.09948664158582687,
      "learning_rate": 7.4705891666798625e-06,
      "loss": 0.0045,
      "step": 15975
    },
    {
      "epoch": 0.25295691688965594,
      "grad_norm": 0.32077354192733765,
      "learning_rate": 7.470430831103442e-06,
      "loss": 0.069,
      "step": 15976
    },
    {
      "epoch": 0.252972750447298,
      "grad_norm": 0.0008328371914103627,
      "learning_rate": 7.47027249552702e-06,
      "loss": 0.0,
      "step": 15977
    },
    {
      "epoch": 0.25298858400494006,
      "grad_norm": 0.0757310763001442,
      "learning_rate": 7.4701141599506e-06,
      "loss": 0.0026,
      "step": 15978
    },
    {
      "epoch": 0.25300441756258213,
      "grad_norm": 0.9506154656410217,
      "learning_rate": 7.469955824374179e-06,
      "loss": 0.372,
      "step": 15979
    },
    {
      "epoch": 0.2530202511202242,
      "grad_norm": 0.2819945216178894,
      "learning_rate": 7.469797488797759e-06,
      "loss": 0.0715,
      "step": 15980
    },
    {
      "epoch": 0.25303608467786626,
      "grad_norm": 0.2089693695306778,
      "learning_rate": 7.469639153221338e-06,
      "loss": 0.0082,
      "step": 15981
    },
    {
      "epoch": 0.2530519182355083,
      "grad_norm": 0.5383710861206055,
      "learning_rate": 7.469480817644918e-06,
      "loss": 0.091,
      "step": 15982
    },
    {
      "epoch": 0.2530677517931504,
      "grad_norm": 0.34056565165519714,
      "learning_rate": 7.469322482068496e-06,
      "loss": 0.0726,
      "step": 15983
    },
    {
      "epoch": 0.25308358535079245,
      "grad_norm": 0.3741728961467743,
      "learning_rate": 7.469164146492076e-06,
      "loss": 0.0982,
      "step": 15984
    },
    {
      "epoch": 0.2530994189084345,
      "grad_norm": 0.02647765539586544,
      "learning_rate": 7.469005810915655e-06,
      "loss": 0.0013,
      "step": 15985
    },
    {
      "epoch": 0.2531152524660766,
      "grad_norm": 0.40624067187309265,
      "learning_rate": 7.468847475339235e-06,
      "loss": 0.322,
      "step": 15986
    },
    {
      "epoch": 0.25313108602371864,
      "grad_norm": 0.929705798625946,
      "learning_rate": 7.468689139762814e-06,
      "loss": 0.2979,
      "step": 15987
    },
    {
      "epoch": 0.25314691958136076,
      "grad_norm": 0.2362053096294403,
      "learning_rate": 7.468530804186394e-06,
      "loss": 0.0484,
      "step": 15988
    },
    {
      "epoch": 0.2531627531390028,
      "grad_norm": 0.3706931471824646,
      "learning_rate": 7.468372468609972e-06,
      "loss": 0.241,
      "step": 15989
    },
    {
      "epoch": 0.2531785866966449,
      "grad_norm": 0.1842486709356308,
      "learning_rate": 7.468214133033552e-06,
      "loss": 0.0344,
      "step": 15990
    },
    {
      "epoch": 0.25319442025428696,
      "grad_norm": 0.3585478365421295,
      "learning_rate": 7.468055797457131e-06,
      "loss": 0.0466,
      "step": 15991
    },
    {
      "epoch": 0.253210253811929,
      "grad_norm": 0.72962486743927,
      "learning_rate": 7.467897461880711e-06,
      "loss": 0.0929,
      "step": 15992
    },
    {
      "epoch": 0.2532260873695711,
      "grad_norm": 0.0002629208320286125,
      "learning_rate": 7.46773912630429e-06,
      "loss": 0.0,
      "step": 15993
    },
    {
      "epoch": 0.25324192092721315,
      "grad_norm": 0.23324531316757202,
      "learning_rate": 7.46758079072787e-06,
      "loss": 0.0087,
      "step": 15994
    },
    {
      "epoch": 0.2532577544848552,
      "grad_norm": 0.12413346767425537,
      "learning_rate": 7.467422455151448e-06,
      "loss": 0.0056,
      "step": 15995
    },
    {
      "epoch": 0.2532735880424973,
      "grad_norm": 0.38512030243873596,
      "learning_rate": 7.467264119575028e-06,
      "loss": 0.1055,
      "step": 15996
    },
    {
      "epoch": 0.25328942160013934,
      "grad_norm": 0.28072497248649597,
      "learning_rate": 7.467105783998607e-06,
      "loss": 0.0599,
      "step": 15997
    },
    {
      "epoch": 0.2533052551577814,
      "grad_norm": 1.0123167037963867,
      "learning_rate": 7.466947448422187e-06,
      "loss": 0.0294,
      "step": 15998
    },
    {
      "epoch": 0.25332108871542347,
      "grad_norm": 0.46156400442123413,
      "learning_rate": 7.4667891128457655e-06,
      "loss": 0.1972,
      "step": 15999
    },
    {
      "epoch": 0.25333692227306553,
      "grad_norm": 0.4938162565231323,
      "learning_rate": 7.4666307772693446e-06,
      "loss": 0.424,
      "step": 16000
    },
    {
      "epoch": 0.2533527558307076,
      "grad_norm": 0.013833179138600826,
      "learning_rate": 7.4664724416929245e-06,
      "loss": 0.0005,
      "step": 16001
    },
    {
      "epoch": 0.25336858938834966,
      "grad_norm": 0.6696054339408875,
      "learning_rate": 7.4663141061165036e-06,
      "loss": 0.0845,
      "step": 16002
    },
    {
      "epoch": 0.2533844229459917,
      "grad_norm": 0.0005719978362321854,
      "learning_rate": 7.4661557705400835e-06,
      "loss": 0.0,
      "step": 16003
    },
    {
      "epoch": 0.2534002565036338,
      "grad_norm": 0.028609124943614006,
      "learning_rate": 7.465997434963662e-06,
      "loss": 0.0013,
      "step": 16004
    },
    {
      "epoch": 0.25341609006127586,
      "grad_norm": 0.4367363452911377,
      "learning_rate": 7.465839099387242e-06,
      "loss": 0.1182,
      "step": 16005
    },
    {
      "epoch": 0.2534319236189179,
      "grad_norm": 0.3708958923816681,
      "learning_rate": 7.465680763810821e-06,
      "loss": 0.099,
      "step": 16006
    },
    {
      "epoch": 0.25344775717656,
      "grad_norm": 0.2596947252750397,
      "learning_rate": 7.465522428234401e-06,
      "loss": 0.0539,
      "step": 16007
    },
    {
      "epoch": 0.25346359073420205,
      "grad_norm": 0.021692030131816864,
      "learning_rate": 7.46536409265798e-06,
      "loss": 0.0013,
      "step": 16008
    },
    {
      "epoch": 0.2534794242918441,
      "grad_norm": 0.20364058017730713,
      "learning_rate": 7.46520575708156e-06,
      "loss": 0.0496,
      "step": 16009
    },
    {
      "epoch": 0.2534952578494862,
      "grad_norm": 0.49384796619415283,
      "learning_rate": 7.465047421505138e-06,
      "loss": 0.1945,
      "step": 16010
    },
    {
      "epoch": 0.25351109140712824,
      "grad_norm": 0.17866720259189606,
      "learning_rate": 7.464889085928718e-06,
      "loss": 0.0762,
      "step": 16011
    },
    {
      "epoch": 0.25352692496477036,
      "grad_norm": 0.022974269464612007,
      "learning_rate": 7.464730750352297e-06,
      "loss": 0.0012,
      "step": 16012
    },
    {
      "epoch": 0.2535427585224124,
      "grad_norm": 0.32728826999664307,
      "learning_rate": 7.464572414775877e-06,
      "loss": 0.1002,
      "step": 16013
    },
    {
      "epoch": 0.2535585920800545,
      "grad_norm": 0.02513616532087326,
      "learning_rate": 7.464414079199456e-06,
      "loss": 0.0013,
      "step": 16014
    },
    {
      "epoch": 0.25357442563769655,
      "grad_norm": 0.0001762496103765443,
      "learning_rate": 7.464255743623036e-06,
      "loss": 0.0,
      "step": 16015
    },
    {
      "epoch": 0.2535902591953386,
      "grad_norm": 0.006295040715485811,
      "learning_rate": 7.464097408046614e-06,
      "loss": 0.0003,
      "step": 16016
    },
    {
      "epoch": 0.2536060927529807,
      "grad_norm": 0.001607796992175281,
      "learning_rate": 7.463939072470194e-06,
      "loss": 0.0001,
      "step": 16017
    },
    {
      "epoch": 0.25362192631062275,
      "grad_norm": 0.4550245404243469,
      "learning_rate": 7.463780736893773e-06,
      "loss": 0.0851,
      "step": 16018
    },
    {
      "epoch": 0.2536377598682648,
      "grad_norm": 0.11863326281309128,
      "learning_rate": 7.463622401317353e-06,
      "loss": 0.0039,
      "step": 16019
    },
    {
      "epoch": 0.2536535934259069,
      "grad_norm": 0.44455358386039734,
      "learning_rate": 7.463464065740932e-06,
      "loss": 0.1703,
      "step": 16020
    },
    {
      "epoch": 0.25366942698354894,
      "grad_norm": 0.3069482743740082,
      "learning_rate": 7.463305730164512e-06,
      "loss": 0.0728,
      "step": 16021
    },
    {
      "epoch": 0.253685260541191,
      "grad_norm": 0.23245590925216675,
      "learning_rate": 7.46314739458809e-06,
      "loss": 0.0688,
      "step": 16022
    },
    {
      "epoch": 0.25370109409883307,
      "grad_norm": 0.8203363418579102,
      "learning_rate": 7.46298905901167e-06,
      "loss": 0.1882,
      "step": 16023
    },
    {
      "epoch": 0.25371692765647513,
      "grad_norm": 0.011937807314097881,
      "learning_rate": 7.462830723435249e-06,
      "loss": 0.0007,
      "step": 16024
    },
    {
      "epoch": 0.2537327612141172,
      "grad_norm": 0.24527902901172638,
      "learning_rate": 7.462672387858828e-06,
      "loss": 0.0679,
      "step": 16025
    },
    {
      "epoch": 0.25374859477175926,
      "grad_norm": 0.7245373725891113,
      "learning_rate": 7.462514052282408e-06,
      "loss": 0.2109,
      "step": 16026
    },
    {
      "epoch": 0.2537644283294013,
      "grad_norm": 0.19426760077476501,
      "learning_rate": 7.4623557167059865e-06,
      "loss": 0.0737,
      "step": 16027
    },
    {
      "epoch": 0.2537802618870434,
      "grad_norm": 0.296090304851532,
      "learning_rate": 7.462197381129566e-06,
      "loss": 0.1867,
      "step": 16028
    },
    {
      "epoch": 0.25379609544468545,
      "grad_norm": 0.5976754426956177,
      "learning_rate": 7.4620390455531455e-06,
      "loss": 0.4574,
      "step": 16029
    },
    {
      "epoch": 0.2538119290023275,
      "grad_norm": 0.015729181468486786,
      "learning_rate": 7.4618807099767254e-06,
      "loss": 0.0007,
      "step": 16030
    },
    {
      "epoch": 0.2538277625599696,
      "grad_norm": 0.6540662050247192,
      "learning_rate": 7.4617223744003045e-06,
      "loss": 0.5858,
      "step": 16031
    },
    {
      "epoch": 0.25384359611761165,
      "grad_norm": 0.2411598414182663,
      "learning_rate": 7.4615640388238844e-06,
      "loss": 0.0333,
      "step": 16032
    },
    {
      "epoch": 0.2538594296752537,
      "grad_norm": 0.018514540046453476,
      "learning_rate": 7.461405703247463e-06,
      "loss": 0.0009,
      "step": 16033
    },
    {
      "epoch": 0.2538752632328958,
      "grad_norm": 0.3445708453655243,
      "learning_rate": 7.461247367671043e-06,
      "loss": 0.7652,
      "step": 16034
    },
    {
      "epoch": 0.25389109679053784,
      "grad_norm": 0.16739927232265472,
      "learning_rate": 7.461089032094622e-06,
      "loss": 0.006,
      "step": 16035
    },
    {
      "epoch": 0.25390693034817996,
      "grad_norm": 0.13935735821723938,
      "learning_rate": 7.460930696518202e-06,
      "loss": 0.0087,
      "step": 16036
    },
    {
      "epoch": 0.253922763905822,
      "grad_norm": 0.3971875309944153,
      "learning_rate": 7.460772360941781e-06,
      "loss": 0.181,
      "step": 16037
    },
    {
      "epoch": 0.2539385974634641,
      "grad_norm": 0.42837268114089966,
      "learning_rate": 7.460614025365361e-06,
      "loss": 0.1194,
      "step": 16038
    },
    {
      "epoch": 0.25395443102110615,
      "grad_norm": 0.11889965087175369,
      "learning_rate": 7.460455689788939e-06,
      "loss": 0.0111,
      "step": 16039
    },
    {
      "epoch": 0.2539702645787482,
      "grad_norm": 0.29313230514526367,
      "learning_rate": 7.460297354212519e-06,
      "loss": 0.0921,
      "step": 16040
    },
    {
      "epoch": 0.2539860981363903,
      "grad_norm": 0.5365990996360779,
      "learning_rate": 7.460139018636098e-06,
      "loss": 0.1919,
      "step": 16041
    },
    {
      "epoch": 0.25400193169403235,
      "grad_norm": 0.4781733751296997,
      "learning_rate": 7.459980683059678e-06,
      "loss": 0.0575,
      "step": 16042
    },
    {
      "epoch": 0.2540177652516744,
      "grad_norm": 0.33616963028907776,
      "learning_rate": 7.459822347483257e-06,
      "loss": 0.117,
      "step": 16043
    },
    {
      "epoch": 0.2540335988093165,
      "grad_norm": 0.548926591873169,
      "learning_rate": 7.459664011906837e-06,
      "loss": 0.1902,
      "step": 16044
    },
    {
      "epoch": 0.25404943236695854,
      "grad_norm": 0.5130295157432556,
      "learning_rate": 7.459505676330415e-06,
      "loss": 0.1517,
      "step": 16045
    },
    {
      "epoch": 0.2540652659246006,
      "grad_norm": 0.5802887082099915,
      "learning_rate": 7.459347340753995e-06,
      "loss": 0.1271,
      "step": 16046
    },
    {
      "epoch": 0.25408109948224267,
      "grad_norm": 0.46539372205734253,
      "learning_rate": 7.459189005177574e-06,
      "loss": 0.1162,
      "step": 16047
    },
    {
      "epoch": 0.25409693303988473,
      "grad_norm": 0.7721487283706665,
      "learning_rate": 7.459030669601153e-06,
      "loss": 0.7059,
      "step": 16048
    },
    {
      "epoch": 0.2541127665975268,
      "grad_norm": 0.2893349826335907,
      "learning_rate": 7.458872334024733e-06,
      "loss": 0.0386,
      "step": 16049
    },
    {
      "epoch": 0.25412860015516886,
      "grad_norm": 0.5745692849159241,
      "learning_rate": 7.458713998448311e-06,
      "loss": 0.1458,
      "step": 16050
    },
    {
      "epoch": 0.2541444337128109,
      "grad_norm": 0.5572883486747742,
      "learning_rate": 7.458555662871891e-06,
      "loss": 0.2071,
      "step": 16051
    },
    {
      "epoch": 0.254160267270453,
      "grad_norm": 0.5968901515007019,
      "learning_rate": 7.45839732729547e-06,
      "loss": 0.3743,
      "step": 16052
    },
    {
      "epoch": 0.25417610082809505,
      "grad_norm": 0.39212220907211304,
      "learning_rate": 7.45823899171905e-06,
      "loss": 0.0795,
      "step": 16053
    },
    {
      "epoch": 0.2541919343857371,
      "grad_norm": 0.962415337562561,
      "learning_rate": 7.458080656142629e-06,
      "loss": 0.2043,
      "step": 16054
    },
    {
      "epoch": 0.2542077679433792,
      "grad_norm": 0.25445327162742615,
      "learning_rate": 7.457922320566209e-06,
      "loss": 0.2606,
      "step": 16055
    },
    {
      "epoch": 0.25422360150102125,
      "grad_norm": 0.012380331754684448,
      "learning_rate": 7.4577639849897874e-06,
      "loss": 0.0005,
      "step": 16056
    },
    {
      "epoch": 0.2542394350586633,
      "grad_norm": 0.2798929810523987,
      "learning_rate": 7.457605649413367e-06,
      "loss": 0.047,
      "step": 16057
    },
    {
      "epoch": 0.2542552686163054,
      "grad_norm": 0.007793815806508064,
      "learning_rate": 7.4574473138369464e-06,
      "loss": 0.0004,
      "step": 16058
    },
    {
      "epoch": 0.25427110217394744,
      "grad_norm": 0.008278978057205677,
      "learning_rate": 7.457288978260526e-06,
      "loss": 0.0003,
      "step": 16059
    },
    {
      "epoch": 0.25428693573158956,
      "grad_norm": 0.0053031775169074535,
      "learning_rate": 7.4571306426841054e-06,
      "loss": 0.0002,
      "step": 16060
    },
    {
      "epoch": 0.2543027692892316,
      "grad_norm": 0.5904815196990967,
      "learning_rate": 7.4569723071076845e-06,
      "loss": 0.0287,
      "step": 16061
    },
    {
      "epoch": 0.2543186028468737,
      "grad_norm": 0.33974745869636536,
      "learning_rate": 7.456813971531264e-06,
      "loss": 0.131,
      "step": 16062
    },
    {
      "epoch": 0.25433443640451575,
      "grad_norm": 0.32346662878990173,
      "learning_rate": 7.4566556359548435e-06,
      "loss": 0.0457,
      "step": 16063
    },
    {
      "epoch": 0.2543502699621578,
      "grad_norm": 0.0035815476439893246,
      "learning_rate": 7.456497300378423e-06,
      "loss": 0.0001,
      "step": 16064
    },
    {
      "epoch": 0.2543661035197999,
      "grad_norm": 0.3206154704093933,
      "learning_rate": 7.4563389648020025e-06,
      "loss": 0.0527,
      "step": 16065
    },
    {
      "epoch": 0.25438193707744194,
      "grad_norm": 0.768944501876831,
      "learning_rate": 7.456180629225581e-06,
      "loss": 0.0638,
      "step": 16066
    },
    {
      "epoch": 0.254397770635084,
      "grad_norm": 6.305595161393285e-05,
      "learning_rate": 7.456022293649161e-06,
      "loss": 0.0,
      "step": 16067
    },
    {
      "epoch": 0.2544136041927261,
      "grad_norm": 0.9165416955947876,
      "learning_rate": 7.45586395807274e-06,
      "loss": 0.5008,
      "step": 16068
    },
    {
      "epoch": 0.25442943775036814,
      "grad_norm": 0.15222492814064026,
      "learning_rate": 7.45570562249632e-06,
      "loss": 0.0652,
      "step": 16069
    },
    {
      "epoch": 0.2544452713080102,
      "grad_norm": 0.19505877792835236,
      "learning_rate": 7.455547286919899e-06,
      "loss": 0.0661,
      "step": 16070
    },
    {
      "epoch": 0.25446110486565227,
      "grad_norm": 0.24031129479408264,
      "learning_rate": 7.455388951343479e-06,
      "loss": 0.0795,
      "step": 16071
    },
    {
      "epoch": 0.25447693842329433,
      "grad_norm": 0.38298964500427246,
      "learning_rate": 7.455230615767057e-06,
      "loss": 0.0975,
      "step": 16072
    },
    {
      "epoch": 0.2544927719809364,
      "grad_norm": 0.5932328104972839,
      "learning_rate": 7.455072280190636e-06,
      "loss": 0.756,
      "step": 16073
    },
    {
      "epoch": 0.25450860553857846,
      "grad_norm": 7.017545431153849e-05,
      "learning_rate": 7.454913944614216e-06,
      "loss": 0.0,
      "step": 16074
    },
    {
      "epoch": 0.2545244390962205,
      "grad_norm": 0.19297148287296295,
      "learning_rate": 7.454755609037795e-06,
      "loss": 0.0629,
      "step": 16075
    },
    {
      "epoch": 0.2545402726538626,
      "grad_norm": 0.545145571231842,
      "learning_rate": 7.454597273461375e-06,
      "loss": 0.254,
      "step": 16076
    },
    {
      "epoch": 0.25455610621150465,
      "grad_norm": 0.3693079352378845,
      "learning_rate": 7.454438937884953e-06,
      "loss": 0.1434,
      "step": 16077
    },
    {
      "epoch": 0.2545719397691467,
      "grad_norm": 0.634955108165741,
      "learning_rate": 7.454280602308533e-06,
      "loss": 0.6164,
      "step": 16078
    },
    {
      "epoch": 0.2545877733267888,
      "grad_norm": 0.5250701904296875,
      "learning_rate": 7.454122266732112e-06,
      "loss": 0.0994,
      "step": 16079
    },
    {
      "epoch": 0.25460360688443084,
      "grad_norm": 0.0004982421523891389,
      "learning_rate": 7.453963931155692e-06,
      "loss": 0.0,
      "step": 16080
    },
    {
      "epoch": 0.2546194404420729,
      "grad_norm": 0.051078323274850845,
      "learning_rate": 7.453805595579271e-06,
      "loss": 0.0031,
      "step": 16081
    },
    {
      "epoch": 0.254635273999715,
      "grad_norm": 0.49292615056037903,
      "learning_rate": 7.453647260002851e-06,
      "loss": 0.038,
      "step": 16082
    },
    {
      "epoch": 0.25465110755735704,
      "grad_norm": 0.2429303526878357,
      "learning_rate": 7.453488924426429e-06,
      "loss": 0.03,
      "step": 16083
    },
    {
      "epoch": 0.25466694111499916,
      "grad_norm": 0.02742178551852703,
      "learning_rate": 7.453330588850009e-06,
      "loss": 0.001,
      "step": 16084
    },
    {
      "epoch": 0.2546827746726412,
      "grad_norm": 0.19023309648036957,
      "learning_rate": 7.453172253273588e-06,
      "loss": 0.0276,
      "step": 16085
    },
    {
      "epoch": 0.2546986082302833,
      "grad_norm": 0.6337363719940186,
      "learning_rate": 7.453013917697168e-06,
      "loss": 0.4797,
      "step": 16086
    },
    {
      "epoch": 0.25471444178792535,
      "grad_norm": 0.04711846262216568,
      "learning_rate": 7.452855582120747e-06,
      "loss": 0.0029,
      "step": 16087
    },
    {
      "epoch": 0.2547302753455674,
      "grad_norm": 0.2924010455608368,
      "learning_rate": 7.452697246544327e-06,
      "loss": 0.1815,
      "step": 16088
    },
    {
      "epoch": 0.2547461089032095,
      "grad_norm": 0.31940221786499023,
      "learning_rate": 7.4525389109679055e-06,
      "loss": 0.0122,
      "step": 16089
    },
    {
      "epoch": 0.25476194246085154,
      "grad_norm": 0.010575646534562111,
      "learning_rate": 7.4523805753914854e-06,
      "loss": 0.0005,
      "step": 16090
    },
    {
      "epoch": 0.2547777760184936,
      "grad_norm": 0.27274683117866516,
      "learning_rate": 7.4522222398150645e-06,
      "loss": 0.109,
      "step": 16091
    },
    {
      "epoch": 0.25479360957613567,
      "grad_norm": 0.6016289591789246,
      "learning_rate": 7.4520639042386445e-06,
      "loss": 0.447,
      "step": 16092
    },
    {
      "epoch": 0.25480944313377774,
      "grad_norm": 0.7940562963485718,
      "learning_rate": 7.4519055686622235e-06,
      "loss": 0.3718,
      "step": 16093
    },
    {
      "epoch": 0.2548252766914198,
      "grad_norm": 0.6743248701095581,
      "learning_rate": 7.4517472330858035e-06,
      "loss": 0.1673,
      "step": 16094
    },
    {
      "epoch": 0.25484111024906186,
      "grad_norm": 0.28090181946754456,
      "learning_rate": 7.451588897509382e-06,
      "loss": 0.0242,
      "step": 16095
    },
    {
      "epoch": 0.25485694380670393,
      "grad_norm": 0.0523420125246048,
      "learning_rate": 7.451430561932962e-06,
      "loss": 0.0044,
      "step": 16096
    },
    {
      "epoch": 0.254872777364346,
      "grad_norm": 0.021223057061433792,
      "learning_rate": 7.451272226356541e-06,
      "loss": 0.0009,
      "step": 16097
    },
    {
      "epoch": 0.25488861092198806,
      "grad_norm": 0.0006553619750775397,
      "learning_rate": 7.45111389078012e-06,
      "loss": 0.0,
      "step": 16098
    },
    {
      "epoch": 0.2549044444796301,
      "grad_norm": 1.8339002132415771,
      "learning_rate": 7.4509555552037e-06,
      "loss": 0.4726,
      "step": 16099
    },
    {
      "epoch": 0.2549202780372722,
      "grad_norm": 0.26023390889167786,
      "learning_rate": 7.450797219627278e-06,
      "loss": 0.0569,
      "step": 16100
    },
    {
      "epoch": 0.25493611159491425,
      "grad_norm": 0.14429053664207458,
      "learning_rate": 7.450638884050858e-06,
      "loss": 0.0297,
      "step": 16101
    },
    {
      "epoch": 0.2549519451525563,
      "grad_norm": 1.555290937423706,
      "learning_rate": 7.450480548474437e-06,
      "loss": 0.1589,
      "step": 16102
    },
    {
      "epoch": 0.2549677787101984,
      "grad_norm": 0.3284464478492737,
      "learning_rate": 7.450322212898017e-06,
      "loss": 0.0493,
      "step": 16103
    },
    {
      "epoch": 0.25498361226784044,
      "grad_norm": 0.03507797792553902,
      "learning_rate": 7.450163877321596e-06,
      "loss": 0.0017,
      "step": 16104
    },
    {
      "epoch": 0.2549994458254825,
      "grad_norm": 0.6239413619041443,
      "learning_rate": 7.450005541745176e-06,
      "loss": 0.1727,
      "step": 16105
    },
    {
      "epoch": 0.25501527938312457,
      "grad_norm": 5.044124603271484,
      "learning_rate": 7.449847206168754e-06,
      "loss": 0.455,
      "step": 16106
    },
    {
      "epoch": 0.25503111294076664,
      "grad_norm": 0.16373172402381897,
      "learning_rate": 7.449688870592334e-06,
      "loss": 0.012,
      "step": 16107
    },
    {
      "epoch": 0.2550469464984087,
      "grad_norm": 0.007596288342028856,
      "learning_rate": 7.449530535015913e-06,
      "loss": 0.0004,
      "step": 16108
    },
    {
      "epoch": 0.2550627800560508,
      "grad_norm": 0.3653378486633301,
      "learning_rate": 7.449372199439493e-06,
      "loss": 0.0516,
      "step": 16109
    },
    {
      "epoch": 0.2550786136136929,
      "grad_norm": 0.04750896990299225,
      "learning_rate": 7.449213863863072e-06,
      "loss": 0.0026,
      "step": 16110
    },
    {
      "epoch": 0.25509444717133495,
      "grad_norm": 0.4351683259010315,
      "learning_rate": 7.449055528286652e-06,
      "loss": 0.1749,
      "step": 16111
    },
    {
      "epoch": 0.255110280728977,
      "grad_norm": 0.4392518699169159,
      "learning_rate": 7.44889719271023e-06,
      "loss": 0.2129,
      "step": 16112
    },
    {
      "epoch": 0.2551261142866191,
      "grad_norm": 0.06047850847244263,
      "learning_rate": 7.44873885713381e-06,
      "loss": 0.0034,
      "step": 16113
    },
    {
      "epoch": 0.25514194784426114,
      "grad_norm": 0.017209438607096672,
      "learning_rate": 7.448580521557389e-06,
      "loss": 0.0007,
      "step": 16114
    },
    {
      "epoch": 0.2551577814019032,
      "grad_norm": 0.11161107569932938,
      "learning_rate": 7.448422185980969e-06,
      "loss": 0.0197,
      "step": 16115
    },
    {
      "epoch": 0.25517361495954527,
      "grad_norm": 0.40410116314888,
      "learning_rate": 7.448263850404548e-06,
      "loss": 0.0871,
      "step": 16116
    },
    {
      "epoch": 0.25518944851718733,
      "grad_norm": 0.4653099775314331,
      "learning_rate": 7.448105514828128e-06,
      "loss": 0.1553,
      "step": 16117
    },
    {
      "epoch": 0.2552052820748294,
      "grad_norm": 0.49677082896232605,
      "learning_rate": 7.4479471792517065e-06,
      "loss": 0.479,
      "step": 16118
    },
    {
      "epoch": 0.25522111563247146,
      "grad_norm": 0.2850243151187897,
      "learning_rate": 7.447788843675286e-06,
      "loss": 0.1747,
      "step": 16119
    },
    {
      "epoch": 0.2552369491901135,
      "grad_norm": 0.46797165274620056,
      "learning_rate": 7.4476305080988655e-06,
      "loss": 0.1928,
      "step": 16120
    },
    {
      "epoch": 0.2552527827477556,
      "grad_norm": 0.06679564714431763,
      "learning_rate": 7.4474721725224445e-06,
      "loss": 0.0037,
      "step": 16121
    },
    {
      "epoch": 0.25526861630539766,
      "grad_norm": 0.00016486375534441322,
      "learning_rate": 7.4473138369460245e-06,
      "loss": 0.0,
      "step": 16122
    },
    {
      "epoch": 0.2552844498630397,
      "grad_norm": 0.8373832702636719,
      "learning_rate": 7.447155501369603e-06,
      "loss": 0.5314,
      "step": 16123
    },
    {
      "epoch": 0.2553002834206818,
      "grad_norm": 0.00043281851685605943,
      "learning_rate": 7.446997165793183e-06,
      "loss": 0.0,
      "step": 16124
    },
    {
      "epoch": 0.25531611697832385,
      "grad_norm": 0.34760957956314087,
      "learning_rate": 7.446838830216762e-06,
      "loss": 0.0675,
      "step": 16125
    },
    {
      "epoch": 0.2553319505359659,
      "grad_norm": 0.02137508988380432,
      "learning_rate": 7.446680494640342e-06,
      "loss": 0.0012,
      "step": 16126
    },
    {
      "epoch": 0.255347784093608,
      "grad_norm": 0.1979266107082367,
      "learning_rate": 7.446522159063921e-06,
      "loss": 0.0696,
      "step": 16127
    },
    {
      "epoch": 0.25536361765125004,
      "grad_norm": 0.0024908180348575115,
      "learning_rate": 7.4463638234875e-06,
      "loss": 0.0001,
      "step": 16128
    },
    {
      "epoch": 0.2553794512088921,
      "grad_norm": 0.4911486506462097,
      "learning_rate": 7.446205487911079e-06,
      "loss": 0.1597,
      "step": 16129
    },
    {
      "epoch": 0.25539528476653417,
      "grad_norm": 0.798158586025238,
      "learning_rate": 7.446047152334659e-06,
      "loss": 0.4706,
      "step": 16130
    },
    {
      "epoch": 0.25541111832417623,
      "grad_norm": 0.7236805558204651,
      "learning_rate": 7.445888816758238e-06,
      "loss": 0.1725,
      "step": 16131
    },
    {
      "epoch": 0.2554269518818183,
      "grad_norm": 0.4947947561740875,
      "learning_rate": 7.445730481181818e-06,
      "loss": 0.1335,
      "step": 16132
    },
    {
      "epoch": 0.2554427854394604,
      "grad_norm": 0.2767280340194702,
      "learning_rate": 7.445572145605396e-06,
      "loss": 0.0537,
      "step": 16133
    },
    {
      "epoch": 0.2554586189971025,
      "grad_norm": 9.364917787024751e-05,
      "learning_rate": 7.445413810028976e-06,
      "loss": 0.0,
      "step": 16134
    },
    {
      "epoch": 0.25547445255474455,
      "grad_norm": 0.0028134281747043133,
      "learning_rate": 7.445255474452555e-06,
      "loss": 0.0001,
      "step": 16135
    },
    {
      "epoch": 0.2554902861123866,
      "grad_norm": 0.6307706236839294,
      "learning_rate": 7.445097138876135e-06,
      "loss": 0.0288,
      "step": 16136
    },
    {
      "epoch": 0.2555061196700287,
      "grad_norm": 0.00668342737480998,
      "learning_rate": 7.444938803299714e-06,
      "loss": 0.0003,
      "step": 16137
    },
    {
      "epoch": 0.25552195322767074,
      "grad_norm": 0.22749926149845123,
      "learning_rate": 7.444780467723294e-06,
      "loss": 0.0779,
      "step": 16138
    },
    {
      "epoch": 0.2555377867853128,
      "grad_norm": 1.5963354110717773,
      "learning_rate": 7.444622132146872e-06,
      "loss": 0.6257,
      "step": 16139
    },
    {
      "epoch": 0.25555362034295487,
      "grad_norm": 0.4972650706768036,
      "learning_rate": 7.444463796570452e-06,
      "loss": 0.333,
      "step": 16140
    },
    {
      "epoch": 0.25556945390059693,
      "grad_norm": 0.20076298713684082,
      "learning_rate": 7.444305460994031e-06,
      "loss": 0.0635,
      "step": 16141
    },
    {
      "epoch": 0.255585287458239,
      "grad_norm": 0.15957970917224884,
      "learning_rate": 7.444147125417611e-06,
      "loss": 0.018,
      "step": 16142
    },
    {
      "epoch": 0.25560112101588106,
      "grad_norm": 0.277071088552475,
      "learning_rate": 7.44398878984119e-06,
      "loss": 0.0727,
      "step": 16143
    },
    {
      "epoch": 0.2556169545735231,
      "grad_norm": 1.581803560256958,
      "learning_rate": 7.44383045426477e-06,
      "loss": 0.2057,
      "step": 16144
    },
    {
      "epoch": 0.2556327881311652,
      "grad_norm": 0.435057669878006,
      "learning_rate": 7.443672118688348e-06,
      "loss": 0.2049,
      "step": 16145
    },
    {
      "epoch": 0.25564862168880725,
      "grad_norm": 0.00767661863937974,
      "learning_rate": 7.4435137831119275e-06,
      "loss": 0.0004,
      "step": 16146
    },
    {
      "epoch": 0.2556644552464493,
      "grad_norm": 0.513780951499939,
      "learning_rate": 7.443355447535507e-06,
      "loss": 0.3017,
      "step": 16147
    },
    {
      "epoch": 0.2556802888040914,
      "grad_norm": 0.1936037391424179,
      "learning_rate": 7.4431971119590865e-06,
      "loss": 0.0076,
      "step": 16148
    },
    {
      "epoch": 0.25569612236173345,
      "grad_norm": 0.3547000288963318,
      "learning_rate": 7.443038776382666e-06,
      "loss": 0.0965,
      "step": 16149
    },
    {
      "epoch": 0.2557119559193755,
      "grad_norm": 0.5861464738845825,
      "learning_rate": 7.442880440806245e-06,
      "loss": 0.0743,
      "step": 16150
    },
    {
      "epoch": 0.2557277894770176,
      "grad_norm": 0.6101319193840027,
      "learning_rate": 7.4427221052298245e-06,
      "loss": 0.2833,
      "step": 16151
    },
    {
      "epoch": 0.25574362303465964,
      "grad_norm": 0.6349557638168335,
      "learning_rate": 7.442563769653404e-06,
      "loss": 0.267,
      "step": 16152
    },
    {
      "epoch": 0.2557594565923017,
      "grad_norm": 0.5740742683410645,
      "learning_rate": 7.4424054340769836e-06,
      "loss": 0.0537,
      "step": 16153
    },
    {
      "epoch": 0.25577529014994377,
      "grad_norm": 0.27623918652534485,
      "learning_rate": 7.442247098500563e-06,
      "loss": 0.07,
      "step": 16154
    },
    {
      "epoch": 0.25579112370758583,
      "grad_norm": 0.007472263183444738,
      "learning_rate": 7.4420887629241426e-06,
      "loss": 0.0003,
      "step": 16155
    },
    {
      "epoch": 0.2558069572652279,
      "grad_norm": 0.00741159962490201,
      "learning_rate": 7.441930427347721e-06,
      "loss": 0.0004,
      "step": 16156
    },
    {
      "epoch": 0.25582279082287,
      "grad_norm": 0.044821202754974365,
      "learning_rate": 7.441772091771301e-06,
      "loss": 0.003,
      "step": 16157
    },
    {
      "epoch": 0.2558386243805121,
      "grad_norm": 0.010467405430972576,
      "learning_rate": 7.44161375619488e-06,
      "loss": 0.0004,
      "step": 16158
    },
    {
      "epoch": 0.25585445793815415,
      "grad_norm": 0.5463125705718994,
      "learning_rate": 7.44145542061846e-06,
      "loss": 0.228,
      "step": 16159
    },
    {
      "epoch": 0.2558702914957962,
      "grad_norm": 0.0005634402623400092,
      "learning_rate": 7.441297085042039e-06,
      "loss": 0.0,
      "step": 16160
    },
    {
      "epoch": 0.2558861250534383,
      "grad_norm": 0.007915385998785496,
      "learning_rate": 7.441138749465619e-06,
      "loss": 0.0003,
      "step": 16161
    },
    {
      "epoch": 0.25590195861108034,
      "grad_norm": 0.4677426815032959,
      "learning_rate": 7.440980413889197e-06,
      "loss": 0.0955,
      "step": 16162
    },
    {
      "epoch": 0.2559177921687224,
      "grad_norm": 0.19970107078552246,
      "learning_rate": 7.440822078312777e-06,
      "loss": 0.0386,
      "step": 16163
    },
    {
      "epoch": 0.25593362572636447,
      "grad_norm": 0.024204116314649582,
      "learning_rate": 7.440663742736356e-06,
      "loss": 0.0012,
      "step": 16164
    },
    {
      "epoch": 0.25594945928400653,
      "grad_norm": 0.4399200677871704,
      "learning_rate": 7.440505407159936e-06,
      "loss": 0.0596,
      "step": 16165
    },
    {
      "epoch": 0.2559652928416486,
      "grad_norm": 0.254137247800827,
      "learning_rate": 7.440347071583515e-06,
      "loss": 0.1038,
      "step": 16166
    },
    {
      "epoch": 0.25598112639929066,
      "grad_norm": 0.049429893493652344,
      "learning_rate": 7.440188736007095e-06,
      "loss": 0.0021,
      "step": 16167
    },
    {
      "epoch": 0.2559969599569327,
      "grad_norm": 0.31319382786750793,
      "learning_rate": 7.440030400430673e-06,
      "loss": 0.1989,
      "step": 16168
    },
    {
      "epoch": 0.2560127935145748,
      "grad_norm": 0.565028965473175,
      "learning_rate": 7.439872064854252e-06,
      "loss": 0.1136,
      "step": 16169
    },
    {
      "epoch": 0.25602862707221685,
      "grad_norm": 0.00020456797210499644,
      "learning_rate": 7.439713729277832e-06,
      "loss": 0.0,
      "step": 16170
    },
    {
      "epoch": 0.2560444606298589,
      "grad_norm": 0.5929010510444641,
      "learning_rate": 7.439555393701411e-06,
      "loss": 0.3338,
      "step": 16171
    },
    {
      "epoch": 0.256060294187501,
      "grad_norm": 0.4142947196960449,
      "learning_rate": 7.439397058124991e-06,
      "loss": 0.182,
      "step": 16172
    },
    {
      "epoch": 0.25607612774514305,
      "grad_norm": 0.6338436007499695,
      "learning_rate": 7.439238722548569e-06,
      "loss": 0.1213,
      "step": 16173
    },
    {
      "epoch": 0.2560919613027851,
      "grad_norm": 0.5904810428619385,
      "learning_rate": 7.439080386972149e-06,
      "loss": 0.4743,
      "step": 16174
    },
    {
      "epoch": 0.2561077948604272,
      "grad_norm": 0.6933596134185791,
      "learning_rate": 7.438922051395728e-06,
      "loss": 0.3386,
      "step": 16175
    },
    {
      "epoch": 0.25612362841806924,
      "grad_norm": 0.2610820233821869,
      "learning_rate": 7.438763715819308e-06,
      "loss": 0.0917,
      "step": 16176
    },
    {
      "epoch": 0.2561394619757113,
      "grad_norm": 0.13307538628578186,
      "learning_rate": 7.438605380242887e-06,
      "loss": 0.0035,
      "step": 16177
    },
    {
      "epoch": 0.25615529553335337,
      "grad_norm": 0.3620615303516388,
      "learning_rate": 7.438447044666467e-06,
      "loss": 0.1618,
      "step": 16178
    },
    {
      "epoch": 0.25617112909099543,
      "grad_norm": 0.025434091687202454,
      "learning_rate": 7.4382887090900456e-06,
      "loss": 0.0012,
      "step": 16179
    },
    {
      "epoch": 0.2561869626486375,
      "grad_norm": 0.8313252329826355,
      "learning_rate": 7.4381303735136255e-06,
      "loss": 0.3878,
      "step": 16180
    },
    {
      "epoch": 0.2562027962062796,
      "grad_norm": 0.33970513939857483,
      "learning_rate": 7.4379720379372046e-06,
      "loss": 0.0401,
      "step": 16181
    },
    {
      "epoch": 0.2562186297639217,
      "grad_norm": 0.3366369605064392,
      "learning_rate": 7.4378137023607845e-06,
      "loss": 0.8366,
      "step": 16182
    },
    {
      "epoch": 0.25623446332156374,
      "grad_norm": 0.7005631327629089,
      "learning_rate": 7.4376553667843636e-06,
      "loss": 0.1444,
      "step": 16183
    },
    {
      "epoch": 0.2562502968792058,
      "grad_norm": 0.34247952699661255,
      "learning_rate": 7.4374970312079435e-06,
      "loss": 0.1377,
      "step": 16184
    },
    {
      "epoch": 0.25626613043684787,
      "grad_norm": 0.47521746158599854,
      "learning_rate": 7.437338695631522e-06,
      "loss": 0.1147,
      "step": 16185
    },
    {
      "epoch": 0.25628196399448994,
      "grad_norm": 1.9138039350509644,
      "learning_rate": 7.437180360055102e-06,
      "loss": 0.1181,
      "step": 16186
    },
    {
      "epoch": 0.256297797552132,
      "grad_norm": 0.5885576009750366,
      "learning_rate": 7.437022024478681e-06,
      "loss": 0.1533,
      "step": 16187
    },
    {
      "epoch": 0.25631363110977406,
      "grad_norm": 0.7635651230812073,
      "learning_rate": 7.436863688902261e-06,
      "loss": 0.417,
      "step": 16188
    },
    {
      "epoch": 0.25632946466741613,
      "grad_norm": 0.47443053126335144,
      "learning_rate": 7.43670535332584e-06,
      "loss": 0.365,
      "step": 16189
    },
    {
      "epoch": 0.2563452982250582,
      "grad_norm": 0.6755239367485046,
      "learning_rate": 7.436547017749419e-06,
      "loss": 0.1095,
      "step": 16190
    },
    {
      "epoch": 0.25636113178270026,
      "grad_norm": 0.195327028632164,
      "learning_rate": 7.436388682172998e-06,
      "loss": 0.037,
      "step": 16191
    },
    {
      "epoch": 0.2563769653403423,
      "grad_norm": 0.705062210559845,
      "learning_rate": 7.436230346596578e-06,
      "loss": 0.2023,
      "step": 16192
    },
    {
      "epoch": 0.2563927988979844,
      "grad_norm": 0.8238884806632996,
      "learning_rate": 7.436072011020157e-06,
      "loss": 1.0553,
      "step": 16193
    },
    {
      "epoch": 0.25640863245562645,
      "grad_norm": 0.004948473069816828,
      "learning_rate": 7.435913675443735e-06,
      "loss": 0.0002,
      "step": 16194
    },
    {
      "epoch": 0.2564244660132685,
      "grad_norm": 0.0181428249925375,
      "learning_rate": 7.435755339867315e-06,
      "loss": 0.0008,
      "step": 16195
    },
    {
      "epoch": 0.2564402995709106,
      "grad_norm": 0.4642016291618347,
      "learning_rate": 7.435597004290894e-06,
      "loss": 0.0705,
      "step": 16196
    },
    {
      "epoch": 0.25645613312855264,
      "grad_norm": 0.24099910259246826,
      "learning_rate": 7.435438668714474e-06,
      "loss": 0.1082,
      "step": 16197
    },
    {
      "epoch": 0.2564719666861947,
      "grad_norm": 0.010887552052736282,
      "learning_rate": 7.435280333138053e-06,
      "loss": 0.0005,
      "step": 16198
    },
    {
      "epoch": 0.25648780024383677,
      "grad_norm": 0.2932624816894531,
      "learning_rate": 7.435121997561633e-06,
      "loss": 0.0661,
      "step": 16199
    },
    {
      "epoch": 0.25650363380147884,
      "grad_norm": 0.3029959797859192,
      "learning_rate": 7.434963661985211e-06,
      "loss": 0.0604,
      "step": 16200
    },
    {
      "epoch": 0.2565194673591209,
      "grad_norm": 0.7319672107696533,
      "learning_rate": 7.434805326408791e-06,
      "loss": 0.0824,
      "step": 16201
    },
    {
      "epoch": 0.25653530091676296,
      "grad_norm": 0.023908929899334908,
      "learning_rate": 7.43464699083237e-06,
      "loss": 0.0012,
      "step": 16202
    },
    {
      "epoch": 0.25655113447440503,
      "grad_norm": 0.0004389083478599787,
      "learning_rate": 7.43448865525595e-06,
      "loss": 0.0,
      "step": 16203
    },
    {
      "epoch": 0.2565669680320471,
      "grad_norm": 0.023959320038557053,
      "learning_rate": 7.434330319679529e-06,
      "loss": 0.001,
      "step": 16204
    },
    {
      "epoch": 0.2565828015896892,
      "grad_norm": 0.04995490610599518,
      "learning_rate": 7.434171984103109e-06,
      "loss": 0.0026,
      "step": 16205
    },
    {
      "epoch": 0.2565986351473313,
      "grad_norm": 0.00022787533816881478,
      "learning_rate": 7.4340136485266875e-06,
      "loss": 0.0,
      "step": 16206
    },
    {
      "epoch": 0.25661446870497334,
      "grad_norm": 0.0002094430528813973,
      "learning_rate": 7.433855312950267e-06,
      "loss": 0.0,
      "step": 16207
    },
    {
      "epoch": 0.2566303022626154,
      "grad_norm": 0.4552218019962311,
      "learning_rate": 7.4336969773738465e-06,
      "loss": 0.2796,
      "step": 16208
    },
    {
      "epoch": 0.25664613582025747,
      "grad_norm": 0.3208531439304352,
      "learning_rate": 7.433538641797426e-06,
      "loss": 0.0716,
      "step": 16209
    },
    {
      "epoch": 0.25666196937789953,
      "grad_norm": 0.03660863637924194,
      "learning_rate": 7.4333803062210055e-06,
      "loss": 0.0018,
      "step": 16210
    },
    {
      "epoch": 0.2566778029355416,
      "grad_norm": 0.006019888911396265,
      "learning_rate": 7.433221970644585e-06,
      "loss": 0.0002,
      "step": 16211
    },
    {
      "epoch": 0.25669363649318366,
      "grad_norm": 0.019364673644304276,
      "learning_rate": 7.433063635068164e-06,
      "loss": 0.001,
      "step": 16212
    },
    {
      "epoch": 0.2567094700508257,
      "grad_norm": 0.19030702114105225,
      "learning_rate": 7.4329052994917436e-06,
      "loss": 0.0567,
      "step": 16213
    },
    {
      "epoch": 0.2567253036084678,
      "grad_norm": 0.21781475841999054,
      "learning_rate": 7.432746963915323e-06,
      "loss": 0.0366,
      "step": 16214
    },
    {
      "epoch": 0.25674113716610986,
      "grad_norm": 0.4846580922603607,
      "learning_rate": 7.432588628338903e-06,
      "loss": 0.1133,
      "step": 16215
    },
    {
      "epoch": 0.2567569707237519,
      "grad_norm": 0.5102960467338562,
      "learning_rate": 7.432430292762482e-06,
      "loss": 0.0147,
      "step": 16216
    },
    {
      "epoch": 0.256772804281394,
      "grad_norm": 0.27532705664634705,
      "learning_rate": 7.43227195718606e-06,
      "loss": 0.0473,
      "step": 16217
    },
    {
      "epoch": 0.25678863783903605,
      "grad_norm": 1.2188900709152222,
      "learning_rate": 7.43211362160964e-06,
      "loss": 1.0671,
      "step": 16218
    },
    {
      "epoch": 0.2568044713966781,
      "grad_norm": 0.4328208267688751,
      "learning_rate": 7.431955286033219e-06,
      "loss": 0.0531,
      "step": 16219
    },
    {
      "epoch": 0.2568203049543202,
      "grad_norm": 0.8384356498718262,
      "learning_rate": 7.431796950456799e-06,
      "loss": 0.3341,
      "step": 16220
    },
    {
      "epoch": 0.25683613851196224,
      "grad_norm": 0.0005127365002408624,
      "learning_rate": 7.431638614880378e-06,
      "loss": 0.0,
      "step": 16221
    },
    {
      "epoch": 0.2568519720696043,
      "grad_norm": 0.5570136904716492,
      "learning_rate": 7.431480279303958e-06,
      "loss": 0.2877,
      "step": 16222
    },
    {
      "epoch": 0.25686780562724637,
      "grad_norm": 0.6314262747764587,
      "learning_rate": 7.431321943727536e-06,
      "loss": 0.0768,
      "step": 16223
    },
    {
      "epoch": 0.25688363918488843,
      "grad_norm": 0.2923535406589508,
      "learning_rate": 7.431163608151116e-06,
      "loss": 0.0411,
      "step": 16224
    },
    {
      "epoch": 0.2568994727425305,
      "grad_norm": 0.6748514175415039,
      "learning_rate": 7.431005272574695e-06,
      "loss": 0.4695,
      "step": 16225
    },
    {
      "epoch": 0.25691530630017256,
      "grad_norm": 0.46010658144950867,
      "learning_rate": 7.430846936998275e-06,
      "loss": 0.4061,
      "step": 16226
    },
    {
      "epoch": 0.2569311398578146,
      "grad_norm": 0.006359999068081379,
      "learning_rate": 7.430688601421854e-06,
      "loss": 0.0003,
      "step": 16227
    },
    {
      "epoch": 0.2569469734154567,
      "grad_norm": 0.4205428957939148,
      "learning_rate": 7.430530265845434e-06,
      "loss": 0.23,
      "step": 16228
    },
    {
      "epoch": 0.2569628069730988,
      "grad_norm": 0.016384942457079887,
      "learning_rate": 7.430371930269012e-06,
      "loss": 0.0004,
      "step": 16229
    },
    {
      "epoch": 0.2569786405307409,
      "grad_norm": 0.2963828146457672,
      "learning_rate": 7.430213594692592e-06,
      "loss": 0.0327,
      "step": 16230
    },
    {
      "epoch": 0.25699447408838294,
      "grad_norm": 0.580605685710907,
      "learning_rate": 7.430055259116171e-06,
      "loss": 0.3116,
      "step": 16231
    },
    {
      "epoch": 0.257010307646025,
      "grad_norm": 0.5004929304122925,
      "learning_rate": 7.429896923539751e-06,
      "loss": 0.1076,
      "step": 16232
    },
    {
      "epoch": 0.25702614120366707,
      "grad_norm": 0.2351711243391037,
      "learning_rate": 7.42973858796333e-06,
      "loss": 0.0543,
      "step": 16233
    },
    {
      "epoch": 0.25704197476130913,
      "grad_norm": 0.8192779421806335,
      "learning_rate": 7.42958025238691e-06,
      "loss": 0.1087,
      "step": 16234
    },
    {
      "epoch": 0.2570578083189512,
      "grad_norm": 0.18333640694618225,
      "learning_rate": 7.429421916810488e-06,
      "loss": 0.0571,
      "step": 16235
    },
    {
      "epoch": 0.25707364187659326,
      "grad_norm": 0.36908385157585144,
      "learning_rate": 7.429263581234068e-06,
      "loss": 0.1331,
      "step": 16236
    },
    {
      "epoch": 0.2570894754342353,
      "grad_norm": 0.3334444761276245,
      "learning_rate": 7.429105245657647e-06,
      "loss": 0.1389,
      "step": 16237
    },
    {
      "epoch": 0.2571053089918774,
      "grad_norm": 0.5497545003890991,
      "learning_rate": 7.428946910081227e-06,
      "loss": 0.3014,
      "step": 16238
    },
    {
      "epoch": 0.25712114254951945,
      "grad_norm": 0.28729403018951416,
      "learning_rate": 7.428788574504806e-06,
      "loss": 0.0438,
      "step": 16239
    },
    {
      "epoch": 0.2571369761071615,
      "grad_norm": 0.006913476157933474,
      "learning_rate": 7.428630238928386e-06,
      "loss": 0.0003,
      "step": 16240
    },
    {
      "epoch": 0.2571528096648036,
      "grad_norm": 0.4153590202331543,
      "learning_rate": 7.4284719033519646e-06,
      "loss": 0.1147,
      "step": 16241
    },
    {
      "epoch": 0.25716864322244565,
      "grad_norm": 0.5378677248954773,
      "learning_rate": 7.428313567775544e-06,
      "loss": 0.3451,
      "step": 16242
    },
    {
      "epoch": 0.2571844767800877,
      "grad_norm": 0.7927735447883606,
      "learning_rate": 7.428155232199124e-06,
      "loss": 0.6054,
      "step": 16243
    },
    {
      "epoch": 0.2572003103377298,
      "grad_norm": 0.050947804003953934,
      "learning_rate": 7.427996896622703e-06,
      "loss": 0.0033,
      "step": 16244
    },
    {
      "epoch": 0.25721614389537184,
      "grad_norm": 0.3982716202735901,
      "learning_rate": 7.427838561046283e-06,
      "loss": 0.1497,
      "step": 16245
    },
    {
      "epoch": 0.2572319774530139,
      "grad_norm": 0.5396959781646729,
      "learning_rate": 7.427680225469861e-06,
      "loss": 0.6698,
      "step": 16246
    },
    {
      "epoch": 0.25724781101065597,
      "grad_norm": 0.3704497218132019,
      "learning_rate": 7.427521889893441e-06,
      "loss": 0.0261,
      "step": 16247
    },
    {
      "epoch": 0.25726364456829803,
      "grad_norm": 0.3585631251335144,
      "learning_rate": 7.42736355431702e-06,
      "loss": 0.1911,
      "step": 16248
    },
    {
      "epoch": 0.2572794781259401,
      "grad_norm": 0.4251965582370758,
      "learning_rate": 7.4272052187406e-06,
      "loss": 0.0788,
      "step": 16249
    },
    {
      "epoch": 0.25729531168358216,
      "grad_norm": 1.1118261814117432,
      "learning_rate": 7.427046883164179e-06,
      "loss": 0.22,
      "step": 16250
    },
    {
      "epoch": 0.2573111452412242,
      "grad_norm": 0.013190804980695248,
      "learning_rate": 7.426888547587759e-06,
      "loss": 0.0003,
      "step": 16251
    },
    {
      "epoch": 0.2573269787988663,
      "grad_norm": 0.3988364040851593,
      "learning_rate": 7.426730212011337e-06,
      "loss": 0.1045,
      "step": 16252
    },
    {
      "epoch": 0.2573428123565084,
      "grad_norm": 0.4060284197330475,
      "learning_rate": 7.426571876434917e-06,
      "loss": 0.3752,
      "step": 16253
    },
    {
      "epoch": 0.2573586459141505,
      "grad_norm": 0.0005816069315187633,
      "learning_rate": 7.426413540858496e-06,
      "loss": 0.0,
      "step": 16254
    },
    {
      "epoch": 0.25737447947179254,
      "grad_norm": 0.41181516647338867,
      "learning_rate": 7.426255205282076e-06,
      "loss": 0.112,
      "step": 16255
    },
    {
      "epoch": 0.2573903130294346,
      "grad_norm": 0.40747129917144775,
      "learning_rate": 7.426096869705654e-06,
      "loss": 0.0431,
      "step": 16256
    },
    {
      "epoch": 0.25740614658707667,
      "grad_norm": 0.3910768926143646,
      "learning_rate": 7.425938534129234e-06,
      "loss": 0.0587,
      "step": 16257
    },
    {
      "epoch": 0.25742198014471873,
      "grad_norm": 0.14921307563781738,
      "learning_rate": 7.425780198552813e-06,
      "loss": 0.0327,
      "step": 16258
    },
    {
      "epoch": 0.2574378137023608,
      "grad_norm": 0.6395306587219238,
      "learning_rate": 7.425621862976393e-06,
      "loss": 0.5018,
      "step": 16259
    },
    {
      "epoch": 0.25745364726000286,
      "grad_norm": 0.14928199350833893,
      "learning_rate": 7.425463527399972e-06,
      "loss": 0.0395,
      "step": 16260
    },
    {
      "epoch": 0.2574694808176449,
      "grad_norm": 0.748339056968689,
      "learning_rate": 7.425305191823552e-06,
      "loss": 0.1042,
      "step": 16261
    },
    {
      "epoch": 0.257485314375287,
      "grad_norm": 0.26658448576927185,
      "learning_rate": 7.42514685624713e-06,
      "loss": 0.0605,
      "step": 16262
    },
    {
      "epoch": 0.25750114793292905,
      "grad_norm": 0.48615762591362,
      "learning_rate": 7.42498852067071e-06,
      "loss": 0.0666,
      "step": 16263
    },
    {
      "epoch": 0.2575169814905711,
      "grad_norm": 0.533017098903656,
      "learning_rate": 7.424830185094289e-06,
      "loss": 0.1658,
      "step": 16264
    },
    {
      "epoch": 0.2575328150482132,
      "grad_norm": 1.1569488048553467,
      "learning_rate": 7.424671849517868e-06,
      "loss": 0.1315,
      "step": 16265
    },
    {
      "epoch": 0.25754864860585525,
      "grad_norm": 0.015572578646242619,
      "learning_rate": 7.424513513941448e-06,
      "loss": 0.0006,
      "step": 16266
    },
    {
      "epoch": 0.2575644821634973,
      "grad_norm": 0.06710562109947205,
      "learning_rate": 7.4243551783650266e-06,
      "loss": 0.0007,
      "step": 16267
    },
    {
      "epoch": 0.2575803157211394,
      "grad_norm": 0.7499108910560608,
      "learning_rate": 7.4241968427886065e-06,
      "loss": 0.272,
      "step": 16268
    },
    {
      "epoch": 0.25759614927878144,
      "grad_norm": 0.1657087653875351,
      "learning_rate": 7.424038507212186e-06,
      "loss": 0.045,
      "step": 16269
    },
    {
      "epoch": 0.2576119828364235,
      "grad_norm": 0.697900652885437,
      "learning_rate": 7.4238801716357655e-06,
      "loss": 0.424,
      "step": 16270
    },
    {
      "epoch": 0.25762781639406557,
      "grad_norm": 0.34986814856529236,
      "learning_rate": 7.423721836059345e-06,
      "loss": 0.0564,
      "step": 16271
    },
    {
      "epoch": 0.25764364995170763,
      "grad_norm": 0.6419509649276733,
      "learning_rate": 7.4235635004829245e-06,
      "loss": 0.5216,
      "step": 16272
    },
    {
      "epoch": 0.2576594835093497,
      "grad_norm": 0.6032753586769104,
      "learning_rate": 7.423405164906503e-06,
      "loss": 0.3839,
      "step": 16273
    },
    {
      "epoch": 0.25767531706699176,
      "grad_norm": 0.4465014934539795,
      "learning_rate": 7.423246829330083e-06,
      "loss": 0.1523,
      "step": 16274
    },
    {
      "epoch": 0.2576911506246338,
      "grad_norm": 0.5464835166931152,
      "learning_rate": 7.423088493753662e-06,
      "loss": 0.1871,
      "step": 16275
    },
    {
      "epoch": 0.2577069841822759,
      "grad_norm": 0.35416239500045776,
      "learning_rate": 7.422930158177242e-06,
      "loss": 0.144,
      "step": 16276
    },
    {
      "epoch": 0.257722817739918,
      "grad_norm": 0.3122771084308624,
      "learning_rate": 7.422771822600821e-06,
      "loss": 0.058,
      "step": 16277
    },
    {
      "epoch": 0.2577386512975601,
      "grad_norm": 0.13603512942790985,
      "learning_rate": 7.422613487024401e-06,
      "loss": 0.0084,
      "step": 16278
    },
    {
      "epoch": 0.25775448485520214,
      "grad_norm": 0.0456475205719471,
      "learning_rate": 7.422455151447979e-06,
      "loss": 0.0042,
      "step": 16279
    },
    {
      "epoch": 0.2577703184128442,
      "grad_norm": 0.021246273070573807,
      "learning_rate": 7.422296815871559e-06,
      "loss": 0.0012,
      "step": 16280
    },
    {
      "epoch": 0.25778615197048627,
      "grad_norm": 0.32336774468421936,
      "learning_rate": 7.422138480295138e-06,
      "loss": 0.1182,
      "step": 16281
    },
    {
      "epoch": 0.25780198552812833,
      "grad_norm": 0.446783185005188,
      "learning_rate": 7.421980144718718e-06,
      "loss": 0.2417,
      "step": 16282
    },
    {
      "epoch": 0.2578178190857704,
      "grad_norm": 0.032977472990751266,
      "learning_rate": 7.421821809142297e-06,
      "loss": 0.0015,
      "step": 16283
    },
    {
      "epoch": 0.25783365264341246,
      "grad_norm": 0.5876729488372803,
      "learning_rate": 7.421663473565877e-06,
      "loss": 0.1467,
      "step": 16284
    },
    {
      "epoch": 0.2578494862010545,
      "grad_norm": 0.5175355076789856,
      "learning_rate": 7.421505137989455e-06,
      "loss": 0.0841,
      "step": 16285
    },
    {
      "epoch": 0.2578653197586966,
      "grad_norm": 0.008447282947599888,
      "learning_rate": 7.421346802413035e-06,
      "loss": 0.0003,
      "step": 16286
    },
    {
      "epoch": 0.25788115331633865,
      "grad_norm": 0.467365026473999,
      "learning_rate": 7.421188466836614e-06,
      "loss": 0.1967,
      "step": 16287
    },
    {
      "epoch": 0.2578969868739807,
      "grad_norm": 0.5208359360694885,
      "learning_rate": 7.421030131260194e-06,
      "loss": 0.2629,
      "step": 16288
    },
    {
      "epoch": 0.2579128204316228,
      "grad_norm": 0.5862646102905273,
      "learning_rate": 7.420871795683773e-06,
      "loss": 0.1765,
      "step": 16289
    },
    {
      "epoch": 0.25792865398926484,
      "grad_norm": 0.5580174326896667,
      "learning_rate": 7.420713460107351e-06,
      "loss": 0.351,
      "step": 16290
    },
    {
      "epoch": 0.2579444875469069,
      "grad_norm": 0.2597661316394806,
      "learning_rate": 7.420555124530931e-06,
      "loss": 0.0746,
      "step": 16291
    },
    {
      "epoch": 0.257960321104549,
      "grad_norm": 0.012065284885466099,
      "learning_rate": 7.42039678895451e-06,
      "loss": 0.0005,
      "step": 16292
    },
    {
      "epoch": 0.25797615466219104,
      "grad_norm": 0.8945679664611816,
      "learning_rate": 7.42023845337809e-06,
      "loss": 0.6132,
      "step": 16293
    },
    {
      "epoch": 0.2579919882198331,
      "grad_norm": 0.29931116104125977,
      "learning_rate": 7.420080117801669e-06,
      "loss": 0.1072,
      "step": 16294
    },
    {
      "epoch": 0.25800782177747517,
      "grad_norm": 0.4378453195095062,
      "learning_rate": 7.419921782225249e-06,
      "loss": 0.2658,
      "step": 16295
    },
    {
      "epoch": 0.25802365533511723,
      "grad_norm": 4.071889400482178,
      "learning_rate": 7.4197634466488275e-06,
      "loss": 1.1503,
      "step": 16296
    },
    {
      "epoch": 0.2580394888927593,
      "grad_norm": 0.8978092670440674,
      "learning_rate": 7.4196051110724074e-06,
      "loss": 0.2947,
      "step": 16297
    },
    {
      "epoch": 0.25805532245040136,
      "grad_norm": 0.3618241548538208,
      "learning_rate": 7.4194467754959865e-06,
      "loss": 0.1473,
      "step": 16298
    },
    {
      "epoch": 0.2580711560080434,
      "grad_norm": 0.6169306039810181,
      "learning_rate": 7.4192884399195664e-06,
      "loss": 0.566,
      "step": 16299
    },
    {
      "epoch": 0.2580869895656855,
      "grad_norm": 0.21616077423095703,
      "learning_rate": 7.4191301043431455e-06,
      "loss": 0.078,
      "step": 16300
    },
    {
      "epoch": 0.2581028231233276,
      "grad_norm": 0.04285392165184021,
      "learning_rate": 7.4189717687667254e-06,
      "loss": 0.0038,
      "step": 16301
    },
    {
      "epoch": 0.25811865668096967,
      "grad_norm": 0.6431708931922913,
      "learning_rate": 7.418813433190304e-06,
      "loss": 0.0701,
      "step": 16302
    },
    {
      "epoch": 0.25813449023861174,
      "grad_norm": 0.26652756333351135,
      "learning_rate": 7.418655097613884e-06,
      "loss": 0.1476,
      "step": 16303
    },
    {
      "epoch": 0.2581503237962538,
      "grad_norm": 0.48505690693855286,
      "learning_rate": 7.418496762037463e-06,
      "loss": 0.2583,
      "step": 16304
    },
    {
      "epoch": 0.25816615735389586,
      "grad_norm": 0.25058645009994507,
      "learning_rate": 7.418338426461043e-06,
      "loss": 0.0841,
      "step": 16305
    },
    {
      "epoch": 0.25818199091153793,
      "grad_norm": 0.014155556447803974,
      "learning_rate": 7.418180090884622e-06,
      "loss": 0.0006,
      "step": 16306
    },
    {
      "epoch": 0.25819782446918,
      "grad_norm": 0.47808265686035156,
      "learning_rate": 7.418021755308202e-06,
      "loss": 0.2615,
      "step": 16307
    },
    {
      "epoch": 0.25821365802682206,
      "grad_norm": 0.4028299152851105,
      "learning_rate": 7.41786341973178e-06,
      "loss": 0.0922,
      "step": 16308
    },
    {
      "epoch": 0.2582294915844641,
      "grad_norm": 0.3231819272041321,
      "learning_rate": 7.41770508415536e-06,
      "loss": 0.1348,
      "step": 16309
    },
    {
      "epoch": 0.2582453251421062,
      "grad_norm": 0.018652210012078285,
      "learning_rate": 7.417546748578939e-06,
      "loss": 0.0007,
      "step": 16310
    },
    {
      "epoch": 0.25826115869974825,
      "grad_norm": 0.06176149100065231,
      "learning_rate": 7.417388413002519e-06,
      "loss": 0.0025,
      "step": 16311
    },
    {
      "epoch": 0.2582769922573903,
      "grad_norm": 0.3895591199398041,
      "learning_rate": 7.417230077426098e-06,
      "loss": 0.1149,
      "step": 16312
    },
    {
      "epoch": 0.2582928258150324,
      "grad_norm": 0.2496282011270523,
      "learning_rate": 7.417071741849676e-06,
      "loss": 0.0587,
      "step": 16313
    },
    {
      "epoch": 0.25830865937267444,
      "grad_norm": 0.2777777314186096,
      "learning_rate": 7.416913406273256e-06,
      "loss": 0.0595,
      "step": 16314
    },
    {
      "epoch": 0.2583244929303165,
      "grad_norm": 0.0007427615928463638,
      "learning_rate": 7.416755070696835e-06,
      "loss": 0.0,
      "step": 16315
    },
    {
      "epoch": 0.25834032648795857,
      "grad_norm": 0.33350303769111633,
      "learning_rate": 7.416596735120415e-06,
      "loss": 0.082,
      "step": 16316
    },
    {
      "epoch": 0.25835616004560064,
      "grad_norm": 0.014257623814046383,
      "learning_rate": 7.416438399543994e-06,
      "loss": 0.0006,
      "step": 16317
    },
    {
      "epoch": 0.2583719936032427,
      "grad_norm": 0.0040301005356013775,
      "learning_rate": 7.416280063967573e-06,
      "loss": 0.0001,
      "step": 16318
    },
    {
      "epoch": 0.25838782716088476,
      "grad_norm": 0.4315793812274933,
      "learning_rate": 7.416121728391152e-06,
      "loss": 0.1836,
      "step": 16319
    },
    {
      "epoch": 0.25840366071852683,
      "grad_norm": 0.028088930994272232,
      "learning_rate": 7.415963392814732e-06,
      "loss": 0.0013,
      "step": 16320
    },
    {
      "epoch": 0.2584194942761689,
      "grad_norm": 0.5459182262420654,
      "learning_rate": 7.415805057238311e-06,
      "loss": 0.2217,
      "step": 16321
    },
    {
      "epoch": 0.25843532783381096,
      "grad_norm": 0.5075112581253052,
      "learning_rate": 7.415646721661891e-06,
      "loss": 0.0795,
      "step": 16322
    },
    {
      "epoch": 0.258451161391453,
      "grad_norm": 0.04319712519645691,
      "learning_rate": 7.4154883860854694e-06,
      "loss": 0.003,
      "step": 16323
    },
    {
      "epoch": 0.2584669949490951,
      "grad_norm": 0.5389560461044312,
      "learning_rate": 7.415330050509049e-06,
      "loss": 0.2125,
      "step": 16324
    },
    {
      "epoch": 0.2584828285067372,
      "grad_norm": 0.36569276452064514,
      "learning_rate": 7.4151717149326284e-06,
      "loss": 0.0975,
      "step": 16325
    },
    {
      "epoch": 0.25849866206437927,
      "grad_norm": 0.0164154265075922,
      "learning_rate": 7.415013379356208e-06,
      "loss": 0.0008,
      "step": 16326
    },
    {
      "epoch": 0.25851449562202133,
      "grad_norm": 0.31537652015686035,
      "learning_rate": 7.4148550437797874e-06,
      "loss": 0.0508,
      "step": 16327
    },
    {
      "epoch": 0.2585303291796634,
      "grad_norm": 0.24049973487854004,
      "learning_rate": 7.414696708203367e-06,
      "loss": 0.0591,
      "step": 16328
    },
    {
      "epoch": 0.25854616273730546,
      "grad_norm": 0.034079600125551224,
      "learning_rate": 7.414538372626946e-06,
      "loss": 0.0018,
      "step": 16329
    },
    {
      "epoch": 0.2585619962949475,
      "grad_norm": 0.13744251430034637,
      "learning_rate": 7.4143800370505255e-06,
      "loss": 0.0137,
      "step": 16330
    },
    {
      "epoch": 0.2585778298525896,
      "grad_norm": 0.01332159899175167,
      "learning_rate": 7.414221701474105e-06,
      "loss": 0.0005,
      "step": 16331
    },
    {
      "epoch": 0.25859366341023166,
      "grad_norm": 0.009634112007915974,
      "learning_rate": 7.4140633658976845e-06,
      "loss": 0.0004,
      "step": 16332
    },
    {
      "epoch": 0.2586094969678737,
      "grad_norm": 0.5101023316383362,
      "learning_rate": 7.413905030321264e-06,
      "loss": 0.083,
      "step": 16333
    },
    {
      "epoch": 0.2586253305255158,
      "grad_norm": 0.7747379541397095,
      "learning_rate": 7.4137466947448435e-06,
      "loss": 0.073,
      "step": 16334
    },
    {
      "epoch": 0.25864116408315785,
      "grad_norm": 0.2805938720703125,
      "learning_rate": 7.413588359168422e-06,
      "loss": 0.0614,
      "step": 16335
    },
    {
      "epoch": 0.2586569976407999,
      "grad_norm": 0.36809036135673523,
      "learning_rate": 7.413430023592002e-06,
      "loss": 0.1464,
      "step": 16336
    },
    {
      "epoch": 0.258672831198442,
      "grad_norm": 0.33284714818000793,
      "learning_rate": 7.413271688015581e-06,
      "loss": 0.1653,
      "step": 16337
    },
    {
      "epoch": 0.25868866475608404,
      "grad_norm": 0.4797636866569519,
      "learning_rate": 7.41311335243916e-06,
      "loss": 0.1695,
      "step": 16338
    },
    {
      "epoch": 0.2587044983137261,
      "grad_norm": 0.47186413407325745,
      "learning_rate": 7.41295501686274e-06,
      "loss": 0.14,
      "step": 16339
    },
    {
      "epoch": 0.25872033187136817,
      "grad_norm": 0.907630443572998,
      "learning_rate": 7.412796681286318e-06,
      "loss": 0.5659,
      "step": 16340
    },
    {
      "epoch": 0.25873616542901023,
      "grad_norm": 0.3635123670101166,
      "learning_rate": 7.412638345709898e-06,
      "loss": 0.0642,
      "step": 16341
    },
    {
      "epoch": 0.2587519989866523,
      "grad_norm": 0.4705814719200134,
      "learning_rate": 7.412480010133477e-06,
      "loss": 0.0827,
      "step": 16342
    },
    {
      "epoch": 0.25876783254429436,
      "grad_norm": 0.1801193505525589,
      "learning_rate": 7.412321674557057e-06,
      "loss": 0.0583,
      "step": 16343
    },
    {
      "epoch": 0.2587836661019364,
      "grad_norm": 0.0055290390737354755,
      "learning_rate": 7.412163338980636e-06,
      "loss": 0.0002,
      "step": 16344
    },
    {
      "epoch": 0.2587994996595785,
      "grad_norm": 0.5733241438865662,
      "learning_rate": 7.412005003404216e-06,
      "loss": 0.2249,
      "step": 16345
    },
    {
      "epoch": 0.25881533321722056,
      "grad_norm": 0.376087486743927,
      "learning_rate": 7.411846667827794e-06,
      "loss": 0.2165,
      "step": 16346
    },
    {
      "epoch": 0.2588311667748626,
      "grad_norm": 0.14516286551952362,
      "learning_rate": 7.411688332251374e-06,
      "loss": 0.0367,
      "step": 16347
    },
    {
      "epoch": 0.2588470003325047,
      "grad_norm": 0.018308019265532494,
      "learning_rate": 7.411529996674953e-06,
      "loss": 0.0005,
      "step": 16348
    },
    {
      "epoch": 0.2588628338901468,
      "grad_norm": 0.22439296543598175,
      "learning_rate": 7.411371661098533e-06,
      "loss": 0.0649,
      "step": 16349
    },
    {
      "epoch": 0.25887866744778887,
      "grad_norm": 0.4026668071746826,
      "learning_rate": 7.411213325522112e-06,
      "loss": 0.082,
      "step": 16350
    },
    {
      "epoch": 0.25889450100543093,
      "grad_norm": 0.3826294541358948,
      "learning_rate": 7.411054989945692e-06,
      "loss": 0.1049,
      "step": 16351
    },
    {
      "epoch": 0.258910334563073,
      "grad_norm": 0.027044588699936867,
      "learning_rate": 7.41089665436927e-06,
      "loss": 0.0013,
      "step": 16352
    },
    {
      "epoch": 0.25892616812071506,
      "grad_norm": 1.1187222003936768,
      "learning_rate": 7.41073831879285e-06,
      "loss": 0.2043,
      "step": 16353
    },
    {
      "epoch": 0.2589420016783571,
      "grad_norm": 0.1859864890575409,
      "learning_rate": 7.410579983216429e-06,
      "loss": 0.0503,
      "step": 16354
    },
    {
      "epoch": 0.2589578352359992,
      "grad_norm": 0.00945256557315588,
      "learning_rate": 7.410421647640009e-06,
      "loss": 0.0004,
      "step": 16355
    },
    {
      "epoch": 0.25897366879364125,
      "grad_norm": 0.0043552108108997345,
      "learning_rate": 7.410263312063588e-06,
      "loss": 0.0001,
      "step": 16356
    },
    {
      "epoch": 0.2589895023512833,
      "grad_norm": 0.20422105491161346,
      "learning_rate": 7.410104976487168e-06,
      "loss": 0.0568,
      "step": 16357
    },
    {
      "epoch": 0.2590053359089254,
      "grad_norm": 0.5459492206573486,
      "learning_rate": 7.4099466409107465e-06,
      "loss": 0.3013,
      "step": 16358
    },
    {
      "epoch": 0.25902116946656745,
      "grad_norm": 0.7036117315292358,
      "learning_rate": 7.4097883053343265e-06,
      "loss": 0.0269,
      "step": 16359
    },
    {
      "epoch": 0.2590370030242095,
      "grad_norm": 1.1258233785629272,
      "learning_rate": 7.4096299697579055e-06,
      "loss": 0.5658,
      "step": 16360
    },
    {
      "epoch": 0.2590528365818516,
      "grad_norm": 0.16308461129665375,
      "learning_rate": 7.409471634181485e-06,
      "loss": 0.0166,
      "step": 16361
    },
    {
      "epoch": 0.25906867013949364,
      "grad_norm": 0.0031483727507293224,
      "learning_rate": 7.4093132986050645e-06,
      "loss": 0.0001,
      "step": 16362
    },
    {
      "epoch": 0.2590845036971357,
      "grad_norm": 0.035755179822444916,
      "learning_rate": 7.409154963028643e-06,
      "loss": 0.0021,
      "step": 16363
    },
    {
      "epoch": 0.25910033725477777,
      "grad_norm": 0.011725803837180138,
      "learning_rate": 7.408996627452223e-06,
      "loss": 0.0005,
      "step": 16364
    },
    {
      "epoch": 0.25911617081241983,
      "grad_norm": 0.12497768551111221,
      "learning_rate": 7.408838291875802e-06,
      "loss": 0.0063,
      "step": 16365
    },
    {
      "epoch": 0.2591320043700619,
      "grad_norm": 0.44451817870140076,
      "learning_rate": 7.408679956299382e-06,
      "loss": 0.1226,
      "step": 16366
    },
    {
      "epoch": 0.25914783792770396,
      "grad_norm": 0.47045549750328064,
      "learning_rate": 7.408521620722961e-06,
      "loss": 0.0274,
      "step": 16367
    },
    {
      "epoch": 0.259163671485346,
      "grad_norm": 0.8295232057571411,
      "learning_rate": 7.408363285146541e-06,
      "loss": 0.8176,
      "step": 16368
    },
    {
      "epoch": 0.2591795050429881,
      "grad_norm": 0.33143553137779236,
      "learning_rate": 7.408204949570119e-06,
      "loss": 0.0437,
      "step": 16369
    },
    {
      "epoch": 0.25919533860063015,
      "grad_norm": 0.6012723445892334,
      "learning_rate": 7.408046613993699e-06,
      "loss": 0.1474,
      "step": 16370
    },
    {
      "epoch": 0.2592111721582722,
      "grad_norm": 0.5128729343414307,
      "learning_rate": 7.407888278417278e-06,
      "loss": 0.4234,
      "step": 16371
    },
    {
      "epoch": 0.2592270057159143,
      "grad_norm": 0.5429016351699829,
      "learning_rate": 7.407729942840858e-06,
      "loss": 0.0905,
      "step": 16372
    },
    {
      "epoch": 0.2592428392735564,
      "grad_norm": 0.04115720093250275,
      "learning_rate": 7.407571607264437e-06,
      "loss": 0.0014,
      "step": 16373
    },
    {
      "epoch": 0.25925867283119847,
      "grad_norm": 0.5487990379333496,
      "learning_rate": 7.407413271688017e-06,
      "loss": 0.1094,
      "step": 16374
    },
    {
      "epoch": 0.25927450638884053,
      "grad_norm": 0.3058699071407318,
      "learning_rate": 7.407254936111595e-06,
      "loss": 0.0493,
      "step": 16375
    },
    {
      "epoch": 0.2592903399464826,
      "grad_norm": 0.014046347700059414,
      "learning_rate": 7.407096600535175e-06,
      "loss": 0.0006,
      "step": 16376
    },
    {
      "epoch": 0.25930617350412466,
      "grad_norm": 0.20104019343852997,
      "learning_rate": 7.406938264958754e-06,
      "loss": 0.0266,
      "step": 16377
    },
    {
      "epoch": 0.2593220070617667,
      "grad_norm": 0.620515763759613,
      "learning_rate": 7.406779929382334e-06,
      "loss": 0.3572,
      "step": 16378
    },
    {
      "epoch": 0.2593378406194088,
      "grad_norm": 0.11524412781000137,
      "learning_rate": 7.406621593805913e-06,
      "loss": 0.0083,
      "step": 16379
    },
    {
      "epoch": 0.25935367417705085,
      "grad_norm": 0.5647937655448914,
      "learning_rate": 7.406463258229493e-06,
      "loss": 0.1965,
      "step": 16380
    },
    {
      "epoch": 0.2593695077346929,
      "grad_norm": 0.5917332768440247,
      "learning_rate": 7.406304922653071e-06,
      "loss": 0.5113,
      "step": 16381
    },
    {
      "epoch": 0.259385341292335,
      "grad_norm": 0.5009128451347351,
      "learning_rate": 7.406146587076651e-06,
      "loss": 0.3213,
      "step": 16382
    },
    {
      "epoch": 0.25940117484997705,
      "grad_norm": 0.39169615507125854,
      "learning_rate": 7.40598825150023e-06,
      "loss": 0.1667,
      "step": 16383
    },
    {
      "epoch": 0.2594170084076191,
      "grad_norm": 0.6435315608978271,
      "learning_rate": 7.40582991592381e-06,
      "loss": 0.0697,
      "step": 16384
    },
    {
      "epoch": 0.2594328419652612,
      "grad_norm": 0.4382835626602173,
      "learning_rate": 7.4056715803473885e-06,
      "loss": 0.0677,
      "step": 16385
    },
    {
      "epoch": 0.25944867552290324,
      "grad_norm": 0.5882763266563416,
      "learning_rate": 7.4055132447709675e-06,
      "loss": 0.1934,
      "step": 16386
    },
    {
      "epoch": 0.2594645090805453,
      "grad_norm": 0.37698838114738464,
      "learning_rate": 7.4053549091945475e-06,
      "loss": 0.0725,
      "step": 16387
    },
    {
      "epoch": 0.25948034263818737,
      "grad_norm": 0.03492968529462814,
      "learning_rate": 7.4051965736181265e-06,
      "loss": 0.002,
      "step": 16388
    },
    {
      "epoch": 0.25949617619582943,
      "grad_norm": 0.3970142900943756,
      "learning_rate": 7.4050382380417065e-06,
      "loss": 0.0336,
      "step": 16389
    },
    {
      "epoch": 0.2595120097534715,
      "grad_norm": 0.3155266344547272,
      "learning_rate": 7.404879902465285e-06,
      "loss": 0.0691,
      "step": 16390
    },
    {
      "epoch": 0.25952784331111356,
      "grad_norm": 0.5513212084770203,
      "learning_rate": 7.404721566888865e-06,
      "loss": 0.0815,
      "step": 16391
    },
    {
      "epoch": 0.2595436768687556,
      "grad_norm": 0.008335406892001629,
      "learning_rate": 7.404563231312444e-06,
      "loss": 0.0004,
      "step": 16392
    },
    {
      "epoch": 0.2595595104263977,
      "grad_norm": 0.41326019167900085,
      "learning_rate": 7.404404895736024e-06,
      "loss": 0.1772,
      "step": 16393
    },
    {
      "epoch": 0.25957534398403975,
      "grad_norm": 0.20106911659240723,
      "learning_rate": 7.404246560159603e-06,
      "loss": 0.0321,
      "step": 16394
    },
    {
      "epoch": 0.2595911775416818,
      "grad_norm": 0.03515847027301788,
      "learning_rate": 7.404088224583183e-06,
      "loss": 0.0014,
      "step": 16395
    },
    {
      "epoch": 0.2596070110993239,
      "grad_norm": 0.5057411789894104,
      "learning_rate": 7.403929889006761e-06,
      "loss": 0.1809,
      "step": 16396
    },
    {
      "epoch": 0.259622844656966,
      "grad_norm": 0.48814356327056885,
      "learning_rate": 7.403771553430341e-06,
      "loss": 0.3099,
      "step": 16397
    },
    {
      "epoch": 0.25963867821460807,
      "grad_norm": 0.14799495041370392,
      "learning_rate": 7.40361321785392e-06,
      "loss": 0.0097,
      "step": 16398
    },
    {
      "epoch": 0.25965451177225013,
      "grad_norm": 0.030430004000663757,
      "learning_rate": 7.4034548822775e-06,
      "loss": 0.0014,
      "step": 16399
    },
    {
      "epoch": 0.2596703453298922,
      "grad_norm": 0.4425857365131378,
      "learning_rate": 7.403296546701079e-06,
      "loss": 0.1121,
      "step": 16400
    },
    {
      "epoch": 0.25968617888753426,
      "grad_norm": 0.026537595316767693,
      "learning_rate": 7.403138211124659e-06,
      "loss": 0.0011,
      "step": 16401
    },
    {
      "epoch": 0.2597020124451763,
      "grad_norm": 0.0006839399575255811,
      "learning_rate": 7.402979875548237e-06,
      "loss": 0.0,
      "step": 16402
    },
    {
      "epoch": 0.2597178460028184,
      "grad_norm": 0.47732260823249817,
      "learning_rate": 7.402821539971817e-06,
      "loss": 0.2502,
      "step": 16403
    },
    {
      "epoch": 0.25973367956046045,
      "grad_norm": 1.5281041860580444,
      "learning_rate": 7.402663204395396e-06,
      "loss": 0.1796,
      "step": 16404
    },
    {
      "epoch": 0.2597495131181025,
      "grad_norm": 0.4174884855747223,
      "learning_rate": 7.402504868818976e-06,
      "loss": 0.1751,
      "step": 16405
    },
    {
      "epoch": 0.2597653466757446,
      "grad_norm": 1.0647152662277222,
      "learning_rate": 7.402346533242555e-06,
      "loss": 0.6627,
      "step": 16406
    },
    {
      "epoch": 0.25978118023338664,
      "grad_norm": 0.2628495395183563,
      "learning_rate": 7.402188197666135e-06,
      "loss": 0.0878,
      "step": 16407
    },
    {
      "epoch": 0.2597970137910287,
      "grad_norm": 0.5266420841217041,
      "learning_rate": 7.402029862089713e-06,
      "loss": 0.2127,
      "step": 16408
    },
    {
      "epoch": 0.2598128473486708,
      "grad_norm": 0.09402944892644882,
      "learning_rate": 7.401871526513292e-06,
      "loss": 0.0084,
      "step": 16409
    },
    {
      "epoch": 0.25982868090631284,
      "grad_norm": 0.005526815541088581,
      "learning_rate": 7.401713190936872e-06,
      "loss": 0.0001,
      "step": 16410
    },
    {
      "epoch": 0.2598445144639549,
      "grad_norm": 0.03314334526658058,
      "learning_rate": 7.401554855360451e-06,
      "loss": 0.0017,
      "step": 16411
    },
    {
      "epoch": 0.25986034802159697,
      "grad_norm": 0.4821772873401642,
      "learning_rate": 7.401396519784031e-06,
      "loss": 0.1532,
      "step": 16412
    },
    {
      "epoch": 0.25987618157923903,
      "grad_norm": 0.342852920293808,
      "learning_rate": 7.4012381842076095e-06,
      "loss": 0.0623,
      "step": 16413
    },
    {
      "epoch": 0.2598920151368811,
      "grad_norm": 0.24761401116847992,
      "learning_rate": 7.401079848631189e-06,
      "loss": 0.1208,
      "step": 16414
    },
    {
      "epoch": 0.25990784869452316,
      "grad_norm": 0.9760129451751709,
      "learning_rate": 7.4009215130547685e-06,
      "loss": 0.3593,
      "step": 16415
    },
    {
      "epoch": 0.2599236822521652,
      "grad_norm": 0.2385452687740326,
      "learning_rate": 7.400763177478348e-06,
      "loss": 0.0642,
      "step": 16416
    },
    {
      "epoch": 0.2599395158098073,
      "grad_norm": 0.9429041147232056,
      "learning_rate": 7.4006048419019275e-06,
      "loss": 0.6415,
      "step": 16417
    },
    {
      "epoch": 0.25995534936744935,
      "grad_norm": 0.0017099202377721667,
      "learning_rate": 7.400446506325507e-06,
      "loss": 0.0,
      "step": 16418
    },
    {
      "epoch": 0.2599711829250914,
      "grad_norm": 0.6123321056365967,
      "learning_rate": 7.400288170749086e-06,
      "loss": 0.0849,
      "step": 16419
    },
    {
      "epoch": 0.2599870164827335,
      "grad_norm": 0.21891707181930542,
      "learning_rate": 7.4001298351726656e-06,
      "loss": 0.0461,
      "step": 16420
    },
    {
      "epoch": 0.2600028500403756,
      "grad_norm": 0.4141899645328522,
      "learning_rate": 7.399971499596245e-06,
      "loss": 0.4892,
      "step": 16421
    },
    {
      "epoch": 0.26001868359801766,
      "grad_norm": 0.005156149156391621,
      "learning_rate": 7.3998131640198246e-06,
      "loss": 0.0002,
      "step": 16422
    },
    {
      "epoch": 0.26003451715565973,
      "grad_norm": 0.5467617511749268,
      "learning_rate": 7.399654828443404e-06,
      "loss": 0.137,
      "step": 16423
    },
    {
      "epoch": 0.2600503507133018,
      "grad_norm": 0.40712741017341614,
      "learning_rate": 7.3994964928669836e-06,
      "loss": 0.1666,
      "step": 16424
    },
    {
      "epoch": 0.26006618427094386,
      "grad_norm": 0.3616630733013153,
      "learning_rate": 7.399338157290562e-06,
      "loss": 0.0103,
      "step": 16425
    },
    {
      "epoch": 0.2600820178285859,
      "grad_norm": 0.00035507557913661003,
      "learning_rate": 7.399179821714142e-06,
      "loss": 0.0,
      "step": 16426
    },
    {
      "epoch": 0.260097851386228,
      "grad_norm": 0.11288440972566605,
      "learning_rate": 7.399021486137721e-06,
      "loss": 0.0026,
      "step": 16427
    },
    {
      "epoch": 0.26011368494387005,
      "grad_norm": 0.23226302862167358,
      "learning_rate": 7.398863150561301e-06,
      "loss": 0.0877,
      "step": 16428
    },
    {
      "epoch": 0.2601295185015121,
      "grad_norm": 0.8024919629096985,
      "learning_rate": 7.39870481498488e-06,
      "loss": 0.6296,
      "step": 16429
    },
    {
      "epoch": 0.2601453520591542,
      "grad_norm": 0.013690643012523651,
      "learning_rate": 7.39854647940846e-06,
      "loss": 0.0005,
      "step": 16430
    },
    {
      "epoch": 0.26016118561679624,
      "grad_norm": 0.18137966096401215,
      "learning_rate": 7.398388143832038e-06,
      "loss": 0.0491,
      "step": 16431
    },
    {
      "epoch": 0.2601770191744383,
      "grad_norm": 0.4924912452697754,
      "learning_rate": 7.398229808255618e-06,
      "loss": 0.1319,
      "step": 16432
    },
    {
      "epoch": 0.26019285273208037,
      "grad_norm": 0.0006929710507392883,
      "learning_rate": 7.398071472679197e-06,
      "loss": 0.0,
      "step": 16433
    },
    {
      "epoch": 0.26020868628972244,
      "grad_norm": 0.36768224835395813,
      "learning_rate": 7.397913137102776e-06,
      "loss": 0.0251,
      "step": 16434
    },
    {
      "epoch": 0.2602245198473645,
      "grad_norm": 0.28776246309280396,
      "learning_rate": 7.397754801526356e-06,
      "loss": 0.055,
      "step": 16435
    },
    {
      "epoch": 0.26024035340500656,
      "grad_norm": 0.863079309463501,
      "learning_rate": 7.397596465949934e-06,
      "loss": 0.161,
      "step": 16436
    },
    {
      "epoch": 0.26025618696264863,
      "grad_norm": 0.456231027841568,
      "learning_rate": 7.397438130373514e-06,
      "loss": 0.279,
      "step": 16437
    },
    {
      "epoch": 0.2602720205202907,
      "grad_norm": 0.40781691670417786,
      "learning_rate": 7.397279794797093e-06,
      "loss": 0.1532,
      "step": 16438
    },
    {
      "epoch": 0.26028785407793276,
      "grad_norm": 0.3432844877243042,
      "learning_rate": 7.397121459220673e-06,
      "loss": 0.1,
      "step": 16439
    },
    {
      "epoch": 0.2603036876355748,
      "grad_norm": 0.03330297768115997,
      "learning_rate": 7.396963123644252e-06,
      "loss": 0.0018,
      "step": 16440
    },
    {
      "epoch": 0.2603195211932169,
      "grad_norm": 0.08625305444002151,
      "learning_rate": 7.396804788067832e-06,
      "loss": 0.0084,
      "step": 16441
    },
    {
      "epoch": 0.26033535475085895,
      "grad_norm": 0.9303712248802185,
      "learning_rate": 7.39664645249141e-06,
      "loss": 0.297,
      "step": 16442
    },
    {
      "epoch": 0.260351188308501,
      "grad_norm": 0.24085821211338043,
      "learning_rate": 7.39648811691499e-06,
      "loss": 0.0837,
      "step": 16443
    },
    {
      "epoch": 0.2603670218661431,
      "grad_norm": 0.469735711812973,
      "learning_rate": 7.396329781338569e-06,
      "loss": 0.0278,
      "step": 16444
    },
    {
      "epoch": 0.2603828554237852,
      "grad_norm": 0.5233193039894104,
      "learning_rate": 7.396171445762149e-06,
      "loss": 0.1379,
      "step": 16445
    },
    {
      "epoch": 0.26039868898142726,
      "grad_norm": 0.39451736211776733,
      "learning_rate": 7.396013110185728e-06,
      "loss": 0.1261,
      "step": 16446
    },
    {
      "epoch": 0.2604145225390693,
      "grad_norm": 0.1730761080980301,
      "learning_rate": 7.3958547746093075e-06,
      "loss": 0.0478,
      "step": 16447
    },
    {
      "epoch": 0.2604303560967114,
      "grad_norm": 0.6561121940612793,
      "learning_rate": 7.3956964390328866e-06,
      "loss": 0.4473,
      "step": 16448
    },
    {
      "epoch": 0.26044618965435345,
      "grad_norm": 0.020432280376553535,
      "learning_rate": 7.3955381034564665e-06,
      "loss": 0.0011,
      "step": 16449
    },
    {
      "epoch": 0.2604620232119955,
      "grad_norm": 0.27297142148017883,
      "learning_rate": 7.3953797678800456e-06,
      "loss": 0.0681,
      "step": 16450
    },
    {
      "epoch": 0.2604778567696376,
      "grad_norm": 0.36650219559669495,
      "learning_rate": 7.3952214323036255e-06,
      "loss": 0.1686,
      "step": 16451
    },
    {
      "epoch": 0.26049369032727965,
      "grad_norm": 0.006375985685735941,
      "learning_rate": 7.395063096727204e-06,
      "loss": 0.0003,
      "step": 16452
    },
    {
      "epoch": 0.2605095238849217,
      "grad_norm": 0.10964049398899078,
      "learning_rate": 7.394904761150784e-06,
      "loss": 0.0039,
      "step": 16453
    },
    {
      "epoch": 0.2605253574425638,
      "grad_norm": 0.2932318449020386,
      "learning_rate": 7.394746425574363e-06,
      "loss": 0.0275,
      "step": 16454
    },
    {
      "epoch": 0.26054119100020584,
      "grad_norm": 0.27533113956451416,
      "learning_rate": 7.394588089997943e-06,
      "loss": 0.1223,
      "step": 16455
    },
    {
      "epoch": 0.2605570245578479,
      "grad_norm": 0.5044299960136414,
      "learning_rate": 7.394429754421522e-06,
      "loss": 0.033,
      "step": 16456
    },
    {
      "epoch": 0.26057285811548997,
      "grad_norm": 0.4326409101486206,
      "learning_rate": 7.3942714188451e-06,
      "loss": 0.1227,
      "step": 16457
    },
    {
      "epoch": 0.26058869167313203,
      "grad_norm": 0.46782344579696655,
      "learning_rate": 7.39411308326868e-06,
      "loss": 0.1862,
      "step": 16458
    },
    {
      "epoch": 0.2606045252307741,
      "grad_norm": 0.48422208428382874,
      "learning_rate": 7.393954747692259e-06,
      "loss": 0.1037,
      "step": 16459
    },
    {
      "epoch": 0.26062035878841616,
      "grad_norm": 1.055469036102295,
      "learning_rate": 7.393796412115839e-06,
      "loss": 0.6636,
      "step": 16460
    },
    {
      "epoch": 0.2606361923460582,
      "grad_norm": 0.8645753860473633,
      "learning_rate": 7.393638076539418e-06,
      "loss": 0.1672,
      "step": 16461
    },
    {
      "epoch": 0.2606520259037003,
      "grad_norm": 0.475241482257843,
      "learning_rate": 7.393479740962998e-06,
      "loss": 0.1642,
      "step": 16462
    },
    {
      "epoch": 0.26066785946134235,
      "grad_norm": 0.009761468507349491,
      "learning_rate": 7.393321405386576e-06,
      "loss": 0.0004,
      "step": 16463
    },
    {
      "epoch": 0.2606836930189844,
      "grad_norm": 0.14360937476158142,
      "learning_rate": 7.393163069810156e-06,
      "loss": 0.0041,
      "step": 16464
    },
    {
      "epoch": 0.2606995265766265,
      "grad_norm": 0.36056238412857056,
      "learning_rate": 7.393004734233735e-06,
      "loss": 0.1424,
      "step": 16465
    },
    {
      "epoch": 0.26071536013426855,
      "grad_norm": 0.27230748534202576,
      "learning_rate": 7.392846398657315e-06,
      "loss": 0.0143,
      "step": 16466
    },
    {
      "epoch": 0.2607311936919106,
      "grad_norm": 0.0014969301410019398,
      "learning_rate": 7.392688063080894e-06,
      "loss": 0.0,
      "step": 16467
    },
    {
      "epoch": 0.2607470272495527,
      "grad_norm": 0.0008105244487524033,
      "learning_rate": 7.392529727504474e-06,
      "loss": 0.0,
      "step": 16468
    },
    {
      "epoch": 0.2607628608071948,
      "grad_norm": 0.03751101717352867,
      "learning_rate": 7.392371391928052e-06,
      "loss": 0.0017,
      "step": 16469
    },
    {
      "epoch": 0.26077869436483686,
      "grad_norm": 0.36254608631134033,
      "learning_rate": 7.392213056351632e-06,
      "loss": 0.0395,
      "step": 16470
    },
    {
      "epoch": 0.2607945279224789,
      "grad_norm": 0.6039351224899292,
      "learning_rate": 7.392054720775211e-06,
      "loss": 0.0601,
      "step": 16471
    },
    {
      "epoch": 0.260810361480121,
      "grad_norm": 0.5978076457977295,
      "learning_rate": 7.391896385198791e-06,
      "loss": 0.4467,
      "step": 16472
    },
    {
      "epoch": 0.26082619503776305,
      "grad_norm": 0.3600507974624634,
      "learning_rate": 7.39173804962237e-06,
      "loss": 0.1032,
      "step": 16473
    },
    {
      "epoch": 0.2608420285954051,
      "grad_norm": 0.7514225840568542,
      "learning_rate": 7.39157971404595e-06,
      "loss": 0.1447,
      "step": 16474
    },
    {
      "epoch": 0.2608578621530472,
      "grad_norm": 0.7305300235748291,
      "learning_rate": 7.3914213784695285e-06,
      "loss": 0.5838,
      "step": 16475
    },
    {
      "epoch": 0.26087369571068925,
      "grad_norm": 0.5847047567367554,
      "learning_rate": 7.391263042893108e-06,
      "loss": 0.1949,
      "step": 16476
    },
    {
      "epoch": 0.2608895292683313,
      "grad_norm": 0.3210552930831909,
      "learning_rate": 7.3911047073166875e-06,
      "loss": 0.0523,
      "step": 16477
    },
    {
      "epoch": 0.2609053628259734,
      "grad_norm": 0.008679511025547981,
      "learning_rate": 7.390946371740267e-06,
      "loss": 0.0004,
      "step": 16478
    },
    {
      "epoch": 0.26092119638361544,
      "grad_norm": 0.018534431234002113,
      "learning_rate": 7.3907880361638465e-06,
      "loss": 0.0008,
      "step": 16479
    },
    {
      "epoch": 0.2609370299412575,
      "grad_norm": 0.7250832915306091,
      "learning_rate": 7.3906297005874264e-06,
      "loss": 0.1449,
      "step": 16480
    },
    {
      "epoch": 0.26095286349889957,
      "grad_norm": 0.49245312809944153,
      "learning_rate": 7.390471365011005e-06,
      "loss": 0.0269,
      "step": 16481
    },
    {
      "epoch": 0.26096869705654163,
      "grad_norm": 0.9766209125518799,
      "learning_rate": 7.390313029434584e-06,
      "loss": 0.7826,
      "step": 16482
    },
    {
      "epoch": 0.2609845306141837,
      "grad_norm": 0.00020493502961471677,
      "learning_rate": 7.390154693858164e-06,
      "loss": 0.0,
      "step": 16483
    },
    {
      "epoch": 0.26100036417182576,
      "grad_norm": 0.0024312790483236313,
      "learning_rate": 7.389996358281743e-06,
      "loss": 0.0001,
      "step": 16484
    },
    {
      "epoch": 0.2610161977294678,
      "grad_norm": 0.15374387800693512,
      "learning_rate": 7.389838022705323e-06,
      "loss": 0.0253,
      "step": 16485
    },
    {
      "epoch": 0.2610320312871099,
      "grad_norm": 0.528832733631134,
      "learning_rate": 7.389679687128901e-06,
      "loss": 0.0232,
      "step": 16486
    },
    {
      "epoch": 0.26104786484475195,
      "grad_norm": 2.416454315185547,
      "learning_rate": 7.389521351552481e-06,
      "loss": 0.1773,
      "step": 16487
    },
    {
      "epoch": 0.261063698402394,
      "grad_norm": 0.00012092215183656663,
      "learning_rate": 7.38936301597606e-06,
      "loss": 0.0,
      "step": 16488
    },
    {
      "epoch": 0.2610795319600361,
      "grad_norm": 0.14628271758556366,
      "learning_rate": 7.38920468039964e-06,
      "loss": 0.0592,
      "step": 16489
    },
    {
      "epoch": 0.26109536551767815,
      "grad_norm": 0.014582706615328789,
      "learning_rate": 7.389046344823219e-06,
      "loss": 0.0008,
      "step": 16490
    },
    {
      "epoch": 0.2611111990753202,
      "grad_norm": 0.0007732030935585499,
      "learning_rate": 7.388888009246799e-06,
      "loss": 0.0,
      "step": 16491
    },
    {
      "epoch": 0.2611270326329623,
      "grad_norm": 0.39750295877456665,
      "learning_rate": 7.388729673670377e-06,
      "loss": 0.1212,
      "step": 16492
    },
    {
      "epoch": 0.2611428661906044,
      "grad_norm": 0.19595478475093842,
      "learning_rate": 7.388571338093957e-06,
      "loss": 0.067,
      "step": 16493
    },
    {
      "epoch": 0.26115869974824646,
      "grad_norm": 0.23795266449451447,
      "learning_rate": 7.388413002517536e-06,
      "loss": 0.0367,
      "step": 16494
    },
    {
      "epoch": 0.2611745333058885,
      "grad_norm": 0.3620719313621521,
      "learning_rate": 7.388254666941116e-06,
      "loss": 0.0932,
      "step": 16495
    },
    {
      "epoch": 0.2611903668635306,
      "grad_norm": 0.4880231022834778,
      "learning_rate": 7.388096331364695e-06,
      "loss": 0.2507,
      "step": 16496
    },
    {
      "epoch": 0.26120620042117265,
      "grad_norm": 0.2404177188873291,
      "learning_rate": 7.387937995788275e-06,
      "loss": 0.0853,
      "step": 16497
    },
    {
      "epoch": 0.2612220339788147,
      "grad_norm": 0.6811693906784058,
      "learning_rate": 7.387779660211853e-06,
      "loss": 0.3883,
      "step": 16498
    },
    {
      "epoch": 0.2612378675364568,
      "grad_norm": 0.48313677310943604,
      "learning_rate": 7.387621324635433e-06,
      "loss": 0.1277,
      "step": 16499
    },
    {
      "epoch": 0.26125370109409884,
      "grad_norm": 0.014238967560231686,
      "learning_rate": 7.387462989059012e-06,
      "loss": 0.0007,
      "step": 16500
    },
    {
      "epoch": 0.2612695346517409,
      "grad_norm": 0.32544806599617004,
      "learning_rate": 7.387304653482592e-06,
      "loss": 0.006,
      "step": 16501
    },
    {
      "epoch": 0.261285368209383,
      "grad_norm": 0.6752024292945862,
      "learning_rate": 7.387146317906171e-06,
      "loss": 0.1962,
      "step": 16502
    },
    {
      "epoch": 0.26130120176702504,
      "grad_norm": 0.0016823508776724339,
      "learning_rate": 7.386987982329751e-06,
      "loss": 0.0,
      "step": 16503
    },
    {
      "epoch": 0.2613170353246671,
      "grad_norm": 0.6016101241111755,
      "learning_rate": 7.386829646753329e-06,
      "loss": 0.292,
      "step": 16504
    },
    {
      "epoch": 0.26133286888230917,
      "grad_norm": 0.5306941866874695,
      "learning_rate": 7.386671311176909e-06,
      "loss": 0.0592,
      "step": 16505
    },
    {
      "epoch": 0.26134870243995123,
      "grad_norm": 0.937986433506012,
      "learning_rate": 7.386512975600488e-06,
      "loss": 0.0456,
      "step": 16506
    },
    {
      "epoch": 0.2613645359975933,
      "grad_norm": 0.5891847014427185,
      "learning_rate": 7.3863546400240675e-06,
      "loss": 0.4348,
      "step": 16507
    },
    {
      "epoch": 0.26138036955523536,
      "grad_norm": 0.2864076495170593,
      "learning_rate": 7.3861963044476474e-06,
      "loss": 0.0741,
      "step": 16508
    },
    {
      "epoch": 0.2613962031128774,
      "grad_norm": 0.022457249462604523,
      "learning_rate": 7.386037968871226e-06,
      "loss": 0.001,
      "step": 16509
    },
    {
      "epoch": 0.2614120366705195,
      "grad_norm": 0.00021934710093773901,
      "learning_rate": 7.385879633294806e-06,
      "loss": 0.0,
      "step": 16510
    },
    {
      "epoch": 0.26142787022816155,
      "grad_norm": 0.008352681994438171,
      "learning_rate": 7.385721297718385e-06,
      "loss": 0.0004,
      "step": 16511
    },
    {
      "epoch": 0.2614437037858036,
      "grad_norm": 0.20368528366088867,
      "learning_rate": 7.385562962141965e-06,
      "loss": 0.1223,
      "step": 16512
    },
    {
      "epoch": 0.2614595373434457,
      "grad_norm": 0.008756102062761784,
      "learning_rate": 7.385404626565543e-06,
      "loss": 0.0004,
      "step": 16513
    },
    {
      "epoch": 0.26147537090108774,
      "grad_norm": 0.6007871031761169,
      "learning_rate": 7.385246290989123e-06,
      "loss": 0.0628,
      "step": 16514
    },
    {
      "epoch": 0.2614912044587298,
      "grad_norm": 0.24078276753425598,
      "learning_rate": 7.385087955412702e-06,
      "loss": 0.003,
      "step": 16515
    },
    {
      "epoch": 0.2615070380163719,
      "grad_norm": 0.4954651892185211,
      "learning_rate": 7.384929619836282e-06,
      "loss": 0.2065,
      "step": 16516
    },
    {
      "epoch": 0.26152287157401394,
      "grad_norm": 0.48325008153915405,
      "learning_rate": 7.384771284259861e-06,
      "loss": 0.1955,
      "step": 16517
    },
    {
      "epoch": 0.26153870513165606,
      "grad_norm": 0.313549280166626,
      "learning_rate": 7.384612948683441e-06,
      "loss": 0.1675,
      "step": 16518
    },
    {
      "epoch": 0.2615545386892981,
      "grad_norm": 0.00045698031317442656,
      "learning_rate": 7.384454613107019e-06,
      "loss": 0.0,
      "step": 16519
    },
    {
      "epoch": 0.2615703722469402,
      "grad_norm": 0.5043885111808777,
      "learning_rate": 7.384296277530599e-06,
      "loss": 0.6349,
      "step": 16520
    },
    {
      "epoch": 0.26158620580458225,
      "grad_norm": 0.29071682691574097,
      "learning_rate": 7.384137941954178e-06,
      "loss": 0.185,
      "step": 16521
    },
    {
      "epoch": 0.2616020393622243,
      "grad_norm": 0.00020228829816915095,
      "learning_rate": 7.383979606377758e-06,
      "loss": 0.0,
      "step": 16522
    },
    {
      "epoch": 0.2616178729198664,
      "grad_norm": 0.007753143087029457,
      "learning_rate": 7.383821270801337e-06,
      "loss": 0.0004,
      "step": 16523
    },
    {
      "epoch": 0.26163370647750844,
      "grad_norm": 0.023167185485363007,
      "learning_rate": 7.383662935224917e-06,
      "loss": 0.0014,
      "step": 16524
    },
    {
      "epoch": 0.2616495400351505,
      "grad_norm": 0.4703546166419983,
      "learning_rate": 7.383504599648495e-06,
      "loss": 0.027,
      "step": 16525
    },
    {
      "epoch": 0.26166537359279257,
      "grad_norm": 0.47875481843948364,
      "learning_rate": 7.383346264072075e-06,
      "loss": 0.134,
      "step": 16526
    },
    {
      "epoch": 0.26168120715043464,
      "grad_norm": 0.32161396741867065,
      "learning_rate": 7.383187928495654e-06,
      "loss": 0.1039,
      "step": 16527
    },
    {
      "epoch": 0.2616970407080767,
      "grad_norm": 0.2218128740787506,
      "learning_rate": 7.383029592919234e-06,
      "loss": 0.0288,
      "step": 16528
    },
    {
      "epoch": 0.26171287426571876,
      "grad_norm": 0.4047613739967346,
      "learning_rate": 7.382871257342813e-06,
      "loss": 0.2154,
      "step": 16529
    },
    {
      "epoch": 0.26172870782336083,
      "grad_norm": 0.05175897479057312,
      "learning_rate": 7.382712921766391e-06,
      "loss": 0.0042,
      "step": 16530
    },
    {
      "epoch": 0.2617445413810029,
      "grad_norm": 0.5669618844985962,
      "learning_rate": 7.382554586189971e-06,
      "loss": 0.1431,
      "step": 16531
    },
    {
      "epoch": 0.26176037493864496,
      "grad_norm": 0.9828355312347412,
      "learning_rate": 7.38239625061355e-06,
      "loss": 0.6634,
      "step": 16532
    },
    {
      "epoch": 0.261776208496287,
      "grad_norm": 0.17138290405273438,
      "learning_rate": 7.38223791503713e-06,
      "loss": 0.0515,
      "step": 16533
    },
    {
      "epoch": 0.2617920420539291,
      "grad_norm": 0.0012304192641749978,
      "learning_rate": 7.3820795794607094e-06,
      "loss": 0.0,
      "step": 16534
    },
    {
      "epoch": 0.26180787561157115,
      "grad_norm": 0.000980951590463519,
      "learning_rate": 7.381921243884289e-06,
      "loss": 0.0,
      "step": 16535
    },
    {
      "epoch": 0.2618237091692132,
      "grad_norm": 0.8779600858688354,
      "learning_rate": 7.381762908307868e-06,
      "loss": 0.2984,
      "step": 16536
    },
    {
      "epoch": 0.2618395427268553,
      "grad_norm": 0.18420276045799255,
      "learning_rate": 7.3816045727314475e-06,
      "loss": 0.0647,
      "step": 16537
    },
    {
      "epoch": 0.26185537628449734,
      "grad_norm": 0.007051380351185799,
      "learning_rate": 7.381446237155027e-06,
      "loss": 0.0003,
      "step": 16538
    },
    {
      "epoch": 0.2618712098421394,
      "grad_norm": 0.6238507628440857,
      "learning_rate": 7.3812879015786065e-06,
      "loss": 0.5396,
      "step": 16539
    },
    {
      "epoch": 0.26188704339978147,
      "grad_norm": 5.951334969722666e-05,
      "learning_rate": 7.381129566002186e-06,
      "loss": 0.0,
      "step": 16540
    },
    {
      "epoch": 0.26190287695742354,
      "grad_norm": 0.23579342663288116,
      "learning_rate": 7.3809712304257655e-06,
      "loss": 0.0622,
      "step": 16541
    },
    {
      "epoch": 0.26191871051506566,
      "grad_norm": 0.12596748769283295,
      "learning_rate": 7.380812894849344e-06,
      "loss": 0.0052,
      "step": 16542
    },
    {
      "epoch": 0.2619345440727077,
      "grad_norm": 0.29665228724479675,
      "learning_rate": 7.380654559272924e-06,
      "loss": 0.1126,
      "step": 16543
    },
    {
      "epoch": 0.2619503776303498,
      "grad_norm": 0.6432754397392273,
      "learning_rate": 7.380496223696503e-06,
      "loss": 0.6242,
      "step": 16544
    },
    {
      "epoch": 0.26196621118799185,
      "grad_norm": 0.48506665229797363,
      "learning_rate": 7.380337888120083e-06,
      "loss": 0.516,
      "step": 16545
    },
    {
      "epoch": 0.2619820447456339,
      "grad_norm": 0.28483372926712036,
      "learning_rate": 7.380179552543662e-06,
      "loss": 0.0672,
      "step": 16546
    },
    {
      "epoch": 0.261997878303276,
      "grad_norm": 0.16166891157627106,
      "learning_rate": 7.380021216967242e-06,
      "loss": 0.0109,
      "step": 16547
    },
    {
      "epoch": 0.26201371186091804,
      "grad_norm": 0.026178408414125443,
      "learning_rate": 7.37986288139082e-06,
      "loss": 0.0014,
      "step": 16548
    },
    {
      "epoch": 0.2620295454185601,
      "grad_norm": 0.00882931612432003,
      "learning_rate": 7.3797045458144e-06,
      "loss": 0.0001,
      "step": 16549
    },
    {
      "epoch": 0.26204537897620217,
      "grad_norm": 0.35141992568969727,
      "learning_rate": 7.379546210237979e-06,
      "loss": 0.1164,
      "step": 16550
    },
    {
      "epoch": 0.26206121253384423,
      "grad_norm": 0.3343146741390228,
      "learning_rate": 7.379387874661559e-06,
      "loss": 0.1476,
      "step": 16551
    },
    {
      "epoch": 0.2620770460914863,
      "grad_norm": 0.9559170603752136,
      "learning_rate": 7.379229539085138e-06,
      "loss": 0.5701,
      "step": 16552
    },
    {
      "epoch": 0.26209287964912836,
      "grad_norm": 0.34677621722221375,
      "learning_rate": 7.379071203508718e-06,
      "loss": 0.0511,
      "step": 16553
    },
    {
      "epoch": 0.2621087132067704,
      "grad_norm": 0.3641810715198517,
      "learning_rate": 7.378912867932296e-06,
      "loss": 0.0543,
      "step": 16554
    },
    {
      "epoch": 0.2621245467644125,
      "grad_norm": 0.2006906270980835,
      "learning_rate": 7.378754532355875e-06,
      "loss": 0.0442,
      "step": 16555
    },
    {
      "epoch": 0.26214038032205456,
      "grad_norm": 0.012665516696870327,
      "learning_rate": 7.378596196779455e-06,
      "loss": 0.0005,
      "step": 16556
    },
    {
      "epoch": 0.2621562138796966,
      "grad_norm": 0.5358514189720154,
      "learning_rate": 7.378437861203034e-06,
      "loss": 0.1144,
      "step": 16557
    },
    {
      "epoch": 0.2621720474373387,
      "grad_norm": 0.17639288306236267,
      "learning_rate": 7.378279525626614e-06,
      "loss": 0.0145,
      "step": 16558
    },
    {
      "epoch": 0.26218788099498075,
      "grad_norm": 0.6608176827430725,
      "learning_rate": 7.378121190050192e-06,
      "loss": 0.2903,
      "step": 16559
    },
    {
      "epoch": 0.2622037145526228,
      "grad_norm": 0.7107349038124084,
      "learning_rate": 7.377962854473772e-06,
      "loss": 0.0807,
      "step": 16560
    },
    {
      "epoch": 0.2622195481102649,
      "grad_norm": 0.17673379182815552,
      "learning_rate": 7.377804518897351e-06,
      "loss": 0.012,
      "step": 16561
    },
    {
      "epoch": 0.26223538166790694,
      "grad_norm": 0.34333598613739014,
      "learning_rate": 7.377646183320931e-06,
      "loss": 0.1156,
      "step": 16562
    },
    {
      "epoch": 0.262251215225549,
      "grad_norm": 0.5865139961242676,
      "learning_rate": 7.37748784774451e-06,
      "loss": 0.1572,
      "step": 16563
    },
    {
      "epoch": 0.26226704878319107,
      "grad_norm": 0.48302724957466125,
      "learning_rate": 7.37732951216809e-06,
      "loss": 0.0361,
      "step": 16564
    },
    {
      "epoch": 0.26228288234083313,
      "grad_norm": 0.5702506899833679,
      "learning_rate": 7.3771711765916685e-06,
      "loss": 0.1953,
      "step": 16565
    },
    {
      "epoch": 0.26229871589847525,
      "grad_norm": 0.320121705532074,
      "learning_rate": 7.3770128410152484e-06,
      "loss": 0.0604,
      "step": 16566
    },
    {
      "epoch": 0.2623145494561173,
      "grad_norm": 0.5330442190170288,
      "learning_rate": 7.3768545054388275e-06,
      "loss": 0.1161,
      "step": 16567
    },
    {
      "epoch": 0.2623303830137594,
      "grad_norm": 0.19373944401741028,
      "learning_rate": 7.3766961698624074e-06,
      "loss": 0.0598,
      "step": 16568
    },
    {
      "epoch": 0.26234621657140145,
      "grad_norm": 0.2594851553440094,
      "learning_rate": 7.3765378342859865e-06,
      "loss": 0.0301,
      "step": 16569
    },
    {
      "epoch": 0.2623620501290435,
      "grad_norm": 0.625385582447052,
      "learning_rate": 7.3763794987095665e-06,
      "loss": 0.2498,
      "step": 16570
    },
    {
      "epoch": 0.2623778836866856,
      "grad_norm": 0.16952931880950928,
      "learning_rate": 7.376221163133145e-06,
      "loss": 0.0567,
      "step": 16571
    },
    {
      "epoch": 0.26239371724432764,
      "grad_norm": 0.00019993654859717935,
      "learning_rate": 7.376062827556725e-06,
      "loss": 0.0,
      "step": 16572
    },
    {
      "epoch": 0.2624095508019697,
      "grad_norm": 0.01628507673740387,
      "learning_rate": 7.375904491980304e-06,
      "loss": 0.0007,
      "step": 16573
    },
    {
      "epoch": 0.26242538435961177,
      "grad_norm": 0.00013507595576811582,
      "learning_rate": 7.375746156403884e-06,
      "loss": 0.0,
      "step": 16574
    },
    {
      "epoch": 0.26244121791725383,
      "grad_norm": 0.19942142069339752,
      "learning_rate": 7.375587820827462e-06,
      "loss": 0.0714,
      "step": 16575
    },
    {
      "epoch": 0.2624570514748959,
      "grad_norm": 0.43414974212646484,
      "learning_rate": 7.375429485251042e-06,
      "loss": 0.1245,
      "step": 16576
    },
    {
      "epoch": 0.26247288503253796,
      "grad_norm": 0.3358268439769745,
      "learning_rate": 7.375271149674621e-06,
      "loss": 0.1387,
      "step": 16577
    },
    {
      "epoch": 0.26248871859018,
      "grad_norm": 0.6854260563850403,
      "learning_rate": 7.3751128140982e-06,
      "loss": 0.2615,
      "step": 16578
    },
    {
      "epoch": 0.2625045521478221,
      "grad_norm": 0.014727271161973476,
      "learning_rate": 7.37495447852178e-06,
      "loss": 0.0006,
      "step": 16579
    },
    {
      "epoch": 0.26252038570546415,
      "grad_norm": 0.35052409768104553,
      "learning_rate": 7.374796142945358e-06,
      "loss": 0.0883,
      "step": 16580
    },
    {
      "epoch": 0.2625362192631062,
      "grad_norm": 0.6359937787055969,
      "learning_rate": 7.374637807368938e-06,
      "loss": 0.4363,
      "step": 16581
    },
    {
      "epoch": 0.2625520528207483,
      "grad_norm": 0.3132571578025818,
      "learning_rate": 7.374479471792517e-06,
      "loss": 0.0259,
      "step": 16582
    },
    {
      "epoch": 0.26256788637839035,
      "grad_norm": 0.0002202872565248981,
      "learning_rate": 7.374321136216097e-06,
      "loss": 0.0,
      "step": 16583
    },
    {
      "epoch": 0.2625837199360324,
      "grad_norm": 0.03951544314622879,
      "learning_rate": 7.374162800639676e-06,
      "loss": 0.0019,
      "step": 16584
    },
    {
      "epoch": 0.2625995534936745,
      "grad_norm": 0.7297414541244507,
      "learning_rate": 7.374004465063256e-06,
      "loss": 0.1849,
      "step": 16585
    },
    {
      "epoch": 0.26261538705131654,
      "grad_norm": 0.020023789256811142,
      "learning_rate": 7.373846129486834e-06,
      "loss": 0.0002,
      "step": 16586
    },
    {
      "epoch": 0.2626312206089586,
      "grad_norm": 0.001726084272377193,
      "learning_rate": 7.373687793910414e-06,
      "loss": 0.0,
      "step": 16587
    },
    {
      "epoch": 0.26264705416660067,
      "grad_norm": 0.5778976678848267,
      "learning_rate": 7.373529458333993e-06,
      "loss": 0.3655,
      "step": 16588
    },
    {
      "epoch": 0.26266288772424273,
      "grad_norm": 0.465463250875473,
      "learning_rate": 7.373371122757573e-06,
      "loss": 0.5152,
      "step": 16589
    },
    {
      "epoch": 0.26267872128188485,
      "grad_norm": 0.025021856650710106,
      "learning_rate": 7.373212787181152e-06,
      "loss": 0.0013,
      "step": 16590
    },
    {
      "epoch": 0.2626945548395269,
      "grad_norm": 0.5647135972976685,
      "learning_rate": 7.373054451604732e-06,
      "loss": 0.2565,
      "step": 16591
    },
    {
      "epoch": 0.262710388397169,
      "grad_norm": 0.7834445834159851,
      "learning_rate": 7.3728961160283104e-06,
      "loss": 0.6757,
      "step": 16592
    },
    {
      "epoch": 0.26272622195481105,
      "grad_norm": 0.8700590133666992,
      "learning_rate": 7.37273778045189e-06,
      "loss": 0.3105,
      "step": 16593
    },
    {
      "epoch": 0.2627420555124531,
      "grad_norm": 0.6321190595626831,
      "learning_rate": 7.3725794448754694e-06,
      "loss": 0.3446,
      "step": 16594
    },
    {
      "epoch": 0.2627578890700952,
      "grad_norm": 0.0003588432737160474,
      "learning_rate": 7.372421109299049e-06,
      "loss": 0.0,
      "step": 16595
    },
    {
      "epoch": 0.26277372262773724,
      "grad_norm": 0.3253423869609833,
      "learning_rate": 7.3722627737226285e-06,
      "loss": 0.1007,
      "step": 16596
    },
    {
      "epoch": 0.2627895561853793,
      "grad_norm": 0.22402174770832062,
      "learning_rate": 7.372104438146208e-06,
      "loss": 0.0636,
      "step": 16597
    },
    {
      "epoch": 0.26280538974302137,
      "grad_norm": 0.4706763029098511,
      "learning_rate": 7.371946102569787e-06,
      "loss": 0.075,
      "step": 16598
    },
    {
      "epoch": 0.26282122330066343,
      "grad_norm": 0.34494972229003906,
      "learning_rate": 7.3717877669933665e-06,
      "loss": 0.0662,
      "step": 16599
    },
    {
      "epoch": 0.2628370568583055,
      "grad_norm": 0.9799399375915527,
      "learning_rate": 7.371629431416946e-06,
      "loss": 0.1456,
      "step": 16600
    },
    {
      "epoch": 0.26285289041594756,
      "grad_norm": 0.27620601654052734,
      "learning_rate": 7.3714710958405255e-06,
      "loss": 0.0565,
      "step": 16601
    },
    {
      "epoch": 0.2628687239735896,
      "grad_norm": 0.5465816259384155,
      "learning_rate": 7.371312760264105e-06,
      "loss": 0.7138,
      "step": 16602
    },
    {
      "epoch": 0.2628845575312317,
      "grad_norm": 0.4811512231826782,
      "learning_rate": 7.371154424687683e-06,
      "loss": 0.091,
      "step": 16603
    },
    {
      "epoch": 0.26290039108887375,
      "grad_norm": 0.39024871587753296,
      "learning_rate": 7.370996089111263e-06,
      "loss": 0.1369,
      "step": 16604
    },
    {
      "epoch": 0.2629162246465158,
      "grad_norm": 1.0933709144592285,
      "learning_rate": 7.370837753534842e-06,
      "loss": 0.129,
      "step": 16605
    },
    {
      "epoch": 0.2629320582041579,
      "grad_norm": 0.24663369357585907,
      "learning_rate": 7.370679417958422e-06,
      "loss": 0.0447,
      "step": 16606
    },
    {
      "epoch": 0.26294789176179995,
      "grad_norm": 0.6563205718994141,
      "learning_rate": 7.370521082382001e-06,
      "loss": 0.4277,
      "step": 16607
    },
    {
      "epoch": 0.262963725319442,
      "grad_norm": 0.014843400567770004,
      "learning_rate": 7.370362746805581e-06,
      "loss": 0.0008,
      "step": 16608
    },
    {
      "epoch": 0.2629795588770841,
      "grad_norm": 2.351027488708496,
      "learning_rate": 7.370204411229159e-06,
      "loss": 0.1025,
      "step": 16609
    },
    {
      "epoch": 0.26299539243472614,
      "grad_norm": 0.19351449608802795,
      "learning_rate": 7.370046075652739e-06,
      "loss": 0.0085,
      "step": 16610
    },
    {
      "epoch": 0.2630112259923682,
      "grad_norm": 0.20638194680213928,
      "learning_rate": 7.369887740076318e-06,
      "loss": 0.0274,
      "step": 16611
    },
    {
      "epoch": 0.26302705955001027,
      "grad_norm": 0.35945478081703186,
      "learning_rate": 7.369729404499898e-06,
      "loss": 0.2242,
      "step": 16612
    },
    {
      "epoch": 0.26304289310765233,
      "grad_norm": 0.15637212991714478,
      "learning_rate": 7.369571068923477e-06,
      "loss": 0.0265,
      "step": 16613
    },
    {
      "epoch": 0.26305872666529445,
      "grad_norm": 0.4099690914154053,
      "learning_rate": 7.369412733347057e-06,
      "loss": 0.2378,
      "step": 16614
    },
    {
      "epoch": 0.2630745602229365,
      "grad_norm": 0.3311119079589844,
      "learning_rate": 7.369254397770635e-06,
      "loss": 0.0465,
      "step": 16615
    },
    {
      "epoch": 0.2630903937805786,
      "grad_norm": 0.33596500754356384,
      "learning_rate": 7.369096062194215e-06,
      "loss": 0.0624,
      "step": 16616
    },
    {
      "epoch": 0.26310622733822064,
      "grad_norm": 0.023829931393265724,
      "learning_rate": 7.368937726617794e-06,
      "loss": 0.0011,
      "step": 16617
    },
    {
      "epoch": 0.2631220608958627,
      "grad_norm": 0.4532926082611084,
      "learning_rate": 7.368779391041374e-06,
      "loss": 0.1646,
      "step": 16618
    },
    {
      "epoch": 0.2631378944535048,
      "grad_norm": 0.2511986792087555,
      "learning_rate": 7.368621055464953e-06,
      "loss": 0.0339,
      "step": 16619
    },
    {
      "epoch": 0.26315372801114684,
      "grad_norm": 0.6993113160133362,
      "learning_rate": 7.368462719888533e-06,
      "loss": 0.6151,
      "step": 16620
    },
    {
      "epoch": 0.2631695615687889,
      "grad_norm": 0.0058541567996144295,
      "learning_rate": 7.368304384312111e-06,
      "loss": 0.0002,
      "step": 16621
    },
    {
      "epoch": 0.26318539512643097,
      "grad_norm": 0.43669089674949646,
      "learning_rate": 7.368146048735691e-06,
      "loss": 0.1808,
      "step": 16622
    },
    {
      "epoch": 0.26320122868407303,
      "grad_norm": 0.1937553584575653,
      "learning_rate": 7.36798771315927e-06,
      "loss": 0.002,
      "step": 16623
    },
    {
      "epoch": 0.2632170622417151,
      "grad_norm": 0.5107094645500183,
      "learning_rate": 7.36782937758285e-06,
      "loss": 0.4526,
      "step": 16624
    },
    {
      "epoch": 0.26323289579935716,
      "grad_norm": 0.17285548150539398,
      "learning_rate": 7.367671042006429e-06,
      "loss": 0.0169,
      "step": 16625
    },
    {
      "epoch": 0.2632487293569992,
      "grad_norm": 0.02316281385719776,
      "learning_rate": 7.367512706430008e-06,
      "loss": 0.0011,
      "step": 16626
    },
    {
      "epoch": 0.2632645629146413,
      "grad_norm": 0.012583788484334946,
      "learning_rate": 7.3673543708535875e-06,
      "loss": 0.0007,
      "step": 16627
    },
    {
      "epoch": 0.26328039647228335,
      "grad_norm": 0.25840961933135986,
      "learning_rate": 7.367196035277167e-06,
      "loss": 0.0221,
      "step": 16628
    },
    {
      "epoch": 0.2632962300299254,
      "grad_norm": 0.05833500251173973,
      "learning_rate": 7.3670376997007465e-06,
      "loss": 0.0042,
      "step": 16629
    },
    {
      "epoch": 0.2633120635875675,
      "grad_norm": 0.022630546241998672,
      "learning_rate": 7.366879364124326e-06,
      "loss": 0.0011,
      "step": 16630
    },
    {
      "epoch": 0.26332789714520954,
      "grad_norm": 0.4276527762413025,
      "learning_rate": 7.3667210285479056e-06,
      "loss": 0.4068,
      "step": 16631
    },
    {
      "epoch": 0.2633437307028516,
      "grad_norm": 0.0003724369453266263,
      "learning_rate": 7.366562692971484e-06,
      "loss": 0.0,
      "step": 16632
    },
    {
      "epoch": 0.2633595642604937,
      "grad_norm": 0.3306542634963989,
      "learning_rate": 7.366404357395064e-06,
      "loss": 0.0772,
      "step": 16633
    },
    {
      "epoch": 0.26337539781813574,
      "grad_norm": 0.013717214576900005,
      "learning_rate": 7.366246021818643e-06,
      "loss": 0.0007,
      "step": 16634
    },
    {
      "epoch": 0.2633912313757778,
      "grad_norm": 0.7244495153427124,
      "learning_rate": 7.366087686242223e-06,
      "loss": 0.7661,
      "step": 16635
    },
    {
      "epoch": 0.26340706493341987,
      "grad_norm": 0.4375157952308655,
      "learning_rate": 7.365929350665802e-06,
      "loss": 0.0899,
      "step": 16636
    },
    {
      "epoch": 0.26342289849106193,
      "grad_norm": 0.010603796690702438,
      "learning_rate": 7.365771015089382e-06,
      "loss": 0.0005,
      "step": 16637
    },
    {
      "epoch": 0.26343873204870405,
      "grad_norm": 0.38775014877319336,
      "learning_rate": 7.36561267951296e-06,
      "loss": 0.1093,
      "step": 16638
    },
    {
      "epoch": 0.2634545656063461,
      "grad_norm": 0.43924006819725037,
      "learning_rate": 7.36545434393654e-06,
      "loss": 0.3634,
      "step": 16639
    },
    {
      "epoch": 0.2634703991639882,
      "grad_norm": 0.36203858256340027,
      "learning_rate": 7.365296008360119e-06,
      "loss": 0.1295,
      "step": 16640
    },
    {
      "epoch": 0.26348623272163024,
      "grad_norm": 0.3253670334815979,
      "learning_rate": 7.365137672783699e-06,
      "loss": 0.1181,
      "step": 16641
    },
    {
      "epoch": 0.2635020662792723,
      "grad_norm": 0.019953077659010887,
      "learning_rate": 7.364979337207277e-06,
      "loss": 0.0007,
      "step": 16642
    },
    {
      "epoch": 0.26351789983691437,
      "grad_norm": 0.548941433429718,
      "learning_rate": 7.364821001630857e-06,
      "loss": 0.2481,
      "step": 16643
    },
    {
      "epoch": 0.26353373339455644,
      "grad_norm": 0.21597407758235931,
      "learning_rate": 7.364662666054436e-06,
      "loss": 0.0526,
      "step": 16644
    },
    {
      "epoch": 0.2635495669521985,
      "grad_norm": 0.360537588596344,
      "learning_rate": 7.364504330478016e-06,
      "loss": 0.0402,
      "step": 16645
    },
    {
      "epoch": 0.26356540050984056,
      "grad_norm": 0.3630816638469696,
      "learning_rate": 7.364345994901595e-06,
      "loss": 0.1478,
      "step": 16646
    },
    {
      "epoch": 0.26358123406748263,
      "grad_norm": 0.13727332651615143,
      "learning_rate": 7.364187659325175e-06,
      "loss": 0.0495,
      "step": 16647
    },
    {
      "epoch": 0.2635970676251247,
      "grad_norm": 0.42101427912712097,
      "learning_rate": 7.364029323748753e-06,
      "loss": 0.2528,
      "step": 16648
    },
    {
      "epoch": 0.26361290118276676,
      "grad_norm": 0.4797581732273102,
      "learning_rate": 7.363870988172333e-06,
      "loss": 0.3208,
      "step": 16649
    },
    {
      "epoch": 0.2636287347404088,
      "grad_norm": 0.0002609709626995027,
      "learning_rate": 7.363712652595912e-06,
      "loss": 0.0,
      "step": 16650
    },
    {
      "epoch": 0.2636445682980509,
      "grad_norm": 0.14789564907550812,
      "learning_rate": 7.363554317019491e-06,
      "loss": 0.0033,
      "step": 16651
    },
    {
      "epoch": 0.26366040185569295,
      "grad_norm": 0.17524871230125427,
      "learning_rate": 7.363395981443071e-06,
      "loss": 0.0488,
      "step": 16652
    },
    {
      "epoch": 0.263676235413335,
      "grad_norm": 1.2351787090301514,
      "learning_rate": 7.3632376458666495e-06,
      "loss": 0.3023,
      "step": 16653
    },
    {
      "epoch": 0.2636920689709771,
      "grad_norm": 0.661342442035675,
      "learning_rate": 7.3630793102902295e-06,
      "loss": 0.5152,
      "step": 16654
    },
    {
      "epoch": 0.26370790252861914,
      "grad_norm": 0.0036422519478946924,
      "learning_rate": 7.3629209747138085e-06,
      "loss": 0.0001,
      "step": 16655
    },
    {
      "epoch": 0.2637237360862612,
      "grad_norm": 0.3497835397720337,
      "learning_rate": 7.3627626391373885e-06,
      "loss": 0.0673,
      "step": 16656
    },
    {
      "epoch": 0.26373956964390327,
      "grad_norm": 0.5579133033752441,
      "learning_rate": 7.3626043035609676e-06,
      "loss": 0.3663,
      "step": 16657
    },
    {
      "epoch": 0.26375540320154534,
      "grad_norm": 0.04643874987959862,
      "learning_rate": 7.3624459679845475e-06,
      "loss": 0.0022,
      "step": 16658
    },
    {
      "epoch": 0.2637712367591874,
      "grad_norm": 0.3341652452945709,
      "learning_rate": 7.362287632408126e-06,
      "loss": 0.0393,
      "step": 16659
    },
    {
      "epoch": 0.26378707031682946,
      "grad_norm": 0.9534509778022766,
      "learning_rate": 7.362129296831706e-06,
      "loss": 0.0413,
      "step": 16660
    },
    {
      "epoch": 0.26380290387447153,
      "grad_norm": 0.06121328845620155,
      "learning_rate": 7.361970961255285e-06,
      "loss": 0.0022,
      "step": 16661
    },
    {
      "epoch": 0.26381873743211365,
      "grad_norm": 0.38534924387931824,
      "learning_rate": 7.361812625678865e-06,
      "loss": 0.0874,
      "step": 16662
    },
    {
      "epoch": 0.2638345709897557,
      "grad_norm": 0.2840324938297272,
      "learning_rate": 7.361654290102444e-06,
      "loss": 0.1226,
      "step": 16663
    },
    {
      "epoch": 0.2638504045473978,
      "grad_norm": 0.42454448342323303,
      "learning_rate": 7.361495954526024e-06,
      "loss": 0.0717,
      "step": 16664
    },
    {
      "epoch": 0.26386623810503984,
      "grad_norm": 0.27678927779197693,
      "learning_rate": 7.361337618949602e-06,
      "loss": 0.189,
      "step": 16665
    },
    {
      "epoch": 0.2638820716626819,
      "grad_norm": 0.000304474524455145,
      "learning_rate": 7.361179283373182e-06,
      "loss": 0.0,
      "step": 16666
    },
    {
      "epoch": 0.26389790522032397,
      "grad_norm": 0.0531892403960228,
      "learning_rate": 7.361020947796761e-06,
      "loss": 0.0022,
      "step": 16667
    },
    {
      "epoch": 0.26391373877796603,
      "grad_norm": 0.6006861925125122,
      "learning_rate": 7.360862612220341e-06,
      "loss": 0.0804,
      "step": 16668
    },
    {
      "epoch": 0.2639295723356081,
      "grad_norm": 0.5310037136077881,
      "learning_rate": 7.36070427664392e-06,
      "loss": 0.1348,
      "step": 16669
    },
    {
      "epoch": 0.26394540589325016,
      "grad_norm": 0.48570090532302856,
      "learning_rate": 7.3605459410675e-06,
      "loss": 0.2456,
      "step": 16670
    },
    {
      "epoch": 0.2639612394508922,
      "grad_norm": 0.000327239278703928,
      "learning_rate": 7.360387605491078e-06,
      "loss": 0.0,
      "step": 16671
    },
    {
      "epoch": 0.2639770730085343,
      "grad_norm": 0.9523522257804871,
      "learning_rate": 7.360229269914658e-06,
      "loss": 0.2113,
      "step": 16672
    },
    {
      "epoch": 0.26399290656617636,
      "grad_norm": 0.06379619985818863,
      "learning_rate": 7.360070934338237e-06,
      "loss": 0.0029,
      "step": 16673
    },
    {
      "epoch": 0.2640087401238184,
      "grad_norm": 0.48489394783973694,
      "learning_rate": 7.359912598761816e-06,
      "loss": 0.3176,
      "step": 16674
    },
    {
      "epoch": 0.2640245736814605,
      "grad_norm": 0.582385241985321,
      "learning_rate": 7.359754263185396e-06,
      "loss": 0.1635,
      "step": 16675
    },
    {
      "epoch": 0.26404040723910255,
      "grad_norm": 0.5308393239974976,
      "learning_rate": 7.359595927608974e-06,
      "loss": 0.2457,
      "step": 16676
    },
    {
      "epoch": 0.2640562407967446,
      "grad_norm": 0.00017928919987753034,
      "learning_rate": 7.359437592032554e-06,
      "loss": 0.0,
      "step": 16677
    },
    {
      "epoch": 0.2640720743543867,
      "grad_norm": 0.32614171504974365,
      "learning_rate": 7.359279256456133e-06,
      "loss": 0.0864,
      "step": 16678
    },
    {
      "epoch": 0.26408790791202874,
      "grad_norm": 0.42071980237960815,
      "learning_rate": 7.359120920879713e-06,
      "loss": 0.0518,
      "step": 16679
    },
    {
      "epoch": 0.2641037414696708,
      "grad_norm": 0.42814964056015015,
      "learning_rate": 7.358962585303292e-06,
      "loss": 0.0596,
      "step": 16680
    },
    {
      "epoch": 0.26411957502731287,
      "grad_norm": 0.0004449584521353245,
      "learning_rate": 7.358804249726872e-06,
      "loss": 0.0,
      "step": 16681
    },
    {
      "epoch": 0.26413540858495493,
      "grad_norm": 0.6639410257339478,
      "learning_rate": 7.3586459141504505e-06,
      "loss": 0.5108,
      "step": 16682
    },
    {
      "epoch": 0.264151242142597,
      "grad_norm": 0.36592087149620056,
      "learning_rate": 7.35848757857403e-06,
      "loss": 0.1245,
      "step": 16683
    },
    {
      "epoch": 0.26416707570023906,
      "grad_norm": 0.08717551082372665,
      "learning_rate": 7.3583292429976095e-06,
      "loss": 0.0043,
      "step": 16684
    },
    {
      "epoch": 0.2641829092578811,
      "grad_norm": 0.3046669661998749,
      "learning_rate": 7.358170907421189e-06,
      "loss": 0.0842,
      "step": 16685
    },
    {
      "epoch": 0.26419874281552325,
      "grad_norm": 0.4459860324859619,
      "learning_rate": 7.3580125718447685e-06,
      "loss": 0.0931,
      "step": 16686
    },
    {
      "epoch": 0.2642145763731653,
      "grad_norm": 0.042522817850112915,
      "learning_rate": 7.357854236268348e-06,
      "loss": 0.0022,
      "step": 16687
    },
    {
      "epoch": 0.2642304099308074,
      "grad_norm": 0.01455460675060749,
      "learning_rate": 7.357695900691927e-06,
      "loss": 0.0006,
      "step": 16688
    },
    {
      "epoch": 0.26424624348844944,
      "grad_norm": 0.0007556008058600128,
      "learning_rate": 7.3575375651155066e-06,
      "loss": 0.0,
      "step": 16689
    },
    {
      "epoch": 0.2642620770460915,
      "grad_norm": 0.05276123806834221,
      "learning_rate": 7.357379229539086e-06,
      "loss": 0.0028,
      "step": 16690
    },
    {
      "epoch": 0.26427791060373357,
      "grad_norm": 0.07898953557014465,
      "learning_rate": 7.3572208939626656e-06,
      "loss": 0.0045,
      "step": 16691
    },
    {
      "epoch": 0.26429374416137563,
      "grad_norm": 0.7240391969680786,
      "learning_rate": 7.357062558386245e-06,
      "loss": 0.5593,
      "step": 16692
    },
    {
      "epoch": 0.2643095777190177,
      "grad_norm": 0.7432206869125366,
      "learning_rate": 7.356904222809825e-06,
      "loss": 0.3486,
      "step": 16693
    },
    {
      "epoch": 0.26432541127665976,
      "grad_norm": 1.07454252243042,
      "learning_rate": 7.356745887233403e-06,
      "loss": 0.0767,
      "step": 16694
    },
    {
      "epoch": 0.2643412448343018,
      "grad_norm": 0.39220139384269714,
      "learning_rate": 7.356587551656983e-06,
      "loss": 0.1329,
      "step": 16695
    },
    {
      "epoch": 0.2643570783919439,
      "grad_norm": 0.06797715276479721,
      "learning_rate": 7.356429216080562e-06,
      "loss": 0.0032,
      "step": 16696
    },
    {
      "epoch": 0.26437291194958595,
      "grad_norm": 0.6680655479431152,
      "learning_rate": 7.356270880504142e-06,
      "loss": 0.4481,
      "step": 16697
    },
    {
      "epoch": 0.264388745507228,
      "grad_norm": 0.006989321205765009,
      "learning_rate": 7.356112544927721e-06,
      "loss": 0.0002,
      "step": 16698
    },
    {
      "epoch": 0.2644045790648701,
      "grad_norm": 0.3333790898323059,
      "learning_rate": 7.355954209351299e-06,
      "loss": 0.15,
      "step": 16699
    },
    {
      "epoch": 0.26442041262251215,
      "grad_norm": 0.3426695764064789,
      "learning_rate": 7.355795873774879e-06,
      "loss": 0.0515,
      "step": 16700
    },
    {
      "epoch": 0.2644362461801542,
      "grad_norm": 0.0656057670712471,
      "learning_rate": 7.355637538198458e-06,
      "loss": 0.0038,
      "step": 16701
    },
    {
      "epoch": 0.2644520797377963,
      "grad_norm": 0.18406032025814056,
      "learning_rate": 7.355479202622038e-06,
      "loss": 0.0902,
      "step": 16702
    },
    {
      "epoch": 0.26446791329543834,
      "grad_norm": 0.4243995249271393,
      "learning_rate": 7.355320867045617e-06,
      "loss": 0.0974,
      "step": 16703
    },
    {
      "epoch": 0.2644837468530804,
      "grad_norm": 0.2952115535736084,
      "learning_rate": 7.355162531469196e-06,
      "loss": 0.0498,
      "step": 16704
    },
    {
      "epoch": 0.26449958041072247,
      "grad_norm": 0.6351209282875061,
      "learning_rate": 7.355004195892775e-06,
      "loss": 0.3906,
      "step": 16705
    },
    {
      "epoch": 0.26451541396836453,
      "grad_norm": 0.15697188675403595,
      "learning_rate": 7.354845860316355e-06,
      "loss": 0.0486,
      "step": 16706
    },
    {
      "epoch": 0.2645312475260066,
      "grad_norm": 1.010721206665039,
      "learning_rate": 7.354687524739934e-06,
      "loss": 0.757,
      "step": 16707
    },
    {
      "epoch": 0.26454708108364866,
      "grad_norm": 0.2671433985233307,
      "learning_rate": 7.354529189163514e-06,
      "loss": 0.1105,
      "step": 16708
    },
    {
      "epoch": 0.2645629146412907,
      "grad_norm": 0.03116077557206154,
      "learning_rate": 7.354370853587092e-06,
      "loss": 0.0012,
      "step": 16709
    },
    {
      "epoch": 0.26457874819893284,
      "grad_norm": 0.15427249670028687,
      "learning_rate": 7.354212518010672e-06,
      "loss": 0.0294,
      "step": 16710
    },
    {
      "epoch": 0.2645945817565749,
      "grad_norm": 0.36571377515792847,
      "learning_rate": 7.354054182434251e-06,
      "loss": 0.1365,
      "step": 16711
    },
    {
      "epoch": 0.264610415314217,
      "grad_norm": 0.41371503472328186,
      "learning_rate": 7.353895846857831e-06,
      "loss": 0.2116,
      "step": 16712
    },
    {
      "epoch": 0.26462624887185904,
      "grad_norm": 0.5524840950965881,
      "learning_rate": 7.35373751128141e-06,
      "loss": 0.1833,
      "step": 16713
    },
    {
      "epoch": 0.2646420824295011,
      "grad_norm": 0.6129438281059265,
      "learning_rate": 7.35357917570499e-06,
      "loss": 0.2372,
      "step": 16714
    },
    {
      "epoch": 0.26465791598714317,
      "grad_norm": 0.7948050498962402,
      "learning_rate": 7.3534208401285686e-06,
      "loss": 0.5176,
      "step": 16715
    },
    {
      "epoch": 0.26467374954478523,
      "grad_norm": 0.34349772334098816,
      "learning_rate": 7.3532625045521485e-06,
      "loss": 0.0997,
      "step": 16716
    },
    {
      "epoch": 0.2646895831024273,
      "grad_norm": 0.00014455105701927096,
      "learning_rate": 7.3531041689757276e-06,
      "loss": 0.0,
      "step": 16717
    },
    {
      "epoch": 0.26470541666006936,
      "grad_norm": 0.7017439603805542,
      "learning_rate": 7.3529458333993075e-06,
      "loss": 0.0839,
      "step": 16718
    },
    {
      "epoch": 0.2647212502177114,
      "grad_norm": 0.2392507642507553,
      "learning_rate": 7.352787497822887e-06,
      "loss": 0.0902,
      "step": 16719
    },
    {
      "epoch": 0.2647370837753535,
      "grad_norm": 0.0001647346798563376,
      "learning_rate": 7.3526291622464665e-06,
      "loss": 0.0,
      "step": 16720
    },
    {
      "epoch": 0.26475291733299555,
      "grad_norm": 0.023536352440714836,
      "learning_rate": 7.352470826670045e-06,
      "loss": 0.0011,
      "step": 16721
    },
    {
      "epoch": 0.2647687508906376,
      "grad_norm": 1.0554189682006836,
      "learning_rate": 7.352312491093624e-06,
      "loss": 0.0367,
      "step": 16722
    },
    {
      "epoch": 0.2647845844482797,
      "grad_norm": 0.1763240098953247,
      "learning_rate": 7.352154155517204e-06,
      "loss": 0.0532,
      "step": 16723
    },
    {
      "epoch": 0.26480041800592174,
      "grad_norm": 0.20622187852859497,
      "learning_rate": 7.351995819940783e-06,
      "loss": 0.0745,
      "step": 16724
    },
    {
      "epoch": 0.2648162515635638,
      "grad_norm": 0.35757535696029663,
      "learning_rate": 7.351837484364363e-06,
      "loss": 0.0671,
      "step": 16725
    },
    {
      "epoch": 0.2648320851212059,
      "grad_norm": 0.34663912653923035,
      "learning_rate": 7.351679148787941e-06,
      "loss": 0.0832,
      "step": 16726
    },
    {
      "epoch": 0.26484791867884794,
      "grad_norm": 0.27783477306365967,
      "learning_rate": 7.351520813211521e-06,
      "loss": 0.0459,
      "step": 16727
    },
    {
      "epoch": 0.26486375223649,
      "grad_norm": 0.0002297960309078917,
      "learning_rate": 7.3513624776351e-06,
      "loss": 0.0,
      "step": 16728
    },
    {
      "epoch": 0.26487958579413207,
      "grad_norm": 0.543127179145813,
      "learning_rate": 7.35120414205868e-06,
      "loss": 0.218,
      "step": 16729
    },
    {
      "epoch": 0.26489541935177413,
      "grad_norm": 0.2486683428287506,
      "learning_rate": 7.351045806482259e-06,
      "loss": 0.1056,
      "step": 16730
    },
    {
      "epoch": 0.2649112529094162,
      "grad_norm": 0.07214560359716415,
      "learning_rate": 7.350887470905839e-06,
      "loss": 0.0022,
      "step": 16731
    },
    {
      "epoch": 0.26492708646705826,
      "grad_norm": 0.19219093024730682,
      "learning_rate": 7.350729135329417e-06,
      "loss": 0.0025,
      "step": 16732
    },
    {
      "epoch": 0.2649429200247003,
      "grad_norm": 0.4415474832057953,
      "learning_rate": 7.350570799752997e-06,
      "loss": 0.463,
      "step": 16733
    },
    {
      "epoch": 0.26495875358234244,
      "grad_norm": 0.5238540172576904,
      "learning_rate": 7.350412464176576e-06,
      "loss": 0.1628,
      "step": 16734
    },
    {
      "epoch": 0.2649745871399845,
      "grad_norm": 0.01677882671356201,
      "learning_rate": 7.350254128600156e-06,
      "loss": 0.0007,
      "step": 16735
    },
    {
      "epoch": 0.26499042069762657,
      "grad_norm": 0.2350655049085617,
      "learning_rate": 7.350095793023735e-06,
      "loss": 0.0924,
      "step": 16736
    },
    {
      "epoch": 0.26500625425526864,
      "grad_norm": 0.7189798355102539,
      "learning_rate": 7.349937457447315e-06,
      "loss": 0.1336,
      "step": 16737
    },
    {
      "epoch": 0.2650220878129107,
      "grad_norm": 0.6132673621177673,
      "learning_rate": 7.349779121870893e-06,
      "loss": 0.4536,
      "step": 16738
    },
    {
      "epoch": 0.26503792137055276,
      "grad_norm": 0.6129259467124939,
      "learning_rate": 7.349620786294473e-06,
      "loss": 0.1873,
      "step": 16739
    },
    {
      "epoch": 0.26505375492819483,
      "grad_norm": 0.01931847259402275,
      "learning_rate": 7.349462450718052e-06,
      "loss": 0.001,
      "step": 16740
    },
    {
      "epoch": 0.2650695884858369,
      "grad_norm": 0.2827572226524353,
      "learning_rate": 7.349304115141632e-06,
      "loss": 0.1134,
      "step": 16741
    },
    {
      "epoch": 0.26508542204347896,
      "grad_norm": 0.00037444091867655516,
      "learning_rate": 7.349145779565211e-06,
      "loss": 0.0,
      "step": 16742
    },
    {
      "epoch": 0.265101255601121,
      "grad_norm": 0.46753859519958496,
      "learning_rate": 7.348987443988791e-06,
      "loss": 0.1066,
      "step": 16743
    },
    {
      "epoch": 0.2651170891587631,
      "grad_norm": 1.8973581790924072,
      "learning_rate": 7.3488291084123695e-06,
      "loss": 0.3473,
      "step": 16744
    },
    {
      "epoch": 0.26513292271640515,
      "grad_norm": 0.017145344987511635,
      "learning_rate": 7.348670772835949e-06,
      "loss": 0.0008,
      "step": 16745
    },
    {
      "epoch": 0.2651487562740472,
      "grad_norm": 0.271272748708725,
      "learning_rate": 7.3485124372595285e-06,
      "loss": 0.0602,
      "step": 16746
    },
    {
      "epoch": 0.2651645898316893,
      "grad_norm": 0.6241709589958191,
      "learning_rate": 7.348354101683108e-06,
      "loss": 0.8427,
      "step": 16747
    },
    {
      "epoch": 0.26518042338933134,
      "grad_norm": 0.4850304126739502,
      "learning_rate": 7.3481957661066875e-06,
      "loss": 0.1863,
      "step": 16748
    },
    {
      "epoch": 0.2651962569469734,
      "grad_norm": 0.0018953533144667745,
      "learning_rate": 7.348037430530266e-06,
      "loss": 0.0001,
      "step": 16749
    },
    {
      "epoch": 0.26521209050461547,
      "grad_norm": 0.1323784589767456,
      "learning_rate": 7.347879094953846e-06,
      "loss": 0.0052,
      "step": 16750
    },
    {
      "epoch": 0.26522792406225754,
      "grad_norm": 0.7095934748649597,
      "learning_rate": 7.347720759377425e-06,
      "loss": 0.1556,
      "step": 16751
    },
    {
      "epoch": 0.2652437576198996,
      "grad_norm": 0.010111621581017971,
      "learning_rate": 7.347562423801005e-06,
      "loss": 0.0004,
      "step": 16752
    },
    {
      "epoch": 0.26525959117754166,
      "grad_norm": 0.36319974064826965,
      "learning_rate": 7.347404088224584e-06,
      "loss": 0.1237,
      "step": 16753
    },
    {
      "epoch": 0.26527542473518373,
      "grad_norm": 0.64483642578125,
      "learning_rate": 7.347245752648164e-06,
      "loss": 0.5656,
      "step": 16754
    },
    {
      "epoch": 0.2652912582928258,
      "grad_norm": 0.7936238050460815,
      "learning_rate": 7.347087417071742e-06,
      "loss": 0.7522,
      "step": 16755
    },
    {
      "epoch": 0.26530709185046786,
      "grad_norm": 0.4924022853374481,
      "learning_rate": 7.346929081495322e-06,
      "loss": 0.1527,
      "step": 16756
    },
    {
      "epoch": 0.2653229254081099,
      "grad_norm": 0.548572301864624,
      "learning_rate": 7.346770745918901e-06,
      "loss": 0.1797,
      "step": 16757
    },
    {
      "epoch": 0.26533875896575204,
      "grad_norm": 0.4410800635814667,
      "learning_rate": 7.346612410342481e-06,
      "loss": 0.0496,
      "step": 16758
    },
    {
      "epoch": 0.2653545925233941,
      "grad_norm": 0.27133244276046753,
      "learning_rate": 7.34645407476606e-06,
      "loss": 0.0741,
      "step": 16759
    },
    {
      "epoch": 0.26537042608103617,
      "grad_norm": 0.2842693328857422,
      "learning_rate": 7.34629573918964e-06,
      "loss": 0.0895,
      "step": 16760
    },
    {
      "epoch": 0.26538625963867823,
      "grad_norm": 0.5833415985107422,
      "learning_rate": 7.346137403613218e-06,
      "loss": 0.0423,
      "step": 16761
    },
    {
      "epoch": 0.2654020931963203,
      "grad_norm": 0.5931210517883301,
      "learning_rate": 7.345979068036798e-06,
      "loss": 0.1644,
      "step": 16762
    },
    {
      "epoch": 0.26541792675396236,
      "grad_norm": 0.5690929293632507,
      "learning_rate": 7.345820732460377e-06,
      "loss": 0.1945,
      "step": 16763
    },
    {
      "epoch": 0.2654337603116044,
      "grad_norm": 0.6591864824295044,
      "learning_rate": 7.345662396883957e-06,
      "loss": 0.6528,
      "step": 16764
    },
    {
      "epoch": 0.2654495938692465,
      "grad_norm": 0.6485353708267212,
      "learning_rate": 7.345504061307536e-06,
      "loss": 0.4313,
      "step": 16765
    },
    {
      "epoch": 0.26546542742688856,
      "grad_norm": 0.38093072175979614,
      "learning_rate": 7.345345725731115e-06,
      "loss": 0.2227,
      "step": 16766
    },
    {
      "epoch": 0.2654812609845306,
      "grad_norm": 0.8414454460144043,
      "learning_rate": 7.345187390154694e-06,
      "loss": 0.1112,
      "step": 16767
    },
    {
      "epoch": 0.2654970945421727,
      "grad_norm": 0.2945520579814911,
      "learning_rate": 7.345029054578274e-06,
      "loss": 0.0415,
      "step": 16768
    },
    {
      "epoch": 0.26551292809981475,
      "grad_norm": 0.3385326862335205,
      "learning_rate": 7.344870719001853e-06,
      "loss": 0.0408,
      "step": 16769
    },
    {
      "epoch": 0.2655287616574568,
      "grad_norm": 0.2551961839199066,
      "learning_rate": 7.3447123834254315e-06,
      "loss": 0.061,
      "step": 16770
    },
    {
      "epoch": 0.2655445952150989,
      "grad_norm": 0.39006662368774414,
      "learning_rate": 7.344554047849011e-06,
      "loss": 0.0846,
      "step": 16771
    },
    {
      "epoch": 0.26556042877274094,
      "grad_norm": 0.45977258682250977,
      "learning_rate": 7.3443957122725905e-06,
      "loss": 0.5023,
      "step": 16772
    },
    {
      "epoch": 0.265576262330383,
      "grad_norm": 0.0007162594702094793,
      "learning_rate": 7.3442373766961704e-06,
      "loss": 0.0,
      "step": 16773
    },
    {
      "epoch": 0.26559209588802507,
      "grad_norm": 0.6169124245643616,
      "learning_rate": 7.3440790411197495e-06,
      "loss": 0.2499,
      "step": 16774
    },
    {
      "epoch": 0.26560792944566713,
      "grad_norm": 0.9399453997612,
      "learning_rate": 7.3439207055433294e-06,
      "loss": 0.4703,
      "step": 16775
    },
    {
      "epoch": 0.2656237630033092,
      "grad_norm": 0.5256521105766296,
      "learning_rate": 7.343762369966908e-06,
      "loss": 0.2477,
      "step": 16776
    },
    {
      "epoch": 0.26563959656095126,
      "grad_norm": 0.7363907098770142,
      "learning_rate": 7.343604034390488e-06,
      "loss": 0.2104,
      "step": 16777
    },
    {
      "epoch": 0.2656554301185933,
      "grad_norm": 0.34122565388679504,
      "learning_rate": 7.343445698814067e-06,
      "loss": 0.1067,
      "step": 16778
    },
    {
      "epoch": 0.2656712636762354,
      "grad_norm": 0.4909270405769348,
      "learning_rate": 7.343287363237647e-06,
      "loss": 0.1293,
      "step": 16779
    },
    {
      "epoch": 0.26568709723387746,
      "grad_norm": 0.27603045105934143,
      "learning_rate": 7.343129027661226e-06,
      "loss": 0.0518,
      "step": 16780
    },
    {
      "epoch": 0.2657029307915195,
      "grad_norm": 0.8363428115844727,
      "learning_rate": 7.342970692084806e-06,
      "loss": 0.2573,
      "step": 16781
    },
    {
      "epoch": 0.26571876434916164,
      "grad_norm": 0.3924048840999603,
      "learning_rate": 7.342812356508384e-06,
      "loss": 0.1627,
      "step": 16782
    },
    {
      "epoch": 0.2657345979068037,
      "grad_norm": 0.27061110734939575,
      "learning_rate": 7.342654020931964e-06,
      "loss": 0.0624,
      "step": 16783
    },
    {
      "epoch": 0.26575043146444577,
      "grad_norm": 0.013557572849094868,
      "learning_rate": 7.342495685355543e-06,
      "loss": 0.0006,
      "step": 16784
    },
    {
      "epoch": 0.26576626502208783,
      "grad_norm": 0.6569817662239075,
      "learning_rate": 7.342337349779123e-06,
      "loss": 0.3851,
      "step": 16785
    },
    {
      "epoch": 0.2657820985797299,
      "grad_norm": 0.019320623949170113,
      "learning_rate": 7.342179014202702e-06,
      "loss": 0.001,
      "step": 16786
    },
    {
      "epoch": 0.26579793213737196,
      "grad_norm": 0.06990204006433487,
      "learning_rate": 7.342020678626282e-06,
      "loss": 0.0026,
      "step": 16787
    },
    {
      "epoch": 0.265813765695014,
      "grad_norm": 0.017402159050107002,
      "learning_rate": 7.34186234304986e-06,
      "loss": 0.0009,
      "step": 16788
    },
    {
      "epoch": 0.2658295992526561,
      "grad_norm": 0.00011638414434855804,
      "learning_rate": 7.34170400747344e-06,
      "loss": 0.0,
      "step": 16789
    },
    {
      "epoch": 0.26584543281029815,
      "grad_norm": 0.03941788151860237,
      "learning_rate": 7.341545671897019e-06,
      "loss": 0.0015,
      "step": 16790
    },
    {
      "epoch": 0.2658612663679402,
      "grad_norm": 0.3716316223144531,
      "learning_rate": 7.341387336320599e-06,
      "loss": 0.0463,
      "step": 16791
    },
    {
      "epoch": 0.2658770999255823,
      "grad_norm": 0.4385247826576233,
      "learning_rate": 7.341229000744178e-06,
      "loss": 0.2192,
      "step": 16792
    },
    {
      "epoch": 0.26589293348322435,
      "grad_norm": 0.05084729939699173,
      "learning_rate": 7.341070665167758e-06,
      "loss": 0.0033,
      "step": 16793
    },
    {
      "epoch": 0.2659087670408664,
      "grad_norm": 0.9702237248420715,
      "learning_rate": 7.340912329591336e-06,
      "loss": 0.1363,
      "step": 16794
    },
    {
      "epoch": 0.2659246005985085,
      "grad_norm": 0.6130988001823425,
      "learning_rate": 7.340753994014915e-06,
      "loss": 0.2627,
      "step": 16795
    },
    {
      "epoch": 0.26594043415615054,
      "grad_norm": 0.02022251859307289,
      "learning_rate": 7.340595658438495e-06,
      "loss": 0.0009,
      "step": 16796
    },
    {
      "epoch": 0.2659562677137926,
      "grad_norm": 0.4569809138774872,
      "learning_rate": 7.340437322862074e-06,
      "loss": 0.3328,
      "step": 16797
    },
    {
      "epoch": 0.26597210127143467,
      "grad_norm": 0.4723181128501892,
      "learning_rate": 7.340278987285654e-06,
      "loss": 0.2211,
      "step": 16798
    },
    {
      "epoch": 0.26598793482907673,
      "grad_norm": 0.010801397264003754,
      "learning_rate": 7.3401206517092324e-06,
      "loss": 0.0006,
      "step": 16799
    },
    {
      "epoch": 0.2660037683867188,
      "grad_norm": 0.2599313259124756,
      "learning_rate": 7.339962316132812e-06,
      "loss": 0.0952,
      "step": 16800
    },
    {
      "epoch": 0.26601960194436086,
      "grad_norm": 0.3101542294025421,
      "learning_rate": 7.3398039805563914e-06,
      "loss": 0.0437,
      "step": 16801
    },
    {
      "epoch": 0.2660354355020029,
      "grad_norm": 0.24797378480434418,
      "learning_rate": 7.339645644979971e-06,
      "loss": 0.0725,
      "step": 16802
    },
    {
      "epoch": 0.266051269059645,
      "grad_norm": 0.15360620617866516,
      "learning_rate": 7.3394873094035504e-06,
      "loss": 0.0068,
      "step": 16803
    },
    {
      "epoch": 0.26606710261728705,
      "grad_norm": 0.452492356300354,
      "learning_rate": 7.33932897382713e-06,
      "loss": 0.0796,
      "step": 16804
    },
    {
      "epoch": 0.2660829361749291,
      "grad_norm": 0.5454999208450317,
      "learning_rate": 7.339170638250709e-06,
      "loss": 0.3357,
      "step": 16805
    },
    {
      "epoch": 0.26609876973257124,
      "grad_norm": 0.525667667388916,
      "learning_rate": 7.3390123026742885e-06,
      "loss": 0.259,
      "step": 16806
    },
    {
      "epoch": 0.2661146032902133,
      "grad_norm": 0.24854756891727448,
      "learning_rate": 7.338853967097868e-06,
      "loss": 0.0652,
      "step": 16807
    },
    {
      "epoch": 0.26613043684785537,
      "grad_norm": 0.31859028339385986,
      "learning_rate": 7.3386956315214475e-06,
      "loss": 0.1005,
      "step": 16808
    },
    {
      "epoch": 0.26614627040549743,
      "grad_norm": 0.014218582771718502,
      "learning_rate": 7.338537295945027e-06,
      "loss": 0.0007,
      "step": 16809
    },
    {
      "epoch": 0.2661621039631395,
      "grad_norm": 1.009503722190857,
      "learning_rate": 7.3383789603686065e-06,
      "loss": 0.8301,
      "step": 16810
    },
    {
      "epoch": 0.26617793752078156,
      "grad_norm": 0.16279663145542145,
      "learning_rate": 7.338220624792185e-06,
      "loss": 0.0843,
      "step": 16811
    },
    {
      "epoch": 0.2661937710784236,
      "grad_norm": 0.20336954295635223,
      "learning_rate": 7.338062289215765e-06,
      "loss": 0.0321,
      "step": 16812
    },
    {
      "epoch": 0.2662096046360657,
      "grad_norm": 0.00013576284982264042,
      "learning_rate": 7.337903953639344e-06,
      "loss": 0.0,
      "step": 16813
    },
    {
      "epoch": 0.26622543819370775,
      "grad_norm": 0.0003807377943303436,
      "learning_rate": 7.337745618062924e-06,
      "loss": 0.0,
      "step": 16814
    },
    {
      "epoch": 0.2662412717513498,
      "grad_norm": 0.022255007177591324,
      "learning_rate": 7.337587282486503e-06,
      "loss": 0.0011,
      "step": 16815
    },
    {
      "epoch": 0.2662571053089919,
      "grad_norm": 0.16794465482234955,
      "learning_rate": 7.337428946910083e-06,
      "loss": 0.0205,
      "step": 16816
    },
    {
      "epoch": 0.26627293886663395,
      "grad_norm": 0.4425847828388214,
      "learning_rate": 7.337270611333661e-06,
      "loss": 0.0764,
      "step": 16817
    },
    {
      "epoch": 0.266288772424276,
      "grad_norm": 0.33744359016418457,
      "learning_rate": 7.33711227575724e-06,
      "loss": 0.0993,
      "step": 16818
    },
    {
      "epoch": 0.2663046059819181,
      "grad_norm": 0.000279411266092211,
      "learning_rate": 7.33695394018082e-06,
      "loss": 0.0,
      "step": 16819
    },
    {
      "epoch": 0.26632043953956014,
      "grad_norm": 0.5155896544456482,
      "learning_rate": 7.336795604604399e-06,
      "loss": 0.2252,
      "step": 16820
    },
    {
      "epoch": 0.2663362730972022,
      "grad_norm": 0.32285967469215393,
      "learning_rate": 7.336637269027979e-06,
      "loss": 0.0986,
      "step": 16821
    },
    {
      "epoch": 0.26635210665484427,
      "grad_norm": 0.00010986876441165805,
      "learning_rate": 7.336478933451557e-06,
      "loss": 0.0,
      "step": 16822
    },
    {
      "epoch": 0.26636794021248633,
      "grad_norm": 0.7582512497901917,
      "learning_rate": 7.336320597875137e-06,
      "loss": 0.0919,
      "step": 16823
    },
    {
      "epoch": 0.2663837737701284,
      "grad_norm": 0.5363048911094666,
      "learning_rate": 7.336162262298716e-06,
      "loss": 0.3419,
      "step": 16824
    },
    {
      "epoch": 0.26639960732777046,
      "grad_norm": 0.2891903519630432,
      "learning_rate": 7.336003926722296e-06,
      "loss": 0.1174,
      "step": 16825
    },
    {
      "epoch": 0.2664154408854125,
      "grad_norm": 0.3981683850288391,
      "learning_rate": 7.335845591145875e-06,
      "loss": 0.0724,
      "step": 16826
    },
    {
      "epoch": 0.2664312744430546,
      "grad_norm": 0.515572726726532,
      "learning_rate": 7.335687255569455e-06,
      "loss": 0.3996,
      "step": 16827
    },
    {
      "epoch": 0.26644710800069665,
      "grad_norm": 0.26490843296051025,
      "learning_rate": 7.335528919993033e-06,
      "loss": 0.0244,
      "step": 16828
    },
    {
      "epoch": 0.2664629415583387,
      "grad_norm": 0.47166720032691956,
      "learning_rate": 7.335370584416613e-06,
      "loss": 0.228,
      "step": 16829
    },
    {
      "epoch": 0.26647877511598084,
      "grad_norm": 0.01210244931280613,
      "learning_rate": 7.335212248840192e-06,
      "loss": 0.0006,
      "step": 16830
    },
    {
      "epoch": 0.2664946086736229,
      "grad_norm": 0.2740055024623871,
      "learning_rate": 7.335053913263772e-06,
      "loss": 0.1001,
      "step": 16831
    },
    {
      "epoch": 0.26651044223126497,
      "grad_norm": 0.4622339606285095,
      "learning_rate": 7.334895577687351e-06,
      "loss": 0.0911,
      "step": 16832
    },
    {
      "epoch": 0.26652627578890703,
      "grad_norm": 0.343610942363739,
      "learning_rate": 7.3347372421109304e-06,
      "loss": 0.1061,
      "step": 16833
    },
    {
      "epoch": 0.2665421093465491,
      "grad_norm": 0.0023422937374562025,
      "learning_rate": 7.3345789065345095e-06,
      "loss": 0.0,
      "step": 16834
    },
    {
      "epoch": 0.26655794290419116,
      "grad_norm": 0.00029912477475591004,
      "learning_rate": 7.3344205709580895e-06,
      "loss": 0.0,
      "step": 16835
    },
    {
      "epoch": 0.2665737764618332,
      "grad_norm": 0.25679296255111694,
      "learning_rate": 7.3342622353816685e-06,
      "loss": 0.0174,
      "step": 16836
    },
    {
      "epoch": 0.2665896100194753,
      "grad_norm": 0.3861166834831238,
      "learning_rate": 7.3341038998052485e-06,
      "loss": 0.0668,
      "step": 16837
    },
    {
      "epoch": 0.26660544357711735,
      "grad_norm": 0.27059128880500793,
      "learning_rate": 7.333945564228827e-06,
      "loss": 0.0841,
      "step": 16838
    },
    {
      "epoch": 0.2666212771347594,
      "grad_norm": 0.012199753895401955,
      "learning_rate": 7.333787228652407e-06,
      "loss": 0.0006,
      "step": 16839
    },
    {
      "epoch": 0.2666371106924015,
      "grad_norm": 0.01219456922262907,
      "learning_rate": 7.333628893075986e-06,
      "loss": 0.0006,
      "step": 16840
    },
    {
      "epoch": 0.26665294425004354,
      "grad_norm": 0.48916810750961304,
      "learning_rate": 7.333470557499566e-06,
      "loss": 0.5307,
      "step": 16841
    },
    {
      "epoch": 0.2666687778076856,
      "grad_norm": 0.9785890579223633,
      "learning_rate": 7.333312221923145e-06,
      "loss": 0.2381,
      "step": 16842
    },
    {
      "epoch": 0.2666846113653277,
      "grad_norm": 0.4187804162502289,
      "learning_rate": 7.333153886346723e-06,
      "loss": 0.1124,
      "step": 16843
    },
    {
      "epoch": 0.26670044492296974,
      "grad_norm": 0.6880649924278259,
      "learning_rate": 7.332995550770303e-06,
      "loss": 0.285,
      "step": 16844
    },
    {
      "epoch": 0.2667162784806118,
      "grad_norm": 0.14636936783790588,
      "learning_rate": 7.332837215193882e-06,
      "loss": 0.0052,
      "step": 16845
    },
    {
      "epoch": 0.26673211203825387,
      "grad_norm": 0.20646457374095917,
      "learning_rate": 7.332678879617462e-06,
      "loss": 0.0518,
      "step": 16846
    },
    {
      "epoch": 0.26674794559589593,
      "grad_norm": 0.01526704989373684,
      "learning_rate": 7.332520544041041e-06,
      "loss": 0.0008,
      "step": 16847
    },
    {
      "epoch": 0.266763779153538,
      "grad_norm": 0.00018147716764360666,
      "learning_rate": 7.332362208464621e-06,
      "loss": 0.0,
      "step": 16848
    },
    {
      "epoch": 0.26677961271118006,
      "grad_norm": 0.23303836584091187,
      "learning_rate": 7.332203872888199e-06,
      "loss": 0.0461,
      "step": 16849
    },
    {
      "epoch": 0.2667954462688221,
      "grad_norm": 0.33663472533226013,
      "learning_rate": 7.332045537311779e-06,
      "loss": 0.0566,
      "step": 16850
    },
    {
      "epoch": 0.2668112798264642,
      "grad_norm": 0.20850953459739685,
      "learning_rate": 7.331887201735358e-06,
      "loss": 0.051,
      "step": 16851
    },
    {
      "epoch": 0.26682711338410625,
      "grad_norm": 0.39876285195350647,
      "learning_rate": 7.331728866158938e-06,
      "loss": 0.111,
      "step": 16852
    },
    {
      "epoch": 0.2668429469417483,
      "grad_norm": 0.0004230509221088141,
      "learning_rate": 7.331570530582517e-06,
      "loss": 0.0,
      "step": 16853
    },
    {
      "epoch": 0.26685878049939044,
      "grad_norm": 0.47583094239234924,
      "learning_rate": 7.331412195006097e-06,
      "loss": 0.1226,
      "step": 16854
    },
    {
      "epoch": 0.2668746140570325,
      "grad_norm": 0.015380779281258583,
      "learning_rate": 7.331253859429675e-06,
      "loss": 0.0008,
      "step": 16855
    },
    {
      "epoch": 0.26689044761467456,
      "grad_norm": 0.6679626703262329,
      "learning_rate": 7.331095523853255e-06,
      "loss": 0.1005,
      "step": 16856
    },
    {
      "epoch": 0.26690628117231663,
      "grad_norm": 0.2114870250225067,
      "learning_rate": 7.330937188276834e-06,
      "loss": 0.0054,
      "step": 16857
    },
    {
      "epoch": 0.2669221147299587,
      "grad_norm": 0.5485273003578186,
      "learning_rate": 7.330778852700414e-06,
      "loss": 0.2968,
      "step": 16858
    },
    {
      "epoch": 0.26693794828760076,
      "grad_norm": 0.3200555145740509,
      "learning_rate": 7.330620517123993e-06,
      "loss": 0.0353,
      "step": 16859
    },
    {
      "epoch": 0.2669537818452428,
      "grad_norm": 0.5601916909217834,
      "learning_rate": 7.330462181547573e-06,
      "loss": 0.2916,
      "step": 16860
    },
    {
      "epoch": 0.2669696154028849,
      "grad_norm": 1.648593783378601,
      "learning_rate": 7.3303038459711514e-06,
      "loss": 0.4341,
      "step": 16861
    },
    {
      "epoch": 0.26698544896052695,
      "grad_norm": 0.2072390466928482,
      "learning_rate": 7.330145510394731e-06,
      "loss": 0.0293,
      "step": 16862
    },
    {
      "epoch": 0.267001282518169,
      "grad_norm": 0.18967942893505096,
      "learning_rate": 7.3299871748183105e-06,
      "loss": 0.0254,
      "step": 16863
    },
    {
      "epoch": 0.2670171160758111,
      "grad_norm": 0.28180161118507385,
      "learning_rate": 7.32982883924189e-06,
      "loss": 0.0764,
      "step": 16864
    },
    {
      "epoch": 0.26703294963345314,
      "grad_norm": 0.02388332039117813,
      "learning_rate": 7.3296705036654695e-06,
      "loss": 0.0008,
      "step": 16865
    },
    {
      "epoch": 0.2670487831910952,
      "grad_norm": 0.4150485098361969,
      "learning_rate": 7.329512168089048e-06,
      "loss": 0.1299,
      "step": 16866
    },
    {
      "epoch": 0.26706461674873727,
      "grad_norm": 0.5375992655754089,
      "learning_rate": 7.329353832512628e-06,
      "loss": 0.6436,
      "step": 16867
    },
    {
      "epoch": 0.26708045030637934,
      "grad_norm": 0.6618110537528992,
      "learning_rate": 7.329195496936207e-06,
      "loss": 0.5523,
      "step": 16868
    },
    {
      "epoch": 0.2670962838640214,
      "grad_norm": 0.006699965335428715,
      "learning_rate": 7.329037161359787e-06,
      "loss": 0.0001,
      "step": 16869
    },
    {
      "epoch": 0.26711211742166346,
      "grad_norm": 0.2964089810848236,
      "learning_rate": 7.328878825783366e-06,
      "loss": 0.1243,
      "step": 16870
    },
    {
      "epoch": 0.26712795097930553,
      "grad_norm": 0.3849881589412689,
      "learning_rate": 7.328720490206946e-06,
      "loss": 0.1124,
      "step": 16871
    },
    {
      "epoch": 0.2671437845369476,
      "grad_norm": 1.2901041507720947,
      "learning_rate": 7.328562154630524e-06,
      "loss": 0.5756,
      "step": 16872
    },
    {
      "epoch": 0.26715961809458966,
      "grad_norm": 0.43253663182258606,
      "learning_rate": 7.328403819054104e-06,
      "loss": 0.1023,
      "step": 16873
    },
    {
      "epoch": 0.2671754516522317,
      "grad_norm": 0.007438504137098789,
      "learning_rate": 7.328245483477683e-06,
      "loss": 0.0003,
      "step": 16874
    },
    {
      "epoch": 0.2671912852098738,
      "grad_norm": 0.403156578540802,
      "learning_rate": 7.328087147901263e-06,
      "loss": 0.0643,
      "step": 16875
    },
    {
      "epoch": 0.26720711876751585,
      "grad_norm": 0.7454771399497986,
      "learning_rate": 7.327928812324842e-06,
      "loss": 0.2742,
      "step": 16876
    },
    {
      "epoch": 0.2672229523251579,
      "grad_norm": 0.3542419373989105,
      "learning_rate": 7.327770476748422e-06,
      "loss": 0.0934,
      "step": 16877
    },
    {
      "epoch": 0.26723878588280003,
      "grad_norm": 0.17045457661151886,
      "learning_rate": 7.327612141172e-06,
      "loss": 0.0191,
      "step": 16878
    },
    {
      "epoch": 0.2672546194404421,
      "grad_norm": 0.3357747197151184,
      "learning_rate": 7.32745380559558e-06,
      "loss": 0.0587,
      "step": 16879
    },
    {
      "epoch": 0.26727045299808416,
      "grad_norm": 0.42707890272140503,
      "learning_rate": 7.327295470019159e-06,
      "loss": 0.2194,
      "step": 16880
    },
    {
      "epoch": 0.2672862865557262,
      "grad_norm": 0.5795267820358276,
      "learning_rate": 7.327137134442739e-06,
      "loss": 0.5008,
      "step": 16881
    },
    {
      "epoch": 0.2673021201133683,
      "grad_norm": 0.011834344826638699,
      "learning_rate": 7.326978798866318e-06,
      "loss": 0.0006,
      "step": 16882
    },
    {
      "epoch": 0.26731795367101036,
      "grad_norm": 0.3594478666782379,
      "learning_rate": 7.326820463289898e-06,
      "loss": 0.1024,
      "step": 16883
    },
    {
      "epoch": 0.2673337872286524,
      "grad_norm": 0.2590616047382355,
      "learning_rate": 7.326662127713476e-06,
      "loss": 0.0139,
      "step": 16884
    },
    {
      "epoch": 0.2673496207862945,
      "grad_norm": 0.3417419493198395,
      "learning_rate": 7.326503792137056e-06,
      "loss": 0.2741,
      "step": 16885
    },
    {
      "epoch": 0.26736545434393655,
      "grad_norm": 0.21222634613513947,
      "learning_rate": 7.326345456560635e-06,
      "loss": 0.0482,
      "step": 16886
    },
    {
      "epoch": 0.2673812879015786,
      "grad_norm": 0.02328435890376568,
      "learning_rate": 7.326187120984215e-06,
      "loss": 0.0012,
      "step": 16887
    },
    {
      "epoch": 0.2673971214592207,
      "grad_norm": 0.25197499990463257,
      "learning_rate": 7.326028785407794e-06,
      "loss": 0.0751,
      "step": 16888
    },
    {
      "epoch": 0.26741295501686274,
      "grad_norm": 0.1699897199869156,
      "learning_rate": 7.325870449831374e-06,
      "loss": 0.0211,
      "step": 16889
    },
    {
      "epoch": 0.2674287885745048,
      "grad_norm": 0.0003844865714199841,
      "learning_rate": 7.325712114254952e-06,
      "loss": 0.0,
      "step": 16890
    },
    {
      "epoch": 0.26744462213214687,
      "grad_norm": 0.41471385955810547,
      "learning_rate": 7.3255537786785315e-06,
      "loss": 0.0452,
      "step": 16891
    },
    {
      "epoch": 0.26746045568978893,
      "grad_norm": 0.3095157742500305,
      "learning_rate": 7.325395443102111e-06,
      "loss": 0.1106,
      "step": 16892
    },
    {
      "epoch": 0.267476289247431,
      "grad_norm": 0.3161437213420868,
      "learning_rate": 7.3252371075256905e-06,
      "loss": 0.0784,
      "step": 16893
    },
    {
      "epoch": 0.26749212280507306,
      "grad_norm": 0.023775527253746986,
      "learning_rate": 7.32507877194927e-06,
      "loss": 0.0011,
      "step": 16894
    },
    {
      "epoch": 0.2675079563627151,
      "grad_norm": 0.1643223911523819,
      "learning_rate": 7.324920436372849e-06,
      "loss": 0.0434,
      "step": 16895
    },
    {
      "epoch": 0.2675237899203572,
      "grad_norm": 1.0481326580047607,
      "learning_rate": 7.3247621007964286e-06,
      "loss": 0.2959,
      "step": 16896
    },
    {
      "epoch": 0.26753962347799926,
      "grad_norm": 0.3562750220298767,
      "learning_rate": 7.324603765220008e-06,
      "loss": 0.0748,
      "step": 16897
    },
    {
      "epoch": 0.2675554570356413,
      "grad_norm": 0.2826273739337921,
      "learning_rate": 7.3244454296435876e-06,
      "loss": 0.0365,
      "step": 16898
    },
    {
      "epoch": 0.2675712905932834,
      "grad_norm": 0.5266470313072205,
      "learning_rate": 7.324287094067166e-06,
      "loss": 0.1346,
      "step": 16899
    },
    {
      "epoch": 0.26758712415092545,
      "grad_norm": 0.013785707764327526,
      "learning_rate": 7.324128758490746e-06,
      "loss": 0.0006,
      "step": 16900
    },
    {
      "epoch": 0.2676029577085675,
      "grad_norm": 0.9152820706367493,
      "learning_rate": 7.323970422914325e-06,
      "loss": 0.218,
      "step": 16901
    },
    {
      "epoch": 0.2676187912662096,
      "grad_norm": 0.004984995815902948,
      "learning_rate": 7.323812087337905e-06,
      "loss": 0.0001,
      "step": 16902
    },
    {
      "epoch": 0.2676346248238517,
      "grad_norm": 0.04181336611509323,
      "learning_rate": 7.323653751761484e-06,
      "loss": 0.0024,
      "step": 16903
    },
    {
      "epoch": 0.26765045838149376,
      "grad_norm": 0.48298725485801697,
      "learning_rate": 7.323495416185064e-06,
      "loss": 0.0549,
      "step": 16904
    },
    {
      "epoch": 0.2676662919391358,
      "grad_norm": 0.20256952941417694,
      "learning_rate": 7.323337080608642e-06,
      "loss": 0.1124,
      "step": 16905
    },
    {
      "epoch": 0.2676821254967779,
      "grad_norm": 0.034058041870594025,
      "learning_rate": 7.323178745032222e-06,
      "loss": 0.0021,
      "step": 16906
    },
    {
      "epoch": 0.26769795905441995,
      "grad_norm": 0.35875242948532104,
      "learning_rate": 7.323020409455801e-06,
      "loss": 0.2099,
      "step": 16907
    },
    {
      "epoch": 0.267713792612062,
      "grad_norm": 0.008663676679134369,
      "learning_rate": 7.322862073879381e-06,
      "loss": 0.0004,
      "step": 16908
    },
    {
      "epoch": 0.2677296261697041,
      "grad_norm": 0.17553439736366272,
      "learning_rate": 7.32270373830296e-06,
      "loss": 0.015,
      "step": 16909
    },
    {
      "epoch": 0.26774545972734615,
      "grad_norm": 0.2830315828323364,
      "learning_rate": 7.32254540272654e-06,
      "loss": 0.0639,
      "step": 16910
    },
    {
      "epoch": 0.2677612932849882,
      "grad_norm": 0.042756665498018265,
      "learning_rate": 7.322387067150118e-06,
      "loss": 0.0019,
      "step": 16911
    },
    {
      "epoch": 0.2677771268426303,
      "grad_norm": 0.5213096737861633,
      "learning_rate": 7.322228731573698e-06,
      "loss": 0.2752,
      "step": 16912
    },
    {
      "epoch": 0.26779296040027234,
      "grad_norm": 0.5643959641456604,
      "learning_rate": 7.322070395997277e-06,
      "loss": 0.2889,
      "step": 16913
    },
    {
      "epoch": 0.2678087939579144,
      "grad_norm": 0.3476335406303406,
      "learning_rate": 7.321912060420857e-06,
      "loss": 0.0112,
      "step": 16914
    },
    {
      "epoch": 0.26782462751555647,
      "grad_norm": 0.600759744644165,
      "learning_rate": 7.321753724844436e-06,
      "loss": 0.0814,
      "step": 16915
    },
    {
      "epoch": 0.26784046107319853,
      "grad_norm": 0.5446797013282776,
      "learning_rate": 7.321595389268014e-06,
      "loss": 0.2753,
      "step": 16916
    },
    {
      "epoch": 0.2678562946308406,
      "grad_norm": 0.9286640882492065,
      "learning_rate": 7.321437053691594e-06,
      "loss": 0.0178,
      "step": 16917
    },
    {
      "epoch": 0.26787212818848266,
      "grad_norm": 0.06262411922216415,
      "learning_rate": 7.321278718115173e-06,
      "loss": 0.0027,
      "step": 16918
    },
    {
      "epoch": 0.2678879617461247,
      "grad_norm": 1.5836596488952637,
      "learning_rate": 7.321120382538753e-06,
      "loss": 0.4472,
      "step": 16919
    },
    {
      "epoch": 0.2679037953037668,
      "grad_norm": 0.0334736667573452,
      "learning_rate": 7.320962046962332e-06,
      "loss": 0.0016,
      "step": 16920
    },
    {
      "epoch": 0.26791962886140885,
      "grad_norm": 0.0027080257423222065,
      "learning_rate": 7.320803711385912e-06,
      "loss": 0.0001,
      "step": 16921
    },
    {
      "epoch": 0.2679354624190509,
      "grad_norm": 0.8792058229446411,
      "learning_rate": 7.3206453758094905e-06,
      "loss": 0.0916,
      "step": 16922
    },
    {
      "epoch": 0.267951295976693,
      "grad_norm": 0.9607245922088623,
      "learning_rate": 7.3204870402330705e-06,
      "loss": 0.8792,
      "step": 16923
    },
    {
      "epoch": 0.26796712953433505,
      "grad_norm": 0.46440574526786804,
      "learning_rate": 7.3203287046566496e-06,
      "loss": 0.0567,
      "step": 16924
    },
    {
      "epoch": 0.2679829630919771,
      "grad_norm": 0.443149596452713,
      "learning_rate": 7.3201703690802295e-06,
      "loss": 0.3681,
      "step": 16925
    },
    {
      "epoch": 0.2679987966496192,
      "grad_norm": 0.23644383251667023,
      "learning_rate": 7.3200120335038086e-06,
      "loss": 0.0691,
      "step": 16926
    },
    {
      "epoch": 0.2680146302072613,
      "grad_norm": 0.2805328667163849,
      "learning_rate": 7.3198536979273885e-06,
      "loss": 0.0289,
      "step": 16927
    },
    {
      "epoch": 0.26803046376490336,
      "grad_norm": 0.5310098528862,
      "learning_rate": 7.319695362350967e-06,
      "loss": 0.5712,
      "step": 16928
    },
    {
      "epoch": 0.2680462973225454,
      "grad_norm": 0.3034341633319855,
      "learning_rate": 7.319537026774547e-06,
      "loss": 0.0995,
      "step": 16929
    },
    {
      "epoch": 0.2680621308801875,
      "grad_norm": 0.00022910741972737014,
      "learning_rate": 7.319378691198126e-06,
      "loss": 0.0,
      "step": 16930
    },
    {
      "epoch": 0.26807796443782955,
      "grad_norm": 0.5360522866249084,
      "learning_rate": 7.319220355621706e-06,
      "loss": 0.0961,
      "step": 16931
    },
    {
      "epoch": 0.2680937979954716,
      "grad_norm": 0.45411011576652527,
      "learning_rate": 7.319062020045285e-06,
      "loss": 0.2558,
      "step": 16932
    },
    {
      "epoch": 0.2681096315531137,
      "grad_norm": 0.45817604660987854,
      "learning_rate": 7.318903684468865e-06,
      "loss": 0.1363,
      "step": 16933
    },
    {
      "epoch": 0.26812546511075575,
      "grad_norm": 0.00011354887101333588,
      "learning_rate": 7.318745348892443e-06,
      "loss": 0.0,
      "step": 16934
    },
    {
      "epoch": 0.2681412986683978,
      "grad_norm": 0.2688443660736084,
      "learning_rate": 7.318587013316023e-06,
      "loss": 0.0736,
      "step": 16935
    },
    {
      "epoch": 0.2681571322260399,
      "grad_norm": 0.3865680694580078,
      "learning_rate": 7.318428677739602e-06,
      "loss": 0.121,
      "step": 16936
    },
    {
      "epoch": 0.26817296578368194,
      "grad_norm": 0.5557312369346619,
      "learning_rate": 7.318270342163182e-06,
      "loss": 0.3122,
      "step": 16937
    },
    {
      "epoch": 0.268188799341324,
      "grad_norm": 0.34897997975349426,
      "learning_rate": 7.318112006586761e-06,
      "loss": 0.0574,
      "step": 16938
    },
    {
      "epoch": 0.26820463289896607,
      "grad_norm": 0.31505781412124634,
      "learning_rate": 7.317953671010339e-06,
      "loss": 0.0975,
      "step": 16939
    },
    {
      "epoch": 0.26822046645660813,
      "grad_norm": 0.421508252620697,
      "learning_rate": 7.317795335433919e-06,
      "loss": 0.0901,
      "step": 16940
    },
    {
      "epoch": 0.2682363000142502,
      "grad_norm": 0.9317829608917236,
      "learning_rate": 7.317636999857498e-06,
      "loss": 1.4882,
      "step": 16941
    },
    {
      "epoch": 0.26825213357189226,
      "grad_norm": 0.011156894266605377,
      "learning_rate": 7.317478664281078e-06,
      "loss": 0.0003,
      "step": 16942
    },
    {
      "epoch": 0.2682679671295343,
      "grad_norm": 0.062015242874622345,
      "learning_rate": 7.317320328704657e-06,
      "loss": 0.0035,
      "step": 16943
    },
    {
      "epoch": 0.2682838006871764,
      "grad_norm": 0.5057681202888489,
      "learning_rate": 7.317161993128237e-06,
      "loss": 0.0725,
      "step": 16944
    },
    {
      "epoch": 0.26829963424481845,
      "grad_norm": 0.17081807553768158,
      "learning_rate": 7.317003657551815e-06,
      "loss": 0.0639,
      "step": 16945
    },
    {
      "epoch": 0.2683154678024605,
      "grad_norm": 0.4558243751525879,
      "learning_rate": 7.316845321975395e-06,
      "loss": 0.1467,
      "step": 16946
    },
    {
      "epoch": 0.2683313013601026,
      "grad_norm": 0.04251402989029884,
      "learning_rate": 7.316686986398974e-06,
      "loss": 0.0027,
      "step": 16947
    },
    {
      "epoch": 0.26834713491774465,
      "grad_norm": 0.010343706235289574,
      "learning_rate": 7.316528650822554e-06,
      "loss": 0.0004,
      "step": 16948
    },
    {
      "epoch": 0.2683629684753867,
      "grad_norm": 0.12555095553398132,
      "learning_rate": 7.316370315246133e-06,
      "loss": 0.0039,
      "step": 16949
    },
    {
      "epoch": 0.2683788020330288,
      "grad_norm": 0.018441081047058105,
      "learning_rate": 7.316211979669713e-06,
      "loss": 0.0009,
      "step": 16950
    },
    {
      "epoch": 0.2683946355906709,
      "grad_norm": 0.4171392023563385,
      "learning_rate": 7.3160536440932915e-06,
      "loss": 0.2419,
      "step": 16951
    },
    {
      "epoch": 0.26841046914831296,
      "grad_norm": 0.031188100576400757,
      "learning_rate": 7.315895308516871e-06,
      "loss": 0.0015,
      "step": 16952
    },
    {
      "epoch": 0.268426302705955,
      "grad_norm": 0.2466663420200348,
      "learning_rate": 7.3157369729404505e-06,
      "loss": 0.0374,
      "step": 16953
    },
    {
      "epoch": 0.2684421362635971,
      "grad_norm": 0.6732298135757446,
      "learning_rate": 7.31557863736403e-06,
      "loss": 0.3079,
      "step": 16954
    },
    {
      "epoch": 0.26845796982123915,
      "grad_norm": 0.2547556757926941,
      "learning_rate": 7.3154203017876095e-06,
      "loss": 0.0746,
      "step": 16955
    },
    {
      "epoch": 0.2684738033788812,
      "grad_norm": 0.4317358136177063,
      "learning_rate": 7.315261966211189e-06,
      "loss": 0.0969,
      "step": 16956
    },
    {
      "epoch": 0.2684896369365233,
      "grad_norm": 0.37158963084220886,
      "learning_rate": 7.315103630634768e-06,
      "loss": 0.1315,
      "step": 16957
    },
    {
      "epoch": 0.26850547049416534,
      "grad_norm": 0.00010216525697614998,
      "learning_rate": 7.314945295058348e-06,
      "loss": 0.0,
      "step": 16958
    },
    {
      "epoch": 0.2685213040518074,
      "grad_norm": 0.007960581220686436,
      "learning_rate": 7.314786959481927e-06,
      "loss": 0.0004,
      "step": 16959
    },
    {
      "epoch": 0.26853713760944947,
      "grad_norm": 0.25643569231033325,
      "learning_rate": 7.314628623905507e-06,
      "loss": 0.1258,
      "step": 16960
    },
    {
      "epoch": 0.26855297116709154,
      "grad_norm": 0.6732251644134521,
      "learning_rate": 7.314470288329085e-06,
      "loss": 0.8696,
      "step": 16961
    },
    {
      "epoch": 0.2685688047247336,
      "grad_norm": 0.85987788438797,
      "learning_rate": 7.314311952752665e-06,
      "loss": 0.0967,
      "step": 16962
    },
    {
      "epoch": 0.26858463828237567,
      "grad_norm": 0.2922501862049103,
      "learning_rate": 7.314153617176244e-06,
      "loss": 0.0918,
      "step": 16963
    },
    {
      "epoch": 0.26860047184001773,
      "grad_norm": 0.031793590635061264,
      "learning_rate": 7.313995281599823e-06,
      "loss": 0.0014,
      "step": 16964
    },
    {
      "epoch": 0.2686163053976598,
      "grad_norm": 0.3682161867618561,
      "learning_rate": 7.313836946023403e-06,
      "loss": 0.0471,
      "step": 16965
    },
    {
      "epoch": 0.26863213895530186,
      "grad_norm": 0.007277693133801222,
      "learning_rate": 7.313678610446981e-06,
      "loss": 0.0003,
      "step": 16966
    },
    {
      "epoch": 0.2686479725129439,
      "grad_norm": 0.2559381425380707,
      "learning_rate": 7.313520274870561e-06,
      "loss": 0.0994,
      "step": 16967
    },
    {
      "epoch": 0.268663806070586,
      "grad_norm": 0.29335087537765503,
      "learning_rate": 7.31336193929414e-06,
      "loss": 0.0805,
      "step": 16968
    },
    {
      "epoch": 0.26867963962822805,
      "grad_norm": 0.00013372927787713706,
      "learning_rate": 7.31320360371772e-06,
      "loss": 0.0,
      "step": 16969
    },
    {
      "epoch": 0.2686954731858701,
      "grad_norm": 0.655683696269989,
      "learning_rate": 7.313045268141299e-06,
      "loss": 0.5152,
      "step": 16970
    },
    {
      "epoch": 0.2687113067435122,
      "grad_norm": 0.3720545470714569,
      "learning_rate": 7.312886932564879e-06,
      "loss": 0.1386,
      "step": 16971
    },
    {
      "epoch": 0.26872714030115424,
      "grad_norm": 0.3414825201034546,
      "learning_rate": 7.312728596988457e-06,
      "loss": 0.1,
      "step": 16972
    },
    {
      "epoch": 0.2687429738587963,
      "grad_norm": 0.49609339237213135,
      "learning_rate": 7.312570261412037e-06,
      "loss": 0.0449,
      "step": 16973
    },
    {
      "epoch": 0.26875880741643837,
      "grad_norm": 0.5526333451271057,
      "learning_rate": 7.312411925835616e-06,
      "loss": 1.0355,
      "step": 16974
    },
    {
      "epoch": 0.2687746409740805,
      "grad_norm": 0.695003867149353,
      "learning_rate": 7.312253590259196e-06,
      "loss": 0.1739,
      "step": 16975
    },
    {
      "epoch": 0.26879047453172256,
      "grad_norm": 0.5423387885093689,
      "learning_rate": 7.312095254682775e-06,
      "loss": 0.6165,
      "step": 16976
    },
    {
      "epoch": 0.2688063080893646,
      "grad_norm": 0.00023178281844593585,
      "learning_rate": 7.311936919106355e-06,
      "loss": 0.0,
      "step": 16977
    },
    {
      "epoch": 0.2688221416470067,
      "grad_norm": 0.04451945051550865,
      "learning_rate": 7.311778583529933e-06,
      "loss": 0.0022,
      "step": 16978
    },
    {
      "epoch": 0.26883797520464875,
      "grad_norm": 0.00013830848911311477,
      "learning_rate": 7.311620247953513e-06,
      "loss": 0.0,
      "step": 16979
    },
    {
      "epoch": 0.2688538087622908,
      "grad_norm": 0.25082865357398987,
      "learning_rate": 7.311461912377092e-06,
      "loss": 0.0926,
      "step": 16980
    },
    {
      "epoch": 0.2688696423199329,
      "grad_norm": 0.13534758985042572,
      "learning_rate": 7.311303576800672e-06,
      "loss": 0.0458,
      "step": 16981
    },
    {
      "epoch": 0.26888547587757494,
      "grad_norm": 0.029110148549079895,
      "learning_rate": 7.311145241224251e-06,
      "loss": 0.0015,
      "step": 16982
    },
    {
      "epoch": 0.268901309435217,
      "grad_norm": 0.5154163837432861,
      "learning_rate": 7.310986905647831e-06,
      "loss": 0.158,
      "step": 16983
    },
    {
      "epoch": 0.26891714299285907,
      "grad_norm": 0.023373598232865334,
      "learning_rate": 7.3108285700714096e-06,
      "loss": 0.0011,
      "step": 16984
    },
    {
      "epoch": 0.26893297655050113,
      "grad_norm": 0.73487389087677,
      "learning_rate": 7.3106702344949895e-06,
      "loss": 0.392,
      "step": 16985
    },
    {
      "epoch": 0.2689488101081432,
      "grad_norm": 0.006190164014697075,
      "learning_rate": 7.310511898918569e-06,
      "loss": 0.0001,
      "step": 16986
    },
    {
      "epoch": 0.26896464366578526,
      "grad_norm": 0.24740545451641083,
      "learning_rate": 7.310353563342148e-06,
      "loss": 0.0235,
      "step": 16987
    },
    {
      "epoch": 0.26898047722342733,
      "grad_norm": 0.13464844226837158,
      "learning_rate": 7.310195227765728e-06,
      "loss": 0.0229,
      "step": 16988
    },
    {
      "epoch": 0.2689963107810694,
      "grad_norm": 0.8366172909736633,
      "learning_rate": 7.310036892189306e-06,
      "loss": 0.3644,
      "step": 16989
    },
    {
      "epoch": 0.26901214433871146,
      "grad_norm": 0.01782122626900673,
      "learning_rate": 7.309878556612886e-06,
      "loss": 0.0008,
      "step": 16990
    },
    {
      "epoch": 0.2690279778963535,
      "grad_norm": 0.3765084445476532,
      "learning_rate": 7.309720221036465e-06,
      "loss": 0.1102,
      "step": 16991
    },
    {
      "epoch": 0.2690438114539956,
      "grad_norm": 0.8062437772750854,
      "learning_rate": 7.309561885460045e-06,
      "loss": 0.3713,
      "step": 16992
    },
    {
      "epoch": 0.26905964501163765,
      "grad_norm": 0.3066686987876892,
      "learning_rate": 7.309403549883624e-06,
      "loss": 0.0317,
      "step": 16993
    },
    {
      "epoch": 0.2690754785692797,
      "grad_norm": 0.001423953683115542,
      "learning_rate": 7.309245214307204e-06,
      "loss": 0.0,
      "step": 16994
    },
    {
      "epoch": 0.2690913121269218,
      "grad_norm": 0.006134191062301397,
      "learning_rate": 7.309086878730782e-06,
      "loss": 0.0002,
      "step": 16995
    },
    {
      "epoch": 0.26910714568456384,
      "grad_norm": 0.0003232405870221555,
      "learning_rate": 7.308928543154362e-06,
      "loss": 0.0,
      "step": 16996
    },
    {
      "epoch": 0.2691229792422059,
      "grad_norm": 0.6677908897399902,
      "learning_rate": 7.308770207577941e-06,
      "loss": 0.2121,
      "step": 16997
    },
    {
      "epoch": 0.26913881279984797,
      "grad_norm": 0.1700311005115509,
      "learning_rate": 7.308611872001521e-06,
      "loss": 0.0678,
      "step": 16998
    },
    {
      "epoch": 0.2691546463574901,
      "grad_norm": 0.43621212244033813,
      "learning_rate": 7.3084535364251e-06,
      "loss": 0.124,
      "step": 16999
    },
    {
      "epoch": 0.26917047991513215,
      "grad_norm": 0.24245168268680573,
      "learning_rate": 7.30829520084868e-06,
      "loss": 0.1014,
      "step": 17000
    },
    {
      "epoch": 0.2691863134727742,
      "grad_norm": 0.003808446228504181,
      "learning_rate": 7.308136865272258e-06,
      "loss": 0.0001,
      "step": 17001
    },
    {
      "epoch": 0.2692021470304163,
      "grad_norm": 0.6812559366226196,
      "learning_rate": 7.307978529695838e-06,
      "loss": 0.2591,
      "step": 17002
    },
    {
      "epoch": 0.26921798058805835,
      "grad_norm": 0.9111965894699097,
      "learning_rate": 7.307820194119417e-06,
      "loss": 0.2826,
      "step": 17003
    },
    {
      "epoch": 0.2692338141457004,
      "grad_norm": 0.45579108595848083,
      "learning_rate": 7.307661858542997e-06,
      "loss": 0.1558,
      "step": 17004
    },
    {
      "epoch": 0.2692496477033425,
      "grad_norm": 0.31246620416641235,
      "learning_rate": 7.307503522966576e-06,
      "loss": 0.099,
      "step": 17005
    },
    {
      "epoch": 0.26926548126098454,
      "grad_norm": 0.7503952383995056,
      "learning_rate": 7.307345187390156e-06,
      "loss": 0.5462,
      "step": 17006
    },
    {
      "epoch": 0.2692813148186266,
      "grad_norm": 0.4667726159095764,
      "learning_rate": 7.307186851813734e-06,
      "loss": 0.1407,
      "step": 17007
    },
    {
      "epoch": 0.26929714837626867,
      "grad_norm": 0.2912185788154602,
      "learning_rate": 7.307028516237314e-06,
      "loss": 0.077,
      "step": 17008
    },
    {
      "epoch": 0.26931298193391073,
      "grad_norm": 0.010367849841713905,
      "learning_rate": 7.306870180660893e-06,
      "loss": 0.0004,
      "step": 17009
    },
    {
      "epoch": 0.2693288154915528,
      "grad_norm": 0.07160516828298569,
      "learning_rate": 7.306711845084473e-06,
      "loss": 0.0035,
      "step": 17010
    },
    {
      "epoch": 0.26934464904919486,
      "grad_norm": 0.7347135543823242,
      "learning_rate": 7.306553509508052e-06,
      "loss": 0.5536,
      "step": 17011
    },
    {
      "epoch": 0.2693604826068369,
      "grad_norm": 0.45010945200920105,
      "learning_rate": 7.306395173931631e-06,
      "loss": 0.0882,
      "step": 17012
    },
    {
      "epoch": 0.269376316164479,
      "grad_norm": 0.4494223892688751,
      "learning_rate": 7.3062368383552105e-06,
      "loss": 0.1818,
      "step": 17013
    },
    {
      "epoch": 0.26939214972212105,
      "grad_norm": 0.02032971754670143,
      "learning_rate": 7.30607850277879e-06,
      "loss": 0.0006,
      "step": 17014
    },
    {
      "epoch": 0.2694079832797631,
      "grad_norm": 0.5196799635887146,
      "learning_rate": 7.3059201672023695e-06,
      "loss": 0.0339,
      "step": 17015
    },
    {
      "epoch": 0.2694238168374052,
      "grad_norm": 0.1636904925107956,
      "learning_rate": 7.305761831625949e-06,
      "loss": 0.0249,
      "step": 17016
    },
    {
      "epoch": 0.26943965039504725,
      "grad_norm": 0.22221896052360535,
      "learning_rate": 7.3056034960495285e-06,
      "loss": 0.0359,
      "step": 17017
    },
    {
      "epoch": 0.2694554839526893,
      "grad_norm": 0.01882188394665718,
      "learning_rate": 7.305445160473107e-06,
      "loss": 0.0005,
      "step": 17018
    },
    {
      "epoch": 0.2694713175103314,
      "grad_norm": 0.01839284598827362,
      "learning_rate": 7.305286824896687e-06,
      "loss": 0.0008,
      "step": 17019
    },
    {
      "epoch": 0.26948715106797344,
      "grad_norm": 0.17772537469863892,
      "learning_rate": 7.305128489320266e-06,
      "loss": 0.0589,
      "step": 17020
    },
    {
      "epoch": 0.2695029846256155,
      "grad_norm": 0.2675703167915344,
      "learning_rate": 7.304970153743846e-06,
      "loss": 0.0874,
      "step": 17021
    },
    {
      "epoch": 0.26951881818325757,
      "grad_norm": 0.27594658732414246,
      "learning_rate": 7.304811818167425e-06,
      "loss": 0.3345,
      "step": 17022
    },
    {
      "epoch": 0.2695346517408997,
      "grad_norm": 0.7575740814208984,
      "learning_rate": 7.304653482591004e-06,
      "loss": 0.3127,
      "step": 17023
    },
    {
      "epoch": 0.26955048529854175,
      "grad_norm": 0.3633630871772766,
      "learning_rate": 7.304495147014583e-06,
      "loss": 0.1351,
      "step": 17024
    },
    {
      "epoch": 0.2695663188561838,
      "grad_norm": 0.6185039281845093,
      "learning_rate": 7.304336811438163e-06,
      "loss": 0.2256,
      "step": 17025
    },
    {
      "epoch": 0.2695821524138259,
      "grad_norm": 0.5189341306686401,
      "learning_rate": 7.304178475861742e-06,
      "loss": 0.1591,
      "step": 17026
    },
    {
      "epoch": 0.26959798597146795,
      "grad_norm": 0.43540501594543457,
      "learning_rate": 7.304020140285322e-06,
      "loss": 0.1375,
      "step": 17027
    },
    {
      "epoch": 0.26961381952911,
      "grad_norm": 0.4401543140411377,
      "learning_rate": 7.3038618047089e-06,
      "loss": 0.2145,
      "step": 17028
    },
    {
      "epoch": 0.2696296530867521,
      "grad_norm": 0.7530274987220764,
      "learning_rate": 7.30370346913248e-06,
      "loss": 0.5541,
      "step": 17029
    },
    {
      "epoch": 0.26964548664439414,
      "grad_norm": 0.37173953652381897,
      "learning_rate": 7.303545133556059e-06,
      "loss": 0.236,
      "step": 17030
    },
    {
      "epoch": 0.2696613202020362,
      "grad_norm": 0.3206130564212799,
      "learning_rate": 7.303386797979639e-06,
      "loss": 0.0303,
      "step": 17031
    },
    {
      "epoch": 0.26967715375967827,
      "grad_norm": 1.0205066204071045,
      "learning_rate": 7.303228462403218e-06,
      "loss": 0.3685,
      "step": 17032
    },
    {
      "epoch": 0.26969298731732033,
      "grad_norm": 0.0023245157208293676,
      "learning_rate": 7.303070126826798e-06,
      "loss": 0.0,
      "step": 17033
    },
    {
      "epoch": 0.2697088208749624,
      "grad_norm": 0.004000477958470583,
      "learning_rate": 7.302911791250376e-06,
      "loss": 0.0001,
      "step": 17034
    },
    {
      "epoch": 0.26972465443260446,
      "grad_norm": 0.004115168005228043,
      "learning_rate": 7.302753455673955e-06,
      "loss": 0.0001,
      "step": 17035
    },
    {
      "epoch": 0.2697404879902465,
      "grad_norm": 0.29270800948143005,
      "learning_rate": 7.302595120097535e-06,
      "loss": 0.0334,
      "step": 17036
    },
    {
      "epoch": 0.2697563215478886,
      "grad_norm": 0.8087480664253235,
      "learning_rate": 7.302436784521114e-06,
      "loss": 0.4171,
      "step": 17037
    },
    {
      "epoch": 0.26977215510553065,
      "grad_norm": 0.012569001875817776,
      "learning_rate": 7.302278448944694e-06,
      "loss": 0.0004,
      "step": 17038
    },
    {
      "epoch": 0.2697879886631727,
      "grad_norm": 0.030965231359004974,
      "learning_rate": 7.3021201133682725e-06,
      "loss": 0.0014,
      "step": 17039
    },
    {
      "epoch": 0.2698038222208148,
      "grad_norm": 0.49829068779945374,
      "learning_rate": 7.3019617777918524e-06,
      "loss": 0.1568,
      "step": 17040
    },
    {
      "epoch": 0.26981965577845685,
      "grad_norm": 0.43922555446624756,
      "learning_rate": 7.3018034422154315e-06,
      "loss": 0.1365,
      "step": 17041
    },
    {
      "epoch": 0.2698354893360989,
      "grad_norm": 0.015437169931828976,
      "learning_rate": 7.3016451066390114e-06,
      "loss": 0.0006,
      "step": 17042
    },
    {
      "epoch": 0.269851322893741,
      "grad_norm": 0.7578657269477844,
      "learning_rate": 7.3014867710625905e-06,
      "loss": 0.1007,
      "step": 17043
    },
    {
      "epoch": 0.26986715645138304,
      "grad_norm": 0.23890891671180725,
      "learning_rate": 7.3013284354861704e-06,
      "loss": 0.0649,
      "step": 17044
    },
    {
      "epoch": 0.2698829900090251,
      "grad_norm": 0.20850394666194916,
      "learning_rate": 7.301170099909749e-06,
      "loss": 0.0174,
      "step": 17045
    },
    {
      "epoch": 0.26989882356666717,
      "grad_norm": 1.0791824934131e-05,
      "learning_rate": 7.301011764333329e-06,
      "loss": 0.0,
      "step": 17046
    },
    {
      "epoch": 0.2699146571243093,
      "grad_norm": 0.36098164319992065,
      "learning_rate": 7.300853428756908e-06,
      "loss": 0.0671,
      "step": 17047
    },
    {
      "epoch": 0.26993049068195135,
      "grad_norm": 0.4652973413467407,
      "learning_rate": 7.300695093180488e-06,
      "loss": 0.1172,
      "step": 17048
    },
    {
      "epoch": 0.2699463242395934,
      "grad_norm": 1.645528793334961,
      "learning_rate": 7.300536757604067e-06,
      "loss": 0.7564,
      "step": 17049
    },
    {
      "epoch": 0.2699621577972355,
      "grad_norm": 0.30846863985061646,
      "learning_rate": 7.300378422027647e-06,
      "loss": 0.067,
      "step": 17050
    },
    {
      "epoch": 0.26997799135487754,
      "grad_norm": 0.030933231115341187,
      "learning_rate": 7.300220086451225e-06,
      "loss": 0.0014,
      "step": 17051
    },
    {
      "epoch": 0.2699938249125196,
      "grad_norm": 0.41775885224342346,
      "learning_rate": 7.300061750874805e-06,
      "loss": 0.0902,
      "step": 17052
    },
    {
      "epoch": 0.2700096584701617,
      "grad_norm": 0.026075974106788635,
      "learning_rate": 7.299903415298384e-06,
      "loss": 0.0013,
      "step": 17053
    },
    {
      "epoch": 0.27002549202780374,
      "grad_norm": 0.5656160712242126,
      "learning_rate": 7.299745079721964e-06,
      "loss": 0.1499,
      "step": 17054
    },
    {
      "epoch": 0.2700413255854458,
      "grad_norm": 0.31589409708976746,
      "learning_rate": 7.299586744145543e-06,
      "loss": 0.0119,
      "step": 17055
    },
    {
      "epoch": 0.27005715914308787,
      "grad_norm": 0.4435824751853943,
      "learning_rate": 7.299428408569123e-06,
      "loss": 0.1119,
      "step": 17056
    },
    {
      "epoch": 0.27007299270072993,
      "grad_norm": 0.27601078152656555,
      "learning_rate": 7.299270072992701e-06,
      "loss": 0.0565,
      "step": 17057
    },
    {
      "epoch": 0.270088826258372,
      "grad_norm": 0.58753901720047,
      "learning_rate": 7.299111737416281e-06,
      "loss": 0.4054,
      "step": 17058
    },
    {
      "epoch": 0.27010465981601406,
      "grad_norm": 0.5943726301193237,
      "learning_rate": 7.29895340183986e-06,
      "loss": 0.1189,
      "step": 17059
    },
    {
      "epoch": 0.2701204933736561,
      "grad_norm": 0.6137797832489014,
      "learning_rate": 7.298795066263439e-06,
      "loss": 0.2082,
      "step": 17060
    },
    {
      "epoch": 0.2701363269312982,
      "grad_norm": 0.2764238119125366,
      "learning_rate": 7.298636730687019e-06,
      "loss": 0.1234,
      "step": 17061
    },
    {
      "epoch": 0.27015216048894025,
      "grad_norm": 8.70538133312948e-05,
      "learning_rate": 7.298478395110597e-06,
      "loss": 0.0,
      "step": 17062
    },
    {
      "epoch": 0.2701679940465823,
      "grad_norm": 0.6060808300971985,
      "learning_rate": 7.298320059534177e-06,
      "loss": 0.7724,
      "step": 17063
    },
    {
      "epoch": 0.2701838276042244,
      "grad_norm": 0.31733542680740356,
      "learning_rate": 7.298161723957756e-06,
      "loss": 0.2596,
      "step": 17064
    },
    {
      "epoch": 0.27019966116186644,
      "grad_norm": 0.0001616899826331064,
      "learning_rate": 7.298003388381336e-06,
      "loss": 0.0,
      "step": 17065
    },
    {
      "epoch": 0.2702154947195085,
      "grad_norm": 0.011150442063808441,
      "learning_rate": 7.297845052804915e-06,
      "loss": 0.0005,
      "step": 17066
    },
    {
      "epoch": 0.2702313282771506,
      "grad_norm": 0.0052564735524356365,
      "learning_rate": 7.297686717228495e-06,
      "loss": 0.0002,
      "step": 17067
    },
    {
      "epoch": 0.27024716183479264,
      "grad_norm": 0.7259244918823242,
      "learning_rate": 7.2975283816520734e-06,
      "loss": 0.1885,
      "step": 17068
    },
    {
      "epoch": 0.2702629953924347,
      "grad_norm": 1.0279755592346191,
      "learning_rate": 7.297370046075653e-06,
      "loss": 0.7732,
      "step": 17069
    },
    {
      "epoch": 0.27027882895007677,
      "grad_norm": 0.570447564125061,
      "learning_rate": 7.2972117104992324e-06,
      "loss": 0.2603,
      "step": 17070
    },
    {
      "epoch": 0.2702946625077189,
      "grad_norm": 0.0026135204825550318,
      "learning_rate": 7.297053374922812e-06,
      "loss": 0.0001,
      "step": 17071
    },
    {
      "epoch": 0.27031049606536095,
      "grad_norm": 0.5047075748443604,
      "learning_rate": 7.2968950393463914e-06,
      "loss": 0.1833,
      "step": 17072
    },
    {
      "epoch": 0.270326329623003,
      "grad_norm": 0.23058176040649414,
      "learning_rate": 7.296736703769971e-06,
      "loss": 0.0811,
      "step": 17073
    },
    {
      "epoch": 0.2703421631806451,
      "grad_norm": 0.030072158202528954,
      "learning_rate": 7.29657836819355e-06,
      "loss": 0.0003,
      "step": 17074
    },
    {
      "epoch": 0.27035799673828714,
      "grad_norm": 0.428142786026001,
      "learning_rate": 7.2964200326171295e-06,
      "loss": 0.0991,
      "step": 17075
    },
    {
      "epoch": 0.2703738302959292,
      "grad_norm": 0.000362626975402236,
      "learning_rate": 7.296261697040709e-06,
      "loss": 0.0,
      "step": 17076
    },
    {
      "epoch": 0.27038966385357127,
      "grad_norm": 0.7872717976570129,
      "learning_rate": 7.2961033614642885e-06,
      "loss": 0.2824,
      "step": 17077
    },
    {
      "epoch": 0.27040549741121334,
      "grad_norm": 0.027285560965538025,
      "learning_rate": 7.295945025887868e-06,
      "loss": 0.0008,
      "step": 17078
    },
    {
      "epoch": 0.2704213309688554,
      "grad_norm": 0.6026566624641418,
      "learning_rate": 7.2957866903114475e-06,
      "loss": 0.5746,
      "step": 17079
    },
    {
      "epoch": 0.27043716452649746,
      "grad_norm": 0.21703843772411346,
      "learning_rate": 7.295628354735026e-06,
      "loss": 0.0063,
      "step": 17080
    },
    {
      "epoch": 0.27045299808413953,
      "grad_norm": 0.3729725778102875,
      "learning_rate": 7.295470019158606e-06,
      "loss": 0.0716,
      "step": 17081
    },
    {
      "epoch": 0.2704688316417816,
      "grad_norm": 0.5402215123176575,
      "learning_rate": 7.295311683582185e-06,
      "loss": 0.4434,
      "step": 17082
    },
    {
      "epoch": 0.27048466519942366,
      "grad_norm": 0.011863592080771923,
      "learning_rate": 7.295153348005764e-06,
      "loss": 0.0005,
      "step": 17083
    },
    {
      "epoch": 0.2705004987570657,
      "grad_norm": 0.46094754338264465,
      "learning_rate": 7.294995012429344e-06,
      "loss": 0.1542,
      "step": 17084
    },
    {
      "epoch": 0.2705163323147078,
      "grad_norm": 0.02122439816594124,
      "learning_rate": 7.294836676852922e-06,
      "loss": 0.0011,
      "step": 17085
    },
    {
      "epoch": 0.27053216587234985,
      "grad_norm": 0.4253344237804413,
      "learning_rate": 7.294678341276502e-06,
      "loss": 0.0851,
      "step": 17086
    },
    {
      "epoch": 0.2705479994299919,
      "grad_norm": 0.3911481499671936,
      "learning_rate": 7.294520005700081e-06,
      "loss": 0.0456,
      "step": 17087
    },
    {
      "epoch": 0.270563832987634,
      "grad_norm": 0.4853534996509552,
      "learning_rate": 7.294361670123661e-06,
      "loss": 0.1969,
      "step": 17088
    },
    {
      "epoch": 0.27057966654527604,
      "grad_norm": 0.0001840371114667505,
      "learning_rate": 7.29420333454724e-06,
      "loss": 0.0,
      "step": 17089
    },
    {
      "epoch": 0.2705955001029181,
      "grad_norm": 0.810845136642456,
      "learning_rate": 7.294044998970819e-06,
      "loss": 0.0613,
      "step": 17090
    },
    {
      "epoch": 0.27061133366056017,
      "grad_norm": 0.2592073678970337,
      "learning_rate": 7.293886663394398e-06,
      "loss": 0.092,
      "step": 17091
    },
    {
      "epoch": 0.27062716721820224,
      "grad_norm": 0.7204595804214478,
      "learning_rate": 7.293728327817978e-06,
      "loss": 0.4256,
      "step": 17092
    },
    {
      "epoch": 0.2706430007758443,
      "grad_norm": 0.0006298217340372503,
      "learning_rate": 7.293569992241557e-06,
      "loss": 0.0,
      "step": 17093
    },
    {
      "epoch": 0.27065883433348636,
      "grad_norm": 0.3719773590564728,
      "learning_rate": 7.293411656665137e-06,
      "loss": 0.0871,
      "step": 17094
    },
    {
      "epoch": 0.2706746678911285,
      "grad_norm": 0.2302914410829544,
      "learning_rate": 7.293253321088715e-06,
      "loss": 0.0479,
      "step": 17095
    },
    {
      "epoch": 0.27069050144877055,
      "grad_norm": 0.4138586223125458,
      "learning_rate": 7.293094985512295e-06,
      "loss": 0.7257,
      "step": 17096
    },
    {
      "epoch": 0.2707063350064126,
      "grad_norm": 0.01060545351356268,
      "learning_rate": 7.292936649935874e-06,
      "loss": 0.0006,
      "step": 17097
    },
    {
      "epoch": 0.2707221685640547,
      "grad_norm": 1.1567933559417725,
      "learning_rate": 7.292778314359454e-06,
      "loss": 0.4128,
      "step": 17098
    },
    {
      "epoch": 0.27073800212169674,
      "grad_norm": 2.5800633430480957,
      "learning_rate": 7.292619978783033e-06,
      "loss": 0.2909,
      "step": 17099
    },
    {
      "epoch": 0.2707538356793388,
      "grad_norm": 8.878052904037759e-05,
      "learning_rate": 7.292461643206613e-06,
      "loss": 0.0,
      "step": 17100
    },
    {
      "epoch": 0.27076966923698087,
      "grad_norm": 0.7887483239173889,
      "learning_rate": 7.2923033076301915e-06,
      "loss": 0.3602,
      "step": 17101
    },
    {
      "epoch": 0.27078550279462293,
      "grad_norm": 0.5108932256698608,
      "learning_rate": 7.2921449720537715e-06,
      "loss": 0.1803,
      "step": 17102
    },
    {
      "epoch": 0.270801336352265,
      "grad_norm": 9.260304068448022e-05,
      "learning_rate": 7.2919866364773505e-06,
      "loss": 0.0,
      "step": 17103
    },
    {
      "epoch": 0.27081716990990706,
      "grad_norm": 0.5308801531791687,
      "learning_rate": 7.2918283009009305e-06,
      "loss": 0.1298,
      "step": 17104
    },
    {
      "epoch": 0.2708330034675491,
      "grad_norm": 0.4536057710647583,
      "learning_rate": 7.2916699653245095e-06,
      "loss": 0.1163,
      "step": 17105
    },
    {
      "epoch": 0.2708488370251912,
      "grad_norm": 0.3635568618774414,
      "learning_rate": 7.2915116297480895e-06,
      "loss": 0.1382,
      "step": 17106
    },
    {
      "epoch": 0.27086467058283326,
      "grad_norm": 0.03252723440527916,
      "learning_rate": 7.291353294171668e-06,
      "loss": 0.0019,
      "step": 17107
    },
    {
      "epoch": 0.2708805041404753,
      "grad_norm": 0.46340999007225037,
      "learning_rate": 7.291194958595247e-06,
      "loss": 0.169,
      "step": 17108
    },
    {
      "epoch": 0.2708963376981174,
      "grad_norm": 0.42770814895629883,
      "learning_rate": 7.291036623018827e-06,
      "loss": 0.177,
      "step": 17109
    },
    {
      "epoch": 0.27091217125575945,
      "grad_norm": 0.24233466386795044,
      "learning_rate": 7.290878287442406e-06,
      "loss": 0.0903,
      "step": 17110
    },
    {
      "epoch": 0.2709280048134015,
      "grad_norm": 0.050003115087747574,
      "learning_rate": 7.290719951865986e-06,
      "loss": 0.0021,
      "step": 17111
    },
    {
      "epoch": 0.2709438383710436,
      "grad_norm": 0.20174969732761383,
      "learning_rate": 7.290561616289564e-06,
      "loss": 0.0662,
      "step": 17112
    },
    {
      "epoch": 0.27095967192868564,
      "grad_norm": 0.01113344356417656,
      "learning_rate": 7.290403280713144e-06,
      "loss": 0.0006,
      "step": 17113
    },
    {
      "epoch": 0.2709755054863277,
      "grad_norm": 0.02453397586941719,
      "learning_rate": 7.290244945136723e-06,
      "loss": 0.0012,
      "step": 17114
    },
    {
      "epoch": 0.27099133904396977,
      "grad_norm": 0.6990767121315002,
      "learning_rate": 7.290086609560303e-06,
      "loss": 0.1667,
      "step": 17115
    },
    {
      "epoch": 0.27100717260161183,
      "grad_norm": 0.5672706365585327,
      "learning_rate": 7.289928273983882e-06,
      "loss": 0.3219,
      "step": 17116
    },
    {
      "epoch": 0.2710230061592539,
      "grad_norm": 0.6995548605918884,
      "learning_rate": 7.289769938407462e-06,
      "loss": 0.2146,
      "step": 17117
    },
    {
      "epoch": 0.27103883971689596,
      "grad_norm": 0.7267785668373108,
      "learning_rate": 7.28961160283104e-06,
      "loss": 0.226,
      "step": 17118
    },
    {
      "epoch": 0.2710546732745381,
      "grad_norm": 0.1735837757587433,
      "learning_rate": 7.28945326725462e-06,
      "loss": 0.0563,
      "step": 17119
    },
    {
      "epoch": 0.27107050683218015,
      "grad_norm": 0.0002608091745059937,
      "learning_rate": 7.289294931678199e-06,
      "loss": 0.0,
      "step": 17120
    },
    {
      "epoch": 0.2710863403898222,
      "grad_norm": 0.45367488265037537,
      "learning_rate": 7.289136596101779e-06,
      "loss": 0.1566,
      "step": 17121
    },
    {
      "epoch": 0.2711021739474643,
      "grad_norm": 0.0398896150290966,
      "learning_rate": 7.288978260525358e-06,
      "loss": 0.002,
      "step": 17122
    },
    {
      "epoch": 0.27111800750510634,
      "grad_norm": 0.022066500037908554,
      "learning_rate": 7.288819924948938e-06,
      "loss": 0.0011,
      "step": 17123
    },
    {
      "epoch": 0.2711338410627484,
      "grad_norm": 0.7618955969810486,
      "learning_rate": 7.288661589372516e-06,
      "loss": 0.1272,
      "step": 17124
    },
    {
      "epoch": 0.27114967462039047,
      "grad_norm": 0.9606836438179016,
      "learning_rate": 7.288503253796096e-06,
      "loss": 0.112,
      "step": 17125
    },
    {
      "epoch": 0.27116550817803253,
      "grad_norm": 0.40333443880081177,
      "learning_rate": 7.288344918219675e-06,
      "loss": 0.448,
      "step": 17126
    },
    {
      "epoch": 0.2711813417356746,
      "grad_norm": 0.00012544252967927605,
      "learning_rate": 7.288186582643255e-06,
      "loss": 0.0,
      "step": 17127
    },
    {
      "epoch": 0.27119717529331666,
      "grad_norm": 0.011538230814039707,
      "learning_rate": 7.288028247066834e-06,
      "loss": 0.0004,
      "step": 17128
    },
    {
      "epoch": 0.2712130088509587,
      "grad_norm": 0.17779406905174255,
      "learning_rate": 7.287869911490414e-06,
      "loss": 0.0593,
      "step": 17129
    },
    {
      "epoch": 0.2712288424086008,
      "grad_norm": 0.6930109262466431,
      "learning_rate": 7.2877115759139925e-06,
      "loss": 0.4744,
      "step": 17130
    },
    {
      "epoch": 0.27124467596624285,
      "grad_norm": 0.00026787095703184605,
      "learning_rate": 7.2875532403375715e-06,
      "loss": 0.0,
      "step": 17131
    },
    {
      "epoch": 0.2712605095238849,
      "grad_norm": 0.8603925108909607,
      "learning_rate": 7.2873949047611515e-06,
      "loss": 0.641,
      "step": 17132
    },
    {
      "epoch": 0.271276343081527,
      "grad_norm": 0.8048726320266724,
      "learning_rate": 7.2872365691847305e-06,
      "loss": 0.6067,
      "step": 17133
    },
    {
      "epoch": 0.27129217663916905,
      "grad_norm": 0.09514714032411575,
      "learning_rate": 7.2870782336083105e-06,
      "loss": 0.0027,
      "step": 17134
    },
    {
      "epoch": 0.2713080101968111,
      "grad_norm": 0.310034841299057,
      "learning_rate": 7.286919898031889e-06,
      "loss": 0.0081,
      "step": 17135
    },
    {
      "epoch": 0.2713238437544532,
      "grad_norm": 0.48232302069664,
      "learning_rate": 7.286761562455469e-06,
      "loss": 0.2101,
      "step": 17136
    },
    {
      "epoch": 0.27133967731209524,
      "grad_norm": 0.7001755833625793,
      "learning_rate": 7.286603226879048e-06,
      "loss": 0.2231,
      "step": 17137
    },
    {
      "epoch": 0.2713555108697373,
      "grad_norm": 0.3399217128753662,
      "learning_rate": 7.286444891302628e-06,
      "loss": 0.1021,
      "step": 17138
    },
    {
      "epoch": 0.27137134442737937,
      "grad_norm": 0.00010774161637527868,
      "learning_rate": 7.286286555726207e-06,
      "loss": 0.0,
      "step": 17139
    },
    {
      "epoch": 0.27138717798502143,
      "grad_norm": 0.5281137228012085,
      "learning_rate": 7.286128220149787e-06,
      "loss": 0.159,
      "step": 17140
    },
    {
      "epoch": 0.2714030115426635,
      "grad_norm": 0.4649268388748169,
      "learning_rate": 7.285969884573365e-06,
      "loss": 0.0976,
      "step": 17141
    },
    {
      "epoch": 0.27141884510030556,
      "grad_norm": 0.005113361403346062,
      "learning_rate": 7.285811548996945e-06,
      "loss": 0.0002,
      "step": 17142
    },
    {
      "epoch": 0.2714346786579477,
      "grad_norm": 0.32997116446495056,
      "learning_rate": 7.285653213420524e-06,
      "loss": 0.0622,
      "step": 17143
    },
    {
      "epoch": 0.27145051221558975,
      "grad_norm": 0.006180484779179096,
      "learning_rate": 7.285494877844104e-06,
      "loss": 0.0002,
      "step": 17144
    },
    {
      "epoch": 0.2714663457732318,
      "grad_norm": 0.2401593029499054,
      "learning_rate": 7.285336542267683e-06,
      "loss": 0.2127,
      "step": 17145
    },
    {
      "epoch": 0.2714821793308739,
      "grad_norm": 0.2663900554180145,
      "learning_rate": 7.285178206691263e-06,
      "loss": 0.0332,
      "step": 17146
    },
    {
      "epoch": 0.27149801288851594,
      "grad_norm": 0.022897688671946526,
      "learning_rate": 7.285019871114841e-06,
      "loss": 0.0014,
      "step": 17147
    },
    {
      "epoch": 0.271513846446158,
      "grad_norm": 0.52003014087677,
      "learning_rate": 7.284861535538421e-06,
      "loss": 0.1943,
      "step": 17148
    },
    {
      "epoch": 0.27152968000380007,
      "grad_norm": 0.35442960262298584,
      "learning_rate": 7.284703199962e-06,
      "loss": 0.0521,
      "step": 17149
    },
    {
      "epoch": 0.27154551356144213,
      "grad_norm": 0.23319111764431,
      "learning_rate": 7.28454486438558e-06,
      "loss": 0.0653,
      "step": 17150
    },
    {
      "epoch": 0.2715613471190842,
      "grad_norm": 0.6219366788864136,
      "learning_rate": 7.284386528809159e-06,
      "loss": 0.2024,
      "step": 17151
    },
    {
      "epoch": 0.27157718067672626,
      "grad_norm": 0.21719379723072052,
      "learning_rate": 7.284228193232738e-06,
      "loss": 0.0722,
      "step": 17152
    },
    {
      "epoch": 0.2715930142343683,
      "grad_norm": 0.3008924126625061,
      "learning_rate": 7.284069857656317e-06,
      "loss": 0.0923,
      "step": 17153
    },
    {
      "epoch": 0.2716088477920104,
      "grad_norm": 1.0197820663452148,
      "learning_rate": 7.283911522079897e-06,
      "loss": 0.172,
      "step": 17154
    },
    {
      "epoch": 0.27162468134965245,
      "grad_norm": 0.24802576005458832,
      "learning_rate": 7.283753186503476e-06,
      "loss": 0.0869,
      "step": 17155
    },
    {
      "epoch": 0.2716405149072945,
      "grad_norm": 0.21903444826602936,
      "learning_rate": 7.2835948509270545e-06,
      "loss": 0.068,
      "step": 17156
    },
    {
      "epoch": 0.2716563484649366,
      "grad_norm": 0.4489462077617645,
      "learning_rate": 7.283436515350634e-06,
      "loss": 0.1881,
      "step": 17157
    },
    {
      "epoch": 0.27167218202257865,
      "grad_norm": 0.28465399146080017,
      "learning_rate": 7.2832781797742135e-06,
      "loss": 0.0373,
      "step": 17158
    },
    {
      "epoch": 0.2716880155802207,
      "grad_norm": 0.4854435324668884,
      "learning_rate": 7.283119844197793e-06,
      "loss": 0.1095,
      "step": 17159
    },
    {
      "epoch": 0.2717038491378628,
      "grad_norm": 0.8977459073066711,
      "learning_rate": 7.2829615086213725e-06,
      "loss": 0.0801,
      "step": 17160
    },
    {
      "epoch": 0.27171968269550484,
      "grad_norm": 0.8678178787231445,
      "learning_rate": 7.282803173044952e-06,
      "loss": 0.8183,
      "step": 17161
    },
    {
      "epoch": 0.2717355162531469,
      "grad_norm": 0.41908881068229675,
      "learning_rate": 7.282644837468531e-06,
      "loss": 0.1437,
      "step": 17162
    },
    {
      "epoch": 0.27175134981078897,
      "grad_norm": 0.030732303857803345,
      "learning_rate": 7.2824865018921106e-06,
      "loss": 0.0016,
      "step": 17163
    },
    {
      "epoch": 0.27176718336843103,
      "grad_norm": 0.81560879945755,
      "learning_rate": 7.28232816631569e-06,
      "loss": 0.0537,
      "step": 17164
    },
    {
      "epoch": 0.2717830169260731,
      "grad_norm": 1.1002978086471558,
      "learning_rate": 7.2821698307392696e-06,
      "loss": 0.3288,
      "step": 17165
    },
    {
      "epoch": 0.27179885048371516,
      "grad_norm": 0.35400646924972534,
      "learning_rate": 7.282011495162849e-06,
      "loss": 0.1026,
      "step": 17166
    },
    {
      "epoch": 0.2718146840413573,
      "grad_norm": 0.26165980100631714,
      "learning_rate": 7.2818531595864286e-06,
      "loss": 0.0502,
      "step": 17167
    },
    {
      "epoch": 0.27183051759899934,
      "grad_norm": 0.2995280623435974,
      "learning_rate": 7.281694824010007e-06,
      "loss": 0.121,
      "step": 17168
    },
    {
      "epoch": 0.2718463511566414,
      "grad_norm": 0.09369618445634842,
      "learning_rate": 7.281536488433587e-06,
      "loss": 0.0089,
      "step": 17169
    },
    {
      "epoch": 0.2718621847142835,
      "grad_norm": 0.6021615266799927,
      "learning_rate": 7.281378152857166e-06,
      "loss": 0.4153,
      "step": 17170
    },
    {
      "epoch": 0.27187801827192554,
      "grad_norm": 0.5288451313972473,
      "learning_rate": 7.281219817280746e-06,
      "loss": 0.1699,
      "step": 17171
    },
    {
      "epoch": 0.2718938518295676,
      "grad_norm": 0.2230985313653946,
      "learning_rate": 7.281061481704325e-06,
      "loss": 0.0861,
      "step": 17172
    },
    {
      "epoch": 0.27190968538720967,
      "grad_norm": 0.0005114580853842199,
      "learning_rate": 7.280903146127905e-06,
      "loss": 0.0,
      "step": 17173
    },
    {
      "epoch": 0.27192551894485173,
      "grad_norm": 0.011514049023389816,
      "learning_rate": 7.280744810551483e-06,
      "loss": 0.0005,
      "step": 17174
    },
    {
      "epoch": 0.2719413525024938,
      "grad_norm": 0.025539066642522812,
      "learning_rate": 7.280586474975063e-06,
      "loss": 0.0012,
      "step": 17175
    },
    {
      "epoch": 0.27195718606013586,
      "grad_norm": 0.020090777426958084,
      "learning_rate": 7.280428139398642e-06,
      "loss": 0.0009,
      "step": 17176
    },
    {
      "epoch": 0.2719730196177779,
      "grad_norm": 0.2409982830286026,
      "learning_rate": 7.280269803822222e-06,
      "loss": 0.0511,
      "step": 17177
    },
    {
      "epoch": 0.27198885317542,
      "grad_norm": 0.8272088170051575,
      "learning_rate": 7.280111468245801e-06,
      "loss": 0.5801,
      "step": 17178
    },
    {
      "epoch": 0.27200468673306205,
      "grad_norm": 0.0230408925563097,
      "learning_rate": 7.279953132669379e-06,
      "loss": 0.001,
      "step": 17179
    },
    {
      "epoch": 0.2720205202907041,
      "grad_norm": 0.32292914390563965,
      "learning_rate": 7.279794797092959e-06,
      "loss": 0.0814,
      "step": 17180
    },
    {
      "epoch": 0.2720363538483462,
      "grad_norm": 0.49540820717811584,
      "learning_rate": 7.279636461516538e-06,
      "loss": 0.1173,
      "step": 17181
    },
    {
      "epoch": 0.27205218740598824,
      "grad_norm": 0.009542221203446388,
      "learning_rate": 7.279478125940118e-06,
      "loss": 0.0004,
      "step": 17182
    },
    {
      "epoch": 0.2720680209636303,
      "grad_norm": 0.3048367500305176,
      "learning_rate": 7.279319790363697e-06,
      "loss": 0.098,
      "step": 17183
    },
    {
      "epoch": 0.2720838545212724,
      "grad_norm": 0.04100882261991501,
      "learning_rate": 7.279161454787277e-06,
      "loss": 0.0021,
      "step": 17184
    },
    {
      "epoch": 0.27209968807891444,
      "grad_norm": 0.2251381129026413,
      "learning_rate": 7.279003119210855e-06,
      "loss": 0.0965,
      "step": 17185
    },
    {
      "epoch": 0.2721155216365565,
      "grad_norm": 0.024636143818497658,
      "learning_rate": 7.278844783634435e-06,
      "loss": 0.0011,
      "step": 17186
    },
    {
      "epoch": 0.27213135519419857,
      "grad_norm": 0.203715980052948,
      "learning_rate": 7.278686448058014e-06,
      "loss": 0.0643,
      "step": 17187
    },
    {
      "epoch": 0.27214718875184063,
      "grad_norm": 0.25764963030815125,
      "learning_rate": 7.278528112481594e-06,
      "loss": 0.1308,
      "step": 17188
    },
    {
      "epoch": 0.2721630223094827,
      "grad_norm": 0.26039719581604004,
      "learning_rate": 7.278369776905173e-06,
      "loss": 0.1045,
      "step": 17189
    },
    {
      "epoch": 0.27217885586712476,
      "grad_norm": 0.31995508074760437,
      "learning_rate": 7.278211441328753e-06,
      "loss": 0.1132,
      "step": 17190
    },
    {
      "epoch": 0.2721946894247669,
      "grad_norm": 0.31181952357292175,
      "learning_rate": 7.2780531057523316e-06,
      "loss": 0.0071,
      "step": 17191
    },
    {
      "epoch": 0.27221052298240894,
      "grad_norm": 0.9286196827888489,
      "learning_rate": 7.2778947701759115e-06,
      "loss": 0.2643,
      "step": 17192
    },
    {
      "epoch": 0.272226356540051,
      "grad_norm": 0.4831535518169403,
      "learning_rate": 7.2777364345994906e-06,
      "loss": 0.1182,
      "step": 17193
    },
    {
      "epoch": 0.27224219009769307,
      "grad_norm": 0.0315684974193573,
      "learning_rate": 7.2775780990230705e-06,
      "loss": 0.0013,
      "step": 17194
    },
    {
      "epoch": 0.27225802365533514,
      "grad_norm": 0.014091195538640022,
      "learning_rate": 7.2774197634466496e-06,
      "loss": 0.0006,
      "step": 17195
    },
    {
      "epoch": 0.2722738572129772,
      "grad_norm": 9.952971595339477e-05,
      "learning_rate": 7.2772614278702295e-06,
      "loss": 0.0,
      "step": 17196
    },
    {
      "epoch": 0.27228969077061926,
      "grad_norm": 0.022868279367685318,
      "learning_rate": 7.277103092293808e-06,
      "loss": 0.0011,
      "step": 17197
    },
    {
      "epoch": 0.27230552432826133,
      "grad_norm": 0.007590543944388628,
      "learning_rate": 7.276944756717388e-06,
      "loss": 0.0003,
      "step": 17198
    },
    {
      "epoch": 0.2723213578859034,
      "grad_norm": 0.1861424744129181,
      "learning_rate": 7.276786421140967e-06,
      "loss": 0.0932,
      "step": 17199
    },
    {
      "epoch": 0.27233719144354546,
      "grad_norm": 0.5411405563354492,
      "learning_rate": 7.276628085564547e-06,
      "loss": 0.1342,
      "step": 17200
    },
    {
      "epoch": 0.2723530250011875,
      "grad_norm": 0.49187877774238586,
      "learning_rate": 7.276469749988126e-06,
      "loss": 0.226,
      "step": 17201
    },
    {
      "epoch": 0.2723688585588296,
      "grad_norm": 0.6424612998962402,
      "learning_rate": 7.276311414411706e-06,
      "loss": 0.4502,
      "step": 17202
    },
    {
      "epoch": 0.27238469211647165,
      "grad_norm": 0.03271961212158203,
      "learning_rate": 7.276153078835284e-06,
      "loss": 0.0015,
      "step": 17203
    },
    {
      "epoch": 0.2724005256741137,
      "grad_norm": 0.011817767284810543,
      "learning_rate": 7.275994743258863e-06,
      "loss": 0.0004,
      "step": 17204
    },
    {
      "epoch": 0.2724163592317558,
      "grad_norm": 0.2473263144493103,
      "learning_rate": 7.275836407682443e-06,
      "loss": 0.0729,
      "step": 17205
    },
    {
      "epoch": 0.27243219278939784,
      "grad_norm": 0.20335857570171356,
      "learning_rate": 7.275678072106022e-06,
      "loss": 0.0317,
      "step": 17206
    },
    {
      "epoch": 0.2724480263470399,
      "grad_norm": 0.8147637844085693,
      "learning_rate": 7.275519736529602e-06,
      "loss": 0.5649,
      "step": 17207
    },
    {
      "epoch": 0.27246385990468197,
      "grad_norm": 0.3482634425163269,
      "learning_rate": 7.27536140095318e-06,
      "loss": 0.1072,
      "step": 17208
    },
    {
      "epoch": 0.27247969346232404,
      "grad_norm": 2.3268048763275146,
      "learning_rate": 7.27520306537676e-06,
      "loss": 0.4156,
      "step": 17209
    },
    {
      "epoch": 0.2724955270199661,
      "grad_norm": 0.5152813196182251,
      "learning_rate": 7.275044729800339e-06,
      "loss": 0.5006,
      "step": 17210
    },
    {
      "epoch": 0.27251136057760816,
      "grad_norm": 0.34061750769615173,
      "learning_rate": 7.274886394223919e-06,
      "loss": 0.1048,
      "step": 17211
    },
    {
      "epoch": 0.27252719413525023,
      "grad_norm": 0.6841232180595398,
      "learning_rate": 7.274728058647498e-06,
      "loss": 0.1872,
      "step": 17212
    },
    {
      "epoch": 0.2725430276928923,
      "grad_norm": 0.3245700001716614,
      "learning_rate": 7.274569723071078e-06,
      "loss": 0.0956,
      "step": 17213
    },
    {
      "epoch": 0.27255886125053436,
      "grad_norm": 3.4342498779296875,
      "learning_rate": 7.274411387494656e-06,
      "loss": 0.153,
      "step": 17214
    },
    {
      "epoch": 0.2725746948081765,
      "grad_norm": 0.022669954225420952,
      "learning_rate": 7.274253051918236e-06,
      "loss": 0.001,
      "step": 17215
    },
    {
      "epoch": 0.27259052836581854,
      "grad_norm": 0.5001983046531677,
      "learning_rate": 7.274094716341815e-06,
      "loss": 0.2572,
      "step": 17216
    },
    {
      "epoch": 0.2726063619234606,
      "grad_norm": 0.5258707404136658,
      "learning_rate": 7.273936380765395e-06,
      "loss": 0.1404,
      "step": 17217
    },
    {
      "epoch": 0.27262219548110267,
      "grad_norm": 0.23810207843780518,
      "learning_rate": 7.2737780451889735e-06,
      "loss": 0.0624,
      "step": 17218
    },
    {
      "epoch": 0.27263802903874473,
      "grad_norm": 0.4896896481513977,
      "learning_rate": 7.273619709612553e-06,
      "loss": 0.0543,
      "step": 17219
    },
    {
      "epoch": 0.2726538625963868,
      "grad_norm": 0.36486905813217163,
      "learning_rate": 7.2734613740361325e-06,
      "loss": 0.1266,
      "step": 17220
    },
    {
      "epoch": 0.27266969615402886,
      "grad_norm": 0.3514418303966522,
      "learning_rate": 7.273303038459712e-06,
      "loss": 0.0996,
      "step": 17221
    },
    {
      "epoch": 0.2726855297116709,
      "grad_norm": 0.6558048129081726,
      "learning_rate": 7.2731447028832915e-06,
      "loss": 0.1138,
      "step": 17222
    },
    {
      "epoch": 0.272701363269313,
      "grad_norm": 0.6047001481056213,
      "learning_rate": 7.272986367306871e-06,
      "loss": 0.351,
      "step": 17223
    },
    {
      "epoch": 0.27271719682695506,
      "grad_norm": 0.5850541591644287,
      "learning_rate": 7.27282803173045e-06,
      "loss": 0.083,
      "step": 17224
    },
    {
      "epoch": 0.2727330303845971,
      "grad_norm": 0.08532606065273285,
      "learning_rate": 7.27266969615403e-06,
      "loss": 0.0078,
      "step": 17225
    },
    {
      "epoch": 0.2727488639422392,
      "grad_norm": 0.00012501765741035342,
      "learning_rate": 7.272511360577609e-06,
      "loss": 0.0,
      "step": 17226
    },
    {
      "epoch": 0.27276469749988125,
      "grad_norm": 0.069887176156044,
      "learning_rate": 7.272353025001188e-06,
      "loss": 0.0053,
      "step": 17227
    },
    {
      "epoch": 0.2727805310575233,
      "grad_norm": 0.30120649933815,
      "learning_rate": 7.272194689424768e-06,
      "loss": 0.0422,
      "step": 17228
    },
    {
      "epoch": 0.2727963646151654,
      "grad_norm": 0.6219019889831543,
      "learning_rate": 7.272036353848346e-06,
      "loss": 0.2419,
      "step": 17229
    },
    {
      "epoch": 0.27281219817280744,
      "grad_norm": 0.2741793096065521,
      "learning_rate": 7.271878018271926e-06,
      "loss": 0.1454,
      "step": 17230
    },
    {
      "epoch": 0.2728280317304495,
      "grad_norm": 0.00031512550776824355,
      "learning_rate": 7.271719682695505e-06,
      "loss": 0.0,
      "step": 17231
    },
    {
      "epoch": 0.27284386528809157,
      "grad_norm": 0.21722601354122162,
      "learning_rate": 7.271561347119085e-06,
      "loss": 0.0598,
      "step": 17232
    },
    {
      "epoch": 0.27285969884573363,
      "grad_norm": 0.562933623790741,
      "learning_rate": 7.271403011542664e-06,
      "loss": 0.1959,
      "step": 17233
    },
    {
      "epoch": 0.2728755324033757,
      "grad_norm": 0.6928890347480774,
      "learning_rate": 7.271244675966244e-06,
      "loss": 0.2957,
      "step": 17234
    },
    {
      "epoch": 0.27289136596101776,
      "grad_norm": 1.2764217853546143,
      "learning_rate": 7.271086340389822e-06,
      "loss": 0.6205,
      "step": 17235
    },
    {
      "epoch": 0.2729071995186598,
      "grad_norm": 0.21812455356121063,
      "learning_rate": 7.270928004813402e-06,
      "loss": 0.0667,
      "step": 17236
    },
    {
      "epoch": 0.2729230330763019,
      "grad_norm": 0.06347223371267319,
      "learning_rate": 7.270769669236981e-06,
      "loss": 0.0035,
      "step": 17237
    },
    {
      "epoch": 0.27293886663394396,
      "grad_norm": 0.5480811595916748,
      "learning_rate": 7.270611333660561e-06,
      "loss": 0.192,
      "step": 17238
    },
    {
      "epoch": 0.2729547001915861,
      "grad_norm": 1.1883825063705444,
      "learning_rate": 7.27045299808414e-06,
      "loss": 0.6828,
      "step": 17239
    },
    {
      "epoch": 0.27297053374922814,
      "grad_norm": 0.6777796745300293,
      "learning_rate": 7.27029466250772e-06,
      "loss": 0.2054,
      "step": 17240
    },
    {
      "epoch": 0.2729863673068702,
      "grad_norm": 0.4536808133125305,
      "learning_rate": 7.270136326931298e-06,
      "loss": 0.3113,
      "step": 17241
    },
    {
      "epoch": 0.27300220086451227,
      "grad_norm": 0.30855539441108704,
      "learning_rate": 7.269977991354878e-06,
      "loss": 0.0743,
      "step": 17242
    },
    {
      "epoch": 0.27301803442215433,
      "grad_norm": 0.9034211039543152,
      "learning_rate": 7.269819655778457e-06,
      "loss": 0.2886,
      "step": 17243
    },
    {
      "epoch": 0.2730338679797964,
      "grad_norm": 0.4491199851036072,
      "learning_rate": 7.269661320202037e-06,
      "loss": 0.0487,
      "step": 17244
    },
    {
      "epoch": 0.27304970153743846,
      "grad_norm": 0.12175549566745758,
      "learning_rate": 7.269502984625616e-06,
      "loss": 0.0029,
      "step": 17245
    },
    {
      "epoch": 0.2730655350950805,
      "grad_norm": 0.001488608424551785,
      "learning_rate": 7.269344649049196e-06,
      "loss": 0.0,
      "step": 17246
    },
    {
      "epoch": 0.2730813686527226,
      "grad_norm": 0.006922819651663303,
      "learning_rate": 7.269186313472774e-06,
      "loss": 0.0002,
      "step": 17247
    },
    {
      "epoch": 0.27309720221036465,
      "grad_norm": 0.4165705740451813,
      "learning_rate": 7.269027977896354e-06,
      "loss": 0.1127,
      "step": 17248
    },
    {
      "epoch": 0.2731130357680067,
      "grad_norm": 0.2875964045524597,
      "learning_rate": 7.268869642319933e-06,
      "loss": 0.0444,
      "step": 17249
    },
    {
      "epoch": 0.2731288693256488,
      "grad_norm": 0.2563353180885315,
      "learning_rate": 7.268711306743513e-06,
      "loss": 0.0847,
      "step": 17250
    },
    {
      "epoch": 0.27314470288329085,
      "grad_norm": 0.18059217929840088,
      "learning_rate": 7.2685529711670924e-06,
      "loss": 0.0305,
      "step": 17251
    },
    {
      "epoch": 0.2731605364409329,
      "grad_norm": 0.027851946651935577,
      "learning_rate": 7.268394635590671e-06,
      "loss": 0.0015,
      "step": 17252
    },
    {
      "epoch": 0.273176369998575,
      "grad_norm": 0.20250581204891205,
      "learning_rate": 7.268236300014251e-06,
      "loss": 0.0355,
      "step": 17253
    },
    {
      "epoch": 0.27319220355621704,
      "grad_norm": 0.8389174342155457,
      "learning_rate": 7.26807796443783e-06,
      "loss": 0.2501,
      "step": 17254
    },
    {
      "epoch": 0.2732080371138591,
      "grad_norm": 0.9516313076019287,
      "learning_rate": 7.26791962886141e-06,
      "loss": 1.1115,
      "step": 17255
    },
    {
      "epoch": 0.27322387067150117,
      "grad_norm": 0.06196668744087219,
      "learning_rate": 7.267761293284989e-06,
      "loss": 0.0054,
      "step": 17256
    },
    {
      "epoch": 0.27323970422914323,
      "grad_norm": 0.8158076405525208,
      "learning_rate": 7.267602957708569e-06,
      "loss": 0.1386,
      "step": 17257
    },
    {
      "epoch": 0.2732555377867853,
      "grad_norm": 0.29521942138671875,
      "learning_rate": 7.267444622132147e-06,
      "loss": 0.1372,
      "step": 17258
    },
    {
      "epoch": 0.27327137134442736,
      "grad_norm": 0.3293151557445526,
      "learning_rate": 7.267286286555727e-06,
      "loss": 0.16,
      "step": 17259
    },
    {
      "epoch": 0.2732872049020694,
      "grad_norm": 0.06410562247037888,
      "learning_rate": 7.267127950979306e-06,
      "loss": 0.0027,
      "step": 17260
    },
    {
      "epoch": 0.2733030384597115,
      "grad_norm": 0.2210758477449417,
      "learning_rate": 7.266969615402886e-06,
      "loss": 0.063,
      "step": 17261
    },
    {
      "epoch": 0.27331887201735355,
      "grad_norm": 1.5188508033752441,
      "learning_rate": 7.266811279826465e-06,
      "loss": 0.2798,
      "step": 17262
    },
    {
      "epoch": 0.2733347055749957,
      "grad_norm": 0.0002469942846801132,
      "learning_rate": 7.266652944250045e-06,
      "loss": 0.0,
      "step": 17263
    },
    {
      "epoch": 0.27335053913263774,
      "grad_norm": 0.5135107040405273,
      "learning_rate": 7.266494608673623e-06,
      "loss": 0.3219,
      "step": 17264
    },
    {
      "epoch": 0.2733663726902798,
      "grad_norm": 0.6834215521812439,
      "learning_rate": 7.266336273097203e-06,
      "loss": 0.3335,
      "step": 17265
    },
    {
      "epoch": 0.27338220624792187,
      "grad_norm": 0.617365300655365,
      "learning_rate": 7.266177937520782e-06,
      "loss": 0.1721,
      "step": 17266
    },
    {
      "epoch": 0.27339803980556393,
      "grad_norm": 0.014674979262053967,
      "learning_rate": 7.266019601944362e-06,
      "loss": 0.0006,
      "step": 17267
    },
    {
      "epoch": 0.273413873363206,
      "grad_norm": 0.285176545381546,
      "learning_rate": 7.265861266367941e-06,
      "loss": 0.1478,
      "step": 17268
    },
    {
      "epoch": 0.27342970692084806,
      "grad_norm": 0.005242484156042337,
      "learning_rate": 7.265702930791521e-06,
      "loss": 0.0002,
      "step": 17269
    },
    {
      "epoch": 0.2734455404784901,
      "grad_norm": 0.32890719175338745,
      "learning_rate": 7.265544595215099e-06,
      "loss": 0.1187,
      "step": 17270
    },
    {
      "epoch": 0.2734613740361322,
      "grad_norm": 0.011516546830534935,
      "learning_rate": 7.265386259638679e-06,
      "loss": 0.0005,
      "step": 17271
    },
    {
      "epoch": 0.27347720759377425,
      "grad_norm": 0.3301892876625061,
      "learning_rate": 7.265227924062258e-06,
      "loss": 0.0555,
      "step": 17272
    },
    {
      "epoch": 0.2734930411514163,
      "grad_norm": 0.7910768985748291,
      "learning_rate": 7.265069588485838e-06,
      "loss": 0.2222,
      "step": 17273
    },
    {
      "epoch": 0.2735088747090584,
      "grad_norm": 0.46738842129707336,
      "learning_rate": 7.264911252909417e-06,
      "loss": 0.3527,
      "step": 17274
    },
    {
      "epoch": 0.27352470826670044,
      "grad_norm": 0.43383875489234924,
      "learning_rate": 7.264752917332995e-06,
      "loss": 0.0311,
      "step": 17275
    },
    {
      "epoch": 0.2735405418243425,
      "grad_norm": 0.007931067608296871,
      "learning_rate": 7.264594581756575e-06,
      "loss": 0.0003,
      "step": 17276
    },
    {
      "epoch": 0.2735563753819846,
      "grad_norm": 0.21381786465644836,
      "learning_rate": 7.2644362461801544e-06,
      "loss": 0.0399,
      "step": 17277
    },
    {
      "epoch": 0.27357220893962664,
      "grad_norm": 0.7239548563957214,
      "learning_rate": 7.264277910603734e-06,
      "loss": 0.128,
      "step": 17278
    },
    {
      "epoch": 0.2735880424972687,
      "grad_norm": 0.8672429919242859,
      "learning_rate": 7.2641195750273134e-06,
      "loss": 0.1752,
      "step": 17279
    },
    {
      "epoch": 0.27360387605491077,
      "grad_norm": 0.7166152596473694,
      "learning_rate": 7.2639612394508925e-06,
      "loss": 0.2675,
      "step": 17280
    },
    {
      "epoch": 0.27361970961255283,
      "grad_norm": 0.45808669924736023,
      "learning_rate": 7.263802903874472e-06,
      "loss": 0.1472,
      "step": 17281
    },
    {
      "epoch": 0.2736355431701949,
      "grad_norm": 0.049263447523117065,
      "learning_rate": 7.2636445682980515e-06,
      "loss": 0.0029,
      "step": 17282
    },
    {
      "epoch": 0.27365137672783696,
      "grad_norm": 0.3426576256752014,
      "learning_rate": 7.263486232721631e-06,
      "loss": 0.075,
      "step": 17283
    },
    {
      "epoch": 0.273667210285479,
      "grad_norm": 0.9199325442314148,
      "learning_rate": 7.2633278971452105e-06,
      "loss": 0.1675,
      "step": 17284
    },
    {
      "epoch": 0.2736830438431211,
      "grad_norm": 0.1977856308221817,
      "learning_rate": 7.263169561568789e-06,
      "loss": 0.0784,
      "step": 17285
    },
    {
      "epoch": 0.27369887740076315,
      "grad_norm": 1.0625824928283691,
      "learning_rate": 7.263011225992369e-06,
      "loss": 0.4518,
      "step": 17286
    },
    {
      "epoch": 0.27371471095840527,
      "grad_norm": 0.6607850790023804,
      "learning_rate": 7.262852890415948e-06,
      "loss": 0.0496,
      "step": 17287
    },
    {
      "epoch": 0.27373054451604734,
      "grad_norm": 0.058075569570064545,
      "learning_rate": 7.262694554839528e-06,
      "loss": 0.0032,
      "step": 17288
    },
    {
      "epoch": 0.2737463780736894,
      "grad_norm": 0.744594395160675,
      "learning_rate": 7.262536219263107e-06,
      "loss": 0.3725,
      "step": 17289
    },
    {
      "epoch": 0.27376221163133146,
      "grad_norm": 0.000250843761023134,
      "learning_rate": 7.262377883686687e-06,
      "loss": 0.0,
      "step": 17290
    },
    {
      "epoch": 0.27377804518897353,
      "grad_norm": 0.08459712564945221,
      "learning_rate": 7.262219548110265e-06,
      "loss": 0.0029,
      "step": 17291
    },
    {
      "epoch": 0.2737938787466156,
      "grad_norm": 0.028096944093704224,
      "learning_rate": 7.262061212533845e-06,
      "loss": 0.0016,
      "step": 17292
    },
    {
      "epoch": 0.27380971230425766,
      "grad_norm": 0.4880295991897583,
      "learning_rate": 7.261902876957424e-06,
      "loss": 0.1135,
      "step": 17293
    },
    {
      "epoch": 0.2738255458618997,
      "grad_norm": 0.15240782499313354,
      "learning_rate": 7.261744541381004e-06,
      "loss": 0.03,
      "step": 17294
    },
    {
      "epoch": 0.2738413794195418,
      "grad_norm": 0.8751502633094788,
      "learning_rate": 7.261586205804583e-06,
      "loss": 0.2039,
      "step": 17295
    },
    {
      "epoch": 0.27385721297718385,
      "grad_norm": 0.36209696531295776,
      "learning_rate": 7.261427870228163e-06,
      "loss": 0.0913,
      "step": 17296
    },
    {
      "epoch": 0.2738730465348259,
      "grad_norm": 0.0680483803153038,
      "learning_rate": 7.261269534651741e-06,
      "loss": 0.0055,
      "step": 17297
    },
    {
      "epoch": 0.273888880092468,
      "grad_norm": 0.7715736031532288,
      "learning_rate": 7.261111199075321e-06,
      "loss": 0.202,
      "step": 17298
    },
    {
      "epoch": 0.27390471365011004,
      "grad_norm": 0.01932254619896412,
      "learning_rate": 7.2609528634989e-06,
      "loss": 0.001,
      "step": 17299
    },
    {
      "epoch": 0.2739205472077521,
      "grad_norm": 0.3431849479675293,
      "learning_rate": 7.260794527922479e-06,
      "loss": 0.1716,
      "step": 17300
    },
    {
      "epoch": 0.27393638076539417,
      "grad_norm": 0.01805947534739971,
      "learning_rate": 7.260636192346059e-06,
      "loss": 0.0008,
      "step": 17301
    },
    {
      "epoch": 0.27395221432303624,
      "grad_norm": 0.4213765263557434,
      "learning_rate": 7.260477856769637e-06,
      "loss": 0.0231,
      "step": 17302
    },
    {
      "epoch": 0.2739680478806783,
      "grad_norm": 0.27076536417007446,
      "learning_rate": 7.260319521193217e-06,
      "loss": 0.0141,
      "step": 17303
    },
    {
      "epoch": 0.27398388143832036,
      "grad_norm": 0.25299280881881714,
      "learning_rate": 7.260161185616796e-06,
      "loss": 0.0952,
      "step": 17304
    },
    {
      "epoch": 0.27399971499596243,
      "grad_norm": 0.5532211661338806,
      "learning_rate": 7.260002850040376e-06,
      "loss": 0.1352,
      "step": 17305
    },
    {
      "epoch": 0.2740155485536045,
      "grad_norm": 0.12031888216733932,
      "learning_rate": 7.259844514463955e-06,
      "loss": 0.0517,
      "step": 17306
    },
    {
      "epoch": 0.27403138211124656,
      "grad_norm": 0.019435731694102287,
      "learning_rate": 7.259686178887535e-06,
      "loss": 0.0013,
      "step": 17307
    },
    {
      "epoch": 0.2740472156688886,
      "grad_norm": 0.23223021626472473,
      "learning_rate": 7.2595278433111135e-06,
      "loss": 0.0933,
      "step": 17308
    },
    {
      "epoch": 0.2740630492265307,
      "grad_norm": 1.5862393379211426,
      "learning_rate": 7.2593695077346934e-06,
      "loss": 0.185,
      "step": 17309
    },
    {
      "epoch": 0.27407888278417275,
      "grad_norm": 0.22534699738025665,
      "learning_rate": 7.2592111721582725e-06,
      "loss": 0.0068,
      "step": 17310
    },
    {
      "epoch": 0.2740947163418148,
      "grad_norm": 0.22797851264476776,
      "learning_rate": 7.2590528365818524e-06,
      "loss": 0.1086,
      "step": 17311
    },
    {
      "epoch": 0.27411054989945693,
      "grad_norm": 0.46304798126220703,
      "learning_rate": 7.2588945010054315e-06,
      "loss": 0.136,
      "step": 17312
    },
    {
      "epoch": 0.274126383457099,
      "grad_norm": 0.0038275676779448986,
      "learning_rate": 7.2587361654290115e-06,
      "loss": 0.0003,
      "step": 17313
    },
    {
      "epoch": 0.27414221701474106,
      "grad_norm": 0.0022992088925093412,
      "learning_rate": 7.25857782985259e-06,
      "loss": 0.0001,
      "step": 17314
    },
    {
      "epoch": 0.2741580505723831,
      "grad_norm": 0.013331249356269836,
      "learning_rate": 7.25841949427617e-06,
      "loss": 0.0008,
      "step": 17315
    },
    {
      "epoch": 0.2741738841300252,
      "grad_norm": 0.5581871271133423,
      "learning_rate": 7.258261158699749e-06,
      "loss": 0.2227,
      "step": 17316
    },
    {
      "epoch": 0.27418971768766726,
      "grad_norm": 0.6252429485321045,
      "learning_rate": 7.258102823123329e-06,
      "loss": 0.6424,
      "step": 17317
    },
    {
      "epoch": 0.2742055512453093,
      "grad_norm": 0.5010267496109009,
      "learning_rate": 7.257944487546908e-06,
      "loss": 0.0893,
      "step": 17318
    },
    {
      "epoch": 0.2742213848029514,
      "grad_norm": 0.25250107049942017,
      "learning_rate": 7.257786151970488e-06,
      "loss": 0.0262,
      "step": 17319
    },
    {
      "epoch": 0.27423721836059345,
      "grad_norm": 0.4573238790035248,
      "learning_rate": 7.257627816394066e-06,
      "loss": 0.1791,
      "step": 17320
    },
    {
      "epoch": 0.2742530519182355,
      "grad_norm": 0.702996015548706,
      "learning_rate": 7.257469480817646e-06,
      "loss": 0.3915,
      "step": 17321
    },
    {
      "epoch": 0.2742688854758776,
      "grad_norm": 0.025635313242673874,
      "learning_rate": 7.257311145241225e-06,
      "loss": 0.0014,
      "step": 17322
    },
    {
      "epoch": 0.27428471903351964,
      "grad_norm": 0.6287153959274292,
      "learning_rate": 7.257152809664805e-06,
      "loss": 0.1496,
      "step": 17323
    },
    {
      "epoch": 0.2743005525911617,
      "grad_norm": 0.3603670299053192,
      "learning_rate": 7.256994474088384e-06,
      "loss": 0.1932,
      "step": 17324
    },
    {
      "epoch": 0.27431638614880377,
      "grad_norm": 0.0003959716996178031,
      "learning_rate": 7.256836138511962e-06,
      "loss": 0.0,
      "step": 17325
    },
    {
      "epoch": 0.27433221970644583,
      "grad_norm": 0.4805431365966797,
      "learning_rate": 7.256677802935542e-06,
      "loss": 0.1346,
      "step": 17326
    },
    {
      "epoch": 0.2743480532640879,
      "grad_norm": 0.5070105791091919,
      "learning_rate": 7.256519467359121e-06,
      "loss": 0.2449,
      "step": 17327
    },
    {
      "epoch": 0.27436388682172996,
      "grad_norm": 0.023440120741724968,
      "learning_rate": 7.256361131782701e-06,
      "loss": 0.0014,
      "step": 17328
    },
    {
      "epoch": 0.274379720379372,
      "grad_norm": 0.37293344736099243,
      "learning_rate": 7.25620279620628e-06,
      "loss": 0.1953,
      "step": 17329
    },
    {
      "epoch": 0.2743955539370141,
      "grad_norm": 0.15903201699256897,
      "learning_rate": 7.25604446062986e-06,
      "loss": 0.0924,
      "step": 17330
    },
    {
      "epoch": 0.27441138749465616,
      "grad_norm": 0.4303306043148041,
      "learning_rate": 7.255886125053438e-06,
      "loss": 0.191,
      "step": 17331
    },
    {
      "epoch": 0.2744272210522982,
      "grad_norm": 0.0053898668847978115,
      "learning_rate": 7.255727789477018e-06,
      "loss": 0.0002,
      "step": 17332
    },
    {
      "epoch": 0.2744430546099403,
      "grad_norm": 0.2259293496608734,
      "learning_rate": 7.255569453900597e-06,
      "loss": 0.054,
      "step": 17333
    },
    {
      "epoch": 0.27445888816758235,
      "grad_norm": 1.9052470922470093,
      "learning_rate": 7.255411118324177e-06,
      "loss": 0.9579,
      "step": 17334
    },
    {
      "epoch": 0.2744747217252244,
      "grad_norm": 0.648091197013855,
      "learning_rate": 7.255252782747756e-06,
      "loss": 0.0355,
      "step": 17335
    },
    {
      "epoch": 0.27449055528286653,
      "grad_norm": 0.5549638867378235,
      "learning_rate": 7.255094447171336e-06,
      "loss": 0.1297,
      "step": 17336
    },
    {
      "epoch": 0.2745063888405086,
      "grad_norm": 0.4244753122329712,
      "learning_rate": 7.2549361115949144e-06,
      "loss": 0.1397,
      "step": 17337
    },
    {
      "epoch": 0.27452222239815066,
      "grad_norm": 0.2811569273471832,
      "learning_rate": 7.254777776018494e-06,
      "loss": 0.028,
      "step": 17338
    },
    {
      "epoch": 0.2745380559557927,
      "grad_norm": 0.7522943019866943,
      "learning_rate": 7.2546194404420735e-06,
      "loss": 0.1461,
      "step": 17339
    },
    {
      "epoch": 0.2745538895134348,
      "grad_norm": 0.0892009437084198,
      "learning_rate": 7.254461104865653e-06,
      "loss": 0.0056,
      "step": 17340
    },
    {
      "epoch": 0.27456972307107685,
      "grad_norm": 0.05239095538854599,
      "learning_rate": 7.2543027692892325e-06,
      "loss": 0.0028,
      "step": 17341
    },
    {
      "epoch": 0.2745855566287189,
      "grad_norm": 0.3545137345790863,
      "learning_rate": 7.254144433712812e-06,
      "loss": 0.0959,
      "step": 17342
    },
    {
      "epoch": 0.274601390186361,
      "grad_norm": 0.5691713690757751,
      "learning_rate": 7.253986098136391e-06,
      "loss": 0.2522,
      "step": 17343
    },
    {
      "epoch": 0.27461722374400305,
      "grad_norm": 0.013717089779675007,
      "learning_rate": 7.2538277625599705e-06,
      "loss": 0.0008,
      "step": 17344
    },
    {
      "epoch": 0.2746330573016451,
      "grad_norm": 0.3556370437145233,
      "learning_rate": 7.25366942698355e-06,
      "loss": 0.099,
      "step": 17345
    },
    {
      "epoch": 0.2746488908592872,
      "grad_norm": 0.21826790273189545,
      "learning_rate": 7.2535110914071295e-06,
      "loss": 0.0969,
      "step": 17346
    },
    {
      "epoch": 0.27466472441692924,
      "grad_norm": 0.17024341225624084,
      "learning_rate": 7.253352755830708e-06,
      "loss": 0.031,
      "step": 17347
    },
    {
      "epoch": 0.2746805579745713,
      "grad_norm": 0.01180349476635456,
      "learning_rate": 7.253194420254287e-06,
      "loss": 0.0007,
      "step": 17348
    },
    {
      "epoch": 0.27469639153221337,
      "grad_norm": 0.30711397528648376,
      "learning_rate": 7.253036084677867e-06,
      "loss": 0.052,
      "step": 17349
    },
    {
      "epoch": 0.27471222508985543,
      "grad_norm": 0.8880987763404846,
      "learning_rate": 7.252877749101446e-06,
      "loss": 0.1374,
      "step": 17350
    },
    {
      "epoch": 0.2747280586474975,
      "grad_norm": 0.5602708458900452,
      "learning_rate": 7.252719413525026e-06,
      "loss": 0.1103,
      "step": 17351
    },
    {
      "epoch": 0.27474389220513956,
      "grad_norm": 0.037265148013830185,
      "learning_rate": 7.252561077948604e-06,
      "loss": 0.0008,
      "step": 17352
    },
    {
      "epoch": 0.2747597257627816,
      "grad_norm": 0.3880540132522583,
      "learning_rate": 7.252402742372184e-06,
      "loss": 0.1972,
      "step": 17353
    },
    {
      "epoch": 0.2747755593204237,
      "grad_norm": 0.41138267517089844,
      "learning_rate": 7.252244406795763e-06,
      "loss": 0.2144,
      "step": 17354
    },
    {
      "epoch": 0.27479139287806575,
      "grad_norm": 0.4535924792289734,
      "learning_rate": 7.252086071219343e-06,
      "loss": 0.0951,
      "step": 17355
    },
    {
      "epoch": 0.2748072264357078,
      "grad_norm": 0.9230633974075317,
      "learning_rate": 7.251927735642922e-06,
      "loss": 0.2868,
      "step": 17356
    },
    {
      "epoch": 0.2748230599933499,
      "grad_norm": 0.008407956920564175,
      "learning_rate": 7.251769400066502e-06,
      "loss": 0.0003,
      "step": 17357
    },
    {
      "epoch": 0.27483889355099195,
      "grad_norm": 0.006144271232187748,
      "learning_rate": 7.25161106449008e-06,
      "loss": 0.0003,
      "step": 17358
    },
    {
      "epoch": 0.274854727108634,
      "grad_norm": 0.57868492603302,
      "learning_rate": 7.25145272891366e-06,
      "loss": 0.1144,
      "step": 17359
    },
    {
      "epoch": 0.27487056066627613,
      "grad_norm": 0.8107051849365234,
      "learning_rate": 7.251294393337239e-06,
      "loss": 0.2388,
      "step": 17360
    },
    {
      "epoch": 0.2748863942239182,
      "grad_norm": 0.018751194700598717,
      "learning_rate": 7.251136057760819e-06,
      "loss": 0.0013,
      "step": 17361
    },
    {
      "epoch": 0.27490222778156026,
      "grad_norm": 0.3639444410800934,
      "learning_rate": 7.250977722184398e-06,
      "loss": 0.18,
      "step": 17362
    },
    {
      "epoch": 0.2749180613392023,
      "grad_norm": 0.8556704521179199,
      "learning_rate": 7.250819386607978e-06,
      "loss": 0.4967,
      "step": 17363
    },
    {
      "epoch": 0.2749338948968444,
      "grad_norm": 0.5698739290237427,
      "learning_rate": 7.250661051031556e-06,
      "loss": 0.0738,
      "step": 17364
    },
    {
      "epoch": 0.27494972845448645,
      "grad_norm": 0.005871962755918503,
      "learning_rate": 7.250502715455136e-06,
      "loss": 0.0002,
      "step": 17365
    },
    {
      "epoch": 0.2749655620121285,
      "grad_norm": 0.5219345092773438,
      "learning_rate": 7.250344379878715e-06,
      "loss": 0.5006,
      "step": 17366
    },
    {
      "epoch": 0.2749813955697706,
      "grad_norm": 0.021727267652750015,
      "learning_rate": 7.250186044302295e-06,
      "loss": 0.001,
      "step": 17367
    },
    {
      "epoch": 0.27499722912741265,
      "grad_norm": 0.20632043480873108,
      "learning_rate": 7.250027708725874e-06,
      "loss": 0.0469,
      "step": 17368
    },
    {
      "epoch": 0.2750130626850547,
      "grad_norm": 0.23779527842998505,
      "learning_rate": 7.249869373149454e-06,
      "loss": 0.067,
      "step": 17369
    },
    {
      "epoch": 0.2750288962426968,
      "grad_norm": 0.9224621057510376,
      "learning_rate": 7.2497110375730325e-06,
      "loss": 0.6133,
      "step": 17370
    },
    {
      "epoch": 0.27504472980033884,
      "grad_norm": 0.000772146217059344,
      "learning_rate": 7.2495527019966125e-06,
      "loss": 0.0,
      "step": 17371
    },
    {
      "epoch": 0.2750605633579809,
      "grad_norm": 0.43674713373184204,
      "learning_rate": 7.2493943664201915e-06,
      "loss": 0.14,
      "step": 17372
    },
    {
      "epoch": 0.27507639691562297,
      "grad_norm": 0.2912115454673767,
      "learning_rate": 7.249236030843771e-06,
      "loss": 0.1042,
      "step": 17373
    },
    {
      "epoch": 0.27509223047326503,
      "grad_norm": 0.019936123862862587,
      "learning_rate": 7.2490776952673506e-06,
      "loss": 0.0012,
      "step": 17374
    },
    {
      "epoch": 0.2751080640309071,
      "grad_norm": 0.004757192451506853,
      "learning_rate": 7.248919359690929e-06,
      "loss": 0.0001,
      "step": 17375
    },
    {
      "epoch": 0.27512389758854916,
      "grad_norm": 0.17085514962673187,
      "learning_rate": 7.248761024114509e-06,
      "loss": 0.0428,
      "step": 17376
    },
    {
      "epoch": 0.2751397311461912,
      "grad_norm": 0.004020373802632093,
      "learning_rate": 7.248602688538088e-06,
      "loss": 0.0002,
      "step": 17377
    },
    {
      "epoch": 0.2751555647038333,
      "grad_norm": 0.5686905980110168,
      "learning_rate": 7.248444352961668e-06,
      "loss": 0.5778,
      "step": 17378
    },
    {
      "epoch": 0.27517139826147535,
      "grad_norm": 0.8823404908180237,
      "learning_rate": 7.248286017385247e-06,
      "loss": 0.2091,
      "step": 17379
    },
    {
      "epoch": 0.2751872318191174,
      "grad_norm": 0.4139111340045929,
      "learning_rate": 7.248127681808827e-06,
      "loss": 0.1583,
      "step": 17380
    },
    {
      "epoch": 0.2752030653767595,
      "grad_norm": 0.4441568851470947,
      "learning_rate": 7.247969346232405e-06,
      "loss": 0.1312,
      "step": 17381
    },
    {
      "epoch": 0.27521889893440155,
      "grad_norm": 0.0002683674974832684,
      "learning_rate": 7.247811010655985e-06,
      "loss": 0.0,
      "step": 17382
    },
    {
      "epoch": 0.2752347324920436,
      "grad_norm": 0.32184362411499023,
      "learning_rate": 7.247652675079564e-06,
      "loss": 0.0156,
      "step": 17383
    },
    {
      "epoch": 0.27525056604968573,
      "grad_norm": 0.23367752134799957,
      "learning_rate": 7.247494339503144e-06,
      "loss": 0.1314,
      "step": 17384
    },
    {
      "epoch": 0.2752663996073278,
      "grad_norm": 0.6637683510780334,
      "learning_rate": 7.247336003926723e-06,
      "loss": 0.1352,
      "step": 17385
    },
    {
      "epoch": 0.27528223316496986,
      "grad_norm": 0.022133538499474525,
      "learning_rate": 7.247177668350303e-06,
      "loss": 0.0013,
      "step": 17386
    },
    {
      "epoch": 0.2752980667226119,
      "grad_norm": 0.7197412252426147,
      "learning_rate": 7.247019332773881e-06,
      "loss": 0.28,
      "step": 17387
    },
    {
      "epoch": 0.275313900280254,
      "grad_norm": 0.0160079188644886,
      "learning_rate": 7.246860997197461e-06,
      "loss": 0.0009,
      "step": 17388
    },
    {
      "epoch": 0.27532973383789605,
      "grad_norm": 0.6414257287979126,
      "learning_rate": 7.24670266162104e-06,
      "loss": 0.2366,
      "step": 17389
    },
    {
      "epoch": 0.2753455673955381,
      "grad_norm": 0.3552936315536499,
      "learning_rate": 7.24654432604462e-06,
      "loss": 0.1233,
      "step": 17390
    },
    {
      "epoch": 0.2753614009531802,
      "grad_norm": 0.5882493257522583,
      "learning_rate": 7.246385990468199e-06,
      "loss": 0.9506,
      "step": 17391
    },
    {
      "epoch": 0.27537723451082224,
      "grad_norm": 0.28789907693862915,
      "learning_rate": 7.246227654891779e-06,
      "loss": 0.0802,
      "step": 17392
    },
    {
      "epoch": 0.2753930680684643,
      "grad_norm": 0.4394710958003998,
      "learning_rate": 7.246069319315357e-06,
      "loss": 0.0691,
      "step": 17393
    },
    {
      "epoch": 0.2754089016261064,
      "grad_norm": 0.2818571925163269,
      "learning_rate": 7.245910983738937e-06,
      "loss": 0.0804,
      "step": 17394
    },
    {
      "epoch": 0.27542473518374844,
      "grad_norm": 0.7828707098960876,
      "learning_rate": 7.245752648162516e-06,
      "loss": 0.1939,
      "step": 17395
    },
    {
      "epoch": 0.2754405687413905,
      "grad_norm": 0.5416550636291504,
      "learning_rate": 7.245594312586095e-06,
      "loss": 0.1851,
      "step": 17396
    },
    {
      "epoch": 0.27545640229903257,
      "grad_norm": 0.009339201264083385,
      "learning_rate": 7.245435977009675e-06,
      "loss": 0.0004,
      "step": 17397
    },
    {
      "epoch": 0.27547223585667463,
      "grad_norm": 0.18739522993564606,
      "learning_rate": 7.2452776414332535e-06,
      "loss": 0.0399,
      "step": 17398
    },
    {
      "epoch": 0.2754880694143167,
      "grad_norm": 0.39352554082870483,
      "learning_rate": 7.2451193058568335e-06,
      "loss": 0.0878,
      "step": 17399
    },
    {
      "epoch": 0.27550390297195876,
      "grad_norm": 0.8461294770240784,
      "learning_rate": 7.2449609702804126e-06,
      "loss": 0.1982,
      "step": 17400
    },
    {
      "epoch": 0.2755197365296008,
      "grad_norm": 0.5255141258239746,
      "learning_rate": 7.2448026347039925e-06,
      "loss": 0.0413,
      "step": 17401
    },
    {
      "epoch": 0.2755355700872429,
      "grad_norm": 0.5628483891487122,
      "learning_rate": 7.2446442991275716e-06,
      "loss": 0.1431,
      "step": 17402
    },
    {
      "epoch": 0.27555140364488495,
      "grad_norm": 0.6529912352561951,
      "learning_rate": 7.2444859635511515e-06,
      "loss": 0.2223,
      "step": 17403
    },
    {
      "epoch": 0.275567237202527,
      "grad_norm": 0.3412536382675171,
      "learning_rate": 7.24432762797473e-06,
      "loss": 0.0539,
      "step": 17404
    },
    {
      "epoch": 0.2755830707601691,
      "grad_norm": 0.44324493408203125,
      "learning_rate": 7.24416929239831e-06,
      "loss": 0.1921,
      "step": 17405
    },
    {
      "epoch": 0.27559890431781114,
      "grad_norm": 0.20317310094833374,
      "learning_rate": 7.244010956821889e-06,
      "loss": 0.0612,
      "step": 17406
    },
    {
      "epoch": 0.2756147378754532,
      "grad_norm": 0.17853222787380219,
      "learning_rate": 7.243852621245469e-06,
      "loss": 0.0067,
      "step": 17407
    },
    {
      "epoch": 0.27563057143309533,
      "grad_norm": 0.36312809586524963,
      "learning_rate": 7.243694285669048e-06,
      "loss": 0.0986,
      "step": 17408
    },
    {
      "epoch": 0.2756464049907374,
      "grad_norm": 0.009586673229932785,
      "learning_rate": 7.243535950092627e-06,
      "loss": 0.0003,
      "step": 17409
    },
    {
      "epoch": 0.27566223854837946,
      "grad_norm": 0.9516617655754089,
      "learning_rate": 7.243377614516206e-06,
      "loss": 0.0643,
      "step": 17410
    },
    {
      "epoch": 0.2756780721060215,
      "grad_norm": 0.3363697826862335,
      "learning_rate": 7.243219278939786e-06,
      "loss": 0.0119,
      "step": 17411
    },
    {
      "epoch": 0.2756939056636636,
      "grad_norm": 0.018653837963938713,
      "learning_rate": 7.243060943363365e-06,
      "loss": 0.0008,
      "step": 17412
    },
    {
      "epoch": 0.27570973922130565,
      "grad_norm": 0.00483141141012311,
      "learning_rate": 7.242902607786945e-06,
      "loss": 0.0001,
      "step": 17413
    },
    {
      "epoch": 0.2757255727789477,
      "grad_norm": 0.3848595917224884,
      "learning_rate": 7.242744272210523e-06,
      "loss": 0.0235,
      "step": 17414
    },
    {
      "epoch": 0.2757414063365898,
      "grad_norm": 0.4993411600589752,
      "learning_rate": 7.242585936634103e-06,
      "loss": 0.1819,
      "step": 17415
    },
    {
      "epoch": 0.27575723989423184,
      "grad_norm": 0.38493695855140686,
      "learning_rate": 7.242427601057682e-06,
      "loss": 0.0769,
      "step": 17416
    },
    {
      "epoch": 0.2757730734518739,
      "grad_norm": 0.049981579184532166,
      "learning_rate": 7.242269265481262e-06,
      "loss": 0.003,
      "step": 17417
    },
    {
      "epoch": 0.27578890700951597,
      "grad_norm": 1.7607688903808594,
      "learning_rate": 7.242110929904841e-06,
      "loss": 0.6876,
      "step": 17418
    },
    {
      "epoch": 0.27580474056715804,
      "grad_norm": 0.47112223505973816,
      "learning_rate": 7.241952594328421e-06,
      "loss": 0.1395,
      "step": 17419
    },
    {
      "epoch": 0.2758205741248001,
      "grad_norm": 0.5727644562721252,
      "learning_rate": 7.241794258751999e-06,
      "loss": 0.1845,
      "step": 17420
    },
    {
      "epoch": 0.27583640768244216,
      "grad_norm": 0.30677083134651184,
      "learning_rate": 7.241635923175578e-06,
      "loss": 0.0708,
      "step": 17421
    },
    {
      "epoch": 0.27585224124008423,
      "grad_norm": 0.2405494898557663,
      "learning_rate": 7.241477587599158e-06,
      "loss": 0.0401,
      "step": 17422
    },
    {
      "epoch": 0.2758680747977263,
      "grad_norm": 0.5430765151977539,
      "learning_rate": 7.241319252022737e-06,
      "loss": 0.1926,
      "step": 17423
    },
    {
      "epoch": 0.27588390835536836,
      "grad_norm": 0.45103025436401367,
      "learning_rate": 7.241160916446317e-06,
      "loss": 0.0773,
      "step": 17424
    },
    {
      "epoch": 0.2758997419130104,
      "grad_norm": 0.3660331964492798,
      "learning_rate": 7.2410025808698955e-06,
      "loss": 0.1802,
      "step": 17425
    },
    {
      "epoch": 0.2759155754706525,
      "grad_norm": 0.33470624685287476,
      "learning_rate": 7.240844245293475e-06,
      "loss": 0.2879,
      "step": 17426
    },
    {
      "epoch": 0.27593140902829455,
      "grad_norm": 0.45764613151550293,
      "learning_rate": 7.2406859097170545e-06,
      "loss": 0.093,
      "step": 17427
    },
    {
      "epoch": 0.2759472425859366,
      "grad_norm": 0.2017270028591156,
      "learning_rate": 7.240527574140634e-06,
      "loss": 0.0616,
      "step": 17428
    },
    {
      "epoch": 0.2759630761435787,
      "grad_norm": 0.4088750183582306,
      "learning_rate": 7.2403692385642135e-06,
      "loss": 0.039,
      "step": 17429
    },
    {
      "epoch": 0.27597890970122074,
      "grad_norm": 0.20848624408245087,
      "learning_rate": 7.240210902987793e-06,
      "loss": 0.005,
      "step": 17430
    },
    {
      "epoch": 0.2759947432588628,
      "grad_norm": 0.40892964601516724,
      "learning_rate": 7.240052567411372e-06,
      "loss": 0.0657,
      "step": 17431
    },
    {
      "epoch": 0.2760105768165049,
      "grad_norm": 0.0016814925475046039,
      "learning_rate": 7.2398942318349516e-06,
      "loss": 0.0001,
      "step": 17432
    },
    {
      "epoch": 0.276026410374147,
      "grad_norm": 0.8262023329734802,
      "learning_rate": 7.239735896258531e-06,
      "loss": 0.0822,
      "step": 17433
    },
    {
      "epoch": 0.27604224393178906,
      "grad_norm": 0.7897324562072754,
      "learning_rate": 7.2395775606821106e-06,
      "loss": 0.3046,
      "step": 17434
    },
    {
      "epoch": 0.2760580774894311,
      "grad_norm": 0.01779625564813614,
      "learning_rate": 7.23941922510569e-06,
      "loss": 0.001,
      "step": 17435
    },
    {
      "epoch": 0.2760739110470732,
      "grad_norm": 0.1533835530281067,
      "learning_rate": 7.23926088952927e-06,
      "loss": 0.0438,
      "step": 17436
    },
    {
      "epoch": 0.27608974460471525,
      "grad_norm": 0.21715517342090607,
      "learning_rate": 7.239102553952848e-06,
      "loss": 0.0831,
      "step": 17437
    },
    {
      "epoch": 0.2761055781623573,
      "grad_norm": 0.46437183022499084,
      "learning_rate": 7.238944218376428e-06,
      "loss": 0.1027,
      "step": 17438
    },
    {
      "epoch": 0.2761214117199994,
      "grad_norm": 0.3237176835536957,
      "learning_rate": 7.238785882800007e-06,
      "loss": 0.0467,
      "step": 17439
    },
    {
      "epoch": 0.27613724527764144,
      "grad_norm": 0.4440516531467438,
      "learning_rate": 7.238627547223587e-06,
      "loss": 0.2017,
      "step": 17440
    },
    {
      "epoch": 0.2761530788352835,
      "grad_norm": 0.6429123282432556,
      "learning_rate": 7.238469211647166e-06,
      "loss": 0.2849,
      "step": 17441
    },
    {
      "epoch": 0.27616891239292557,
      "grad_norm": 0.2478729635477066,
      "learning_rate": 7.238310876070746e-06,
      "loss": 0.0832,
      "step": 17442
    },
    {
      "epoch": 0.27618474595056763,
      "grad_norm": 0.7306998372077942,
      "learning_rate": 7.238152540494324e-06,
      "loss": 0.4348,
      "step": 17443
    },
    {
      "epoch": 0.2762005795082097,
      "grad_norm": 0.1473105251789093,
      "learning_rate": 7.237994204917903e-06,
      "loss": 0.0091,
      "step": 17444
    },
    {
      "epoch": 0.27621641306585176,
      "grad_norm": 0.9356790781021118,
      "learning_rate": 7.237835869341483e-06,
      "loss": 0.8029,
      "step": 17445
    },
    {
      "epoch": 0.2762322466234938,
      "grad_norm": 0.009970424696803093,
      "learning_rate": 7.237677533765062e-06,
      "loss": 0.0005,
      "step": 17446
    },
    {
      "epoch": 0.2762480801811359,
      "grad_norm": 0.4284634292125702,
      "learning_rate": 7.237519198188642e-06,
      "loss": 0.0549,
      "step": 17447
    },
    {
      "epoch": 0.27626391373877796,
      "grad_norm": 0.4563528299331665,
      "learning_rate": 7.23736086261222e-06,
      "loss": 0.1991,
      "step": 17448
    },
    {
      "epoch": 0.27627974729642,
      "grad_norm": 0.25255781412124634,
      "learning_rate": 7.2372025270358e-06,
      "loss": 0.0961,
      "step": 17449
    },
    {
      "epoch": 0.2762955808540621,
      "grad_norm": 0.006752497516572475,
      "learning_rate": 7.237044191459379e-06,
      "loss": 0.0002,
      "step": 17450
    },
    {
      "epoch": 0.27631141441170415,
      "grad_norm": 0.029141345992684364,
      "learning_rate": 7.236885855882959e-06,
      "loss": 0.0018,
      "step": 17451
    },
    {
      "epoch": 0.2763272479693462,
      "grad_norm": 0.5104775428771973,
      "learning_rate": 7.236727520306538e-06,
      "loss": 0.1021,
      "step": 17452
    },
    {
      "epoch": 0.2763430815269883,
      "grad_norm": 0.5184447765350342,
      "learning_rate": 7.236569184730118e-06,
      "loss": 0.1063,
      "step": 17453
    },
    {
      "epoch": 0.27635891508463034,
      "grad_norm": 1.1660194396972656,
      "learning_rate": 7.236410849153696e-06,
      "loss": 0.3236,
      "step": 17454
    },
    {
      "epoch": 0.2763747486422724,
      "grad_norm": 0.00019690812041517347,
      "learning_rate": 7.236252513577276e-06,
      "loss": 0.0,
      "step": 17455
    },
    {
      "epoch": 0.2763905821999145,
      "grad_norm": 0.43633201718330383,
      "learning_rate": 7.236094178000855e-06,
      "loss": 0.0363,
      "step": 17456
    },
    {
      "epoch": 0.2764064157575566,
      "grad_norm": 0.01903967186808586,
      "learning_rate": 7.235935842424435e-06,
      "loss": 0.0012,
      "step": 17457
    },
    {
      "epoch": 0.27642224931519865,
      "grad_norm": 0.455159455537796,
      "learning_rate": 7.235777506848014e-06,
      "loss": 0.2465,
      "step": 17458
    },
    {
      "epoch": 0.2764380828728407,
      "grad_norm": 0.2527260184288025,
      "learning_rate": 7.235619171271594e-06,
      "loss": 0.0368,
      "step": 17459
    },
    {
      "epoch": 0.2764539164304828,
      "grad_norm": 0.46613916754722595,
      "learning_rate": 7.2354608356951726e-06,
      "loss": 0.1522,
      "step": 17460
    },
    {
      "epoch": 0.27646974998812485,
      "grad_norm": 0.028949491679668427,
      "learning_rate": 7.2353025001187525e-06,
      "loss": 0.0017,
      "step": 17461
    },
    {
      "epoch": 0.2764855835457669,
      "grad_norm": 0.3157193660736084,
      "learning_rate": 7.2351441645423316e-06,
      "loss": 0.0622,
      "step": 17462
    },
    {
      "epoch": 0.276501417103409,
      "grad_norm": 0.37489861249923706,
      "learning_rate": 7.2349858289659115e-06,
      "loss": 0.1298,
      "step": 17463
    },
    {
      "epoch": 0.27651725066105104,
      "grad_norm": 0.7976051568984985,
      "learning_rate": 7.234827493389491e-06,
      "loss": 0.0645,
      "step": 17464
    },
    {
      "epoch": 0.2765330842186931,
      "grad_norm": 0.44870829582214355,
      "learning_rate": 7.2346691578130705e-06,
      "loss": 0.1136,
      "step": 17465
    },
    {
      "epoch": 0.27654891777633517,
      "grad_norm": 0.4028679132461548,
      "learning_rate": 7.234510822236649e-06,
      "loss": 0.0837,
      "step": 17466
    },
    {
      "epoch": 0.27656475133397723,
      "grad_norm": 0.1948239952325821,
      "learning_rate": 7.234352486660229e-06,
      "loss": 0.0424,
      "step": 17467
    },
    {
      "epoch": 0.2765805848916193,
      "grad_norm": 0.3452153205871582,
      "learning_rate": 7.234194151083808e-06,
      "loss": 0.0432,
      "step": 17468
    },
    {
      "epoch": 0.27659641844926136,
      "grad_norm": 0.695091962814331,
      "learning_rate": 7.234035815507387e-06,
      "loss": 0.1325,
      "step": 17469
    },
    {
      "epoch": 0.2766122520069034,
      "grad_norm": 0.022273480892181396,
      "learning_rate": 7.233877479930967e-06,
      "loss": 0.0011,
      "step": 17470
    },
    {
      "epoch": 0.2766280855645455,
      "grad_norm": 0.004672933369874954,
      "learning_rate": 7.233719144354545e-06,
      "loss": 0.0002,
      "step": 17471
    },
    {
      "epoch": 0.27664391912218755,
      "grad_norm": 0.00011644104233710095,
      "learning_rate": 7.233560808778125e-06,
      "loss": 0.0,
      "step": 17472
    },
    {
      "epoch": 0.2766597526798296,
      "grad_norm": 0.3357304334640503,
      "learning_rate": 7.233402473201704e-06,
      "loss": 0.0963,
      "step": 17473
    },
    {
      "epoch": 0.2766755862374717,
      "grad_norm": 0.7934132814407349,
      "learning_rate": 7.233244137625284e-06,
      "loss": 0.2402,
      "step": 17474
    },
    {
      "epoch": 0.27669141979511375,
      "grad_norm": 0.33773505687713623,
      "learning_rate": 7.233085802048862e-06,
      "loss": 0.0787,
      "step": 17475
    },
    {
      "epoch": 0.2767072533527558,
      "grad_norm": 0.6845892667770386,
      "learning_rate": 7.232927466472442e-06,
      "loss": 0.2795,
      "step": 17476
    },
    {
      "epoch": 0.2767230869103979,
      "grad_norm": 0.0005466010770760477,
      "learning_rate": 7.232769130896021e-06,
      "loss": 0.0,
      "step": 17477
    },
    {
      "epoch": 0.27673892046803994,
      "grad_norm": 0.00047139794332906604,
      "learning_rate": 7.232610795319601e-06,
      "loss": 0.0,
      "step": 17478
    },
    {
      "epoch": 0.276754754025682,
      "grad_norm": 0.5329199433326721,
      "learning_rate": 7.23245245974318e-06,
      "loss": 0.076,
      "step": 17479
    },
    {
      "epoch": 0.2767705875833241,
      "grad_norm": 0.3509296476840973,
      "learning_rate": 7.23229412416676e-06,
      "loss": 0.1439,
      "step": 17480
    },
    {
      "epoch": 0.2767864211409662,
      "grad_norm": 0.15989644825458527,
      "learning_rate": 7.232135788590338e-06,
      "loss": 0.0417,
      "step": 17481
    },
    {
      "epoch": 0.27680225469860825,
      "grad_norm": 0.6884463429450989,
      "learning_rate": 7.231977453013918e-06,
      "loss": 0.1092,
      "step": 17482
    },
    {
      "epoch": 0.2768180882562503,
      "grad_norm": 0.35149067640304565,
      "learning_rate": 7.231819117437497e-06,
      "loss": 0.0316,
      "step": 17483
    },
    {
      "epoch": 0.2768339218138924,
      "grad_norm": 0.5816149711608887,
      "learning_rate": 7.231660781861077e-06,
      "loss": 0.24,
      "step": 17484
    },
    {
      "epoch": 0.27684975537153445,
      "grad_norm": 0.5597361326217651,
      "learning_rate": 7.231502446284656e-06,
      "loss": 0.5114,
      "step": 17485
    },
    {
      "epoch": 0.2768655889291765,
      "grad_norm": 0.4009365141391754,
      "learning_rate": 7.231344110708236e-06,
      "loss": 0.0944,
      "step": 17486
    },
    {
      "epoch": 0.2768814224868186,
      "grad_norm": 0.00013341692101676017,
      "learning_rate": 7.2311857751318145e-06,
      "loss": 0.0,
      "step": 17487
    },
    {
      "epoch": 0.27689725604446064,
      "grad_norm": 0.22648827731609344,
      "learning_rate": 7.231027439555394e-06,
      "loss": 0.0075,
      "step": 17488
    },
    {
      "epoch": 0.2769130896021027,
      "grad_norm": 0.0006451771478168666,
      "learning_rate": 7.2308691039789735e-06,
      "loss": 0.0,
      "step": 17489
    },
    {
      "epoch": 0.27692892315974477,
      "grad_norm": 0.6708545088768005,
      "learning_rate": 7.2307107684025534e-06,
      "loss": 0.1692,
      "step": 17490
    },
    {
      "epoch": 0.27694475671738683,
      "grad_norm": 0.17340178787708282,
      "learning_rate": 7.2305524328261325e-06,
      "loss": 0.0675,
      "step": 17491
    },
    {
      "epoch": 0.2769605902750289,
      "grad_norm": 0.337165504693985,
      "learning_rate": 7.230394097249711e-06,
      "loss": 0.1051,
      "step": 17492
    },
    {
      "epoch": 0.27697642383267096,
      "grad_norm": 0.009716330096125603,
      "learning_rate": 7.230235761673291e-06,
      "loss": 0.0005,
      "step": 17493
    },
    {
      "epoch": 0.276992257390313,
      "grad_norm": 0.004595103207975626,
      "learning_rate": 7.23007742609687e-06,
      "loss": 0.0002,
      "step": 17494
    },
    {
      "epoch": 0.2770080909479551,
      "grad_norm": 0.3012203574180603,
      "learning_rate": 7.22991909052045e-06,
      "loss": 0.0905,
      "step": 17495
    },
    {
      "epoch": 0.27702392450559715,
      "grad_norm": 0.056749001145362854,
      "learning_rate": 7.229760754944029e-06,
      "loss": 0.0033,
      "step": 17496
    },
    {
      "epoch": 0.2770397580632392,
      "grad_norm": 0.5759412050247192,
      "learning_rate": 7.229602419367609e-06,
      "loss": 0.1751,
      "step": 17497
    },
    {
      "epoch": 0.2770555916208813,
      "grad_norm": 0.24058844149112701,
      "learning_rate": 7.229444083791187e-06,
      "loss": 0.0288,
      "step": 17498
    },
    {
      "epoch": 0.27707142517852335,
      "grad_norm": 0.03465782105922699,
      "learning_rate": 7.229285748214767e-06,
      "loss": 0.0024,
      "step": 17499
    },
    {
      "epoch": 0.2770872587361654,
      "grad_norm": 0.34936225414276123,
      "learning_rate": 7.229127412638346e-06,
      "loss": 0.1105,
      "step": 17500
    },
    {
      "epoch": 0.2771030922938075,
      "grad_norm": 0.5901200175285339,
      "learning_rate": 7.228969077061926e-06,
      "loss": 0.098,
      "step": 17501
    },
    {
      "epoch": 0.27711892585144954,
      "grad_norm": 0.5832439064979553,
      "learning_rate": 7.228810741485505e-06,
      "loss": 0.0437,
      "step": 17502
    },
    {
      "epoch": 0.2771347594090916,
      "grad_norm": 0.6288256645202637,
      "learning_rate": 7.228652405909085e-06,
      "loss": 0.2864,
      "step": 17503
    },
    {
      "epoch": 0.2771505929667337,
      "grad_norm": 0.047991711646318436,
      "learning_rate": 7.228494070332663e-06,
      "loss": 0.0023,
      "step": 17504
    },
    {
      "epoch": 0.2771664265243758,
      "grad_norm": 0.534592866897583,
      "learning_rate": 7.228335734756243e-06,
      "loss": 0.1706,
      "step": 17505
    },
    {
      "epoch": 0.27718226008201785,
      "grad_norm": 0.5789686441421509,
      "learning_rate": 7.228177399179822e-06,
      "loss": 0.1016,
      "step": 17506
    },
    {
      "epoch": 0.2771980936396599,
      "grad_norm": 0.8496679663658142,
      "learning_rate": 7.228019063603402e-06,
      "loss": 0.5622,
      "step": 17507
    },
    {
      "epoch": 0.277213927197302,
      "grad_norm": 0.2526837885379791,
      "learning_rate": 7.227860728026981e-06,
      "loss": 0.0383,
      "step": 17508
    },
    {
      "epoch": 0.27722976075494404,
      "grad_norm": 0.4603220522403717,
      "learning_rate": 7.227702392450561e-06,
      "loss": 0.2373,
      "step": 17509
    },
    {
      "epoch": 0.2772455943125861,
      "grad_norm": 0.38358762860298157,
      "learning_rate": 7.227544056874139e-06,
      "loss": 0.151,
      "step": 17510
    },
    {
      "epoch": 0.27726142787022817,
      "grad_norm": 0.09636933356523514,
      "learning_rate": 7.227385721297719e-06,
      "loss": 0.0041,
      "step": 17511
    },
    {
      "epoch": 0.27727726142787024,
      "grad_norm": 0.0065306005999445915,
      "learning_rate": 7.227227385721298e-06,
      "loss": 0.0003,
      "step": 17512
    },
    {
      "epoch": 0.2772930949855123,
      "grad_norm": 0.032320503145456314,
      "learning_rate": 7.227069050144878e-06,
      "loss": 0.0017,
      "step": 17513
    },
    {
      "epoch": 0.27730892854315436,
      "grad_norm": 0.3350065350532532,
      "learning_rate": 7.226910714568457e-06,
      "loss": 0.0705,
      "step": 17514
    },
    {
      "epoch": 0.27732476210079643,
      "grad_norm": 0.240679532289505,
      "learning_rate": 7.226752378992037e-06,
      "loss": 0.0364,
      "step": 17515
    },
    {
      "epoch": 0.2773405956584385,
      "grad_norm": 0.005823678802698851,
      "learning_rate": 7.2265940434156154e-06,
      "loss": 0.0002,
      "step": 17516
    },
    {
      "epoch": 0.27735642921608056,
      "grad_norm": 0.0001069818390533328,
      "learning_rate": 7.2264357078391945e-06,
      "loss": 0.0,
      "step": 17517
    },
    {
      "epoch": 0.2773722627737226,
      "grad_norm": 0.000332363328197971,
      "learning_rate": 7.2262773722627744e-06,
      "loss": 0.0,
      "step": 17518
    },
    {
      "epoch": 0.2773880963313647,
      "grad_norm": 0.2987987697124481,
      "learning_rate": 7.2261190366863535e-06,
      "loss": 0.0921,
      "step": 17519
    },
    {
      "epoch": 0.27740392988900675,
      "grad_norm": 0.6435920596122742,
      "learning_rate": 7.2259607011099334e-06,
      "loss": 0.2033,
      "step": 17520
    },
    {
      "epoch": 0.2774197634466488,
      "grad_norm": 0.32636645436286926,
      "learning_rate": 7.225802365533512e-06,
      "loss": 0.0696,
      "step": 17521
    },
    {
      "epoch": 0.2774355970042909,
      "grad_norm": 0.5109505653381348,
      "learning_rate": 7.225644029957092e-06,
      "loss": 0.2013,
      "step": 17522
    },
    {
      "epoch": 0.27745143056193294,
      "grad_norm": 0.5284900069236755,
      "learning_rate": 7.225485694380671e-06,
      "loss": 0.1207,
      "step": 17523
    },
    {
      "epoch": 0.277467264119575,
      "grad_norm": 0.7089970111846924,
      "learning_rate": 7.225327358804251e-06,
      "loss": 0.1957,
      "step": 17524
    },
    {
      "epoch": 0.27748309767721707,
      "grad_norm": 0.009212980978190899,
      "learning_rate": 7.22516902322783e-06,
      "loss": 0.0004,
      "step": 17525
    },
    {
      "epoch": 0.27749893123485914,
      "grad_norm": 0.02410687506198883,
      "learning_rate": 7.22501068765141e-06,
      "loss": 0.0011,
      "step": 17526
    },
    {
      "epoch": 0.2775147647925012,
      "grad_norm": 0.30981355905532837,
      "learning_rate": 7.224852352074988e-06,
      "loss": 0.0888,
      "step": 17527
    },
    {
      "epoch": 0.2775305983501433,
      "grad_norm": 0.3696974813938141,
      "learning_rate": 7.224694016498568e-06,
      "loss": 0.1657,
      "step": 17528
    },
    {
      "epoch": 0.2775464319077854,
      "grad_norm": 0.39808088541030884,
      "learning_rate": 7.224535680922147e-06,
      "loss": 0.2147,
      "step": 17529
    },
    {
      "epoch": 0.27756226546542745,
      "grad_norm": 0.6219942569732666,
      "learning_rate": 7.224377345345727e-06,
      "loss": 0.6667,
      "step": 17530
    },
    {
      "epoch": 0.2775780990230695,
      "grad_norm": 0.5523946285247803,
      "learning_rate": 7.224219009769306e-06,
      "loss": 0.2695,
      "step": 17531
    },
    {
      "epoch": 0.2775939325807116,
      "grad_norm": 0.010110503993928432,
      "learning_rate": 7.224060674192886e-06,
      "loss": 0.0005,
      "step": 17532
    },
    {
      "epoch": 0.27760976613835364,
      "grad_norm": 1.95516836643219,
      "learning_rate": 7.223902338616464e-06,
      "loss": 0.2599,
      "step": 17533
    },
    {
      "epoch": 0.2776255996959957,
      "grad_norm": 0.36673444509506226,
      "learning_rate": 7.223744003040044e-06,
      "loss": 0.127,
      "step": 17534
    },
    {
      "epoch": 0.27764143325363777,
      "grad_norm": 0.4365278482437134,
      "learning_rate": 7.223585667463623e-06,
      "loss": 0.1011,
      "step": 17535
    },
    {
      "epoch": 0.27765726681127983,
      "grad_norm": 0.9404059648513794,
      "learning_rate": 7.223427331887203e-06,
      "loss": 0.4367,
      "step": 17536
    },
    {
      "epoch": 0.2776731003689219,
      "grad_norm": 0.00017170268984045833,
      "learning_rate": 7.223268996310781e-06,
      "loss": 0.0,
      "step": 17537
    },
    {
      "epoch": 0.27768893392656396,
      "grad_norm": 0.32029083371162415,
      "learning_rate": 7.223110660734361e-06,
      "loss": 0.0313,
      "step": 17538
    },
    {
      "epoch": 0.277704767484206,
      "grad_norm": 0.3643356263637543,
      "learning_rate": 7.22295232515794e-06,
      "loss": 0.1851,
      "step": 17539
    },
    {
      "epoch": 0.2777206010418481,
      "grad_norm": 0.8499065637588501,
      "learning_rate": 7.222793989581519e-06,
      "loss": 0.3118,
      "step": 17540
    },
    {
      "epoch": 0.27773643459949016,
      "grad_norm": 0.24792683124542236,
      "learning_rate": 7.222635654005099e-06,
      "loss": 0.1062,
      "step": 17541
    },
    {
      "epoch": 0.2777522681571322,
      "grad_norm": 0.33222565054893494,
      "learning_rate": 7.222477318428677e-06,
      "loss": 0.1104,
      "step": 17542
    },
    {
      "epoch": 0.2777681017147743,
      "grad_norm": 0.000191817685845308,
      "learning_rate": 7.222318982852257e-06,
      "loss": 0.0,
      "step": 17543
    },
    {
      "epoch": 0.27778393527241635,
      "grad_norm": 0.002055378397926688,
      "learning_rate": 7.2221606472758364e-06,
      "loss": 0.0001,
      "step": 17544
    },
    {
      "epoch": 0.2777997688300584,
      "grad_norm": 0.09744933247566223,
      "learning_rate": 7.222002311699416e-06,
      "loss": 0.009,
      "step": 17545
    },
    {
      "epoch": 0.2778156023877005,
      "grad_norm": 0.22691141068935394,
      "learning_rate": 7.2218439761229954e-06,
      "loss": 0.0981,
      "step": 17546
    },
    {
      "epoch": 0.27783143594534254,
      "grad_norm": 0.44009271264076233,
      "learning_rate": 7.221685640546575e-06,
      "loss": 0.1358,
      "step": 17547
    },
    {
      "epoch": 0.2778472695029846,
      "grad_norm": 0.5977500677108765,
      "learning_rate": 7.221527304970154e-06,
      "loss": 0.1398,
      "step": 17548
    },
    {
      "epoch": 0.27786310306062667,
      "grad_norm": 1.3942556381225586,
      "learning_rate": 7.2213689693937335e-06,
      "loss": 0.1953,
      "step": 17549
    },
    {
      "epoch": 0.27787893661826873,
      "grad_norm": 0.8103618621826172,
      "learning_rate": 7.221210633817313e-06,
      "loss": 0.3364,
      "step": 17550
    },
    {
      "epoch": 0.2778947701759108,
      "grad_norm": 0.5040156245231628,
      "learning_rate": 7.2210522982408925e-06,
      "loss": 0.2277,
      "step": 17551
    },
    {
      "epoch": 0.2779106037335529,
      "grad_norm": 0.14426198601722717,
      "learning_rate": 7.220893962664472e-06,
      "loss": 0.0401,
      "step": 17552
    },
    {
      "epoch": 0.277926437291195,
      "grad_norm": 0.6231465935707092,
      "learning_rate": 7.2207356270880515e-06,
      "loss": 0.0547,
      "step": 17553
    },
    {
      "epoch": 0.27794227084883705,
      "grad_norm": 0.43157291412353516,
      "learning_rate": 7.22057729151163e-06,
      "loss": 0.1104,
      "step": 17554
    },
    {
      "epoch": 0.2779581044064791,
      "grad_norm": 0.026988785713911057,
      "learning_rate": 7.22041895593521e-06,
      "loss": 0.0008,
      "step": 17555
    },
    {
      "epoch": 0.2779739379641212,
      "grad_norm": 0.49903374910354614,
      "learning_rate": 7.220260620358789e-06,
      "loss": 0.21,
      "step": 17556
    },
    {
      "epoch": 0.27798977152176324,
      "grad_norm": 0.6467613577842712,
      "learning_rate": 7.220102284782369e-06,
      "loss": 0.5977,
      "step": 17557
    },
    {
      "epoch": 0.2780056050794053,
      "grad_norm": 0.4403229355812073,
      "learning_rate": 7.219943949205948e-06,
      "loss": 0.1397,
      "step": 17558
    },
    {
      "epoch": 0.27802143863704737,
      "grad_norm": 0.020568549633026123,
      "learning_rate": 7.219785613629528e-06,
      "loss": 0.0011,
      "step": 17559
    },
    {
      "epoch": 0.27803727219468943,
      "grad_norm": 0.30864179134368896,
      "learning_rate": 7.219627278053106e-06,
      "loss": 0.0989,
      "step": 17560
    },
    {
      "epoch": 0.2780531057523315,
      "grad_norm": 0.007201515603810549,
      "learning_rate": 7.219468942476686e-06,
      "loss": 0.0003,
      "step": 17561
    },
    {
      "epoch": 0.27806893930997356,
      "grad_norm": 0.00018652663857210428,
      "learning_rate": 7.219310606900265e-06,
      "loss": 0.0,
      "step": 17562
    },
    {
      "epoch": 0.2780847728676156,
      "grad_norm": 0.1555398851633072,
      "learning_rate": 7.219152271323845e-06,
      "loss": 0.0106,
      "step": 17563
    },
    {
      "epoch": 0.2781006064252577,
      "grad_norm": 0.5937294960021973,
      "learning_rate": 7.218993935747424e-06,
      "loss": 0.1335,
      "step": 17564
    },
    {
      "epoch": 0.27811643998289975,
      "grad_norm": 0.3813210725784302,
      "learning_rate": 7.218835600171002e-06,
      "loss": 0.0668,
      "step": 17565
    },
    {
      "epoch": 0.2781322735405418,
      "grad_norm": 0.3150871694087982,
      "learning_rate": 7.218677264594582e-06,
      "loss": 0.078,
      "step": 17566
    },
    {
      "epoch": 0.2781481070981839,
      "grad_norm": 0.5884946584701538,
      "learning_rate": 7.218518929018161e-06,
      "loss": 0.6605,
      "step": 17567
    },
    {
      "epoch": 0.27816394065582595,
      "grad_norm": 0.25948166847229004,
      "learning_rate": 7.218360593441741e-06,
      "loss": 0.0365,
      "step": 17568
    },
    {
      "epoch": 0.278179774213468,
      "grad_norm": 0.43436938524246216,
      "learning_rate": 7.21820225786532e-06,
      "loss": 0.2259,
      "step": 17569
    },
    {
      "epoch": 0.2781956077711101,
      "grad_norm": 0.5315398573875427,
      "learning_rate": 7.2180439222889e-06,
      "loss": 0.1868,
      "step": 17570
    },
    {
      "epoch": 0.27821144132875214,
      "grad_norm": 1.1821969747543335,
      "learning_rate": 7.217885586712478e-06,
      "loss": 0.5161,
      "step": 17571
    },
    {
      "epoch": 0.2782272748863942,
      "grad_norm": 0.00960541982203722,
      "learning_rate": 7.217727251136058e-06,
      "loss": 0.0004,
      "step": 17572
    },
    {
      "epoch": 0.27824310844403627,
      "grad_norm": 0.19089122116565704,
      "learning_rate": 7.217568915559637e-06,
      "loss": 0.0854,
      "step": 17573
    },
    {
      "epoch": 0.27825894200167833,
      "grad_norm": 1.366926670074463,
      "learning_rate": 7.217410579983217e-06,
      "loss": 0.2154,
      "step": 17574
    },
    {
      "epoch": 0.2782747755593204,
      "grad_norm": 0.3113445043563843,
      "learning_rate": 7.217252244406796e-06,
      "loss": 0.0935,
      "step": 17575
    },
    {
      "epoch": 0.2782906091169625,
      "grad_norm": 0.6255553364753723,
      "learning_rate": 7.217093908830376e-06,
      "loss": 0.1969,
      "step": 17576
    },
    {
      "epoch": 0.2783064426746046,
      "grad_norm": 0.022487979382276535,
      "learning_rate": 7.2169355732539545e-06,
      "loss": 0.001,
      "step": 17577
    },
    {
      "epoch": 0.27832227623224665,
      "grad_norm": 0.014703084714710712,
      "learning_rate": 7.2167772376775345e-06,
      "loss": 0.0008,
      "step": 17578
    },
    {
      "epoch": 0.2783381097898887,
      "grad_norm": 0.33564189076423645,
      "learning_rate": 7.2166189021011135e-06,
      "loss": 0.0916,
      "step": 17579
    },
    {
      "epoch": 0.2783539433475308,
      "grad_norm": 0.6737411022186279,
      "learning_rate": 7.2164605665246935e-06,
      "loss": 0.5591,
      "step": 17580
    },
    {
      "epoch": 0.27836977690517284,
      "grad_norm": 0.8126881122589111,
      "learning_rate": 7.2163022309482725e-06,
      "loss": 0.778,
      "step": 17581
    },
    {
      "epoch": 0.2783856104628149,
      "grad_norm": 0.2719653844833374,
      "learning_rate": 7.2161438953718525e-06,
      "loss": 0.0563,
      "step": 17582
    },
    {
      "epoch": 0.27840144402045697,
      "grad_norm": 0.2726239562034607,
      "learning_rate": 7.215985559795431e-06,
      "loss": 0.1106,
      "step": 17583
    },
    {
      "epoch": 0.27841727757809903,
      "grad_norm": 0.0021118586882948875,
      "learning_rate": 7.215827224219011e-06,
      "loss": 0.0,
      "step": 17584
    },
    {
      "epoch": 0.2784331111357411,
      "grad_norm": 0.27702295780181885,
      "learning_rate": 7.21566888864259e-06,
      "loss": 0.0626,
      "step": 17585
    },
    {
      "epoch": 0.27844894469338316,
      "grad_norm": 0.34586286544799805,
      "learning_rate": 7.21551055306617e-06,
      "loss": 0.1087,
      "step": 17586
    },
    {
      "epoch": 0.2784647782510252,
      "grad_norm": 0.7132647037506104,
      "learning_rate": 7.215352217489749e-06,
      "loss": 0.1452,
      "step": 17587
    },
    {
      "epoch": 0.2784806118086673,
      "grad_norm": 7.872909191064537e-05,
      "learning_rate": 7.215193881913327e-06,
      "loss": 0.0,
      "step": 17588
    },
    {
      "epoch": 0.27849644536630935,
      "grad_norm": 0.2662526071071625,
      "learning_rate": 7.215035546336907e-06,
      "loss": 0.0869,
      "step": 17589
    },
    {
      "epoch": 0.2785122789239514,
      "grad_norm": 0.7492318749427795,
      "learning_rate": 7.214877210760486e-06,
      "loss": 0.4681,
      "step": 17590
    },
    {
      "epoch": 0.2785281124815935,
      "grad_norm": 0.6056702136993408,
      "learning_rate": 7.214718875184066e-06,
      "loss": 0.1592,
      "step": 17591
    },
    {
      "epoch": 0.27854394603923555,
      "grad_norm": 0.9301841259002686,
      "learning_rate": 7.214560539607645e-06,
      "loss": 0.0594,
      "step": 17592
    },
    {
      "epoch": 0.2785597795968776,
      "grad_norm": 0.726971447467804,
      "learning_rate": 7.214402204031225e-06,
      "loss": 0.554,
      "step": 17593
    },
    {
      "epoch": 0.2785756131545197,
      "grad_norm": 0.4492991864681244,
      "learning_rate": 7.214243868454803e-06,
      "loss": 0.2545,
      "step": 17594
    },
    {
      "epoch": 0.27859144671216174,
      "grad_norm": 0.9161638021469116,
      "learning_rate": 7.214085532878383e-06,
      "loss": 0.1619,
      "step": 17595
    },
    {
      "epoch": 0.2786072802698038,
      "grad_norm": 0.031475476920604706,
      "learning_rate": 7.213927197301962e-06,
      "loss": 0.0013,
      "step": 17596
    },
    {
      "epoch": 0.27862311382744587,
      "grad_norm": 0.4937230050563812,
      "learning_rate": 7.213768861725542e-06,
      "loss": 0.2585,
      "step": 17597
    },
    {
      "epoch": 0.27863894738508793,
      "grad_norm": 0.3469103276729584,
      "learning_rate": 7.213610526149121e-06,
      "loss": 0.1103,
      "step": 17598
    },
    {
      "epoch": 0.27865478094273,
      "grad_norm": 0.35712292790412903,
      "learning_rate": 7.213452190572701e-06,
      "loss": 0.0554,
      "step": 17599
    },
    {
      "epoch": 0.2786706145003721,
      "grad_norm": 0.048802100121974945,
      "learning_rate": 7.213293854996279e-06,
      "loss": 0.0034,
      "step": 17600
    },
    {
      "epoch": 0.2786864480580142,
      "grad_norm": 1.6300287246704102,
      "learning_rate": 7.213135519419859e-06,
      "loss": 0.3367,
      "step": 17601
    },
    {
      "epoch": 0.27870228161565624,
      "grad_norm": 0.1691291779279709,
      "learning_rate": 7.212977183843438e-06,
      "loss": 0.0325,
      "step": 17602
    },
    {
      "epoch": 0.2787181151732983,
      "grad_norm": 0.16065774857997894,
      "learning_rate": 7.212818848267018e-06,
      "loss": 0.0444,
      "step": 17603
    },
    {
      "epoch": 0.2787339487309404,
      "grad_norm": 0.002628736663609743,
      "learning_rate": 7.2126605126905964e-06,
      "loss": 0.0001,
      "step": 17604
    },
    {
      "epoch": 0.27874978228858244,
      "grad_norm": 0.31616273522377014,
      "learning_rate": 7.212502177114176e-06,
      "loss": 0.0789,
      "step": 17605
    },
    {
      "epoch": 0.2787656158462245,
      "grad_norm": 0.1963977962732315,
      "learning_rate": 7.2123438415377555e-06,
      "loss": 0.0934,
      "step": 17606
    },
    {
      "epoch": 0.27878144940386657,
      "grad_norm": 0.581226646900177,
      "learning_rate": 7.212185505961335e-06,
      "loss": 0.1283,
      "step": 17607
    },
    {
      "epoch": 0.27879728296150863,
      "grad_norm": 0.02741404063999653,
      "learning_rate": 7.2120271703849145e-06,
      "loss": 0.0013,
      "step": 17608
    },
    {
      "epoch": 0.2788131165191507,
      "grad_norm": 0.3410477638244629,
      "learning_rate": 7.211868834808494e-06,
      "loss": 0.1217,
      "step": 17609
    },
    {
      "epoch": 0.27882895007679276,
      "grad_norm": 0.1986686736345291,
      "learning_rate": 7.211710499232073e-06,
      "loss": 0.0036,
      "step": 17610
    },
    {
      "epoch": 0.2788447836344348,
      "grad_norm": 0.3247058689594269,
      "learning_rate": 7.2115521636556525e-06,
      "loss": 0.0558,
      "step": 17611
    },
    {
      "epoch": 0.2788606171920769,
      "grad_norm": 0.11965987086296082,
      "learning_rate": 7.211393828079232e-06,
      "loss": 0.0062,
      "step": 17612
    },
    {
      "epoch": 0.27887645074971895,
      "grad_norm": 0.4855421185493469,
      "learning_rate": 7.211235492502811e-06,
      "loss": 0.0638,
      "step": 17613
    },
    {
      "epoch": 0.278892284307361,
      "grad_norm": 0.37133392691612244,
      "learning_rate": 7.211077156926391e-06,
      "loss": 0.2907,
      "step": 17614
    },
    {
      "epoch": 0.2789081178650031,
      "grad_norm": 0.03903709724545479,
      "learning_rate": 7.210918821349969e-06,
      "loss": 0.0008,
      "step": 17615
    },
    {
      "epoch": 0.27892395142264514,
      "grad_norm": 0.6287026405334473,
      "learning_rate": 7.210760485773549e-06,
      "loss": 0.0595,
      "step": 17616
    },
    {
      "epoch": 0.2789397849802872,
      "grad_norm": 0.3796637952327728,
      "learning_rate": 7.210602150197128e-06,
      "loss": 0.1336,
      "step": 17617
    },
    {
      "epoch": 0.2789556185379293,
      "grad_norm": 0.04002445563673973,
      "learning_rate": 7.210443814620708e-06,
      "loss": 0.0027,
      "step": 17618
    },
    {
      "epoch": 0.27897145209557134,
      "grad_norm": 0.3944797217845917,
      "learning_rate": 7.210285479044287e-06,
      "loss": 0.1179,
      "step": 17619
    },
    {
      "epoch": 0.2789872856532134,
      "grad_norm": 0.8740238547325134,
      "learning_rate": 7.210127143467867e-06,
      "loss": 0.1346,
      "step": 17620
    },
    {
      "epoch": 0.27900311921085547,
      "grad_norm": 0.28537416458129883,
      "learning_rate": 7.209968807891445e-06,
      "loss": 0.0794,
      "step": 17621
    },
    {
      "epoch": 0.27901895276849753,
      "grad_norm": 0.7346845865249634,
      "learning_rate": 7.209810472315025e-06,
      "loss": 0.0865,
      "step": 17622
    },
    {
      "epoch": 0.2790347863261396,
      "grad_norm": 0.6090998649597168,
      "learning_rate": 7.209652136738604e-06,
      "loss": 0.1432,
      "step": 17623
    },
    {
      "epoch": 0.2790506198837817,
      "grad_norm": 0.28594186902046204,
      "learning_rate": 7.209493801162184e-06,
      "loss": 0.04,
      "step": 17624
    },
    {
      "epoch": 0.2790664534414238,
      "grad_norm": 0.0013371446402743459,
      "learning_rate": 7.209335465585763e-06,
      "loss": 0.0,
      "step": 17625
    },
    {
      "epoch": 0.27908228699906584,
      "grad_norm": 0.027273038402199745,
      "learning_rate": 7.209177130009343e-06,
      "loss": 0.0018,
      "step": 17626
    },
    {
      "epoch": 0.2790981205567079,
      "grad_norm": 0.38770392537117004,
      "learning_rate": 7.209018794432921e-06,
      "loss": 0.128,
      "step": 17627
    },
    {
      "epoch": 0.27911395411434997,
      "grad_norm": 0.17186616361141205,
      "learning_rate": 7.208860458856501e-06,
      "loss": 0.0194,
      "step": 17628
    },
    {
      "epoch": 0.27912978767199204,
      "grad_norm": 0.16535212099552155,
      "learning_rate": 7.20870212328008e-06,
      "loss": 0.0114,
      "step": 17629
    },
    {
      "epoch": 0.2791456212296341,
      "grad_norm": 0.2769213318824768,
      "learning_rate": 7.20854378770366e-06,
      "loss": 0.0235,
      "step": 17630
    },
    {
      "epoch": 0.27916145478727616,
      "grad_norm": 0.000943662307690829,
      "learning_rate": 7.208385452127239e-06,
      "loss": 0.0,
      "step": 17631
    },
    {
      "epoch": 0.27917728834491823,
      "grad_norm": 0.7438706159591675,
      "learning_rate": 7.208227116550819e-06,
      "loss": 0.4481,
      "step": 17632
    },
    {
      "epoch": 0.2791931219025603,
      "grad_norm": 1.2034471035003662,
      "learning_rate": 7.208068780974397e-06,
      "loss": 0.6544,
      "step": 17633
    },
    {
      "epoch": 0.27920895546020236,
      "grad_norm": 0.651345431804657,
      "learning_rate": 7.207910445397977e-06,
      "loss": 0.1319,
      "step": 17634
    },
    {
      "epoch": 0.2792247890178444,
      "grad_norm": 9.026741463458166e-05,
      "learning_rate": 7.207752109821556e-06,
      "loss": 0.0,
      "step": 17635
    },
    {
      "epoch": 0.2792406225754865,
      "grad_norm": 0.3597908616065979,
      "learning_rate": 7.2075937742451355e-06,
      "loss": 0.0728,
      "step": 17636
    },
    {
      "epoch": 0.27925645613312855,
      "grad_norm": 0.5907738208770752,
      "learning_rate": 7.207435438668715e-06,
      "loss": 0.3105,
      "step": 17637
    },
    {
      "epoch": 0.2792722896907706,
      "grad_norm": 0.15583160519599915,
      "learning_rate": 7.207277103092294e-06,
      "loss": 0.0455,
      "step": 17638
    },
    {
      "epoch": 0.2792881232484127,
      "grad_norm": 0.4124026894569397,
      "learning_rate": 7.2071187675158736e-06,
      "loss": 0.1853,
      "step": 17639
    },
    {
      "epoch": 0.27930395680605474,
      "grad_norm": 0.438220351934433,
      "learning_rate": 7.206960431939453e-06,
      "loss": 0.126,
      "step": 17640
    },
    {
      "epoch": 0.2793197903636968,
      "grad_norm": 0.6800450086593628,
      "learning_rate": 7.2068020963630326e-06,
      "loss": 0.2631,
      "step": 17641
    },
    {
      "epoch": 0.27933562392133887,
      "grad_norm": 0.8068923354148865,
      "learning_rate": 7.206643760786612e-06,
      "loss": 0.0738,
      "step": 17642
    },
    {
      "epoch": 0.27935145747898094,
      "grad_norm": 0.010663558728992939,
      "learning_rate": 7.2064854252101916e-06,
      "loss": 0.0006,
      "step": 17643
    },
    {
      "epoch": 0.279367291036623,
      "grad_norm": 0.03351066634058952,
      "learning_rate": 7.20632708963377e-06,
      "loss": 0.0024,
      "step": 17644
    },
    {
      "epoch": 0.27938312459426506,
      "grad_norm": 0.00010436046432005242,
      "learning_rate": 7.20616875405735e-06,
      "loss": 0.0,
      "step": 17645
    },
    {
      "epoch": 0.27939895815190713,
      "grad_norm": 0.03663439676165581,
      "learning_rate": 7.206010418480929e-06,
      "loss": 0.0002,
      "step": 17646
    },
    {
      "epoch": 0.2794147917095492,
      "grad_norm": 0.5330854654312134,
      "learning_rate": 7.205852082904509e-06,
      "loss": 0.1076,
      "step": 17647
    },
    {
      "epoch": 0.2794306252671913,
      "grad_norm": 4.541776657104492,
      "learning_rate": 7.205693747328088e-06,
      "loss": 0.2738,
      "step": 17648
    },
    {
      "epoch": 0.2794464588248334,
      "grad_norm": 0.20300456881523132,
      "learning_rate": 7.205535411751668e-06,
      "loss": 0.0386,
      "step": 17649
    },
    {
      "epoch": 0.27946229238247544,
      "grad_norm": 0.055576760321855545,
      "learning_rate": 7.205377076175246e-06,
      "loss": 0.0029,
      "step": 17650
    },
    {
      "epoch": 0.2794781259401175,
      "grad_norm": 0.27412736415863037,
      "learning_rate": 7.205218740598826e-06,
      "loss": 0.1242,
      "step": 17651
    },
    {
      "epoch": 0.27949395949775957,
      "grad_norm": 0.010481060482561588,
      "learning_rate": 7.205060405022405e-06,
      "loss": 0.0005,
      "step": 17652
    },
    {
      "epoch": 0.27950979305540163,
      "grad_norm": 0.012924101203680038,
      "learning_rate": 7.204902069445985e-06,
      "loss": 0.0006,
      "step": 17653
    },
    {
      "epoch": 0.2795256266130437,
      "grad_norm": 0.11819224804639816,
      "learning_rate": 7.204743733869564e-06,
      "loss": 0.0042,
      "step": 17654
    },
    {
      "epoch": 0.27954146017068576,
      "grad_norm": 0.4548285901546478,
      "learning_rate": 7.204585398293144e-06,
      "loss": 0.2652,
      "step": 17655
    },
    {
      "epoch": 0.2795572937283278,
      "grad_norm": 0.6279563307762146,
      "learning_rate": 7.204427062716722e-06,
      "loss": 0.1838,
      "step": 17656
    },
    {
      "epoch": 0.2795731272859699,
      "grad_norm": 0.5614768266677856,
      "learning_rate": 7.204268727140302e-06,
      "loss": 0.6112,
      "step": 17657
    },
    {
      "epoch": 0.27958896084361196,
      "grad_norm": 0.3082660734653473,
      "learning_rate": 7.204110391563881e-06,
      "loss": 0.0704,
      "step": 17658
    },
    {
      "epoch": 0.279604794401254,
      "grad_norm": 0.45532068610191345,
      "learning_rate": 7.203952055987461e-06,
      "loss": 0.0949,
      "step": 17659
    },
    {
      "epoch": 0.2796206279588961,
      "grad_norm": 0.20494739711284637,
      "learning_rate": 7.20379372041104e-06,
      "loss": 0.0158,
      "step": 17660
    },
    {
      "epoch": 0.27963646151653815,
      "grad_norm": 0.31963062286376953,
      "learning_rate": 7.203635384834618e-06,
      "loss": 0.0768,
      "step": 17661
    },
    {
      "epoch": 0.2796522950741802,
      "grad_norm": 0.36018049716949463,
      "learning_rate": 7.203477049258198e-06,
      "loss": 0.1428,
      "step": 17662
    },
    {
      "epoch": 0.2796681286318223,
      "grad_norm": 0.02617470547556877,
      "learning_rate": 7.203318713681777e-06,
      "loss": 0.0013,
      "step": 17663
    },
    {
      "epoch": 0.27968396218946434,
      "grad_norm": 0.1781737357378006,
      "learning_rate": 7.203160378105357e-06,
      "loss": 0.0438,
      "step": 17664
    },
    {
      "epoch": 0.2796997957471064,
      "grad_norm": 0.0003061894385609776,
      "learning_rate": 7.203002042528936e-06,
      "loss": 0.0,
      "step": 17665
    },
    {
      "epoch": 0.27971562930474847,
      "grad_norm": 0.9059140682220459,
      "learning_rate": 7.2028437069525155e-06,
      "loss": 0.329,
      "step": 17666
    },
    {
      "epoch": 0.27973146286239053,
      "grad_norm": 0.027354827150702477,
      "learning_rate": 7.2026853713760946e-06,
      "loss": 0.0012,
      "step": 17667
    },
    {
      "epoch": 0.2797472964200326,
      "grad_norm": 0.5316135883331299,
      "learning_rate": 7.2025270357996745e-06,
      "loss": 0.4659,
      "step": 17668
    },
    {
      "epoch": 0.27976312997767466,
      "grad_norm": 0.3197598457336426,
      "learning_rate": 7.2023687002232536e-06,
      "loss": 0.0866,
      "step": 17669
    },
    {
      "epoch": 0.2797789635353167,
      "grad_norm": 0.4524923264980316,
      "learning_rate": 7.2022103646468335e-06,
      "loss": 0.095,
      "step": 17670
    },
    {
      "epoch": 0.2797947970929588,
      "grad_norm": 0.47606152296066284,
      "learning_rate": 7.202052029070412e-06,
      "loss": 0.0907,
      "step": 17671
    },
    {
      "epoch": 0.2798106306506009,
      "grad_norm": 0.009734293445944786,
      "learning_rate": 7.201893693493992e-06,
      "loss": 0.0004,
      "step": 17672
    },
    {
      "epoch": 0.279826464208243,
      "grad_norm": 0.25060299038887024,
      "learning_rate": 7.201735357917571e-06,
      "loss": 0.0019,
      "step": 17673
    },
    {
      "epoch": 0.27984229776588504,
      "grad_norm": 0.6961286664009094,
      "learning_rate": 7.201577022341151e-06,
      "loss": 0.254,
      "step": 17674
    },
    {
      "epoch": 0.2798581313235271,
      "grad_norm": 0.1694885790348053,
      "learning_rate": 7.20141868676473e-06,
      "loss": 0.0603,
      "step": 17675
    },
    {
      "epoch": 0.27987396488116917,
      "grad_norm": 0.541566789150238,
      "learning_rate": 7.20126035118831e-06,
      "loss": 0.1884,
      "step": 17676
    },
    {
      "epoch": 0.27988979843881123,
      "grad_norm": 0.04032624885439873,
      "learning_rate": 7.201102015611888e-06,
      "loss": 0.0004,
      "step": 17677
    },
    {
      "epoch": 0.2799056319964533,
      "grad_norm": 0.4596601724624634,
      "learning_rate": 7.200943680035468e-06,
      "loss": 0.1557,
      "step": 17678
    },
    {
      "epoch": 0.27992146555409536,
      "grad_norm": 0.3433399200439453,
      "learning_rate": 7.200785344459047e-06,
      "loss": 0.0902,
      "step": 17679
    },
    {
      "epoch": 0.2799372991117374,
      "grad_norm": 0.3415297865867615,
      "learning_rate": 7.200627008882627e-06,
      "loss": 0.1973,
      "step": 17680
    },
    {
      "epoch": 0.2799531326693795,
      "grad_norm": 0.6925044059753418,
      "learning_rate": 7.200468673306206e-06,
      "loss": 0.389,
      "step": 17681
    },
    {
      "epoch": 0.27996896622702155,
      "grad_norm": 0.30922114849090576,
      "learning_rate": 7.200310337729786e-06,
      "loss": 0.0834,
      "step": 17682
    },
    {
      "epoch": 0.2799847997846636,
      "grad_norm": 0.5238896608352661,
      "learning_rate": 7.200152002153364e-06,
      "loss": 0.091,
      "step": 17683
    },
    {
      "epoch": 0.2800006333423057,
      "grad_norm": 0.2642163038253784,
      "learning_rate": 7.199993666576943e-06,
      "loss": 0.1232,
      "step": 17684
    },
    {
      "epoch": 0.28001646689994775,
      "grad_norm": 0.0073128920048475266,
      "learning_rate": 7.199835331000523e-06,
      "loss": 0.0003,
      "step": 17685
    },
    {
      "epoch": 0.2800323004575898,
      "grad_norm": 0.2987882196903229,
      "learning_rate": 7.199676995424102e-06,
      "loss": 0.0649,
      "step": 17686
    },
    {
      "epoch": 0.2800481340152319,
      "grad_norm": 0.43440622091293335,
      "learning_rate": 7.199518659847682e-06,
      "loss": 0.1595,
      "step": 17687
    },
    {
      "epoch": 0.28006396757287394,
      "grad_norm": 0.5668933987617493,
      "learning_rate": 7.19936032427126e-06,
      "loss": 0.1179,
      "step": 17688
    },
    {
      "epoch": 0.280079801130516,
      "grad_norm": 0.1996179074048996,
      "learning_rate": 7.19920198869484e-06,
      "loss": 0.0176,
      "step": 17689
    },
    {
      "epoch": 0.28009563468815807,
      "grad_norm": 0.8610941767692566,
      "learning_rate": 7.199043653118419e-06,
      "loss": 0.4725,
      "step": 17690
    },
    {
      "epoch": 0.28011146824580013,
      "grad_norm": 0.08210448920726776,
      "learning_rate": 7.198885317541999e-06,
      "loss": 0.0031,
      "step": 17691
    },
    {
      "epoch": 0.2801273018034422,
      "grad_norm": 0.22093525528907776,
      "learning_rate": 7.198726981965578e-06,
      "loss": 0.1053,
      "step": 17692
    },
    {
      "epoch": 0.28014313536108426,
      "grad_norm": 0.014074779115617275,
      "learning_rate": 7.198568646389158e-06,
      "loss": 0.0005,
      "step": 17693
    },
    {
      "epoch": 0.2801589689187263,
      "grad_norm": 0.2800148129463196,
      "learning_rate": 7.1984103108127365e-06,
      "loss": 0.1034,
      "step": 17694
    },
    {
      "epoch": 0.2801748024763684,
      "grad_norm": 0.31305554509162903,
      "learning_rate": 7.198251975236316e-06,
      "loss": 0.2721,
      "step": 17695
    },
    {
      "epoch": 0.2801906360340105,
      "grad_norm": 0.5806033611297607,
      "learning_rate": 7.1980936396598955e-06,
      "loss": 0.0167,
      "step": 17696
    },
    {
      "epoch": 0.2802064695916526,
      "grad_norm": 0.22879600524902344,
      "learning_rate": 7.197935304083475e-06,
      "loss": 0.0339,
      "step": 17697
    },
    {
      "epoch": 0.28022230314929464,
      "grad_norm": 0.0027432357892394066,
      "learning_rate": 7.1977769685070545e-06,
      "loss": 0.0,
      "step": 17698
    },
    {
      "epoch": 0.2802381367069367,
      "grad_norm": 0.054093148559331894,
      "learning_rate": 7.197618632930634e-06,
      "loss": 0.0016,
      "step": 17699
    },
    {
      "epoch": 0.28025397026457877,
      "grad_norm": 0.282439649105072,
      "learning_rate": 7.197460297354213e-06,
      "loss": 0.0331,
      "step": 17700
    },
    {
      "epoch": 0.28026980382222083,
      "grad_norm": 0.5661566853523254,
      "learning_rate": 7.197301961777793e-06,
      "loss": 0.0412,
      "step": 17701
    },
    {
      "epoch": 0.2802856373798629,
      "grad_norm": 0.18595075607299805,
      "learning_rate": 7.197143626201372e-06,
      "loss": 0.0439,
      "step": 17702
    },
    {
      "epoch": 0.28030147093750496,
      "grad_norm": 1.326309323310852,
      "learning_rate": 7.196985290624952e-06,
      "loss": 0.9211,
      "step": 17703
    },
    {
      "epoch": 0.280317304495147,
      "grad_norm": 0.013251198455691338,
      "learning_rate": 7.196826955048531e-06,
      "loss": 0.0006,
      "step": 17704
    },
    {
      "epoch": 0.2803331380527891,
      "grad_norm": 0.03073306754231453,
      "learning_rate": 7.196668619472111e-06,
      "loss": 0.0018,
      "step": 17705
    },
    {
      "epoch": 0.28034897161043115,
      "grad_norm": 0.38161271810531616,
      "learning_rate": 7.196510283895689e-06,
      "loss": 0.0825,
      "step": 17706
    },
    {
      "epoch": 0.2803648051680732,
      "grad_norm": 0.30724674463272095,
      "learning_rate": 7.196351948319269e-06,
      "loss": 0.0412,
      "step": 17707
    },
    {
      "epoch": 0.2803806387257153,
      "grad_norm": 0.3197796940803528,
      "learning_rate": 7.196193612742848e-06,
      "loss": 0.0543,
      "step": 17708
    },
    {
      "epoch": 0.28039647228335735,
      "grad_norm": 0.34668752551078796,
      "learning_rate": 7.196035277166427e-06,
      "loss": 0.077,
      "step": 17709
    },
    {
      "epoch": 0.2804123058409994,
      "grad_norm": 0.2627195715904236,
      "learning_rate": 7.195876941590007e-06,
      "loss": 0.0403,
      "step": 17710
    },
    {
      "epoch": 0.2804281393986415,
      "grad_norm": 0.4411877393722534,
      "learning_rate": 7.195718606013585e-06,
      "loss": 0.2153,
      "step": 17711
    },
    {
      "epoch": 0.28044397295628354,
      "grad_norm": 0.012602011673152447,
      "learning_rate": 7.195560270437165e-06,
      "loss": 0.0006,
      "step": 17712
    },
    {
      "epoch": 0.2804598065139256,
      "grad_norm": 0.34386634826660156,
      "learning_rate": 7.195401934860744e-06,
      "loss": 0.0932,
      "step": 17713
    },
    {
      "epoch": 0.28047564007156767,
      "grad_norm": 0.6552152633666992,
      "learning_rate": 7.195243599284324e-06,
      "loss": 0.2487,
      "step": 17714
    },
    {
      "epoch": 0.28049147362920973,
      "grad_norm": 0.5004345774650574,
      "learning_rate": 7.195085263707903e-06,
      "loss": 0.2483,
      "step": 17715
    },
    {
      "epoch": 0.2805073071868518,
      "grad_norm": 0.7454961538314819,
      "learning_rate": 7.194926928131483e-06,
      "loss": 0.8126,
      "step": 17716
    },
    {
      "epoch": 0.28052314074449386,
      "grad_norm": 0.025245094671845436,
      "learning_rate": 7.194768592555061e-06,
      "loss": 0.0014,
      "step": 17717
    },
    {
      "epoch": 0.2805389743021359,
      "grad_norm": 0.9191721081733704,
      "learning_rate": 7.194610256978641e-06,
      "loss": 0.3851,
      "step": 17718
    },
    {
      "epoch": 0.280554807859778,
      "grad_norm": 0.21678553521633148,
      "learning_rate": 7.19445192140222e-06,
      "loss": 0.0257,
      "step": 17719
    },
    {
      "epoch": 0.28057064141742005,
      "grad_norm": 0.4300222098827362,
      "learning_rate": 7.1942935858258e-06,
      "loss": 0.1518,
      "step": 17720
    },
    {
      "epoch": 0.2805864749750622,
      "grad_norm": 0.01093229465186596,
      "learning_rate": 7.194135250249379e-06,
      "loss": 0.0006,
      "step": 17721
    },
    {
      "epoch": 0.28060230853270424,
      "grad_norm": 0.1438300609588623,
      "learning_rate": 7.193976914672959e-06,
      "loss": 0.0104,
      "step": 17722
    },
    {
      "epoch": 0.2806181420903463,
      "grad_norm": 0.6916123032569885,
      "learning_rate": 7.193818579096537e-06,
      "loss": 0.1803,
      "step": 17723
    },
    {
      "epoch": 0.28063397564798837,
      "grad_norm": 1.4837205410003662,
      "learning_rate": 7.193660243520117e-06,
      "loss": 0.3139,
      "step": 17724
    },
    {
      "epoch": 0.28064980920563043,
      "grad_norm": 0.011618484742939472,
      "learning_rate": 7.193501907943696e-06,
      "loss": 0.0005,
      "step": 17725
    },
    {
      "epoch": 0.2806656427632725,
      "grad_norm": 0.2493455410003662,
      "learning_rate": 7.193343572367276e-06,
      "loss": 0.129,
      "step": 17726
    },
    {
      "epoch": 0.28068147632091456,
      "grad_norm": 0.0004930148716084659,
      "learning_rate": 7.193185236790855e-06,
      "loss": 0.0,
      "step": 17727
    },
    {
      "epoch": 0.2806973098785566,
      "grad_norm": 0.33022427558898926,
      "learning_rate": 7.1930269012144345e-06,
      "loss": 0.1497,
      "step": 17728
    },
    {
      "epoch": 0.2807131434361987,
      "grad_norm": 0.33308887481689453,
      "learning_rate": 7.192868565638014e-06,
      "loss": 0.0973,
      "step": 17729
    },
    {
      "epoch": 0.28072897699384075,
      "grad_norm": 0.0003789670008700341,
      "learning_rate": 7.1927102300615935e-06,
      "loss": 0.0,
      "step": 17730
    },
    {
      "epoch": 0.2807448105514828,
      "grad_norm": 0.011755726300179958,
      "learning_rate": 7.192551894485173e-06,
      "loss": 0.0006,
      "step": 17731
    },
    {
      "epoch": 0.2807606441091249,
      "grad_norm": 0.5614811778068542,
      "learning_rate": 7.1923935589087525e-06,
      "loss": 0.0695,
      "step": 17732
    },
    {
      "epoch": 0.28077647766676694,
      "grad_norm": 1.6479300260543823,
      "learning_rate": 7.192235223332331e-06,
      "loss": 0.3612,
      "step": 17733
    },
    {
      "epoch": 0.280792311224409,
      "grad_norm": 0.20944517850875854,
      "learning_rate": 7.19207688775591e-06,
      "loss": 0.0379,
      "step": 17734
    },
    {
      "epoch": 0.2808081447820511,
      "grad_norm": 0.3191773593425751,
      "learning_rate": 7.19191855217949e-06,
      "loss": 0.1274,
      "step": 17735
    },
    {
      "epoch": 0.28082397833969314,
      "grad_norm": 0.04675798490643501,
      "learning_rate": 7.191760216603069e-06,
      "loss": 0.0022,
      "step": 17736
    },
    {
      "epoch": 0.2808398118973352,
      "grad_norm": 0.41010499000549316,
      "learning_rate": 7.191601881026649e-06,
      "loss": 0.1975,
      "step": 17737
    },
    {
      "epoch": 0.28085564545497727,
      "grad_norm": 0.039935674518346786,
      "learning_rate": 7.191443545450227e-06,
      "loss": 0.0021,
      "step": 17738
    },
    {
      "epoch": 0.28087147901261933,
      "grad_norm": 0.0002043381828116253,
      "learning_rate": 7.191285209873807e-06,
      "loss": 0.0,
      "step": 17739
    },
    {
      "epoch": 0.2808873125702614,
      "grad_norm": 0.684680163860321,
      "learning_rate": 7.191126874297386e-06,
      "loss": 0.2879,
      "step": 17740
    },
    {
      "epoch": 0.28090314612790346,
      "grad_norm": 0.634584367275238,
      "learning_rate": 7.190968538720966e-06,
      "loss": 0.1398,
      "step": 17741
    },
    {
      "epoch": 0.2809189796855455,
      "grad_norm": 0.8858618140220642,
      "learning_rate": 7.190810203144545e-06,
      "loss": 0.2394,
      "step": 17742
    },
    {
      "epoch": 0.2809348132431876,
      "grad_norm": 0.18045967817306519,
      "learning_rate": 7.190651867568125e-06,
      "loss": 0.0595,
      "step": 17743
    },
    {
      "epoch": 0.28095064680082965,
      "grad_norm": 0.4044661521911621,
      "learning_rate": 7.190493531991703e-06,
      "loss": 0.1777,
      "step": 17744
    },
    {
      "epoch": 0.28096648035847177,
      "grad_norm": 0.36160987615585327,
      "learning_rate": 7.190335196415283e-06,
      "loss": 0.0816,
      "step": 17745
    },
    {
      "epoch": 0.28098231391611384,
      "grad_norm": 0.008790475316345692,
      "learning_rate": 7.190176860838862e-06,
      "loss": 0.0004,
      "step": 17746
    },
    {
      "epoch": 0.2809981474737559,
      "grad_norm": 0.9796772599220276,
      "learning_rate": 7.190018525262442e-06,
      "loss": 0.5384,
      "step": 17747
    },
    {
      "epoch": 0.28101398103139796,
      "grad_norm": 1.156255841255188,
      "learning_rate": 7.189860189686021e-06,
      "loss": 0.1434,
      "step": 17748
    },
    {
      "epoch": 0.28102981458904003,
      "grad_norm": 0.41159817576408386,
      "learning_rate": 7.189701854109601e-06,
      "loss": 0.0857,
      "step": 17749
    },
    {
      "epoch": 0.2810456481466821,
      "grad_norm": 0.4925818145275116,
      "learning_rate": 7.189543518533179e-06,
      "loss": 0.406,
      "step": 17750
    },
    {
      "epoch": 0.28106148170432416,
      "grad_norm": 0.03296421095728874,
      "learning_rate": 7.189385182956759e-06,
      "loss": 0.0017,
      "step": 17751
    },
    {
      "epoch": 0.2810773152619662,
      "grad_norm": 0.341038316488266,
      "learning_rate": 7.189226847380338e-06,
      "loss": 0.1239,
      "step": 17752
    },
    {
      "epoch": 0.2810931488196083,
      "grad_norm": 0.05671670287847519,
      "learning_rate": 7.189068511803918e-06,
      "loss": 0.0028,
      "step": 17753
    },
    {
      "epoch": 0.28110898237725035,
      "grad_norm": 0.4330645501613617,
      "learning_rate": 7.188910176227497e-06,
      "loss": 0.1259,
      "step": 17754
    },
    {
      "epoch": 0.2811248159348924,
      "grad_norm": 0.22707460820674896,
      "learning_rate": 7.188751840651077e-06,
      "loss": 0.0448,
      "step": 17755
    },
    {
      "epoch": 0.2811406494925345,
      "grad_norm": 0.2407837063074112,
      "learning_rate": 7.1885935050746555e-06,
      "loss": 0.0688,
      "step": 17756
    },
    {
      "epoch": 0.28115648305017654,
      "grad_norm": 0.6631194353103638,
      "learning_rate": 7.188435169498235e-06,
      "loss": 0.2228,
      "step": 17757
    },
    {
      "epoch": 0.2811723166078186,
      "grad_norm": 0.8287817239761353,
      "learning_rate": 7.1882768339218145e-06,
      "loss": 0.6863,
      "step": 17758
    },
    {
      "epoch": 0.28118815016546067,
      "grad_norm": 0.5025038123130798,
      "learning_rate": 7.188118498345394e-06,
      "loss": 0.2382,
      "step": 17759
    },
    {
      "epoch": 0.28120398372310274,
      "grad_norm": 0.8241702318191528,
      "learning_rate": 7.1879601627689735e-06,
      "loss": 0.1391,
      "step": 17760
    },
    {
      "epoch": 0.2812198172807448,
      "grad_norm": 0.009536046534776688,
      "learning_rate": 7.187801827192552e-06,
      "loss": 0.0004,
      "step": 17761
    },
    {
      "epoch": 0.28123565083838686,
      "grad_norm": 0.41144317388534546,
      "learning_rate": 7.187643491616132e-06,
      "loss": 0.1004,
      "step": 17762
    },
    {
      "epoch": 0.28125148439602893,
      "grad_norm": 0.5321953296661377,
      "learning_rate": 7.187485156039711e-06,
      "loss": 0.1374,
      "step": 17763
    },
    {
      "epoch": 0.281267317953671,
      "grad_norm": 0.018704650923609734,
      "learning_rate": 7.187326820463291e-06,
      "loss": 0.001,
      "step": 17764
    },
    {
      "epoch": 0.28128315151131306,
      "grad_norm": 0.013670935295522213,
      "learning_rate": 7.18716848488687e-06,
      "loss": 0.0008,
      "step": 17765
    },
    {
      "epoch": 0.2812989850689551,
      "grad_norm": 0.31779593229293823,
      "learning_rate": 7.18701014931045e-06,
      "loss": 0.0884,
      "step": 17766
    },
    {
      "epoch": 0.2813148186265972,
      "grad_norm": 0.026619531214237213,
      "learning_rate": 7.186851813734028e-06,
      "loss": 0.0014,
      "step": 17767
    },
    {
      "epoch": 0.28133065218423925,
      "grad_norm": 0.02625664696097374,
      "learning_rate": 7.186693478157608e-06,
      "loss": 0.0014,
      "step": 17768
    },
    {
      "epoch": 0.28134648574188137,
      "grad_norm": 0.12660394608974457,
      "learning_rate": 7.186535142581187e-06,
      "loss": 0.03,
      "step": 17769
    },
    {
      "epoch": 0.28136231929952343,
      "grad_norm": 0.25608599185943604,
      "learning_rate": 7.186376807004767e-06,
      "loss": 0.0271,
      "step": 17770
    },
    {
      "epoch": 0.2813781528571655,
      "grad_norm": 0.5964326858520508,
      "learning_rate": 7.186218471428346e-06,
      "loss": 0.2264,
      "step": 17771
    },
    {
      "epoch": 0.28139398641480756,
      "grad_norm": 0.16796310245990753,
      "learning_rate": 7.186060135851926e-06,
      "loss": 0.0107,
      "step": 17772
    },
    {
      "epoch": 0.2814098199724496,
      "grad_norm": 0.405558317899704,
      "learning_rate": 7.185901800275504e-06,
      "loss": 0.1671,
      "step": 17773
    },
    {
      "epoch": 0.2814256535300917,
      "grad_norm": 0.008325834758579731,
      "learning_rate": 7.185743464699084e-06,
      "loss": 0.0005,
      "step": 17774
    },
    {
      "epoch": 0.28144148708773375,
      "grad_norm": 0.778928816318512,
      "learning_rate": 7.185585129122663e-06,
      "loss": 0.2041,
      "step": 17775
    },
    {
      "epoch": 0.2814573206453758,
      "grad_norm": 0.4062158465385437,
      "learning_rate": 7.185426793546243e-06,
      "loss": 0.1659,
      "step": 17776
    },
    {
      "epoch": 0.2814731542030179,
      "grad_norm": 0.025966865941882133,
      "learning_rate": 7.185268457969822e-06,
      "loss": 0.0029,
      "step": 17777
    },
    {
      "epoch": 0.28148898776065995,
      "grad_norm": 0.005798404570668936,
      "learning_rate": 7.185110122393402e-06,
      "loss": 0.0003,
      "step": 17778
    },
    {
      "epoch": 0.281504821318302,
      "grad_norm": 0.2199632078409195,
      "learning_rate": 7.18495178681698e-06,
      "loss": 0.0475,
      "step": 17779
    },
    {
      "epoch": 0.2815206548759441,
      "grad_norm": 0.31997522711753845,
      "learning_rate": 7.18479345124056e-06,
      "loss": 0.1124,
      "step": 17780
    },
    {
      "epoch": 0.28153648843358614,
      "grad_norm": 0.45475268363952637,
      "learning_rate": 7.184635115664139e-06,
      "loss": 0.101,
      "step": 17781
    },
    {
      "epoch": 0.2815523219912282,
      "grad_norm": 0.034049052745103836,
      "learning_rate": 7.184476780087718e-06,
      "loss": 0.0018,
      "step": 17782
    },
    {
      "epoch": 0.28156815554887027,
      "grad_norm": 0.6521809697151184,
      "learning_rate": 7.184318444511298e-06,
      "loss": 0.3945,
      "step": 17783
    },
    {
      "epoch": 0.28158398910651233,
      "grad_norm": 0.00044554282794706523,
      "learning_rate": 7.1841601089348765e-06,
      "loss": 0.0,
      "step": 17784
    },
    {
      "epoch": 0.2815998226641544,
      "grad_norm": 0.2755964398384094,
      "learning_rate": 7.1840017733584564e-06,
      "loss": 0.0494,
      "step": 17785
    },
    {
      "epoch": 0.28161565622179646,
      "grad_norm": 0.7662052512168884,
      "learning_rate": 7.1838434377820355e-06,
      "loss": 0.5408,
      "step": 17786
    },
    {
      "epoch": 0.2816314897794385,
      "grad_norm": 0.3155094385147095,
      "learning_rate": 7.1836851022056154e-06,
      "loss": 0.0939,
      "step": 17787
    },
    {
      "epoch": 0.2816473233370806,
      "grad_norm": 0.41568028926849365,
      "learning_rate": 7.1835267666291945e-06,
      "loss": 0.1096,
      "step": 17788
    },
    {
      "epoch": 0.28166315689472265,
      "grad_norm": 0.00013745645992457867,
      "learning_rate": 7.1833684310527744e-06,
      "loss": 0.0,
      "step": 17789
    },
    {
      "epoch": 0.2816789904523647,
      "grad_norm": 0.3170241415500641,
      "learning_rate": 7.183210095476353e-06,
      "loss": 0.0406,
      "step": 17790
    },
    {
      "epoch": 0.2816948240100068,
      "grad_norm": 0.17075873911380768,
      "learning_rate": 7.183051759899933e-06,
      "loss": 0.0148,
      "step": 17791
    },
    {
      "epoch": 0.28171065756764885,
      "grad_norm": 0.4501796364784241,
      "learning_rate": 7.182893424323512e-06,
      "loss": 0.0967,
      "step": 17792
    },
    {
      "epoch": 0.28172649112529097,
      "grad_norm": 0.5669792890548706,
      "learning_rate": 7.182735088747092e-06,
      "loss": 0.1592,
      "step": 17793
    },
    {
      "epoch": 0.28174232468293303,
      "grad_norm": 0.1880849152803421,
      "learning_rate": 7.18257675317067e-06,
      "loss": 0.0781,
      "step": 17794
    },
    {
      "epoch": 0.2817581582405751,
      "grad_norm": 0.7421723008155823,
      "learning_rate": 7.18241841759425e-06,
      "loss": 0.428,
      "step": 17795
    },
    {
      "epoch": 0.28177399179821716,
      "grad_norm": 0.28427210450172424,
      "learning_rate": 7.182260082017829e-06,
      "loss": 0.0993,
      "step": 17796
    },
    {
      "epoch": 0.2817898253558592,
      "grad_norm": 0.5261095762252808,
      "learning_rate": 7.182101746441409e-06,
      "loss": 0.3103,
      "step": 17797
    },
    {
      "epoch": 0.2818056589135013,
      "grad_norm": 0.7340233325958252,
      "learning_rate": 7.181943410864988e-06,
      "loss": 0.9197,
      "step": 17798
    },
    {
      "epoch": 0.28182149247114335,
      "grad_norm": 0.01692000776529312,
      "learning_rate": 7.181785075288568e-06,
      "loss": 0.0008,
      "step": 17799
    },
    {
      "epoch": 0.2818373260287854,
      "grad_norm": 0.4061819314956665,
      "learning_rate": 7.181626739712146e-06,
      "loss": 0.0937,
      "step": 17800
    },
    {
      "epoch": 0.2818531595864275,
      "grad_norm": 1.2373968362808228,
      "learning_rate": 7.181468404135726e-06,
      "loss": 0.2098,
      "step": 17801
    },
    {
      "epoch": 0.28186899314406955,
      "grad_norm": 0.641348659992218,
      "learning_rate": 7.181310068559305e-06,
      "loss": 0.3746,
      "step": 17802
    },
    {
      "epoch": 0.2818848267017116,
      "grad_norm": 0.3025607168674469,
      "learning_rate": 7.181151732982885e-06,
      "loss": 0.0471,
      "step": 17803
    },
    {
      "epoch": 0.2819006602593537,
      "grad_norm": 0.0001020673880702816,
      "learning_rate": 7.180993397406464e-06,
      "loss": 0.0,
      "step": 17804
    },
    {
      "epoch": 0.28191649381699574,
      "grad_norm": 0.225687637925148,
      "learning_rate": 7.180835061830042e-06,
      "loss": 0.0608,
      "step": 17805
    },
    {
      "epoch": 0.2819323273746378,
      "grad_norm": 0.009163446724414825,
      "learning_rate": 7.180676726253622e-06,
      "loss": 0.0004,
      "step": 17806
    },
    {
      "epoch": 0.28194816093227987,
      "grad_norm": 0.26896414160728455,
      "learning_rate": 7.180518390677201e-06,
      "loss": 0.0402,
      "step": 17807
    },
    {
      "epoch": 0.28196399448992193,
      "grad_norm": 0.0007925222162157297,
      "learning_rate": 7.180360055100781e-06,
      "loss": 0.0,
      "step": 17808
    },
    {
      "epoch": 0.281979828047564,
      "grad_norm": 0.210981085896492,
      "learning_rate": 7.18020171952436e-06,
      "loss": 0.0289,
      "step": 17809
    },
    {
      "epoch": 0.28199566160520606,
      "grad_norm": 0.6293541193008423,
      "learning_rate": 7.18004338394794e-06,
      "loss": 0.0639,
      "step": 17810
    },
    {
      "epoch": 0.2820114951628481,
      "grad_norm": 0.2296837568283081,
      "learning_rate": 7.1798850483715184e-06,
      "loss": 0.0474,
      "step": 17811
    },
    {
      "epoch": 0.2820273287204902,
      "grad_norm": 0.4232606589794159,
      "learning_rate": 7.179726712795098e-06,
      "loss": 0.0074,
      "step": 17812
    },
    {
      "epoch": 0.28204316227813225,
      "grad_norm": 0.033221080899238586,
      "learning_rate": 7.1795683772186774e-06,
      "loss": 0.0017,
      "step": 17813
    },
    {
      "epoch": 0.2820589958357743,
      "grad_norm": 0.395118772983551,
      "learning_rate": 7.179410041642257e-06,
      "loss": 0.1749,
      "step": 17814
    },
    {
      "epoch": 0.2820748293934164,
      "grad_norm": 0.008695926517248154,
      "learning_rate": 7.1792517060658364e-06,
      "loss": 0.0004,
      "step": 17815
    },
    {
      "epoch": 0.28209066295105845,
      "grad_norm": 0.2013959139585495,
      "learning_rate": 7.179093370489416e-06,
      "loss": 0.0558,
      "step": 17816
    },
    {
      "epoch": 0.28210649650870057,
      "grad_norm": 0.00048399216029793024,
      "learning_rate": 7.178935034912995e-06,
      "loss": 0.0,
      "step": 17817
    },
    {
      "epoch": 0.28212233006634263,
      "grad_norm": 0.013895264826714993,
      "learning_rate": 7.1787766993365745e-06,
      "loss": 0.0007,
      "step": 17818
    },
    {
      "epoch": 0.2821381636239847,
      "grad_norm": 0.5279363393783569,
      "learning_rate": 7.178618363760154e-06,
      "loss": 0.0446,
      "step": 17819
    },
    {
      "epoch": 0.28215399718162676,
      "grad_norm": 0.029427042230963707,
      "learning_rate": 7.1784600281837335e-06,
      "loss": 0.0014,
      "step": 17820
    },
    {
      "epoch": 0.2821698307392688,
      "grad_norm": 0.18245159089565277,
      "learning_rate": 7.178301692607313e-06,
      "loss": 0.0199,
      "step": 17821
    },
    {
      "epoch": 0.2821856642969109,
      "grad_norm": 0.3020923137664795,
      "learning_rate": 7.1781433570308925e-06,
      "loss": 0.0799,
      "step": 17822
    },
    {
      "epoch": 0.28220149785455295,
      "grad_norm": 0.7711015939712524,
      "learning_rate": 7.177985021454471e-06,
      "loss": 0.2733,
      "step": 17823
    },
    {
      "epoch": 0.282217331412195,
      "grad_norm": 0.7873954772949219,
      "learning_rate": 7.177826685878051e-06,
      "loss": 0.7241,
      "step": 17824
    },
    {
      "epoch": 0.2822331649698371,
      "grad_norm": 0.028343772515654564,
      "learning_rate": 7.17766835030163e-06,
      "loss": 0.0014,
      "step": 17825
    },
    {
      "epoch": 0.28224899852747914,
      "grad_norm": 0.49364620447158813,
      "learning_rate": 7.17751001472521e-06,
      "loss": 0.0858,
      "step": 17826
    },
    {
      "epoch": 0.2822648320851212,
      "grad_norm": 0.32792389392852783,
      "learning_rate": 7.177351679148789e-06,
      "loss": 0.1878,
      "step": 17827
    },
    {
      "epoch": 0.2822806656427633,
      "grad_norm": 0.3043235242366791,
      "learning_rate": 7.177193343572369e-06,
      "loss": 0.0559,
      "step": 17828
    },
    {
      "epoch": 0.28229649920040534,
      "grad_norm": 0.012908176518976688,
      "learning_rate": 7.177035007995947e-06,
      "loss": 0.0005,
      "step": 17829
    },
    {
      "epoch": 0.2823123327580474,
      "grad_norm": 0.6456815004348755,
      "learning_rate": 7.176876672419526e-06,
      "loss": 0.3032,
      "step": 17830
    },
    {
      "epoch": 0.28232816631568947,
      "grad_norm": 0.3302017152309418,
      "learning_rate": 7.176718336843106e-06,
      "loss": 0.058,
      "step": 17831
    },
    {
      "epoch": 0.28234399987333153,
      "grad_norm": 0.02014932595193386,
      "learning_rate": 7.176560001266685e-06,
      "loss": 0.0009,
      "step": 17832
    },
    {
      "epoch": 0.2823598334309736,
      "grad_norm": 0.4954899549484253,
      "learning_rate": 7.176401665690265e-06,
      "loss": 0.0823,
      "step": 17833
    },
    {
      "epoch": 0.28237566698861566,
      "grad_norm": 0.0112468171864748,
      "learning_rate": 7.176243330113843e-06,
      "loss": 0.0004,
      "step": 17834
    },
    {
      "epoch": 0.2823915005462577,
      "grad_norm": 0.24529896676540375,
      "learning_rate": 7.176084994537423e-06,
      "loss": 0.0896,
      "step": 17835
    },
    {
      "epoch": 0.2824073341038998,
      "grad_norm": 0.41164684295654297,
      "learning_rate": 7.175926658961002e-06,
      "loss": 0.1415,
      "step": 17836
    },
    {
      "epoch": 0.28242316766154185,
      "grad_norm": 0.38802582025527954,
      "learning_rate": 7.175768323384582e-06,
      "loss": 0.2508,
      "step": 17837
    },
    {
      "epoch": 0.2824390012191839,
      "grad_norm": 0.32637032866477966,
      "learning_rate": 7.175609987808161e-06,
      "loss": 0.0769,
      "step": 17838
    },
    {
      "epoch": 0.282454834776826,
      "grad_norm": 0.2132846862077713,
      "learning_rate": 7.175451652231741e-06,
      "loss": 0.0274,
      "step": 17839
    },
    {
      "epoch": 0.28247066833446804,
      "grad_norm": 0.00913164485245943,
      "learning_rate": 7.175293316655319e-06,
      "loss": 0.0004,
      "step": 17840
    },
    {
      "epoch": 0.28248650189211016,
      "grad_norm": 0.8312642574310303,
      "learning_rate": 7.175134981078899e-06,
      "loss": 0.3712,
      "step": 17841
    },
    {
      "epoch": 0.28250233544975223,
      "grad_norm": 0.35797688364982605,
      "learning_rate": 7.174976645502478e-06,
      "loss": 0.1198,
      "step": 17842
    },
    {
      "epoch": 0.2825181690073943,
      "grad_norm": 0.31867411732673645,
      "learning_rate": 7.174818309926058e-06,
      "loss": 0.1482,
      "step": 17843
    },
    {
      "epoch": 0.28253400256503636,
      "grad_norm": 0.13196596503257751,
      "learning_rate": 7.174659974349637e-06,
      "loss": 0.0543,
      "step": 17844
    },
    {
      "epoch": 0.2825498361226784,
      "grad_norm": 0.010418449528515339,
      "learning_rate": 7.174501638773217e-06,
      "loss": 0.0003,
      "step": 17845
    },
    {
      "epoch": 0.2825656696803205,
      "grad_norm": 0.5034393072128296,
      "learning_rate": 7.1743433031967955e-06,
      "loss": 0.1511,
      "step": 17846
    },
    {
      "epoch": 0.28258150323796255,
      "grad_norm": 0.27687370777130127,
      "learning_rate": 7.1741849676203755e-06,
      "loss": 0.0404,
      "step": 17847
    },
    {
      "epoch": 0.2825973367956046,
      "grad_norm": 0.35400378704071045,
      "learning_rate": 7.1740266320439545e-06,
      "loss": 0.0723,
      "step": 17848
    },
    {
      "epoch": 0.2826131703532467,
      "grad_norm": 0.05465111881494522,
      "learning_rate": 7.1738682964675345e-06,
      "loss": 0.0026,
      "step": 17849
    },
    {
      "epoch": 0.28262900391088874,
      "grad_norm": 0.1533748209476471,
      "learning_rate": 7.1737099608911135e-06,
      "loss": 0.0367,
      "step": 17850
    },
    {
      "epoch": 0.2826448374685308,
      "grad_norm": 0.04339286684989929,
      "learning_rate": 7.1735516253146935e-06,
      "loss": 0.0023,
      "step": 17851
    },
    {
      "epoch": 0.28266067102617287,
      "grad_norm": 0.43789660930633545,
      "learning_rate": 7.173393289738272e-06,
      "loss": 0.1157,
      "step": 17852
    },
    {
      "epoch": 0.28267650458381494,
      "grad_norm": 1.7690123319625854,
      "learning_rate": 7.173234954161851e-06,
      "loss": 0.6815,
      "step": 17853
    },
    {
      "epoch": 0.282692338141457,
      "grad_norm": 0.004389538429677486,
      "learning_rate": 7.173076618585431e-06,
      "loss": 0.0002,
      "step": 17854
    },
    {
      "epoch": 0.28270817169909906,
      "grad_norm": 0.26693347096443176,
      "learning_rate": 7.17291828300901e-06,
      "loss": 0.0573,
      "step": 17855
    },
    {
      "epoch": 0.28272400525674113,
      "grad_norm": 0.3474361300468445,
      "learning_rate": 7.17275994743259e-06,
      "loss": 0.1523,
      "step": 17856
    },
    {
      "epoch": 0.2827398388143832,
      "grad_norm": 0.3589973449707031,
      "learning_rate": 7.172601611856168e-06,
      "loss": 0.1113,
      "step": 17857
    },
    {
      "epoch": 0.28275567237202526,
      "grad_norm": 0.017221173271536827,
      "learning_rate": 7.172443276279748e-06,
      "loss": 0.0008,
      "step": 17858
    },
    {
      "epoch": 0.2827715059296673,
      "grad_norm": 0.4833977222442627,
      "learning_rate": 7.172284940703327e-06,
      "loss": 0.2361,
      "step": 17859
    },
    {
      "epoch": 0.2827873394873094,
      "grad_norm": 0.2587890028953552,
      "learning_rate": 7.172126605126907e-06,
      "loss": 0.043,
      "step": 17860
    },
    {
      "epoch": 0.28280317304495145,
      "grad_norm": 0.61297607421875,
      "learning_rate": 7.171968269550485e-06,
      "loss": 0.1283,
      "step": 17861
    },
    {
      "epoch": 0.2828190066025935,
      "grad_norm": 0.04778354987502098,
      "learning_rate": 7.171809933974065e-06,
      "loss": 0.0026,
      "step": 17862
    },
    {
      "epoch": 0.2828348401602356,
      "grad_norm": 0.5071398019790649,
      "learning_rate": 7.171651598397644e-06,
      "loss": 0.1821,
      "step": 17863
    },
    {
      "epoch": 0.28285067371787764,
      "grad_norm": 0.6483977437019348,
      "learning_rate": 7.171493262821224e-06,
      "loss": 0.2299,
      "step": 17864
    },
    {
      "epoch": 0.28286650727551976,
      "grad_norm": 0.4597427248954773,
      "learning_rate": 7.171334927244803e-06,
      "loss": 0.105,
      "step": 17865
    },
    {
      "epoch": 0.2828823408331618,
      "grad_norm": 0.010707211680710316,
      "learning_rate": 7.171176591668383e-06,
      "loss": 0.0005,
      "step": 17866
    },
    {
      "epoch": 0.2828981743908039,
      "grad_norm": 0.002146495273336768,
      "learning_rate": 7.171018256091961e-06,
      "loss": 0.0,
      "step": 17867
    },
    {
      "epoch": 0.28291400794844596,
      "grad_norm": 0.00015784033166710287,
      "learning_rate": 7.170859920515541e-06,
      "loss": 0.0,
      "step": 17868
    },
    {
      "epoch": 0.282929841506088,
      "grad_norm": 0.29305392503738403,
      "learning_rate": 7.17070158493912e-06,
      "loss": 0.0999,
      "step": 17869
    },
    {
      "epoch": 0.2829456750637301,
      "grad_norm": 0.00020284678612370044,
      "learning_rate": 7.1705432493627e-06,
      "loss": 0.0,
      "step": 17870
    },
    {
      "epoch": 0.28296150862137215,
      "grad_norm": 0.3560439348220825,
      "learning_rate": 7.170384913786279e-06,
      "loss": 0.103,
      "step": 17871
    },
    {
      "epoch": 0.2829773421790142,
      "grad_norm": 0.33058029413223267,
      "learning_rate": 7.170226578209859e-06,
      "loss": 0.1229,
      "step": 17872
    },
    {
      "epoch": 0.2829931757366563,
      "grad_norm": 0.24792484939098358,
      "learning_rate": 7.1700682426334375e-06,
      "loss": 0.0533,
      "step": 17873
    },
    {
      "epoch": 0.28300900929429834,
      "grad_norm": 0.5855307579040527,
      "learning_rate": 7.169909907057017e-06,
      "loss": 0.4293,
      "step": 17874
    },
    {
      "epoch": 0.2830248428519404,
      "grad_norm": 0.3067329525947571,
      "learning_rate": 7.1697515714805965e-06,
      "loss": 0.0655,
      "step": 17875
    },
    {
      "epoch": 0.28304067640958247,
      "grad_norm": 8.222043834393844e-05,
      "learning_rate": 7.169593235904176e-06,
      "loss": 0.0,
      "step": 17876
    },
    {
      "epoch": 0.28305650996722453,
      "grad_norm": 0.5020509958267212,
      "learning_rate": 7.1694349003277555e-06,
      "loss": 0.0445,
      "step": 17877
    },
    {
      "epoch": 0.2830723435248666,
      "grad_norm": 0.05945040285587311,
      "learning_rate": 7.169276564751334e-06,
      "loss": 0.0023,
      "step": 17878
    },
    {
      "epoch": 0.28308817708250866,
      "grad_norm": 0.48307961225509644,
      "learning_rate": 7.169118229174914e-06,
      "loss": 0.1829,
      "step": 17879
    },
    {
      "epoch": 0.2831040106401507,
      "grad_norm": 0.0019521871581673622,
      "learning_rate": 7.168959893598493e-06,
      "loss": 0.0,
      "step": 17880
    },
    {
      "epoch": 0.2831198441977928,
      "grad_norm": 0.004068724811077118,
      "learning_rate": 7.168801558022073e-06,
      "loss": 0.0001,
      "step": 17881
    },
    {
      "epoch": 0.28313567775543486,
      "grad_norm": 0.3061870038509369,
      "learning_rate": 7.168643222445652e-06,
      "loss": 0.0935,
      "step": 17882
    },
    {
      "epoch": 0.2831515113130769,
      "grad_norm": 6.940018647583202e-05,
      "learning_rate": 7.168484886869232e-06,
      "loss": 0.0,
      "step": 17883
    },
    {
      "epoch": 0.283167344870719,
      "grad_norm": 0.004330026917159557,
      "learning_rate": 7.16832655129281e-06,
      "loss": 0.0002,
      "step": 17884
    },
    {
      "epoch": 0.28318317842836105,
      "grad_norm": 0.0005585206672549248,
      "learning_rate": 7.16816821571639e-06,
      "loss": 0.0,
      "step": 17885
    },
    {
      "epoch": 0.2831990119860031,
      "grad_norm": 0.007323659956455231,
      "learning_rate": 7.168009880139969e-06,
      "loss": 0.0003,
      "step": 17886
    },
    {
      "epoch": 0.2832148455436452,
      "grad_norm": 0.20209893584251404,
      "learning_rate": 7.167851544563549e-06,
      "loss": 0.0805,
      "step": 17887
    },
    {
      "epoch": 0.28323067910128724,
      "grad_norm": 0.009702904149889946,
      "learning_rate": 7.167693208987128e-06,
      "loss": 0.0004,
      "step": 17888
    },
    {
      "epoch": 0.28324651265892936,
      "grad_norm": 0.2985529899597168,
      "learning_rate": 7.167534873410708e-06,
      "loss": 0.0784,
      "step": 17889
    },
    {
      "epoch": 0.2832623462165714,
      "grad_norm": 0.4210996627807617,
      "learning_rate": 7.167376537834286e-06,
      "loss": 0.0539,
      "step": 17890
    },
    {
      "epoch": 0.2832781797742135,
      "grad_norm": 0.2890188992023468,
      "learning_rate": 7.167218202257866e-06,
      "loss": 0.1184,
      "step": 17891
    },
    {
      "epoch": 0.28329401333185555,
      "grad_norm": 0.002344823209568858,
      "learning_rate": 7.167059866681445e-06,
      "loss": 0.0001,
      "step": 17892
    },
    {
      "epoch": 0.2833098468894976,
      "grad_norm": 0.00019906414672732353,
      "learning_rate": 7.166901531105025e-06,
      "loss": 0.0,
      "step": 17893
    },
    {
      "epoch": 0.2833256804471397,
      "grad_norm": 0.3817972242832184,
      "learning_rate": 7.166743195528604e-06,
      "loss": 0.1795,
      "step": 17894
    },
    {
      "epoch": 0.28334151400478175,
      "grad_norm": 0.3094182312488556,
      "learning_rate": 7.166584859952184e-06,
      "loss": 0.0755,
      "step": 17895
    },
    {
      "epoch": 0.2833573475624238,
      "grad_norm": 0.6259627342224121,
      "learning_rate": 7.166426524375762e-06,
      "loss": 0.2636,
      "step": 17896
    },
    {
      "epoch": 0.2833731811200659,
      "grad_norm": 1.4581042528152466,
      "learning_rate": 7.166268188799342e-06,
      "loss": 0.1425,
      "step": 17897
    },
    {
      "epoch": 0.28338901467770794,
      "grad_norm": 1.2045178413391113,
      "learning_rate": 7.166109853222921e-06,
      "loss": 0.6004,
      "step": 17898
    },
    {
      "epoch": 0.28340484823535,
      "grad_norm": 0.08013560622930527,
      "learning_rate": 7.165951517646501e-06,
      "loss": 0.0051,
      "step": 17899
    },
    {
      "epoch": 0.28342068179299207,
      "grad_norm": 0.0003649865393526852,
      "learning_rate": 7.16579318207008e-06,
      "loss": 0.0,
      "step": 17900
    },
    {
      "epoch": 0.28343651535063413,
      "grad_norm": 0.7738956809043884,
      "learning_rate": 7.1656348464936585e-06,
      "loss": 0.1839,
      "step": 17901
    },
    {
      "epoch": 0.2834523489082762,
      "grad_norm": 0.024734174832701683,
      "learning_rate": 7.165476510917238e-06,
      "loss": 0.0018,
      "step": 17902
    },
    {
      "epoch": 0.28346818246591826,
      "grad_norm": 0.20680032670497894,
      "learning_rate": 7.1653181753408175e-06,
      "loss": 0.074,
      "step": 17903
    },
    {
      "epoch": 0.2834840160235603,
      "grad_norm": 0.000621646351646632,
      "learning_rate": 7.165159839764397e-06,
      "loss": 0.0,
      "step": 17904
    },
    {
      "epoch": 0.2834998495812024,
      "grad_norm": 1.7562772035598755,
      "learning_rate": 7.1650015041879765e-06,
      "loss": 0.429,
      "step": 17905
    },
    {
      "epoch": 0.28351568313884445,
      "grad_norm": 0.46384382247924805,
      "learning_rate": 7.164843168611556e-06,
      "loss": 0.1855,
      "step": 17906
    },
    {
      "epoch": 0.2835315166964865,
      "grad_norm": 0.6514800786972046,
      "learning_rate": 7.164684833035135e-06,
      "loss": 0.4773,
      "step": 17907
    },
    {
      "epoch": 0.2835473502541286,
      "grad_norm": 0.4103896915912628,
      "learning_rate": 7.1645264974587146e-06,
      "loss": 0.1418,
      "step": 17908
    },
    {
      "epoch": 0.28356318381177065,
      "grad_norm": 0.3573497235774994,
      "learning_rate": 7.164368161882294e-06,
      "loss": 0.0527,
      "step": 17909
    },
    {
      "epoch": 0.2835790173694127,
      "grad_norm": 0.2882820665836334,
      "learning_rate": 7.1642098263058736e-06,
      "loss": 0.0557,
      "step": 17910
    },
    {
      "epoch": 0.2835948509270548,
      "grad_norm": 0.01659492589533329,
      "learning_rate": 7.164051490729453e-06,
      "loss": 0.0008,
      "step": 17911
    },
    {
      "epoch": 0.28361068448469684,
      "grad_norm": 0.7267804145812988,
      "learning_rate": 7.1638931551530326e-06,
      "loss": 0.892,
      "step": 17912
    },
    {
      "epoch": 0.28362651804233896,
      "grad_norm": 0.01709543541073799,
      "learning_rate": 7.163734819576611e-06,
      "loss": 0.0008,
      "step": 17913
    },
    {
      "epoch": 0.283642351599981,
      "grad_norm": 0.26243630051612854,
      "learning_rate": 7.163576484000191e-06,
      "loss": 0.0431,
      "step": 17914
    },
    {
      "epoch": 0.2836581851576231,
      "grad_norm": 0.7572354078292847,
      "learning_rate": 7.16341814842377e-06,
      "loss": 1.5875,
      "step": 17915
    },
    {
      "epoch": 0.28367401871526515,
      "grad_norm": 0.00041078354115597904,
      "learning_rate": 7.16325981284735e-06,
      "loss": 0.0,
      "step": 17916
    },
    {
      "epoch": 0.2836898522729072,
      "grad_norm": 0.36816760897636414,
      "learning_rate": 7.163101477270929e-06,
      "loss": 0.1332,
      "step": 17917
    },
    {
      "epoch": 0.2837056858305493,
      "grad_norm": 0.7060426473617554,
      "learning_rate": 7.162943141694509e-06,
      "loss": 0.094,
      "step": 17918
    },
    {
      "epoch": 0.28372151938819135,
      "grad_norm": 0.18999522924423218,
      "learning_rate": 7.162784806118087e-06,
      "loss": 0.0196,
      "step": 17919
    },
    {
      "epoch": 0.2837373529458334,
      "grad_norm": 0.4243584871292114,
      "learning_rate": 7.162626470541667e-06,
      "loss": 0.1807,
      "step": 17920
    },
    {
      "epoch": 0.2837531865034755,
      "grad_norm": 0.6290603280067444,
      "learning_rate": 7.162468134965246e-06,
      "loss": 0.2805,
      "step": 17921
    },
    {
      "epoch": 0.28376902006111754,
      "grad_norm": 0.8555884957313538,
      "learning_rate": 7.162309799388826e-06,
      "loss": 0.5889,
      "step": 17922
    },
    {
      "epoch": 0.2837848536187596,
      "grad_norm": 0.7325001358985901,
      "learning_rate": 7.162151463812404e-06,
      "loss": 0.5614,
      "step": 17923
    },
    {
      "epoch": 0.28380068717640167,
      "grad_norm": 0.5248745083808899,
      "learning_rate": 7.161993128235984e-06,
      "loss": 0.2767,
      "step": 17924
    },
    {
      "epoch": 0.28381652073404373,
      "grad_norm": 0.2863486707210541,
      "learning_rate": 7.161834792659563e-06,
      "loss": 0.0744,
      "step": 17925
    },
    {
      "epoch": 0.2838323542916858,
      "grad_norm": 0.7790817618370056,
      "learning_rate": 7.161676457083142e-06,
      "loss": 0.0099,
      "step": 17926
    },
    {
      "epoch": 0.28384818784932786,
      "grad_norm": 0.24583040177822113,
      "learning_rate": 7.161518121506722e-06,
      "loss": 0.0713,
      "step": 17927
    },
    {
      "epoch": 0.2838640214069699,
      "grad_norm": 0.7549557685852051,
      "learning_rate": 7.1613597859303e-06,
      "loss": 0.336,
      "step": 17928
    },
    {
      "epoch": 0.283879854964612,
      "grad_norm": 1.096677303314209,
      "learning_rate": 7.16120145035388e-06,
      "loss": 0.0674,
      "step": 17929
    },
    {
      "epoch": 0.28389568852225405,
      "grad_norm": 0.37152308225631714,
      "learning_rate": 7.161043114777459e-06,
      "loss": 0.0547,
      "step": 17930
    },
    {
      "epoch": 0.2839115220798961,
      "grad_norm": 0.27224311232566833,
      "learning_rate": 7.160884779201039e-06,
      "loss": 0.1001,
      "step": 17931
    },
    {
      "epoch": 0.2839273556375382,
      "grad_norm": 0.5994533896446228,
      "learning_rate": 7.160726443624618e-06,
      "loss": 0.6011,
      "step": 17932
    },
    {
      "epoch": 0.28394318919518025,
      "grad_norm": 0.28549516201019287,
      "learning_rate": 7.160568108048198e-06,
      "loss": 0.0679,
      "step": 17933
    },
    {
      "epoch": 0.2839590227528223,
      "grad_norm": 0.349650502204895,
      "learning_rate": 7.1604097724717766e-06,
      "loss": 0.1334,
      "step": 17934
    },
    {
      "epoch": 0.2839748563104644,
      "grad_norm": 0.0366877056658268,
      "learning_rate": 7.1602514368953565e-06,
      "loss": 0.0018,
      "step": 17935
    },
    {
      "epoch": 0.28399068986810644,
      "grad_norm": 0.4462911784648895,
      "learning_rate": 7.1600931013189356e-06,
      "loss": 0.1443,
      "step": 17936
    },
    {
      "epoch": 0.28400652342574856,
      "grad_norm": 0.22602106630802155,
      "learning_rate": 7.1599347657425155e-06,
      "loss": 0.0815,
      "step": 17937
    },
    {
      "epoch": 0.2840223569833906,
      "grad_norm": 0.007869030348956585,
      "learning_rate": 7.1597764301660946e-06,
      "loss": 0.0004,
      "step": 17938
    },
    {
      "epoch": 0.2840381905410327,
      "grad_norm": 0.00021320341329555959,
      "learning_rate": 7.1596180945896745e-06,
      "loss": 0.0,
      "step": 17939
    },
    {
      "epoch": 0.28405402409867475,
      "grad_norm": 0.48472610116004944,
      "learning_rate": 7.159459759013253e-06,
      "loss": 0.3377,
      "step": 17940
    },
    {
      "epoch": 0.2840698576563168,
      "grad_norm": 0.005149205680936575,
      "learning_rate": 7.159301423436833e-06,
      "loss": 0.0002,
      "step": 17941
    },
    {
      "epoch": 0.2840856912139589,
      "grad_norm": 0.7951223254203796,
      "learning_rate": 7.159143087860412e-06,
      "loss": 0.5016,
      "step": 17942
    },
    {
      "epoch": 0.28410152477160094,
      "grad_norm": 0.23909710347652435,
      "learning_rate": 7.158984752283992e-06,
      "loss": 0.0531,
      "step": 17943
    },
    {
      "epoch": 0.284117358329243,
      "grad_norm": 0.36562567949295044,
      "learning_rate": 7.158826416707571e-06,
      "loss": 0.0406,
      "step": 17944
    },
    {
      "epoch": 0.2841331918868851,
      "grad_norm": 0.3965391218662262,
      "learning_rate": 7.158668081131151e-06,
      "loss": 0.0983,
      "step": 17945
    },
    {
      "epoch": 0.28414902544452714,
      "grad_norm": 0.6379627585411072,
      "learning_rate": 7.158509745554729e-06,
      "loss": 0.0889,
      "step": 17946
    },
    {
      "epoch": 0.2841648590021692,
      "grad_norm": 0.1607012003660202,
      "learning_rate": 7.158351409978309e-06,
      "loss": 0.0122,
      "step": 17947
    },
    {
      "epoch": 0.28418069255981127,
      "grad_norm": 0.3085598945617676,
      "learning_rate": 7.158193074401888e-06,
      "loss": 0.0585,
      "step": 17948
    },
    {
      "epoch": 0.28419652611745333,
      "grad_norm": 0.4119409918785095,
      "learning_rate": 7.158034738825467e-06,
      "loss": 0.0712,
      "step": 17949
    },
    {
      "epoch": 0.2842123596750954,
      "grad_norm": 0.0001235155068570748,
      "learning_rate": 7.157876403249047e-06,
      "loss": 0.0,
      "step": 17950
    },
    {
      "epoch": 0.28422819323273746,
      "grad_norm": 0.00257129711098969,
      "learning_rate": 7.157718067672625e-06,
      "loss": 0.0,
      "step": 17951
    },
    {
      "epoch": 0.2842440267903795,
      "grad_norm": 0.2887989580631256,
      "learning_rate": 7.157559732096205e-06,
      "loss": 0.1367,
      "step": 17952
    },
    {
      "epoch": 0.2842598603480216,
      "grad_norm": 0.6909843683242798,
      "learning_rate": 7.157401396519784e-06,
      "loss": 0.0272,
      "step": 17953
    },
    {
      "epoch": 0.28427569390566365,
      "grad_norm": 0.010167884640395641,
      "learning_rate": 7.157243060943364e-06,
      "loss": 0.0005,
      "step": 17954
    },
    {
      "epoch": 0.2842915274633057,
      "grad_norm": 0.1412908285856247,
      "learning_rate": 7.157084725366943e-06,
      "loss": 0.0063,
      "step": 17955
    },
    {
      "epoch": 0.2843073610209478,
      "grad_norm": 0.4695977568626404,
      "learning_rate": 7.156926389790523e-06,
      "loss": 0.0443,
      "step": 17956
    },
    {
      "epoch": 0.28432319457858984,
      "grad_norm": 0.006037506740540266,
      "learning_rate": 7.156768054214101e-06,
      "loss": 0.0003,
      "step": 17957
    },
    {
      "epoch": 0.2843390281362319,
      "grad_norm": 0.28000685572624207,
      "learning_rate": 7.156609718637681e-06,
      "loss": 0.0779,
      "step": 17958
    },
    {
      "epoch": 0.284354861693874,
      "grad_norm": 0.6402414441108704,
      "learning_rate": 7.15645138306126e-06,
      "loss": 0.1126,
      "step": 17959
    },
    {
      "epoch": 0.28437069525151604,
      "grad_norm": 0.33783143758773804,
      "learning_rate": 7.15629304748484e-06,
      "loss": 0.1492,
      "step": 17960
    },
    {
      "epoch": 0.28438652880915816,
      "grad_norm": 0.031224088743329048,
      "learning_rate": 7.156134711908419e-06,
      "loss": 0.0031,
      "step": 17961
    },
    {
      "epoch": 0.2844023623668002,
      "grad_norm": 0.061661384999752045,
      "learning_rate": 7.155976376331999e-06,
      "loss": 0.0022,
      "step": 17962
    },
    {
      "epoch": 0.2844181959244423,
      "grad_norm": 0.4558444619178772,
      "learning_rate": 7.1558180407555775e-06,
      "loss": 0.1841,
      "step": 17963
    },
    {
      "epoch": 0.28443402948208435,
      "grad_norm": 0.21036174893379211,
      "learning_rate": 7.155659705179157e-06,
      "loss": 0.0391,
      "step": 17964
    },
    {
      "epoch": 0.2844498630397264,
      "grad_norm": 0.40616029500961304,
      "learning_rate": 7.1555013696027365e-06,
      "loss": 0.0915,
      "step": 17965
    },
    {
      "epoch": 0.2844656965973685,
      "grad_norm": 0.1934005171060562,
      "learning_rate": 7.155343034026316e-06,
      "loss": 0.07,
      "step": 17966
    },
    {
      "epoch": 0.28448153015501054,
      "grad_norm": 0.5533999800682068,
      "learning_rate": 7.1551846984498955e-06,
      "loss": 0.1351,
      "step": 17967
    },
    {
      "epoch": 0.2844973637126526,
      "grad_norm": 3.395760359126143e-05,
      "learning_rate": 7.1550263628734754e-06,
      "loss": 0.0,
      "step": 17968
    },
    {
      "epoch": 0.28451319727029467,
      "grad_norm": 0.43485841155052185,
      "learning_rate": 7.154868027297054e-06,
      "loss": 0.0857,
      "step": 17969
    },
    {
      "epoch": 0.28452903082793674,
      "grad_norm": 0.032727163285017014,
      "learning_rate": 7.154709691720634e-06,
      "loss": 0.0022,
      "step": 17970
    },
    {
      "epoch": 0.2845448643855788,
      "grad_norm": 0.6712021827697754,
      "learning_rate": 7.154551356144213e-06,
      "loss": 0.4624,
      "step": 17971
    },
    {
      "epoch": 0.28456069794322086,
      "grad_norm": 0.43938305974006653,
      "learning_rate": 7.154393020567793e-06,
      "loss": 0.2574,
      "step": 17972
    },
    {
      "epoch": 0.28457653150086293,
      "grad_norm": 0.6445894837379456,
      "learning_rate": 7.154234684991372e-06,
      "loss": 0.2741,
      "step": 17973
    },
    {
      "epoch": 0.284592365058505,
      "grad_norm": 0.3145301640033722,
      "learning_rate": 7.15407634941495e-06,
      "loss": 0.1086,
      "step": 17974
    },
    {
      "epoch": 0.28460819861614706,
      "grad_norm": 0.028416050598025322,
      "learning_rate": 7.15391801383853e-06,
      "loss": 0.0011,
      "step": 17975
    },
    {
      "epoch": 0.2846240321737891,
      "grad_norm": 0.4699201285839081,
      "learning_rate": 7.153759678262109e-06,
      "loss": 0.2469,
      "step": 17976
    },
    {
      "epoch": 0.2846398657314312,
      "grad_norm": 0.32455193996429443,
      "learning_rate": 7.153601342685689e-06,
      "loss": 0.0661,
      "step": 17977
    },
    {
      "epoch": 0.28465569928907325,
      "grad_norm": 0.6327435970306396,
      "learning_rate": 7.153443007109268e-06,
      "loss": 0.1227,
      "step": 17978
    },
    {
      "epoch": 0.2846715328467153,
      "grad_norm": 0.39645901322364807,
      "learning_rate": 7.153284671532848e-06,
      "loss": 0.0538,
      "step": 17979
    },
    {
      "epoch": 0.2846873664043574,
      "grad_norm": 0.5537647604942322,
      "learning_rate": 7.153126335956426e-06,
      "loss": 0.0975,
      "step": 17980
    },
    {
      "epoch": 0.28470319996199944,
      "grad_norm": 0.007868565618991852,
      "learning_rate": 7.152968000380006e-06,
      "loss": 0.0003,
      "step": 17981
    },
    {
      "epoch": 0.2847190335196415,
      "grad_norm": 0.2027207911014557,
      "learning_rate": 7.152809664803585e-06,
      "loss": 0.1047,
      "step": 17982
    },
    {
      "epoch": 0.28473486707728357,
      "grad_norm": 0.005874092690646648,
      "learning_rate": 7.152651329227165e-06,
      "loss": 0.0002,
      "step": 17983
    },
    {
      "epoch": 0.28475070063492564,
      "grad_norm": 0.08154549449682236,
      "learning_rate": 7.152492993650744e-06,
      "loss": 0.0078,
      "step": 17984
    },
    {
      "epoch": 0.28476653419256776,
      "grad_norm": 0.7559195160865784,
      "learning_rate": 7.152334658074323e-06,
      "loss": 0.3738,
      "step": 17985
    },
    {
      "epoch": 0.2847823677502098,
      "grad_norm": 0.00045472889905795455,
      "learning_rate": 7.152176322497902e-06,
      "loss": 0.0,
      "step": 17986
    },
    {
      "epoch": 0.2847982013078519,
      "grad_norm": 0.5281296968460083,
      "learning_rate": 7.152017986921482e-06,
      "loss": 0.1824,
      "step": 17987
    },
    {
      "epoch": 0.28481403486549395,
      "grad_norm": 0.840833306312561,
      "learning_rate": 7.151859651345061e-06,
      "loss": 0.4407,
      "step": 17988
    },
    {
      "epoch": 0.284829868423136,
      "grad_norm": 0.00029033049941062927,
      "learning_rate": 7.151701315768641e-06,
      "loss": 0.0,
      "step": 17989
    },
    {
      "epoch": 0.2848457019807781,
      "grad_norm": 0.37257370352745056,
      "learning_rate": 7.151542980192219e-06,
      "loss": 0.0863,
      "step": 17990
    },
    {
      "epoch": 0.28486153553842014,
      "grad_norm": 0.01734391413629055,
      "learning_rate": 7.151384644615799e-06,
      "loss": 0.0005,
      "step": 17991
    },
    {
      "epoch": 0.2848773690960622,
      "grad_norm": 0.2765234708786011,
      "learning_rate": 7.151226309039378e-06,
      "loss": 0.0454,
      "step": 17992
    },
    {
      "epoch": 0.28489320265370427,
      "grad_norm": 0.5608179569244385,
      "learning_rate": 7.151067973462958e-06,
      "loss": 0.0653,
      "step": 17993
    },
    {
      "epoch": 0.28490903621134633,
      "grad_norm": 0.00012294741463847458,
      "learning_rate": 7.1509096378865374e-06,
      "loss": 0.0,
      "step": 17994
    },
    {
      "epoch": 0.2849248697689884,
      "grad_norm": 0.43181583285331726,
      "learning_rate": 7.150751302310117e-06,
      "loss": 0.2361,
      "step": 17995
    },
    {
      "epoch": 0.28494070332663046,
      "grad_norm": 0.5800723433494568,
      "learning_rate": 7.150592966733696e-06,
      "loss": 0.3162,
      "step": 17996
    },
    {
      "epoch": 0.2849565368842725,
      "grad_norm": 0.3789953887462616,
      "learning_rate": 7.150434631157275e-06,
      "loss": 0.0666,
      "step": 17997
    },
    {
      "epoch": 0.2849723704419146,
      "grad_norm": 0.22606323659420013,
      "learning_rate": 7.150276295580855e-06,
      "loss": 0.0201,
      "step": 17998
    },
    {
      "epoch": 0.28498820399955666,
      "grad_norm": 0.00022592190362047404,
      "learning_rate": 7.150117960004434e-06,
      "loss": 0.0,
      "step": 17999
    },
    {
      "epoch": 0.2850040375571987,
      "grad_norm": 0.5236548781394958,
      "learning_rate": 7.149959624428014e-06,
      "loss": 0.2853,
      "step": 18000
    },
    {
      "epoch": 0.2850198711148408,
      "grad_norm": 0.30595865845680237,
      "learning_rate": 7.149801288851592e-06,
      "loss": 0.106,
      "step": 18001
    },
    {
      "epoch": 0.28503570467248285,
      "grad_norm": 0.7624081969261169,
      "learning_rate": 7.149642953275172e-06,
      "loss": 0.5405,
      "step": 18002
    },
    {
      "epoch": 0.2850515382301249,
      "grad_norm": 0.8738939166069031,
      "learning_rate": 7.149484617698751e-06,
      "loss": 0.2872,
      "step": 18003
    },
    {
      "epoch": 0.285067371787767,
      "grad_norm": 0.05206887423992157,
      "learning_rate": 7.149326282122331e-06,
      "loss": 0.0025,
      "step": 18004
    },
    {
      "epoch": 0.28508320534540904,
      "grad_norm": 0.6108590960502625,
      "learning_rate": 7.14916794654591e-06,
      "loss": 0.2513,
      "step": 18005
    },
    {
      "epoch": 0.2850990389030511,
      "grad_norm": 0.5212554931640625,
      "learning_rate": 7.14900961096949e-06,
      "loss": 0.3019,
      "step": 18006
    },
    {
      "epoch": 0.28511487246069317,
      "grad_norm": 0.7548394799232483,
      "learning_rate": 7.148851275393068e-06,
      "loss": 0.5231,
      "step": 18007
    },
    {
      "epoch": 0.28513070601833523,
      "grad_norm": 0.016013799235224724,
      "learning_rate": 7.148692939816648e-06,
      "loss": 0.0008,
      "step": 18008
    },
    {
      "epoch": 0.28514653957597735,
      "grad_norm": 0.00010765141632873565,
      "learning_rate": 7.148534604240227e-06,
      "loss": 0.0,
      "step": 18009
    },
    {
      "epoch": 0.2851623731336194,
      "grad_norm": 0.6045441031455994,
      "learning_rate": 7.148376268663807e-06,
      "loss": 0.0648,
      "step": 18010
    },
    {
      "epoch": 0.2851782066912615,
      "grad_norm": 0.6696222424507141,
      "learning_rate": 7.148217933087386e-06,
      "loss": 0.1284,
      "step": 18011
    },
    {
      "epoch": 0.28519404024890355,
      "grad_norm": 1.6580981016159058,
      "learning_rate": 7.148059597510966e-06,
      "loss": 0.3313,
      "step": 18012
    },
    {
      "epoch": 0.2852098738065456,
      "grad_norm": 0.5712592005729675,
      "learning_rate": 7.147901261934544e-06,
      "loss": 0.2996,
      "step": 18013
    },
    {
      "epoch": 0.2852257073641877,
      "grad_norm": 0.22982250154018402,
      "learning_rate": 7.147742926358124e-06,
      "loss": 0.0601,
      "step": 18014
    },
    {
      "epoch": 0.28524154092182974,
      "grad_norm": 0.48843809962272644,
      "learning_rate": 7.147584590781703e-06,
      "loss": 0.2906,
      "step": 18015
    },
    {
      "epoch": 0.2852573744794718,
      "grad_norm": 0.38155168294906616,
      "learning_rate": 7.147426255205283e-06,
      "loss": 0.1217,
      "step": 18016
    },
    {
      "epoch": 0.28527320803711387,
      "grad_norm": 0.8322710990905762,
      "learning_rate": 7.147267919628862e-06,
      "loss": 0.6634,
      "step": 18017
    },
    {
      "epoch": 0.28528904159475593,
      "grad_norm": 0.02829612046480179,
      "learning_rate": 7.147109584052442e-06,
      "loss": 0.0012,
      "step": 18018
    },
    {
      "epoch": 0.285304875152398,
      "grad_norm": 0.44534361362457275,
      "learning_rate": 7.14695124847602e-06,
      "loss": 0.0722,
      "step": 18019
    },
    {
      "epoch": 0.28532070871004006,
      "grad_norm": 0.5501174330711365,
      "learning_rate": 7.1467929128996e-06,
      "loss": 0.2515,
      "step": 18020
    },
    {
      "epoch": 0.2853365422676821,
      "grad_norm": 0.10717905312776566,
      "learning_rate": 7.146634577323179e-06,
      "loss": 0.0022,
      "step": 18021
    },
    {
      "epoch": 0.2853523758253242,
      "grad_norm": 0.3050616681575775,
      "learning_rate": 7.1464762417467584e-06,
      "loss": 0.0776,
      "step": 18022
    },
    {
      "epoch": 0.28536820938296625,
      "grad_norm": 0.2723071575164795,
      "learning_rate": 7.146317906170338e-06,
      "loss": 0.0349,
      "step": 18023
    },
    {
      "epoch": 0.2853840429406083,
      "grad_norm": 0.4882435202598572,
      "learning_rate": 7.146159570593917e-06,
      "loss": 0.1464,
      "step": 18024
    },
    {
      "epoch": 0.2853998764982504,
      "grad_norm": 0.024133188650012016,
      "learning_rate": 7.1460012350174965e-06,
      "loss": 0.0012,
      "step": 18025
    },
    {
      "epoch": 0.28541571005589245,
      "grad_norm": 0.38191869854927063,
      "learning_rate": 7.145842899441076e-06,
      "loss": 0.1957,
      "step": 18026
    },
    {
      "epoch": 0.2854315436135345,
      "grad_norm": 0.002130873268470168,
      "learning_rate": 7.1456845638646555e-06,
      "loss": 0.0,
      "step": 18027
    },
    {
      "epoch": 0.2854473771711766,
      "grad_norm": 0.03154248371720314,
      "learning_rate": 7.145526228288235e-06,
      "loss": 0.001,
      "step": 18028
    },
    {
      "epoch": 0.28546321072881864,
      "grad_norm": 0.4462885558605194,
      "learning_rate": 7.1453678927118145e-06,
      "loss": 0.1962,
      "step": 18029
    },
    {
      "epoch": 0.2854790442864607,
      "grad_norm": 0.03661154955625534,
      "learning_rate": 7.145209557135393e-06,
      "loss": 0.002,
      "step": 18030
    },
    {
      "epoch": 0.28549487784410277,
      "grad_norm": 0.029999708756804466,
      "learning_rate": 7.145051221558973e-06,
      "loss": 0.0011,
      "step": 18031
    },
    {
      "epoch": 0.28551071140174483,
      "grad_norm": 0.6630364656448364,
      "learning_rate": 7.144892885982552e-06,
      "loss": 0.4347,
      "step": 18032
    },
    {
      "epoch": 0.28552654495938695,
      "grad_norm": 0.5145555734634399,
      "learning_rate": 7.144734550406132e-06,
      "loss": 0.1583,
      "step": 18033
    },
    {
      "epoch": 0.285542378517029,
      "grad_norm": 0.41281288862228394,
      "learning_rate": 7.144576214829711e-06,
      "loss": 0.1924,
      "step": 18034
    },
    {
      "epoch": 0.2855582120746711,
      "grad_norm": 0.15376777946949005,
      "learning_rate": 7.144417879253291e-06,
      "loss": 0.0079,
      "step": 18035
    },
    {
      "epoch": 0.28557404563231314,
      "grad_norm": 0.021968349814414978,
      "learning_rate": 7.144259543676869e-06,
      "loss": 0.0009,
      "step": 18036
    },
    {
      "epoch": 0.2855898791899552,
      "grad_norm": 0.9146631956100464,
      "learning_rate": 7.144101208100449e-06,
      "loss": 0.2181,
      "step": 18037
    },
    {
      "epoch": 0.2856057127475973,
      "grad_norm": 0.6406377553939819,
      "learning_rate": 7.143942872524028e-06,
      "loss": 0.3448,
      "step": 18038
    },
    {
      "epoch": 0.28562154630523934,
      "grad_norm": 0.8065482378005981,
      "learning_rate": 7.143784536947608e-06,
      "loss": 0.2483,
      "step": 18039
    },
    {
      "epoch": 0.2856373798628814,
      "grad_norm": 0.01019770186394453,
      "learning_rate": 7.143626201371187e-06,
      "loss": 0.0004,
      "step": 18040
    },
    {
      "epoch": 0.28565321342052347,
      "grad_norm": 0.0001744372711982578,
      "learning_rate": 7.143467865794767e-06,
      "loss": 0.0,
      "step": 18041
    },
    {
      "epoch": 0.28566904697816553,
      "grad_norm": 0.35404616594314575,
      "learning_rate": 7.143309530218345e-06,
      "loss": 0.3482,
      "step": 18042
    },
    {
      "epoch": 0.2856848805358076,
      "grad_norm": 1.311042308807373,
      "learning_rate": 7.143151194641925e-06,
      "loss": 0.6892,
      "step": 18043
    },
    {
      "epoch": 0.28570071409344966,
      "grad_norm": 2.225743293762207,
      "learning_rate": 7.142992859065504e-06,
      "loss": 0.1717,
      "step": 18044
    },
    {
      "epoch": 0.2857165476510917,
      "grad_norm": 0.006475270725786686,
      "learning_rate": 7.142834523489083e-06,
      "loss": 0.0003,
      "step": 18045
    },
    {
      "epoch": 0.2857323812087338,
      "grad_norm": 0.5149883031845093,
      "learning_rate": 7.142676187912663e-06,
      "loss": 0.0964,
      "step": 18046
    },
    {
      "epoch": 0.28574821476637585,
      "grad_norm": 0.18340276181697845,
      "learning_rate": 7.142517852336241e-06,
      "loss": 0.0434,
      "step": 18047
    },
    {
      "epoch": 0.2857640483240179,
      "grad_norm": 0.2928462028503418,
      "learning_rate": 7.142359516759821e-06,
      "loss": 0.0359,
      "step": 18048
    },
    {
      "epoch": 0.28577988188166,
      "grad_norm": 0.5564143657684326,
      "learning_rate": 7.1422011811834e-06,
      "loss": 0.2279,
      "step": 18049
    },
    {
      "epoch": 0.28579571543930204,
      "grad_norm": 1.1295855045318604,
      "learning_rate": 7.14204284560698e-06,
      "loss": 0.9767,
      "step": 18050
    },
    {
      "epoch": 0.2858115489969441,
      "grad_norm": 0.22562682628631592,
      "learning_rate": 7.141884510030559e-06,
      "loss": 0.0498,
      "step": 18051
    },
    {
      "epoch": 0.2858273825545862,
      "grad_norm": 0.6901885867118835,
      "learning_rate": 7.1417261744541384e-06,
      "loss": 0.1347,
      "step": 18052
    },
    {
      "epoch": 0.28584321611222824,
      "grad_norm": 0.6951707601547241,
      "learning_rate": 7.1415678388777175e-06,
      "loss": 0.1223,
      "step": 18053
    },
    {
      "epoch": 0.2858590496698703,
      "grad_norm": 0.36853525042533875,
      "learning_rate": 7.1414095033012974e-06,
      "loss": 0.1023,
      "step": 18054
    },
    {
      "epoch": 0.28587488322751237,
      "grad_norm": 0.28016260266304016,
      "learning_rate": 7.1412511677248765e-06,
      "loss": 0.0685,
      "step": 18055
    },
    {
      "epoch": 0.28589071678515443,
      "grad_norm": 0.06278016418218613,
      "learning_rate": 7.1410928321484565e-06,
      "loss": 0.003,
      "step": 18056
    },
    {
      "epoch": 0.28590655034279655,
      "grad_norm": 0.3292696475982666,
      "learning_rate": 7.140934496572035e-06,
      "loss": 0.0805,
      "step": 18057
    },
    {
      "epoch": 0.2859223839004386,
      "grad_norm": 0.2501251697540283,
      "learning_rate": 7.140776160995615e-06,
      "loss": 0.0857,
      "step": 18058
    },
    {
      "epoch": 0.2859382174580807,
      "grad_norm": 0.9982199668884277,
      "learning_rate": 7.140617825419194e-06,
      "loss": 0.4798,
      "step": 18059
    },
    {
      "epoch": 0.28595405101572274,
      "grad_norm": 0.32682108879089355,
      "learning_rate": 7.140459489842774e-06,
      "loss": 0.0837,
      "step": 18060
    },
    {
      "epoch": 0.2859698845733648,
      "grad_norm": 0.03714634105563164,
      "learning_rate": 7.140301154266353e-06,
      "loss": 0.0016,
      "step": 18061
    },
    {
      "epoch": 0.28598571813100687,
      "grad_norm": 0.2146448940038681,
      "learning_rate": 7.140142818689933e-06,
      "loss": 0.0721,
      "step": 18062
    },
    {
      "epoch": 0.28600155168864894,
      "grad_norm": 0.016004767268896103,
      "learning_rate": 7.139984483113511e-06,
      "loss": 0.0009,
      "step": 18063
    },
    {
      "epoch": 0.286017385246291,
      "grad_norm": 0.29774269461631775,
      "learning_rate": 7.139826147537091e-06,
      "loss": 0.1153,
      "step": 18064
    },
    {
      "epoch": 0.28603321880393306,
      "grad_norm": 0.3256758451461792,
      "learning_rate": 7.13966781196067e-06,
      "loss": 0.0794,
      "step": 18065
    },
    {
      "epoch": 0.28604905236157513,
      "grad_norm": 0.3657856285572052,
      "learning_rate": 7.13950947638425e-06,
      "loss": 0.1287,
      "step": 18066
    },
    {
      "epoch": 0.2860648859192172,
      "grad_norm": 0.009519432671368122,
      "learning_rate": 7.139351140807829e-06,
      "loss": 0.0004,
      "step": 18067
    },
    {
      "epoch": 0.28608071947685926,
      "grad_norm": 0.022053822875022888,
      "learning_rate": 7.139192805231409e-06,
      "loss": 0.0014,
      "step": 18068
    },
    {
      "epoch": 0.2860965530345013,
      "grad_norm": 0.912548840045929,
      "learning_rate": 7.139034469654987e-06,
      "loss": 0.3092,
      "step": 18069
    },
    {
      "epoch": 0.2861123865921434,
      "grad_norm": 1.8344383239746094,
      "learning_rate": 7.138876134078566e-06,
      "loss": 0.1644,
      "step": 18070
    },
    {
      "epoch": 0.28612822014978545,
      "grad_norm": 0.1943562626838684,
      "learning_rate": 7.138717798502146e-06,
      "loss": 0.0135,
      "step": 18071
    },
    {
      "epoch": 0.2861440537074275,
      "grad_norm": 0.22392936050891876,
      "learning_rate": 7.138559462925725e-06,
      "loss": 0.0628,
      "step": 18072
    },
    {
      "epoch": 0.2861598872650696,
      "grad_norm": 0.27483418583869934,
      "learning_rate": 7.138401127349305e-06,
      "loss": 0.1449,
      "step": 18073
    },
    {
      "epoch": 0.28617572082271164,
      "grad_norm": 0.5561277270317078,
      "learning_rate": 7.138242791772883e-06,
      "loss": 0.1537,
      "step": 18074
    },
    {
      "epoch": 0.2861915543803537,
      "grad_norm": 0.95408034324646,
      "learning_rate": 7.138084456196463e-06,
      "loss": 0.2711,
      "step": 18075
    },
    {
      "epoch": 0.28620738793799577,
      "grad_norm": 0.011925242841243744,
      "learning_rate": 7.137926120620042e-06,
      "loss": 0.0004,
      "step": 18076
    },
    {
      "epoch": 0.28622322149563784,
      "grad_norm": 1.991335153579712,
      "learning_rate": 7.137767785043622e-06,
      "loss": 0.3947,
      "step": 18077
    },
    {
      "epoch": 0.2862390550532799,
      "grad_norm": 0.24920424818992615,
      "learning_rate": 7.137609449467201e-06,
      "loss": 0.043,
      "step": 18078
    },
    {
      "epoch": 0.28625488861092196,
      "grad_norm": 0.18284544348716736,
      "learning_rate": 7.137451113890781e-06,
      "loss": 0.069,
      "step": 18079
    },
    {
      "epoch": 0.28627072216856403,
      "grad_norm": 0.41595637798309326,
      "learning_rate": 7.1372927783143594e-06,
      "loss": 0.2428,
      "step": 18080
    },
    {
      "epoch": 0.28628655572620615,
      "grad_norm": 0.008055069483816624,
      "learning_rate": 7.137134442737939e-06,
      "loss": 0.0003,
      "step": 18081
    },
    {
      "epoch": 0.2863023892838482,
      "grad_norm": 0.17070944607257843,
      "learning_rate": 7.1369761071615184e-06,
      "loss": 0.0592,
      "step": 18082
    },
    {
      "epoch": 0.2863182228414903,
      "grad_norm": 0.20485273003578186,
      "learning_rate": 7.136817771585098e-06,
      "loss": 0.0995,
      "step": 18083
    },
    {
      "epoch": 0.28633405639913234,
      "grad_norm": 0.3918980062007904,
      "learning_rate": 7.1366594360086775e-06,
      "loss": 0.0793,
      "step": 18084
    },
    {
      "epoch": 0.2863498899567744,
      "grad_norm": 0.29622188210487366,
      "learning_rate": 7.136501100432257e-06,
      "loss": 0.0869,
      "step": 18085
    },
    {
      "epoch": 0.28636572351441647,
      "grad_norm": 0.30572718381881714,
      "learning_rate": 7.136342764855836e-06,
      "loss": 0.5459,
      "step": 18086
    },
    {
      "epoch": 0.28638155707205853,
      "grad_norm": 1.282932996749878,
      "learning_rate": 7.1361844292794155e-06,
      "loss": 0.6138,
      "step": 18087
    },
    {
      "epoch": 0.2863973906297006,
      "grad_norm": 0.5405911207199097,
      "learning_rate": 7.136026093702995e-06,
      "loss": 0.2585,
      "step": 18088
    },
    {
      "epoch": 0.28641322418734266,
      "grad_norm": 0.34995195269584656,
      "learning_rate": 7.1358677581265745e-06,
      "loss": 0.1079,
      "step": 18089
    },
    {
      "epoch": 0.2864290577449847,
      "grad_norm": 0.6117882132530212,
      "learning_rate": 7.135709422550154e-06,
      "loss": 0.0618,
      "step": 18090
    },
    {
      "epoch": 0.2864448913026268,
      "grad_norm": 0.5174700021743774,
      "learning_rate": 7.1355510869737336e-06,
      "loss": 0.1166,
      "step": 18091
    },
    {
      "epoch": 0.28646072486026886,
      "grad_norm": 0.47774428129196167,
      "learning_rate": 7.135392751397312e-06,
      "loss": 0.0665,
      "step": 18092
    },
    {
      "epoch": 0.2864765584179109,
      "grad_norm": 0.20869025588035583,
      "learning_rate": 7.135234415820891e-06,
      "loss": 0.0246,
      "step": 18093
    },
    {
      "epoch": 0.286492391975553,
      "grad_norm": 0.548258364200592,
      "learning_rate": 7.135076080244471e-06,
      "loss": 0.0956,
      "step": 18094
    },
    {
      "epoch": 0.28650822553319505,
      "grad_norm": 0.00011989709310000762,
      "learning_rate": 7.13491774466805e-06,
      "loss": 0.0,
      "step": 18095
    },
    {
      "epoch": 0.2865240590908371,
      "grad_norm": 0.5037875771522522,
      "learning_rate": 7.13475940909163e-06,
      "loss": 0.1118,
      "step": 18096
    },
    {
      "epoch": 0.2865398926484792,
      "grad_norm": 0.4956890344619751,
      "learning_rate": 7.134601073515208e-06,
      "loss": 0.2125,
      "step": 18097
    },
    {
      "epoch": 0.28655572620612124,
      "grad_norm": 0.673308789730072,
      "learning_rate": 7.134442737938788e-06,
      "loss": 0.447,
      "step": 18098
    },
    {
      "epoch": 0.2865715597637633,
      "grad_norm": 0.011519774794578552,
      "learning_rate": 7.134284402362367e-06,
      "loss": 0.0004,
      "step": 18099
    },
    {
      "epoch": 0.28658739332140537,
      "grad_norm": 0.4469441771507263,
      "learning_rate": 7.134126066785947e-06,
      "loss": 0.0769,
      "step": 18100
    },
    {
      "epoch": 0.28660322687904743,
      "grad_norm": 0.31451162695884705,
      "learning_rate": 7.133967731209526e-06,
      "loss": 0.1057,
      "step": 18101
    },
    {
      "epoch": 0.2866190604366895,
      "grad_norm": 0.323371022939682,
      "learning_rate": 7.133809395633106e-06,
      "loss": 0.0542,
      "step": 18102
    },
    {
      "epoch": 0.28663489399433156,
      "grad_norm": 0.4455987811088562,
      "learning_rate": 7.133651060056684e-06,
      "loss": 0.1149,
      "step": 18103
    },
    {
      "epoch": 0.2866507275519736,
      "grad_norm": 0.22060219943523407,
      "learning_rate": 7.133492724480264e-06,
      "loss": 0.0296,
      "step": 18104
    },
    {
      "epoch": 0.2866665611096157,
      "grad_norm": 0.016115956008434296,
      "learning_rate": 7.133334388903843e-06,
      "loss": 0.0006,
      "step": 18105
    },
    {
      "epoch": 0.2866823946672578,
      "grad_norm": 0.3518245816230774,
      "learning_rate": 7.133176053327423e-06,
      "loss": 0.0406,
      "step": 18106
    },
    {
      "epoch": 0.2866982282248999,
      "grad_norm": 0.0002582445740699768,
      "learning_rate": 7.133017717751002e-06,
      "loss": 0.0,
      "step": 18107
    },
    {
      "epoch": 0.28671406178254194,
      "grad_norm": 0.4520876407623291,
      "learning_rate": 7.132859382174582e-06,
      "loss": 0.0911,
      "step": 18108
    },
    {
      "epoch": 0.286729895340184,
      "grad_norm": 0.4496522545814514,
      "learning_rate": 7.13270104659816e-06,
      "loss": 0.4059,
      "step": 18109
    },
    {
      "epoch": 0.28674572889782607,
      "grad_norm": 0.46687567234039307,
      "learning_rate": 7.13254271102174e-06,
      "loss": 0.1288,
      "step": 18110
    },
    {
      "epoch": 0.28676156245546813,
      "grad_norm": 0.004439945332705975,
      "learning_rate": 7.132384375445319e-06,
      "loss": 0.0001,
      "step": 18111
    },
    {
      "epoch": 0.2867773960131102,
      "grad_norm": 0.26597994565963745,
      "learning_rate": 7.132226039868899e-06,
      "loss": 0.0388,
      "step": 18112
    },
    {
      "epoch": 0.28679322957075226,
      "grad_norm": 0.2592693269252777,
      "learning_rate": 7.132067704292478e-06,
      "loss": 0.0685,
      "step": 18113
    },
    {
      "epoch": 0.2868090631283943,
      "grad_norm": 0.39024659991264343,
      "learning_rate": 7.1319093687160575e-06,
      "loss": 0.0867,
      "step": 18114
    },
    {
      "epoch": 0.2868248966860364,
      "grad_norm": 0.022930404171347618,
      "learning_rate": 7.1317510331396365e-06,
      "loss": 0.0009,
      "step": 18115
    },
    {
      "epoch": 0.28684073024367845,
      "grad_norm": 0.008885138668119907,
      "learning_rate": 7.1315926975632165e-06,
      "loss": 0.0003,
      "step": 18116
    },
    {
      "epoch": 0.2868565638013205,
      "grad_norm": 0.005955578293651342,
      "learning_rate": 7.1314343619867956e-06,
      "loss": 0.0002,
      "step": 18117
    },
    {
      "epoch": 0.2868723973589626,
      "grad_norm": 0.1435782015323639,
      "learning_rate": 7.131276026410374e-06,
      "loss": 0.0332,
      "step": 18118
    },
    {
      "epoch": 0.28688823091660465,
      "grad_norm": 0.8458601832389832,
      "learning_rate": 7.131117690833954e-06,
      "loss": 0.0266,
      "step": 18119
    },
    {
      "epoch": 0.2869040644742467,
      "grad_norm": 0.007952723652124405,
      "learning_rate": 7.130959355257533e-06,
      "loss": 0.0004,
      "step": 18120
    },
    {
      "epoch": 0.2869198980318888,
      "grad_norm": 0.009447668679058552,
      "learning_rate": 7.130801019681113e-06,
      "loss": 0.0005,
      "step": 18121
    },
    {
      "epoch": 0.28693573158953084,
      "grad_norm": 0.4790043830871582,
      "learning_rate": 7.130642684104692e-06,
      "loss": 0.1221,
      "step": 18122
    },
    {
      "epoch": 0.2869515651471729,
      "grad_norm": 0.586358904838562,
      "learning_rate": 7.130484348528272e-06,
      "loss": 0.5753,
      "step": 18123
    },
    {
      "epoch": 0.28696739870481497,
      "grad_norm": 0.5318402051925659,
      "learning_rate": 7.13032601295185e-06,
      "loss": 0.1566,
      "step": 18124
    },
    {
      "epoch": 0.28698323226245703,
      "grad_norm": 0.010581529699265957,
      "learning_rate": 7.13016767737543e-06,
      "loss": 0.0004,
      "step": 18125
    },
    {
      "epoch": 0.2869990658200991,
      "grad_norm": 0.5402831435203552,
      "learning_rate": 7.130009341799009e-06,
      "loss": 0.1262,
      "step": 18126
    },
    {
      "epoch": 0.28701489937774116,
      "grad_norm": 0.6459599137306213,
      "learning_rate": 7.129851006222589e-06,
      "loss": 0.2119,
      "step": 18127
    },
    {
      "epoch": 0.2870307329353832,
      "grad_norm": 0.35783663392066956,
      "learning_rate": 7.129692670646168e-06,
      "loss": 0.265,
      "step": 18128
    },
    {
      "epoch": 0.2870465664930253,
      "grad_norm": 0.3354845643043518,
      "learning_rate": 7.129534335069748e-06,
      "loss": 0.0063,
      "step": 18129
    },
    {
      "epoch": 0.2870624000506674,
      "grad_norm": 4.774637699127197,
      "learning_rate": 7.129375999493326e-06,
      "loss": 0.4476,
      "step": 18130
    },
    {
      "epoch": 0.2870782336083095,
      "grad_norm": 0.20847952365875244,
      "learning_rate": 7.129217663916906e-06,
      "loss": 0.0139,
      "step": 18131
    },
    {
      "epoch": 0.28709406716595154,
      "grad_norm": 0.65619295835495,
      "learning_rate": 7.129059328340485e-06,
      "loss": 0.1509,
      "step": 18132
    },
    {
      "epoch": 0.2871099007235936,
      "grad_norm": 0.00012612502905540168,
      "learning_rate": 7.128900992764065e-06,
      "loss": 0.0,
      "step": 18133
    },
    {
      "epoch": 0.28712573428123567,
      "grad_norm": 0.49840301275253296,
      "learning_rate": 7.128742657187644e-06,
      "loss": 0.4334,
      "step": 18134
    },
    {
      "epoch": 0.28714156783887773,
      "grad_norm": 0.4707958996295929,
      "learning_rate": 7.128584321611224e-06,
      "loss": 0.1515,
      "step": 18135
    },
    {
      "epoch": 0.2871574013965198,
      "grad_norm": 0.09551813453435898,
      "learning_rate": 7.128425986034802e-06,
      "loss": 0.0071,
      "step": 18136
    },
    {
      "epoch": 0.28717323495416186,
      "grad_norm": 0.003589888336136937,
      "learning_rate": 7.128267650458382e-06,
      "loss": 0.0001,
      "step": 18137
    },
    {
      "epoch": 0.2871890685118039,
      "grad_norm": 0.3598116338253021,
      "learning_rate": 7.128109314881961e-06,
      "loss": 0.1584,
      "step": 18138
    },
    {
      "epoch": 0.287204902069446,
      "grad_norm": 0.7609689235687256,
      "learning_rate": 7.127950979305541e-06,
      "loss": 0.1257,
      "step": 18139
    },
    {
      "epoch": 0.28722073562708805,
      "grad_norm": 0.9012120366096497,
      "learning_rate": 7.12779264372912e-06,
      "loss": 0.8444,
      "step": 18140
    },
    {
      "epoch": 0.2872365691847301,
      "grad_norm": 1.6181801557540894,
      "learning_rate": 7.1276343081527e-06,
      "loss": 0.1282,
      "step": 18141
    },
    {
      "epoch": 0.2872524027423722,
      "grad_norm": 0.42188698053359985,
      "learning_rate": 7.1274759725762785e-06,
      "loss": 0.0205,
      "step": 18142
    },
    {
      "epoch": 0.28726823630001425,
      "grad_norm": 0.390583872795105,
      "learning_rate": 7.1273176369998575e-06,
      "loss": 0.1445,
      "step": 18143
    },
    {
      "epoch": 0.2872840698576563,
      "grad_norm": 0.00900671910494566,
      "learning_rate": 7.1271593014234375e-06,
      "loss": 0.0003,
      "step": 18144
    },
    {
      "epoch": 0.2872999034152984,
      "grad_norm": 0.660683274269104,
      "learning_rate": 7.1270009658470166e-06,
      "loss": 0.1416,
      "step": 18145
    },
    {
      "epoch": 0.28731573697294044,
      "grad_norm": 0.520408034324646,
      "learning_rate": 7.1268426302705965e-06,
      "loss": 0.173,
      "step": 18146
    },
    {
      "epoch": 0.2873315705305825,
      "grad_norm": 0.5253757834434509,
      "learning_rate": 7.126684294694175e-06,
      "loss": 0.171,
      "step": 18147
    },
    {
      "epoch": 0.28734740408822457,
      "grad_norm": 9.538495214655995e-05,
      "learning_rate": 7.126525959117755e-06,
      "loss": 0.0,
      "step": 18148
    },
    {
      "epoch": 0.28736323764586663,
      "grad_norm": 0.04110578075051308,
      "learning_rate": 7.126367623541334e-06,
      "loss": 0.0018,
      "step": 18149
    },
    {
      "epoch": 0.2873790712035087,
      "grad_norm": 0.07813072949647903,
      "learning_rate": 7.126209287964914e-06,
      "loss": 0.0022,
      "step": 18150
    },
    {
      "epoch": 0.28739490476115076,
      "grad_norm": 0.41731157898902893,
      "learning_rate": 7.126050952388493e-06,
      "loss": 0.2707,
      "step": 18151
    },
    {
      "epoch": 0.2874107383187928,
      "grad_norm": 0.40779006481170654,
      "learning_rate": 7.125892616812073e-06,
      "loss": 0.1605,
      "step": 18152
    },
    {
      "epoch": 0.2874265718764349,
      "grad_norm": 0.2283141165971756,
      "learning_rate": 7.125734281235651e-06,
      "loss": 0.0802,
      "step": 18153
    },
    {
      "epoch": 0.287442405434077,
      "grad_norm": 0.2509625554084778,
      "learning_rate": 7.125575945659231e-06,
      "loss": 0.0582,
      "step": 18154
    },
    {
      "epoch": 0.2874582389917191,
      "grad_norm": 0.0016412587137892842,
      "learning_rate": 7.12541761008281e-06,
      "loss": 0.0,
      "step": 18155
    },
    {
      "epoch": 0.28747407254936114,
      "grad_norm": 0.20927906036376953,
      "learning_rate": 7.12525927450639e-06,
      "loss": 0.0582,
      "step": 18156
    },
    {
      "epoch": 0.2874899061070032,
      "grad_norm": 0.8687872886657715,
      "learning_rate": 7.125100938929969e-06,
      "loss": 0.0766,
      "step": 18157
    },
    {
      "epoch": 0.28750573966464527,
      "grad_norm": 0.6864060163497925,
      "learning_rate": 7.124942603353549e-06,
      "loss": 0.1275,
      "step": 18158
    },
    {
      "epoch": 0.28752157322228733,
      "grad_norm": 5.808712376165204e-05,
      "learning_rate": 7.124784267777127e-06,
      "loss": 0.0,
      "step": 18159
    },
    {
      "epoch": 0.2875374067799294,
      "grad_norm": 0.07446528226137161,
      "learning_rate": 7.124625932200707e-06,
      "loss": 0.0057,
      "step": 18160
    },
    {
      "epoch": 0.28755324033757146,
      "grad_norm": 0.0001866162638179958,
      "learning_rate": 7.124467596624286e-06,
      "loss": 0.0,
      "step": 18161
    },
    {
      "epoch": 0.2875690738952135,
      "grad_norm": 0.7917664051055908,
      "learning_rate": 7.124309261047866e-06,
      "loss": 0.7358,
      "step": 18162
    },
    {
      "epoch": 0.2875849074528556,
      "grad_norm": 0.2576788365840912,
      "learning_rate": 7.124150925471445e-06,
      "loss": 0.0283,
      "step": 18163
    },
    {
      "epoch": 0.28760074101049765,
      "grad_norm": 0.65110844373703,
      "learning_rate": 7.123992589895025e-06,
      "loss": 0.2955,
      "step": 18164
    },
    {
      "epoch": 0.2876165745681397,
      "grad_norm": 0.13382869958877563,
      "learning_rate": 7.123834254318603e-06,
      "loss": 0.0072,
      "step": 18165
    },
    {
      "epoch": 0.2876324081257818,
      "grad_norm": 0.01812182366847992,
      "learning_rate": 7.123675918742182e-06,
      "loss": 0.001,
      "step": 18166
    },
    {
      "epoch": 0.28764824168342384,
      "grad_norm": 0.18608541786670685,
      "learning_rate": 7.123517583165762e-06,
      "loss": 0.0382,
      "step": 18167
    },
    {
      "epoch": 0.2876640752410659,
      "grad_norm": 0.17974480986595154,
      "learning_rate": 7.123359247589341e-06,
      "loss": 0.0411,
      "step": 18168
    },
    {
      "epoch": 0.287679908798708,
      "grad_norm": 0.7261583805084229,
      "learning_rate": 7.123200912012921e-06,
      "loss": 0.1168,
      "step": 18169
    },
    {
      "epoch": 0.28769574235635004,
      "grad_norm": 7.172364712459967e-05,
      "learning_rate": 7.1230425764364995e-06,
      "loss": 0.0,
      "step": 18170
    },
    {
      "epoch": 0.2877115759139921,
      "grad_norm": 0.026762336492538452,
      "learning_rate": 7.122884240860079e-06,
      "loss": 0.0016,
      "step": 18171
    },
    {
      "epoch": 0.28772740947163417,
      "grad_norm": 0.5178655982017517,
      "learning_rate": 7.1227259052836585e-06,
      "loss": 0.0539,
      "step": 18172
    },
    {
      "epoch": 0.28774324302927623,
      "grad_norm": 0.012638024985790253,
      "learning_rate": 7.122567569707238e-06,
      "loss": 0.0005,
      "step": 18173
    },
    {
      "epoch": 0.2877590765869183,
      "grad_norm": 0.2765513062477112,
      "learning_rate": 7.1224092341308175e-06,
      "loss": 0.0713,
      "step": 18174
    },
    {
      "epoch": 0.28777491014456036,
      "grad_norm": 0.02753371372818947,
      "learning_rate": 7.122250898554397e-06,
      "loss": 0.0012,
      "step": 18175
    },
    {
      "epoch": 0.2877907437022024,
      "grad_norm": 0.8340619802474976,
      "learning_rate": 7.122092562977976e-06,
      "loss": 0.086,
      "step": 18176
    },
    {
      "epoch": 0.2878065772598445,
      "grad_norm": 0.6669843196868896,
      "learning_rate": 7.1219342274015556e-06,
      "loss": 0.2186,
      "step": 18177
    },
    {
      "epoch": 0.2878224108174866,
      "grad_norm": 0.6841190457344055,
      "learning_rate": 7.121775891825135e-06,
      "loss": 0.1642,
      "step": 18178
    },
    {
      "epoch": 0.28783824437512867,
      "grad_norm": 0.36095407605171204,
      "learning_rate": 7.121617556248715e-06,
      "loss": 0.0997,
      "step": 18179
    },
    {
      "epoch": 0.28785407793277074,
      "grad_norm": 0.015630371868610382,
      "learning_rate": 7.121459220672293e-06,
      "loss": 0.0008,
      "step": 18180
    },
    {
      "epoch": 0.2878699114904128,
      "grad_norm": 1.7027283906936646,
      "learning_rate": 7.121300885095873e-06,
      "loss": 0.4431,
      "step": 18181
    },
    {
      "epoch": 0.28788574504805486,
      "grad_norm": 0.0012635743478313088,
      "learning_rate": 7.121142549519452e-06,
      "loss": 0.0,
      "step": 18182
    },
    {
      "epoch": 0.28790157860569693,
      "grad_norm": 0.41078951954841614,
      "learning_rate": 7.120984213943032e-06,
      "loss": 0.2473,
      "step": 18183
    },
    {
      "epoch": 0.287917412163339,
      "grad_norm": 1.1260350942611694,
      "learning_rate": 7.120825878366611e-06,
      "loss": 0.183,
      "step": 18184
    },
    {
      "epoch": 0.28793324572098106,
      "grad_norm": 0.3330908715724945,
      "learning_rate": 7.120667542790191e-06,
      "loss": 0.0559,
      "step": 18185
    },
    {
      "epoch": 0.2879490792786231,
      "grad_norm": 0.3016151189804077,
      "learning_rate": 7.120509207213769e-06,
      "loss": 0.118,
      "step": 18186
    },
    {
      "epoch": 0.2879649128362652,
      "grad_norm": 0.7606149911880493,
      "learning_rate": 7.120350871637349e-06,
      "loss": 0.0675,
      "step": 18187
    },
    {
      "epoch": 0.28798074639390725,
      "grad_norm": 0.30987128615379333,
      "learning_rate": 7.120192536060928e-06,
      "loss": 0.0921,
      "step": 18188
    },
    {
      "epoch": 0.2879965799515493,
      "grad_norm": 0.0006567829404957592,
      "learning_rate": 7.120034200484508e-06,
      "loss": 0.0,
      "step": 18189
    },
    {
      "epoch": 0.2880124135091914,
      "grad_norm": 0.23620012402534485,
      "learning_rate": 7.119875864908087e-06,
      "loss": 0.043,
      "step": 18190
    },
    {
      "epoch": 0.28802824706683344,
      "grad_norm": 0.23624958097934723,
      "learning_rate": 7.119717529331665e-06,
      "loss": 0.0578,
      "step": 18191
    },
    {
      "epoch": 0.2880440806244755,
      "grad_norm": 0.5439490675926208,
      "learning_rate": 7.119559193755245e-06,
      "loss": 0.0971,
      "step": 18192
    },
    {
      "epoch": 0.28805991418211757,
      "grad_norm": 0.3905366361141205,
      "learning_rate": 7.119400858178824e-06,
      "loss": 0.1387,
      "step": 18193
    },
    {
      "epoch": 0.28807574773975964,
      "grad_norm": 0.619121789932251,
      "learning_rate": 7.119242522602404e-06,
      "loss": 0.5407,
      "step": 18194
    },
    {
      "epoch": 0.2880915812974017,
      "grad_norm": 0.48871269822120667,
      "learning_rate": 7.119084187025983e-06,
      "loss": 0.0649,
      "step": 18195
    },
    {
      "epoch": 0.28810741485504376,
      "grad_norm": 0.0005682752816937864,
      "learning_rate": 7.118925851449563e-06,
      "loss": 0.0,
      "step": 18196
    },
    {
      "epoch": 0.28812324841268583,
      "grad_norm": 0.46342822909355164,
      "learning_rate": 7.118767515873141e-06,
      "loss": 0.0275,
      "step": 18197
    },
    {
      "epoch": 0.2881390819703279,
      "grad_norm": 0.010053022764623165,
      "learning_rate": 7.118609180296721e-06,
      "loss": 0.0005,
      "step": 18198
    },
    {
      "epoch": 0.28815491552796996,
      "grad_norm": 0.36219942569732666,
      "learning_rate": 7.1184508447203e-06,
      "loss": 0.0379,
      "step": 18199
    },
    {
      "epoch": 0.288170749085612,
      "grad_norm": 0.013926113024353981,
      "learning_rate": 7.11829250914388e-06,
      "loss": 0.0007,
      "step": 18200
    },
    {
      "epoch": 0.2881865826432541,
      "grad_norm": 1.9173885583877563,
      "learning_rate": 7.118134173567459e-06,
      "loss": 0.3055,
      "step": 18201
    },
    {
      "epoch": 0.2882024162008962,
      "grad_norm": 0.42739665508270264,
      "learning_rate": 7.117975837991039e-06,
      "loss": 0.0507,
      "step": 18202
    },
    {
      "epoch": 0.28821824975853827,
      "grad_norm": 0.5713777542114258,
      "learning_rate": 7.1178175024146176e-06,
      "loss": 0.1655,
      "step": 18203
    },
    {
      "epoch": 0.28823408331618033,
      "grad_norm": 0.3414524495601654,
      "learning_rate": 7.1176591668381975e-06,
      "loss": 0.1287,
      "step": 18204
    },
    {
      "epoch": 0.2882499168738224,
      "grad_norm": 0.0002727339160628617,
      "learning_rate": 7.1175008312617766e-06,
      "loss": 0.0,
      "step": 18205
    },
    {
      "epoch": 0.28826575043146446,
      "grad_norm": 1.7832494974136353,
      "learning_rate": 7.1173424956853565e-06,
      "loss": 0.3812,
      "step": 18206
    },
    {
      "epoch": 0.2882815839891065,
      "grad_norm": 0.27321743965148926,
      "learning_rate": 7.117184160108936e-06,
      "loss": 0.1277,
      "step": 18207
    },
    {
      "epoch": 0.2882974175467486,
      "grad_norm": 0.4520702362060547,
      "learning_rate": 7.1170258245325155e-06,
      "loss": 0.1113,
      "step": 18208
    },
    {
      "epoch": 0.28831325110439066,
      "grad_norm": 0.34682655334472656,
      "learning_rate": 7.116867488956094e-06,
      "loss": 0.1112,
      "step": 18209
    },
    {
      "epoch": 0.2883290846620327,
      "grad_norm": 0.3837738335132599,
      "learning_rate": 7.116709153379674e-06,
      "loss": 0.1347,
      "step": 18210
    },
    {
      "epoch": 0.2883449182196748,
      "grad_norm": 0.007125223986804485,
      "learning_rate": 7.116550817803253e-06,
      "loss": 0.0002,
      "step": 18211
    },
    {
      "epoch": 0.28836075177731685,
      "grad_norm": 0.6342196464538574,
      "learning_rate": 7.116392482226833e-06,
      "loss": 0.1558,
      "step": 18212
    },
    {
      "epoch": 0.2883765853349589,
      "grad_norm": 0.3242587447166443,
      "learning_rate": 7.116234146650412e-06,
      "loss": 0.0482,
      "step": 18213
    },
    {
      "epoch": 0.288392418892601,
      "grad_norm": 0.0243565384298563,
      "learning_rate": 7.11607581107399e-06,
      "loss": 0.0003,
      "step": 18214
    },
    {
      "epoch": 0.28840825245024304,
      "grad_norm": 0.8037155270576477,
      "learning_rate": 7.11591747549757e-06,
      "loss": 0.1381,
      "step": 18215
    },
    {
      "epoch": 0.2884240860078851,
      "grad_norm": 0.2044820636510849,
      "learning_rate": 7.115759139921149e-06,
      "loss": 0.0791,
      "step": 18216
    },
    {
      "epoch": 0.28843991956552717,
      "grad_norm": 0.33373069763183594,
      "learning_rate": 7.115600804344729e-06,
      "loss": 0.1436,
      "step": 18217
    },
    {
      "epoch": 0.28845575312316923,
      "grad_norm": 0.0001687839685473591,
      "learning_rate": 7.115442468768308e-06,
      "loss": 0.0,
      "step": 18218
    },
    {
      "epoch": 0.2884715866808113,
      "grad_norm": 0.006413200870156288,
      "learning_rate": 7.115284133191888e-06,
      "loss": 0.0002,
      "step": 18219
    },
    {
      "epoch": 0.28848742023845336,
      "grad_norm": 0.2729279696941376,
      "learning_rate": 7.115125797615466e-06,
      "loss": 0.1221,
      "step": 18220
    },
    {
      "epoch": 0.2885032537960954,
      "grad_norm": 0.7490418553352356,
      "learning_rate": 7.114967462039046e-06,
      "loss": 0.2233,
      "step": 18221
    },
    {
      "epoch": 0.2885190873537375,
      "grad_norm": 0.6496483087539673,
      "learning_rate": 7.114809126462625e-06,
      "loss": 0.2579,
      "step": 18222
    },
    {
      "epoch": 0.28853492091137956,
      "grad_norm": 0.7875145077705383,
      "learning_rate": 7.114650790886205e-06,
      "loss": 0.9073,
      "step": 18223
    },
    {
      "epoch": 0.2885507544690216,
      "grad_norm": 0.9989168643951416,
      "learning_rate": 7.114492455309784e-06,
      "loss": 0.0796,
      "step": 18224
    },
    {
      "epoch": 0.2885665880266637,
      "grad_norm": 0.5934338569641113,
      "learning_rate": 7.114334119733364e-06,
      "loss": 0.6302,
      "step": 18225
    },
    {
      "epoch": 0.2885824215843058,
      "grad_norm": 0.37195345759391785,
      "learning_rate": 7.114175784156942e-06,
      "loss": 0.0903,
      "step": 18226
    },
    {
      "epoch": 0.28859825514194787,
      "grad_norm": 0.7098271250724792,
      "learning_rate": 7.114017448580522e-06,
      "loss": 0.0653,
      "step": 18227
    },
    {
      "epoch": 0.28861408869958993,
      "grad_norm": 0.3358060121536255,
      "learning_rate": 7.113859113004101e-06,
      "loss": 0.116,
      "step": 18228
    },
    {
      "epoch": 0.288629922257232,
      "grad_norm": 0.5419982671737671,
      "learning_rate": 7.113700777427681e-06,
      "loss": 0.0832,
      "step": 18229
    },
    {
      "epoch": 0.28864575581487406,
      "grad_norm": 0.20261693000793457,
      "learning_rate": 7.11354244185126e-06,
      "loss": 0.0732,
      "step": 18230
    },
    {
      "epoch": 0.2886615893725161,
      "grad_norm": 0.010153187438845634,
      "learning_rate": 7.11338410627484e-06,
      "loss": 0.0005,
      "step": 18231
    },
    {
      "epoch": 0.2886774229301582,
      "grad_norm": 0.007442719768732786,
      "learning_rate": 7.1132257706984185e-06,
      "loss": 0.0004,
      "step": 18232
    },
    {
      "epoch": 0.28869325648780025,
      "grad_norm": 0.253249853849411,
      "learning_rate": 7.1130674351219984e-06,
      "loss": 0.1081,
      "step": 18233
    },
    {
      "epoch": 0.2887090900454423,
      "grad_norm": 0.44093289971351624,
      "learning_rate": 7.1129090995455775e-06,
      "loss": 0.5891,
      "step": 18234
    },
    {
      "epoch": 0.2887249236030844,
      "grad_norm": 0.8089525103569031,
      "learning_rate": 7.1127507639691574e-06,
      "loss": 0.0921,
      "step": 18235
    },
    {
      "epoch": 0.28874075716072645,
      "grad_norm": 0.027800584211945534,
      "learning_rate": 7.1125924283927365e-06,
      "loss": 0.0015,
      "step": 18236
    },
    {
      "epoch": 0.2887565907183685,
      "grad_norm": 0.04424259066581726,
      "learning_rate": 7.1124340928163164e-06,
      "loss": 0.0017,
      "step": 18237
    },
    {
      "epoch": 0.2887724242760106,
      "grad_norm": 0.3117334842681885,
      "learning_rate": 7.112275757239895e-06,
      "loss": 0.1426,
      "step": 18238
    },
    {
      "epoch": 0.28878825783365264,
      "grad_norm": 0.215548574924469,
      "learning_rate": 7.112117421663474e-06,
      "loss": 0.0703,
      "step": 18239
    },
    {
      "epoch": 0.2888040913912947,
      "grad_norm": 0.7921339869499207,
      "learning_rate": 7.111959086087054e-06,
      "loss": 0.152,
      "step": 18240
    },
    {
      "epoch": 0.28881992494893677,
      "grad_norm": 0.5051413178443909,
      "learning_rate": 7.111800750510633e-06,
      "loss": 0.2002,
      "step": 18241
    },
    {
      "epoch": 0.28883575850657883,
      "grad_norm": 0.43056756258010864,
      "learning_rate": 7.111642414934212e-06,
      "loss": 0.1262,
      "step": 18242
    },
    {
      "epoch": 0.2888515920642209,
      "grad_norm": 0.30885443091392517,
      "learning_rate": 7.111484079357791e-06,
      "loss": 0.1412,
      "step": 18243
    },
    {
      "epoch": 0.28886742562186296,
      "grad_norm": 0.35633254051208496,
      "learning_rate": 7.111325743781371e-06,
      "loss": 0.1926,
      "step": 18244
    },
    {
      "epoch": 0.288883259179505,
      "grad_norm": 0.5413103699684143,
      "learning_rate": 7.11116740820495e-06,
      "loss": 0.2402,
      "step": 18245
    },
    {
      "epoch": 0.2888990927371471,
      "grad_norm": 0.4314523935317993,
      "learning_rate": 7.11100907262853e-06,
      "loss": 0.0094,
      "step": 18246
    },
    {
      "epoch": 0.28891492629478915,
      "grad_norm": 0.5555335283279419,
      "learning_rate": 7.110850737052108e-06,
      "loss": 0.1124,
      "step": 18247
    },
    {
      "epoch": 0.2889307598524312,
      "grad_norm": 0.562053918838501,
      "learning_rate": 7.110692401475688e-06,
      "loss": 0.1419,
      "step": 18248
    },
    {
      "epoch": 0.2889465934100733,
      "grad_norm": 0.010389918461441994,
      "learning_rate": 7.110534065899267e-06,
      "loss": 0.0006,
      "step": 18249
    },
    {
      "epoch": 0.2889624269677154,
      "grad_norm": 0.3788727819919586,
      "learning_rate": 7.110375730322847e-06,
      "loss": 0.1318,
      "step": 18250
    },
    {
      "epoch": 0.28897826052535747,
      "grad_norm": 1.7999831438064575,
      "learning_rate": 7.110217394746426e-06,
      "loss": 0.2253,
      "step": 18251
    },
    {
      "epoch": 0.28899409408299953,
      "grad_norm": 0.014893990941345692,
      "learning_rate": 7.110059059170006e-06,
      "loss": 0.0009,
      "step": 18252
    },
    {
      "epoch": 0.2890099276406416,
      "grad_norm": 0.004528997931629419,
      "learning_rate": 7.109900723593584e-06,
      "loss": 0.0002,
      "step": 18253
    },
    {
      "epoch": 0.28902576119828366,
      "grad_norm": 0.9680033326148987,
      "learning_rate": 7.109742388017164e-06,
      "loss": 0.037,
      "step": 18254
    },
    {
      "epoch": 0.2890415947559257,
      "grad_norm": 0.007495393976569176,
      "learning_rate": 7.109584052440743e-06,
      "loss": 0.0003,
      "step": 18255
    },
    {
      "epoch": 0.2890574283135678,
      "grad_norm": 0.47640660405158997,
      "learning_rate": 7.109425716864323e-06,
      "loss": 0.1793,
      "step": 18256
    },
    {
      "epoch": 0.28907326187120985,
      "grad_norm": 0.18943631649017334,
      "learning_rate": 7.109267381287902e-06,
      "loss": 0.0257,
      "step": 18257
    },
    {
      "epoch": 0.2890890954288519,
      "grad_norm": 0.4225460886955261,
      "learning_rate": 7.109109045711482e-06,
      "loss": 0.1874,
      "step": 18258
    },
    {
      "epoch": 0.289104928986494,
      "grad_norm": 0.2665495276451111,
      "learning_rate": 7.1089507101350604e-06,
      "loss": 0.0664,
      "step": 18259
    },
    {
      "epoch": 0.28912076254413605,
      "grad_norm": 0.399471253156662,
      "learning_rate": 7.10879237455864e-06,
      "loss": 0.158,
      "step": 18260
    },
    {
      "epoch": 0.2891365961017781,
      "grad_norm": 0.08604182302951813,
      "learning_rate": 7.1086340389822194e-06,
      "loss": 0.0052,
      "step": 18261
    },
    {
      "epoch": 0.2891524296594202,
      "grad_norm": 0.3691423237323761,
      "learning_rate": 7.1084757034057985e-06,
      "loss": 0.0568,
      "step": 18262
    },
    {
      "epoch": 0.28916826321706224,
      "grad_norm": 0.2239249050617218,
      "learning_rate": 7.1083173678293784e-06,
      "loss": 0.0532,
      "step": 18263
    },
    {
      "epoch": 0.2891840967747043,
      "grad_norm": 0.4774889647960663,
      "learning_rate": 7.108159032252957e-06,
      "loss": 0.2421,
      "step": 18264
    },
    {
      "epoch": 0.28919993033234637,
      "grad_norm": 0.36112314462661743,
      "learning_rate": 7.108000696676537e-06,
      "loss": 0.1018,
      "step": 18265
    },
    {
      "epoch": 0.28921576388998843,
      "grad_norm": 0.4710730016231537,
      "learning_rate": 7.107842361100116e-06,
      "loss": 0.082,
      "step": 18266
    },
    {
      "epoch": 0.2892315974476305,
      "grad_norm": 0.30655941367149353,
      "learning_rate": 7.107684025523696e-06,
      "loss": 0.0298,
      "step": 18267
    },
    {
      "epoch": 0.28924743100527256,
      "grad_norm": 0.2589075267314911,
      "learning_rate": 7.107525689947275e-06,
      "loss": 0.076,
      "step": 18268
    },
    {
      "epoch": 0.2892632645629146,
      "grad_norm": 0.3738493025302887,
      "learning_rate": 7.107367354370855e-06,
      "loss": 0.0989,
      "step": 18269
    },
    {
      "epoch": 0.2892790981205567,
      "grad_norm": 0.517048716545105,
      "learning_rate": 7.107209018794433e-06,
      "loss": 0.0843,
      "step": 18270
    },
    {
      "epoch": 0.28929493167819875,
      "grad_norm": 0.25731825828552246,
      "learning_rate": 7.107050683218013e-06,
      "loss": 0.0536,
      "step": 18271
    },
    {
      "epoch": 0.2893107652358408,
      "grad_norm": 0.6179378032684326,
      "learning_rate": 7.106892347641592e-06,
      "loss": 0.4396,
      "step": 18272
    },
    {
      "epoch": 0.2893265987934829,
      "grad_norm": 0.44790422916412354,
      "learning_rate": 7.106734012065172e-06,
      "loss": 0.2177,
      "step": 18273
    },
    {
      "epoch": 0.289342432351125,
      "grad_norm": 0.38090935349464417,
      "learning_rate": 7.106575676488751e-06,
      "loss": 0.0438,
      "step": 18274
    },
    {
      "epoch": 0.28935826590876706,
      "grad_norm": 0.004979054909199476,
      "learning_rate": 7.106417340912331e-06,
      "loss": 0.0001,
      "step": 18275
    },
    {
      "epoch": 0.28937409946640913,
      "grad_norm": 0.4499487578868866,
      "learning_rate": 7.106259005335909e-06,
      "loss": 0.1217,
      "step": 18276
    },
    {
      "epoch": 0.2893899330240512,
      "grad_norm": 0.41320547461509705,
      "learning_rate": 7.106100669759489e-06,
      "loss": 0.0484,
      "step": 18277
    },
    {
      "epoch": 0.28940576658169326,
      "grad_norm": 0.3332728147506714,
      "learning_rate": 7.105942334183068e-06,
      "loss": 0.0768,
      "step": 18278
    },
    {
      "epoch": 0.2894216001393353,
      "grad_norm": 0.6165502071380615,
      "learning_rate": 7.105783998606648e-06,
      "loss": 1.0024,
      "step": 18279
    },
    {
      "epoch": 0.2894374336969774,
      "grad_norm": 0.39800208806991577,
      "learning_rate": 7.105625663030227e-06,
      "loss": 0.1284,
      "step": 18280
    },
    {
      "epoch": 0.28945326725461945,
      "grad_norm": 0.46456778049468994,
      "learning_rate": 7.105467327453807e-06,
      "loss": 0.0847,
      "step": 18281
    },
    {
      "epoch": 0.2894691008122615,
      "grad_norm": 1.1475143432617188,
      "learning_rate": 7.105308991877385e-06,
      "loss": 0.2171,
      "step": 18282
    },
    {
      "epoch": 0.2894849343699036,
      "grad_norm": 0.7204254865646362,
      "learning_rate": 7.105150656300965e-06,
      "loss": 0.25,
      "step": 18283
    },
    {
      "epoch": 0.28950076792754564,
      "grad_norm": 0.017813406884670258,
      "learning_rate": 7.104992320724544e-06,
      "loss": 0.0005,
      "step": 18284
    },
    {
      "epoch": 0.2895166014851877,
      "grad_norm": 0.6566255688667297,
      "learning_rate": 7.104833985148124e-06,
      "loss": 0.2452,
      "step": 18285
    },
    {
      "epoch": 0.28953243504282977,
      "grad_norm": 0.4227493107318878,
      "learning_rate": 7.104675649571703e-06,
      "loss": 0.1158,
      "step": 18286
    },
    {
      "epoch": 0.28954826860047184,
      "grad_norm": 0.6356741786003113,
      "learning_rate": 7.1045173139952814e-06,
      "loss": 0.1478,
      "step": 18287
    },
    {
      "epoch": 0.2895641021581139,
      "grad_norm": 0.7463671565055847,
      "learning_rate": 7.104358978418861e-06,
      "loss": 0.1311,
      "step": 18288
    },
    {
      "epoch": 0.28957993571575597,
      "grad_norm": 0.26652175188064575,
      "learning_rate": 7.1042006428424404e-06,
      "loss": 0.0594,
      "step": 18289
    },
    {
      "epoch": 0.28959576927339803,
      "grad_norm": 0.7920778393745422,
      "learning_rate": 7.10404230726602e-06,
      "loss": 0.5112,
      "step": 18290
    },
    {
      "epoch": 0.2896116028310401,
      "grad_norm": 0.6713294982910156,
      "learning_rate": 7.1038839716895994e-06,
      "loss": 0.588,
      "step": 18291
    },
    {
      "epoch": 0.28962743638868216,
      "grad_norm": 0.30543652176856995,
      "learning_rate": 7.103725636113179e-06,
      "loss": 0.0669,
      "step": 18292
    },
    {
      "epoch": 0.2896432699463242,
      "grad_norm": 0.6033081412315369,
      "learning_rate": 7.103567300536758e-06,
      "loss": 0.2552,
      "step": 18293
    },
    {
      "epoch": 0.2896591035039663,
      "grad_norm": 0.00043804917368106544,
      "learning_rate": 7.1034089649603375e-06,
      "loss": 0.0,
      "step": 18294
    },
    {
      "epoch": 0.28967493706160835,
      "grad_norm": 0.005068330094218254,
      "learning_rate": 7.103250629383917e-06,
      "loss": 0.0001,
      "step": 18295
    },
    {
      "epoch": 0.2896907706192504,
      "grad_norm": 0.7304733395576477,
      "learning_rate": 7.1030922938074965e-06,
      "loss": 0.5073,
      "step": 18296
    },
    {
      "epoch": 0.2897066041768925,
      "grad_norm": 0.28789445757865906,
      "learning_rate": 7.102933958231076e-06,
      "loss": 0.1577,
      "step": 18297
    },
    {
      "epoch": 0.2897224377345346,
      "grad_norm": 0.021243402734398842,
      "learning_rate": 7.1027756226546555e-06,
      "loss": 0.0009,
      "step": 18298
    },
    {
      "epoch": 0.28973827129217666,
      "grad_norm": 0.8508250117301941,
      "learning_rate": 7.102617287078234e-06,
      "loss": 0.2158,
      "step": 18299
    },
    {
      "epoch": 0.2897541048498187,
      "grad_norm": 0.0018504648469388485,
      "learning_rate": 7.102458951501814e-06,
      "loss": 0.0001,
      "step": 18300
    },
    {
      "epoch": 0.2897699384074608,
      "grad_norm": 1.1881330013275146,
      "learning_rate": 7.102300615925393e-06,
      "loss": 0.1186,
      "step": 18301
    },
    {
      "epoch": 0.28978577196510286,
      "grad_norm": 0.2852461338043213,
      "learning_rate": 7.102142280348973e-06,
      "loss": 0.0935,
      "step": 18302
    },
    {
      "epoch": 0.2898016055227449,
      "grad_norm": 1.4315375089645386,
      "learning_rate": 7.101983944772552e-06,
      "loss": 0.1008,
      "step": 18303
    },
    {
      "epoch": 0.289817439080387,
      "grad_norm": 0.3458191156387329,
      "learning_rate": 7.101825609196132e-06,
      "loss": 0.058,
      "step": 18304
    },
    {
      "epoch": 0.28983327263802905,
      "grad_norm": 0.842059850692749,
      "learning_rate": 7.10166727361971e-06,
      "loss": 0.3637,
      "step": 18305
    },
    {
      "epoch": 0.2898491061956711,
      "grad_norm": 0.4591695964336395,
      "learning_rate": 7.10150893804329e-06,
      "loss": 0.1875,
      "step": 18306
    },
    {
      "epoch": 0.2898649397533132,
      "grad_norm": 0.024767301976680756,
      "learning_rate": 7.101350602466869e-06,
      "loss": 0.0013,
      "step": 18307
    },
    {
      "epoch": 0.28988077331095524,
      "grad_norm": 0.3440021872520447,
      "learning_rate": 7.101192266890449e-06,
      "loss": 0.1072,
      "step": 18308
    },
    {
      "epoch": 0.2898966068685973,
      "grad_norm": 0.7376720309257507,
      "learning_rate": 7.101033931314027e-06,
      "loss": 0.665,
      "step": 18309
    },
    {
      "epoch": 0.28991244042623937,
      "grad_norm": 1.224990963935852,
      "learning_rate": 7.100875595737606e-06,
      "loss": 0.1321,
      "step": 18310
    },
    {
      "epoch": 0.28992827398388143,
      "grad_norm": 1.179511308670044,
      "learning_rate": 7.100717260161186e-06,
      "loss": 0.1246,
      "step": 18311
    },
    {
      "epoch": 0.2899441075415235,
      "grad_norm": 0.1437450349330902,
      "learning_rate": 7.100558924584765e-06,
      "loss": 0.039,
      "step": 18312
    },
    {
      "epoch": 0.28995994109916556,
      "grad_norm": 0.5164451003074646,
      "learning_rate": 7.100400589008345e-06,
      "loss": 0.3749,
      "step": 18313
    },
    {
      "epoch": 0.28997577465680763,
      "grad_norm": 0.021222669631242752,
      "learning_rate": 7.100242253431923e-06,
      "loss": 0.0011,
      "step": 18314
    },
    {
      "epoch": 0.2899916082144497,
      "grad_norm": 0.2648898661136627,
      "learning_rate": 7.100083917855503e-06,
      "loss": 0.1053,
      "step": 18315
    },
    {
      "epoch": 0.29000744177209176,
      "grad_norm": 0.17153459787368774,
      "learning_rate": 7.099925582279082e-06,
      "loss": 0.005,
      "step": 18316
    },
    {
      "epoch": 0.2900232753297338,
      "grad_norm": 0.44708794355392456,
      "learning_rate": 7.099767246702662e-06,
      "loss": 0.2371,
      "step": 18317
    },
    {
      "epoch": 0.2900391088873759,
      "grad_norm": 0.4200015068054199,
      "learning_rate": 7.099608911126241e-06,
      "loss": 0.0744,
      "step": 18318
    },
    {
      "epoch": 0.29005494244501795,
      "grad_norm": 0.3846341073513031,
      "learning_rate": 7.099450575549821e-06,
      "loss": 0.0386,
      "step": 18319
    },
    {
      "epoch": 0.29007077600266,
      "grad_norm": 0.46733516454696655,
      "learning_rate": 7.0992922399733995e-06,
      "loss": 0.0545,
      "step": 18320
    },
    {
      "epoch": 0.2900866095603021,
      "grad_norm": 0.023689858615398407,
      "learning_rate": 7.0991339043969795e-06,
      "loss": 0.0012,
      "step": 18321
    },
    {
      "epoch": 0.2901024431179442,
      "grad_norm": 0.4731028974056244,
      "learning_rate": 7.0989755688205585e-06,
      "loss": 0.2215,
      "step": 18322
    },
    {
      "epoch": 0.29011827667558626,
      "grad_norm": 0.05221887305378914,
      "learning_rate": 7.0988172332441385e-06,
      "loss": 0.001,
      "step": 18323
    },
    {
      "epoch": 0.2901341102332283,
      "grad_norm": 0.3615967929363251,
      "learning_rate": 7.0986588976677175e-06,
      "loss": 0.1978,
      "step": 18324
    },
    {
      "epoch": 0.2901499437908704,
      "grad_norm": 0.03861597180366516,
      "learning_rate": 7.0985005620912975e-06,
      "loss": 0.0009,
      "step": 18325
    },
    {
      "epoch": 0.29016577734851245,
      "grad_norm": 0.02140152081847191,
      "learning_rate": 7.098342226514876e-06,
      "loss": 0.0014,
      "step": 18326
    },
    {
      "epoch": 0.2901816109061545,
      "grad_norm": 0.0006348122260533273,
      "learning_rate": 7.098183890938456e-06,
      "loss": 0.0,
      "step": 18327
    },
    {
      "epoch": 0.2901974444637966,
      "grad_norm": 0.8742899298667908,
      "learning_rate": 7.098025555362035e-06,
      "loss": 0.2956,
      "step": 18328
    },
    {
      "epoch": 0.29021327802143865,
      "grad_norm": 0.03290864825248718,
      "learning_rate": 7.097867219785615e-06,
      "loss": 0.0012,
      "step": 18329
    },
    {
      "epoch": 0.2902291115790807,
      "grad_norm": 0.812433660030365,
      "learning_rate": 7.097708884209194e-06,
      "loss": 0.4812,
      "step": 18330
    },
    {
      "epoch": 0.2902449451367228,
      "grad_norm": 0.41389816999435425,
      "learning_rate": 7.097550548632774e-06,
      "loss": 0.0609,
      "step": 18331
    },
    {
      "epoch": 0.29026077869436484,
      "grad_norm": 0.9540979862213135,
      "learning_rate": 7.097392213056352e-06,
      "loss": 0.7274,
      "step": 18332
    },
    {
      "epoch": 0.2902766122520069,
      "grad_norm": 0.00022425480710808188,
      "learning_rate": 7.097233877479932e-06,
      "loss": 0.0,
      "step": 18333
    },
    {
      "epoch": 0.29029244580964897,
      "grad_norm": 0.4364835023880005,
      "learning_rate": 7.097075541903511e-06,
      "loss": 0.2038,
      "step": 18334
    },
    {
      "epoch": 0.29030827936729103,
      "grad_norm": 0.0029818250332027674,
      "learning_rate": 7.09691720632709e-06,
      "loss": 0.0001,
      "step": 18335
    },
    {
      "epoch": 0.2903241129249331,
      "grad_norm": 0.6301555037498474,
      "learning_rate": 7.09675887075067e-06,
      "loss": 0.008,
      "step": 18336
    },
    {
      "epoch": 0.29033994648257516,
      "grad_norm": 0.48553401231765747,
      "learning_rate": 7.096600535174248e-06,
      "loss": 0.2105,
      "step": 18337
    },
    {
      "epoch": 0.2903557800402172,
      "grad_norm": 0.5916121602058411,
      "learning_rate": 7.096442199597828e-06,
      "loss": 0.0628,
      "step": 18338
    },
    {
      "epoch": 0.2903716135978593,
      "grad_norm": 0.4409622251987457,
      "learning_rate": 7.096283864021407e-06,
      "loss": 0.1262,
      "step": 18339
    },
    {
      "epoch": 0.29038744715550135,
      "grad_norm": 0.19686289131641388,
      "learning_rate": 7.096125528444987e-06,
      "loss": 0.0726,
      "step": 18340
    },
    {
      "epoch": 0.2904032807131434,
      "grad_norm": 0.014476981945335865,
      "learning_rate": 7.095967192868566e-06,
      "loss": 0.0006,
      "step": 18341
    },
    {
      "epoch": 0.2904191142707855,
      "grad_norm": 0.3507193326950073,
      "learning_rate": 7.095808857292146e-06,
      "loss": 0.0395,
      "step": 18342
    },
    {
      "epoch": 0.29043494782842755,
      "grad_norm": 0.25993019342422485,
      "learning_rate": 7.095650521715724e-06,
      "loss": 0.0504,
      "step": 18343
    },
    {
      "epoch": 0.2904507813860696,
      "grad_norm": 0.4012768268585205,
      "learning_rate": 7.095492186139304e-06,
      "loss": 0.1247,
      "step": 18344
    },
    {
      "epoch": 0.2904666149437117,
      "grad_norm": 0.011000225320458412,
      "learning_rate": 7.095333850562883e-06,
      "loss": 0.0004,
      "step": 18345
    },
    {
      "epoch": 0.2904824485013538,
      "grad_norm": 0.025795476511120796,
      "learning_rate": 7.095175514986463e-06,
      "loss": 0.0014,
      "step": 18346
    },
    {
      "epoch": 0.29049828205899586,
      "grad_norm": 0.12405801564455032,
      "learning_rate": 7.095017179410042e-06,
      "loss": 0.0042,
      "step": 18347
    },
    {
      "epoch": 0.2905141156166379,
      "grad_norm": 2.060615301132202,
      "learning_rate": 7.094858843833622e-06,
      "loss": 0.041,
      "step": 18348
    },
    {
      "epoch": 0.29052994917428,
      "grad_norm": 0.0004270223143976182,
      "learning_rate": 7.0947005082572005e-06,
      "loss": 0.0,
      "step": 18349
    },
    {
      "epoch": 0.29054578273192205,
      "grad_norm": 0.9604238867759705,
      "learning_rate": 7.09454217268078e-06,
      "loss": 0.264,
      "step": 18350
    },
    {
      "epoch": 0.2905616162895641,
      "grad_norm": 0.9057613611221313,
      "learning_rate": 7.0943838371043595e-06,
      "loss": 0.2956,
      "step": 18351
    },
    {
      "epoch": 0.2905774498472062,
      "grad_norm": 0.2397979497909546,
      "learning_rate": 7.094225501527939e-06,
      "loss": 0.0396,
      "step": 18352
    },
    {
      "epoch": 0.29059328340484825,
      "grad_norm": 0.13880687952041626,
      "learning_rate": 7.0940671659515185e-06,
      "loss": 0.0344,
      "step": 18353
    },
    {
      "epoch": 0.2906091169624903,
      "grad_norm": 0.5368260145187378,
      "learning_rate": 7.093908830375098e-06,
      "loss": 0.0898,
      "step": 18354
    },
    {
      "epoch": 0.2906249505201324,
      "grad_norm": 0.3679257035255432,
      "learning_rate": 7.093750494798677e-06,
      "loss": 0.027,
      "step": 18355
    },
    {
      "epoch": 0.29064078407777444,
      "grad_norm": 0.39923572540283203,
      "learning_rate": 7.0935921592222566e-06,
      "loss": 0.0618,
      "step": 18356
    },
    {
      "epoch": 0.2906566176354165,
      "grad_norm": 0.6974488496780396,
      "learning_rate": 7.093433823645836e-06,
      "loss": 0.2704,
      "step": 18357
    },
    {
      "epoch": 0.29067245119305857,
      "grad_norm": 0.40984877943992615,
      "learning_rate": 7.093275488069415e-06,
      "loss": 0.0523,
      "step": 18358
    },
    {
      "epoch": 0.29068828475070063,
      "grad_norm": 0.8191208839416504,
      "learning_rate": 7.093117152492995e-06,
      "loss": 0.2008,
      "step": 18359
    },
    {
      "epoch": 0.2907041183083427,
      "grad_norm": 0.8364866971969604,
      "learning_rate": 7.092958816916573e-06,
      "loss": 0.2287,
      "step": 18360
    },
    {
      "epoch": 0.29071995186598476,
      "grad_norm": 0.3043351471424103,
      "learning_rate": 7.092800481340153e-06,
      "loss": 0.1009,
      "step": 18361
    },
    {
      "epoch": 0.2907357854236268,
      "grad_norm": 0.007413765881210566,
      "learning_rate": 7.092642145763732e-06,
      "loss": 0.0003,
      "step": 18362
    },
    {
      "epoch": 0.2907516189812689,
      "grad_norm": 0.5105176568031311,
      "learning_rate": 7.092483810187312e-06,
      "loss": 0.1032,
      "step": 18363
    },
    {
      "epoch": 0.29076745253891095,
      "grad_norm": 0.5550540089607239,
      "learning_rate": 7.092325474610891e-06,
      "loss": 0.1622,
      "step": 18364
    },
    {
      "epoch": 0.290783286096553,
      "grad_norm": 1.1996711492538452,
      "learning_rate": 7.092167139034471e-06,
      "loss": 0.0442,
      "step": 18365
    },
    {
      "epoch": 0.2907991196541951,
      "grad_norm": 0.00014799056225456297,
      "learning_rate": 7.092008803458049e-06,
      "loss": 0.0,
      "step": 18366
    },
    {
      "epoch": 0.29081495321183715,
      "grad_norm": 0.7578051686286926,
      "learning_rate": 7.091850467881629e-06,
      "loss": 0.4746,
      "step": 18367
    },
    {
      "epoch": 0.2908307867694792,
      "grad_norm": 0.24280068278312683,
      "learning_rate": 7.091692132305208e-06,
      "loss": 0.0668,
      "step": 18368
    },
    {
      "epoch": 0.2908466203271213,
      "grad_norm": 0.3935510218143463,
      "learning_rate": 7.091533796728788e-06,
      "loss": 0.0549,
      "step": 18369
    },
    {
      "epoch": 0.2908624538847634,
      "grad_norm": 0.807398796081543,
      "learning_rate": 7.091375461152367e-06,
      "loss": 0.3018,
      "step": 18370
    },
    {
      "epoch": 0.29087828744240546,
      "grad_norm": 0.570827841758728,
      "learning_rate": 7.091217125575946e-06,
      "loss": 0.2969,
      "step": 18371
    },
    {
      "epoch": 0.2908941210000475,
      "grad_norm": 0.17397300899028778,
      "learning_rate": 7.091058789999525e-06,
      "loss": 0.069,
      "step": 18372
    },
    {
      "epoch": 0.2909099545576896,
      "grad_norm": 0.01172643806785345,
      "learning_rate": 7.090900454423105e-06,
      "loss": 0.0005,
      "step": 18373
    },
    {
      "epoch": 0.29092578811533165,
      "grad_norm": 0.006237420719116926,
      "learning_rate": 7.090742118846684e-06,
      "loss": 0.0003,
      "step": 18374
    },
    {
      "epoch": 0.2909416216729737,
      "grad_norm": 0.29817450046539307,
      "learning_rate": 7.090583783270264e-06,
      "loss": 0.0072,
      "step": 18375
    },
    {
      "epoch": 0.2909574552306158,
      "grad_norm": 0.009631572291254997,
      "learning_rate": 7.090425447693842e-06,
      "loss": 0.0005,
      "step": 18376
    },
    {
      "epoch": 0.29097328878825784,
      "grad_norm": 0.01914791390299797,
      "learning_rate": 7.090267112117422e-06,
      "loss": 0.0008,
      "step": 18377
    },
    {
      "epoch": 0.2909891223458999,
      "grad_norm": 0.5338414311408997,
      "learning_rate": 7.090108776541001e-06,
      "loss": 0.346,
      "step": 18378
    },
    {
      "epoch": 0.291004955903542,
      "grad_norm": 0.6460146307945251,
      "learning_rate": 7.089950440964581e-06,
      "loss": 0.1643,
      "step": 18379
    },
    {
      "epoch": 0.29102078946118404,
      "grad_norm": 0.15600384771823883,
      "learning_rate": 7.08979210538816e-06,
      "loss": 0.0423,
      "step": 18380
    },
    {
      "epoch": 0.2910366230188261,
      "grad_norm": 0.8882768750190735,
      "learning_rate": 7.08963376981174e-06,
      "loss": 0.2635,
      "step": 18381
    },
    {
      "epoch": 0.29105245657646817,
      "grad_norm": 0.006413430441170931,
      "learning_rate": 7.0894754342353185e-06,
      "loss": 0.0003,
      "step": 18382
    },
    {
      "epoch": 0.29106829013411023,
      "grad_norm": 0.5463588833808899,
      "learning_rate": 7.089317098658898e-06,
      "loss": 0.8213,
      "step": 18383
    },
    {
      "epoch": 0.2910841236917523,
      "grad_norm": 0.06995612382888794,
      "learning_rate": 7.0891587630824776e-06,
      "loss": 0.0037,
      "step": 18384
    },
    {
      "epoch": 0.29109995724939436,
      "grad_norm": 0.540940523147583,
      "learning_rate": 7.089000427506057e-06,
      "loss": 0.1869,
      "step": 18385
    },
    {
      "epoch": 0.2911157908070364,
      "grad_norm": 0.035348501056432724,
      "learning_rate": 7.0888420919296366e-06,
      "loss": 0.002,
      "step": 18386
    },
    {
      "epoch": 0.2911316243646785,
      "grad_norm": 0.32130542397499084,
      "learning_rate": 7.088683756353215e-06,
      "loss": 0.2152,
      "step": 18387
    },
    {
      "epoch": 0.29114745792232055,
      "grad_norm": 0.003015075344592333,
      "learning_rate": 7.088525420776795e-06,
      "loss": 0.0002,
      "step": 18388
    },
    {
      "epoch": 0.2911632914799626,
      "grad_norm": 0.6804322600364685,
      "learning_rate": 7.088367085200374e-06,
      "loss": 0.2428,
      "step": 18389
    },
    {
      "epoch": 0.2911791250376047,
      "grad_norm": 0.341582715511322,
      "learning_rate": 7.088208749623954e-06,
      "loss": 0.0243,
      "step": 18390
    },
    {
      "epoch": 0.29119495859524674,
      "grad_norm": 0.5050519704818726,
      "learning_rate": 7.088050414047533e-06,
      "loss": 0.1625,
      "step": 18391
    },
    {
      "epoch": 0.2912107921528888,
      "grad_norm": 0.1637185662984848,
      "learning_rate": 7.087892078471113e-06,
      "loss": 0.0521,
      "step": 18392
    },
    {
      "epoch": 0.2912266257105309,
      "grad_norm": 0.4076092839241028,
      "learning_rate": 7.087733742894691e-06,
      "loss": 0.0453,
      "step": 18393
    },
    {
      "epoch": 0.291242459268173,
      "grad_norm": 0.41635459661483765,
      "learning_rate": 7.087575407318271e-06,
      "loss": 0.1887,
      "step": 18394
    },
    {
      "epoch": 0.29125829282581506,
      "grad_norm": 0.01023691426962614,
      "learning_rate": 7.08741707174185e-06,
      "loss": 0.0003,
      "step": 18395
    },
    {
      "epoch": 0.2912741263834571,
      "grad_norm": 0.5550592541694641,
      "learning_rate": 7.08725873616543e-06,
      "loss": 0.2851,
      "step": 18396
    },
    {
      "epoch": 0.2912899599410992,
      "grad_norm": 0.2385648787021637,
      "learning_rate": 7.087100400589009e-06,
      "loss": 0.097,
      "step": 18397
    },
    {
      "epoch": 0.29130579349874125,
      "grad_norm": 0.8841477632522583,
      "learning_rate": 7.086942065012589e-06,
      "loss": 0.5433,
      "step": 18398
    },
    {
      "epoch": 0.2913216270563833,
      "grad_norm": 0.3733646273612976,
      "learning_rate": 7.086783729436167e-06,
      "loss": 0.1807,
      "step": 18399
    },
    {
      "epoch": 0.2913374606140254,
      "grad_norm": 0.476845920085907,
      "learning_rate": 7.086625393859747e-06,
      "loss": 0.1496,
      "step": 18400
    },
    {
      "epoch": 0.29135329417166744,
      "grad_norm": 0.006083684973418713,
      "learning_rate": 7.086467058283326e-06,
      "loss": 0.0002,
      "step": 18401
    },
    {
      "epoch": 0.2913691277293095,
      "grad_norm": 0.45179182291030884,
      "learning_rate": 7.086308722706906e-06,
      "loss": 0.0672,
      "step": 18402
    },
    {
      "epoch": 0.29138496128695157,
      "grad_norm": 0.2951463758945465,
      "learning_rate": 7.086150387130485e-06,
      "loss": 0.0956,
      "step": 18403
    },
    {
      "epoch": 0.29140079484459364,
      "grad_norm": 0.2368786782026291,
      "learning_rate": 7.085992051554065e-06,
      "loss": 0.0606,
      "step": 18404
    },
    {
      "epoch": 0.2914166284022357,
      "grad_norm": 3.194389820098877,
      "learning_rate": 7.085833715977643e-06,
      "loss": 0.1192,
      "step": 18405
    },
    {
      "epoch": 0.29143246195987776,
      "grad_norm": 0.0031212156172841787,
      "learning_rate": 7.085675380401222e-06,
      "loss": 0.0001,
      "step": 18406
    },
    {
      "epoch": 0.29144829551751983,
      "grad_norm": 0.772097110748291,
      "learning_rate": 7.085517044824802e-06,
      "loss": 0.1861,
      "step": 18407
    },
    {
      "epoch": 0.2914641290751619,
      "grad_norm": 0.28416907787323,
      "learning_rate": 7.085358709248381e-06,
      "loss": 0.0419,
      "step": 18408
    },
    {
      "epoch": 0.29147996263280396,
      "grad_norm": 0.011063078418374062,
      "learning_rate": 7.085200373671961e-06,
      "loss": 0.0004,
      "step": 18409
    },
    {
      "epoch": 0.291495796190446,
      "grad_norm": 0.5554242134094238,
      "learning_rate": 7.0850420380955396e-06,
      "loss": 0.1162,
      "step": 18410
    },
    {
      "epoch": 0.2915116297480881,
      "grad_norm": 7.288630149560049e-05,
      "learning_rate": 7.0848837025191195e-06,
      "loss": 0.0,
      "step": 18411
    },
    {
      "epoch": 0.29152746330573015,
      "grad_norm": 0.29938432574272156,
      "learning_rate": 7.0847253669426986e-06,
      "loss": 0.0538,
      "step": 18412
    },
    {
      "epoch": 0.2915432968633722,
      "grad_norm": 0.4213780164718628,
      "learning_rate": 7.0845670313662785e-06,
      "loss": 0.1135,
      "step": 18413
    },
    {
      "epoch": 0.2915591304210143,
      "grad_norm": 0.007884291931986809,
      "learning_rate": 7.0844086957898576e-06,
      "loss": 0.0001,
      "step": 18414
    },
    {
      "epoch": 0.29157496397865634,
      "grad_norm": 0.7549771070480347,
      "learning_rate": 7.0842503602134375e-06,
      "loss": 0.2074,
      "step": 18415
    },
    {
      "epoch": 0.2915907975362984,
      "grad_norm": 0.4622849225997925,
      "learning_rate": 7.084092024637016e-06,
      "loss": 0.1201,
      "step": 18416
    },
    {
      "epoch": 0.29160663109394047,
      "grad_norm": 0.0024011044297367334,
      "learning_rate": 7.083933689060596e-06,
      "loss": 0.0001,
      "step": 18417
    },
    {
      "epoch": 0.2916224646515826,
      "grad_norm": 0.28253889083862305,
      "learning_rate": 7.083775353484175e-06,
      "loss": 0.0611,
      "step": 18418
    },
    {
      "epoch": 0.29163829820922466,
      "grad_norm": 0.18716460466384888,
      "learning_rate": 7.083617017907755e-06,
      "loss": 0.0597,
      "step": 18419
    },
    {
      "epoch": 0.2916541317668667,
      "grad_norm": 0.36762991547584534,
      "learning_rate": 7.083458682331334e-06,
      "loss": 0.0437,
      "step": 18420
    },
    {
      "epoch": 0.2916699653245088,
      "grad_norm": 0.00035924403346143663,
      "learning_rate": 7.083300346754914e-06,
      "loss": 0.0,
      "step": 18421
    },
    {
      "epoch": 0.29168579888215085,
      "grad_norm": 0.5960997939109802,
      "learning_rate": 7.083142011178492e-06,
      "loss": 0.4721,
      "step": 18422
    },
    {
      "epoch": 0.2917016324397929,
      "grad_norm": 0.7061865925788879,
      "learning_rate": 7.082983675602072e-06,
      "loss": 0.279,
      "step": 18423
    },
    {
      "epoch": 0.291717465997435,
      "grad_norm": 0.20957188308238983,
      "learning_rate": 7.082825340025651e-06,
      "loss": 0.0287,
      "step": 18424
    },
    {
      "epoch": 0.29173329955507704,
      "grad_norm": 1.5382510423660278,
      "learning_rate": 7.082667004449231e-06,
      "loss": 0.1506,
      "step": 18425
    },
    {
      "epoch": 0.2917491331127191,
      "grad_norm": 0.00039036606904119253,
      "learning_rate": 7.08250866887281e-06,
      "loss": 0.0,
      "step": 18426
    },
    {
      "epoch": 0.29176496667036117,
      "grad_norm": 0.4226039946079254,
      "learning_rate": 7.08235033329639e-06,
      "loss": 0.043,
      "step": 18427
    },
    {
      "epoch": 0.29178080022800323,
      "grad_norm": 0.6225477457046509,
      "learning_rate": 7.082191997719968e-06,
      "loss": 0.212,
      "step": 18428
    },
    {
      "epoch": 0.2917966337856453,
      "grad_norm": 0.4277665317058563,
      "learning_rate": 7.082033662143548e-06,
      "loss": 0.1803,
      "step": 18429
    },
    {
      "epoch": 0.29181246734328736,
      "grad_norm": 0.007460880558937788,
      "learning_rate": 7.081875326567127e-06,
      "loss": 0.0004,
      "step": 18430
    },
    {
      "epoch": 0.2918283009009294,
      "grad_norm": 0.015825333073735237,
      "learning_rate": 7.081716990990706e-06,
      "loss": 0.0009,
      "step": 18431
    },
    {
      "epoch": 0.2918441344585715,
      "grad_norm": 1.6001856327056885,
      "learning_rate": 7.081558655414286e-06,
      "loss": 0.0687,
      "step": 18432
    },
    {
      "epoch": 0.29185996801621356,
      "grad_norm": 0.3041543960571289,
      "learning_rate": 7.081400319837864e-06,
      "loss": 0.1103,
      "step": 18433
    },
    {
      "epoch": 0.2918758015738556,
      "grad_norm": 0.7231204509735107,
      "learning_rate": 7.081241984261444e-06,
      "loss": 0.3188,
      "step": 18434
    },
    {
      "epoch": 0.2918916351314977,
      "grad_norm": 0.1128883808851242,
      "learning_rate": 7.081083648685023e-06,
      "loss": 0.0342,
      "step": 18435
    },
    {
      "epoch": 0.29190746868913975,
      "grad_norm": 0.0124666141346097,
      "learning_rate": 7.080925313108603e-06,
      "loss": 0.0004,
      "step": 18436
    },
    {
      "epoch": 0.2919233022467818,
      "grad_norm": 0.7817611694335938,
      "learning_rate": 7.0807669775321815e-06,
      "loss": 0.3091,
      "step": 18437
    },
    {
      "epoch": 0.2919391358044239,
      "grad_norm": 0.01499710138887167,
      "learning_rate": 7.080608641955761e-06,
      "loss": 0.0006,
      "step": 18438
    },
    {
      "epoch": 0.29195496936206594,
      "grad_norm": 0.3727494776248932,
      "learning_rate": 7.0804503063793405e-06,
      "loss": 0.1338,
      "step": 18439
    },
    {
      "epoch": 0.291970802919708,
      "grad_norm": 2.5382864475250244,
      "learning_rate": 7.08029197080292e-06,
      "loss": 0.1108,
      "step": 18440
    },
    {
      "epoch": 0.29198663647735007,
      "grad_norm": 0.16202300786972046,
      "learning_rate": 7.0801336352264995e-06,
      "loss": 0.055,
      "step": 18441
    },
    {
      "epoch": 0.2920024700349922,
      "grad_norm": 0.004612558055669069,
      "learning_rate": 7.079975299650079e-06,
      "loss": 0.0001,
      "step": 18442
    },
    {
      "epoch": 0.29201830359263425,
      "grad_norm": 0.547620952129364,
      "learning_rate": 7.079816964073658e-06,
      "loss": 0.2734,
      "step": 18443
    },
    {
      "epoch": 0.2920341371502763,
      "grad_norm": 0.09690884500741959,
      "learning_rate": 7.0796586284972376e-06,
      "loss": 0.0055,
      "step": 18444
    },
    {
      "epoch": 0.2920499707079184,
      "grad_norm": 0.4979366064071655,
      "learning_rate": 7.079500292920817e-06,
      "loss": 0.1893,
      "step": 18445
    },
    {
      "epoch": 0.29206580426556045,
      "grad_norm": 0.0004793101397808641,
      "learning_rate": 7.079341957344397e-06,
      "loss": 0.0,
      "step": 18446
    },
    {
      "epoch": 0.2920816378232025,
      "grad_norm": 0.47293534874916077,
      "learning_rate": 7.079183621767976e-06,
      "loss": 0.0598,
      "step": 18447
    },
    {
      "epoch": 0.2920974713808446,
      "grad_norm": 0.00862317904829979,
      "learning_rate": 7.079025286191556e-06,
      "loss": 0.0005,
      "step": 18448
    },
    {
      "epoch": 0.29211330493848664,
      "grad_norm": 0.02666190266609192,
      "learning_rate": 7.078866950615134e-06,
      "loss": 0.0012,
      "step": 18449
    },
    {
      "epoch": 0.2921291384961287,
      "grad_norm": 0.45984116196632385,
      "learning_rate": 7.078708615038714e-06,
      "loss": 0.1669,
      "step": 18450
    },
    {
      "epoch": 0.29214497205377077,
      "grad_norm": 0.018809586763381958,
      "learning_rate": 7.078550279462293e-06,
      "loss": 0.0008,
      "step": 18451
    },
    {
      "epoch": 0.29216080561141283,
      "grad_norm": 0.349448025226593,
      "learning_rate": 7.078391943885873e-06,
      "loss": 0.0498,
      "step": 18452
    },
    {
      "epoch": 0.2921766391690549,
      "grad_norm": 0.01217179000377655,
      "learning_rate": 7.078233608309452e-06,
      "loss": 0.0005,
      "step": 18453
    },
    {
      "epoch": 0.29219247272669696,
      "grad_norm": 0.6303485035896301,
      "learning_rate": 7.07807527273303e-06,
      "loss": 0.2584,
      "step": 18454
    },
    {
      "epoch": 0.292208306284339,
      "grad_norm": 0.0832996815443039,
      "learning_rate": 7.07791693715661e-06,
      "loss": 0.0014,
      "step": 18455
    },
    {
      "epoch": 0.2922241398419811,
      "grad_norm": 0.4019196927547455,
      "learning_rate": 7.077758601580189e-06,
      "loss": 0.1029,
      "step": 18456
    },
    {
      "epoch": 0.29223997339962315,
      "grad_norm": 0.37179335951805115,
      "learning_rate": 7.077600266003769e-06,
      "loss": 0.0957,
      "step": 18457
    },
    {
      "epoch": 0.2922558069572652,
      "grad_norm": 0.353176087141037,
      "learning_rate": 7.077441930427348e-06,
      "loss": 0.1458,
      "step": 18458
    },
    {
      "epoch": 0.2922716405149073,
      "grad_norm": 0.008712169714272022,
      "learning_rate": 7.077283594850928e-06,
      "loss": 0.0003,
      "step": 18459
    },
    {
      "epoch": 0.29228747407254935,
      "grad_norm": 0.0006400232086889446,
      "learning_rate": 7.077125259274506e-06,
      "loss": 0.0,
      "step": 18460
    },
    {
      "epoch": 0.2923033076301914,
      "grad_norm": 0.008390543982386589,
      "learning_rate": 7.076966923698086e-06,
      "loss": 0.0001,
      "step": 18461
    },
    {
      "epoch": 0.2923191411878335,
      "grad_norm": 0.05836471915245056,
      "learning_rate": 7.076808588121665e-06,
      "loss": 0.0022,
      "step": 18462
    },
    {
      "epoch": 0.29233497474547554,
      "grad_norm": 0.5105801224708557,
      "learning_rate": 7.076650252545245e-06,
      "loss": 0.1506,
      "step": 18463
    },
    {
      "epoch": 0.2923508083031176,
      "grad_norm": 0.45553553104400635,
      "learning_rate": 7.076491916968824e-06,
      "loss": 0.0448,
      "step": 18464
    },
    {
      "epoch": 0.29236664186075967,
      "grad_norm": 0.4491957426071167,
      "learning_rate": 7.076333581392404e-06,
      "loss": 0.0804,
      "step": 18465
    },
    {
      "epoch": 0.2923824754184018,
      "grad_norm": 0.5874223709106445,
      "learning_rate": 7.076175245815982e-06,
      "loss": 0.2668,
      "step": 18466
    },
    {
      "epoch": 0.29239830897604385,
      "grad_norm": 0.02909320779144764,
      "learning_rate": 7.076016910239562e-06,
      "loss": 0.0013,
      "step": 18467
    },
    {
      "epoch": 0.2924141425336859,
      "grad_norm": 0.034955430775880814,
      "learning_rate": 7.075858574663141e-06,
      "loss": 0.0018,
      "step": 18468
    },
    {
      "epoch": 0.292429976091328,
      "grad_norm": 0.025914669036865234,
      "learning_rate": 7.075700239086721e-06,
      "loss": 0.0013,
      "step": 18469
    },
    {
      "epoch": 0.29244580964897005,
      "grad_norm": 0.8877862691879272,
      "learning_rate": 7.0755419035103e-06,
      "loss": 0.3181,
      "step": 18470
    },
    {
      "epoch": 0.2924616432066121,
      "grad_norm": 0.670059084892273,
      "learning_rate": 7.07538356793388e-06,
      "loss": 0.7345,
      "step": 18471
    },
    {
      "epoch": 0.2924774767642542,
      "grad_norm": 0.38232704997062683,
      "learning_rate": 7.075225232357459e-06,
      "loss": 0.1276,
      "step": 18472
    },
    {
      "epoch": 0.29249331032189624,
      "grad_norm": 0.0002461319381836802,
      "learning_rate": 7.0750668967810385e-06,
      "loss": 0.0,
      "step": 18473
    },
    {
      "epoch": 0.2925091438795383,
      "grad_norm": 0.639349639415741,
      "learning_rate": 7.074908561204618e-06,
      "loss": 0.2066,
      "step": 18474
    },
    {
      "epoch": 0.29252497743718037,
      "grad_norm": 0.3060472011566162,
      "learning_rate": 7.0747502256281975e-06,
      "loss": 0.0945,
      "step": 18475
    },
    {
      "epoch": 0.29254081099482243,
      "grad_norm": 0.6760830283164978,
      "learning_rate": 7.074591890051777e-06,
      "loss": 0.2295,
      "step": 18476
    },
    {
      "epoch": 0.2925566445524645,
      "grad_norm": 0.2730615735054016,
      "learning_rate": 7.0744335544753565e-06,
      "loss": 0.0322,
      "step": 18477
    },
    {
      "epoch": 0.29257247811010656,
      "grad_norm": 0.0009183304500766098,
      "learning_rate": 7.074275218898935e-06,
      "loss": 0.0,
      "step": 18478
    },
    {
      "epoch": 0.2925883116677486,
      "grad_norm": 1.0415266752243042,
      "learning_rate": 7.074116883322514e-06,
      "loss": 0.1884,
      "step": 18479
    },
    {
      "epoch": 0.2926041452253907,
      "grad_norm": 0.03234934061765671,
      "learning_rate": 7.073958547746094e-06,
      "loss": 0.0019,
      "step": 18480
    },
    {
      "epoch": 0.29261997878303275,
      "grad_norm": 0.44108396768569946,
      "learning_rate": 7.073800212169673e-06,
      "loss": 0.0709,
      "step": 18481
    },
    {
      "epoch": 0.2926358123406748,
      "grad_norm": 0.16590693593025208,
      "learning_rate": 7.073641876593253e-06,
      "loss": 0.0336,
      "step": 18482
    },
    {
      "epoch": 0.2926516458983169,
      "grad_norm": 0.29960235953330994,
      "learning_rate": 7.073483541016831e-06,
      "loss": 0.0586,
      "step": 18483
    },
    {
      "epoch": 0.29266747945595895,
      "grad_norm": 0.02233770675957203,
      "learning_rate": 7.073325205440411e-06,
      "loss": 0.0011,
      "step": 18484
    },
    {
      "epoch": 0.292683313013601,
      "grad_norm": 0.38334769010543823,
      "learning_rate": 7.07316686986399e-06,
      "loss": 0.081,
      "step": 18485
    },
    {
      "epoch": 0.2926991465712431,
      "grad_norm": 0.8775935173034668,
      "learning_rate": 7.07300853428757e-06,
      "loss": 0.1401,
      "step": 18486
    },
    {
      "epoch": 0.29271498012888514,
      "grad_norm": 0.12866933643817902,
      "learning_rate": 7.072850198711149e-06,
      "loss": 0.0064,
      "step": 18487
    },
    {
      "epoch": 0.2927308136865272,
      "grad_norm": 0.037976011633872986,
      "learning_rate": 7.072691863134729e-06,
      "loss": 0.0015,
      "step": 18488
    },
    {
      "epoch": 0.29274664724416927,
      "grad_norm": 0.3649344742298126,
      "learning_rate": 7.072533527558307e-06,
      "loss": 0.0503,
      "step": 18489
    },
    {
      "epoch": 0.2927624808018114,
      "grad_norm": 0.12870407104492188,
      "learning_rate": 7.072375191981887e-06,
      "loss": 0.0048,
      "step": 18490
    },
    {
      "epoch": 0.29277831435945345,
      "grad_norm": 0.12054084241390228,
      "learning_rate": 7.072216856405466e-06,
      "loss": 0.0036,
      "step": 18491
    },
    {
      "epoch": 0.2927941479170955,
      "grad_norm": 0.17122569680213928,
      "learning_rate": 7.072058520829046e-06,
      "loss": 0.0087,
      "step": 18492
    },
    {
      "epoch": 0.2928099814747376,
      "grad_norm": 0.39075857400894165,
      "learning_rate": 7.071900185252625e-06,
      "loss": 0.06,
      "step": 18493
    },
    {
      "epoch": 0.29282581503237964,
      "grad_norm": 0.132971853017807,
      "learning_rate": 7.071741849676205e-06,
      "loss": 0.0277,
      "step": 18494
    },
    {
      "epoch": 0.2928416485900217,
      "grad_norm": 0.00037258394877426326,
      "learning_rate": 7.071583514099783e-06,
      "loss": 0.0,
      "step": 18495
    },
    {
      "epoch": 0.2928574821476638,
      "grad_norm": 0.02049289271235466,
      "learning_rate": 7.071425178523363e-06,
      "loss": 0.0012,
      "step": 18496
    },
    {
      "epoch": 0.29287331570530584,
      "grad_norm": 0.18660619854927063,
      "learning_rate": 7.071266842946942e-06,
      "loss": 0.0601,
      "step": 18497
    },
    {
      "epoch": 0.2928891492629479,
      "grad_norm": 0.008424708619713783,
      "learning_rate": 7.071108507370522e-06,
      "loss": 0.0004,
      "step": 18498
    },
    {
      "epoch": 0.29290498282058997,
      "grad_norm": 0.5367059111595154,
      "learning_rate": 7.0709501717941005e-06,
      "loss": 0.295,
      "step": 18499
    },
    {
      "epoch": 0.29292081637823203,
      "grad_norm": 0.33518657088279724,
      "learning_rate": 7.0707918362176804e-06,
      "loss": 0.2694,
      "step": 18500
    },
    {
      "epoch": 0.2929366499358741,
      "grad_norm": 8.110132330330089e-05,
      "learning_rate": 7.0706335006412595e-06,
      "loss": 0.0,
      "step": 18501
    },
    {
      "epoch": 0.29295248349351616,
      "grad_norm": 0.49673065543174744,
      "learning_rate": 7.070475165064839e-06,
      "loss": 0.2327,
      "step": 18502
    },
    {
      "epoch": 0.2929683170511582,
      "grad_norm": 0.009915469214320183,
      "learning_rate": 7.0703168294884185e-06,
      "loss": 0.0005,
      "step": 18503
    },
    {
      "epoch": 0.2929841506088003,
      "grad_norm": 0.6360880136489868,
      "learning_rate": 7.070158493911997e-06,
      "loss": 0.0433,
      "step": 18504
    },
    {
      "epoch": 0.29299998416644235,
      "grad_norm": 0.22991301119327545,
      "learning_rate": 7.070000158335577e-06,
      "loss": 0.072,
      "step": 18505
    },
    {
      "epoch": 0.2930158177240844,
      "grad_norm": 0.46806618571281433,
      "learning_rate": 7.069841822759156e-06,
      "loss": 0.1587,
      "step": 18506
    },
    {
      "epoch": 0.2930316512817265,
      "grad_norm": 0.012277797795832157,
      "learning_rate": 7.069683487182736e-06,
      "loss": 0.0005,
      "step": 18507
    },
    {
      "epoch": 0.29304748483936854,
      "grad_norm": 0.9961397647857666,
      "learning_rate": 7.069525151606315e-06,
      "loss": 0.3183,
      "step": 18508
    },
    {
      "epoch": 0.2930633183970106,
      "grad_norm": 0.42630255222320557,
      "learning_rate": 7.069366816029895e-06,
      "loss": 0.1482,
      "step": 18509
    },
    {
      "epoch": 0.2930791519546527,
      "grad_norm": 0.6696459650993347,
      "learning_rate": 7.069208480453473e-06,
      "loss": 0.3134,
      "step": 18510
    },
    {
      "epoch": 0.29309498551229474,
      "grad_norm": 0.4207957684993744,
      "learning_rate": 7.069050144877053e-06,
      "loss": 0.0775,
      "step": 18511
    },
    {
      "epoch": 0.2931108190699368,
      "grad_norm": 0.005347297061234713,
      "learning_rate": 7.068891809300632e-06,
      "loss": 0.0002,
      "step": 18512
    },
    {
      "epoch": 0.29312665262757887,
      "grad_norm": 0.00012514175614342093,
      "learning_rate": 7.068733473724212e-06,
      "loss": 0.0,
      "step": 18513
    },
    {
      "epoch": 0.29314248618522093,
      "grad_norm": 0.3466397225856781,
      "learning_rate": 7.068575138147791e-06,
      "loss": 0.1237,
      "step": 18514
    },
    {
      "epoch": 0.29315831974286305,
      "grad_norm": 0.7306806445121765,
      "learning_rate": 7.068416802571371e-06,
      "loss": 0.3947,
      "step": 18515
    },
    {
      "epoch": 0.2931741533005051,
      "grad_norm": 0.18193776905536652,
      "learning_rate": 7.068258466994949e-06,
      "loss": 0.0655,
      "step": 18516
    },
    {
      "epoch": 0.2931899868581472,
      "grad_norm": 0.0003132088459096849,
      "learning_rate": 7.068100131418529e-06,
      "loss": 0.0,
      "step": 18517
    },
    {
      "epoch": 0.29320582041578924,
      "grad_norm": 0.8085657358169556,
      "learning_rate": 7.067941795842108e-06,
      "loss": 0.3035,
      "step": 18518
    },
    {
      "epoch": 0.2932216539734313,
      "grad_norm": 1.839758276939392,
      "learning_rate": 7.067783460265688e-06,
      "loss": 0.121,
      "step": 18519
    },
    {
      "epoch": 0.29323748753107337,
      "grad_norm": 0.24477547407150269,
      "learning_rate": 7.067625124689267e-06,
      "loss": 0.1348,
      "step": 18520
    },
    {
      "epoch": 0.29325332108871544,
      "grad_norm": 0.6582446694374084,
      "learning_rate": 7.067466789112847e-06,
      "loss": 0.365,
      "step": 18521
    },
    {
      "epoch": 0.2932691546463575,
      "grad_norm": 0.2925484776496887,
      "learning_rate": 7.067308453536425e-06,
      "loss": 0.0325,
      "step": 18522
    },
    {
      "epoch": 0.29328498820399956,
      "grad_norm": 0.6471500992774963,
      "learning_rate": 7.067150117960005e-06,
      "loss": 0.2242,
      "step": 18523
    },
    {
      "epoch": 0.29330082176164163,
      "grad_norm": 0.4716954827308655,
      "learning_rate": 7.066991782383584e-06,
      "loss": 0.4376,
      "step": 18524
    },
    {
      "epoch": 0.2933166553192837,
      "grad_norm": 0.5548129677772522,
      "learning_rate": 7.066833446807164e-06,
      "loss": 0.1802,
      "step": 18525
    },
    {
      "epoch": 0.29333248887692576,
      "grad_norm": 0.01815529726445675,
      "learning_rate": 7.066675111230743e-06,
      "loss": 0.001,
      "step": 18526
    },
    {
      "epoch": 0.2933483224345678,
      "grad_norm": 0.29529696702957153,
      "learning_rate": 7.0665167756543215e-06,
      "loss": 0.0823,
      "step": 18527
    },
    {
      "epoch": 0.2933641559922099,
      "grad_norm": 0.44387519359588623,
      "learning_rate": 7.0663584400779014e-06,
      "loss": 0.1492,
      "step": 18528
    },
    {
      "epoch": 0.29337998954985195,
      "grad_norm": 0.6742839217185974,
      "learning_rate": 7.0662001045014805e-06,
      "loss": 0.2672,
      "step": 18529
    },
    {
      "epoch": 0.293395823107494,
      "grad_norm": 0.3933950662612915,
      "learning_rate": 7.0660417689250604e-06,
      "loss": 0.103,
      "step": 18530
    },
    {
      "epoch": 0.2934116566651361,
      "grad_norm": 0.3259851932525635,
      "learning_rate": 7.0658834333486395e-06,
      "loss": 0.3327,
      "step": 18531
    },
    {
      "epoch": 0.29342749022277814,
      "grad_norm": 0.2601113021373749,
      "learning_rate": 7.0657250977722194e-06,
      "loss": 0.1035,
      "step": 18532
    },
    {
      "epoch": 0.2934433237804202,
      "grad_norm": 0.41079819202423096,
      "learning_rate": 7.065566762195798e-06,
      "loss": 0.2309,
      "step": 18533
    },
    {
      "epoch": 0.29345915733806227,
      "grad_norm": 0.46602118015289307,
      "learning_rate": 7.065408426619378e-06,
      "loss": 0.1803,
      "step": 18534
    },
    {
      "epoch": 0.29347499089570434,
      "grad_norm": 0.3776003122329712,
      "learning_rate": 7.065250091042957e-06,
      "loss": 0.1576,
      "step": 18535
    },
    {
      "epoch": 0.2934908244533464,
      "grad_norm": 0.00019774939573835582,
      "learning_rate": 7.065091755466537e-06,
      "loss": 0.0,
      "step": 18536
    },
    {
      "epoch": 0.29350665801098846,
      "grad_norm": 0.27490031719207764,
      "learning_rate": 7.064933419890116e-06,
      "loss": 0.0378,
      "step": 18537
    },
    {
      "epoch": 0.29352249156863053,
      "grad_norm": 0.5505346059799194,
      "learning_rate": 7.064775084313696e-06,
      "loss": 0.2132,
      "step": 18538
    },
    {
      "epoch": 0.29353832512627265,
      "grad_norm": 0.02751031517982483,
      "learning_rate": 7.064616748737274e-06,
      "loss": 0.0014,
      "step": 18539
    },
    {
      "epoch": 0.2935541586839147,
      "grad_norm": 1.0957796573638916,
      "learning_rate": 7.064458413160854e-06,
      "loss": 0.128,
      "step": 18540
    },
    {
      "epoch": 0.2935699922415568,
      "grad_norm": 0.8378738164901733,
      "learning_rate": 7.064300077584433e-06,
      "loss": 0.8894,
      "step": 18541
    },
    {
      "epoch": 0.29358582579919884,
      "grad_norm": 0.026466380804777145,
      "learning_rate": 7.064141742008013e-06,
      "loss": 0.0015,
      "step": 18542
    },
    {
      "epoch": 0.2936016593568409,
      "grad_norm": 0.5518524050712585,
      "learning_rate": 7.063983406431592e-06,
      "loss": 0.2062,
      "step": 18543
    },
    {
      "epoch": 0.29361749291448297,
      "grad_norm": 0.23619358241558075,
      "learning_rate": 7.063825070855172e-06,
      "loss": 0.0596,
      "step": 18544
    },
    {
      "epoch": 0.29363332647212503,
      "grad_norm": 0.3096074163913727,
      "learning_rate": 7.06366673527875e-06,
      "loss": 0.1347,
      "step": 18545
    },
    {
      "epoch": 0.2936491600297671,
      "grad_norm": 0.010964462533593178,
      "learning_rate": 7.06350839970233e-06,
      "loss": 0.0006,
      "step": 18546
    },
    {
      "epoch": 0.29366499358740916,
      "grad_norm": 0.20595191419124603,
      "learning_rate": 7.063350064125909e-06,
      "loss": 0.0628,
      "step": 18547
    },
    {
      "epoch": 0.2936808271450512,
      "grad_norm": 1.031159520149231,
      "learning_rate": 7.063191728549489e-06,
      "loss": 0.9199,
      "step": 18548
    },
    {
      "epoch": 0.2936966607026933,
      "grad_norm": 0.007927801460027695,
      "learning_rate": 7.063033392973068e-06,
      "loss": 0.0003,
      "step": 18549
    },
    {
      "epoch": 0.29371249426033536,
      "grad_norm": 0.33621400594711304,
      "learning_rate": 7.062875057396648e-06,
      "loss": 0.0908,
      "step": 18550
    },
    {
      "epoch": 0.2937283278179774,
      "grad_norm": 0.02547604776918888,
      "learning_rate": 7.062716721820226e-06,
      "loss": 0.0011,
      "step": 18551
    },
    {
      "epoch": 0.2937441613756195,
      "grad_norm": 0.021840978413820267,
      "learning_rate": 7.062558386243805e-06,
      "loss": 0.0011,
      "step": 18552
    },
    {
      "epoch": 0.29375999493326155,
      "grad_norm": 0.4099642038345337,
      "learning_rate": 7.062400050667385e-06,
      "loss": 0.0516,
      "step": 18553
    },
    {
      "epoch": 0.2937758284909036,
      "grad_norm": 0.12557895481586456,
      "learning_rate": 7.062241715090964e-06,
      "loss": 0.0377,
      "step": 18554
    },
    {
      "epoch": 0.2937916620485457,
      "grad_norm": 0.023942574858665466,
      "learning_rate": 7.062083379514544e-06,
      "loss": 0.0002,
      "step": 18555
    },
    {
      "epoch": 0.29380749560618774,
      "grad_norm": 0.5969299077987671,
      "learning_rate": 7.0619250439381224e-06,
      "loss": 0.0786,
      "step": 18556
    },
    {
      "epoch": 0.2938233291638298,
      "grad_norm": 0.9279298186302185,
      "learning_rate": 7.061766708361702e-06,
      "loss": 0.4039,
      "step": 18557
    },
    {
      "epoch": 0.29383916272147187,
      "grad_norm": 0.6681786179542542,
      "learning_rate": 7.0616083727852814e-06,
      "loss": 0.4615,
      "step": 18558
    },
    {
      "epoch": 0.29385499627911393,
      "grad_norm": 0.37863144278526306,
      "learning_rate": 7.061450037208861e-06,
      "loss": 0.0911,
      "step": 18559
    },
    {
      "epoch": 0.293870829836756,
      "grad_norm": 0.818399965763092,
      "learning_rate": 7.0612917016324405e-06,
      "loss": 0.2854,
      "step": 18560
    },
    {
      "epoch": 0.29388666339439806,
      "grad_norm": 0.17886120080947876,
      "learning_rate": 7.06113336605602e-06,
      "loss": 0.0239,
      "step": 18561
    },
    {
      "epoch": 0.2939024969520401,
      "grad_norm": 0.8133827447891235,
      "learning_rate": 7.060975030479599e-06,
      "loss": 0.3989,
      "step": 18562
    },
    {
      "epoch": 0.29391833050968225,
      "grad_norm": 0.42417097091674805,
      "learning_rate": 7.0608166949031785e-06,
      "loss": 0.176,
      "step": 18563
    },
    {
      "epoch": 0.2939341640673243,
      "grad_norm": 0.6523653864860535,
      "learning_rate": 7.060658359326758e-06,
      "loss": 0.1551,
      "step": 18564
    },
    {
      "epoch": 0.2939499976249664,
      "grad_norm": 0.16091087460517883,
      "learning_rate": 7.0605000237503375e-06,
      "loss": 0.0635,
      "step": 18565
    },
    {
      "epoch": 0.29396583118260844,
      "grad_norm": 0.019704822450876236,
      "learning_rate": 7.060341688173916e-06,
      "loss": 0.0011,
      "step": 18566
    },
    {
      "epoch": 0.2939816647402505,
      "grad_norm": 0.09143054485321045,
      "learning_rate": 7.060183352597496e-06,
      "loss": 0.0026,
      "step": 18567
    },
    {
      "epoch": 0.29399749829789257,
      "grad_norm": 0.00785036850720644,
      "learning_rate": 7.060025017021075e-06,
      "loss": 0.0003,
      "step": 18568
    },
    {
      "epoch": 0.29401333185553463,
      "grad_norm": 0.3573756515979767,
      "learning_rate": 7.059866681444655e-06,
      "loss": 0.0357,
      "step": 18569
    },
    {
      "epoch": 0.2940291654131767,
      "grad_norm": 0.007470012176781893,
      "learning_rate": 7.059708345868234e-06,
      "loss": 0.0003,
      "step": 18570
    },
    {
      "epoch": 0.29404499897081876,
      "grad_norm": 0.6321210265159607,
      "learning_rate": 7.059550010291814e-06,
      "loss": 0.2294,
      "step": 18571
    },
    {
      "epoch": 0.2940608325284608,
      "grad_norm": 0.3428822457790375,
      "learning_rate": 7.059391674715392e-06,
      "loss": 0.0439,
      "step": 18572
    },
    {
      "epoch": 0.2940766660861029,
      "grad_norm": 0.5419734120368958,
      "learning_rate": 7.059233339138972e-06,
      "loss": 0.1393,
      "step": 18573
    },
    {
      "epoch": 0.29409249964374495,
      "grad_norm": 0.7193946242332458,
      "learning_rate": 7.059075003562551e-06,
      "loss": 0.1904,
      "step": 18574
    },
    {
      "epoch": 0.294108333201387,
      "grad_norm": 0.0007801505853421986,
      "learning_rate": 7.05891666798613e-06,
      "loss": 0.0,
      "step": 18575
    },
    {
      "epoch": 0.2941241667590291,
      "grad_norm": 0.6709029078483582,
      "learning_rate": 7.05875833240971e-06,
      "loss": 0.1025,
      "step": 18576
    },
    {
      "epoch": 0.29414000031667115,
      "grad_norm": 0.31659799814224243,
      "learning_rate": 7.058599996833288e-06,
      "loss": 0.0537,
      "step": 18577
    },
    {
      "epoch": 0.2941558338743132,
      "grad_norm": 0.16627103090286255,
      "learning_rate": 7.058441661256868e-06,
      "loss": 0.0431,
      "step": 18578
    },
    {
      "epoch": 0.2941716674319553,
      "grad_norm": 0.011938849464058876,
      "learning_rate": 7.058283325680447e-06,
      "loss": 0.0005,
      "step": 18579
    },
    {
      "epoch": 0.29418750098959734,
      "grad_norm": 0.3091616630554199,
      "learning_rate": 7.058124990104027e-06,
      "loss": 0.0846,
      "step": 18580
    },
    {
      "epoch": 0.2942033345472394,
      "grad_norm": 0.727664589881897,
      "learning_rate": 7.057966654527606e-06,
      "loss": 0.1545,
      "step": 18581
    },
    {
      "epoch": 0.29421916810488147,
      "grad_norm": 0.007979798130691051,
      "learning_rate": 7.057808318951186e-06,
      "loss": 0.0004,
      "step": 18582
    },
    {
      "epoch": 0.29423500166252353,
      "grad_norm": 0.026401298120617867,
      "learning_rate": 7.057649983374764e-06,
      "loss": 0.0013,
      "step": 18583
    },
    {
      "epoch": 0.2942508352201656,
      "grad_norm": 0.0002313054574187845,
      "learning_rate": 7.057491647798344e-06,
      "loss": 0.0,
      "step": 18584
    },
    {
      "epoch": 0.29426666877780766,
      "grad_norm": 0.4383411109447479,
      "learning_rate": 7.057333312221923e-06,
      "loss": 0.2977,
      "step": 18585
    },
    {
      "epoch": 0.2942825023354497,
      "grad_norm": 0.022444911301136017,
      "learning_rate": 7.057174976645503e-06,
      "loss": 0.0009,
      "step": 18586
    },
    {
      "epoch": 0.29429833589309184,
      "grad_norm": 0.30104026198387146,
      "learning_rate": 7.057016641069082e-06,
      "loss": 0.0502,
      "step": 18587
    },
    {
      "epoch": 0.2943141694507339,
      "grad_norm": 0.43361857533454895,
      "learning_rate": 7.056858305492662e-06,
      "loss": 0.2954,
      "step": 18588
    },
    {
      "epoch": 0.294330003008376,
      "grad_norm": 0.01176511775702238,
      "learning_rate": 7.0566999699162405e-06,
      "loss": 0.0007,
      "step": 18589
    },
    {
      "epoch": 0.29434583656601804,
      "grad_norm": 0.6542894244194031,
      "learning_rate": 7.0565416343398205e-06,
      "loss": 0.0304,
      "step": 18590
    },
    {
      "epoch": 0.2943616701236601,
      "grad_norm": 0.18568125367164612,
      "learning_rate": 7.0563832987633995e-06,
      "loss": 0.013,
      "step": 18591
    },
    {
      "epoch": 0.29437750368130217,
      "grad_norm": 0.17998777329921722,
      "learning_rate": 7.0562249631869795e-06,
      "loss": 0.0547,
      "step": 18592
    },
    {
      "epoch": 0.29439333723894423,
      "grad_norm": 0.9162169098854065,
      "learning_rate": 7.0560666276105585e-06,
      "loss": 0.2748,
      "step": 18593
    },
    {
      "epoch": 0.2944091707965863,
      "grad_norm": 0.3933788537979126,
      "learning_rate": 7.0559082920341385e-06,
      "loss": 0.1798,
      "step": 18594
    },
    {
      "epoch": 0.29442500435422836,
      "grad_norm": 0.2931417226791382,
      "learning_rate": 7.055749956457717e-06,
      "loss": 0.0497,
      "step": 18595
    },
    {
      "epoch": 0.2944408379118704,
      "grad_norm": 0.4626254439353943,
      "learning_rate": 7.055591620881297e-06,
      "loss": 0.0551,
      "step": 18596
    },
    {
      "epoch": 0.2944566714695125,
      "grad_norm": 0.39914223551750183,
      "learning_rate": 7.055433285304876e-06,
      "loss": 0.0836,
      "step": 18597
    },
    {
      "epoch": 0.29447250502715455,
      "grad_norm": 0.6464750170707703,
      "learning_rate": 7.055274949728456e-06,
      "loss": 0.1194,
      "step": 18598
    },
    {
      "epoch": 0.2944883385847966,
      "grad_norm": 0.00025637177168391645,
      "learning_rate": 7.055116614152035e-06,
      "loss": 0.0,
      "step": 18599
    },
    {
      "epoch": 0.2945041721424387,
      "grad_norm": 0.11746150255203247,
      "learning_rate": 7.054958278575613e-06,
      "loss": 0.0053,
      "step": 18600
    },
    {
      "epoch": 0.29452000570008074,
      "grad_norm": 0.03523891419172287,
      "learning_rate": 7.054799942999193e-06,
      "loss": 0.0022,
      "step": 18601
    },
    {
      "epoch": 0.2945358392577228,
      "grad_norm": 0.7855649590492249,
      "learning_rate": 7.054641607422772e-06,
      "loss": 0.6519,
      "step": 18602
    },
    {
      "epoch": 0.2945516728153649,
      "grad_norm": 0.6717853546142578,
      "learning_rate": 7.054483271846352e-06,
      "loss": 0.0267,
      "step": 18603
    },
    {
      "epoch": 0.29456750637300694,
      "grad_norm": 0.27140650153160095,
      "learning_rate": 7.054324936269931e-06,
      "loss": 0.0632,
      "step": 18604
    },
    {
      "epoch": 0.294583339930649,
      "grad_norm": 0.25759774446487427,
      "learning_rate": 7.054166600693511e-06,
      "loss": 0.0974,
      "step": 18605
    },
    {
      "epoch": 0.29459917348829107,
      "grad_norm": 0.7074337005615234,
      "learning_rate": 7.054008265117089e-06,
      "loss": 0.4925,
      "step": 18606
    },
    {
      "epoch": 0.29461500704593313,
      "grad_norm": 0.09525202959775925,
      "learning_rate": 7.053849929540669e-06,
      "loss": 0.0055,
      "step": 18607
    },
    {
      "epoch": 0.2946308406035752,
      "grad_norm": 0.5688021779060364,
      "learning_rate": 7.053691593964248e-06,
      "loss": 0.3765,
      "step": 18608
    },
    {
      "epoch": 0.29464667416121726,
      "grad_norm": 0.009570368565618992,
      "learning_rate": 7.053533258387828e-06,
      "loss": 0.0004,
      "step": 18609
    },
    {
      "epoch": 0.2946625077188593,
      "grad_norm": 0.9429755210876465,
      "learning_rate": 7.053374922811407e-06,
      "loss": 0.2047,
      "step": 18610
    },
    {
      "epoch": 0.29467834127650144,
      "grad_norm": 0.40144893527030945,
      "learning_rate": 7.053216587234987e-06,
      "loss": 0.1053,
      "step": 18611
    },
    {
      "epoch": 0.2946941748341435,
      "grad_norm": 0.3941800892353058,
      "learning_rate": 7.053058251658565e-06,
      "loss": 0.1682,
      "step": 18612
    },
    {
      "epoch": 0.29471000839178557,
      "grad_norm": 0.4625629782676697,
      "learning_rate": 7.052899916082145e-06,
      "loss": 0.2413,
      "step": 18613
    },
    {
      "epoch": 0.29472584194942764,
      "grad_norm": 0.7357259392738342,
      "learning_rate": 7.052741580505724e-06,
      "loss": 0.1155,
      "step": 18614
    },
    {
      "epoch": 0.2947416755070697,
      "grad_norm": 0.017897842451930046,
      "learning_rate": 7.052583244929304e-06,
      "loss": 0.0011,
      "step": 18615
    },
    {
      "epoch": 0.29475750906471176,
      "grad_norm": 0.23881976306438446,
      "learning_rate": 7.052424909352883e-06,
      "loss": 0.0734,
      "step": 18616
    },
    {
      "epoch": 0.29477334262235383,
      "grad_norm": 0.9981459379196167,
      "learning_rate": 7.052266573776463e-06,
      "loss": 0.4518,
      "step": 18617
    },
    {
      "epoch": 0.2947891761799959,
      "grad_norm": 0.0032649189233779907,
      "learning_rate": 7.0521082382000415e-06,
      "loss": 0.0001,
      "step": 18618
    },
    {
      "epoch": 0.29480500973763796,
      "grad_norm": 0.5081090331077576,
      "learning_rate": 7.051949902623621e-06,
      "loss": 0.245,
      "step": 18619
    },
    {
      "epoch": 0.29482084329528,
      "grad_norm": 0.7369967103004456,
      "learning_rate": 7.0517915670472005e-06,
      "loss": 0.8206,
      "step": 18620
    },
    {
      "epoch": 0.2948366768529221,
      "grad_norm": 0.1909652203321457,
      "learning_rate": 7.05163323147078e-06,
      "loss": 0.0044,
      "step": 18621
    },
    {
      "epoch": 0.29485251041056415,
      "grad_norm": 0.23649616539478302,
      "learning_rate": 7.0514748958943595e-06,
      "loss": 0.1187,
      "step": 18622
    },
    {
      "epoch": 0.2948683439682062,
      "grad_norm": 0.43748342990875244,
      "learning_rate": 7.051316560317938e-06,
      "loss": 0.2244,
      "step": 18623
    },
    {
      "epoch": 0.2948841775258483,
      "grad_norm": 6.861454312456772e-05,
      "learning_rate": 7.051158224741518e-06,
      "loss": 0.0,
      "step": 18624
    },
    {
      "epoch": 0.29490001108349034,
      "grad_norm": 0.4239228665828705,
      "learning_rate": 7.050999889165097e-06,
      "loss": 0.2734,
      "step": 18625
    },
    {
      "epoch": 0.2949158446411324,
      "grad_norm": 0.0002745208621490747,
      "learning_rate": 7.050841553588677e-06,
      "loss": 0.0,
      "step": 18626
    },
    {
      "epoch": 0.29493167819877447,
      "grad_norm": 0.6416297554969788,
      "learning_rate": 7.050683218012256e-06,
      "loss": 0.2798,
      "step": 18627
    },
    {
      "epoch": 0.29494751175641654,
      "grad_norm": 0.0001033930093399249,
      "learning_rate": 7.050524882435835e-06,
      "loss": 0.0,
      "step": 18628
    },
    {
      "epoch": 0.2949633453140586,
      "grad_norm": 0.7008726596832275,
      "learning_rate": 7.050366546859414e-06,
      "loss": 0.1015,
      "step": 18629
    },
    {
      "epoch": 0.29497917887170066,
      "grad_norm": 0.1555231660604477,
      "learning_rate": 7.050208211282994e-06,
      "loss": 0.0504,
      "step": 18630
    },
    {
      "epoch": 0.29499501242934273,
      "grad_norm": 0.0023820195347070694,
      "learning_rate": 7.050049875706573e-06,
      "loss": 0.0001,
      "step": 18631
    },
    {
      "epoch": 0.2950108459869848,
      "grad_norm": 0.31848853826522827,
      "learning_rate": 7.049891540130153e-06,
      "loss": 0.0738,
      "step": 18632
    },
    {
      "epoch": 0.29502667954462686,
      "grad_norm": 0.5551002621650696,
      "learning_rate": 7.049733204553731e-06,
      "loss": 0.4988,
      "step": 18633
    },
    {
      "epoch": 0.2950425131022689,
      "grad_norm": 0.7268469333648682,
      "learning_rate": 7.049574868977311e-06,
      "loss": 0.4696,
      "step": 18634
    },
    {
      "epoch": 0.29505834665991104,
      "grad_norm": 0.493179053068161,
      "learning_rate": 7.04941653340089e-06,
      "loss": 0.0832,
      "step": 18635
    },
    {
      "epoch": 0.2950741802175531,
      "grad_norm": 0.00016976319602690637,
      "learning_rate": 7.04925819782447e-06,
      "loss": 0.0,
      "step": 18636
    },
    {
      "epoch": 0.29509001377519517,
      "grad_norm": 0.018978962674736977,
      "learning_rate": 7.049099862248049e-06,
      "loss": 0.001,
      "step": 18637
    },
    {
      "epoch": 0.29510584733283723,
      "grad_norm": 0.013539126142859459,
      "learning_rate": 7.048941526671629e-06,
      "loss": 0.0007,
      "step": 18638
    },
    {
      "epoch": 0.2951216808904793,
      "grad_norm": 0.2685595750808716,
      "learning_rate": 7.048783191095207e-06,
      "loss": 0.0221,
      "step": 18639
    },
    {
      "epoch": 0.29513751444812136,
      "grad_norm": 0.7618343830108643,
      "learning_rate": 7.048624855518787e-06,
      "loss": 0.19,
      "step": 18640
    },
    {
      "epoch": 0.2951533480057634,
      "grad_norm": 0.579515814781189,
      "learning_rate": 7.048466519942366e-06,
      "loss": 0.211,
      "step": 18641
    },
    {
      "epoch": 0.2951691815634055,
      "grad_norm": 0.02673434093594551,
      "learning_rate": 7.048308184365946e-06,
      "loss": 0.0012,
      "step": 18642
    },
    {
      "epoch": 0.29518501512104756,
      "grad_norm": 0.0032062826212495565,
      "learning_rate": 7.048149848789525e-06,
      "loss": 0.0001,
      "step": 18643
    },
    {
      "epoch": 0.2952008486786896,
      "grad_norm": 0.0004124057886656374,
      "learning_rate": 7.047991513213105e-06,
      "loss": 0.0,
      "step": 18644
    },
    {
      "epoch": 0.2952166822363317,
      "grad_norm": 0.4398757517337799,
      "learning_rate": 7.047833177636683e-06,
      "loss": 0.2253,
      "step": 18645
    },
    {
      "epoch": 0.29523251579397375,
      "grad_norm": 0.4814474582672119,
      "learning_rate": 7.047674842060263e-06,
      "loss": 0.2355,
      "step": 18646
    },
    {
      "epoch": 0.2952483493516158,
      "grad_norm": 0.4663514494895935,
      "learning_rate": 7.047516506483842e-06,
      "loss": 0.1663,
      "step": 18647
    },
    {
      "epoch": 0.2952641829092579,
      "grad_norm": 0.4484465420246124,
      "learning_rate": 7.0473581709074215e-06,
      "loss": 0.1613,
      "step": 18648
    },
    {
      "epoch": 0.29528001646689994,
      "grad_norm": 0.009334574453532696,
      "learning_rate": 7.047199835331001e-06,
      "loss": 0.0004,
      "step": 18649
    },
    {
      "epoch": 0.295295850024542,
      "grad_norm": 0.48878028988838196,
      "learning_rate": 7.04704149975458e-06,
      "loss": 0.077,
      "step": 18650
    },
    {
      "epoch": 0.29531168358218407,
      "grad_norm": 0.5164845585823059,
      "learning_rate": 7.0468831641781596e-06,
      "loss": 0.3391,
      "step": 18651
    },
    {
      "epoch": 0.29532751713982613,
      "grad_norm": 0.42564427852630615,
      "learning_rate": 7.046724828601739e-06,
      "loss": 0.0185,
      "step": 18652
    },
    {
      "epoch": 0.2953433506974682,
      "grad_norm": 0.041374433785676956,
      "learning_rate": 7.0465664930253186e-06,
      "loss": 0.0019,
      "step": 18653
    },
    {
      "epoch": 0.29535918425511026,
      "grad_norm": 0.013365432620048523,
      "learning_rate": 7.046408157448898e-06,
      "loss": 0.0007,
      "step": 18654
    },
    {
      "epoch": 0.2953750178127523,
      "grad_norm": 0.2946682870388031,
      "learning_rate": 7.0462498218724776e-06,
      "loss": 0.1394,
      "step": 18655
    },
    {
      "epoch": 0.2953908513703944,
      "grad_norm": 0.21014851331710815,
      "learning_rate": 7.046091486296056e-06,
      "loss": 0.0437,
      "step": 18656
    },
    {
      "epoch": 0.29540668492803646,
      "grad_norm": 0.49518004059791565,
      "learning_rate": 7.045933150719636e-06,
      "loss": 0.1084,
      "step": 18657
    },
    {
      "epoch": 0.2954225184856785,
      "grad_norm": 0.817782998085022,
      "learning_rate": 7.045774815143215e-06,
      "loss": 0.613,
      "step": 18658
    },
    {
      "epoch": 0.29543835204332064,
      "grad_norm": 0.015467657707631588,
      "learning_rate": 7.045616479566795e-06,
      "loss": 0.0007,
      "step": 18659
    },
    {
      "epoch": 0.2954541856009627,
      "grad_norm": 0.21496522426605225,
      "learning_rate": 7.045458143990374e-06,
      "loss": 0.054,
      "step": 18660
    },
    {
      "epoch": 0.29547001915860477,
      "grad_norm": 0.014718870632350445,
      "learning_rate": 7.045299808413954e-06,
      "loss": 0.0007,
      "step": 18661
    },
    {
      "epoch": 0.29548585271624683,
      "grad_norm": 0.43219926953315735,
      "learning_rate": 7.045141472837532e-06,
      "loss": 0.2407,
      "step": 18662
    },
    {
      "epoch": 0.2955016862738889,
      "grad_norm": 0.3362083435058594,
      "learning_rate": 7.044983137261112e-06,
      "loss": 0.0468,
      "step": 18663
    },
    {
      "epoch": 0.29551751983153096,
      "grad_norm": 0.35925930738449097,
      "learning_rate": 7.044824801684691e-06,
      "loss": 0.0644,
      "step": 18664
    },
    {
      "epoch": 0.295533353389173,
      "grad_norm": 0.00022760129650123417,
      "learning_rate": 7.044666466108271e-06,
      "loss": 0.0,
      "step": 18665
    },
    {
      "epoch": 0.2955491869468151,
      "grad_norm": 0.262876957654953,
      "learning_rate": 7.04450813053185e-06,
      "loss": 0.0604,
      "step": 18666
    },
    {
      "epoch": 0.29556502050445715,
      "grad_norm": 0.22313515841960907,
      "learning_rate": 7.04434979495543e-06,
      "loss": 0.0525,
      "step": 18667
    },
    {
      "epoch": 0.2955808540620992,
      "grad_norm": 0.023272069171071053,
      "learning_rate": 7.044191459379008e-06,
      "loss": 0.0011,
      "step": 18668
    },
    {
      "epoch": 0.2955966876197413,
      "grad_norm": 0.3878026306629181,
      "learning_rate": 7.044033123802588e-06,
      "loss": 0.0468,
      "step": 18669
    },
    {
      "epoch": 0.29561252117738335,
      "grad_norm": 0.4140717089176178,
      "learning_rate": 7.043874788226167e-06,
      "loss": 0.3028,
      "step": 18670
    },
    {
      "epoch": 0.2956283547350254,
      "grad_norm": 0.5239830613136292,
      "learning_rate": 7.043716452649746e-06,
      "loss": 0.221,
      "step": 18671
    },
    {
      "epoch": 0.2956441882926675,
      "grad_norm": 0.04088154062628746,
      "learning_rate": 7.043558117073326e-06,
      "loss": 0.0009,
      "step": 18672
    },
    {
      "epoch": 0.29566002185030954,
      "grad_norm": 0.8992669582366943,
      "learning_rate": 7.043399781496904e-06,
      "loss": 0.2392,
      "step": 18673
    },
    {
      "epoch": 0.2956758554079516,
      "grad_norm": 0.2883807122707367,
      "learning_rate": 7.043241445920484e-06,
      "loss": 0.0363,
      "step": 18674
    },
    {
      "epoch": 0.29569168896559367,
      "grad_norm": 0.0011827698908746243,
      "learning_rate": 7.043083110344063e-06,
      "loss": 0.0,
      "step": 18675
    },
    {
      "epoch": 0.29570752252323573,
      "grad_norm": 0.687519907951355,
      "learning_rate": 7.042924774767643e-06,
      "loss": 0.1891,
      "step": 18676
    },
    {
      "epoch": 0.2957233560808778,
      "grad_norm": 0.45481979846954346,
      "learning_rate": 7.042766439191222e-06,
      "loss": 0.2337,
      "step": 18677
    },
    {
      "epoch": 0.29573918963851986,
      "grad_norm": 0.5311316251754761,
      "learning_rate": 7.042608103614802e-06,
      "loss": 0.1546,
      "step": 18678
    },
    {
      "epoch": 0.2957550231961619,
      "grad_norm": 0.41249385476112366,
      "learning_rate": 7.0424497680383806e-06,
      "loss": 0.162,
      "step": 18679
    },
    {
      "epoch": 0.295770856753804,
      "grad_norm": 0.4847339391708374,
      "learning_rate": 7.0422914324619605e-06,
      "loss": 0.0736,
      "step": 18680
    },
    {
      "epoch": 0.29578669031144605,
      "grad_norm": 0.9037359356880188,
      "learning_rate": 7.0421330968855396e-06,
      "loss": 0.1351,
      "step": 18681
    },
    {
      "epoch": 0.2958025238690881,
      "grad_norm": 0.019408952444791794,
      "learning_rate": 7.0419747613091195e-06,
      "loss": 0.0008,
      "step": 18682
    },
    {
      "epoch": 0.29581835742673024,
      "grad_norm": 1.2352439165115356,
      "learning_rate": 7.041816425732699e-06,
      "loss": 0.5408,
      "step": 18683
    },
    {
      "epoch": 0.2958341909843723,
      "grad_norm": 0.7394517064094543,
      "learning_rate": 7.0416580901562785e-06,
      "loss": 0.6054,
      "step": 18684
    },
    {
      "epoch": 0.29585002454201437,
      "grad_norm": 1.0947587490081787,
      "learning_rate": 7.041499754579857e-06,
      "loss": 0.4833,
      "step": 18685
    },
    {
      "epoch": 0.29586585809965643,
      "grad_norm": 0.016198281198740005,
      "learning_rate": 7.041341419003437e-06,
      "loss": 0.0005,
      "step": 18686
    },
    {
      "epoch": 0.2958816916572985,
      "grad_norm": 0.0001907725672936067,
      "learning_rate": 7.041183083427016e-06,
      "loss": 0.0,
      "step": 18687
    },
    {
      "epoch": 0.29589752521494056,
      "grad_norm": 0.5670175552368164,
      "learning_rate": 7.041024747850596e-06,
      "loss": 0.2563,
      "step": 18688
    },
    {
      "epoch": 0.2959133587725826,
      "grad_norm": 0.3792700469493866,
      "learning_rate": 7.040866412274175e-06,
      "loss": 0.0635,
      "step": 18689
    },
    {
      "epoch": 0.2959291923302247,
      "grad_norm": 0.21852479875087738,
      "learning_rate": 7.040708076697754e-06,
      "loss": 0.0448,
      "step": 18690
    },
    {
      "epoch": 0.29594502588786675,
      "grad_norm": 0.8926311731338501,
      "learning_rate": 7.040549741121333e-06,
      "loss": 0.5478,
      "step": 18691
    },
    {
      "epoch": 0.2959608594455088,
      "grad_norm": 0.15910117328166962,
      "learning_rate": 7.040391405544913e-06,
      "loss": 0.005,
      "step": 18692
    },
    {
      "epoch": 0.2959766930031509,
      "grad_norm": 0.5594216585159302,
      "learning_rate": 7.040233069968492e-06,
      "loss": 0.0919,
      "step": 18693
    },
    {
      "epoch": 0.29599252656079295,
      "grad_norm": 0.24428999423980713,
      "learning_rate": 7.040074734392072e-06,
      "loss": 0.0082,
      "step": 18694
    },
    {
      "epoch": 0.296008360118435,
      "grad_norm": 0.0009310931200161576,
      "learning_rate": 7.03991639881565e-06,
      "loss": 0.0,
      "step": 18695
    },
    {
      "epoch": 0.2960241936760771,
      "grad_norm": 0.919457733631134,
      "learning_rate": 7.039758063239229e-06,
      "loss": 0.2018,
      "step": 18696
    },
    {
      "epoch": 0.29604002723371914,
      "grad_norm": 0.6272892951965332,
      "learning_rate": 7.039599727662809e-06,
      "loss": 0.2728,
      "step": 18697
    },
    {
      "epoch": 0.2960558607913612,
      "grad_norm": 0.2888926565647125,
      "learning_rate": 7.039441392086388e-06,
      "loss": 0.0119,
      "step": 18698
    },
    {
      "epoch": 0.29607169434900327,
      "grad_norm": 1.785740613937378,
      "learning_rate": 7.039283056509968e-06,
      "loss": 0.1641,
      "step": 18699
    },
    {
      "epoch": 0.29608752790664533,
      "grad_norm": 0.025410789996385574,
      "learning_rate": 7.039124720933546e-06,
      "loss": 0.0014,
      "step": 18700
    },
    {
      "epoch": 0.2961033614642874,
      "grad_norm": 0.1465204507112503,
      "learning_rate": 7.038966385357126e-06,
      "loss": 0.0265,
      "step": 18701
    },
    {
      "epoch": 0.29611919502192946,
      "grad_norm": 0.192532479763031,
      "learning_rate": 7.038808049780705e-06,
      "loss": 0.0384,
      "step": 18702
    },
    {
      "epoch": 0.2961350285795715,
      "grad_norm": 0.0266860481351614,
      "learning_rate": 7.038649714204285e-06,
      "loss": 0.0017,
      "step": 18703
    },
    {
      "epoch": 0.2961508621372136,
      "grad_norm": 0.5353468060493469,
      "learning_rate": 7.038491378627864e-06,
      "loss": 0.0221,
      "step": 18704
    },
    {
      "epoch": 0.29616669569485565,
      "grad_norm": 1.2543615102767944,
      "learning_rate": 7.038333043051444e-06,
      "loss": 0.4545,
      "step": 18705
    },
    {
      "epoch": 0.2961825292524977,
      "grad_norm": 0.4427947402000427,
      "learning_rate": 7.0381747074750225e-06,
      "loss": 0.0861,
      "step": 18706
    },
    {
      "epoch": 0.29619836281013984,
      "grad_norm": 0.0159973856061697,
      "learning_rate": 7.038016371898602e-06,
      "loss": 0.0008,
      "step": 18707
    },
    {
      "epoch": 0.2962141963677819,
      "grad_norm": 1.1904668807983398,
      "learning_rate": 7.0378580363221815e-06,
      "loss": 0.517,
      "step": 18708
    },
    {
      "epoch": 0.29623002992542397,
      "grad_norm": 0.4525846242904663,
      "learning_rate": 7.037699700745761e-06,
      "loss": 0.0472,
      "step": 18709
    },
    {
      "epoch": 0.29624586348306603,
      "grad_norm": 0.0008561171125620604,
      "learning_rate": 7.0375413651693405e-06,
      "loss": 0.0,
      "step": 18710
    },
    {
      "epoch": 0.2962616970407081,
      "grad_norm": 0.00023753076675347984,
      "learning_rate": 7.0373830295929204e-06,
      "loss": 0.0,
      "step": 18711
    },
    {
      "epoch": 0.29627753059835016,
      "grad_norm": 0.0005324272206053138,
      "learning_rate": 7.037224694016499e-06,
      "loss": 0.0,
      "step": 18712
    },
    {
      "epoch": 0.2962933641559922,
      "grad_norm": 0.643376886844635,
      "learning_rate": 7.037066358440079e-06,
      "loss": 0.0215,
      "step": 18713
    },
    {
      "epoch": 0.2963091977136343,
      "grad_norm": 0.36646631360054016,
      "learning_rate": 7.036908022863658e-06,
      "loss": 0.1031,
      "step": 18714
    },
    {
      "epoch": 0.29632503127127635,
      "grad_norm": 0.013116979971528053,
      "learning_rate": 7.036749687287238e-06,
      "loss": 0.0001,
      "step": 18715
    },
    {
      "epoch": 0.2963408648289184,
      "grad_norm": 0.0011922979028895497,
      "learning_rate": 7.036591351710817e-06,
      "loss": 0.0,
      "step": 18716
    },
    {
      "epoch": 0.2963566983865605,
      "grad_norm": 0.37861084938049316,
      "learning_rate": 7.036433016134397e-06,
      "loss": 0.0682,
      "step": 18717
    },
    {
      "epoch": 0.29637253194420254,
      "grad_norm": 0.6790931820869446,
      "learning_rate": 7.036274680557975e-06,
      "loss": 0.0967,
      "step": 18718
    },
    {
      "epoch": 0.2963883655018446,
      "grad_norm": 0.0029568553436547518,
      "learning_rate": 7.036116344981554e-06,
      "loss": 0.0001,
      "step": 18719
    },
    {
      "epoch": 0.2964041990594867,
      "grad_norm": 0.5634254217147827,
      "learning_rate": 7.035958009405134e-06,
      "loss": 0.1114,
      "step": 18720
    },
    {
      "epoch": 0.29642003261712874,
      "grad_norm": 0.4684470593929291,
      "learning_rate": 7.035799673828713e-06,
      "loss": 0.0833,
      "step": 18721
    },
    {
      "epoch": 0.2964358661747708,
      "grad_norm": 0.00015368183085229248,
      "learning_rate": 7.035641338252293e-06,
      "loss": 0.0,
      "step": 18722
    },
    {
      "epoch": 0.29645169973241287,
      "grad_norm": 0.023173751309514046,
      "learning_rate": 7.035483002675871e-06,
      "loss": 0.001,
      "step": 18723
    },
    {
      "epoch": 0.29646753329005493,
      "grad_norm": 0.3750166594982147,
      "learning_rate": 7.035324667099451e-06,
      "loss": 0.0884,
      "step": 18724
    },
    {
      "epoch": 0.296483366847697,
      "grad_norm": 0.2381146401166916,
      "learning_rate": 7.03516633152303e-06,
      "loss": 0.0437,
      "step": 18725
    },
    {
      "epoch": 0.29649920040533906,
      "grad_norm": 0.8542711734771729,
      "learning_rate": 7.03500799594661e-06,
      "loss": 0.1108,
      "step": 18726
    },
    {
      "epoch": 0.2965150339629811,
      "grad_norm": 0.16514252126216888,
      "learning_rate": 7.034849660370189e-06,
      "loss": 0.0464,
      "step": 18727
    },
    {
      "epoch": 0.2965308675206232,
      "grad_norm": 1.1271873712539673,
      "learning_rate": 7.034691324793769e-06,
      "loss": 0.2546,
      "step": 18728
    },
    {
      "epoch": 0.29654670107826525,
      "grad_norm": 0.025440741330385208,
      "learning_rate": 7.034532989217347e-06,
      "loss": 0.0015,
      "step": 18729
    },
    {
      "epoch": 0.2965625346359073,
      "grad_norm": 0.16561242938041687,
      "learning_rate": 7.034374653640927e-06,
      "loss": 0.0222,
      "step": 18730
    },
    {
      "epoch": 0.29657836819354944,
      "grad_norm": 0.46038544178009033,
      "learning_rate": 7.034216318064506e-06,
      "loss": 0.0988,
      "step": 18731
    },
    {
      "epoch": 0.2965942017511915,
      "grad_norm": 0.31378668546676636,
      "learning_rate": 7.034057982488086e-06,
      "loss": 0.1208,
      "step": 18732
    },
    {
      "epoch": 0.29661003530883356,
      "grad_norm": 0.2593233287334442,
      "learning_rate": 7.033899646911665e-06,
      "loss": 0.0948,
      "step": 18733
    },
    {
      "epoch": 0.29662586886647563,
      "grad_norm": 0.01743597351014614,
      "learning_rate": 7.033741311335245e-06,
      "loss": 0.0009,
      "step": 18734
    },
    {
      "epoch": 0.2966417024241177,
      "grad_norm": 0.6013133525848389,
      "learning_rate": 7.033582975758823e-06,
      "loss": 0.128,
      "step": 18735
    },
    {
      "epoch": 0.29665753598175976,
      "grad_norm": 0.17314232885837555,
      "learning_rate": 7.033424640182403e-06,
      "loss": 0.0508,
      "step": 18736
    },
    {
      "epoch": 0.2966733695394018,
      "grad_norm": 0.26696062088012695,
      "learning_rate": 7.0332663046059824e-06,
      "loss": 0.0338,
      "step": 18737
    },
    {
      "epoch": 0.2966892030970439,
      "grad_norm": 0.03940301761031151,
      "learning_rate": 7.033107969029562e-06,
      "loss": 0.0005,
      "step": 18738
    },
    {
      "epoch": 0.29670503665468595,
      "grad_norm": 1.0257515907287598,
      "learning_rate": 7.0329496334531414e-06,
      "loss": 0.2929,
      "step": 18739
    },
    {
      "epoch": 0.296720870212328,
      "grad_norm": 0.7972080707550049,
      "learning_rate": 7.032791297876721e-06,
      "loss": 0.1697,
      "step": 18740
    },
    {
      "epoch": 0.2967367037699701,
      "grad_norm": 0.3144674003124237,
      "learning_rate": 7.0326329623003e-06,
      "loss": 0.039,
      "step": 18741
    },
    {
      "epoch": 0.29675253732761214,
      "grad_norm": 0.22761666774749756,
      "learning_rate": 7.0324746267238795e-06,
      "loss": 0.0486,
      "step": 18742
    },
    {
      "epoch": 0.2967683708852542,
      "grad_norm": 0.0076622553169727325,
      "learning_rate": 7.032316291147459e-06,
      "loss": 0.0003,
      "step": 18743
    },
    {
      "epoch": 0.29678420444289627,
      "grad_norm": 0.516444981098175,
      "learning_rate": 7.032157955571038e-06,
      "loss": 0.1326,
      "step": 18744
    },
    {
      "epoch": 0.29680003800053834,
      "grad_norm": 0.6366209983825684,
      "learning_rate": 7.031999619994618e-06,
      "loss": 0.0331,
      "step": 18745
    },
    {
      "epoch": 0.2968158715581804,
      "grad_norm": 0.19665604829788208,
      "learning_rate": 7.031841284418196e-06,
      "loss": 0.081,
      "step": 18746
    },
    {
      "epoch": 0.29683170511582246,
      "grad_norm": 0.1939467191696167,
      "learning_rate": 7.031682948841776e-06,
      "loss": 0.0536,
      "step": 18747
    },
    {
      "epoch": 0.29684753867346453,
      "grad_norm": 0.0017221183516085148,
      "learning_rate": 7.031524613265355e-06,
      "loss": 0.0,
      "step": 18748
    },
    {
      "epoch": 0.2968633722311066,
      "grad_norm": 0.8773123025894165,
      "learning_rate": 7.031366277688935e-06,
      "loss": 0.1767,
      "step": 18749
    },
    {
      "epoch": 0.29687920578874866,
      "grad_norm": 0.381098210811615,
      "learning_rate": 7.031207942112514e-06,
      "loss": 0.046,
      "step": 18750
    },
    {
      "epoch": 0.2968950393463907,
      "grad_norm": 0.8666965961456299,
      "learning_rate": 7.031049606536094e-06,
      "loss": 0.3017,
      "step": 18751
    },
    {
      "epoch": 0.2969108729040328,
      "grad_norm": 0.14416000247001648,
      "learning_rate": 7.030891270959672e-06,
      "loss": 0.0299,
      "step": 18752
    },
    {
      "epoch": 0.29692670646167485,
      "grad_norm": 0.38944894075393677,
      "learning_rate": 7.030732935383252e-06,
      "loss": 0.0496,
      "step": 18753
    },
    {
      "epoch": 0.2969425400193169,
      "grad_norm": 0.8908247947692871,
      "learning_rate": 7.030574599806831e-06,
      "loss": 0.0526,
      "step": 18754
    },
    {
      "epoch": 0.29695837357695903,
      "grad_norm": 0.04150081053376198,
      "learning_rate": 7.030416264230411e-06,
      "loss": 0.0011,
      "step": 18755
    },
    {
      "epoch": 0.2969742071346011,
      "grad_norm": 0.037988074123859406,
      "learning_rate": 7.030257928653989e-06,
      "loss": 0.0018,
      "step": 18756
    },
    {
      "epoch": 0.29699004069224316,
      "grad_norm": 1.4345358610153198,
      "learning_rate": 7.030099593077569e-06,
      "loss": 0.0681,
      "step": 18757
    },
    {
      "epoch": 0.2970058742498852,
      "grad_norm": 0.009749229066073895,
      "learning_rate": 7.029941257501148e-06,
      "loss": 0.0004,
      "step": 18758
    },
    {
      "epoch": 0.2970217078075273,
      "grad_norm": 0.312611848115921,
      "learning_rate": 7.029782921924728e-06,
      "loss": 0.1625,
      "step": 18759
    },
    {
      "epoch": 0.29703754136516936,
      "grad_norm": 0.6206226944923401,
      "learning_rate": 7.029624586348307e-06,
      "loss": 0.2701,
      "step": 18760
    },
    {
      "epoch": 0.2970533749228114,
      "grad_norm": 0.33833980560302734,
      "learning_rate": 7.029466250771887e-06,
      "loss": 0.2071,
      "step": 18761
    },
    {
      "epoch": 0.2970692084804535,
      "grad_norm": 2.8879213333129883,
      "learning_rate": 7.029307915195465e-06,
      "loss": 0.0483,
      "step": 18762
    },
    {
      "epoch": 0.29708504203809555,
      "grad_norm": 0.511942446231842,
      "learning_rate": 7.029149579619045e-06,
      "loss": 0.2657,
      "step": 18763
    },
    {
      "epoch": 0.2971008755957376,
      "grad_norm": 0.34119755029678345,
      "learning_rate": 7.028991244042624e-06,
      "loss": 0.1364,
      "step": 18764
    },
    {
      "epoch": 0.2971167091533797,
      "grad_norm": 0.5793789625167847,
      "learning_rate": 7.028832908466204e-06,
      "loss": 0.1449,
      "step": 18765
    },
    {
      "epoch": 0.29713254271102174,
      "grad_norm": 0.35080379247665405,
      "learning_rate": 7.028674572889783e-06,
      "loss": 0.1736,
      "step": 18766
    },
    {
      "epoch": 0.2971483762686638,
      "grad_norm": 0.3154654800891876,
      "learning_rate": 7.028516237313362e-06,
      "loss": 0.0798,
      "step": 18767
    },
    {
      "epoch": 0.29716420982630587,
      "grad_norm": 0.29729804396629333,
      "learning_rate": 7.0283579017369415e-06,
      "loss": 0.0751,
      "step": 18768
    },
    {
      "epoch": 0.29718004338394793,
      "grad_norm": 0.9536129236221313,
      "learning_rate": 7.028199566160521e-06,
      "loss": 0.379,
      "step": 18769
    },
    {
      "epoch": 0.29719587694159,
      "grad_norm": 0.10118012130260468,
      "learning_rate": 7.0280412305841005e-06,
      "loss": 0.0018,
      "step": 18770
    },
    {
      "epoch": 0.29721171049923206,
      "grad_norm": 0.4966231882572174,
      "learning_rate": 7.02788289500768e-06,
      "loss": 0.4072,
      "step": 18771
    },
    {
      "epoch": 0.2972275440568741,
      "grad_norm": 0.24482029676437378,
      "learning_rate": 7.0277245594312595e-06,
      "loss": 0.1187,
      "step": 18772
    },
    {
      "epoch": 0.2972433776145162,
      "grad_norm": 0.38144758343696594,
      "learning_rate": 7.027566223854838e-06,
      "loss": 0.204,
      "step": 18773
    },
    {
      "epoch": 0.29725921117215826,
      "grad_norm": 0.2991113066673279,
      "learning_rate": 7.027407888278418e-06,
      "loss": 0.0624,
      "step": 18774
    },
    {
      "epoch": 0.2972750447298003,
      "grad_norm": 0.25549212098121643,
      "learning_rate": 7.027249552701997e-06,
      "loss": 0.0483,
      "step": 18775
    },
    {
      "epoch": 0.2972908782874424,
      "grad_norm": 0.022103769704699516,
      "learning_rate": 7.027091217125577e-06,
      "loss": 0.0012,
      "step": 18776
    },
    {
      "epoch": 0.29730671184508445,
      "grad_norm": 7.913619629107416e-05,
      "learning_rate": 7.026932881549156e-06,
      "loss": 0.0,
      "step": 18777
    },
    {
      "epoch": 0.2973225454027265,
      "grad_norm": 0.6154026985168457,
      "learning_rate": 7.026774545972736e-06,
      "loss": 0.2606,
      "step": 18778
    },
    {
      "epoch": 0.29733837896036863,
      "grad_norm": 0.8874503970146179,
      "learning_rate": 7.026616210396314e-06,
      "loss": 0.1301,
      "step": 18779
    },
    {
      "epoch": 0.2973542125180107,
      "grad_norm": 0.49119797348976135,
      "learning_rate": 7.026457874819894e-06,
      "loss": 0.2245,
      "step": 18780
    },
    {
      "epoch": 0.29737004607565276,
      "grad_norm": 0.30982521176338196,
      "learning_rate": 7.026299539243473e-06,
      "loss": 0.0056,
      "step": 18781
    },
    {
      "epoch": 0.2973858796332948,
      "grad_norm": 5.610299110412598,
      "learning_rate": 7.026141203667053e-06,
      "loss": 0.9855,
      "step": 18782
    },
    {
      "epoch": 0.2974017131909369,
      "grad_norm": 0.7849866151809692,
      "learning_rate": 7.025982868090632e-06,
      "loss": 0.2251,
      "step": 18783
    },
    {
      "epoch": 0.29741754674857895,
      "grad_norm": 0.7423682808876038,
      "learning_rate": 7.025824532514212e-06,
      "loss": 0.4672,
      "step": 18784
    },
    {
      "epoch": 0.297433380306221,
      "grad_norm": 0.38930439949035645,
      "learning_rate": 7.02566619693779e-06,
      "loss": 0.1179,
      "step": 18785
    },
    {
      "epoch": 0.2974492138638631,
      "grad_norm": 0.7186036705970764,
      "learning_rate": 7.02550786136137e-06,
      "loss": 0.2279,
      "step": 18786
    },
    {
      "epoch": 0.29746504742150515,
      "grad_norm": 0.00037420130684040487,
      "learning_rate": 7.025349525784949e-06,
      "loss": 0.0,
      "step": 18787
    },
    {
      "epoch": 0.2974808809791472,
      "grad_norm": 0.18621589243412018,
      "learning_rate": 7.025191190208529e-06,
      "loss": 0.0308,
      "step": 18788
    },
    {
      "epoch": 0.2974967145367893,
      "grad_norm": 0.7498430013656616,
      "learning_rate": 7.025032854632108e-06,
      "loss": 0.2631,
      "step": 18789
    },
    {
      "epoch": 0.29751254809443134,
      "grad_norm": 0.23694336414337158,
      "learning_rate": 7.024874519055688e-06,
      "loss": 0.0761,
      "step": 18790
    },
    {
      "epoch": 0.2975283816520734,
      "grad_norm": 0.30484291911125183,
      "learning_rate": 7.024716183479266e-06,
      "loss": 0.0528,
      "step": 18791
    },
    {
      "epoch": 0.29754421520971547,
      "grad_norm": 0.016734717413783073,
      "learning_rate": 7.024557847902845e-06,
      "loss": 0.0008,
      "step": 18792
    },
    {
      "epoch": 0.29756004876735753,
      "grad_norm": 0.3403646647930145,
      "learning_rate": 7.024399512326425e-06,
      "loss": 0.0618,
      "step": 18793
    },
    {
      "epoch": 0.2975758823249996,
      "grad_norm": 0.3607138991355896,
      "learning_rate": 7.024241176750004e-06,
      "loss": 0.0636,
      "step": 18794
    },
    {
      "epoch": 0.29759171588264166,
      "grad_norm": 0.757136344909668,
      "learning_rate": 7.024082841173584e-06,
      "loss": 0.5195,
      "step": 18795
    },
    {
      "epoch": 0.2976075494402837,
      "grad_norm": 0.6474865674972534,
      "learning_rate": 7.0239245055971625e-06,
      "loss": 0.4883,
      "step": 18796
    },
    {
      "epoch": 0.2976233829979258,
      "grad_norm": 0.021751679480075836,
      "learning_rate": 7.0237661700207424e-06,
      "loss": 0.0011,
      "step": 18797
    },
    {
      "epoch": 0.29763921655556785,
      "grad_norm": 0.670252799987793,
      "learning_rate": 7.0236078344443215e-06,
      "loss": 0.224,
      "step": 18798
    },
    {
      "epoch": 0.2976550501132099,
      "grad_norm": 0.0015359690878540277,
      "learning_rate": 7.0234494988679015e-06,
      "loss": 0.0,
      "step": 18799
    },
    {
      "epoch": 0.297670883670852,
      "grad_norm": 1.0383397340774536,
      "learning_rate": 7.0232911632914805e-06,
      "loss": 0.6455,
      "step": 18800
    },
    {
      "epoch": 0.29768671722849405,
      "grad_norm": 0.467629998922348,
      "learning_rate": 7.0231328277150605e-06,
      "loss": 0.129,
      "step": 18801
    },
    {
      "epoch": 0.2977025507861361,
      "grad_norm": 0.4708296060562134,
      "learning_rate": 7.022974492138639e-06,
      "loss": 0.0984,
      "step": 18802
    },
    {
      "epoch": 0.29771838434377823,
      "grad_norm": 0.0019369010115042329,
      "learning_rate": 7.022816156562219e-06,
      "loss": 0.0,
      "step": 18803
    },
    {
      "epoch": 0.2977342179014203,
      "grad_norm": 0.5770651698112488,
      "learning_rate": 7.022657820985798e-06,
      "loss": 0.0398,
      "step": 18804
    },
    {
      "epoch": 0.29775005145906236,
      "grad_norm": 0.07730644941329956,
      "learning_rate": 7.022499485409378e-06,
      "loss": 0.0036,
      "step": 18805
    },
    {
      "epoch": 0.2977658850167044,
      "grad_norm": 0.5570942163467407,
      "learning_rate": 7.022341149832957e-06,
      "loss": 0.0586,
      "step": 18806
    },
    {
      "epoch": 0.2977817185743465,
      "grad_norm": 0.22095230221748352,
      "learning_rate": 7.022182814256537e-06,
      "loss": 0.0438,
      "step": 18807
    },
    {
      "epoch": 0.29779755213198855,
      "grad_norm": 0.0388367734849453,
      "learning_rate": 7.022024478680115e-06,
      "loss": 0.0021,
      "step": 18808
    },
    {
      "epoch": 0.2978133856896306,
      "grad_norm": 1.0114524364471436,
      "learning_rate": 7.021866143103695e-06,
      "loss": 1.421,
      "step": 18809
    },
    {
      "epoch": 0.2978292192472727,
      "grad_norm": 0.0572202131152153,
      "learning_rate": 7.021707807527274e-06,
      "loss": 0.0037,
      "step": 18810
    },
    {
      "epoch": 0.29784505280491474,
      "grad_norm": 0.2361518144607544,
      "learning_rate": 7.021549471950854e-06,
      "loss": 0.0711,
      "step": 18811
    },
    {
      "epoch": 0.2978608863625568,
      "grad_norm": 0.37707749009132385,
      "learning_rate": 7.021391136374433e-06,
      "loss": 0.0438,
      "step": 18812
    },
    {
      "epoch": 0.2978767199201989,
      "grad_norm": 0.799986720085144,
      "learning_rate": 7.021232800798013e-06,
      "loss": 0.5259,
      "step": 18813
    },
    {
      "epoch": 0.29789255347784094,
      "grad_norm": 0.009810857474803925,
      "learning_rate": 7.021074465221591e-06,
      "loss": 0.0004,
      "step": 18814
    },
    {
      "epoch": 0.297908387035483,
      "grad_norm": 0.00841799471527338,
      "learning_rate": 7.02091612964517e-06,
      "loss": 0.0004,
      "step": 18815
    },
    {
      "epoch": 0.29792422059312507,
      "grad_norm": 0.7874008417129517,
      "learning_rate": 7.02075779406875e-06,
      "loss": 0.2079,
      "step": 18816
    },
    {
      "epoch": 0.29794005415076713,
      "grad_norm": 0.48691466450691223,
      "learning_rate": 7.020599458492329e-06,
      "loss": 0.0641,
      "step": 18817
    },
    {
      "epoch": 0.2979558877084092,
      "grad_norm": 0.00031184294493868947,
      "learning_rate": 7.020441122915909e-06,
      "loss": 0.0,
      "step": 18818
    },
    {
      "epoch": 0.29797172126605126,
      "grad_norm": 0.439949095249176,
      "learning_rate": 7.020282787339487e-06,
      "loss": 0.1554,
      "step": 18819
    },
    {
      "epoch": 0.2979875548236933,
      "grad_norm": 0.6415836811065674,
      "learning_rate": 7.020124451763067e-06,
      "loss": 0.3166,
      "step": 18820
    },
    {
      "epoch": 0.2980033883813354,
      "grad_norm": 2.012868881225586,
      "learning_rate": 7.019966116186646e-06,
      "loss": 0.2716,
      "step": 18821
    },
    {
      "epoch": 0.29801922193897745,
      "grad_norm": 1.135909914970398,
      "learning_rate": 7.019807780610226e-06,
      "loss": 0.2945,
      "step": 18822
    },
    {
      "epoch": 0.2980350554966195,
      "grad_norm": 0.2808510661125183,
      "learning_rate": 7.0196494450338044e-06,
      "loss": 0.0683,
      "step": 18823
    },
    {
      "epoch": 0.2980508890542616,
      "grad_norm": 0.7545123100280762,
      "learning_rate": 7.019491109457384e-06,
      "loss": 0.6091,
      "step": 18824
    },
    {
      "epoch": 0.29806672261190365,
      "grad_norm": 0.39280179142951965,
      "learning_rate": 7.0193327738809634e-06,
      "loss": 0.1097,
      "step": 18825
    },
    {
      "epoch": 0.2980825561695457,
      "grad_norm": 0.01510562002658844,
      "learning_rate": 7.019174438304543e-06,
      "loss": 0.0005,
      "step": 18826
    },
    {
      "epoch": 0.29809838972718783,
      "grad_norm": 0.23570406436920166,
      "learning_rate": 7.0190161027281225e-06,
      "loss": 0.0307,
      "step": 18827
    },
    {
      "epoch": 0.2981142232848299,
      "grad_norm": 0.23057222366333008,
      "learning_rate": 7.018857767151702e-06,
      "loss": 0.0062,
      "step": 18828
    },
    {
      "epoch": 0.29813005684247196,
      "grad_norm": 0.9676827788352966,
      "learning_rate": 7.018699431575281e-06,
      "loss": 0.2367,
      "step": 18829
    },
    {
      "epoch": 0.298145890400114,
      "grad_norm": 0.3372834026813507,
      "learning_rate": 7.0185410959988605e-06,
      "loss": 0.1008,
      "step": 18830
    },
    {
      "epoch": 0.2981617239577561,
      "grad_norm": 0.2791406214237213,
      "learning_rate": 7.01838276042244e-06,
      "loss": 0.0802,
      "step": 18831
    },
    {
      "epoch": 0.29817755751539815,
      "grad_norm": 0.4228542447090149,
      "learning_rate": 7.0182244248460195e-06,
      "loss": 0.168,
      "step": 18832
    },
    {
      "epoch": 0.2981933910730402,
      "grad_norm": 0.4872299134731293,
      "learning_rate": 7.018066089269599e-06,
      "loss": 0.2111,
      "step": 18833
    },
    {
      "epoch": 0.2982092246306823,
      "grad_norm": 0.007994056679308414,
      "learning_rate": 7.0179077536931786e-06,
      "loss": 0.0001,
      "step": 18834
    },
    {
      "epoch": 0.29822505818832434,
      "grad_norm": 0.013553144410252571,
      "learning_rate": 7.017749418116757e-06,
      "loss": 0.0008,
      "step": 18835
    },
    {
      "epoch": 0.2982408917459664,
      "grad_norm": 0.32841071486473083,
      "learning_rate": 7.017591082540337e-06,
      "loss": 0.1042,
      "step": 18836
    },
    {
      "epoch": 0.29825672530360847,
      "grad_norm": 0.000428775732871145,
      "learning_rate": 7.017432746963916e-06,
      "loss": 0.0,
      "step": 18837
    },
    {
      "epoch": 0.29827255886125054,
      "grad_norm": 0.44087323546409607,
      "learning_rate": 7.017274411387496e-06,
      "loss": 0.0515,
      "step": 18838
    },
    {
      "epoch": 0.2982883924188926,
      "grad_norm": 0.5291190147399902,
      "learning_rate": 7.017116075811075e-06,
      "loss": 0.2445,
      "step": 18839
    },
    {
      "epoch": 0.29830422597653466,
      "grad_norm": 0.1665709912776947,
      "learning_rate": 7.016957740234653e-06,
      "loss": 0.0156,
      "step": 18840
    },
    {
      "epoch": 0.29832005953417673,
      "grad_norm": 0.5956368446350098,
      "learning_rate": 7.016799404658233e-06,
      "loss": 0.3158,
      "step": 18841
    },
    {
      "epoch": 0.2983358930918188,
      "grad_norm": 0.4288836717605591,
      "learning_rate": 7.016641069081812e-06,
      "loss": 0.3649,
      "step": 18842
    },
    {
      "epoch": 0.29835172664946086,
      "grad_norm": 0.026141254231333733,
      "learning_rate": 7.016482733505392e-06,
      "loss": 0.0012,
      "step": 18843
    },
    {
      "epoch": 0.2983675602071029,
      "grad_norm": 0.6504619717597961,
      "learning_rate": 7.016324397928971e-06,
      "loss": 0.3374,
      "step": 18844
    },
    {
      "epoch": 0.298383393764745,
      "grad_norm": 0.18232852220535278,
      "learning_rate": 7.016166062352551e-06,
      "loss": 0.0868,
      "step": 18845
    },
    {
      "epoch": 0.29839922732238705,
      "grad_norm": 0.32983171939849854,
      "learning_rate": 7.016007726776129e-06,
      "loss": 0.0907,
      "step": 18846
    },
    {
      "epoch": 0.2984150608800291,
      "grad_norm": 0.0003769551694858819,
      "learning_rate": 7.015849391199709e-06,
      "loss": 0.0,
      "step": 18847
    },
    {
      "epoch": 0.2984308944376712,
      "grad_norm": 0.8632598519325256,
      "learning_rate": 7.015691055623288e-06,
      "loss": 0.322,
      "step": 18848
    },
    {
      "epoch": 0.29844672799531324,
      "grad_norm": 0.6594915986061096,
      "learning_rate": 7.015532720046868e-06,
      "loss": 0.2997,
      "step": 18849
    },
    {
      "epoch": 0.2984625615529553,
      "grad_norm": 0.29056400060653687,
      "learning_rate": 7.015374384470447e-06,
      "loss": 0.0674,
      "step": 18850
    },
    {
      "epoch": 0.2984783951105974,
      "grad_norm": 0.0007188274175859988,
      "learning_rate": 7.015216048894027e-06,
      "loss": 0.0,
      "step": 18851
    },
    {
      "epoch": 0.2984942286682395,
      "grad_norm": 0.053349174559116364,
      "learning_rate": 7.015057713317605e-06,
      "loss": 0.0022,
      "step": 18852
    },
    {
      "epoch": 0.29851006222588156,
      "grad_norm": 0.08788909018039703,
      "learning_rate": 7.014899377741185e-06,
      "loss": 0.0015,
      "step": 18853
    },
    {
      "epoch": 0.2985258957835236,
      "grad_norm": 0.29338380694389343,
      "learning_rate": 7.014741042164764e-06,
      "loss": 0.1228,
      "step": 18854
    },
    {
      "epoch": 0.2985417293411657,
      "grad_norm": 0.38060835003852844,
      "learning_rate": 7.014582706588344e-06,
      "loss": 0.1061,
      "step": 18855
    },
    {
      "epoch": 0.29855756289880775,
      "grad_norm": 0.11643752455711365,
      "learning_rate": 7.014424371011923e-06,
      "loss": 0.0142,
      "step": 18856
    },
    {
      "epoch": 0.2985733964564498,
      "grad_norm": 0.40602537989616394,
      "learning_rate": 7.014266035435503e-06,
      "loss": 0.0792,
      "step": 18857
    },
    {
      "epoch": 0.2985892300140919,
      "grad_norm": 0.00037315263762138784,
      "learning_rate": 7.0141076998590815e-06,
      "loss": 0.0,
      "step": 18858
    },
    {
      "epoch": 0.29860506357173394,
      "grad_norm": 0.019409479573369026,
      "learning_rate": 7.0139493642826615e-06,
      "loss": 0.001,
      "step": 18859
    },
    {
      "epoch": 0.298620897129376,
      "grad_norm": 0.03279615938663483,
      "learning_rate": 7.0137910287062406e-06,
      "loss": 0.0025,
      "step": 18860
    },
    {
      "epoch": 0.29863673068701807,
      "grad_norm": 0.19754435122013092,
      "learning_rate": 7.0136326931298205e-06,
      "loss": 0.042,
      "step": 18861
    },
    {
      "epoch": 0.29865256424466013,
      "grad_norm": 0.6208432912826538,
      "learning_rate": 7.0134743575533996e-06,
      "loss": 0.6308,
      "step": 18862
    },
    {
      "epoch": 0.2986683978023022,
      "grad_norm": 0.2694718539714813,
      "learning_rate": 7.013316021976978e-06,
      "loss": 0.064,
      "step": 18863
    },
    {
      "epoch": 0.29868423135994426,
      "grad_norm": 0.7188985347747803,
      "learning_rate": 7.013157686400558e-06,
      "loss": 0.5924,
      "step": 18864
    },
    {
      "epoch": 0.2987000649175863,
      "grad_norm": 0.4102511703968048,
      "learning_rate": 7.012999350824137e-06,
      "loss": 0.1713,
      "step": 18865
    },
    {
      "epoch": 0.2987158984752284,
      "grad_norm": 0.6823621988296509,
      "learning_rate": 7.012841015247717e-06,
      "loss": 0.4992,
      "step": 18866
    },
    {
      "epoch": 0.29873173203287046,
      "grad_norm": 0.39127737283706665,
      "learning_rate": 7.012682679671296e-06,
      "loss": 0.1038,
      "step": 18867
    },
    {
      "epoch": 0.2987475655905125,
      "grad_norm": 0.4345979392528534,
      "learning_rate": 7.012524344094876e-06,
      "loss": 0.1658,
      "step": 18868
    },
    {
      "epoch": 0.2987633991481546,
      "grad_norm": 0.9337669014930725,
      "learning_rate": 7.012366008518454e-06,
      "loss": 0.2142,
      "step": 18869
    },
    {
      "epoch": 0.29877923270579665,
      "grad_norm": 0.33866867423057556,
      "learning_rate": 7.012207672942034e-06,
      "loss": 0.1352,
      "step": 18870
    },
    {
      "epoch": 0.2987950662634387,
      "grad_norm": 0.48821476101875305,
      "learning_rate": 7.012049337365613e-06,
      "loss": 0.0541,
      "step": 18871
    },
    {
      "epoch": 0.2988108998210808,
      "grad_norm": 0.6141648888587952,
      "learning_rate": 7.011891001789193e-06,
      "loss": 0.2904,
      "step": 18872
    },
    {
      "epoch": 0.29882673337872284,
      "grad_norm": 0.636284351348877,
      "learning_rate": 7.011732666212772e-06,
      "loss": 0.6893,
      "step": 18873
    },
    {
      "epoch": 0.2988425669363649,
      "grad_norm": 0.7448903918266296,
      "learning_rate": 7.011574330636352e-06,
      "loss": 0.0982,
      "step": 18874
    },
    {
      "epoch": 0.298858400494007,
      "grad_norm": 0.7511382102966309,
      "learning_rate": 7.01141599505993e-06,
      "loss": 0.1513,
      "step": 18875
    },
    {
      "epoch": 0.2988742340516491,
      "grad_norm": 0.6997852921485901,
      "learning_rate": 7.01125765948351e-06,
      "loss": 0.09,
      "step": 18876
    },
    {
      "epoch": 0.29889006760929115,
      "grad_norm": 0.43980690836906433,
      "learning_rate": 7.011099323907089e-06,
      "loss": 0.0668,
      "step": 18877
    },
    {
      "epoch": 0.2989059011669332,
      "grad_norm": 0.6979491710662842,
      "learning_rate": 7.010940988330669e-06,
      "loss": 0.0975,
      "step": 18878
    },
    {
      "epoch": 0.2989217347245753,
      "grad_norm": 0.00071629200829193,
      "learning_rate": 7.010782652754248e-06,
      "loss": 0.0,
      "step": 18879
    },
    {
      "epoch": 0.29893756828221735,
      "grad_norm": 0.19711318612098694,
      "learning_rate": 7.010624317177828e-06,
      "loss": 0.0803,
      "step": 18880
    },
    {
      "epoch": 0.2989534018398594,
      "grad_norm": 0.38488513231277466,
      "learning_rate": 7.010465981601406e-06,
      "loss": 0.0889,
      "step": 18881
    },
    {
      "epoch": 0.2989692353975015,
      "grad_norm": 0.5475218892097473,
      "learning_rate": 7.010307646024986e-06,
      "loss": 0.1531,
      "step": 18882
    },
    {
      "epoch": 0.29898506895514354,
      "grad_norm": 0.33001306653022766,
      "learning_rate": 7.010149310448565e-06,
      "loss": 0.0688,
      "step": 18883
    },
    {
      "epoch": 0.2990009025127856,
      "grad_norm": 0.3799631595611572,
      "learning_rate": 7.009990974872145e-06,
      "loss": 0.0645,
      "step": 18884
    },
    {
      "epoch": 0.29901673607042767,
      "grad_norm": 1.1134190559387207,
      "learning_rate": 7.0098326392957235e-06,
      "loss": 0.092,
      "step": 18885
    },
    {
      "epoch": 0.29903256962806973,
      "grad_norm": 0.0023917616344988346,
      "learning_rate": 7.009674303719303e-06,
      "loss": 0.0001,
      "step": 18886
    },
    {
      "epoch": 0.2990484031857118,
      "grad_norm": 0.010462098754942417,
      "learning_rate": 7.0095159681428825e-06,
      "loss": 0.0005,
      "step": 18887
    },
    {
      "epoch": 0.29906423674335386,
      "grad_norm": 9.357621456729248e-05,
      "learning_rate": 7.0093576325664616e-06,
      "loss": 0.0,
      "step": 18888
    },
    {
      "epoch": 0.2990800703009959,
      "grad_norm": 0.17275957763195038,
      "learning_rate": 7.0091992969900415e-06,
      "loss": 0.007,
      "step": 18889
    },
    {
      "epoch": 0.299095903858638,
      "grad_norm": 0.013691512867808342,
      "learning_rate": 7.00904096141362e-06,
      "loss": 0.0007,
      "step": 18890
    },
    {
      "epoch": 0.29911173741628005,
      "grad_norm": 0.48225295543670654,
      "learning_rate": 7.0088826258372e-06,
      "loss": 0.1239,
      "step": 18891
    },
    {
      "epoch": 0.2991275709739221,
      "grad_norm": 0.4890800714492798,
      "learning_rate": 7.008724290260779e-06,
      "loss": 0.2219,
      "step": 18892
    },
    {
      "epoch": 0.2991434045315642,
      "grad_norm": 0.5325824618339539,
      "learning_rate": 7.008565954684359e-06,
      "loss": 0.6311,
      "step": 18893
    },
    {
      "epoch": 0.29915923808920625,
      "grad_norm": 0.30499696731567383,
      "learning_rate": 7.008407619107938e-06,
      "loss": 0.0579,
      "step": 18894
    },
    {
      "epoch": 0.2991750716468483,
      "grad_norm": 0.5045990943908691,
      "learning_rate": 7.008249283531518e-06,
      "loss": 0.0272,
      "step": 18895
    },
    {
      "epoch": 0.2991909052044904,
      "grad_norm": 0.025951378047466278,
      "learning_rate": 7.008090947955096e-06,
      "loss": 0.0014,
      "step": 18896
    },
    {
      "epoch": 0.29920673876213244,
      "grad_norm": 0.6935709714889526,
      "learning_rate": 7.007932612378676e-06,
      "loss": 0.1832,
      "step": 18897
    },
    {
      "epoch": 0.2992225723197745,
      "grad_norm": 0.5265333652496338,
      "learning_rate": 7.007774276802255e-06,
      "loss": 0.5371,
      "step": 18898
    },
    {
      "epoch": 0.2992384058774166,
      "grad_norm": 0.02209318056702614,
      "learning_rate": 7.007615941225835e-06,
      "loss": 0.0012,
      "step": 18899
    },
    {
      "epoch": 0.2992542394350587,
      "grad_norm": 0.0011017731158062816,
      "learning_rate": 7.007457605649414e-06,
      "loss": 0.0,
      "step": 18900
    },
    {
      "epoch": 0.29927007299270075,
      "grad_norm": 0.01892501674592495,
      "learning_rate": 7.007299270072994e-06,
      "loss": 0.0008,
      "step": 18901
    },
    {
      "epoch": 0.2992859065503428,
      "grad_norm": 0.2877996563911438,
      "learning_rate": 7.007140934496572e-06,
      "loss": 0.0443,
      "step": 18902
    },
    {
      "epoch": 0.2993017401079849,
      "grad_norm": 0.04463097080588341,
      "learning_rate": 7.006982598920152e-06,
      "loss": 0.0005,
      "step": 18903
    },
    {
      "epoch": 0.29931757366562695,
      "grad_norm": 0.2989773452281952,
      "learning_rate": 7.006824263343731e-06,
      "loss": 0.0856,
      "step": 18904
    },
    {
      "epoch": 0.299333407223269,
      "grad_norm": 0.614561140537262,
      "learning_rate": 7.006665927767311e-06,
      "loss": 0.2326,
      "step": 18905
    },
    {
      "epoch": 0.2993492407809111,
      "grad_norm": 0.018059084191918373,
      "learning_rate": 7.00650759219089e-06,
      "loss": 0.001,
      "step": 18906
    },
    {
      "epoch": 0.29936507433855314,
      "grad_norm": 0.5675570964813232,
      "learning_rate": 7.00634925661447e-06,
      "loss": 0.119,
      "step": 18907
    },
    {
      "epoch": 0.2993809078961952,
      "grad_norm": 0.09274119138717651,
      "learning_rate": 7.006190921038048e-06,
      "loss": 0.0072,
      "step": 18908
    },
    {
      "epoch": 0.29939674145383727,
      "grad_norm": 0.002480035414919257,
      "learning_rate": 7.006032585461628e-06,
      "loss": 0.0001,
      "step": 18909
    },
    {
      "epoch": 0.29941257501147933,
      "grad_norm": 0.2203836888074875,
      "learning_rate": 7.005874249885207e-06,
      "loss": 0.0646,
      "step": 18910
    },
    {
      "epoch": 0.2994284085691214,
      "grad_norm": 0.2745756208896637,
      "learning_rate": 7.005715914308787e-06,
      "loss": 0.0359,
      "step": 18911
    },
    {
      "epoch": 0.29944424212676346,
      "grad_norm": 0.0005062427371740341,
      "learning_rate": 7.005557578732366e-06,
      "loss": 0.0,
      "step": 18912
    },
    {
      "epoch": 0.2994600756844055,
      "grad_norm": 0.3306470811367035,
      "learning_rate": 7.0053992431559445e-06,
      "loss": 0.1228,
      "step": 18913
    },
    {
      "epoch": 0.2994759092420476,
      "grad_norm": 0.4489302635192871,
      "learning_rate": 7.005240907579524e-06,
      "loss": 0.3021,
      "step": 18914
    },
    {
      "epoch": 0.29949174279968965,
      "grad_norm": 0.25674501061439514,
      "learning_rate": 7.0050825720031035e-06,
      "loss": 0.0816,
      "step": 18915
    },
    {
      "epoch": 0.2995075763573317,
      "grad_norm": 0.013232937082648277,
      "learning_rate": 7.004924236426683e-06,
      "loss": 0.0006,
      "step": 18916
    },
    {
      "epoch": 0.2995234099149738,
      "grad_norm": 0.5049465894699097,
      "learning_rate": 7.0047659008502625e-06,
      "loss": 0.1947,
      "step": 18917
    },
    {
      "epoch": 0.29953924347261585,
      "grad_norm": 0.4697993993759155,
      "learning_rate": 7.004607565273842e-06,
      "loss": 0.1666,
      "step": 18918
    },
    {
      "epoch": 0.2995550770302579,
      "grad_norm": 0.6635625958442688,
      "learning_rate": 7.004449229697421e-06,
      "loss": 0.2484,
      "step": 18919
    },
    {
      "epoch": 0.2995709105879,
      "grad_norm": 0.5894107818603516,
      "learning_rate": 7.0042908941210006e-06,
      "loss": 0.1234,
      "step": 18920
    },
    {
      "epoch": 0.29958674414554204,
      "grad_norm": 0.00032164400909096,
      "learning_rate": 7.00413255854458e-06,
      "loss": 0.0,
      "step": 18921
    },
    {
      "epoch": 0.2996025777031841,
      "grad_norm": 0.01649758778512478,
      "learning_rate": 7.00397422296816e-06,
      "loss": 0.0009,
      "step": 18922
    },
    {
      "epoch": 0.29961841126082617,
      "grad_norm": 0.21517518162727356,
      "learning_rate": 7.003815887391739e-06,
      "loss": 0.0535,
      "step": 18923
    },
    {
      "epoch": 0.2996342448184683,
      "grad_norm": 0.018697131425142288,
      "learning_rate": 7.003657551815319e-06,
      "loss": 0.0008,
      "step": 18924
    },
    {
      "epoch": 0.29965007837611035,
      "grad_norm": 0.46534162759780884,
      "learning_rate": 7.003499216238897e-06,
      "loss": 0.0656,
      "step": 18925
    },
    {
      "epoch": 0.2996659119337524,
      "grad_norm": 0.40460115671157837,
      "learning_rate": 7.003340880662477e-06,
      "loss": 0.083,
      "step": 18926
    },
    {
      "epoch": 0.2996817454913945,
      "grad_norm": 0.6844786405563354,
      "learning_rate": 7.003182545086056e-06,
      "loss": 0.2519,
      "step": 18927
    },
    {
      "epoch": 0.29969757904903654,
      "grad_norm": 0.029748613014817238,
      "learning_rate": 7.003024209509636e-06,
      "loss": 0.0013,
      "step": 18928
    },
    {
      "epoch": 0.2997134126066786,
      "grad_norm": 0.1462310403585434,
      "learning_rate": 7.002865873933215e-06,
      "loss": 0.0515,
      "step": 18929
    },
    {
      "epoch": 0.2997292461643207,
      "grad_norm": 0.42643794417381287,
      "learning_rate": 7.002707538356795e-06,
      "loss": 0.1517,
      "step": 18930
    },
    {
      "epoch": 0.29974507972196274,
      "grad_norm": 0.013022326864302158,
      "learning_rate": 7.002549202780373e-06,
      "loss": 0.0006,
      "step": 18931
    },
    {
      "epoch": 0.2997609132796048,
      "grad_norm": 0.3247987627983093,
      "learning_rate": 7.002390867203953e-06,
      "loss": 0.0415,
      "step": 18932
    },
    {
      "epoch": 0.29977674683724687,
      "grad_norm": 0.0016493619186803699,
      "learning_rate": 7.002232531627532e-06,
      "loss": 0.0,
      "step": 18933
    },
    {
      "epoch": 0.29979258039488893,
      "grad_norm": 0.0006744671845808625,
      "learning_rate": 7.002074196051112e-06,
      "loss": 0.0,
      "step": 18934
    },
    {
      "epoch": 0.299808413952531,
      "grad_norm": 0.20267781615257263,
      "learning_rate": 7.001915860474691e-06,
      "loss": 0.0467,
      "step": 18935
    },
    {
      "epoch": 0.29982424751017306,
      "grad_norm": 0.4225621521472931,
      "learning_rate": 7.001757524898269e-06,
      "loss": 0.15,
      "step": 18936
    },
    {
      "epoch": 0.2998400810678151,
      "grad_norm": 0.10222480446100235,
      "learning_rate": 7.001599189321849e-06,
      "loss": 0.0103,
      "step": 18937
    },
    {
      "epoch": 0.2998559146254572,
      "grad_norm": 0.21909862756729126,
      "learning_rate": 7.001440853745428e-06,
      "loss": 0.047,
      "step": 18938
    },
    {
      "epoch": 0.29987174818309925,
      "grad_norm": 0.5222054719924927,
      "learning_rate": 7.001282518169008e-06,
      "loss": 0.5452,
      "step": 18939
    },
    {
      "epoch": 0.2998875817407413,
      "grad_norm": 0.6075180172920227,
      "learning_rate": 7.001124182592587e-06,
      "loss": 0.3416,
      "step": 18940
    },
    {
      "epoch": 0.2999034152983834,
      "grad_norm": 0.054428581148386,
      "learning_rate": 7.000965847016167e-06,
      "loss": 0.0029,
      "step": 18941
    },
    {
      "epoch": 0.29991924885602544,
      "grad_norm": 0.24304211139678955,
      "learning_rate": 7.000807511439745e-06,
      "loss": 0.0548,
      "step": 18942
    },
    {
      "epoch": 0.2999350824136675,
      "grad_norm": 0.03912732005119324,
      "learning_rate": 7.000649175863325e-06,
      "loss": 0.0025,
      "step": 18943
    },
    {
      "epoch": 0.2999509159713096,
      "grad_norm": 0.3776474595069885,
      "learning_rate": 7.000490840286904e-06,
      "loss": 0.0631,
      "step": 18944
    },
    {
      "epoch": 0.29996674952895164,
      "grad_norm": 0.27292779088020325,
      "learning_rate": 7.000332504710484e-06,
      "loss": 0.0887,
      "step": 18945
    },
    {
      "epoch": 0.2999825830865937,
      "grad_norm": 0.5145988464355469,
      "learning_rate": 7.000174169134063e-06,
      "loss": 0.223,
      "step": 18946
    },
    {
      "epoch": 0.29999841664423577,
      "grad_norm": 0.0014084131689742208,
      "learning_rate": 7.0000158335576425e-06,
      "loss": 0.0,
      "step": 18947
    },
    {
      "epoch": 0.3000142502018779,
      "grad_norm": 0.3076198399066925,
      "learning_rate": 6.9998574979812216e-06,
      "loss": 0.0123,
      "step": 18948
    },
    {
      "epoch": 0.30003008375951995,
      "grad_norm": 0.7985448837280273,
      "learning_rate": 6.9996991624048015e-06,
      "loss": 0.3892,
      "step": 18949
    },
    {
      "epoch": 0.300045917317162,
      "grad_norm": 0.014334158971905708,
      "learning_rate": 6.999540826828381e-06,
      "loss": 0.0006,
      "step": 18950
    },
    {
      "epoch": 0.3000617508748041,
      "grad_norm": 1.751627802848816,
      "learning_rate": 6.9993824912519605e-06,
      "loss": 0.3277,
      "step": 18951
    },
    {
      "epoch": 0.30007758443244614,
      "grad_norm": 0.5216449499130249,
      "learning_rate": 6.999224155675539e-06,
      "loss": 0.2538,
      "step": 18952
    },
    {
      "epoch": 0.3000934179900882,
      "grad_norm": 0.04972665756940842,
      "learning_rate": 6.999065820099119e-06,
      "loss": 0.0027,
      "step": 18953
    },
    {
      "epoch": 0.30010925154773027,
      "grad_norm": 0.13479405641555786,
      "learning_rate": 6.998907484522698e-06,
      "loss": 0.0429,
      "step": 18954
    },
    {
      "epoch": 0.30012508510537234,
      "grad_norm": 0.36823010444641113,
      "learning_rate": 6.998749148946278e-06,
      "loss": 0.065,
      "step": 18955
    },
    {
      "epoch": 0.3001409186630144,
      "grad_norm": 0.5254764556884766,
      "learning_rate": 6.998590813369857e-06,
      "loss": 0.1796,
      "step": 18956
    },
    {
      "epoch": 0.30015675222065646,
      "grad_norm": 0.00041809561662375927,
      "learning_rate": 6.998432477793437e-06,
      "loss": 0.0,
      "step": 18957
    },
    {
      "epoch": 0.30017258577829853,
      "grad_norm": 0.5825127959251404,
      "learning_rate": 6.998274142217015e-06,
      "loss": 0.2183,
      "step": 18958
    },
    {
      "epoch": 0.3001884193359406,
      "grad_norm": 0.7124377489089966,
      "learning_rate": 6.998115806640595e-06,
      "loss": 0.1043,
      "step": 18959
    },
    {
      "epoch": 0.30020425289358266,
      "grad_norm": 0.8424750566482544,
      "learning_rate": 6.997957471064174e-06,
      "loss": 0.5415,
      "step": 18960
    },
    {
      "epoch": 0.3002200864512247,
      "grad_norm": 0.7050451040267944,
      "learning_rate": 6.997799135487753e-06,
      "loss": 0.2433,
      "step": 18961
    },
    {
      "epoch": 0.3002359200088668,
      "grad_norm": 0.0262724831700325,
      "learning_rate": 6.997640799911333e-06,
      "loss": 0.0017,
      "step": 18962
    },
    {
      "epoch": 0.30025175356650885,
      "grad_norm": 0.4362960755825043,
      "learning_rate": 6.997482464334911e-06,
      "loss": 0.1883,
      "step": 18963
    },
    {
      "epoch": 0.3002675871241509,
      "grad_norm": 1.1825653314590454,
      "learning_rate": 6.997324128758491e-06,
      "loss": 0.6991,
      "step": 18964
    },
    {
      "epoch": 0.300283420681793,
      "grad_norm": 0.05421243607997894,
      "learning_rate": 6.99716579318207e-06,
      "loss": 0.0031,
      "step": 18965
    },
    {
      "epoch": 0.30029925423943504,
      "grad_norm": 0.3751102089881897,
      "learning_rate": 6.99700745760565e-06,
      "loss": 0.2171,
      "step": 18966
    },
    {
      "epoch": 0.3003150877970771,
      "grad_norm": 0.0002836206112988293,
      "learning_rate": 6.996849122029229e-06,
      "loss": 0.0,
      "step": 18967
    },
    {
      "epoch": 0.30033092135471917,
      "grad_norm": 0.4698318541049957,
      "learning_rate": 6.996690786452809e-06,
      "loss": 0.1633,
      "step": 18968
    },
    {
      "epoch": 0.30034675491236124,
      "grad_norm": 1.2993723154067993,
      "learning_rate": 6.996532450876387e-06,
      "loss": 0.6678,
      "step": 18969
    },
    {
      "epoch": 0.3003625884700033,
      "grad_norm": 0.6546079516410828,
      "learning_rate": 6.996374115299967e-06,
      "loss": 0.8145,
      "step": 18970
    },
    {
      "epoch": 0.30037842202764536,
      "grad_norm": 0.36603137850761414,
      "learning_rate": 6.996215779723546e-06,
      "loss": 0.0797,
      "step": 18971
    },
    {
      "epoch": 0.3003942555852875,
      "grad_norm": 0.4693441390991211,
      "learning_rate": 6.996057444147126e-06,
      "loss": 0.1484,
      "step": 18972
    },
    {
      "epoch": 0.30041008914292955,
      "grad_norm": 0.5681506991386414,
      "learning_rate": 6.995899108570705e-06,
      "loss": 0.4518,
      "step": 18973
    },
    {
      "epoch": 0.3004259227005716,
      "grad_norm": 0.022000538185238838,
      "learning_rate": 6.995740772994285e-06,
      "loss": 0.0014,
      "step": 18974
    },
    {
      "epoch": 0.3004417562582137,
      "grad_norm": 0.8727579712867737,
      "learning_rate": 6.9955824374178635e-06,
      "loss": 0.1236,
      "step": 18975
    },
    {
      "epoch": 0.30045758981585574,
      "grad_norm": 0.3923800587654114,
      "learning_rate": 6.9954241018414434e-06,
      "loss": 0.1067,
      "step": 18976
    },
    {
      "epoch": 0.3004734233734978,
      "grad_norm": 0.11889821290969849,
      "learning_rate": 6.9952657662650225e-06,
      "loss": 0.0504,
      "step": 18977
    },
    {
      "epoch": 0.30048925693113987,
      "grad_norm": 0.6542380452156067,
      "learning_rate": 6.9951074306886024e-06,
      "loss": 0.1742,
      "step": 18978
    },
    {
      "epoch": 0.30050509048878193,
      "grad_norm": 0.4532373249530792,
      "learning_rate": 6.9949490951121815e-06,
      "loss": 0.1309,
      "step": 18979
    },
    {
      "epoch": 0.300520924046424,
      "grad_norm": 0.4253629446029663,
      "learning_rate": 6.9947907595357614e-06,
      "loss": 0.1325,
      "step": 18980
    },
    {
      "epoch": 0.30053675760406606,
      "grad_norm": 0.25598931312561035,
      "learning_rate": 6.99463242395934e-06,
      "loss": 0.0648,
      "step": 18981
    },
    {
      "epoch": 0.3005525911617081,
      "grad_norm": 0.4320579767227173,
      "learning_rate": 6.99447408838292e-06,
      "loss": 0.1621,
      "step": 18982
    },
    {
      "epoch": 0.3005684247193502,
      "grad_norm": 0.44237884879112244,
      "learning_rate": 6.994315752806499e-06,
      "loss": 0.0448,
      "step": 18983
    },
    {
      "epoch": 0.30058425827699226,
      "grad_norm": 0.5502259731292725,
      "learning_rate": 6.994157417230078e-06,
      "loss": 0.2764,
      "step": 18984
    },
    {
      "epoch": 0.3006000918346343,
      "grad_norm": 0.44360169768333435,
      "learning_rate": 6.993999081653658e-06,
      "loss": 0.1093,
      "step": 18985
    },
    {
      "epoch": 0.3006159253922764,
      "grad_norm": 0.16805127263069153,
      "learning_rate": 6.993840746077236e-06,
      "loss": 0.0455,
      "step": 18986
    },
    {
      "epoch": 0.30063175894991845,
      "grad_norm": 0.21221129596233368,
      "learning_rate": 6.993682410500816e-06,
      "loss": 0.0572,
      "step": 18987
    },
    {
      "epoch": 0.3006475925075605,
      "grad_norm": 0.6738721132278442,
      "learning_rate": 6.993524074924395e-06,
      "loss": 0.0765,
      "step": 18988
    },
    {
      "epoch": 0.3006634260652026,
      "grad_norm": 0.6611428260803223,
      "learning_rate": 6.993365739347975e-06,
      "loss": 0.0807,
      "step": 18989
    },
    {
      "epoch": 0.30067925962284464,
      "grad_norm": 0.5654823780059814,
      "learning_rate": 6.993207403771554e-06,
      "loss": 0.3973,
      "step": 18990
    },
    {
      "epoch": 0.3006950931804867,
      "grad_norm": 0.27930590510368347,
      "learning_rate": 6.993049068195134e-06,
      "loss": 0.0618,
      "step": 18991
    },
    {
      "epoch": 0.30071092673812877,
      "grad_norm": 0.00033413711935281754,
      "learning_rate": 6.992890732618712e-06,
      "loss": 0.0,
      "step": 18992
    },
    {
      "epoch": 0.30072676029577083,
      "grad_norm": 0.7525768280029297,
      "learning_rate": 6.992732397042292e-06,
      "loss": 0.2779,
      "step": 18993
    },
    {
      "epoch": 0.3007425938534129,
      "grad_norm": 0.3197682797908783,
      "learning_rate": 6.992574061465871e-06,
      "loss": 0.1201,
      "step": 18994
    },
    {
      "epoch": 0.30075842741105496,
      "grad_norm": 0.008069525472819805,
      "learning_rate": 6.992415725889451e-06,
      "loss": 0.0004,
      "step": 18995
    },
    {
      "epoch": 0.3007742609686971,
      "grad_norm": 0.0038420562632381916,
      "learning_rate": 6.99225739031303e-06,
      "loss": 0.0002,
      "step": 18996
    },
    {
      "epoch": 0.30079009452633915,
      "grad_norm": 0.2676111161708832,
      "learning_rate": 6.99209905473661e-06,
      "loss": 0.051,
      "step": 18997
    },
    {
      "epoch": 0.3008059280839812,
      "grad_norm": 0.3345790505409241,
      "learning_rate": 6.991940719160188e-06,
      "loss": 0.1029,
      "step": 18998
    },
    {
      "epoch": 0.3008217616416233,
      "grad_norm": 0.8242515921592712,
      "learning_rate": 6.991782383583768e-06,
      "loss": 0.4788,
      "step": 18999
    },
    {
      "epoch": 0.30083759519926534,
      "grad_norm": 0.6621699333190918,
      "learning_rate": 6.991624048007347e-06,
      "loss": 0.2035,
      "step": 19000
    },
    {
      "epoch": 0.3008534287569074,
      "grad_norm": 0.054962579160928726,
      "learning_rate": 6.991465712430927e-06,
      "loss": 0.001,
      "step": 19001
    },
    {
      "epoch": 0.30086926231454947,
      "grad_norm": 0.32075566053390503,
      "learning_rate": 6.991307376854506e-06,
      "loss": 0.0856,
      "step": 19002
    },
    {
      "epoch": 0.30088509587219153,
      "grad_norm": 0.5950973629951477,
      "learning_rate": 6.991149041278086e-06,
      "loss": 0.1086,
      "step": 19003
    },
    {
      "epoch": 0.3009009294298336,
      "grad_norm": 0.010154916904866695,
      "learning_rate": 6.9909907057016644e-06,
      "loss": 0.0004,
      "step": 19004
    },
    {
      "epoch": 0.30091676298747566,
      "grad_norm": 0.27277901768684387,
      "learning_rate": 6.990832370125244e-06,
      "loss": 0.0173,
      "step": 19005
    },
    {
      "epoch": 0.3009325965451177,
      "grad_norm": 0.44379258155822754,
      "learning_rate": 6.9906740345488234e-06,
      "loss": 0.4762,
      "step": 19006
    },
    {
      "epoch": 0.3009484301027598,
      "grad_norm": 0.4049338102340698,
      "learning_rate": 6.990515698972403e-06,
      "loss": 0.1358,
      "step": 19007
    },
    {
      "epoch": 0.30096426366040185,
      "grad_norm": 0.44575008749961853,
      "learning_rate": 6.9903573633959824e-06,
      "loss": 0.1164,
      "step": 19008
    },
    {
      "epoch": 0.3009800972180439,
      "grad_norm": 0.0496588796377182,
      "learning_rate": 6.990199027819561e-06,
      "loss": 0.0032,
      "step": 19009
    },
    {
      "epoch": 0.300995930775686,
      "grad_norm": 0.5505780577659607,
      "learning_rate": 6.990040692243141e-06,
      "loss": 0.2386,
      "step": 19010
    },
    {
      "epoch": 0.30101176433332805,
      "grad_norm": 0.6748826503753662,
      "learning_rate": 6.98988235666672e-06,
      "loss": 0.0503,
      "step": 19011
    },
    {
      "epoch": 0.3010275978909701,
      "grad_norm": 0.36266422271728516,
      "learning_rate": 6.9897240210903e-06,
      "loss": 0.1464,
      "step": 19012
    },
    {
      "epoch": 0.3010434314486122,
      "grad_norm": 0.4255392849445343,
      "learning_rate": 6.989565685513878e-06,
      "loss": 0.1301,
      "step": 19013
    },
    {
      "epoch": 0.30105926500625424,
      "grad_norm": 0.0006799278198741376,
      "learning_rate": 6.989407349937458e-06,
      "loss": 0.0,
      "step": 19014
    },
    {
      "epoch": 0.3010750985638963,
      "grad_norm": 2.625065326690674,
      "learning_rate": 6.989249014361037e-06,
      "loss": 0.0786,
      "step": 19015
    },
    {
      "epoch": 0.30109093212153837,
      "grad_norm": 0.26192766427993774,
      "learning_rate": 6.989090678784617e-06,
      "loss": 0.052,
      "step": 19016
    },
    {
      "epoch": 0.30110676567918043,
      "grad_norm": 0.6997842192649841,
      "learning_rate": 6.988932343208196e-06,
      "loss": 0.0622,
      "step": 19017
    },
    {
      "epoch": 0.3011225992368225,
      "grad_norm": 0.2481023371219635,
      "learning_rate": 6.988774007631776e-06,
      "loss": 0.1257,
      "step": 19018
    },
    {
      "epoch": 0.30113843279446456,
      "grad_norm": 0.0002399428776698187,
      "learning_rate": 6.988615672055354e-06,
      "loss": 0.0,
      "step": 19019
    },
    {
      "epoch": 0.3011542663521067,
      "grad_norm": 0.3355967700481415,
      "learning_rate": 6.988457336478934e-06,
      "loss": 0.1654,
      "step": 19020
    },
    {
      "epoch": 0.30117009990974875,
      "grad_norm": 0.582603931427002,
      "learning_rate": 6.988299000902513e-06,
      "loss": 0.2112,
      "step": 19021
    },
    {
      "epoch": 0.3011859334673908,
      "grad_norm": 0.8555358648300171,
      "learning_rate": 6.988140665326093e-06,
      "loss": 0.4351,
      "step": 19022
    },
    {
      "epoch": 0.3012017670250329,
      "grad_norm": 0.5844340324401855,
      "learning_rate": 6.987982329749672e-06,
      "loss": 0.2449,
      "step": 19023
    },
    {
      "epoch": 0.30121760058267494,
      "grad_norm": 0.6266768574714661,
      "learning_rate": 6.987823994173252e-06,
      "loss": 0.3089,
      "step": 19024
    },
    {
      "epoch": 0.301233434140317,
      "grad_norm": 0.5192646980285645,
      "learning_rate": 6.98766565859683e-06,
      "loss": 0.1559,
      "step": 19025
    },
    {
      "epoch": 0.30124926769795907,
      "grad_norm": 0.0031357703264802694,
      "learning_rate": 6.98750732302041e-06,
      "loss": 0.0001,
      "step": 19026
    },
    {
      "epoch": 0.30126510125560113,
      "grad_norm": 0.7046506404876709,
      "learning_rate": 6.987348987443989e-06,
      "loss": 0.1525,
      "step": 19027
    },
    {
      "epoch": 0.3012809348132432,
      "grad_norm": 0.00024549232330173254,
      "learning_rate": 6.987190651867569e-06,
      "loss": 0.0,
      "step": 19028
    },
    {
      "epoch": 0.30129676837088526,
      "grad_norm": 0.008257796987891197,
      "learning_rate": 6.987032316291148e-06,
      "loss": 0.0003,
      "step": 19029
    },
    {
      "epoch": 0.3013126019285273,
      "grad_norm": 0.37250006198883057,
      "learning_rate": 6.986873980714728e-06,
      "loss": 0.1194,
      "step": 19030
    },
    {
      "epoch": 0.3013284354861694,
      "grad_norm": 0.42306795716285706,
      "learning_rate": 6.986715645138306e-06,
      "loss": 0.0859,
      "step": 19031
    },
    {
      "epoch": 0.30134426904381145,
      "grad_norm": 0.5254163146018982,
      "learning_rate": 6.9865573095618854e-06,
      "loss": 0.235,
      "step": 19032
    },
    {
      "epoch": 0.3013601026014535,
      "grad_norm": 0.46848008036613464,
      "learning_rate": 6.986398973985465e-06,
      "loss": 0.1336,
      "step": 19033
    },
    {
      "epoch": 0.3013759361590956,
      "grad_norm": 0.05098680779337883,
      "learning_rate": 6.9862406384090444e-06,
      "loss": 0.0037,
      "step": 19034
    },
    {
      "epoch": 0.30139176971673765,
      "grad_norm": 0.5714628100395203,
      "learning_rate": 6.986082302832624e-06,
      "loss": 0.0419,
      "step": 19035
    },
    {
      "epoch": 0.3014076032743797,
      "grad_norm": 0.453578919172287,
      "learning_rate": 6.985923967256203e-06,
      "loss": 0.102,
      "step": 19036
    },
    {
      "epoch": 0.3014234368320218,
      "grad_norm": 0.029800215736031532,
      "learning_rate": 6.9857656316797825e-06,
      "loss": 0.0016,
      "step": 19037
    },
    {
      "epoch": 0.30143927038966384,
      "grad_norm": 0.014840413816273212,
      "learning_rate": 6.985607296103362e-06,
      "loss": 0.0002,
      "step": 19038
    },
    {
      "epoch": 0.3014551039473059,
      "grad_norm": 0.18058085441589355,
      "learning_rate": 6.9854489605269415e-06,
      "loss": 0.0836,
      "step": 19039
    },
    {
      "epoch": 0.30147093750494797,
      "grad_norm": 0.330460786819458,
      "learning_rate": 6.985290624950521e-06,
      "loss": 0.0546,
      "step": 19040
    },
    {
      "epoch": 0.30148677106259003,
      "grad_norm": 0.1841401606798172,
      "learning_rate": 6.9851322893741005e-06,
      "loss": 0.0091,
      "step": 19041
    },
    {
      "epoch": 0.3015026046202321,
      "grad_norm": 0.09210406243801117,
      "learning_rate": 6.984973953797679e-06,
      "loss": 0.0067,
      "step": 19042
    },
    {
      "epoch": 0.30151843817787416,
      "grad_norm": 0.8336204290390015,
      "learning_rate": 6.984815618221259e-06,
      "loss": 0.7705,
      "step": 19043
    },
    {
      "epoch": 0.3015342717355163,
      "grad_norm": 0.7099428772926331,
      "learning_rate": 6.984657282644838e-06,
      "loss": 0.0503,
      "step": 19044
    },
    {
      "epoch": 0.30155010529315834,
      "grad_norm": 0.5502110123634338,
      "learning_rate": 6.984498947068418e-06,
      "loss": 0.2518,
      "step": 19045
    },
    {
      "epoch": 0.3015659388508004,
      "grad_norm": 0.5484415888786316,
      "learning_rate": 6.984340611491997e-06,
      "loss": 0.2245,
      "step": 19046
    },
    {
      "epoch": 0.30158177240844247,
      "grad_norm": 0.18728037178516388,
      "learning_rate": 6.984182275915577e-06,
      "loss": 0.0659,
      "step": 19047
    },
    {
      "epoch": 0.30159760596608454,
      "grad_norm": 0.0003656853223219514,
      "learning_rate": 6.984023940339155e-06,
      "loss": 0.0,
      "step": 19048
    },
    {
      "epoch": 0.3016134395237266,
      "grad_norm": 0.05557980760931969,
      "learning_rate": 6.983865604762735e-06,
      "loss": 0.0032,
      "step": 19049
    },
    {
      "epoch": 0.30162927308136867,
      "grad_norm": 0.4419007897377014,
      "learning_rate": 6.983707269186314e-06,
      "loss": 0.2412,
      "step": 19050
    },
    {
      "epoch": 0.30164510663901073,
      "grad_norm": 0.5803635716438293,
      "learning_rate": 6.983548933609894e-06,
      "loss": 0.863,
      "step": 19051
    },
    {
      "epoch": 0.3016609401966528,
      "grad_norm": 0.5851885676383972,
      "learning_rate": 6.983390598033473e-06,
      "loss": 0.2661,
      "step": 19052
    },
    {
      "epoch": 0.30167677375429486,
      "grad_norm": 0.1668257862329483,
      "learning_rate": 6.983232262457053e-06,
      "loss": 0.0291,
      "step": 19053
    },
    {
      "epoch": 0.3016926073119369,
      "grad_norm": 0.0004826924414373934,
      "learning_rate": 6.983073926880631e-06,
      "loss": 0.0,
      "step": 19054
    },
    {
      "epoch": 0.301708440869579,
      "grad_norm": 0.017241396009922028,
      "learning_rate": 6.982915591304211e-06,
      "loss": 0.0007,
      "step": 19055
    },
    {
      "epoch": 0.30172427442722105,
      "grad_norm": 0.6481676697731018,
      "learning_rate": 6.98275725572779e-06,
      "loss": 0.031,
      "step": 19056
    },
    {
      "epoch": 0.3017401079848631,
      "grad_norm": 0.0417548231780529,
      "learning_rate": 6.982598920151369e-06,
      "loss": 0.0026,
      "step": 19057
    },
    {
      "epoch": 0.3017559415425052,
      "grad_norm": 0.4157175123691559,
      "learning_rate": 6.982440584574949e-06,
      "loss": 0.1209,
      "step": 19058
    },
    {
      "epoch": 0.30177177510014724,
      "grad_norm": 0.0004034047306049615,
      "learning_rate": 6.982282248998527e-06,
      "loss": 0.0,
      "step": 19059
    },
    {
      "epoch": 0.3017876086577893,
      "grad_norm": 0.4115438759326935,
      "learning_rate": 6.982123913422107e-06,
      "loss": 0.033,
      "step": 19060
    },
    {
      "epoch": 0.3018034422154314,
      "grad_norm": 0.34677472710609436,
      "learning_rate": 6.981965577845686e-06,
      "loss": 0.0942,
      "step": 19061
    },
    {
      "epoch": 0.30181927577307344,
      "grad_norm": 0.40789249539375305,
      "learning_rate": 6.981807242269266e-06,
      "loss": 0.1408,
      "step": 19062
    },
    {
      "epoch": 0.3018351093307155,
      "grad_norm": 0.38868436217308044,
      "learning_rate": 6.981648906692845e-06,
      "loss": 0.0776,
      "step": 19063
    },
    {
      "epoch": 0.30185094288835757,
      "grad_norm": 0.003132483921945095,
      "learning_rate": 6.981490571116425e-06,
      "loss": 0.0001,
      "step": 19064
    },
    {
      "epoch": 0.30186677644599963,
      "grad_norm": 0.9393457770347595,
      "learning_rate": 6.9813322355400035e-06,
      "loss": 0.3089,
      "step": 19065
    },
    {
      "epoch": 0.3018826100036417,
      "grad_norm": 0.2675069272518158,
      "learning_rate": 6.9811738999635835e-06,
      "loss": 0.0518,
      "step": 19066
    },
    {
      "epoch": 0.30189844356128376,
      "grad_norm": 0.2001478224992752,
      "learning_rate": 6.9810155643871625e-06,
      "loss": 0.0347,
      "step": 19067
    },
    {
      "epoch": 0.3019142771189259,
      "grad_norm": 0.18435440957546234,
      "learning_rate": 6.9808572288107425e-06,
      "loss": 0.0276,
      "step": 19068
    },
    {
      "epoch": 0.30193011067656794,
      "grad_norm": 0.3095303475856781,
      "learning_rate": 6.9806988932343215e-06,
      "loss": 0.0738,
      "step": 19069
    },
    {
      "epoch": 0.30194594423421,
      "grad_norm": 0.12316752225160599,
      "learning_rate": 6.9805405576579015e-06,
      "loss": 0.0112,
      "step": 19070
    },
    {
      "epoch": 0.30196177779185207,
      "grad_norm": 1.0194886922836304,
      "learning_rate": 6.98038222208148e-06,
      "loss": 0.2679,
      "step": 19071
    },
    {
      "epoch": 0.30197761134949413,
      "grad_norm": 0.6084055304527283,
      "learning_rate": 6.98022388650506e-06,
      "loss": 0.1805,
      "step": 19072
    },
    {
      "epoch": 0.3019934449071362,
      "grad_norm": 0.527393102645874,
      "learning_rate": 6.980065550928639e-06,
      "loss": 0.0744,
      "step": 19073
    },
    {
      "epoch": 0.30200927846477826,
      "grad_norm": 0.01261706929653883,
      "learning_rate": 6.979907215352219e-06,
      "loss": 0.0006,
      "step": 19074
    },
    {
      "epoch": 0.30202511202242033,
      "grad_norm": 0.01647200621664524,
      "learning_rate": 6.979748879775798e-06,
      "loss": 0.0008,
      "step": 19075
    },
    {
      "epoch": 0.3020409455800624,
      "grad_norm": 0.24950607120990753,
      "learning_rate": 6.979590544199377e-06,
      "loss": 0.042,
      "step": 19076
    },
    {
      "epoch": 0.30205677913770446,
      "grad_norm": 0.010387737303972244,
      "learning_rate": 6.979432208622956e-06,
      "loss": 0.0006,
      "step": 19077
    },
    {
      "epoch": 0.3020726126953465,
      "grad_norm": 0.598193883895874,
      "learning_rate": 6.979273873046536e-06,
      "loss": 0.1361,
      "step": 19078
    },
    {
      "epoch": 0.3020884462529886,
      "grad_norm": 0.014050076715648174,
      "learning_rate": 6.979115537470115e-06,
      "loss": 0.0007,
      "step": 19079
    },
    {
      "epoch": 0.30210427981063065,
      "grad_norm": 0.8478682041168213,
      "learning_rate": 6.978957201893693e-06,
      "loss": 0.1956,
      "step": 19080
    },
    {
      "epoch": 0.3021201133682727,
      "grad_norm": 0.6348716020584106,
      "learning_rate": 6.978798866317273e-06,
      "loss": 0.3169,
      "step": 19081
    },
    {
      "epoch": 0.3021359469259148,
      "grad_norm": 0.5314903259277344,
      "learning_rate": 6.978640530740852e-06,
      "loss": 0.1175,
      "step": 19082
    },
    {
      "epoch": 0.30215178048355684,
      "grad_norm": 0.7569792866706848,
      "learning_rate": 6.978482195164432e-06,
      "loss": 0.5329,
      "step": 19083
    },
    {
      "epoch": 0.3021676140411989,
      "grad_norm": 1.356136441230774,
      "learning_rate": 6.978323859588011e-06,
      "loss": 0.2583,
      "step": 19084
    },
    {
      "epoch": 0.30218344759884097,
      "grad_norm": 0.006715241353958845,
      "learning_rate": 6.978165524011591e-06,
      "loss": 0.0001,
      "step": 19085
    },
    {
      "epoch": 0.30219928115648304,
      "grad_norm": 0.5392315983772278,
      "learning_rate": 6.978007188435169e-06,
      "loss": 0.3947,
      "step": 19086
    },
    {
      "epoch": 0.3022151147141251,
      "grad_norm": 0.5555709600448608,
      "learning_rate": 6.977848852858749e-06,
      "loss": 0.1837,
      "step": 19087
    },
    {
      "epoch": 0.30223094827176716,
      "grad_norm": 0.5483624935150146,
      "learning_rate": 6.977690517282328e-06,
      "loss": 0.2369,
      "step": 19088
    },
    {
      "epoch": 0.30224678182940923,
      "grad_norm": 0.0004646891902666539,
      "learning_rate": 6.977532181705908e-06,
      "loss": 0.0,
      "step": 19089
    },
    {
      "epoch": 0.3022626153870513,
      "grad_norm": 0.38159242272377014,
      "learning_rate": 6.977373846129487e-06,
      "loss": 0.212,
      "step": 19090
    },
    {
      "epoch": 0.30227844894469336,
      "grad_norm": 0.5514476895332336,
      "learning_rate": 6.977215510553067e-06,
      "loss": 0.167,
      "step": 19091
    },
    {
      "epoch": 0.3022942825023355,
      "grad_norm": 0.022425413131713867,
      "learning_rate": 6.9770571749766455e-06,
      "loss": 0.0011,
      "step": 19092
    },
    {
      "epoch": 0.30231011605997754,
      "grad_norm": 0.32636475563049316,
      "learning_rate": 6.976898839400225e-06,
      "loss": 0.0832,
      "step": 19093
    },
    {
      "epoch": 0.3023259496176196,
      "grad_norm": 0.4021226167678833,
      "learning_rate": 6.9767405038238045e-06,
      "loss": 0.1538,
      "step": 19094
    },
    {
      "epoch": 0.30234178317526167,
      "grad_norm": 0.28044813871383667,
      "learning_rate": 6.976582168247384e-06,
      "loss": 0.0686,
      "step": 19095
    },
    {
      "epoch": 0.30235761673290373,
      "grad_norm": 0.028213700279593468,
      "learning_rate": 6.9764238326709635e-06,
      "loss": 0.0016,
      "step": 19096
    },
    {
      "epoch": 0.3023734502905458,
      "grad_norm": 0.01329039502888918,
      "learning_rate": 6.976265497094543e-06,
      "loss": 0.0006,
      "step": 19097
    },
    {
      "epoch": 0.30238928384818786,
      "grad_norm": 0.9405021667480469,
      "learning_rate": 6.976107161518122e-06,
      "loss": 0.0992,
      "step": 19098
    },
    {
      "epoch": 0.3024051174058299,
      "grad_norm": 0.3682882785797119,
      "learning_rate": 6.9759488259417016e-06,
      "loss": 0.0807,
      "step": 19099
    },
    {
      "epoch": 0.302420950963472,
      "grad_norm": 0.6171855926513672,
      "learning_rate": 6.975790490365281e-06,
      "loss": 0.2156,
      "step": 19100
    },
    {
      "epoch": 0.30243678452111405,
      "grad_norm": 0.03710903599858284,
      "learning_rate": 6.9756321547888606e-06,
      "loss": 0.0021,
      "step": 19101
    },
    {
      "epoch": 0.3024526180787561,
      "grad_norm": 0.035802047699689865,
      "learning_rate": 6.97547381921244e-06,
      "loss": 0.0017,
      "step": 19102
    },
    {
      "epoch": 0.3024684516363982,
      "grad_norm": 0.17469361424446106,
      "learning_rate": 6.9753154836360196e-06,
      "loss": 0.0643,
      "step": 19103
    },
    {
      "epoch": 0.30248428519404025,
      "grad_norm": 0.8067433834075928,
      "learning_rate": 6.975157148059598e-06,
      "loss": 0.071,
      "step": 19104
    },
    {
      "epoch": 0.3025001187516823,
      "grad_norm": 0.02797655574977398,
      "learning_rate": 6.974998812483177e-06,
      "loss": 0.0012,
      "step": 19105
    },
    {
      "epoch": 0.3025159523093244,
      "grad_norm": 0.0006799268303439021,
      "learning_rate": 6.974840476906757e-06,
      "loss": 0.0,
      "step": 19106
    },
    {
      "epoch": 0.30253178586696644,
      "grad_norm": 0.0004307400668039918,
      "learning_rate": 6.974682141330336e-06,
      "loss": 0.0,
      "step": 19107
    },
    {
      "epoch": 0.3025476194246085,
      "grad_norm": 0.009105803444981575,
      "learning_rate": 6.974523805753916e-06,
      "loss": 0.0004,
      "step": 19108
    },
    {
      "epoch": 0.30256345298225057,
      "grad_norm": 0.0007995978812687099,
      "learning_rate": 6.974365470177494e-06,
      "loss": 0.0,
      "step": 19109
    },
    {
      "epoch": 0.30257928653989263,
      "grad_norm": 0.35750699043273926,
      "learning_rate": 6.974207134601074e-06,
      "loss": 0.1171,
      "step": 19110
    },
    {
      "epoch": 0.3025951200975347,
      "grad_norm": 0.0002997494302690029,
      "learning_rate": 6.974048799024653e-06,
      "loss": 0.0,
      "step": 19111
    },
    {
      "epoch": 0.30261095365517676,
      "grad_norm": 0.46740543842315674,
      "learning_rate": 6.973890463448233e-06,
      "loss": 0.0858,
      "step": 19112
    },
    {
      "epoch": 0.3026267872128188,
      "grad_norm": 0.37731263041496277,
      "learning_rate": 6.973732127871812e-06,
      "loss": 0.0531,
      "step": 19113
    },
    {
      "epoch": 0.3026426207704609,
      "grad_norm": 0.72763991355896,
      "learning_rate": 6.973573792295392e-06,
      "loss": 0.1142,
      "step": 19114
    },
    {
      "epoch": 0.30265845432810295,
      "grad_norm": 0.6121235489845276,
      "learning_rate": 6.97341545671897e-06,
      "loss": 0.2141,
      "step": 19115
    },
    {
      "epoch": 0.3026742878857451,
      "grad_norm": 0.2860963046550751,
      "learning_rate": 6.97325712114255e-06,
      "loss": 0.0578,
      "step": 19116
    },
    {
      "epoch": 0.30269012144338714,
      "grad_norm": 0.5644258260726929,
      "learning_rate": 6.973098785566129e-06,
      "loss": 0.0624,
      "step": 19117
    },
    {
      "epoch": 0.3027059550010292,
      "grad_norm": 0.30792468786239624,
      "learning_rate": 6.972940449989709e-06,
      "loss": 0.0612,
      "step": 19118
    },
    {
      "epoch": 0.30272178855867127,
      "grad_norm": 0.41763731837272644,
      "learning_rate": 6.972782114413288e-06,
      "loss": 0.104,
      "step": 19119
    },
    {
      "epoch": 0.30273762211631333,
      "grad_norm": 0.5116100311279297,
      "learning_rate": 6.972623778836868e-06,
      "loss": 0.1965,
      "step": 19120
    },
    {
      "epoch": 0.3027534556739554,
      "grad_norm": 0.22416852414608002,
      "learning_rate": 6.972465443260446e-06,
      "loss": 0.0505,
      "step": 19121
    },
    {
      "epoch": 0.30276928923159746,
      "grad_norm": 1.0170434713363647,
      "learning_rate": 6.972307107684026e-06,
      "loss": 0.9602,
      "step": 19122
    },
    {
      "epoch": 0.3027851227892395,
      "grad_norm": 0.10661526024341583,
      "learning_rate": 6.972148772107605e-06,
      "loss": 0.0044,
      "step": 19123
    },
    {
      "epoch": 0.3028009563468816,
      "grad_norm": 0.37678876519203186,
      "learning_rate": 6.971990436531185e-06,
      "loss": 0.1125,
      "step": 19124
    },
    {
      "epoch": 0.30281678990452365,
      "grad_norm": 0.024028107523918152,
      "learning_rate": 6.971832100954764e-06,
      "loss": 0.0011,
      "step": 19125
    },
    {
      "epoch": 0.3028326234621657,
      "grad_norm": 0.30806756019592285,
      "learning_rate": 6.971673765378344e-06,
      "loss": 0.019,
      "step": 19126
    },
    {
      "epoch": 0.3028484570198078,
      "grad_norm": 0.026509208604693413,
      "learning_rate": 6.9715154298019226e-06,
      "loss": 0.0015,
      "step": 19127
    },
    {
      "epoch": 0.30286429057744985,
      "grad_norm": 0.044370006769895554,
      "learning_rate": 6.971357094225502e-06,
      "loss": 0.0028,
      "step": 19128
    },
    {
      "epoch": 0.3028801241350919,
      "grad_norm": 0.00870650727301836,
      "learning_rate": 6.9711987586490816e-06,
      "loss": 0.0004,
      "step": 19129
    },
    {
      "epoch": 0.302895957692734,
      "grad_norm": 0.05260797590017319,
      "learning_rate": 6.971040423072661e-06,
      "loss": 0.0029,
      "step": 19130
    },
    {
      "epoch": 0.30291179125037604,
      "grad_norm": 0.45240217447280884,
      "learning_rate": 6.9708820874962406e-06,
      "loss": 0.2176,
      "step": 19131
    },
    {
      "epoch": 0.3029276248080181,
      "grad_norm": 0.00730691896751523,
      "learning_rate": 6.970723751919819e-06,
      "loss": 0.0004,
      "step": 19132
    },
    {
      "epoch": 0.30294345836566017,
      "grad_norm": 0.7638511061668396,
      "learning_rate": 6.970565416343399e-06,
      "loss": 0.3574,
      "step": 19133
    },
    {
      "epoch": 0.30295929192330223,
      "grad_norm": 0.6191180944442749,
      "learning_rate": 6.970407080766978e-06,
      "loss": 0.2146,
      "step": 19134
    },
    {
      "epoch": 0.3029751254809443,
      "grad_norm": 0.09884019196033478,
      "learning_rate": 6.970248745190558e-06,
      "loss": 0.004,
      "step": 19135
    },
    {
      "epoch": 0.30299095903858636,
      "grad_norm": 0.46051862835884094,
      "learning_rate": 6.970090409614137e-06,
      "loss": 0.7241,
      "step": 19136
    },
    {
      "epoch": 0.3030067925962284,
      "grad_norm": 0.866113007068634,
      "learning_rate": 6.969932074037717e-06,
      "loss": 0.3215,
      "step": 19137
    },
    {
      "epoch": 0.3030226261538705,
      "grad_norm": 0.009573597460985184,
      "learning_rate": 6.969773738461295e-06,
      "loss": 0.0003,
      "step": 19138
    },
    {
      "epoch": 0.30303845971151255,
      "grad_norm": 0.1567857563495636,
      "learning_rate": 6.969615402884875e-06,
      "loss": 0.0178,
      "step": 19139
    },
    {
      "epoch": 0.3030542932691547,
      "grad_norm": 2.480989933013916,
      "learning_rate": 6.969457067308454e-06,
      "loss": 0.7178,
      "step": 19140
    },
    {
      "epoch": 0.30307012682679674,
      "grad_norm": 0.022538619115948677,
      "learning_rate": 6.969298731732034e-06,
      "loss": 0.0015,
      "step": 19141
    },
    {
      "epoch": 0.3030859603844388,
      "grad_norm": 0.008504563942551613,
      "learning_rate": 6.969140396155612e-06,
      "loss": 0.0002,
      "step": 19142
    },
    {
      "epoch": 0.30310179394208087,
      "grad_norm": 0.6272392868995667,
      "learning_rate": 6.968982060579192e-06,
      "loss": 0.1832,
      "step": 19143
    },
    {
      "epoch": 0.30311762749972293,
      "grad_norm": 0.6291797757148743,
      "learning_rate": 6.968823725002771e-06,
      "loss": 0.2408,
      "step": 19144
    },
    {
      "epoch": 0.303133461057365,
      "grad_norm": 0.2573200762271881,
      "learning_rate": 6.968665389426351e-06,
      "loss": 0.0689,
      "step": 19145
    },
    {
      "epoch": 0.30314929461500706,
      "grad_norm": 0.491445928812027,
      "learning_rate": 6.96850705384993e-06,
      "loss": 0.1037,
      "step": 19146
    },
    {
      "epoch": 0.3031651281726491,
      "grad_norm": 0.9675896167755127,
      "learning_rate": 6.96834871827351e-06,
      "loss": 0.1096,
      "step": 19147
    },
    {
      "epoch": 0.3031809617302912,
      "grad_norm": 0.41930922865867615,
      "learning_rate": 6.968190382697088e-06,
      "loss": 0.0958,
      "step": 19148
    },
    {
      "epoch": 0.30319679528793325,
      "grad_norm": 0.39824196696281433,
      "learning_rate": 6.968032047120668e-06,
      "loss": 0.0448,
      "step": 19149
    },
    {
      "epoch": 0.3032126288455753,
      "grad_norm": 0.01586679182946682,
      "learning_rate": 6.967873711544247e-06,
      "loss": 0.0009,
      "step": 19150
    },
    {
      "epoch": 0.3032284624032174,
      "grad_norm": 0.16951939463615417,
      "learning_rate": 6.967715375967827e-06,
      "loss": 0.0346,
      "step": 19151
    },
    {
      "epoch": 0.30324429596085944,
      "grad_norm": 0.5262653827667236,
      "learning_rate": 6.967557040391406e-06,
      "loss": 0.2818,
      "step": 19152
    },
    {
      "epoch": 0.3032601295185015,
      "grad_norm": 0.012350614182651043,
      "learning_rate": 6.9673987048149846e-06,
      "loss": 0.0004,
      "step": 19153
    },
    {
      "epoch": 0.3032759630761436,
      "grad_norm": 0.2242313027381897,
      "learning_rate": 6.9672403692385645e-06,
      "loss": 0.017,
      "step": 19154
    },
    {
      "epoch": 0.30329179663378564,
      "grad_norm": 0.5215273499488831,
      "learning_rate": 6.9670820336621436e-06,
      "loss": 0.266,
      "step": 19155
    },
    {
      "epoch": 0.3033076301914277,
      "grad_norm": 0.6655612587928772,
      "learning_rate": 6.9669236980857235e-06,
      "loss": 0.2474,
      "step": 19156
    },
    {
      "epoch": 0.30332346374906977,
      "grad_norm": 0.5811481475830078,
      "learning_rate": 6.9667653625093026e-06,
      "loss": 0.2016,
      "step": 19157
    },
    {
      "epoch": 0.30333929730671183,
      "grad_norm": 0.012442173436284065,
      "learning_rate": 6.9666070269328825e-06,
      "loss": 0.0007,
      "step": 19158
    },
    {
      "epoch": 0.3033551308643539,
      "grad_norm": 0.1464162915945053,
      "learning_rate": 6.966448691356461e-06,
      "loss": 0.0481,
      "step": 19159
    },
    {
      "epoch": 0.30337096442199596,
      "grad_norm": 0.28917139768600464,
      "learning_rate": 6.966290355780041e-06,
      "loss": 0.8558,
      "step": 19160
    },
    {
      "epoch": 0.303386797979638,
      "grad_norm": 0.4192700982093811,
      "learning_rate": 6.96613202020362e-06,
      "loss": 0.0781,
      "step": 19161
    },
    {
      "epoch": 0.3034026315372801,
      "grad_norm": 0.9820138812065125,
      "learning_rate": 6.9659736846272e-06,
      "loss": 0.301,
      "step": 19162
    },
    {
      "epoch": 0.30341846509492215,
      "grad_norm": 0.004748901352286339,
      "learning_rate": 6.965815349050779e-06,
      "loss": 0.0002,
      "step": 19163
    },
    {
      "epoch": 0.30343429865256427,
      "grad_norm": 1.0386085510253906,
      "learning_rate": 6.965657013474359e-06,
      "loss": 0.4674,
      "step": 19164
    },
    {
      "epoch": 0.30345013221020634,
      "grad_norm": 0.3360808491706848,
      "learning_rate": 6.965498677897937e-06,
      "loss": 0.0291,
      "step": 19165
    },
    {
      "epoch": 0.3034659657678484,
      "grad_norm": 1.5877785682678223,
      "learning_rate": 6.965340342321517e-06,
      "loss": 1.0247,
      "step": 19166
    },
    {
      "epoch": 0.30348179932549046,
      "grad_norm": 0.3454790413379669,
      "learning_rate": 6.965182006745096e-06,
      "loss": 0.1544,
      "step": 19167
    },
    {
      "epoch": 0.30349763288313253,
      "grad_norm": 0.5061208605766296,
      "learning_rate": 6.965023671168676e-06,
      "loss": 0.0838,
      "step": 19168
    },
    {
      "epoch": 0.3035134664407746,
      "grad_norm": 0.6011143922805786,
      "learning_rate": 6.964865335592255e-06,
      "loss": 0.6609,
      "step": 19169
    },
    {
      "epoch": 0.30352929999841666,
      "grad_norm": 0.23176611959934235,
      "learning_rate": 6.964707000015835e-06,
      "loss": 0.0754,
      "step": 19170
    },
    {
      "epoch": 0.3035451335560587,
      "grad_norm": 0.5838492512702942,
      "learning_rate": 6.964548664439413e-06,
      "loss": 0.1838,
      "step": 19171
    },
    {
      "epoch": 0.3035609671137008,
      "grad_norm": 0.7099684476852417,
      "learning_rate": 6.964390328862993e-06,
      "loss": 0.3463,
      "step": 19172
    },
    {
      "epoch": 0.30357680067134285,
      "grad_norm": 0.009950327686965466,
      "learning_rate": 6.964231993286572e-06,
      "loss": 0.0004,
      "step": 19173
    },
    {
      "epoch": 0.3035926342289849,
      "grad_norm": 0.22416062653064728,
      "learning_rate": 6.964073657710152e-06,
      "loss": 0.0719,
      "step": 19174
    },
    {
      "epoch": 0.303608467786627,
      "grad_norm": 1.2738250494003296,
      "learning_rate": 6.963915322133731e-06,
      "loss": 0.4041,
      "step": 19175
    },
    {
      "epoch": 0.30362430134426904,
      "grad_norm": 0.18794234097003937,
      "learning_rate": 6.963756986557309e-06,
      "loss": 0.0101,
      "step": 19176
    },
    {
      "epoch": 0.3036401349019111,
      "grad_norm": 0.00036142958560958505,
      "learning_rate": 6.963598650980889e-06,
      "loss": 0.0,
      "step": 19177
    },
    {
      "epoch": 0.30365596845955317,
      "grad_norm": 0.02554619312286377,
      "learning_rate": 6.963440315404468e-06,
      "loss": 0.0008,
      "step": 19178
    },
    {
      "epoch": 0.30367180201719524,
      "grad_norm": 0.16638612747192383,
      "learning_rate": 6.963281979828048e-06,
      "loss": 0.0429,
      "step": 19179
    },
    {
      "epoch": 0.3036876355748373,
      "grad_norm": 0.0007542058010585606,
      "learning_rate": 6.963123644251627e-06,
      "loss": 0.0,
      "step": 19180
    },
    {
      "epoch": 0.30370346913247936,
      "grad_norm": 0.6752446293830872,
      "learning_rate": 6.962965308675207e-06,
      "loss": 0.1131,
      "step": 19181
    },
    {
      "epoch": 0.30371930269012143,
      "grad_norm": 0.09208810329437256,
      "learning_rate": 6.9628069730987855e-06,
      "loss": 0.009,
      "step": 19182
    },
    {
      "epoch": 0.3037351362477635,
      "grad_norm": 0.21745319664478302,
      "learning_rate": 6.962648637522365e-06,
      "loss": 0.0539,
      "step": 19183
    },
    {
      "epoch": 0.30375096980540556,
      "grad_norm": 0.19077420234680176,
      "learning_rate": 6.9624903019459445e-06,
      "loss": 0.0508,
      "step": 19184
    },
    {
      "epoch": 0.3037668033630476,
      "grad_norm": 0.8995605707168579,
      "learning_rate": 6.962331966369524e-06,
      "loss": 0.9672,
      "step": 19185
    },
    {
      "epoch": 0.3037826369206897,
      "grad_norm": 0.40302857756614685,
      "learning_rate": 6.9621736307931035e-06,
      "loss": 0.3339,
      "step": 19186
    },
    {
      "epoch": 0.30379847047833175,
      "grad_norm": 0.5533467531204224,
      "learning_rate": 6.962015295216683e-06,
      "loss": 0.1168,
      "step": 19187
    },
    {
      "epoch": 0.30381430403597387,
      "grad_norm": 0.19764365255832672,
      "learning_rate": 6.961856959640262e-06,
      "loss": 0.0686,
      "step": 19188
    },
    {
      "epoch": 0.30383013759361593,
      "grad_norm": 0.0009324656566604972,
      "learning_rate": 6.961698624063842e-06,
      "loss": 0.0,
      "step": 19189
    },
    {
      "epoch": 0.303845971151258,
      "grad_norm": 0.02840556390583515,
      "learning_rate": 6.961540288487421e-06,
      "loss": 0.0019,
      "step": 19190
    },
    {
      "epoch": 0.30386180470890006,
      "grad_norm": 0.36390143632888794,
      "learning_rate": 6.961381952911001e-06,
      "loss": 0.0334,
      "step": 19191
    },
    {
      "epoch": 0.3038776382665421,
      "grad_norm": 0.24260473251342773,
      "learning_rate": 6.96122361733458e-06,
      "loss": 0.0624,
      "step": 19192
    },
    {
      "epoch": 0.3038934718241842,
      "grad_norm": 0.193902850151062,
      "learning_rate": 6.96106528175816e-06,
      "loss": 0.0457,
      "step": 19193
    },
    {
      "epoch": 0.30390930538182626,
      "grad_norm": 0.304193913936615,
      "learning_rate": 6.960906946181738e-06,
      "loss": 0.0513,
      "step": 19194
    },
    {
      "epoch": 0.3039251389394683,
      "grad_norm": 0.01488577388226986,
      "learning_rate": 6.960748610605318e-06,
      "loss": 0.0008,
      "step": 19195
    },
    {
      "epoch": 0.3039409724971104,
      "grad_norm": 0.6472565531730652,
      "learning_rate": 6.960590275028897e-06,
      "loss": 0.09,
      "step": 19196
    },
    {
      "epoch": 0.30395680605475245,
      "grad_norm": 0.4277704060077667,
      "learning_rate": 6.960431939452477e-06,
      "loss": 0.1068,
      "step": 19197
    },
    {
      "epoch": 0.3039726396123945,
      "grad_norm": 0.41579532623291016,
      "learning_rate": 6.960273603876056e-06,
      "loss": 0.1365,
      "step": 19198
    },
    {
      "epoch": 0.3039884731700366,
      "grad_norm": 0.44214385747909546,
      "learning_rate": 6.960115268299636e-06,
      "loss": 0.2715,
      "step": 19199
    },
    {
      "epoch": 0.30400430672767864,
      "grad_norm": 0.48230263590812683,
      "learning_rate": 6.959956932723214e-06,
      "loss": 0.2431,
      "step": 19200
    },
    {
      "epoch": 0.3040201402853207,
      "grad_norm": 0.006526727229356766,
      "learning_rate": 6.959798597146793e-06,
      "loss": 0.0003,
      "step": 19201
    },
    {
      "epoch": 0.30403597384296277,
      "grad_norm": 0.0133445980027318,
      "learning_rate": 6.959640261570373e-06,
      "loss": 0.0009,
      "step": 19202
    },
    {
      "epoch": 0.30405180740060483,
      "grad_norm": 0.7965412139892578,
      "learning_rate": 6.959481925993952e-06,
      "loss": 0.4968,
      "step": 19203
    },
    {
      "epoch": 0.3040676409582469,
      "grad_norm": 0.4065324068069458,
      "learning_rate": 6.959323590417531e-06,
      "loss": 0.1578,
      "step": 19204
    },
    {
      "epoch": 0.30408347451588896,
      "grad_norm": 0.658831000328064,
      "learning_rate": 6.95916525484111e-06,
      "loss": 0.4798,
      "step": 19205
    },
    {
      "epoch": 0.304099308073531,
      "grad_norm": 0.4583333432674408,
      "learning_rate": 6.95900691926469e-06,
      "loss": 0.095,
      "step": 19206
    },
    {
      "epoch": 0.3041151416311731,
      "grad_norm": 0.3986511528491974,
      "learning_rate": 6.958848583688269e-06,
      "loss": 0.0498,
      "step": 19207
    },
    {
      "epoch": 0.30413097518881516,
      "grad_norm": 0.00043370737694203854,
      "learning_rate": 6.958690248111849e-06,
      "loss": 0.0,
      "step": 19208
    },
    {
      "epoch": 0.3041468087464572,
      "grad_norm": 0.0640421211719513,
      "learning_rate": 6.958531912535427e-06,
      "loss": 0.0041,
      "step": 19209
    },
    {
      "epoch": 0.3041626423040993,
      "grad_norm": 0.4874676764011383,
      "learning_rate": 6.958373576959007e-06,
      "loss": 0.156,
      "step": 19210
    },
    {
      "epoch": 0.30417847586174135,
      "grad_norm": 0.48309797048568726,
      "learning_rate": 6.958215241382586e-06,
      "loss": 0.1897,
      "step": 19211
    },
    {
      "epoch": 0.30419430941938347,
      "grad_norm": 0.048926059156656265,
      "learning_rate": 6.958056905806166e-06,
      "loss": 0.0035,
      "step": 19212
    },
    {
      "epoch": 0.30421014297702553,
      "grad_norm": 0.44317391514778137,
      "learning_rate": 6.957898570229745e-06,
      "loss": 0.065,
      "step": 19213
    },
    {
      "epoch": 0.3042259765346676,
      "grad_norm": 0.3668271601200104,
      "learning_rate": 6.957740234653325e-06,
      "loss": 0.1715,
      "step": 19214
    },
    {
      "epoch": 0.30424181009230966,
      "grad_norm": 0.3442746698856354,
      "learning_rate": 6.957581899076904e-06,
      "loss": 0.0382,
      "step": 19215
    },
    {
      "epoch": 0.3042576436499517,
      "grad_norm": 0.4200734794139862,
      "learning_rate": 6.9574235635004835e-06,
      "loss": 0.0368,
      "step": 19216
    },
    {
      "epoch": 0.3042734772075938,
      "grad_norm": 0.33859217166900635,
      "learning_rate": 6.957265227924063e-06,
      "loss": 0.0528,
      "step": 19217
    },
    {
      "epoch": 0.30428931076523585,
      "grad_norm": 0.2469627559185028,
      "learning_rate": 6.9571068923476425e-06,
      "loss": 0.0717,
      "step": 19218
    },
    {
      "epoch": 0.3043051443228779,
      "grad_norm": 0.7521412968635559,
      "learning_rate": 6.956948556771222e-06,
      "loss": 0.1347,
      "step": 19219
    },
    {
      "epoch": 0.30432097788052,
      "grad_norm": 0.712736189365387,
      "learning_rate": 6.9567902211948015e-06,
      "loss": 0.151,
      "step": 19220
    },
    {
      "epoch": 0.30433681143816205,
      "grad_norm": 0.3192174434661865,
      "learning_rate": 6.95663188561838e-06,
      "loss": 0.0332,
      "step": 19221
    },
    {
      "epoch": 0.3043526449958041,
      "grad_norm": 0.0006795918452553451,
      "learning_rate": 6.95647355004196e-06,
      "loss": 0.0,
      "step": 19222
    },
    {
      "epoch": 0.3043684785534462,
      "grad_norm": 0.5827735066413879,
      "learning_rate": 6.956315214465539e-06,
      "loss": 0.1908,
      "step": 19223
    },
    {
      "epoch": 0.30438431211108824,
      "grad_norm": 0.0006443487945944071,
      "learning_rate": 6.956156878889118e-06,
      "loss": 0.0,
      "step": 19224
    },
    {
      "epoch": 0.3044001456687303,
      "grad_norm": 0.677093505859375,
      "learning_rate": 6.955998543312698e-06,
      "loss": 0.6944,
      "step": 19225
    },
    {
      "epoch": 0.30441597922637237,
      "grad_norm": 0.034637145698070526,
      "learning_rate": 6.955840207736276e-06,
      "loss": 0.0019,
      "step": 19226
    },
    {
      "epoch": 0.30443181278401443,
      "grad_norm": 0.5221208930015564,
      "learning_rate": 6.955681872159856e-06,
      "loss": 0.5435,
      "step": 19227
    },
    {
      "epoch": 0.3044476463416565,
      "grad_norm": 0.3574571907520294,
      "learning_rate": 6.955523536583435e-06,
      "loss": 0.0955,
      "step": 19228
    },
    {
      "epoch": 0.30446347989929856,
      "grad_norm": 0.7211139798164368,
      "learning_rate": 6.955365201007015e-06,
      "loss": 0.5223,
      "step": 19229
    },
    {
      "epoch": 0.3044793134569406,
      "grad_norm": 0.650128185749054,
      "learning_rate": 6.955206865430594e-06,
      "loss": 0.3702,
      "step": 19230
    },
    {
      "epoch": 0.3044951470145827,
      "grad_norm": 0.45990094542503357,
      "learning_rate": 6.955048529854174e-06,
      "loss": 0.2704,
      "step": 19231
    },
    {
      "epoch": 0.30451098057222475,
      "grad_norm": 0.5106555819511414,
      "learning_rate": 6.954890194277752e-06,
      "loss": 0.4076,
      "step": 19232
    },
    {
      "epoch": 0.3045268141298668,
      "grad_norm": 0.0030878453981131315,
      "learning_rate": 6.954731858701332e-06,
      "loss": 0.0001,
      "step": 19233
    },
    {
      "epoch": 0.3045426476875089,
      "grad_norm": 0.21938613057136536,
      "learning_rate": 6.954573523124911e-06,
      "loss": 0.0162,
      "step": 19234
    },
    {
      "epoch": 0.30455848124515095,
      "grad_norm": 0.31004294753074646,
      "learning_rate": 6.954415187548491e-06,
      "loss": 0.1049,
      "step": 19235
    },
    {
      "epoch": 0.30457431480279307,
      "grad_norm": 0.3733612596988678,
      "learning_rate": 6.95425685197207e-06,
      "loss": 0.0495,
      "step": 19236
    },
    {
      "epoch": 0.30459014836043513,
      "grad_norm": 0.22152525186538696,
      "learning_rate": 6.95409851639565e-06,
      "loss": 0.0361,
      "step": 19237
    },
    {
      "epoch": 0.3046059819180772,
      "grad_norm": 0.00917397066950798,
      "learning_rate": 6.953940180819228e-06,
      "loss": 0.0006,
      "step": 19238
    },
    {
      "epoch": 0.30462181547571926,
      "grad_norm": 0.014694981276988983,
      "learning_rate": 6.953781845242808e-06,
      "loss": 0.0006,
      "step": 19239
    },
    {
      "epoch": 0.3046376490333613,
      "grad_norm": 0.04240335896611214,
      "learning_rate": 6.953623509666387e-06,
      "loss": 0.0027,
      "step": 19240
    },
    {
      "epoch": 0.3046534825910034,
      "grad_norm": 0.7119972109794617,
      "learning_rate": 6.953465174089967e-06,
      "loss": 0.1606,
      "step": 19241
    },
    {
      "epoch": 0.30466931614864545,
      "grad_norm": 0.03217020630836487,
      "learning_rate": 6.953306838513546e-06,
      "loss": 0.0017,
      "step": 19242
    },
    {
      "epoch": 0.3046851497062875,
      "grad_norm": 0.0029462880920618773,
      "learning_rate": 6.953148502937126e-06,
      "loss": 0.0001,
      "step": 19243
    },
    {
      "epoch": 0.3047009832639296,
      "grad_norm": 0.0008275544387288392,
      "learning_rate": 6.9529901673607045e-06,
      "loss": 0.0,
      "step": 19244
    },
    {
      "epoch": 0.30471681682157165,
      "grad_norm": 0.8440592885017395,
      "learning_rate": 6.9528318317842844e-06,
      "loss": 0.1966,
      "step": 19245
    },
    {
      "epoch": 0.3047326503792137,
      "grad_norm": 0.22225460410118103,
      "learning_rate": 6.9526734962078635e-06,
      "loss": 0.0663,
      "step": 19246
    },
    {
      "epoch": 0.3047484839368558,
      "grad_norm": 0.2088804990053177,
      "learning_rate": 6.9525151606314434e-06,
      "loss": 0.05,
      "step": 19247
    },
    {
      "epoch": 0.30476431749449784,
      "grad_norm": 0.022552646696567535,
      "learning_rate": 6.9523568250550225e-06,
      "loss": 0.0011,
      "step": 19248
    },
    {
      "epoch": 0.3047801510521399,
      "grad_norm": 0.6616005301475525,
      "learning_rate": 6.952198489478601e-06,
      "loss": 0.2399,
      "step": 19249
    },
    {
      "epoch": 0.30479598460978197,
      "grad_norm": 0.5296401381492615,
      "learning_rate": 6.952040153902181e-06,
      "loss": 0.1169,
      "step": 19250
    },
    {
      "epoch": 0.30481181816742403,
      "grad_norm": 0.6327098608016968,
      "learning_rate": 6.95188181832576e-06,
      "loss": 0.233,
      "step": 19251
    },
    {
      "epoch": 0.3048276517250661,
      "grad_norm": 0.025036415085196495,
      "learning_rate": 6.95172348274934e-06,
      "loss": 0.0013,
      "step": 19252
    },
    {
      "epoch": 0.30484348528270816,
      "grad_norm": 0.23751471936702728,
      "learning_rate": 6.951565147172919e-06,
      "loss": 0.0583,
      "step": 19253
    },
    {
      "epoch": 0.3048593188403502,
      "grad_norm": 0.5376972556114197,
      "learning_rate": 6.951406811596499e-06,
      "loss": 0.1004,
      "step": 19254
    },
    {
      "epoch": 0.3048751523979923,
      "grad_norm": 0.5156146883964539,
      "learning_rate": 6.951248476020077e-06,
      "loss": 0.0685,
      "step": 19255
    },
    {
      "epoch": 0.30489098595563435,
      "grad_norm": 0.0673283040523529,
      "learning_rate": 6.951090140443657e-06,
      "loss": 0.0032,
      "step": 19256
    },
    {
      "epoch": 0.3049068195132764,
      "grad_norm": 0.47302621603012085,
      "learning_rate": 6.950931804867236e-06,
      "loss": 0.1057,
      "step": 19257
    },
    {
      "epoch": 0.3049226530709185,
      "grad_norm": 0.35068878531455994,
      "learning_rate": 6.950773469290816e-06,
      "loss": 0.0824,
      "step": 19258
    },
    {
      "epoch": 0.30493848662856055,
      "grad_norm": 0.01728546805679798,
      "learning_rate": 6.950615133714395e-06,
      "loss": 0.0007,
      "step": 19259
    },
    {
      "epoch": 0.30495432018620267,
      "grad_norm": 0.005141456611454487,
      "learning_rate": 6.950456798137975e-06,
      "loss": 0.0001,
      "step": 19260
    },
    {
      "epoch": 0.30497015374384473,
      "grad_norm": 0.012640019878745079,
      "learning_rate": 6.950298462561553e-06,
      "loss": 0.0006,
      "step": 19261
    },
    {
      "epoch": 0.3049859873014868,
      "grad_norm": 0.01143060252070427,
      "learning_rate": 6.950140126985133e-06,
      "loss": 0.0004,
      "step": 19262
    },
    {
      "epoch": 0.30500182085912886,
      "grad_norm": 0.00021463567099999636,
      "learning_rate": 6.949981791408712e-06,
      "loss": 0.0,
      "step": 19263
    },
    {
      "epoch": 0.3050176544167709,
      "grad_norm": 0.3420015871524811,
      "learning_rate": 6.949823455832292e-06,
      "loss": 0.1318,
      "step": 19264
    },
    {
      "epoch": 0.305033487974413,
      "grad_norm": 0.033380214124917984,
      "learning_rate": 6.949665120255871e-06,
      "loss": 0.0008,
      "step": 19265
    },
    {
      "epoch": 0.30504932153205505,
      "grad_norm": 0.6294679641723633,
      "learning_rate": 6.949506784679451e-06,
      "loss": 0.1192,
      "step": 19266
    },
    {
      "epoch": 0.3050651550896971,
      "grad_norm": 0.7444490790367126,
      "learning_rate": 6.949348449103029e-06,
      "loss": 0.256,
      "step": 19267
    },
    {
      "epoch": 0.3050809886473392,
      "grad_norm": 0.5163825154304504,
      "learning_rate": 6.949190113526609e-06,
      "loss": 0.0307,
      "step": 19268
    },
    {
      "epoch": 0.30509682220498124,
      "grad_norm": 0.4816166162490845,
      "learning_rate": 6.949031777950188e-06,
      "loss": 0.0896,
      "step": 19269
    },
    {
      "epoch": 0.3051126557626233,
      "grad_norm": 0.37027987837791443,
      "learning_rate": 6.948873442373768e-06,
      "loss": 0.1965,
      "step": 19270
    },
    {
      "epoch": 0.3051284893202654,
      "grad_norm": 0.00018126035865861923,
      "learning_rate": 6.9487151067973464e-06,
      "loss": 0.0,
      "step": 19271
    },
    {
      "epoch": 0.30514432287790744,
      "grad_norm": 0.004899135325103998,
      "learning_rate": 6.9485567712209255e-06,
      "loss": 0.0002,
      "step": 19272
    },
    {
      "epoch": 0.3051601564355495,
      "grad_norm": 0.1590028703212738,
      "learning_rate": 6.9483984356445054e-06,
      "loss": 0.0458,
      "step": 19273
    },
    {
      "epoch": 0.30517598999319157,
      "grad_norm": 0.009534267708659172,
      "learning_rate": 6.9482401000680845e-06,
      "loss": 0.0004,
      "step": 19274
    },
    {
      "epoch": 0.30519182355083363,
      "grad_norm": 0.0023407340049743652,
      "learning_rate": 6.9480817644916644e-06,
      "loss": 0.0,
      "step": 19275
    },
    {
      "epoch": 0.3052076571084757,
      "grad_norm": 0.37992867827415466,
      "learning_rate": 6.947923428915243e-06,
      "loss": 0.0665,
      "step": 19276
    },
    {
      "epoch": 0.30522349066611776,
      "grad_norm": 0.026067109778523445,
      "learning_rate": 6.947765093338823e-06,
      "loss": 0.0012,
      "step": 19277
    },
    {
      "epoch": 0.3052393242237598,
      "grad_norm": 0.04376939311623573,
      "learning_rate": 6.947606757762402e-06,
      "loss": 0.0026,
      "step": 19278
    },
    {
      "epoch": 0.3052551577814019,
      "grad_norm": 0.630053699016571,
      "learning_rate": 6.947448422185982e-06,
      "loss": 0.1894,
      "step": 19279
    },
    {
      "epoch": 0.30527099133904395,
      "grad_norm": 0.26508593559265137,
      "learning_rate": 6.947290086609561e-06,
      "loss": 0.0807,
      "step": 19280
    },
    {
      "epoch": 0.305286824896686,
      "grad_norm": 0.02656867541372776,
      "learning_rate": 6.947131751033141e-06,
      "loss": 0.0015,
      "step": 19281
    },
    {
      "epoch": 0.3053026584543281,
      "grad_norm": 0.0038899159990251064,
      "learning_rate": 6.946973415456719e-06,
      "loss": 0.0001,
      "step": 19282
    },
    {
      "epoch": 0.30531849201197014,
      "grad_norm": 0.6809464693069458,
      "learning_rate": 6.946815079880299e-06,
      "loss": 0.1222,
      "step": 19283
    },
    {
      "epoch": 0.30533432556961226,
      "grad_norm": 0.6011870503425598,
      "learning_rate": 6.946656744303878e-06,
      "loss": 0.0571,
      "step": 19284
    },
    {
      "epoch": 0.30535015912725433,
      "grad_norm": 0.530333399772644,
      "learning_rate": 6.946498408727458e-06,
      "loss": 0.1734,
      "step": 19285
    },
    {
      "epoch": 0.3053659926848964,
      "grad_norm": 0.012887279503047466,
      "learning_rate": 6.946340073151037e-06,
      "loss": 0.0005,
      "step": 19286
    },
    {
      "epoch": 0.30538182624253846,
      "grad_norm": 0.3086054027080536,
      "learning_rate": 6.946181737574617e-06,
      "loss": 0.0789,
      "step": 19287
    },
    {
      "epoch": 0.3053976598001805,
      "grad_norm": 0.31526580452919006,
      "learning_rate": 6.946023401998195e-06,
      "loss": 0.115,
      "step": 19288
    },
    {
      "epoch": 0.3054134933578226,
      "grad_norm": 0.49257659912109375,
      "learning_rate": 6.945865066421775e-06,
      "loss": 0.2171,
      "step": 19289
    },
    {
      "epoch": 0.30542932691546465,
      "grad_norm": 0.16480781137943268,
      "learning_rate": 6.945706730845354e-06,
      "loss": 0.0044,
      "step": 19290
    },
    {
      "epoch": 0.3054451604731067,
      "grad_norm": 0.024384068325161934,
      "learning_rate": 6.945548395268934e-06,
      "loss": 0.0012,
      "step": 19291
    },
    {
      "epoch": 0.3054609940307488,
      "grad_norm": 0.17963561415672302,
      "learning_rate": 6.945390059692513e-06,
      "loss": 0.054,
      "step": 19292
    },
    {
      "epoch": 0.30547682758839084,
      "grad_norm": 0.01431901752948761,
      "learning_rate": 6.945231724116093e-06,
      "loss": 0.0007,
      "step": 19293
    },
    {
      "epoch": 0.3054926611460329,
      "grad_norm": 0.0006691713351756334,
      "learning_rate": 6.945073388539671e-06,
      "loss": 0.0,
      "step": 19294
    },
    {
      "epoch": 0.30550849470367497,
      "grad_norm": 0.0016804509796202183,
      "learning_rate": 6.944915052963251e-06,
      "loss": 0.0001,
      "step": 19295
    },
    {
      "epoch": 0.30552432826131704,
      "grad_norm": 0.01794421300292015,
      "learning_rate": 6.94475671738683e-06,
      "loss": 0.001,
      "step": 19296
    },
    {
      "epoch": 0.3055401618189591,
      "grad_norm": 0.6264178156852722,
      "learning_rate": 6.944598381810409e-06,
      "loss": 0.244,
      "step": 19297
    },
    {
      "epoch": 0.30555599537660116,
      "grad_norm": 0.17388096451759338,
      "learning_rate": 6.944440046233989e-06,
      "loss": 0.0031,
      "step": 19298
    },
    {
      "epoch": 0.30557182893424323,
      "grad_norm": 0.2708262801170349,
      "learning_rate": 6.9442817106575674e-06,
      "loss": 0.0636,
      "step": 19299
    },
    {
      "epoch": 0.3055876624918853,
      "grad_norm": 0.026951579377055168,
      "learning_rate": 6.944123375081147e-06,
      "loss": 0.0017,
      "step": 19300
    },
    {
      "epoch": 0.30560349604952736,
      "grad_norm": 0.5107987523078918,
      "learning_rate": 6.9439650395047264e-06,
      "loss": 0.1786,
      "step": 19301
    },
    {
      "epoch": 0.3056193296071694,
      "grad_norm": 0.20700034499168396,
      "learning_rate": 6.943806703928306e-06,
      "loss": 0.0487,
      "step": 19302
    },
    {
      "epoch": 0.3056351631648115,
      "grad_norm": 0.08422883599996567,
      "learning_rate": 6.9436483683518855e-06,
      "loss": 0.0146,
      "step": 19303
    },
    {
      "epoch": 0.30565099672245355,
      "grad_norm": 0.22715793550014496,
      "learning_rate": 6.943490032775465e-06,
      "loss": 0.0363,
      "step": 19304
    },
    {
      "epoch": 0.3056668302800956,
      "grad_norm": 0.7498722076416016,
      "learning_rate": 6.943331697199044e-06,
      "loss": 0.2174,
      "step": 19305
    },
    {
      "epoch": 0.3056826638377377,
      "grad_norm": 0.2846529185771942,
      "learning_rate": 6.9431733616226235e-06,
      "loss": 0.1081,
      "step": 19306
    },
    {
      "epoch": 0.30569849739537974,
      "grad_norm": 0.6000903248786926,
      "learning_rate": 6.943015026046203e-06,
      "loss": 0.0998,
      "step": 19307
    },
    {
      "epoch": 0.30571433095302186,
      "grad_norm": 0.5649402737617493,
      "learning_rate": 6.9428566904697825e-06,
      "loss": 0.1355,
      "step": 19308
    },
    {
      "epoch": 0.3057301645106639,
      "grad_norm": 0.8567384481430054,
      "learning_rate": 6.942698354893362e-06,
      "loss": 0.2474,
      "step": 19309
    },
    {
      "epoch": 0.305745998068306,
      "grad_norm": 0.4071342945098877,
      "learning_rate": 6.9425400193169415e-06,
      "loss": 0.0388,
      "step": 19310
    },
    {
      "epoch": 0.30576183162594806,
      "grad_norm": 0.041034769266843796,
      "learning_rate": 6.94238168374052e-06,
      "loss": 0.0015,
      "step": 19311
    },
    {
      "epoch": 0.3057776651835901,
      "grad_norm": 0.7131404876708984,
      "learning_rate": 6.9422233481641e-06,
      "loss": 0.3199,
      "step": 19312
    },
    {
      "epoch": 0.3057934987412322,
      "grad_norm": 0.3174864649772644,
      "learning_rate": 6.942065012587679e-06,
      "loss": 0.0575,
      "step": 19313
    },
    {
      "epoch": 0.30580933229887425,
      "grad_norm": 0.4319605827331543,
      "learning_rate": 6.941906677011259e-06,
      "loss": 0.1857,
      "step": 19314
    },
    {
      "epoch": 0.3058251658565163,
      "grad_norm": 0.2435554563999176,
      "learning_rate": 6.941748341434838e-06,
      "loss": 0.0839,
      "step": 19315
    },
    {
      "epoch": 0.3058409994141584,
      "grad_norm": 0.42621108889579773,
      "learning_rate": 6.941590005858418e-06,
      "loss": 0.0627,
      "step": 19316
    },
    {
      "epoch": 0.30585683297180044,
      "grad_norm": 0.01093223225325346,
      "learning_rate": 6.941431670281996e-06,
      "loss": 0.0007,
      "step": 19317
    },
    {
      "epoch": 0.3058726665294425,
      "grad_norm": 0.6063268184661865,
      "learning_rate": 6.941273334705576e-06,
      "loss": 0.1102,
      "step": 19318
    },
    {
      "epoch": 0.30588850008708457,
      "grad_norm": 0.8554184436798096,
      "learning_rate": 6.941114999129155e-06,
      "loss": 0.361,
      "step": 19319
    },
    {
      "epoch": 0.30590433364472663,
      "grad_norm": 0.055069003254175186,
      "learning_rate": 6.940956663552735e-06,
      "loss": 0.0032,
      "step": 19320
    },
    {
      "epoch": 0.3059201672023687,
      "grad_norm": 0.37010133266448975,
      "learning_rate": 6.940798327976314e-06,
      "loss": 0.188,
      "step": 19321
    },
    {
      "epoch": 0.30593600076001076,
      "grad_norm": 0.18161413073539734,
      "learning_rate": 6.940639992399892e-06,
      "loss": 0.0459,
      "step": 19322
    },
    {
      "epoch": 0.3059518343176528,
      "grad_norm": 0.3917936086654663,
      "learning_rate": 6.940481656823472e-06,
      "loss": 0.0691,
      "step": 19323
    },
    {
      "epoch": 0.3059676678752949,
      "grad_norm": 0.7466856837272644,
      "learning_rate": 6.940323321247051e-06,
      "loss": 0.1327,
      "step": 19324
    },
    {
      "epoch": 0.30598350143293696,
      "grad_norm": 0.6928231120109558,
      "learning_rate": 6.940164985670631e-06,
      "loss": 0.7808,
      "step": 19325
    },
    {
      "epoch": 0.305999334990579,
      "grad_norm": 0.19093334674835205,
      "learning_rate": 6.94000665009421e-06,
      "loss": 0.0527,
      "step": 19326
    },
    {
      "epoch": 0.3060151685482211,
      "grad_norm": 0.0004618744133040309,
      "learning_rate": 6.93984831451779e-06,
      "loss": 0.0,
      "step": 19327
    },
    {
      "epoch": 0.30603100210586315,
      "grad_norm": 0.22680269181728363,
      "learning_rate": 6.939689978941368e-06,
      "loss": 0.0883,
      "step": 19328
    },
    {
      "epoch": 0.3060468356635052,
      "grad_norm": 0.21562530100345612,
      "learning_rate": 6.939531643364948e-06,
      "loss": 0.095,
      "step": 19329
    },
    {
      "epoch": 0.3060626692211473,
      "grad_norm": 0.4583975374698639,
      "learning_rate": 6.939373307788527e-06,
      "loss": 0.1754,
      "step": 19330
    },
    {
      "epoch": 0.30607850277878934,
      "grad_norm": 0.33039015531539917,
      "learning_rate": 6.939214972212107e-06,
      "loss": 0.0799,
      "step": 19331
    },
    {
      "epoch": 0.3060943363364314,
      "grad_norm": 0.33079367876052856,
      "learning_rate": 6.939056636635686e-06,
      "loss": 0.0374,
      "step": 19332
    },
    {
      "epoch": 0.3061101698940735,
      "grad_norm": 0.05613997206091881,
      "learning_rate": 6.9388983010592655e-06,
      "loss": 0.0012,
      "step": 19333
    },
    {
      "epoch": 0.3061260034517156,
      "grad_norm": 0.2653467655181885,
      "learning_rate": 6.9387399654828445e-06,
      "loss": 0.0667,
      "step": 19334
    },
    {
      "epoch": 0.30614183700935765,
      "grad_norm": 0.27900898456573486,
      "learning_rate": 6.9385816299064245e-06,
      "loss": 0.1065,
      "step": 19335
    },
    {
      "epoch": 0.3061576705669997,
      "grad_norm": 0.0003963705967180431,
      "learning_rate": 6.9384232943300035e-06,
      "loss": 0.0,
      "step": 19336
    },
    {
      "epoch": 0.3061735041246418,
      "grad_norm": 0.002656765514984727,
      "learning_rate": 6.9382649587535835e-06,
      "loss": 0.0001,
      "step": 19337
    },
    {
      "epoch": 0.30618933768228385,
      "grad_norm": 0.5388925671577454,
      "learning_rate": 6.938106623177162e-06,
      "loss": 0.155,
      "step": 19338
    },
    {
      "epoch": 0.3062051712399259,
      "grad_norm": 0.2961188852787018,
      "learning_rate": 6.937948287600742e-06,
      "loss": 0.0499,
      "step": 19339
    },
    {
      "epoch": 0.306221004797568,
      "grad_norm": 1.0377360582351685,
      "learning_rate": 6.937789952024321e-06,
      "loss": 0.8329,
      "step": 19340
    },
    {
      "epoch": 0.30623683835521004,
      "grad_norm": 0.7058069705963135,
      "learning_rate": 6.937631616447901e-06,
      "loss": 0.2957,
      "step": 19341
    },
    {
      "epoch": 0.3062526719128521,
      "grad_norm": 0.20481392741203308,
      "learning_rate": 6.93747328087148e-06,
      "loss": 0.0195,
      "step": 19342
    },
    {
      "epoch": 0.30626850547049417,
      "grad_norm": 0.7333935499191284,
      "learning_rate": 6.93731494529506e-06,
      "loss": 0.4369,
      "step": 19343
    },
    {
      "epoch": 0.30628433902813623,
      "grad_norm": 0.19868485629558563,
      "learning_rate": 6.937156609718638e-06,
      "loss": 0.027,
      "step": 19344
    },
    {
      "epoch": 0.3063001725857783,
      "grad_norm": 0.615943193435669,
      "learning_rate": 6.936998274142217e-06,
      "loss": 0.2647,
      "step": 19345
    },
    {
      "epoch": 0.30631600614342036,
      "grad_norm": 0.7192354798316956,
      "learning_rate": 6.936839938565797e-06,
      "loss": 0.4377,
      "step": 19346
    },
    {
      "epoch": 0.3063318397010624,
      "grad_norm": 0.0014227170031517744,
      "learning_rate": 6.936681602989376e-06,
      "loss": 0.0,
      "step": 19347
    },
    {
      "epoch": 0.3063476732587045,
      "grad_norm": 0.39525091648101807,
      "learning_rate": 6.936523267412956e-06,
      "loss": 0.0438,
      "step": 19348
    },
    {
      "epoch": 0.30636350681634655,
      "grad_norm": 0.26432493329048157,
      "learning_rate": 6.936364931836534e-06,
      "loss": 0.1271,
      "step": 19349
    },
    {
      "epoch": 0.3063793403739886,
      "grad_norm": 0.009435009211301804,
      "learning_rate": 6.936206596260114e-06,
      "loss": 0.0004,
      "step": 19350
    },
    {
      "epoch": 0.3063951739316307,
      "grad_norm": 0.0002911709889303893,
      "learning_rate": 6.936048260683693e-06,
      "loss": 0.0,
      "step": 19351
    },
    {
      "epoch": 0.30641100748927275,
      "grad_norm": 0.2345944344997406,
      "learning_rate": 6.935889925107273e-06,
      "loss": 0.1298,
      "step": 19352
    },
    {
      "epoch": 0.3064268410469148,
      "grad_norm": 0.37795311212539673,
      "learning_rate": 6.935731589530852e-06,
      "loss": 0.0946,
      "step": 19353
    },
    {
      "epoch": 0.3064426746045569,
      "grad_norm": 0.05757710337638855,
      "learning_rate": 6.935573253954432e-06,
      "loss": 0.0011,
      "step": 19354
    },
    {
      "epoch": 0.30645850816219894,
      "grad_norm": 0.5968789458274841,
      "learning_rate": 6.93541491837801e-06,
      "loss": 0.322,
      "step": 19355
    },
    {
      "epoch": 0.306474341719841,
      "grad_norm": 0.08060391992330551,
      "learning_rate": 6.93525658280159e-06,
      "loss": 0.0051,
      "step": 19356
    },
    {
      "epoch": 0.3064901752774831,
      "grad_norm": 0.00012762154801748693,
      "learning_rate": 6.935098247225169e-06,
      "loss": 0.0,
      "step": 19357
    },
    {
      "epoch": 0.3065060088351252,
      "grad_norm": 0.12817256152629852,
      "learning_rate": 6.934939911648749e-06,
      "loss": 0.015,
      "step": 19358
    },
    {
      "epoch": 0.30652184239276725,
      "grad_norm": 0.6095711588859558,
      "learning_rate": 6.934781576072328e-06,
      "loss": 0.7008,
      "step": 19359
    },
    {
      "epoch": 0.3065376759504093,
      "grad_norm": 0.3853283226490021,
      "learning_rate": 6.934623240495908e-06,
      "loss": 0.1018,
      "step": 19360
    },
    {
      "epoch": 0.3065535095080514,
      "grad_norm": 0.6948893070220947,
      "learning_rate": 6.9344649049194865e-06,
      "loss": 0.1272,
      "step": 19361
    },
    {
      "epoch": 0.30656934306569344,
      "grad_norm": 0.0016293416265398264,
      "learning_rate": 6.934306569343066e-06,
      "loss": 0.0001,
      "step": 19362
    },
    {
      "epoch": 0.3065851766233355,
      "grad_norm": 0.14751723408699036,
      "learning_rate": 6.9341482337666455e-06,
      "loss": 0.0071,
      "step": 19363
    },
    {
      "epoch": 0.3066010101809776,
      "grad_norm": 0.6865794658660889,
      "learning_rate": 6.933989898190225e-06,
      "loss": 0.1537,
      "step": 19364
    },
    {
      "epoch": 0.30661684373861964,
      "grad_norm": 0.007597635500133038,
      "learning_rate": 6.9338315626138045e-06,
      "loss": 0.0004,
      "step": 19365
    },
    {
      "epoch": 0.3066326772962617,
      "grad_norm": 0.5860832929611206,
      "learning_rate": 6.933673227037384e-06,
      "loss": 0.2385,
      "step": 19366
    },
    {
      "epoch": 0.30664851085390377,
      "grad_norm": 0.1589185893535614,
      "learning_rate": 6.933514891460963e-06,
      "loss": 0.0207,
      "step": 19367
    },
    {
      "epoch": 0.30666434441154583,
      "grad_norm": 0.3470783233642578,
      "learning_rate": 6.9333565558845426e-06,
      "loss": 0.1236,
      "step": 19368
    },
    {
      "epoch": 0.3066801779691879,
      "grad_norm": 0.3719140589237213,
      "learning_rate": 6.933198220308122e-06,
      "loss": 0.184,
      "step": 19369
    },
    {
      "epoch": 0.30669601152682996,
      "grad_norm": 0.2243606001138687,
      "learning_rate": 6.933039884731701e-06,
      "loss": 0.0354,
      "step": 19370
    },
    {
      "epoch": 0.306711845084472,
      "grad_norm": 0.5928065180778503,
      "learning_rate": 6.932881549155281e-06,
      "loss": 0.0529,
      "step": 19371
    },
    {
      "epoch": 0.3067276786421141,
      "grad_norm": 0.19588883221149445,
      "learning_rate": 6.932723213578859e-06,
      "loss": 0.0465,
      "step": 19372
    },
    {
      "epoch": 0.30674351219975615,
      "grad_norm": 0.3698481619358063,
      "learning_rate": 6.932564878002439e-06,
      "loss": 0.1677,
      "step": 19373
    },
    {
      "epoch": 0.3067593457573982,
      "grad_norm": 0.3133384883403778,
      "learning_rate": 6.932406542426018e-06,
      "loss": 0.1124,
      "step": 19374
    },
    {
      "epoch": 0.3067751793150403,
      "grad_norm": 0.1845765858888626,
      "learning_rate": 6.932248206849598e-06,
      "loss": 0.0124,
      "step": 19375
    },
    {
      "epoch": 0.30679101287268234,
      "grad_norm": 0.6064523458480835,
      "learning_rate": 6.932089871273177e-06,
      "loss": 0.0731,
      "step": 19376
    },
    {
      "epoch": 0.3068068464303244,
      "grad_norm": 0.4017447233200073,
      "learning_rate": 6.931931535696757e-06,
      "loss": 0.0633,
      "step": 19377
    },
    {
      "epoch": 0.3068226799879665,
      "grad_norm": 0.01525927521288395,
      "learning_rate": 6.931773200120335e-06,
      "loss": 0.0008,
      "step": 19378
    },
    {
      "epoch": 0.30683851354560854,
      "grad_norm": 1.3752330541610718,
      "learning_rate": 6.931614864543915e-06,
      "loss": 0.2499,
      "step": 19379
    },
    {
      "epoch": 0.3068543471032506,
      "grad_norm": 0.19681496918201447,
      "learning_rate": 6.931456528967494e-06,
      "loss": 0.1014,
      "step": 19380
    },
    {
      "epoch": 0.3068701806608927,
      "grad_norm": 0.5396381616592407,
      "learning_rate": 6.931298193391074e-06,
      "loss": 0.1783,
      "step": 19381
    },
    {
      "epoch": 0.3068860142185348,
      "grad_norm": 0.0009036150295287371,
      "learning_rate": 6.931139857814653e-06,
      "loss": 0.0,
      "step": 19382
    },
    {
      "epoch": 0.30690184777617685,
      "grad_norm": 0.019052373245358467,
      "learning_rate": 6.930981522238233e-06,
      "loss": 0.0011,
      "step": 19383
    },
    {
      "epoch": 0.3069176813338189,
      "grad_norm": 0.0015421390999108553,
      "learning_rate": 6.930823186661811e-06,
      "loss": 0.0,
      "step": 19384
    },
    {
      "epoch": 0.306933514891461,
      "grad_norm": 0.45354601740837097,
      "learning_rate": 6.930664851085391e-06,
      "loss": 0.2022,
      "step": 19385
    },
    {
      "epoch": 0.30694934844910304,
      "grad_norm": 0.31939786672592163,
      "learning_rate": 6.93050651550897e-06,
      "loss": 0.1674,
      "step": 19386
    },
    {
      "epoch": 0.3069651820067451,
      "grad_norm": 0.7256954908370972,
      "learning_rate": 6.93034817993255e-06,
      "loss": 0.6054,
      "step": 19387
    },
    {
      "epoch": 0.30698101556438717,
      "grad_norm": 0.7775775194168091,
      "learning_rate": 6.930189844356129e-06,
      "loss": 0.6809,
      "step": 19388
    },
    {
      "epoch": 0.30699684912202924,
      "grad_norm": 1.2641955614089966,
      "learning_rate": 6.930031508779709e-06,
      "loss": 0.3469,
      "step": 19389
    },
    {
      "epoch": 0.3070126826796713,
      "grad_norm": 0.21829143166542053,
      "learning_rate": 6.929873173203287e-06,
      "loss": 0.0239,
      "step": 19390
    },
    {
      "epoch": 0.30702851623731336,
      "grad_norm": 0.27136868238449097,
      "learning_rate": 6.929714837626867e-06,
      "loss": 0.0531,
      "step": 19391
    },
    {
      "epoch": 0.30704434979495543,
      "grad_norm": 0.7422367930412292,
      "learning_rate": 6.929556502050446e-06,
      "loss": 0.2069,
      "step": 19392
    },
    {
      "epoch": 0.3070601833525975,
      "grad_norm": 0.4668513834476471,
      "learning_rate": 6.9293981664740255e-06,
      "loss": 0.0258,
      "step": 19393
    },
    {
      "epoch": 0.30707601691023956,
      "grad_norm": 0.7367837429046631,
      "learning_rate": 6.929239830897605e-06,
      "loss": 0.1258,
      "step": 19394
    },
    {
      "epoch": 0.3070918504678816,
      "grad_norm": 0.26121869683265686,
      "learning_rate": 6.929081495321184e-06,
      "loss": 0.0477,
      "step": 19395
    },
    {
      "epoch": 0.3071076840255237,
      "grad_norm": 0.8948801755905151,
      "learning_rate": 6.9289231597447636e-06,
      "loss": 0.5335,
      "step": 19396
    },
    {
      "epoch": 0.30712351758316575,
      "grad_norm": 0.37441927194595337,
      "learning_rate": 6.928764824168343e-06,
      "loss": 0.1332,
      "step": 19397
    },
    {
      "epoch": 0.3071393511408078,
      "grad_norm": 0.03674860671162605,
      "learning_rate": 6.9286064885919226e-06,
      "loss": 0.0028,
      "step": 19398
    },
    {
      "epoch": 0.3071551846984499,
      "grad_norm": 0.2824968695640564,
      "learning_rate": 6.928448153015501e-06,
      "loss": 0.0345,
      "step": 19399
    },
    {
      "epoch": 0.30717101825609194,
      "grad_norm": 0.5469462871551514,
      "learning_rate": 6.928289817439081e-06,
      "loss": 0.0155,
      "step": 19400
    },
    {
      "epoch": 0.307186851813734,
      "grad_norm": 0.20374943315982819,
      "learning_rate": 6.92813148186266e-06,
      "loss": 0.0678,
      "step": 19401
    },
    {
      "epoch": 0.30720268537137607,
      "grad_norm": 0.2965341806411743,
      "learning_rate": 6.92797314628624e-06,
      "loss": 0.0817,
      "step": 19402
    },
    {
      "epoch": 0.30721851892901814,
      "grad_norm": 0.012263310141861439,
      "learning_rate": 6.927814810709819e-06,
      "loss": 0.0005,
      "step": 19403
    },
    {
      "epoch": 0.3072343524866602,
      "grad_norm": 0.011680000461637974,
      "learning_rate": 6.927656475133399e-06,
      "loss": 0.0006,
      "step": 19404
    },
    {
      "epoch": 0.3072501860443023,
      "grad_norm": 0.0007732496596872807,
      "learning_rate": 6.927498139556977e-06,
      "loss": 0.0,
      "step": 19405
    },
    {
      "epoch": 0.3072660196019444,
      "grad_norm": 0.17947839200496674,
      "learning_rate": 6.927339803980557e-06,
      "loss": 0.0124,
      "step": 19406
    },
    {
      "epoch": 0.30728185315958645,
      "grad_norm": 0.20117154717445374,
      "learning_rate": 6.927181468404136e-06,
      "loss": 0.0678,
      "step": 19407
    },
    {
      "epoch": 0.3072976867172285,
      "grad_norm": 0.105173259973526,
      "learning_rate": 6.927023132827716e-06,
      "loss": 0.0029,
      "step": 19408
    },
    {
      "epoch": 0.3073135202748706,
      "grad_norm": 0.2929633557796478,
      "learning_rate": 6.926864797251295e-06,
      "loss": 0.0354,
      "step": 19409
    },
    {
      "epoch": 0.30732935383251264,
      "grad_norm": 0.0022738827392458916,
      "learning_rate": 6.926706461674875e-06,
      "loss": 0.0001,
      "step": 19410
    },
    {
      "epoch": 0.3073451873901547,
      "grad_norm": 0.013944375328719616,
      "learning_rate": 6.926548126098453e-06,
      "loss": 0.0007,
      "step": 19411
    },
    {
      "epoch": 0.30736102094779677,
      "grad_norm": 0.05926991254091263,
      "learning_rate": 6.926389790522033e-06,
      "loss": 0.0027,
      "step": 19412
    },
    {
      "epoch": 0.30737685450543883,
      "grad_norm": 0.6687424778938293,
      "learning_rate": 6.926231454945612e-06,
      "loss": 0.2452,
      "step": 19413
    },
    {
      "epoch": 0.3073926880630809,
      "grad_norm": 0.00047784295747987926,
      "learning_rate": 6.926073119369192e-06,
      "loss": 0.0,
      "step": 19414
    },
    {
      "epoch": 0.30740852162072296,
      "grad_norm": 0.49059897661209106,
      "learning_rate": 6.925914783792771e-06,
      "loss": 0.1615,
      "step": 19415
    },
    {
      "epoch": 0.307424355178365,
      "grad_norm": 0.6540683507919312,
      "learning_rate": 6.925756448216351e-06,
      "loss": 0.2679,
      "step": 19416
    },
    {
      "epoch": 0.3074401887360071,
      "grad_norm": 0.7507897019386292,
      "learning_rate": 6.925598112639929e-06,
      "loss": 0.178,
      "step": 19417
    },
    {
      "epoch": 0.30745602229364916,
      "grad_norm": 0.22838470339775085,
      "learning_rate": 6.925439777063508e-06,
      "loss": 0.0133,
      "step": 19418
    },
    {
      "epoch": 0.3074718558512912,
      "grad_norm": 0.022250937297940254,
      "learning_rate": 6.925281441487088e-06,
      "loss": 0.0013,
      "step": 19419
    },
    {
      "epoch": 0.3074876894089333,
      "grad_norm": 0.08421588689088821,
      "learning_rate": 6.925123105910667e-06,
      "loss": 0.003,
      "step": 19420
    },
    {
      "epoch": 0.30750352296657535,
      "grad_norm": 0.26918259263038635,
      "learning_rate": 6.924964770334247e-06,
      "loss": 0.0079,
      "step": 19421
    },
    {
      "epoch": 0.3075193565242174,
      "grad_norm": 0.07277832180261612,
      "learning_rate": 6.9248064347578256e-06,
      "loss": 0.0022,
      "step": 19422
    },
    {
      "epoch": 0.3075351900818595,
      "grad_norm": 0.015092093497514725,
      "learning_rate": 6.9246480991814055e-06,
      "loss": 0.0009,
      "step": 19423
    },
    {
      "epoch": 0.30755102363950154,
      "grad_norm": 0.33884623646736145,
      "learning_rate": 6.9244897636049846e-06,
      "loss": 0.0631,
      "step": 19424
    },
    {
      "epoch": 0.3075668571971436,
      "grad_norm": 0.5671746730804443,
      "learning_rate": 6.9243314280285645e-06,
      "loss": 0.2161,
      "step": 19425
    },
    {
      "epoch": 0.30758269075478567,
      "grad_norm": 0.0024854333605617285,
      "learning_rate": 6.9241730924521436e-06,
      "loss": 0.0001,
      "step": 19426
    },
    {
      "epoch": 0.30759852431242773,
      "grad_norm": 0.009985373355448246,
      "learning_rate": 6.9240147568757235e-06,
      "loss": 0.0004,
      "step": 19427
    },
    {
      "epoch": 0.3076143578700698,
      "grad_norm": 0.02305230125784874,
      "learning_rate": 6.923856421299302e-06,
      "loss": 0.0012,
      "step": 19428
    },
    {
      "epoch": 0.3076301914277119,
      "grad_norm": 0.8188955783843994,
      "learning_rate": 6.923698085722882e-06,
      "loss": 0.071,
      "step": 19429
    },
    {
      "epoch": 0.307646024985354,
      "grad_norm": 0.00028966524405404925,
      "learning_rate": 6.923539750146461e-06,
      "loss": 0.0,
      "step": 19430
    },
    {
      "epoch": 0.30766185854299605,
      "grad_norm": 0.7754029035568237,
      "learning_rate": 6.923381414570041e-06,
      "loss": 0.1164,
      "step": 19431
    },
    {
      "epoch": 0.3076776921006381,
      "grad_norm": 0.5371827483177185,
      "learning_rate": 6.92322307899362e-06,
      "loss": 0.1632,
      "step": 19432
    },
    {
      "epoch": 0.3076935256582802,
      "grad_norm": 0.001443162327632308,
      "learning_rate": 6.9230647434172e-06,
      "loss": 0.0,
      "step": 19433
    },
    {
      "epoch": 0.30770935921592224,
      "grad_norm": 0.19645944237709045,
      "learning_rate": 6.922906407840778e-06,
      "loss": 0.086,
      "step": 19434
    },
    {
      "epoch": 0.3077251927735643,
      "grad_norm": 0.6708971858024597,
      "learning_rate": 6.922748072264358e-06,
      "loss": 0.8519,
      "step": 19435
    },
    {
      "epoch": 0.30774102633120637,
      "grad_norm": 0.6621431708335876,
      "learning_rate": 6.922589736687937e-06,
      "loss": 0.1765,
      "step": 19436
    },
    {
      "epoch": 0.30775685988884843,
      "grad_norm": 0.7343341708183289,
      "learning_rate": 6.922431401111517e-06,
      "loss": 0.5534,
      "step": 19437
    },
    {
      "epoch": 0.3077726934464905,
      "grad_norm": 0.28693217039108276,
      "learning_rate": 6.922273065535096e-06,
      "loss": 0.0148,
      "step": 19438
    },
    {
      "epoch": 0.30778852700413256,
      "grad_norm": 0.37879249453544617,
      "learning_rate": 6.922114729958676e-06,
      "loss": 0.0431,
      "step": 19439
    },
    {
      "epoch": 0.3078043605617746,
      "grad_norm": 0.0002776089240796864,
      "learning_rate": 6.921956394382254e-06,
      "loss": 0.0,
      "step": 19440
    },
    {
      "epoch": 0.3078201941194167,
      "grad_norm": 0.5026673078536987,
      "learning_rate": 6.921798058805833e-06,
      "loss": 0.2411,
      "step": 19441
    },
    {
      "epoch": 0.30783602767705875,
      "grad_norm": 0.00417425436899066,
      "learning_rate": 6.921639723229413e-06,
      "loss": 0.0001,
      "step": 19442
    },
    {
      "epoch": 0.3078518612347008,
      "grad_norm": 0.5907816886901855,
      "learning_rate": 6.921481387652992e-06,
      "loss": 0.1041,
      "step": 19443
    },
    {
      "epoch": 0.3078676947923429,
      "grad_norm": 0.15808552503585815,
      "learning_rate": 6.921323052076572e-06,
      "loss": 0.0225,
      "step": 19444
    },
    {
      "epoch": 0.30788352834998495,
      "grad_norm": 0.00550069147720933,
      "learning_rate": 6.92116471650015e-06,
      "loss": 0.0003,
      "step": 19445
    },
    {
      "epoch": 0.307899361907627,
      "grad_norm": 0.0074243987910449505,
      "learning_rate": 6.92100638092373e-06,
      "loss": 0.0004,
      "step": 19446
    },
    {
      "epoch": 0.3079151954652691,
      "grad_norm": 0.6143883466720581,
      "learning_rate": 6.920848045347309e-06,
      "loss": 0.4066,
      "step": 19447
    },
    {
      "epoch": 0.30793102902291114,
      "grad_norm": 0.5904665589332581,
      "learning_rate": 6.920689709770889e-06,
      "loss": 0.0607,
      "step": 19448
    },
    {
      "epoch": 0.3079468625805532,
      "grad_norm": 0.3830101788043976,
      "learning_rate": 6.920531374194468e-06,
      "loss": 0.1783,
      "step": 19449
    },
    {
      "epoch": 0.30796269613819527,
      "grad_norm": 0.9477962851524353,
      "learning_rate": 6.920373038618048e-06,
      "loss": 0.2908,
      "step": 19450
    },
    {
      "epoch": 0.30797852969583733,
      "grad_norm": 0.3426745533943176,
      "learning_rate": 6.9202147030416265e-06,
      "loss": 0.066,
      "step": 19451
    },
    {
      "epoch": 0.3079943632534794,
      "grad_norm": 0.40031999349594116,
      "learning_rate": 6.920056367465206e-06,
      "loss": 0.0745,
      "step": 19452
    },
    {
      "epoch": 0.3080101968111215,
      "grad_norm": 0.8561243414878845,
      "learning_rate": 6.9198980318887855e-06,
      "loss": 0.2649,
      "step": 19453
    },
    {
      "epoch": 0.3080260303687636,
      "grad_norm": 0.7950266003608704,
      "learning_rate": 6.9197396963123654e-06,
      "loss": 0.4944,
      "step": 19454
    },
    {
      "epoch": 0.30804186392640565,
      "grad_norm": 0.3911535143852234,
      "learning_rate": 6.9195813607359445e-06,
      "loss": 0.0817,
      "step": 19455
    },
    {
      "epoch": 0.3080576974840477,
      "grad_norm": 0.694770872592926,
      "learning_rate": 6.9194230251595244e-06,
      "loss": 0.3041,
      "step": 19456
    },
    {
      "epoch": 0.3080735310416898,
      "grad_norm": 0.32985347509384155,
      "learning_rate": 6.919264689583103e-06,
      "loss": 0.1633,
      "step": 19457
    },
    {
      "epoch": 0.30808936459933184,
      "grad_norm": 0.36106303334236145,
      "learning_rate": 6.919106354006683e-06,
      "loss": 0.1419,
      "step": 19458
    },
    {
      "epoch": 0.3081051981569739,
      "grad_norm": 0.019278667867183685,
      "learning_rate": 6.918948018430262e-06,
      "loss": 0.0009,
      "step": 19459
    },
    {
      "epoch": 0.30812103171461597,
      "grad_norm": 0.0010476649040356278,
      "learning_rate": 6.918789682853842e-06,
      "loss": 0.0,
      "step": 19460
    },
    {
      "epoch": 0.30813686527225803,
      "grad_norm": 0.4751277267932892,
      "learning_rate": 6.91863134727742e-06,
      "loss": 0.18,
      "step": 19461
    },
    {
      "epoch": 0.3081526988299001,
      "grad_norm": 0.3572804927825928,
      "learning_rate": 6.918473011701e-06,
      "loss": 0.0487,
      "step": 19462
    },
    {
      "epoch": 0.30816853238754216,
      "grad_norm": 0.34162041544914246,
      "learning_rate": 6.918314676124579e-06,
      "loss": 0.1886,
      "step": 19463
    },
    {
      "epoch": 0.3081843659451842,
      "grad_norm": 0.4877125918865204,
      "learning_rate": 6.918156340548159e-06,
      "loss": 0.131,
      "step": 19464
    },
    {
      "epoch": 0.3082001995028263,
      "grad_norm": 0.16207076609134674,
      "learning_rate": 6.917998004971738e-06,
      "loss": 0.045,
      "step": 19465
    },
    {
      "epoch": 0.30821603306046835,
      "grad_norm": 0.6992353796958923,
      "learning_rate": 6.917839669395316e-06,
      "loss": 0.2325,
      "step": 19466
    },
    {
      "epoch": 0.3082318666181104,
      "grad_norm": 0.40367114543914795,
      "learning_rate": 6.917681333818896e-06,
      "loss": 0.0517,
      "step": 19467
    },
    {
      "epoch": 0.3082477001757525,
      "grad_norm": 0.6531504988670349,
      "learning_rate": 6.917522998242475e-06,
      "loss": 0.1336,
      "step": 19468
    },
    {
      "epoch": 0.30826353373339455,
      "grad_norm": 0.036839134991168976,
      "learning_rate": 6.917364662666055e-06,
      "loss": 0.002,
      "step": 19469
    },
    {
      "epoch": 0.3082793672910366,
      "grad_norm": 1.1204252243041992,
      "learning_rate": 6.917206327089634e-06,
      "loss": 0.1537,
      "step": 19470
    },
    {
      "epoch": 0.3082952008486787,
      "grad_norm": 0.016363343223929405,
      "learning_rate": 6.917047991513214e-06,
      "loss": 0.0007,
      "step": 19471
    },
    {
      "epoch": 0.30831103440632074,
      "grad_norm": 0.016583185642957687,
      "learning_rate": 6.916889655936792e-06,
      "loss": 0.0008,
      "step": 19472
    },
    {
      "epoch": 0.3083268679639628,
      "grad_norm": 0.19076181948184967,
      "learning_rate": 6.916731320360372e-06,
      "loss": 0.0545,
      "step": 19473
    },
    {
      "epoch": 0.30834270152160487,
      "grad_norm": 0.30945801734924316,
      "learning_rate": 6.916572984783951e-06,
      "loss": 0.0474,
      "step": 19474
    },
    {
      "epoch": 0.30835853507924693,
      "grad_norm": 0.24556231498718262,
      "learning_rate": 6.916414649207531e-06,
      "loss": 0.0722,
      "step": 19475
    },
    {
      "epoch": 0.308374368636889,
      "grad_norm": 0.10782893747091293,
      "learning_rate": 6.91625631363111e-06,
      "loss": 0.0089,
      "step": 19476
    },
    {
      "epoch": 0.3083902021945311,
      "grad_norm": 0.23087310791015625,
      "learning_rate": 6.91609797805469e-06,
      "loss": 0.1354,
      "step": 19477
    },
    {
      "epoch": 0.3084060357521732,
      "grad_norm": 0.7269246578216553,
      "learning_rate": 6.915939642478268e-06,
      "loss": 0.1557,
      "step": 19478
    },
    {
      "epoch": 0.30842186930981524,
      "grad_norm": 0.0034595481120049953,
      "learning_rate": 6.915781306901848e-06,
      "loss": 0.0001,
      "step": 19479
    },
    {
      "epoch": 0.3084377028674573,
      "grad_norm": 0.663396954536438,
      "learning_rate": 6.9156229713254274e-06,
      "loss": 0.0662,
      "step": 19480
    },
    {
      "epoch": 0.3084535364250994,
      "grad_norm": 0.34022364020347595,
      "learning_rate": 6.915464635749007e-06,
      "loss": 0.0907,
      "step": 19481
    },
    {
      "epoch": 0.30846936998274144,
      "grad_norm": 0.9753960967063904,
      "learning_rate": 6.9153063001725864e-06,
      "loss": 0.1017,
      "step": 19482
    },
    {
      "epoch": 0.3084852035403835,
      "grad_norm": 0.000782205315772444,
      "learning_rate": 6.915147964596166e-06,
      "loss": 0.0,
      "step": 19483
    },
    {
      "epoch": 0.30850103709802557,
      "grad_norm": 0.20226271450519562,
      "learning_rate": 6.914989629019745e-06,
      "loss": 0.0688,
      "step": 19484
    },
    {
      "epoch": 0.30851687065566763,
      "grad_norm": 0.6104835271835327,
      "learning_rate": 6.9148312934433245e-06,
      "loss": 0.2508,
      "step": 19485
    },
    {
      "epoch": 0.3085327042133097,
      "grad_norm": 0.7638998031616211,
      "learning_rate": 6.914672957866904e-06,
      "loss": 0.241,
      "step": 19486
    },
    {
      "epoch": 0.30854853777095176,
      "grad_norm": 0.2178996503353119,
      "learning_rate": 6.9145146222904835e-06,
      "loss": 0.0501,
      "step": 19487
    },
    {
      "epoch": 0.3085643713285938,
      "grad_norm": 0.15076644718647003,
      "learning_rate": 6.914356286714063e-06,
      "loss": 0.0129,
      "step": 19488
    },
    {
      "epoch": 0.3085802048862359,
      "grad_norm": 0.41275325417518616,
      "learning_rate": 6.914197951137641e-06,
      "loss": 0.1191,
      "step": 19489
    },
    {
      "epoch": 0.30859603844387795,
      "grad_norm": 0.1957351118326187,
      "learning_rate": 6.914039615561221e-06,
      "loss": 0.0473,
      "step": 19490
    },
    {
      "epoch": 0.30861187200152,
      "grad_norm": 0.29973098635673523,
      "learning_rate": 6.9138812799848e-06,
      "loss": 0.0363,
      "step": 19491
    },
    {
      "epoch": 0.3086277055591621,
      "grad_norm": 0.9618670344352722,
      "learning_rate": 6.91372294440838e-06,
      "loss": 0.722,
      "step": 19492
    },
    {
      "epoch": 0.30864353911680414,
      "grad_norm": 0.14459849894046783,
      "learning_rate": 6.913564608831959e-06,
      "loss": 0.0643,
      "step": 19493
    },
    {
      "epoch": 0.3086593726744462,
      "grad_norm": 0.6139907836914062,
      "learning_rate": 6.913406273255539e-06,
      "loss": 0.3816,
      "step": 19494
    },
    {
      "epoch": 0.3086752062320883,
      "grad_norm": 0.09438564628362656,
      "learning_rate": 6.913247937679117e-06,
      "loss": 0.0059,
      "step": 19495
    },
    {
      "epoch": 0.30869103978973034,
      "grad_norm": 0.04498779773712158,
      "learning_rate": 6.913089602102697e-06,
      "loss": 0.0025,
      "step": 19496
    },
    {
      "epoch": 0.3087068733473724,
      "grad_norm": 0.40098807215690613,
      "learning_rate": 6.912931266526276e-06,
      "loss": 0.1231,
      "step": 19497
    },
    {
      "epoch": 0.30872270690501447,
      "grad_norm": 0.7727556824684143,
      "learning_rate": 6.912772930949856e-06,
      "loss": 0.0658,
      "step": 19498
    },
    {
      "epoch": 0.30873854046265653,
      "grad_norm": 0.4010851979255676,
      "learning_rate": 6.912614595373435e-06,
      "loss": 0.1638,
      "step": 19499
    },
    {
      "epoch": 0.3087543740202986,
      "grad_norm": 0.4499932825565338,
      "learning_rate": 6.912456259797015e-06,
      "loss": 0.0112,
      "step": 19500
    },
    {
      "epoch": 0.3087702075779407,
      "grad_norm": 0.8585208058357239,
      "learning_rate": 6.912297924220593e-06,
      "loss": 0.5869,
      "step": 19501
    },
    {
      "epoch": 0.3087860411355828,
      "grad_norm": 0.0006189183914102614,
      "learning_rate": 6.912139588644173e-06,
      "loss": 0.0,
      "step": 19502
    },
    {
      "epoch": 0.30880187469322484,
      "grad_norm": 0.507856011390686,
      "learning_rate": 6.911981253067752e-06,
      "loss": 0.2076,
      "step": 19503
    },
    {
      "epoch": 0.3088177082508669,
      "grad_norm": 0.3015604019165039,
      "learning_rate": 6.911822917491332e-06,
      "loss": 0.0956,
      "step": 19504
    },
    {
      "epoch": 0.30883354180850897,
      "grad_norm": 0.5356760621070862,
      "learning_rate": 6.911664581914911e-06,
      "loss": 0.1998,
      "step": 19505
    },
    {
      "epoch": 0.30884937536615104,
      "grad_norm": 0.27708449959754944,
      "learning_rate": 6.911506246338491e-06,
      "loss": 0.0387,
      "step": 19506
    },
    {
      "epoch": 0.3088652089237931,
      "grad_norm": 0.20402541756629944,
      "learning_rate": 6.911347910762069e-06,
      "loss": 0.0953,
      "step": 19507
    },
    {
      "epoch": 0.30888104248143516,
      "grad_norm": 0.6236860752105713,
      "learning_rate": 6.911189575185649e-06,
      "loss": 0.1655,
      "step": 19508
    },
    {
      "epoch": 0.30889687603907723,
      "grad_norm": 0.3367110788822174,
      "learning_rate": 6.911031239609228e-06,
      "loss": 0.0608,
      "step": 19509
    },
    {
      "epoch": 0.3089127095967193,
      "grad_norm": 0.14902955293655396,
      "learning_rate": 6.910872904032808e-06,
      "loss": 0.0324,
      "step": 19510
    },
    {
      "epoch": 0.30892854315436136,
      "grad_norm": 0.34057095646858215,
      "learning_rate": 6.910714568456387e-06,
      "loss": 0.1464,
      "step": 19511
    },
    {
      "epoch": 0.3089443767120034,
      "grad_norm": 0.29964056611061096,
      "learning_rate": 6.910556232879967e-06,
      "loss": 0.1192,
      "step": 19512
    },
    {
      "epoch": 0.3089602102696455,
      "grad_norm": 0.004111161921173334,
      "learning_rate": 6.9103978973035455e-06,
      "loss": 0.0001,
      "step": 19513
    },
    {
      "epoch": 0.30897604382728755,
      "grad_norm": 0.0010218111565336585,
      "learning_rate": 6.910239561727125e-06,
      "loss": 0.0,
      "step": 19514
    },
    {
      "epoch": 0.3089918773849296,
      "grad_norm": 0.008103912696242332,
      "learning_rate": 6.9100812261507045e-06,
      "loss": 0.0003,
      "step": 19515
    },
    {
      "epoch": 0.3090077109425717,
      "grad_norm": 0.3258505165576935,
      "learning_rate": 6.909922890574284e-06,
      "loss": 0.2392,
      "step": 19516
    },
    {
      "epoch": 0.30902354450021374,
      "grad_norm": 0.48885443806648254,
      "learning_rate": 6.9097645549978635e-06,
      "loss": 0.2702,
      "step": 19517
    },
    {
      "epoch": 0.3090393780578558,
      "grad_norm": 0.31589001417160034,
      "learning_rate": 6.909606219421442e-06,
      "loss": 0.1821,
      "step": 19518
    },
    {
      "epoch": 0.30905521161549787,
      "grad_norm": 0.1793813556432724,
      "learning_rate": 6.909447883845022e-06,
      "loss": 0.0673,
      "step": 19519
    },
    {
      "epoch": 0.30907104517313994,
      "grad_norm": 0.39456045627593994,
      "learning_rate": 6.909289548268601e-06,
      "loss": 0.0543,
      "step": 19520
    },
    {
      "epoch": 0.309086878730782,
      "grad_norm": 0.513239860534668,
      "learning_rate": 6.909131212692181e-06,
      "loss": 0.0993,
      "step": 19521
    },
    {
      "epoch": 0.30910271228842406,
      "grad_norm": 0.15574638545513153,
      "learning_rate": 6.90897287711576e-06,
      "loss": 0.0368,
      "step": 19522
    },
    {
      "epoch": 0.30911854584606613,
      "grad_norm": 0.22044523060321808,
      "learning_rate": 6.90881454153934e-06,
      "loss": 0.0358,
      "step": 19523
    },
    {
      "epoch": 0.3091343794037082,
      "grad_norm": 0.45390841364860535,
      "learning_rate": 6.908656205962918e-06,
      "loss": 0.423,
      "step": 19524
    },
    {
      "epoch": 0.3091502129613503,
      "grad_norm": 0.272665411233902,
      "learning_rate": 6.908497870386498e-06,
      "loss": 0.1658,
      "step": 19525
    },
    {
      "epoch": 0.3091660465189924,
      "grad_norm": 0.02404118701815605,
      "learning_rate": 6.908339534810077e-06,
      "loss": 0.0012,
      "step": 19526
    },
    {
      "epoch": 0.30918188007663444,
      "grad_norm": 0.046923741698265076,
      "learning_rate": 6.908181199233657e-06,
      "loss": 0.0025,
      "step": 19527
    },
    {
      "epoch": 0.3091977136342765,
      "grad_norm": 0.21099217236042023,
      "learning_rate": 6.908022863657235e-06,
      "loss": 0.0779,
      "step": 19528
    },
    {
      "epoch": 0.30921354719191857,
      "grad_norm": 0.4683702290058136,
      "learning_rate": 6.907864528080815e-06,
      "loss": 0.2262,
      "step": 19529
    },
    {
      "epoch": 0.30922938074956063,
      "grad_norm": 0.6016536951065063,
      "learning_rate": 6.907706192504394e-06,
      "loss": 0.1977,
      "step": 19530
    },
    {
      "epoch": 0.3092452143072027,
      "grad_norm": 0.2594543993473053,
      "learning_rate": 6.907547856927974e-06,
      "loss": 0.0872,
      "step": 19531
    },
    {
      "epoch": 0.30926104786484476,
      "grad_norm": 0.32257649302482605,
      "learning_rate": 6.907389521351553e-06,
      "loss": 0.1232,
      "step": 19532
    },
    {
      "epoch": 0.3092768814224868,
      "grad_norm": 0.024731718003749847,
      "learning_rate": 6.907231185775133e-06,
      "loss": 0.0016,
      "step": 19533
    },
    {
      "epoch": 0.3092927149801289,
      "grad_norm": 0.2932060658931732,
      "learning_rate": 6.907072850198711e-06,
      "loss": 0.0343,
      "step": 19534
    },
    {
      "epoch": 0.30930854853777096,
      "grad_norm": 0.026699261739850044,
      "learning_rate": 6.906914514622291e-06,
      "loss": 0.0014,
      "step": 19535
    },
    {
      "epoch": 0.309324382095413,
      "grad_norm": 0.2665335536003113,
      "learning_rate": 6.90675617904587e-06,
      "loss": 0.0632,
      "step": 19536
    },
    {
      "epoch": 0.3093402156530551,
      "grad_norm": 0.023973826318979263,
      "learning_rate": 6.906597843469449e-06,
      "loss": 0.0013,
      "step": 19537
    },
    {
      "epoch": 0.30935604921069715,
      "grad_norm": 0.23490068316459656,
      "learning_rate": 6.906439507893029e-06,
      "loss": 0.0844,
      "step": 19538
    },
    {
      "epoch": 0.3093718827683392,
      "grad_norm": 0.5586662888526917,
      "learning_rate": 6.9062811723166075e-06,
      "loss": 0.0216,
      "step": 19539
    },
    {
      "epoch": 0.3093877163259813,
      "grad_norm": 0.1596616953611374,
      "learning_rate": 6.9061228367401874e-06,
      "loss": 0.0693,
      "step": 19540
    },
    {
      "epoch": 0.30940354988362334,
      "grad_norm": 0.32625144720077515,
      "learning_rate": 6.9059645011637665e-06,
      "loss": 0.1063,
      "step": 19541
    },
    {
      "epoch": 0.3094193834412654,
      "grad_norm": 0.39406120777130127,
      "learning_rate": 6.9058061655873465e-06,
      "loss": 0.1682,
      "step": 19542
    },
    {
      "epoch": 0.30943521699890747,
      "grad_norm": 0.02119215577840805,
      "learning_rate": 6.9056478300109255e-06,
      "loss": 0.0009,
      "step": 19543
    },
    {
      "epoch": 0.30945105055654953,
      "grad_norm": 0.6266862750053406,
      "learning_rate": 6.9054894944345055e-06,
      "loss": 0.4305,
      "step": 19544
    },
    {
      "epoch": 0.3094668841141916,
      "grad_norm": 0.5264551043510437,
      "learning_rate": 6.905331158858084e-06,
      "loss": 0.0212,
      "step": 19545
    },
    {
      "epoch": 0.30948271767183366,
      "grad_norm": 0.007038702256977558,
      "learning_rate": 6.905172823281664e-06,
      "loss": 0.0003,
      "step": 19546
    },
    {
      "epoch": 0.3094985512294757,
      "grad_norm": 0.0008522561984136701,
      "learning_rate": 6.905014487705243e-06,
      "loss": 0.0,
      "step": 19547
    },
    {
      "epoch": 0.3095143847871178,
      "grad_norm": 0.3407592475414276,
      "learning_rate": 6.904856152128823e-06,
      "loss": 0.1149,
      "step": 19548
    },
    {
      "epoch": 0.3095302183447599,
      "grad_norm": 0.002367014531046152,
      "learning_rate": 6.904697816552402e-06,
      "loss": 0.0001,
      "step": 19549
    },
    {
      "epoch": 0.309546051902402,
      "grad_norm": 0.0023093095514923334,
      "learning_rate": 6.904539480975982e-06,
      "loss": 0.0,
      "step": 19550
    },
    {
      "epoch": 0.30956188546004404,
      "grad_norm": 1.2640153169631958,
      "learning_rate": 6.90438114539956e-06,
      "loss": 0.329,
      "step": 19551
    },
    {
      "epoch": 0.3095777190176861,
      "grad_norm": 0.7344533801078796,
      "learning_rate": 6.90422280982314e-06,
      "loss": 0.4704,
      "step": 19552
    },
    {
      "epoch": 0.30959355257532817,
      "grad_norm": 0.8209765553474426,
      "learning_rate": 6.904064474246719e-06,
      "loss": 0.4584,
      "step": 19553
    },
    {
      "epoch": 0.30960938613297023,
      "grad_norm": 0.00011252715194132179,
      "learning_rate": 6.903906138670299e-06,
      "loss": 0.0,
      "step": 19554
    },
    {
      "epoch": 0.3096252196906123,
      "grad_norm": 0.010838341899216175,
      "learning_rate": 6.903747803093878e-06,
      "loss": 0.0005,
      "step": 19555
    },
    {
      "epoch": 0.30964105324825436,
      "grad_norm": 0.35038602352142334,
      "learning_rate": 6.903589467517458e-06,
      "loss": 0.1844,
      "step": 19556
    },
    {
      "epoch": 0.3096568868058964,
      "grad_norm": 0.2744976580142975,
      "learning_rate": 6.903431131941036e-06,
      "loss": 0.0392,
      "step": 19557
    },
    {
      "epoch": 0.3096727203635385,
      "grad_norm": 0.9200620055198669,
      "learning_rate": 6.903272796364616e-06,
      "loss": 0.2322,
      "step": 19558
    },
    {
      "epoch": 0.30968855392118055,
      "grad_norm": 0.0009329344611614943,
      "learning_rate": 6.903114460788195e-06,
      "loss": 0.0,
      "step": 19559
    },
    {
      "epoch": 0.3097043874788226,
      "grad_norm": 0.0010153800249099731,
      "learning_rate": 6.902956125211775e-06,
      "loss": 0.0,
      "step": 19560
    },
    {
      "epoch": 0.3097202210364647,
      "grad_norm": 0.0003325144061818719,
      "learning_rate": 6.902797789635354e-06,
      "loss": 0.0,
      "step": 19561
    },
    {
      "epoch": 0.30973605459410675,
      "grad_norm": 0.0040567717514932156,
      "learning_rate": 6.902639454058932e-06,
      "loss": 0.0001,
      "step": 19562
    },
    {
      "epoch": 0.3097518881517488,
      "grad_norm": 0.7193855047225952,
      "learning_rate": 6.902481118482512e-06,
      "loss": 0.9302,
      "step": 19563
    },
    {
      "epoch": 0.3097677217093909,
      "grad_norm": 0.07125458866357803,
      "learning_rate": 6.902322782906091e-06,
      "loss": 0.0043,
      "step": 19564
    },
    {
      "epoch": 0.30978355526703294,
      "grad_norm": 0.33201152086257935,
      "learning_rate": 6.902164447329671e-06,
      "loss": 0.1677,
      "step": 19565
    },
    {
      "epoch": 0.309799388824675,
      "grad_norm": 0.17495766282081604,
      "learning_rate": 6.90200611175325e-06,
      "loss": 0.0553,
      "step": 19566
    },
    {
      "epoch": 0.30981522238231707,
      "grad_norm": 0.1735350340604782,
      "learning_rate": 6.90184777617683e-06,
      "loss": 0.0182,
      "step": 19567
    },
    {
      "epoch": 0.30983105593995913,
      "grad_norm": 0.05404157191514969,
      "learning_rate": 6.9016894406004084e-06,
      "loss": 0.0028,
      "step": 19568
    },
    {
      "epoch": 0.3098468894976012,
      "grad_norm": 0.5277689099311829,
      "learning_rate": 6.901531105023988e-06,
      "loss": 0.0088,
      "step": 19569
    },
    {
      "epoch": 0.30986272305524326,
      "grad_norm": 0.18492795526981354,
      "learning_rate": 6.9013727694475675e-06,
      "loss": 0.0393,
      "step": 19570
    },
    {
      "epoch": 0.3098785566128853,
      "grad_norm": 0.49150222539901733,
      "learning_rate": 6.901214433871147e-06,
      "loss": 0.0525,
      "step": 19571
    },
    {
      "epoch": 0.3098943901705274,
      "grad_norm": 1.5214531421661377,
      "learning_rate": 6.9010560982947265e-06,
      "loss": 0.0658,
      "step": 19572
    },
    {
      "epoch": 0.3099102237281695,
      "grad_norm": 0.9295605421066284,
      "learning_rate": 6.900897762718306e-06,
      "loss": 0.1414,
      "step": 19573
    },
    {
      "epoch": 0.3099260572858116,
      "grad_norm": 0.6640437841415405,
      "learning_rate": 6.900739427141885e-06,
      "loss": 0.1117,
      "step": 19574
    },
    {
      "epoch": 0.30994189084345364,
      "grad_norm": 0.5429705381393433,
      "learning_rate": 6.9005810915654645e-06,
      "loss": 0.2006,
      "step": 19575
    },
    {
      "epoch": 0.3099577244010957,
      "grad_norm": 0.3602373003959656,
      "learning_rate": 6.900422755989044e-06,
      "loss": 0.12,
      "step": 19576
    },
    {
      "epoch": 0.30997355795873777,
      "grad_norm": 0.33910587430000305,
      "learning_rate": 6.9002644204126236e-06,
      "loss": 0.087,
      "step": 19577
    },
    {
      "epoch": 0.30998939151637983,
      "grad_norm": 0.21401344239711761,
      "learning_rate": 6.900106084836203e-06,
      "loss": 0.0352,
      "step": 19578
    },
    {
      "epoch": 0.3100052250740219,
      "grad_norm": 0.001251592650078237,
      "learning_rate": 6.8999477492597826e-06,
      "loss": 0.0,
      "step": 19579
    },
    {
      "epoch": 0.31002105863166396,
      "grad_norm": 6.096024990081787,
      "learning_rate": 6.899789413683361e-06,
      "loss": 0.4122,
      "step": 19580
    },
    {
      "epoch": 0.310036892189306,
      "grad_norm": 0.15319408476352692,
      "learning_rate": 6.899631078106941e-06,
      "loss": 0.0136,
      "step": 19581
    },
    {
      "epoch": 0.3100527257469481,
      "grad_norm": 1.9961851835250854,
      "learning_rate": 6.89947274253052e-06,
      "loss": 0.1761,
      "step": 19582
    },
    {
      "epoch": 0.31006855930459015,
      "grad_norm": 0.32881125807762146,
      "learning_rate": 6.8993144069541e-06,
      "loss": 0.0844,
      "step": 19583
    },
    {
      "epoch": 0.3100843928622322,
      "grad_norm": 0.4600284695625305,
      "learning_rate": 6.899156071377679e-06,
      "loss": 0.0525,
      "step": 19584
    },
    {
      "epoch": 0.3101002264198743,
      "grad_norm": 0.16390764713287354,
      "learning_rate": 6.898997735801257e-06,
      "loss": 0.0193,
      "step": 19585
    },
    {
      "epoch": 0.31011605997751635,
      "grad_norm": 0.3742610812187195,
      "learning_rate": 6.898839400224837e-06,
      "loss": 0.152,
      "step": 19586
    },
    {
      "epoch": 0.3101318935351584,
      "grad_norm": 0.47008016705513,
      "learning_rate": 6.898681064648416e-06,
      "loss": 0.0797,
      "step": 19587
    },
    {
      "epoch": 0.3101477270928005,
      "grad_norm": 0.0378253199160099,
      "learning_rate": 6.898522729071996e-06,
      "loss": 0.0022,
      "step": 19588
    },
    {
      "epoch": 0.31016356065044254,
      "grad_norm": 0.7790384292602539,
      "learning_rate": 6.898364393495575e-06,
      "loss": 0.2504,
      "step": 19589
    },
    {
      "epoch": 0.3101793942080846,
      "grad_norm": 0.20234128832817078,
      "learning_rate": 6.898206057919154e-06,
      "loss": 0.0403,
      "step": 19590
    },
    {
      "epoch": 0.31019522776572667,
      "grad_norm": 0.0009357258095405996,
      "learning_rate": 6.898047722342733e-06,
      "loss": 0.0,
      "step": 19591
    },
    {
      "epoch": 0.31021106132336873,
      "grad_norm": 0.7916828989982605,
      "learning_rate": 6.897889386766313e-06,
      "loss": 0.583,
      "step": 19592
    },
    {
      "epoch": 0.3102268948810108,
      "grad_norm": 0.6762294769287109,
      "learning_rate": 6.897731051189892e-06,
      "loss": 0.2243,
      "step": 19593
    },
    {
      "epoch": 0.31024272843865286,
      "grad_norm": 0.5329579710960388,
      "learning_rate": 6.897572715613472e-06,
      "loss": 0.1238,
      "step": 19594
    },
    {
      "epoch": 0.3102585619962949,
      "grad_norm": 0.38798850774765015,
      "learning_rate": 6.89741438003705e-06,
      "loss": 0.0966,
      "step": 19595
    },
    {
      "epoch": 0.310274395553937,
      "grad_norm": 0.03540012240409851,
      "learning_rate": 6.89725604446063e-06,
      "loss": 0.0021,
      "step": 19596
    },
    {
      "epoch": 0.3102902291115791,
      "grad_norm": 0.8193363547325134,
      "learning_rate": 6.897097708884209e-06,
      "loss": 0.5829,
      "step": 19597
    },
    {
      "epoch": 0.31030606266922117,
      "grad_norm": 0.5046384930610657,
      "learning_rate": 6.896939373307789e-06,
      "loss": 0.1842,
      "step": 19598
    },
    {
      "epoch": 0.31032189622686324,
      "grad_norm": 0.5425176024436951,
      "learning_rate": 6.896781037731368e-06,
      "loss": 0.6197,
      "step": 19599
    },
    {
      "epoch": 0.3103377297845053,
      "grad_norm": 0.41676193475723267,
      "learning_rate": 6.896622702154948e-06,
      "loss": 0.1437,
      "step": 19600
    },
    {
      "epoch": 0.31035356334214736,
      "grad_norm": 0.18330252170562744,
      "learning_rate": 6.8964643665785265e-06,
      "loss": 0.0593,
      "step": 19601
    },
    {
      "epoch": 0.31036939689978943,
      "grad_norm": 0.26524561643600464,
      "learning_rate": 6.8963060310021065e-06,
      "loss": 0.0379,
      "step": 19602
    },
    {
      "epoch": 0.3103852304574315,
      "grad_norm": 0.018748225644230843,
      "learning_rate": 6.8961476954256856e-06,
      "loss": 0.001,
      "step": 19603
    },
    {
      "epoch": 0.31040106401507356,
      "grad_norm": 0.40005528926849365,
      "learning_rate": 6.8959893598492655e-06,
      "loss": 0.0666,
      "step": 19604
    },
    {
      "epoch": 0.3104168975727156,
      "grad_norm": 0.5036479234695435,
      "learning_rate": 6.8958310242728446e-06,
      "loss": 0.3289,
      "step": 19605
    },
    {
      "epoch": 0.3104327311303577,
      "grad_norm": 0.4535289406776428,
      "learning_rate": 6.8956726886964245e-06,
      "loss": 0.143,
      "step": 19606
    },
    {
      "epoch": 0.31044856468799975,
      "grad_norm": 0.00022237452503759414,
      "learning_rate": 6.895514353120003e-06,
      "loss": 0.0,
      "step": 19607
    },
    {
      "epoch": 0.3104643982456418,
      "grad_norm": 0.5167233943939209,
      "learning_rate": 6.895356017543583e-06,
      "loss": 0.1016,
      "step": 19608
    },
    {
      "epoch": 0.3104802318032839,
      "grad_norm": 0.01882597804069519,
      "learning_rate": 6.895197681967162e-06,
      "loss": 0.0006,
      "step": 19609
    },
    {
      "epoch": 0.31049606536092594,
      "grad_norm": 0.5180042386054993,
      "learning_rate": 6.895039346390741e-06,
      "loss": 0.1584,
      "step": 19610
    },
    {
      "epoch": 0.310511898918568,
      "grad_norm": 0.4581052362918854,
      "learning_rate": 6.894881010814321e-06,
      "loss": 0.4288,
      "step": 19611
    },
    {
      "epoch": 0.31052773247621007,
      "grad_norm": 0.8094320893287659,
      "learning_rate": 6.894722675237899e-06,
      "loss": 0.0571,
      "step": 19612
    },
    {
      "epoch": 0.31054356603385214,
      "grad_norm": 0.5556663274765015,
      "learning_rate": 6.894564339661479e-06,
      "loss": 0.1582,
      "step": 19613
    },
    {
      "epoch": 0.3105593995914942,
      "grad_norm": 0.1206212267279625,
      "learning_rate": 6.894406004085058e-06,
      "loss": 0.0061,
      "step": 19614
    },
    {
      "epoch": 0.31057523314913626,
      "grad_norm": 0.5992917418479919,
      "learning_rate": 6.894247668508638e-06,
      "loss": 0.3001,
      "step": 19615
    },
    {
      "epoch": 0.31059106670677833,
      "grad_norm": 0.33436766266822815,
      "learning_rate": 6.894089332932217e-06,
      "loss": 0.009,
      "step": 19616
    },
    {
      "epoch": 0.3106069002644204,
      "grad_norm": 0.4988463819026947,
      "learning_rate": 6.893930997355797e-06,
      "loss": 0.1032,
      "step": 19617
    },
    {
      "epoch": 0.31062273382206246,
      "grad_norm": 0.02328408509492874,
      "learning_rate": 6.893772661779375e-06,
      "loss": 0.0009,
      "step": 19618
    },
    {
      "epoch": 0.3106385673797045,
      "grad_norm": 0.8534961938858032,
      "learning_rate": 6.893614326202955e-06,
      "loss": 0.0615,
      "step": 19619
    },
    {
      "epoch": 0.3106544009373466,
      "grad_norm": 0.6187883615493774,
      "learning_rate": 6.893455990626534e-06,
      "loss": 0.0742,
      "step": 19620
    },
    {
      "epoch": 0.3106702344949887,
      "grad_norm": 0.0003986224182881415,
      "learning_rate": 6.893297655050114e-06,
      "loss": 0.0,
      "step": 19621
    },
    {
      "epoch": 0.31068606805263077,
      "grad_norm": 0.46981632709503174,
      "learning_rate": 6.893139319473693e-06,
      "loss": 0.2452,
      "step": 19622
    },
    {
      "epoch": 0.31070190161027283,
      "grad_norm": 0.07429715991020203,
      "learning_rate": 6.892980983897273e-06,
      "loss": 0.0046,
      "step": 19623
    },
    {
      "epoch": 0.3107177351679149,
      "grad_norm": 0.7343894243240356,
      "learning_rate": 6.892822648320851e-06,
      "loss": 0.2505,
      "step": 19624
    },
    {
      "epoch": 0.31073356872555696,
      "grad_norm": 0.644192636013031,
      "learning_rate": 6.892664312744431e-06,
      "loss": 0.0836,
      "step": 19625
    },
    {
      "epoch": 0.310749402283199,
      "grad_norm": 0.16489161550998688,
      "learning_rate": 6.89250597716801e-06,
      "loss": 0.0136,
      "step": 19626
    },
    {
      "epoch": 0.3107652358408411,
      "grad_norm": 0.5914367437362671,
      "learning_rate": 6.89234764159159e-06,
      "loss": 0.2002,
      "step": 19627
    },
    {
      "epoch": 0.31078106939848316,
      "grad_norm": 0.609001100063324,
      "learning_rate": 6.892189306015169e-06,
      "loss": 0.1858,
      "step": 19628
    },
    {
      "epoch": 0.3107969029561252,
      "grad_norm": 0.8557444214820862,
      "learning_rate": 6.892030970438749e-06,
      "loss": 0.2019,
      "step": 19629
    },
    {
      "epoch": 0.3108127365137673,
      "grad_norm": 0.015017214231193066,
      "learning_rate": 6.8918726348623275e-06,
      "loss": 0.0008,
      "step": 19630
    },
    {
      "epoch": 0.31082857007140935,
      "grad_norm": 0.9690171480178833,
      "learning_rate": 6.891714299285907e-06,
      "loss": 0.2396,
      "step": 19631
    },
    {
      "epoch": 0.3108444036290514,
      "grad_norm": 0.006196525879204273,
      "learning_rate": 6.8915559637094865e-06,
      "loss": 0.0003,
      "step": 19632
    },
    {
      "epoch": 0.3108602371866935,
      "grad_norm": 0.01175384595990181,
      "learning_rate": 6.8913976281330656e-06,
      "loss": 0.0006,
      "step": 19633
    },
    {
      "epoch": 0.31087607074433554,
      "grad_norm": 0.34308284521102905,
      "learning_rate": 6.8912392925566455e-06,
      "loss": 0.0571,
      "step": 19634
    },
    {
      "epoch": 0.3108919043019776,
      "grad_norm": 0.9424399733543396,
      "learning_rate": 6.891080956980224e-06,
      "loss": 0.5739,
      "step": 19635
    },
    {
      "epoch": 0.31090773785961967,
      "grad_norm": 0.8277916312217712,
      "learning_rate": 6.890922621403804e-06,
      "loss": 0.1907,
      "step": 19636
    },
    {
      "epoch": 0.31092357141726173,
      "grad_norm": 0.28982412815093994,
      "learning_rate": 6.890764285827383e-06,
      "loss": 0.0905,
      "step": 19637
    },
    {
      "epoch": 0.3109394049749038,
      "grad_norm": 0.5552980899810791,
      "learning_rate": 6.890605950250963e-06,
      "loss": 0.3862,
      "step": 19638
    },
    {
      "epoch": 0.31095523853254586,
      "grad_norm": 0.40324482321739197,
      "learning_rate": 6.890447614674542e-06,
      "loss": 0.2242,
      "step": 19639
    },
    {
      "epoch": 0.3109710720901879,
      "grad_norm": 0.004587431903928518,
      "learning_rate": 6.890289279098122e-06,
      "loss": 0.0002,
      "step": 19640
    },
    {
      "epoch": 0.31098690564783,
      "grad_norm": 0.02626216411590576,
      "learning_rate": 6.8901309435217e-06,
      "loss": 0.0015,
      "step": 19641
    },
    {
      "epoch": 0.31100273920547206,
      "grad_norm": 0.4684089124202728,
      "learning_rate": 6.88997260794528e-06,
      "loss": 0.1058,
      "step": 19642
    },
    {
      "epoch": 0.3110185727631141,
      "grad_norm": 0.09638877213001251,
      "learning_rate": 6.889814272368859e-06,
      "loss": 0.0032,
      "step": 19643
    },
    {
      "epoch": 0.3110344063207562,
      "grad_norm": 0.10194436460733414,
      "learning_rate": 6.889655936792439e-06,
      "loss": 0.0029,
      "step": 19644
    },
    {
      "epoch": 0.3110502398783983,
      "grad_norm": 0.23720145225524902,
      "learning_rate": 6.889497601216018e-06,
      "loss": 0.05,
      "step": 19645
    },
    {
      "epoch": 0.31106607343604037,
      "grad_norm": 0.0001824071805458516,
      "learning_rate": 6.889339265639598e-06,
      "loss": 0.0,
      "step": 19646
    },
    {
      "epoch": 0.31108190699368243,
      "grad_norm": 0.4848325252532959,
      "learning_rate": 6.889180930063176e-06,
      "loss": 0.0191,
      "step": 19647
    },
    {
      "epoch": 0.3110977405513245,
      "grad_norm": 0.557575523853302,
      "learning_rate": 6.889022594486756e-06,
      "loss": 0.1212,
      "step": 19648
    },
    {
      "epoch": 0.31111357410896656,
      "grad_norm": 0.43758538365364075,
      "learning_rate": 6.888864258910335e-06,
      "loss": 0.1002,
      "step": 19649
    },
    {
      "epoch": 0.3111294076666086,
      "grad_norm": 0.6286876201629639,
      "learning_rate": 6.888705923333915e-06,
      "loss": 0.0761,
      "step": 19650
    },
    {
      "epoch": 0.3111452412242507,
      "grad_norm": 0.21811406314373016,
      "learning_rate": 6.888547587757494e-06,
      "loss": 0.0647,
      "step": 19651
    },
    {
      "epoch": 0.31116107478189275,
      "grad_norm": 0.2322726845741272,
      "learning_rate": 6.888389252181073e-06,
      "loss": 0.0743,
      "step": 19652
    },
    {
      "epoch": 0.3111769083395348,
      "grad_norm": 0.39072829484939575,
      "learning_rate": 6.888230916604652e-06,
      "loss": 0.1101,
      "step": 19653
    },
    {
      "epoch": 0.3111927418971769,
      "grad_norm": 0.017753036692738533,
      "learning_rate": 6.888072581028232e-06,
      "loss": 0.0007,
      "step": 19654
    },
    {
      "epoch": 0.31120857545481895,
      "grad_norm": 0.6867402195930481,
      "learning_rate": 6.887914245451811e-06,
      "loss": 0.1049,
      "step": 19655
    },
    {
      "epoch": 0.311224409012461,
      "grad_norm": 1.3289482593536377,
      "learning_rate": 6.887755909875391e-06,
      "loss": 0.1185,
      "step": 19656
    },
    {
      "epoch": 0.3112402425701031,
      "grad_norm": 1.643907904624939,
      "learning_rate": 6.887597574298969e-06,
      "loss": 0.2714,
      "step": 19657
    },
    {
      "epoch": 0.31125607612774514,
      "grad_norm": 0.38926562666893005,
      "learning_rate": 6.8874392387225485e-06,
      "loss": 0.0917,
      "step": 19658
    },
    {
      "epoch": 0.3112719096853872,
      "grad_norm": 0.27513235807418823,
      "learning_rate": 6.887280903146128e-06,
      "loss": 0.0865,
      "step": 19659
    },
    {
      "epoch": 0.31128774324302927,
      "grad_norm": 1.1145601272583008,
      "learning_rate": 6.8871225675697075e-06,
      "loss": 0.1392,
      "step": 19660
    },
    {
      "epoch": 0.31130357680067133,
      "grad_norm": 0.02206404320895672,
      "learning_rate": 6.886964231993287e-06,
      "loss": 0.0013,
      "step": 19661
    },
    {
      "epoch": 0.3113194103583134,
      "grad_norm": 0.21595649421215057,
      "learning_rate": 6.886805896416866e-06,
      "loss": 0.0639,
      "step": 19662
    },
    {
      "epoch": 0.31133524391595546,
      "grad_norm": 0.7831223607063293,
      "learning_rate": 6.8866475608404456e-06,
      "loss": 0.2605,
      "step": 19663
    },
    {
      "epoch": 0.3113510774735975,
      "grad_norm": 0.6779784560203552,
      "learning_rate": 6.886489225264025e-06,
      "loss": 0.4008,
      "step": 19664
    },
    {
      "epoch": 0.3113669110312396,
      "grad_norm": 0.25048428773880005,
      "learning_rate": 6.8863308896876046e-06,
      "loss": 0.0205,
      "step": 19665
    },
    {
      "epoch": 0.31138274458888165,
      "grad_norm": 0.01192012894898653,
      "learning_rate": 6.886172554111184e-06,
      "loss": 0.0007,
      "step": 19666
    },
    {
      "epoch": 0.3113985781465237,
      "grad_norm": 1.0624314546585083,
      "learning_rate": 6.886014218534764e-06,
      "loss": 0.1137,
      "step": 19667
    },
    {
      "epoch": 0.3114144117041658,
      "grad_norm": 0.46217674016952515,
      "learning_rate": 6.885855882958342e-06,
      "loss": 0.1438,
      "step": 19668
    },
    {
      "epoch": 0.3114302452618079,
      "grad_norm": 0.6114792823791504,
      "learning_rate": 6.885697547381922e-06,
      "loss": 0.0097,
      "step": 19669
    },
    {
      "epoch": 0.31144607881944997,
      "grad_norm": 0.737067461013794,
      "learning_rate": 6.885539211805501e-06,
      "loss": 0.1937,
      "step": 19670
    },
    {
      "epoch": 0.31146191237709203,
      "grad_norm": 0.23584063351154327,
      "learning_rate": 6.885380876229081e-06,
      "loss": 0.0632,
      "step": 19671
    },
    {
      "epoch": 0.3114777459347341,
      "grad_norm": 0.029199356213212013,
      "learning_rate": 6.88522254065266e-06,
      "loss": 0.0014,
      "step": 19672
    },
    {
      "epoch": 0.31149357949237616,
      "grad_norm": 0.9833987355232239,
      "learning_rate": 6.88506420507624e-06,
      "loss": 0.0429,
      "step": 19673
    },
    {
      "epoch": 0.3115094130500182,
      "grad_norm": 0.5019368529319763,
      "learning_rate": 6.884905869499818e-06,
      "loss": 0.021,
      "step": 19674
    },
    {
      "epoch": 0.3115252466076603,
      "grad_norm": 2.0819478034973145,
      "learning_rate": 6.884747533923398e-06,
      "loss": 0.0187,
      "step": 19675
    },
    {
      "epoch": 0.31154108016530235,
      "grad_norm": 0.1865396946668625,
      "learning_rate": 6.884589198346977e-06,
      "loss": 0.0343,
      "step": 19676
    },
    {
      "epoch": 0.3115569137229444,
      "grad_norm": 0.23150864243507385,
      "learning_rate": 6.884430862770557e-06,
      "loss": 0.104,
      "step": 19677
    },
    {
      "epoch": 0.3115727472805865,
      "grad_norm": 0.5508111715316772,
      "learning_rate": 6.884272527194136e-06,
      "loss": 0.5185,
      "step": 19678
    },
    {
      "epoch": 0.31158858083822855,
      "grad_norm": 0.3999248743057251,
      "learning_rate": 6.884114191617716e-06,
      "loss": 0.1591,
      "step": 19679
    },
    {
      "epoch": 0.3116044143958706,
      "grad_norm": 0.8130897879600525,
      "learning_rate": 6.883955856041294e-06,
      "loss": 0.4591,
      "step": 19680
    },
    {
      "epoch": 0.3116202479535127,
      "grad_norm": 0.28187114000320435,
      "learning_rate": 6.883797520464873e-06,
      "loss": 0.107,
      "step": 19681
    },
    {
      "epoch": 0.31163608151115474,
      "grad_norm": 0.8225173950195312,
      "learning_rate": 6.883639184888453e-06,
      "loss": 0.195,
      "step": 19682
    },
    {
      "epoch": 0.3116519150687968,
      "grad_norm": 0.001296691712923348,
      "learning_rate": 6.883480849312032e-06,
      "loss": 0.0,
      "step": 19683
    },
    {
      "epoch": 0.31166774862643887,
      "grad_norm": 0.5844758749008179,
      "learning_rate": 6.883322513735612e-06,
      "loss": 0.1839,
      "step": 19684
    },
    {
      "epoch": 0.31168358218408093,
      "grad_norm": 0.26426249742507935,
      "learning_rate": 6.88316417815919e-06,
      "loss": 0.086,
      "step": 19685
    },
    {
      "epoch": 0.311699415741723,
      "grad_norm": 0.7642704248428345,
      "learning_rate": 6.88300584258277e-06,
      "loss": 0.1346,
      "step": 19686
    },
    {
      "epoch": 0.31171524929936506,
      "grad_norm": 0.9300355315208435,
      "learning_rate": 6.882847507006349e-06,
      "loss": 0.2821,
      "step": 19687
    },
    {
      "epoch": 0.3117310828570071,
      "grad_norm": 0.27596384286880493,
      "learning_rate": 6.882689171429929e-06,
      "loss": 0.0628,
      "step": 19688
    },
    {
      "epoch": 0.3117469164146492,
      "grad_norm": 0.17819558084011078,
      "learning_rate": 6.882530835853508e-06,
      "loss": 0.0372,
      "step": 19689
    },
    {
      "epoch": 0.31176274997229125,
      "grad_norm": 0.7864089608192444,
      "learning_rate": 6.882372500277088e-06,
      "loss": 0.3404,
      "step": 19690
    },
    {
      "epoch": 0.3117785835299333,
      "grad_norm": 0.025277117267251015,
      "learning_rate": 6.8822141647006666e-06,
      "loss": 0.0013,
      "step": 19691
    },
    {
      "epoch": 0.3117944170875754,
      "grad_norm": 0.7644413709640503,
      "learning_rate": 6.8820558291242465e-06,
      "loss": 0.6845,
      "step": 19692
    },
    {
      "epoch": 0.3118102506452175,
      "grad_norm": 0.6943273544311523,
      "learning_rate": 6.881897493547826e-06,
      "loss": 0.1889,
      "step": 19693
    },
    {
      "epoch": 0.31182608420285957,
      "grad_norm": 0.2778291404247284,
      "learning_rate": 6.8817391579714055e-06,
      "loss": 0.02,
      "step": 19694
    },
    {
      "epoch": 0.31184191776050163,
      "grad_norm": 0.006020252127200365,
      "learning_rate": 6.881580822394985e-06,
      "loss": 0.0001,
      "step": 19695
    },
    {
      "epoch": 0.3118577513181437,
      "grad_norm": 0.010612891986966133,
      "learning_rate": 6.8814224868185645e-06,
      "loss": 0.0003,
      "step": 19696
    },
    {
      "epoch": 0.31187358487578576,
      "grad_norm": 0.9284811615943909,
      "learning_rate": 6.881264151242143e-06,
      "loss": 0.0105,
      "step": 19697
    },
    {
      "epoch": 0.3118894184334278,
      "grad_norm": 0.4916706085205078,
      "learning_rate": 6.881105815665723e-06,
      "loss": 0.189,
      "step": 19698
    },
    {
      "epoch": 0.3119052519910699,
      "grad_norm": 0.3708564341068268,
      "learning_rate": 6.880947480089302e-06,
      "loss": 0.0453,
      "step": 19699
    },
    {
      "epoch": 0.31192108554871195,
      "grad_norm": 0.026099810376763344,
      "learning_rate": 6.880789144512882e-06,
      "loss": 0.0012,
      "step": 19700
    },
    {
      "epoch": 0.311936919106354,
      "grad_norm": 0.018938595429062843,
      "learning_rate": 6.880630808936461e-06,
      "loss": 0.0011,
      "step": 19701
    },
    {
      "epoch": 0.3119527526639961,
      "grad_norm": 0.03570409491658211,
      "learning_rate": 6.880472473360041e-06,
      "loss": 0.0021,
      "step": 19702
    },
    {
      "epoch": 0.31196858622163814,
      "grad_norm": 0.7597036957740784,
      "learning_rate": 6.880314137783619e-06,
      "loss": 0.2699,
      "step": 19703
    },
    {
      "epoch": 0.3119844197792802,
      "grad_norm": 0.13014055788516998,
      "learning_rate": 6.880155802207199e-06,
      "loss": 0.0479,
      "step": 19704
    },
    {
      "epoch": 0.3120002533369223,
      "grad_norm": 0.6856734752655029,
      "learning_rate": 6.879997466630778e-06,
      "loss": 0.0937,
      "step": 19705
    },
    {
      "epoch": 0.31201608689456434,
      "grad_norm": 0.6343035101890564,
      "learning_rate": 6.879839131054357e-06,
      "loss": 0.2438,
      "step": 19706
    },
    {
      "epoch": 0.3120319204522064,
      "grad_norm": 0.26298362016677856,
      "learning_rate": 6.879680795477937e-06,
      "loss": 0.0608,
      "step": 19707
    },
    {
      "epoch": 0.31204775400984847,
      "grad_norm": 0.5184423923492432,
      "learning_rate": 6.879522459901515e-06,
      "loss": 0.0644,
      "step": 19708
    },
    {
      "epoch": 0.31206358756749053,
      "grad_norm": 0.5094759464263916,
      "learning_rate": 6.879364124325095e-06,
      "loss": 0.1598,
      "step": 19709
    },
    {
      "epoch": 0.3120794211251326,
      "grad_norm": 0.34515056014060974,
      "learning_rate": 6.879205788748674e-06,
      "loss": 0.1215,
      "step": 19710
    },
    {
      "epoch": 0.31209525468277466,
      "grad_norm": 0.3467830419540405,
      "learning_rate": 6.879047453172254e-06,
      "loss": 0.0961,
      "step": 19711
    },
    {
      "epoch": 0.3121110882404167,
      "grad_norm": 0.03239569067955017,
      "learning_rate": 6.878889117595833e-06,
      "loss": 0.0016,
      "step": 19712
    },
    {
      "epoch": 0.3121269217980588,
      "grad_norm": 0.6323226094245911,
      "learning_rate": 6.878730782019413e-06,
      "loss": 0.4401,
      "step": 19713
    },
    {
      "epoch": 0.31214275535570085,
      "grad_norm": 0.15132984519004822,
      "learning_rate": 6.878572446442991e-06,
      "loss": 0.0047,
      "step": 19714
    },
    {
      "epoch": 0.3121585889133429,
      "grad_norm": 0.0016950084827840328,
      "learning_rate": 6.878414110866571e-06,
      "loss": 0.0,
      "step": 19715
    },
    {
      "epoch": 0.312174422470985,
      "grad_norm": 0.3119576871395111,
      "learning_rate": 6.87825577529015e-06,
      "loss": 0.0317,
      "step": 19716
    },
    {
      "epoch": 0.31219025602862704,
      "grad_norm": 0.5244043469429016,
      "learning_rate": 6.87809743971373e-06,
      "loss": 0.4616,
      "step": 19717
    },
    {
      "epoch": 0.31220608958626916,
      "grad_norm": 0.0171638373285532,
      "learning_rate": 6.8779391041373085e-06,
      "loss": 0.0007,
      "step": 19718
    },
    {
      "epoch": 0.31222192314391123,
      "grad_norm": 0.5065129399299622,
      "learning_rate": 6.8777807685608884e-06,
      "loss": 0.3358,
      "step": 19719
    },
    {
      "epoch": 0.3122377567015533,
      "grad_norm": 0.0010438964236527681,
      "learning_rate": 6.8776224329844675e-06,
      "loss": 0.0,
      "step": 19720
    },
    {
      "epoch": 0.31225359025919536,
      "grad_norm": 0.2146511673927307,
      "learning_rate": 6.8774640974080474e-06,
      "loss": 0.0279,
      "step": 19721
    },
    {
      "epoch": 0.3122694238168374,
      "grad_norm": 2.2347075939178467,
      "learning_rate": 6.8773057618316265e-06,
      "loss": 0.1224,
      "step": 19722
    },
    {
      "epoch": 0.3122852573744795,
      "grad_norm": 0.0004372569965198636,
      "learning_rate": 6.8771474262552064e-06,
      "loss": 0.0,
      "step": 19723
    },
    {
      "epoch": 0.31230109093212155,
      "grad_norm": 0.0036817986983805895,
      "learning_rate": 6.876989090678785e-06,
      "loss": 0.0001,
      "step": 19724
    },
    {
      "epoch": 0.3123169244897636,
      "grad_norm": 0.018836475908756256,
      "learning_rate": 6.876830755102365e-06,
      "loss": 0.001,
      "step": 19725
    },
    {
      "epoch": 0.3123327580474057,
      "grad_norm": 0.4843969941139221,
      "learning_rate": 6.876672419525944e-06,
      "loss": 0.1208,
      "step": 19726
    },
    {
      "epoch": 0.31234859160504774,
      "grad_norm": 0.8660706281661987,
      "learning_rate": 6.876514083949524e-06,
      "loss": 0.0393,
      "step": 19727
    },
    {
      "epoch": 0.3123644251626898,
      "grad_norm": 0.00027298839995637536,
      "learning_rate": 6.876355748373103e-06,
      "loss": 0.0,
      "step": 19728
    },
    {
      "epoch": 0.31238025872033187,
      "grad_norm": 0.23438392579555511,
      "learning_rate": 6.876197412796683e-06,
      "loss": 0.0064,
      "step": 19729
    },
    {
      "epoch": 0.31239609227797394,
      "grad_norm": 0.3668459355831146,
      "learning_rate": 6.876039077220261e-06,
      "loss": 0.1051,
      "step": 19730
    },
    {
      "epoch": 0.312411925835616,
      "grad_norm": 0.41591203212738037,
      "learning_rate": 6.87588074164384e-06,
      "loss": 0.1864,
      "step": 19731
    },
    {
      "epoch": 0.31242775939325806,
      "grad_norm": 0.0005323820514604449,
      "learning_rate": 6.87572240606742e-06,
      "loss": 0.0,
      "step": 19732
    },
    {
      "epoch": 0.31244359295090013,
      "grad_norm": 0.00013123538519721478,
      "learning_rate": 6.875564070490999e-06,
      "loss": 0.0,
      "step": 19733
    },
    {
      "epoch": 0.3124594265085422,
      "grad_norm": 0.015698853880167007,
      "learning_rate": 6.875405734914579e-06,
      "loss": 0.0005,
      "step": 19734
    },
    {
      "epoch": 0.31247526006618426,
      "grad_norm": 0.0007547547575086355,
      "learning_rate": 6.875247399338157e-06,
      "loss": 0.0,
      "step": 19735
    },
    {
      "epoch": 0.3124910936238263,
      "grad_norm": 0.4823921322822571,
      "learning_rate": 6.875089063761737e-06,
      "loss": 0.1366,
      "step": 19736
    },
    {
      "epoch": 0.3125069271814684,
      "grad_norm": 1.2197439670562744,
      "learning_rate": 6.874930728185316e-06,
      "loss": 0.1063,
      "step": 19737
    },
    {
      "epoch": 0.31252276073911045,
      "grad_norm": 0.008727598935365677,
      "learning_rate": 6.874772392608896e-06,
      "loss": 0.0005,
      "step": 19738
    },
    {
      "epoch": 0.3125385942967525,
      "grad_norm": 0.009541376493871212,
      "learning_rate": 6.874614057032475e-06,
      "loss": 0.0004,
      "step": 19739
    },
    {
      "epoch": 0.3125544278543946,
      "grad_norm": 1.14341402053833,
      "learning_rate": 6.874455721456055e-06,
      "loss": 0.1738,
      "step": 19740
    },
    {
      "epoch": 0.31257026141203664,
      "grad_norm": 0.1358845978975296,
      "learning_rate": 6.874297385879633e-06,
      "loss": 0.0187,
      "step": 19741
    },
    {
      "epoch": 0.31258609496967876,
      "grad_norm": 0.8262261748313904,
      "learning_rate": 6.874139050303213e-06,
      "loss": 0.2105,
      "step": 19742
    },
    {
      "epoch": 0.3126019285273208,
      "grad_norm": 1.168630838394165,
      "learning_rate": 6.873980714726792e-06,
      "loss": 0.9844,
      "step": 19743
    },
    {
      "epoch": 0.3126177620849629,
      "grad_norm": 0.025276437401771545,
      "learning_rate": 6.873822379150372e-06,
      "loss": 0.0014,
      "step": 19744
    },
    {
      "epoch": 0.31263359564260496,
      "grad_norm": 1.0586748123168945,
      "learning_rate": 6.873664043573951e-06,
      "loss": 0.0435,
      "step": 19745
    },
    {
      "epoch": 0.312649429200247,
      "grad_norm": 0.3924328088760376,
      "learning_rate": 6.873505707997531e-06,
      "loss": 0.1532,
      "step": 19746
    },
    {
      "epoch": 0.3126652627578891,
      "grad_norm": 0.18364807963371277,
      "learning_rate": 6.8733473724211094e-06,
      "loss": 0.0252,
      "step": 19747
    },
    {
      "epoch": 0.31268109631553115,
      "grad_norm": 0.3866255283355713,
      "learning_rate": 6.873189036844689e-06,
      "loss": 0.1223,
      "step": 19748
    },
    {
      "epoch": 0.3126969298731732,
      "grad_norm": 0.30162110924720764,
      "learning_rate": 6.8730307012682684e-06,
      "loss": 0.0329,
      "step": 19749
    },
    {
      "epoch": 0.3127127634308153,
      "grad_norm": 1.078525424003601,
      "learning_rate": 6.872872365691848e-06,
      "loss": 0.3034,
      "step": 19750
    },
    {
      "epoch": 0.31272859698845734,
      "grad_norm": 0.17068246006965637,
      "learning_rate": 6.8727140301154274e-06,
      "loss": 0.0028,
      "step": 19751
    },
    {
      "epoch": 0.3127444305460994,
      "grad_norm": 0.49393826723098755,
      "learning_rate": 6.872555694539007e-06,
      "loss": 0.165,
      "step": 19752
    },
    {
      "epoch": 0.31276026410374147,
      "grad_norm": 1.5719581842422485,
      "learning_rate": 6.872397358962586e-06,
      "loss": 0.7381,
      "step": 19753
    },
    {
      "epoch": 0.31277609766138353,
      "grad_norm": 0.006319384090602398,
      "learning_rate": 6.872239023386165e-06,
      "loss": 0.0003,
      "step": 19754
    },
    {
      "epoch": 0.3127919312190256,
      "grad_norm": 0.618977963924408,
      "learning_rate": 6.872080687809745e-06,
      "loss": 0.121,
      "step": 19755
    },
    {
      "epoch": 0.31280776477666766,
      "grad_norm": 0.02036348730325699,
      "learning_rate": 6.871922352233324e-06,
      "loss": 0.0007,
      "step": 19756
    },
    {
      "epoch": 0.3128235983343097,
      "grad_norm": 1.480709433555603,
      "learning_rate": 6.871764016656904e-06,
      "loss": 0.7688,
      "step": 19757
    },
    {
      "epoch": 0.3128394318919518,
      "grad_norm": 0.9146206974983215,
      "learning_rate": 6.871605681080482e-06,
      "loss": 0.0562,
      "step": 19758
    },
    {
      "epoch": 0.31285526544959386,
      "grad_norm": 0.013903922401368618,
      "learning_rate": 6.871447345504062e-06,
      "loss": 0.0007,
      "step": 19759
    },
    {
      "epoch": 0.3128710990072359,
      "grad_norm": 0.08911186456680298,
      "learning_rate": 6.871289009927641e-06,
      "loss": 0.0047,
      "step": 19760
    },
    {
      "epoch": 0.312886932564878,
      "grad_norm": 0.19093576073646545,
      "learning_rate": 6.871130674351221e-06,
      "loss": 0.0588,
      "step": 19761
    },
    {
      "epoch": 0.31290276612252005,
      "grad_norm": 0.1772949993610382,
      "learning_rate": 6.8709723387748e-06,
      "loss": 0.0426,
      "step": 19762
    },
    {
      "epoch": 0.3129185996801621,
      "grad_norm": 0.7545818090438843,
      "learning_rate": 6.87081400319838e-06,
      "loss": 0.6922,
      "step": 19763
    },
    {
      "epoch": 0.3129344332378042,
      "grad_norm": 1.1027824878692627,
      "learning_rate": 6.870655667621958e-06,
      "loss": 0.3058,
      "step": 19764
    },
    {
      "epoch": 0.31295026679544624,
      "grad_norm": 0.8446852564811707,
      "learning_rate": 6.870497332045538e-06,
      "loss": 0.5959,
      "step": 19765
    },
    {
      "epoch": 0.31296610035308836,
      "grad_norm": 0.014707261696457863,
      "learning_rate": 6.870338996469117e-06,
      "loss": 0.0006,
      "step": 19766
    },
    {
      "epoch": 0.3129819339107304,
      "grad_norm": 0.00011651618115138263,
      "learning_rate": 6.870180660892697e-06,
      "loss": 0.0,
      "step": 19767
    },
    {
      "epoch": 0.3129977674683725,
      "grad_norm": 0.01030106283724308,
      "learning_rate": 6.870022325316276e-06,
      "loss": 0.0004,
      "step": 19768
    },
    {
      "epoch": 0.31301360102601455,
      "grad_norm": 0.07561935484409332,
      "learning_rate": 6.869863989739856e-06,
      "loss": 0.0038,
      "step": 19769
    },
    {
      "epoch": 0.3130294345836566,
      "grad_norm": 0.8586115837097168,
      "learning_rate": 6.869705654163434e-06,
      "loss": 0.0955,
      "step": 19770
    },
    {
      "epoch": 0.3130452681412987,
      "grad_norm": 0.884899377822876,
      "learning_rate": 6.869547318587014e-06,
      "loss": 0.0613,
      "step": 19771
    },
    {
      "epoch": 0.31306110169894075,
      "grad_norm": 0.4766271412372589,
      "learning_rate": 6.869388983010593e-06,
      "loss": 0.1622,
      "step": 19772
    },
    {
      "epoch": 0.3130769352565828,
      "grad_norm": 0.02138018049299717,
      "learning_rate": 6.869230647434173e-06,
      "loss": 0.001,
      "step": 19773
    },
    {
      "epoch": 0.3130927688142249,
      "grad_norm": 0.43403708934783936,
      "learning_rate": 6.869072311857752e-06,
      "loss": 0.0434,
      "step": 19774
    },
    {
      "epoch": 0.31310860237186694,
      "grad_norm": 0.6287585496902466,
      "learning_rate": 6.868913976281332e-06,
      "loss": 0.2247,
      "step": 19775
    },
    {
      "epoch": 0.313124435929509,
      "grad_norm": 0.4283859431743622,
      "learning_rate": 6.86875564070491e-06,
      "loss": 0.1312,
      "step": 19776
    },
    {
      "epoch": 0.31314026948715107,
      "grad_norm": 0.19444848597049713,
      "learning_rate": 6.86859730512849e-06,
      "loss": 0.0688,
      "step": 19777
    },
    {
      "epoch": 0.31315610304479313,
      "grad_norm": 0.043166473507881165,
      "learning_rate": 6.868438969552069e-06,
      "loss": 0.0016,
      "step": 19778
    },
    {
      "epoch": 0.3131719366024352,
      "grad_norm": 0.40018898248672485,
      "learning_rate": 6.8682806339756484e-06,
      "loss": 0.2224,
      "step": 19779
    },
    {
      "epoch": 0.31318777016007726,
      "grad_norm": 0.4060727059841156,
      "learning_rate": 6.868122298399228e-06,
      "loss": 0.0294,
      "step": 19780
    },
    {
      "epoch": 0.3132036037177193,
      "grad_norm": 0.0247026439756155,
      "learning_rate": 6.867963962822807e-06,
      "loss": 0.0013,
      "step": 19781
    },
    {
      "epoch": 0.3132194372753614,
      "grad_norm": 0.3001616597175598,
      "learning_rate": 6.8678056272463865e-06,
      "loss": 0.0943,
      "step": 19782
    },
    {
      "epoch": 0.31323527083300345,
      "grad_norm": 0.013963259756565094,
      "learning_rate": 6.867647291669966e-06,
      "loss": 0.0007,
      "step": 19783
    },
    {
      "epoch": 0.3132511043906455,
      "grad_norm": 0.0021684146486222744,
      "learning_rate": 6.8674889560935455e-06,
      "loss": 0.0,
      "step": 19784
    },
    {
      "epoch": 0.3132669379482876,
      "grad_norm": 0.34469813108444214,
      "learning_rate": 6.867330620517124e-06,
      "loss": 0.0311,
      "step": 19785
    },
    {
      "epoch": 0.31328277150592965,
      "grad_norm": 0.37557530403137207,
      "learning_rate": 6.867172284940704e-06,
      "loss": 0.2039,
      "step": 19786
    },
    {
      "epoch": 0.3132986050635717,
      "grad_norm": 0.6714717745780945,
      "learning_rate": 6.867013949364283e-06,
      "loss": 0.2499,
      "step": 19787
    },
    {
      "epoch": 0.3133144386212138,
      "grad_norm": 0.33685028553009033,
      "learning_rate": 6.866855613787863e-06,
      "loss": 0.0851,
      "step": 19788
    },
    {
      "epoch": 0.31333027217885584,
      "grad_norm": 0.5639284253120422,
      "learning_rate": 6.866697278211442e-06,
      "loss": 0.2778,
      "step": 19789
    },
    {
      "epoch": 0.31334610573649796,
      "grad_norm": 0.20625148713588715,
      "learning_rate": 6.866538942635022e-06,
      "loss": 0.0768,
      "step": 19790
    },
    {
      "epoch": 0.31336193929414,
      "grad_norm": 0.041501663625240326,
      "learning_rate": 6.8663806070586e-06,
      "loss": 0.0021,
      "step": 19791
    },
    {
      "epoch": 0.3133777728517821,
      "grad_norm": 0.0710705891251564,
      "learning_rate": 6.86622227148218e-06,
      "loss": 0.004,
      "step": 19792
    },
    {
      "epoch": 0.31339360640942415,
      "grad_norm": 0.698357343673706,
      "learning_rate": 6.866063935905759e-06,
      "loss": 0.2958,
      "step": 19793
    },
    {
      "epoch": 0.3134094399670662,
      "grad_norm": 0.011699901893734932,
      "learning_rate": 6.865905600329339e-06,
      "loss": 0.0008,
      "step": 19794
    },
    {
      "epoch": 0.3134252735247083,
      "grad_norm": 0.36478734016418457,
      "learning_rate": 6.865747264752918e-06,
      "loss": 0.0556,
      "step": 19795
    },
    {
      "epoch": 0.31344110708235035,
      "grad_norm": 0.31295549869537354,
      "learning_rate": 6.865588929176498e-06,
      "loss": 0.0724,
      "step": 19796
    },
    {
      "epoch": 0.3134569406399924,
      "grad_norm": 0.07247675210237503,
      "learning_rate": 6.865430593600076e-06,
      "loss": 0.004,
      "step": 19797
    },
    {
      "epoch": 0.3134727741976345,
      "grad_norm": 0.2950815260410309,
      "learning_rate": 6.865272258023656e-06,
      "loss": 0.064,
      "step": 19798
    },
    {
      "epoch": 0.31348860775527654,
      "grad_norm": 0.3569651246070862,
      "learning_rate": 6.865113922447235e-06,
      "loss": 0.0833,
      "step": 19799
    },
    {
      "epoch": 0.3135044413129186,
      "grad_norm": 0.23437856137752533,
      "learning_rate": 6.864955586870815e-06,
      "loss": 0.0576,
      "step": 19800
    },
    {
      "epoch": 0.31352027487056067,
      "grad_norm": 0.9423203468322754,
      "learning_rate": 6.864797251294394e-06,
      "loss": 0.0958,
      "step": 19801
    },
    {
      "epoch": 0.31353610842820273,
      "grad_norm": 0.2554253935813904,
      "learning_rate": 6.864638915717972e-06,
      "loss": 0.0377,
      "step": 19802
    },
    {
      "epoch": 0.3135519419858448,
      "grad_norm": 0.045522406697273254,
      "learning_rate": 6.864480580141552e-06,
      "loss": 0.0029,
      "step": 19803
    },
    {
      "epoch": 0.31356777554348686,
      "grad_norm": 0.34144678711891174,
      "learning_rate": 6.864322244565131e-06,
      "loss": 0.0648,
      "step": 19804
    },
    {
      "epoch": 0.3135836091011289,
      "grad_norm": 0.6856107115745544,
      "learning_rate": 6.864163908988711e-06,
      "loss": 0.2164,
      "step": 19805
    },
    {
      "epoch": 0.313599442658771,
      "grad_norm": 0.8670046329498291,
      "learning_rate": 6.86400557341229e-06,
      "loss": 0.1631,
      "step": 19806
    },
    {
      "epoch": 0.31361527621641305,
      "grad_norm": 0.7438865303993225,
      "learning_rate": 6.86384723783587e-06,
      "loss": 0.0272,
      "step": 19807
    },
    {
      "epoch": 0.3136311097740551,
      "grad_norm": 0.33858415484428406,
      "learning_rate": 6.8636889022594485e-06,
      "loss": 0.0399,
      "step": 19808
    },
    {
      "epoch": 0.3136469433316972,
      "grad_norm": 0.347800612449646,
      "learning_rate": 6.8635305666830285e-06,
      "loss": 0.2152,
      "step": 19809
    },
    {
      "epoch": 0.31366277688933925,
      "grad_norm": 0.5886645913124084,
      "learning_rate": 6.8633722311066075e-06,
      "loss": 0.1985,
      "step": 19810
    },
    {
      "epoch": 0.3136786104469813,
      "grad_norm": 0.03819127008318901,
      "learning_rate": 6.8632138955301875e-06,
      "loss": 0.0024,
      "step": 19811
    },
    {
      "epoch": 0.3136944440046234,
      "grad_norm": 0.006313761230558157,
      "learning_rate": 6.8630555599537665e-06,
      "loss": 0.0002,
      "step": 19812
    },
    {
      "epoch": 0.31371027756226544,
      "grad_norm": 0.41823193430900574,
      "learning_rate": 6.8628972243773465e-06,
      "loss": 0.3842,
      "step": 19813
    },
    {
      "epoch": 0.31372611111990756,
      "grad_norm": 0.6517950296401978,
      "learning_rate": 6.862738888800925e-06,
      "loss": 0.2223,
      "step": 19814
    },
    {
      "epoch": 0.3137419446775496,
      "grad_norm": 0.0001908148406073451,
      "learning_rate": 6.862580553224505e-06,
      "loss": 0.0,
      "step": 19815
    },
    {
      "epoch": 0.3137577782351917,
      "grad_norm": 0.6372238397598267,
      "learning_rate": 6.862422217648084e-06,
      "loss": 0.3928,
      "step": 19816
    },
    {
      "epoch": 0.31377361179283375,
      "grad_norm": 0.13977046310901642,
      "learning_rate": 6.862263882071664e-06,
      "loss": 0.0248,
      "step": 19817
    },
    {
      "epoch": 0.3137894453504758,
      "grad_norm": 0.5666294097900391,
      "learning_rate": 6.862105546495243e-06,
      "loss": 0.0441,
      "step": 19818
    },
    {
      "epoch": 0.3138052789081179,
      "grad_norm": 1.4405932426452637,
      "learning_rate": 6.861947210918823e-06,
      "loss": 0.201,
      "step": 19819
    },
    {
      "epoch": 0.31382111246575994,
      "grad_norm": 0.334450900554657,
      "learning_rate": 6.861788875342401e-06,
      "loss": 0.0658,
      "step": 19820
    },
    {
      "epoch": 0.313836946023402,
      "grad_norm": 0.012158137746155262,
      "learning_rate": 6.861630539765981e-06,
      "loss": 0.0004,
      "step": 19821
    },
    {
      "epoch": 0.3138527795810441,
      "grad_norm": 0.2730916440486908,
      "learning_rate": 6.86147220418956e-06,
      "loss": 0.0464,
      "step": 19822
    },
    {
      "epoch": 0.31386861313868614,
      "grad_norm": 1.005276083946228,
      "learning_rate": 6.86131386861314e-06,
      "loss": 0.1582,
      "step": 19823
    },
    {
      "epoch": 0.3138844466963282,
      "grad_norm": 0.3258274793624878,
      "learning_rate": 6.861155533036719e-06,
      "loss": 0.0533,
      "step": 19824
    },
    {
      "epoch": 0.31390028025397027,
      "grad_norm": 0.15951846539974213,
      "learning_rate": 6.860997197460299e-06,
      "loss": 0.0415,
      "step": 19825
    },
    {
      "epoch": 0.31391611381161233,
      "grad_norm": 0.1513245701789856,
      "learning_rate": 6.860838861883877e-06,
      "loss": 0.0053,
      "step": 19826
    },
    {
      "epoch": 0.3139319473692544,
      "grad_norm": 0.8566426038742065,
      "learning_rate": 6.860680526307456e-06,
      "loss": 0.5281,
      "step": 19827
    },
    {
      "epoch": 0.31394778092689646,
      "grad_norm": 0.8721957802772522,
      "learning_rate": 6.860522190731036e-06,
      "loss": 0.3684,
      "step": 19828
    },
    {
      "epoch": 0.3139636144845385,
      "grad_norm": 0.7491023540496826,
      "learning_rate": 6.860363855154615e-06,
      "loss": 0.2332,
      "step": 19829
    },
    {
      "epoch": 0.3139794480421806,
      "grad_norm": 0.663237452507019,
      "learning_rate": 6.860205519578195e-06,
      "loss": 0.5666,
      "step": 19830
    },
    {
      "epoch": 0.31399528159982265,
      "grad_norm": 0.4613913893699646,
      "learning_rate": 6.860047184001773e-06,
      "loss": 0.0969,
      "step": 19831
    },
    {
      "epoch": 0.3140111151574647,
      "grad_norm": 0.5487146377563477,
      "learning_rate": 6.859888848425353e-06,
      "loss": 0.1901,
      "step": 19832
    },
    {
      "epoch": 0.3140269487151068,
      "grad_norm": 0.3261808454990387,
      "learning_rate": 6.859730512848932e-06,
      "loss": 0.1327,
      "step": 19833
    },
    {
      "epoch": 0.31404278227274884,
      "grad_norm": 0.06804627180099487,
      "learning_rate": 6.859572177272512e-06,
      "loss": 0.0048,
      "step": 19834
    },
    {
      "epoch": 0.3140586158303909,
      "grad_norm": 0.5550814270973206,
      "learning_rate": 6.859413841696091e-06,
      "loss": 0.1434,
      "step": 19835
    },
    {
      "epoch": 0.314074449388033,
      "grad_norm": 0.5508300065994263,
      "learning_rate": 6.859255506119671e-06,
      "loss": 0.0706,
      "step": 19836
    },
    {
      "epoch": 0.31409028294567504,
      "grad_norm": 0.4133862853050232,
      "learning_rate": 6.8590971705432495e-06,
      "loss": 0.0304,
      "step": 19837
    },
    {
      "epoch": 0.31410611650331716,
      "grad_norm": 0.43360915780067444,
      "learning_rate": 6.858938834966829e-06,
      "loss": 0.1091,
      "step": 19838
    },
    {
      "epoch": 0.3141219500609592,
      "grad_norm": 2.5618131160736084,
      "learning_rate": 6.8587804993904085e-06,
      "loss": 1.0025,
      "step": 19839
    },
    {
      "epoch": 0.3141377836186013,
      "grad_norm": 0.5801730155944824,
      "learning_rate": 6.858622163813988e-06,
      "loss": 0.2414,
      "step": 19840
    },
    {
      "epoch": 0.31415361717624335,
      "grad_norm": 0.8347033262252808,
      "learning_rate": 6.8584638282375675e-06,
      "loss": 0.0475,
      "step": 19841
    },
    {
      "epoch": 0.3141694507338854,
      "grad_norm": 0.6007348895072937,
      "learning_rate": 6.858305492661147e-06,
      "loss": 0.0922,
      "step": 19842
    },
    {
      "epoch": 0.3141852842915275,
      "grad_norm": 0.22155721485614777,
      "learning_rate": 6.858147157084726e-06,
      "loss": 0.0622,
      "step": 19843
    },
    {
      "epoch": 0.31420111784916954,
      "grad_norm": 0.00026030815206468105,
      "learning_rate": 6.8579888215083056e-06,
      "loss": 0.0,
      "step": 19844
    },
    {
      "epoch": 0.3142169514068116,
      "grad_norm": 0.0067020901478827,
      "learning_rate": 6.857830485931885e-06,
      "loss": 0.0003,
      "step": 19845
    },
    {
      "epoch": 0.31423278496445367,
      "grad_norm": 0.3610229790210724,
      "learning_rate": 6.8576721503554646e-06,
      "loss": 0.1018,
      "step": 19846
    },
    {
      "epoch": 0.31424861852209574,
      "grad_norm": 0.28695183992385864,
      "learning_rate": 6.857513814779043e-06,
      "loss": 0.0271,
      "step": 19847
    },
    {
      "epoch": 0.3142644520797378,
      "grad_norm": 0.019099757075309753,
      "learning_rate": 6.857355479202623e-06,
      "loss": 0.001,
      "step": 19848
    },
    {
      "epoch": 0.31428028563737986,
      "grad_norm": 0.6187863349914551,
      "learning_rate": 6.857197143626202e-06,
      "loss": 0.2578,
      "step": 19849
    },
    {
      "epoch": 0.31429611919502193,
      "grad_norm": 0.7785883545875549,
      "learning_rate": 6.857038808049781e-06,
      "loss": 0.3579,
      "step": 19850
    },
    {
      "epoch": 0.314311952752664,
      "grad_norm": 0.04069950431585312,
      "learning_rate": 6.856880472473361e-06,
      "loss": 0.0028,
      "step": 19851
    },
    {
      "epoch": 0.31432778631030606,
      "grad_norm": 0.00032041355734691024,
      "learning_rate": 6.856722136896939e-06,
      "loss": 0.0,
      "step": 19852
    },
    {
      "epoch": 0.3143436198679481,
      "grad_norm": 0.1681469976902008,
      "learning_rate": 6.856563801320519e-06,
      "loss": 0.0886,
      "step": 19853
    },
    {
      "epoch": 0.3143594534255902,
      "grad_norm": 0.0008746028761379421,
      "learning_rate": 6.856405465744098e-06,
      "loss": 0.0,
      "step": 19854
    },
    {
      "epoch": 0.31437528698323225,
      "grad_norm": 0.010338804684579372,
      "learning_rate": 6.856247130167678e-06,
      "loss": 0.0005,
      "step": 19855
    },
    {
      "epoch": 0.3143911205408743,
      "grad_norm": 0.309548020362854,
      "learning_rate": 6.856088794591257e-06,
      "loss": 0.1168,
      "step": 19856
    },
    {
      "epoch": 0.3144069540985164,
      "grad_norm": 0.5397459864616394,
      "learning_rate": 6.855930459014837e-06,
      "loss": 0.1318,
      "step": 19857
    },
    {
      "epoch": 0.31442278765615844,
      "grad_norm": 0.5671253800392151,
      "learning_rate": 6.855772123438415e-06,
      "loss": 0.0565,
      "step": 19858
    },
    {
      "epoch": 0.3144386212138005,
      "grad_norm": 0.6011003255844116,
      "learning_rate": 6.855613787861995e-06,
      "loss": 0.1294,
      "step": 19859
    },
    {
      "epoch": 0.31445445477144257,
      "grad_norm": 0.003034967463463545,
      "learning_rate": 6.855455452285574e-06,
      "loss": 0.0001,
      "step": 19860
    },
    {
      "epoch": 0.31447028832908464,
      "grad_norm": 0.35162553191185,
      "learning_rate": 6.855297116709154e-06,
      "loss": 0.0528,
      "step": 19861
    },
    {
      "epoch": 0.31448612188672675,
      "grad_norm": 0.020439166575670242,
      "learning_rate": 6.855138781132733e-06,
      "loss": 0.0012,
      "step": 19862
    },
    {
      "epoch": 0.3145019554443688,
      "grad_norm": 0.3330693244934082,
      "learning_rate": 6.854980445556313e-06,
      "loss": 0.1317,
      "step": 19863
    },
    {
      "epoch": 0.3145177890020109,
      "grad_norm": 0.8851323127746582,
      "learning_rate": 6.854822109979891e-06,
      "loss": 0.127,
      "step": 19864
    },
    {
      "epoch": 0.31453362255965295,
      "grad_norm": 0.010656465776264668,
      "learning_rate": 6.854663774403471e-06,
      "loss": 0.0005,
      "step": 19865
    },
    {
      "epoch": 0.314549456117295,
      "grad_norm": 0.36559805274009705,
      "learning_rate": 6.85450543882705e-06,
      "loss": 0.1181,
      "step": 19866
    },
    {
      "epoch": 0.3145652896749371,
      "grad_norm": 0.33670613169670105,
      "learning_rate": 6.85434710325063e-06,
      "loss": 0.0448,
      "step": 19867
    },
    {
      "epoch": 0.31458112323257914,
      "grad_norm": 1.0707371234893799,
      "learning_rate": 6.854188767674209e-06,
      "loss": 0.8717,
      "step": 19868
    },
    {
      "epoch": 0.3145969567902212,
      "grad_norm": 0.0006485744961537421,
      "learning_rate": 6.854030432097789e-06,
      "loss": 0.0,
      "step": 19869
    },
    {
      "epoch": 0.31461279034786327,
      "grad_norm": 0.451982706785202,
      "learning_rate": 6.8538720965213676e-06,
      "loss": 0.1898,
      "step": 19870
    },
    {
      "epoch": 0.31462862390550533,
      "grad_norm": 0.2350100725889206,
      "learning_rate": 6.8537137609449475e-06,
      "loss": 0.024,
      "step": 19871
    },
    {
      "epoch": 0.3146444574631474,
      "grad_norm": 0.627610445022583,
      "learning_rate": 6.8535554253685266e-06,
      "loss": 0.1757,
      "step": 19872
    },
    {
      "epoch": 0.31466029102078946,
      "grad_norm": 0.3018026351928711,
      "learning_rate": 6.8533970897921065e-06,
      "loss": 0.046,
      "step": 19873
    },
    {
      "epoch": 0.3146761245784315,
      "grad_norm": 0.3247283697128296,
      "learning_rate": 6.8532387542156856e-06,
      "loss": 0.0801,
      "step": 19874
    },
    {
      "epoch": 0.3146919581360736,
      "grad_norm": 0.25929057598114014,
      "learning_rate": 6.853080418639264e-06,
      "loss": 0.0885,
      "step": 19875
    },
    {
      "epoch": 0.31470779169371565,
      "grad_norm": 0.03317699208855629,
      "learning_rate": 6.852922083062844e-06,
      "loss": 0.0014,
      "step": 19876
    },
    {
      "epoch": 0.3147236252513577,
      "grad_norm": 0.043827783316373825,
      "learning_rate": 6.852763747486423e-06,
      "loss": 0.0055,
      "step": 19877
    },
    {
      "epoch": 0.3147394588089998,
      "grad_norm": 0.5939390063285828,
      "learning_rate": 6.852605411910003e-06,
      "loss": 0.127,
      "step": 19878
    },
    {
      "epoch": 0.31475529236664185,
      "grad_norm": 0.00018269378051627427,
      "learning_rate": 6.852447076333582e-06,
      "loss": 0.0,
      "step": 19879
    },
    {
      "epoch": 0.3147711259242839,
      "grad_norm": 0.32210487127304077,
      "learning_rate": 6.852288740757162e-06,
      "loss": 0.0167,
      "step": 19880
    },
    {
      "epoch": 0.314786959481926,
      "grad_norm": 0.9942280054092407,
      "learning_rate": 6.85213040518074e-06,
      "loss": 0.4957,
      "step": 19881
    },
    {
      "epoch": 0.31480279303956804,
      "grad_norm": 0.23582518100738525,
      "learning_rate": 6.85197206960432e-06,
      "loss": 0.0521,
      "step": 19882
    },
    {
      "epoch": 0.3148186265972101,
      "grad_norm": 0.636873722076416,
      "learning_rate": 6.851813734027899e-06,
      "loss": 0.2183,
      "step": 19883
    },
    {
      "epoch": 0.31483446015485217,
      "grad_norm": 0.48658835887908936,
      "learning_rate": 6.851655398451479e-06,
      "loss": 0.0654,
      "step": 19884
    },
    {
      "epoch": 0.31485029371249423,
      "grad_norm": 0.34238719940185547,
      "learning_rate": 6.851497062875058e-06,
      "loss": 0.0872,
      "step": 19885
    },
    {
      "epoch": 0.31486612727013635,
      "grad_norm": 0.0006054879631847143,
      "learning_rate": 6.851338727298638e-06,
      "loss": 0.0,
      "step": 19886
    },
    {
      "epoch": 0.3148819608277784,
      "grad_norm": 0.40619173645973206,
      "learning_rate": 6.851180391722216e-06,
      "loss": 0.0742,
      "step": 19887
    },
    {
      "epoch": 0.3148977943854205,
      "grad_norm": 0.00032611339702270925,
      "learning_rate": 6.851022056145796e-06,
      "loss": 0.0,
      "step": 19888
    },
    {
      "epoch": 0.31491362794306255,
      "grad_norm": 0.32167935371398926,
      "learning_rate": 6.850863720569375e-06,
      "loss": 0.0246,
      "step": 19889
    },
    {
      "epoch": 0.3149294615007046,
      "grad_norm": 0.7057735323905945,
      "learning_rate": 6.850705384992955e-06,
      "loss": 0.2491,
      "step": 19890
    },
    {
      "epoch": 0.3149452950583467,
      "grad_norm": 0.04661799222230911,
      "learning_rate": 6.850547049416534e-06,
      "loss": 0.0028,
      "step": 19891
    },
    {
      "epoch": 0.31496112861598874,
      "grad_norm": 0.0005483167478814721,
      "learning_rate": 6.850388713840114e-06,
      "loss": 0.0,
      "step": 19892
    },
    {
      "epoch": 0.3149769621736308,
      "grad_norm": 0.399225115776062,
      "learning_rate": 6.850230378263692e-06,
      "loss": 0.1021,
      "step": 19893
    },
    {
      "epoch": 0.31499279573127287,
      "grad_norm": 0.03259451687335968,
      "learning_rate": 6.850072042687272e-06,
      "loss": 0.0015,
      "step": 19894
    },
    {
      "epoch": 0.31500862928891493,
      "grad_norm": 0.23323450982570648,
      "learning_rate": 6.849913707110851e-06,
      "loss": 0.0282,
      "step": 19895
    },
    {
      "epoch": 0.315024462846557,
      "grad_norm": 0.0004361157480161637,
      "learning_rate": 6.849755371534431e-06,
      "loss": 0.0,
      "step": 19896
    },
    {
      "epoch": 0.31504029640419906,
      "grad_norm": 0.016129231080412865,
      "learning_rate": 6.84959703595801e-06,
      "loss": 0.0008,
      "step": 19897
    },
    {
      "epoch": 0.3150561299618411,
      "grad_norm": 0.013336720876395702,
      "learning_rate": 6.8494387003815886e-06,
      "loss": 0.0005,
      "step": 19898
    },
    {
      "epoch": 0.3150719635194832,
      "grad_norm": 0.010269890539348125,
      "learning_rate": 6.8492803648051685e-06,
      "loss": 0.0006,
      "step": 19899
    },
    {
      "epoch": 0.31508779707712525,
      "grad_norm": 0.020076187327504158,
      "learning_rate": 6.8491220292287476e-06,
      "loss": 0.0009,
      "step": 19900
    },
    {
      "epoch": 0.3151036306347673,
      "grad_norm": 0.408682644367218,
      "learning_rate": 6.8489636936523275e-06,
      "loss": 0.1966,
      "step": 19901
    },
    {
      "epoch": 0.3151194641924094,
      "grad_norm": 0.027828052639961243,
      "learning_rate": 6.8488053580759066e-06,
      "loss": 0.0016,
      "step": 19902
    },
    {
      "epoch": 0.31513529775005145,
      "grad_norm": 0.2438865303993225,
      "learning_rate": 6.8486470224994865e-06,
      "loss": 0.0917,
      "step": 19903
    },
    {
      "epoch": 0.3151511313076935,
      "grad_norm": 0.5657527446746826,
      "learning_rate": 6.848488686923065e-06,
      "loss": 0.2245,
      "step": 19904
    },
    {
      "epoch": 0.3151669648653356,
      "grad_norm": 0.265076220035553,
      "learning_rate": 6.848330351346645e-06,
      "loss": 0.1229,
      "step": 19905
    },
    {
      "epoch": 0.31518279842297764,
      "grad_norm": 0.5830942392349243,
      "learning_rate": 6.848172015770224e-06,
      "loss": 0.4504,
      "step": 19906
    },
    {
      "epoch": 0.3151986319806197,
      "grad_norm": 0.23374047875404358,
      "learning_rate": 6.848013680193804e-06,
      "loss": 0.0656,
      "step": 19907
    },
    {
      "epoch": 0.31521446553826177,
      "grad_norm": 0.3340144455432892,
      "learning_rate": 6.847855344617383e-06,
      "loss": 0.0802,
      "step": 19908
    },
    {
      "epoch": 0.31523029909590383,
      "grad_norm": 0.017358725890517235,
      "learning_rate": 6.847697009040962e-06,
      "loss": 0.001,
      "step": 19909
    },
    {
      "epoch": 0.31524613265354595,
      "grad_norm": 0.4183906614780426,
      "learning_rate": 6.847538673464541e-06,
      "loss": 0.1028,
      "step": 19910
    },
    {
      "epoch": 0.315261966211188,
      "grad_norm": 0.697246789932251,
      "learning_rate": 6.847380337888121e-06,
      "loss": 0.3601,
      "step": 19911
    },
    {
      "epoch": 0.3152777997688301,
      "grad_norm": 0.8715192079544067,
      "learning_rate": 6.8472220023117e-06,
      "loss": 0.1124,
      "step": 19912
    },
    {
      "epoch": 0.31529363332647214,
      "grad_norm": 0.00021436097449623048,
      "learning_rate": 6.84706366673528e-06,
      "loss": 0.0,
      "step": 19913
    },
    {
      "epoch": 0.3153094668841142,
      "grad_norm": 0.4115903079509735,
      "learning_rate": 6.846905331158858e-06,
      "loss": 0.097,
      "step": 19914
    },
    {
      "epoch": 0.3153253004417563,
      "grad_norm": 0.1805475652217865,
      "learning_rate": 6.846746995582438e-06,
      "loss": 0.0293,
      "step": 19915
    },
    {
      "epoch": 0.31534113399939834,
      "grad_norm": 0.3971683382987976,
      "learning_rate": 6.846588660006017e-06,
      "loss": 0.1383,
      "step": 19916
    },
    {
      "epoch": 0.3153569675570404,
      "grad_norm": 0.2738577127456665,
      "learning_rate": 6.846430324429597e-06,
      "loss": 0.0728,
      "step": 19917
    },
    {
      "epoch": 0.31537280111468247,
      "grad_norm": 0.01835392229259014,
      "learning_rate": 6.846271988853176e-06,
      "loss": 0.001,
      "step": 19918
    },
    {
      "epoch": 0.31538863467232453,
      "grad_norm": 0.43436959385871887,
      "learning_rate": 6.846113653276756e-06,
      "loss": 0.2232,
      "step": 19919
    },
    {
      "epoch": 0.3154044682299666,
      "grad_norm": 0.5452309846878052,
      "learning_rate": 6.845955317700334e-06,
      "loss": 0.13,
      "step": 19920
    },
    {
      "epoch": 0.31542030178760866,
      "grad_norm": 0.3087904453277588,
      "learning_rate": 6.845796982123914e-06,
      "loss": 0.0905,
      "step": 19921
    },
    {
      "epoch": 0.3154361353452507,
      "grad_norm": 0.01920648105442524,
      "learning_rate": 6.845638646547493e-06,
      "loss": 0.0012,
      "step": 19922
    },
    {
      "epoch": 0.3154519689028928,
      "grad_norm": 0.9836719632148743,
      "learning_rate": 6.845480310971072e-06,
      "loss": 0.2649,
      "step": 19923
    },
    {
      "epoch": 0.31546780246053485,
      "grad_norm": 0.03185834735631943,
      "learning_rate": 6.845321975394652e-06,
      "loss": 0.0019,
      "step": 19924
    },
    {
      "epoch": 0.3154836360181769,
      "grad_norm": 0.4555814862251282,
      "learning_rate": 6.8451636398182305e-06,
      "loss": 0.128,
      "step": 19925
    },
    {
      "epoch": 0.315499469575819,
      "grad_norm": 0.4075496792793274,
      "learning_rate": 6.84500530424181e-06,
      "loss": 0.0886,
      "step": 19926
    },
    {
      "epoch": 0.31551530313346104,
      "grad_norm": 0.3358100950717926,
      "learning_rate": 6.8448469686653895e-06,
      "loss": 0.0635,
      "step": 19927
    },
    {
      "epoch": 0.3155311366911031,
      "grad_norm": 0.5912715196609497,
      "learning_rate": 6.844688633088969e-06,
      "loss": 0.1797,
      "step": 19928
    },
    {
      "epoch": 0.3155469702487452,
      "grad_norm": 1.532425045967102,
      "learning_rate": 6.8445302975125485e-06,
      "loss": 0.0464,
      "step": 19929
    },
    {
      "epoch": 0.31556280380638724,
      "grad_norm": 0.5161404013633728,
      "learning_rate": 6.844371961936128e-06,
      "loss": 0.2283,
      "step": 19930
    },
    {
      "epoch": 0.3155786373640293,
      "grad_norm": 0.848157525062561,
      "learning_rate": 6.844213626359707e-06,
      "loss": 0.6058,
      "step": 19931
    },
    {
      "epoch": 0.31559447092167137,
      "grad_norm": 0.02382975071668625,
      "learning_rate": 6.844055290783287e-06,
      "loss": 0.0016,
      "step": 19932
    },
    {
      "epoch": 0.31561030447931343,
      "grad_norm": 0.6029000878334045,
      "learning_rate": 6.843896955206866e-06,
      "loss": 0.1954,
      "step": 19933
    },
    {
      "epoch": 0.31562613803695555,
      "grad_norm": 1.7673790454864502,
      "learning_rate": 6.843738619630446e-06,
      "loss": 0.7408,
      "step": 19934
    },
    {
      "epoch": 0.3156419715945976,
      "grad_norm": 0.052025046199560165,
      "learning_rate": 6.843580284054025e-06,
      "loss": 0.0011,
      "step": 19935
    },
    {
      "epoch": 0.3156578051522397,
      "grad_norm": 0.03164156153798103,
      "learning_rate": 6.843421948477605e-06,
      "loss": 0.0017,
      "step": 19936
    },
    {
      "epoch": 0.31567363870988174,
      "grad_norm": 0.324201375246048,
      "learning_rate": 6.843263612901183e-06,
      "loss": 0.0121,
      "step": 19937
    },
    {
      "epoch": 0.3156894722675238,
      "grad_norm": 0.7030790448188782,
      "learning_rate": 6.843105277324763e-06,
      "loss": 0.4522,
      "step": 19938
    },
    {
      "epoch": 0.31570530582516587,
      "grad_norm": 0.39878469705581665,
      "learning_rate": 6.842946941748342e-06,
      "loss": 0.1383,
      "step": 19939
    },
    {
      "epoch": 0.31572113938280794,
      "grad_norm": 0.07730111479759216,
      "learning_rate": 6.842788606171922e-06,
      "loss": 0.0048,
      "step": 19940
    },
    {
      "epoch": 0.31573697294045,
      "grad_norm": 0.6689322590827942,
      "learning_rate": 6.842630270595501e-06,
      "loss": 0.2344,
      "step": 19941
    },
    {
      "epoch": 0.31575280649809206,
      "grad_norm": 0.5340023040771484,
      "learning_rate": 6.842471935019081e-06,
      "loss": 0.1985,
      "step": 19942
    },
    {
      "epoch": 0.31576864005573413,
      "grad_norm": 0.6569247245788574,
      "learning_rate": 6.842313599442659e-06,
      "loss": 0.1932,
      "step": 19943
    },
    {
      "epoch": 0.3157844736133762,
      "grad_norm": 0.009353308007121086,
      "learning_rate": 6.842155263866239e-06,
      "loss": 0.0006,
      "step": 19944
    },
    {
      "epoch": 0.31580030717101826,
      "grad_norm": 0.022466978058218956,
      "learning_rate": 6.841996928289818e-06,
      "loss": 0.0013,
      "step": 19945
    },
    {
      "epoch": 0.3158161407286603,
      "grad_norm": 0.30015140771865845,
      "learning_rate": 6.841838592713397e-06,
      "loss": 0.0771,
      "step": 19946
    },
    {
      "epoch": 0.3158319742863024,
      "grad_norm": 0.0067529333755373955,
      "learning_rate": 6.841680257136977e-06,
      "loss": 0.0003,
      "step": 19947
    },
    {
      "epoch": 0.31584780784394445,
      "grad_norm": 0.4955999255180359,
      "learning_rate": 6.841521921560555e-06,
      "loss": 0.2351,
      "step": 19948
    },
    {
      "epoch": 0.3158636414015865,
      "grad_norm": 4.829172611236572,
      "learning_rate": 6.841363585984135e-06,
      "loss": 0.4727,
      "step": 19949
    },
    {
      "epoch": 0.3158794749592286,
      "grad_norm": 0.025569340214133263,
      "learning_rate": 6.841205250407714e-06,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.31589530851687064,
      "grad_norm": 0.2184007465839386,
      "learning_rate": 6.841046914831294e-06,
      "loss": 0.0416,
      "step": 19951
    },
    {
      "epoch": 0.3159111420745127,
      "grad_norm": 0.4172995388507843,
      "learning_rate": 6.840888579254873e-06,
      "loss": 0.1559,
      "step": 19952
    },
    {
      "epoch": 0.31592697563215477,
      "grad_norm": 1.0827836990356445,
      "learning_rate": 6.840730243678453e-06,
      "loss": 1.0547,
      "step": 19953
    },
    {
      "epoch": 0.31594280918979684,
      "grad_norm": 0.3273096978664398,
      "learning_rate": 6.840571908102031e-06,
      "loss": 0.1579,
      "step": 19954
    },
    {
      "epoch": 0.3159586427474389,
      "grad_norm": 0.6147337555885315,
      "learning_rate": 6.840413572525611e-06,
      "loss": 0.742,
      "step": 19955
    },
    {
      "epoch": 0.31597447630508096,
      "grad_norm": 0.0007669783080928028,
      "learning_rate": 6.84025523694919e-06,
      "loss": 0.0,
      "step": 19956
    },
    {
      "epoch": 0.31599030986272303,
      "grad_norm": 0.44080010056495667,
      "learning_rate": 6.84009690137277e-06,
      "loss": 0.4964,
      "step": 19957
    },
    {
      "epoch": 0.31600614342036515,
      "grad_norm": 0.3374001085758209,
      "learning_rate": 6.8399385657963494e-06,
      "loss": 0.0689,
      "step": 19958
    },
    {
      "epoch": 0.3160219769780072,
      "grad_norm": 0.42514854669570923,
      "learning_rate": 6.839780230219929e-06,
      "loss": 0.1742,
      "step": 19959
    },
    {
      "epoch": 0.3160378105356493,
      "grad_norm": 0.018176255747675896,
      "learning_rate": 6.839621894643508e-06,
      "loss": 0.0011,
      "step": 19960
    },
    {
      "epoch": 0.31605364409329134,
      "grad_norm": 0.7467638254165649,
      "learning_rate": 6.8394635590670875e-06,
      "loss": 0.1832,
      "step": 19961
    },
    {
      "epoch": 0.3160694776509334,
      "grad_norm": 0.5887563824653625,
      "learning_rate": 6.839305223490667e-06,
      "loss": 0.2359,
      "step": 19962
    },
    {
      "epoch": 0.31608531120857547,
      "grad_norm": 0.007458917796611786,
      "learning_rate": 6.8391468879142465e-06,
      "loss": 0.0004,
      "step": 19963
    },
    {
      "epoch": 0.31610114476621753,
      "grad_norm": 0.37104910612106323,
      "learning_rate": 6.838988552337826e-06,
      "loss": 0.0185,
      "step": 19964
    },
    {
      "epoch": 0.3161169783238596,
      "grad_norm": 0.02418086677789688,
      "learning_rate": 6.8388302167614055e-06,
      "loss": 0.0012,
      "step": 19965
    },
    {
      "epoch": 0.31613281188150166,
      "grad_norm": 0.0053190989419817924,
      "learning_rate": 6.838671881184984e-06,
      "loss": 0.0002,
      "step": 19966
    },
    {
      "epoch": 0.3161486454391437,
      "grad_norm": 0.0005930852494202554,
      "learning_rate": 6.838513545608564e-06,
      "loss": 0.0,
      "step": 19967
    },
    {
      "epoch": 0.3161644789967858,
      "grad_norm": 0.37118998169898987,
      "learning_rate": 6.838355210032143e-06,
      "loss": 0.1056,
      "step": 19968
    },
    {
      "epoch": 0.31618031255442786,
      "grad_norm": 0.00014645353076048195,
      "learning_rate": 6.838196874455723e-06,
      "loss": 0.0,
      "step": 19969
    },
    {
      "epoch": 0.3161961461120699,
      "grad_norm": 0.01021861657500267,
      "learning_rate": 6.838038538879302e-06,
      "loss": 0.0006,
      "step": 19970
    },
    {
      "epoch": 0.316211979669712,
      "grad_norm": 0.4136516749858856,
      "learning_rate": 6.83788020330288e-06,
      "loss": 0.0294,
      "step": 19971
    },
    {
      "epoch": 0.31622781322735405,
      "grad_norm": 0.3506932556629181,
      "learning_rate": 6.83772186772646e-06,
      "loss": 0.0385,
      "step": 19972
    },
    {
      "epoch": 0.3162436467849961,
      "grad_norm": 1.048417329788208,
      "learning_rate": 6.837563532150039e-06,
      "loss": 0.3647,
      "step": 19973
    },
    {
      "epoch": 0.3162594803426382,
      "grad_norm": 0.5196529626846313,
      "learning_rate": 6.837405196573619e-06,
      "loss": 0.4636,
      "step": 19974
    },
    {
      "epoch": 0.31627531390028024,
      "grad_norm": 0.3274022042751312,
      "learning_rate": 6.837246860997197e-06,
      "loss": 0.0304,
      "step": 19975
    },
    {
      "epoch": 0.3162911474579223,
      "grad_norm": 0.20937293767929077,
      "learning_rate": 6.837088525420777e-06,
      "loss": 0.0912,
      "step": 19976
    },
    {
      "epoch": 0.31630698101556437,
      "grad_norm": 0.28974348306655884,
      "learning_rate": 6.836930189844356e-06,
      "loss": 0.0315,
      "step": 19977
    },
    {
      "epoch": 0.31632281457320643,
      "grad_norm": 0.3002278506755829,
      "learning_rate": 6.836771854267936e-06,
      "loss": 0.0817,
      "step": 19978
    },
    {
      "epoch": 0.3163386481308485,
      "grad_norm": 0.01309124194085598,
      "learning_rate": 6.836613518691515e-06,
      "loss": 0.0008,
      "step": 19979
    },
    {
      "epoch": 0.31635448168849056,
      "grad_norm": 0.12084990739822388,
      "learning_rate": 6.836455183115095e-06,
      "loss": 0.0206,
      "step": 19980
    },
    {
      "epoch": 0.3163703152461326,
      "grad_norm": 0.4354584217071533,
      "learning_rate": 6.836296847538673e-06,
      "loss": 0.1671,
      "step": 19981
    },
    {
      "epoch": 0.31638614880377475,
      "grad_norm": 0.9851392507553101,
      "learning_rate": 6.836138511962253e-06,
      "loss": 0.2071,
      "step": 19982
    },
    {
      "epoch": 0.3164019823614168,
      "grad_norm": 0.5473652482032776,
      "learning_rate": 6.835980176385832e-06,
      "loss": 0.0308,
      "step": 19983
    },
    {
      "epoch": 0.3164178159190589,
      "grad_norm": 0.0051162149757146835,
      "learning_rate": 6.835821840809412e-06,
      "loss": 0.0002,
      "step": 19984
    },
    {
      "epoch": 0.31643364947670094,
      "grad_norm": 0.1894194334745407,
      "learning_rate": 6.835663505232991e-06,
      "loss": 0.0486,
      "step": 19985
    },
    {
      "epoch": 0.316449483034343,
      "grad_norm": 0.3226092755794525,
      "learning_rate": 6.835505169656571e-06,
      "loss": 0.1084,
      "step": 19986
    },
    {
      "epoch": 0.31646531659198507,
      "grad_norm": 0.0016654663486406207,
      "learning_rate": 6.8353468340801495e-06,
      "loss": 0.0,
      "step": 19987
    },
    {
      "epoch": 0.31648115014962713,
      "grad_norm": 0.007474609185010195,
      "learning_rate": 6.8351884985037294e-06,
      "loss": 0.0002,
      "step": 19988
    },
    {
      "epoch": 0.3164969837072692,
      "grad_norm": 0.6354922652244568,
      "learning_rate": 6.8350301629273085e-06,
      "loss": 0.2553,
      "step": 19989
    },
    {
      "epoch": 0.31651281726491126,
      "grad_norm": 0.0002635036944411695,
      "learning_rate": 6.8348718273508884e-06,
      "loss": 0.0,
      "step": 19990
    },
    {
      "epoch": 0.3165286508225533,
      "grad_norm": 1.3832789659500122,
      "learning_rate": 6.8347134917744675e-06,
      "loss": 0.3483,
      "step": 19991
    },
    {
      "epoch": 0.3165444843801954,
      "grad_norm": 0.3590661883354187,
      "learning_rate": 6.8345551561980474e-06,
      "loss": 0.127,
      "step": 19992
    },
    {
      "epoch": 0.31656031793783745,
      "grad_norm": 0.690328061580658,
      "learning_rate": 6.834396820621626e-06,
      "loss": 0.7729,
      "step": 19993
    },
    {
      "epoch": 0.3165761514954795,
      "grad_norm": 0.18612180650234222,
      "learning_rate": 6.834238485045205e-06,
      "loss": 0.0842,
      "step": 19994
    },
    {
      "epoch": 0.3165919850531216,
      "grad_norm": 0.6326619982719421,
      "learning_rate": 6.834080149468785e-06,
      "loss": 0.2132,
      "step": 19995
    },
    {
      "epoch": 0.31660781861076365,
      "grad_norm": 0.6342043876647949,
      "learning_rate": 6.833921813892364e-06,
      "loss": 0.3144,
      "step": 19996
    },
    {
      "epoch": 0.3166236521684057,
      "grad_norm": 0.5850056409835815,
      "learning_rate": 6.833763478315944e-06,
      "loss": 0.094,
      "step": 19997
    },
    {
      "epoch": 0.3166394857260478,
      "grad_norm": 0.3977614641189575,
      "learning_rate": 6.833605142739522e-06,
      "loss": 0.1682,
      "step": 19998
    },
    {
      "epoch": 0.31665531928368984,
      "grad_norm": 0.25947105884552,
      "learning_rate": 6.833446807163102e-06,
      "loss": 0.0896,
      "step": 19999
    },
    {
      "epoch": 0.3166711528413319,
      "grad_norm": 0.2889367341995239,
      "learning_rate": 6.833288471586681e-06,
      "loss": 0.1156,
      "step": 20000
    }
  ],
  "logging_steps": 1,
  "max_steps": 63157,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10000,
  "total_flos": 2.5478469516219494e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
