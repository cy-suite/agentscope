{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.15833557642066595,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.5833557642066596e-05,
      "grad_norm": 0.009549028240144253,
      "learning_rate": 9.99984166442358e-06,
      "loss": 0.0022,
      "step": 1
    },
    {
      "epoch": 3.166711528413319e-05,
      "grad_norm": 0.0017209409270435572,
      "learning_rate": 9.999683328847159e-06,
      "loss": 0.0007,
      "step": 2
    },
    {
      "epoch": 4.7500672926199785e-05,
      "grad_norm": 0.012444515712559223,
      "learning_rate": 9.999524993270738e-06,
      "loss": 0.0511,
      "step": 3
    },
    {
      "epoch": 6.333423056826638e-05,
      "grad_norm": 0.02099083736538887,
      "learning_rate": 9.999366657694319e-06,
      "loss": 0.0437,
      "step": 4
    },
    {
      "epoch": 7.916778821033298e-05,
      "grad_norm": 0.024516690522432327,
      "learning_rate": 9.999208322117896e-06,
      "loss": 0.0033,
      "step": 5
    },
    {
      "epoch": 9.500134585239957e-05,
      "grad_norm": 0.0017424607649445534,
      "learning_rate": 9.999049986541477e-06,
      "loss": 0.0031,
      "step": 6
    },
    {
      "epoch": 0.00011083490349446618,
      "grad_norm": 0.08374258130788803,
      "learning_rate": 9.998891650965056e-06,
      "loss": 0.477,
      "step": 7
    },
    {
      "epoch": 0.00012666846113653277,
      "grad_norm": 0.0025217514485120773,
      "learning_rate": 9.998733315388635e-06,
      "loss": 0.0016,
      "step": 8
    },
    {
      "epoch": 0.00014250201877859936,
      "grad_norm": 0.10024815052747726,
      "learning_rate": 9.998574979812214e-06,
      "loss": 0.4695,
      "step": 9
    },
    {
      "epoch": 0.00015833557642066595,
      "grad_norm": 0.06881558150053024,
      "learning_rate": 9.998416644235795e-06,
      "loss": 0.5057,
      "step": 10
    },
    {
      "epoch": 0.00017416913406273255,
      "grad_norm": 0.049916237592697144,
      "learning_rate": 9.998258308659372e-06,
      "loss": 0.3245,
      "step": 11
    },
    {
      "epoch": 0.00019000269170479914,
      "grad_norm": 0.13558970391750336,
      "learning_rate": 9.998099973082953e-06,
      "loss": 0.6892,
      "step": 12
    },
    {
      "epoch": 0.00020583624934686576,
      "grad_norm": 0.31221309304237366,
      "learning_rate": 9.997941637506532e-06,
      "loss": 0.223,
      "step": 13
    },
    {
      "epoch": 0.00022166980698893235,
      "grad_norm": 0.0009371935157105327,
      "learning_rate": 9.997783301930111e-06,
      "loss": 0.0006,
      "step": 14
    },
    {
      "epoch": 0.00023750336463099894,
      "grad_norm": 0.08024498075246811,
      "learning_rate": 9.99762496635369e-06,
      "loss": 0.8434,
      "step": 15
    },
    {
      "epoch": 0.00025333692227306554,
      "grad_norm": 0.07346603274345398,
      "learning_rate": 9.997466630777271e-06,
      "loss": 0.3763,
      "step": 16
    },
    {
      "epoch": 0.00026917047991513216,
      "grad_norm": 0.12533129751682281,
      "learning_rate": 9.997308295200849e-06,
      "loss": 0.8408,
      "step": 17
    },
    {
      "epoch": 0.0002850040375571987,
      "grad_norm": 0.10334694385528564,
      "learning_rate": 9.99714995962443e-06,
      "loss": 0.4418,
      "step": 18
    },
    {
      "epoch": 0.00030083759519926534,
      "grad_norm": 0.0735989362001419,
      "learning_rate": 9.996991624048008e-06,
      "loss": 0.4275,
      "step": 19
    },
    {
      "epoch": 0.0003166711528413319,
      "grad_norm": 0.18988938629627228,
      "learning_rate": 9.996833288471587e-06,
      "loss": 1.6,
      "step": 20
    },
    {
      "epoch": 0.00033250471048339853,
      "grad_norm": 0.08330987393856049,
      "learning_rate": 9.996674952895167e-06,
      "loss": 0.5237,
      "step": 21
    },
    {
      "epoch": 0.0003483382681254651,
      "grad_norm": 0.0009659160277806222,
      "learning_rate": 9.996516617318747e-06,
      "loss": 0.0009,
      "step": 22
    },
    {
      "epoch": 0.0003641718257675317,
      "grad_norm": 0.001814314629882574,
      "learning_rate": 9.996358281742325e-06,
      "loss": 0.0005,
      "step": 23
    },
    {
      "epoch": 0.0003800053834095983,
      "grad_norm": 0.13740240037441254,
      "learning_rate": 9.996199946165906e-06,
      "loss": 0.9509,
      "step": 24
    },
    {
      "epoch": 0.0003958389410516649,
      "grad_norm": 0.11589418351650238,
      "learning_rate": 9.996041610589485e-06,
      "loss": 0.8276,
      "step": 25
    },
    {
      "epoch": 0.0004116724986937315,
      "grad_norm": 0.01746157929301262,
      "learning_rate": 9.995883275013064e-06,
      "loss": 0.0038,
      "step": 26
    },
    {
      "epoch": 0.0004275060563357981,
      "grad_norm": 0.12686511874198914,
      "learning_rate": 9.995724939436643e-06,
      "loss": 1.2706,
      "step": 27
    },
    {
      "epoch": 0.0004433396139778647,
      "grad_norm": 0.2126140296459198,
      "learning_rate": 9.995566603860222e-06,
      "loss": 0.8804,
      "step": 28
    },
    {
      "epoch": 0.00045917317161993127,
      "grad_norm": 0.00014149839989840984,
      "learning_rate": 9.995408268283801e-06,
      "loss": 0.0001,
      "step": 29
    },
    {
      "epoch": 0.0004750067292619979,
      "grad_norm": 0.0024453471414744854,
      "learning_rate": 9.99524993270738e-06,
      "loss": 0.0026,
      "step": 30
    },
    {
      "epoch": 0.0004908402869040645,
      "grad_norm": 0.001601002411916852,
      "learning_rate": 9.99509159713096e-06,
      "loss": 0.0013,
      "step": 31
    },
    {
      "epoch": 0.0005066738445461311,
      "grad_norm": 0.10811514407396317,
      "learning_rate": 9.99493326155454e-06,
      "loss": 0.6468,
      "step": 32
    },
    {
      "epoch": 0.0005225074021881976,
      "grad_norm": 0.0012616730527952313,
      "learning_rate": 9.994774925978119e-06,
      "loss": 0.0013,
      "step": 33
    },
    {
      "epoch": 0.0005383409598302643,
      "grad_norm": 0.15551474690437317,
      "learning_rate": 9.994616590401698e-06,
      "loss": 1.148,
      "step": 34
    },
    {
      "epoch": 0.0005541745174723309,
      "grad_norm": 0.054219868034124374,
      "learning_rate": 9.994458254825277e-06,
      "loss": 0.3273,
      "step": 35
    },
    {
      "epoch": 0.0005700080751143974,
      "grad_norm": 0.1302778720855713,
      "learning_rate": 9.994299919248856e-06,
      "loss": 0.8915,
      "step": 36
    },
    {
      "epoch": 0.000585841632756464,
      "grad_norm": 0.08080433309078217,
      "learning_rate": 9.994141583672437e-06,
      "loss": 0.4028,
      "step": 37
    },
    {
      "epoch": 0.0006016751903985307,
      "grad_norm": 0.08283331245183945,
      "learning_rate": 9.993983248096016e-06,
      "loss": 0.5418,
      "step": 38
    },
    {
      "epoch": 0.0006175087480405972,
      "grad_norm": 0.07551029324531555,
      "learning_rate": 9.993824912519595e-06,
      "loss": 0.4436,
      "step": 39
    },
    {
      "epoch": 0.0006333423056826638,
      "grad_norm": 0.19364207983016968,
      "learning_rate": 9.993666576943174e-06,
      "loss": 1.1459,
      "step": 40
    },
    {
      "epoch": 0.0006491758633247304,
      "grad_norm": 0.08432217687368393,
      "learning_rate": 9.993508241366753e-06,
      "loss": 0.5505,
      "step": 41
    },
    {
      "epoch": 0.0006650094209667971,
      "grad_norm": 0.020948216319084167,
      "learning_rate": 9.993349905790332e-06,
      "loss": 0.0161,
      "step": 42
    },
    {
      "epoch": 0.0006808429786088636,
      "grad_norm": 0.2126137763261795,
      "learning_rate": 9.993191570213913e-06,
      "loss": 1.0368,
      "step": 43
    },
    {
      "epoch": 0.0006966765362509302,
      "grad_norm": 0.2826763391494751,
      "learning_rate": 9.993033234637492e-06,
      "loss": 1.2182,
      "step": 44
    },
    {
      "epoch": 0.0007125100938929969,
      "grad_norm": 0.087503582239151,
      "learning_rate": 9.992874899061071e-06,
      "loss": 0.5854,
      "step": 45
    },
    {
      "epoch": 0.0007283436515350634,
      "grad_norm": 0.10889165103435516,
      "learning_rate": 9.99271656348465e-06,
      "loss": 0.4563,
      "step": 46
    },
    {
      "epoch": 0.00074417720917713,
      "grad_norm": 0.09513632953166962,
      "learning_rate": 9.99255822790823e-06,
      "loss": 0.411,
      "step": 47
    },
    {
      "epoch": 0.0007600107668191966,
      "grad_norm": 0.011006605811417103,
      "learning_rate": 9.992399892331808e-06,
      "loss": 0.0034,
      "step": 48
    },
    {
      "epoch": 0.0007758443244612632,
      "grad_norm": 0.11770033091306686,
      "learning_rate": 9.992241556755388e-06,
      "loss": 0.6058,
      "step": 49
    },
    {
      "epoch": 0.0007916778821033298,
      "grad_norm": 0.0026376894675195217,
      "learning_rate": 9.992083221178968e-06,
      "loss": 0.0005,
      "step": 50
    },
    {
      "epoch": 0.0008075114397453964,
      "grad_norm": 0.15608087182044983,
      "learning_rate": 9.991924885602546e-06,
      "loss": 0.9222,
      "step": 51
    },
    {
      "epoch": 0.000823344997387463,
      "grad_norm": 0.19168764352798462,
      "learning_rate": 9.991766550026127e-06,
      "loss": 0.4958,
      "step": 52
    },
    {
      "epoch": 0.0008391785550295296,
      "grad_norm": 0.0017862268723547459,
      "learning_rate": 9.991608214449706e-06,
      "loss": 0.0003,
      "step": 53
    },
    {
      "epoch": 0.0008550121126715962,
      "grad_norm": 0.11516502499580383,
      "learning_rate": 9.991449878873285e-06,
      "loss": 0.5747,
      "step": 54
    },
    {
      "epoch": 0.0008708456703136627,
      "grad_norm": 0.024485934525728226,
      "learning_rate": 9.991291543296864e-06,
      "loss": 0.0385,
      "step": 55
    },
    {
      "epoch": 0.0008866792279557294,
      "grad_norm": 0.16667406260967255,
      "learning_rate": 9.991133207720445e-06,
      "loss": 0.4092,
      "step": 56
    },
    {
      "epoch": 0.000902512785597796,
      "grad_norm": 0.20859448611736298,
      "learning_rate": 9.990974872144022e-06,
      "loss": 1.0125,
      "step": 57
    },
    {
      "epoch": 0.0009183463432398625,
      "grad_norm": 0.001060187118127942,
      "learning_rate": 9.990816536567603e-06,
      "loss": 0.0011,
      "step": 58
    },
    {
      "epoch": 0.0009341799008819292,
      "grad_norm": 0.2154386043548584,
      "learning_rate": 9.990658200991182e-06,
      "loss": 1.0443,
      "step": 59
    },
    {
      "epoch": 0.0009500134585239958,
      "grad_norm": 0.1269068568944931,
      "learning_rate": 9.99049986541476e-06,
      "loss": 0.475,
      "step": 60
    },
    {
      "epoch": 0.0009658470161660623,
      "grad_norm": 0.0009222918306477368,
      "learning_rate": 9.99034152983834e-06,
      "loss": 0.0011,
      "step": 61
    },
    {
      "epoch": 0.000981680573808129,
      "grad_norm": 0.13616850972175598,
      "learning_rate": 9.99018319426192e-06,
      "loss": 0.6892,
      "step": 62
    },
    {
      "epoch": 0.0009975141314501955,
      "grad_norm": 0.10625823587179184,
      "learning_rate": 9.990024858685498e-06,
      "loss": 0.4045,
      "step": 63
    },
    {
      "epoch": 0.0010133476890922621,
      "grad_norm": 0.06626837700605392,
      "learning_rate": 9.989866523109079e-06,
      "loss": 0.0151,
      "step": 64
    },
    {
      "epoch": 0.0010291812467343288,
      "grad_norm": 0.13001835346221924,
      "learning_rate": 9.989708187532658e-06,
      "loss": 0.5253,
      "step": 65
    },
    {
      "epoch": 0.0010450148043763953,
      "grad_norm": 0.29824236035346985,
      "learning_rate": 9.989549851956237e-06,
      "loss": 1.2763,
      "step": 66
    },
    {
      "epoch": 0.001060848362018462,
      "grad_norm": 0.00824787374585867,
      "learning_rate": 9.989391516379816e-06,
      "loss": 0.0014,
      "step": 67
    },
    {
      "epoch": 0.0010766819196605286,
      "grad_norm": 0.1510777473449707,
      "learning_rate": 9.989233180803395e-06,
      "loss": 0.5492,
      "step": 68
    },
    {
      "epoch": 0.001092515477302595,
      "grad_norm": 0.11179883033037186,
      "learning_rate": 9.989074845226974e-06,
      "loss": 0.3297,
      "step": 69
    },
    {
      "epoch": 0.0011083490349446618,
      "grad_norm": 0.025956137105822563,
      "learning_rate": 9.988916509650555e-06,
      "loss": 0.011,
      "step": 70
    },
    {
      "epoch": 0.0011241825925867282,
      "grad_norm": 0.08283741027116776,
      "learning_rate": 9.988758174074134e-06,
      "loss": 0.0078,
      "step": 71
    },
    {
      "epoch": 0.0011400161502287949,
      "grad_norm": 0.055794715881347656,
      "learning_rate": 9.988599838497713e-06,
      "loss": 0.0077,
      "step": 72
    },
    {
      "epoch": 0.0011558497078708616,
      "grad_norm": 0.0012560684699565172,
      "learning_rate": 9.988441502921292e-06,
      "loss": 0.0002,
      "step": 73
    },
    {
      "epoch": 0.001171683265512928,
      "grad_norm": 0.017799796536564827,
      "learning_rate": 9.988283167344871e-06,
      "loss": 0.0247,
      "step": 74
    },
    {
      "epoch": 0.0011875168231549947,
      "grad_norm": 0.38171806931495667,
      "learning_rate": 9.98812483176845e-06,
      "loss": 0.6108,
      "step": 75
    },
    {
      "epoch": 0.0012033503807970614,
      "grad_norm": 0.16280591487884521,
      "learning_rate": 9.98796649619203e-06,
      "loss": 0.5415,
      "step": 76
    },
    {
      "epoch": 0.0012191839384391278,
      "grad_norm": 0.021820012480020523,
      "learning_rate": 9.98780816061561e-06,
      "loss": 0.062,
      "step": 77
    },
    {
      "epoch": 0.0012350174960811945,
      "grad_norm": 0.27795130014419556,
      "learning_rate": 9.987649825039188e-06,
      "loss": 1.0931,
      "step": 78
    },
    {
      "epoch": 0.0012508510537232612,
      "grad_norm": 0.11948113143444061,
      "learning_rate": 9.987491489462768e-06,
      "loss": 0.4695,
      "step": 79
    },
    {
      "epoch": 0.0012666846113653276,
      "grad_norm": 0.17866678535938263,
      "learning_rate": 9.987333153886348e-06,
      "loss": 0.595,
      "step": 80
    },
    {
      "epoch": 0.0012825181690073943,
      "grad_norm": 0.10373400151729584,
      "learning_rate": 9.987174818309927e-06,
      "loss": 0.4021,
      "step": 81
    },
    {
      "epoch": 0.0012983517266494608,
      "grad_norm": 0.17529912292957306,
      "learning_rate": 9.987016482733506e-06,
      "loss": 0.6249,
      "step": 82
    },
    {
      "epoch": 0.0013141852842915274,
      "grad_norm": 0.0009613331058062613,
      "learning_rate": 9.986858147157086e-06,
      "loss": 0.0004,
      "step": 83
    },
    {
      "epoch": 0.0013300188419335941,
      "grad_norm": 0.1065700426697731,
      "learning_rate": 9.986699811580664e-06,
      "loss": 0.6118,
      "step": 84
    },
    {
      "epoch": 0.0013458523995756606,
      "grad_norm": 0.1624743938446045,
      "learning_rate": 9.986541476004245e-06,
      "loss": 0.5322,
      "step": 85
    },
    {
      "epoch": 0.0013616859572177272,
      "grad_norm": 0.0004935457836836576,
      "learning_rate": 9.986383140427824e-06,
      "loss": 0.0001,
      "step": 86
    },
    {
      "epoch": 0.001377519514859794,
      "grad_norm": 0.15382859110832214,
      "learning_rate": 9.986224804851403e-06,
      "loss": 0.5005,
      "step": 87
    },
    {
      "epoch": 0.0013933530725018604,
      "grad_norm": 0.13668665289878845,
      "learning_rate": 9.986066469274982e-06,
      "loss": 0.5103,
      "step": 88
    },
    {
      "epoch": 0.001409186630143927,
      "grad_norm": 0.006998836062848568,
      "learning_rate": 9.985908133698563e-06,
      "loss": 0.0019,
      "step": 89
    },
    {
      "epoch": 0.0014250201877859937,
      "grad_norm": 0.20401957631111145,
      "learning_rate": 9.98574979812214e-06,
      "loss": 0.535,
      "step": 90
    },
    {
      "epoch": 0.0014408537454280602,
      "grad_norm": 0.23224419355392456,
      "learning_rate": 9.98559146254572e-06,
      "loss": 0.7848,
      "step": 91
    },
    {
      "epoch": 0.0014566873030701268,
      "grad_norm": 0.09886462241411209,
      "learning_rate": 9.9854331269693e-06,
      "loss": 0.0128,
      "step": 92
    },
    {
      "epoch": 0.0014725208607121935,
      "grad_norm": 0.0012029223144054413,
      "learning_rate": 9.985274791392879e-06,
      "loss": 0.001,
      "step": 93
    },
    {
      "epoch": 0.00148835441835426,
      "grad_norm": 0.06808362156152725,
      "learning_rate": 9.985116455816458e-06,
      "loss": 0.0108,
      "step": 94
    },
    {
      "epoch": 0.0015041879759963267,
      "grad_norm": 0.09977144747972488,
      "learning_rate": 9.984958120240039e-06,
      "loss": 0.3551,
      "step": 95
    },
    {
      "epoch": 0.0015200215336383931,
      "grad_norm": 0.09376240521669388,
      "learning_rate": 9.984799784663616e-06,
      "loss": 0.8363,
      "step": 96
    },
    {
      "epoch": 0.0015358550912804598,
      "grad_norm": 0.17177484929561615,
      "learning_rate": 9.984641449087195e-06,
      "loss": 0.6697,
      "step": 97
    },
    {
      "epoch": 0.0015516886489225265,
      "grad_norm": 0.19827400147914886,
      "learning_rate": 9.984483113510776e-06,
      "loss": 0.4899,
      "step": 98
    },
    {
      "epoch": 0.001567522206564593,
      "grad_norm": 0.023699043318629265,
      "learning_rate": 9.984324777934355e-06,
      "loss": 0.0106,
      "step": 99
    },
    {
      "epoch": 0.0015833557642066596,
      "grad_norm": 0.2619759738445282,
      "learning_rate": 9.984166442357934e-06,
      "loss": 0.6906,
      "step": 100
    },
    {
      "epoch": 0.0015991893218487263,
      "grad_norm": 0.1015174388885498,
      "learning_rate": 9.984008106781513e-06,
      "loss": 0.6035,
      "step": 101
    },
    {
      "epoch": 0.0016150228794907927,
      "grad_norm": 0.31170666217803955,
      "learning_rate": 9.983849771205092e-06,
      "loss": 1.0896,
      "step": 102
    },
    {
      "epoch": 0.0016308564371328594,
      "grad_norm": 0.15823842585086823,
      "learning_rate": 9.983691435628671e-06,
      "loss": 0.5058,
      "step": 103
    },
    {
      "epoch": 0.001646689994774926,
      "grad_norm": 0.009703189134597778,
      "learning_rate": 9.983533100052252e-06,
      "loss": 0.0061,
      "step": 104
    },
    {
      "epoch": 0.0016625235524169925,
      "grad_norm": 0.2551317512989044,
      "learning_rate": 9.983374764475831e-06,
      "loss": 0.748,
      "step": 105
    },
    {
      "epoch": 0.0016783571100590592,
      "grad_norm": 0.16905830800533295,
      "learning_rate": 9.98321642889941e-06,
      "loss": 0.4767,
      "step": 106
    },
    {
      "epoch": 0.0016941906677011257,
      "grad_norm": 0.0016261546406894922,
      "learning_rate": 9.98305809332299e-06,
      "loss": 0.0003,
      "step": 107
    },
    {
      "epoch": 0.0017100242253431923,
      "grad_norm": 0.13766929507255554,
      "learning_rate": 9.982899757746569e-06,
      "loss": 0.3647,
      "step": 108
    },
    {
      "epoch": 0.001725857782985259,
      "grad_norm": 0.0020476875361055136,
      "learning_rate": 9.982741422170148e-06,
      "loss": 0.0014,
      "step": 109
    },
    {
      "epoch": 0.0017416913406273255,
      "grad_norm": 0.14967814087867737,
      "learning_rate": 9.982583086593728e-06,
      "loss": 0.0252,
      "step": 110
    },
    {
      "epoch": 0.0017575248982693921,
      "grad_norm": 0.14309704303741455,
      "learning_rate": 9.982424751017307e-06,
      "loss": 0.4388,
      "step": 111
    },
    {
      "epoch": 0.0017733584559114588,
      "grad_norm": 0.13660967350006104,
      "learning_rate": 9.982266415440887e-06,
      "loss": 0.9232,
      "step": 112
    },
    {
      "epoch": 0.0017891920135535253,
      "grad_norm": 0.2733531892299652,
      "learning_rate": 9.982108079864466e-06,
      "loss": 1.1023,
      "step": 113
    },
    {
      "epoch": 0.001805025571195592,
      "grad_norm": 0.004135933704674244,
      "learning_rate": 9.981949744288045e-06,
      "loss": 0.0019,
      "step": 114
    },
    {
      "epoch": 0.0018208591288376586,
      "grad_norm": 0.16974951326847076,
      "learning_rate": 9.981791408711624e-06,
      "loss": 0.6332,
      "step": 115
    },
    {
      "epoch": 0.001836692686479725,
      "grad_norm": 0.030651528388261795,
      "learning_rate": 9.981633073135205e-06,
      "loss": 0.0085,
      "step": 116
    },
    {
      "epoch": 0.0018525262441217917,
      "grad_norm": 0.0011418514186516404,
      "learning_rate": 9.981474737558784e-06,
      "loss": 0.0002,
      "step": 117
    },
    {
      "epoch": 0.0018683598017638584,
      "grad_norm": 0.25053536891937256,
      "learning_rate": 9.981316401982363e-06,
      "loss": 2.0716,
      "step": 118
    },
    {
      "epoch": 0.0018841933594059249,
      "grad_norm": 0.2738971710205078,
      "learning_rate": 9.981158066405942e-06,
      "loss": 0.6449,
      "step": 119
    },
    {
      "epoch": 0.0019000269170479916,
      "grad_norm": 0.0035754155833274126,
      "learning_rate": 9.980999730829521e-06,
      "loss": 0.002,
      "step": 120
    },
    {
      "epoch": 0.001915860474690058,
      "grad_norm": 0.0011735304724425077,
      "learning_rate": 9.9808413952531e-06,
      "loss": 0.0007,
      "step": 121
    },
    {
      "epoch": 0.0019316940323321247,
      "grad_norm": 0.17823772132396698,
      "learning_rate": 9.980683059676679e-06,
      "loss": 0.5969,
      "step": 122
    },
    {
      "epoch": 0.0019475275899741914,
      "grad_norm": 0.15650323033332825,
      "learning_rate": 9.98052472410026e-06,
      "loss": 0.4019,
      "step": 123
    },
    {
      "epoch": 0.001963361147616258,
      "grad_norm": 0.1470641940832138,
      "learning_rate": 9.980366388523837e-06,
      "loss": 0.3414,
      "step": 124
    },
    {
      "epoch": 0.0019791947052583245,
      "grad_norm": 0.21640987694263458,
      "learning_rate": 9.980208052947418e-06,
      "loss": 0.5302,
      "step": 125
    },
    {
      "epoch": 0.001995028262900391,
      "grad_norm": 0.30398809909820557,
      "learning_rate": 9.980049717370997e-06,
      "loss": 0.9125,
      "step": 126
    },
    {
      "epoch": 0.002010861820542458,
      "grad_norm": 0.19463799893856049,
      "learning_rate": 9.979891381794576e-06,
      "loss": 0.1336,
      "step": 127
    },
    {
      "epoch": 0.0020266953781845243,
      "grad_norm": 0.15077227354049683,
      "learning_rate": 9.979733046218155e-06,
      "loss": 0.4297,
      "step": 128
    },
    {
      "epoch": 0.0020425289358265908,
      "grad_norm": 0.20800620317459106,
      "learning_rate": 9.979574710641734e-06,
      "loss": 0.5247,
      "step": 129
    },
    {
      "epoch": 0.0020583624934686576,
      "grad_norm": 0.19781212508678436,
      "learning_rate": 9.979416375065313e-06,
      "loss": 0.3354,
      "step": 130
    },
    {
      "epoch": 0.002074196051110724,
      "grad_norm": 0.11103102564811707,
      "learning_rate": 9.979258039488894e-06,
      "loss": 0.3653,
      "step": 131
    },
    {
      "epoch": 0.0020900296087527906,
      "grad_norm": 0.3256242573261261,
      "learning_rate": 9.979099703912473e-06,
      "loss": 0.7,
      "step": 132
    },
    {
      "epoch": 0.0021058631663948574,
      "grad_norm": 0.0018955058185383677,
      "learning_rate": 9.978941368336052e-06,
      "loss": 0.0003,
      "step": 133
    },
    {
      "epoch": 0.002121696724036924,
      "grad_norm": 0.0036404321435838938,
      "learning_rate": 9.978783032759631e-06,
      "loss": 0.0005,
      "step": 134
    },
    {
      "epoch": 0.0021375302816789904,
      "grad_norm": 0.16861359775066376,
      "learning_rate": 9.97862469718321e-06,
      "loss": 0.3639,
      "step": 135
    },
    {
      "epoch": 0.0021533638393210573,
      "grad_norm": 0.14039890468120575,
      "learning_rate": 9.97846636160679e-06,
      "loss": 0.2633,
      "step": 136
    },
    {
      "epoch": 0.0021691973969631237,
      "grad_norm": 0.0025500082410871983,
      "learning_rate": 9.97830802603037e-06,
      "loss": 0.0017,
      "step": 137
    },
    {
      "epoch": 0.00218503095460519,
      "grad_norm": 0.17217987775802612,
      "learning_rate": 9.97814969045395e-06,
      "loss": 0.5646,
      "step": 138
    },
    {
      "epoch": 0.0022008645122472566,
      "grad_norm": 0.24327801167964935,
      "learning_rate": 9.977991354877528e-06,
      "loss": 0.587,
      "step": 139
    },
    {
      "epoch": 0.0022166980698893235,
      "grad_norm": 0.004667855799198151,
      "learning_rate": 9.977833019301108e-06,
      "loss": 0.004,
      "step": 140
    },
    {
      "epoch": 0.00223253162753139,
      "grad_norm": 0.3195638954639435,
      "learning_rate": 9.977674683724687e-06,
      "loss": 0.7712,
      "step": 141
    },
    {
      "epoch": 0.0022483651851734564,
      "grad_norm": 0.1912132203578949,
      "learning_rate": 9.977516348148266e-06,
      "loss": 0.4726,
      "step": 142
    },
    {
      "epoch": 0.0022641987428155233,
      "grad_norm": 0.3067915439605713,
      "learning_rate": 9.977358012571846e-06,
      "loss": 0.8928,
      "step": 143
    },
    {
      "epoch": 0.0022800323004575898,
      "grad_norm": 0.25456109642982483,
      "learning_rate": 9.977199676995426e-06,
      "loss": 0.4765,
      "step": 144
    },
    {
      "epoch": 0.0022958658580996562,
      "grad_norm": 0.18634775280952454,
      "learning_rate": 9.977041341419003e-06,
      "loss": 0.454,
      "step": 145
    },
    {
      "epoch": 0.002311699415741723,
      "grad_norm": 0.002807406708598137,
      "learning_rate": 9.976883005842584e-06,
      "loss": 0.0004,
      "step": 146
    },
    {
      "epoch": 0.0023275329733837896,
      "grad_norm": 0.0019052557181566954,
      "learning_rate": 9.976724670266163e-06,
      "loss": 0.0004,
      "step": 147
    },
    {
      "epoch": 0.002343366531025856,
      "grad_norm": 0.0014433516189455986,
      "learning_rate": 9.976566334689742e-06,
      "loss": 0.0009,
      "step": 148
    },
    {
      "epoch": 0.002359200088667923,
      "grad_norm": 0.17246361076831818,
      "learning_rate": 9.976407999113321e-06,
      "loss": 0.3897,
      "step": 149
    },
    {
      "epoch": 0.0023750336463099894,
      "grad_norm": 0.02206731215119362,
      "learning_rate": 9.976249663536902e-06,
      "loss": 0.0771,
      "step": 150
    },
    {
      "epoch": 0.002390867203952056,
      "grad_norm": 0.0317988395690918,
      "learning_rate": 9.976091327960479e-06,
      "loss": 0.0237,
      "step": 151
    },
    {
      "epoch": 0.0024067007615941227,
      "grad_norm": 0.024743998423218727,
      "learning_rate": 9.97593299238406e-06,
      "loss": 0.0526,
      "step": 152
    },
    {
      "epoch": 0.002422534319236189,
      "grad_norm": 0.0057337223552167416,
      "learning_rate": 9.975774656807639e-06,
      "loss": 0.0005,
      "step": 153
    },
    {
      "epoch": 0.0024383678768782556,
      "grad_norm": 0.30469992756843567,
      "learning_rate": 9.975616321231218e-06,
      "loss": 0.4933,
      "step": 154
    },
    {
      "epoch": 0.0024542014345203225,
      "grad_norm": 0.1619243621826172,
      "learning_rate": 9.975457985654797e-06,
      "loss": 0.4114,
      "step": 155
    },
    {
      "epoch": 0.002470034992162389,
      "grad_norm": 0.46053797006607056,
      "learning_rate": 9.975299650078378e-06,
      "loss": 1.0309,
      "step": 156
    },
    {
      "epoch": 0.0024858685498044555,
      "grad_norm": 0.19906608760356903,
      "learning_rate": 9.975141314501955e-06,
      "loss": 0.465,
      "step": 157
    },
    {
      "epoch": 0.0025017021074465223,
      "grad_norm": 0.003262799931690097,
      "learning_rate": 9.974982978925536e-06,
      "loss": 0.0004,
      "step": 158
    },
    {
      "epoch": 0.002517535665088589,
      "grad_norm": 0.1754283457994461,
      "learning_rate": 9.974824643349115e-06,
      "loss": 0.3165,
      "step": 159
    },
    {
      "epoch": 0.0025333692227306553,
      "grad_norm": 0.005975264590233564,
      "learning_rate": 9.974666307772694e-06,
      "loss": 0.0039,
      "step": 160
    },
    {
      "epoch": 0.002549202780372722,
      "grad_norm": 0.29889431595802307,
      "learning_rate": 9.974507972196273e-06,
      "loss": 0.7497,
      "step": 161
    },
    {
      "epoch": 0.0025650363380147886,
      "grad_norm": 0.15220099687576294,
      "learning_rate": 9.974349636619854e-06,
      "loss": 0.3473,
      "step": 162
    },
    {
      "epoch": 0.002580869895656855,
      "grad_norm": 0.016549037769436836,
      "learning_rate": 9.974191301043431e-06,
      "loss": 0.004,
      "step": 163
    },
    {
      "epoch": 0.0025967034532989215,
      "grad_norm": 0.05167160928249359,
      "learning_rate": 9.974032965467012e-06,
      "loss": 0.0099,
      "step": 164
    },
    {
      "epoch": 0.0026125370109409884,
      "grad_norm": 0.12245532870292664,
      "learning_rate": 9.973874629890591e-06,
      "loss": 0.3639,
      "step": 165
    },
    {
      "epoch": 0.002628370568583055,
      "grad_norm": 0.09160980582237244,
      "learning_rate": 9.97371629431417e-06,
      "loss": 0.3302,
      "step": 166
    },
    {
      "epoch": 0.0026442041262251213,
      "grad_norm": 0.7140626907348633,
      "learning_rate": 9.97355795873775e-06,
      "loss": 1.2638,
      "step": 167
    },
    {
      "epoch": 0.0026600376838671882,
      "grad_norm": 0.008477488532662392,
      "learning_rate": 9.97339962316133e-06,
      "loss": 0.0032,
      "step": 168
    },
    {
      "epoch": 0.0026758712415092547,
      "grad_norm": 0.35834288597106934,
      "learning_rate": 9.973241287584908e-06,
      "loss": 0.9396,
      "step": 169
    },
    {
      "epoch": 0.002691704799151321,
      "grad_norm": 0.15275996923446655,
      "learning_rate": 9.973082952008487e-06,
      "loss": 0.2898,
      "step": 170
    },
    {
      "epoch": 0.002707538356793388,
      "grad_norm": 0.008951704949140549,
      "learning_rate": 9.972924616432067e-06,
      "loss": 0.0026,
      "step": 171
    },
    {
      "epoch": 0.0027233719144354545,
      "grad_norm": 0.002589691197499633,
      "learning_rate": 9.972766280855647e-06,
      "loss": 0.0017,
      "step": 172
    },
    {
      "epoch": 0.002739205472077521,
      "grad_norm": 0.15915228426456451,
      "learning_rate": 9.972607945279226e-06,
      "loss": 0.3517,
      "step": 173
    },
    {
      "epoch": 0.002755039029719588,
      "grad_norm": 0.23325404524803162,
      "learning_rate": 9.972449609702805e-06,
      "loss": 0.3936,
      "step": 174
    },
    {
      "epoch": 0.0027708725873616543,
      "grad_norm": 0.002361560706049204,
      "learning_rate": 9.972291274126384e-06,
      "loss": 0.0004,
      "step": 175
    },
    {
      "epoch": 0.0027867061450037207,
      "grad_norm": 0.19060209393501282,
      "learning_rate": 9.972132938549963e-06,
      "loss": 0.3529,
      "step": 176
    },
    {
      "epoch": 0.0028025397026457876,
      "grad_norm": 0.06073798984289169,
      "learning_rate": 9.971974602973544e-06,
      "loss": 0.0104,
      "step": 177
    },
    {
      "epoch": 0.002818373260287854,
      "grad_norm": 0.3064928948879242,
      "learning_rate": 9.971816267397123e-06,
      "loss": 0.9666,
      "step": 178
    },
    {
      "epoch": 0.0028342068179299205,
      "grad_norm": 0.591271162033081,
      "learning_rate": 9.971657931820702e-06,
      "loss": 1.1767,
      "step": 179
    },
    {
      "epoch": 0.0028500403755719874,
      "grad_norm": 0.006068781949579716,
      "learning_rate": 9.971499596244281e-06,
      "loss": 0.0008,
      "step": 180
    },
    {
      "epoch": 0.002865873933214054,
      "grad_norm": 0.17346562445163727,
      "learning_rate": 9.97134126066786e-06,
      "loss": 0.2947,
      "step": 181
    },
    {
      "epoch": 0.0028817074908561204,
      "grad_norm": 0.1792832911014557,
      "learning_rate": 9.971182925091439e-06,
      "loss": 0.3838,
      "step": 182
    },
    {
      "epoch": 0.0028975410484981872,
      "grad_norm": 0.12663432955741882,
      "learning_rate": 9.97102458951502e-06,
      "loss": 0.0603,
      "step": 183
    },
    {
      "epoch": 0.0029133746061402537,
      "grad_norm": 0.13010068237781525,
      "learning_rate": 9.970866253938599e-06,
      "loss": 0.4028,
      "step": 184
    },
    {
      "epoch": 0.00292920816378232,
      "grad_norm": 0.005660518538206816,
      "learning_rate": 9.970707918362178e-06,
      "loss": 0.0006,
      "step": 185
    },
    {
      "epoch": 0.002945041721424387,
      "grad_norm": 0.0230889692902565,
      "learning_rate": 9.970549582785757e-06,
      "loss": 0.0045,
      "step": 186
    },
    {
      "epoch": 0.0029608752790664535,
      "grad_norm": 0.21668608486652374,
      "learning_rate": 9.970391247209336e-06,
      "loss": 0.3557,
      "step": 187
    },
    {
      "epoch": 0.00297670883670852,
      "grad_norm": 0.010715280659496784,
      "learning_rate": 9.970232911632915e-06,
      "loss": 0.0027,
      "step": 188
    },
    {
      "epoch": 0.0029925423943505864,
      "grad_norm": 0.010224621742963791,
      "learning_rate": 9.970074576056496e-06,
      "loss": 0.0029,
      "step": 189
    },
    {
      "epoch": 0.0030083759519926533,
      "grad_norm": 0.0040183099918067455,
      "learning_rate": 9.969916240480075e-06,
      "loss": 0.0014,
      "step": 190
    },
    {
      "epoch": 0.0030242095096347198,
      "grad_norm": 0.17297323048114777,
      "learning_rate": 9.969757904903654e-06,
      "loss": 0.3947,
      "step": 191
    },
    {
      "epoch": 0.0030400430672767862,
      "grad_norm": 0.10081689059734344,
      "learning_rate": 9.969599569327233e-06,
      "loss": 0.4316,
      "step": 192
    },
    {
      "epoch": 0.003055876624918853,
      "grad_norm": 0.004345884080976248,
      "learning_rate": 9.969441233750812e-06,
      "loss": 0.0022,
      "step": 193
    },
    {
      "epoch": 0.0030717101825609196,
      "grad_norm": 0.006702863611280918,
      "learning_rate": 9.969282898174391e-06,
      "loss": 0.0014,
      "step": 194
    },
    {
      "epoch": 0.003087543740202986,
      "grad_norm": 0.014808648265898228,
      "learning_rate": 9.96912456259797e-06,
      "loss": 0.0024,
      "step": 195
    },
    {
      "epoch": 0.003103377297845053,
      "grad_norm": 0.17169295251369476,
      "learning_rate": 9.96896622702155e-06,
      "loss": 0.3934,
      "step": 196
    },
    {
      "epoch": 0.0031192108554871194,
      "grad_norm": 0.1552625596523285,
      "learning_rate": 9.968807891445129e-06,
      "loss": 0.5404,
      "step": 197
    },
    {
      "epoch": 0.003135044413129186,
      "grad_norm": 0.23274265229701996,
      "learning_rate": 9.96864955586871e-06,
      "loss": 0.363,
      "step": 198
    },
    {
      "epoch": 0.0031508779707712527,
      "grad_norm": 0.3716132640838623,
      "learning_rate": 9.968491220292288e-06,
      "loss": 0.7521,
      "step": 199
    },
    {
      "epoch": 0.003166711528413319,
      "grad_norm": 0.1431673914194107,
      "learning_rate": 9.968332884715868e-06,
      "loss": 0.8664,
      "step": 200
    },
    {
      "epoch": 0.0031825450860553856,
      "grad_norm": 0.008871303871273994,
      "learning_rate": 9.968174549139447e-06,
      "loss": 0.0009,
      "step": 201
    },
    {
      "epoch": 0.0031983786436974525,
      "grad_norm": 0.0032362372148782015,
      "learning_rate": 9.968016213563026e-06,
      "loss": 0.0004,
      "step": 202
    },
    {
      "epoch": 0.003214212201339519,
      "grad_norm": 0.018232207745313644,
      "learning_rate": 9.967857877986605e-06,
      "loss": 0.0062,
      "step": 203
    },
    {
      "epoch": 0.0032300457589815854,
      "grad_norm": 0.13140001893043518,
      "learning_rate": 9.967699542410186e-06,
      "loss": 0.2526,
      "step": 204
    },
    {
      "epoch": 0.0032458793166236523,
      "grad_norm": 0.026272466406226158,
      "learning_rate": 9.967541206833765e-06,
      "loss": 0.0026,
      "step": 205
    },
    {
      "epoch": 0.003261712874265719,
      "grad_norm": 0.1726243644952774,
      "learning_rate": 9.967382871257344e-06,
      "loss": 0.351,
      "step": 206
    },
    {
      "epoch": 0.0032775464319077852,
      "grad_norm": 0.1572379767894745,
      "learning_rate": 9.967224535680923e-06,
      "loss": 0.2905,
      "step": 207
    },
    {
      "epoch": 0.003293379989549852,
      "grad_norm": 0.14853259921073914,
      "learning_rate": 9.967066200104502e-06,
      "loss": 0.4431,
      "step": 208
    },
    {
      "epoch": 0.0033092135471919186,
      "grad_norm": 0.017935890704393387,
      "learning_rate": 9.966907864528081e-06,
      "loss": 0.0072,
      "step": 209
    },
    {
      "epoch": 0.003325047104833985,
      "grad_norm": 0.10735051333904266,
      "learning_rate": 9.966749528951662e-06,
      "loss": 0.3725,
      "step": 210
    },
    {
      "epoch": 0.003340880662476052,
      "grad_norm": 0.17696513235569,
      "learning_rate": 9.96659119337524e-06,
      "loss": 0.3849,
      "step": 211
    },
    {
      "epoch": 0.0033567142201181184,
      "grad_norm": 0.0032565610017627478,
      "learning_rate": 9.96643285779882e-06,
      "loss": 0.0005,
      "step": 212
    },
    {
      "epoch": 0.003372547777760185,
      "grad_norm": 0.16482013463974,
      "learning_rate": 9.966274522222399e-06,
      "loss": 0.5169,
      "step": 213
    },
    {
      "epoch": 0.0033883813354022513,
      "grad_norm": 0.2144971340894699,
      "learning_rate": 9.966116186645978e-06,
      "loss": 0.4596,
      "step": 214
    },
    {
      "epoch": 0.003404214893044318,
      "grad_norm": 0.2146884649991989,
      "learning_rate": 9.965957851069557e-06,
      "loss": 0.391,
      "step": 215
    },
    {
      "epoch": 0.0034200484506863847,
      "grad_norm": 0.2358623743057251,
      "learning_rate": 9.965799515493138e-06,
      "loss": 0.2683,
      "step": 216
    },
    {
      "epoch": 0.003435882008328451,
      "grad_norm": 0.23018477857112885,
      "learning_rate": 9.965641179916717e-06,
      "loss": 0.8922,
      "step": 217
    },
    {
      "epoch": 0.003451715565970518,
      "grad_norm": 0.007566220127046108,
      "learning_rate": 9.965482844340294e-06,
      "loss": 0.0025,
      "step": 218
    },
    {
      "epoch": 0.0034675491236125845,
      "grad_norm": 0.19855187833309174,
      "learning_rate": 9.965324508763875e-06,
      "loss": 0.3329,
      "step": 219
    },
    {
      "epoch": 0.003483382681254651,
      "grad_norm": 0.21579797565937042,
      "learning_rate": 9.965166173187454e-06,
      "loss": 0.4329,
      "step": 220
    },
    {
      "epoch": 0.003499216238896718,
      "grad_norm": 0.009744573384523392,
      "learning_rate": 9.965007837611033e-06,
      "loss": 0.003,
      "step": 221
    },
    {
      "epoch": 0.0035150497965387843,
      "grad_norm": 0.205060675740242,
      "learning_rate": 9.964849502034612e-06,
      "loss": 0.2828,
      "step": 222
    },
    {
      "epoch": 0.0035308833541808507,
      "grad_norm": 0.11512064933776855,
      "learning_rate": 9.964691166458193e-06,
      "loss": 0.3015,
      "step": 223
    },
    {
      "epoch": 0.0035467169118229176,
      "grad_norm": 0.15732184052467346,
      "learning_rate": 9.96453283088177e-06,
      "loss": 0.245,
      "step": 224
    },
    {
      "epoch": 0.003562550469464984,
      "grad_norm": 0.0054745920933783054,
      "learning_rate": 9.964374495305351e-06,
      "loss": 0.0019,
      "step": 225
    },
    {
      "epoch": 0.0035783840271070505,
      "grad_norm": 0.009767338633537292,
      "learning_rate": 9.96421615972893e-06,
      "loss": 0.0022,
      "step": 226
    },
    {
      "epoch": 0.0035942175847491174,
      "grad_norm": 0.18345136940479279,
      "learning_rate": 9.96405782415251e-06,
      "loss": 0.3169,
      "step": 227
    },
    {
      "epoch": 0.003610051142391184,
      "grad_norm": 0.10999652743339539,
      "learning_rate": 9.963899488576089e-06,
      "loss": 0.2694,
      "step": 228
    },
    {
      "epoch": 0.0036258847000332503,
      "grad_norm": 0.18546287715435028,
      "learning_rate": 9.96374115299967e-06,
      "loss": 0.3931,
      "step": 229
    },
    {
      "epoch": 0.0036417182576753172,
      "grad_norm": 0.13805978000164032,
      "learning_rate": 9.963582817423247e-06,
      "loss": 0.2938,
      "step": 230
    },
    {
      "epoch": 0.0036575518153173837,
      "grad_norm": 0.2351319044828415,
      "learning_rate": 9.963424481846827e-06,
      "loss": 0.5793,
      "step": 231
    },
    {
      "epoch": 0.00367338537295945,
      "grad_norm": 0.015063561499118805,
      "learning_rate": 9.963266146270407e-06,
      "loss": 0.0021,
      "step": 232
    },
    {
      "epoch": 0.003689218930601517,
      "grad_norm": 0.029820695519447327,
      "learning_rate": 9.963107810693986e-06,
      "loss": 0.0219,
      "step": 233
    },
    {
      "epoch": 0.0037050524882435835,
      "grad_norm": 0.30157724022865295,
      "learning_rate": 9.962949475117565e-06,
      "loss": 0.5479,
      "step": 234
    },
    {
      "epoch": 0.00372088604588565,
      "grad_norm": 0.03394952043890953,
      "learning_rate": 9.962791139541146e-06,
      "loss": 0.0032,
      "step": 235
    },
    {
      "epoch": 0.003736719603527717,
      "grad_norm": 0.052624449133872986,
      "learning_rate": 9.962632803964723e-06,
      "loss": 0.0039,
      "step": 236
    },
    {
      "epoch": 0.0037525531611697833,
      "grad_norm": 0.19180668890476227,
      "learning_rate": 9.962474468388304e-06,
      "loss": 0.3366,
      "step": 237
    },
    {
      "epoch": 0.0037683867188118498,
      "grad_norm": 0.006749501917511225,
      "learning_rate": 9.962316132811883e-06,
      "loss": 0.0014,
      "step": 238
    },
    {
      "epoch": 0.003784220276453916,
      "grad_norm": 0.044387638568878174,
      "learning_rate": 9.962157797235462e-06,
      "loss": 0.0035,
      "step": 239
    },
    {
      "epoch": 0.003800053834095983,
      "grad_norm": 0.112523153424263,
      "learning_rate": 9.961999461659041e-06,
      "loss": 0.2028,
      "step": 240
    },
    {
      "epoch": 0.0038158873917380496,
      "grad_norm": 0.23372362554073334,
      "learning_rate": 9.96184112608262e-06,
      "loss": 0.4424,
      "step": 241
    },
    {
      "epoch": 0.003831720949380116,
      "grad_norm": 0.2404651790857315,
      "learning_rate": 9.961682790506199e-06,
      "loss": 0.3158,
      "step": 242
    },
    {
      "epoch": 0.003847554507022183,
      "grad_norm": 0.3821435570716858,
      "learning_rate": 9.961524454929778e-06,
      "loss": 0.765,
      "step": 243
    },
    {
      "epoch": 0.0038633880646642494,
      "grad_norm": 0.2227005809545517,
      "learning_rate": 9.961366119353359e-06,
      "loss": 0.5147,
      "step": 244
    },
    {
      "epoch": 0.003879221622306316,
      "grad_norm": 0.13781504333019257,
      "learning_rate": 9.961207783776938e-06,
      "loss": 0.5487,
      "step": 245
    },
    {
      "epoch": 0.0038950551799483827,
      "grad_norm": 0.29882925748825073,
      "learning_rate": 9.961049448200517e-06,
      "loss": 1.1469,
      "step": 246
    },
    {
      "epoch": 0.003910888737590449,
      "grad_norm": 0.2488427758216858,
      "learning_rate": 9.960891112624096e-06,
      "loss": 0.0428,
      "step": 247
    },
    {
      "epoch": 0.003926722295232516,
      "grad_norm": 0.24822445213794708,
      "learning_rate": 9.960732777047675e-06,
      "loss": 0.4768,
      "step": 248
    },
    {
      "epoch": 0.003942555852874582,
      "grad_norm": 0.01221451535820961,
      "learning_rate": 9.960574441471254e-06,
      "loss": 0.0061,
      "step": 249
    },
    {
      "epoch": 0.003958389410516649,
      "grad_norm": 0.11343801021575928,
      "learning_rate": 9.960416105894835e-06,
      "loss": 0.8271,
      "step": 250
    },
    {
      "epoch": 0.003974222968158716,
      "grad_norm": 0.04255273565649986,
      "learning_rate": 9.960257770318414e-06,
      "loss": 0.0501,
      "step": 251
    },
    {
      "epoch": 0.003990056525800782,
      "grad_norm": 0.06271181255578995,
      "learning_rate": 9.960099434741993e-06,
      "loss": 0.0085,
      "step": 252
    },
    {
      "epoch": 0.004005890083442849,
      "grad_norm": 0.2606784403324127,
      "learning_rate": 9.959941099165572e-06,
      "loss": 1.6378,
      "step": 253
    },
    {
      "epoch": 0.004021723641084916,
      "grad_norm": 0.1851351112127304,
      "learning_rate": 9.959782763589151e-06,
      "loss": 0.247,
      "step": 254
    },
    {
      "epoch": 0.004037557198726982,
      "grad_norm": 0.053956013172864914,
      "learning_rate": 9.95962442801273e-06,
      "loss": 0.0378,
      "step": 255
    },
    {
      "epoch": 0.004053390756369049,
      "grad_norm": 0.11883155256509781,
      "learning_rate": 9.959466092436311e-06,
      "loss": 0.2095,
      "step": 256
    },
    {
      "epoch": 0.0040692243140111155,
      "grad_norm": 0.15312603116035461,
      "learning_rate": 9.95930775685989e-06,
      "loss": 0.2427,
      "step": 257
    },
    {
      "epoch": 0.0040850578716531815,
      "grad_norm": 0.040300481021404266,
      "learning_rate": 9.95914942128347e-06,
      "loss": 0.0233,
      "step": 258
    },
    {
      "epoch": 0.004100891429295248,
      "grad_norm": 0.21111571788787842,
      "learning_rate": 9.958991085707048e-06,
      "loss": 0.4325,
      "step": 259
    },
    {
      "epoch": 0.004116724986937315,
      "grad_norm": 0.3649633824825287,
      "learning_rate": 9.958832750130628e-06,
      "loss": 0.7276,
      "step": 260
    },
    {
      "epoch": 0.004132558544579381,
      "grad_norm": 0.3292938768863678,
      "learning_rate": 9.958674414554207e-06,
      "loss": 0.827,
      "step": 261
    },
    {
      "epoch": 0.004148392102221448,
      "grad_norm": 0.2477172613143921,
      "learning_rate": 9.958516078977787e-06,
      "loss": 0.6388,
      "step": 262
    },
    {
      "epoch": 0.004164225659863515,
      "grad_norm": 0.15332692861557007,
      "learning_rate": 9.958357743401365e-06,
      "loss": 0.1967,
      "step": 263
    },
    {
      "epoch": 0.004180059217505581,
      "grad_norm": 0.01941896788775921,
      "learning_rate": 9.958199407824946e-06,
      "loss": 0.0015,
      "step": 264
    },
    {
      "epoch": 0.004195892775147648,
      "grad_norm": 0.27537915110588074,
      "learning_rate": 9.958041072248525e-06,
      "loss": 0.4076,
      "step": 265
    },
    {
      "epoch": 0.004211726332789715,
      "grad_norm": 0.1563398241996765,
      "learning_rate": 9.957882736672104e-06,
      "loss": 0.2748,
      "step": 266
    },
    {
      "epoch": 0.004227559890431781,
      "grad_norm": 0.00428351853042841,
      "learning_rate": 9.957724401095683e-06,
      "loss": 0.0008,
      "step": 267
    },
    {
      "epoch": 0.004243393448073848,
      "grad_norm": 0.17370988428592682,
      "learning_rate": 9.957566065519262e-06,
      "loss": 0.2683,
      "step": 268
    },
    {
      "epoch": 0.004259227005715915,
      "grad_norm": 0.1664610207080841,
      "learning_rate": 9.957407729942841e-06,
      "loss": 0.2667,
      "step": 269
    },
    {
      "epoch": 0.004275060563357981,
      "grad_norm": 0.12281399965286255,
      "learning_rate": 9.95724939436642e-06,
      "loss": 0.2528,
      "step": 270
    },
    {
      "epoch": 0.004290894121000048,
      "grad_norm": 0.043227940797805786,
      "learning_rate": 9.95709105879e-06,
      "loss": 0.0234,
      "step": 271
    },
    {
      "epoch": 0.0043067276786421145,
      "grad_norm": 0.13840356469154358,
      "learning_rate": 9.95693272321358e-06,
      "loss": 0.537,
      "step": 272
    },
    {
      "epoch": 0.0043225612362841805,
      "grad_norm": 0.012726793065667152,
      "learning_rate": 9.956774387637159e-06,
      "loss": 0.0019,
      "step": 273
    },
    {
      "epoch": 0.004338394793926247,
      "grad_norm": 0.024622773751616478,
      "learning_rate": 9.956616052060738e-06,
      "loss": 0.0039,
      "step": 274
    },
    {
      "epoch": 0.004354228351568314,
      "grad_norm": 0.14618360996246338,
      "learning_rate": 9.956457716484317e-06,
      "loss": 0.352,
      "step": 275
    },
    {
      "epoch": 0.00437006190921038,
      "grad_norm": 0.03999729081988335,
      "learning_rate": 9.956299380907896e-06,
      "loss": 0.003,
      "step": 276
    },
    {
      "epoch": 0.004385895466852447,
      "grad_norm": 0.018252728506922722,
      "learning_rate": 9.956141045331477e-06,
      "loss": 0.0016,
      "step": 277
    },
    {
      "epoch": 0.004401729024494513,
      "grad_norm": 0.18866556882858276,
      "learning_rate": 9.955982709755056e-06,
      "loss": 0.4541,
      "step": 278
    },
    {
      "epoch": 0.00441756258213658,
      "grad_norm": 0.23655040562152863,
      "learning_rate": 9.955824374178635e-06,
      "loss": 0.4127,
      "step": 279
    },
    {
      "epoch": 0.004433396139778647,
      "grad_norm": 0.2078113555908203,
      "learning_rate": 9.955666038602214e-06,
      "loss": 0.2871,
      "step": 280
    },
    {
      "epoch": 0.004449229697420713,
      "grad_norm": 0.11422951519489288,
      "learning_rate": 9.955507703025793e-06,
      "loss": 0.233,
      "step": 281
    },
    {
      "epoch": 0.00446506325506278,
      "grad_norm": 0.11236073076725006,
      "learning_rate": 9.955349367449372e-06,
      "loss": 0.3888,
      "step": 282
    },
    {
      "epoch": 0.004480896812704847,
      "grad_norm": 0.1475507915019989,
      "learning_rate": 9.955191031872953e-06,
      "loss": 0.272,
      "step": 283
    },
    {
      "epoch": 0.004496730370346913,
      "grad_norm": 0.19572071731090546,
      "learning_rate": 9.955032696296532e-06,
      "loss": 0.2484,
      "step": 284
    },
    {
      "epoch": 0.00451256392798898,
      "grad_norm": 0.14682739973068237,
      "learning_rate": 9.954874360720111e-06,
      "loss": 0.2324,
      "step": 285
    },
    {
      "epoch": 0.004528397485631047,
      "grad_norm": 0.1866181343793869,
      "learning_rate": 9.95471602514369e-06,
      "loss": 0.2648,
      "step": 286
    },
    {
      "epoch": 0.004544231043273113,
      "grad_norm": 0.28730860352516174,
      "learning_rate": 9.95455768956727e-06,
      "loss": 0.5845,
      "step": 287
    },
    {
      "epoch": 0.0045600646009151796,
      "grad_norm": 0.18464899063110352,
      "learning_rate": 9.954399353990849e-06,
      "loss": 0.362,
      "step": 288
    },
    {
      "epoch": 0.0045758981585572464,
      "grad_norm": 0.14025232195854187,
      "learning_rate": 9.954241018414428e-06,
      "loss": 0.7008,
      "step": 289
    },
    {
      "epoch": 0.0045917317161993125,
      "grad_norm": 0.11472612619400024,
      "learning_rate": 9.954082682838008e-06,
      "loss": 0.2205,
      "step": 290
    },
    {
      "epoch": 0.004607565273841379,
      "grad_norm": 0.18133628368377686,
      "learning_rate": 9.953924347261586e-06,
      "loss": 0.2485,
      "step": 291
    },
    {
      "epoch": 0.004623398831483446,
      "grad_norm": 0.008414819836616516,
      "learning_rate": 9.953766011685167e-06,
      "loss": 0.0005,
      "step": 292
    },
    {
      "epoch": 0.004639232389125512,
      "grad_norm": 0.28746575117111206,
      "learning_rate": 9.953607676108746e-06,
      "loss": 0.5678,
      "step": 293
    },
    {
      "epoch": 0.004655065946767579,
      "grad_norm": 0.29579460620880127,
      "learning_rate": 9.953449340532325e-06,
      "loss": 0.2618,
      "step": 294
    },
    {
      "epoch": 0.004670899504409646,
      "grad_norm": 0.14591187238693237,
      "learning_rate": 9.953291004955904e-06,
      "loss": 0.3874,
      "step": 295
    },
    {
      "epoch": 0.004686733062051712,
      "grad_norm": 0.14124096930027008,
      "learning_rate": 9.953132669379485e-06,
      "loss": 0.2825,
      "step": 296
    },
    {
      "epoch": 0.004702566619693779,
      "grad_norm": 0.02158026583492756,
      "learning_rate": 9.952974333803062e-06,
      "loss": 0.003,
      "step": 297
    },
    {
      "epoch": 0.004718400177335846,
      "grad_norm": 0.049700018018484116,
      "learning_rate": 9.952815998226643e-06,
      "loss": 0.0042,
      "step": 298
    },
    {
      "epoch": 0.004734233734977912,
      "grad_norm": 0.26115500926971436,
      "learning_rate": 9.952657662650222e-06,
      "loss": 1.0829,
      "step": 299
    },
    {
      "epoch": 0.004750067292619979,
      "grad_norm": 0.015550561249256134,
      "learning_rate": 9.952499327073801e-06,
      "loss": 0.0036,
      "step": 300
    },
    {
      "epoch": 0.004765900850262046,
      "grad_norm": 0.186232328414917,
      "learning_rate": 9.95234099149738e-06,
      "loss": 0.2149,
      "step": 301
    },
    {
      "epoch": 0.004781734407904112,
      "grad_norm": 0.21860481798648834,
      "learning_rate": 9.95218265592096e-06,
      "loss": 0.3145,
      "step": 302
    },
    {
      "epoch": 0.004797567965546179,
      "grad_norm": 0.1449349820613861,
      "learning_rate": 9.952024320344538e-06,
      "loss": 0.4146,
      "step": 303
    },
    {
      "epoch": 0.0048134015231882455,
      "grad_norm": 0.2860616147518158,
      "learning_rate": 9.951865984768119e-06,
      "loss": 0.7534,
      "step": 304
    },
    {
      "epoch": 0.0048292350808303115,
      "grad_norm": 0.22614073753356934,
      "learning_rate": 9.951707649191698e-06,
      "loss": 0.4586,
      "step": 305
    },
    {
      "epoch": 0.004845068638472378,
      "grad_norm": 0.1271626353263855,
      "learning_rate": 9.951549313615277e-06,
      "loss": 0.2974,
      "step": 306
    },
    {
      "epoch": 0.004860902196114445,
      "grad_norm": 0.20471598207950592,
      "learning_rate": 9.951390978038856e-06,
      "loss": 0.0106,
      "step": 307
    },
    {
      "epoch": 0.004876735753756511,
      "grad_norm": 0.18087147176265717,
      "learning_rate": 9.951232642462437e-06,
      "loss": 0.6018,
      "step": 308
    },
    {
      "epoch": 0.004892569311398578,
      "grad_norm": 0.2274368703365326,
      "learning_rate": 9.951074306886014e-06,
      "loss": 0.4812,
      "step": 309
    },
    {
      "epoch": 0.004908402869040645,
      "grad_norm": 0.11501148343086243,
      "learning_rate": 9.950915971309595e-06,
      "loss": 0.2864,
      "step": 310
    },
    {
      "epoch": 0.004924236426682711,
      "grad_norm": 0.2931443154811859,
      "learning_rate": 9.950757635733174e-06,
      "loss": 0.0362,
      "step": 311
    },
    {
      "epoch": 0.004940069984324778,
      "grad_norm": 0.10908076912164688,
      "learning_rate": 9.950599300156753e-06,
      "loss": 0.4254,
      "step": 312
    },
    {
      "epoch": 0.004955903541966845,
      "grad_norm": 0.20615004003047943,
      "learning_rate": 9.950440964580332e-06,
      "loss": 0.3864,
      "step": 313
    },
    {
      "epoch": 0.004971737099608911,
      "grad_norm": 0.12444325536489487,
      "learning_rate": 9.950282629003911e-06,
      "loss": 0.543,
      "step": 314
    },
    {
      "epoch": 0.004987570657250978,
      "grad_norm": 0.008557585068047047,
      "learning_rate": 9.95012429342749e-06,
      "loss": 0.0026,
      "step": 315
    },
    {
      "epoch": 0.005003404214893045,
      "grad_norm": 0.29145023226737976,
      "learning_rate": 9.94996595785107e-06,
      "loss": 0.4602,
      "step": 316
    },
    {
      "epoch": 0.005019237772535111,
      "grad_norm": 0.1262989491224289,
      "learning_rate": 9.94980762227465e-06,
      "loss": 0.188,
      "step": 317
    },
    {
      "epoch": 0.005035071330177178,
      "grad_norm": 0.015278558246791363,
      "learning_rate": 9.94964928669823e-06,
      "loss": 0.0028,
      "step": 318
    },
    {
      "epoch": 0.0050509048878192445,
      "grad_norm": 0.13242878019809723,
      "learning_rate": 9.949490951121809e-06,
      "loss": 0.2811,
      "step": 319
    },
    {
      "epoch": 0.0050667384454613105,
      "grad_norm": 0.12145698815584183,
      "learning_rate": 9.949332615545388e-06,
      "loss": 0.3533,
      "step": 320
    },
    {
      "epoch": 0.005082572003103377,
      "grad_norm": 0.10661057382822037,
      "learning_rate": 9.949174279968967e-06,
      "loss": 0.722,
      "step": 321
    },
    {
      "epoch": 0.005098405560745444,
      "grad_norm": 0.03199078515172005,
      "learning_rate": 9.949015944392546e-06,
      "loss": 0.0158,
      "step": 322
    },
    {
      "epoch": 0.00511423911838751,
      "grad_norm": 0.06099319830536842,
      "learning_rate": 9.948857608816127e-06,
      "loss": 0.0291,
      "step": 323
    },
    {
      "epoch": 0.005130072676029577,
      "grad_norm": 0.18134257197380066,
      "learning_rate": 9.948699273239704e-06,
      "loss": 0.379,
      "step": 324
    },
    {
      "epoch": 0.005145906233671644,
      "grad_norm": 0.042172182351350784,
      "learning_rate": 9.948540937663285e-06,
      "loss": 0.0023,
      "step": 325
    },
    {
      "epoch": 0.00516173979131371,
      "grad_norm": 0.06923355907201767,
      "learning_rate": 9.948382602086864e-06,
      "loss": 0.0096,
      "step": 326
    },
    {
      "epoch": 0.005177573348955777,
      "grad_norm": 0.018550213426351547,
      "learning_rate": 9.948224266510443e-06,
      "loss": 0.0022,
      "step": 327
    },
    {
      "epoch": 0.005193406906597843,
      "grad_norm": 0.09898251295089722,
      "learning_rate": 9.948065930934022e-06,
      "loss": 0.1128,
      "step": 328
    },
    {
      "epoch": 0.00520924046423991,
      "grad_norm": 0.20357738435268402,
      "learning_rate": 9.947907595357603e-06,
      "loss": 0.2149,
      "step": 329
    },
    {
      "epoch": 0.005225074021881977,
      "grad_norm": 0.06990405172109604,
      "learning_rate": 9.94774925978118e-06,
      "loss": 0.2796,
      "step": 330
    },
    {
      "epoch": 0.005240907579524043,
      "grad_norm": 0.23168805241584778,
      "learning_rate": 9.947590924204761e-06,
      "loss": 0.436,
      "step": 331
    },
    {
      "epoch": 0.00525674113716611,
      "grad_norm": 0.016833720728754997,
      "learning_rate": 9.94743258862834e-06,
      "loss": 0.0053,
      "step": 332
    },
    {
      "epoch": 0.005272574694808177,
      "grad_norm": 0.11891798675060272,
      "learning_rate": 9.947274253051919e-06,
      "loss": 0.1616,
      "step": 333
    },
    {
      "epoch": 0.005288408252450243,
      "grad_norm": 0.026209698989987373,
      "learning_rate": 9.947115917475498e-06,
      "loss": 0.0023,
      "step": 334
    },
    {
      "epoch": 0.0053042418100923095,
      "grad_norm": 0.17521606385707855,
      "learning_rate": 9.946957581899079e-06,
      "loss": 0.1971,
      "step": 335
    },
    {
      "epoch": 0.0053200753677343764,
      "grad_norm": 0.30822885036468506,
      "learning_rate": 9.946799246322656e-06,
      "loss": 0.4833,
      "step": 336
    },
    {
      "epoch": 0.0053359089253764425,
      "grad_norm": 0.046953920274972916,
      "learning_rate": 9.946640910746235e-06,
      "loss": 0.0133,
      "step": 337
    },
    {
      "epoch": 0.005351742483018509,
      "grad_norm": 0.03136293217539787,
      "learning_rate": 9.946482575169816e-06,
      "loss": 0.0024,
      "step": 338
    },
    {
      "epoch": 0.005367576040660576,
      "grad_norm": 0.009246259927749634,
      "learning_rate": 9.946324239593395e-06,
      "loss": 0.0004,
      "step": 339
    },
    {
      "epoch": 0.005383409598302642,
      "grad_norm": 0.012457126751542091,
      "learning_rate": 9.946165904016974e-06,
      "loss": 0.0009,
      "step": 340
    },
    {
      "epoch": 0.005399243155944709,
      "grad_norm": 0.026538778096437454,
      "learning_rate": 9.946007568440553e-06,
      "loss": 0.002,
      "step": 341
    },
    {
      "epoch": 0.005415076713586776,
      "grad_norm": 0.31829872727394104,
      "learning_rate": 9.945849232864132e-06,
      "loss": 0.6211,
      "step": 342
    },
    {
      "epoch": 0.005430910271228842,
      "grad_norm": 0.27685338258743286,
      "learning_rate": 9.945690897287712e-06,
      "loss": 0.3833,
      "step": 343
    },
    {
      "epoch": 0.005446743828870909,
      "grad_norm": 0.014884773641824722,
      "learning_rate": 9.945532561711292e-06,
      "loss": 0.0016,
      "step": 344
    },
    {
      "epoch": 0.005462577386512976,
      "grad_norm": 0.13214871287345886,
      "learning_rate": 9.945374226134871e-06,
      "loss": 0.2384,
      "step": 345
    },
    {
      "epoch": 0.005478410944155042,
      "grad_norm": 0.008882617577910423,
      "learning_rate": 9.94521589055845e-06,
      "loss": 0.0016,
      "step": 346
    },
    {
      "epoch": 0.005494244501797109,
      "grad_norm": 0.06924037635326385,
      "learning_rate": 9.94505755498203e-06,
      "loss": 0.0049,
      "step": 347
    },
    {
      "epoch": 0.005510078059439176,
      "grad_norm": 0.018024537712335587,
      "learning_rate": 9.944899219405609e-06,
      "loss": 0.0018,
      "step": 348
    },
    {
      "epoch": 0.005525911617081242,
      "grad_norm": 0.26894134283065796,
      "learning_rate": 9.944740883829188e-06,
      "loss": 1.1813,
      "step": 349
    },
    {
      "epoch": 0.005541745174723309,
      "grad_norm": 0.20416727662086487,
      "learning_rate": 9.944582548252768e-06,
      "loss": 0.3872,
      "step": 350
    },
    {
      "epoch": 0.0055575787323653755,
      "grad_norm": 0.08384701609611511,
      "learning_rate": 9.944424212676348e-06,
      "loss": 0.0565,
      "step": 351
    },
    {
      "epoch": 0.0055734122900074415,
      "grad_norm": 0.020032603293657303,
      "learning_rate": 9.944265877099927e-06,
      "loss": 0.0017,
      "step": 352
    },
    {
      "epoch": 0.005589245847649508,
      "grad_norm": 0.14328362047672272,
      "learning_rate": 9.944107541523506e-06,
      "loss": 0.1359,
      "step": 353
    },
    {
      "epoch": 0.005605079405291575,
      "grad_norm": 0.29666927456855774,
      "learning_rate": 9.943949205947085e-06,
      "loss": 0.4649,
      "step": 354
    },
    {
      "epoch": 0.005620912962933641,
      "grad_norm": 0.28270223736763,
      "learning_rate": 9.943790870370664e-06,
      "loss": 0.3714,
      "step": 355
    },
    {
      "epoch": 0.005636746520575708,
      "grad_norm": 0.11123662441968918,
      "learning_rate": 9.943632534794245e-06,
      "loss": 0.1079,
      "step": 356
    },
    {
      "epoch": 0.005652580078217775,
      "grad_norm": 0.2356419861316681,
      "learning_rate": 9.943474199217824e-06,
      "loss": 0.2631,
      "step": 357
    },
    {
      "epoch": 0.005668413635859841,
      "grad_norm": 0.14847031235694885,
      "learning_rate": 9.943315863641403e-06,
      "loss": 0.3745,
      "step": 358
    },
    {
      "epoch": 0.005684247193501908,
      "grad_norm": 0.25727933645248413,
      "learning_rate": 9.943157528064982e-06,
      "loss": 0.8646,
      "step": 359
    },
    {
      "epoch": 0.005700080751143975,
      "grad_norm": 0.3071674108505249,
      "learning_rate": 9.942999192488561e-06,
      "loss": 0.8148,
      "step": 360
    },
    {
      "epoch": 0.005715914308786041,
      "grad_norm": 0.20067144930362701,
      "learning_rate": 9.94284085691214e-06,
      "loss": 0.4132,
      "step": 361
    },
    {
      "epoch": 0.005731747866428108,
      "grad_norm": 0.14473895728588104,
      "learning_rate": 9.942682521335719e-06,
      "loss": 0.1559,
      "step": 362
    },
    {
      "epoch": 0.005747581424070175,
      "grad_norm": 0.015038612298667431,
      "learning_rate": 9.9425241857593e-06,
      "loss": 0.0015,
      "step": 363
    },
    {
      "epoch": 0.005763414981712241,
      "grad_norm": 0.01923498511314392,
      "learning_rate": 9.942365850182877e-06,
      "loss": 0.0011,
      "step": 364
    },
    {
      "epoch": 0.005779248539354308,
      "grad_norm": 0.1821965128183365,
      "learning_rate": 9.942207514606458e-06,
      "loss": 0.4055,
      "step": 365
    },
    {
      "epoch": 0.0057950820969963745,
      "grad_norm": 0.14633508026599884,
      "learning_rate": 9.942049179030037e-06,
      "loss": 0.2447,
      "step": 366
    },
    {
      "epoch": 0.0058109156546384405,
      "grad_norm": 0.07674510776996613,
      "learning_rate": 9.941890843453616e-06,
      "loss": 0.007,
      "step": 367
    },
    {
      "epoch": 0.005826749212280507,
      "grad_norm": 0.24609623849391937,
      "learning_rate": 9.941732507877195e-06,
      "loss": 0.7572,
      "step": 368
    },
    {
      "epoch": 0.005842582769922574,
      "grad_norm": 0.05781614035367966,
      "learning_rate": 9.941574172300776e-06,
      "loss": 0.0031,
      "step": 369
    },
    {
      "epoch": 0.00585841632756464,
      "grad_norm": 0.1666058897972107,
      "learning_rate": 9.941415836724353e-06,
      "loss": 0.3879,
      "step": 370
    },
    {
      "epoch": 0.005874249885206707,
      "grad_norm": 0.0401301309466362,
      "learning_rate": 9.941257501147934e-06,
      "loss": 0.033,
      "step": 371
    },
    {
      "epoch": 0.005890083442848774,
      "grad_norm": 0.12475882470607758,
      "learning_rate": 9.941099165571513e-06,
      "loss": 0.1519,
      "step": 372
    },
    {
      "epoch": 0.00590591700049084,
      "grad_norm": 0.2074122577905655,
      "learning_rate": 9.940940829995092e-06,
      "loss": 0.3386,
      "step": 373
    },
    {
      "epoch": 0.005921750558132907,
      "grad_norm": 0.22648866474628448,
      "learning_rate": 9.940782494418671e-06,
      "loss": 0.2413,
      "step": 374
    },
    {
      "epoch": 0.005937584115774974,
      "grad_norm": 0.1250697672367096,
      "learning_rate": 9.940624158842252e-06,
      "loss": 0.6122,
      "step": 375
    },
    {
      "epoch": 0.00595341767341704,
      "grad_norm": 0.1677875965833664,
      "learning_rate": 9.94046582326583e-06,
      "loss": 0.1576,
      "step": 376
    },
    {
      "epoch": 0.005969251231059107,
      "grad_norm": 0.3978118300437927,
      "learning_rate": 9.94030748768941e-06,
      "loss": 0.3889,
      "step": 377
    },
    {
      "epoch": 0.005985084788701173,
      "grad_norm": 0.18630985915660858,
      "learning_rate": 9.94014915211299e-06,
      "loss": 0.289,
      "step": 378
    },
    {
      "epoch": 0.00600091834634324,
      "grad_norm": 0.01646358333528042,
      "learning_rate": 9.939990816536569e-06,
      "loss": 0.0022,
      "step": 379
    },
    {
      "epoch": 0.006016751903985307,
      "grad_norm": 0.20479357242584229,
      "learning_rate": 9.939832480960148e-06,
      "loss": 0.9228,
      "step": 380
    },
    {
      "epoch": 0.006032585461627373,
      "grad_norm": 0.40290388464927673,
      "learning_rate": 9.939674145383728e-06,
      "loss": 0.5464,
      "step": 381
    },
    {
      "epoch": 0.0060484190192694395,
      "grad_norm": 0.18146799504756927,
      "learning_rate": 9.939515809807306e-06,
      "loss": 0.1915,
      "step": 382
    },
    {
      "epoch": 0.006064252576911506,
      "grad_norm": 0.02340736798942089,
      "learning_rate": 9.939357474230887e-06,
      "loss": 0.0024,
      "step": 383
    },
    {
      "epoch": 0.0060800861345535724,
      "grad_norm": 0.3594001233577728,
      "learning_rate": 9.939199138654466e-06,
      "loss": 0.2888,
      "step": 384
    },
    {
      "epoch": 0.006095919692195639,
      "grad_norm": 0.008274676278233528,
      "learning_rate": 9.939040803078045e-06,
      "loss": 0.0003,
      "step": 385
    },
    {
      "epoch": 0.006111753249837706,
      "grad_norm": 0.07803957164287567,
      "learning_rate": 9.938882467501624e-06,
      "loss": 0.0472,
      "step": 386
    },
    {
      "epoch": 0.006127586807479772,
      "grad_norm": 0.18930356204509735,
      "learning_rate": 9.938724131925203e-06,
      "loss": 0.1622,
      "step": 387
    },
    {
      "epoch": 0.006143420365121839,
      "grad_norm": 0.0035104251001030207,
      "learning_rate": 9.938565796348782e-06,
      "loss": 0.0002,
      "step": 388
    },
    {
      "epoch": 0.006159253922763906,
      "grad_norm": 0.2796124219894409,
      "learning_rate": 9.938407460772361e-06,
      "loss": 0.2857,
      "step": 389
    },
    {
      "epoch": 0.006175087480405972,
      "grad_norm": 0.1787189543247223,
      "learning_rate": 9.938249125195942e-06,
      "loss": 0.4628,
      "step": 390
    },
    {
      "epoch": 0.006190921038048039,
      "grad_norm": 0.1503419727087021,
      "learning_rate": 9.93809078961952e-06,
      "loss": 0.3722,
      "step": 391
    },
    {
      "epoch": 0.006206754595690106,
      "grad_norm": 0.23440538346767426,
      "learning_rate": 9.9379324540431e-06,
      "loss": 0.012,
      "step": 392
    },
    {
      "epoch": 0.006222588153332172,
      "grad_norm": 0.10974723100662231,
      "learning_rate": 9.937774118466679e-06,
      "loss": 0.5149,
      "step": 393
    },
    {
      "epoch": 0.006238421710974239,
      "grad_norm": 0.13677158951759338,
      "learning_rate": 9.937615782890258e-06,
      "loss": 0.3477,
      "step": 394
    },
    {
      "epoch": 0.006254255268616306,
      "grad_norm": 0.06661403924226761,
      "learning_rate": 9.937457447313837e-06,
      "loss": 0.0406,
      "step": 395
    },
    {
      "epoch": 0.006270088826258372,
      "grad_norm": 0.014045697636902332,
      "learning_rate": 9.937299111737418e-06,
      "loss": 0.0039,
      "step": 396
    },
    {
      "epoch": 0.0062859223839004386,
      "grad_norm": 0.006769078318029642,
      "learning_rate": 9.937140776160995e-06,
      "loss": 0.0004,
      "step": 397
    },
    {
      "epoch": 0.0063017559415425055,
      "grad_norm": 0.5536237955093384,
      "learning_rate": 9.936982440584576e-06,
      "loss": 0.2623,
      "step": 398
    },
    {
      "epoch": 0.0063175894991845715,
      "grad_norm": 0.2288985699415207,
      "learning_rate": 9.936824105008155e-06,
      "loss": 0.1804,
      "step": 399
    },
    {
      "epoch": 0.006333423056826638,
      "grad_norm": 0.10425763577222824,
      "learning_rate": 9.936665769431734e-06,
      "loss": 0.3883,
      "step": 400
    },
    {
      "epoch": 0.006349256614468705,
      "grad_norm": 0.14722710847854614,
      "learning_rate": 9.936507433855313e-06,
      "loss": 0.1404,
      "step": 401
    },
    {
      "epoch": 0.006365090172110771,
      "grad_norm": 0.025067949667572975,
      "learning_rate": 9.936349098278894e-06,
      "loss": 0.001,
      "step": 402
    },
    {
      "epoch": 0.006380923729752838,
      "grad_norm": 0.17934143543243408,
      "learning_rate": 9.936190762702472e-06,
      "loss": 0.908,
      "step": 403
    },
    {
      "epoch": 0.006396757287394905,
      "grad_norm": 0.12092451751232147,
      "learning_rate": 9.936032427126052e-06,
      "loss": 0.1067,
      "step": 404
    },
    {
      "epoch": 0.006412590845036971,
      "grad_norm": 0.2972470223903656,
      "learning_rate": 9.935874091549631e-06,
      "loss": 0.4315,
      "step": 405
    },
    {
      "epoch": 0.006428424402679038,
      "grad_norm": 0.32957693934440613,
      "learning_rate": 9.93571575597321e-06,
      "loss": 0.4621,
      "step": 406
    },
    {
      "epoch": 0.006444257960321105,
      "grad_norm": 0.20266124606132507,
      "learning_rate": 9.93555742039679e-06,
      "loss": 0.2083,
      "step": 407
    },
    {
      "epoch": 0.006460091517963171,
      "grad_norm": 0.17974995076656342,
      "learning_rate": 9.93539908482037e-06,
      "loss": 0.622,
      "step": 408
    },
    {
      "epoch": 0.006475925075605238,
      "grad_norm": 0.057230476289987564,
      "learning_rate": 9.935240749243948e-06,
      "loss": 0.0292,
      "step": 409
    },
    {
      "epoch": 0.006491758633247305,
      "grad_norm": 0.18825788795948029,
      "learning_rate": 9.935082413667527e-06,
      "loss": 0.2019,
      "step": 410
    },
    {
      "epoch": 0.006507592190889371,
      "grad_norm": 0.024086033925414085,
      "learning_rate": 9.934924078091108e-06,
      "loss": 0.0045,
      "step": 411
    },
    {
      "epoch": 0.006523425748531438,
      "grad_norm": 0.001938547007739544,
      "learning_rate": 9.934765742514687e-06,
      "loss": 0.0002,
      "step": 412
    },
    {
      "epoch": 0.0065392593061735045,
      "grad_norm": 0.12466089427471161,
      "learning_rate": 9.934607406938266e-06,
      "loss": 0.2278,
      "step": 413
    },
    {
      "epoch": 0.0065550928638155705,
      "grad_norm": 0.3511088192462921,
      "learning_rate": 9.934449071361845e-06,
      "loss": 0.4743,
      "step": 414
    },
    {
      "epoch": 0.006570926421457637,
      "grad_norm": 0.021653732284903526,
      "learning_rate": 9.934290735785424e-06,
      "loss": 0.0006,
      "step": 415
    },
    {
      "epoch": 0.006586759979099704,
      "grad_norm": 0.016445783898234367,
      "learning_rate": 9.934132400209003e-06,
      "loss": 0.0018,
      "step": 416
    },
    {
      "epoch": 0.00660259353674177,
      "grad_norm": 0.22100557386875153,
      "learning_rate": 9.933974064632584e-06,
      "loss": 0.2458,
      "step": 417
    },
    {
      "epoch": 0.006618427094383837,
      "grad_norm": 0.18607787787914276,
      "learning_rate": 9.933815729056163e-06,
      "loss": 0.32,
      "step": 418
    },
    {
      "epoch": 0.006634260652025904,
      "grad_norm": 0.20915812253952026,
      "learning_rate": 9.933657393479742e-06,
      "loss": 0.446,
      "step": 419
    },
    {
      "epoch": 0.00665009420966797,
      "grad_norm": 0.0031291956547647715,
      "learning_rate": 9.933499057903321e-06,
      "loss": 0.0002,
      "step": 420
    },
    {
      "epoch": 0.006665927767310037,
      "grad_norm": 0.20261895656585693,
      "learning_rate": 9.9333407223269e-06,
      "loss": 0.3613,
      "step": 421
    },
    {
      "epoch": 0.006681761324952104,
      "grad_norm": 0.3306773602962494,
      "learning_rate": 9.933182386750479e-06,
      "loss": 0.0238,
      "step": 422
    },
    {
      "epoch": 0.00669759488259417,
      "grad_norm": 0.26247361302375793,
      "learning_rate": 9.93302405117406e-06,
      "loss": 0.4387,
      "step": 423
    },
    {
      "epoch": 0.006713428440236237,
      "grad_norm": 0.3074961006641388,
      "learning_rate": 9.932865715597639e-06,
      "loss": 0.2086,
      "step": 424
    },
    {
      "epoch": 0.006729261997878304,
      "grad_norm": 0.0040196687914431095,
      "learning_rate": 9.932707380021218e-06,
      "loss": 0.001,
      "step": 425
    },
    {
      "epoch": 0.00674509555552037,
      "grad_norm": 0.2285570502281189,
      "learning_rate": 9.932549044444797e-06,
      "loss": 0.3949,
      "step": 426
    },
    {
      "epoch": 0.006760929113162437,
      "grad_norm": 0.08787815272808075,
      "learning_rate": 9.932390708868376e-06,
      "loss": 0.038,
      "step": 427
    },
    {
      "epoch": 0.006776762670804503,
      "grad_norm": 0.012052350677549839,
      "learning_rate": 9.932232373291955e-06,
      "loss": 0.0019,
      "step": 428
    },
    {
      "epoch": 0.0067925962284465695,
      "grad_norm": 0.00402620155364275,
      "learning_rate": 9.932074037715536e-06,
      "loss": 0.0002,
      "step": 429
    },
    {
      "epoch": 0.006808429786088636,
      "grad_norm": 0.3033667504787445,
      "learning_rate": 9.931915702139115e-06,
      "loss": 0.567,
      "step": 430
    },
    {
      "epoch": 0.0068242633437307024,
      "grad_norm": 0.10274910926818848,
      "learning_rate": 9.931757366562694e-06,
      "loss": 0.0967,
      "step": 431
    },
    {
      "epoch": 0.006840096901372769,
      "grad_norm": 0.1196698248386383,
      "learning_rate": 9.931599030986273e-06,
      "loss": 0.0766,
      "step": 432
    },
    {
      "epoch": 0.006855930459014836,
      "grad_norm": 0.17395059764385223,
      "learning_rate": 9.931440695409852e-06,
      "loss": 0.0101,
      "step": 433
    },
    {
      "epoch": 0.006871764016656902,
      "grad_norm": 0.24219702184200287,
      "learning_rate": 9.931282359833431e-06,
      "loss": 0.2944,
      "step": 434
    },
    {
      "epoch": 0.006887597574298969,
      "grad_norm": 0.4138032793998718,
      "learning_rate": 9.93112402425701e-06,
      "loss": 1.1903,
      "step": 435
    },
    {
      "epoch": 0.006903431131941036,
      "grad_norm": 0.23079189658164978,
      "learning_rate": 9.930965688680591e-06,
      "loss": 0.2093,
      "step": 436
    },
    {
      "epoch": 0.006919264689583102,
      "grad_norm": 0.009299476630985737,
      "learning_rate": 9.930807353104169e-06,
      "loss": 0.0023,
      "step": 437
    },
    {
      "epoch": 0.006935098247225169,
      "grad_norm": 0.27972325682640076,
      "learning_rate": 9.93064901752775e-06,
      "loss": 0.8619,
      "step": 438
    },
    {
      "epoch": 0.006950931804867236,
      "grad_norm": 0.18542450666427612,
      "learning_rate": 9.930490681951329e-06,
      "loss": 0.1994,
      "step": 439
    },
    {
      "epoch": 0.006966765362509302,
      "grad_norm": 0.10218259692192078,
      "learning_rate": 9.930332346374908e-06,
      "loss": 0.0682,
      "step": 440
    },
    {
      "epoch": 0.006982598920151369,
      "grad_norm": 0.11620473116636276,
      "learning_rate": 9.930174010798487e-06,
      "loss": 0.1543,
      "step": 441
    },
    {
      "epoch": 0.006998432477793436,
      "grad_norm": 0.17965057492256165,
      "learning_rate": 9.930015675222067e-06,
      "loss": 0.0107,
      "step": 442
    },
    {
      "epoch": 0.007014266035435502,
      "grad_norm": 0.2045314908027649,
      "learning_rate": 9.929857339645645e-06,
      "loss": 0.3271,
      "step": 443
    },
    {
      "epoch": 0.0070300995930775685,
      "grad_norm": 0.17406268417835236,
      "learning_rate": 9.929699004069226e-06,
      "loss": 0.6297,
      "step": 444
    },
    {
      "epoch": 0.0070459331507196354,
      "grad_norm": 0.3396933376789093,
      "learning_rate": 9.929540668492805e-06,
      "loss": 0.4231,
      "step": 445
    },
    {
      "epoch": 0.0070617667083617015,
      "grad_norm": 0.19698193669319153,
      "learning_rate": 9.929382332916384e-06,
      "loss": 0.4297,
      "step": 446
    },
    {
      "epoch": 0.007077600266003768,
      "grad_norm": 0.12297069281339645,
      "learning_rate": 9.929223997339963e-06,
      "loss": 0.1222,
      "step": 447
    },
    {
      "epoch": 0.007093433823645835,
      "grad_norm": 0.0054575675167143345,
      "learning_rate": 9.929065661763542e-06,
      "loss": 0.0011,
      "step": 448
    },
    {
      "epoch": 0.007109267381287901,
      "grad_norm": 0.23864680528640747,
      "learning_rate": 9.928907326187121e-06,
      "loss": 0.1858,
      "step": 449
    },
    {
      "epoch": 0.007125100938929968,
      "grad_norm": 0.01114620640873909,
      "learning_rate": 9.928748990610702e-06,
      "loss": 0.0021,
      "step": 450
    },
    {
      "epoch": 0.007140934496572035,
      "grad_norm": 0.007045639678835869,
      "learning_rate": 9.928590655034281e-06,
      "loss": 0.0014,
      "step": 451
    },
    {
      "epoch": 0.007156768054214101,
      "grad_norm": 0.16470001637935638,
      "learning_rate": 9.92843231945786e-06,
      "loss": 0.549,
      "step": 452
    },
    {
      "epoch": 0.007172601611856168,
      "grad_norm": 0.10956254601478577,
      "learning_rate": 9.928273983881439e-06,
      "loss": 0.0931,
      "step": 453
    },
    {
      "epoch": 0.007188435169498235,
      "grad_norm": 0.35809555649757385,
      "learning_rate": 9.928115648305018e-06,
      "loss": 0.3142,
      "step": 454
    },
    {
      "epoch": 0.007204268727140301,
      "grad_norm": 0.006458303425461054,
      "learning_rate": 9.927957312728597e-06,
      "loss": 0.0009,
      "step": 455
    },
    {
      "epoch": 0.007220102284782368,
      "grad_norm": 0.1624583899974823,
      "learning_rate": 9.927798977152178e-06,
      "loss": 0.2785,
      "step": 456
    },
    {
      "epoch": 0.007235935842424435,
      "grad_norm": 0.24366475641727448,
      "learning_rate": 9.927640641575757e-06,
      "loss": 0.072,
      "step": 457
    },
    {
      "epoch": 0.007251769400066501,
      "grad_norm": 0.15057329833507538,
      "learning_rate": 9.927482305999334e-06,
      "loss": 0.2952,
      "step": 458
    },
    {
      "epoch": 0.007267602957708568,
      "grad_norm": 0.15956181287765503,
      "learning_rate": 9.927323970422915e-06,
      "loss": 0.1499,
      "step": 459
    },
    {
      "epoch": 0.0072834365153506345,
      "grad_norm": 0.12118963152170181,
      "learning_rate": 9.927165634846494e-06,
      "loss": 0.0701,
      "step": 460
    },
    {
      "epoch": 0.0072992700729927005,
      "grad_norm": 0.24531133472919464,
      "learning_rate": 9.927007299270073e-06,
      "loss": 0.5738,
      "step": 461
    },
    {
      "epoch": 0.007315103630634767,
      "grad_norm": 0.4076966345310211,
      "learning_rate": 9.926848963693652e-06,
      "loss": 0.1394,
      "step": 462
    },
    {
      "epoch": 0.007330937188276834,
      "grad_norm": 0.4340772330760956,
      "learning_rate": 9.926690628117233e-06,
      "loss": 0.4344,
      "step": 463
    },
    {
      "epoch": 0.0073467707459189,
      "grad_norm": 0.1503659039735794,
      "learning_rate": 9.92653229254081e-06,
      "loss": 0.0882,
      "step": 464
    },
    {
      "epoch": 0.007362604303560967,
      "grad_norm": 0.21641811728477478,
      "learning_rate": 9.926373956964391e-06,
      "loss": 0.1681,
      "step": 465
    },
    {
      "epoch": 0.007378437861203034,
      "grad_norm": 0.27003225684165955,
      "learning_rate": 9.92621562138797e-06,
      "loss": 0.8069,
      "step": 466
    },
    {
      "epoch": 0.0073942714188451,
      "grad_norm": 0.17110112309455872,
      "learning_rate": 9.92605728581155e-06,
      "loss": 0.1603,
      "step": 467
    },
    {
      "epoch": 0.007410104976487167,
      "grad_norm": 0.5133691430091858,
      "learning_rate": 9.925898950235129e-06,
      "loss": 0.2352,
      "step": 468
    },
    {
      "epoch": 0.007425938534129234,
      "grad_norm": 0.005046075209975243,
      "learning_rate": 9.92574061465871e-06,
      "loss": 0.0009,
      "step": 469
    },
    {
      "epoch": 0.0074417720917713,
      "grad_norm": 0.002766478806734085,
      "learning_rate": 9.925582279082287e-06,
      "loss": 0.0005,
      "step": 470
    },
    {
      "epoch": 0.007457605649413367,
      "grad_norm": 0.3346391022205353,
      "learning_rate": 9.925423943505868e-06,
      "loss": 0.8637,
      "step": 471
    },
    {
      "epoch": 0.007473439207055434,
      "grad_norm": 0.00764854159206152,
      "learning_rate": 9.925265607929447e-06,
      "loss": 0.0014,
      "step": 472
    },
    {
      "epoch": 0.0074892727646975,
      "grad_norm": 0.16513241827487946,
      "learning_rate": 9.925107272353026e-06,
      "loss": 0.2284,
      "step": 473
    },
    {
      "epoch": 0.007505106322339567,
      "grad_norm": 0.004683326464146376,
      "learning_rate": 9.924948936776605e-06,
      "loss": 0.0008,
      "step": 474
    },
    {
      "epoch": 0.0075209398799816335,
      "grad_norm": 0.33542707562446594,
      "learning_rate": 9.924790601200186e-06,
      "loss": 0.0488,
      "step": 475
    },
    {
      "epoch": 0.0075367734376236995,
      "grad_norm": 0.14071804285049438,
      "learning_rate": 9.924632265623763e-06,
      "loss": 0.0349,
      "step": 476
    },
    {
      "epoch": 0.007552606995265766,
      "grad_norm": 0.1206224337220192,
      "learning_rate": 9.924473930047344e-06,
      "loss": 0.1461,
      "step": 477
    },
    {
      "epoch": 0.007568440552907832,
      "grad_norm": 0.11448629945516586,
      "learning_rate": 9.924315594470923e-06,
      "loss": 0.1084,
      "step": 478
    },
    {
      "epoch": 0.007584274110549899,
      "grad_norm": 0.2541140615940094,
      "learning_rate": 9.924157258894502e-06,
      "loss": 0.8753,
      "step": 479
    },
    {
      "epoch": 0.007600107668191966,
      "grad_norm": 0.0011801292421296239,
      "learning_rate": 9.923998923318081e-06,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 0.007615941225834032,
      "grad_norm": 0.16744975745677948,
      "learning_rate": 9.923840587741662e-06,
      "loss": 0.1024,
      "step": 481
    },
    {
      "epoch": 0.007631774783476099,
      "grad_norm": 0.24471817910671234,
      "learning_rate": 9.923682252165239e-06,
      "loss": 0.2524,
      "step": 482
    },
    {
      "epoch": 0.007647608341118166,
      "grad_norm": 0.12861649692058563,
      "learning_rate": 9.923523916588818e-06,
      "loss": 0.1252,
      "step": 483
    },
    {
      "epoch": 0.007663441898760232,
      "grad_norm": 0.09119585901498795,
      "learning_rate": 9.923365581012399e-06,
      "loss": 0.0063,
      "step": 484
    },
    {
      "epoch": 0.007679275456402299,
      "grad_norm": 0.1965228170156479,
      "learning_rate": 9.923207245435978e-06,
      "loss": 0.2145,
      "step": 485
    },
    {
      "epoch": 0.007695109014044366,
      "grad_norm": 0.1866941750049591,
      "learning_rate": 9.923048909859557e-06,
      "loss": 0.0906,
      "step": 486
    },
    {
      "epoch": 0.007710942571686432,
      "grad_norm": 0.048414140939712524,
      "learning_rate": 9.922890574283136e-06,
      "loss": 0.0009,
      "step": 487
    },
    {
      "epoch": 0.007726776129328499,
      "grad_norm": 0.015936216339468956,
      "learning_rate": 9.922732238706715e-06,
      "loss": 0.0026,
      "step": 488
    },
    {
      "epoch": 0.007742609686970566,
      "grad_norm": 0.46749791502952576,
      "learning_rate": 9.922573903130294e-06,
      "loss": 1.0663,
      "step": 489
    },
    {
      "epoch": 0.007758443244612632,
      "grad_norm": 0.24306955933570862,
      "learning_rate": 9.922415567553875e-06,
      "loss": 0.3412,
      "step": 490
    },
    {
      "epoch": 0.0077742768022546985,
      "grad_norm": 0.17493344843387604,
      "learning_rate": 9.922257231977454e-06,
      "loss": 0.244,
      "step": 491
    },
    {
      "epoch": 0.007790110359896765,
      "grad_norm": 0.24237821996212006,
      "learning_rate": 9.922098896401033e-06,
      "loss": 0.2026,
      "step": 492
    },
    {
      "epoch": 0.0078059439175388315,
      "grad_norm": 0.0008758165640756488,
      "learning_rate": 9.921940560824612e-06,
      "loss": 0.0,
      "step": 493
    },
    {
      "epoch": 0.007821777475180898,
      "grad_norm": 0.1528089940547943,
      "learning_rate": 9.921782225248191e-06,
      "loss": 0.102,
      "step": 494
    },
    {
      "epoch": 0.007837611032822964,
      "grad_norm": 0.005115389823913574,
      "learning_rate": 9.92162388967177e-06,
      "loss": 0.0009,
      "step": 495
    },
    {
      "epoch": 0.007853444590465032,
      "grad_norm": 0.2850903570652008,
      "learning_rate": 9.921465554095351e-06,
      "loss": 0.556,
      "step": 496
    },
    {
      "epoch": 0.007869278148107098,
      "grad_norm": 0.3389894366264343,
      "learning_rate": 9.92130721851893e-06,
      "loss": 0.1846,
      "step": 497
    },
    {
      "epoch": 0.007885111705749164,
      "grad_norm": 0.00027438855613581836,
      "learning_rate": 9.92114888294251e-06,
      "loss": 0.0,
      "step": 498
    },
    {
      "epoch": 0.007900945263391232,
      "grad_norm": 0.10812778770923615,
      "learning_rate": 9.920990547366089e-06,
      "loss": 0.1013,
      "step": 499
    },
    {
      "epoch": 0.007916778821033298,
      "grad_norm": 0.0031444134656339884,
      "learning_rate": 9.920832211789668e-06,
      "loss": 0.0005,
      "step": 500
    },
    {
      "epoch": 0.007932612378675364,
      "grad_norm": 0.1860533207654953,
      "learning_rate": 9.920673876213247e-06,
      "loss": 0.328,
      "step": 501
    },
    {
      "epoch": 0.007948445936317432,
      "grad_norm": 0.12316174060106277,
      "learning_rate": 9.920515540636828e-06,
      "loss": 0.2886,
      "step": 502
    },
    {
      "epoch": 0.007964279493959498,
      "grad_norm": 0.5482801198959351,
      "learning_rate": 9.920357205060407e-06,
      "loss": 0.0975,
      "step": 503
    },
    {
      "epoch": 0.007980113051601564,
      "grad_norm": 0.3646445572376251,
      "learning_rate": 9.920198869483986e-06,
      "loss": 0.549,
      "step": 504
    },
    {
      "epoch": 0.007995946609243632,
      "grad_norm": 0.5679334998130798,
      "learning_rate": 9.920040533907565e-06,
      "loss": 0.1177,
      "step": 505
    },
    {
      "epoch": 0.008011780166885698,
      "grad_norm": 0.11137101799249649,
      "learning_rate": 9.919882198331144e-06,
      "loss": 0.1294,
      "step": 506
    },
    {
      "epoch": 0.008027613724527764,
      "grad_norm": 0.20839069783687592,
      "learning_rate": 9.919723862754723e-06,
      "loss": 0.2051,
      "step": 507
    },
    {
      "epoch": 0.008043447282169831,
      "grad_norm": 0.5764037370681763,
      "learning_rate": 9.919565527178302e-06,
      "loss": 0.1444,
      "step": 508
    },
    {
      "epoch": 0.008059280839811897,
      "grad_norm": 0.11373446881771088,
      "learning_rate": 9.919407191601883e-06,
      "loss": 0.0993,
      "step": 509
    },
    {
      "epoch": 0.008075114397453963,
      "grad_norm": 0.2872902452945709,
      "learning_rate": 9.91924885602546e-06,
      "loss": 0.1496,
      "step": 510
    },
    {
      "epoch": 0.008090947955096031,
      "grad_norm": 0.2817120850086212,
      "learning_rate": 9.919090520449041e-06,
      "loss": 0.5065,
      "step": 511
    },
    {
      "epoch": 0.008106781512738097,
      "grad_norm": 0.01712021231651306,
      "learning_rate": 9.91893218487262e-06,
      "loss": 0.002,
      "step": 512
    },
    {
      "epoch": 0.008122615070380163,
      "grad_norm": 0.0006617412436753511,
      "learning_rate": 9.918773849296199e-06,
      "loss": 0.0,
      "step": 513
    },
    {
      "epoch": 0.008138448628022231,
      "grad_norm": 0.4967556893825531,
      "learning_rate": 9.918615513719778e-06,
      "loss": 0.3359,
      "step": 514
    },
    {
      "epoch": 0.008154282185664297,
      "grad_norm": 0.12370916455984116,
      "learning_rate": 9.918457178143357e-06,
      "loss": 0.4318,
      "step": 515
    },
    {
      "epoch": 0.008170115743306363,
      "grad_norm": 0.2984420955181122,
      "learning_rate": 9.918298842566936e-06,
      "loss": 0.2741,
      "step": 516
    },
    {
      "epoch": 0.00818594930094843,
      "grad_norm": 0.002389810746535659,
      "learning_rate": 9.918140506990517e-06,
      "loss": 0.0004,
      "step": 517
    },
    {
      "epoch": 0.008201782858590497,
      "grad_norm": 0.018952321261167526,
      "learning_rate": 9.917982171414096e-06,
      "loss": 0.0006,
      "step": 518
    },
    {
      "epoch": 0.008217616416232563,
      "grad_norm": 0.006373904645442963,
      "learning_rate": 9.917823835837675e-06,
      "loss": 0.001,
      "step": 519
    },
    {
      "epoch": 0.00823344997387463,
      "grad_norm": 0.001194702577777207,
      "learning_rate": 9.917665500261254e-06,
      "loss": 0.0,
      "step": 520
    },
    {
      "epoch": 0.008249283531516697,
      "grad_norm": 0.12056237459182739,
      "learning_rate": 9.917507164684833e-06,
      "loss": 0.1737,
      "step": 521
    },
    {
      "epoch": 0.008265117089158763,
      "grad_norm": 0.002995030488818884,
      "learning_rate": 9.917348829108412e-06,
      "loss": 0.0002,
      "step": 522
    },
    {
      "epoch": 0.00828095064680083,
      "grad_norm": 0.5704007744789124,
      "learning_rate": 9.917190493531993e-06,
      "loss": 0.0834,
      "step": 523
    },
    {
      "epoch": 0.008296784204442896,
      "grad_norm": 0.3038080930709839,
      "learning_rate": 9.917032157955572e-06,
      "loss": 0.341,
      "step": 524
    },
    {
      "epoch": 0.008312617762084962,
      "grad_norm": 0.16801242530345917,
      "learning_rate": 9.916873822379151e-06,
      "loss": 0.9016,
      "step": 525
    },
    {
      "epoch": 0.00832845131972703,
      "grad_norm": 0.16182294487953186,
      "learning_rate": 9.91671548680273e-06,
      "loss": 0.1518,
      "step": 526
    },
    {
      "epoch": 0.008344284877369096,
      "grad_norm": 0.1738498955965042,
      "learning_rate": 9.91655715122631e-06,
      "loss": 0.4432,
      "step": 527
    },
    {
      "epoch": 0.008360118435011162,
      "grad_norm": 0.03444599360227585,
      "learning_rate": 9.916398815649889e-06,
      "loss": 0.0272,
      "step": 528
    },
    {
      "epoch": 0.00837595199265323,
      "grad_norm": 0.3353728950023651,
      "learning_rate": 9.91624048007347e-06,
      "loss": 0.1687,
      "step": 529
    },
    {
      "epoch": 0.008391785550295296,
      "grad_norm": 0.13900943100452423,
      "learning_rate": 9.916082144497049e-06,
      "loss": 0.2318,
      "step": 530
    },
    {
      "epoch": 0.008407619107937362,
      "grad_norm": 0.010477317497134209,
      "learning_rate": 9.915923808920626e-06,
      "loss": 0.0016,
      "step": 531
    },
    {
      "epoch": 0.00842345266557943,
      "grad_norm": 0.196328803896904,
      "learning_rate": 9.915765473344207e-06,
      "loss": 0.3099,
      "step": 532
    },
    {
      "epoch": 0.008439286223221496,
      "grad_norm": 0.14459475874900818,
      "learning_rate": 9.915607137767786e-06,
      "loss": 0.2003,
      "step": 533
    },
    {
      "epoch": 0.008455119780863562,
      "grad_norm": 0.004228019621223211,
      "learning_rate": 9.915448802191365e-06,
      "loss": 0.0007,
      "step": 534
    },
    {
      "epoch": 0.00847095333850563,
      "grad_norm": 0.1255909949541092,
      "learning_rate": 9.915290466614944e-06,
      "loss": 0.1983,
      "step": 535
    },
    {
      "epoch": 0.008486786896147696,
      "grad_norm": 0.22452016174793243,
      "learning_rate": 9.915132131038525e-06,
      "loss": 0.0157,
      "step": 536
    },
    {
      "epoch": 0.008502620453789762,
      "grad_norm": 0.16815637052059174,
      "learning_rate": 9.914973795462102e-06,
      "loss": 0.0522,
      "step": 537
    },
    {
      "epoch": 0.00851845401143183,
      "grad_norm": 0.18841131031513214,
      "learning_rate": 9.914815459885683e-06,
      "loss": 0.2294,
      "step": 538
    },
    {
      "epoch": 0.008534287569073895,
      "grad_norm": 0.16428382694721222,
      "learning_rate": 9.914657124309262e-06,
      "loss": 0.4027,
      "step": 539
    },
    {
      "epoch": 0.008550121126715961,
      "grad_norm": 0.1680772602558136,
      "learning_rate": 9.914498788732841e-06,
      "loss": 0.2729,
      "step": 540
    },
    {
      "epoch": 0.00856595468435803,
      "grad_norm": 0.1620749980211258,
      "learning_rate": 9.91434045315642e-06,
      "loss": 0.1574,
      "step": 541
    },
    {
      "epoch": 0.008581788242000095,
      "grad_norm": 0.21055302023887634,
      "learning_rate": 9.914182117580001e-06,
      "loss": 0.1206,
      "step": 542
    },
    {
      "epoch": 0.008597621799642161,
      "grad_norm": 0.0034190674778074026,
      "learning_rate": 9.914023782003578e-06,
      "loss": 0.0001,
      "step": 543
    },
    {
      "epoch": 0.008613455357284229,
      "grad_norm": 0.35671257972717285,
      "learning_rate": 9.913865446427159e-06,
      "loss": 0.1145,
      "step": 544
    },
    {
      "epoch": 0.008629288914926295,
      "grad_norm": 0.0021180908661335707,
      "learning_rate": 9.913707110850738e-06,
      "loss": 0.0003,
      "step": 545
    },
    {
      "epoch": 0.008645122472568361,
      "grad_norm": 0.10732036828994751,
      "learning_rate": 9.913548775274317e-06,
      "loss": 0.2084,
      "step": 546
    },
    {
      "epoch": 0.008660956030210429,
      "grad_norm": 0.10659465193748474,
      "learning_rate": 9.913390439697896e-06,
      "loss": 0.1242,
      "step": 547
    },
    {
      "epoch": 0.008676789587852495,
      "grad_norm": 0.22552630305290222,
      "learning_rate": 9.913232104121477e-06,
      "loss": 0.2256,
      "step": 548
    },
    {
      "epoch": 0.00869262314549456,
      "grad_norm": 0.22442644834518433,
      "learning_rate": 9.913073768545054e-06,
      "loss": 0.192,
      "step": 549
    },
    {
      "epoch": 0.008708456703136629,
      "grad_norm": 0.17977623641490936,
      "learning_rate": 9.912915432968635e-06,
      "loss": 0.0938,
      "step": 550
    },
    {
      "epoch": 0.008724290260778695,
      "grad_norm": 0.21836748719215393,
      "learning_rate": 9.912757097392214e-06,
      "loss": 0.0735,
      "step": 551
    },
    {
      "epoch": 0.00874012381842076,
      "grad_norm": 0.23047074675559998,
      "learning_rate": 9.912598761815793e-06,
      "loss": 0.234,
      "step": 552
    },
    {
      "epoch": 0.008755957376062828,
      "grad_norm": 0.0007137034554034472,
      "learning_rate": 9.912440426239372e-06,
      "loss": 0.0,
      "step": 553
    },
    {
      "epoch": 0.008771790933704894,
      "grad_norm": 0.11167491972446442,
      "learning_rate": 9.912282090662952e-06,
      "loss": 0.3437,
      "step": 554
    },
    {
      "epoch": 0.00878762449134696,
      "grad_norm": 0.02683841437101364,
      "learning_rate": 9.91212375508653e-06,
      "loss": 0.0035,
      "step": 555
    },
    {
      "epoch": 0.008803458048989026,
      "grad_norm": 0.22801603376865387,
      "learning_rate": 9.91196541951011e-06,
      "loss": 0.3121,
      "step": 556
    },
    {
      "epoch": 0.008819291606631094,
      "grad_norm": 0.31407901644706726,
      "learning_rate": 9.91180708393369e-06,
      "loss": 0.5302,
      "step": 557
    },
    {
      "epoch": 0.00883512516427316,
      "grad_norm": 0.1580042541027069,
      "learning_rate": 9.91164874835727e-06,
      "loss": 0.4226,
      "step": 558
    },
    {
      "epoch": 0.008850958721915226,
      "grad_norm": 0.00048290376435033977,
      "learning_rate": 9.911490412780849e-06,
      "loss": 0.0,
      "step": 559
    },
    {
      "epoch": 0.008866792279557294,
      "grad_norm": 0.1570255160331726,
      "learning_rate": 9.911332077204428e-06,
      "loss": 0.2448,
      "step": 560
    },
    {
      "epoch": 0.00888262583719936,
      "grad_norm": 0.11854482442140579,
      "learning_rate": 9.911173741628007e-06,
      "loss": 0.1133,
      "step": 561
    },
    {
      "epoch": 0.008898459394841426,
      "grad_norm": 0.38206595182418823,
      "learning_rate": 9.911015406051586e-06,
      "loss": 0.3473,
      "step": 562
    },
    {
      "epoch": 0.008914292952483494,
      "grad_norm": 0.0030509568750858307,
      "learning_rate": 9.910857070475167e-06,
      "loss": 0.0002,
      "step": 563
    },
    {
      "epoch": 0.00893012651012556,
      "grad_norm": 0.2144039273262024,
      "learning_rate": 9.910698734898746e-06,
      "loss": 0.2621,
      "step": 564
    },
    {
      "epoch": 0.008945960067767626,
      "grad_norm": 0.33115702867507935,
      "learning_rate": 9.910540399322325e-06,
      "loss": 0.2022,
      "step": 565
    },
    {
      "epoch": 0.008961793625409694,
      "grad_norm": 0.2293154001235962,
      "learning_rate": 9.910382063745904e-06,
      "loss": 0.3069,
      "step": 566
    },
    {
      "epoch": 0.00897762718305176,
      "grad_norm": 0.24360057711601257,
      "learning_rate": 9.910223728169483e-06,
      "loss": 0.241,
      "step": 567
    },
    {
      "epoch": 0.008993460740693826,
      "grad_norm": 0.12641510367393494,
      "learning_rate": 9.910065392593062e-06,
      "loss": 0.1547,
      "step": 568
    },
    {
      "epoch": 0.009009294298335893,
      "grad_norm": 0.3290146589279175,
      "learning_rate": 9.909907057016643e-06,
      "loss": 0.0794,
      "step": 569
    },
    {
      "epoch": 0.00902512785597796,
      "grad_norm": 0.10169757157564163,
      "learning_rate": 9.909748721440222e-06,
      "loss": 0.146,
      "step": 570
    },
    {
      "epoch": 0.009040961413620026,
      "grad_norm": 0.0005475611542351544,
      "learning_rate": 9.909590385863801e-06,
      "loss": 0.0,
      "step": 571
    },
    {
      "epoch": 0.009056794971262093,
      "grad_norm": 0.27528947591781616,
      "learning_rate": 9.90943205028738e-06,
      "loss": 0.6647,
      "step": 572
    },
    {
      "epoch": 0.00907262852890416,
      "grad_norm": 0.11961095035076141,
      "learning_rate": 9.909273714710959e-06,
      "loss": 0.0948,
      "step": 573
    },
    {
      "epoch": 0.009088462086546225,
      "grad_norm": 0.1290542632341385,
      "learning_rate": 9.909115379134538e-06,
      "loss": 0.0452,
      "step": 574
    },
    {
      "epoch": 0.009104295644188293,
      "grad_norm": 0.004359581507742405,
      "learning_rate": 9.908957043558119e-06,
      "loss": 0.0006,
      "step": 575
    },
    {
      "epoch": 0.009120129201830359,
      "grad_norm": 0.842438817024231,
      "learning_rate": 9.908798707981698e-06,
      "loss": 0.1332,
      "step": 576
    },
    {
      "epoch": 0.009135962759472425,
      "grad_norm": 0.15271617472171783,
      "learning_rate": 9.908640372405277e-06,
      "loss": 0.1368,
      "step": 577
    },
    {
      "epoch": 0.009151796317114493,
      "grad_norm": 0.20593339204788208,
      "learning_rate": 9.908482036828856e-06,
      "loss": 0.1061,
      "step": 578
    },
    {
      "epoch": 0.009167629874756559,
      "grad_norm": 0.041886068880558014,
      "learning_rate": 9.908323701252435e-06,
      "loss": 0.0012,
      "step": 579
    },
    {
      "epoch": 0.009183463432398625,
      "grad_norm": 0.15713420510292053,
      "learning_rate": 9.908165365676014e-06,
      "loss": 0.1037,
      "step": 580
    },
    {
      "epoch": 0.009199296990040693,
      "grad_norm": 0.07670062780380249,
      "learning_rate": 9.908007030099593e-06,
      "loss": 0.1153,
      "step": 581
    },
    {
      "epoch": 0.009215130547682759,
      "grad_norm": 0.10249734669923782,
      "learning_rate": 9.907848694523173e-06,
      "loss": 0.1024,
      "step": 582
    },
    {
      "epoch": 0.009230964105324825,
      "grad_norm": 0.32977399230003357,
      "learning_rate": 9.907690358946752e-06,
      "loss": 0.1346,
      "step": 583
    },
    {
      "epoch": 0.009246797662966892,
      "grad_norm": 0.16181613504886627,
      "learning_rate": 9.907532023370332e-06,
      "loss": 0.4391,
      "step": 584
    },
    {
      "epoch": 0.009262631220608959,
      "grad_norm": 0.13735973834991455,
      "learning_rate": 9.907373687793911e-06,
      "loss": 0.1301,
      "step": 585
    },
    {
      "epoch": 0.009278464778251025,
      "grad_norm": 0.19234196841716766,
      "learning_rate": 9.90721535221749e-06,
      "loss": 0.1227,
      "step": 586
    },
    {
      "epoch": 0.009294298335893092,
      "grad_norm": 0.0008679121965542436,
      "learning_rate": 9.90705701664107e-06,
      "loss": 0.0001,
      "step": 587
    },
    {
      "epoch": 0.009310131893535158,
      "grad_norm": 0.007019930053502321,
      "learning_rate": 9.906898681064649e-06,
      "loss": 0.0011,
      "step": 588
    },
    {
      "epoch": 0.009325965451177224,
      "grad_norm": 0.3522869348526001,
      "learning_rate": 9.906740345488228e-06,
      "loss": 0.4563,
      "step": 589
    },
    {
      "epoch": 0.009341799008819292,
      "grad_norm": 0.13088764250278473,
      "learning_rate": 9.906582009911809e-06,
      "loss": 0.0912,
      "step": 590
    },
    {
      "epoch": 0.009357632566461358,
      "grad_norm": 0.007143805734813213,
      "learning_rate": 9.906423674335388e-06,
      "loss": 0.0014,
      "step": 591
    },
    {
      "epoch": 0.009373466124103424,
      "grad_norm": 0.27736997604370117,
      "learning_rate": 9.906265338758967e-06,
      "loss": 0.1457,
      "step": 592
    },
    {
      "epoch": 0.009389299681745492,
      "grad_norm": 0.22913308441638947,
      "learning_rate": 9.906107003182546e-06,
      "loss": 0.3918,
      "step": 593
    },
    {
      "epoch": 0.009405133239387558,
      "grad_norm": 0.03880467265844345,
      "learning_rate": 9.905948667606125e-06,
      "loss": 0.0151,
      "step": 594
    },
    {
      "epoch": 0.009420966797029624,
      "grad_norm": 0.16890734434127808,
      "learning_rate": 9.905790332029704e-06,
      "loss": 0.2169,
      "step": 595
    },
    {
      "epoch": 0.009436800354671692,
      "grad_norm": 0.14732715487480164,
      "learning_rate": 9.905631996453285e-06,
      "loss": 0.4806,
      "step": 596
    },
    {
      "epoch": 0.009452633912313758,
      "grad_norm": 0.12676678597927094,
      "learning_rate": 9.905473660876864e-06,
      "loss": 0.0726,
      "step": 597
    },
    {
      "epoch": 0.009468467469955824,
      "grad_norm": 0.19942253828048706,
      "learning_rate": 9.905315325300443e-06,
      "loss": 0.107,
      "step": 598
    },
    {
      "epoch": 0.009484301027597892,
      "grad_norm": 0.16183370351791382,
      "learning_rate": 9.905156989724022e-06,
      "loss": 0.324,
      "step": 599
    },
    {
      "epoch": 0.009500134585239958,
      "grad_norm": 0.2328149527311325,
      "learning_rate": 9.904998654147601e-06,
      "loss": 0.2967,
      "step": 600
    },
    {
      "epoch": 0.009515968142882024,
      "grad_norm": 0.2233864963054657,
      "learning_rate": 9.90484031857118e-06,
      "loss": 0.2847,
      "step": 601
    },
    {
      "epoch": 0.009531801700524091,
      "grad_norm": 0.004482703283429146,
      "learning_rate": 9.90468198299476e-06,
      "loss": 0.0006,
      "step": 602
    },
    {
      "epoch": 0.009547635258166157,
      "grad_norm": 0.24971868097782135,
      "learning_rate": 9.90452364741834e-06,
      "loss": 0.1247,
      "step": 603
    },
    {
      "epoch": 0.009563468815808223,
      "grad_norm": 0.11665043234825134,
      "learning_rate": 9.904365311841917e-06,
      "loss": 0.0921,
      "step": 604
    },
    {
      "epoch": 0.009579302373450291,
      "grad_norm": 0.3431459367275238,
      "learning_rate": 9.904206976265498e-06,
      "loss": 0.8109,
      "step": 605
    },
    {
      "epoch": 0.009595135931092357,
      "grad_norm": 0.15591225028038025,
      "learning_rate": 9.904048640689077e-06,
      "loss": 0.1872,
      "step": 606
    },
    {
      "epoch": 0.009610969488734423,
      "grad_norm": 0.05753123015165329,
      "learning_rate": 9.903890305112656e-06,
      "loss": 0.0026,
      "step": 607
    },
    {
      "epoch": 0.009626803046376491,
      "grad_norm": 0.22491797804832458,
      "learning_rate": 9.903731969536235e-06,
      "loss": 0.1819,
      "step": 608
    },
    {
      "epoch": 0.009642636604018557,
      "grad_norm": 0.2618364989757538,
      "learning_rate": 9.903573633959816e-06,
      "loss": 0.2785,
      "step": 609
    },
    {
      "epoch": 0.009658470161660623,
      "grad_norm": 0.21224386990070343,
      "learning_rate": 9.903415298383394e-06,
      "loss": 0.1997,
      "step": 610
    },
    {
      "epoch": 0.00967430371930269,
      "grad_norm": 0.22123102843761444,
      "learning_rate": 9.903256962806974e-06,
      "loss": 0.1771,
      "step": 611
    },
    {
      "epoch": 0.009690137276944757,
      "grad_norm": 0.18782861530780792,
      "learning_rate": 9.903098627230553e-06,
      "loss": 0.1108,
      "step": 612
    },
    {
      "epoch": 0.009705970834586823,
      "grad_norm": 0.15224222838878632,
      "learning_rate": 9.902940291654132e-06,
      "loss": 0.263,
      "step": 613
    },
    {
      "epoch": 0.00972180439222889,
      "grad_norm": 0.30735117197036743,
      "learning_rate": 9.902781956077712e-06,
      "loss": 0.7994,
      "step": 614
    },
    {
      "epoch": 0.009737637949870957,
      "grad_norm": 0.000487033132230863,
      "learning_rate": 9.902623620501292e-06,
      "loss": 0.0,
      "step": 615
    },
    {
      "epoch": 0.009753471507513023,
      "grad_norm": 0.13484646379947662,
      "learning_rate": 9.90246528492487e-06,
      "loss": 0.2214,
      "step": 616
    },
    {
      "epoch": 0.00976930506515509,
      "grad_norm": 0.008057071827352047,
      "learning_rate": 9.90230694934845e-06,
      "loss": 0.0011,
      "step": 617
    },
    {
      "epoch": 0.009785138622797156,
      "grad_norm": 0.1489749252796173,
      "learning_rate": 9.90214861377203e-06,
      "loss": 0.0756,
      "step": 618
    },
    {
      "epoch": 0.009800972180439222,
      "grad_norm": 0.5749388337135315,
      "learning_rate": 9.901990278195609e-06,
      "loss": 0.2786,
      "step": 619
    },
    {
      "epoch": 0.00981680573808129,
      "grad_norm": 0.4012594223022461,
      "learning_rate": 9.901831942619188e-06,
      "loss": 0.0342,
      "step": 620
    },
    {
      "epoch": 0.009832639295723356,
      "grad_norm": 0.136914923787117,
      "learning_rate": 9.901673607042768e-06,
      "loss": 0.1563,
      "step": 621
    },
    {
      "epoch": 0.009848472853365422,
      "grad_norm": 0.09799312055110931,
      "learning_rate": 9.901515271466346e-06,
      "loss": 0.0845,
      "step": 622
    },
    {
      "epoch": 0.00986430641100749,
      "grad_norm": 0.25248539447784424,
      "learning_rate": 9.901356935889927e-06,
      "loss": 0.3094,
      "step": 623
    },
    {
      "epoch": 0.009880139968649556,
      "grad_norm": 0.6593313813209534,
      "learning_rate": 9.901198600313506e-06,
      "loss": 0.1174,
      "step": 624
    },
    {
      "epoch": 0.009895973526291622,
      "grad_norm": 0.11892316490411758,
      "learning_rate": 9.901040264737085e-06,
      "loss": 0.462,
      "step": 625
    },
    {
      "epoch": 0.00991180708393369,
      "grad_norm": 0.1580301970243454,
      "learning_rate": 9.900881929160664e-06,
      "loss": 0.2728,
      "step": 626
    },
    {
      "epoch": 0.009927640641575756,
      "grad_norm": 0.13546122610569,
      "learning_rate": 9.900723593584243e-06,
      "loss": 0.0353,
      "step": 627
    },
    {
      "epoch": 0.009943474199217822,
      "grad_norm": 0.1864871084690094,
      "learning_rate": 9.900565258007822e-06,
      "loss": 0.265,
      "step": 628
    },
    {
      "epoch": 0.00995930775685989,
      "grad_norm": 0.05721933767199516,
      "learning_rate": 9.900406922431401e-06,
      "loss": 0.0226,
      "step": 629
    },
    {
      "epoch": 0.009975141314501956,
      "grad_norm": 0.004169785417616367,
      "learning_rate": 9.900248586854982e-06,
      "loss": 0.0005,
      "step": 630
    },
    {
      "epoch": 0.009990974872144022,
      "grad_norm": 0.23123787343502045,
      "learning_rate": 9.900090251278561e-06,
      "loss": 0.4124,
      "step": 631
    },
    {
      "epoch": 0.01000680842978609,
      "grad_norm": 0.13639138638973236,
      "learning_rate": 9.89993191570214e-06,
      "loss": 0.0954,
      "step": 632
    },
    {
      "epoch": 0.010022641987428155,
      "grad_norm": 0.10353206098079681,
      "learning_rate": 9.899773580125719e-06,
      "loss": 0.0463,
      "step": 633
    },
    {
      "epoch": 0.010038475545070221,
      "grad_norm": 0.14749795198440552,
      "learning_rate": 9.899615244549298e-06,
      "loss": 0.2396,
      "step": 634
    },
    {
      "epoch": 0.01005430910271229,
      "grad_norm": 0.27587220072746277,
      "learning_rate": 9.899456908972877e-06,
      "loss": 0.0158,
      "step": 635
    },
    {
      "epoch": 0.010070142660354355,
      "grad_norm": 0.0010060203494504094,
      "learning_rate": 9.899298573396458e-06,
      "loss": 0.0001,
      "step": 636
    },
    {
      "epoch": 0.010085976217996421,
      "grad_norm": 0.09201911836862564,
      "learning_rate": 9.899140237820037e-06,
      "loss": 0.0261,
      "step": 637
    },
    {
      "epoch": 0.010101809775638489,
      "grad_norm": 0.27794814109802246,
      "learning_rate": 9.898981902243616e-06,
      "loss": 0.1537,
      "step": 638
    },
    {
      "epoch": 0.010117643333280555,
      "grad_norm": 0.268767386674881,
      "learning_rate": 9.898823566667195e-06,
      "loss": 0.6924,
      "step": 639
    },
    {
      "epoch": 0.010133476890922621,
      "grad_norm": 0.0719422772526741,
      "learning_rate": 9.898665231090774e-06,
      "loss": 0.0102,
      "step": 640
    },
    {
      "epoch": 0.010149310448564689,
      "grad_norm": 0.12347095459699631,
      "learning_rate": 9.898506895514353e-06,
      "loss": 0.1007,
      "step": 641
    },
    {
      "epoch": 0.010165144006206755,
      "grad_norm": 0.21105365455150604,
      "learning_rate": 9.898348559937934e-06,
      "loss": 0.049,
      "step": 642
    },
    {
      "epoch": 0.01018097756384882,
      "grad_norm": 0.19000674784183502,
      "learning_rate": 9.898190224361512e-06,
      "loss": 0.3048,
      "step": 643
    },
    {
      "epoch": 0.010196811121490889,
      "grad_norm": 0.12041661888360977,
      "learning_rate": 9.898031888785092e-06,
      "loss": 0.0746,
      "step": 644
    },
    {
      "epoch": 0.010212644679132955,
      "grad_norm": 0.13407176733016968,
      "learning_rate": 9.897873553208671e-06,
      "loss": 0.251,
      "step": 645
    },
    {
      "epoch": 0.01022847823677502,
      "grad_norm": 0.20853038132190704,
      "learning_rate": 9.89771521763225e-06,
      "loss": 0.0154,
      "step": 646
    },
    {
      "epoch": 0.010244311794417088,
      "grad_norm": 0.009828821755945683,
      "learning_rate": 9.89755688205583e-06,
      "loss": 0.0013,
      "step": 647
    },
    {
      "epoch": 0.010260145352059154,
      "grad_norm": 0.13567085564136505,
      "learning_rate": 9.89739854647941e-06,
      "loss": 0.1118,
      "step": 648
    },
    {
      "epoch": 0.01027597890970122,
      "grad_norm": 0.15364988148212433,
      "learning_rate": 9.897240210902988e-06,
      "loss": 0.1416,
      "step": 649
    },
    {
      "epoch": 0.010291812467343288,
      "grad_norm": 0.1322309821844101,
      "learning_rate": 9.897081875326567e-06,
      "loss": 0.1385,
      "step": 650
    },
    {
      "epoch": 0.010307646024985354,
      "grad_norm": 0.0007033093716017902,
      "learning_rate": 9.896923539750148e-06,
      "loss": 0.0,
      "step": 651
    },
    {
      "epoch": 0.01032347958262742,
      "grad_norm": 0.1413312405347824,
      "learning_rate": 9.896765204173727e-06,
      "loss": 0.1198,
      "step": 652
    },
    {
      "epoch": 0.010339313140269488,
      "grad_norm": 0.12585343420505524,
      "learning_rate": 9.896606868597306e-06,
      "loss": 0.4183,
      "step": 653
    },
    {
      "epoch": 0.010355146697911554,
      "grad_norm": 0.2081059366464615,
      "learning_rate": 9.896448533020885e-06,
      "loss": 0.2811,
      "step": 654
    },
    {
      "epoch": 0.01037098025555362,
      "grad_norm": 0.20360423624515533,
      "learning_rate": 9.896290197444464e-06,
      "loss": 0.5934,
      "step": 655
    },
    {
      "epoch": 0.010386813813195686,
      "grad_norm": 0.09086161106824875,
      "learning_rate": 9.896131861868043e-06,
      "loss": 0.3371,
      "step": 656
    },
    {
      "epoch": 0.010402647370837754,
      "grad_norm": 0.019334787502884865,
      "learning_rate": 9.895973526291624e-06,
      "loss": 0.0016,
      "step": 657
    },
    {
      "epoch": 0.01041848092847982,
      "grad_norm": 0.2285521924495697,
      "learning_rate": 9.895815190715203e-06,
      "loss": 0.1432,
      "step": 658
    },
    {
      "epoch": 0.010434314486121886,
      "grad_norm": 0.011415368877351284,
      "learning_rate": 9.895656855138782e-06,
      "loss": 0.0012,
      "step": 659
    },
    {
      "epoch": 0.010450148043763954,
      "grad_norm": 0.40031540393829346,
      "learning_rate": 9.895498519562361e-06,
      "loss": 0.772,
      "step": 660
    },
    {
      "epoch": 0.01046598160140602,
      "grad_norm": 0.1311563402414322,
      "learning_rate": 9.89534018398594e-06,
      "loss": 0.1074,
      "step": 661
    },
    {
      "epoch": 0.010481815159048086,
      "grad_norm": 0.0006249173893593252,
      "learning_rate": 9.89518184840952e-06,
      "loss": 0.0,
      "step": 662
    },
    {
      "epoch": 0.010497648716690153,
      "grad_norm": 0.0636143758893013,
      "learning_rate": 9.8950235128331e-06,
      "loss": 0.0098,
      "step": 663
    },
    {
      "epoch": 0.01051348227433222,
      "grad_norm": 0.007976981811225414,
      "learning_rate": 9.894865177256679e-06,
      "loss": 0.0017,
      "step": 664
    },
    {
      "epoch": 0.010529315831974286,
      "grad_norm": 0.07209618389606476,
      "learning_rate": 9.894706841680258e-06,
      "loss": 0.0472,
      "step": 665
    },
    {
      "epoch": 0.010545149389616353,
      "grad_norm": 0.24698317050933838,
      "learning_rate": 9.894548506103837e-06,
      "loss": 0.6915,
      "step": 666
    },
    {
      "epoch": 0.01056098294725842,
      "grad_norm": 0.3060181140899658,
      "learning_rate": 9.894390170527416e-06,
      "loss": 0.3335,
      "step": 667
    },
    {
      "epoch": 0.010576816504900485,
      "grad_norm": 1.1496374607086182,
      "learning_rate": 9.894231834950995e-06,
      "loss": 0.4733,
      "step": 668
    },
    {
      "epoch": 0.010592650062542553,
      "grad_norm": 0.09974686801433563,
      "learning_rate": 9.894073499374576e-06,
      "loss": 0.0406,
      "step": 669
    },
    {
      "epoch": 0.010608483620184619,
      "grad_norm": 0.02144831046462059,
      "learning_rate": 9.893915163798155e-06,
      "loss": 0.0033,
      "step": 670
    },
    {
      "epoch": 0.010624317177826685,
      "grad_norm": 0.011031761765480042,
      "learning_rate": 9.893756828221734e-06,
      "loss": 0.0015,
      "step": 671
    },
    {
      "epoch": 0.010640150735468753,
      "grad_norm": 0.2079346925020218,
      "learning_rate": 9.893598492645313e-06,
      "loss": 0.5336,
      "step": 672
    },
    {
      "epoch": 0.010655984293110819,
      "grad_norm": 0.08365631103515625,
      "learning_rate": 9.893440157068892e-06,
      "loss": 0.0519,
      "step": 673
    },
    {
      "epoch": 0.010671817850752885,
      "grad_norm": 0.11199688166379929,
      "learning_rate": 9.893281821492472e-06,
      "loss": 0.0829,
      "step": 674
    },
    {
      "epoch": 0.010687651408394953,
      "grad_norm": 0.09391134232282639,
      "learning_rate": 9.89312348591605e-06,
      "loss": 0.1241,
      "step": 675
    },
    {
      "epoch": 0.010703484966037019,
      "grad_norm": 0.0004732778179459274,
      "learning_rate": 9.892965150339631e-06,
      "loss": 0.0,
      "step": 676
    },
    {
      "epoch": 0.010719318523679085,
      "grad_norm": 0.11590702086687088,
      "learning_rate": 9.892806814763209e-06,
      "loss": 0.4718,
      "step": 677
    },
    {
      "epoch": 0.010735152081321152,
      "grad_norm": 0.1207687258720398,
      "learning_rate": 9.89264847918679e-06,
      "loss": 0.1115,
      "step": 678
    },
    {
      "epoch": 0.010750985638963219,
      "grad_norm": 0.014555007219314575,
      "learning_rate": 9.892490143610369e-06,
      "loss": 0.0035,
      "step": 679
    },
    {
      "epoch": 0.010766819196605285,
      "grad_norm": 0.00334149575792253,
      "learning_rate": 9.892331808033948e-06,
      "loss": 0.0005,
      "step": 680
    },
    {
      "epoch": 0.010782652754247352,
      "grad_norm": 0.000600659113842994,
      "learning_rate": 9.892173472457527e-06,
      "loss": 0.0,
      "step": 681
    },
    {
      "epoch": 0.010798486311889418,
      "grad_norm": 0.15534961223602295,
      "learning_rate": 9.892015136881108e-06,
      "loss": 0.0659,
      "step": 682
    },
    {
      "epoch": 0.010814319869531484,
      "grad_norm": 0.16013476252555847,
      "learning_rate": 9.891856801304685e-06,
      "loss": 0.3372,
      "step": 683
    },
    {
      "epoch": 0.010830153427173552,
      "grad_norm": 0.16107335686683655,
      "learning_rate": 9.891698465728266e-06,
      "loss": 0.1404,
      "step": 684
    },
    {
      "epoch": 0.010845986984815618,
      "grad_norm": 0.03416791185736656,
      "learning_rate": 9.891540130151845e-06,
      "loss": 0.0013,
      "step": 685
    },
    {
      "epoch": 0.010861820542457684,
      "grad_norm": 0.012790314853191376,
      "learning_rate": 9.891381794575424e-06,
      "loss": 0.0019,
      "step": 686
    },
    {
      "epoch": 0.010877654100099752,
      "grad_norm": 0.30667737126350403,
      "learning_rate": 9.891223458999003e-06,
      "loss": 0.0568,
      "step": 687
    },
    {
      "epoch": 0.010893487657741818,
      "grad_norm": 0.2725077271461487,
      "learning_rate": 9.891065123422584e-06,
      "loss": 0.7008,
      "step": 688
    },
    {
      "epoch": 0.010909321215383884,
      "grad_norm": 0.1523822695016861,
      "learning_rate": 9.890906787846161e-06,
      "loss": 0.0857,
      "step": 689
    },
    {
      "epoch": 0.010925154773025952,
      "grad_norm": 0.3014080226421356,
      "learning_rate": 9.890748452269742e-06,
      "loss": 1.5885,
      "step": 690
    },
    {
      "epoch": 0.010940988330668018,
      "grad_norm": 0.002539721317589283,
      "learning_rate": 9.890590116693321e-06,
      "loss": 0.0,
      "step": 691
    },
    {
      "epoch": 0.010956821888310084,
      "grad_norm": 0.1444011926651001,
      "learning_rate": 9.8904317811169e-06,
      "loss": 0.1931,
      "step": 692
    },
    {
      "epoch": 0.010972655445952152,
      "grad_norm": 0.09293606877326965,
      "learning_rate": 9.890273445540479e-06,
      "loss": 0.1245,
      "step": 693
    },
    {
      "epoch": 0.010988489003594218,
      "grad_norm": 0.025914473459124565,
      "learning_rate": 9.89011510996406e-06,
      "loss": 0.0101,
      "step": 694
    },
    {
      "epoch": 0.011004322561236284,
      "grad_norm": 0.1903005689382553,
      "learning_rate": 9.889956774387637e-06,
      "loss": 0.2909,
      "step": 695
    },
    {
      "epoch": 0.011020156118878351,
      "grad_norm": 0.20134001970291138,
      "learning_rate": 9.889798438811218e-06,
      "loss": 0.3532,
      "step": 696
    },
    {
      "epoch": 0.011035989676520417,
      "grad_norm": 0.5187063217163086,
      "learning_rate": 9.889640103234797e-06,
      "loss": 0.385,
      "step": 697
    },
    {
      "epoch": 0.011051823234162483,
      "grad_norm": 0.47729408740997314,
      "learning_rate": 9.889481767658376e-06,
      "loss": 0.0903,
      "step": 698
    },
    {
      "epoch": 0.011067656791804551,
      "grad_norm": 0.2061307728290558,
      "learning_rate": 9.889323432081955e-06,
      "loss": 0.4348,
      "step": 699
    },
    {
      "epoch": 0.011083490349446617,
      "grad_norm": 0.3189311623573303,
      "learning_rate": 9.889165096505534e-06,
      "loss": 0.2685,
      "step": 700
    },
    {
      "epoch": 0.011099323907088683,
      "grad_norm": 0.3883686065673828,
      "learning_rate": 9.889006760929113e-06,
      "loss": 0.182,
      "step": 701
    },
    {
      "epoch": 0.011115157464730751,
      "grad_norm": 0.22419032454490662,
      "learning_rate": 9.888848425352693e-06,
      "loss": 0.0686,
      "step": 702
    },
    {
      "epoch": 0.011130991022372817,
      "grad_norm": 0.9490784406661987,
      "learning_rate": 9.888690089776273e-06,
      "loss": 0.3189,
      "step": 703
    },
    {
      "epoch": 0.011146824580014883,
      "grad_norm": 0.3470587134361267,
      "learning_rate": 9.888531754199852e-06,
      "loss": 0.1475,
      "step": 704
    },
    {
      "epoch": 0.01116265813765695,
      "grad_norm": 0.004022796172648668,
      "learning_rate": 9.888373418623431e-06,
      "loss": 0.0005,
      "step": 705
    },
    {
      "epoch": 0.011178491695299017,
      "grad_norm": 0.0008399140206165612,
      "learning_rate": 9.88821508304701e-06,
      "loss": 0.0,
      "step": 706
    },
    {
      "epoch": 0.011194325252941083,
      "grad_norm": 0.17178186774253845,
      "learning_rate": 9.88805674747059e-06,
      "loss": 0.2027,
      "step": 707
    },
    {
      "epoch": 0.01121015881058315,
      "grad_norm": 0.1331586241722107,
      "learning_rate": 9.887898411894169e-06,
      "loss": 0.3581,
      "step": 708
    },
    {
      "epoch": 0.011225992368225217,
      "grad_norm": 0.26027965545654297,
      "learning_rate": 9.88774007631775e-06,
      "loss": 0.197,
      "step": 709
    },
    {
      "epoch": 0.011241825925867283,
      "grad_norm": 0.10797062516212463,
      "learning_rate": 9.887581740741327e-06,
      "loss": 0.0415,
      "step": 710
    },
    {
      "epoch": 0.01125765948350935,
      "grad_norm": 0.011348539963364601,
      "learning_rate": 9.887423405164908e-06,
      "loss": 0.0008,
      "step": 711
    },
    {
      "epoch": 0.011273493041151416,
      "grad_norm": 0.02176702953875065,
      "learning_rate": 9.887265069588487e-06,
      "loss": 0.0043,
      "step": 712
    },
    {
      "epoch": 0.011289326598793482,
      "grad_norm": 0.09069015085697174,
      "learning_rate": 9.887106734012066e-06,
      "loss": 0.0079,
      "step": 713
    },
    {
      "epoch": 0.01130516015643555,
      "grad_norm": 0.12679822742938995,
      "learning_rate": 9.886948398435645e-06,
      "loss": 0.0778,
      "step": 714
    },
    {
      "epoch": 0.011320993714077616,
      "grad_norm": 0.11488168686628342,
      "learning_rate": 9.886790062859226e-06,
      "loss": 0.3441,
      "step": 715
    },
    {
      "epoch": 0.011336827271719682,
      "grad_norm": 0.308884859085083,
      "learning_rate": 9.886631727282803e-06,
      "loss": 0.1672,
      "step": 716
    },
    {
      "epoch": 0.01135266082936175,
      "grad_norm": 0.4225795269012451,
      "learning_rate": 9.886473391706384e-06,
      "loss": 0.666,
      "step": 717
    },
    {
      "epoch": 0.011368494387003816,
      "grad_norm": 0.006300037726759911,
      "learning_rate": 9.886315056129963e-06,
      "loss": 0.0009,
      "step": 718
    },
    {
      "epoch": 0.011384327944645882,
      "grad_norm": 0.18215878307819366,
      "learning_rate": 9.886156720553542e-06,
      "loss": 0.3581,
      "step": 719
    },
    {
      "epoch": 0.01140016150228795,
      "grad_norm": 0.21029339730739594,
      "learning_rate": 9.885998384977121e-06,
      "loss": 0.0996,
      "step": 720
    },
    {
      "epoch": 0.011415995059930016,
      "grad_norm": 0.700093150138855,
      "learning_rate": 9.885840049400702e-06,
      "loss": 0.0944,
      "step": 721
    },
    {
      "epoch": 0.011431828617572082,
      "grad_norm": 0.0002973829105030745,
      "learning_rate": 9.88568171382428e-06,
      "loss": 0.0,
      "step": 722
    },
    {
      "epoch": 0.01144766217521415,
      "grad_norm": 0.18251781165599823,
      "learning_rate": 9.885523378247858e-06,
      "loss": 0.2192,
      "step": 723
    },
    {
      "epoch": 0.011463495732856216,
      "grad_norm": 0.09082294255495071,
      "learning_rate": 9.885365042671439e-06,
      "loss": 0.0058,
      "step": 724
    },
    {
      "epoch": 0.011479329290498282,
      "grad_norm": 0.006589248310774565,
      "learning_rate": 9.885206707095018e-06,
      "loss": 0.0008,
      "step": 725
    },
    {
      "epoch": 0.01149516284814035,
      "grad_norm": 0.1214446872472763,
      "learning_rate": 9.885048371518597e-06,
      "loss": 0.5981,
      "step": 726
    },
    {
      "epoch": 0.011510996405782415,
      "grad_norm": 0.2869561016559601,
      "learning_rate": 9.884890035942176e-06,
      "loss": 0.0165,
      "step": 727
    },
    {
      "epoch": 0.011526829963424481,
      "grad_norm": 0.12903371453285217,
      "learning_rate": 9.884731700365755e-06,
      "loss": 0.3896,
      "step": 728
    },
    {
      "epoch": 0.01154266352106655,
      "grad_norm": 0.11257928609848022,
      "learning_rate": 9.884573364789334e-06,
      "loss": 0.1107,
      "step": 729
    },
    {
      "epoch": 0.011558497078708615,
      "grad_norm": 0.061468563973903656,
      "learning_rate": 9.884415029212915e-06,
      "loss": 0.0124,
      "step": 730
    },
    {
      "epoch": 0.011574330636350681,
      "grad_norm": 0.00031541037606075406,
      "learning_rate": 9.884256693636494e-06,
      "loss": 0.0,
      "step": 731
    },
    {
      "epoch": 0.011590164193992749,
      "grad_norm": 0.3023359179496765,
      "learning_rate": 9.884098358060073e-06,
      "loss": 0.1972,
      "step": 732
    },
    {
      "epoch": 0.011605997751634815,
      "grad_norm": 0.1714288741350174,
      "learning_rate": 9.883940022483652e-06,
      "loss": 0.1304,
      "step": 733
    },
    {
      "epoch": 0.011621831309276881,
      "grad_norm": 0.09699272364377975,
      "learning_rate": 9.883781686907232e-06,
      "loss": 0.0821,
      "step": 734
    },
    {
      "epoch": 0.011637664866918949,
      "grad_norm": 0.00037757668178528547,
      "learning_rate": 9.88362335133081e-06,
      "loss": 0.0,
      "step": 735
    },
    {
      "epoch": 0.011653498424561015,
      "grad_norm": 0.33370402455329895,
      "learning_rate": 9.883465015754391e-06,
      "loss": 0.3153,
      "step": 736
    },
    {
      "epoch": 0.01166933198220308,
      "grad_norm": 0.08093868941068649,
      "learning_rate": 9.88330668017797e-06,
      "loss": 0.1146,
      "step": 737
    },
    {
      "epoch": 0.011685165539845149,
      "grad_norm": 0.3348827362060547,
      "learning_rate": 9.88314834460155e-06,
      "loss": 0.1201,
      "step": 738
    },
    {
      "epoch": 0.011700999097487215,
      "grad_norm": 0.6770622134208679,
      "learning_rate": 9.882990009025129e-06,
      "loss": 0.6745,
      "step": 739
    },
    {
      "epoch": 0.01171683265512928,
      "grad_norm": 0.7026774883270264,
      "learning_rate": 9.882831673448708e-06,
      "loss": 0.2279,
      "step": 740
    },
    {
      "epoch": 0.011732666212771348,
      "grad_norm": 0.1505044847726822,
      "learning_rate": 9.882673337872287e-06,
      "loss": 0.1022,
      "step": 741
    },
    {
      "epoch": 0.011748499770413414,
      "grad_norm": 0.20799358189105988,
      "learning_rate": 9.882515002295868e-06,
      "loss": 0.2152,
      "step": 742
    },
    {
      "epoch": 0.01176433332805548,
      "grad_norm": 0.16184400022029877,
      "learning_rate": 9.882356666719447e-06,
      "loss": 0.125,
      "step": 743
    },
    {
      "epoch": 0.011780166885697548,
      "grad_norm": 0.002826302545145154,
      "learning_rate": 9.882198331143026e-06,
      "loss": 0.0005,
      "step": 744
    },
    {
      "epoch": 0.011796000443339614,
      "grad_norm": 0.02155025489628315,
      "learning_rate": 9.882039995566605e-06,
      "loss": 0.0005,
      "step": 745
    },
    {
      "epoch": 0.01181183400098168,
      "grad_norm": 0.013735217042267323,
      "learning_rate": 9.881881659990184e-06,
      "loss": 0.0017,
      "step": 746
    },
    {
      "epoch": 0.011827667558623748,
      "grad_norm": 0.3179418742656708,
      "learning_rate": 9.881723324413763e-06,
      "loss": 0.1589,
      "step": 747
    },
    {
      "epoch": 0.011843501116265814,
      "grad_norm": 0.3097347319126129,
      "learning_rate": 9.881564988837342e-06,
      "loss": 0.5523,
      "step": 748
    },
    {
      "epoch": 0.01185933467390788,
      "grad_norm": 0.4108816087245941,
      "learning_rate": 9.881406653260923e-06,
      "loss": 0.1773,
      "step": 749
    },
    {
      "epoch": 0.011875168231549948,
      "grad_norm": 0.004062117543071508,
      "learning_rate": 9.8812483176845e-06,
      "loss": 0.0002,
      "step": 750
    },
    {
      "epoch": 0.011891001789192014,
      "grad_norm": 0.03686654567718506,
      "learning_rate": 9.881089982108081e-06,
      "loss": 0.003,
      "step": 751
    },
    {
      "epoch": 0.01190683534683408,
      "grad_norm": 0.023513400927186012,
      "learning_rate": 9.88093164653166e-06,
      "loss": 0.0031,
      "step": 752
    },
    {
      "epoch": 0.011922668904476148,
      "grad_norm": 0.203761488199234,
      "learning_rate": 9.88077331095524e-06,
      "loss": 0.64,
      "step": 753
    },
    {
      "epoch": 0.011938502462118214,
      "grad_norm": 0.11818791180849075,
      "learning_rate": 9.880614975378818e-06,
      "loss": 0.4015,
      "step": 754
    },
    {
      "epoch": 0.01195433601976028,
      "grad_norm": 0.3849150538444519,
      "learning_rate": 9.880456639802399e-06,
      "loss": 0.1949,
      "step": 755
    },
    {
      "epoch": 0.011970169577402346,
      "grad_norm": 0.015458697453141212,
      "learning_rate": 9.880298304225976e-06,
      "loss": 0.001,
      "step": 756
    },
    {
      "epoch": 0.011986003135044413,
      "grad_norm": 0.24676689505577087,
      "learning_rate": 9.880139968649557e-06,
      "loss": 0.6185,
      "step": 757
    },
    {
      "epoch": 0.01200183669268648,
      "grad_norm": 0.1876205950975418,
      "learning_rate": 9.879981633073136e-06,
      "loss": 0.1862,
      "step": 758
    },
    {
      "epoch": 0.012017670250328545,
      "grad_norm": 0.25310665369033813,
      "learning_rate": 9.879823297496715e-06,
      "loss": 0.6786,
      "step": 759
    },
    {
      "epoch": 0.012033503807970613,
      "grad_norm": 0.1661648005247116,
      "learning_rate": 9.879664961920294e-06,
      "loss": 0.2675,
      "step": 760
    },
    {
      "epoch": 0.01204933736561268,
      "grad_norm": 0.014966050162911415,
      "learning_rate": 9.879506626343875e-06,
      "loss": 0.0021,
      "step": 761
    },
    {
      "epoch": 0.012065170923254745,
      "grad_norm": 0.14396418631076813,
      "learning_rate": 9.879348290767453e-06,
      "loss": 0.1632,
      "step": 762
    },
    {
      "epoch": 0.012081004480896813,
      "grad_norm": 0.16464030742645264,
      "learning_rate": 9.879189955191033e-06,
      "loss": 0.0659,
      "step": 763
    },
    {
      "epoch": 0.012096838038538879,
      "grad_norm": 0.09436269104480743,
      "learning_rate": 9.879031619614612e-06,
      "loss": 0.1048,
      "step": 764
    },
    {
      "epoch": 0.012112671596180945,
      "grad_norm": 0.055303145200014114,
      "learning_rate": 9.878873284038191e-06,
      "loss": 0.0246,
      "step": 765
    },
    {
      "epoch": 0.012128505153823013,
      "grad_norm": 0.1969558596611023,
      "learning_rate": 9.87871494846177e-06,
      "loss": 0.2399,
      "step": 766
    },
    {
      "epoch": 0.012144338711465079,
      "grad_norm": 0.0033078480046242476,
      "learning_rate": 9.878556612885351e-06,
      "loss": 0.0001,
      "step": 767
    },
    {
      "epoch": 0.012160172269107145,
      "grad_norm": 0.1355588287115097,
      "learning_rate": 9.878398277308929e-06,
      "loss": 0.0709,
      "step": 768
    },
    {
      "epoch": 0.012176005826749213,
      "grad_norm": 0.11788182705640793,
      "learning_rate": 9.87823994173251e-06,
      "loss": 0.0821,
      "step": 769
    },
    {
      "epoch": 0.012191839384391279,
      "grad_norm": 0.0023887534625828266,
      "learning_rate": 9.878081606156089e-06,
      "loss": 0.0001,
      "step": 770
    },
    {
      "epoch": 0.012207672942033345,
      "grad_norm": 0.13075613975524902,
      "learning_rate": 9.877923270579668e-06,
      "loss": 0.3348,
      "step": 771
    },
    {
      "epoch": 0.012223506499675412,
      "grad_norm": 0.8403295278549194,
      "learning_rate": 9.877764935003247e-06,
      "loss": 0.1434,
      "step": 772
    },
    {
      "epoch": 0.012239340057317478,
      "grad_norm": 0.2810913622379303,
      "learning_rate": 9.877606599426826e-06,
      "loss": 0.2209,
      "step": 773
    },
    {
      "epoch": 0.012255173614959545,
      "grad_norm": 0.15633924305438995,
      "learning_rate": 9.877448263850405e-06,
      "loss": 0.0729,
      "step": 774
    },
    {
      "epoch": 0.012271007172601612,
      "grad_norm": 0.15734414756298065,
      "learning_rate": 9.877289928273984e-06,
      "loss": 0.4002,
      "step": 775
    },
    {
      "epoch": 0.012286840730243678,
      "grad_norm": 0.15567202866077423,
      "learning_rate": 9.877131592697565e-06,
      "loss": 0.3765,
      "step": 776
    },
    {
      "epoch": 0.012302674287885744,
      "grad_norm": 0.18091288208961487,
      "learning_rate": 9.876973257121142e-06,
      "loss": 0.8215,
      "step": 777
    },
    {
      "epoch": 0.012318507845527812,
      "grad_norm": 0.372118204832077,
      "learning_rate": 9.876814921544723e-06,
      "loss": 0.1915,
      "step": 778
    },
    {
      "epoch": 0.012334341403169878,
      "grad_norm": 0.24423159658908844,
      "learning_rate": 9.876656585968302e-06,
      "loss": 0.0908,
      "step": 779
    },
    {
      "epoch": 0.012350174960811944,
      "grad_norm": 0.0007880999473854899,
      "learning_rate": 9.876498250391881e-06,
      "loss": 0.0,
      "step": 780
    },
    {
      "epoch": 0.012366008518454012,
      "grad_norm": 0.16098329424858093,
      "learning_rate": 9.87633991481546e-06,
      "loss": 0.436,
      "step": 781
    },
    {
      "epoch": 0.012381842076096078,
      "grad_norm": 0.24300283193588257,
      "learning_rate": 9.876181579239041e-06,
      "loss": 0.2251,
      "step": 782
    },
    {
      "epoch": 0.012397675633738144,
      "grad_norm": 0.18720002472400665,
      "learning_rate": 9.876023243662618e-06,
      "loss": 0.0805,
      "step": 783
    },
    {
      "epoch": 0.012413509191380212,
      "grad_norm": 0.16914844512939453,
      "learning_rate": 9.875864908086199e-06,
      "loss": 0.5029,
      "step": 784
    },
    {
      "epoch": 0.012429342749022278,
      "grad_norm": 0.29408371448516846,
      "learning_rate": 9.875706572509778e-06,
      "loss": 0.5636,
      "step": 785
    },
    {
      "epoch": 0.012445176306664344,
      "grad_norm": 0.004040357191115618,
      "learning_rate": 9.875548236933357e-06,
      "loss": 0.0001,
      "step": 786
    },
    {
      "epoch": 0.012461009864306411,
      "grad_norm": 0.3523278832435608,
      "learning_rate": 9.875389901356936e-06,
      "loss": 0.3411,
      "step": 787
    },
    {
      "epoch": 0.012476843421948478,
      "grad_norm": 0.1286684274673462,
      "learning_rate": 9.875231565780517e-06,
      "loss": 0.1203,
      "step": 788
    },
    {
      "epoch": 0.012492676979590544,
      "grad_norm": 0.10025297850370407,
      "learning_rate": 9.875073230204094e-06,
      "loss": 0.0456,
      "step": 789
    },
    {
      "epoch": 0.012508510537232611,
      "grad_norm": 0.4225686490535736,
      "learning_rate": 9.874914894627675e-06,
      "loss": 0.1145,
      "step": 790
    },
    {
      "epoch": 0.012524344094874677,
      "grad_norm": 0.14524388313293457,
      "learning_rate": 9.874756559051254e-06,
      "loss": 0.0579,
      "step": 791
    },
    {
      "epoch": 0.012540177652516743,
      "grad_norm": 0.17208006978034973,
      "learning_rate": 9.874598223474833e-06,
      "loss": 0.3313,
      "step": 792
    },
    {
      "epoch": 0.012556011210158811,
      "grad_norm": 0.2834396958351135,
      "learning_rate": 9.874439887898413e-06,
      "loss": 0.0179,
      "step": 793
    },
    {
      "epoch": 0.012571844767800877,
      "grad_norm": 0.23674432933330536,
      "learning_rate": 9.874281552321992e-06,
      "loss": 0.3018,
      "step": 794
    },
    {
      "epoch": 0.012587678325442943,
      "grad_norm": 0.24835152924060822,
      "learning_rate": 9.87412321674557e-06,
      "loss": 0.246,
      "step": 795
    },
    {
      "epoch": 0.012603511883085011,
      "grad_norm": 0.4167848825454712,
      "learning_rate": 9.87396488116915e-06,
      "loss": 0.5032,
      "step": 796
    },
    {
      "epoch": 0.012619345440727077,
      "grad_norm": 0.05355679243803024,
      "learning_rate": 9.87380654559273e-06,
      "loss": 0.0052,
      "step": 797
    },
    {
      "epoch": 0.012635178998369143,
      "grad_norm": 0.16873395442962646,
      "learning_rate": 9.87364821001631e-06,
      "loss": 0.2106,
      "step": 798
    },
    {
      "epoch": 0.01265101255601121,
      "grad_norm": 0.0010185912251472473,
      "learning_rate": 9.873489874439889e-06,
      "loss": 0.0,
      "step": 799
    },
    {
      "epoch": 0.012666846113653277,
      "grad_norm": 0.031452476978302,
      "learning_rate": 9.873331538863468e-06,
      "loss": 0.0045,
      "step": 800
    },
    {
      "epoch": 0.012682679671295343,
      "grad_norm": 0.25817736983299255,
      "learning_rate": 9.873173203287047e-06,
      "loss": 0.7794,
      "step": 801
    },
    {
      "epoch": 0.01269851322893741,
      "grad_norm": 0.005121726077049971,
      "learning_rate": 9.873014867710626e-06,
      "loss": 0.0005,
      "step": 802
    },
    {
      "epoch": 0.012714346786579477,
      "grad_norm": 0.01921714097261429,
      "learning_rate": 9.872856532134207e-06,
      "loss": 0.0022,
      "step": 803
    },
    {
      "epoch": 0.012730180344221543,
      "grad_norm": 0.00034688360756263137,
      "learning_rate": 9.872698196557786e-06,
      "loss": 0.0,
      "step": 804
    },
    {
      "epoch": 0.01274601390186361,
      "grad_norm": 0.823332667350769,
      "learning_rate": 9.872539860981365e-06,
      "loss": 0.3205,
      "step": 805
    },
    {
      "epoch": 0.012761847459505676,
      "grad_norm": 0.20351813733577728,
      "learning_rate": 9.872381525404944e-06,
      "loss": 0.0646,
      "step": 806
    },
    {
      "epoch": 0.012777681017147742,
      "grad_norm": 0.2882081866264343,
      "learning_rate": 9.872223189828523e-06,
      "loss": 0.2307,
      "step": 807
    },
    {
      "epoch": 0.01279351457478981,
      "grad_norm": 0.25344979763031006,
      "learning_rate": 9.872064854252102e-06,
      "loss": 0.3571,
      "step": 808
    },
    {
      "epoch": 0.012809348132431876,
      "grad_norm": 0.30762970447540283,
      "learning_rate": 9.871906518675683e-06,
      "loss": 0.0876,
      "step": 809
    },
    {
      "epoch": 0.012825181690073942,
      "grad_norm": 0.30692043900489807,
      "learning_rate": 9.871748183099262e-06,
      "loss": 0.7638,
      "step": 810
    },
    {
      "epoch": 0.01284101524771601,
      "grad_norm": 0.17507924139499664,
      "learning_rate": 9.871589847522841e-06,
      "loss": 0.117,
      "step": 811
    },
    {
      "epoch": 0.012856848805358076,
      "grad_norm": 0.0001772078830981627,
      "learning_rate": 9.87143151194642e-06,
      "loss": 0.0,
      "step": 812
    },
    {
      "epoch": 0.012872682363000142,
      "grad_norm": 0.20068618655204773,
      "learning_rate": 9.87127317637e-06,
      "loss": 0.264,
      "step": 813
    },
    {
      "epoch": 0.01288851592064221,
      "grad_norm": 0.16057434678077698,
      "learning_rate": 9.871114840793578e-06,
      "loss": 0.2793,
      "step": 814
    },
    {
      "epoch": 0.012904349478284276,
      "grad_norm": 0.02194494940340519,
      "learning_rate": 9.870956505217159e-06,
      "loss": 0.0031,
      "step": 815
    },
    {
      "epoch": 0.012920183035926342,
      "grad_norm": 0.09580826014280319,
      "learning_rate": 9.870798169640738e-06,
      "loss": 0.0463,
      "step": 816
    },
    {
      "epoch": 0.01293601659356841,
      "grad_norm": 0.05214225500822067,
      "learning_rate": 9.870639834064317e-06,
      "loss": 0.0445,
      "step": 817
    },
    {
      "epoch": 0.012951850151210476,
      "grad_norm": 0.23591375350952148,
      "learning_rate": 9.870481498487896e-06,
      "loss": 0.2149,
      "step": 818
    },
    {
      "epoch": 0.012967683708852542,
      "grad_norm": 0.6041731834411621,
      "learning_rate": 9.870323162911475e-06,
      "loss": 0.5746,
      "step": 819
    },
    {
      "epoch": 0.01298351726649461,
      "grad_norm": 0.14000079035758972,
      "learning_rate": 9.870164827335054e-06,
      "loss": 0.0651,
      "step": 820
    },
    {
      "epoch": 0.012999350824136675,
      "grad_norm": 0.2673950493335724,
      "learning_rate": 9.870006491758634e-06,
      "loss": 0.2583,
      "step": 821
    },
    {
      "epoch": 0.013015184381778741,
      "grad_norm": 0.018329543992877007,
      "learning_rate": 9.869848156182214e-06,
      "loss": 0.0023,
      "step": 822
    },
    {
      "epoch": 0.01303101793942081,
      "grad_norm": 0.2700289785861969,
      "learning_rate": 9.869689820605792e-06,
      "loss": 0.1267,
      "step": 823
    },
    {
      "epoch": 0.013046851497062875,
      "grad_norm": 0.14938269555568695,
      "learning_rate": 9.869531485029372e-06,
      "loss": 0.1115,
      "step": 824
    },
    {
      "epoch": 0.013062685054704941,
      "grad_norm": 0.13691702485084534,
      "learning_rate": 9.869373149452952e-06,
      "loss": 0.233,
      "step": 825
    },
    {
      "epoch": 0.013078518612347009,
      "grad_norm": 0.17819033563137054,
      "learning_rate": 9.86921481387653e-06,
      "loss": 0.3792,
      "step": 826
    },
    {
      "epoch": 0.013094352169989075,
      "grad_norm": 0.1259356588125229,
      "learning_rate": 9.86905647830011e-06,
      "loss": 0.1003,
      "step": 827
    },
    {
      "epoch": 0.013110185727631141,
      "grad_norm": 0.30765867233276367,
      "learning_rate": 9.86889814272369e-06,
      "loss": 0.2696,
      "step": 828
    },
    {
      "epoch": 0.013126019285273209,
      "grad_norm": 0.13274015486240387,
      "learning_rate": 9.868739807147268e-06,
      "loss": 0.3086,
      "step": 829
    },
    {
      "epoch": 0.013141852842915275,
      "grad_norm": 0.0014494581846520305,
      "learning_rate": 9.868581471570849e-06,
      "loss": 0.0001,
      "step": 830
    },
    {
      "epoch": 0.01315768640055734,
      "grad_norm": 0.15983375906944275,
      "learning_rate": 9.868423135994428e-06,
      "loss": 0.0843,
      "step": 831
    },
    {
      "epoch": 0.013173519958199409,
      "grad_norm": 0.16698789596557617,
      "learning_rate": 9.868264800418007e-06,
      "loss": 0.1741,
      "step": 832
    },
    {
      "epoch": 0.013189353515841475,
      "grad_norm": 0.11725477874279022,
      "learning_rate": 9.868106464841586e-06,
      "loss": 0.1108,
      "step": 833
    },
    {
      "epoch": 0.01320518707348354,
      "grad_norm": 0.1650470495223999,
      "learning_rate": 9.867948129265165e-06,
      "loss": 0.11,
      "step": 834
    },
    {
      "epoch": 0.013221020631125608,
      "grad_norm": 0.1555768847465515,
      "learning_rate": 9.867789793688744e-06,
      "loss": 0.0393,
      "step": 835
    },
    {
      "epoch": 0.013236854188767674,
      "grad_norm": 0.13792107999324799,
      "learning_rate": 9.867631458112325e-06,
      "loss": 0.0654,
      "step": 836
    },
    {
      "epoch": 0.01325268774640974,
      "grad_norm": 0.11732828617095947,
      "learning_rate": 9.867473122535904e-06,
      "loss": 0.1009,
      "step": 837
    },
    {
      "epoch": 0.013268521304051808,
      "grad_norm": 0.13270403444766998,
      "learning_rate": 9.867314786959483e-06,
      "loss": 0.1506,
      "step": 838
    },
    {
      "epoch": 0.013284354861693874,
      "grad_norm": 0.002806274453178048,
      "learning_rate": 9.867156451383062e-06,
      "loss": 0.0001,
      "step": 839
    },
    {
      "epoch": 0.01330018841933594,
      "grad_norm": 0.0020325074438005686,
      "learning_rate": 9.866998115806641e-06,
      "loss": 0.0002,
      "step": 840
    },
    {
      "epoch": 0.013316021976978008,
      "grad_norm": 0.26140642166137695,
      "learning_rate": 9.86683978023022e-06,
      "loss": 0.2087,
      "step": 841
    },
    {
      "epoch": 0.013331855534620074,
      "grad_norm": 0.23854094743728638,
      "learning_rate": 9.866681444653801e-06,
      "loss": 0.1913,
      "step": 842
    },
    {
      "epoch": 0.01334768909226214,
      "grad_norm": 0.16999614238739014,
      "learning_rate": 9.86652310907738e-06,
      "loss": 0.1028,
      "step": 843
    },
    {
      "epoch": 0.013363522649904208,
      "grad_norm": 0.0005182767054066062,
      "learning_rate": 9.866364773500957e-06,
      "loss": 0.0,
      "step": 844
    },
    {
      "epoch": 0.013379356207546274,
      "grad_norm": 0.10831165313720703,
      "learning_rate": 9.866206437924538e-06,
      "loss": 0.0426,
      "step": 845
    },
    {
      "epoch": 0.01339518976518834,
      "grad_norm": 0.013771072030067444,
      "learning_rate": 9.866048102348117e-06,
      "loss": 0.0017,
      "step": 846
    },
    {
      "epoch": 0.013411023322830408,
      "grad_norm": 0.10882890224456787,
      "learning_rate": 9.865889766771696e-06,
      "loss": 0.3139,
      "step": 847
    },
    {
      "epoch": 0.013426856880472474,
      "grad_norm": 0.12245538085699081,
      "learning_rate": 9.865731431195275e-06,
      "loss": 0.066,
      "step": 848
    },
    {
      "epoch": 0.01344269043811454,
      "grad_norm": 0.002820781199261546,
      "learning_rate": 9.865573095618856e-06,
      "loss": 0.0001,
      "step": 849
    },
    {
      "epoch": 0.013458523995756607,
      "grad_norm": 0.32129499316215515,
      "learning_rate": 9.865414760042434e-06,
      "loss": 0.1907,
      "step": 850
    },
    {
      "epoch": 0.013474357553398673,
      "grad_norm": 0.14752840995788574,
      "learning_rate": 9.865256424466014e-06,
      "loss": 0.7336,
      "step": 851
    },
    {
      "epoch": 0.01349019111104074,
      "grad_norm": 0.0031999978236854076,
      "learning_rate": 9.865098088889593e-06,
      "loss": 0.0003,
      "step": 852
    },
    {
      "epoch": 0.013506024668682807,
      "grad_norm": 0.0772356167435646,
      "learning_rate": 9.864939753313173e-06,
      "loss": 0.0661,
      "step": 853
    },
    {
      "epoch": 0.013521858226324873,
      "grad_norm": 0.005300198215991259,
      "learning_rate": 9.864781417736752e-06,
      "loss": 0.0005,
      "step": 854
    },
    {
      "epoch": 0.01353769178396694,
      "grad_norm": 0.188967764377594,
      "learning_rate": 9.864623082160332e-06,
      "loss": 0.4396,
      "step": 855
    },
    {
      "epoch": 0.013553525341609005,
      "grad_norm": 0.29686906933784485,
      "learning_rate": 9.86446474658391e-06,
      "loss": 0.0542,
      "step": 856
    },
    {
      "epoch": 0.013569358899251073,
      "grad_norm": 0.08094549179077148,
      "learning_rate": 9.86430641100749e-06,
      "loss": 0.0825,
      "step": 857
    },
    {
      "epoch": 0.013585192456893139,
      "grad_norm": 0.4085392355918884,
      "learning_rate": 9.86414807543107e-06,
      "loss": 0.2048,
      "step": 858
    },
    {
      "epoch": 0.013601026014535205,
      "grad_norm": 0.007914851419627666,
      "learning_rate": 9.863989739854649e-06,
      "loss": 0.0005,
      "step": 859
    },
    {
      "epoch": 0.013616859572177273,
      "grad_norm": 0.26707831025123596,
      "learning_rate": 9.863831404278228e-06,
      "loss": 0.6373,
      "step": 860
    },
    {
      "epoch": 0.013632693129819339,
      "grad_norm": 0.11822493374347687,
      "learning_rate": 9.863673068701809e-06,
      "loss": 0.0064,
      "step": 861
    },
    {
      "epoch": 0.013648526687461405,
      "grad_norm": 0.1973702311515808,
      "learning_rate": 9.863514733125386e-06,
      "loss": 0.1634,
      "step": 862
    },
    {
      "epoch": 0.013664360245103473,
      "grad_norm": 0.0017134540248662233,
      "learning_rate": 9.863356397548967e-06,
      "loss": 0.0002,
      "step": 863
    },
    {
      "epoch": 0.013680193802745539,
      "grad_norm": 0.3092583417892456,
      "learning_rate": 9.863198061972546e-06,
      "loss": 0.3678,
      "step": 864
    },
    {
      "epoch": 0.013696027360387605,
      "grad_norm": 0.21265117824077606,
      "learning_rate": 9.863039726396125e-06,
      "loss": 0.2798,
      "step": 865
    },
    {
      "epoch": 0.013711860918029672,
      "grad_norm": 0.19013765454292297,
      "learning_rate": 9.862881390819704e-06,
      "loss": 0.1054,
      "step": 866
    },
    {
      "epoch": 0.013727694475671738,
      "grad_norm": 0.20415471494197845,
      "learning_rate": 9.862723055243283e-06,
      "loss": 0.1603,
      "step": 867
    },
    {
      "epoch": 0.013743528033313804,
      "grad_norm": 0.28017452359199524,
      "learning_rate": 9.862564719666862e-06,
      "loss": 0.2435,
      "step": 868
    },
    {
      "epoch": 0.013759361590955872,
      "grad_norm": 0.3203125596046448,
      "learning_rate": 9.862406384090441e-06,
      "loss": 0.2452,
      "step": 869
    },
    {
      "epoch": 0.013775195148597938,
      "grad_norm": 0.15808291733264923,
      "learning_rate": 9.862248048514022e-06,
      "loss": 0.2268,
      "step": 870
    },
    {
      "epoch": 0.013791028706240004,
      "grad_norm": 0.2922210395336151,
      "learning_rate": 9.862089712937601e-06,
      "loss": 0.1712,
      "step": 871
    },
    {
      "epoch": 0.013806862263882072,
      "grad_norm": 0.27436670660972595,
      "learning_rate": 9.86193137736118e-06,
      "loss": 0.3065,
      "step": 872
    },
    {
      "epoch": 0.013822695821524138,
      "grad_norm": 0.007323646917939186,
      "learning_rate": 9.86177304178476e-06,
      "loss": 0.0008,
      "step": 873
    },
    {
      "epoch": 0.013838529379166204,
      "grad_norm": 0.40434613823890686,
      "learning_rate": 9.861614706208338e-06,
      "loss": 0.8212,
      "step": 874
    },
    {
      "epoch": 0.013854362936808272,
      "grad_norm": 0.134018212556839,
      "learning_rate": 9.861456370631917e-06,
      "loss": 0.0743,
      "step": 875
    },
    {
      "epoch": 0.013870196494450338,
      "grad_norm": 0.3965778648853302,
      "learning_rate": 9.861298035055498e-06,
      "loss": 0.2129,
      "step": 876
    },
    {
      "epoch": 0.013886030052092404,
      "grad_norm": 0.14583061635494232,
      "learning_rate": 9.861139699479077e-06,
      "loss": 0.2004,
      "step": 877
    },
    {
      "epoch": 0.013901863609734472,
      "grad_norm": 0.09235819429159164,
      "learning_rate": 9.860981363902656e-06,
      "loss": 0.0238,
      "step": 878
    },
    {
      "epoch": 0.013917697167376538,
      "grad_norm": 0.32452595233917236,
      "learning_rate": 9.860823028326235e-06,
      "loss": 0.3293,
      "step": 879
    },
    {
      "epoch": 0.013933530725018604,
      "grad_norm": 0.11173044145107269,
      "learning_rate": 9.860664692749814e-06,
      "loss": 0.174,
      "step": 880
    },
    {
      "epoch": 0.013949364282660671,
      "grad_norm": 0.196629598736763,
      "learning_rate": 9.860506357173394e-06,
      "loss": 0.1261,
      "step": 881
    },
    {
      "epoch": 0.013965197840302737,
      "grad_norm": 0.3231077492237091,
      "learning_rate": 9.860348021596974e-06,
      "loss": 0.0557,
      "step": 882
    },
    {
      "epoch": 0.013981031397944804,
      "grad_norm": 0.3262975215911865,
      "learning_rate": 9.860189686020553e-06,
      "loss": 0.5116,
      "step": 883
    },
    {
      "epoch": 0.013996864955586871,
      "grad_norm": 0.1403467208147049,
      "learning_rate": 9.860031350444132e-06,
      "loss": 0.0626,
      "step": 884
    },
    {
      "epoch": 0.014012698513228937,
      "grad_norm": 0.0006183889345265925,
      "learning_rate": 9.859873014867712e-06,
      "loss": 0.0,
      "step": 885
    },
    {
      "epoch": 0.014028532070871003,
      "grad_norm": 0.3104361891746521,
      "learning_rate": 9.85971467929129e-06,
      "loss": 0.2143,
      "step": 886
    },
    {
      "epoch": 0.014044365628513071,
      "grad_norm": 0.1753973811864853,
      "learning_rate": 9.85955634371487e-06,
      "loss": 0.0922,
      "step": 887
    },
    {
      "epoch": 0.014060199186155137,
      "grad_norm": 0.0004758697177749127,
      "learning_rate": 9.85939800813845e-06,
      "loss": 0.0,
      "step": 888
    },
    {
      "epoch": 0.014076032743797203,
      "grad_norm": 0.44657352566719055,
      "learning_rate": 9.85923967256203e-06,
      "loss": 0.3173,
      "step": 889
    },
    {
      "epoch": 0.014091866301439271,
      "grad_norm": 0.864925742149353,
      "learning_rate": 9.859081336985609e-06,
      "loss": 0.2848,
      "step": 890
    },
    {
      "epoch": 0.014107699859081337,
      "grad_norm": 0.3690597116947174,
      "learning_rate": 9.858923001409188e-06,
      "loss": 0.083,
      "step": 891
    },
    {
      "epoch": 0.014123533416723403,
      "grad_norm": 0.16696946322917938,
      "learning_rate": 9.858764665832767e-06,
      "loss": 0.216,
      "step": 892
    },
    {
      "epoch": 0.01413936697436547,
      "grad_norm": 0.4570220112800598,
      "learning_rate": 9.858606330256346e-06,
      "loss": 0.1404,
      "step": 893
    },
    {
      "epoch": 0.014155200532007537,
      "grad_norm": 0.11804496496915817,
      "learning_rate": 9.858447994679925e-06,
      "loss": 0.046,
      "step": 894
    },
    {
      "epoch": 0.014171034089649603,
      "grad_norm": 0.16220149397850037,
      "learning_rate": 9.858289659103506e-06,
      "loss": 0.7737,
      "step": 895
    },
    {
      "epoch": 0.01418686764729167,
      "grad_norm": 0.14851023256778717,
      "learning_rate": 9.858131323527083e-06,
      "loss": 0.1381,
      "step": 896
    },
    {
      "epoch": 0.014202701204933737,
      "grad_norm": 0.11442571878433228,
      "learning_rate": 9.857972987950664e-06,
      "loss": 0.0637,
      "step": 897
    },
    {
      "epoch": 0.014218534762575803,
      "grad_norm": 0.3451237380504608,
      "learning_rate": 9.857814652374243e-06,
      "loss": 0.1921,
      "step": 898
    },
    {
      "epoch": 0.01423436832021787,
      "grad_norm": 0.1203659176826477,
      "learning_rate": 9.857656316797822e-06,
      "loss": 0.1452,
      "step": 899
    },
    {
      "epoch": 0.014250201877859936,
      "grad_norm": 0.3449884355068207,
      "learning_rate": 9.857497981221401e-06,
      "loss": 0.4897,
      "step": 900
    },
    {
      "epoch": 0.014266035435502002,
      "grad_norm": 0.1142086610198021,
      "learning_rate": 9.85733964564498e-06,
      "loss": 0.3485,
      "step": 901
    },
    {
      "epoch": 0.01428186899314407,
      "grad_norm": 0.001648701960220933,
      "learning_rate": 9.85718131006856e-06,
      "loss": 0.0001,
      "step": 902
    },
    {
      "epoch": 0.014297702550786136,
      "grad_norm": 0.1457752138376236,
      "learning_rate": 9.85702297449214e-06,
      "loss": 0.1747,
      "step": 903
    },
    {
      "epoch": 0.014313536108428202,
      "grad_norm": 0.18777626752853394,
      "learning_rate": 9.856864638915719e-06,
      "loss": 0.1663,
      "step": 904
    },
    {
      "epoch": 0.01432936966607027,
      "grad_norm": 0.03181138634681702,
      "learning_rate": 9.856706303339298e-06,
      "loss": 0.0058,
      "step": 905
    },
    {
      "epoch": 0.014345203223712336,
      "grad_norm": 0.00015145924407988787,
      "learning_rate": 9.856547967762877e-06,
      "loss": 0.0,
      "step": 906
    },
    {
      "epoch": 0.014361036781354402,
      "grad_norm": 0.1372474581003189,
      "learning_rate": 9.856389632186456e-06,
      "loss": 0.2438,
      "step": 907
    },
    {
      "epoch": 0.01437687033899647,
      "grad_norm": 0.111269012093544,
      "learning_rate": 9.856231296610035e-06,
      "loss": 0.1256,
      "step": 908
    },
    {
      "epoch": 0.014392703896638536,
      "grad_norm": 0.12283377349376678,
      "learning_rate": 9.856072961033616e-06,
      "loss": 0.0221,
      "step": 909
    },
    {
      "epoch": 0.014408537454280602,
      "grad_norm": 0.11391652375459671,
      "learning_rate": 9.855914625457195e-06,
      "loss": 0.1497,
      "step": 910
    },
    {
      "epoch": 0.01442437101192267,
      "grad_norm": 0.2250295877456665,
      "learning_rate": 9.855756289880774e-06,
      "loss": 0.1136,
      "step": 911
    },
    {
      "epoch": 0.014440204569564736,
      "grad_norm": 0.14705076813697815,
      "learning_rate": 9.855597954304353e-06,
      "loss": 0.1514,
      "step": 912
    },
    {
      "epoch": 0.014456038127206802,
      "grad_norm": 0.1802295744419098,
      "learning_rate": 9.855439618727933e-06,
      "loss": 0.036,
      "step": 913
    },
    {
      "epoch": 0.01447187168484887,
      "grad_norm": 0.005093245301395655,
      "learning_rate": 9.855281283151512e-06,
      "loss": 0.0005,
      "step": 914
    },
    {
      "epoch": 0.014487705242490935,
      "grad_norm": 0.007397923152893782,
      "learning_rate": 9.85512294757509e-06,
      "loss": 0.0004,
      "step": 915
    },
    {
      "epoch": 0.014503538800133001,
      "grad_norm": 0.14018630981445312,
      "learning_rate": 9.854964611998671e-06,
      "loss": 0.2188,
      "step": 916
    },
    {
      "epoch": 0.014519372357775069,
      "grad_norm": 0.0034134765155613422,
      "learning_rate": 9.854806276422249e-06,
      "loss": 0.0002,
      "step": 917
    },
    {
      "epoch": 0.014535205915417135,
      "grad_norm": 0.260312020778656,
      "learning_rate": 9.85464794084583e-06,
      "loss": 0.2543,
      "step": 918
    },
    {
      "epoch": 0.014551039473059201,
      "grad_norm": 0.21724876761436462,
      "learning_rate": 9.854489605269409e-06,
      "loss": 0.6062,
      "step": 919
    },
    {
      "epoch": 0.014566873030701269,
      "grad_norm": 0.017899690195918083,
      "learning_rate": 9.854331269692988e-06,
      "loss": 0.002,
      "step": 920
    },
    {
      "epoch": 0.014582706588343335,
      "grad_norm": 0.19470632076263428,
      "learning_rate": 9.854172934116567e-06,
      "loss": 0.277,
      "step": 921
    },
    {
      "epoch": 0.014598540145985401,
      "grad_norm": 0.08836271613836288,
      "learning_rate": 9.854014598540148e-06,
      "loss": 0.0299,
      "step": 922
    },
    {
      "epoch": 0.014614373703627469,
      "grad_norm": 0.18569013476371765,
      "learning_rate": 9.853856262963725e-06,
      "loss": 0.252,
      "step": 923
    },
    {
      "epoch": 0.014630207261269535,
      "grad_norm": 0.24837428331375122,
      "learning_rate": 9.853697927387306e-06,
      "loss": 0.4351,
      "step": 924
    },
    {
      "epoch": 0.0146460408189116,
      "grad_norm": 0.3690418601036072,
      "learning_rate": 9.853539591810885e-06,
      "loss": 0.2474,
      "step": 925
    },
    {
      "epoch": 0.014661874376553669,
      "grad_norm": 0.14698563516139984,
      "learning_rate": 9.853381256234464e-06,
      "loss": 0.0998,
      "step": 926
    },
    {
      "epoch": 0.014677707934195735,
      "grad_norm": 0.005860166158527136,
      "learning_rate": 9.853222920658043e-06,
      "loss": 0.0007,
      "step": 927
    },
    {
      "epoch": 0.0146935414918378,
      "grad_norm": 0.00837101973593235,
      "learning_rate": 9.853064585081624e-06,
      "loss": 0.0011,
      "step": 928
    },
    {
      "epoch": 0.014709375049479868,
      "grad_norm": 0.09892037510871887,
      "learning_rate": 9.852906249505201e-06,
      "loss": 0.0786,
      "step": 929
    },
    {
      "epoch": 0.014725208607121934,
      "grad_norm": 0.12181924283504486,
      "learning_rate": 9.852747913928782e-06,
      "loss": 0.0917,
      "step": 930
    },
    {
      "epoch": 0.014741042164764,
      "grad_norm": 0.0032597046811133623,
      "learning_rate": 9.852589578352361e-06,
      "loss": 0.0003,
      "step": 931
    },
    {
      "epoch": 0.014756875722406068,
      "grad_norm": 0.08643785864114761,
      "learning_rate": 9.85243124277594e-06,
      "loss": 0.0259,
      "step": 932
    },
    {
      "epoch": 0.014772709280048134,
      "grad_norm": 0.007737277541309595,
      "learning_rate": 9.85227290719952e-06,
      "loss": 0.0008,
      "step": 933
    },
    {
      "epoch": 0.0147885428376902,
      "grad_norm": 0.11600598692893982,
      "learning_rate": 9.8521145716231e-06,
      "loss": 0.007,
      "step": 934
    },
    {
      "epoch": 0.014804376395332268,
      "grad_norm": 0.10673227161169052,
      "learning_rate": 9.851956236046677e-06,
      "loss": 0.1185,
      "step": 935
    },
    {
      "epoch": 0.014820209952974334,
      "grad_norm": 0.21688322722911835,
      "learning_rate": 9.851797900470258e-06,
      "loss": 0.1138,
      "step": 936
    },
    {
      "epoch": 0.0148360435106164,
      "grad_norm": 0.13450893759727478,
      "learning_rate": 9.851639564893837e-06,
      "loss": 0.2454,
      "step": 937
    },
    {
      "epoch": 0.014851877068258468,
      "grad_norm": 0.12048172950744629,
      "learning_rate": 9.851481229317416e-06,
      "loss": 0.2808,
      "step": 938
    },
    {
      "epoch": 0.014867710625900534,
      "grad_norm": 0.22164250910282135,
      "learning_rate": 9.851322893740995e-06,
      "loss": 0.277,
      "step": 939
    },
    {
      "epoch": 0.0148835441835426,
      "grad_norm": 0.11774879693984985,
      "learning_rate": 9.851164558164574e-06,
      "loss": 0.2114,
      "step": 940
    },
    {
      "epoch": 0.014899377741184668,
      "grad_norm": 0.24759837985038757,
      "learning_rate": 9.851006222588154e-06,
      "loss": 0.4049,
      "step": 941
    },
    {
      "epoch": 0.014915211298826734,
      "grad_norm": 1.1255528926849365,
      "learning_rate": 9.850847887011733e-06,
      "loss": 0.0991,
      "step": 942
    },
    {
      "epoch": 0.0149310448564688,
      "grad_norm": 0.09572003036737442,
      "learning_rate": 9.850689551435313e-06,
      "loss": 0.0317,
      "step": 943
    },
    {
      "epoch": 0.014946878414110867,
      "grad_norm": 0.20149414241313934,
      "learning_rate": 9.850531215858892e-06,
      "loss": 0.3051,
      "step": 944
    },
    {
      "epoch": 0.014962711971752933,
      "grad_norm": 0.2941173017024994,
      "learning_rate": 9.850372880282472e-06,
      "loss": 0.2026,
      "step": 945
    },
    {
      "epoch": 0.014978545529395,
      "grad_norm": 0.13589535653591156,
      "learning_rate": 9.85021454470605e-06,
      "loss": 0.0491,
      "step": 946
    },
    {
      "epoch": 0.014994379087037067,
      "grad_norm": 0.15113718807697296,
      "learning_rate": 9.85005620912963e-06,
      "loss": 0.0989,
      "step": 947
    },
    {
      "epoch": 0.015010212644679133,
      "grad_norm": 0.003633239772170782,
      "learning_rate": 9.849897873553209e-06,
      "loss": 0.0001,
      "step": 948
    },
    {
      "epoch": 0.0150260462023212,
      "grad_norm": 0.17637024819850922,
      "learning_rate": 9.84973953797679e-06,
      "loss": 0.3139,
      "step": 949
    },
    {
      "epoch": 0.015041879759963267,
      "grad_norm": 0.004081406630575657,
      "learning_rate": 9.849581202400369e-06,
      "loss": 0.0004,
      "step": 950
    },
    {
      "epoch": 0.015057713317605333,
      "grad_norm": 0.12411785125732422,
      "learning_rate": 9.849422866823948e-06,
      "loss": 0.0994,
      "step": 951
    },
    {
      "epoch": 0.015073546875247399,
      "grad_norm": 0.259051114320755,
      "learning_rate": 9.849264531247527e-06,
      "loss": 0.1756,
      "step": 952
    },
    {
      "epoch": 0.015089380432889467,
      "grad_norm": 0.0044496068730950356,
      "learning_rate": 9.849106195671106e-06,
      "loss": 0.0004,
      "step": 953
    },
    {
      "epoch": 0.015105213990531533,
      "grad_norm": 0.5929469466209412,
      "learning_rate": 9.848947860094685e-06,
      "loss": 0.2833,
      "step": 954
    },
    {
      "epoch": 0.015121047548173599,
      "grad_norm": 0.13863013684749603,
      "learning_rate": 9.848789524518266e-06,
      "loss": 0.4382,
      "step": 955
    },
    {
      "epoch": 0.015136881105815665,
      "grad_norm": 0.0010258639231324196,
      "learning_rate": 9.848631188941845e-06,
      "loss": 0.0001,
      "step": 956
    },
    {
      "epoch": 0.015152714663457733,
      "grad_norm": 0.2529086470603943,
      "learning_rate": 9.848472853365424e-06,
      "loss": 0.7442,
      "step": 957
    },
    {
      "epoch": 0.015168548221099799,
      "grad_norm": 0.4305349886417389,
      "learning_rate": 9.848314517789003e-06,
      "loss": 0.0228,
      "step": 958
    },
    {
      "epoch": 0.015184381778741865,
      "grad_norm": 0.16054458916187286,
      "learning_rate": 9.848156182212582e-06,
      "loss": 0.0399,
      "step": 959
    },
    {
      "epoch": 0.015200215336383932,
      "grad_norm": 0.38345155119895935,
      "learning_rate": 9.847997846636161e-06,
      "loss": 1.0834,
      "step": 960
    },
    {
      "epoch": 0.015216048894025998,
      "grad_norm": 0.2763131856918335,
      "learning_rate": 9.847839511059742e-06,
      "loss": 0.905,
      "step": 961
    },
    {
      "epoch": 0.015231882451668064,
      "grad_norm": 0.2716766893863678,
      "learning_rate": 9.84768117548332e-06,
      "loss": 0.0576,
      "step": 962
    },
    {
      "epoch": 0.015247716009310132,
      "grad_norm": 0.12171907722949982,
      "learning_rate": 9.847522839906898e-06,
      "loss": 0.0349,
      "step": 963
    },
    {
      "epoch": 0.015263549566952198,
      "grad_norm": 0.14523446559906006,
      "learning_rate": 9.847364504330479e-06,
      "loss": 0.0239,
      "step": 964
    },
    {
      "epoch": 0.015279383124594264,
      "grad_norm": 0.019303904846310616,
      "learning_rate": 9.847206168754058e-06,
      "loss": 0.0041,
      "step": 965
    },
    {
      "epoch": 0.015295216682236332,
      "grad_norm": 0.31075748801231384,
      "learning_rate": 9.847047833177637e-06,
      "loss": 0.206,
      "step": 966
    },
    {
      "epoch": 0.015311050239878398,
      "grad_norm": 0.1404036283493042,
      "learning_rate": 9.846889497601216e-06,
      "loss": 0.0908,
      "step": 967
    },
    {
      "epoch": 0.015326883797520464,
      "grad_norm": 0.35372668504714966,
      "learning_rate": 9.846731162024795e-06,
      "loss": 0.3461,
      "step": 968
    },
    {
      "epoch": 0.015342717355162532,
      "grad_norm": 0.13869501650333405,
      "learning_rate": 9.846572826448375e-06,
      "loss": 0.0147,
      "step": 969
    },
    {
      "epoch": 0.015358550912804598,
      "grad_norm": 0.19220159947872162,
      "learning_rate": 9.846414490871955e-06,
      "loss": 0.0869,
      "step": 970
    },
    {
      "epoch": 0.015374384470446664,
      "grad_norm": 0.6997653841972351,
      "learning_rate": 9.846256155295534e-06,
      "loss": 0.0788,
      "step": 971
    },
    {
      "epoch": 0.015390218028088732,
      "grad_norm": 0.10727263242006302,
      "learning_rate": 9.846097819719113e-06,
      "loss": 0.0051,
      "step": 972
    },
    {
      "epoch": 0.015406051585730798,
      "grad_norm": 0.1658703237771988,
      "learning_rate": 9.845939484142693e-06,
      "loss": 0.1044,
      "step": 973
    },
    {
      "epoch": 0.015421885143372864,
      "grad_norm": 0.3414897620677948,
      "learning_rate": 9.845781148566272e-06,
      "loss": 0.4131,
      "step": 974
    },
    {
      "epoch": 0.015437718701014931,
      "grad_norm": 0.1953303962945938,
      "learning_rate": 9.84562281298985e-06,
      "loss": 0.1051,
      "step": 975
    },
    {
      "epoch": 0.015453552258656997,
      "grad_norm": 0.147767573595047,
      "learning_rate": 9.845464477413431e-06,
      "loss": 0.0332,
      "step": 976
    },
    {
      "epoch": 0.015469385816299063,
      "grad_norm": 0.21231873333454132,
      "learning_rate": 9.84530614183701e-06,
      "loss": 0.1429,
      "step": 977
    },
    {
      "epoch": 0.015485219373941131,
      "grad_norm": 0.3149797022342682,
      "learning_rate": 9.84514780626059e-06,
      "loss": 0.2124,
      "step": 978
    },
    {
      "epoch": 0.015501052931583197,
      "grad_norm": 0.19360031187534332,
      "learning_rate": 9.844989470684169e-06,
      "loss": 0.5445,
      "step": 979
    },
    {
      "epoch": 0.015516886489225263,
      "grad_norm": 0.04290264472365379,
      "learning_rate": 9.844831135107748e-06,
      "loss": 0.002,
      "step": 980
    },
    {
      "epoch": 0.015532720046867331,
      "grad_norm": 0.3376097083091736,
      "learning_rate": 9.844672799531327e-06,
      "loss": 0.2437,
      "step": 981
    },
    {
      "epoch": 0.015548553604509397,
      "grad_norm": 0.11659225076436996,
      "learning_rate": 9.844514463954908e-06,
      "loss": 0.0081,
      "step": 982
    },
    {
      "epoch": 0.015564387162151463,
      "grad_norm": 0.002593307290226221,
      "learning_rate": 9.844356128378487e-06,
      "loss": 0.0,
      "step": 983
    },
    {
      "epoch": 0.01558022071979353,
      "grad_norm": 0.20387431979179382,
      "learning_rate": 9.844197792802066e-06,
      "loss": 0.2228,
      "step": 984
    },
    {
      "epoch": 0.015596054277435597,
      "grad_norm": 0.2898221015930176,
      "learning_rate": 9.844039457225645e-06,
      "loss": 0.2159,
      "step": 985
    },
    {
      "epoch": 0.015611887835077663,
      "grad_norm": 0.12529802322387695,
      "learning_rate": 9.843881121649224e-06,
      "loss": 0.1226,
      "step": 986
    },
    {
      "epoch": 0.01562772139271973,
      "grad_norm": 0.3965023159980774,
      "learning_rate": 9.843722786072803e-06,
      "loss": 0.1272,
      "step": 987
    },
    {
      "epoch": 0.015643554950361797,
      "grad_norm": 0.05040335655212402,
      "learning_rate": 9.843564450496382e-06,
      "loss": 0.0018,
      "step": 988
    },
    {
      "epoch": 0.015659388508003864,
      "grad_norm": 0.14206096529960632,
      "learning_rate": 9.843406114919963e-06,
      "loss": 0.1536,
      "step": 989
    },
    {
      "epoch": 0.01567522206564593,
      "grad_norm": 0.1631268560886383,
      "learning_rate": 9.84324777934354e-06,
      "loss": 0.1472,
      "step": 990
    },
    {
      "epoch": 0.015691055623287996,
      "grad_norm": 0.009340743534266949,
      "learning_rate": 9.843089443767121e-06,
      "loss": 0.001,
      "step": 991
    },
    {
      "epoch": 0.015706889180930064,
      "grad_norm": 0.1623033881187439,
      "learning_rate": 9.8429311081907e-06,
      "loss": 0.1601,
      "step": 992
    },
    {
      "epoch": 0.01572272273857213,
      "grad_norm": 0.04052407667040825,
      "learning_rate": 9.84277277261428e-06,
      "loss": 0.0028,
      "step": 993
    },
    {
      "epoch": 0.015738556296214196,
      "grad_norm": 0.16260144114494324,
      "learning_rate": 9.842614437037858e-06,
      "loss": 0.1406,
      "step": 994
    },
    {
      "epoch": 0.015754389853856264,
      "grad_norm": 0.00012719507503788918,
      "learning_rate": 9.842456101461439e-06,
      "loss": 0.0,
      "step": 995
    },
    {
      "epoch": 0.01577022341149833,
      "grad_norm": 0.22060143947601318,
      "learning_rate": 9.842297765885016e-06,
      "loss": 0.786,
      "step": 996
    },
    {
      "epoch": 0.015786056969140396,
      "grad_norm": 0.0005926218000240624,
      "learning_rate": 9.842139430308597e-06,
      "loss": 0.0,
      "step": 997
    },
    {
      "epoch": 0.015801890526782464,
      "grad_norm": 0.11517470329999924,
      "learning_rate": 9.841981094732176e-06,
      "loss": 0.0598,
      "step": 998
    },
    {
      "epoch": 0.015817724084424528,
      "grad_norm": 0.00042574017425067723,
      "learning_rate": 9.841822759155755e-06,
      "loss": 0.0,
      "step": 999
    },
    {
      "epoch": 0.015833557642066596,
      "grad_norm": 0.15467621386051178,
      "learning_rate": 9.841664423579334e-06,
      "loss": 0.092,
      "step": 1000
    },
    {
      "epoch": 0.015849391199708664,
      "grad_norm": 0.10366616398096085,
      "learning_rate": 9.841506088002915e-06,
      "loss": 0.0036,
      "step": 1001
    },
    {
      "epoch": 0.015865224757350728,
      "grad_norm": 0.2919307351112366,
      "learning_rate": 9.841347752426493e-06,
      "loss": 0.1255,
      "step": 1002
    },
    {
      "epoch": 0.015881058314992796,
      "grad_norm": 0.26256561279296875,
      "learning_rate": 9.841189416850073e-06,
      "loss": 0.3889,
      "step": 1003
    },
    {
      "epoch": 0.015896891872634863,
      "grad_norm": 0.03694721683859825,
      "learning_rate": 9.841031081273652e-06,
      "loss": 0.0039,
      "step": 1004
    },
    {
      "epoch": 0.015912725430276928,
      "grad_norm": 0.2552127242088318,
      "learning_rate": 9.840872745697232e-06,
      "loss": 0.6576,
      "step": 1005
    },
    {
      "epoch": 0.015928558987918996,
      "grad_norm": 0.028635133057832718,
      "learning_rate": 9.84071441012081e-06,
      "loss": 0.0031,
      "step": 1006
    },
    {
      "epoch": 0.015944392545561063,
      "grad_norm": 0.018951117992401123,
      "learning_rate": 9.840556074544391e-06,
      "loss": 0.0019,
      "step": 1007
    },
    {
      "epoch": 0.015960226103203128,
      "grad_norm": 0.38955309987068176,
      "learning_rate": 9.840397738967969e-06,
      "loss": 0.8619,
      "step": 1008
    },
    {
      "epoch": 0.015976059660845195,
      "grad_norm": 0.011359748430550098,
      "learning_rate": 9.84023940339155e-06,
      "loss": 0.0011,
      "step": 1009
    },
    {
      "epoch": 0.015991893218487263,
      "grad_norm": 0.0005795288598164916,
      "learning_rate": 9.840081067815129e-06,
      "loss": 0.0,
      "step": 1010
    },
    {
      "epoch": 0.016007726776129327,
      "grad_norm": 0.006602240260690451,
      "learning_rate": 9.839922732238708e-06,
      "loss": 0.0006,
      "step": 1011
    },
    {
      "epoch": 0.016023560333771395,
      "grad_norm": 0.008457690477371216,
      "learning_rate": 9.839764396662287e-06,
      "loss": 0.001,
      "step": 1012
    },
    {
      "epoch": 0.016039393891413463,
      "grad_norm": 0.19468629360198975,
      "learning_rate": 9.839606061085866e-06,
      "loss": 0.1612,
      "step": 1013
    },
    {
      "epoch": 0.016055227449055527,
      "grad_norm": 0.026795515790581703,
      "learning_rate": 9.839447725509445e-06,
      "loss": 0.0008,
      "step": 1014
    },
    {
      "epoch": 0.016071061006697595,
      "grad_norm": 0.042510613799095154,
      "learning_rate": 9.839289389933024e-06,
      "loss": 0.0041,
      "step": 1015
    },
    {
      "epoch": 0.016086894564339663,
      "grad_norm": 0.3323068618774414,
      "learning_rate": 9.839131054356605e-06,
      "loss": 0.187,
      "step": 1016
    },
    {
      "epoch": 0.016102728121981727,
      "grad_norm": 0.1801418513059616,
      "learning_rate": 9.838972718780184e-06,
      "loss": 0.1047,
      "step": 1017
    },
    {
      "epoch": 0.016118561679623795,
      "grad_norm": 0.2092423439025879,
      "learning_rate": 9.838814383203763e-06,
      "loss": 0.4768,
      "step": 1018
    },
    {
      "epoch": 0.016134395237265862,
      "grad_norm": 0.0038325295317918062,
      "learning_rate": 9.838656047627342e-06,
      "loss": 0.0003,
      "step": 1019
    },
    {
      "epoch": 0.016150228794907927,
      "grad_norm": 0.034527700394392014,
      "learning_rate": 9.838497712050921e-06,
      "loss": 0.0049,
      "step": 1020
    },
    {
      "epoch": 0.016166062352549995,
      "grad_norm": 0.23410075902938843,
      "learning_rate": 9.8383393764745e-06,
      "loss": 0.0402,
      "step": 1021
    },
    {
      "epoch": 0.016181895910192062,
      "grad_norm": 0.14261247217655182,
      "learning_rate": 9.838181040898081e-06,
      "loss": 0.259,
      "step": 1022
    },
    {
      "epoch": 0.016197729467834127,
      "grad_norm": 0.16138917207717896,
      "learning_rate": 9.83802270532166e-06,
      "loss": 0.0652,
      "step": 1023
    },
    {
      "epoch": 0.016213563025476194,
      "grad_norm": 0.2989893853664398,
      "learning_rate": 9.83786436974524e-06,
      "loss": 0.5842,
      "step": 1024
    },
    {
      "epoch": 0.016229396583118262,
      "grad_norm": 0.19027139246463776,
      "learning_rate": 9.837706034168818e-06,
      "loss": 0.0307,
      "step": 1025
    },
    {
      "epoch": 0.016245230140760326,
      "grad_norm": 0.13757087290287018,
      "learning_rate": 9.837547698592397e-06,
      "loss": 0.1069,
      "step": 1026
    },
    {
      "epoch": 0.016261063698402394,
      "grad_norm": 0.15610812604427338,
      "learning_rate": 9.837389363015976e-06,
      "loss": 0.0815,
      "step": 1027
    },
    {
      "epoch": 0.016276897256044462,
      "grad_norm": 0.2618808448314667,
      "learning_rate": 9.837231027439557e-06,
      "loss": 1.059,
      "step": 1028
    },
    {
      "epoch": 0.016292730813686526,
      "grad_norm": 0.13951805233955383,
      "learning_rate": 9.837072691863135e-06,
      "loss": 0.185,
      "step": 1029
    },
    {
      "epoch": 0.016308564371328594,
      "grad_norm": 0.3626885712146759,
      "learning_rate": 9.836914356286715e-06,
      "loss": 0.2149,
      "step": 1030
    },
    {
      "epoch": 0.01632439792897066,
      "grad_norm": 0.3035602867603302,
      "learning_rate": 9.836756020710294e-06,
      "loss": 0.0189,
      "step": 1031
    },
    {
      "epoch": 0.016340231486612726,
      "grad_norm": 0.3155122697353363,
      "learning_rate": 9.836597685133874e-06,
      "loss": 0.3981,
      "step": 1032
    },
    {
      "epoch": 0.016356065044254794,
      "grad_norm": 0.2910010814666748,
      "learning_rate": 9.836439349557453e-06,
      "loss": 0.4133,
      "step": 1033
    },
    {
      "epoch": 0.01637189860189686,
      "grad_norm": 0.19506271183490753,
      "learning_rate": 9.836281013981033e-06,
      "loss": 0.2428,
      "step": 1034
    },
    {
      "epoch": 0.016387732159538926,
      "grad_norm": 0.22157080471515656,
      "learning_rate": 9.83612267840461e-06,
      "loss": 0.8163,
      "step": 1035
    },
    {
      "epoch": 0.016403565717180994,
      "grad_norm": 0.2585146427154541,
      "learning_rate": 9.83596434282819e-06,
      "loss": 0.0402,
      "step": 1036
    },
    {
      "epoch": 0.01641939927482306,
      "grad_norm": 0.08834140747785568,
      "learning_rate": 9.83580600725177e-06,
      "loss": 0.0099,
      "step": 1037
    },
    {
      "epoch": 0.016435232832465126,
      "grad_norm": 0.41324177384376526,
      "learning_rate": 9.83564767167535e-06,
      "loss": 0.0293,
      "step": 1038
    },
    {
      "epoch": 0.016451066390107193,
      "grad_norm": 0.2024921178817749,
      "learning_rate": 9.835489336098929e-06,
      "loss": 0.0402,
      "step": 1039
    },
    {
      "epoch": 0.01646689994774926,
      "grad_norm": 0.029548391699790955,
      "learning_rate": 9.835331000522508e-06,
      "loss": 0.0018,
      "step": 1040
    },
    {
      "epoch": 0.016482733505391325,
      "grad_norm": 0.21871349215507507,
      "learning_rate": 9.835172664946087e-06,
      "loss": 0.0817,
      "step": 1041
    },
    {
      "epoch": 0.016498567063033393,
      "grad_norm": 0.17799760401248932,
      "learning_rate": 9.835014329369666e-06,
      "loss": 0.16,
      "step": 1042
    },
    {
      "epoch": 0.01651440062067546,
      "grad_norm": 0.009903055615723133,
      "learning_rate": 9.834855993793247e-06,
      "loss": 0.0008,
      "step": 1043
    },
    {
      "epoch": 0.016530234178317525,
      "grad_norm": 0.24484172463417053,
      "learning_rate": 9.834697658216826e-06,
      "loss": 0.2903,
      "step": 1044
    },
    {
      "epoch": 0.016546067735959593,
      "grad_norm": 0.0003154478908982128,
      "learning_rate": 9.834539322640405e-06,
      "loss": 0.0,
      "step": 1045
    },
    {
      "epoch": 0.01656190129360166,
      "grad_norm": 0.03775349631905556,
      "learning_rate": 9.834380987063984e-06,
      "loss": 0.0021,
      "step": 1046
    },
    {
      "epoch": 0.016577734851243725,
      "grad_norm": 0.6625392436981201,
      "learning_rate": 9.834222651487563e-06,
      "loss": 0.0384,
      "step": 1047
    },
    {
      "epoch": 0.016593568408885793,
      "grad_norm": 0.22043117880821228,
      "learning_rate": 9.834064315911142e-06,
      "loss": 0.2926,
      "step": 1048
    },
    {
      "epoch": 0.01660940196652786,
      "grad_norm": 0.3131462335586548,
      "learning_rate": 9.833905980334723e-06,
      "loss": 0.2568,
      "step": 1049
    },
    {
      "epoch": 0.016625235524169925,
      "grad_norm": 0.0809522271156311,
      "learning_rate": 9.833747644758302e-06,
      "loss": 0.0345,
      "step": 1050
    },
    {
      "epoch": 0.016641069081811993,
      "grad_norm": 0.00891120359301567,
      "learning_rate": 9.833589309181881e-06,
      "loss": 0.0006,
      "step": 1051
    },
    {
      "epoch": 0.01665690263945406,
      "grad_norm": 0.0012653834419324994,
      "learning_rate": 9.83343097360546e-06,
      "loss": 0.0,
      "step": 1052
    },
    {
      "epoch": 0.016672736197096125,
      "grad_norm": 0.013570980168879032,
      "learning_rate": 9.83327263802904e-06,
      "loss": 0.001,
      "step": 1053
    },
    {
      "epoch": 0.016688569754738192,
      "grad_norm": 0.0006537039880640805,
      "learning_rate": 9.833114302452618e-06,
      "loss": 0.0,
      "step": 1054
    },
    {
      "epoch": 0.01670440331238026,
      "grad_norm": 0.00018303311662748456,
      "learning_rate": 9.832955966876199e-06,
      "loss": 0.0,
      "step": 1055
    },
    {
      "epoch": 0.016720236870022324,
      "grad_norm": 0.14929503202438354,
      "learning_rate": 9.832797631299778e-06,
      "loss": 0.0295,
      "step": 1056
    },
    {
      "epoch": 0.016736070427664392,
      "grad_norm": 0.12295302003622055,
      "learning_rate": 9.832639295723357e-06,
      "loss": 0.0345,
      "step": 1057
    },
    {
      "epoch": 0.01675190398530646,
      "grad_norm": 0.3339938521385193,
      "learning_rate": 9.832480960146936e-06,
      "loss": 0.7346,
      "step": 1058
    },
    {
      "epoch": 0.016767737542948524,
      "grad_norm": 0.17342200875282288,
      "learning_rate": 9.832322624570515e-06,
      "loss": 0.2243,
      "step": 1059
    },
    {
      "epoch": 0.016783571100590592,
      "grad_norm": 0.353693425655365,
      "learning_rate": 9.832164288994095e-06,
      "loss": 0.1161,
      "step": 1060
    },
    {
      "epoch": 0.01679940465823266,
      "grad_norm": 0.6946433186531067,
      "learning_rate": 9.832005953417674e-06,
      "loss": 0.3016,
      "step": 1061
    },
    {
      "epoch": 0.016815238215874724,
      "grad_norm": 0.24998487532138824,
      "learning_rate": 9.831847617841254e-06,
      "loss": 0.1865,
      "step": 1062
    },
    {
      "epoch": 0.016831071773516792,
      "grad_norm": 0.1759006381034851,
      "learning_rate": 9.831689282264832e-06,
      "loss": 0.127,
      "step": 1063
    },
    {
      "epoch": 0.01684690533115886,
      "grad_norm": 0.04659826681017876,
      "learning_rate": 9.831530946688413e-06,
      "loss": 0.0126,
      "step": 1064
    },
    {
      "epoch": 0.016862738888800924,
      "grad_norm": 0.24754680693149567,
      "learning_rate": 9.831372611111992e-06,
      "loss": 0.2611,
      "step": 1065
    },
    {
      "epoch": 0.01687857244644299,
      "grad_norm": 0.010215491987764835,
      "learning_rate": 9.83121427553557e-06,
      "loss": 0.0007,
      "step": 1066
    },
    {
      "epoch": 0.01689440600408506,
      "grad_norm": 0.07888483256101608,
      "learning_rate": 9.83105593995915e-06,
      "loss": 0.025,
      "step": 1067
    },
    {
      "epoch": 0.016910239561727124,
      "grad_norm": 0.001157440710812807,
      "learning_rate": 9.83089760438273e-06,
      "loss": 0.0001,
      "step": 1068
    },
    {
      "epoch": 0.01692607311936919,
      "grad_norm": 0.09593687951564789,
      "learning_rate": 9.830739268806308e-06,
      "loss": 0.0717,
      "step": 1069
    },
    {
      "epoch": 0.01694190667701126,
      "grad_norm": 0.413824200630188,
      "learning_rate": 9.830580933229889e-06,
      "loss": 0.6709,
      "step": 1070
    },
    {
      "epoch": 0.016957740234653323,
      "grad_norm": 0.21964417397975922,
      "learning_rate": 9.830422597653468e-06,
      "loss": 0.5176,
      "step": 1071
    },
    {
      "epoch": 0.01697357379229539,
      "grad_norm": 0.031087545678019524,
      "learning_rate": 9.830264262077047e-06,
      "loss": 0.0014,
      "step": 1072
    },
    {
      "epoch": 0.01698940734993746,
      "grad_norm": 0.004262885078787804,
      "learning_rate": 9.830105926500626e-06,
      "loss": 0.0004,
      "step": 1073
    },
    {
      "epoch": 0.017005240907579523,
      "grad_norm": 0.27246180176734924,
      "learning_rate": 9.829947590924207e-06,
      "loss": 0.1903,
      "step": 1074
    },
    {
      "epoch": 0.01702107446522159,
      "grad_norm": 0.0003943058545701206,
      "learning_rate": 9.829789255347784e-06,
      "loss": 0.0,
      "step": 1075
    },
    {
      "epoch": 0.01703690802286366,
      "grad_norm": 0.3330336809158325,
      "learning_rate": 9.829630919771365e-06,
      "loss": 0.1993,
      "step": 1076
    },
    {
      "epoch": 0.017052741580505723,
      "grad_norm": 0.003488523419946432,
      "learning_rate": 9.829472584194944e-06,
      "loss": 0.0002,
      "step": 1077
    },
    {
      "epoch": 0.01706857513814779,
      "grad_norm": 0.3519037365913391,
      "learning_rate": 9.829314248618523e-06,
      "loss": 1.1867,
      "step": 1078
    },
    {
      "epoch": 0.01708440869578986,
      "grad_norm": 0.16716308891773224,
      "learning_rate": 9.829155913042102e-06,
      "loss": 0.2046,
      "step": 1079
    },
    {
      "epoch": 0.017100242253431923,
      "grad_norm": 0.019289104267954826,
      "learning_rate": 9.828997577465683e-06,
      "loss": 0.0062,
      "step": 1080
    },
    {
      "epoch": 0.01711607581107399,
      "grad_norm": 0.22748176753520966,
      "learning_rate": 9.82883924188926e-06,
      "loss": 0.1076,
      "step": 1081
    },
    {
      "epoch": 0.01713190936871606,
      "grad_norm": 0.30207595229148865,
      "learning_rate": 9.828680906312841e-06,
      "loss": 0.1461,
      "step": 1082
    },
    {
      "epoch": 0.017147742926358123,
      "grad_norm": 0.11784487217664719,
      "learning_rate": 9.82852257073642e-06,
      "loss": 0.0102,
      "step": 1083
    },
    {
      "epoch": 0.01716357648400019,
      "grad_norm": 0.0006843197625130415,
      "learning_rate": 9.82836423516e-06,
      "loss": 0.0,
      "step": 1084
    },
    {
      "epoch": 0.017179410041642258,
      "grad_norm": 0.07302732765674591,
      "learning_rate": 9.828205899583578e-06,
      "loss": 0.0094,
      "step": 1085
    },
    {
      "epoch": 0.017195243599284322,
      "grad_norm": 0.2147589921951294,
      "learning_rate": 9.828047564007157e-06,
      "loss": 0.207,
      "step": 1086
    },
    {
      "epoch": 0.01721107715692639,
      "grad_norm": 0.2967601716518402,
      "learning_rate": 9.827889228430736e-06,
      "loss": 0.1095,
      "step": 1087
    },
    {
      "epoch": 0.017226910714568458,
      "grad_norm": 0.0006822427967563272,
      "learning_rate": 9.827730892854316e-06,
      "loss": 0.0,
      "step": 1088
    },
    {
      "epoch": 0.017242744272210522,
      "grad_norm": 0.038767483085393906,
      "learning_rate": 9.827572557277896e-06,
      "loss": 0.0035,
      "step": 1089
    },
    {
      "epoch": 0.01725857782985259,
      "grad_norm": 0.0004438176692929119,
      "learning_rate": 9.827414221701475e-06,
      "loss": 0.0,
      "step": 1090
    },
    {
      "epoch": 0.017274411387494658,
      "grad_norm": 0.12243156880140305,
      "learning_rate": 9.827255886125054e-06,
      "loss": 0.0675,
      "step": 1091
    },
    {
      "epoch": 0.017290244945136722,
      "grad_norm": 0.19578450918197632,
      "learning_rate": 9.827097550548634e-06,
      "loss": 0.7097,
      "step": 1092
    },
    {
      "epoch": 0.01730607850277879,
      "grad_norm": 0.2061467468738556,
      "learning_rate": 9.826939214972213e-06,
      "loss": 0.0739,
      "step": 1093
    },
    {
      "epoch": 0.017321912060420858,
      "grad_norm": 0.007302087731659412,
      "learning_rate": 9.826780879395792e-06,
      "loss": 0.0007,
      "step": 1094
    },
    {
      "epoch": 0.017337745618062922,
      "grad_norm": 0.03044877201318741,
      "learning_rate": 9.826622543819372e-06,
      "loss": 0.0048,
      "step": 1095
    },
    {
      "epoch": 0.01735357917570499,
      "grad_norm": 0.007906761020421982,
      "learning_rate": 9.82646420824295e-06,
      "loss": 0.0006,
      "step": 1096
    },
    {
      "epoch": 0.017369412733347057,
      "grad_norm": 0.17894351482391357,
      "learning_rate": 9.82630587266653e-06,
      "loss": 0.1418,
      "step": 1097
    },
    {
      "epoch": 0.01738524629098912,
      "grad_norm": 0.49967366456985474,
      "learning_rate": 9.82614753709011e-06,
      "loss": 0.2036,
      "step": 1098
    },
    {
      "epoch": 0.01740107984863119,
      "grad_norm": 0.2511719763278961,
      "learning_rate": 9.825989201513689e-06,
      "loss": 0.1157,
      "step": 1099
    },
    {
      "epoch": 0.017416913406273257,
      "grad_norm": 0.011547796428203583,
      "learning_rate": 9.825830865937268e-06,
      "loss": 0.0007,
      "step": 1100
    },
    {
      "epoch": 0.01743274696391532,
      "grad_norm": 0.1666993349790573,
      "learning_rate": 9.825672530360849e-06,
      "loss": 0.1092,
      "step": 1101
    },
    {
      "epoch": 0.01744858052155739,
      "grad_norm": 0.2679998278617859,
      "learning_rate": 9.825514194784426e-06,
      "loss": 0.304,
      "step": 1102
    },
    {
      "epoch": 0.017464414079199457,
      "grad_norm": 0.008850212208926678,
      "learning_rate": 9.825355859208007e-06,
      "loss": 0.0007,
      "step": 1103
    },
    {
      "epoch": 0.01748024763684152,
      "grad_norm": 0.19729821383953094,
      "learning_rate": 9.825197523631586e-06,
      "loss": 0.3859,
      "step": 1104
    },
    {
      "epoch": 0.01749608119448359,
      "grad_norm": 0.41517412662506104,
      "learning_rate": 9.825039188055165e-06,
      "loss": 0.209,
      "step": 1105
    },
    {
      "epoch": 0.017511914752125657,
      "grad_norm": 0.2198951095342636,
      "learning_rate": 9.824880852478744e-06,
      "loss": 0.4647,
      "step": 1106
    },
    {
      "epoch": 0.01752774830976772,
      "grad_norm": 0.3416651785373688,
      "learning_rate": 9.824722516902323e-06,
      "loss": 1.2803,
      "step": 1107
    },
    {
      "epoch": 0.01754358186740979,
      "grad_norm": 0.34624603390693665,
      "learning_rate": 9.824564181325902e-06,
      "loss": 0.1828,
      "step": 1108
    },
    {
      "epoch": 0.017559415425051853,
      "grad_norm": 0.010970779694616795,
      "learning_rate": 9.824405845749481e-06,
      "loss": 0.0009,
      "step": 1109
    },
    {
      "epoch": 0.01757524898269392,
      "grad_norm": 0.0036879531107842922,
      "learning_rate": 9.824247510173062e-06,
      "loss": 0.0003,
      "step": 1110
    },
    {
      "epoch": 0.01759108254033599,
      "grad_norm": 0.10267233848571777,
      "learning_rate": 9.824089174596641e-06,
      "loss": 0.0744,
      "step": 1111
    },
    {
      "epoch": 0.017606916097978053,
      "grad_norm": 0.21742616593837738,
      "learning_rate": 9.82393083902022e-06,
      "loss": 0.2508,
      "step": 1112
    },
    {
      "epoch": 0.01762274965562012,
      "grad_norm": 0.0087844617664814,
      "learning_rate": 9.8237725034438e-06,
      "loss": 0.0006,
      "step": 1113
    },
    {
      "epoch": 0.01763858321326219,
      "grad_norm": 0.004960497375577688,
      "learning_rate": 9.823614167867378e-06,
      "loss": 0.0004,
      "step": 1114
    },
    {
      "epoch": 0.017654416770904253,
      "grad_norm": 0.020268065854907036,
      "learning_rate": 9.823455832290957e-06,
      "loss": 0.0006,
      "step": 1115
    },
    {
      "epoch": 0.01767025032854632,
      "grad_norm": 0.14755843579769135,
      "learning_rate": 9.823297496714538e-06,
      "loss": 0.2718,
      "step": 1116
    },
    {
      "epoch": 0.01768608388618839,
      "grad_norm": 0.11409737914800644,
      "learning_rate": 9.823139161138117e-06,
      "loss": 0.0651,
      "step": 1117
    },
    {
      "epoch": 0.017701917443830453,
      "grad_norm": 0.001979869557544589,
      "learning_rate": 9.822980825561696e-06,
      "loss": 0.0002,
      "step": 1118
    },
    {
      "epoch": 0.01771775100147252,
      "grad_norm": 0.17927370965480804,
      "learning_rate": 9.822822489985275e-06,
      "loss": 0.2619,
      "step": 1119
    },
    {
      "epoch": 0.017733584559114588,
      "grad_norm": 0.12374573945999146,
      "learning_rate": 9.822664154408855e-06,
      "loss": 0.0918,
      "step": 1120
    },
    {
      "epoch": 0.017749418116756652,
      "grad_norm": 0.002446996048092842,
      "learning_rate": 9.822505818832434e-06,
      "loss": 0.0001,
      "step": 1121
    },
    {
      "epoch": 0.01776525167439872,
      "grad_norm": 0.051329355686903,
      "learning_rate": 9.822347483256014e-06,
      "loss": 0.0083,
      "step": 1122
    },
    {
      "epoch": 0.017781085232040788,
      "grad_norm": 0.40007996559143066,
      "learning_rate": 9.822189147679593e-06,
      "loss": 0.1094,
      "step": 1123
    },
    {
      "epoch": 0.017796918789682852,
      "grad_norm": 0.41432034969329834,
      "learning_rate": 9.822030812103173e-06,
      "loss": 0.1091,
      "step": 1124
    },
    {
      "epoch": 0.01781275234732492,
      "grad_norm": 0.16691987216472626,
      "learning_rate": 9.821872476526752e-06,
      "loss": 0.1827,
      "step": 1125
    },
    {
      "epoch": 0.017828585904966988,
      "grad_norm": 0.1664479672908783,
      "learning_rate": 9.82171414095033e-06,
      "loss": 0.0569,
      "step": 1126
    },
    {
      "epoch": 0.017844419462609052,
      "grad_norm": 0.11790922284126282,
      "learning_rate": 9.82155580537391e-06,
      "loss": 0.0621,
      "step": 1127
    },
    {
      "epoch": 0.01786025302025112,
      "grad_norm": 0.14056606590747833,
      "learning_rate": 9.82139746979749e-06,
      "loss": 0.0401,
      "step": 1128
    },
    {
      "epoch": 0.017876086577893188,
      "grad_norm": 0.2266111969947815,
      "learning_rate": 9.82123913422107e-06,
      "loss": 0.0735,
      "step": 1129
    },
    {
      "epoch": 0.017891920135535252,
      "grad_norm": 0.0022326260805130005,
      "learning_rate": 9.821080798644649e-06,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 0.01790775369317732,
      "grad_norm": 0.1445501297712326,
      "learning_rate": 9.820922463068228e-06,
      "loss": 0.2188,
      "step": 1131
    },
    {
      "epoch": 0.017923587250819387,
      "grad_norm": 0.14642807841300964,
      "learning_rate": 9.820764127491807e-06,
      "loss": 0.0676,
      "step": 1132
    },
    {
      "epoch": 0.01793942080846145,
      "grad_norm": 0.15574200451374054,
      "learning_rate": 9.820605791915386e-06,
      "loss": 0.0491,
      "step": 1133
    },
    {
      "epoch": 0.01795525436610352,
      "grad_norm": 0.19233913719654083,
      "learning_rate": 9.820447456338965e-06,
      "loss": 0.024,
      "step": 1134
    },
    {
      "epoch": 0.017971087923745587,
      "grad_norm": 0.13236026465892792,
      "learning_rate": 9.820289120762546e-06,
      "loss": 0.0342,
      "step": 1135
    },
    {
      "epoch": 0.01798692148138765,
      "grad_norm": 0.00016934478480834514,
      "learning_rate": 9.820130785186123e-06,
      "loss": 0.0,
      "step": 1136
    },
    {
      "epoch": 0.01800275503902972,
      "grad_norm": 0.20833222568035126,
      "learning_rate": 9.819972449609704e-06,
      "loss": 0.0012,
      "step": 1137
    },
    {
      "epoch": 0.018018588596671787,
      "grad_norm": 0.25757917761802673,
      "learning_rate": 9.819814114033283e-06,
      "loss": 0.5947,
      "step": 1138
    },
    {
      "epoch": 0.01803442215431385,
      "grad_norm": 0.2846888601779938,
      "learning_rate": 9.819655778456862e-06,
      "loss": 0.2704,
      "step": 1139
    },
    {
      "epoch": 0.01805025571195592,
      "grad_norm": 0.012799190357327461,
      "learning_rate": 9.819497442880441e-06,
      "loss": 0.0013,
      "step": 1140
    },
    {
      "epoch": 0.018066089269597987,
      "grad_norm": 0.008501293137669563,
      "learning_rate": 9.819339107304022e-06,
      "loss": 0.0008,
      "step": 1141
    },
    {
      "epoch": 0.01808192282724005,
      "grad_norm": 0.00477543193846941,
      "learning_rate": 9.8191807717276e-06,
      "loss": 0.0004,
      "step": 1142
    },
    {
      "epoch": 0.01809775638488212,
      "grad_norm": 0.00025475354050286114,
      "learning_rate": 9.81902243615118e-06,
      "loss": 0.0,
      "step": 1143
    },
    {
      "epoch": 0.018113589942524187,
      "grad_norm": 0.12972554564476013,
      "learning_rate": 9.81886410057476e-06,
      "loss": 0.0425,
      "step": 1144
    },
    {
      "epoch": 0.01812942350016625,
      "grad_norm": 0.10355586558580399,
      "learning_rate": 9.818705764998338e-06,
      "loss": 0.0783,
      "step": 1145
    },
    {
      "epoch": 0.01814525705780832,
      "grad_norm": 0.1742583066225052,
      "learning_rate": 9.818547429421917e-06,
      "loss": 0.2715,
      "step": 1146
    },
    {
      "epoch": 0.018161090615450386,
      "grad_norm": 0.11905334889888763,
      "learning_rate": 9.818389093845498e-06,
      "loss": 0.1383,
      "step": 1147
    },
    {
      "epoch": 0.01817692417309245,
      "grad_norm": 0.3691530227661133,
      "learning_rate": 9.818230758269076e-06,
      "loss": 0.1611,
      "step": 1148
    },
    {
      "epoch": 0.01819275773073452,
      "grad_norm": 0.20284023880958557,
      "learning_rate": 9.818072422692656e-06,
      "loss": 0.0794,
      "step": 1149
    },
    {
      "epoch": 0.018208591288376586,
      "grad_norm": 0.08887042850255966,
      "learning_rate": 9.817914087116235e-06,
      "loss": 0.0655,
      "step": 1150
    },
    {
      "epoch": 0.01822442484601865,
      "grad_norm": 0.26120632886886597,
      "learning_rate": 9.817755751539814e-06,
      "loss": 0.3368,
      "step": 1151
    },
    {
      "epoch": 0.018240258403660718,
      "grad_norm": 0.14282920956611633,
      "learning_rate": 9.817597415963394e-06,
      "loss": 0.0791,
      "step": 1152
    },
    {
      "epoch": 0.018256091961302786,
      "grad_norm": 0.011415495537221432,
      "learning_rate": 9.817439080386973e-06,
      "loss": 0.0012,
      "step": 1153
    },
    {
      "epoch": 0.01827192551894485,
      "grad_norm": 0.018891600891947746,
      "learning_rate": 9.817280744810552e-06,
      "loss": 0.0021,
      "step": 1154
    },
    {
      "epoch": 0.018287759076586918,
      "grad_norm": 0.0006573281134478748,
      "learning_rate": 9.81712240923413e-06,
      "loss": 0.0,
      "step": 1155
    },
    {
      "epoch": 0.018303592634228986,
      "grad_norm": 0.14027169346809387,
      "learning_rate": 9.816964073657712e-06,
      "loss": 0.0686,
      "step": 1156
    },
    {
      "epoch": 0.01831942619187105,
      "grad_norm": 4.883650779724121,
      "learning_rate": 9.816805738081289e-06,
      "loss": 0.8695,
      "step": 1157
    },
    {
      "epoch": 0.018335259749513118,
      "grad_norm": 0.2708306908607483,
      "learning_rate": 9.81664740250487e-06,
      "loss": 0.3334,
      "step": 1158
    },
    {
      "epoch": 0.018351093307155186,
      "grad_norm": 0.13862620294094086,
      "learning_rate": 9.816489066928449e-06,
      "loss": 0.2436,
      "step": 1159
    },
    {
      "epoch": 0.01836692686479725,
      "grad_norm": 0.22858689725399017,
      "learning_rate": 9.816330731352028e-06,
      "loss": 0.5372,
      "step": 1160
    },
    {
      "epoch": 0.018382760422439318,
      "grad_norm": 0.4826166331768036,
      "learning_rate": 9.816172395775607e-06,
      "loss": 0.2014,
      "step": 1161
    },
    {
      "epoch": 0.018398593980081385,
      "grad_norm": 0.008807161822915077,
      "learning_rate": 9.816014060199188e-06,
      "loss": 0.0007,
      "step": 1162
    },
    {
      "epoch": 0.01841442753772345,
      "grad_norm": 0.1225212812423706,
      "learning_rate": 9.815855724622765e-06,
      "loss": 0.0771,
      "step": 1163
    },
    {
      "epoch": 0.018430261095365517,
      "grad_norm": 0.00034410806256346405,
      "learning_rate": 9.815697389046346e-06,
      "loss": 0.0,
      "step": 1164
    },
    {
      "epoch": 0.018446094653007585,
      "grad_norm": 0.30127835273742676,
      "learning_rate": 9.815539053469925e-06,
      "loss": 0.1203,
      "step": 1165
    },
    {
      "epoch": 0.01846192821064965,
      "grad_norm": 0.14817030727863312,
      "learning_rate": 9.815380717893504e-06,
      "loss": 0.0887,
      "step": 1166
    },
    {
      "epoch": 0.018477761768291717,
      "grad_norm": 0.28493329882621765,
      "learning_rate": 9.815222382317083e-06,
      "loss": 1.7386,
      "step": 1167
    },
    {
      "epoch": 0.018493595325933785,
      "grad_norm": 0.0174053143709898,
      "learning_rate": 9.815064046740664e-06,
      "loss": 0.0018,
      "step": 1168
    },
    {
      "epoch": 0.01850942888357585,
      "grad_norm": 0.42152997851371765,
      "learning_rate": 9.814905711164241e-06,
      "loss": 0.0734,
      "step": 1169
    },
    {
      "epoch": 0.018525262441217917,
      "grad_norm": 0.11931940913200378,
      "learning_rate": 9.814747375587822e-06,
      "loss": 0.1126,
      "step": 1170
    },
    {
      "epoch": 0.018541095998859985,
      "grad_norm": 0.006718419957906008,
      "learning_rate": 9.814589040011401e-06,
      "loss": 0.0006,
      "step": 1171
    },
    {
      "epoch": 0.01855692955650205,
      "grad_norm": 0.20719584822654724,
      "learning_rate": 9.81443070443498e-06,
      "loss": 0.4375,
      "step": 1172
    },
    {
      "epoch": 0.018572763114144117,
      "grad_norm": 0.4075062572956085,
      "learning_rate": 9.81427236885856e-06,
      "loss": 0.1734,
      "step": 1173
    },
    {
      "epoch": 0.018588596671786185,
      "grad_norm": 0.6870152950286865,
      "learning_rate": 9.81411403328214e-06,
      "loss": 0.0656,
      "step": 1174
    },
    {
      "epoch": 0.01860443022942825,
      "grad_norm": 0.46712350845336914,
      "learning_rate": 9.813955697705717e-06,
      "loss": 0.1704,
      "step": 1175
    },
    {
      "epoch": 0.018620263787070317,
      "grad_norm": 0.1976577490568161,
      "learning_rate": 9.813797362129298e-06,
      "loss": 0.0116,
      "step": 1176
    },
    {
      "epoch": 0.018636097344712384,
      "grad_norm": 0.2755480408668518,
      "learning_rate": 9.813639026552877e-06,
      "loss": 0.2069,
      "step": 1177
    },
    {
      "epoch": 0.01865193090235445,
      "grad_norm": 0.00039275275776162744,
      "learning_rate": 9.813480690976456e-06,
      "loss": 0.0,
      "step": 1178
    },
    {
      "epoch": 0.018667764459996516,
      "grad_norm": 0.01091793179512024,
      "learning_rate": 9.813322355400035e-06,
      "loss": 0.0011,
      "step": 1179
    },
    {
      "epoch": 0.018683598017638584,
      "grad_norm": 0.16268761456012726,
      "learning_rate": 9.813164019823615e-06,
      "loss": 0.0076,
      "step": 1180
    },
    {
      "epoch": 0.01869943157528065,
      "grad_norm": 0.2374630570411682,
      "learning_rate": 9.813005684247194e-06,
      "loss": 0.2836,
      "step": 1181
    },
    {
      "epoch": 0.018715265132922716,
      "grad_norm": 0.1890849471092224,
      "learning_rate": 9.812847348670773e-06,
      "loss": 0.4253,
      "step": 1182
    },
    {
      "epoch": 0.018731098690564784,
      "grad_norm": 0.13948535919189453,
      "learning_rate": 9.812689013094353e-06,
      "loss": 0.1057,
      "step": 1183
    },
    {
      "epoch": 0.01874693224820685,
      "grad_norm": 0.1382155418395996,
      "learning_rate": 9.812530677517933e-06,
      "loss": 0.5322,
      "step": 1184
    },
    {
      "epoch": 0.018762765805848916,
      "grad_norm": 0.5412607192993164,
      "learning_rate": 9.812372341941512e-06,
      "loss": 0.1055,
      "step": 1185
    },
    {
      "epoch": 0.018778599363490984,
      "grad_norm": 0.0785910114645958,
      "learning_rate": 9.81221400636509e-06,
      "loss": 0.0048,
      "step": 1186
    },
    {
      "epoch": 0.018794432921133048,
      "grad_norm": 0.019679289311170578,
      "learning_rate": 9.81205567078867e-06,
      "loss": 0.002,
      "step": 1187
    },
    {
      "epoch": 0.018810266478775116,
      "grad_norm": 0.7274472713470459,
      "learning_rate": 9.811897335212249e-06,
      "loss": 0.2425,
      "step": 1188
    },
    {
      "epoch": 0.018826100036417184,
      "grad_norm": 0.31653913855552673,
      "learning_rate": 9.81173899963583e-06,
      "loss": 0.2166,
      "step": 1189
    },
    {
      "epoch": 0.018841933594059248,
      "grad_norm": 0.35364386439323425,
      "learning_rate": 9.811580664059409e-06,
      "loss": 0.294,
      "step": 1190
    },
    {
      "epoch": 0.018857767151701316,
      "grad_norm": 0.00030256601166911423,
      "learning_rate": 9.811422328482988e-06,
      "loss": 0.0,
      "step": 1191
    },
    {
      "epoch": 0.018873600709343383,
      "grad_norm": 0.23267942667007446,
      "learning_rate": 9.811263992906567e-06,
      "loss": 0.6347,
      "step": 1192
    },
    {
      "epoch": 0.018889434266985448,
      "grad_norm": 0.2893056869506836,
      "learning_rate": 9.811105657330146e-06,
      "loss": 0.3846,
      "step": 1193
    },
    {
      "epoch": 0.018905267824627515,
      "grad_norm": 0.5385487079620361,
      "learning_rate": 9.810947321753725e-06,
      "loss": 0.2103,
      "step": 1194
    },
    {
      "epoch": 0.018921101382269583,
      "grad_norm": 0.180441752076149,
      "learning_rate": 9.810788986177306e-06,
      "loss": 0.0167,
      "step": 1195
    },
    {
      "epoch": 0.018936934939911648,
      "grad_norm": 0.21099697053432465,
      "learning_rate": 9.810630650600885e-06,
      "loss": 0.1825,
      "step": 1196
    },
    {
      "epoch": 0.018952768497553715,
      "grad_norm": 0.1186661422252655,
      "learning_rate": 9.810472315024464e-06,
      "loss": 0.1214,
      "step": 1197
    },
    {
      "epoch": 0.018968602055195783,
      "grad_norm": 0.1303475797176361,
      "learning_rate": 9.810313979448043e-06,
      "loss": 0.1102,
      "step": 1198
    },
    {
      "epoch": 0.018984435612837847,
      "grad_norm": 0.3105955421924591,
      "learning_rate": 9.810155643871622e-06,
      "loss": 0.6496,
      "step": 1199
    },
    {
      "epoch": 0.019000269170479915,
      "grad_norm": 0.46303653717041016,
      "learning_rate": 9.809997308295201e-06,
      "loss": 0.1472,
      "step": 1200
    },
    {
      "epoch": 0.019016102728121983,
      "grad_norm": 0.2809060215950012,
      "learning_rate": 9.809838972718782e-06,
      "loss": 0.0816,
      "step": 1201
    },
    {
      "epoch": 0.019031936285764047,
      "grad_norm": 0.20791301131248474,
      "learning_rate": 9.809680637142361e-06,
      "loss": 0.5082,
      "step": 1202
    },
    {
      "epoch": 0.019047769843406115,
      "grad_norm": 0.2321985363960266,
      "learning_rate": 9.809522301565938e-06,
      "loss": 0.331,
      "step": 1203
    },
    {
      "epoch": 0.019063603401048183,
      "grad_norm": 0.27797555923461914,
      "learning_rate": 9.80936396598952e-06,
      "loss": 0.7931,
      "step": 1204
    },
    {
      "epoch": 0.019079436958690247,
      "grad_norm": 0.01039035338908434,
      "learning_rate": 9.809205630413098e-06,
      "loss": 0.0008,
      "step": 1205
    },
    {
      "epoch": 0.019095270516332315,
      "grad_norm": 0.15166214108467102,
      "learning_rate": 9.809047294836677e-06,
      "loss": 0.2708,
      "step": 1206
    },
    {
      "epoch": 0.019111104073974382,
      "grad_norm": 0.22056211531162262,
      "learning_rate": 9.808888959260256e-06,
      "loss": 0.3723,
      "step": 1207
    },
    {
      "epoch": 0.019126937631616447,
      "grad_norm": 0.3389981687068939,
      "learning_rate": 9.808730623683837e-06,
      "loss": 0.3342,
      "step": 1208
    },
    {
      "epoch": 0.019142771189258515,
      "grad_norm": 0.34306150674819946,
      "learning_rate": 9.808572288107415e-06,
      "loss": 0.1955,
      "step": 1209
    },
    {
      "epoch": 0.019158604746900582,
      "grad_norm": 3.6088149547576904,
      "learning_rate": 9.808413952530995e-06,
      "loss": 0.7323,
      "step": 1210
    },
    {
      "epoch": 0.019174438304542647,
      "grad_norm": 0.24774356186389923,
      "learning_rate": 9.808255616954574e-06,
      "loss": 0.9383,
      "step": 1211
    },
    {
      "epoch": 0.019190271862184714,
      "grad_norm": 0.29119494557380676,
      "learning_rate": 9.808097281378154e-06,
      "loss": 0.3774,
      "step": 1212
    },
    {
      "epoch": 0.019206105419826782,
      "grad_norm": 0.19935406744480133,
      "learning_rate": 9.807938945801733e-06,
      "loss": 0.1499,
      "step": 1213
    },
    {
      "epoch": 0.019221938977468846,
      "grad_norm": 0.08627239614725113,
      "learning_rate": 9.807780610225313e-06,
      "loss": 0.0045,
      "step": 1214
    },
    {
      "epoch": 0.019237772535110914,
      "grad_norm": 0.10991550981998444,
      "learning_rate": 9.80762227464889e-06,
      "loss": 0.0503,
      "step": 1215
    },
    {
      "epoch": 0.019253606092752982,
      "grad_norm": 0.08603787422180176,
      "learning_rate": 9.807463939072472e-06,
      "loss": 0.0503,
      "step": 1216
    },
    {
      "epoch": 0.019269439650395046,
      "grad_norm": 0.32624515891075134,
      "learning_rate": 9.80730560349605e-06,
      "loss": 0.3785,
      "step": 1217
    },
    {
      "epoch": 0.019285273208037114,
      "grad_norm": 0.005796859506517649,
      "learning_rate": 9.80714726791963e-06,
      "loss": 0.0005,
      "step": 1218
    },
    {
      "epoch": 0.01930110676567918,
      "grad_norm": 0.28420913219451904,
      "learning_rate": 9.806988932343209e-06,
      "loss": 0.0617,
      "step": 1219
    },
    {
      "epoch": 0.019316940323321246,
      "grad_norm": 0.0025379417929798365,
      "learning_rate": 9.806830596766788e-06,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 0.019332773880963314,
      "grad_norm": 0.1900254487991333,
      "learning_rate": 9.806672261190367e-06,
      "loss": 0.427,
      "step": 1221
    },
    {
      "epoch": 0.01934860743860538,
      "grad_norm": 0.20734941959381104,
      "learning_rate": 9.806513925613948e-06,
      "loss": 0.1545,
      "step": 1222
    },
    {
      "epoch": 0.019364440996247446,
      "grad_norm": 0.24112391471862793,
      "learning_rate": 9.806355590037527e-06,
      "loss": 0.2938,
      "step": 1223
    },
    {
      "epoch": 0.019380274553889514,
      "grad_norm": 0.3080074191093445,
      "learning_rate": 9.806197254461106e-06,
      "loss": 0.3292,
      "step": 1224
    },
    {
      "epoch": 0.01939610811153158,
      "grad_norm": 0.014475211501121521,
      "learning_rate": 9.806038918884685e-06,
      "loss": 0.0002,
      "step": 1225
    },
    {
      "epoch": 0.019411941669173646,
      "grad_norm": 0.006963518913835287,
      "learning_rate": 9.805880583308264e-06,
      "loss": 0.0006,
      "step": 1226
    },
    {
      "epoch": 0.019427775226815713,
      "grad_norm": 0.13752472400665283,
      "learning_rate": 9.805722247731843e-06,
      "loss": 0.4556,
      "step": 1227
    },
    {
      "epoch": 0.01944360878445778,
      "grad_norm": 0.008423535153269768,
      "learning_rate": 9.805563912155422e-06,
      "loss": 0.0007,
      "step": 1228
    },
    {
      "epoch": 0.019459442342099845,
      "grad_norm": 0.13140058517456055,
      "learning_rate": 9.805405576579003e-06,
      "loss": 0.0759,
      "step": 1229
    },
    {
      "epoch": 0.019475275899741913,
      "grad_norm": 0.1780419498682022,
      "learning_rate": 9.80524724100258e-06,
      "loss": 0.3025,
      "step": 1230
    },
    {
      "epoch": 0.01949110945738398,
      "grad_norm": 0.004319692961871624,
      "learning_rate": 9.805088905426161e-06,
      "loss": 0.0001,
      "step": 1231
    },
    {
      "epoch": 0.019506943015026045,
      "grad_norm": 0.03994155675172806,
      "learning_rate": 9.80493056984974e-06,
      "loss": 0.0006,
      "step": 1232
    },
    {
      "epoch": 0.019522776572668113,
      "grad_norm": 0.509560763835907,
      "learning_rate": 9.80477223427332e-06,
      "loss": 0.0746,
      "step": 1233
    },
    {
      "epoch": 0.01953861013031018,
      "grad_norm": 0.0022438927553594112,
      "learning_rate": 9.804613898696898e-06,
      "loss": 0.0001,
      "step": 1234
    },
    {
      "epoch": 0.019554443687952245,
      "grad_norm": 0.3877907395362854,
      "learning_rate": 9.80445556312048e-06,
      "loss": 0.229,
      "step": 1235
    },
    {
      "epoch": 0.019570277245594313,
      "grad_norm": 0.14604470133781433,
      "learning_rate": 9.804297227544057e-06,
      "loss": 0.4836,
      "step": 1236
    },
    {
      "epoch": 0.01958611080323638,
      "grad_norm": 0.1399136334657669,
      "learning_rate": 9.804138891967637e-06,
      "loss": 0.2144,
      "step": 1237
    },
    {
      "epoch": 0.019601944360878445,
      "grad_norm": 0.004725488368421793,
      "learning_rate": 9.803980556391216e-06,
      "loss": 0.0003,
      "step": 1238
    },
    {
      "epoch": 0.019617777918520513,
      "grad_norm": 0.02028781548142433,
      "learning_rate": 9.803822220814795e-06,
      "loss": 0.0024,
      "step": 1239
    },
    {
      "epoch": 0.01963361147616258,
      "grad_norm": 0.15354029834270477,
      "learning_rate": 9.803663885238375e-06,
      "loss": 0.0915,
      "step": 1240
    },
    {
      "epoch": 0.019649445033804645,
      "grad_norm": 0.29055875539779663,
      "learning_rate": 9.803505549661955e-06,
      "loss": 0.4102,
      "step": 1241
    },
    {
      "epoch": 0.019665278591446712,
      "grad_norm": 0.19148045778274536,
      "learning_rate": 9.803347214085533e-06,
      "loss": 0.0594,
      "step": 1242
    },
    {
      "epoch": 0.01968111214908878,
      "grad_norm": 0.2463051825761795,
      "learning_rate": 9.803188878509113e-06,
      "loss": 0.2253,
      "step": 1243
    },
    {
      "epoch": 0.019696945706730844,
      "grad_norm": 0.1389198750257492,
      "learning_rate": 9.803030542932693e-06,
      "loss": 0.027,
      "step": 1244
    },
    {
      "epoch": 0.019712779264372912,
      "grad_norm": 0.1517263650894165,
      "learning_rate": 9.802872207356272e-06,
      "loss": 0.5172,
      "step": 1245
    },
    {
      "epoch": 0.01972861282201498,
      "grad_norm": 0.12843680381774902,
      "learning_rate": 9.80271387177985e-06,
      "loss": 0.271,
      "step": 1246
    },
    {
      "epoch": 0.019744446379657044,
      "grad_norm": 0.00262918951921165,
      "learning_rate": 9.802555536203432e-06,
      "loss": 0.0001,
      "step": 1247
    },
    {
      "epoch": 0.019760279937299112,
      "grad_norm": 0.07648025453090668,
      "learning_rate": 9.802397200627009e-06,
      "loss": 0.0344,
      "step": 1248
    },
    {
      "epoch": 0.01977611349494118,
      "grad_norm": 0.3042580783367157,
      "learning_rate": 9.80223886505059e-06,
      "loss": 0.1994,
      "step": 1249
    },
    {
      "epoch": 0.019791947052583244,
      "grad_norm": 0.3017566204071045,
      "learning_rate": 9.802080529474169e-06,
      "loss": 0.2549,
      "step": 1250
    },
    {
      "epoch": 0.019807780610225312,
      "grad_norm": 0.36510488390922546,
      "learning_rate": 9.801922193897748e-06,
      "loss": 0.0995,
      "step": 1251
    },
    {
      "epoch": 0.01982361416786738,
      "grad_norm": 0.2078775018453598,
      "learning_rate": 9.801763858321327e-06,
      "loss": 0.0511,
      "step": 1252
    },
    {
      "epoch": 0.019839447725509444,
      "grad_norm": 0.27893733978271484,
      "learning_rate": 9.801605522744906e-06,
      "loss": 0.2275,
      "step": 1253
    },
    {
      "epoch": 0.01985528128315151,
      "grad_norm": 0.3166007995605469,
      "learning_rate": 9.801447187168485e-06,
      "loss": 0.1189,
      "step": 1254
    },
    {
      "epoch": 0.01987111484079358,
      "grad_norm": 0.13555532693862915,
      "learning_rate": 9.801288851592064e-06,
      "loss": 0.0489,
      "step": 1255
    },
    {
      "epoch": 0.019886948398435644,
      "grad_norm": 0.08517822623252869,
      "learning_rate": 9.801130516015645e-06,
      "loss": 0.0211,
      "step": 1256
    },
    {
      "epoch": 0.01990278195607771,
      "grad_norm": 0.22982032597064972,
      "learning_rate": 9.800972180439224e-06,
      "loss": 0.3887,
      "step": 1257
    },
    {
      "epoch": 0.01991861551371978,
      "grad_norm": 0.08775466680526733,
      "learning_rate": 9.800813844862803e-06,
      "loss": 0.0093,
      "step": 1258
    },
    {
      "epoch": 0.019934449071361843,
      "grad_norm": 0.17641647160053253,
      "learning_rate": 9.800655509286382e-06,
      "loss": 0.1463,
      "step": 1259
    },
    {
      "epoch": 0.01995028262900391,
      "grad_norm": 0.2480398416519165,
      "learning_rate": 9.800497173709961e-06,
      "loss": 0.1361,
      "step": 1260
    },
    {
      "epoch": 0.01996611618664598,
      "grad_norm": 0.2781534492969513,
      "learning_rate": 9.80033883813354e-06,
      "loss": 0.2301,
      "step": 1261
    },
    {
      "epoch": 0.019981949744288043,
      "grad_norm": 0.27662062644958496,
      "learning_rate": 9.800180502557121e-06,
      "loss": 0.1206,
      "step": 1262
    },
    {
      "epoch": 0.01999778330193011,
      "grad_norm": 0.26252758502960205,
      "learning_rate": 9.8000221669807e-06,
      "loss": 0.14,
      "step": 1263
    },
    {
      "epoch": 0.02001361685957218,
      "grad_norm": 0.11522158980369568,
      "learning_rate": 9.79986383140428e-06,
      "loss": 0.2996,
      "step": 1264
    },
    {
      "epoch": 0.020029450417214243,
      "grad_norm": 0.015147381462156773,
      "learning_rate": 9.799705495827858e-06,
      "loss": 0.0012,
      "step": 1265
    },
    {
      "epoch": 0.02004528397485631,
      "grad_norm": 0.1819886565208435,
      "learning_rate": 9.799547160251437e-06,
      "loss": 0.5057,
      "step": 1266
    },
    {
      "epoch": 0.02006111753249838,
      "grad_norm": 0.21898452937602997,
      "learning_rate": 9.799388824675016e-06,
      "loss": 0.5568,
      "step": 1267
    },
    {
      "epoch": 0.020076951090140443,
      "grad_norm": 0.10588287562131882,
      "learning_rate": 9.799230489098597e-06,
      "loss": 0.0083,
      "step": 1268
    },
    {
      "epoch": 0.02009278464778251,
      "grad_norm": 0.6144198775291443,
      "learning_rate": 9.799072153522176e-06,
      "loss": 0.3215,
      "step": 1269
    },
    {
      "epoch": 0.02010861820542458,
      "grad_norm": 0.28605538606643677,
      "learning_rate": 9.798913817945755e-06,
      "loss": 0.3801,
      "step": 1270
    },
    {
      "epoch": 0.020124451763066643,
      "grad_norm": 0.18258318305015564,
      "learning_rate": 9.798755482369335e-06,
      "loss": 0.1776,
      "step": 1271
    },
    {
      "epoch": 0.02014028532070871,
      "grad_norm": 0.2504761219024658,
      "learning_rate": 9.798597146792914e-06,
      "loss": 0.1429,
      "step": 1272
    },
    {
      "epoch": 0.020156118878350778,
      "grad_norm": 0.023819006979465485,
      "learning_rate": 9.798438811216493e-06,
      "loss": 0.0017,
      "step": 1273
    },
    {
      "epoch": 0.020171952435992842,
      "grad_norm": 0.010769879445433617,
      "learning_rate": 9.798280475640073e-06,
      "loss": 0.0004,
      "step": 1274
    },
    {
      "epoch": 0.02018778599363491,
      "grad_norm": 0.1339343786239624,
      "learning_rate": 9.798122140063653e-06,
      "loss": 0.003,
      "step": 1275
    },
    {
      "epoch": 0.020203619551276978,
      "grad_norm": 0.18296273052692413,
      "learning_rate": 9.79796380448723e-06,
      "loss": 0.1327,
      "step": 1276
    },
    {
      "epoch": 0.020219453108919042,
      "grad_norm": 0.00828382559120655,
      "learning_rate": 9.79780546891081e-06,
      "loss": 0.0005,
      "step": 1277
    },
    {
      "epoch": 0.02023528666656111,
      "grad_norm": 0.35741233825683594,
      "learning_rate": 9.79764713333439e-06,
      "loss": 0.1018,
      "step": 1278
    },
    {
      "epoch": 0.020251120224203178,
      "grad_norm": 0.002954653697088361,
      "learning_rate": 9.797488797757969e-06,
      "loss": 0.0001,
      "step": 1279
    },
    {
      "epoch": 0.020266953781845242,
      "grad_norm": 0.30867648124694824,
      "learning_rate": 9.797330462181548e-06,
      "loss": 0.1195,
      "step": 1280
    },
    {
      "epoch": 0.02028278733948731,
      "grad_norm": 0.17308633029460907,
      "learning_rate": 9.797172126605129e-06,
      "loss": 0.0933,
      "step": 1281
    },
    {
      "epoch": 0.020298620897129378,
      "grad_norm": 0.27358192205429077,
      "learning_rate": 9.797013791028706e-06,
      "loss": 0.0843,
      "step": 1282
    },
    {
      "epoch": 0.020314454454771442,
      "grad_norm": 0.40835726261138916,
      "learning_rate": 9.796855455452287e-06,
      "loss": 0.0308,
      "step": 1283
    },
    {
      "epoch": 0.02033028801241351,
      "grad_norm": 0.32077568769454956,
      "learning_rate": 9.796697119875866e-06,
      "loss": 0.4761,
      "step": 1284
    },
    {
      "epoch": 0.020346121570055577,
      "grad_norm": 0.33897465467453003,
      "learning_rate": 9.796538784299445e-06,
      "loss": 0.0377,
      "step": 1285
    },
    {
      "epoch": 0.02036195512769764,
      "grad_norm": 0.17299354076385498,
      "learning_rate": 9.796380448723024e-06,
      "loss": 0.2519,
      "step": 1286
    },
    {
      "epoch": 0.02037778868533971,
      "grad_norm": 0.3031158149242401,
      "learning_rate": 9.796222113146603e-06,
      "loss": 0.3792,
      "step": 1287
    },
    {
      "epoch": 0.020393622242981777,
      "grad_norm": 0.24066036939620972,
      "learning_rate": 9.796063777570182e-06,
      "loss": 0.1748,
      "step": 1288
    },
    {
      "epoch": 0.02040945580062384,
      "grad_norm": 0.1874336451292038,
      "learning_rate": 9.795905441993763e-06,
      "loss": 0.2026,
      "step": 1289
    },
    {
      "epoch": 0.02042528935826591,
      "grad_norm": 0.014294960536062717,
      "learning_rate": 9.795747106417342e-06,
      "loss": 0.001,
      "step": 1290
    },
    {
      "epoch": 0.020441122915907977,
      "grad_norm": 0.2692914605140686,
      "learning_rate": 9.795588770840921e-06,
      "loss": 0.1138,
      "step": 1291
    },
    {
      "epoch": 0.02045695647355004,
      "grad_norm": 0.3228006660938263,
      "learning_rate": 9.7954304352645e-06,
      "loss": 0.2562,
      "step": 1292
    },
    {
      "epoch": 0.02047279003119211,
      "grad_norm": 0.008657047525048256,
      "learning_rate": 9.79527209968808e-06,
      "loss": 0.0008,
      "step": 1293
    },
    {
      "epoch": 0.020488623588834177,
      "grad_norm": 0.25960296392440796,
      "learning_rate": 9.795113764111658e-06,
      "loss": 0.0142,
      "step": 1294
    },
    {
      "epoch": 0.02050445714647624,
      "grad_norm": 0.0010479813208803535,
      "learning_rate": 9.79495542853524e-06,
      "loss": 0.0,
      "step": 1295
    },
    {
      "epoch": 0.02052029070411831,
      "grad_norm": 0.1677124798297882,
      "learning_rate": 9.794797092958818e-06,
      "loss": 0.0643,
      "step": 1296
    },
    {
      "epoch": 0.020536124261760377,
      "grad_norm": 0.007007558364421129,
      "learning_rate": 9.794638757382397e-06,
      "loss": 0.0004,
      "step": 1297
    },
    {
      "epoch": 0.02055195781940244,
      "grad_norm": 0.0232051070779562,
      "learning_rate": 9.794480421805976e-06,
      "loss": 0.004,
      "step": 1298
    },
    {
      "epoch": 0.02056779137704451,
      "grad_norm": 0.04555541276931763,
      "learning_rate": 9.794322086229556e-06,
      "loss": 0.0022,
      "step": 1299
    },
    {
      "epoch": 0.020583624934686576,
      "grad_norm": 0.29738160967826843,
      "learning_rate": 9.794163750653135e-06,
      "loss": 1.2485,
      "step": 1300
    },
    {
      "epoch": 0.02059945849232864,
      "grad_norm": 0.32330116629600525,
      "learning_rate": 9.794005415076714e-06,
      "loss": 0.1182,
      "step": 1301
    },
    {
      "epoch": 0.02061529204997071,
      "grad_norm": 0.3500559329986572,
      "learning_rate": 9.793847079500294e-06,
      "loss": 0.5294,
      "step": 1302
    },
    {
      "epoch": 0.020631125607612776,
      "grad_norm": 0.0014797128969803452,
      "learning_rate": 9.793688743923872e-06,
      "loss": 0.0,
      "step": 1303
    },
    {
      "epoch": 0.02064695916525484,
      "grad_norm": 0.6506023406982422,
      "learning_rate": 9.793530408347453e-06,
      "loss": 0.1427,
      "step": 1304
    },
    {
      "epoch": 0.02066279272289691,
      "grad_norm": 0.2579982578754425,
      "learning_rate": 9.793372072771032e-06,
      "loss": 0.2718,
      "step": 1305
    },
    {
      "epoch": 0.020678626280538976,
      "grad_norm": 0.43280690908432007,
      "learning_rate": 9.79321373719461e-06,
      "loss": 0.3445,
      "step": 1306
    },
    {
      "epoch": 0.02069445983818104,
      "grad_norm": 0.23143848776817322,
      "learning_rate": 9.79305540161819e-06,
      "loss": 0.1205,
      "step": 1307
    },
    {
      "epoch": 0.020710293395823108,
      "grad_norm": 0.5357481241226196,
      "learning_rate": 9.79289706604177e-06,
      "loss": 0.0266,
      "step": 1308
    },
    {
      "epoch": 0.020726126953465172,
      "grad_norm": 0.20544488728046417,
      "learning_rate": 9.792738730465348e-06,
      "loss": 0.2151,
      "step": 1309
    },
    {
      "epoch": 0.02074196051110724,
      "grad_norm": 0.6261719465255737,
      "learning_rate": 9.792580394888929e-06,
      "loss": 0.2305,
      "step": 1310
    },
    {
      "epoch": 0.020757794068749308,
      "grad_norm": 0.08669248968362808,
      "learning_rate": 9.792422059312508e-06,
      "loss": 0.0424,
      "step": 1311
    },
    {
      "epoch": 0.020773627626391372,
      "grad_norm": 0.018658041954040527,
      "learning_rate": 9.792263723736087e-06,
      "loss": 0.0008,
      "step": 1312
    },
    {
      "epoch": 0.02078946118403344,
      "grad_norm": 0.11490418761968613,
      "learning_rate": 9.792105388159666e-06,
      "loss": 0.1414,
      "step": 1313
    },
    {
      "epoch": 0.020805294741675508,
      "grad_norm": 2.2477691173553467,
      "learning_rate": 9.791947052583247e-06,
      "loss": 0.3409,
      "step": 1314
    },
    {
      "epoch": 0.020821128299317572,
      "grad_norm": 0.41241776943206787,
      "learning_rate": 9.791788717006824e-06,
      "loss": 0.048,
      "step": 1315
    },
    {
      "epoch": 0.02083696185695964,
      "grad_norm": 0.35067638754844666,
      "learning_rate": 9.791630381430405e-06,
      "loss": 0.3135,
      "step": 1316
    },
    {
      "epoch": 0.020852795414601707,
      "grad_norm": 0.37361007928848267,
      "learning_rate": 9.791472045853984e-06,
      "loss": 1.32,
      "step": 1317
    },
    {
      "epoch": 0.020868628972243772,
      "grad_norm": 0.18163131177425385,
      "learning_rate": 9.791313710277563e-06,
      "loss": 0.121,
      "step": 1318
    },
    {
      "epoch": 0.02088446252988584,
      "grad_norm": 0.18758980929851532,
      "learning_rate": 9.791155374701142e-06,
      "loss": 0.1274,
      "step": 1319
    },
    {
      "epoch": 0.020900296087527907,
      "grad_norm": 0.19551002979278564,
      "learning_rate": 9.790997039124723e-06,
      "loss": 0.5562,
      "step": 1320
    },
    {
      "epoch": 0.02091612964516997,
      "grad_norm": 0.2286403477191925,
      "learning_rate": 9.7908387035483e-06,
      "loss": 0.1758,
      "step": 1321
    },
    {
      "epoch": 0.02093196320281204,
      "grad_norm": 0.1703656166791916,
      "learning_rate": 9.790680367971881e-06,
      "loss": 0.0673,
      "step": 1322
    },
    {
      "epoch": 0.020947796760454107,
      "grad_norm": 0.15686924755573273,
      "learning_rate": 9.79052203239546e-06,
      "loss": 0.2393,
      "step": 1323
    },
    {
      "epoch": 0.02096363031809617,
      "grad_norm": 0.08055649697780609,
      "learning_rate": 9.79036369681904e-06,
      "loss": 0.0857,
      "step": 1324
    },
    {
      "epoch": 0.02097946387573824,
      "grad_norm": 0.4200853705406189,
      "learning_rate": 9.790205361242618e-06,
      "loss": 0.1126,
      "step": 1325
    },
    {
      "epoch": 0.020995297433380307,
      "grad_norm": 0.007743312045931816,
      "learning_rate": 9.790047025666197e-06,
      "loss": 0.0006,
      "step": 1326
    },
    {
      "epoch": 0.02101113099102237,
      "grad_norm": 0.4638499617576599,
      "learning_rate": 9.789888690089777e-06,
      "loss": 0.0719,
      "step": 1327
    },
    {
      "epoch": 0.02102696454866444,
      "grad_norm": 0.43021321296691895,
      "learning_rate": 9.789730354513356e-06,
      "loss": 0.1797,
      "step": 1328
    },
    {
      "epoch": 0.021042798106306507,
      "grad_norm": 0.07641587406396866,
      "learning_rate": 9.789572018936936e-06,
      "loss": 0.0014,
      "step": 1329
    },
    {
      "epoch": 0.02105863166394857,
      "grad_norm": 0.023343142122030258,
      "learning_rate": 9.789413683360515e-06,
      "loss": 0.0031,
      "step": 1330
    },
    {
      "epoch": 0.02107446522159064,
      "grad_norm": 0.2697482109069824,
      "learning_rate": 9.789255347784095e-06,
      "loss": 0.2875,
      "step": 1331
    },
    {
      "epoch": 0.021090298779232707,
      "grad_norm": 0.007786606438457966,
      "learning_rate": 9.789097012207674e-06,
      "loss": 0.0008,
      "step": 1332
    },
    {
      "epoch": 0.02110613233687477,
      "grad_norm": 0.0921768769621849,
      "learning_rate": 9.788938676631253e-06,
      "loss": 0.0532,
      "step": 1333
    },
    {
      "epoch": 0.02112196589451684,
      "grad_norm": 0.0003681585658341646,
      "learning_rate": 9.788780341054832e-06,
      "loss": 0.0,
      "step": 1334
    },
    {
      "epoch": 0.021137799452158906,
      "grad_norm": 0.23567789793014526,
      "learning_rate": 9.788622005478413e-06,
      "loss": 0.035,
      "step": 1335
    },
    {
      "epoch": 0.02115363300980097,
      "grad_norm": 0.4721473455429077,
      "learning_rate": 9.788463669901992e-06,
      "loss": 0.1529,
      "step": 1336
    },
    {
      "epoch": 0.02116946656744304,
      "grad_norm": 0.2420348823070526,
      "learning_rate": 9.78830533432557e-06,
      "loss": 0.0979,
      "step": 1337
    },
    {
      "epoch": 0.021185300125085106,
      "grad_norm": 0.014460079371929169,
      "learning_rate": 9.78814699874915e-06,
      "loss": 0.0011,
      "step": 1338
    },
    {
      "epoch": 0.02120113368272717,
      "grad_norm": 0.34473416209220886,
      "learning_rate": 9.787988663172729e-06,
      "loss": 0.2692,
      "step": 1339
    },
    {
      "epoch": 0.021216967240369238,
      "grad_norm": 0.0006285851704888046,
      "learning_rate": 9.787830327596308e-06,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 0.021232800798011306,
      "grad_norm": 0.13506393134593964,
      "learning_rate": 9.787671992019889e-06,
      "loss": 0.0825,
      "step": 1341
    },
    {
      "epoch": 0.02124863435565337,
      "grad_norm": 0.2591502070426941,
      "learning_rate": 9.787513656443468e-06,
      "loss": 0.2223,
      "step": 1342
    },
    {
      "epoch": 0.021264467913295438,
      "grad_norm": 0.0017965288134291768,
      "learning_rate": 9.787355320867047e-06,
      "loss": 0.0,
      "step": 1343
    },
    {
      "epoch": 0.021280301470937506,
      "grad_norm": 0.006093097850680351,
      "learning_rate": 9.787196985290626e-06,
      "loss": 0.0006,
      "step": 1344
    },
    {
      "epoch": 0.02129613502857957,
      "grad_norm": 0.022089309990406036,
      "learning_rate": 9.787038649714205e-06,
      "loss": 0.0022,
      "step": 1345
    },
    {
      "epoch": 0.021311968586221638,
      "grad_norm": 0.9780541658401489,
      "learning_rate": 9.786880314137784e-06,
      "loss": 0.2027,
      "step": 1346
    },
    {
      "epoch": 0.021327802143863706,
      "grad_norm": 0.0004989092121832073,
      "learning_rate": 9.786721978561365e-06,
      "loss": 0.0,
      "step": 1347
    },
    {
      "epoch": 0.02134363570150577,
      "grad_norm": 0.012799997813999653,
      "learning_rate": 9.786563642984942e-06,
      "loss": 0.0012,
      "step": 1348
    },
    {
      "epoch": 0.021359469259147838,
      "grad_norm": 0.19506050646305084,
      "learning_rate": 9.786405307408521e-06,
      "loss": 0.1826,
      "step": 1349
    },
    {
      "epoch": 0.021375302816789905,
      "grad_norm": 0.08106569200754166,
      "learning_rate": 9.786246971832102e-06,
      "loss": 0.0177,
      "step": 1350
    },
    {
      "epoch": 0.02139113637443197,
      "grad_norm": 0.38635921478271484,
      "learning_rate": 9.786088636255681e-06,
      "loss": 0.2556,
      "step": 1351
    },
    {
      "epoch": 0.021406969932074037,
      "grad_norm": 0.00032941915560513735,
      "learning_rate": 9.78593030067926e-06,
      "loss": 0.0,
      "step": 1352
    },
    {
      "epoch": 0.021422803489716105,
      "grad_norm": 0.13161788880825043,
      "learning_rate": 9.78577196510284e-06,
      "loss": 0.0671,
      "step": 1353
    },
    {
      "epoch": 0.02143863704735817,
      "grad_norm": 0.1824280023574829,
      "learning_rate": 9.785613629526418e-06,
      "loss": 0.2512,
      "step": 1354
    },
    {
      "epoch": 0.021454470605000237,
      "grad_norm": 0.011965110898017883,
      "learning_rate": 9.785455293949998e-06,
      "loss": 0.0009,
      "step": 1355
    },
    {
      "epoch": 0.021470304162642305,
      "grad_norm": 0.28614163398742676,
      "learning_rate": 9.785296958373578e-06,
      "loss": 0.3881,
      "step": 1356
    },
    {
      "epoch": 0.02148613772028437,
      "grad_norm": 0.0001710309588816017,
      "learning_rate": 9.785138622797157e-06,
      "loss": 0.0,
      "step": 1357
    },
    {
      "epoch": 0.021501971277926437,
      "grad_norm": 0.21685022115707397,
      "learning_rate": 9.784980287220736e-06,
      "loss": 0.0934,
      "step": 1358
    },
    {
      "epoch": 0.021517804835568505,
      "grad_norm": 0.1250048577785492,
      "learning_rate": 9.784821951644316e-06,
      "loss": 0.0902,
      "step": 1359
    },
    {
      "epoch": 0.02153363839321057,
      "grad_norm": 0.14852258563041687,
      "learning_rate": 9.784663616067895e-06,
      "loss": 0.0658,
      "step": 1360
    },
    {
      "epoch": 0.021549471950852637,
      "grad_norm": 0.20543867349624634,
      "learning_rate": 9.784505280491474e-06,
      "loss": 0.0888,
      "step": 1361
    },
    {
      "epoch": 0.021565305508494705,
      "grad_norm": 0.1585494875907898,
      "learning_rate": 9.784346944915054e-06,
      "loss": 0.0922,
      "step": 1362
    },
    {
      "epoch": 0.02158113906613677,
      "grad_norm": 0.22728218138217926,
      "learning_rate": 9.784188609338634e-06,
      "loss": 0.5488,
      "step": 1363
    },
    {
      "epoch": 0.021596972623778837,
      "grad_norm": 0.41539016366004944,
      "learning_rate": 9.784030273762213e-06,
      "loss": 0.4278,
      "step": 1364
    },
    {
      "epoch": 0.021612806181420904,
      "grad_norm": 0.12754184007644653,
      "learning_rate": 9.783871938185792e-06,
      "loss": 0.0659,
      "step": 1365
    },
    {
      "epoch": 0.02162863973906297,
      "grad_norm": 0.20545288920402527,
      "learning_rate": 9.78371360260937e-06,
      "loss": 0.3831,
      "step": 1366
    },
    {
      "epoch": 0.021644473296705036,
      "grad_norm": 0.23839320242404938,
      "learning_rate": 9.78355526703295e-06,
      "loss": 0.0753,
      "step": 1367
    },
    {
      "epoch": 0.021660306854347104,
      "grad_norm": 0.21781215071678162,
      "learning_rate": 9.78339693145653e-06,
      "loss": 0.2968,
      "step": 1368
    },
    {
      "epoch": 0.02167614041198917,
      "grad_norm": 0.10760504007339478,
      "learning_rate": 9.78323859588011e-06,
      "loss": 0.0526,
      "step": 1369
    },
    {
      "epoch": 0.021691973969631236,
      "grad_norm": 0.2687279284000397,
      "learning_rate": 9.783080260303689e-06,
      "loss": 0.257,
      "step": 1370
    },
    {
      "epoch": 0.021707807527273304,
      "grad_norm": 0.24619229137897491,
      "learning_rate": 9.782921924727268e-06,
      "loss": 0.4092,
      "step": 1371
    },
    {
      "epoch": 0.02172364108491537,
      "grad_norm": 0.03349776566028595,
      "learning_rate": 9.782763589150847e-06,
      "loss": 0.0016,
      "step": 1372
    },
    {
      "epoch": 0.021739474642557436,
      "grad_norm": 0.2963785231113434,
      "learning_rate": 9.782605253574426e-06,
      "loss": 0.0962,
      "step": 1373
    },
    {
      "epoch": 0.021755308200199504,
      "grad_norm": 0.05059376731514931,
      "learning_rate": 9.782446917998005e-06,
      "loss": 0.0049,
      "step": 1374
    },
    {
      "epoch": 0.021771141757841568,
      "grad_norm": 0.41075563430786133,
      "learning_rate": 9.782288582421586e-06,
      "loss": 0.3474,
      "step": 1375
    },
    {
      "epoch": 0.021786975315483636,
      "grad_norm": 0.19534391164779663,
      "learning_rate": 9.782130246845163e-06,
      "loss": 0.0448,
      "step": 1376
    },
    {
      "epoch": 0.021802808873125704,
      "grad_norm": 0.31403565406799316,
      "learning_rate": 9.781971911268744e-06,
      "loss": 0.9909,
      "step": 1377
    },
    {
      "epoch": 0.021818642430767768,
      "grad_norm": 0.23567698895931244,
      "learning_rate": 9.781813575692323e-06,
      "loss": 0.2544,
      "step": 1378
    },
    {
      "epoch": 0.021834475988409836,
      "grad_norm": 0.06704030930995941,
      "learning_rate": 9.781655240115902e-06,
      "loss": 0.01,
      "step": 1379
    },
    {
      "epoch": 0.021850309546051903,
      "grad_norm": 0.3037234842777252,
      "learning_rate": 9.781496904539481e-06,
      "loss": 0.2352,
      "step": 1380
    },
    {
      "epoch": 0.021866143103693968,
      "grad_norm": 0.14165472984313965,
      "learning_rate": 9.781338568963062e-06,
      "loss": 0.216,
      "step": 1381
    },
    {
      "epoch": 0.021881976661336035,
      "grad_norm": 0.2635970115661621,
      "learning_rate": 9.78118023338664e-06,
      "loss": 0.1148,
      "step": 1382
    },
    {
      "epoch": 0.021897810218978103,
      "grad_norm": 0.012990019284188747,
      "learning_rate": 9.78102189781022e-06,
      "loss": 0.0012,
      "step": 1383
    },
    {
      "epoch": 0.021913643776620167,
      "grad_norm": 0.007838738150894642,
      "learning_rate": 9.7808635622338e-06,
      "loss": 0.0006,
      "step": 1384
    },
    {
      "epoch": 0.021929477334262235,
      "grad_norm": 0.25270944833755493,
      "learning_rate": 9.780705226657378e-06,
      "loss": 0.1025,
      "step": 1385
    },
    {
      "epoch": 0.021945310891904303,
      "grad_norm": 0.1336379200220108,
      "learning_rate": 9.780546891080957e-06,
      "loss": 0.3064,
      "step": 1386
    },
    {
      "epoch": 0.021961144449546367,
      "grad_norm": 0.37044039368629456,
      "learning_rate": 9.780388555504538e-06,
      "loss": 0.1342,
      "step": 1387
    },
    {
      "epoch": 0.021976978007188435,
      "grad_norm": 0.00020866634440608323,
      "learning_rate": 9.780230219928116e-06,
      "loss": 0.0,
      "step": 1388
    },
    {
      "epoch": 0.021992811564830503,
      "grad_norm": 0.1955777406692505,
      "learning_rate": 9.780071884351696e-06,
      "loss": 0.1243,
      "step": 1389
    },
    {
      "epoch": 0.022008645122472567,
      "grad_norm": 0.0242893286049366,
      "learning_rate": 9.779913548775275e-06,
      "loss": 0.0017,
      "step": 1390
    },
    {
      "epoch": 0.022024478680114635,
      "grad_norm": 0.18376941978931427,
      "learning_rate": 9.779755213198855e-06,
      "loss": 0.1852,
      "step": 1391
    },
    {
      "epoch": 0.022040312237756703,
      "grad_norm": 0.00012928544310852885,
      "learning_rate": 9.779596877622434e-06,
      "loss": 0.0,
      "step": 1392
    },
    {
      "epoch": 0.022056145795398767,
      "grad_norm": 0.39941486716270447,
      "learning_rate": 9.779438542046014e-06,
      "loss": 0.1426,
      "step": 1393
    },
    {
      "epoch": 0.022071979353040835,
      "grad_norm": 0.0003352397179696709,
      "learning_rate": 9.779280206469592e-06,
      "loss": 0.0,
      "step": 1394
    },
    {
      "epoch": 0.022087812910682902,
      "grad_norm": 0.2112663835287094,
      "learning_rate": 9.779121870893173e-06,
      "loss": 0.0507,
      "step": 1395
    },
    {
      "epoch": 0.022103646468324967,
      "grad_norm": 0.213114932179451,
      "learning_rate": 9.778963535316752e-06,
      "loss": 0.1686,
      "step": 1396
    },
    {
      "epoch": 0.022119480025967034,
      "grad_norm": 0.25770413875579834,
      "learning_rate": 9.77880519974033e-06,
      "loss": 0.0606,
      "step": 1397
    },
    {
      "epoch": 0.022135313583609102,
      "grad_norm": 0.2667613625526428,
      "learning_rate": 9.77864686416391e-06,
      "loss": 0.0834,
      "step": 1398
    },
    {
      "epoch": 0.022151147141251167,
      "grad_norm": 0.2208484262228012,
      "learning_rate": 9.778488528587489e-06,
      "loss": 0.1142,
      "step": 1399
    },
    {
      "epoch": 0.022166980698893234,
      "grad_norm": 0.2119283229112625,
      "learning_rate": 9.778330193011068e-06,
      "loss": 0.1984,
      "step": 1400
    },
    {
      "epoch": 0.022182814256535302,
      "grad_norm": 0.17476266622543335,
      "learning_rate": 9.778171857434647e-06,
      "loss": 0.0968,
      "step": 1401
    },
    {
      "epoch": 0.022198647814177366,
      "grad_norm": 0.0031518812756985426,
      "learning_rate": 9.778013521858228e-06,
      "loss": 0.0003,
      "step": 1402
    },
    {
      "epoch": 0.022214481371819434,
      "grad_norm": 0.31742405891418457,
      "learning_rate": 9.777855186281807e-06,
      "loss": 0.1215,
      "step": 1403
    },
    {
      "epoch": 0.022230314929461502,
      "grad_norm": 0.2989650368690491,
      "learning_rate": 9.777696850705386e-06,
      "loss": 0.4019,
      "step": 1404
    },
    {
      "epoch": 0.022246148487103566,
      "grad_norm": 0.17913848161697388,
      "learning_rate": 9.777538515128965e-06,
      "loss": 0.3959,
      "step": 1405
    },
    {
      "epoch": 0.022261982044745634,
      "grad_norm": 0.15338072180747986,
      "learning_rate": 9.777380179552544e-06,
      "loss": 0.029,
      "step": 1406
    },
    {
      "epoch": 0.0222778156023877,
      "grad_norm": 0.007288332562893629,
      "learning_rate": 9.777221843976123e-06,
      "loss": 0.0008,
      "step": 1407
    },
    {
      "epoch": 0.022293649160029766,
      "grad_norm": 0.14597105979919434,
      "learning_rate": 9.777063508399704e-06,
      "loss": 0.1037,
      "step": 1408
    },
    {
      "epoch": 0.022309482717671834,
      "grad_norm": 0.467485249042511,
      "learning_rate": 9.776905172823283e-06,
      "loss": 0.1354,
      "step": 1409
    },
    {
      "epoch": 0.0223253162753139,
      "grad_norm": 0.6921747922897339,
      "learning_rate": 9.776746837246862e-06,
      "loss": 1.3666,
      "step": 1410
    },
    {
      "epoch": 0.022341149832955966,
      "grad_norm": 0.24210301041603088,
      "learning_rate": 9.776588501670441e-06,
      "loss": 0.5047,
      "step": 1411
    },
    {
      "epoch": 0.022356983390598033,
      "grad_norm": 0.309433251619339,
      "learning_rate": 9.77643016609402e-06,
      "loss": 0.4728,
      "step": 1412
    },
    {
      "epoch": 0.0223728169482401,
      "grad_norm": 0.21908767521381378,
      "learning_rate": 9.7762718305176e-06,
      "loss": 0.2234,
      "step": 1413
    },
    {
      "epoch": 0.022388650505882166,
      "grad_norm": 0.3651784658432007,
      "learning_rate": 9.77611349494118e-06,
      "loss": 0.7308,
      "step": 1414
    },
    {
      "epoch": 0.022404484063524233,
      "grad_norm": 0.08690936863422394,
      "learning_rate": 9.775955159364758e-06,
      "loss": 0.1447,
      "step": 1415
    },
    {
      "epoch": 0.0224203176211663,
      "grad_norm": 0.19075272977352142,
      "learning_rate": 9.775796823788338e-06,
      "loss": 0.2498,
      "step": 1416
    },
    {
      "epoch": 0.022436151178808365,
      "grad_norm": 0.24447806179523468,
      "learning_rate": 9.775638488211917e-06,
      "loss": 0.7979,
      "step": 1417
    },
    {
      "epoch": 0.022451984736450433,
      "grad_norm": 0.7578630447387695,
      "learning_rate": 9.775480152635496e-06,
      "loss": 0.1172,
      "step": 1418
    },
    {
      "epoch": 0.0224678182940925,
      "grad_norm": 0.3428960144519806,
      "learning_rate": 9.775321817059076e-06,
      "loss": 0.0824,
      "step": 1419
    },
    {
      "epoch": 0.022483651851734565,
      "grad_norm": 0.231130450963974,
      "learning_rate": 9.775163481482655e-06,
      "loss": 0.1754,
      "step": 1420
    },
    {
      "epoch": 0.022499485409376633,
      "grad_norm": 0.013739210553467274,
      "learning_rate": 9.775005145906234e-06,
      "loss": 0.001,
      "step": 1421
    },
    {
      "epoch": 0.0225153189670187,
      "grad_norm": 0.17843981087207794,
      "learning_rate": 9.774846810329813e-06,
      "loss": 0.2331,
      "step": 1422
    },
    {
      "epoch": 0.022531152524660765,
      "grad_norm": 0.17603550851345062,
      "learning_rate": 9.774688474753394e-06,
      "loss": 0.1051,
      "step": 1423
    },
    {
      "epoch": 0.022546986082302833,
      "grad_norm": 0.1805001199245453,
      "learning_rate": 9.774530139176973e-06,
      "loss": 0.2857,
      "step": 1424
    },
    {
      "epoch": 0.0225628196399449,
      "grad_norm": 0.34466296434402466,
      "learning_rate": 9.774371803600552e-06,
      "loss": 0.0635,
      "step": 1425
    },
    {
      "epoch": 0.022578653197586965,
      "grad_norm": 0.4409661293029785,
      "learning_rate": 9.77421346802413e-06,
      "loss": 0.6628,
      "step": 1426
    },
    {
      "epoch": 0.022594486755229033,
      "grad_norm": 0.13380393385887146,
      "learning_rate": 9.77405513244771e-06,
      "loss": 0.1316,
      "step": 1427
    },
    {
      "epoch": 0.0226103203128711,
      "grad_norm": 0.15805228054523468,
      "learning_rate": 9.773896796871289e-06,
      "loss": 0.0701,
      "step": 1428
    },
    {
      "epoch": 0.022626153870513165,
      "grad_norm": 0.16441231966018677,
      "learning_rate": 9.77373846129487e-06,
      "loss": 0.0759,
      "step": 1429
    },
    {
      "epoch": 0.022641987428155232,
      "grad_norm": 0.11807499080896378,
      "learning_rate": 9.773580125718449e-06,
      "loss": 0.0693,
      "step": 1430
    },
    {
      "epoch": 0.0226578209857973,
      "grad_norm": 0.21759094297885895,
      "learning_rate": 9.773421790142028e-06,
      "loss": 0.3235,
      "step": 1431
    },
    {
      "epoch": 0.022673654543439364,
      "grad_norm": 0.39889782667160034,
      "learning_rate": 9.773263454565607e-06,
      "loss": 0.3078,
      "step": 1432
    },
    {
      "epoch": 0.022689488101081432,
      "grad_norm": 0.005205975379794836,
      "learning_rate": 9.773105118989186e-06,
      "loss": 0.0005,
      "step": 1433
    },
    {
      "epoch": 0.0227053216587235,
      "grad_norm": 0.04188202694058418,
      "learning_rate": 9.772946783412765e-06,
      "loss": 0.0045,
      "step": 1434
    },
    {
      "epoch": 0.022721155216365564,
      "grad_norm": 0.4532817304134369,
      "learning_rate": 9.772788447836346e-06,
      "loss": 0.4638,
      "step": 1435
    },
    {
      "epoch": 0.022736988774007632,
      "grad_norm": 0.027560895308852196,
      "learning_rate": 9.772630112259925e-06,
      "loss": 0.0048,
      "step": 1436
    },
    {
      "epoch": 0.0227528223316497,
      "grad_norm": 0.015319452621042728,
      "learning_rate": 9.772471776683504e-06,
      "loss": 0.0014,
      "step": 1437
    },
    {
      "epoch": 0.022768655889291764,
      "grad_norm": 0.2699643671512604,
      "learning_rate": 9.772313441107083e-06,
      "loss": 0.0804,
      "step": 1438
    },
    {
      "epoch": 0.022784489446933832,
      "grad_norm": 0.19552870094776154,
      "learning_rate": 9.772155105530662e-06,
      "loss": 0.2237,
      "step": 1439
    },
    {
      "epoch": 0.0228003230045759,
      "grad_norm": 0.0013844968052580953,
      "learning_rate": 9.771996769954241e-06,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 0.022816156562217964,
      "grad_norm": 0.23291237652301788,
      "learning_rate": 9.771838434377822e-06,
      "loss": 0.173,
      "step": 1441
    },
    {
      "epoch": 0.02283199011986003,
      "grad_norm": 0.04115493595600128,
      "learning_rate": 9.771680098801401e-06,
      "loss": 0.0032,
      "step": 1442
    },
    {
      "epoch": 0.0228478236775021,
      "grad_norm": 0.14974519610404968,
      "learning_rate": 9.77152176322498e-06,
      "loss": 0.1403,
      "step": 1443
    },
    {
      "epoch": 0.022863657235144164,
      "grad_norm": 0.006117349490523338,
      "learning_rate": 9.77136342764856e-06,
      "loss": 0.0004,
      "step": 1444
    },
    {
      "epoch": 0.02287949079278623,
      "grad_norm": 0.3137219548225403,
      "learning_rate": 9.771205092072138e-06,
      "loss": 0.4273,
      "step": 1445
    },
    {
      "epoch": 0.0228953243504283,
      "grad_norm": 0.02475205436348915,
      "learning_rate": 9.771046756495717e-06,
      "loss": 0.0019,
      "step": 1446
    },
    {
      "epoch": 0.022911157908070363,
      "grad_norm": 0.46512889862060547,
      "learning_rate": 9.770888420919297e-06,
      "loss": 1.1392,
      "step": 1447
    },
    {
      "epoch": 0.02292699146571243,
      "grad_norm": 0.18453899025917053,
      "learning_rate": 9.770730085342877e-06,
      "loss": 0.2427,
      "step": 1448
    },
    {
      "epoch": 0.0229428250233545,
      "grad_norm": 0.5066955089569092,
      "learning_rate": 9.770571749766455e-06,
      "loss": 0.0199,
      "step": 1449
    },
    {
      "epoch": 0.022958658580996563,
      "grad_norm": 0.38988351821899414,
      "learning_rate": 9.770413414190035e-06,
      "loss": 1.055,
      "step": 1450
    },
    {
      "epoch": 0.02297449213863863,
      "grad_norm": 0.041963737457990646,
      "learning_rate": 9.770255078613615e-06,
      "loss": 0.0049,
      "step": 1451
    },
    {
      "epoch": 0.0229903256962807,
      "grad_norm": 0.38452810049057007,
      "learning_rate": 9.770096743037194e-06,
      "loss": 0.7204,
      "step": 1452
    },
    {
      "epoch": 0.023006159253922763,
      "grad_norm": 0.16696539521217346,
      "learning_rate": 9.769938407460773e-06,
      "loss": 0.2371,
      "step": 1453
    },
    {
      "epoch": 0.02302199281156483,
      "grad_norm": 0.004238991532474756,
      "learning_rate": 9.769780071884353e-06,
      "loss": 0.0003,
      "step": 1454
    },
    {
      "epoch": 0.0230378263692069,
      "grad_norm": 0.37321051955223083,
      "learning_rate": 9.769621736307931e-06,
      "loss": 0.0542,
      "step": 1455
    },
    {
      "epoch": 0.023053659926848963,
      "grad_norm": 0.16511860489845276,
      "learning_rate": 9.769463400731512e-06,
      "loss": 0.3512,
      "step": 1456
    },
    {
      "epoch": 0.02306949348449103,
      "grad_norm": 0.6604575514793396,
      "learning_rate": 9.76930506515509e-06,
      "loss": 0.827,
      "step": 1457
    },
    {
      "epoch": 0.0230853270421331,
      "grad_norm": 0.0003390556375961751,
      "learning_rate": 9.76914672957867e-06,
      "loss": 0.0,
      "step": 1458
    },
    {
      "epoch": 0.023101160599775163,
      "grad_norm": 0.00010287523764418438,
      "learning_rate": 9.768988394002249e-06,
      "loss": 0.0,
      "step": 1459
    },
    {
      "epoch": 0.02311699415741723,
      "grad_norm": 0.027842054143548012,
      "learning_rate": 9.76883005842583e-06,
      "loss": 0.0019,
      "step": 1460
    },
    {
      "epoch": 0.023132827715059298,
      "grad_norm": 0.049668461084365845,
      "learning_rate": 9.768671722849407e-06,
      "loss": 0.1769,
      "step": 1461
    },
    {
      "epoch": 0.023148661272701362,
      "grad_norm": 0.0009006208274513483,
      "learning_rate": 9.768513387272988e-06,
      "loss": 0.0,
      "step": 1462
    },
    {
      "epoch": 0.02316449483034343,
      "grad_norm": 0.20167158544063568,
      "learning_rate": 9.768355051696567e-06,
      "loss": 0.1911,
      "step": 1463
    },
    {
      "epoch": 0.023180328387985498,
      "grad_norm": 0.0987536758184433,
      "learning_rate": 9.768196716120146e-06,
      "loss": 0.0057,
      "step": 1464
    },
    {
      "epoch": 0.023196161945627562,
      "grad_norm": 0.42582136392593384,
      "learning_rate": 9.768038380543725e-06,
      "loss": 0.0499,
      "step": 1465
    },
    {
      "epoch": 0.02321199550326963,
      "grad_norm": 0.19457146525382996,
      "learning_rate": 9.767880044967306e-06,
      "loss": 0.3905,
      "step": 1466
    },
    {
      "epoch": 0.023227829060911698,
      "grad_norm": 1.2404723167419434,
      "learning_rate": 9.767721709390883e-06,
      "loss": 0.042,
      "step": 1467
    },
    {
      "epoch": 0.023243662618553762,
      "grad_norm": 0.4515347480773926,
      "learning_rate": 9.767563373814462e-06,
      "loss": 0.3397,
      "step": 1468
    },
    {
      "epoch": 0.02325949617619583,
      "grad_norm": 0.37830379605293274,
      "learning_rate": 9.767405038238043e-06,
      "loss": 1.2918,
      "step": 1469
    },
    {
      "epoch": 0.023275329733837898,
      "grad_norm": 0.017810363322496414,
      "learning_rate": 9.767246702661622e-06,
      "loss": 0.0007,
      "step": 1470
    },
    {
      "epoch": 0.023291163291479962,
      "grad_norm": 0.00037142535438761115,
      "learning_rate": 9.767088367085201e-06,
      "loss": 0.0,
      "step": 1471
    },
    {
      "epoch": 0.02330699684912203,
      "grad_norm": 0.28610605001449585,
      "learning_rate": 9.76693003150878e-06,
      "loss": 0.0743,
      "step": 1472
    },
    {
      "epoch": 0.023322830406764097,
      "grad_norm": 0.4445142447948456,
      "learning_rate": 9.76677169593236e-06,
      "loss": 0.5032,
      "step": 1473
    },
    {
      "epoch": 0.02333866396440616,
      "grad_norm": 0.252277672290802,
      "learning_rate": 9.766613360355938e-06,
      "loss": 0.139,
      "step": 1474
    },
    {
      "epoch": 0.02335449752204823,
      "grad_norm": 0.4216349422931671,
      "learning_rate": 9.76645502477952e-06,
      "loss": 0.6891,
      "step": 1475
    },
    {
      "epoch": 0.023370331079690297,
      "grad_norm": 0.13323068618774414,
      "learning_rate": 9.766296689203098e-06,
      "loss": 0.0311,
      "step": 1476
    },
    {
      "epoch": 0.02338616463733236,
      "grad_norm": 0.004584637004882097,
      "learning_rate": 9.766138353626677e-06,
      "loss": 0.0003,
      "step": 1477
    },
    {
      "epoch": 0.02340199819497443,
      "grad_norm": 0.19789499044418335,
      "learning_rate": 9.765980018050256e-06,
      "loss": 0.2282,
      "step": 1478
    },
    {
      "epoch": 0.023417831752616497,
      "grad_norm": 0.2846505641937256,
      "learning_rate": 9.765821682473836e-06,
      "loss": 0.1886,
      "step": 1479
    },
    {
      "epoch": 0.02343366531025856,
      "grad_norm": 0.3021849989891052,
      "learning_rate": 9.765663346897415e-06,
      "loss": 0.2875,
      "step": 1480
    },
    {
      "epoch": 0.02344949886790063,
      "grad_norm": 0.20432433485984802,
      "learning_rate": 9.765505011320995e-06,
      "loss": 0.0166,
      "step": 1481
    },
    {
      "epoch": 0.023465332425542697,
      "grad_norm": 0.3535306453704834,
      "learning_rate": 9.765346675744573e-06,
      "loss": 0.1907,
      "step": 1482
    },
    {
      "epoch": 0.02348116598318476,
      "grad_norm": 0.003402319271117449,
      "learning_rate": 9.765188340168154e-06,
      "loss": 0.0001,
      "step": 1483
    },
    {
      "epoch": 0.02349699954082683,
      "grad_norm": 0.769307553768158,
      "learning_rate": 9.765030004591733e-06,
      "loss": 0.6128,
      "step": 1484
    },
    {
      "epoch": 0.023512833098468897,
      "grad_norm": 0.17617173492908478,
      "learning_rate": 9.764871669015312e-06,
      "loss": 0.0052,
      "step": 1485
    },
    {
      "epoch": 0.02352866665611096,
      "grad_norm": 0.007321585435420275,
      "learning_rate": 9.76471333343889e-06,
      "loss": 0.0004,
      "step": 1486
    },
    {
      "epoch": 0.02354450021375303,
      "grad_norm": 0.15220175683498383,
      "learning_rate": 9.764554997862472e-06,
      "loss": 0.146,
      "step": 1487
    },
    {
      "epoch": 0.023560333771395096,
      "grad_norm": 0.6812030076980591,
      "learning_rate": 9.764396662286049e-06,
      "loss": 0.0735,
      "step": 1488
    },
    {
      "epoch": 0.02357616732903716,
      "grad_norm": 0.1212698444724083,
      "learning_rate": 9.76423832670963e-06,
      "loss": 0.0349,
      "step": 1489
    },
    {
      "epoch": 0.02359200088667923,
      "grad_norm": 0.1995323747396469,
      "learning_rate": 9.764079991133209e-06,
      "loss": 0.1182,
      "step": 1490
    },
    {
      "epoch": 0.023607834444321296,
      "grad_norm": 0.14506597816944122,
      "learning_rate": 9.763921655556788e-06,
      "loss": 0.0553,
      "step": 1491
    },
    {
      "epoch": 0.02362366800196336,
      "grad_norm": 0.008549707941710949,
      "learning_rate": 9.763763319980367e-06,
      "loss": 0.0002,
      "step": 1492
    },
    {
      "epoch": 0.023639501559605428,
      "grad_norm": 0.24193768203258514,
      "learning_rate": 9.763604984403946e-06,
      "loss": 0.2031,
      "step": 1493
    },
    {
      "epoch": 0.023655335117247496,
      "grad_norm": 0.09586244076490402,
      "learning_rate": 9.763446648827525e-06,
      "loss": 0.0064,
      "step": 1494
    },
    {
      "epoch": 0.02367116867488956,
      "grad_norm": 0.1460445076227188,
      "learning_rate": 9.763288313251104e-06,
      "loss": 0.1844,
      "step": 1495
    },
    {
      "epoch": 0.023687002232531628,
      "grad_norm": 0.00446630734950304,
      "learning_rate": 9.763129977674685e-06,
      "loss": 0.0003,
      "step": 1496
    },
    {
      "epoch": 0.023702835790173696,
      "grad_norm": 0.6009989976882935,
      "learning_rate": 9.762971642098264e-06,
      "loss": 0.1036,
      "step": 1497
    },
    {
      "epoch": 0.02371866934781576,
      "grad_norm": 0.0015113175613805652,
      "learning_rate": 9.762813306521843e-06,
      "loss": 0.0,
      "step": 1498
    },
    {
      "epoch": 0.023734502905457828,
      "grad_norm": 0.0001030397615977563,
      "learning_rate": 9.762654970945422e-06,
      "loss": 0.0,
      "step": 1499
    },
    {
      "epoch": 0.023750336463099896,
      "grad_norm": 0.17585697770118713,
      "learning_rate": 9.762496635369001e-06,
      "loss": 0.022,
      "step": 1500
    },
    {
      "epoch": 0.02376617002074196,
      "grad_norm": 0.31242698431015015,
      "learning_rate": 9.76233829979258e-06,
      "loss": 0.5352,
      "step": 1501
    },
    {
      "epoch": 0.023782003578384028,
      "grad_norm": 0.5091687440872192,
      "learning_rate": 9.762179964216161e-06,
      "loss": 1.1272,
      "step": 1502
    },
    {
      "epoch": 0.023797837136026095,
      "grad_norm": 0.21785889565944672,
      "learning_rate": 9.76202162863974e-06,
      "loss": 0.1207,
      "step": 1503
    },
    {
      "epoch": 0.02381367069366816,
      "grad_norm": 0.5137768983840942,
      "learning_rate": 9.76186329306332e-06,
      "loss": 0.3549,
      "step": 1504
    },
    {
      "epoch": 0.023829504251310227,
      "grad_norm": 0.004117592703551054,
      "learning_rate": 9.761704957486898e-06,
      "loss": 0.0003,
      "step": 1505
    },
    {
      "epoch": 0.023845337808952295,
      "grad_norm": 0.0004653297655750066,
      "learning_rate": 9.761546621910477e-06,
      "loss": 0.0,
      "step": 1506
    },
    {
      "epoch": 0.02386117136659436,
      "grad_norm": 0.28760990500450134,
      "learning_rate": 9.761388286334057e-06,
      "loss": 0.3158,
      "step": 1507
    },
    {
      "epoch": 0.023877004924236427,
      "grad_norm": 0.1497085988521576,
      "learning_rate": 9.761229950757637e-06,
      "loss": 0.1348,
      "step": 1508
    },
    {
      "epoch": 0.02389283848187849,
      "grad_norm": 0.2988128066062927,
      "learning_rate": 9.761071615181216e-06,
      "loss": 0.748,
      "step": 1509
    },
    {
      "epoch": 0.02390867203952056,
      "grad_norm": 0.14431650936603546,
      "learning_rate": 9.760913279604796e-06,
      "loss": 0.0984,
      "step": 1510
    },
    {
      "epoch": 0.023924505597162627,
      "grad_norm": 0.12488822638988495,
      "learning_rate": 9.760754944028375e-06,
      "loss": 0.1738,
      "step": 1511
    },
    {
      "epoch": 0.02394033915480469,
      "grad_norm": 0.21463364362716675,
      "learning_rate": 9.760596608451954e-06,
      "loss": 0.7782,
      "step": 1512
    },
    {
      "epoch": 0.02395617271244676,
      "grad_norm": 0.2716904580593109,
      "learning_rate": 9.760438272875533e-06,
      "loss": 0.1005,
      "step": 1513
    },
    {
      "epoch": 0.023972006270088827,
      "grad_norm": 0.4028022885322571,
      "learning_rate": 9.760279937299114e-06,
      "loss": 0.2443,
      "step": 1514
    },
    {
      "epoch": 0.02398783982773089,
      "grad_norm": 0.12327561527490616,
      "learning_rate": 9.760121601722693e-06,
      "loss": 0.1895,
      "step": 1515
    },
    {
      "epoch": 0.02400367338537296,
      "grad_norm": 0.019279981032013893,
      "learning_rate": 9.75996326614627e-06,
      "loss": 0.0013,
      "step": 1516
    },
    {
      "epoch": 0.024019506943015027,
      "grad_norm": 0.5144664645195007,
      "learning_rate": 9.75980493056985e-06,
      "loss": 0.0719,
      "step": 1517
    },
    {
      "epoch": 0.02403534050065709,
      "grad_norm": 0.4682839810848236,
      "learning_rate": 9.75964659499343e-06,
      "loss": 0.8088,
      "step": 1518
    },
    {
      "epoch": 0.02405117405829916,
      "grad_norm": 0.03916177153587341,
      "learning_rate": 9.759488259417009e-06,
      "loss": 0.0021,
      "step": 1519
    },
    {
      "epoch": 0.024067007615941226,
      "grad_norm": 0.10851497948169708,
      "learning_rate": 9.759329923840588e-06,
      "loss": 0.2144,
      "step": 1520
    },
    {
      "epoch": 0.02408284117358329,
      "grad_norm": 0.2988293468952179,
      "learning_rate": 9.759171588264169e-06,
      "loss": 0.211,
      "step": 1521
    },
    {
      "epoch": 0.02409867473122536,
      "grad_norm": 0.03400726243853569,
      "learning_rate": 9.759013252687746e-06,
      "loss": 0.0014,
      "step": 1522
    },
    {
      "epoch": 0.024114508288867426,
      "grad_norm": 0.22574487328529358,
      "learning_rate": 9.758854917111327e-06,
      "loss": 0.713,
      "step": 1523
    },
    {
      "epoch": 0.02413034184650949,
      "grad_norm": 0.25951918959617615,
      "learning_rate": 9.758696581534906e-06,
      "loss": 0.0565,
      "step": 1524
    },
    {
      "epoch": 0.02414617540415156,
      "grad_norm": 0.004520993679761887,
      "learning_rate": 9.758538245958485e-06,
      "loss": 0.0003,
      "step": 1525
    },
    {
      "epoch": 0.024162008961793626,
      "grad_norm": 0.010589041747152805,
      "learning_rate": 9.758379910382064e-06,
      "loss": 0.0002,
      "step": 1526
    },
    {
      "epoch": 0.02417784251943569,
      "grad_norm": 0.29182168841362,
      "learning_rate": 9.758221574805645e-06,
      "loss": 0.0906,
      "step": 1527
    },
    {
      "epoch": 0.024193676077077758,
      "grad_norm": 0.03230539336800575,
      "learning_rate": 9.758063239229222e-06,
      "loss": 0.0008,
      "step": 1528
    },
    {
      "epoch": 0.024209509634719826,
      "grad_norm": 0.12001316994428635,
      "learning_rate": 9.757904903652803e-06,
      "loss": 0.004,
      "step": 1529
    },
    {
      "epoch": 0.02422534319236189,
      "grad_norm": 0.15230105817317963,
      "learning_rate": 9.757746568076382e-06,
      "loss": 0.343,
      "step": 1530
    },
    {
      "epoch": 0.024241176750003958,
      "grad_norm": 0.1428784877061844,
      "learning_rate": 9.757588232499961e-06,
      "loss": 0.081,
      "step": 1531
    },
    {
      "epoch": 0.024257010307646026,
      "grad_norm": 0.24690507352352142,
      "learning_rate": 9.75742989692354e-06,
      "loss": 0.1241,
      "step": 1532
    },
    {
      "epoch": 0.02427284386528809,
      "grad_norm": 0.20140478014945984,
      "learning_rate": 9.757271561347121e-06,
      "loss": 0.0901,
      "step": 1533
    },
    {
      "epoch": 0.024288677422930158,
      "grad_norm": 0.2089235484600067,
      "learning_rate": 9.757113225770698e-06,
      "loss": 0.0289,
      "step": 1534
    },
    {
      "epoch": 0.024304510980572226,
      "grad_norm": 0.30445602536201477,
      "learning_rate": 9.75695489019428e-06,
      "loss": 0.07,
      "step": 1535
    },
    {
      "epoch": 0.02432034453821429,
      "grad_norm": 0.20210251212120056,
      "learning_rate": 9.756796554617858e-06,
      "loss": 0.1906,
      "step": 1536
    },
    {
      "epoch": 0.024336178095856358,
      "grad_norm": 0.9062479138374329,
      "learning_rate": 9.756638219041437e-06,
      "loss": 0.0259,
      "step": 1537
    },
    {
      "epoch": 0.024352011653498425,
      "grad_norm": 0.25534531474113464,
      "learning_rate": 9.756479883465017e-06,
      "loss": 0.2055,
      "step": 1538
    },
    {
      "epoch": 0.02436784521114049,
      "grad_norm": 0.30504992604255676,
      "learning_rate": 9.756321547888596e-06,
      "loss": 0.3879,
      "step": 1539
    },
    {
      "epoch": 0.024383678768782557,
      "grad_norm": 0.13079902529716492,
      "learning_rate": 9.756163212312175e-06,
      "loss": 0.0692,
      "step": 1540
    },
    {
      "epoch": 0.024399512326424625,
      "grad_norm": 0.07651886343955994,
      "learning_rate": 9.756004876735754e-06,
      "loss": 0.038,
      "step": 1541
    },
    {
      "epoch": 0.02441534588406669,
      "grad_norm": 0.0070991069078445435,
      "learning_rate": 9.755846541159335e-06,
      "loss": 0.0004,
      "step": 1542
    },
    {
      "epoch": 0.024431179441708757,
      "grad_norm": 0.2922329008579254,
      "learning_rate": 9.755688205582912e-06,
      "loss": 0.6011,
      "step": 1543
    },
    {
      "epoch": 0.024447012999350825,
      "grad_norm": 0.003486995818093419,
      "learning_rate": 9.755529870006493e-06,
      "loss": 0.0,
      "step": 1544
    },
    {
      "epoch": 0.02446284655699289,
      "grad_norm": 0.2582740783691406,
      "learning_rate": 9.755371534430072e-06,
      "loss": 0.3649,
      "step": 1545
    },
    {
      "epoch": 0.024478680114634957,
      "grad_norm": 0.11371719092130661,
      "learning_rate": 9.75521319885365e-06,
      "loss": 0.1079,
      "step": 1546
    },
    {
      "epoch": 0.024494513672277025,
      "grad_norm": 0.42176851630210876,
      "learning_rate": 9.75505486327723e-06,
      "loss": 0.2765,
      "step": 1547
    },
    {
      "epoch": 0.02451034722991909,
      "grad_norm": 0.24007117748260498,
      "learning_rate": 9.75489652770081e-06,
      "loss": 0.1151,
      "step": 1548
    },
    {
      "epoch": 0.024526180787561157,
      "grad_norm": 0.16237643361091614,
      "learning_rate": 9.754738192124388e-06,
      "loss": 0.2369,
      "step": 1549
    },
    {
      "epoch": 0.024542014345203225,
      "grad_norm": 0.35145604610443115,
      "learning_rate": 9.754579856547969e-06,
      "loss": 0.315,
      "step": 1550
    },
    {
      "epoch": 0.02455784790284529,
      "grad_norm": 0.08576461672782898,
      "learning_rate": 9.754421520971548e-06,
      "loss": 0.1151,
      "step": 1551
    },
    {
      "epoch": 0.024573681460487357,
      "grad_norm": 0.47745954990386963,
      "learning_rate": 9.754263185395127e-06,
      "loss": 0.2133,
      "step": 1552
    },
    {
      "epoch": 0.024589515018129424,
      "grad_norm": 0.16657480597496033,
      "learning_rate": 9.754104849818706e-06,
      "loss": 0.0837,
      "step": 1553
    },
    {
      "epoch": 0.02460534857577149,
      "grad_norm": 0.04493272677063942,
      "learning_rate": 9.753946514242287e-06,
      "loss": 0.0063,
      "step": 1554
    },
    {
      "epoch": 0.024621182133413556,
      "grad_norm": 0.009582401253283024,
      "learning_rate": 9.753788178665864e-06,
      "loss": 0.0006,
      "step": 1555
    },
    {
      "epoch": 0.024637015691055624,
      "grad_norm": 0.15741659700870514,
      "learning_rate": 9.753629843089445e-06,
      "loss": 0.0787,
      "step": 1556
    },
    {
      "epoch": 0.02465284924869769,
      "grad_norm": 0.015538769774138927,
      "learning_rate": 9.753471507513024e-06,
      "loss": 0.001,
      "step": 1557
    },
    {
      "epoch": 0.024668682806339756,
      "grad_norm": 0.13116414844989777,
      "learning_rate": 9.753313171936603e-06,
      "loss": 0.2433,
      "step": 1558
    },
    {
      "epoch": 0.024684516363981824,
      "grad_norm": 0.192230224609375,
      "learning_rate": 9.753154836360182e-06,
      "loss": 0.0512,
      "step": 1559
    },
    {
      "epoch": 0.024700349921623888,
      "grad_norm": 0.06764914840459824,
      "learning_rate": 9.752996500783763e-06,
      "loss": 0.0031,
      "step": 1560
    },
    {
      "epoch": 0.024716183479265956,
      "grad_norm": 0.12397594004869461,
      "learning_rate": 9.75283816520734e-06,
      "loss": 0.0394,
      "step": 1561
    },
    {
      "epoch": 0.024732017036908024,
      "grad_norm": 0.14967073500156403,
      "learning_rate": 9.752679829630921e-06,
      "loss": 0.0767,
      "step": 1562
    },
    {
      "epoch": 0.024747850594550088,
      "grad_norm": 0.21712778508663177,
      "learning_rate": 9.7525214940545e-06,
      "loss": 0.0347,
      "step": 1563
    },
    {
      "epoch": 0.024763684152192156,
      "grad_norm": 0.19447295367717743,
      "learning_rate": 9.75236315847808e-06,
      "loss": 0.1466,
      "step": 1564
    },
    {
      "epoch": 0.024779517709834224,
      "grad_norm": 0.21117563545703888,
      "learning_rate": 9.752204822901658e-06,
      "loss": 0.0662,
      "step": 1565
    },
    {
      "epoch": 0.024795351267476288,
      "grad_norm": 0.14829878509044647,
      "learning_rate": 9.752046487325238e-06,
      "loss": 0.0854,
      "step": 1566
    },
    {
      "epoch": 0.024811184825118356,
      "grad_norm": 0.13579490780830383,
      "learning_rate": 9.751888151748817e-06,
      "loss": 0.0567,
      "step": 1567
    },
    {
      "epoch": 0.024827018382760423,
      "grad_norm": 0.1621522158384323,
      "learning_rate": 9.751729816172396e-06,
      "loss": 0.1526,
      "step": 1568
    },
    {
      "epoch": 0.024842851940402488,
      "grad_norm": 0.2811354994773865,
      "learning_rate": 9.751571480595976e-06,
      "loss": 0.1496,
      "step": 1569
    },
    {
      "epoch": 0.024858685498044555,
      "grad_norm": 0.01383222546428442,
      "learning_rate": 9.751413145019556e-06,
      "loss": 0.0012,
      "step": 1570
    },
    {
      "epoch": 0.024874519055686623,
      "grad_norm": 0.2206149846315384,
      "learning_rate": 9.751254809443135e-06,
      "loss": 0.0563,
      "step": 1571
    },
    {
      "epoch": 0.024890352613328687,
      "grad_norm": 0.016843179240822792,
      "learning_rate": 9.751096473866714e-06,
      "loss": 0.0009,
      "step": 1572
    },
    {
      "epoch": 0.024906186170970755,
      "grad_norm": 0.21323443949222565,
      "learning_rate": 9.750938138290293e-06,
      "loss": 0.1374,
      "step": 1573
    },
    {
      "epoch": 0.024922019728612823,
      "grad_norm": 0.07339973747730255,
      "learning_rate": 9.750779802713872e-06,
      "loss": 0.0233,
      "step": 1574
    },
    {
      "epoch": 0.024937853286254887,
      "grad_norm": 0.006325129885226488,
      "learning_rate": 9.750621467137453e-06,
      "loss": 0.0003,
      "step": 1575
    },
    {
      "epoch": 0.024953686843896955,
      "grad_norm": 0.31159746646881104,
      "learning_rate": 9.750463131561032e-06,
      "loss": 0.1395,
      "step": 1576
    },
    {
      "epoch": 0.024969520401539023,
      "grad_norm": 0.37339136004447937,
      "learning_rate": 9.75030479598461e-06,
      "loss": 0.8185,
      "step": 1577
    },
    {
      "epoch": 0.024985353959181087,
      "grad_norm": 0.15747730433940887,
      "learning_rate": 9.75014646040819e-06,
      "loss": 0.1152,
      "step": 1578
    },
    {
      "epoch": 0.025001187516823155,
      "grad_norm": 0.037688713520765305,
      "learning_rate": 9.749988124831769e-06,
      "loss": 0.0026,
      "step": 1579
    },
    {
      "epoch": 0.025017021074465223,
      "grad_norm": 0.20730680227279663,
      "learning_rate": 9.749829789255348e-06,
      "loss": 0.0544,
      "step": 1580
    },
    {
      "epoch": 0.025032854632107287,
      "grad_norm": 0.12136804312467575,
      "learning_rate": 9.749671453678929e-06,
      "loss": 0.0688,
      "step": 1581
    },
    {
      "epoch": 0.025048688189749355,
      "grad_norm": 0.25797170400619507,
      "learning_rate": 9.749513118102508e-06,
      "loss": 0.0783,
      "step": 1582
    },
    {
      "epoch": 0.025064521747391422,
      "grad_norm": 0.3510279655456543,
      "learning_rate": 9.749354782526087e-06,
      "loss": 0.081,
      "step": 1583
    },
    {
      "epoch": 0.025080355305033487,
      "grad_norm": 0.3167218267917633,
      "learning_rate": 9.749196446949666e-06,
      "loss": 0.7033,
      "step": 1584
    },
    {
      "epoch": 0.025096188862675554,
      "grad_norm": 0.011688021011650562,
      "learning_rate": 9.749038111373245e-06,
      "loss": 0.0008,
      "step": 1585
    },
    {
      "epoch": 0.025112022420317622,
      "grad_norm": 0.00025243908748961985,
      "learning_rate": 9.748879775796824e-06,
      "loss": 0.0,
      "step": 1586
    },
    {
      "epoch": 0.025127855977959686,
      "grad_norm": 0.2927757501602173,
      "learning_rate": 9.748721440220405e-06,
      "loss": 0.5705,
      "step": 1587
    },
    {
      "epoch": 0.025143689535601754,
      "grad_norm": 0.12079326063394547,
      "learning_rate": 9.748563104643984e-06,
      "loss": 0.0313,
      "step": 1588
    },
    {
      "epoch": 0.025159523093243822,
      "grad_norm": 0.03136926516890526,
      "learning_rate": 9.748404769067561e-06,
      "loss": 0.0016,
      "step": 1589
    },
    {
      "epoch": 0.025175356650885886,
      "grad_norm": 0.1615365445613861,
      "learning_rate": 9.748246433491142e-06,
      "loss": 0.065,
      "step": 1590
    },
    {
      "epoch": 0.025191190208527954,
      "grad_norm": 0.00043143596849404275,
      "learning_rate": 9.748088097914721e-06,
      "loss": 0.0,
      "step": 1591
    },
    {
      "epoch": 0.025207023766170022,
      "grad_norm": 0.18280979990959167,
      "learning_rate": 9.7479297623383e-06,
      "loss": 0.3305,
      "step": 1592
    },
    {
      "epoch": 0.025222857323812086,
      "grad_norm": 0.25898951292037964,
      "learning_rate": 9.74777142676188e-06,
      "loss": 0.2462,
      "step": 1593
    },
    {
      "epoch": 0.025238690881454154,
      "grad_norm": 0.246128112077713,
      "learning_rate": 9.74761309118546e-06,
      "loss": 0.3276,
      "step": 1594
    },
    {
      "epoch": 0.02525452443909622,
      "grad_norm": 0.4963019788265228,
      "learning_rate": 9.747454755609038e-06,
      "loss": 1.2499,
      "step": 1595
    },
    {
      "epoch": 0.025270357996738286,
      "grad_norm": 0.24048350751399994,
      "learning_rate": 9.747296420032618e-06,
      "loss": 0.1549,
      "step": 1596
    },
    {
      "epoch": 0.025286191554380354,
      "grad_norm": 0.006302051246166229,
      "learning_rate": 9.747138084456197e-06,
      "loss": 0.0004,
      "step": 1597
    },
    {
      "epoch": 0.02530202511202242,
      "grad_norm": 0.016490770503878593,
      "learning_rate": 9.746979748879777e-06,
      "loss": 0.0009,
      "step": 1598
    },
    {
      "epoch": 0.025317858669664486,
      "grad_norm": 0.3752472996711731,
      "learning_rate": 9.746821413303356e-06,
      "loss": 0.3158,
      "step": 1599
    },
    {
      "epoch": 0.025333692227306553,
      "grad_norm": 0.2740267515182495,
      "learning_rate": 9.746663077726936e-06,
      "loss": 0.0794,
      "step": 1600
    },
    {
      "epoch": 0.02534952578494862,
      "grad_norm": 0.3344615399837494,
      "learning_rate": 9.746504742150514e-06,
      "loss": 0.2385,
      "step": 1601
    },
    {
      "epoch": 0.025365359342590686,
      "grad_norm": 0.003980426117777824,
      "learning_rate": 9.746346406574095e-06,
      "loss": 0.0002,
      "step": 1602
    },
    {
      "epoch": 0.025381192900232753,
      "grad_norm": 0.638421893119812,
      "learning_rate": 9.746188070997674e-06,
      "loss": 0.9655,
      "step": 1603
    },
    {
      "epoch": 0.02539702645787482,
      "grad_norm": 0.009411867707967758,
      "learning_rate": 9.746029735421253e-06,
      "loss": 0.0005,
      "step": 1604
    },
    {
      "epoch": 0.025412860015516885,
      "grad_norm": 0.004929245915263891,
      "learning_rate": 9.745871399844832e-06,
      "loss": 0.0001,
      "step": 1605
    },
    {
      "epoch": 0.025428693573158953,
      "grad_norm": 0.26866814494132996,
      "learning_rate": 9.745713064268411e-06,
      "loss": 0.226,
      "step": 1606
    },
    {
      "epoch": 0.02544452713080102,
      "grad_norm": 0.215188667178154,
      "learning_rate": 9.74555472869199e-06,
      "loss": 0.1244,
      "step": 1607
    },
    {
      "epoch": 0.025460360688443085,
      "grad_norm": 0.0035229583736509085,
      "learning_rate": 9.74539639311557e-06,
      "loss": 0.0002,
      "step": 1608
    },
    {
      "epoch": 0.025476194246085153,
      "grad_norm": 0.18101057410240173,
      "learning_rate": 9.74523805753915e-06,
      "loss": 0.1975,
      "step": 1609
    },
    {
      "epoch": 0.02549202780372722,
      "grad_norm": 0.2406495362520218,
      "learning_rate": 9.745079721962729e-06,
      "loss": 0.0654,
      "step": 1610
    },
    {
      "epoch": 0.025507861361369285,
      "grad_norm": 0.19783924520015717,
      "learning_rate": 9.744921386386308e-06,
      "loss": 0.9179,
      "step": 1611
    },
    {
      "epoch": 0.025523694919011353,
      "grad_norm": 0.015601448714733124,
      "learning_rate": 9.744763050809887e-06,
      "loss": 0.0005,
      "step": 1612
    },
    {
      "epoch": 0.02553952847665342,
      "grad_norm": 0.1888335645198822,
      "learning_rate": 9.744604715233466e-06,
      "loss": 0.1051,
      "step": 1613
    },
    {
      "epoch": 0.025555362034295485,
      "grad_norm": 0.2067771852016449,
      "learning_rate": 9.744446379657045e-06,
      "loss": 0.128,
      "step": 1614
    },
    {
      "epoch": 0.025571195591937552,
      "grad_norm": 0.3062668740749359,
      "learning_rate": 9.744288044080626e-06,
      "loss": 0.0483,
      "step": 1615
    },
    {
      "epoch": 0.02558702914957962,
      "grad_norm": 0.0035284063778817654,
      "learning_rate": 9.744129708504203e-06,
      "loss": 0.0002,
      "step": 1616
    },
    {
      "epoch": 0.025602862707221685,
      "grad_norm": 0.00713273836299777,
      "learning_rate": 9.743971372927784e-06,
      "loss": 0.0004,
      "step": 1617
    },
    {
      "epoch": 0.025618696264863752,
      "grad_norm": 0.16164730489253998,
      "learning_rate": 9.743813037351363e-06,
      "loss": 0.1218,
      "step": 1618
    },
    {
      "epoch": 0.02563452982250582,
      "grad_norm": 6.31781731499359e-05,
      "learning_rate": 9.743654701774942e-06,
      "loss": 0.0,
      "step": 1619
    },
    {
      "epoch": 0.025650363380147884,
      "grad_norm": 0.009808164089918137,
      "learning_rate": 9.743496366198521e-06,
      "loss": 0.0007,
      "step": 1620
    },
    {
      "epoch": 0.025666196937789952,
      "grad_norm": 0.0003079346497543156,
      "learning_rate": 9.743338030622102e-06,
      "loss": 0.0,
      "step": 1621
    },
    {
      "epoch": 0.02568203049543202,
      "grad_norm": 0.23826347291469574,
      "learning_rate": 9.74317969504568e-06,
      "loss": 0.2767,
      "step": 1622
    },
    {
      "epoch": 0.025697864053074084,
      "grad_norm": 0.0074169267900288105,
      "learning_rate": 9.74302135946926e-06,
      "loss": 0.0004,
      "step": 1623
    },
    {
      "epoch": 0.025713697610716152,
      "grad_norm": 0.08661199361085892,
      "learning_rate": 9.74286302389284e-06,
      "loss": 0.0043,
      "step": 1624
    },
    {
      "epoch": 0.02572953116835822,
      "grad_norm": 0.14018675684928894,
      "learning_rate": 9.742704688316418e-06,
      "loss": 0.0955,
      "step": 1625
    },
    {
      "epoch": 0.025745364726000284,
      "grad_norm": 0.11986232548952103,
      "learning_rate": 9.742546352739998e-06,
      "loss": 0.1191,
      "step": 1626
    },
    {
      "epoch": 0.02576119828364235,
      "grad_norm": 0.009281975217163563,
      "learning_rate": 9.742388017163578e-06,
      "loss": 0.0006,
      "step": 1627
    },
    {
      "epoch": 0.02577703184128442,
      "grad_norm": 0.002904642838984728,
      "learning_rate": 9.742229681587156e-06,
      "loss": 0.0002,
      "step": 1628
    },
    {
      "epoch": 0.025792865398926484,
      "grad_norm": 0.2934626638889313,
      "learning_rate": 9.742071346010736e-06,
      "loss": 1.0049,
      "step": 1629
    },
    {
      "epoch": 0.02580869895656855,
      "grad_norm": 0.00013376024435274303,
      "learning_rate": 9.741913010434316e-06,
      "loss": 0.0,
      "step": 1630
    },
    {
      "epoch": 0.02582453251421062,
      "grad_norm": 0.17596492171287537,
      "learning_rate": 9.741754674857895e-06,
      "loss": 0.0082,
      "step": 1631
    },
    {
      "epoch": 0.025840366071852684,
      "grad_norm": 0.1972682923078537,
      "learning_rate": 9.741596339281474e-06,
      "loss": 0.8234,
      "step": 1632
    },
    {
      "epoch": 0.02585619962949475,
      "grad_norm": 0.2285757064819336,
      "learning_rate": 9.741438003705054e-06,
      "loss": 0.136,
      "step": 1633
    },
    {
      "epoch": 0.02587203318713682,
      "grad_norm": 0.17983731627464294,
      "learning_rate": 9.741279668128632e-06,
      "loss": 0.1824,
      "step": 1634
    },
    {
      "epoch": 0.025887866744778883,
      "grad_norm": 0.011484883725643158,
      "learning_rate": 9.741121332552213e-06,
      "loss": 0.0005,
      "step": 1635
    },
    {
      "epoch": 0.02590370030242095,
      "grad_norm": 0.2855910062789917,
      "learning_rate": 9.740962996975792e-06,
      "loss": 0.7997,
      "step": 1636
    },
    {
      "epoch": 0.02591953386006302,
      "grad_norm": 0.2337479293346405,
      "learning_rate": 9.74080466139937e-06,
      "loss": 0.1531,
      "step": 1637
    },
    {
      "epoch": 0.025935367417705083,
      "grad_norm": 0.02431819774210453,
      "learning_rate": 9.74064632582295e-06,
      "loss": 0.0034,
      "step": 1638
    },
    {
      "epoch": 0.02595120097534715,
      "grad_norm": 0.0002733107830863446,
      "learning_rate": 9.740487990246529e-06,
      "loss": 0.0,
      "step": 1639
    },
    {
      "epoch": 0.02596703453298922,
      "grad_norm": 0.012320132926106453,
      "learning_rate": 9.740329654670108e-06,
      "loss": 0.0009,
      "step": 1640
    },
    {
      "epoch": 0.025982868090631283,
      "grad_norm": 0.0006595695740543306,
      "learning_rate": 9.740171319093687e-06,
      "loss": 0.0,
      "step": 1641
    },
    {
      "epoch": 0.02599870164827335,
      "grad_norm": 0.030271273106336594,
      "learning_rate": 9.740012983517268e-06,
      "loss": 0.0008,
      "step": 1642
    },
    {
      "epoch": 0.02601453520591542,
      "grad_norm": 0.34061190485954285,
      "learning_rate": 9.739854647940847e-06,
      "loss": 0.2544,
      "step": 1643
    },
    {
      "epoch": 0.026030368763557483,
      "grad_norm": 0.3298720717430115,
      "learning_rate": 9.739696312364426e-06,
      "loss": 0.4256,
      "step": 1644
    },
    {
      "epoch": 0.02604620232119955,
      "grad_norm": 0.0018171245465055108,
      "learning_rate": 9.739537976788005e-06,
      "loss": 0.0001,
      "step": 1645
    },
    {
      "epoch": 0.02606203587884162,
      "grad_norm": 0.029819509014487267,
      "learning_rate": 9.739379641211584e-06,
      "loss": 0.002,
      "step": 1646
    },
    {
      "epoch": 0.026077869436483683,
      "grad_norm": 0.2260809689760208,
      "learning_rate": 9.739221305635163e-06,
      "loss": 0.1438,
      "step": 1647
    },
    {
      "epoch": 0.02609370299412575,
      "grad_norm": 0.2596101760864258,
      "learning_rate": 9.739062970058744e-06,
      "loss": 0.0745,
      "step": 1648
    },
    {
      "epoch": 0.026109536551767818,
      "grad_norm": 0.235568568110466,
      "learning_rate": 9.738904634482323e-06,
      "loss": 0.0519,
      "step": 1649
    },
    {
      "epoch": 0.026125370109409882,
      "grad_norm": 0.00027302480884827673,
      "learning_rate": 9.738746298905902e-06,
      "loss": 0.0,
      "step": 1650
    },
    {
      "epoch": 0.02614120366705195,
      "grad_norm": 0.3305518925189972,
      "learning_rate": 9.738587963329481e-06,
      "loss": 0.73,
      "step": 1651
    },
    {
      "epoch": 0.026157037224694018,
      "grad_norm": 0.23432451486587524,
      "learning_rate": 9.73842962775306e-06,
      "loss": 0.2432,
      "step": 1652
    },
    {
      "epoch": 0.026172870782336082,
      "grad_norm": 0.3157850205898285,
      "learning_rate": 9.73827129217664e-06,
      "loss": 0.1978,
      "step": 1653
    },
    {
      "epoch": 0.02618870433997815,
      "grad_norm": 0.14137113094329834,
      "learning_rate": 9.73811295660022e-06,
      "loss": 0.5543,
      "step": 1654
    },
    {
      "epoch": 0.026204537897620218,
      "grad_norm": 0.0001804707571864128,
      "learning_rate": 9.7379546210238e-06,
      "loss": 0.0,
      "step": 1655
    },
    {
      "epoch": 0.026220371455262282,
      "grad_norm": 0.24603642523288727,
      "learning_rate": 9.737796285447378e-06,
      "loss": 0.1562,
      "step": 1656
    },
    {
      "epoch": 0.02623620501290435,
      "grad_norm": 0.19683313369750977,
      "learning_rate": 9.737637949870957e-06,
      "loss": 0.0415,
      "step": 1657
    },
    {
      "epoch": 0.026252038570546418,
      "grad_norm": 0.009363292716443539,
      "learning_rate": 9.737479614294537e-06,
      "loss": 0.0004,
      "step": 1658
    },
    {
      "epoch": 0.026267872128188482,
      "grad_norm": 0.4620562195777893,
      "learning_rate": 9.737321278718116e-06,
      "loss": 0.169,
      "step": 1659
    },
    {
      "epoch": 0.02628370568583055,
      "grad_norm": 0.2489183396100998,
      "learning_rate": 9.737162943141696e-06,
      "loss": 0.0161,
      "step": 1660
    },
    {
      "epoch": 0.026299539243472617,
      "grad_norm": 0.0003294708440080285,
      "learning_rate": 9.737004607565275e-06,
      "loss": 0.0,
      "step": 1661
    },
    {
      "epoch": 0.02631537280111468,
      "grad_norm": 0.22158820927143097,
      "learning_rate": 9.736846271988853e-06,
      "loss": 0.1694,
      "step": 1662
    },
    {
      "epoch": 0.02633120635875675,
      "grad_norm": 0.15092451870441437,
      "learning_rate": 9.736687936412434e-06,
      "loss": 0.0599,
      "step": 1663
    },
    {
      "epoch": 0.026347039916398817,
      "grad_norm": 1.1725902557373047,
      "learning_rate": 9.736529600836013e-06,
      "loss": 0.1389,
      "step": 1664
    },
    {
      "epoch": 0.02636287347404088,
      "grad_norm": 0.283894807100296,
      "learning_rate": 9.736371265259592e-06,
      "loss": 0.1471,
      "step": 1665
    },
    {
      "epoch": 0.02637870703168295,
      "grad_norm": 0.1816900074481964,
      "learning_rate": 9.736212929683171e-06,
      "loss": 0.0771,
      "step": 1666
    },
    {
      "epoch": 0.026394540589325017,
      "grad_norm": 0.14643734693527222,
      "learning_rate": 9.73605459410675e-06,
      "loss": 0.1117,
      "step": 1667
    },
    {
      "epoch": 0.02641037414696708,
      "grad_norm": 0.34100645780563354,
      "learning_rate": 9.735896258530329e-06,
      "loss": 0.0512,
      "step": 1668
    },
    {
      "epoch": 0.02642620770460915,
      "grad_norm": 0.15832722187042236,
      "learning_rate": 9.73573792295391e-06,
      "loss": 0.5531,
      "step": 1669
    },
    {
      "epoch": 0.026442041262251217,
      "grad_norm": 0.0004038835468236357,
      "learning_rate": 9.735579587377489e-06,
      "loss": 0.0,
      "step": 1670
    },
    {
      "epoch": 0.02645787481989328,
      "grad_norm": 0.003941538278013468,
      "learning_rate": 9.735421251801068e-06,
      "loss": 0.0002,
      "step": 1671
    },
    {
      "epoch": 0.02647370837753535,
      "grad_norm": 0.24217328429222107,
      "learning_rate": 9.735262916224647e-06,
      "loss": 0.0693,
      "step": 1672
    },
    {
      "epoch": 0.026489541935177417,
      "grad_norm": 0.33422669768333435,
      "learning_rate": 9.735104580648226e-06,
      "loss": 0.152,
      "step": 1673
    },
    {
      "epoch": 0.02650537549281948,
      "grad_norm": 0.22123713791370392,
      "learning_rate": 9.734946245071805e-06,
      "loss": 0.0036,
      "step": 1674
    },
    {
      "epoch": 0.02652120905046155,
      "grad_norm": 0.3639938533306122,
      "learning_rate": 9.734787909495386e-06,
      "loss": 0.4668,
      "step": 1675
    },
    {
      "epoch": 0.026537042608103616,
      "grad_norm": 0.005679260939359665,
      "learning_rate": 9.734629573918965e-06,
      "loss": 0.0004,
      "step": 1676
    },
    {
      "epoch": 0.02655287616574568,
      "grad_norm": 0.19630149006843567,
      "learning_rate": 9.734471238342544e-06,
      "loss": 0.0678,
      "step": 1677
    },
    {
      "epoch": 0.02656870972338775,
      "grad_norm": 0.18312574923038483,
      "learning_rate": 9.734312902766123e-06,
      "loss": 0.2015,
      "step": 1678
    },
    {
      "epoch": 0.026584543281029816,
      "grad_norm": 0.3063490688800812,
      "learning_rate": 9.734154567189702e-06,
      "loss": 0.1274,
      "step": 1679
    },
    {
      "epoch": 0.02660037683867188,
      "grad_norm": 0.39257538318634033,
      "learning_rate": 9.733996231613281e-06,
      "loss": 0.1218,
      "step": 1680
    },
    {
      "epoch": 0.026616210396313948,
      "grad_norm": 0.18338806927204132,
      "learning_rate": 9.733837896036862e-06,
      "loss": 0.0077,
      "step": 1681
    },
    {
      "epoch": 0.026632043953956016,
      "grad_norm": 0.20010991394519806,
      "learning_rate": 9.733679560460441e-06,
      "loss": 0.0987,
      "step": 1682
    },
    {
      "epoch": 0.02664787751159808,
      "grad_norm": 0.12946628034114838,
      "learning_rate": 9.73352122488402e-06,
      "loss": 0.1408,
      "step": 1683
    },
    {
      "epoch": 0.026663711069240148,
      "grad_norm": 0.19858968257904053,
      "learning_rate": 9.7333628893076e-06,
      "loss": 0.0388,
      "step": 1684
    },
    {
      "epoch": 0.026679544626882216,
      "grad_norm": 0.1882573515176773,
      "learning_rate": 9.733204553731178e-06,
      "loss": 0.2596,
      "step": 1685
    },
    {
      "epoch": 0.02669537818452428,
      "grad_norm": 0.28013646602630615,
      "learning_rate": 9.733046218154758e-06,
      "loss": 0.1237,
      "step": 1686
    },
    {
      "epoch": 0.026711211742166348,
      "grad_norm": 0.00032462383387610316,
      "learning_rate": 9.732887882578337e-06,
      "loss": 0.0,
      "step": 1687
    },
    {
      "epoch": 0.026727045299808416,
      "grad_norm": 0.22890393435955048,
      "learning_rate": 9.732729547001917e-06,
      "loss": 0.5819,
      "step": 1688
    },
    {
      "epoch": 0.02674287885745048,
      "grad_norm": 0.20139360427856445,
      "learning_rate": 9.732571211425495e-06,
      "loss": 0.0939,
      "step": 1689
    },
    {
      "epoch": 0.026758712415092548,
      "grad_norm": 0.004329651594161987,
      "learning_rate": 9.732412875849076e-06,
      "loss": 0.0003,
      "step": 1690
    },
    {
      "epoch": 0.026774545972734615,
      "grad_norm": 0.10690625756978989,
      "learning_rate": 9.732254540272655e-06,
      "loss": 0.0482,
      "step": 1691
    },
    {
      "epoch": 0.02679037953037668,
      "grad_norm": 0.0002562545705586672,
      "learning_rate": 9.732096204696234e-06,
      "loss": 0.0,
      "step": 1692
    },
    {
      "epoch": 0.026806213088018747,
      "grad_norm": 0.5846765041351318,
      "learning_rate": 9.731937869119813e-06,
      "loss": 0.1824,
      "step": 1693
    },
    {
      "epoch": 0.026822046645660815,
      "grad_norm": 0.013707845471799374,
      "learning_rate": 9.731779533543394e-06,
      "loss": 0.0012,
      "step": 1694
    },
    {
      "epoch": 0.02683788020330288,
      "grad_norm": 0.2111404538154602,
      "learning_rate": 9.731621197966971e-06,
      "loss": 0.1734,
      "step": 1695
    },
    {
      "epoch": 0.026853713760944947,
      "grad_norm": 0.4286491274833679,
      "learning_rate": 9.731462862390552e-06,
      "loss": 0.1224,
      "step": 1696
    },
    {
      "epoch": 0.026869547318587015,
      "grad_norm": 0.3043610155582428,
      "learning_rate": 9.73130452681413e-06,
      "loss": 0.2159,
      "step": 1697
    },
    {
      "epoch": 0.02688538087622908,
      "grad_norm": 1.0074864625930786,
      "learning_rate": 9.73114619123771e-06,
      "loss": 0.4689,
      "step": 1698
    },
    {
      "epoch": 0.026901214433871147,
      "grad_norm": 0.1556234359741211,
      "learning_rate": 9.730987855661289e-06,
      "loss": 0.2491,
      "step": 1699
    },
    {
      "epoch": 0.026917047991513215,
      "grad_norm": 0.04158613458275795,
      "learning_rate": 9.73082952008487e-06,
      "loss": 0.0103,
      "step": 1700
    },
    {
      "epoch": 0.02693288154915528,
      "grad_norm": 0.47957244515419006,
      "learning_rate": 9.730671184508447e-06,
      "loss": 0.0503,
      "step": 1701
    },
    {
      "epoch": 0.026948715106797347,
      "grad_norm": 0.22570914030075073,
      "learning_rate": 9.730512848932028e-06,
      "loss": 0.2255,
      "step": 1702
    },
    {
      "epoch": 0.026964548664439415,
      "grad_norm": 0.2550075352191925,
      "learning_rate": 9.730354513355607e-06,
      "loss": 0.1509,
      "step": 1703
    },
    {
      "epoch": 0.02698038222208148,
      "grad_norm": 0.0035339058376848698,
      "learning_rate": 9.730196177779186e-06,
      "loss": 0.0003,
      "step": 1704
    },
    {
      "epoch": 0.026996215779723547,
      "grad_norm": 0.31917592883110046,
      "learning_rate": 9.730037842202765e-06,
      "loss": 0.1768,
      "step": 1705
    },
    {
      "epoch": 0.027012049337365614,
      "grad_norm": 0.016109906136989594,
      "learning_rate": 9.729879506626346e-06,
      "loss": 0.0022,
      "step": 1706
    },
    {
      "epoch": 0.02702788289500768,
      "grad_norm": 0.10456658154726028,
      "learning_rate": 9.729721171049923e-06,
      "loss": 0.0228,
      "step": 1707
    },
    {
      "epoch": 0.027043716452649746,
      "grad_norm": 0.5601552724838257,
      "learning_rate": 9.729562835473504e-06,
      "loss": 0.2595,
      "step": 1708
    },
    {
      "epoch": 0.027059550010291814,
      "grad_norm": 0.09775695204734802,
      "learning_rate": 9.729404499897083e-06,
      "loss": 0.0756,
      "step": 1709
    },
    {
      "epoch": 0.02707538356793388,
      "grad_norm": 0.2509939968585968,
      "learning_rate": 9.729246164320662e-06,
      "loss": 0.5409,
      "step": 1710
    },
    {
      "epoch": 0.027091217125575946,
      "grad_norm": 0.16586834192276,
      "learning_rate": 9.729087828744241e-06,
      "loss": 0.4152,
      "step": 1711
    },
    {
      "epoch": 0.02710705068321801,
      "grad_norm": 0.2365867793560028,
      "learning_rate": 9.72892949316782e-06,
      "loss": 0.1563,
      "step": 1712
    },
    {
      "epoch": 0.02712288424086008,
      "grad_norm": 2.041818857192993,
      "learning_rate": 9.7287711575914e-06,
      "loss": 0.1371,
      "step": 1713
    },
    {
      "epoch": 0.027138717798502146,
      "grad_norm": 0.4363483786582947,
      "learning_rate": 9.728612822014979e-06,
      "loss": 0.4134,
      "step": 1714
    },
    {
      "epoch": 0.02715455135614421,
      "grad_norm": 0.26025447249412537,
      "learning_rate": 9.72845448643856e-06,
      "loss": 0.1679,
      "step": 1715
    },
    {
      "epoch": 0.027170384913786278,
      "grad_norm": 0.476954847574234,
      "learning_rate": 9.728296150862138e-06,
      "loss": 0.3759,
      "step": 1716
    },
    {
      "epoch": 0.027186218471428346,
      "grad_norm": 0.10497832298278809,
      "learning_rate": 9.728137815285717e-06,
      "loss": 0.0028,
      "step": 1717
    },
    {
      "epoch": 0.02720205202907041,
      "grad_norm": 0.21470847725868225,
      "learning_rate": 9.727979479709297e-06,
      "loss": 0.0666,
      "step": 1718
    },
    {
      "epoch": 0.027217885586712478,
      "grad_norm": 0.0995163843035698,
      "learning_rate": 9.727821144132876e-06,
      "loss": 0.0459,
      "step": 1719
    },
    {
      "epoch": 0.027233719144354546,
      "grad_norm": 0.18354062736034393,
      "learning_rate": 9.727662808556455e-06,
      "loss": 0.4439,
      "step": 1720
    },
    {
      "epoch": 0.02724955270199661,
      "grad_norm": 0.09641716629266739,
      "learning_rate": 9.727504472980035e-06,
      "loss": 0.0565,
      "step": 1721
    },
    {
      "epoch": 0.027265386259638678,
      "grad_norm": 0.0014750693226233125,
      "learning_rate": 9.727346137403615e-06,
      "loss": 0.0,
      "step": 1722
    },
    {
      "epoch": 0.027281219817280745,
      "grad_norm": 0.1947847455739975,
      "learning_rate": 9.727187801827194e-06,
      "loss": 0.4965,
      "step": 1723
    },
    {
      "epoch": 0.02729705337492281,
      "grad_norm": 0.27710992097854614,
      "learning_rate": 9.727029466250773e-06,
      "loss": 0.7872,
      "step": 1724
    },
    {
      "epoch": 0.027312886932564878,
      "grad_norm": 0.15671406686306,
      "learning_rate": 9.726871130674352e-06,
      "loss": 0.4057,
      "step": 1725
    },
    {
      "epoch": 0.027328720490206945,
      "grad_norm": 0.006357854697853327,
      "learning_rate": 9.726712795097931e-06,
      "loss": 0.0005,
      "step": 1726
    },
    {
      "epoch": 0.02734455404784901,
      "grad_norm": 0.14544418454170227,
      "learning_rate": 9.726554459521512e-06,
      "loss": 0.0832,
      "step": 1727
    },
    {
      "epoch": 0.027360387605491077,
      "grad_norm": 0.1072259470820427,
      "learning_rate": 9.72639612394509e-06,
      "loss": 0.0616,
      "step": 1728
    },
    {
      "epoch": 0.027376221163133145,
      "grad_norm": 0.0860704854130745,
      "learning_rate": 9.72623778836867e-06,
      "loss": 0.0417,
      "step": 1729
    },
    {
      "epoch": 0.02739205472077521,
      "grad_norm": 0.26416435837745667,
      "learning_rate": 9.726079452792249e-06,
      "loss": 0.7758,
      "step": 1730
    },
    {
      "epoch": 0.027407888278417277,
      "grad_norm": 0.4183577299118042,
      "learning_rate": 9.725921117215828e-06,
      "loss": 0.4285,
      "step": 1731
    },
    {
      "epoch": 0.027423721836059345,
      "grad_norm": 0.005830325186252594,
      "learning_rate": 9.725762781639407e-06,
      "loss": 0.0004,
      "step": 1732
    },
    {
      "epoch": 0.02743955539370141,
      "grad_norm": 0.14452984929084778,
      "learning_rate": 9.725604446062986e-06,
      "loss": 0.0703,
      "step": 1733
    },
    {
      "epoch": 0.027455388951343477,
      "grad_norm": 0.34863385558128357,
      "learning_rate": 9.725446110486565e-06,
      "loss": 0.0671,
      "step": 1734
    },
    {
      "epoch": 0.027471222508985545,
      "grad_norm": 0.3528331518173218,
      "learning_rate": 9.725287774910144e-06,
      "loss": 0.0781,
      "step": 1735
    },
    {
      "epoch": 0.02748705606662761,
      "grad_norm": 0.0005517816753126681,
      "learning_rate": 9.725129439333725e-06,
      "loss": 0.0,
      "step": 1736
    },
    {
      "epoch": 0.027502889624269677,
      "grad_norm": 0.0038614319637417793,
      "learning_rate": 9.724971103757304e-06,
      "loss": 0.0002,
      "step": 1737
    },
    {
      "epoch": 0.027518723181911744,
      "grad_norm": 0.029802845790982246,
      "learning_rate": 9.724812768180883e-06,
      "loss": 0.0043,
      "step": 1738
    },
    {
      "epoch": 0.02753455673955381,
      "grad_norm": 0.10246898978948593,
      "learning_rate": 9.724654432604462e-06,
      "loss": 0.0511,
      "step": 1739
    },
    {
      "epoch": 0.027550390297195877,
      "grad_norm": 0.4894116222858429,
      "learning_rate": 9.724496097028041e-06,
      "loss": 0.1758,
      "step": 1740
    },
    {
      "epoch": 0.027566223854837944,
      "grad_norm": 0.1039317175745964,
      "learning_rate": 9.72433776145162e-06,
      "loss": 0.0065,
      "step": 1741
    },
    {
      "epoch": 0.02758205741248001,
      "grad_norm": 0.012840159237384796,
      "learning_rate": 9.724179425875201e-06,
      "loss": 0.0004,
      "step": 1742
    },
    {
      "epoch": 0.027597890970122076,
      "grad_norm": 0.3250957727432251,
      "learning_rate": 9.72402109029878e-06,
      "loss": 0.4813,
      "step": 1743
    },
    {
      "epoch": 0.027613724527764144,
      "grad_norm": 0.19702307879924774,
      "learning_rate": 9.72386275472236e-06,
      "loss": 0.0806,
      "step": 1744
    },
    {
      "epoch": 0.02762955808540621,
      "grad_norm": 0.1369095891714096,
      "learning_rate": 9.723704419145938e-06,
      "loss": 0.1501,
      "step": 1745
    },
    {
      "epoch": 0.027645391643048276,
      "grad_norm": 0.01341831311583519,
      "learning_rate": 9.723546083569518e-06,
      "loss": 0.0012,
      "step": 1746
    },
    {
      "epoch": 0.027661225200690344,
      "grad_norm": 0.010638189502060413,
      "learning_rate": 9.723387747993097e-06,
      "loss": 0.0008,
      "step": 1747
    },
    {
      "epoch": 0.027677058758332408,
      "grad_norm": 0.1203567385673523,
      "learning_rate": 9.723229412416677e-06,
      "loss": 0.0845,
      "step": 1748
    },
    {
      "epoch": 0.027692892315974476,
      "grad_norm": 0.20380254089832306,
      "learning_rate": 9.723071076840257e-06,
      "loss": 0.4204,
      "step": 1749
    },
    {
      "epoch": 0.027708725873616544,
      "grad_norm": 0.5905002355575562,
      "learning_rate": 9.722912741263836e-06,
      "loss": 0.3858,
      "step": 1750
    },
    {
      "epoch": 0.027724559431258608,
      "grad_norm": 0.15631777048110962,
      "learning_rate": 9.722754405687415e-06,
      "loss": 0.4527,
      "step": 1751
    },
    {
      "epoch": 0.027740392988900676,
      "grad_norm": 0.01443876326084137,
      "learning_rate": 9.722596070110994e-06,
      "loss": 0.0011,
      "step": 1752
    },
    {
      "epoch": 0.027756226546542744,
      "grad_norm": 0.23903560638427734,
      "learning_rate": 9.722437734534573e-06,
      "loss": 0.5353,
      "step": 1753
    },
    {
      "epoch": 0.027772060104184808,
      "grad_norm": 0.5189651250839233,
      "learning_rate": 9.722279398958154e-06,
      "loss": 0.2303,
      "step": 1754
    },
    {
      "epoch": 0.027787893661826876,
      "grad_norm": 0.18743892014026642,
      "learning_rate": 9.722121063381733e-06,
      "loss": 0.2847,
      "step": 1755
    },
    {
      "epoch": 0.027803727219468943,
      "grad_norm": 0.00011379765055608004,
      "learning_rate": 9.721962727805312e-06,
      "loss": 0.0,
      "step": 1756
    },
    {
      "epoch": 0.027819560777111008,
      "grad_norm": 0.01898748241364956,
      "learning_rate": 9.72180439222889e-06,
      "loss": 0.0015,
      "step": 1757
    },
    {
      "epoch": 0.027835394334753075,
      "grad_norm": 0.15553855895996094,
      "learning_rate": 9.72164605665247e-06,
      "loss": 0.1045,
      "step": 1758
    },
    {
      "epoch": 0.027851227892395143,
      "grad_norm": 0.0002603870234452188,
      "learning_rate": 9.721487721076049e-06,
      "loss": 0.0,
      "step": 1759
    },
    {
      "epoch": 0.027867061450037207,
      "grad_norm": 0.17590487003326416,
      "learning_rate": 9.721329385499628e-06,
      "loss": 0.5003,
      "step": 1760
    },
    {
      "epoch": 0.027882895007679275,
      "grad_norm": 0.13364583253860474,
      "learning_rate": 9.721171049923209e-06,
      "loss": 0.2538,
      "step": 1761
    },
    {
      "epoch": 0.027898728565321343,
      "grad_norm": 0.2582436203956604,
      "learning_rate": 9.721012714346786e-06,
      "loss": 0.2309,
      "step": 1762
    },
    {
      "epoch": 0.027914562122963407,
      "grad_norm": 0.16229774057865143,
      "learning_rate": 9.720854378770367e-06,
      "loss": 0.0993,
      "step": 1763
    },
    {
      "epoch": 0.027930395680605475,
      "grad_norm": 0.00016677513485774398,
      "learning_rate": 9.720696043193946e-06,
      "loss": 0.0,
      "step": 1764
    },
    {
      "epoch": 0.027946229238247543,
      "grad_norm": 0.8705059885978699,
      "learning_rate": 9.720537707617525e-06,
      "loss": 0.6949,
      "step": 1765
    },
    {
      "epoch": 0.027962062795889607,
      "grad_norm": 0.2129056602716446,
      "learning_rate": 9.720379372041104e-06,
      "loss": 0.3213,
      "step": 1766
    },
    {
      "epoch": 0.027977896353531675,
      "grad_norm": 0.10007579624652863,
      "learning_rate": 9.720221036464685e-06,
      "loss": 0.005,
      "step": 1767
    },
    {
      "epoch": 0.027993729911173743,
      "grad_norm": 0.00013340922305360436,
      "learning_rate": 9.720062700888262e-06,
      "loss": 0.0,
      "step": 1768
    },
    {
      "epoch": 0.028009563468815807,
      "grad_norm": 0.021365713328123093,
      "learning_rate": 9.719904365311843e-06,
      "loss": 0.0016,
      "step": 1769
    },
    {
      "epoch": 0.028025397026457875,
      "grad_norm": 0.0005519484402611852,
      "learning_rate": 9.719746029735422e-06,
      "loss": 0.0,
      "step": 1770
    },
    {
      "epoch": 0.028041230584099942,
      "grad_norm": 0.6245179176330566,
      "learning_rate": 9.719587694159001e-06,
      "loss": 0.2527,
      "step": 1771
    },
    {
      "epoch": 0.028057064141742007,
      "grad_norm": 0.00019654126663226634,
      "learning_rate": 9.71942935858258e-06,
      "loss": 0.0,
      "step": 1772
    },
    {
      "epoch": 0.028072897699384074,
      "grad_norm": 0.00432869466021657,
      "learning_rate": 9.719271023006161e-06,
      "loss": 0.0002,
      "step": 1773
    },
    {
      "epoch": 0.028088731257026142,
      "grad_norm": 0.23214508593082428,
      "learning_rate": 9.719112687429739e-06,
      "loss": 0.2041,
      "step": 1774
    },
    {
      "epoch": 0.028104564814668206,
      "grad_norm": 0.18223083019256592,
      "learning_rate": 9.71895435185332e-06,
      "loss": 0.0835,
      "step": 1775
    },
    {
      "epoch": 0.028120398372310274,
      "grad_norm": 0.29518285393714905,
      "learning_rate": 9.718796016276898e-06,
      "loss": 0.1014,
      "step": 1776
    },
    {
      "epoch": 0.028136231929952342,
      "grad_norm": 0.3085813522338867,
      "learning_rate": 9.718637680700478e-06,
      "loss": 0.0787,
      "step": 1777
    },
    {
      "epoch": 0.028152065487594406,
      "grad_norm": 0.3057204484939575,
      "learning_rate": 9.718479345124057e-06,
      "loss": 0.5758,
      "step": 1778
    },
    {
      "epoch": 0.028167899045236474,
      "grad_norm": 0.0005428005242720246,
      "learning_rate": 9.718321009547637e-06,
      "loss": 0.0,
      "step": 1779
    },
    {
      "epoch": 0.028183732602878542,
      "grad_norm": 0.002352245384827256,
      "learning_rate": 9.718162673971215e-06,
      "loss": 0.0,
      "step": 1780
    },
    {
      "epoch": 0.028199566160520606,
      "grad_norm": 0.36501121520996094,
      "learning_rate": 9.718004338394794e-06,
      "loss": 0.2635,
      "step": 1781
    },
    {
      "epoch": 0.028215399718162674,
      "grad_norm": 0.2001630961894989,
      "learning_rate": 9.717846002818375e-06,
      "loss": 0.0744,
      "step": 1782
    },
    {
      "epoch": 0.02823123327580474,
      "grad_norm": 0.03143000230193138,
      "learning_rate": 9.717687667241954e-06,
      "loss": 0.0026,
      "step": 1783
    },
    {
      "epoch": 0.028247066833446806,
      "grad_norm": 0.1881580352783203,
      "learning_rate": 9.717529331665533e-06,
      "loss": 0.122,
      "step": 1784
    },
    {
      "epoch": 0.028262900391088874,
      "grad_norm": 0.030267536640167236,
      "learning_rate": 9.717370996089112e-06,
      "loss": 0.0026,
      "step": 1785
    },
    {
      "epoch": 0.02827873394873094,
      "grad_norm": 0.12837840616703033,
      "learning_rate": 9.717212660512691e-06,
      "loss": 0.0642,
      "step": 1786
    },
    {
      "epoch": 0.028294567506373006,
      "grad_norm": 0.15853773057460785,
      "learning_rate": 9.71705432493627e-06,
      "loss": 0.0236,
      "step": 1787
    },
    {
      "epoch": 0.028310401064015073,
      "grad_norm": 0.3098299205303192,
      "learning_rate": 9.71689598935985e-06,
      "loss": 0.0756,
      "step": 1788
    },
    {
      "epoch": 0.02832623462165714,
      "grad_norm": 0.16242116689682007,
      "learning_rate": 9.71673765378343e-06,
      "loss": 0.1712,
      "step": 1789
    },
    {
      "epoch": 0.028342068179299205,
      "grad_norm": 0.010127837769687176,
      "learning_rate": 9.716579318207009e-06,
      "loss": 0.0007,
      "step": 1790
    },
    {
      "epoch": 0.028357901736941273,
      "grad_norm": 0.19622431695461273,
      "learning_rate": 9.716420982630588e-06,
      "loss": 0.0903,
      "step": 1791
    },
    {
      "epoch": 0.02837373529458334,
      "grad_norm": 0.00032852301956154406,
      "learning_rate": 9.716262647054167e-06,
      "loss": 0.0,
      "step": 1792
    },
    {
      "epoch": 0.028389568852225405,
      "grad_norm": 0.21056868135929108,
      "learning_rate": 9.716104311477746e-06,
      "loss": 0.0942,
      "step": 1793
    },
    {
      "epoch": 0.028405402409867473,
      "grad_norm": 0.1483861654996872,
      "learning_rate": 9.715945975901327e-06,
      "loss": 0.124,
      "step": 1794
    },
    {
      "epoch": 0.02842123596750954,
      "grad_norm": 0.6197649836540222,
      "learning_rate": 9.715787640324906e-06,
      "loss": 0.094,
      "step": 1795
    },
    {
      "epoch": 0.028437069525151605,
      "grad_norm": 0.09924707561731339,
      "learning_rate": 9.715629304748485e-06,
      "loss": 0.0501,
      "step": 1796
    },
    {
      "epoch": 0.028452903082793673,
      "grad_norm": 0.0025045531801879406,
      "learning_rate": 9.715470969172064e-06,
      "loss": 0.0001,
      "step": 1797
    },
    {
      "epoch": 0.02846873664043574,
      "grad_norm": 0.22770939767360687,
      "learning_rate": 9.715312633595643e-06,
      "loss": 0.3252,
      "step": 1798
    },
    {
      "epoch": 0.028484570198077805,
      "grad_norm": 0.004143220372498035,
      "learning_rate": 9.715154298019222e-06,
      "loss": 0.0002,
      "step": 1799
    },
    {
      "epoch": 0.028500403755719873,
      "grad_norm": 0.3029457628726959,
      "learning_rate": 9.714995962442803e-06,
      "loss": 0.3283,
      "step": 1800
    },
    {
      "epoch": 0.02851623731336194,
      "grad_norm": 0.013250058516860008,
      "learning_rate": 9.71483762686638e-06,
      "loss": 0.0009,
      "step": 1801
    },
    {
      "epoch": 0.028532070871004005,
      "grad_norm": 0.2365933358669281,
      "learning_rate": 9.714679291289961e-06,
      "loss": 0.0949,
      "step": 1802
    },
    {
      "epoch": 0.028547904428646072,
      "grad_norm": 0.14798064529895782,
      "learning_rate": 9.71452095571354e-06,
      "loss": 0.0515,
      "step": 1803
    },
    {
      "epoch": 0.02856373798628814,
      "grad_norm": 0.2742673456668854,
      "learning_rate": 9.71436262013712e-06,
      "loss": 0.9122,
      "step": 1804
    },
    {
      "epoch": 0.028579571543930204,
      "grad_norm": 0.2885439395904541,
      "learning_rate": 9.714204284560699e-06,
      "loss": 0.2152,
      "step": 1805
    },
    {
      "epoch": 0.028595405101572272,
      "grad_norm": 0.4264698922634125,
      "learning_rate": 9.714045948984278e-06,
      "loss": 0.3223,
      "step": 1806
    },
    {
      "epoch": 0.02861123865921434,
      "grad_norm": 0.21086643636226654,
      "learning_rate": 9.713887613407857e-06,
      "loss": 0.0536,
      "step": 1807
    },
    {
      "epoch": 0.028627072216856404,
      "grad_norm": 0.17957189679145813,
      "learning_rate": 9.713729277831436e-06,
      "loss": 0.1138,
      "step": 1808
    },
    {
      "epoch": 0.028642905774498472,
      "grad_norm": 0.2281426191329956,
      "learning_rate": 9.713570942255017e-06,
      "loss": 0.4654,
      "step": 1809
    },
    {
      "epoch": 0.02865873933214054,
      "grad_norm": 0.2419581264257431,
      "learning_rate": 9.713412606678596e-06,
      "loss": 0.0348,
      "step": 1810
    },
    {
      "epoch": 0.028674572889782604,
      "grad_norm": 0.0034377677366137505,
      "learning_rate": 9.713254271102175e-06,
      "loss": 0.0002,
      "step": 1811
    },
    {
      "epoch": 0.028690406447424672,
      "grad_norm": 0.1724785417318344,
      "learning_rate": 9.713095935525754e-06,
      "loss": 0.1378,
      "step": 1812
    },
    {
      "epoch": 0.02870624000506674,
      "grad_norm": 0.012096368707716465,
      "learning_rate": 9.712937599949333e-06,
      "loss": 0.0009,
      "step": 1813
    },
    {
      "epoch": 0.028722073562708804,
      "grad_norm": 0.5211818218231201,
      "learning_rate": 9.712779264372912e-06,
      "loss": 0.2343,
      "step": 1814
    },
    {
      "epoch": 0.02873790712035087,
      "grad_norm": 0.5609136819839478,
      "learning_rate": 9.712620928796493e-06,
      "loss": 0.9206,
      "step": 1815
    },
    {
      "epoch": 0.02875374067799294,
      "grad_norm": 0.19536447525024414,
      "learning_rate": 9.712462593220072e-06,
      "loss": 0.1107,
      "step": 1816
    },
    {
      "epoch": 0.028769574235635004,
      "grad_norm": 0.006095638033002615,
      "learning_rate": 9.712304257643651e-06,
      "loss": 0.0003,
      "step": 1817
    },
    {
      "epoch": 0.02878540779327707,
      "grad_norm": 0.508224606513977,
      "learning_rate": 9.71214592206723e-06,
      "loss": 0.1474,
      "step": 1818
    },
    {
      "epoch": 0.02880124135091914,
      "grad_norm": 0.2830575406551361,
      "learning_rate": 9.711987586490809e-06,
      "loss": 0.1741,
      "step": 1819
    },
    {
      "epoch": 0.028817074908561204,
      "grad_norm": 0.9340721368789673,
      "learning_rate": 9.711829250914388e-06,
      "loss": 0.4822,
      "step": 1820
    },
    {
      "epoch": 0.02883290846620327,
      "grad_norm": 0.2159697711467743,
      "learning_rate": 9.711670915337969e-06,
      "loss": 0.3452,
      "step": 1821
    },
    {
      "epoch": 0.02884874202384534,
      "grad_norm": 0.02284093201160431,
      "learning_rate": 9.711512579761548e-06,
      "loss": 0.0015,
      "step": 1822
    },
    {
      "epoch": 0.028864575581487403,
      "grad_norm": 0.12485475093126297,
      "learning_rate": 9.711354244185127e-06,
      "loss": 0.0679,
      "step": 1823
    },
    {
      "epoch": 0.02888040913912947,
      "grad_norm": 0.004199136048555374,
      "learning_rate": 9.711195908608706e-06,
      "loss": 0.0002,
      "step": 1824
    },
    {
      "epoch": 0.02889624269677154,
      "grad_norm": 0.25298917293548584,
      "learning_rate": 9.711037573032285e-06,
      "loss": 0.1946,
      "step": 1825
    },
    {
      "epoch": 0.028912076254413603,
      "grad_norm": 0.29215094447135925,
      "learning_rate": 9.710879237455864e-06,
      "loss": 0.2433,
      "step": 1826
    },
    {
      "epoch": 0.02892790981205567,
      "grad_norm": 0.1441289186477661,
      "learning_rate": 9.710720901879445e-06,
      "loss": 0.1394,
      "step": 1827
    },
    {
      "epoch": 0.02894374336969774,
      "grad_norm": 0.08200503140687943,
      "learning_rate": 9.710562566303024e-06,
      "loss": 0.0359,
      "step": 1828
    },
    {
      "epoch": 0.028959576927339803,
      "grad_norm": 1.1912546157836914,
      "learning_rate": 9.710404230726602e-06,
      "loss": 0.1618,
      "step": 1829
    },
    {
      "epoch": 0.02897541048498187,
      "grad_norm": 0.008557453751564026,
      "learning_rate": 9.710245895150182e-06,
      "loss": 0.0006,
      "step": 1830
    },
    {
      "epoch": 0.02899124404262394,
      "grad_norm": 0.012055735103785992,
      "learning_rate": 9.710087559573761e-06,
      "loss": 0.0007,
      "step": 1831
    },
    {
      "epoch": 0.029007077600266003,
      "grad_norm": 0.27134019136428833,
      "learning_rate": 9.70992922399734e-06,
      "loss": 0.6819,
      "step": 1832
    },
    {
      "epoch": 0.02902291115790807,
      "grad_norm": 0.00025198678486049175,
      "learning_rate": 9.70977088842092e-06,
      "loss": 0.0,
      "step": 1833
    },
    {
      "epoch": 0.029038744715550138,
      "grad_norm": 0.21490031480789185,
      "learning_rate": 9.7096125528445e-06,
      "loss": 0.3876,
      "step": 1834
    },
    {
      "epoch": 0.029054578273192203,
      "grad_norm": 0.0026293836999684572,
      "learning_rate": 9.709454217268078e-06,
      "loss": 0.0001,
      "step": 1835
    },
    {
      "epoch": 0.02907041183083427,
      "grad_norm": 0.36035871505737305,
      "learning_rate": 9.709295881691658e-06,
      "loss": 0.4146,
      "step": 1836
    },
    {
      "epoch": 0.029086245388476338,
      "grad_norm": 0.10502099990844727,
      "learning_rate": 9.709137546115238e-06,
      "loss": 0.0525,
      "step": 1837
    },
    {
      "epoch": 0.029102078946118402,
      "grad_norm": 0.353179007768631,
      "learning_rate": 9.708979210538817e-06,
      "loss": 0.2372,
      "step": 1838
    },
    {
      "epoch": 0.02911791250376047,
      "grad_norm": 1.6364244222640991,
      "learning_rate": 9.708820874962396e-06,
      "loss": 0.1273,
      "step": 1839
    },
    {
      "epoch": 0.029133746061402538,
      "grad_norm": 0.17224852740764618,
      "learning_rate": 9.708662539385976e-06,
      "loss": 0.1149,
      "step": 1840
    },
    {
      "epoch": 0.029149579619044602,
      "grad_norm": 0.0003566953237168491,
      "learning_rate": 9.708504203809554e-06,
      "loss": 0.0,
      "step": 1841
    },
    {
      "epoch": 0.02916541317668667,
      "grad_norm": 0.23367057740688324,
      "learning_rate": 9.708345868233135e-06,
      "loss": 0.1021,
      "step": 1842
    },
    {
      "epoch": 0.029181246734328738,
      "grad_norm": 0.19353418052196503,
      "learning_rate": 9.708187532656714e-06,
      "loss": 0.1788,
      "step": 1843
    },
    {
      "epoch": 0.029197080291970802,
      "grad_norm": 0.0017298985039815307,
      "learning_rate": 9.708029197080293e-06,
      "loss": 0.0,
      "step": 1844
    },
    {
      "epoch": 0.02921291384961287,
      "grad_norm": 0.5569878816604614,
      "learning_rate": 9.707870861503872e-06,
      "loss": 0.0911,
      "step": 1845
    },
    {
      "epoch": 0.029228747407254937,
      "grad_norm": 0.1662166863679886,
      "learning_rate": 9.707712525927453e-06,
      "loss": 0.5837,
      "step": 1846
    },
    {
      "epoch": 0.029244580964897002,
      "grad_norm": 0.2608770430088043,
      "learning_rate": 9.70755419035103e-06,
      "loss": 0.1351,
      "step": 1847
    },
    {
      "epoch": 0.02926041452253907,
      "grad_norm": 0.004995341412723064,
      "learning_rate": 9.70739585477461e-06,
      "loss": 0.0004,
      "step": 1848
    },
    {
      "epoch": 0.029276248080181137,
      "grad_norm": 0.15613968670368195,
      "learning_rate": 9.70723751919819e-06,
      "loss": 0.1226,
      "step": 1849
    },
    {
      "epoch": 0.0292920816378232,
      "grad_norm": 0.016816021874547005,
      "learning_rate": 9.707079183621769e-06,
      "loss": 0.0015,
      "step": 1850
    },
    {
      "epoch": 0.02930791519546527,
      "grad_norm": 0.010074201971292496,
      "learning_rate": 9.706920848045348e-06,
      "loss": 0.0007,
      "step": 1851
    },
    {
      "epoch": 0.029323748753107337,
      "grad_norm": 0.2898135483264923,
      "learning_rate": 9.706762512468929e-06,
      "loss": 0.155,
      "step": 1852
    },
    {
      "epoch": 0.0293395823107494,
      "grad_norm": 0.5362422466278076,
      "learning_rate": 9.706604176892506e-06,
      "loss": 0.7859,
      "step": 1853
    },
    {
      "epoch": 0.02935541586839147,
      "grad_norm": 0.16908405721187592,
      "learning_rate": 9.706445841316085e-06,
      "loss": 0.1958,
      "step": 1854
    },
    {
      "epoch": 0.029371249426033537,
      "grad_norm": 0.2658422887325287,
      "learning_rate": 9.706287505739666e-06,
      "loss": 0.5945,
      "step": 1855
    },
    {
      "epoch": 0.0293870829836756,
      "grad_norm": 9.387256432091817e-05,
      "learning_rate": 9.706129170163245e-06,
      "loss": 0.0,
      "step": 1856
    },
    {
      "epoch": 0.02940291654131767,
      "grad_norm": 0.22515171766281128,
      "learning_rate": 9.705970834586824e-06,
      "loss": 0.1697,
      "step": 1857
    },
    {
      "epoch": 0.029418750098959737,
      "grad_norm": 0.13880088925361633,
      "learning_rate": 9.705812499010403e-06,
      "loss": 0.0317,
      "step": 1858
    },
    {
      "epoch": 0.0294345836566018,
      "grad_norm": 0.2158890664577484,
      "learning_rate": 9.705654163433982e-06,
      "loss": 0.1378,
      "step": 1859
    },
    {
      "epoch": 0.02945041721424387,
      "grad_norm": 0.330409437417984,
      "learning_rate": 9.705495827857561e-06,
      "loss": 0.09,
      "step": 1860
    },
    {
      "epoch": 0.029466250771885936,
      "grad_norm": 0.3015693426132202,
      "learning_rate": 9.705337492281142e-06,
      "loss": 0.2721,
      "step": 1861
    },
    {
      "epoch": 0.029482084329528,
      "grad_norm": 0.0003686852869577706,
      "learning_rate": 9.70517915670472e-06,
      "loss": 0.0,
      "step": 1862
    },
    {
      "epoch": 0.02949791788717007,
      "grad_norm": 0.21660968661308289,
      "learning_rate": 9.7050208211283e-06,
      "loss": 0.1547,
      "step": 1863
    },
    {
      "epoch": 0.029513751444812136,
      "grad_norm": 0.16736391186714172,
      "learning_rate": 9.70486248555188e-06,
      "loss": 0.0061,
      "step": 1864
    },
    {
      "epoch": 0.0295295850024542,
      "grad_norm": 0.5195777416229248,
      "learning_rate": 9.704704149975459e-06,
      "loss": 0.3654,
      "step": 1865
    },
    {
      "epoch": 0.02954541856009627,
      "grad_norm": 0.007998497225344181,
      "learning_rate": 9.704545814399038e-06,
      "loss": 0.0006,
      "step": 1866
    },
    {
      "epoch": 0.029561252117738336,
      "grad_norm": 0.3119013011455536,
      "learning_rate": 9.704387478822618e-06,
      "loss": 0.4406,
      "step": 1867
    },
    {
      "epoch": 0.0295770856753804,
      "grad_norm": 0.0001645764714339748,
      "learning_rate": 9.704229143246196e-06,
      "loss": 0.0,
      "step": 1868
    },
    {
      "epoch": 0.029592919233022468,
      "grad_norm": 0.14350099861621857,
      "learning_rate": 9.704070807669777e-06,
      "loss": 0.0882,
      "step": 1869
    },
    {
      "epoch": 0.029608752790664536,
      "grad_norm": 0.0001558955991640687,
      "learning_rate": 9.703912472093356e-06,
      "loss": 0.0,
      "step": 1870
    },
    {
      "epoch": 0.0296245863483066,
      "grad_norm": 0.19803296029567719,
      "learning_rate": 9.703754136516935e-06,
      "loss": 0.2945,
      "step": 1871
    },
    {
      "epoch": 0.029640419905948668,
      "grad_norm": 0.3970946669578552,
      "learning_rate": 9.703595800940514e-06,
      "loss": 0.0639,
      "step": 1872
    },
    {
      "epoch": 0.029656253463590736,
      "grad_norm": 0.17919188737869263,
      "learning_rate": 9.703437465364095e-06,
      "loss": 0.0919,
      "step": 1873
    },
    {
      "epoch": 0.0296720870212328,
      "grad_norm": 0.20659643411636353,
      "learning_rate": 9.703279129787672e-06,
      "loss": 0.1504,
      "step": 1874
    },
    {
      "epoch": 0.029687920578874868,
      "grad_norm": 0.10338149219751358,
      "learning_rate": 9.703120794211253e-06,
      "loss": 0.0576,
      "step": 1875
    },
    {
      "epoch": 0.029703754136516936,
      "grad_norm": 0.1573709100484848,
      "learning_rate": 9.702962458634832e-06,
      "loss": 0.1177,
      "step": 1876
    },
    {
      "epoch": 0.029719587694159,
      "grad_norm": 0.38605618476867676,
      "learning_rate": 9.702804123058411e-06,
      "loss": 0.7045,
      "step": 1877
    },
    {
      "epoch": 0.029735421251801068,
      "grad_norm": 0.34253185987472534,
      "learning_rate": 9.70264578748199e-06,
      "loss": 0.1589,
      "step": 1878
    },
    {
      "epoch": 0.029751254809443135,
      "grad_norm": 0.6847509145736694,
      "learning_rate": 9.702487451905569e-06,
      "loss": 0.0557,
      "step": 1879
    },
    {
      "epoch": 0.0297670883670852,
      "grad_norm": 0.32918158173561096,
      "learning_rate": 9.702329116329148e-06,
      "loss": 0.5439,
      "step": 1880
    },
    {
      "epoch": 0.029782921924727267,
      "grad_norm": 0.01805983856320381,
      "learning_rate": 9.702170780752727e-06,
      "loss": 0.001,
      "step": 1881
    },
    {
      "epoch": 0.029798755482369335,
      "grad_norm": 0.6920174956321716,
      "learning_rate": 9.702012445176308e-06,
      "loss": 1.6267,
      "step": 1882
    },
    {
      "epoch": 0.0298145890400114,
      "grad_norm": 0.00525559252128005,
      "learning_rate": 9.701854109599887e-06,
      "loss": 0.0001,
      "step": 1883
    },
    {
      "epoch": 0.029830422597653467,
      "grad_norm": 0.00042932506767101586,
      "learning_rate": 9.701695774023466e-06,
      "loss": 0.0,
      "step": 1884
    },
    {
      "epoch": 0.029846256155295535,
      "grad_norm": 0.17226333916187286,
      "learning_rate": 9.701537438447045e-06,
      "loss": 0.3587,
      "step": 1885
    },
    {
      "epoch": 0.0298620897129376,
      "grad_norm": 0.2559664249420166,
      "learning_rate": 9.701379102870624e-06,
      "loss": 0.7238,
      "step": 1886
    },
    {
      "epoch": 0.029877923270579667,
      "grad_norm": 0.00018934215768240392,
      "learning_rate": 9.701220767294203e-06,
      "loss": 0.0,
      "step": 1887
    },
    {
      "epoch": 0.029893756828221735,
      "grad_norm": 0.19211141765117645,
      "learning_rate": 9.701062431717784e-06,
      "loss": 0.1046,
      "step": 1888
    },
    {
      "epoch": 0.0299095903858638,
      "grad_norm": 0.5944538712501526,
      "learning_rate": 9.700904096141363e-06,
      "loss": 0.1493,
      "step": 1889
    },
    {
      "epoch": 0.029925423943505867,
      "grad_norm": 0.14092913269996643,
      "learning_rate": 9.700745760564942e-06,
      "loss": 0.0716,
      "step": 1890
    },
    {
      "epoch": 0.029941257501147935,
      "grad_norm": 0.002501468872651458,
      "learning_rate": 9.700587424988521e-06,
      "loss": 0.0001,
      "step": 1891
    },
    {
      "epoch": 0.02995709105879,
      "grad_norm": 0.0046016741544008255,
      "learning_rate": 9.7004290894121e-06,
      "loss": 0.0004,
      "step": 1892
    },
    {
      "epoch": 0.029972924616432067,
      "grad_norm": 0.676157534122467,
      "learning_rate": 9.70027075383568e-06,
      "loss": 0.0876,
      "step": 1893
    },
    {
      "epoch": 0.029988758174074134,
      "grad_norm": 0.5803866982460022,
      "learning_rate": 9.70011241825926e-06,
      "loss": 0.4765,
      "step": 1894
    },
    {
      "epoch": 0.0300045917317162,
      "grad_norm": 0.23516079783439636,
      "learning_rate": 9.69995408268284e-06,
      "loss": 0.0595,
      "step": 1895
    },
    {
      "epoch": 0.030020425289358266,
      "grad_norm": 0.8369619250297546,
      "learning_rate": 9.699795747106418e-06,
      "loss": 0.8945,
      "step": 1896
    },
    {
      "epoch": 0.030036258847000334,
      "grad_norm": 0.13825617730617523,
      "learning_rate": 9.699637411529998e-06,
      "loss": 0.0317,
      "step": 1897
    },
    {
      "epoch": 0.0300520924046424,
      "grad_norm": 0.3154263198375702,
      "learning_rate": 9.699479075953577e-06,
      "loss": 0.0412,
      "step": 1898
    },
    {
      "epoch": 0.030067925962284466,
      "grad_norm": 0.689670979976654,
      "learning_rate": 9.699320740377156e-06,
      "loss": 0.5023,
      "step": 1899
    },
    {
      "epoch": 0.030083759519926534,
      "grad_norm": 0.1105612963438034,
      "learning_rate": 9.699162404800736e-06,
      "loss": 0.0054,
      "step": 1900
    },
    {
      "epoch": 0.030099593077568598,
      "grad_norm": 0.012203938327729702,
      "learning_rate": 9.699004069224316e-06,
      "loss": 0.0008,
      "step": 1901
    },
    {
      "epoch": 0.030115426635210666,
      "grad_norm": 0.01416669599711895,
      "learning_rate": 9.698845733647893e-06,
      "loss": 0.0011,
      "step": 1902
    },
    {
      "epoch": 0.030131260192852734,
      "grad_norm": 0.14548134803771973,
      "learning_rate": 9.698687398071474e-06,
      "loss": 0.0915,
      "step": 1903
    },
    {
      "epoch": 0.030147093750494798,
      "grad_norm": 0.021153977140784264,
      "learning_rate": 9.698529062495053e-06,
      "loss": 0.0012,
      "step": 1904
    },
    {
      "epoch": 0.030162927308136866,
      "grad_norm": 0.018149157986044884,
      "learning_rate": 9.698370726918632e-06,
      "loss": 0.0004,
      "step": 1905
    },
    {
      "epoch": 0.030178760865778934,
      "grad_norm": 0.5482870936393738,
      "learning_rate": 9.698212391342211e-06,
      "loss": 0.603,
      "step": 1906
    },
    {
      "epoch": 0.030194594423420998,
      "grad_norm": 0.00014318659668788314,
      "learning_rate": 9.698054055765792e-06,
      "loss": 0.0,
      "step": 1907
    },
    {
      "epoch": 0.030210427981063066,
      "grad_norm": 0.01210174523293972,
      "learning_rate": 9.697895720189369e-06,
      "loss": 0.0006,
      "step": 1908
    },
    {
      "epoch": 0.030226261538705133,
      "grad_norm": 0.1628986895084381,
      "learning_rate": 9.69773738461295e-06,
      "loss": 0.0912,
      "step": 1909
    },
    {
      "epoch": 0.030242095096347198,
      "grad_norm": 0.006569907069206238,
      "learning_rate": 9.697579049036529e-06,
      "loss": 0.0003,
      "step": 1910
    },
    {
      "epoch": 0.030257928653989265,
      "grad_norm": 0.09044191986322403,
      "learning_rate": 9.697420713460108e-06,
      "loss": 0.0016,
      "step": 1911
    },
    {
      "epoch": 0.03027376221163133,
      "grad_norm": 0.28513258695602417,
      "learning_rate": 9.697262377883687e-06,
      "loss": 0.554,
      "step": 1912
    },
    {
      "epoch": 0.030289595769273397,
      "grad_norm": 0.23000220954418182,
      "learning_rate": 9.697104042307268e-06,
      "loss": 0.021,
      "step": 1913
    },
    {
      "epoch": 0.030305429326915465,
      "grad_norm": 0.13763004541397095,
      "learning_rate": 9.696945706730845e-06,
      "loss": 0.1902,
      "step": 1914
    },
    {
      "epoch": 0.03032126288455753,
      "grad_norm": 0.3466101288795471,
      "learning_rate": 9.696787371154426e-06,
      "loss": 0.4967,
      "step": 1915
    },
    {
      "epoch": 0.030337096442199597,
      "grad_norm": 0.025730200111865997,
      "learning_rate": 9.696629035578005e-06,
      "loss": 0.0017,
      "step": 1916
    },
    {
      "epoch": 0.030352929999841665,
      "grad_norm": 0.33237525820732117,
      "learning_rate": 9.696470700001584e-06,
      "loss": 0.583,
      "step": 1917
    },
    {
      "epoch": 0.03036876355748373,
      "grad_norm": 0.2562853991985321,
      "learning_rate": 9.696312364425163e-06,
      "loss": 0.0985,
      "step": 1918
    },
    {
      "epoch": 0.030384597115125797,
      "grad_norm": 0.06790286302566528,
      "learning_rate": 9.696154028848744e-06,
      "loss": 0.0069,
      "step": 1919
    },
    {
      "epoch": 0.030400430672767865,
      "grad_norm": 0.13863882422447205,
      "learning_rate": 9.695995693272321e-06,
      "loss": 0.0364,
      "step": 1920
    },
    {
      "epoch": 0.03041626423040993,
      "grad_norm": 0.0034359944984316826,
      "learning_rate": 9.695837357695902e-06,
      "loss": 0.0002,
      "step": 1921
    },
    {
      "epoch": 0.030432097788051997,
      "grad_norm": 0.22136889398097992,
      "learning_rate": 9.695679022119481e-06,
      "loss": 0.6082,
      "step": 1922
    },
    {
      "epoch": 0.030447931345694065,
      "grad_norm": 0.14283116161823273,
      "learning_rate": 9.69552068654306e-06,
      "loss": 0.0641,
      "step": 1923
    },
    {
      "epoch": 0.03046376490333613,
      "grad_norm": 0.007065733429044485,
      "learning_rate": 9.69536235096664e-06,
      "loss": 0.0004,
      "step": 1924
    },
    {
      "epoch": 0.030479598460978197,
      "grad_norm": 0.1745954304933548,
      "learning_rate": 9.695204015390219e-06,
      "loss": 0.1721,
      "step": 1925
    },
    {
      "epoch": 0.030495432018620264,
      "grad_norm": 0.1459772288799286,
      "learning_rate": 9.695045679813798e-06,
      "loss": 0.0163,
      "step": 1926
    },
    {
      "epoch": 0.03051126557626233,
      "grad_norm": 0.00017942739941645414,
      "learning_rate": 9.694887344237377e-06,
      "loss": 0.0,
      "step": 1927
    },
    {
      "epoch": 0.030527099133904396,
      "grad_norm": 0.00026076234644278884,
      "learning_rate": 9.694729008660957e-06,
      "loss": 0.0,
      "step": 1928
    },
    {
      "epoch": 0.030542932691546464,
      "grad_norm": 0.2580487132072449,
      "learning_rate": 9.694570673084535e-06,
      "loss": 0.0835,
      "step": 1929
    },
    {
      "epoch": 0.03055876624918853,
      "grad_norm": 0.19458815455436707,
      "learning_rate": 9.694412337508116e-06,
      "loss": 0.1976,
      "step": 1930
    },
    {
      "epoch": 0.030574599806830596,
      "grad_norm": 0.639995276927948,
      "learning_rate": 9.694254001931695e-06,
      "loss": 0.1076,
      "step": 1931
    },
    {
      "epoch": 0.030590433364472664,
      "grad_norm": 0.31292060017585754,
      "learning_rate": 9.694095666355274e-06,
      "loss": 0.1506,
      "step": 1932
    },
    {
      "epoch": 0.03060626692211473,
      "grad_norm": 0.3737933039665222,
      "learning_rate": 9.693937330778853e-06,
      "loss": 0.3307,
      "step": 1933
    },
    {
      "epoch": 0.030622100479756796,
      "grad_norm": 0.18381503224372864,
      "learning_rate": 9.693778995202434e-06,
      "loss": 0.1515,
      "step": 1934
    },
    {
      "epoch": 0.030637934037398864,
      "grad_norm": 0.14940300583839417,
      "learning_rate": 9.693620659626011e-06,
      "loss": 0.1034,
      "step": 1935
    },
    {
      "epoch": 0.030653767595040928,
      "grad_norm": 0.00524567486718297,
      "learning_rate": 9.693462324049592e-06,
      "loss": 0.0003,
      "step": 1936
    },
    {
      "epoch": 0.030669601152682996,
      "grad_norm": 0.18093657493591309,
      "learning_rate": 9.693303988473171e-06,
      "loss": 0.4142,
      "step": 1937
    },
    {
      "epoch": 0.030685434710325064,
      "grad_norm": 0.5718003511428833,
      "learning_rate": 9.69314565289675e-06,
      "loss": 0.2575,
      "step": 1938
    },
    {
      "epoch": 0.030701268267967128,
      "grad_norm": 0.013595428317785263,
      "learning_rate": 9.692987317320329e-06,
      "loss": 0.0008,
      "step": 1939
    },
    {
      "epoch": 0.030717101825609196,
      "grad_norm": 0.35775691270828247,
      "learning_rate": 9.69282898174391e-06,
      "loss": 0.5272,
      "step": 1940
    },
    {
      "epoch": 0.030732935383251263,
      "grad_norm": 0.3018918037414551,
      "learning_rate": 9.692670646167487e-06,
      "loss": 0.1151,
      "step": 1941
    },
    {
      "epoch": 0.030748768940893328,
      "grad_norm": 0.21571482717990875,
      "learning_rate": 9.692512310591068e-06,
      "loss": 0.337,
      "step": 1942
    },
    {
      "epoch": 0.030764602498535396,
      "grad_norm": 0.21505911648273468,
      "learning_rate": 9.692353975014647e-06,
      "loss": 0.1784,
      "step": 1943
    },
    {
      "epoch": 0.030780436056177463,
      "grad_norm": 0.5731784105300903,
      "learning_rate": 9.692195639438226e-06,
      "loss": 0.4397,
      "step": 1944
    },
    {
      "epoch": 0.030796269613819528,
      "grad_norm": 0.19093632698059082,
      "learning_rate": 9.692037303861805e-06,
      "loss": 0.1863,
      "step": 1945
    },
    {
      "epoch": 0.030812103171461595,
      "grad_norm": 0.19052118062973022,
      "learning_rate": 9.691878968285386e-06,
      "loss": 0.1137,
      "step": 1946
    },
    {
      "epoch": 0.030827936729103663,
      "grad_norm": 0.014717831276357174,
      "learning_rate": 9.691720632708963e-06,
      "loss": 0.0012,
      "step": 1947
    },
    {
      "epoch": 0.030843770286745727,
      "grad_norm": 0.16262076795101166,
      "learning_rate": 9.691562297132544e-06,
      "loss": 0.0872,
      "step": 1948
    },
    {
      "epoch": 0.030859603844387795,
      "grad_norm": 0.1619231253862381,
      "learning_rate": 9.691403961556123e-06,
      "loss": 0.0944,
      "step": 1949
    },
    {
      "epoch": 0.030875437402029863,
      "grad_norm": 0.0034595103934407234,
      "learning_rate": 9.691245625979702e-06,
      "loss": 0.0001,
      "step": 1950
    },
    {
      "epoch": 0.030891270959671927,
      "grad_norm": 0.18249720335006714,
      "learning_rate": 9.691087290403281e-06,
      "loss": 0.312,
      "step": 1951
    },
    {
      "epoch": 0.030907104517313995,
      "grad_norm": 0.1513909250497818,
      "learning_rate": 9.69092895482686e-06,
      "loss": 0.2391,
      "step": 1952
    },
    {
      "epoch": 0.030922938074956063,
      "grad_norm": 0.18987146019935608,
      "learning_rate": 9.69077061925044e-06,
      "loss": 0.1388,
      "step": 1953
    },
    {
      "epoch": 0.030938771632598127,
      "grad_norm": 0.00018876715330407023,
      "learning_rate": 9.690612283674019e-06,
      "loss": 0.0,
      "step": 1954
    },
    {
      "epoch": 0.030954605190240195,
      "grad_norm": 0.37268173694610596,
      "learning_rate": 9.6904539480976e-06,
      "loss": 0.1755,
      "step": 1955
    },
    {
      "epoch": 0.030970438747882263,
      "grad_norm": 0.15118053555488586,
      "learning_rate": 9.690295612521178e-06,
      "loss": 0.1871,
      "step": 1956
    },
    {
      "epoch": 0.030986272305524327,
      "grad_norm": 0.009452128782868385,
      "learning_rate": 9.690137276944758e-06,
      "loss": 0.0005,
      "step": 1957
    },
    {
      "epoch": 0.031002105863166395,
      "grad_norm": 0.007407063152641058,
      "learning_rate": 9.689978941368337e-06,
      "loss": 0.0004,
      "step": 1958
    },
    {
      "epoch": 0.031017939420808462,
      "grad_norm": 0.01996256597340107,
      "learning_rate": 9.689820605791916e-06,
      "loss": 0.0001,
      "step": 1959
    },
    {
      "epoch": 0.031033772978450527,
      "grad_norm": 0.23976513743400574,
      "learning_rate": 9.689662270215495e-06,
      "loss": 0.1274,
      "step": 1960
    },
    {
      "epoch": 0.031049606536092594,
      "grad_norm": 0.3124808669090271,
      "learning_rate": 9.689503934639076e-06,
      "loss": 0.3259,
      "step": 1961
    },
    {
      "epoch": 0.031065440093734662,
      "grad_norm": 0.15169766545295715,
      "learning_rate": 9.689345599062655e-06,
      "loss": 0.3017,
      "step": 1962
    },
    {
      "epoch": 0.031081273651376726,
      "grad_norm": 0.07580346614122391,
      "learning_rate": 9.689187263486234e-06,
      "loss": 0.0067,
      "step": 1963
    },
    {
      "epoch": 0.031097107209018794,
      "grad_norm": 0.4125097692012787,
      "learning_rate": 9.689028927909813e-06,
      "loss": 0.0888,
      "step": 1964
    },
    {
      "epoch": 0.031112940766660862,
      "grad_norm": 0.2578946650028229,
      "learning_rate": 9.688870592333392e-06,
      "loss": 0.0061,
      "step": 1965
    },
    {
      "epoch": 0.031128774324302926,
      "grad_norm": 0.19765233993530273,
      "learning_rate": 9.688712256756971e-06,
      "loss": 0.0618,
      "step": 1966
    },
    {
      "epoch": 0.031144607881944994,
      "grad_norm": 0.4278434216976166,
      "learning_rate": 9.688553921180552e-06,
      "loss": 0.1036,
      "step": 1967
    },
    {
      "epoch": 0.03116044143958706,
      "grad_norm": 0.19339661300182343,
      "learning_rate": 9.68839558560413e-06,
      "loss": 0.2139,
      "step": 1968
    },
    {
      "epoch": 0.031176274997229126,
      "grad_norm": 0.2512953281402588,
      "learning_rate": 9.68823725002771e-06,
      "loss": 0.1685,
      "step": 1969
    },
    {
      "epoch": 0.031192108554871194,
      "grad_norm": 0.1938313990831375,
      "learning_rate": 9.688078914451289e-06,
      "loss": 0.0884,
      "step": 1970
    },
    {
      "epoch": 0.03120794211251326,
      "grad_norm": 0.32991883158683777,
      "learning_rate": 9.687920578874868e-06,
      "loss": 0.5497,
      "step": 1971
    },
    {
      "epoch": 0.031223775670155326,
      "grad_norm": 0.0018933296669274569,
      "learning_rate": 9.687762243298447e-06,
      "loss": 0.0001,
      "step": 1972
    },
    {
      "epoch": 0.031239609227797394,
      "grad_norm": 0.00012564851203933358,
      "learning_rate": 9.687603907722026e-06,
      "loss": 0.0,
      "step": 1973
    },
    {
      "epoch": 0.03125544278543946,
      "grad_norm": 0.1919986605644226,
      "learning_rate": 9.687445572145607e-06,
      "loss": 0.229,
      "step": 1974
    },
    {
      "epoch": 0.03127127634308153,
      "grad_norm": 0.11902052909135818,
      "learning_rate": 9.687287236569184e-06,
      "loss": 0.0557,
      "step": 1975
    },
    {
      "epoch": 0.03128710990072359,
      "grad_norm": 0.3205230236053467,
      "learning_rate": 9.687128900992765e-06,
      "loss": 0.1939,
      "step": 1976
    },
    {
      "epoch": 0.03130294345836566,
      "grad_norm": 0.00037969183176755905,
      "learning_rate": 9.686970565416344e-06,
      "loss": 0.0,
      "step": 1977
    },
    {
      "epoch": 0.03131877701600773,
      "grad_norm": 0.012355748564004898,
      "learning_rate": 9.686812229839923e-06,
      "loss": 0.0007,
      "step": 1978
    },
    {
      "epoch": 0.03133461057364979,
      "grad_norm": 0.008255538530647755,
      "learning_rate": 9.686653894263502e-06,
      "loss": 0.0006,
      "step": 1979
    },
    {
      "epoch": 0.03135044413129186,
      "grad_norm": 0.017909327521920204,
      "learning_rate": 9.686495558687083e-06,
      "loss": 0.0006,
      "step": 1980
    },
    {
      "epoch": 0.03136627768893393,
      "grad_norm": 0.3000657260417938,
      "learning_rate": 9.68633722311066e-06,
      "loss": 0.7075,
      "step": 1981
    },
    {
      "epoch": 0.03138211124657599,
      "grad_norm": 0.44029122591018677,
      "learning_rate": 9.686178887534241e-06,
      "loss": 0.7174,
      "step": 1982
    },
    {
      "epoch": 0.03139794480421806,
      "grad_norm": 0.006772732362151146,
      "learning_rate": 9.68602055195782e-06,
      "loss": 0.0005,
      "step": 1983
    },
    {
      "epoch": 0.03141377836186013,
      "grad_norm": 0.02128923311829567,
      "learning_rate": 9.6858622163814e-06,
      "loss": 0.0015,
      "step": 1984
    },
    {
      "epoch": 0.03142961191950219,
      "grad_norm": 0.035649798810482025,
      "learning_rate": 9.685703880804979e-06,
      "loss": 0.0034,
      "step": 1985
    },
    {
      "epoch": 0.03144544547714426,
      "grad_norm": 0.14758865535259247,
      "learning_rate": 9.68554554522856e-06,
      "loss": 0.3082,
      "step": 1986
    },
    {
      "epoch": 0.03146127903478633,
      "grad_norm": 0.0026540029793977737,
      "learning_rate": 9.685387209652137e-06,
      "loss": 0.0001,
      "step": 1987
    },
    {
      "epoch": 0.03147711259242839,
      "grad_norm": 0.00043251211172901094,
      "learning_rate": 9.685228874075718e-06,
      "loss": 0.0,
      "step": 1988
    },
    {
      "epoch": 0.03149294615007046,
      "grad_norm": 0.006239705719053745,
      "learning_rate": 9.685070538499297e-06,
      "loss": 0.0004,
      "step": 1989
    },
    {
      "epoch": 0.03150877970771253,
      "grad_norm": 0.23846901953220367,
      "learning_rate": 9.684912202922876e-06,
      "loss": 0.2406,
      "step": 1990
    },
    {
      "epoch": 0.03152461326535459,
      "grad_norm": 0.02229161001741886,
      "learning_rate": 9.684753867346455e-06,
      "loss": 0.0013,
      "step": 1991
    },
    {
      "epoch": 0.03154044682299666,
      "grad_norm": 0.25386494398117065,
      "learning_rate": 9.684595531770034e-06,
      "loss": 0.2626,
      "step": 1992
    },
    {
      "epoch": 0.03155628038063873,
      "grad_norm": 0.2732141613960266,
      "learning_rate": 9.684437196193613e-06,
      "loss": 0.3375,
      "step": 1993
    },
    {
      "epoch": 0.03157211393828079,
      "grad_norm": 0.10494605451822281,
      "learning_rate": 9.684278860617194e-06,
      "loss": 0.0418,
      "step": 1994
    },
    {
      "epoch": 0.031587947495922857,
      "grad_norm": 0.22286970913410187,
      "learning_rate": 9.684120525040773e-06,
      "loss": 0.2331,
      "step": 1995
    },
    {
      "epoch": 0.03160378105356493,
      "grad_norm": 0.17606224119663239,
      "learning_rate": 9.683962189464352e-06,
      "loss": 0.0322,
      "step": 1996
    },
    {
      "epoch": 0.03161961461120699,
      "grad_norm": 0.4663783609867096,
      "learning_rate": 9.683803853887931e-06,
      "loss": 0.4684,
      "step": 1997
    },
    {
      "epoch": 0.031635448168849056,
      "grad_norm": 0.3044084310531616,
      "learning_rate": 9.68364551831151e-06,
      "loss": 0.1626,
      "step": 1998
    },
    {
      "epoch": 0.03165128172649113,
      "grad_norm": 0.14416292309761047,
      "learning_rate": 9.683487182735089e-06,
      "loss": 0.1248,
      "step": 1999
    },
    {
      "epoch": 0.03166711528413319,
      "grad_norm": 1.4886828660964966,
      "learning_rate": 9.683328847158668e-06,
      "loss": 0.066,
      "step": 2000
    },
    {
      "epoch": 0.031682948841775256,
      "grad_norm": 0.4000561833381653,
      "learning_rate": 9.683170511582249e-06,
      "loss": 0.1394,
      "step": 2001
    },
    {
      "epoch": 0.03169878239941733,
      "grad_norm": 0.005760205443948507,
      "learning_rate": 9.683012176005826e-06,
      "loss": 0.0004,
      "step": 2002
    },
    {
      "epoch": 0.03171461595705939,
      "grad_norm": 0.15310750901699066,
      "learning_rate": 9.682853840429407e-06,
      "loss": 0.0607,
      "step": 2003
    },
    {
      "epoch": 0.031730449514701456,
      "grad_norm": 0.0002403965627308935,
      "learning_rate": 9.682695504852986e-06,
      "loss": 0.0,
      "step": 2004
    },
    {
      "epoch": 0.03174628307234353,
      "grad_norm": 0.2719877362251282,
      "learning_rate": 9.682537169276565e-06,
      "loss": 0.2655,
      "step": 2005
    },
    {
      "epoch": 0.03176211662998559,
      "grad_norm": 0.14378459751605988,
      "learning_rate": 9.682378833700144e-06,
      "loss": 0.0321,
      "step": 2006
    },
    {
      "epoch": 0.031777950187627656,
      "grad_norm": 0.1483507603406906,
      "learning_rate": 9.682220498123725e-06,
      "loss": 0.0409,
      "step": 2007
    },
    {
      "epoch": 0.03179378374526973,
      "grad_norm": 0.012172005139291286,
      "learning_rate": 9.682062162547302e-06,
      "loss": 0.0009,
      "step": 2008
    },
    {
      "epoch": 0.03180961730291179,
      "grad_norm": 0.3712207078933716,
      "learning_rate": 9.681903826970883e-06,
      "loss": 0.1961,
      "step": 2009
    },
    {
      "epoch": 0.031825450860553856,
      "grad_norm": 0.25140616297721863,
      "learning_rate": 9.681745491394462e-06,
      "loss": 0.6151,
      "step": 2010
    },
    {
      "epoch": 0.03184128441819593,
      "grad_norm": 0.02170138619840145,
      "learning_rate": 9.681587155818041e-06,
      "loss": 0.0015,
      "step": 2011
    },
    {
      "epoch": 0.03185711797583799,
      "grad_norm": 0.5938337445259094,
      "learning_rate": 9.68142882024162e-06,
      "loss": 0.2281,
      "step": 2012
    },
    {
      "epoch": 0.031872951533480055,
      "grad_norm": 0.46404939889907837,
      "learning_rate": 9.681270484665201e-06,
      "loss": 0.4202,
      "step": 2013
    },
    {
      "epoch": 0.03188878509112213,
      "grad_norm": 0.013232942670583725,
      "learning_rate": 9.681112149088779e-06,
      "loss": 0.0008,
      "step": 2014
    },
    {
      "epoch": 0.03190461864876419,
      "grad_norm": 0.00011784306116169319,
      "learning_rate": 9.68095381351236e-06,
      "loss": 0.0,
      "step": 2015
    },
    {
      "epoch": 0.031920452206406255,
      "grad_norm": 0.17759430408477783,
      "learning_rate": 9.680795477935939e-06,
      "loss": 0.109,
      "step": 2016
    },
    {
      "epoch": 0.031936285764048326,
      "grad_norm": 0.1998685896396637,
      "learning_rate": 9.680637142359518e-06,
      "loss": 0.163,
      "step": 2017
    },
    {
      "epoch": 0.03195211932169039,
      "grad_norm": 0.004821801092475653,
      "learning_rate": 9.680478806783097e-06,
      "loss": 0.0002,
      "step": 2018
    },
    {
      "epoch": 0.031967952879332455,
      "grad_norm": 0.23503127694129944,
      "learning_rate": 9.680320471206677e-06,
      "loss": 0.2817,
      "step": 2019
    },
    {
      "epoch": 0.031983786436974526,
      "grad_norm": 0.0016730487113818526,
      "learning_rate": 9.680162135630255e-06,
      "loss": 0.0,
      "step": 2020
    },
    {
      "epoch": 0.03199961999461659,
      "grad_norm": 0.014393207617104053,
      "learning_rate": 9.680003800053836e-06,
      "loss": 0.0002,
      "step": 2021
    },
    {
      "epoch": 0.032015453552258655,
      "grad_norm": 0.19439899921417236,
      "learning_rate": 9.679845464477415e-06,
      "loss": 0.1284,
      "step": 2022
    },
    {
      "epoch": 0.032031287109900726,
      "grad_norm": 0.14138473570346832,
      "learning_rate": 9.679687128900994e-06,
      "loss": 0.0711,
      "step": 2023
    },
    {
      "epoch": 0.03204712066754279,
      "grad_norm": 0.06057453900575638,
      "learning_rate": 9.679528793324573e-06,
      "loss": 0.0603,
      "step": 2024
    },
    {
      "epoch": 0.032062954225184855,
      "grad_norm": 0.3308837115764618,
      "learning_rate": 9.679370457748152e-06,
      "loss": 0.1667,
      "step": 2025
    },
    {
      "epoch": 0.032078787782826926,
      "grad_norm": 0.11067065596580505,
      "learning_rate": 9.679212122171731e-06,
      "loss": 0.0273,
      "step": 2026
    },
    {
      "epoch": 0.03209462134046899,
      "grad_norm": 0.41131964325904846,
      "learning_rate": 9.67905378659531e-06,
      "loss": 0.4641,
      "step": 2027
    },
    {
      "epoch": 0.032110454898111054,
      "grad_norm": 0.020413661375641823,
      "learning_rate": 9.678895451018891e-06,
      "loss": 0.002,
      "step": 2028
    },
    {
      "epoch": 0.032126288455753126,
      "grad_norm": 0.19940881431102753,
      "learning_rate": 9.67873711544247e-06,
      "loss": 0.1086,
      "step": 2029
    },
    {
      "epoch": 0.03214212201339519,
      "grad_norm": 0.2597472071647644,
      "learning_rate": 9.678578779866049e-06,
      "loss": 0.7026,
      "step": 2030
    },
    {
      "epoch": 0.032157955571037254,
      "grad_norm": 0.2200799435377121,
      "learning_rate": 9.678420444289628e-06,
      "loss": 0.0445,
      "step": 2031
    },
    {
      "epoch": 0.032173789128679325,
      "grad_norm": 0.3025928735733032,
      "learning_rate": 9.678262108713207e-06,
      "loss": 0.1251,
      "step": 2032
    },
    {
      "epoch": 0.03218962268632139,
      "grad_norm": 0.01117409486323595,
      "learning_rate": 9.678103773136786e-06,
      "loss": 0.001,
      "step": 2033
    },
    {
      "epoch": 0.032205456243963454,
      "grad_norm": 0.16396492719650269,
      "learning_rate": 9.677945437560367e-06,
      "loss": 0.1199,
      "step": 2034
    },
    {
      "epoch": 0.032221289801605525,
      "grad_norm": 0.6404245495796204,
      "learning_rate": 9.677787101983946e-06,
      "loss": 0.2584,
      "step": 2035
    },
    {
      "epoch": 0.03223712335924759,
      "grad_norm": 0.2728918194770813,
      "learning_rate": 9.677628766407525e-06,
      "loss": 0.1101,
      "step": 2036
    },
    {
      "epoch": 0.032252956916889654,
      "grad_norm": 0.20720095932483673,
      "learning_rate": 9.677470430831104e-06,
      "loss": 0.2764,
      "step": 2037
    },
    {
      "epoch": 0.032268790474531725,
      "grad_norm": 0.1166716068983078,
      "learning_rate": 9.677312095254683e-06,
      "loss": 0.0416,
      "step": 2038
    },
    {
      "epoch": 0.03228462403217379,
      "grad_norm": 0.14010129868984222,
      "learning_rate": 9.677153759678262e-06,
      "loss": 0.0563,
      "step": 2039
    },
    {
      "epoch": 0.032300457589815854,
      "grad_norm": 0.013091780245304108,
      "learning_rate": 9.676995424101843e-06,
      "loss": 0.0012,
      "step": 2040
    },
    {
      "epoch": 0.032316291147457925,
      "grad_norm": 0.004962557461112738,
      "learning_rate": 9.676837088525422e-06,
      "loss": 0.0004,
      "step": 2041
    },
    {
      "epoch": 0.03233212470509999,
      "grad_norm": 0.384764701128006,
      "learning_rate": 9.676678752949001e-06,
      "loss": 0.2217,
      "step": 2042
    },
    {
      "epoch": 0.03234795826274205,
      "grad_norm": 0.00023112859344109893,
      "learning_rate": 9.67652041737258e-06,
      "loss": 0.0,
      "step": 2043
    },
    {
      "epoch": 0.032363791820384125,
      "grad_norm": 0.20759446918964386,
      "learning_rate": 9.67636208179616e-06,
      "loss": 0.0763,
      "step": 2044
    },
    {
      "epoch": 0.03237962537802619,
      "grad_norm": 0.1655268371105194,
      "learning_rate": 9.676203746219739e-06,
      "loss": 0.0495,
      "step": 2045
    },
    {
      "epoch": 0.03239545893566825,
      "grad_norm": 0.3046110272407532,
      "learning_rate": 9.676045410643318e-06,
      "loss": 0.1049,
      "step": 2046
    },
    {
      "epoch": 0.032411292493310324,
      "grad_norm": 0.17047618329524994,
      "learning_rate": 9.675887075066898e-06,
      "loss": 0.1706,
      "step": 2047
    },
    {
      "epoch": 0.03242712605095239,
      "grad_norm": 0.22902275621891022,
      "learning_rate": 9.675728739490476e-06,
      "loss": 0.2094,
      "step": 2048
    },
    {
      "epoch": 0.03244295960859445,
      "grad_norm": 0.20395155251026154,
      "learning_rate": 9.675570403914057e-06,
      "loss": 0.0635,
      "step": 2049
    },
    {
      "epoch": 0.032458793166236524,
      "grad_norm": 0.24626654386520386,
      "learning_rate": 9.675412068337636e-06,
      "loss": 0.2286,
      "step": 2050
    },
    {
      "epoch": 0.03247462672387859,
      "grad_norm": 0.08439657837152481,
      "learning_rate": 9.675253732761215e-06,
      "loss": 0.0635,
      "step": 2051
    },
    {
      "epoch": 0.03249046028152065,
      "grad_norm": 0.1730087548494339,
      "learning_rate": 9.675095397184794e-06,
      "loss": 0.4537,
      "step": 2052
    },
    {
      "epoch": 0.032506293839162724,
      "grad_norm": 2.740614652633667,
      "learning_rate": 9.674937061608373e-06,
      "loss": 0.1576,
      "step": 2053
    },
    {
      "epoch": 0.03252212739680479,
      "grad_norm": 0.018109288066625595,
      "learning_rate": 9.674778726031952e-06,
      "loss": 0.0014,
      "step": 2054
    },
    {
      "epoch": 0.03253796095444685,
      "grad_norm": 0.2105119675397873,
      "learning_rate": 9.674620390455533e-06,
      "loss": 0.1295,
      "step": 2055
    },
    {
      "epoch": 0.032553794512088924,
      "grad_norm": 0.14878450334072113,
      "learning_rate": 9.674462054879112e-06,
      "loss": 0.0253,
      "step": 2056
    },
    {
      "epoch": 0.03256962806973099,
      "grad_norm": 0.011661477386951447,
      "learning_rate": 9.674303719302691e-06,
      "loss": 0.0009,
      "step": 2057
    },
    {
      "epoch": 0.03258546162737305,
      "grad_norm": 0.33686384558677673,
      "learning_rate": 9.67414538372627e-06,
      "loss": 0.066,
      "step": 2058
    },
    {
      "epoch": 0.032601295185015124,
      "grad_norm": 0.12405002117156982,
      "learning_rate": 9.673987048149849e-06,
      "loss": 0.0897,
      "step": 2059
    },
    {
      "epoch": 0.03261712874265719,
      "grad_norm": 0.11429840326309204,
      "learning_rate": 9.673828712573428e-06,
      "loss": 0.1272,
      "step": 2060
    },
    {
      "epoch": 0.03263296230029925,
      "grad_norm": 0.14246731996536255,
      "learning_rate": 9.673670376997009e-06,
      "loss": 0.0869,
      "step": 2061
    },
    {
      "epoch": 0.03264879585794132,
      "grad_norm": 0.08477145433425903,
      "learning_rate": 9.673512041420588e-06,
      "loss": 0.0534,
      "step": 2062
    },
    {
      "epoch": 0.03266462941558339,
      "grad_norm": 0.3187282085418701,
      "learning_rate": 9.673353705844167e-06,
      "loss": 0.5207,
      "step": 2063
    },
    {
      "epoch": 0.03268046297322545,
      "grad_norm": 0.06848010420799255,
      "learning_rate": 9.673195370267746e-06,
      "loss": 0.0054,
      "step": 2064
    },
    {
      "epoch": 0.03269629653086752,
      "grad_norm": 0.24459248781204224,
      "learning_rate": 9.673037034691325e-06,
      "loss": 0.0282,
      "step": 2065
    },
    {
      "epoch": 0.03271213008850959,
      "grad_norm": 0.0203145332634449,
      "learning_rate": 9.672878699114904e-06,
      "loss": 0.0017,
      "step": 2066
    },
    {
      "epoch": 0.03272796364615165,
      "grad_norm": 0.23086097836494446,
      "learning_rate": 9.672720363538485e-06,
      "loss": 0.1494,
      "step": 2067
    },
    {
      "epoch": 0.03274379720379372,
      "grad_norm": 0.003103673690930009,
      "learning_rate": 9.672562027962064e-06,
      "loss": 0.0002,
      "step": 2068
    },
    {
      "epoch": 0.03275963076143579,
      "grad_norm": 0.1319248080253601,
      "learning_rate": 9.672403692385643e-06,
      "loss": 0.0732,
      "step": 2069
    },
    {
      "epoch": 0.03277546431907785,
      "grad_norm": 0.13518981635570526,
      "learning_rate": 9.672245356809222e-06,
      "loss": 0.0417,
      "step": 2070
    },
    {
      "epoch": 0.03279129787671992,
      "grad_norm": 0.26994645595550537,
      "learning_rate": 9.672087021232801e-06,
      "loss": 0.0522,
      "step": 2071
    },
    {
      "epoch": 0.03280713143436199,
      "grad_norm": 0.18438035249710083,
      "learning_rate": 9.67192868565638e-06,
      "loss": 0.0869,
      "step": 2072
    },
    {
      "epoch": 0.03282296499200405,
      "grad_norm": 0.12442560493946075,
      "learning_rate": 9.67177035007996e-06,
      "loss": 0.0418,
      "step": 2073
    },
    {
      "epoch": 0.03283879854964612,
      "grad_norm": 0.17571663856506348,
      "learning_rate": 9.67161201450354e-06,
      "loss": 0.0637,
      "step": 2074
    },
    {
      "epoch": 0.03285463210728819,
      "grad_norm": 0.14903363585472107,
      "learning_rate": 9.671453678927118e-06,
      "loss": 0.0372,
      "step": 2075
    },
    {
      "epoch": 0.03287046566493025,
      "grad_norm": 0.00017476372886449099,
      "learning_rate": 9.671295343350699e-06,
      "loss": 0.0,
      "step": 2076
    },
    {
      "epoch": 0.03288629922257232,
      "grad_norm": 0.14050240814685822,
      "learning_rate": 9.671137007774278e-06,
      "loss": 0.0763,
      "step": 2077
    },
    {
      "epoch": 0.03290213278021439,
      "grad_norm": 0.14354489743709564,
      "learning_rate": 9.670978672197857e-06,
      "loss": 0.3168,
      "step": 2078
    },
    {
      "epoch": 0.03291796633785645,
      "grad_norm": 0.37143808603286743,
      "learning_rate": 9.670820336621436e-06,
      "loss": 0.15,
      "step": 2079
    },
    {
      "epoch": 0.03293379989549852,
      "grad_norm": 0.006989198736846447,
      "learning_rate": 9.670662001045017e-06,
      "loss": 0.0004,
      "step": 2080
    },
    {
      "epoch": 0.03294963345314059,
      "grad_norm": 0.009917644783854485,
      "learning_rate": 9.670503665468594e-06,
      "loss": 0.0006,
      "step": 2081
    },
    {
      "epoch": 0.03296546701078265,
      "grad_norm": 0.000981319579295814,
      "learning_rate": 9.670345329892175e-06,
      "loss": 0.0,
      "step": 2082
    },
    {
      "epoch": 0.03298130056842472,
      "grad_norm": 0.000287287519313395,
      "learning_rate": 9.670186994315754e-06,
      "loss": 0.0,
      "step": 2083
    },
    {
      "epoch": 0.032997134126066786,
      "grad_norm": 0.2433471977710724,
      "learning_rate": 9.670028658739333e-06,
      "loss": 0.4408,
      "step": 2084
    },
    {
      "epoch": 0.03301296768370885,
      "grad_norm": 0.44445937871932983,
      "learning_rate": 9.669870323162912e-06,
      "loss": 0.0516,
      "step": 2085
    },
    {
      "epoch": 0.03302880124135092,
      "grad_norm": 1.7324674129486084,
      "learning_rate": 9.669711987586493e-06,
      "loss": 0.0691,
      "step": 2086
    },
    {
      "epoch": 0.033044634798992986,
      "grad_norm": 0.6625894904136658,
      "learning_rate": 9.66955365201007e-06,
      "loss": 0.3316,
      "step": 2087
    },
    {
      "epoch": 0.03306046835663505,
      "grad_norm": 0.40457749366760254,
      "learning_rate": 9.669395316433651e-06,
      "loss": 0.3675,
      "step": 2088
    },
    {
      "epoch": 0.03307630191427712,
      "grad_norm": 0.17996318638324738,
      "learning_rate": 9.66923698085723e-06,
      "loss": 0.0784,
      "step": 2089
    },
    {
      "epoch": 0.033092135471919186,
      "grad_norm": 0.40664878487586975,
      "learning_rate": 9.669078645280809e-06,
      "loss": 0.1133,
      "step": 2090
    },
    {
      "epoch": 0.03310796902956125,
      "grad_norm": 0.14557644724845886,
      "learning_rate": 9.668920309704388e-06,
      "loss": 0.1095,
      "step": 2091
    },
    {
      "epoch": 0.03312380258720332,
      "grad_norm": 0.011412744410336018,
      "learning_rate": 9.668761974127969e-06,
      "loss": 0.0003,
      "step": 2092
    },
    {
      "epoch": 0.033139636144845386,
      "grad_norm": 0.13237109780311584,
      "learning_rate": 9.668603638551546e-06,
      "loss": 0.0811,
      "step": 2093
    },
    {
      "epoch": 0.03315546970248745,
      "grad_norm": 0.0073761469684541225,
      "learning_rate": 9.668445302975125e-06,
      "loss": 0.0004,
      "step": 2094
    },
    {
      "epoch": 0.03317130326012952,
      "grad_norm": 0.3744485378265381,
      "learning_rate": 9.668286967398706e-06,
      "loss": 0.24,
      "step": 2095
    },
    {
      "epoch": 0.033187136817771586,
      "grad_norm": 0.18215355277061462,
      "learning_rate": 9.668128631822285e-06,
      "loss": 0.0533,
      "step": 2096
    },
    {
      "epoch": 0.03320297037541365,
      "grad_norm": 0.25800949335098267,
      "learning_rate": 9.667970296245864e-06,
      "loss": 0.0974,
      "step": 2097
    },
    {
      "epoch": 0.03321880393305572,
      "grad_norm": 0.27793580293655396,
      "learning_rate": 9.667811960669443e-06,
      "loss": 0.1013,
      "step": 2098
    },
    {
      "epoch": 0.033234637490697785,
      "grad_norm": 0.0017412990564480424,
      "learning_rate": 9.667653625093022e-06,
      "loss": 0.0001,
      "step": 2099
    },
    {
      "epoch": 0.03325047104833985,
      "grad_norm": 0.1664513349533081,
      "learning_rate": 9.667495289516602e-06,
      "loss": 0.1497,
      "step": 2100
    },
    {
      "epoch": 0.03326630460598192,
      "grad_norm": 0.9049971103668213,
      "learning_rate": 9.667336953940182e-06,
      "loss": 0.9841,
      "step": 2101
    },
    {
      "epoch": 0.033282138163623985,
      "grad_norm": 9.398103429703042e-05,
      "learning_rate": 9.667178618363761e-06,
      "loss": 0.0,
      "step": 2102
    },
    {
      "epoch": 0.03329797172126605,
      "grad_norm": 0.20133373141288757,
      "learning_rate": 9.66702028278734e-06,
      "loss": 0.0975,
      "step": 2103
    },
    {
      "epoch": 0.03331380527890812,
      "grad_norm": 0.42100000381469727,
      "learning_rate": 9.66686194721092e-06,
      "loss": 0.1436,
      "step": 2104
    },
    {
      "epoch": 0.033329638836550185,
      "grad_norm": 0.019253183156251907,
      "learning_rate": 9.666703611634499e-06,
      "loss": 0.0012,
      "step": 2105
    },
    {
      "epoch": 0.03334547239419225,
      "grad_norm": 0.00016724254237487912,
      "learning_rate": 9.666545276058078e-06,
      "loss": 0.0,
      "step": 2106
    },
    {
      "epoch": 0.03336130595183432,
      "grad_norm": 0.17096585035324097,
      "learning_rate": 9.666386940481658e-06,
      "loss": 0.0896,
      "step": 2107
    },
    {
      "epoch": 0.033377139509476385,
      "grad_norm": 0.17430251836776733,
      "learning_rate": 9.666228604905238e-06,
      "loss": 0.2863,
      "step": 2108
    },
    {
      "epoch": 0.03339297306711845,
      "grad_norm": 0.21349550783634186,
      "learning_rate": 9.666070269328817e-06,
      "loss": 0.0387,
      "step": 2109
    },
    {
      "epoch": 0.03340880662476052,
      "grad_norm": 0.2514702379703522,
      "learning_rate": 9.665911933752396e-06,
      "loss": 0.083,
      "step": 2110
    },
    {
      "epoch": 0.033424640182402585,
      "grad_norm": 0.5950531363487244,
      "learning_rate": 9.665753598175975e-06,
      "loss": 0.6839,
      "step": 2111
    },
    {
      "epoch": 0.03344047374004465,
      "grad_norm": 0.1497335433959961,
      "learning_rate": 9.665595262599554e-06,
      "loss": 0.1217,
      "step": 2112
    },
    {
      "epoch": 0.03345630729768672,
      "grad_norm": 0.15007220208644867,
      "learning_rate": 9.665436927023135e-06,
      "loss": 0.1189,
      "step": 2113
    },
    {
      "epoch": 0.033472140855328784,
      "grad_norm": 0.22950546443462372,
      "learning_rate": 9.665278591446714e-06,
      "loss": 0.1548,
      "step": 2114
    },
    {
      "epoch": 0.03348797441297085,
      "grad_norm": 0.2778874635696411,
      "learning_rate": 9.665120255870293e-06,
      "loss": 0.1647,
      "step": 2115
    },
    {
      "epoch": 0.03350380797061292,
      "grad_norm": 0.31734123826026917,
      "learning_rate": 9.664961920293872e-06,
      "loss": 0.6214,
      "step": 2116
    },
    {
      "epoch": 0.033519641528254984,
      "grad_norm": 0.2311195284128189,
      "learning_rate": 9.664803584717451e-06,
      "loss": 0.1341,
      "step": 2117
    },
    {
      "epoch": 0.03353547508589705,
      "grad_norm": 0.10243549942970276,
      "learning_rate": 9.66464524914103e-06,
      "loss": 0.0837,
      "step": 2118
    },
    {
      "epoch": 0.03355130864353912,
      "grad_norm": 0.006332019809633493,
      "learning_rate": 9.664486913564609e-06,
      "loss": 0.0003,
      "step": 2119
    },
    {
      "epoch": 0.033567142201181184,
      "grad_norm": 0.18471118807792664,
      "learning_rate": 9.664328577988188e-06,
      "loss": 0.1791,
      "step": 2120
    },
    {
      "epoch": 0.03358297575882325,
      "grad_norm": 0.34212055802345276,
      "learning_rate": 9.664170242411767e-06,
      "loss": 0.5927,
      "step": 2121
    },
    {
      "epoch": 0.03359880931646532,
      "grad_norm": 0.228125661611557,
      "learning_rate": 9.664011906835348e-06,
      "loss": 0.0616,
      "step": 2122
    },
    {
      "epoch": 0.033614642874107384,
      "grad_norm": 0.02461891993880272,
      "learning_rate": 9.663853571258927e-06,
      "loss": 0.0016,
      "step": 2123
    },
    {
      "epoch": 0.03363047643174945,
      "grad_norm": 0.3071076571941376,
      "learning_rate": 9.663695235682506e-06,
      "loss": 0.6393,
      "step": 2124
    },
    {
      "epoch": 0.03364630998939152,
      "grad_norm": 0.274188369512558,
      "learning_rate": 9.663536900106085e-06,
      "loss": 0.1298,
      "step": 2125
    },
    {
      "epoch": 0.033662143547033584,
      "grad_norm": 0.23923420906066895,
      "learning_rate": 9.663378564529664e-06,
      "loss": 0.3102,
      "step": 2126
    },
    {
      "epoch": 0.03367797710467565,
      "grad_norm": 0.13099616765975952,
      "learning_rate": 9.663220228953243e-06,
      "loss": 0.003,
      "step": 2127
    },
    {
      "epoch": 0.03369381066231772,
      "grad_norm": 0.19126665592193604,
      "learning_rate": 9.663061893376824e-06,
      "loss": 0.1617,
      "step": 2128
    },
    {
      "epoch": 0.03370964421995978,
      "grad_norm": 0.24501492083072662,
      "learning_rate": 9.662903557800403e-06,
      "loss": 0.1692,
      "step": 2129
    },
    {
      "epoch": 0.03372547777760185,
      "grad_norm": 0.0798797532916069,
      "learning_rate": 9.662745222223982e-06,
      "loss": 0.0122,
      "step": 2130
    },
    {
      "epoch": 0.03374131133524392,
      "grad_norm": 7.52436972106807e-05,
      "learning_rate": 9.662586886647561e-06,
      "loss": 0.0,
      "step": 2131
    },
    {
      "epoch": 0.03375714489288598,
      "grad_norm": 0.2331257313489914,
      "learning_rate": 9.66242855107114e-06,
      "loss": 0.159,
      "step": 2132
    },
    {
      "epoch": 0.03377297845052805,
      "grad_norm": 0.013619376346468925,
      "learning_rate": 9.66227021549472e-06,
      "loss": 0.0007,
      "step": 2133
    },
    {
      "epoch": 0.03378881200817012,
      "grad_norm": 0.29710352420806885,
      "learning_rate": 9.6621118799183e-06,
      "loss": 0.1097,
      "step": 2134
    },
    {
      "epoch": 0.03380464556581218,
      "grad_norm": 0.20276162028312683,
      "learning_rate": 9.66195354434188e-06,
      "loss": 0.0329,
      "step": 2135
    },
    {
      "epoch": 0.03382047912345425,
      "grad_norm": 0.1501714438199997,
      "learning_rate": 9.661795208765459e-06,
      "loss": 0.0526,
      "step": 2136
    },
    {
      "epoch": 0.03383631268109632,
      "grad_norm": 1.8878066839533858e-05,
      "learning_rate": 9.661636873189038e-06,
      "loss": 0.0,
      "step": 2137
    },
    {
      "epoch": 0.03385214623873838,
      "grad_norm": 0.18440423905849457,
      "learning_rate": 9.661478537612617e-06,
      "loss": 0.0672,
      "step": 2138
    },
    {
      "epoch": 0.03386797979638045,
      "grad_norm": 1.1874607801437378,
      "learning_rate": 9.661320202036196e-06,
      "loss": 0.2476,
      "step": 2139
    },
    {
      "epoch": 0.03388381335402252,
      "grad_norm": 0.24751845002174377,
      "learning_rate": 9.661161866459777e-06,
      "loss": 0.1335,
      "step": 2140
    },
    {
      "epoch": 0.03389964691166458,
      "grad_norm": 0.4777428209781647,
      "learning_rate": 9.661003530883356e-06,
      "loss": 0.1239,
      "step": 2141
    },
    {
      "epoch": 0.03391548046930665,
      "grad_norm": 0.17438678443431854,
      "learning_rate": 9.660845195306933e-06,
      "loss": 0.0814,
      "step": 2142
    },
    {
      "epoch": 0.03393131402694872,
      "grad_norm": 0.017587484791874886,
      "learning_rate": 9.660686859730514e-06,
      "loss": 0.0003,
      "step": 2143
    },
    {
      "epoch": 0.03394714758459078,
      "grad_norm": 0.13224910199642181,
      "learning_rate": 9.660528524154093e-06,
      "loss": 0.0191,
      "step": 2144
    },
    {
      "epoch": 0.03396298114223285,
      "grad_norm": 0.6968604326248169,
      "learning_rate": 9.660370188577672e-06,
      "loss": 0.8235,
      "step": 2145
    },
    {
      "epoch": 0.03397881469987492,
      "grad_norm": 0.33090320229530334,
      "learning_rate": 9.660211853001251e-06,
      "loss": 0.8817,
      "step": 2146
    },
    {
      "epoch": 0.03399464825751698,
      "grad_norm": 0.4840832054615021,
      "learning_rate": 9.660053517424832e-06,
      "loss": 0.8849,
      "step": 2147
    },
    {
      "epoch": 0.03401048181515905,
      "grad_norm": 0.3098939061164856,
      "learning_rate": 9.65989518184841e-06,
      "loss": 0.3443,
      "step": 2148
    },
    {
      "epoch": 0.03402631537280112,
      "grad_norm": 0.01418212428689003,
      "learning_rate": 9.65973684627199e-06,
      "loss": 0.0008,
      "step": 2149
    },
    {
      "epoch": 0.03404214893044318,
      "grad_norm": 0.6017822027206421,
      "learning_rate": 9.659578510695569e-06,
      "loss": 0.3026,
      "step": 2150
    },
    {
      "epoch": 0.034057982488085246,
      "grad_norm": 0.28512251377105713,
      "learning_rate": 9.659420175119148e-06,
      "loss": 0.1262,
      "step": 2151
    },
    {
      "epoch": 0.03407381604572732,
      "grad_norm": 0.23068416118621826,
      "learning_rate": 9.659261839542727e-06,
      "loss": 0.0749,
      "step": 2152
    },
    {
      "epoch": 0.03408964960336938,
      "grad_norm": 0.5050410032272339,
      "learning_rate": 9.659103503966308e-06,
      "loss": 0.3235,
      "step": 2153
    },
    {
      "epoch": 0.034105483161011446,
      "grad_norm": 0.33644476532936096,
      "learning_rate": 9.658945168389885e-06,
      "loss": 0.0514,
      "step": 2154
    },
    {
      "epoch": 0.03412131671865352,
      "grad_norm": 0.5148358941078186,
      "learning_rate": 9.658786832813466e-06,
      "loss": 0.3209,
      "step": 2155
    },
    {
      "epoch": 0.03413715027629558,
      "grad_norm": 0.012389694340527058,
      "learning_rate": 9.658628497237045e-06,
      "loss": 0.0007,
      "step": 2156
    },
    {
      "epoch": 0.034152983833937646,
      "grad_norm": 0.15053333342075348,
      "learning_rate": 9.658470161660624e-06,
      "loss": 0.2385,
      "step": 2157
    },
    {
      "epoch": 0.03416881739157972,
      "grad_norm": 0.19707348942756653,
      "learning_rate": 9.658311826084203e-06,
      "loss": 0.1542,
      "step": 2158
    },
    {
      "epoch": 0.03418465094922178,
      "grad_norm": 0.36746978759765625,
      "learning_rate": 9.658153490507784e-06,
      "loss": 0.0427,
      "step": 2159
    },
    {
      "epoch": 0.034200484506863846,
      "grad_norm": 0.3191019296646118,
      "learning_rate": 9.657995154931362e-06,
      "loss": 0.4827,
      "step": 2160
    },
    {
      "epoch": 0.03421631806450592,
      "grad_norm": 0.2191353738307953,
      "learning_rate": 9.657836819354942e-06,
      "loss": 0.0623,
      "step": 2161
    },
    {
      "epoch": 0.03423215162214798,
      "grad_norm": 0.18761666119098663,
      "learning_rate": 9.657678483778521e-06,
      "loss": 0.0655,
      "step": 2162
    },
    {
      "epoch": 0.034247985179790046,
      "grad_norm": 0.3940878212451935,
      "learning_rate": 9.6575201482021e-06,
      "loss": 0.2134,
      "step": 2163
    },
    {
      "epoch": 0.03426381873743212,
      "grad_norm": 0.329495370388031,
      "learning_rate": 9.65736181262568e-06,
      "loss": 0.265,
      "step": 2164
    },
    {
      "epoch": 0.03427965229507418,
      "grad_norm": 0.21555747091770172,
      "learning_rate": 9.65720347704926e-06,
      "loss": 0.0491,
      "step": 2165
    },
    {
      "epoch": 0.034295485852716245,
      "grad_norm": 0.16673342883586884,
      "learning_rate": 9.657045141472838e-06,
      "loss": 0.0633,
      "step": 2166
    },
    {
      "epoch": 0.03431131941035832,
      "grad_norm": 0.027389591559767723,
      "learning_rate": 9.656886805896417e-06,
      "loss": 0.0021,
      "step": 2167
    },
    {
      "epoch": 0.03432715296800038,
      "grad_norm": 0.015699544921517372,
      "learning_rate": 9.656728470319998e-06,
      "loss": 0.0012,
      "step": 2168
    },
    {
      "epoch": 0.034342986525642445,
      "grad_norm": 0.3216994106769562,
      "learning_rate": 9.656570134743577e-06,
      "loss": 0.151,
      "step": 2169
    },
    {
      "epoch": 0.034358820083284516,
      "grad_norm": 0.3131158947944641,
      "learning_rate": 9.656411799167156e-06,
      "loss": 0.1719,
      "step": 2170
    },
    {
      "epoch": 0.03437465364092658,
      "grad_norm": 0.012527799233794212,
      "learning_rate": 9.656253463590735e-06,
      "loss": 0.0008,
      "step": 2171
    },
    {
      "epoch": 0.034390487198568645,
      "grad_norm": 0.2533019483089447,
      "learning_rate": 9.656095128014314e-06,
      "loss": 0.1759,
      "step": 2172
    },
    {
      "epoch": 0.034406320756210716,
      "grad_norm": 0.2332921177148819,
      "learning_rate": 9.655936792437893e-06,
      "loss": 0.0754,
      "step": 2173
    },
    {
      "epoch": 0.03442215431385278,
      "grad_norm": 0.1787082850933075,
      "learning_rate": 9.655778456861474e-06,
      "loss": 0.137,
      "step": 2174
    },
    {
      "epoch": 0.034437987871494845,
      "grad_norm": 0.13913357257843018,
      "learning_rate": 9.655620121285053e-06,
      "loss": 0.2155,
      "step": 2175
    },
    {
      "epoch": 0.034453821429136916,
      "grad_norm": 0.005569706205278635,
      "learning_rate": 9.655461785708632e-06,
      "loss": 0.0003,
      "step": 2176
    },
    {
      "epoch": 0.03446965498677898,
      "grad_norm": 0.28633275628089905,
      "learning_rate": 9.655303450132211e-06,
      "loss": 0.5814,
      "step": 2177
    },
    {
      "epoch": 0.034485488544421045,
      "grad_norm": 0.009467987343668938,
      "learning_rate": 9.65514511455579e-06,
      "loss": 0.0006,
      "step": 2178
    },
    {
      "epoch": 0.034501322102063116,
      "grad_norm": 0.19236548244953156,
      "learning_rate": 9.654986778979369e-06,
      "loss": 0.0668,
      "step": 2179
    },
    {
      "epoch": 0.03451715565970518,
      "grad_norm": 0.16720643639564514,
      "learning_rate": 9.65482844340295e-06,
      "loss": 0.0841,
      "step": 2180
    },
    {
      "epoch": 0.034532989217347244,
      "grad_norm": 0.0037829980719834566,
      "learning_rate": 9.654670107826527e-06,
      "loss": 0.0001,
      "step": 2181
    },
    {
      "epoch": 0.034548822774989316,
      "grad_norm": 0.3914591372013092,
      "learning_rate": 9.654511772250108e-06,
      "loss": 0.1293,
      "step": 2182
    },
    {
      "epoch": 0.03456465633263138,
      "grad_norm": 0.29865187406539917,
      "learning_rate": 9.654353436673687e-06,
      "loss": 0.1058,
      "step": 2183
    },
    {
      "epoch": 0.034580489890273444,
      "grad_norm": 0.0001851027918746695,
      "learning_rate": 9.654195101097266e-06,
      "loss": 0.0,
      "step": 2184
    },
    {
      "epoch": 0.034596323447915515,
      "grad_norm": 0.09117244929075241,
      "learning_rate": 9.654036765520845e-06,
      "loss": 0.0437,
      "step": 2185
    },
    {
      "epoch": 0.03461215700555758,
      "grad_norm": 0.3571338951587677,
      "learning_rate": 9.653878429944426e-06,
      "loss": 0.285,
      "step": 2186
    },
    {
      "epoch": 0.034627990563199644,
      "grad_norm": 0.25765594840049744,
      "learning_rate": 9.653720094368003e-06,
      "loss": 0.118,
      "step": 2187
    },
    {
      "epoch": 0.034643824120841715,
      "grad_norm": 0.17753514647483826,
      "learning_rate": 9.653561758791584e-06,
      "loss": 0.115,
      "step": 2188
    },
    {
      "epoch": 0.03465965767848378,
      "grad_norm": 0.001499860198237002,
      "learning_rate": 9.653403423215163e-06,
      "loss": 0.0,
      "step": 2189
    },
    {
      "epoch": 0.034675491236125844,
      "grad_norm": 0.5826377272605896,
      "learning_rate": 9.653245087638742e-06,
      "loss": 0.2024,
      "step": 2190
    },
    {
      "epoch": 0.034691324793767915,
      "grad_norm": 0.2624950706958771,
      "learning_rate": 9.653086752062321e-06,
      "loss": 0.0848,
      "step": 2191
    },
    {
      "epoch": 0.03470715835140998,
      "grad_norm": 0.21188335120677948,
      "learning_rate": 9.6529284164859e-06,
      "loss": 0.1402,
      "step": 2192
    },
    {
      "epoch": 0.034722991909052044,
      "grad_norm": 0.16023065149784088,
      "learning_rate": 9.65277008090948e-06,
      "loss": 0.059,
      "step": 2193
    },
    {
      "epoch": 0.034738825466694115,
      "grad_norm": 0.10419537127017975,
      "learning_rate": 9.652611745333059e-06,
      "loss": 0.0814,
      "step": 2194
    },
    {
      "epoch": 0.03475465902433618,
      "grad_norm": 0.13548745214939117,
      "learning_rate": 9.65245340975664e-06,
      "loss": 0.0635,
      "step": 2195
    },
    {
      "epoch": 0.03477049258197824,
      "grad_norm": 0.352615088224411,
      "learning_rate": 9.652295074180219e-06,
      "loss": 0.1343,
      "step": 2196
    },
    {
      "epoch": 0.034786326139620315,
      "grad_norm": 0.4252481758594513,
      "learning_rate": 9.652136738603798e-06,
      "loss": 0.0307,
      "step": 2197
    },
    {
      "epoch": 0.03480215969726238,
      "grad_norm": 0.0026529072783887386,
      "learning_rate": 9.651978403027377e-06,
      "loss": 0.0,
      "step": 2198
    },
    {
      "epoch": 0.03481799325490444,
      "grad_norm": 0.006505422294139862,
      "learning_rate": 9.651820067450956e-06,
      "loss": 0.0003,
      "step": 2199
    },
    {
      "epoch": 0.034833826812546514,
      "grad_norm": 0.27451178431510925,
      "learning_rate": 9.651661731874535e-06,
      "loss": 0.1361,
      "step": 2200
    },
    {
      "epoch": 0.03484966037018858,
      "grad_norm": 0.10754604637622833,
      "learning_rate": 9.651503396298116e-06,
      "loss": 0.1658,
      "step": 2201
    },
    {
      "epoch": 0.03486549392783064,
      "grad_norm": 0.00011441967217251658,
      "learning_rate": 9.651345060721695e-06,
      "loss": 0.0,
      "step": 2202
    },
    {
      "epoch": 0.034881327485472714,
      "grad_norm": 0.4376071095466614,
      "learning_rate": 9.651186725145274e-06,
      "loss": 0.1111,
      "step": 2203
    },
    {
      "epoch": 0.03489716104311478,
      "grad_norm": 0.2621849775314331,
      "learning_rate": 9.651028389568853e-06,
      "loss": 0.2527,
      "step": 2204
    },
    {
      "epoch": 0.03491299460075684,
      "grad_norm": 0.06444969028234482,
      "learning_rate": 9.650870053992432e-06,
      "loss": 0.0062,
      "step": 2205
    },
    {
      "epoch": 0.034928828158398914,
      "grad_norm": 0.16647066175937653,
      "learning_rate": 9.650711718416011e-06,
      "loss": 0.2209,
      "step": 2206
    },
    {
      "epoch": 0.03494466171604098,
      "grad_norm": 0.2023501992225647,
      "learning_rate": 9.650553382839592e-06,
      "loss": 0.0425,
      "step": 2207
    },
    {
      "epoch": 0.03496049527368304,
      "grad_norm": 0.15597933530807495,
      "learning_rate": 9.650395047263171e-06,
      "loss": 0.1313,
      "step": 2208
    },
    {
      "epoch": 0.034976328831325114,
      "grad_norm": 0.17480003833770752,
      "learning_rate": 9.65023671168675e-06,
      "loss": 0.5545,
      "step": 2209
    },
    {
      "epoch": 0.03499216238896718,
      "grad_norm": 0.0104835145175457,
      "learning_rate": 9.650078376110329e-06,
      "loss": 0.0004,
      "step": 2210
    },
    {
      "epoch": 0.03500799594660924,
      "grad_norm": 9.069534280570224e-05,
      "learning_rate": 9.649920040533908e-06,
      "loss": 0.0,
      "step": 2211
    },
    {
      "epoch": 0.035023829504251314,
      "grad_norm": 0.2753390967845917,
      "learning_rate": 9.649761704957487e-06,
      "loss": 0.2495,
      "step": 2212
    },
    {
      "epoch": 0.03503966306189338,
      "grad_norm": 0.07644589245319366,
      "learning_rate": 9.649603369381068e-06,
      "loss": 0.0101,
      "step": 2213
    },
    {
      "epoch": 0.03505549661953544,
      "grad_norm": 0.23350180685520172,
      "learning_rate": 9.649445033804647e-06,
      "loss": 0.1244,
      "step": 2214
    },
    {
      "epoch": 0.03507133017717751,
      "grad_norm": 0.2091517448425293,
      "learning_rate": 9.649286698228224e-06,
      "loss": 0.2914,
      "step": 2215
    },
    {
      "epoch": 0.03508716373481958,
      "grad_norm": 0.0017411586595699191,
      "learning_rate": 9.649128362651805e-06,
      "loss": 0.0,
      "step": 2216
    },
    {
      "epoch": 0.03510299729246164,
      "grad_norm": 0.20330336689949036,
      "learning_rate": 9.648970027075384e-06,
      "loss": 0.2072,
      "step": 2217
    },
    {
      "epoch": 0.035118830850103706,
      "grad_norm": 0.0077331773936748505,
      "learning_rate": 9.648811691498963e-06,
      "loss": 0.0003,
      "step": 2218
    },
    {
      "epoch": 0.03513466440774578,
      "grad_norm": 0.16486497223377228,
      "learning_rate": 9.648653355922542e-06,
      "loss": 0.1403,
      "step": 2219
    },
    {
      "epoch": 0.03515049796538784,
      "grad_norm": 0.21216300129890442,
      "learning_rate": 9.648495020346123e-06,
      "loss": 0.0318,
      "step": 2220
    },
    {
      "epoch": 0.035166331523029906,
      "grad_norm": 0.040101271122694016,
      "learning_rate": 9.6483366847697e-06,
      "loss": 0.0025,
      "step": 2221
    },
    {
      "epoch": 0.03518216508067198,
      "grad_norm": 0.19404961168766022,
      "learning_rate": 9.648178349193281e-06,
      "loss": 0.0985,
      "step": 2222
    },
    {
      "epoch": 0.03519799863831404,
      "grad_norm": 0.008840011432766914,
      "learning_rate": 9.64802001361686e-06,
      "loss": 0.0005,
      "step": 2223
    },
    {
      "epoch": 0.035213832195956106,
      "grad_norm": 0.13936132192611694,
      "learning_rate": 9.64786167804044e-06,
      "loss": 0.1236,
      "step": 2224
    },
    {
      "epoch": 0.03522966575359818,
      "grad_norm": 0.2759804129600525,
      "learning_rate": 9.647703342464019e-06,
      "loss": 0.2226,
      "step": 2225
    },
    {
      "epoch": 0.03524549931124024,
      "grad_norm": 0.3755699396133423,
      "learning_rate": 9.6475450068876e-06,
      "loss": 0.7531,
      "step": 2226
    },
    {
      "epoch": 0.035261332868882306,
      "grad_norm": 0.17159603536128998,
      "learning_rate": 9.647386671311177e-06,
      "loss": 0.1616,
      "step": 2227
    },
    {
      "epoch": 0.03527716642652438,
      "grad_norm": 0.0011583180166780949,
      "learning_rate": 9.647228335734758e-06,
      "loss": 0.0,
      "step": 2228
    },
    {
      "epoch": 0.03529299998416644,
      "grad_norm": 0.24403762817382812,
      "learning_rate": 9.647070000158337e-06,
      "loss": 0.0536,
      "step": 2229
    },
    {
      "epoch": 0.035308833541808506,
      "grad_norm": 0.11752799898386002,
      "learning_rate": 9.646911664581916e-06,
      "loss": 0.1365,
      "step": 2230
    },
    {
      "epoch": 0.03532466709945058,
      "grad_norm": 0.011621647514402866,
      "learning_rate": 9.646753329005495e-06,
      "loss": 0.0006,
      "step": 2231
    },
    {
      "epoch": 0.03534050065709264,
      "grad_norm": 0.0003310173924546689,
      "learning_rate": 9.646594993429076e-06,
      "loss": 0.0,
      "step": 2232
    },
    {
      "epoch": 0.035356334214734705,
      "grad_norm": 0.0035198675468564034,
      "learning_rate": 9.646436657852653e-06,
      "loss": 0.0002,
      "step": 2233
    },
    {
      "epoch": 0.03537216777237678,
      "grad_norm": 0.15675723552703857,
      "learning_rate": 9.646278322276234e-06,
      "loss": 0.0673,
      "step": 2234
    },
    {
      "epoch": 0.03538800133001884,
      "grad_norm": 0.47589603066444397,
      "learning_rate": 9.646119986699813e-06,
      "loss": 0.5154,
      "step": 2235
    },
    {
      "epoch": 0.035403834887660905,
      "grad_norm": 0.0075715952552855015,
      "learning_rate": 9.645961651123392e-06,
      "loss": 0.0004,
      "step": 2236
    },
    {
      "epoch": 0.035419668445302976,
      "grad_norm": 0.49976494908332825,
      "learning_rate": 9.645803315546971e-06,
      "loss": 0.1721,
      "step": 2237
    },
    {
      "epoch": 0.03543550200294504,
      "grad_norm": 0.2876819968223572,
      "learning_rate": 9.64564497997055e-06,
      "loss": 0.1744,
      "step": 2238
    },
    {
      "epoch": 0.035451335560587105,
      "grad_norm": 0.24689055979251862,
      "learning_rate": 9.645486644394129e-06,
      "loss": 0.0527,
      "step": 2239
    },
    {
      "epoch": 0.035467169118229176,
      "grad_norm": 0.3671773672103882,
      "learning_rate": 9.645328308817708e-06,
      "loss": 0.2019,
      "step": 2240
    },
    {
      "epoch": 0.03548300267587124,
      "grad_norm": 0.5032632946968079,
      "learning_rate": 9.645169973241289e-06,
      "loss": 0.362,
      "step": 2241
    },
    {
      "epoch": 0.035498836233513305,
      "grad_norm": 0.24190200865268707,
      "learning_rate": 9.645011637664868e-06,
      "loss": 0.1295,
      "step": 2242
    },
    {
      "epoch": 0.035514669791155376,
      "grad_norm": 0.03174448758363724,
      "learning_rate": 9.644853302088447e-06,
      "loss": 0.0009,
      "step": 2243
    },
    {
      "epoch": 0.03553050334879744,
      "grad_norm": 0.22728408873081207,
      "learning_rate": 9.644694966512026e-06,
      "loss": 0.2731,
      "step": 2244
    },
    {
      "epoch": 0.035546336906439505,
      "grad_norm": 0.21861764788627625,
      "learning_rate": 9.644536630935605e-06,
      "loss": 0.102,
      "step": 2245
    },
    {
      "epoch": 0.035562170464081576,
      "grad_norm": 0.18751703202724457,
      "learning_rate": 9.644378295359184e-06,
      "loss": 0.1393,
      "step": 2246
    },
    {
      "epoch": 0.03557800402172364,
      "grad_norm": 0.17482499778270721,
      "learning_rate": 9.644219959782765e-06,
      "loss": 0.2942,
      "step": 2247
    },
    {
      "epoch": 0.035593837579365704,
      "grad_norm": 0.16319511830806732,
      "learning_rate": 9.644061624206343e-06,
      "loss": 0.0447,
      "step": 2248
    },
    {
      "epoch": 0.035609671137007776,
      "grad_norm": 0.22522194683551788,
      "learning_rate": 9.643903288629923e-06,
      "loss": 0.0537,
      "step": 2249
    },
    {
      "epoch": 0.03562550469464984,
      "grad_norm": 0.30492183566093445,
      "learning_rate": 9.643744953053502e-06,
      "loss": 0.4262,
      "step": 2250
    },
    {
      "epoch": 0.035641338252291904,
      "grad_norm": 0.1825820356607437,
      "learning_rate": 9.643586617477081e-06,
      "loss": 0.1568,
      "step": 2251
    },
    {
      "epoch": 0.035657171809933975,
      "grad_norm": 0.13816313445568085,
      "learning_rate": 9.64342828190066e-06,
      "loss": 0.0125,
      "step": 2252
    },
    {
      "epoch": 0.03567300536757604,
      "grad_norm": 0.16334973275661469,
      "learning_rate": 9.643269946324241e-06,
      "loss": 0.0615,
      "step": 2253
    },
    {
      "epoch": 0.035688838925218104,
      "grad_norm": 0.19463452696800232,
      "learning_rate": 9.643111610747819e-06,
      "loss": 0.2067,
      "step": 2254
    },
    {
      "epoch": 0.035704672482860175,
      "grad_norm": 0.2930385172367096,
      "learning_rate": 9.6429532751714e-06,
      "loss": 0.405,
      "step": 2255
    },
    {
      "epoch": 0.03572050604050224,
      "grad_norm": 0.16059695184230804,
      "learning_rate": 9.642794939594979e-06,
      "loss": 0.2816,
      "step": 2256
    },
    {
      "epoch": 0.035736339598144304,
      "grad_norm": 0.24982009828090668,
      "learning_rate": 9.642636604018558e-06,
      "loss": 0.2969,
      "step": 2257
    },
    {
      "epoch": 0.035752173155786375,
      "grad_norm": 0.17414042353630066,
      "learning_rate": 9.642478268442137e-06,
      "loss": 0.0555,
      "step": 2258
    },
    {
      "epoch": 0.03576800671342844,
      "grad_norm": 1.695571780204773,
      "learning_rate": 9.642319932865718e-06,
      "loss": 0.1128,
      "step": 2259
    },
    {
      "epoch": 0.035783840271070504,
      "grad_norm": 0.16352394223213196,
      "learning_rate": 9.642161597289295e-06,
      "loss": 0.092,
      "step": 2260
    },
    {
      "epoch": 0.035799673828712575,
      "grad_norm": 0.2522270679473877,
      "learning_rate": 9.642003261712876e-06,
      "loss": 0.1018,
      "step": 2261
    },
    {
      "epoch": 0.03581550738635464,
      "grad_norm": 0.9070124626159668,
      "learning_rate": 9.641844926136455e-06,
      "loss": 0.3451,
      "step": 2262
    },
    {
      "epoch": 0.0358313409439967,
      "grad_norm": 0.2575909197330475,
      "learning_rate": 9.641686590560034e-06,
      "loss": 0.0493,
      "step": 2263
    },
    {
      "epoch": 0.035847174501638775,
      "grad_norm": 0.36974450945854187,
      "learning_rate": 9.641528254983613e-06,
      "loss": 1.0191,
      "step": 2264
    },
    {
      "epoch": 0.03586300805928084,
      "grad_norm": 0.16440321505069733,
      "learning_rate": 9.641369919407192e-06,
      "loss": 0.1266,
      "step": 2265
    },
    {
      "epoch": 0.0358788416169229,
      "grad_norm": 0.2436601221561432,
      "learning_rate": 9.641211583830771e-06,
      "loss": 0.4369,
      "step": 2266
    },
    {
      "epoch": 0.035894675174564974,
      "grad_norm": 0.07923034578561783,
      "learning_rate": 9.64105324825435e-06,
      "loss": 0.0029,
      "step": 2267
    },
    {
      "epoch": 0.03591050873220704,
      "grad_norm": 0.2328445315361023,
      "learning_rate": 9.640894912677931e-06,
      "loss": 0.1106,
      "step": 2268
    },
    {
      "epoch": 0.0359263422898491,
      "grad_norm": 0.26113754510879517,
      "learning_rate": 9.64073657710151e-06,
      "loss": 0.0482,
      "step": 2269
    },
    {
      "epoch": 0.035942175847491174,
      "grad_norm": 0.7567091584205627,
      "learning_rate": 9.640578241525089e-06,
      "loss": 0.5353,
      "step": 2270
    },
    {
      "epoch": 0.03595800940513324,
      "grad_norm": 0.2547876536846161,
      "learning_rate": 9.640419905948668e-06,
      "loss": 0.4224,
      "step": 2271
    },
    {
      "epoch": 0.0359738429627753,
      "grad_norm": 0.18015849590301514,
      "learning_rate": 9.640261570372247e-06,
      "loss": 0.0325,
      "step": 2272
    },
    {
      "epoch": 0.035989676520417374,
      "grad_norm": 0.19975507259368896,
      "learning_rate": 9.640103234795826e-06,
      "loss": 0.1892,
      "step": 2273
    },
    {
      "epoch": 0.03600551007805944,
      "grad_norm": 0.39109230041503906,
      "learning_rate": 9.639944899219407e-06,
      "loss": 0.2001,
      "step": 2274
    },
    {
      "epoch": 0.0360213436357015,
      "grad_norm": 0.10439812391996384,
      "learning_rate": 9.639786563642986e-06,
      "loss": 0.1123,
      "step": 2275
    },
    {
      "epoch": 0.036037177193343574,
      "grad_norm": 6.340337131405249e-05,
      "learning_rate": 9.639628228066565e-06,
      "loss": 0.0,
      "step": 2276
    },
    {
      "epoch": 0.03605301075098564,
      "grad_norm": 0.10222204029560089,
      "learning_rate": 9.639469892490144e-06,
      "loss": 0.0508,
      "step": 2277
    },
    {
      "epoch": 0.0360688443086277,
      "grad_norm": 0.0046998015604913235,
      "learning_rate": 9.639311556913723e-06,
      "loss": 0.0004,
      "step": 2278
    },
    {
      "epoch": 0.036084677866269774,
      "grad_norm": 0.3103429675102234,
      "learning_rate": 9.639153221337302e-06,
      "loss": 0.8836,
      "step": 2279
    },
    {
      "epoch": 0.03610051142391184,
      "grad_norm": 0.6954065561294556,
      "learning_rate": 9.638994885760883e-06,
      "loss": 0.5928,
      "step": 2280
    },
    {
      "epoch": 0.0361163449815539,
      "grad_norm": 0.16289834678173065,
      "learning_rate": 9.638836550184462e-06,
      "loss": 0.1621,
      "step": 2281
    },
    {
      "epoch": 0.036132178539195973,
      "grad_norm": 9.02386091183871e-05,
      "learning_rate": 9.638678214608041e-06,
      "loss": 0.0,
      "step": 2282
    },
    {
      "epoch": 0.03614801209683804,
      "grad_norm": 0.2508172392845154,
      "learning_rate": 9.63851987903162e-06,
      "loss": 0.1283,
      "step": 2283
    },
    {
      "epoch": 0.0361638456544801,
      "grad_norm": 0.17317575216293335,
      "learning_rate": 9.6383615434552e-06,
      "loss": 0.101,
      "step": 2284
    },
    {
      "epoch": 0.03617967921212217,
      "grad_norm": 0.3194368779659271,
      "learning_rate": 9.638203207878779e-06,
      "loss": 0.3874,
      "step": 2285
    },
    {
      "epoch": 0.03619551276976424,
      "grad_norm": 0.25014156103134155,
      "learning_rate": 9.638044872302358e-06,
      "loss": 0.4978,
      "step": 2286
    },
    {
      "epoch": 0.0362113463274063,
      "grad_norm": 0.17048704624176025,
      "learning_rate": 9.637886536725939e-06,
      "loss": 0.0978,
      "step": 2287
    },
    {
      "epoch": 0.03622717988504837,
      "grad_norm": 0.2440919280052185,
      "learning_rate": 9.637728201149516e-06,
      "loss": 0.2977,
      "step": 2288
    },
    {
      "epoch": 0.03624301344269044,
      "grad_norm": 0.12405233830213547,
      "learning_rate": 9.637569865573097e-06,
      "loss": 0.0396,
      "step": 2289
    },
    {
      "epoch": 0.0362588470003325,
      "grad_norm": 0.23852457106113434,
      "learning_rate": 9.637411529996676e-06,
      "loss": 0.2197,
      "step": 2290
    },
    {
      "epoch": 0.03627468055797457,
      "grad_norm": 0.19832763075828552,
      "learning_rate": 9.637253194420255e-06,
      "loss": 0.2246,
      "step": 2291
    },
    {
      "epoch": 0.03629051411561664,
      "grad_norm": 0.277351975440979,
      "learning_rate": 9.637094858843834e-06,
      "loss": 0.0877,
      "step": 2292
    },
    {
      "epoch": 0.0363063476732587,
      "grad_norm": 0.005729359108954668,
      "learning_rate": 9.636936523267415e-06,
      "loss": 0.0004,
      "step": 2293
    },
    {
      "epoch": 0.03632218123090077,
      "grad_norm": 0.24045045673847198,
      "learning_rate": 9.636778187690992e-06,
      "loss": 0.0627,
      "step": 2294
    },
    {
      "epoch": 0.03633801478854284,
      "grad_norm": 0.19809992611408234,
      "learning_rate": 9.636619852114573e-06,
      "loss": 0.2602,
      "step": 2295
    },
    {
      "epoch": 0.0363538483461849,
      "grad_norm": 0.35121625661849976,
      "learning_rate": 9.636461516538152e-06,
      "loss": 0.522,
      "step": 2296
    },
    {
      "epoch": 0.03636968190382697,
      "grad_norm": 0.14925318956375122,
      "learning_rate": 9.636303180961731e-06,
      "loss": 0.0179,
      "step": 2297
    },
    {
      "epoch": 0.03638551546146904,
      "grad_norm": 0.4679991900920868,
      "learning_rate": 9.63614484538531e-06,
      "loss": 0.2312,
      "step": 2298
    },
    {
      "epoch": 0.0364013490191111,
      "grad_norm": 0.23544643819332123,
      "learning_rate": 9.635986509808891e-06,
      "loss": 0.0085,
      "step": 2299
    },
    {
      "epoch": 0.03641718257675317,
      "grad_norm": 0.30615055561065674,
      "learning_rate": 9.635828174232468e-06,
      "loss": 0.3087,
      "step": 2300
    },
    {
      "epoch": 0.03643301613439524,
      "grad_norm": 0.14277289807796478,
      "learning_rate": 9.635669838656049e-06,
      "loss": 0.1261,
      "step": 2301
    },
    {
      "epoch": 0.0364488496920373,
      "grad_norm": 0.013628248125314713,
      "learning_rate": 9.635511503079628e-06,
      "loss": 0.0008,
      "step": 2302
    },
    {
      "epoch": 0.03646468324967937,
      "grad_norm": 0.15200866758823395,
      "learning_rate": 9.635353167503207e-06,
      "loss": 0.0313,
      "step": 2303
    },
    {
      "epoch": 0.036480516807321436,
      "grad_norm": 0.2135559618473053,
      "learning_rate": 9.635194831926786e-06,
      "loss": 0.5549,
      "step": 2304
    },
    {
      "epoch": 0.0364963503649635,
      "grad_norm": 0.32898223400115967,
      "learning_rate": 9.635036496350367e-06,
      "loss": 0.9807,
      "step": 2305
    },
    {
      "epoch": 0.03651218392260557,
      "grad_norm": 0.2382412552833557,
      "learning_rate": 9.634878160773944e-06,
      "loss": 0.0336,
      "step": 2306
    },
    {
      "epoch": 0.036528017480247636,
      "grad_norm": 0.502782940864563,
      "learning_rate": 9.634719825197525e-06,
      "loss": 0.163,
      "step": 2307
    },
    {
      "epoch": 0.0365438510378897,
      "grad_norm": 0.130975142121315,
      "learning_rate": 9.634561489621104e-06,
      "loss": 0.0165,
      "step": 2308
    },
    {
      "epoch": 0.03655968459553177,
      "grad_norm": 0.17457067966461182,
      "learning_rate": 9.634403154044683e-06,
      "loss": 0.1768,
      "step": 2309
    },
    {
      "epoch": 0.036575518153173836,
      "grad_norm": 0.00010036381718236953,
      "learning_rate": 9.634244818468262e-06,
      "loss": 0.0,
      "step": 2310
    },
    {
      "epoch": 0.0365913517108159,
      "grad_norm": 0.16081702709197998,
      "learning_rate": 9.634086482891842e-06,
      "loss": 0.0991,
      "step": 2311
    },
    {
      "epoch": 0.03660718526845797,
      "grad_norm": 0.33653974533081055,
      "learning_rate": 9.63392814731542e-06,
      "loss": 0.183,
      "step": 2312
    },
    {
      "epoch": 0.036623018826100036,
      "grad_norm": 4.2538278648862615e-05,
      "learning_rate": 9.633769811739e-06,
      "loss": 0.0,
      "step": 2313
    },
    {
      "epoch": 0.0366388523837421,
      "grad_norm": 0.352954238653183,
      "learning_rate": 9.63361147616258e-06,
      "loss": 0.545,
      "step": 2314
    },
    {
      "epoch": 0.03665468594138417,
      "grad_norm": 0.0015862889122217894,
      "learning_rate": 9.633453140586158e-06,
      "loss": 0.0,
      "step": 2315
    },
    {
      "epoch": 0.036670519499026236,
      "grad_norm": 0.21768590807914734,
      "learning_rate": 9.633294805009739e-06,
      "loss": 0.1899,
      "step": 2316
    },
    {
      "epoch": 0.0366863530566683,
      "grad_norm": 0.2397667020559311,
      "learning_rate": 9.633136469433318e-06,
      "loss": 0.1322,
      "step": 2317
    },
    {
      "epoch": 0.03670218661431037,
      "grad_norm": 0.2021428495645523,
      "learning_rate": 9.632978133856897e-06,
      "loss": 0.0832,
      "step": 2318
    },
    {
      "epoch": 0.036718020171952435,
      "grad_norm": 0.19091233611106873,
      "learning_rate": 9.632819798280476e-06,
      "loss": 0.6377,
      "step": 2319
    },
    {
      "epoch": 0.0367338537295945,
      "grad_norm": 0.2312638759613037,
      "learning_rate": 9.632661462704057e-06,
      "loss": 0.1321,
      "step": 2320
    },
    {
      "epoch": 0.03674968728723657,
      "grad_norm": 0.2831008732318878,
      "learning_rate": 9.632503127127634e-06,
      "loss": 0.1202,
      "step": 2321
    },
    {
      "epoch": 0.036765520844878635,
      "grad_norm": 5.138817310333252,
      "learning_rate": 9.632344791551215e-06,
      "loss": 0.5869,
      "step": 2322
    },
    {
      "epoch": 0.0367813544025207,
      "grad_norm": 0.025907164439558983,
      "learning_rate": 9.632186455974794e-06,
      "loss": 0.0014,
      "step": 2323
    },
    {
      "epoch": 0.03679718796016277,
      "grad_norm": 0.3517865240573883,
      "learning_rate": 9.632028120398373e-06,
      "loss": 0.2778,
      "step": 2324
    },
    {
      "epoch": 0.036813021517804835,
      "grad_norm": 0.019581014290452003,
      "learning_rate": 9.631869784821952e-06,
      "loss": 0.0015,
      "step": 2325
    },
    {
      "epoch": 0.0368288550754469,
      "grad_norm": 0.09988363832235336,
      "learning_rate": 9.631711449245533e-06,
      "loss": 0.1143,
      "step": 2326
    },
    {
      "epoch": 0.03684468863308897,
      "grad_norm": 4.922886728309095e-05,
      "learning_rate": 9.63155311366911e-06,
      "loss": 0.0,
      "step": 2327
    },
    {
      "epoch": 0.036860522190731035,
      "grad_norm": 0.43868646025657654,
      "learning_rate": 9.631394778092691e-06,
      "loss": 0.6408,
      "step": 2328
    },
    {
      "epoch": 0.0368763557483731,
      "grad_norm": 0.28848254680633545,
      "learning_rate": 9.63123644251627e-06,
      "loss": 0.128,
      "step": 2329
    },
    {
      "epoch": 0.03689218930601517,
      "grad_norm": 0.025764362886548042,
      "learning_rate": 9.631078106939849e-06,
      "loss": 0.0018,
      "step": 2330
    },
    {
      "epoch": 0.036908022863657235,
      "grad_norm": 0.2709597647190094,
      "learning_rate": 9.630919771363428e-06,
      "loss": 0.2626,
      "step": 2331
    },
    {
      "epoch": 0.0369238564212993,
      "grad_norm": 1.2569782733917236,
      "learning_rate": 9.630761435787009e-06,
      "loss": 0.0655,
      "step": 2332
    },
    {
      "epoch": 0.03693968997894137,
      "grad_norm": 0.17587676644325256,
      "learning_rate": 9.630603100210586e-06,
      "loss": 0.2161,
      "step": 2333
    },
    {
      "epoch": 0.036955523536583434,
      "grad_norm": 0.2807467579841614,
      "learning_rate": 9.630444764634165e-06,
      "loss": 0.3681,
      "step": 2334
    },
    {
      "epoch": 0.0369713570942255,
      "grad_norm": 0.019110750406980515,
      "learning_rate": 9.630286429057746e-06,
      "loss": 0.0013,
      "step": 2335
    },
    {
      "epoch": 0.03698719065186757,
      "grad_norm": 0.1969696432352066,
      "learning_rate": 9.630128093481325e-06,
      "loss": 0.1156,
      "step": 2336
    },
    {
      "epoch": 0.037003024209509634,
      "grad_norm": 0.17432419955730438,
      "learning_rate": 9.629969757904904e-06,
      "loss": 0.2449,
      "step": 2337
    },
    {
      "epoch": 0.0370188577671517,
      "grad_norm": 0.12854109704494476,
      "learning_rate": 9.629811422328483e-06,
      "loss": 0.1803,
      "step": 2338
    },
    {
      "epoch": 0.03703469132479377,
      "grad_norm": 0.018470700830221176,
      "learning_rate": 9.629653086752063e-06,
      "loss": 0.0014,
      "step": 2339
    },
    {
      "epoch": 0.037050524882435834,
      "grad_norm": 0.028178667649626732,
      "learning_rate": 9.629494751175642e-06,
      "loss": 0.0019,
      "step": 2340
    },
    {
      "epoch": 0.0370663584400779,
      "grad_norm": 0.3453865647315979,
      "learning_rate": 9.629336415599222e-06,
      "loss": 0.6998,
      "step": 2341
    },
    {
      "epoch": 0.03708219199771997,
      "grad_norm": 0.7412229180335999,
      "learning_rate": 9.629178080022801e-06,
      "loss": 0.1095,
      "step": 2342
    },
    {
      "epoch": 0.037098025555362034,
      "grad_norm": 0.2002539336681366,
      "learning_rate": 9.62901974444638e-06,
      "loss": 0.0068,
      "step": 2343
    },
    {
      "epoch": 0.0371138591130041,
      "grad_norm": 0.296813040971756,
      "learning_rate": 9.62886140886996e-06,
      "loss": 0.6175,
      "step": 2344
    },
    {
      "epoch": 0.03712969267064617,
      "grad_norm": 0.14289215207099915,
      "learning_rate": 9.628703073293539e-06,
      "loss": 0.1168,
      "step": 2345
    },
    {
      "epoch": 0.037145526228288234,
      "grad_norm": 0.3494161069393158,
      "learning_rate": 9.628544737717118e-06,
      "loss": 0.9223,
      "step": 2346
    },
    {
      "epoch": 0.0371613597859303,
      "grad_norm": 0.5921170115470886,
      "learning_rate": 9.628386402140699e-06,
      "loss": 0.6181,
      "step": 2347
    },
    {
      "epoch": 0.03717719334357237,
      "grad_norm": 0.0058856550604105,
      "learning_rate": 9.628228066564278e-06,
      "loss": 0.0004,
      "step": 2348
    },
    {
      "epoch": 0.037193026901214433,
      "grad_norm": 0.17721296846866608,
      "learning_rate": 9.628069730987857e-06,
      "loss": 0.0722,
      "step": 2349
    },
    {
      "epoch": 0.0372088604588565,
      "grad_norm": 0.017464114353060722,
      "learning_rate": 9.627911395411436e-06,
      "loss": 0.0022,
      "step": 2350
    },
    {
      "epoch": 0.03722469401649857,
      "grad_norm": 0.02134157530963421,
      "learning_rate": 9.627753059835015e-06,
      "loss": 0.0014,
      "step": 2351
    },
    {
      "epoch": 0.03724052757414063,
      "grad_norm": 0.005136486608535051,
      "learning_rate": 9.627594724258594e-06,
      "loss": 0.0004,
      "step": 2352
    },
    {
      "epoch": 0.0372563611317827,
      "grad_norm": 0.012684760615229607,
      "learning_rate": 9.627436388682175e-06,
      "loss": 0.001,
      "step": 2353
    },
    {
      "epoch": 0.03727219468942477,
      "grad_norm": 0.4291542172431946,
      "learning_rate": 9.627278053105754e-06,
      "loss": 0.2372,
      "step": 2354
    },
    {
      "epoch": 0.03728802824706683,
      "grad_norm": 0.09854841977357864,
      "learning_rate": 9.627119717529333e-06,
      "loss": 0.0049,
      "step": 2355
    },
    {
      "epoch": 0.0373038618047089,
      "grad_norm": 0.00032504339469596744,
      "learning_rate": 9.626961381952912e-06,
      "loss": 0.0,
      "step": 2356
    },
    {
      "epoch": 0.03731969536235097,
      "grad_norm": 0.19297006726264954,
      "learning_rate": 9.626803046376491e-06,
      "loss": 0.0408,
      "step": 2357
    },
    {
      "epoch": 0.03733552891999303,
      "grad_norm": 0.29288673400878906,
      "learning_rate": 9.62664471080007e-06,
      "loss": 0.2929,
      "step": 2358
    },
    {
      "epoch": 0.0373513624776351,
      "grad_norm": 0.00018135854043066502,
      "learning_rate": 9.62648637522365e-06,
      "loss": 0.0,
      "step": 2359
    },
    {
      "epoch": 0.03736719603527717,
      "grad_norm": 0.4961111545562744,
      "learning_rate": 9.62632803964723e-06,
      "loss": 0.0637,
      "step": 2360
    },
    {
      "epoch": 0.03738302959291923,
      "grad_norm": 0.7149310111999512,
      "learning_rate": 9.626169704070807e-06,
      "loss": 0.8313,
      "step": 2361
    },
    {
      "epoch": 0.0373988631505613,
      "grad_norm": 0.014205406419932842,
      "learning_rate": 9.626011368494388e-06,
      "loss": 0.0022,
      "step": 2362
    },
    {
      "epoch": 0.03741469670820337,
      "grad_norm": 0.015457730740308762,
      "learning_rate": 9.625853032917967e-06,
      "loss": 0.0013,
      "step": 2363
    },
    {
      "epoch": 0.03743053026584543,
      "grad_norm": 0.15157684683799744,
      "learning_rate": 9.625694697341546e-06,
      "loss": 0.1015,
      "step": 2364
    },
    {
      "epoch": 0.0374463638234875,
      "grad_norm": 0.016613824293017387,
      "learning_rate": 9.625536361765125e-06,
      "loss": 0.0015,
      "step": 2365
    },
    {
      "epoch": 0.03746219738112957,
      "grad_norm": 0.19315432012081146,
      "learning_rate": 9.625378026188706e-06,
      "loss": 0.4909,
      "step": 2366
    },
    {
      "epoch": 0.03747803093877163,
      "grad_norm": 0.17820203304290771,
      "learning_rate": 9.625219690612284e-06,
      "loss": 0.0981,
      "step": 2367
    },
    {
      "epoch": 0.0374938644964137,
      "grad_norm": 0.43128085136413574,
      "learning_rate": 9.625061355035864e-06,
      "loss": 0.097,
      "step": 2368
    },
    {
      "epoch": 0.03750969805405577,
      "grad_norm": 0.00038639098056592047,
      "learning_rate": 9.624903019459443e-06,
      "loss": 0.0,
      "step": 2369
    },
    {
      "epoch": 0.03752553161169783,
      "grad_norm": 0.010212321765720844,
      "learning_rate": 9.624744683883022e-06,
      "loss": 0.0008,
      "step": 2370
    },
    {
      "epoch": 0.037541365169339896,
      "grad_norm": 0.16552124917507172,
      "learning_rate": 9.624586348306602e-06,
      "loss": 0.9525,
      "step": 2371
    },
    {
      "epoch": 0.03755719872698197,
      "grad_norm": 0.0003574842703528702,
      "learning_rate": 9.62442801273018e-06,
      "loss": 0.0,
      "step": 2372
    },
    {
      "epoch": 0.03757303228462403,
      "grad_norm": 0.0636560469865799,
      "learning_rate": 9.62426967715376e-06,
      "loss": 0.0068,
      "step": 2373
    },
    {
      "epoch": 0.037588865842266096,
      "grad_norm": 0.0003051795647479594,
      "learning_rate": 9.62411134157734e-06,
      "loss": 0.0,
      "step": 2374
    },
    {
      "epoch": 0.03760469939990817,
      "grad_norm": 0.10956041514873505,
      "learning_rate": 9.62395300600092e-06,
      "loss": 0.0437,
      "step": 2375
    },
    {
      "epoch": 0.03762053295755023,
      "grad_norm": 0.47827261686325073,
      "learning_rate": 9.623794670424499e-06,
      "loss": 0.6541,
      "step": 2376
    },
    {
      "epoch": 0.037636366515192296,
      "grad_norm": 0.22102701663970947,
      "learning_rate": 9.623636334848078e-06,
      "loss": 0.1407,
      "step": 2377
    },
    {
      "epoch": 0.03765220007283437,
      "grad_norm": 0.08352378755807877,
      "learning_rate": 9.623477999271657e-06,
      "loss": 0.0063,
      "step": 2378
    },
    {
      "epoch": 0.03766803363047643,
      "grad_norm": 0.002909030532464385,
      "learning_rate": 9.623319663695236e-06,
      "loss": 0.0001,
      "step": 2379
    },
    {
      "epoch": 0.037683867188118496,
      "grad_norm": 0.020570384338498116,
      "learning_rate": 9.623161328118817e-06,
      "loss": 0.0029,
      "step": 2380
    },
    {
      "epoch": 0.03769970074576057,
      "grad_norm": 0.17432402074337006,
      "learning_rate": 9.623002992542396e-06,
      "loss": 0.216,
      "step": 2381
    },
    {
      "epoch": 0.03771553430340263,
      "grad_norm": 0.1846025288105011,
      "learning_rate": 9.622844656965973e-06,
      "loss": 0.4738,
      "step": 2382
    },
    {
      "epoch": 0.037731367861044696,
      "grad_norm": 0.31369802355766296,
      "learning_rate": 9.622686321389554e-06,
      "loss": 0.3687,
      "step": 2383
    },
    {
      "epoch": 0.03774720141868677,
      "grad_norm": 0.010574974119663239,
      "learning_rate": 9.622527985813133e-06,
      "loss": 0.0007,
      "step": 2384
    },
    {
      "epoch": 0.03776303497632883,
      "grad_norm": 0.03458017483353615,
      "learning_rate": 9.622369650236712e-06,
      "loss": 0.0023,
      "step": 2385
    },
    {
      "epoch": 0.037778868533970895,
      "grad_norm": 5.877941657672636e-05,
      "learning_rate": 9.622211314660291e-06,
      "loss": 0.0,
      "step": 2386
    },
    {
      "epoch": 0.03779470209161297,
      "grad_norm": 0.23927028477191925,
      "learning_rate": 9.622052979083872e-06,
      "loss": 0.0832,
      "step": 2387
    },
    {
      "epoch": 0.03781053564925503,
      "grad_norm": 0.046031154692173004,
      "learning_rate": 9.62189464350745e-06,
      "loss": 0.0012,
      "step": 2388
    },
    {
      "epoch": 0.037826369206897095,
      "grad_norm": 0.0002138307609129697,
      "learning_rate": 9.62173630793103e-06,
      "loss": 0.0,
      "step": 2389
    },
    {
      "epoch": 0.037842202764539166,
      "grad_norm": 0.28830277919769287,
      "learning_rate": 9.621577972354609e-06,
      "loss": 0.1959,
      "step": 2390
    },
    {
      "epoch": 0.03785803632218123,
      "grad_norm": 0.26613545417785645,
      "learning_rate": 9.621419636778188e-06,
      "loss": 0.1486,
      "step": 2391
    },
    {
      "epoch": 0.037873869879823295,
      "grad_norm": 0.0038959041703492403,
      "learning_rate": 9.621261301201767e-06,
      "loss": 0.0003,
      "step": 2392
    },
    {
      "epoch": 0.037889703437465366,
      "grad_norm": 0.0009579664329066873,
      "learning_rate": 9.621102965625348e-06,
      "loss": 0.0,
      "step": 2393
    },
    {
      "epoch": 0.03790553699510743,
      "grad_norm": 0.38434937596321106,
      "learning_rate": 9.620944630048925e-06,
      "loss": 1.5548,
      "step": 2394
    },
    {
      "epoch": 0.037921370552749495,
      "grad_norm": 0.3330758213996887,
      "learning_rate": 9.620786294472506e-06,
      "loss": 0.1553,
      "step": 2395
    },
    {
      "epoch": 0.037937204110391566,
      "grad_norm": 0.217409148812294,
      "learning_rate": 9.620627958896085e-06,
      "loss": 0.1155,
      "step": 2396
    },
    {
      "epoch": 0.03795303766803363,
      "grad_norm": 0.31824687123298645,
      "learning_rate": 9.620469623319664e-06,
      "loss": 0.2036,
      "step": 2397
    },
    {
      "epoch": 0.037968871225675695,
      "grad_norm": 0.44291695952415466,
      "learning_rate": 9.620311287743243e-06,
      "loss": 0.3164,
      "step": 2398
    },
    {
      "epoch": 0.037984704783317766,
      "grad_norm": 0.1679408848285675,
      "learning_rate": 9.620152952166824e-06,
      "loss": 0.0438,
      "step": 2399
    },
    {
      "epoch": 0.03800053834095983,
      "grad_norm": 0.6519336700439453,
      "learning_rate": 9.619994616590402e-06,
      "loss": 0.2861,
      "step": 2400
    },
    {
      "epoch": 0.038016371898601894,
      "grad_norm": 0.1767701357603073,
      "learning_rate": 9.619836281013982e-06,
      "loss": 0.1997,
      "step": 2401
    },
    {
      "epoch": 0.038032205456243966,
      "grad_norm": 0.2885819971561432,
      "learning_rate": 9.619677945437561e-06,
      "loss": 0.4293,
      "step": 2402
    },
    {
      "epoch": 0.03804803901388603,
      "grad_norm": 0.1601427048444748,
      "learning_rate": 9.61951960986114e-06,
      "loss": 0.0656,
      "step": 2403
    },
    {
      "epoch": 0.038063872571528094,
      "grad_norm": 0.43006473779678345,
      "learning_rate": 9.61936127428472e-06,
      "loss": 0.6387,
      "step": 2404
    },
    {
      "epoch": 0.038079706129170166,
      "grad_norm": 0.01681973785161972,
      "learning_rate": 9.6192029387083e-06,
      "loss": 0.0014,
      "step": 2405
    },
    {
      "epoch": 0.03809553968681223,
      "grad_norm": 0.018252085894346237,
      "learning_rate": 9.619044603131878e-06,
      "loss": 0.0012,
      "step": 2406
    },
    {
      "epoch": 0.038111373244454294,
      "grad_norm": 0.1806401163339615,
      "learning_rate": 9.618886267555457e-06,
      "loss": 0.078,
      "step": 2407
    },
    {
      "epoch": 0.038127206802096365,
      "grad_norm": 0.004772108513861895,
      "learning_rate": 9.618727931979038e-06,
      "loss": 0.0002,
      "step": 2408
    },
    {
      "epoch": 0.03814304035973843,
      "grad_norm": 0.21324211359024048,
      "learning_rate": 9.618569596402617e-06,
      "loss": 0.1447,
      "step": 2409
    },
    {
      "epoch": 0.038158873917380494,
      "grad_norm": 0.23929552733898163,
      "learning_rate": 9.618411260826196e-06,
      "loss": 0.1336,
      "step": 2410
    },
    {
      "epoch": 0.038174707475022565,
      "grad_norm": 0.03374297171831131,
      "learning_rate": 9.618252925249775e-06,
      "loss": 0.0007,
      "step": 2411
    },
    {
      "epoch": 0.03819054103266463,
      "grad_norm": 0.2535785138607025,
      "learning_rate": 9.618094589673354e-06,
      "loss": 0.0727,
      "step": 2412
    },
    {
      "epoch": 0.038206374590306694,
      "grad_norm": 0.030126826837658882,
      "learning_rate": 9.617936254096933e-06,
      "loss": 0.0031,
      "step": 2413
    },
    {
      "epoch": 0.038222208147948765,
      "grad_norm": 0.37891802191734314,
      "learning_rate": 9.617777918520514e-06,
      "loss": 0.2683,
      "step": 2414
    },
    {
      "epoch": 0.03823804170559083,
      "grad_norm": 0.19422931969165802,
      "learning_rate": 9.617619582944093e-06,
      "loss": 0.074,
      "step": 2415
    },
    {
      "epoch": 0.038253875263232893,
      "grad_norm": 0.1510234773159027,
      "learning_rate": 9.617461247367672e-06,
      "loss": 0.0046,
      "step": 2416
    },
    {
      "epoch": 0.038269708820874965,
      "grad_norm": 0.4412555992603302,
      "learning_rate": 9.617302911791251e-06,
      "loss": 0.1154,
      "step": 2417
    },
    {
      "epoch": 0.03828554237851703,
      "grad_norm": 0.17912457883358002,
      "learning_rate": 9.61714457621483e-06,
      "loss": 0.0658,
      "step": 2418
    },
    {
      "epoch": 0.03830137593615909,
      "grad_norm": 0.021527333185076714,
      "learning_rate": 9.61698624063841e-06,
      "loss": 0.0036,
      "step": 2419
    },
    {
      "epoch": 0.038317209493801165,
      "grad_norm": 0.00017867634596768767,
      "learning_rate": 9.61682790506199e-06,
      "loss": 0.0,
      "step": 2420
    },
    {
      "epoch": 0.03833304305144323,
      "grad_norm": 0.19943225383758545,
      "learning_rate": 9.616669569485569e-06,
      "loss": 0.0352,
      "step": 2421
    },
    {
      "epoch": 0.03834887660908529,
      "grad_norm": 0.21140816807746887,
      "learning_rate": 9.616511233909148e-06,
      "loss": 0.2201,
      "step": 2422
    },
    {
      "epoch": 0.038364710166727364,
      "grad_norm": 0.19531875848770142,
      "learning_rate": 9.616352898332727e-06,
      "loss": 0.0884,
      "step": 2423
    },
    {
      "epoch": 0.03838054372436943,
      "grad_norm": 0.14033666253089905,
      "learning_rate": 9.616194562756306e-06,
      "loss": 0.1112,
      "step": 2424
    },
    {
      "epoch": 0.03839637728201149,
      "grad_norm": 0.11248625069856644,
      "learning_rate": 9.616036227179885e-06,
      "loss": 0.1056,
      "step": 2425
    },
    {
      "epoch": 0.038412210839653564,
      "grad_norm": 0.02344396896660328,
      "learning_rate": 9.615877891603466e-06,
      "loss": 0.0016,
      "step": 2426
    },
    {
      "epoch": 0.03842804439729563,
      "grad_norm": 0.18675905466079712,
      "learning_rate": 9.615719556027045e-06,
      "loss": 0.4051,
      "step": 2427
    },
    {
      "epoch": 0.03844387795493769,
      "grad_norm": 0.21088938415050507,
      "learning_rate": 9.615561220450624e-06,
      "loss": 0.1332,
      "step": 2428
    },
    {
      "epoch": 0.038459711512579764,
      "grad_norm": 0.008226051926612854,
      "learning_rate": 9.615402884874203e-06,
      "loss": 0.0004,
      "step": 2429
    },
    {
      "epoch": 0.03847554507022183,
      "grad_norm": 0.23963378369808197,
      "learning_rate": 9.615244549297782e-06,
      "loss": 0.1424,
      "step": 2430
    },
    {
      "epoch": 0.03849137862786389,
      "grad_norm": 0.0035508093424141407,
      "learning_rate": 9.615086213721362e-06,
      "loss": 0.0003,
      "step": 2431
    },
    {
      "epoch": 0.038507212185505964,
      "grad_norm": 0.16036009788513184,
      "learning_rate": 9.61492787814494e-06,
      "loss": 0.0025,
      "step": 2432
    },
    {
      "epoch": 0.03852304574314803,
      "grad_norm": 0.22391580045223236,
      "learning_rate": 9.614769542568521e-06,
      "loss": 0.0636,
      "step": 2433
    },
    {
      "epoch": 0.03853887930079009,
      "grad_norm": 0.3100396692752838,
      "learning_rate": 9.614611206992099e-06,
      "loss": 0.1876,
      "step": 2434
    },
    {
      "epoch": 0.038554712858432164,
      "grad_norm": 0.1191185936331749,
      "learning_rate": 9.61445287141568e-06,
      "loss": 0.0399,
      "step": 2435
    },
    {
      "epoch": 0.03857054641607423,
      "grad_norm": 0.20137111842632294,
      "learning_rate": 9.614294535839259e-06,
      "loss": 0.3814,
      "step": 2436
    },
    {
      "epoch": 0.03858637997371629,
      "grad_norm": 0.1282501220703125,
      "learning_rate": 9.614136200262838e-06,
      "loss": 0.247,
      "step": 2437
    },
    {
      "epoch": 0.03860221353135836,
      "grad_norm": 0.38270288705825806,
      "learning_rate": 9.613977864686417e-06,
      "loss": 0.598,
      "step": 2438
    },
    {
      "epoch": 0.03861804708900043,
      "grad_norm": 0.16847601532936096,
      "learning_rate": 9.613819529109996e-06,
      "loss": 0.2319,
      "step": 2439
    },
    {
      "epoch": 0.03863388064664249,
      "grad_norm": 0.22964569926261902,
      "learning_rate": 9.613661193533575e-06,
      "loss": 0.0778,
      "step": 2440
    },
    {
      "epoch": 0.03864971420428456,
      "grad_norm": 0.28629207611083984,
      "learning_rate": 9.613502857957156e-06,
      "loss": 0.0778,
      "step": 2441
    },
    {
      "epoch": 0.03866554776192663,
      "grad_norm": 0.27178633213043213,
      "learning_rate": 9.613344522380735e-06,
      "loss": 0.1555,
      "step": 2442
    },
    {
      "epoch": 0.03868138131956869,
      "grad_norm": 0.1619936227798462,
      "learning_rate": 9.613186186804314e-06,
      "loss": 0.0284,
      "step": 2443
    },
    {
      "epoch": 0.03869721487721076,
      "grad_norm": 0.3034757375717163,
      "learning_rate": 9.613027851227893e-06,
      "loss": 0.4192,
      "step": 2444
    },
    {
      "epoch": 0.03871304843485283,
      "grad_norm": 0.24834376573562622,
      "learning_rate": 9.612869515651472e-06,
      "loss": 0.3941,
      "step": 2445
    },
    {
      "epoch": 0.03872888199249489,
      "grad_norm": 0.1474708467721939,
      "learning_rate": 9.612711180075051e-06,
      "loss": 0.3096,
      "step": 2446
    },
    {
      "epoch": 0.03874471555013696,
      "grad_norm": 0.26692646741867065,
      "learning_rate": 9.612552844498632e-06,
      "loss": 0.1741,
      "step": 2447
    },
    {
      "epoch": 0.03876054910777903,
      "grad_norm": 0.3750495910644531,
      "learning_rate": 9.612394508922211e-06,
      "loss": 0.6669,
      "step": 2448
    },
    {
      "epoch": 0.03877638266542109,
      "grad_norm": 0.12952907383441925,
      "learning_rate": 9.61223617334579e-06,
      "loss": 0.0296,
      "step": 2449
    },
    {
      "epoch": 0.03879221622306316,
      "grad_norm": 0.007893337868154049,
      "learning_rate": 9.612077837769369e-06,
      "loss": 0.0007,
      "step": 2450
    },
    {
      "epoch": 0.03880804978070523,
      "grad_norm": 0.17191314697265625,
      "learning_rate": 9.611919502192948e-06,
      "loss": 0.2397,
      "step": 2451
    },
    {
      "epoch": 0.03882388333834729,
      "grad_norm": 0.1445620208978653,
      "learning_rate": 9.611761166616527e-06,
      "loss": 0.0544,
      "step": 2452
    },
    {
      "epoch": 0.03883971689598936,
      "grad_norm": 0.18612851202487946,
      "learning_rate": 9.611602831040108e-06,
      "loss": 0.327,
      "step": 2453
    },
    {
      "epoch": 0.03885555045363143,
      "grad_norm": 0.1971685141324997,
      "learning_rate": 9.611444495463687e-06,
      "loss": 0.1477,
      "step": 2454
    },
    {
      "epoch": 0.03887138401127349,
      "grad_norm": 2.1880930944462307e-05,
      "learning_rate": 9.611286159887265e-06,
      "loss": 0.0,
      "step": 2455
    },
    {
      "epoch": 0.03888721756891556,
      "grad_norm": 0.5033878087997437,
      "learning_rate": 9.611127824310845e-06,
      "loss": 0.0474,
      "step": 2456
    },
    {
      "epoch": 0.038903051126557626,
      "grad_norm": 0.3223523199558258,
      "learning_rate": 9.610969488734424e-06,
      "loss": 0.1047,
      "step": 2457
    },
    {
      "epoch": 0.03891888468419969,
      "grad_norm": 0.358635276556015,
      "learning_rate": 9.610811153158003e-06,
      "loss": 0.279,
      "step": 2458
    },
    {
      "epoch": 0.03893471824184176,
      "grad_norm": 0.006550786085426807,
      "learning_rate": 9.610652817581583e-06,
      "loss": 0.0005,
      "step": 2459
    },
    {
      "epoch": 0.038950551799483826,
      "grad_norm": 0.22215352952480316,
      "learning_rate": 9.610494482005163e-06,
      "loss": 0.1413,
      "step": 2460
    },
    {
      "epoch": 0.03896638535712589,
      "grad_norm": 0.0001921823131851852,
      "learning_rate": 9.61033614642874e-06,
      "loss": 0.0,
      "step": 2461
    },
    {
      "epoch": 0.03898221891476796,
      "grad_norm": 0.039812661707401276,
      "learning_rate": 9.610177810852321e-06,
      "loss": 0.0034,
      "step": 2462
    },
    {
      "epoch": 0.038998052472410026,
      "grad_norm": 0.31563836336135864,
      "learning_rate": 9.6100194752759e-06,
      "loss": 0.2117,
      "step": 2463
    },
    {
      "epoch": 0.03901388603005209,
      "grad_norm": 0.6064561009407043,
      "learning_rate": 9.60986113969948e-06,
      "loss": 0.7385,
      "step": 2464
    },
    {
      "epoch": 0.03902971958769416,
      "grad_norm": 0.019838273525238037,
      "learning_rate": 9.609702804123059e-06,
      "loss": 0.0014,
      "step": 2465
    },
    {
      "epoch": 0.039045553145336226,
      "grad_norm": 0.4142135977745056,
      "learning_rate": 9.60954446854664e-06,
      "loss": 0.2804,
      "step": 2466
    },
    {
      "epoch": 0.03906138670297829,
      "grad_norm": 0.0005338639602996409,
      "learning_rate": 9.609386132970217e-06,
      "loss": 0.0,
      "step": 2467
    },
    {
      "epoch": 0.03907722026062036,
      "grad_norm": 6.359741382766515e-05,
      "learning_rate": 9.609227797393798e-06,
      "loss": 0.0,
      "step": 2468
    },
    {
      "epoch": 0.039093053818262426,
      "grad_norm": 0.20114898681640625,
      "learning_rate": 9.609069461817377e-06,
      "loss": 0.0508,
      "step": 2469
    },
    {
      "epoch": 0.03910888737590449,
      "grad_norm": 0.23108705878257751,
      "learning_rate": 9.608911126240956e-06,
      "loss": 0.0239,
      "step": 2470
    },
    {
      "epoch": 0.03912472093354656,
      "grad_norm": 0.0063627175986766815,
      "learning_rate": 9.608752790664535e-06,
      "loss": 0.0004,
      "step": 2471
    },
    {
      "epoch": 0.039140554491188626,
      "grad_norm": 0.33919423818588257,
      "learning_rate": 9.608594455088116e-06,
      "loss": 0.2115,
      "step": 2472
    },
    {
      "epoch": 0.03915638804883069,
      "grad_norm": 0.1730022430419922,
      "learning_rate": 9.608436119511693e-06,
      "loss": 0.3093,
      "step": 2473
    },
    {
      "epoch": 0.03917222160647276,
      "grad_norm": 0.007286380976438522,
      "learning_rate": 9.608277783935274e-06,
      "loss": 0.0006,
      "step": 2474
    },
    {
      "epoch": 0.039188055164114825,
      "grad_norm": 0.23976412415504456,
      "learning_rate": 9.608119448358853e-06,
      "loss": 0.2212,
      "step": 2475
    },
    {
      "epoch": 0.03920388872175689,
      "grad_norm": 0.0008290827972814441,
      "learning_rate": 9.607961112782432e-06,
      "loss": 0.0,
      "step": 2476
    },
    {
      "epoch": 0.03921972227939896,
      "grad_norm": 0.003545984858646989,
      "learning_rate": 9.607802777206011e-06,
      "loss": 0.0001,
      "step": 2477
    },
    {
      "epoch": 0.039235555837041025,
      "grad_norm": 0.11661713570356369,
      "learning_rate": 9.607644441629592e-06,
      "loss": 0.0244,
      "step": 2478
    },
    {
      "epoch": 0.03925138939468309,
      "grad_norm": 0.18465928733348846,
      "learning_rate": 9.60748610605317e-06,
      "loss": 0.0927,
      "step": 2479
    },
    {
      "epoch": 0.03926722295232516,
      "grad_norm": 0.39648038148880005,
      "learning_rate": 9.607327770476748e-06,
      "loss": 0.1051,
      "step": 2480
    },
    {
      "epoch": 0.039283056509967225,
      "grad_norm": 0.5352205038070679,
      "learning_rate": 9.607169434900329e-06,
      "loss": 0.6103,
      "step": 2481
    },
    {
      "epoch": 0.03929889006760929,
      "grad_norm": 0.23738136887550354,
      "learning_rate": 9.607011099323908e-06,
      "loss": 0.1385,
      "step": 2482
    },
    {
      "epoch": 0.03931472362525136,
      "grad_norm": 0.20610538125038147,
      "learning_rate": 9.606852763747487e-06,
      "loss": 0.5263,
      "step": 2483
    },
    {
      "epoch": 0.039330557182893425,
      "grad_norm": 0.17641659080982208,
      "learning_rate": 9.606694428171066e-06,
      "loss": 0.0305,
      "step": 2484
    },
    {
      "epoch": 0.03934639074053549,
      "grad_norm": 0.35552966594696045,
      "learning_rate": 9.606536092594645e-06,
      "loss": 0.083,
      "step": 2485
    },
    {
      "epoch": 0.03936222429817756,
      "grad_norm": 0.36347728967666626,
      "learning_rate": 9.606377757018224e-06,
      "loss": 0.3018,
      "step": 2486
    },
    {
      "epoch": 0.039378057855819625,
      "grad_norm": 0.1866600662469864,
      "learning_rate": 9.606219421441805e-06,
      "loss": 0.2291,
      "step": 2487
    },
    {
      "epoch": 0.03939389141346169,
      "grad_norm": 0.1747291535139084,
      "learning_rate": 9.606061085865384e-06,
      "loss": 0.0911,
      "step": 2488
    },
    {
      "epoch": 0.03940972497110376,
      "grad_norm": 0.02348126657307148,
      "learning_rate": 9.605902750288963e-06,
      "loss": 0.0018,
      "step": 2489
    },
    {
      "epoch": 0.039425558528745824,
      "grad_norm": 0.38016578555107117,
      "learning_rate": 9.605744414712542e-06,
      "loss": 0.3333,
      "step": 2490
    },
    {
      "epoch": 0.03944139208638789,
      "grad_norm": 0.13946522772312164,
      "learning_rate": 9.605586079136122e-06,
      "loss": 0.0571,
      "step": 2491
    },
    {
      "epoch": 0.03945722564402996,
      "grad_norm": 0.3581361770629883,
      "learning_rate": 9.6054277435597e-06,
      "loss": 0.188,
      "step": 2492
    },
    {
      "epoch": 0.039473059201672024,
      "grad_norm": 0.3058589696884155,
      "learning_rate": 9.605269407983281e-06,
      "loss": 0.2534,
      "step": 2493
    },
    {
      "epoch": 0.03948889275931409,
      "grad_norm": 0.5364047288894653,
      "learning_rate": 9.60511107240686e-06,
      "loss": 1.0946,
      "step": 2494
    },
    {
      "epoch": 0.03950472631695616,
      "grad_norm": 0.15221206843852997,
      "learning_rate": 9.60495273683044e-06,
      "loss": 0.0814,
      "step": 2495
    },
    {
      "epoch": 0.039520559874598224,
      "grad_norm": 4.755149348056875e-05,
      "learning_rate": 9.604794401254019e-06,
      "loss": 0.0,
      "step": 2496
    },
    {
      "epoch": 0.03953639343224029,
      "grad_norm": 0.2670913338661194,
      "learning_rate": 9.604636065677598e-06,
      "loss": 0.1539,
      "step": 2497
    },
    {
      "epoch": 0.03955222698988236,
      "grad_norm": 0.04150371626019478,
      "learning_rate": 9.604477730101177e-06,
      "loss": 0.0051,
      "step": 2498
    },
    {
      "epoch": 0.039568060547524424,
      "grad_norm": 0.34675538539886475,
      "learning_rate": 9.604319394524758e-06,
      "loss": 0.1664,
      "step": 2499
    },
    {
      "epoch": 0.03958389410516649,
      "grad_norm": 0.13461105525493622,
      "learning_rate": 9.604161058948337e-06,
      "loss": 0.077,
      "step": 2500
    },
    {
      "epoch": 0.03959972766280856,
      "grad_norm": 0.00013964904064778239,
      "learning_rate": 9.604002723371916e-06,
      "loss": 0.0,
      "step": 2501
    },
    {
      "epoch": 0.039615561220450624,
      "grad_norm": 0.18313923478126526,
      "learning_rate": 9.603844387795495e-06,
      "loss": 0.0804,
      "step": 2502
    },
    {
      "epoch": 0.03963139477809269,
      "grad_norm": 0.03735746443271637,
      "learning_rate": 9.603686052219074e-06,
      "loss": 0.003,
      "step": 2503
    },
    {
      "epoch": 0.03964722833573476,
      "grad_norm": 0.21450486779212952,
      "learning_rate": 9.603527716642653e-06,
      "loss": 0.2338,
      "step": 2504
    },
    {
      "epoch": 0.03966306189337682,
      "grad_norm": 0.35953080654144287,
      "learning_rate": 9.603369381066232e-06,
      "loss": 0.2624,
      "step": 2505
    },
    {
      "epoch": 0.03967889545101889,
      "grad_norm": 0.013283421285450459,
      "learning_rate": 9.603211045489811e-06,
      "loss": 0.0011,
      "step": 2506
    },
    {
      "epoch": 0.03969472900866096,
      "grad_norm": 0.3713766038417816,
      "learning_rate": 9.60305270991339e-06,
      "loss": 0.1123,
      "step": 2507
    },
    {
      "epoch": 0.03971056256630302,
      "grad_norm": 0.3568452000617981,
      "learning_rate": 9.602894374336971e-06,
      "loss": 0.6835,
      "step": 2508
    },
    {
      "epoch": 0.03972639612394509,
      "grad_norm": 0.016487106680870056,
      "learning_rate": 9.60273603876055e-06,
      "loss": 0.001,
      "step": 2509
    },
    {
      "epoch": 0.03974222968158716,
      "grad_norm": 0.028959039598703384,
      "learning_rate": 9.60257770318413e-06,
      "loss": 0.0013,
      "step": 2510
    },
    {
      "epoch": 0.03975806323922922,
      "grad_norm": 0.21640263497829437,
      "learning_rate": 9.602419367607708e-06,
      "loss": 0.297,
      "step": 2511
    },
    {
      "epoch": 0.03977389679687129,
      "grad_norm": 0.6169019341468811,
      "learning_rate": 9.602261032031287e-06,
      "loss": 0.13,
      "step": 2512
    },
    {
      "epoch": 0.03978973035451336,
      "grad_norm": 0.268353134393692,
      "learning_rate": 9.602102696454866e-06,
      "loss": 0.1824,
      "step": 2513
    },
    {
      "epoch": 0.03980556391215542,
      "grad_norm": 0.2866036593914032,
      "learning_rate": 9.601944360878447e-06,
      "loss": 0.5906,
      "step": 2514
    },
    {
      "epoch": 0.03982139746979749,
      "grad_norm": 0.30646082758903503,
      "learning_rate": 9.601786025302026e-06,
      "loss": 0.3069,
      "step": 2515
    },
    {
      "epoch": 0.03983723102743956,
      "grad_norm": 0.36768826842308044,
      "learning_rate": 9.601627689725605e-06,
      "loss": 0.2669,
      "step": 2516
    },
    {
      "epoch": 0.03985306458508162,
      "grad_norm": 0.018291447311639786,
      "learning_rate": 9.601469354149184e-06,
      "loss": 0.0012,
      "step": 2517
    },
    {
      "epoch": 0.03986889814272369,
      "grad_norm": 0.1925843358039856,
      "learning_rate": 9.601311018572763e-06,
      "loss": 0.0628,
      "step": 2518
    },
    {
      "epoch": 0.03988473170036576,
      "grad_norm": 0.03853030502796173,
      "learning_rate": 9.601152682996343e-06,
      "loss": 0.0023,
      "step": 2519
    },
    {
      "epoch": 0.03990056525800782,
      "grad_norm": 0.0005284125218167901,
      "learning_rate": 9.600994347419923e-06,
      "loss": 0.0,
      "step": 2520
    },
    {
      "epoch": 0.03991639881564989,
      "grad_norm": 0.14232157170772552,
      "learning_rate": 9.600836011843502e-06,
      "loss": 0.0054,
      "step": 2521
    },
    {
      "epoch": 0.03993223237329196,
      "grad_norm": 0.17278419435024261,
      "learning_rate": 9.600677676267082e-06,
      "loss": 0.153,
      "step": 2522
    },
    {
      "epoch": 0.03994806593093402,
      "grad_norm": 0.1752084493637085,
      "learning_rate": 9.60051934069066e-06,
      "loss": 0.0153,
      "step": 2523
    },
    {
      "epoch": 0.039963899488576086,
      "grad_norm": 0.5914977788925171,
      "learning_rate": 9.60036100511424e-06,
      "loss": 0.7645,
      "step": 2524
    },
    {
      "epoch": 0.03997973304621816,
      "grad_norm": 0.17591112852096558,
      "learning_rate": 9.600202669537819e-06,
      "loss": 0.2557,
      "step": 2525
    },
    {
      "epoch": 0.03999556660386022,
      "grad_norm": 0.17562299966812134,
      "learning_rate": 9.6000443339614e-06,
      "loss": 0.1112,
      "step": 2526
    },
    {
      "epoch": 0.040011400161502286,
      "grad_norm": 0.03786285221576691,
      "learning_rate": 9.599885998384979e-06,
      "loss": 0.0045,
      "step": 2527
    },
    {
      "epoch": 0.04002723371914436,
      "grad_norm": 0.024807577952742577,
      "learning_rate": 9.599727662808556e-06,
      "loss": 0.0015,
      "step": 2528
    },
    {
      "epoch": 0.04004306727678642,
      "grad_norm": 0.395304411649704,
      "learning_rate": 9.599569327232137e-06,
      "loss": 0.4542,
      "step": 2529
    },
    {
      "epoch": 0.040058900834428486,
      "grad_norm": 0.2629961371421814,
      "learning_rate": 9.599410991655716e-06,
      "loss": 0.1894,
      "step": 2530
    },
    {
      "epoch": 0.04007473439207056,
      "grad_norm": 0.15298794209957123,
      "learning_rate": 9.599252656079295e-06,
      "loss": 0.052,
      "step": 2531
    },
    {
      "epoch": 0.04009056794971262,
      "grad_norm": 0.21312807500362396,
      "learning_rate": 9.599094320502874e-06,
      "loss": 0.1604,
      "step": 2532
    },
    {
      "epoch": 0.040106401507354686,
      "grad_norm": 0.3416026532649994,
      "learning_rate": 9.598935984926455e-06,
      "loss": 0.6639,
      "step": 2533
    },
    {
      "epoch": 0.04012223506499676,
      "grad_norm": 0.13120391964912415,
      "learning_rate": 9.598777649350032e-06,
      "loss": 0.0134,
      "step": 2534
    },
    {
      "epoch": 0.04013806862263882,
      "grad_norm": 6.0438884247560054e-05,
      "learning_rate": 9.598619313773613e-06,
      "loss": 0.0,
      "step": 2535
    },
    {
      "epoch": 0.040153902180280886,
      "grad_norm": 0.0032093713525682688,
      "learning_rate": 9.598460978197192e-06,
      "loss": 0.0002,
      "step": 2536
    },
    {
      "epoch": 0.04016973573792296,
      "grad_norm": 0.36280596256256104,
      "learning_rate": 9.598302642620771e-06,
      "loss": 0.3027,
      "step": 2537
    },
    {
      "epoch": 0.04018556929556502,
      "grad_norm": 0.33244630694389343,
      "learning_rate": 9.59814430704435e-06,
      "loss": 0.2973,
      "step": 2538
    },
    {
      "epoch": 0.040201402853207086,
      "grad_norm": 0.32686546444892883,
      "learning_rate": 9.597985971467931e-06,
      "loss": 0.3624,
      "step": 2539
    },
    {
      "epoch": 0.04021723641084916,
      "grad_norm": 0.28894132375717163,
      "learning_rate": 9.597827635891508e-06,
      "loss": 0.2719,
      "step": 2540
    },
    {
      "epoch": 0.04023306996849122,
      "grad_norm": 0.5983544588088989,
      "learning_rate": 9.597669300315089e-06,
      "loss": 0.4665,
      "step": 2541
    },
    {
      "epoch": 0.040248903526133285,
      "grad_norm": 0.013009022921323776,
      "learning_rate": 9.597510964738668e-06,
      "loss": 0.0007,
      "step": 2542
    },
    {
      "epoch": 0.04026473708377536,
      "grad_norm": 0.0003607612452469766,
      "learning_rate": 9.597352629162247e-06,
      "loss": 0.0,
      "step": 2543
    },
    {
      "epoch": 0.04028057064141742,
      "grad_norm": 0.5873808264732361,
      "learning_rate": 9.597194293585826e-06,
      "loss": 0.1484,
      "step": 2544
    },
    {
      "epoch": 0.040296404199059485,
      "grad_norm": 0.36444148421287537,
      "learning_rate": 9.597035958009407e-06,
      "loss": 0.1091,
      "step": 2545
    },
    {
      "epoch": 0.040312237756701556,
      "grad_norm": 0.24759246408939362,
      "learning_rate": 9.596877622432985e-06,
      "loss": 0.8596,
      "step": 2546
    },
    {
      "epoch": 0.04032807131434362,
      "grad_norm": 0.0004172952030785382,
      "learning_rate": 9.596719286856565e-06,
      "loss": 0.0,
      "step": 2547
    },
    {
      "epoch": 0.040343904871985685,
      "grad_norm": 0.37130457162857056,
      "learning_rate": 9.596560951280144e-06,
      "loss": 0.1853,
      "step": 2548
    },
    {
      "epoch": 0.040359738429627756,
      "grad_norm": 0.9645060300827026,
      "learning_rate": 9.596402615703723e-06,
      "loss": 0.1247,
      "step": 2549
    },
    {
      "epoch": 0.04037557198726982,
      "grad_norm": 2.1477186237461865e-05,
      "learning_rate": 9.596244280127303e-06,
      "loss": 0.0,
      "step": 2550
    },
    {
      "epoch": 0.040391405544911885,
      "grad_norm": 0.020619913935661316,
      "learning_rate": 9.596085944550882e-06,
      "loss": 0.0014,
      "step": 2551
    },
    {
      "epoch": 0.040407239102553956,
      "grad_norm": 0.010523761622607708,
      "learning_rate": 9.59592760897446e-06,
      "loss": 0.0006,
      "step": 2552
    },
    {
      "epoch": 0.04042307266019602,
      "grad_norm": 0.26519227027893066,
      "learning_rate": 9.59576927339804e-06,
      "loss": 0.7132,
      "step": 2553
    },
    {
      "epoch": 0.040438906217838085,
      "grad_norm": 0.14789257943630219,
      "learning_rate": 9.59561093782162e-06,
      "loss": 0.2972,
      "step": 2554
    },
    {
      "epoch": 0.040454739775480156,
      "grad_norm": 0.008372578769922256,
      "learning_rate": 9.5954526022452e-06,
      "loss": 0.0006,
      "step": 2555
    },
    {
      "epoch": 0.04047057333312222,
      "grad_norm": 0.2549852132797241,
      "learning_rate": 9.595294266668779e-06,
      "loss": 0.0275,
      "step": 2556
    },
    {
      "epoch": 0.040486406890764284,
      "grad_norm": 8.96657511475496e-05,
      "learning_rate": 9.595135931092358e-06,
      "loss": 0.0,
      "step": 2557
    },
    {
      "epoch": 0.040502240448406356,
      "grad_norm": 0.16920706629753113,
      "learning_rate": 9.594977595515937e-06,
      "loss": 0.2087,
      "step": 2558
    },
    {
      "epoch": 0.04051807400604842,
      "grad_norm": 0.22374822199344635,
      "learning_rate": 9.594819259939516e-06,
      "loss": 0.1244,
      "step": 2559
    },
    {
      "epoch": 0.040533907563690484,
      "grad_norm": 0.25939667224884033,
      "learning_rate": 9.594660924363097e-06,
      "loss": 0.1402,
      "step": 2560
    },
    {
      "epoch": 0.040549741121332555,
      "grad_norm": 0.384369432926178,
      "learning_rate": 9.594502588786676e-06,
      "loss": 0.1186,
      "step": 2561
    },
    {
      "epoch": 0.04056557467897462,
      "grad_norm": 0.030432527884840965,
      "learning_rate": 9.594344253210255e-06,
      "loss": 0.0012,
      "step": 2562
    },
    {
      "epoch": 0.040581408236616684,
      "grad_norm": 0.1238776221871376,
      "learning_rate": 9.594185917633834e-06,
      "loss": 0.1098,
      "step": 2563
    },
    {
      "epoch": 0.040597241794258755,
      "grad_norm": 0.011602443642914295,
      "learning_rate": 9.594027582057413e-06,
      "loss": 0.0008,
      "step": 2564
    },
    {
      "epoch": 0.04061307535190082,
      "grad_norm": 0.21978911757469177,
      "learning_rate": 9.593869246480992e-06,
      "loss": 0.1016,
      "step": 2565
    },
    {
      "epoch": 0.040628908909542884,
      "grad_norm": 0.10477190464735031,
      "learning_rate": 9.593710910904573e-06,
      "loss": 0.0451,
      "step": 2566
    },
    {
      "epoch": 0.040644742467184955,
      "grad_norm": 0.13862992823123932,
      "learning_rate": 9.59355257532815e-06,
      "loss": 0.2546,
      "step": 2567
    },
    {
      "epoch": 0.04066057602482702,
      "grad_norm": 0.17630140483379364,
      "learning_rate": 9.593394239751731e-06,
      "loss": 0.2795,
      "step": 2568
    },
    {
      "epoch": 0.040676409582469084,
      "grad_norm": 0.4531501531600952,
      "learning_rate": 9.59323590417531e-06,
      "loss": 0.3292,
      "step": 2569
    },
    {
      "epoch": 0.040692243140111155,
      "grad_norm": 0.21279391646385193,
      "learning_rate": 9.59307756859889e-06,
      "loss": 0.3133,
      "step": 2570
    },
    {
      "epoch": 0.04070807669775322,
      "grad_norm": 0.51209956407547,
      "learning_rate": 9.592919233022468e-06,
      "loss": 0.21,
      "step": 2571
    },
    {
      "epoch": 0.04072391025539528,
      "grad_norm": 0.31652283668518066,
      "learning_rate": 9.592760897446049e-06,
      "loss": 0.2021,
      "step": 2572
    },
    {
      "epoch": 0.040739743813037355,
      "grad_norm": 0.2642032206058502,
      "learning_rate": 9.592602561869626e-06,
      "loss": 0.1474,
      "step": 2573
    },
    {
      "epoch": 0.04075557737067942,
      "grad_norm": 0.17445725202560425,
      "learning_rate": 9.592444226293207e-06,
      "loss": 0.211,
      "step": 2574
    },
    {
      "epoch": 0.04077141092832148,
      "grad_norm": 0.22465170919895172,
      "learning_rate": 9.592285890716786e-06,
      "loss": 0.1831,
      "step": 2575
    },
    {
      "epoch": 0.040787244485963554,
      "grad_norm": 0.0027124362532049417,
      "learning_rate": 9.592127555140365e-06,
      "loss": 0.0,
      "step": 2576
    },
    {
      "epoch": 0.04080307804360562,
      "grad_norm": 0.1547963172197342,
      "learning_rate": 9.591969219563944e-06,
      "loss": 0.0702,
      "step": 2577
    },
    {
      "epoch": 0.04081891160124768,
      "grad_norm": 0.17449209094047546,
      "learning_rate": 9.591810883987524e-06,
      "loss": 0.0961,
      "step": 2578
    },
    {
      "epoch": 0.040834745158889754,
      "grad_norm": 0.15342983603477478,
      "learning_rate": 9.591652548411103e-06,
      "loss": 0.1419,
      "step": 2579
    },
    {
      "epoch": 0.04085057871653182,
      "grad_norm": 0.010570096783339977,
      "learning_rate": 9.591494212834682e-06,
      "loss": 0.0006,
      "step": 2580
    },
    {
      "epoch": 0.04086641227417388,
      "grad_norm": 0.010522767901420593,
      "learning_rate": 9.591335877258262e-06,
      "loss": 0.0006,
      "step": 2581
    },
    {
      "epoch": 0.040882245831815954,
      "grad_norm": 0.007827337831258774,
      "learning_rate": 9.591177541681842e-06,
      "loss": 0.0004,
      "step": 2582
    },
    {
      "epoch": 0.04089807938945802,
      "grad_norm": 0.2741861343383789,
      "learning_rate": 9.59101920610542e-06,
      "loss": 0.0931,
      "step": 2583
    },
    {
      "epoch": 0.04091391294710008,
      "grad_norm": 0.39982178807258606,
      "learning_rate": 9.590860870529e-06,
      "loss": 0.0785,
      "step": 2584
    },
    {
      "epoch": 0.040929746504742154,
      "grad_norm": 0.1969478875398636,
      "learning_rate": 9.590702534952579e-06,
      "loss": 0.3825,
      "step": 2585
    },
    {
      "epoch": 0.04094558006238422,
      "grad_norm": 0.43267831206321716,
      "learning_rate": 9.590544199376158e-06,
      "loss": 0.5673,
      "step": 2586
    },
    {
      "epoch": 0.04096141362002628,
      "grad_norm": 0.15592710673809052,
      "learning_rate": 9.590385863799739e-06,
      "loss": 0.0507,
      "step": 2587
    },
    {
      "epoch": 0.040977247177668354,
      "grad_norm": 0.04084897041320801,
      "learning_rate": 9.590227528223318e-06,
      "loss": 0.0024,
      "step": 2588
    },
    {
      "epoch": 0.04099308073531042,
      "grad_norm": 0.25267380475997925,
      "learning_rate": 9.590069192646897e-06,
      "loss": 0.0312,
      "step": 2589
    },
    {
      "epoch": 0.04100891429295248,
      "grad_norm": 0.15442074835300446,
      "learning_rate": 9.589910857070476e-06,
      "loss": 0.0687,
      "step": 2590
    },
    {
      "epoch": 0.04102474785059455,
      "grad_norm": 0.20196907222270966,
      "learning_rate": 9.589752521494055e-06,
      "loss": 0.5227,
      "step": 2591
    },
    {
      "epoch": 0.04104058140823662,
      "grad_norm": 0.0068452367559075356,
      "learning_rate": 9.589594185917634e-06,
      "loss": 0.0004,
      "step": 2592
    },
    {
      "epoch": 0.04105641496587868,
      "grad_norm": 6.048022987670265e-05,
      "learning_rate": 9.589435850341215e-06,
      "loss": 0.0,
      "step": 2593
    },
    {
      "epoch": 0.04107224852352075,
      "grad_norm": 0.2348337024450302,
      "learning_rate": 9.589277514764794e-06,
      "loss": 0.0426,
      "step": 2594
    },
    {
      "epoch": 0.04108808208116282,
      "grad_norm": 0.05638828128576279,
      "learning_rate": 9.589119179188373e-06,
      "loss": 0.0019,
      "step": 2595
    },
    {
      "epoch": 0.04110391563880488,
      "grad_norm": 0.13468578457832336,
      "learning_rate": 9.588960843611952e-06,
      "loss": 0.1077,
      "step": 2596
    },
    {
      "epoch": 0.04111974919644695,
      "grad_norm": 8.15145467640832e-05,
      "learning_rate": 9.588802508035531e-06,
      "loss": 0.0,
      "step": 2597
    },
    {
      "epoch": 0.04113558275408902,
      "grad_norm": 0.002264331793412566,
      "learning_rate": 9.58864417245911e-06,
      "loss": 0.0001,
      "step": 2598
    },
    {
      "epoch": 0.04115141631173108,
      "grad_norm": 0.16689103841781616,
      "learning_rate": 9.58848583688269e-06,
      "loss": 0.2602,
      "step": 2599
    },
    {
      "epoch": 0.04116724986937315,
      "grad_norm": 0.29931795597076416,
      "learning_rate": 9.58832750130627e-06,
      "loss": 0.4952,
      "step": 2600
    },
    {
      "epoch": 0.04118308342701522,
      "grad_norm": 8.708496898179874e-05,
      "learning_rate": 9.588169165729847e-06,
      "loss": 0.0,
      "step": 2601
    },
    {
      "epoch": 0.04119891698465728,
      "grad_norm": 0.38029980659484863,
      "learning_rate": 9.588010830153428e-06,
      "loss": 0.2799,
      "step": 2602
    },
    {
      "epoch": 0.04121475054229935,
      "grad_norm": 0.01594998687505722,
      "learning_rate": 9.587852494577007e-06,
      "loss": 0.0011,
      "step": 2603
    },
    {
      "epoch": 0.04123058409994142,
      "grad_norm": 0.11272268742322922,
      "learning_rate": 9.587694159000586e-06,
      "loss": 0.0818,
      "step": 2604
    },
    {
      "epoch": 0.04124641765758348,
      "grad_norm": 0.5537500381469727,
      "learning_rate": 9.587535823424165e-06,
      "loss": 0.2133,
      "step": 2605
    },
    {
      "epoch": 0.04126225121522555,
      "grad_norm": 0.16561102867126465,
      "learning_rate": 9.587377487847746e-06,
      "loss": 0.0361,
      "step": 2606
    },
    {
      "epoch": 0.04127808477286762,
      "grad_norm": 0.20604878664016724,
      "learning_rate": 9.587219152271324e-06,
      "loss": 0.1191,
      "step": 2607
    },
    {
      "epoch": 0.04129391833050968,
      "grad_norm": 0.2670052945613861,
      "learning_rate": 9.587060816694904e-06,
      "loss": 0.021,
      "step": 2608
    },
    {
      "epoch": 0.04130975188815175,
      "grad_norm": 0.20050935447216034,
      "learning_rate": 9.586902481118483e-06,
      "loss": 0.3827,
      "step": 2609
    },
    {
      "epoch": 0.04132558544579382,
      "grad_norm": 0.01898265816271305,
      "learning_rate": 9.586744145542063e-06,
      "loss": 0.0014,
      "step": 2610
    },
    {
      "epoch": 0.04134141900343588,
      "grad_norm": 0.34561964869499207,
      "learning_rate": 9.586585809965642e-06,
      "loss": 0.0056,
      "step": 2611
    },
    {
      "epoch": 0.04135725256107795,
      "grad_norm": 0.3642352521419525,
      "learning_rate": 9.586427474389222e-06,
      "loss": 0.2062,
      "step": 2612
    },
    {
      "epoch": 0.041373086118720016,
      "grad_norm": 0.22316952049732208,
      "learning_rate": 9.5862691388128e-06,
      "loss": 0.1133,
      "step": 2613
    },
    {
      "epoch": 0.04138891967636208,
      "grad_norm": 0.5638969540596008,
      "learning_rate": 9.58611080323638e-06,
      "loss": 0.2075,
      "step": 2614
    },
    {
      "epoch": 0.041404753234004145,
      "grad_norm": 0.1916263997554779,
      "learning_rate": 9.58595246765996e-06,
      "loss": 0.0974,
      "step": 2615
    },
    {
      "epoch": 0.041420586791646216,
      "grad_norm": 0.26548877358436584,
      "learning_rate": 9.585794132083539e-06,
      "loss": 0.0551,
      "step": 2616
    },
    {
      "epoch": 0.04143642034928828,
      "grad_norm": 0.1715630143880844,
      "learning_rate": 9.585635796507118e-06,
      "loss": 0.377,
      "step": 2617
    },
    {
      "epoch": 0.041452253906930345,
      "grad_norm": 0.043593261390924454,
      "learning_rate": 9.585477460930699e-06,
      "loss": 0.0065,
      "step": 2618
    },
    {
      "epoch": 0.041468087464572416,
      "grad_norm": 0.004518034867942333,
      "learning_rate": 9.585319125354276e-06,
      "loss": 0.0002,
      "step": 2619
    },
    {
      "epoch": 0.04148392102221448,
      "grad_norm": 0.41492533683776855,
      "learning_rate": 9.585160789777857e-06,
      "loss": 0.4926,
      "step": 2620
    },
    {
      "epoch": 0.041499754579856545,
      "grad_norm": 0.00010281663708155975,
      "learning_rate": 9.585002454201436e-06,
      "loss": 0.0,
      "step": 2621
    },
    {
      "epoch": 0.041515588137498616,
      "grad_norm": 0.17002147436141968,
      "learning_rate": 9.584844118625015e-06,
      "loss": 0.1452,
      "step": 2622
    },
    {
      "epoch": 0.04153142169514068,
      "grad_norm": 0.13410978019237518,
      "learning_rate": 9.584685783048594e-06,
      "loss": 0.1197,
      "step": 2623
    },
    {
      "epoch": 0.041547255252782744,
      "grad_norm": 0.0001711233489913866,
      "learning_rate": 9.584527447472173e-06,
      "loss": 0.0,
      "step": 2624
    },
    {
      "epoch": 0.041563088810424816,
      "grad_norm": 0.00020839407807216048,
      "learning_rate": 9.584369111895752e-06,
      "loss": 0.0,
      "step": 2625
    },
    {
      "epoch": 0.04157892236806688,
      "grad_norm": 0.28710126876831055,
      "learning_rate": 9.584210776319331e-06,
      "loss": 0.0757,
      "step": 2626
    },
    {
      "epoch": 0.041594755925708944,
      "grad_norm": 0.2346828132867813,
      "learning_rate": 9.584052440742912e-06,
      "loss": 0.1284,
      "step": 2627
    },
    {
      "epoch": 0.041610589483351015,
      "grad_norm": 0.182534322142601,
      "learning_rate": 9.583894105166491e-06,
      "loss": 0.3343,
      "step": 2628
    },
    {
      "epoch": 0.04162642304099308,
      "grad_norm": 8.058928506216034e-05,
      "learning_rate": 9.58373576959007e-06,
      "loss": 0.0,
      "step": 2629
    },
    {
      "epoch": 0.041642256598635144,
      "grad_norm": 0.11963587999343872,
      "learning_rate": 9.58357743401365e-06,
      "loss": 0.0363,
      "step": 2630
    },
    {
      "epoch": 0.041658090156277215,
      "grad_norm": 0.31556791067123413,
      "learning_rate": 9.583419098437228e-06,
      "loss": 1.1183,
      "step": 2631
    },
    {
      "epoch": 0.04167392371391928,
      "grad_norm": 0.30077436566352844,
      "learning_rate": 9.583260762860807e-06,
      "loss": 0.1787,
      "step": 2632
    },
    {
      "epoch": 0.041689757271561344,
      "grad_norm": 0.13405272364616394,
      "learning_rate": 9.583102427284388e-06,
      "loss": 0.0092,
      "step": 2633
    },
    {
      "epoch": 0.041705590829203415,
      "grad_norm": 4.9203456001123413e-05,
      "learning_rate": 9.582944091707966e-06,
      "loss": 0.0,
      "step": 2634
    },
    {
      "epoch": 0.04172142438684548,
      "grad_norm": 0.007636163849383593,
      "learning_rate": 9.582785756131546e-06,
      "loss": 0.0004,
      "step": 2635
    },
    {
      "epoch": 0.041737257944487544,
      "grad_norm": 0.002769327722489834,
      "learning_rate": 9.582627420555125e-06,
      "loss": 0.0002,
      "step": 2636
    },
    {
      "epoch": 0.041753091502129615,
      "grad_norm": 0.006315050646662712,
      "learning_rate": 9.582469084978704e-06,
      "loss": 0.0004,
      "step": 2637
    },
    {
      "epoch": 0.04176892505977168,
      "grad_norm": 0.0061051626689732075,
      "learning_rate": 9.582310749402284e-06,
      "loss": 0.0004,
      "step": 2638
    },
    {
      "epoch": 0.04178475861741374,
      "grad_norm": 0.01361195556819439,
      "learning_rate": 9.582152413825864e-06,
      "loss": 0.0009,
      "step": 2639
    },
    {
      "epoch": 0.041800592175055815,
      "grad_norm": 0.22000178694725037,
      "learning_rate": 9.581994078249442e-06,
      "loss": 0.1348,
      "step": 2640
    },
    {
      "epoch": 0.04181642573269788,
      "grad_norm": 0.3439115881919861,
      "learning_rate": 9.581835742673022e-06,
      "loss": 0.3497,
      "step": 2641
    },
    {
      "epoch": 0.04183225929033994,
      "grad_norm": 0.3751281499862671,
      "learning_rate": 9.581677407096602e-06,
      "loss": 0.2981,
      "step": 2642
    },
    {
      "epoch": 0.041848092847982014,
      "grad_norm": 4.8128142225323245e-05,
      "learning_rate": 9.58151907152018e-06,
      "loss": 0.0,
      "step": 2643
    },
    {
      "epoch": 0.04186392640562408,
      "grad_norm": 0.29601484537124634,
      "learning_rate": 9.58136073594376e-06,
      "loss": 0.2484,
      "step": 2644
    },
    {
      "epoch": 0.04187975996326614,
      "grad_norm": 0.2332678884267807,
      "learning_rate": 9.58120240036734e-06,
      "loss": 0.1329,
      "step": 2645
    },
    {
      "epoch": 0.041895593520908214,
      "grad_norm": 0.08757971972227097,
      "learning_rate": 9.581044064790918e-06,
      "loss": 0.0161,
      "step": 2646
    },
    {
      "epoch": 0.04191142707855028,
      "grad_norm": 0.26028627157211304,
      "learning_rate": 9.580885729214497e-06,
      "loss": 0.2642,
      "step": 2647
    },
    {
      "epoch": 0.04192726063619234,
      "grad_norm": 0.24442645907402039,
      "learning_rate": 9.580727393638078e-06,
      "loss": 0.2198,
      "step": 2648
    },
    {
      "epoch": 0.041943094193834414,
      "grad_norm": 0.33582398295402527,
      "learning_rate": 9.580569058061657e-06,
      "loss": 0.2068,
      "step": 2649
    },
    {
      "epoch": 0.04195892775147648,
      "grad_norm": 0.00025594167527742684,
      "learning_rate": 9.580410722485236e-06,
      "loss": 0.0,
      "step": 2650
    },
    {
      "epoch": 0.04197476130911854,
      "grad_norm": 0.17198149859905243,
      "learning_rate": 9.580252386908815e-06,
      "loss": 0.0531,
      "step": 2651
    },
    {
      "epoch": 0.041990594866760614,
      "grad_norm": 0.3267371952533722,
      "learning_rate": 9.580094051332394e-06,
      "loss": 0.246,
      "step": 2652
    },
    {
      "epoch": 0.04200642842440268,
      "grad_norm": 0.39957213401794434,
      "learning_rate": 9.579935715755973e-06,
      "loss": 0.4662,
      "step": 2653
    },
    {
      "epoch": 0.04202226198204474,
      "grad_norm": 0.00024104792100843042,
      "learning_rate": 9.579777380179554e-06,
      "loss": 0.0,
      "step": 2654
    },
    {
      "epoch": 0.042038095539686814,
      "grad_norm": 0.19216546416282654,
      "learning_rate": 9.579619044603133e-06,
      "loss": 0.1547,
      "step": 2655
    },
    {
      "epoch": 0.04205392909732888,
      "grad_norm": 0.03235781192779541,
      "learning_rate": 9.579460709026712e-06,
      "loss": 0.001,
      "step": 2656
    },
    {
      "epoch": 0.04206976265497094,
      "grad_norm": 0.018697589635849,
      "learning_rate": 9.579302373450291e-06,
      "loss": 0.0011,
      "step": 2657
    },
    {
      "epoch": 0.04208559621261301,
      "grad_norm": 0.14728014171123505,
      "learning_rate": 9.57914403787387e-06,
      "loss": 0.0528,
      "step": 2658
    },
    {
      "epoch": 0.04210142977025508,
      "grad_norm": 0.008958518505096436,
      "learning_rate": 9.57898570229745e-06,
      "loss": 0.0006,
      "step": 2659
    },
    {
      "epoch": 0.04211726332789714,
      "grad_norm": 0.4313611090183258,
      "learning_rate": 9.57882736672103e-06,
      "loss": 0.1893,
      "step": 2660
    },
    {
      "epoch": 0.04213309688553921,
      "grad_norm": 0.1284356415271759,
      "learning_rate": 9.578669031144609e-06,
      "loss": 0.0591,
      "step": 2661
    },
    {
      "epoch": 0.04214893044318128,
      "grad_norm": 0.4918127954006195,
      "learning_rate": 9.578510695568188e-06,
      "loss": 0.2079,
      "step": 2662
    },
    {
      "epoch": 0.04216476400082334,
      "grad_norm": 0.3936024606227875,
      "learning_rate": 9.578352359991767e-06,
      "loss": 0.9095,
      "step": 2663
    },
    {
      "epoch": 0.04218059755846541,
      "grad_norm": 0.11367720365524292,
      "learning_rate": 9.578194024415346e-06,
      "loss": 0.0836,
      "step": 2664
    },
    {
      "epoch": 0.04219643111610748,
      "grad_norm": 0.15339267253875732,
      "learning_rate": 9.578035688838925e-06,
      "loss": 0.0689,
      "step": 2665
    },
    {
      "epoch": 0.04221226467374954,
      "grad_norm": 0.311454176902771,
      "learning_rate": 9.577877353262506e-06,
      "loss": 0.3897,
      "step": 2666
    },
    {
      "epoch": 0.04222809823139161,
      "grad_norm": 0.20211327075958252,
      "learning_rate": 9.577719017686085e-06,
      "loss": 0.0518,
      "step": 2667
    },
    {
      "epoch": 0.04224393178903368,
      "grad_norm": 0.19826684892177582,
      "learning_rate": 9.577560682109664e-06,
      "loss": 0.2776,
      "step": 2668
    },
    {
      "epoch": 0.04225976534667574,
      "grad_norm": 0.2610440254211426,
      "learning_rate": 9.577402346533243e-06,
      "loss": 0.2143,
      "step": 2669
    },
    {
      "epoch": 0.04227559890431781,
      "grad_norm": 0.18043845891952515,
      "learning_rate": 9.577244010956823e-06,
      "loss": 0.0578,
      "step": 2670
    },
    {
      "epoch": 0.04229143246195988,
      "grad_norm": 0.11066903173923492,
      "learning_rate": 9.577085675380402e-06,
      "loss": 0.0482,
      "step": 2671
    },
    {
      "epoch": 0.04230726601960194,
      "grad_norm": 0.004962692968547344,
      "learning_rate": 9.57692733980398e-06,
      "loss": 0.0003,
      "step": 2672
    },
    {
      "epoch": 0.04232309957724401,
      "grad_norm": 0.2547040283679962,
      "learning_rate": 9.576769004227561e-06,
      "loss": 0.3527,
      "step": 2673
    },
    {
      "epoch": 0.04233893313488608,
      "grad_norm": 0.025677554309368134,
      "learning_rate": 9.576610668651139e-06,
      "loss": 0.0019,
      "step": 2674
    },
    {
      "epoch": 0.04235476669252814,
      "grad_norm": 0.2791871726512909,
      "learning_rate": 9.57645233307472e-06,
      "loss": 0.0585,
      "step": 2675
    },
    {
      "epoch": 0.04237060025017021,
      "grad_norm": 0.16401539742946625,
      "learning_rate": 9.576293997498299e-06,
      "loss": 0.047,
      "step": 2676
    },
    {
      "epoch": 0.04238643380781228,
      "grad_norm": 0.0006163982907310128,
      "learning_rate": 9.576135661921878e-06,
      "loss": 0.0,
      "step": 2677
    },
    {
      "epoch": 0.04240226736545434,
      "grad_norm": 0.21547502279281616,
      "learning_rate": 9.575977326345457e-06,
      "loss": 0.058,
      "step": 2678
    },
    {
      "epoch": 0.04241810092309641,
      "grad_norm": 0.21695926785469055,
      "learning_rate": 9.575818990769038e-06,
      "loss": 0.1611,
      "step": 2679
    },
    {
      "epoch": 0.042433934480738476,
      "grad_norm": 0.005713543388992548,
      "learning_rate": 9.575660655192615e-06,
      "loss": 0.0003,
      "step": 2680
    },
    {
      "epoch": 0.04244976803838054,
      "grad_norm": 0.00024064072931651026,
      "learning_rate": 9.575502319616196e-06,
      "loss": 0.0,
      "step": 2681
    },
    {
      "epoch": 0.04246560159602261,
      "grad_norm": 0.2879912257194519,
      "learning_rate": 9.575343984039775e-06,
      "loss": 0.1097,
      "step": 2682
    },
    {
      "epoch": 0.042481435153664676,
      "grad_norm": 0.021065402776002884,
      "learning_rate": 9.575185648463354e-06,
      "loss": 0.0014,
      "step": 2683
    },
    {
      "epoch": 0.04249726871130674,
      "grad_norm": 0.19994617998600006,
      "learning_rate": 9.575027312886933e-06,
      "loss": 0.204,
      "step": 2684
    },
    {
      "epoch": 0.04251310226894881,
      "grad_norm": 0.1883566826581955,
      "learning_rate": 9.574868977310514e-06,
      "loss": 0.2393,
      "step": 2685
    },
    {
      "epoch": 0.042528935826590876,
      "grad_norm": 0.00015325588174164295,
      "learning_rate": 9.574710641734091e-06,
      "loss": 0.0,
      "step": 2686
    },
    {
      "epoch": 0.04254476938423294,
      "grad_norm": 0.0038900738582015038,
      "learning_rate": 9.574552306157672e-06,
      "loss": 0.0002,
      "step": 2687
    },
    {
      "epoch": 0.04256060294187501,
      "grad_norm": 0.14916305243968964,
      "learning_rate": 9.574393970581251e-06,
      "loss": 0.0325,
      "step": 2688
    },
    {
      "epoch": 0.042576436499517076,
      "grad_norm": 0.2529420256614685,
      "learning_rate": 9.57423563500483e-06,
      "loss": 0.1078,
      "step": 2689
    },
    {
      "epoch": 0.04259227005715914,
      "grad_norm": 0.13934174180030823,
      "learning_rate": 9.57407729942841e-06,
      "loss": 0.0286,
      "step": 2690
    },
    {
      "epoch": 0.04260810361480121,
      "grad_norm": 0.2961046099662781,
      "learning_rate": 9.57391896385199e-06,
      "loss": 0.8734,
      "step": 2691
    },
    {
      "epoch": 0.042623937172443276,
      "grad_norm": 0.20439966022968292,
      "learning_rate": 9.573760628275567e-06,
      "loss": 0.0746,
      "step": 2692
    },
    {
      "epoch": 0.04263977073008534,
      "grad_norm": 0.02376309409737587,
      "learning_rate": 9.573602292699148e-06,
      "loss": 0.0005,
      "step": 2693
    },
    {
      "epoch": 0.04265560428772741,
      "grad_norm": 0.21218521893024445,
      "learning_rate": 9.573443957122727e-06,
      "loss": 0.1927,
      "step": 2694
    },
    {
      "epoch": 0.042671437845369475,
      "grad_norm": 0.27903541922569275,
      "learning_rate": 9.573285621546306e-06,
      "loss": 0.2003,
      "step": 2695
    },
    {
      "epoch": 0.04268727140301154,
      "grad_norm": 0.3106652796268463,
      "learning_rate": 9.573127285969885e-06,
      "loss": 0.2141,
      "step": 2696
    },
    {
      "epoch": 0.04270310496065361,
      "grad_norm": 0.2186606526374817,
      "learning_rate": 9.572968950393464e-06,
      "loss": 0.1454,
      "step": 2697
    },
    {
      "epoch": 0.042718938518295675,
      "grad_norm": 0.017654459923505783,
      "learning_rate": 9.572810614817044e-06,
      "loss": 0.0009,
      "step": 2698
    },
    {
      "epoch": 0.04273477207593774,
      "grad_norm": 0.003853149712085724,
      "learning_rate": 9.572652279240623e-06,
      "loss": 0.0002,
      "step": 2699
    },
    {
      "epoch": 0.04275060563357981,
      "grad_norm": 0.1567426323890686,
      "learning_rate": 9.572493943664203e-06,
      "loss": 0.0255,
      "step": 2700
    },
    {
      "epoch": 0.042766439191221875,
      "grad_norm": 0.15329669415950775,
      "learning_rate": 9.57233560808778e-06,
      "loss": 0.1128,
      "step": 2701
    },
    {
      "epoch": 0.04278227274886394,
      "grad_norm": 0.3686073422431946,
      "learning_rate": 9.572177272511362e-06,
      "loss": 0.0142,
      "step": 2702
    },
    {
      "epoch": 0.04279810630650601,
      "grad_norm": 0.1691971868276596,
      "learning_rate": 9.57201893693494e-06,
      "loss": 0.0787,
      "step": 2703
    },
    {
      "epoch": 0.042813939864148075,
      "grad_norm": 0.010884175077080727,
      "learning_rate": 9.57186060135852e-06,
      "loss": 0.0007,
      "step": 2704
    },
    {
      "epoch": 0.04282977342179014,
      "grad_norm": 0.2613900303840637,
      "learning_rate": 9.571702265782099e-06,
      "loss": 0.1394,
      "step": 2705
    },
    {
      "epoch": 0.04284560697943221,
      "grad_norm": 0.13601481914520264,
      "learning_rate": 9.57154393020568e-06,
      "loss": 0.0536,
      "step": 2706
    },
    {
      "epoch": 0.042861440537074275,
      "grad_norm": 0.19938677549362183,
      "learning_rate": 9.571385594629257e-06,
      "loss": 0.2458,
      "step": 2707
    },
    {
      "epoch": 0.04287727409471634,
      "grad_norm": 0.01732606440782547,
      "learning_rate": 9.571227259052838e-06,
      "loss": 0.001,
      "step": 2708
    },
    {
      "epoch": 0.04289310765235841,
      "grad_norm": 0.18649651110172272,
      "learning_rate": 9.571068923476417e-06,
      "loss": 0.0622,
      "step": 2709
    },
    {
      "epoch": 0.042908941210000474,
      "grad_norm": 0.14929239451885223,
      "learning_rate": 9.570910587899996e-06,
      "loss": 0.0185,
      "step": 2710
    },
    {
      "epoch": 0.04292477476764254,
      "grad_norm": 0.1707276850938797,
      "learning_rate": 9.570752252323575e-06,
      "loss": 0.0726,
      "step": 2711
    },
    {
      "epoch": 0.04294060832528461,
      "grad_norm": 0.37650439143180847,
      "learning_rate": 9.570593916747156e-06,
      "loss": 0.6403,
      "step": 2712
    },
    {
      "epoch": 0.042956441882926674,
      "grad_norm": 0.003825913183391094,
      "learning_rate": 9.570435581170733e-06,
      "loss": 0.0002,
      "step": 2713
    },
    {
      "epoch": 0.04297227544056874,
      "grad_norm": 0.06294536590576172,
      "learning_rate": 9.570277245594314e-06,
      "loss": 0.0014,
      "step": 2714
    },
    {
      "epoch": 0.04298810899821081,
      "grad_norm": 0.5581181645393372,
      "learning_rate": 9.570118910017893e-06,
      "loss": 0.6624,
      "step": 2715
    },
    {
      "epoch": 0.043003942555852874,
      "grad_norm": 0.3356453478336334,
      "learning_rate": 9.569960574441472e-06,
      "loss": 0.1663,
      "step": 2716
    },
    {
      "epoch": 0.04301977611349494,
      "grad_norm": 0.38092607259750366,
      "learning_rate": 9.569802238865051e-06,
      "loss": 0.6416,
      "step": 2717
    },
    {
      "epoch": 0.04303560967113701,
      "grad_norm": 0.17050187289714813,
      "learning_rate": 9.569643903288632e-06,
      "loss": 0.0659,
      "step": 2718
    },
    {
      "epoch": 0.043051443228779074,
      "grad_norm": 9.199037594953552e-05,
      "learning_rate": 9.56948556771221e-06,
      "loss": 0.0,
      "step": 2719
    },
    {
      "epoch": 0.04306727678642114,
      "grad_norm": 0.1835985630750656,
      "learning_rate": 9.569327232135788e-06,
      "loss": 0.041,
      "step": 2720
    },
    {
      "epoch": 0.04308311034406321,
      "grad_norm": 0.4173605144023895,
      "learning_rate": 9.56916889655937e-06,
      "loss": 0.2911,
      "step": 2721
    },
    {
      "epoch": 0.043098943901705274,
      "grad_norm": 0.2690803110599518,
      "learning_rate": 9.569010560982948e-06,
      "loss": 0.1429,
      "step": 2722
    },
    {
      "epoch": 0.04311477745934734,
      "grad_norm": 0.4544312357902527,
      "learning_rate": 9.568852225406527e-06,
      "loss": 0.3522,
      "step": 2723
    },
    {
      "epoch": 0.04313061101698941,
      "grad_norm": 0.29977428913116455,
      "learning_rate": 9.568693889830106e-06,
      "loss": 0.544,
      "step": 2724
    },
    {
      "epoch": 0.04314644457463147,
      "grad_norm": 0.022271107882261276,
      "learning_rate": 9.568535554253685e-06,
      "loss": 0.0012,
      "step": 2725
    },
    {
      "epoch": 0.04316227813227354,
      "grad_norm": 0.4481164813041687,
      "learning_rate": 9.568377218677265e-06,
      "loss": 0.0478,
      "step": 2726
    },
    {
      "epoch": 0.04317811168991561,
      "grad_norm": 0.03133709728717804,
      "learning_rate": 9.568218883100845e-06,
      "loss": 0.004,
      "step": 2727
    },
    {
      "epoch": 0.04319394524755767,
      "grad_norm": 0.31357643008232117,
      "learning_rate": 9.568060547524424e-06,
      "loss": 0.217,
      "step": 2728
    },
    {
      "epoch": 0.04320977880519974,
      "grad_norm": 4.745516343973577e-05,
      "learning_rate": 9.567902211948003e-06,
      "loss": 0.0,
      "step": 2729
    },
    {
      "epoch": 0.04322561236284181,
      "grad_norm": 0.04413112625479698,
      "learning_rate": 9.567743876371583e-06,
      "loss": 0.0073,
      "step": 2730
    },
    {
      "epoch": 0.04324144592048387,
      "grad_norm": 0.018198346719145775,
      "learning_rate": 9.567585540795162e-06,
      "loss": 0.0005,
      "step": 2731
    },
    {
      "epoch": 0.04325727947812594,
      "grad_norm": 0.08935393393039703,
      "learning_rate": 9.56742720521874e-06,
      "loss": 0.0289,
      "step": 2732
    },
    {
      "epoch": 0.04327311303576801,
      "grad_norm": 0.23292501270771027,
      "learning_rate": 9.567268869642322e-06,
      "loss": 0.336,
      "step": 2733
    },
    {
      "epoch": 0.04328894659341007,
      "grad_norm": 0.22719182074069977,
      "learning_rate": 9.5671105340659e-06,
      "loss": 0.346,
      "step": 2734
    },
    {
      "epoch": 0.04330478015105214,
      "grad_norm": 0.3772391378879547,
      "learning_rate": 9.56695219848948e-06,
      "loss": 0.2638,
      "step": 2735
    },
    {
      "epoch": 0.04332061370869421,
      "grad_norm": 2.583420753479004,
      "learning_rate": 9.566793862913059e-06,
      "loss": 0.1953,
      "step": 2736
    },
    {
      "epoch": 0.04333644726633627,
      "grad_norm": 0.2346140593290329,
      "learning_rate": 9.566635527336638e-06,
      "loss": 0.0827,
      "step": 2737
    },
    {
      "epoch": 0.04335228082397834,
      "grad_norm": 0.00041683969902805984,
      "learning_rate": 9.566477191760217e-06,
      "loss": 0.0,
      "step": 2738
    },
    {
      "epoch": 0.04336811438162041,
      "grad_norm": 0.18936073780059814,
      "learning_rate": 9.566318856183798e-06,
      "loss": 0.2159,
      "step": 2739
    },
    {
      "epoch": 0.04338394793926247,
      "grad_norm": 0.257319837808609,
      "learning_rate": 9.566160520607377e-06,
      "loss": 0.2028,
      "step": 2740
    },
    {
      "epoch": 0.04339978149690454,
      "grad_norm": 0.008782237768173218,
      "learning_rate": 9.566002185030956e-06,
      "loss": 0.0005,
      "step": 2741
    },
    {
      "epoch": 0.04341561505454661,
      "grad_norm": 0.32244473695755005,
      "learning_rate": 9.565843849454535e-06,
      "loss": 0.706,
      "step": 2742
    },
    {
      "epoch": 0.04343144861218867,
      "grad_norm": 0.2701543867588043,
      "learning_rate": 9.565685513878114e-06,
      "loss": 0.189,
      "step": 2743
    },
    {
      "epoch": 0.04344728216983074,
      "grad_norm": 0.3323199152946472,
      "learning_rate": 9.565527178301693e-06,
      "loss": 0.4265,
      "step": 2744
    },
    {
      "epoch": 0.04346311572747281,
      "grad_norm": 0.1830955594778061,
      "learning_rate": 9.565368842725272e-06,
      "loss": 0.1834,
      "step": 2745
    },
    {
      "epoch": 0.04347894928511487,
      "grad_norm": 0.17021498084068298,
      "learning_rate": 9.565210507148853e-06,
      "loss": 0.2051,
      "step": 2746
    },
    {
      "epoch": 0.043494782842756936,
      "grad_norm": 0.038236528635025024,
      "learning_rate": 9.56505217157243e-06,
      "loss": 0.0037,
      "step": 2747
    },
    {
      "epoch": 0.04351061640039901,
      "grad_norm": 0.0006926608621142805,
      "learning_rate": 9.564893835996011e-06,
      "loss": 0.0,
      "step": 2748
    },
    {
      "epoch": 0.04352644995804107,
      "grad_norm": 0.2855294942855835,
      "learning_rate": 9.56473550041959e-06,
      "loss": 0.0344,
      "step": 2749
    },
    {
      "epoch": 0.043542283515683136,
      "grad_norm": 0.30252203345298767,
      "learning_rate": 9.56457716484317e-06,
      "loss": 0.5406,
      "step": 2750
    },
    {
      "epoch": 0.04355811707332521,
      "grad_norm": 0.1965821236371994,
      "learning_rate": 9.564418829266748e-06,
      "loss": 0.1323,
      "step": 2751
    },
    {
      "epoch": 0.04357395063096727,
      "grad_norm": 0.12022922188043594,
      "learning_rate": 9.564260493690329e-06,
      "loss": 0.0367,
      "step": 2752
    },
    {
      "epoch": 0.043589784188609336,
      "grad_norm": 0.0012996889417991042,
      "learning_rate": 9.564102158113906e-06,
      "loss": 0.0,
      "step": 2753
    },
    {
      "epoch": 0.04360561774625141,
      "grad_norm": 0.147008016705513,
      "learning_rate": 9.563943822537487e-06,
      "loss": 0.0668,
      "step": 2754
    },
    {
      "epoch": 0.04362145130389347,
      "grad_norm": 0.2726682722568512,
      "learning_rate": 9.563785486961066e-06,
      "loss": 0.1062,
      "step": 2755
    },
    {
      "epoch": 0.043637284861535536,
      "grad_norm": 0.0012395201483741403,
      "learning_rate": 9.563627151384645e-06,
      "loss": 0.0,
      "step": 2756
    },
    {
      "epoch": 0.04365311841917761,
      "grad_norm": 0.25314861536026,
      "learning_rate": 9.563468815808224e-06,
      "loss": 0.1565,
      "step": 2757
    },
    {
      "epoch": 0.04366895197681967,
      "grad_norm": 0.3412947654724121,
      "learning_rate": 9.563310480231804e-06,
      "loss": 0.7389,
      "step": 2758
    },
    {
      "epoch": 0.043684785534461736,
      "grad_norm": 0.20832104980945587,
      "learning_rate": 9.563152144655383e-06,
      "loss": 0.1798,
      "step": 2759
    },
    {
      "epoch": 0.04370061909210381,
      "grad_norm": 0.16770799458026886,
      "learning_rate": 9.562993809078963e-06,
      "loss": 0.1784,
      "step": 2760
    },
    {
      "epoch": 0.04371645264974587,
      "grad_norm": 0.39973869919776917,
      "learning_rate": 9.562835473502543e-06,
      "loss": 0.1373,
      "step": 2761
    },
    {
      "epoch": 0.043732286207387935,
      "grad_norm": 0.2215854525566101,
      "learning_rate": 9.562677137926122e-06,
      "loss": 0.118,
      "step": 2762
    },
    {
      "epoch": 0.04374811976503001,
      "grad_norm": 0.1571452021598816,
      "learning_rate": 9.5625188023497e-06,
      "loss": 0.2426,
      "step": 2763
    },
    {
      "epoch": 0.04376395332267207,
      "grad_norm": 0.1667812168598175,
      "learning_rate": 9.56236046677328e-06,
      "loss": 0.0408,
      "step": 2764
    },
    {
      "epoch": 0.043779786880314135,
      "grad_norm": 0.21554113924503326,
      "learning_rate": 9.562202131196859e-06,
      "loss": 0.0709,
      "step": 2765
    },
    {
      "epoch": 0.043795620437956206,
      "grad_norm": 0.4376116096973419,
      "learning_rate": 9.56204379562044e-06,
      "loss": 0.1732,
      "step": 2766
    },
    {
      "epoch": 0.04381145399559827,
      "grad_norm": 0.3162975013256073,
      "learning_rate": 9.561885460044019e-06,
      "loss": 0.0818,
      "step": 2767
    },
    {
      "epoch": 0.043827287553240335,
      "grad_norm": 0.26726415753364563,
      "learning_rate": 9.561727124467596e-06,
      "loss": 0.0928,
      "step": 2768
    },
    {
      "epoch": 0.043843121110882406,
      "grad_norm": 0.19036689400672913,
      "learning_rate": 9.561568788891177e-06,
      "loss": 0.1129,
      "step": 2769
    },
    {
      "epoch": 0.04385895466852447,
      "grad_norm": 0.22175101935863495,
      "learning_rate": 9.561410453314756e-06,
      "loss": 0.2055,
      "step": 2770
    },
    {
      "epoch": 0.043874788226166535,
      "grad_norm": 0.2795112729072571,
      "learning_rate": 9.561252117738335e-06,
      "loss": 0.3525,
      "step": 2771
    },
    {
      "epoch": 0.043890621783808606,
      "grad_norm": 0.012790955603122711,
      "learning_rate": 9.561093782161914e-06,
      "loss": 0.0008,
      "step": 2772
    },
    {
      "epoch": 0.04390645534145067,
      "grad_norm": 0.2518511712551117,
      "learning_rate": 9.560935446585495e-06,
      "loss": 0.2173,
      "step": 2773
    },
    {
      "epoch": 0.043922288899092735,
      "grad_norm": 0.14744876325130463,
      "learning_rate": 9.560777111009072e-06,
      "loss": 0.0171,
      "step": 2774
    },
    {
      "epoch": 0.043938122456734806,
      "grad_norm": 0.24569909274578094,
      "learning_rate": 9.560618775432653e-06,
      "loss": 0.0885,
      "step": 2775
    },
    {
      "epoch": 0.04395395601437687,
      "grad_norm": 0.014120809733867645,
      "learning_rate": 9.560460439856232e-06,
      "loss": 0.0008,
      "step": 2776
    },
    {
      "epoch": 0.043969789572018934,
      "grad_norm": 0.27275145053863525,
      "learning_rate": 9.560302104279811e-06,
      "loss": 0.326,
      "step": 2777
    },
    {
      "epoch": 0.043985623129661006,
      "grad_norm": 0.00025864344206638634,
      "learning_rate": 9.56014376870339e-06,
      "loss": 0.0,
      "step": 2778
    },
    {
      "epoch": 0.04400145668730307,
      "grad_norm": 0.006685313768684864,
      "learning_rate": 9.559985433126971e-06,
      "loss": 0.0005,
      "step": 2779
    },
    {
      "epoch": 0.044017290244945134,
      "grad_norm": 0.33543822169303894,
      "learning_rate": 9.559827097550548e-06,
      "loss": 0.4755,
      "step": 2780
    },
    {
      "epoch": 0.044033123802587205,
      "grad_norm": 0.2111055552959442,
      "learning_rate": 9.55966876197413e-06,
      "loss": 0.0991,
      "step": 2781
    },
    {
      "epoch": 0.04404895736022927,
      "grad_norm": 0.23333795368671417,
      "learning_rate": 9.559510426397708e-06,
      "loss": 0.0998,
      "step": 2782
    },
    {
      "epoch": 0.044064790917871334,
      "grad_norm": 0.07996624708175659,
      "learning_rate": 9.559352090821287e-06,
      "loss": 0.0329,
      "step": 2783
    },
    {
      "epoch": 0.044080624475513405,
      "grad_norm": 0.03757377341389656,
      "learning_rate": 9.559193755244866e-06,
      "loss": 0.0026,
      "step": 2784
    },
    {
      "epoch": 0.04409645803315547,
      "grad_norm": 0.557287871837616,
      "learning_rate": 9.559035419668447e-06,
      "loss": 0.4884,
      "step": 2785
    },
    {
      "epoch": 0.044112291590797534,
      "grad_norm": 0.01830420456826687,
      "learning_rate": 9.558877084092025e-06,
      "loss": 0.0009,
      "step": 2786
    },
    {
      "epoch": 0.044128125148439605,
      "grad_norm": 0.01349679660052061,
      "learning_rate": 9.558718748515605e-06,
      "loss": 0.0009,
      "step": 2787
    },
    {
      "epoch": 0.04414395870608167,
      "grad_norm": 0.21720920503139496,
      "learning_rate": 9.558560412939184e-06,
      "loss": 0.2249,
      "step": 2788
    },
    {
      "epoch": 0.044159792263723734,
      "grad_norm": 0.17132630944252014,
      "learning_rate": 9.558402077362764e-06,
      "loss": 0.0612,
      "step": 2789
    },
    {
      "epoch": 0.044175625821365805,
      "grad_norm": 0.00015691353473812342,
      "learning_rate": 9.558243741786343e-06,
      "loss": 0.0,
      "step": 2790
    },
    {
      "epoch": 0.04419145937900787,
      "grad_norm": 9.691115701571107e-05,
      "learning_rate": 9.558085406209922e-06,
      "loss": 0.0,
      "step": 2791
    },
    {
      "epoch": 0.04420729293664993,
      "grad_norm": 0.34748661518096924,
      "learning_rate": 9.5579270706335e-06,
      "loss": 0.2821,
      "step": 2792
    },
    {
      "epoch": 0.044223126494292005,
      "grad_norm": 0.4748176038265228,
      "learning_rate": 9.55776873505708e-06,
      "loss": 0.1861,
      "step": 2793
    },
    {
      "epoch": 0.04423896005193407,
      "grad_norm": 0.13372762501239777,
      "learning_rate": 9.55761039948066e-06,
      "loss": 0.0293,
      "step": 2794
    },
    {
      "epoch": 0.04425479360957613,
      "grad_norm": 0.12676189839839935,
      "learning_rate": 9.55745206390424e-06,
      "loss": 0.0373,
      "step": 2795
    },
    {
      "epoch": 0.044270627167218204,
      "grad_norm": 0.19396494328975677,
      "learning_rate": 9.557293728327819e-06,
      "loss": 0.0772,
      "step": 2796
    },
    {
      "epoch": 0.04428646072486027,
      "grad_norm": 5.65284353797324e-05,
      "learning_rate": 9.557135392751398e-06,
      "loss": 0.0,
      "step": 2797
    },
    {
      "epoch": 0.04430229428250233,
      "grad_norm": 0.3465065360069275,
      "learning_rate": 9.556977057174977e-06,
      "loss": 0.7892,
      "step": 2798
    },
    {
      "epoch": 0.044318127840144404,
      "grad_norm": 0.011788654141128063,
      "learning_rate": 9.556818721598556e-06,
      "loss": 0.0007,
      "step": 2799
    },
    {
      "epoch": 0.04433396139778647,
      "grad_norm": 0.23117513954639435,
      "learning_rate": 9.556660386022137e-06,
      "loss": 0.1065,
      "step": 2800
    },
    {
      "epoch": 0.04434979495542853,
      "grad_norm": 0.44751402735710144,
      "learning_rate": 9.556502050445716e-06,
      "loss": 0.1986,
      "step": 2801
    },
    {
      "epoch": 0.044365628513070604,
      "grad_norm": 0.2788543701171875,
      "learning_rate": 9.556343714869295e-06,
      "loss": 0.2593,
      "step": 2802
    },
    {
      "epoch": 0.04438146207071267,
      "grad_norm": 0.16165155172348022,
      "learning_rate": 9.556185379292874e-06,
      "loss": 0.0831,
      "step": 2803
    },
    {
      "epoch": 0.04439729562835473,
      "grad_norm": 0.329475462436676,
      "learning_rate": 9.556027043716453e-06,
      "loss": 0.1452,
      "step": 2804
    },
    {
      "epoch": 0.044413129185996804,
      "grad_norm": 0.18024395406246185,
      "learning_rate": 9.555868708140032e-06,
      "loss": 0.1053,
      "step": 2805
    },
    {
      "epoch": 0.04442896274363887,
      "grad_norm": 0.16150256991386414,
      "learning_rate": 9.555710372563613e-06,
      "loss": 0.0494,
      "step": 2806
    },
    {
      "epoch": 0.04444479630128093,
      "grad_norm": 0.5298454761505127,
      "learning_rate": 9.555552036987192e-06,
      "loss": 0.1219,
      "step": 2807
    },
    {
      "epoch": 0.044460629858923004,
      "grad_norm": 0.0056101358495652676,
      "learning_rate": 9.555393701410771e-06,
      "loss": 0.0003,
      "step": 2808
    },
    {
      "epoch": 0.04447646341656507,
      "grad_norm": 0.2752605676651001,
      "learning_rate": 9.55523536583435e-06,
      "loss": 0.0995,
      "step": 2809
    },
    {
      "epoch": 0.04449229697420713,
      "grad_norm": 0.23112159967422485,
      "learning_rate": 9.55507703025793e-06,
      "loss": 0.1221,
      "step": 2810
    },
    {
      "epoch": 0.044508130531849203,
      "grad_norm": 0.2927340865135193,
      "learning_rate": 9.554918694681508e-06,
      "loss": 0.0792,
      "step": 2811
    },
    {
      "epoch": 0.04452396408949127,
      "grad_norm": 0.23062530159950256,
      "learning_rate": 9.554760359105089e-06,
      "loss": 0.1427,
      "step": 2812
    },
    {
      "epoch": 0.04453979764713333,
      "grad_norm": 0.450038343667984,
      "learning_rate": 9.554602023528668e-06,
      "loss": 0.253,
      "step": 2813
    },
    {
      "epoch": 0.0445556312047754,
      "grad_norm": 0.17358289659023285,
      "learning_rate": 9.554443687952247e-06,
      "loss": 0.0757,
      "step": 2814
    },
    {
      "epoch": 0.04457146476241747,
      "grad_norm": 0.010302543640136719,
      "learning_rate": 9.554285352375826e-06,
      "loss": 0.0005,
      "step": 2815
    },
    {
      "epoch": 0.04458729832005953,
      "grad_norm": 0.0049104951322078705,
      "learning_rate": 9.554127016799405e-06,
      "loss": 0.0003,
      "step": 2816
    },
    {
      "epoch": 0.0446031318777016,
      "grad_norm": 0.347194641828537,
      "learning_rate": 9.553968681222985e-06,
      "loss": 0.0467,
      "step": 2817
    },
    {
      "epoch": 0.04461896543534367,
      "grad_norm": 0.0032373247668147087,
      "learning_rate": 9.553810345646564e-06,
      "loss": 0.0001,
      "step": 2818
    },
    {
      "epoch": 0.04463479899298573,
      "grad_norm": 0.018724851310253143,
      "learning_rate": 9.553652010070144e-06,
      "loss": 0.001,
      "step": 2819
    },
    {
      "epoch": 0.0446506325506278,
      "grad_norm": 0.25799810886383057,
      "learning_rate": 9.553493674493722e-06,
      "loss": 0.1331,
      "step": 2820
    },
    {
      "epoch": 0.04466646610826987,
      "grad_norm": 0.285251647233963,
      "learning_rate": 9.553335338917303e-06,
      "loss": 0.279,
      "step": 2821
    },
    {
      "epoch": 0.04468229966591193,
      "grad_norm": 0.27973780035972595,
      "learning_rate": 9.553177003340882e-06,
      "loss": 0.0529,
      "step": 2822
    },
    {
      "epoch": 0.044698133223554,
      "grad_norm": 0.34280964732170105,
      "learning_rate": 9.55301866776446e-06,
      "loss": 0.206,
      "step": 2823
    },
    {
      "epoch": 0.04471396678119607,
      "grad_norm": 0.09624728560447693,
      "learning_rate": 9.55286033218804e-06,
      "loss": 0.0131,
      "step": 2824
    },
    {
      "epoch": 0.04472980033883813,
      "grad_norm": 0.34211230278015137,
      "learning_rate": 9.552701996611619e-06,
      "loss": 0.0151,
      "step": 2825
    },
    {
      "epoch": 0.0447456338964802,
      "grad_norm": 0.0005412776372395456,
      "learning_rate": 9.552543661035198e-06,
      "loss": 0.0,
      "step": 2826
    },
    {
      "epoch": 0.04476146745412227,
      "grad_norm": 0.0808369442820549,
      "learning_rate": 9.552385325458779e-06,
      "loss": 0.0018,
      "step": 2827
    },
    {
      "epoch": 0.04477730101176433,
      "grad_norm": 0.2844981253147125,
      "learning_rate": 9.552226989882358e-06,
      "loss": 0.1123,
      "step": 2828
    },
    {
      "epoch": 0.0447931345694064,
      "grad_norm": 0.2699401378631592,
      "learning_rate": 9.552068654305937e-06,
      "loss": 0.1551,
      "step": 2829
    },
    {
      "epoch": 0.04480896812704847,
      "grad_norm": 0.00021142212790437043,
      "learning_rate": 9.551910318729516e-06,
      "loss": 0.0,
      "step": 2830
    },
    {
      "epoch": 0.04482480168469053,
      "grad_norm": 0.1498013734817505,
      "learning_rate": 9.551751983153095e-06,
      "loss": 0.0565,
      "step": 2831
    },
    {
      "epoch": 0.0448406352423326,
      "grad_norm": 0.025195498019456863,
      "learning_rate": 9.551593647576674e-06,
      "loss": 0.0017,
      "step": 2832
    },
    {
      "epoch": 0.044856468799974666,
      "grad_norm": 0.19119910895824432,
      "learning_rate": 9.551435312000255e-06,
      "loss": 0.1072,
      "step": 2833
    },
    {
      "epoch": 0.04487230235761673,
      "grad_norm": 0.22533977031707764,
      "learning_rate": 9.551276976423834e-06,
      "loss": 0.1236,
      "step": 2834
    },
    {
      "epoch": 0.0448881359152588,
      "grad_norm": 0.19382475316524506,
      "learning_rate": 9.551118640847413e-06,
      "loss": 0.0415,
      "step": 2835
    },
    {
      "epoch": 0.044903969472900866,
      "grad_norm": 0.00027974395197816193,
      "learning_rate": 9.550960305270992e-06,
      "loss": 0.0,
      "step": 2836
    },
    {
      "epoch": 0.04491980303054293,
      "grad_norm": 0.295206755399704,
      "learning_rate": 9.550801969694571e-06,
      "loss": 0.1505,
      "step": 2837
    },
    {
      "epoch": 0.044935636588185,
      "grad_norm": 0.19858390092849731,
      "learning_rate": 9.55064363411815e-06,
      "loss": 0.0961,
      "step": 2838
    },
    {
      "epoch": 0.044951470145827066,
      "grad_norm": 0.20614668726921082,
      "learning_rate": 9.550485298541731e-06,
      "loss": 0.1323,
      "step": 2839
    },
    {
      "epoch": 0.04496730370346913,
      "grad_norm": 1.903058409690857,
      "learning_rate": 9.55032696296531e-06,
      "loss": 0.1303,
      "step": 2840
    },
    {
      "epoch": 0.0449831372611112,
      "grad_norm": 0.3931833803653717,
      "learning_rate": 9.550168627388888e-06,
      "loss": 0.0686,
      "step": 2841
    },
    {
      "epoch": 0.044998970818753266,
      "grad_norm": 0.32795262336730957,
      "learning_rate": 9.550010291812468e-06,
      "loss": 0.1442,
      "step": 2842
    },
    {
      "epoch": 0.04501480437639533,
      "grad_norm": 0.13700532913208008,
      "learning_rate": 9.549851956236047e-06,
      "loss": 0.0791,
      "step": 2843
    },
    {
      "epoch": 0.0450306379340374,
      "grad_norm": 0.013507421128451824,
      "learning_rate": 9.549693620659626e-06,
      "loss": 0.0006,
      "step": 2844
    },
    {
      "epoch": 0.045046471491679466,
      "grad_norm": 0.006685621105134487,
      "learning_rate": 9.549535285083206e-06,
      "loss": 0.0003,
      "step": 2845
    },
    {
      "epoch": 0.04506230504932153,
      "grad_norm": 0.1383964866399765,
      "learning_rate": 9.549376949506786e-06,
      "loss": 0.1166,
      "step": 2846
    },
    {
      "epoch": 0.0450781386069636,
      "grad_norm": 0.2365627884864807,
      "learning_rate": 9.549218613930364e-06,
      "loss": 0.437,
      "step": 2847
    },
    {
      "epoch": 0.045093972164605665,
      "grad_norm": 0.03838960826396942,
      "learning_rate": 9.549060278353944e-06,
      "loss": 0.0033,
      "step": 2848
    },
    {
      "epoch": 0.04510980572224773,
      "grad_norm": 0.19763807952404022,
      "learning_rate": 9.548901942777524e-06,
      "loss": 0.0719,
      "step": 2849
    },
    {
      "epoch": 0.0451256392798898,
      "grad_norm": 0.38737285137176514,
      "learning_rate": 9.548743607201103e-06,
      "loss": 0.174,
      "step": 2850
    },
    {
      "epoch": 0.045141472837531865,
      "grad_norm": 0.2664961516857147,
      "learning_rate": 9.548585271624682e-06,
      "loss": 0.1701,
      "step": 2851
    },
    {
      "epoch": 0.04515730639517393,
      "grad_norm": 0.0003225266991648823,
      "learning_rate": 9.548426936048262e-06,
      "loss": 0.0,
      "step": 2852
    },
    {
      "epoch": 0.045173139952816,
      "grad_norm": 0.24461837112903595,
      "learning_rate": 9.54826860047184e-06,
      "loss": 0.1534,
      "step": 2853
    },
    {
      "epoch": 0.045188973510458065,
      "grad_norm": 0.18797600269317627,
      "learning_rate": 9.54811026489542e-06,
      "loss": 0.1083,
      "step": 2854
    },
    {
      "epoch": 0.04520480706810013,
      "grad_norm": 0.004033118020743132,
      "learning_rate": 9.547951929319e-06,
      "loss": 0.0003,
      "step": 2855
    },
    {
      "epoch": 0.0452206406257422,
      "grad_norm": 0.005762308370321989,
      "learning_rate": 9.547793593742579e-06,
      "loss": 0.0003,
      "step": 2856
    },
    {
      "epoch": 0.045236474183384265,
      "grad_norm": 0.2687215209007263,
      "learning_rate": 9.547635258166158e-06,
      "loss": 0.0194,
      "step": 2857
    },
    {
      "epoch": 0.04525230774102633,
      "grad_norm": 0.5278180837631226,
      "learning_rate": 9.547476922589739e-06,
      "loss": 0.4067,
      "step": 2858
    },
    {
      "epoch": 0.0452681412986684,
      "grad_norm": 0.30884042382240295,
      "learning_rate": 9.547318587013316e-06,
      "loss": 0.1406,
      "step": 2859
    },
    {
      "epoch": 0.045283974856310465,
      "grad_norm": 0.398542582988739,
      "learning_rate": 9.547160251436897e-06,
      "loss": 0.7493,
      "step": 2860
    },
    {
      "epoch": 0.04529980841395253,
      "grad_norm": 0.2771572768688202,
      "learning_rate": 9.547001915860476e-06,
      "loss": 0.0502,
      "step": 2861
    },
    {
      "epoch": 0.0453156419715946,
      "grad_norm": 0.22682137787342072,
      "learning_rate": 9.546843580284055e-06,
      "loss": 0.1742,
      "step": 2862
    },
    {
      "epoch": 0.045331475529236664,
      "grad_norm": 0.17098353803157806,
      "learning_rate": 9.546685244707634e-06,
      "loss": 0.0461,
      "step": 2863
    },
    {
      "epoch": 0.04534730908687873,
      "grad_norm": 0.34254124760627747,
      "learning_rate": 9.546526909131213e-06,
      "loss": 0.1905,
      "step": 2864
    },
    {
      "epoch": 0.0453631426445208,
      "grad_norm": 0.21687494218349457,
      "learning_rate": 9.546368573554792e-06,
      "loss": 0.141,
      "step": 2865
    },
    {
      "epoch": 0.045378976202162864,
      "grad_norm": 0.21754851937294006,
      "learning_rate": 9.546210237978371e-06,
      "loss": 0.1361,
      "step": 2866
    },
    {
      "epoch": 0.04539480975980493,
      "grad_norm": 0.19917048513889313,
      "learning_rate": 9.546051902401952e-06,
      "loss": 0.6767,
      "step": 2867
    },
    {
      "epoch": 0.045410643317447,
      "grad_norm": 0.0004668148176278919,
      "learning_rate": 9.545893566825531e-06,
      "loss": 0.0,
      "step": 2868
    },
    {
      "epoch": 0.045426476875089064,
      "grad_norm": 0.09884808212518692,
      "learning_rate": 9.54573523124911e-06,
      "loss": 0.0026,
      "step": 2869
    },
    {
      "epoch": 0.04544231043273113,
      "grad_norm": 0.18164880573749542,
      "learning_rate": 9.54557689567269e-06,
      "loss": 0.196,
      "step": 2870
    },
    {
      "epoch": 0.0454581439903732,
      "grad_norm": 0.26178738474845886,
      "learning_rate": 9.545418560096268e-06,
      "loss": 0.0314,
      "step": 2871
    },
    {
      "epoch": 0.045473977548015264,
      "grad_norm": 0.21623052656650543,
      "learning_rate": 9.545260224519847e-06,
      "loss": 0.1348,
      "step": 2872
    },
    {
      "epoch": 0.04548981110565733,
      "grad_norm": 0.01462891697883606,
      "learning_rate": 9.545101888943428e-06,
      "loss": 0.0006,
      "step": 2873
    },
    {
      "epoch": 0.0455056446632994,
      "grad_norm": 0.24391689896583557,
      "learning_rate": 9.544943553367007e-06,
      "loss": 0.1859,
      "step": 2874
    },
    {
      "epoch": 0.045521478220941464,
      "grad_norm": 0.34995582699775696,
      "learning_rate": 9.544785217790586e-06,
      "loss": 0.4519,
      "step": 2875
    },
    {
      "epoch": 0.04553731177858353,
      "grad_norm": 0.3748111128807068,
      "learning_rate": 9.544626882214165e-06,
      "loss": 0.5958,
      "step": 2876
    },
    {
      "epoch": 0.0455531453362256,
      "grad_norm": 0.5474520921707153,
      "learning_rate": 9.544468546637745e-06,
      "loss": 0.5191,
      "step": 2877
    },
    {
      "epoch": 0.045568978893867663,
      "grad_norm": 0.00015300085942726582,
      "learning_rate": 9.544310211061324e-06,
      "loss": 0.0,
      "step": 2878
    },
    {
      "epoch": 0.04558481245150973,
      "grad_norm": 0.1591777503490448,
      "learning_rate": 9.544151875484904e-06,
      "loss": 0.1804,
      "step": 2879
    },
    {
      "epoch": 0.0456006460091518,
      "grad_norm": 0.22560955584049225,
      "learning_rate": 9.543993539908483e-06,
      "loss": 0.1809,
      "step": 2880
    },
    {
      "epoch": 0.04561647956679386,
      "grad_norm": 0.17281842231750488,
      "learning_rate": 9.543835204332063e-06,
      "loss": 0.1005,
      "step": 2881
    },
    {
      "epoch": 0.04563231312443593,
      "grad_norm": 0.4555535912513733,
      "learning_rate": 9.543676868755642e-06,
      "loss": 0.7019,
      "step": 2882
    },
    {
      "epoch": 0.045648146682078,
      "grad_norm": 0.00959241297096014,
      "learning_rate": 9.54351853317922e-06,
      "loss": 0.0005,
      "step": 2883
    },
    {
      "epoch": 0.04566398023972006,
      "grad_norm": 0.41261374950408936,
      "learning_rate": 9.5433601976028e-06,
      "loss": 0.2093,
      "step": 2884
    },
    {
      "epoch": 0.04567981379736213,
      "grad_norm": 0.16399125754833221,
      "learning_rate": 9.54320186202638e-06,
      "loss": 0.0673,
      "step": 2885
    },
    {
      "epoch": 0.0456956473550042,
      "grad_norm": 0.28902536630630493,
      "learning_rate": 9.543043526449958e-06,
      "loss": 0.1834,
      "step": 2886
    },
    {
      "epoch": 0.04571148091264626,
      "grad_norm": 0.3018750846385956,
      "learning_rate": 9.542885190873539e-06,
      "loss": 0.2718,
      "step": 2887
    },
    {
      "epoch": 0.04572731447028833,
      "grad_norm": 0.25013411045074463,
      "learning_rate": 9.542726855297118e-06,
      "loss": 0.1321,
      "step": 2888
    },
    {
      "epoch": 0.0457431480279304,
      "grad_norm": 0.4327862858772278,
      "learning_rate": 9.542568519720697e-06,
      "loss": 0.237,
      "step": 2889
    },
    {
      "epoch": 0.04575898158557246,
      "grad_norm": 6.330360338324681e-05,
      "learning_rate": 9.542410184144276e-06,
      "loss": 0.0,
      "step": 2890
    },
    {
      "epoch": 0.04577481514321453,
      "grad_norm": 0.25905218720436096,
      "learning_rate": 9.542251848567855e-06,
      "loss": 0.4495,
      "step": 2891
    },
    {
      "epoch": 0.0457906487008566,
      "grad_norm": 3.0544877517968416e-05,
      "learning_rate": 9.542093512991434e-06,
      "loss": 0.0,
      "step": 2892
    },
    {
      "epoch": 0.04580648225849866,
      "grad_norm": 0.14059031009674072,
      "learning_rate": 9.541935177415013e-06,
      "loss": 0.0639,
      "step": 2893
    },
    {
      "epoch": 0.04582231581614073,
      "grad_norm": 0.2800884246826172,
      "learning_rate": 9.541776841838594e-06,
      "loss": 0.0298,
      "step": 2894
    },
    {
      "epoch": 0.0458381493737828,
      "grad_norm": 0.01977887935936451,
      "learning_rate": 9.541618506262173e-06,
      "loss": 0.0009,
      "step": 2895
    },
    {
      "epoch": 0.04585398293142486,
      "grad_norm": 0.17855948209762573,
      "learning_rate": 9.541460170685752e-06,
      "loss": 0.1086,
      "step": 2896
    },
    {
      "epoch": 0.04586981648906693,
      "grad_norm": 0.0001858368777902797,
      "learning_rate": 9.541301835109331e-06,
      "loss": 0.0,
      "step": 2897
    },
    {
      "epoch": 0.045885650046709,
      "grad_norm": 0.24133770167827606,
      "learning_rate": 9.54114349953291e-06,
      "loss": 0.0358,
      "step": 2898
    },
    {
      "epoch": 0.04590148360435106,
      "grad_norm": 0.023838309571146965,
      "learning_rate": 9.54098516395649e-06,
      "loss": 0.0012,
      "step": 2899
    },
    {
      "epoch": 0.045917317161993126,
      "grad_norm": 0.17994263768196106,
      "learning_rate": 9.54082682838007e-06,
      "loss": 0.0309,
      "step": 2900
    },
    {
      "epoch": 0.0459331507196352,
      "grad_norm": 0.31158167123794556,
      "learning_rate": 9.54066849280365e-06,
      "loss": 0.1819,
      "step": 2901
    },
    {
      "epoch": 0.04594898427727726,
      "grad_norm": 0.01120244711637497,
      "learning_rate": 9.540510157227228e-06,
      "loss": 0.0005,
      "step": 2902
    },
    {
      "epoch": 0.045964817834919326,
      "grad_norm": 0.0077894749119877815,
      "learning_rate": 9.540351821650807e-06,
      "loss": 0.0004,
      "step": 2903
    },
    {
      "epoch": 0.0459806513925614,
      "grad_norm": 5.957937901257537e-05,
      "learning_rate": 9.540193486074386e-06,
      "loss": 0.0,
      "step": 2904
    },
    {
      "epoch": 0.04599648495020346,
      "grad_norm": 9.51460751821287e-05,
      "learning_rate": 9.540035150497966e-06,
      "loss": 0.0,
      "step": 2905
    },
    {
      "epoch": 0.046012318507845526,
      "grad_norm": 0.018122656270861626,
      "learning_rate": 9.539876814921546e-06,
      "loss": 0.0004,
      "step": 2906
    },
    {
      "epoch": 0.0460281520654876,
      "grad_norm": 0.00697725173085928,
      "learning_rate": 9.539718479345125e-06,
      "loss": 0.0004,
      "step": 2907
    },
    {
      "epoch": 0.04604398562312966,
      "grad_norm": 0.26618248224258423,
      "learning_rate": 9.539560143768704e-06,
      "loss": 0.4889,
      "step": 2908
    },
    {
      "epoch": 0.046059819180771726,
      "grad_norm": 0.027099138125777245,
      "learning_rate": 9.539401808192284e-06,
      "loss": 0.0014,
      "step": 2909
    },
    {
      "epoch": 0.0460756527384138,
      "grad_norm": 0.1312868297100067,
      "learning_rate": 9.539243472615863e-06,
      "loss": 0.0729,
      "step": 2910
    },
    {
      "epoch": 0.04609148629605586,
      "grad_norm": 0.34934234619140625,
      "learning_rate": 9.539085137039442e-06,
      "loss": 0.2064,
      "step": 2911
    },
    {
      "epoch": 0.046107319853697926,
      "grad_norm": 0.20553472638130188,
      "learning_rate": 9.53892680146302e-06,
      "loss": 0.0466,
      "step": 2912
    },
    {
      "epoch": 0.04612315341134,
      "grad_norm": 0.30725568532943726,
      "learning_rate": 9.538768465886602e-06,
      "loss": 0.2103,
      "step": 2913
    },
    {
      "epoch": 0.04613898696898206,
      "grad_norm": 0.15818536281585693,
      "learning_rate": 9.538610130310179e-06,
      "loss": 0.0415,
      "step": 2914
    },
    {
      "epoch": 0.046154820526624125,
      "grad_norm": 0.046832069754600525,
      "learning_rate": 9.53845179473376e-06,
      "loss": 0.0001,
      "step": 2915
    },
    {
      "epoch": 0.0461706540842662,
      "grad_norm": 0.16963668167591095,
      "learning_rate": 9.538293459157339e-06,
      "loss": 0.0621,
      "step": 2916
    },
    {
      "epoch": 0.04618648764190826,
      "grad_norm": 0.046458806842565536,
      "learning_rate": 9.538135123580918e-06,
      "loss": 0.0047,
      "step": 2917
    },
    {
      "epoch": 0.046202321199550325,
      "grad_norm": 0.2370653748512268,
      "learning_rate": 9.537976788004497e-06,
      "loss": 0.2643,
      "step": 2918
    },
    {
      "epoch": 0.046218154757192396,
      "grad_norm": 0.2634598910808563,
      "learning_rate": 9.537818452428078e-06,
      "loss": 0.0531,
      "step": 2919
    },
    {
      "epoch": 0.04623398831483446,
      "grad_norm": 0.14027509093284607,
      "learning_rate": 9.537660116851655e-06,
      "loss": 0.0575,
      "step": 2920
    },
    {
      "epoch": 0.046249821872476525,
      "grad_norm": 0.33724445104599,
      "learning_rate": 9.537501781275236e-06,
      "loss": 0.4181,
      "step": 2921
    },
    {
      "epoch": 0.046265655430118596,
      "grad_norm": 0.5322287082672119,
      "learning_rate": 9.537343445698815e-06,
      "loss": 0.4711,
      "step": 2922
    },
    {
      "epoch": 0.04628148898776066,
      "grad_norm": 0.0018046105979010463,
      "learning_rate": 9.537185110122394e-06,
      "loss": 0.0,
      "step": 2923
    },
    {
      "epoch": 0.046297322545402725,
      "grad_norm": 0.00010182914411416277,
      "learning_rate": 9.537026774545973e-06,
      "loss": 0.0,
      "step": 2924
    },
    {
      "epoch": 0.046313156103044796,
      "grad_norm": 0.16991287469863892,
      "learning_rate": 9.536868438969554e-06,
      "loss": 0.1252,
      "step": 2925
    },
    {
      "epoch": 0.04632898966068686,
      "grad_norm": 0.018293989822268486,
      "learning_rate": 9.536710103393131e-06,
      "loss": 0.0011,
      "step": 2926
    },
    {
      "epoch": 0.046344823218328925,
      "grad_norm": 0.23093706369400024,
      "learning_rate": 9.536551767816712e-06,
      "loss": 0.1048,
      "step": 2927
    },
    {
      "epoch": 0.046360656775970996,
      "grad_norm": 0.29460716247558594,
      "learning_rate": 9.536393432240291e-06,
      "loss": 0.1347,
      "step": 2928
    },
    {
      "epoch": 0.04637649033361306,
      "grad_norm": 0.49170172214508057,
      "learning_rate": 9.53623509666387e-06,
      "loss": 0.0797,
      "step": 2929
    },
    {
      "epoch": 0.046392323891255124,
      "grad_norm": 0.14654850959777832,
      "learning_rate": 9.53607676108745e-06,
      "loss": 0.1419,
      "step": 2930
    },
    {
      "epoch": 0.046408157448897196,
      "grad_norm": 0.557471752166748,
      "learning_rate": 9.53591842551103e-06,
      "loss": 0.2512,
      "step": 2931
    },
    {
      "epoch": 0.04642399100653926,
      "grad_norm": 0.07300570607185364,
      "learning_rate": 9.535760089934607e-06,
      "loss": 0.0047,
      "step": 2932
    },
    {
      "epoch": 0.046439824564181324,
      "grad_norm": 0.14793545007705688,
      "learning_rate": 9.535601754358188e-06,
      "loss": 0.0496,
      "step": 2933
    },
    {
      "epoch": 0.046455658121823395,
      "grad_norm": 0.33215534687042236,
      "learning_rate": 9.535443418781767e-06,
      "loss": 0.0745,
      "step": 2934
    },
    {
      "epoch": 0.04647149167946546,
      "grad_norm": 0.10338149964809418,
      "learning_rate": 9.535285083205346e-06,
      "loss": 0.0418,
      "step": 2935
    },
    {
      "epoch": 0.046487325237107524,
      "grad_norm": 0.14954257011413574,
      "learning_rate": 9.535126747628925e-06,
      "loss": 0.02,
      "step": 2936
    },
    {
      "epoch": 0.046503158794749595,
      "grad_norm": 0.12402965128421783,
      "learning_rate": 9.534968412052505e-06,
      "loss": 0.0241,
      "step": 2937
    },
    {
      "epoch": 0.04651899235239166,
      "grad_norm": 0.003415542421862483,
      "learning_rate": 9.534810076476084e-06,
      "loss": 0.0001,
      "step": 2938
    },
    {
      "epoch": 0.046534825910033724,
      "grad_norm": 0.13989220559597015,
      "learning_rate": 9.534651740899663e-06,
      "loss": 0.0358,
      "step": 2939
    },
    {
      "epoch": 0.046550659467675795,
      "grad_norm": 0.23171575367450714,
      "learning_rate": 9.534493405323243e-06,
      "loss": 0.2872,
      "step": 2940
    },
    {
      "epoch": 0.04656649302531786,
      "grad_norm": 0.3751122057437897,
      "learning_rate": 9.534335069746823e-06,
      "loss": 0.2149,
      "step": 2941
    },
    {
      "epoch": 0.046582326582959924,
      "grad_norm": 0.3500088155269623,
      "learning_rate": 9.534176734170402e-06,
      "loss": 0.1606,
      "step": 2942
    },
    {
      "epoch": 0.046598160140601995,
      "grad_norm": 0.18482773005962372,
      "learning_rate": 9.53401839859398e-06,
      "loss": 0.113,
      "step": 2943
    },
    {
      "epoch": 0.04661399369824406,
      "grad_norm": 0.13870736956596375,
      "learning_rate": 9.53386006301756e-06,
      "loss": 0.1465,
      "step": 2944
    },
    {
      "epoch": 0.046629827255886123,
      "grad_norm": 0.0150450449436903,
      "learning_rate": 9.533701727441139e-06,
      "loss": 0.0009,
      "step": 2945
    },
    {
      "epoch": 0.046645660813528195,
      "grad_norm": 0.25229591131210327,
      "learning_rate": 9.53354339186472e-06,
      "loss": 0.0072,
      "step": 2946
    },
    {
      "epoch": 0.04666149437117026,
      "grad_norm": 0.15094392001628876,
      "learning_rate": 9.533385056288299e-06,
      "loss": 0.0585,
      "step": 2947
    },
    {
      "epoch": 0.04667732792881232,
      "grad_norm": 0.004802952986210585,
      "learning_rate": 9.533226720711878e-06,
      "loss": 0.0002,
      "step": 2948
    },
    {
      "epoch": 0.046693161486454395,
      "grad_norm": 0.3786640465259552,
      "learning_rate": 9.533068385135457e-06,
      "loss": 0.1912,
      "step": 2949
    },
    {
      "epoch": 0.04670899504409646,
      "grad_norm": 0.5857585668563843,
      "learning_rate": 9.532910049559036e-06,
      "loss": 0.2698,
      "step": 2950
    },
    {
      "epoch": 0.04672482860173852,
      "grad_norm": 0.1440339833498001,
      "learning_rate": 9.532751713982615e-06,
      "loss": 0.0701,
      "step": 2951
    },
    {
      "epoch": 0.046740662159380594,
      "grad_norm": 0.667610764503479,
      "learning_rate": 9.532593378406196e-06,
      "loss": 0.0969,
      "step": 2952
    },
    {
      "epoch": 0.04675649571702266,
      "grad_norm": 0.26545676589012146,
      "learning_rate": 9.532435042829773e-06,
      "loss": 0.1186,
      "step": 2953
    },
    {
      "epoch": 0.04677232927466472,
      "grad_norm": 0.48856502771377563,
      "learning_rate": 9.532276707253354e-06,
      "loss": 0.7618,
      "step": 2954
    },
    {
      "epoch": 0.046788162832306794,
      "grad_norm": 0.24344301223754883,
      "learning_rate": 9.532118371676933e-06,
      "loss": 0.0783,
      "step": 2955
    },
    {
      "epoch": 0.04680399638994886,
      "grad_norm": 0.39275991916656494,
      "learning_rate": 9.531960036100512e-06,
      "loss": 0.2019,
      "step": 2956
    },
    {
      "epoch": 0.04681982994759092,
      "grad_norm": 0.006932069547474384,
      "learning_rate": 9.531801700524091e-06,
      "loss": 0.0003,
      "step": 2957
    },
    {
      "epoch": 0.046835663505232994,
      "grad_norm": 0.14562088251113892,
      "learning_rate": 9.531643364947672e-06,
      "loss": 0.0844,
      "step": 2958
    },
    {
      "epoch": 0.04685149706287506,
      "grad_norm": 0.3095614016056061,
      "learning_rate": 9.53148502937125e-06,
      "loss": 0.926,
      "step": 2959
    },
    {
      "epoch": 0.04686733062051712,
      "grad_norm": 0.23938240110874176,
      "learning_rate": 9.531326693794828e-06,
      "loss": 0.0691,
      "step": 2960
    },
    {
      "epoch": 0.046883164178159194,
      "grad_norm": 0.004648889880627394,
      "learning_rate": 9.53116835821841e-06,
      "loss": 0.0002,
      "step": 2961
    },
    {
      "epoch": 0.04689899773580126,
      "grad_norm": 0.33027127385139465,
      "learning_rate": 9.531010022641988e-06,
      "loss": 0.056,
      "step": 2962
    },
    {
      "epoch": 0.04691483129344332,
      "grad_norm": 0.1414068043231964,
      "learning_rate": 9.530851687065567e-06,
      "loss": 0.0836,
      "step": 2963
    },
    {
      "epoch": 0.046930664851085394,
      "grad_norm": 0.0017192171653732657,
      "learning_rate": 9.530693351489146e-06,
      "loss": 0.0,
      "step": 2964
    },
    {
      "epoch": 0.04694649840872746,
      "grad_norm": 0.36922934651374817,
      "learning_rate": 9.530535015912726e-06,
      "loss": 0.6773,
      "step": 2965
    },
    {
      "epoch": 0.04696233196636952,
      "grad_norm": 0.1855543851852417,
      "learning_rate": 9.530376680336305e-06,
      "loss": 0.0835,
      "step": 2966
    },
    {
      "epoch": 0.04697816552401159,
      "grad_norm": 0.15940004587173462,
      "learning_rate": 9.530218344759885e-06,
      "loss": 0.0343,
      "step": 2967
    },
    {
      "epoch": 0.04699399908165366,
      "grad_norm": 0.09820403903722763,
      "learning_rate": 9.530060009183464e-06,
      "loss": 0.0596,
      "step": 2968
    },
    {
      "epoch": 0.04700983263929572,
      "grad_norm": 0.00011831821029772982,
      "learning_rate": 9.529901673607044e-06,
      "loss": 0.0,
      "step": 2969
    },
    {
      "epoch": 0.04702566619693779,
      "grad_norm": 0.11373927444219589,
      "learning_rate": 9.529743338030623e-06,
      "loss": 0.0097,
      "step": 2970
    },
    {
      "epoch": 0.04704149975457986,
      "grad_norm": 0.41257521510124207,
      "learning_rate": 9.529585002454202e-06,
      "loss": 0.4177,
      "step": 2971
    },
    {
      "epoch": 0.04705733331222192,
      "grad_norm": 0.20744045078754425,
      "learning_rate": 9.52942666687778e-06,
      "loss": 0.2175,
      "step": 2972
    },
    {
      "epoch": 0.04707316686986399,
      "grad_norm": 0.009426558390259743,
      "learning_rate": 9.529268331301362e-06,
      "loss": 0.0005,
      "step": 2973
    },
    {
      "epoch": 0.04708900042750606,
      "grad_norm": 0.00012552764383144677,
      "learning_rate": 9.52910999572494e-06,
      "loss": 0.0,
      "step": 2974
    },
    {
      "epoch": 0.04710483398514812,
      "grad_norm": 0.2724049687385559,
      "learning_rate": 9.52895166014852e-06,
      "loss": 0.0934,
      "step": 2975
    },
    {
      "epoch": 0.04712066754279019,
      "grad_norm": 0.32039326429367065,
      "learning_rate": 9.528793324572099e-06,
      "loss": 0.0507,
      "step": 2976
    },
    {
      "epoch": 0.04713650110043226,
      "grad_norm": 0.23484408855438232,
      "learning_rate": 9.528634988995678e-06,
      "loss": 0.2754,
      "step": 2977
    },
    {
      "epoch": 0.04715233465807432,
      "grad_norm": 0.15278290212154388,
      "learning_rate": 9.528476653419257e-06,
      "loss": 0.052,
      "step": 2978
    },
    {
      "epoch": 0.04716816821571639,
      "grad_norm": 6.288666190812364e-05,
      "learning_rate": 9.528318317842838e-06,
      "loss": 0.0,
      "step": 2979
    },
    {
      "epoch": 0.04718400177335846,
      "grad_norm": 9.841596329351887e-05,
      "learning_rate": 9.528159982266417e-06,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 0.04719983533100052,
      "grad_norm": 0.027430014684796333,
      "learning_rate": 9.528001646689996e-06,
      "loss": 0.0018,
      "step": 2981
    },
    {
      "epoch": 0.04721566888864259,
      "grad_norm": 0.17630867660045624,
      "learning_rate": 9.527843311113575e-06,
      "loss": 0.1202,
      "step": 2982
    },
    {
      "epoch": 0.04723150244628466,
      "grad_norm": 0.12649022042751312,
      "learning_rate": 9.527684975537154e-06,
      "loss": 0.0517,
      "step": 2983
    },
    {
      "epoch": 0.04724733600392672,
      "grad_norm": 0.27394402027130127,
      "learning_rate": 9.527526639960733e-06,
      "loss": 0.1387,
      "step": 2984
    },
    {
      "epoch": 0.04726316956156879,
      "grad_norm": 0.1553238481283188,
      "learning_rate": 9.527368304384312e-06,
      "loss": 0.0867,
      "step": 2985
    },
    {
      "epoch": 0.047279003119210856,
      "grad_norm": 0.5013685822486877,
      "learning_rate": 9.527209968807893e-06,
      "loss": 0.0233,
      "step": 2986
    },
    {
      "epoch": 0.04729483667685292,
      "grad_norm": 0.5856660604476929,
      "learning_rate": 9.52705163323147e-06,
      "loss": 0.0881,
      "step": 2987
    },
    {
      "epoch": 0.04731067023449499,
      "grad_norm": 0.13950686156749725,
      "learning_rate": 9.526893297655051e-06,
      "loss": 0.0373,
      "step": 2988
    },
    {
      "epoch": 0.047326503792137056,
      "grad_norm": 0.8825330138206482,
      "learning_rate": 9.52673496207863e-06,
      "loss": 0.0673,
      "step": 2989
    },
    {
      "epoch": 0.04734233734977912,
      "grad_norm": 0.2205466330051422,
      "learning_rate": 9.52657662650221e-06,
      "loss": 0.3023,
      "step": 2990
    },
    {
      "epoch": 0.04735817090742119,
      "grad_norm": 0.18944290280342102,
      "learning_rate": 9.526418290925788e-06,
      "loss": 0.0669,
      "step": 2991
    },
    {
      "epoch": 0.047374004465063256,
      "grad_norm": 0.4592667818069458,
      "learning_rate": 9.52625995534937e-06,
      "loss": 0.201,
      "step": 2992
    },
    {
      "epoch": 0.04738983802270532,
      "grad_norm": 0.05426446720957756,
      "learning_rate": 9.526101619772947e-06,
      "loss": 0.0033,
      "step": 2993
    },
    {
      "epoch": 0.04740567158034739,
      "grad_norm": 0.33852216601371765,
      "learning_rate": 9.525943284196527e-06,
      "loss": 0.7632,
      "step": 2994
    },
    {
      "epoch": 0.047421505137989456,
      "grad_norm": 0.26885029673576355,
      "learning_rate": 9.525784948620106e-06,
      "loss": 0.1867,
      "step": 2995
    },
    {
      "epoch": 0.04743733869563152,
      "grad_norm": 0.16686640679836273,
      "learning_rate": 9.525626613043686e-06,
      "loss": 0.0893,
      "step": 2996
    },
    {
      "epoch": 0.04745317225327359,
      "grad_norm": 0.21296004951000214,
      "learning_rate": 9.525468277467265e-06,
      "loss": 0.0779,
      "step": 2997
    },
    {
      "epoch": 0.047469005810915656,
      "grad_norm": 0.14435815811157227,
      "learning_rate": 9.525309941890845e-06,
      "loss": 0.0961,
      "step": 2998
    },
    {
      "epoch": 0.04748483936855772,
      "grad_norm": 0.020931104198098183,
      "learning_rate": 9.525151606314423e-06,
      "loss": 0.0004,
      "step": 2999
    },
    {
      "epoch": 0.04750067292619979,
      "grad_norm": 0.00438942713662982,
      "learning_rate": 9.524993270738004e-06,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 0.047516506483841855,
      "grad_norm": 0.15655359625816345,
      "learning_rate": 9.524834935161583e-06,
      "loss": 0.1531,
      "step": 3001
    },
    {
      "epoch": 0.04753234004148392,
      "grad_norm": 0.17417491972446442,
      "learning_rate": 9.524676599585162e-06,
      "loss": 0.1587,
      "step": 3002
    },
    {
      "epoch": 0.04754817359912599,
      "grad_norm": 0.00957653857767582,
      "learning_rate": 9.52451826400874e-06,
      "loss": 0.0005,
      "step": 3003
    },
    {
      "epoch": 0.047564007156768055,
      "grad_norm": 0.6192219853401184,
      "learning_rate": 9.524359928432322e-06,
      "loss": 0.1094,
      "step": 3004
    },
    {
      "epoch": 0.04757984071441012,
      "grad_norm": 0.7117235064506531,
      "learning_rate": 9.524201592855899e-06,
      "loss": 0.286,
      "step": 3005
    },
    {
      "epoch": 0.04759567427205219,
      "grad_norm": 0.16470876336097717,
      "learning_rate": 9.52404325727948e-06,
      "loss": 0.3004,
      "step": 3006
    },
    {
      "epoch": 0.047611507829694255,
      "grad_norm": 0.006058920174837112,
      "learning_rate": 9.523884921703059e-06,
      "loss": 0.0004,
      "step": 3007
    },
    {
      "epoch": 0.04762734138733632,
      "grad_norm": 0.017077907919883728,
      "learning_rate": 9.523726586126638e-06,
      "loss": 0.0009,
      "step": 3008
    },
    {
      "epoch": 0.04764317494497839,
      "grad_norm": 0.3060593008995056,
      "learning_rate": 9.523568250550217e-06,
      "loss": 0.3381,
      "step": 3009
    },
    {
      "epoch": 0.047659008502620455,
      "grad_norm": 0.3540397584438324,
      "learning_rate": 9.523409914973796e-06,
      "loss": 0.6388,
      "step": 3010
    },
    {
      "epoch": 0.04767484206026252,
      "grad_norm": 0.4695564806461334,
      "learning_rate": 9.523251579397375e-06,
      "loss": 0.2671,
      "step": 3011
    },
    {
      "epoch": 0.04769067561790459,
      "grad_norm": 0.1366479992866516,
      "learning_rate": 9.523093243820954e-06,
      "loss": 0.2668,
      "step": 3012
    },
    {
      "epoch": 0.047706509175546655,
      "grad_norm": 0.21871718764305115,
      "learning_rate": 9.522934908244535e-06,
      "loss": 0.1895,
      "step": 3013
    },
    {
      "epoch": 0.04772234273318872,
      "grad_norm": 0.09199639409780502,
      "learning_rate": 9.522776572668114e-06,
      "loss": 0.0071,
      "step": 3014
    },
    {
      "epoch": 0.04773817629083079,
      "grad_norm": 0.3509499430656433,
      "learning_rate": 9.522618237091693e-06,
      "loss": 0.3342,
      "step": 3015
    },
    {
      "epoch": 0.047754009848472855,
      "grad_norm": 0.009369853883981705,
      "learning_rate": 9.522459901515272e-06,
      "loss": 0.0006,
      "step": 3016
    },
    {
      "epoch": 0.04776984340611492,
      "grad_norm": 0.0007735745166428387,
      "learning_rate": 9.522301565938851e-06,
      "loss": 0.0,
      "step": 3017
    },
    {
      "epoch": 0.04778567696375698,
      "grad_norm": 0.5139538049697876,
      "learning_rate": 9.52214323036243e-06,
      "loss": 0.1342,
      "step": 3018
    },
    {
      "epoch": 0.047801510521399054,
      "grad_norm": 0.18893016874790192,
      "learning_rate": 9.521984894786011e-06,
      "loss": 0.1776,
      "step": 3019
    },
    {
      "epoch": 0.04781734407904112,
      "grad_norm": 0.5351142287254333,
      "learning_rate": 9.521826559209588e-06,
      "loss": 0.1339,
      "step": 3020
    },
    {
      "epoch": 0.04783317763668318,
      "grad_norm": 0.20356152951717377,
      "learning_rate": 9.52166822363317e-06,
      "loss": 0.2164,
      "step": 3021
    },
    {
      "epoch": 0.047849011194325254,
      "grad_norm": 0.3547482490539551,
      "learning_rate": 9.521509888056748e-06,
      "loss": 0.0823,
      "step": 3022
    },
    {
      "epoch": 0.04786484475196732,
      "grad_norm": 0.014579687267541885,
      "learning_rate": 9.521351552480327e-06,
      "loss": 0.0009,
      "step": 3023
    },
    {
      "epoch": 0.04788067830960938,
      "grad_norm": 0.15092267096042633,
      "learning_rate": 9.521193216903907e-06,
      "loss": 0.0491,
      "step": 3024
    },
    {
      "epoch": 0.047896511867251454,
      "grad_norm": 0.18958427011966705,
      "learning_rate": 9.521034881327487e-06,
      "loss": 0.1472,
      "step": 3025
    },
    {
      "epoch": 0.04791234542489352,
      "grad_norm": 0.24437780678272247,
      "learning_rate": 9.520876545751065e-06,
      "loss": 0.1053,
      "step": 3026
    },
    {
      "epoch": 0.04792817898253558,
      "grad_norm": 0.24023526906967163,
      "learning_rate": 9.520718210174645e-06,
      "loss": 0.0426,
      "step": 3027
    },
    {
      "epoch": 0.047944012540177654,
      "grad_norm": 0.39186909794807434,
      "learning_rate": 9.520559874598225e-06,
      "loss": 0.2439,
      "step": 3028
    },
    {
      "epoch": 0.04795984609781972,
      "grad_norm": 0.01677163876593113,
      "learning_rate": 9.520401539021804e-06,
      "loss": 0.001,
      "step": 3029
    },
    {
      "epoch": 0.04797567965546178,
      "grad_norm": 0.08677788078784943,
      "learning_rate": 9.520243203445383e-06,
      "loss": 0.0148,
      "step": 3030
    },
    {
      "epoch": 0.047991513213103854,
      "grad_norm": 0.00024571697576902807,
      "learning_rate": 9.520084867868963e-06,
      "loss": 0.0,
      "step": 3031
    },
    {
      "epoch": 0.04800734677074592,
      "grad_norm": 0.2673178017139435,
      "learning_rate": 9.51992653229254e-06,
      "loss": 0.2176,
      "step": 3032
    },
    {
      "epoch": 0.04802318032838798,
      "grad_norm": 0.054302748292684555,
      "learning_rate": 9.51976819671612e-06,
      "loss": 0.0104,
      "step": 3033
    },
    {
      "epoch": 0.04803901388603005,
      "grad_norm": 0.2891137897968292,
      "learning_rate": 9.5196098611397e-06,
      "loss": 0.0738,
      "step": 3034
    },
    {
      "epoch": 0.04805484744367212,
      "grad_norm": 0.2213631421327591,
      "learning_rate": 9.51945152556328e-06,
      "loss": 0.2247,
      "step": 3035
    },
    {
      "epoch": 0.04807068100131418,
      "grad_norm": 0.31717589497566223,
      "learning_rate": 9.519293189986859e-06,
      "loss": 0.5111,
      "step": 3036
    },
    {
      "epoch": 0.04808651455895625,
      "grad_norm": 0.16830319166183472,
      "learning_rate": 9.519134854410438e-06,
      "loss": 0.0517,
      "step": 3037
    },
    {
      "epoch": 0.04810234811659832,
      "grad_norm": 0.6102517247200012,
      "learning_rate": 9.518976518834017e-06,
      "loss": 0.0482,
      "step": 3038
    },
    {
      "epoch": 0.04811818167424038,
      "grad_norm": 0.5605877041816711,
      "learning_rate": 9.518818183257596e-06,
      "loss": 1.1991,
      "step": 3039
    },
    {
      "epoch": 0.04813401523188245,
      "grad_norm": 0.2634751498699188,
      "learning_rate": 9.518659847681177e-06,
      "loss": 0.1556,
      "step": 3040
    },
    {
      "epoch": 0.04814984878952452,
      "grad_norm": 0.35085123777389526,
      "learning_rate": 9.518501512104756e-06,
      "loss": 0.2185,
      "step": 3041
    },
    {
      "epoch": 0.04816568234716658,
      "grad_norm": 2.489079713821411,
      "learning_rate": 9.518343176528335e-06,
      "loss": 0.4154,
      "step": 3042
    },
    {
      "epoch": 0.04818151590480865,
      "grad_norm": 0.00013609087909571826,
      "learning_rate": 9.518184840951914e-06,
      "loss": 0.0,
      "step": 3043
    },
    {
      "epoch": 0.04819734946245072,
      "grad_norm": 0.0009821598650887609,
      "learning_rate": 9.518026505375493e-06,
      "loss": 0.0,
      "step": 3044
    },
    {
      "epoch": 0.04821318302009278,
      "grad_norm": 0.27016809582710266,
      "learning_rate": 9.517868169799072e-06,
      "loss": 0.3205,
      "step": 3045
    },
    {
      "epoch": 0.04822901657773485,
      "grad_norm": 0.17560413479804993,
      "learning_rate": 9.517709834222653e-06,
      "loss": 0.2588,
      "step": 3046
    },
    {
      "epoch": 0.04824485013537692,
      "grad_norm": 0.005084407515823841,
      "learning_rate": 9.517551498646232e-06,
      "loss": 0.0001,
      "step": 3047
    },
    {
      "epoch": 0.04826068369301898,
      "grad_norm": 0.40671399235725403,
      "learning_rate": 9.517393163069811e-06,
      "loss": 0.2111,
      "step": 3048
    },
    {
      "epoch": 0.04827651725066105,
      "grad_norm": 0.16557271778583527,
      "learning_rate": 9.51723482749339e-06,
      "loss": 0.1425,
      "step": 3049
    },
    {
      "epoch": 0.04829235080830312,
      "grad_norm": 0.30220121145248413,
      "learning_rate": 9.51707649191697e-06,
      "loss": 0.0754,
      "step": 3050
    },
    {
      "epoch": 0.04830818436594518,
      "grad_norm": 0.21651707589626312,
      "learning_rate": 9.516918156340548e-06,
      "loss": 0.1654,
      "step": 3051
    },
    {
      "epoch": 0.04832401792358725,
      "grad_norm": 0.3105863630771637,
      "learning_rate": 9.51675982076413e-06,
      "loss": 0.0603,
      "step": 3052
    },
    {
      "epoch": 0.048339851481229316,
      "grad_norm": 0.29064568877220154,
      "learning_rate": 9.516601485187708e-06,
      "loss": 0.4784,
      "step": 3053
    },
    {
      "epoch": 0.04835568503887138,
      "grad_norm": 0.429712176322937,
      "learning_rate": 9.516443149611287e-06,
      "loss": 0.0889,
      "step": 3054
    },
    {
      "epoch": 0.04837151859651345,
      "grad_norm": 0.01725633069872856,
      "learning_rate": 9.516284814034866e-06,
      "loss": 0.0011,
      "step": 3055
    },
    {
      "epoch": 0.048387352154155516,
      "grad_norm": 0.8054636716842651,
      "learning_rate": 9.516126478458446e-06,
      "loss": 0.0286,
      "step": 3056
    },
    {
      "epoch": 0.04840318571179758,
      "grad_norm": 0.19340498745441437,
      "learning_rate": 9.515968142882025e-06,
      "loss": 0.5325,
      "step": 3057
    },
    {
      "epoch": 0.04841901926943965,
      "grad_norm": 0.012696245685219765,
      "learning_rate": 9.515809807305604e-06,
      "loss": 0.0007,
      "step": 3058
    },
    {
      "epoch": 0.048434852827081716,
      "grad_norm": 0.24621529877185822,
      "learning_rate": 9.515651471729184e-06,
      "loss": 0.0835,
      "step": 3059
    },
    {
      "epoch": 0.04845068638472378,
      "grad_norm": 0.4519304037094116,
      "learning_rate": 9.515493136152762e-06,
      "loss": 0.4467,
      "step": 3060
    },
    {
      "epoch": 0.04846651994236585,
      "grad_norm": 0.15251849591732025,
      "learning_rate": 9.515334800576343e-06,
      "loss": 0.0642,
      "step": 3061
    },
    {
      "epoch": 0.048482353500007916,
      "grad_norm": 0.1147250160574913,
      "learning_rate": 9.515176464999922e-06,
      "loss": 0.0085,
      "step": 3062
    },
    {
      "epoch": 0.04849818705764998,
      "grad_norm": 0.18574340641498566,
      "learning_rate": 9.5150181294235e-06,
      "loss": 0.0163,
      "step": 3063
    },
    {
      "epoch": 0.04851402061529205,
      "grad_norm": 0.5519943237304688,
      "learning_rate": 9.51485979384708e-06,
      "loss": 0.177,
      "step": 3064
    },
    {
      "epoch": 0.048529854172934116,
      "grad_norm": 0.40269792079925537,
      "learning_rate": 9.51470145827066e-06,
      "loss": 0.8536,
      "step": 3065
    },
    {
      "epoch": 0.04854568773057618,
      "grad_norm": 0.0003562290803529322,
      "learning_rate": 9.514543122694238e-06,
      "loss": 0.0,
      "step": 3066
    },
    {
      "epoch": 0.04856152128821825,
      "grad_norm": 0.35050928592681885,
      "learning_rate": 9.514384787117819e-06,
      "loss": 0.0154,
      "step": 3067
    },
    {
      "epoch": 0.048577354845860315,
      "grad_norm": 0.007627183571457863,
      "learning_rate": 9.514226451541398e-06,
      "loss": 0.0001,
      "step": 3068
    },
    {
      "epoch": 0.04859318840350238,
      "grad_norm": 0.01563931629061699,
      "learning_rate": 9.514068115964977e-06,
      "loss": 0.001,
      "step": 3069
    },
    {
      "epoch": 0.04860902196114445,
      "grad_norm": 0.19623027741909027,
      "learning_rate": 9.513909780388556e-06,
      "loss": 0.1816,
      "step": 3070
    },
    {
      "epoch": 0.048624855518786515,
      "grad_norm": 0.31195276975631714,
      "learning_rate": 9.513751444812137e-06,
      "loss": 0.4242,
      "step": 3071
    },
    {
      "epoch": 0.04864068907642858,
      "grad_norm": 0.15905223786830902,
      "learning_rate": 9.513593109235714e-06,
      "loss": 0.1395,
      "step": 3072
    },
    {
      "epoch": 0.04865652263407065,
      "grad_norm": 0.18144182860851288,
      "learning_rate": 9.513434773659295e-06,
      "loss": 0.2829,
      "step": 3073
    },
    {
      "epoch": 0.048672356191712715,
      "grad_norm": 0.18852011859416962,
      "learning_rate": 9.513276438082874e-06,
      "loss": 0.0393,
      "step": 3074
    },
    {
      "epoch": 0.04868818974935478,
      "grad_norm": 2.8812315464019775,
      "learning_rate": 9.513118102506453e-06,
      "loss": 0.0765,
      "step": 3075
    },
    {
      "epoch": 0.04870402330699685,
      "grad_norm": 0.38564348220825195,
      "learning_rate": 9.512959766930032e-06,
      "loss": 0.2823,
      "step": 3076
    },
    {
      "epoch": 0.048719856864638915,
      "grad_norm": 0.017638789489865303,
      "learning_rate": 9.512801431353611e-06,
      "loss": 0.0011,
      "step": 3077
    },
    {
      "epoch": 0.04873569042228098,
      "grad_norm": 1.2130943536758423,
      "learning_rate": 9.51264309577719e-06,
      "loss": 0.1521,
      "step": 3078
    },
    {
      "epoch": 0.04875152397992305,
      "grad_norm": 0.27756401896476746,
      "learning_rate": 9.512484760200771e-06,
      "loss": 0.0856,
      "step": 3079
    },
    {
      "epoch": 0.048767357537565115,
      "grad_norm": 0.17712973058223724,
      "learning_rate": 9.51232642462435e-06,
      "loss": 0.0326,
      "step": 3080
    },
    {
      "epoch": 0.04878319109520718,
      "grad_norm": 0.16688109934329987,
      "learning_rate": 9.512168089047928e-06,
      "loss": 0.174,
      "step": 3081
    },
    {
      "epoch": 0.04879902465284925,
      "grad_norm": 0.003023938275873661,
      "learning_rate": 9.512009753471508e-06,
      "loss": 0.0002,
      "step": 3082
    },
    {
      "epoch": 0.048814858210491315,
      "grad_norm": 0.3611888587474823,
      "learning_rate": 9.511851417895087e-06,
      "loss": 0.8079,
      "step": 3083
    },
    {
      "epoch": 0.04883069176813338,
      "grad_norm": 0.03097635880112648,
      "learning_rate": 9.511693082318667e-06,
      "loss": 0.0014,
      "step": 3084
    },
    {
      "epoch": 0.04884652532577545,
      "grad_norm": 0.17254841327667236,
      "learning_rate": 9.511534746742246e-06,
      "loss": 0.0727,
      "step": 3085
    },
    {
      "epoch": 0.048862358883417514,
      "grad_norm": 0.25931838154792786,
      "learning_rate": 9.511376411165826e-06,
      "loss": 0.0461,
      "step": 3086
    },
    {
      "epoch": 0.04887819244105958,
      "grad_norm": 0.23637232184410095,
      "learning_rate": 9.511218075589404e-06,
      "loss": 0.1358,
      "step": 3087
    },
    {
      "epoch": 0.04889402599870165,
      "grad_norm": 0.3239976763725281,
      "learning_rate": 9.511059740012985e-06,
      "loss": 0.4726,
      "step": 3088
    },
    {
      "epoch": 0.048909859556343714,
      "grad_norm": 0.14179566502571106,
      "learning_rate": 9.510901404436564e-06,
      "loss": 0.0341,
      "step": 3089
    },
    {
      "epoch": 0.04892569311398578,
      "grad_norm": 0.008997559547424316,
      "learning_rate": 9.510743068860143e-06,
      "loss": 0.0006,
      "step": 3090
    },
    {
      "epoch": 0.04894152667162785,
      "grad_norm": 1.2827317714691162,
      "learning_rate": 9.510584733283722e-06,
      "loss": 0.0835,
      "step": 3091
    },
    {
      "epoch": 0.048957360229269914,
      "grad_norm": 0.599227249622345,
      "learning_rate": 9.510426397707303e-06,
      "loss": 0.882,
      "step": 3092
    },
    {
      "epoch": 0.04897319378691198,
      "grad_norm": 0.4008488059043884,
      "learning_rate": 9.51026806213088e-06,
      "loss": 0.2462,
      "step": 3093
    },
    {
      "epoch": 0.04898902734455405,
      "grad_norm": 0.22888706624507904,
      "learning_rate": 9.51010972655446e-06,
      "loss": 0.2774,
      "step": 3094
    },
    {
      "epoch": 0.049004860902196114,
      "grad_norm": 4.087978231837042e-05,
      "learning_rate": 9.50995139097804e-06,
      "loss": 0.0,
      "step": 3095
    },
    {
      "epoch": 0.04902069445983818,
      "grad_norm": 0.49720266461372375,
      "learning_rate": 9.509793055401619e-06,
      "loss": 0.1131,
      "step": 3096
    },
    {
      "epoch": 0.04903652801748025,
      "grad_norm": 0.19110488891601562,
      "learning_rate": 9.509634719825198e-06,
      "loss": 0.0633,
      "step": 3097
    },
    {
      "epoch": 0.049052361575122314,
      "grad_norm": 0.3347189426422119,
      "learning_rate": 9.509476384248779e-06,
      "loss": 0.0269,
      "step": 3098
    },
    {
      "epoch": 0.04906819513276438,
      "grad_norm": 0.0172402523458004,
      "learning_rate": 9.509318048672356e-06,
      "loss": 0.0014,
      "step": 3099
    },
    {
      "epoch": 0.04908402869040645,
      "grad_norm": 0.3985386788845062,
      "learning_rate": 9.509159713095937e-06,
      "loss": 0.1819,
      "step": 3100
    },
    {
      "epoch": 0.04909986224804851,
      "grad_norm": 0.17875488102436066,
      "learning_rate": 9.509001377519516e-06,
      "loss": 0.6281,
      "step": 3101
    },
    {
      "epoch": 0.04911569580569058,
      "grad_norm": 0.01182536594569683,
      "learning_rate": 9.508843041943095e-06,
      "loss": 0.0006,
      "step": 3102
    },
    {
      "epoch": 0.04913152936333265,
      "grad_norm": 0.32133838534355164,
      "learning_rate": 9.508684706366674e-06,
      "loss": 0.3929,
      "step": 3103
    },
    {
      "epoch": 0.04914736292097471,
      "grad_norm": 0.0003403589071240276,
      "learning_rate": 9.508526370790253e-06,
      "loss": 0.0,
      "step": 3104
    },
    {
      "epoch": 0.04916319647861678,
      "grad_norm": 0.5406513810157776,
      "learning_rate": 9.508368035213832e-06,
      "loss": 0.671,
      "step": 3105
    },
    {
      "epoch": 0.04917903003625885,
      "grad_norm": 0.18342208862304688,
      "learning_rate": 9.508209699637411e-06,
      "loss": 0.1373,
      "step": 3106
    },
    {
      "epoch": 0.04919486359390091,
      "grad_norm": 0.07264930009841919,
      "learning_rate": 9.508051364060992e-06,
      "loss": 0.0041,
      "step": 3107
    },
    {
      "epoch": 0.04921069715154298,
      "grad_norm": 0.16129134595394135,
      "learning_rate": 9.507893028484571e-06,
      "loss": 0.0554,
      "step": 3108
    },
    {
      "epoch": 0.04922653070918505,
      "grad_norm": 0.21690800786018372,
      "learning_rate": 9.50773469290815e-06,
      "loss": 0.2795,
      "step": 3109
    },
    {
      "epoch": 0.04924236426682711,
      "grad_norm": 0.17201276123523712,
      "learning_rate": 9.50757635733173e-06,
      "loss": 0.1221,
      "step": 3110
    },
    {
      "epoch": 0.04925819782446918,
      "grad_norm": 0.00011049624299630523,
      "learning_rate": 9.507418021755308e-06,
      "loss": 0.0,
      "step": 3111
    },
    {
      "epoch": 0.04927403138211125,
      "grad_norm": 0.6616012454032898,
      "learning_rate": 9.507259686178888e-06,
      "loss": 0.1609,
      "step": 3112
    },
    {
      "epoch": 0.04928986493975331,
      "grad_norm": 0.3361899256706238,
      "learning_rate": 9.507101350602468e-06,
      "loss": 0.2204,
      "step": 3113
    },
    {
      "epoch": 0.04930569849739538,
      "grad_norm": 0.41792407631874084,
      "learning_rate": 9.506943015026047e-06,
      "loss": 0.8278,
      "step": 3114
    },
    {
      "epoch": 0.04932153205503745,
      "grad_norm": 0.0012434679083526134,
      "learning_rate": 9.506784679449626e-06,
      "loss": 0.0,
      "step": 3115
    },
    {
      "epoch": 0.04933736561267951,
      "grad_norm": 0.2357766330242157,
      "learning_rate": 9.506626343873206e-06,
      "loss": 0.3025,
      "step": 3116
    },
    {
      "epoch": 0.04935319917032158,
      "grad_norm": 0.1893119513988495,
      "learning_rate": 9.506468008296785e-06,
      "loss": 0.1055,
      "step": 3117
    },
    {
      "epoch": 0.04936903272796365,
      "grad_norm": 0.32703638076782227,
      "learning_rate": 9.506309672720364e-06,
      "loss": 0.2694,
      "step": 3118
    },
    {
      "epoch": 0.04938486628560571,
      "grad_norm": 0.00014658864529337734,
      "learning_rate": 9.506151337143944e-06,
      "loss": 0.0,
      "step": 3119
    },
    {
      "epoch": 0.049400699843247776,
      "grad_norm": 0.00022479734616354108,
      "learning_rate": 9.505993001567524e-06,
      "loss": 0.0,
      "step": 3120
    },
    {
      "epoch": 0.04941653340088985,
      "grad_norm": 0.2985672056674957,
      "learning_rate": 9.505834665991103e-06,
      "loss": 0.5898,
      "step": 3121
    },
    {
      "epoch": 0.04943236695853191,
      "grad_norm": 0.0042205858044326305,
      "learning_rate": 9.505676330414682e-06,
      "loss": 0.0002,
      "step": 3122
    },
    {
      "epoch": 0.049448200516173976,
      "grad_norm": 0.14628678560256958,
      "learning_rate": 9.50551799483826e-06,
      "loss": 0.1478,
      "step": 3123
    },
    {
      "epoch": 0.04946403407381605,
      "grad_norm": 0.1705237179994583,
      "learning_rate": 9.50535965926184e-06,
      "loss": 0.0824,
      "step": 3124
    },
    {
      "epoch": 0.04947986763145811,
      "grad_norm": 0.45032426714897156,
      "learning_rate": 9.50520132368542e-06,
      "loss": 0.6356,
      "step": 3125
    },
    {
      "epoch": 0.049495701189100176,
      "grad_norm": 0.5642430782318115,
      "learning_rate": 9.505042988109e-06,
      "loss": 0.8568,
      "step": 3126
    },
    {
      "epoch": 0.04951153474674225,
      "grad_norm": 0.001285082777030766,
      "learning_rate": 9.504884652532579e-06,
      "loss": 0.0001,
      "step": 3127
    },
    {
      "epoch": 0.04952736830438431,
      "grad_norm": 0.04289797320961952,
      "learning_rate": 9.504726316956158e-06,
      "loss": 0.0013,
      "step": 3128
    },
    {
      "epoch": 0.049543201862026376,
      "grad_norm": 0.27141010761260986,
      "learning_rate": 9.504567981379737e-06,
      "loss": 0.2042,
      "step": 3129
    },
    {
      "epoch": 0.04955903541966845,
      "grad_norm": 0.1592726707458496,
      "learning_rate": 9.504409645803316e-06,
      "loss": 0.0349,
      "step": 3130
    },
    {
      "epoch": 0.04957486897731051,
      "grad_norm": 0.24662859737873077,
      "learning_rate": 9.504251310226895e-06,
      "loss": 0.0978,
      "step": 3131
    },
    {
      "epoch": 0.049590702534952576,
      "grad_norm": 0.23249000310897827,
      "learning_rate": 9.504092974650476e-06,
      "loss": 0.1661,
      "step": 3132
    },
    {
      "epoch": 0.04960653609259465,
      "grad_norm": 0.4314413070678711,
      "learning_rate": 9.503934639074053e-06,
      "loss": 0.1287,
      "step": 3133
    },
    {
      "epoch": 0.04962236965023671,
      "grad_norm": 0.1982213705778122,
      "learning_rate": 9.503776303497634e-06,
      "loss": 0.0977,
      "step": 3134
    },
    {
      "epoch": 0.049638203207878775,
      "grad_norm": 0.8761141896247864,
      "learning_rate": 9.503617967921213e-06,
      "loss": 0.0864,
      "step": 3135
    },
    {
      "epoch": 0.04965403676552085,
      "grad_norm": 0.3607306480407715,
      "learning_rate": 9.503459632344792e-06,
      "loss": 0.0092,
      "step": 3136
    },
    {
      "epoch": 0.04966987032316291,
      "grad_norm": 0.005314398091286421,
      "learning_rate": 9.503301296768371e-06,
      "loss": 0.0004,
      "step": 3137
    },
    {
      "epoch": 0.049685703880804975,
      "grad_norm": 0.000124476951896213,
      "learning_rate": 9.503142961191952e-06,
      "loss": 0.0,
      "step": 3138
    },
    {
      "epoch": 0.049701537438447047,
      "grad_norm": 0.21151581406593323,
      "learning_rate": 9.50298462561553e-06,
      "loss": 0.0318,
      "step": 3139
    },
    {
      "epoch": 0.04971737099608911,
      "grad_norm": 0.007749043870717287,
      "learning_rate": 9.50282629003911e-06,
      "loss": 0.0005,
      "step": 3140
    },
    {
      "epoch": 0.049733204553731175,
      "grad_norm": 0.3778652846813202,
      "learning_rate": 9.50266795446269e-06,
      "loss": 0.0911,
      "step": 3141
    },
    {
      "epoch": 0.049749038111373246,
      "grad_norm": 0.018177952617406845,
      "learning_rate": 9.502509618886268e-06,
      "loss": 0.0008,
      "step": 3142
    },
    {
      "epoch": 0.04976487166901531,
      "grad_norm": 0.6644328832626343,
      "learning_rate": 9.502351283309847e-06,
      "loss": 0.0535,
      "step": 3143
    },
    {
      "epoch": 0.049780705226657375,
      "grad_norm": 0.11555428802967072,
      "learning_rate": 9.502192947733427e-06,
      "loss": 0.0623,
      "step": 3144
    },
    {
      "epoch": 0.049796538784299446,
      "grad_norm": 0.8996164202690125,
      "learning_rate": 9.502034612157006e-06,
      "loss": 0.0461,
      "step": 3145
    },
    {
      "epoch": 0.04981237234194151,
      "grad_norm": 0.01570410095155239,
      "learning_rate": 9.501876276580586e-06,
      "loss": 0.0008,
      "step": 3146
    },
    {
      "epoch": 0.049828205899583575,
      "grad_norm": 0.1906139999628067,
      "learning_rate": 9.501717941004165e-06,
      "loss": 0.0555,
      "step": 3147
    },
    {
      "epoch": 0.049844039457225646,
      "grad_norm": 0.40936583280563354,
      "learning_rate": 9.501559605427745e-06,
      "loss": 0.1022,
      "step": 3148
    },
    {
      "epoch": 0.04985987301486771,
      "grad_norm": 0.34155699610710144,
      "learning_rate": 9.501401269851324e-06,
      "loss": 0.0645,
      "step": 3149
    },
    {
      "epoch": 0.049875706572509775,
      "grad_norm": 0.1477288454771042,
      "learning_rate": 9.501242934274903e-06,
      "loss": 0.0674,
      "step": 3150
    },
    {
      "epoch": 0.049891540130151846,
      "grad_norm": 0.29863715171813965,
      "learning_rate": 9.501084598698482e-06,
      "loss": 0.192,
      "step": 3151
    },
    {
      "epoch": 0.04990737368779391,
      "grad_norm": 0.00014568700862582773,
      "learning_rate": 9.500926263122061e-06,
      "loss": 0.0,
      "step": 3152
    },
    {
      "epoch": 0.049923207245435974,
      "grad_norm": 0.35376450419425964,
      "learning_rate": 9.500767927545642e-06,
      "loss": 0.4615,
      "step": 3153
    },
    {
      "epoch": 0.049939040803078046,
      "grad_norm": 0.3966400623321533,
      "learning_rate": 9.500609591969219e-06,
      "loss": 0.3249,
      "step": 3154
    },
    {
      "epoch": 0.04995487436072011,
      "grad_norm": 0.17900626361370087,
      "learning_rate": 9.5004512563928e-06,
      "loss": 0.2077,
      "step": 3155
    },
    {
      "epoch": 0.049970707918362174,
      "grad_norm": 0.025558574125170708,
      "learning_rate": 9.500292920816379e-06,
      "loss": 0.0015,
      "step": 3156
    },
    {
      "epoch": 0.049986541476004245,
      "grad_norm": 0.2722357213497162,
      "learning_rate": 9.500134585239958e-06,
      "loss": 0.0067,
      "step": 3157
    },
    {
      "epoch": 0.05000237503364631,
      "grad_norm": 0.5014975070953369,
      "learning_rate": 9.499976249663537e-06,
      "loss": 0.1813,
      "step": 3158
    },
    {
      "epoch": 0.050018208591288374,
      "grad_norm": 0.23461908102035522,
      "learning_rate": 9.499817914087118e-06,
      "loss": 0.2661,
      "step": 3159
    },
    {
      "epoch": 0.050034042148930445,
      "grad_norm": 0.0014731594128534198,
      "learning_rate": 9.499659578510695e-06,
      "loss": 0.0001,
      "step": 3160
    },
    {
      "epoch": 0.05004987570657251,
      "grad_norm": 0.2463424950838089,
      "learning_rate": 9.499501242934276e-06,
      "loss": 0.1582,
      "step": 3161
    },
    {
      "epoch": 0.050065709264214574,
      "grad_norm": 0.01805185154080391,
      "learning_rate": 9.499342907357855e-06,
      "loss": 0.0018,
      "step": 3162
    },
    {
      "epoch": 0.050081542821856645,
      "grad_norm": 0.12910188734531403,
      "learning_rate": 9.499184571781434e-06,
      "loss": 0.0311,
      "step": 3163
    },
    {
      "epoch": 0.05009737637949871,
      "grad_norm": 0.2298203557729721,
      "learning_rate": 9.499026236205013e-06,
      "loss": 0.0602,
      "step": 3164
    },
    {
      "epoch": 0.050113209937140774,
      "grad_norm": 0.25986170768737793,
      "learning_rate": 9.498867900628594e-06,
      "loss": 0.1462,
      "step": 3165
    },
    {
      "epoch": 0.050129043494782845,
      "grad_norm": 0.4068487286567688,
      "learning_rate": 9.498709565052171e-06,
      "loss": 0.0311,
      "step": 3166
    },
    {
      "epoch": 0.05014487705242491,
      "grad_norm": 0.25559723377227783,
      "learning_rate": 9.498551229475752e-06,
      "loss": 0.081,
      "step": 3167
    },
    {
      "epoch": 0.05016071061006697,
      "grad_norm": 0.4136394262313843,
      "learning_rate": 9.498392893899331e-06,
      "loss": 0.0832,
      "step": 3168
    },
    {
      "epoch": 0.050176544167709045,
      "grad_norm": 0.026620915159583092,
      "learning_rate": 9.49823455832291e-06,
      "loss": 0.0015,
      "step": 3169
    },
    {
      "epoch": 0.05019237772535111,
      "grad_norm": 5.7206591009162366e-05,
      "learning_rate": 9.49807622274649e-06,
      "loss": 0.0,
      "step": 3170
    },
    {
      "epoch": 0.05020821128299317,
      "grad_norm": 0.13230104744434357,
      "learning_rate": 9.49791788717007e-06,
      "loss": 0.0804,
      "step": 3171
    },
    {
      "epoch": 0.050224044840635244,
      "grad_norm": 0.23470769822597504,
      "learning_rate": 9.497759551593648e-06,
      "loss": 0.1752,
      "step": 3172
    },
    {
      "epoch": 0.05023987839827731,
      "grad_norm": 0.24373875558376312,
      "learning_rate": 9.497601216017228e-06,
      "loss": 0.0731,
      "step": 3173
    },
    {
      "epoch": 0.05025571195591937,
      "grad_norm": 0.0020188859198242426,
      "learning_rate": 9.497442880440807e-06,
      "loss": 0.0,
      "step": 3174
    },
    {
      "epoch": 0.050271545513561444,
      "grad_norm": 0.00012940613669343293,
      "learning_rate": 9.497284544864386e-06,
      "loss": 0.0,
      "step": 3175
    },
    {
      "epoch": 0.05028737907120351,
      "grad_norm": 0.1027422696352005,
      "learning_rate": 9.497126209287966e-06,
      "loss": 0.0494,
      "step": 3176
    },
    {
      "epoch": 0.05030321262884557,
      "grad_norm": 0.12313685566186905,
      "learning_rate": 9.496967873711545e-06,
      "loss": 0.0446,
      "step": 3177
    },
    {
      "epoch": 0.050319046186487644,
      "grad_norm": 0.023552706465125084,
      "learning_rate": 9.496809538135124e-06,
      "loss": 0.0016,
      "step": 3178
    },
    {
      "epoch": 0.05033487974412971,
      "grad_norm": 0.0641687735915184,
      "learning_rate": 9.496651202558703e-06,
      "loss": 0.0126,
      "step": 3179
    },
    {
      "epoch": 0.05035071330177177,
      "grad_norm": 0.1436343938112259,
      "learning_rate": 9.496492866982284e-06,
      "loss": 0.0328,
      "step": 3180
    },
    {
      "epoch": 0.050366546859413844,
      "grad_norm": 0.2985846698284149,
      "learning_rate": 9.496334531405863e-06,
      "loss": 0.2988,
      "step": 3181
    },
    {
      "epoch": 0.05038238041705591,
      "grad_norm": 0.535045325756073,
      "learning_rate": 9.496176195829442e-06,
      "loss": 0.144,
      "step": 3182
    },
    {
      "epoch": 0.05039821397469797,
      "grad_norm": 0.1389448046684265,
      "learning_rate": 9.49601786025302e-06,
      "loss": 0.1006,
      "step": 3183
    },
    {
      "epoch": 0.050414047532340044,
      "grad_norm": 5.86368259973824e-05,
      "learning_rate": 9.4958595246766e-06,
      "loss": 0.0,
      "step": 3184
    },
    {
      "epoch": 0.05042988108998211,
      "grad_norm": 0.11142411082983017,
      "learning_rate": 9.495701189100179e-06,
      "loss": 0.0052,
      "step": 3185
    },
    {
      "epoch": 0.05044571464762417,
      "grad_norm": 0.46392932534217834,
      "learning_rate": 9.49554285352376e-06,
      "loss": 0.277,
      "step": 3186
    },
    {
      "epoch": 0.05046154820526624,
      "grad_norm": 0.2343815118074417,
      "learning_rate": 9.495384517947339e-06,
      "loss": 0.3002,
      "step": 3187
    },
    {
      "epoch": 0.05047738176290831,
      "grad_norm": 0.08454849570989609,
      "learning_rate": 9.495226182370918e-06,
      "loss": 0.0029,
      "step": 3188
    },
    {
      "epoch": 0.05049321532055037,
      "grad_norm": 0.016998864710330963,
      "learning_rate": 9.495067846794497e-06,
      "loss": 0.0012,
      "step": 3189
    },
    {
      "epoch": 0.05050904887819244,
      "grad_norm": 0.27154839038848877,
      "learning_rate": 9.494909511218076e-06,
      "loss": 0.1641,
      "step": 3190
    },
    {
      "epoch": 0.05052488243583451,
      "grad_norm": 0.20075520873069763,
      "learning_rate": 9.494751175641655e-06,
      "loss": 0.1448,
      "step": 3191
    },
    {
      "epoch": 0.05054071599347657,
      "grad_norm": 0.36153215169906616,
      "learning_rate": 9.494592840065236e-06,
      "loss": 0.0935,
      "step": 3192
    },
    {
      "epoch": 0.05055654955111864,
      "grad_norm": 0.09807723015546799,
      "learning_rate": 9.494434504488815e-06,
      "loss": 0.0021,
      "step": 3193
    },
    {
      "epoch": 0.05057238310876071,
      "grad_norm": 0.2696293294429779,
      "learning_rate": 9.494276168912394e-06,
      "loss": 0.0782,
      "step": 3194
    },
    {
      "epoch": 0.05058821666640277,
      "grad_norm": 0.23965094983577728,
      "learning_rate": 9.494117833335973e-06,
      "loss": 0.0824,
      "step": 3195
    },
    {
      "epoch": 0.05060405022404484,
      "grad_norm": 0.37784603238105774,
      "learning_rate": 9.493959497759552e-06,
      "loss": 0.5304,
      "step": 3196
    },
    {
      "epoch": 0.05061988378168691,
      "grad_norm": 0.17517715692520142,
      "learning_rate": 9.493801162183131e-06,
      "loss": 0.0653,
      "step": 3197
    },
    {
      "epoch": 0.05063571733932897,
      "grad_norm": 0.2468690574169159,
      "learning_rate": 9.493642826606712e-06,
      "loss": 0.1272,
      "step": 3198
    },
    {
      "epoch": 0.05065155089697104,
      "grad_norm": 0.212747260928154,
      "learning_rate": 9.493484491030291e-06,
      "loss": 0.0889,
      "step": 3199
    },
    {
      "epoch": 0.05066738445461311,
      "grad_norm": 0.3448713421821594,
      "learning_rate": 9.493326155453869e-06,
      "loss": 0.1461,
      "step": 3200
    },
    {
      "epoch": 0.05068321801225517,
      "grad_norm": 0.33724445104599,
      "learning_rate": 9.49316781987745e-06,
      "loss": 0.401,
      "step": 3201
    },
    {
      "epoch": 0.05069905156989724,
      "grad_norm": 0.017139939591288567,
      "learning_rate": 9.493009484301028e-06,
      "loss": 0.001,
      "step": 3202
    },
    {
      "epoch": 0.05071488512753931,
      "grad_norm": 0.2897612750530243,
      "learning_rate": 9.492851148724607e-06,
      "loss": 0.0388,
      "step": 3203
    },
    {
      "epoch": 0.05073071868518137,
      "grad_norm": 0.3534632921218872,
      "learning_rate": 9.492692813148187e-06,
      "loss": 0.5058,
      "step": 3204
    },
    {
      "epoch": 0.05074655224282344,
      "grad_norm": 0.2766265273094177,
      "learning_rate": 9.492534477571767e-06,
      "loss": 0.3708,
      "step": 3205
    },
    {
      "epoch": 0.050762385800465507,
      "grad_norm": 0.17684240639209747,
      "learning_rate": 9.492376141995345e-06,
      "loss": 0.1223,
      "step": 3206
    },
    {
      "epoch": 0.05077821935810757,
      "grad_norm": 0.013033296912908554,
      "learning_rate": 9.492217806418925e-06,
      "loss": 0.0007,
      "step": 3207
    },
    {
      "epoch": 0.05079405291574964,
      "grad_norm": 0.08839596807956696,
      "learning_rate": 9.492059470842505e-06,
      "loss": 0.0475,
      "step": 3208
    },
    {
      "epoch": 0.050809886473391706,
      "grad_norm": 0.4594787657260895,
      "learning_rate": 9.491901135266084e-06,
      "loss": 0.6174,
      "step": 3209
    },
    {
      "epoch": 0.05082572003103377,
      "grad_norm": 0.22364073991775513,
      "learning_rate": 9.491742799689663e-06,
      "loss": 0.3781,
      "step": 3210
    },
    {
      "epoch": 0.05084155358867584,
      "grad_norm": 0.30036160349845886,
      "learning_rate": 9.491584464113242e-06,
      "loss": 0.0431,
      "step": 3211
    },
    {
      "epoch": 0.050857387146317906,
      "grad_norm": 0.17598167061805725,
      "learning_rate": 9.491426128536821e-06,
      "loss": 0.0686,
      "step": 3212
    },
    {
      "epoch": 0.05087322070395997,
      "grad_norm": 0.16938979923725128,
      "learning_rate": 9.491267792960402e-06,
      "loss": 0.0157,
      "step": 3213
    },
    {
      "epoch": 0.05088905426160204,
      "grad_norm": 0.31533822417259216,
      "learning_rate": 9.49110945738398e-06,
      "loss": 0.1636,
      "step": 3214
    },
    {
      "epoch": 0.050904887819244106,
      "grad_norm": 0.04219396784901619,
      "learning_rate": 9.49095112180756e-06,
      "loss": 0.0021,
      "step": 3215
    },
    {
      "epoch": 0.05092072137688617,
      "grad_norm": 0.6602518558502197,
      "learning_rate": 9.490792786231139e-06,
      "loss": 0.1407,
      "step": 3216
    },
    {
      "epoch": 0.05093655493452824,
      "grad_norm": 9.107076766667888e-05,
      "learning_rate": 9.490634450654718e-06,
      "loss": 0.0,
      "step": 3217
    },
    {
      "epoch": 0.050952388492170306,
      "grad_norm": 0.010486979968845844,
      "learning_rate": 9.490476115078297e-06,
      "loss": 0.0003,
      "step": 3218
    },
    {
      "epoch": 0.05096822204981237,
      "grad_norm": 0.12715575098991394,
      "learning_rate": 9.490317779501878e-06,
      "loss": 0.0826,
      "step": 3219
    },
    {
      "epoch": 0.05098405560745444,
      "grad_norm": 0.4902588427066803,
      "learning_rate": 9.490159443925457e-06,
      "loss": 0.1181,
      "step": 3220
    },
    {
      "epoch": 0.050999889165096506,
      "grad_norm": 5.550810813903809,
      "learning_rate": 9.490001108349036e-06,
      "loss": 0.5798,
      "step": 3221
    },
    {
      "epoch": 0.05101572272273857,
      "grad_norm": 0.21930167078971863,
      "learning_rate": 9.489842772772615e-06,
      "loss": 0.2395,
      "step": 3222
    },
    {
      "epoch": 0.05103155628038064,
      "grad_norm": 0.13967977464199066,
      "learning_rate": 9.489684437196194e-06,
      "loss": 0.1125,
      "step": 3223
    },
    {
      "epoch": 0.051047389838022705,
      "grad_norm": 0.4463514983654022,
      "learning_rate": 9.489526101619773e-06,
      "loss": 0.5132,
      "step": 3224
    },
    {
      "epoch": 0.05106322339566477,
      "grad_norm": 0.3006434142589569,
      "learning_rate": 9.489367766043352e-06,
      "loss": 0.3043,
      "step": 3225
    },
    {
      "epoch": 0.05107905695330684,
      "grad_norm": 0.18020592629909515,
      "learning_rate": 9.489209430466933e-06,
      "loss": 0.0736,
      "step": 3226
    },
    {
      "epoch": 0.051094890510948905,
      "grad_norm": 0.01700383424758911,
      "learning_rate": 9.48905109489051e-06,
      "loss": 0.001,
      "step": 3227
    },
    {
      "epoch": 0.05111072406859097,
      "grad_norm": 0.2986529469490051,
      "learning_rate": 9.488892759314091e-06,
      "loss": 0.1446,
      "step": 3228
    },
    {
      "epoch": 0.05112655762623304,
      "grad_norm": 0.21353980898857117,
      "learning_rate": 9.48873442373767e-06,
      "loss": 0.5168,
      "step": 3229
    },
    {
      "epoch": 0.051142391183875105,
      "grad_norm": 5.1416598580544814e-05,
      "learning_rate": 9.48857608816125e-06,
      "loss": 0.0,
      "step": 3230
    },
    {
      "epoch": 0.05115822474151717,
      "grad_norm": 0.24821338057518005,
      "learning_rate": 9.488417752584828e-06,
      "loss": 0.1479,
      "step": 3231
    },
    {
      "epoch": 0.05117405829915924,
      "grad_norm": 0.040125250816345215,
      "learning_rate": 9.48825941700841e-06,
      "loss": 0.0122,
      "step": 3232
    },
    {
      "epoch": 0.051189891856801305,
      "grad_norm": 0.11875433474779129,
      "learning_rate": 9.488101081431987e-06,
      "loss": 0.0907,
      "step": 3233
    },
    {
      "epoch": 0.05120572541444337,
      "grad_norm": 0.10766758024692535,
      "learning_rate": 9.487942745855567e-06,
      "loss": 0.0084,
      "step": 3234
    },
    {
      "epoch": 0.05122155897208544,
      "grad_norm": 0.00023973402858246118,
      "learning_rate": 9.487784410279147e-06,
      "loss": 0.0,
      "step": 3235
    },
    {
      "epoch": 0.051237392529727505,
      "grad_norm": 0.24132026731967926,
      "learning_rate": 9.487626074702726e-06,
      "loss": 0.3363,
      "step": 3236
    },
    {
      "epoch": 0.05125322608736957,
      "grad_norm": 0.04989249259233475,
      "learning_rate": 9.487467739126305e-06,
      "loss": 0.0028,
      "step": 3237
    },
    {
      "epoch": 0.05126905964501164,
      "grad_norm": 0.30694642663002014,
      "learning_rate": 9.487309403549885e-06,
      "loss": 0.1996,
      "step": 3238
    },
    {
      "epoch": 0.051284893202653704,
      "grad_norm": 0.26589930057525635,
      "learning_rate": 9.487151067973463e-06,
      "loss": 0.2891,
      "step": 3239
    },
    {
      "epoch": 0.05130072676029577,
      "grad_norm": 0.18999530375003815,
      "learning_rate": 9.486992732397044e-06,
      "loss": 0.0931,
      "step": 3240
    },
    {
      "epoch": 0.05131656031793784,
      "grad_norm": 0.00016092939767986536,
      "learning_rate": 9.486834396820623e-06,
      "loss": 0.0,
      "step": 3241
    },
    {
      "epoch": 0.051332393875579904,
      "grad_norm": 0.25138482451438904,
      "learning_rate": 9.486676061244202e-06,
      "loss": 0.0353,
      "step": 3242
    },
    {
      "epoch": 0.05134822743322197,
      "grad_norm": 0.4328591525554657,
      "learning_rate": 9.48651772566778e-06,
      "loss": 0.2976,
      "step": 3243
    },
    {
      "epoch": 0.05136406099086404,
      "grad_norm": 0.288782000541687,
      "learning_rate": 9.486359390091362e-06,
      "loss": 0.6915,
      "step": 3244
    },
    {
      "epoch": 0.051379894548506104,
      "grad_norm": 7.006011583143845e-05,
      "learning_rate": 9.486201054514939e-06,
      "loss": 0.0,
      "step": 3245
    },
    {
      "epoch": 0.05139572810614817,
      "grad_norm": 0.11183785647153854,
      "learning_rate": 9.48604271893852e-06,
      "loss": 0.0365,
      "step": 3246
    },
    {
      "epoch": 0.05141156166379024,
      "grad_norm": 0.33772677183151245,
      "learning_rate": 9.485884383362099e-06,
      "loss": 0.1106,
      "step": 3247
    },
    {
      "epoch": 0.051427395221432304,
      "grad_norm": 0.005168743897229433,
      "learning_rate": 9.485726047785678e-06,
      "loss": 0.0003,
      "step": 3248
    },
    {
      "epoch": 0.05144322877907437,
      "grad_norm": 0.16192208230495453,
      "learning_rate": 9.485567712209257e-06,
      "loss": 0.1226,
      "step": 3249
    },
    {
      "epoch": 0.05145906233671644,
      "grad_norm": 0.15022693574428558,
      "learning_rate": 9.485409376632836e-06,
      "loss": 0.0785,
      "step": 3250
    },
    {
      "epoch": 0.051474895894358504,
      "grad_norm": 0.25439557433128357,
      "learning_rate": 9.485251041056415e-06,
      "loss": 0.0602,
      "step": 3251
    },
    {
      "epoch": 0.05149072945200057,
      "grad_norm": 0.15379786491394043,
      "learning_rate": 9.485092705479994e-06,
      "loss": 0.27,
      "step": 3252
    },
    {
      "epoch": 0.05150656300964264,
      "grad_norm": 0.1436670869588852,
      "learning_rate": 9.484934369903575e-06,
      "loss": 0.0968,
      "step": 3253
    },
    {
      "epoch": 0.0515223965672847,
      "grad_norm": 0.31809520721435547,
      "learning_rate": 9.484776034327154e-06,
      "loss": 0.2817,
      "step": 3254
    },
    {
      "epoch": 0.05153823012492677,
      "grad_norm": 0.305608332157135,
      "learning_rate": 9.484617698750733e-06,
      "loss": 0.1447,
      "step": 3255
    },
    {
      "epoch": 0.05155406368256884,
      "grad_norm": 0.26049622893333435,
      "learning_rate": 9.484459363174312e-06,
      "loss": 0.0261,
      "step": 3256
    },
    {
      "epoch": 0.0515698972402109,
      "grad_norm": 0.018240030854940414,
      "learning_rate": 9.484301027597891e-06,
      "loss": 0.0007,
      "step": 3257
    },
    {
      "epoch": 0.05158573079785297,
      "grad_norm": 0.14324644207954407,
      "learning_rate": 9.48414269202147e-06,
      "loss": 0.0639,
      "step": 3258
    },
    {
      "epoch": 0.05160156435549504,
      "grad_norm": 0.43239450454711914,
      "learning_rate": 9.483984356445051e-06,
      "loss": 0.3024,
      "step": 3259
    },
    {
      "epoch": 0.0516173979131371,
      "grad_norm": 0.4056670665740967,
      "learning_rate": 9.48382602086863e-06,
      "loss": 1.7068,
      "step": 3260
    },
    {
      "epoch": 0.05163323147077917,
      "grad_norm": 0.34010323882102966,
      "learning_rate": 9.48366768529221e-06,
      "loss": 0.0628,
      "step": 3261
    },
    {
      "epoch": 0.05164906502842124,
      "grad_norm": 0.027411669492721558,
      "learning_rate": 9.483509349715788e-06,
      "loss": 0.0019,
      "step": 3262
    },
    {
      "epoch": 0.0516648985860633,
      "grad_norm": 0.0013462714850902557,
      "learning_rate": 9.483351014139368e-06,
      "loss": 0.0,
      "step": 3263
    },
    {
      "epoch": 0.05168073214370537,
      "grad_norm": 0.23254278302192688,
      "learning_rate": 9.483192678562947e-06,
      "loss": 0.226,
      "step": 3264
    },
    {
      "epoch": 0.05169656570134744,
      "grad_norm": 0.2733146846294403,
      "learning_rate": 9.483034342986527e-06,
      "loss": 0.532,
      "step": 3265
    },
    {
      "epoch": 0.0517123992589895,
      "grad_norm": 0.1199086606502533,
      "learning_rate": 9.482876007410106e-06,
      "loss": 0.053,
      "step": 3266
    },
    {
      "epoch": 0.05172823281663157,
      "grad_norm": 0.023327408358454704,
      "learning_rate": 9.482717671833686e-06,
      "loss": 0.0015,
      "step": 3267
    },
    {
      "epoch": 0.05174406637427364,
      "grad_norm": 0.25211018323898315,
      "learning_rate": 9.482559336257265e-06,
      "loss": 0.1129,
      "step": 3268
    },
    {
      "epoch": 0.0517598999319157,
      "grad_norm": 0.025625424459576607,
      "learning_rate": 9.482401000680844e-06,
      "loss": 0.0019,
      "step": 3269
    },
    {
      "epoch": 0.05177573348955777,
      "grad_norm": 0.3084900975227356,
      "learning_rate": 9.482242665104423e-06,
      "loss": 0.2769,
      "step": 3270
    },
    {
      "epoch": 0.05179156704719984,
      "grad_norm": 0.00733152125030756,
      "learning_rate": 9.482084329528004e-06,
      "loss": 0.0005,
      "step": 3271
    },
    {
      "epoch": 0.0518074006048419,
      "grad_norm": 0.11568213254213333,
      "learning_rate": 9.481925993951581e-06,
      "loss": 0.0205,
      "step": 3272
    },
    {
      "epoch": 0.051823234162483967,
      "grad_norm": 0.10963480174541473,
      "learning_rate": 9.48176765837516e-06,
      "loss": 0.0874,
      "step": 3273
    },
    {
      "epoch": 0.05183906772012604,
      "grad_norm": 0.4192190170288086,
      "learning_rate": 9.48160932279874e-06,
      "loss": 0.1259,
      "step": 3274
    },
    {
      "epoch": 0.0518549012777681,
      "grad_norm": 0.17803265154361725,
      "learning_rate": 9.48145098722232e-06,
      "loss": 0.0819,
      "step": 3275
    },
    {
      "epoch": 0.051870734835410166,
      "grad_norm": 0.2694368362426758,
      "learning_rate": 9.481292651645899e-06,
      "loss": 0.0455,
      "step": 3276
    },
    {
      "epoch": 0.05188656839305224,
      "grad_norm": 0.6903430223464966,
      "learning_rate": 9.481134316069478e-06,
      "loss": 0.1781,
      "step": 3277
    },
    {
      "epoch": 0.0519024019506943,
      "grad_norm": 0.534539520740509,
      "learning_rate": 9.480975980493057e-06,
      "loss": 0.0629,
      "step": 3278
    },
    {
      "epoch": 0.051918235508336366,
      "grad_norm": 0.27816662192344666,
      "learning_rate": 9.480817644916636e-06,
      "loss": 0.1265,
      "step": 3279
    },
    {
      "epoch": 0.05193406906597844,
      "grad_norm": 0.06092694401741028,
      "learning_rate": 9.480659309340217e-06,
      "loss": 0.0039,
      "step": 3280
    },
    {
      "epoch": 0.0519499026236205,
      "grad_norm": 0.1854197382926941,
      "learning_rate": 9.480500973763796e-06,
      "loss": 0.2489,
      "step": 3281
    },
    {
      "epoch": 0.051965736181262566,
      "grad_norm": 0.3052445650100708,
      "learning_rate": 9.480342638187375e-06,
      "loss": 0.206,
      "step": 3282
    },
    {
      "epoch": 0.05198156973890464,
      "grad_norm": 7.029091648291796e-05,
      "learning_rate": 9.480184302610954e-06,
      "loss": 0.0,
      "step": 3283
    },
    {
      "epoch": 0.0519974032965467,
      "grad_norm": 0.2855454087257385,
      "learning_rate": 9.480025967034533e-06,
      "loss": 0.4461,
      "step": 3284
    },
    {
      "epoch": 0.052013236854188766,
      "grad_norm": 0.013667072169482708,
      "learning_rate": 9.479867631458112e-06,
      "loss": 0.0007,
      "step": 3285
    },
    {
      "epoch": 0.05202907041183084,
      "grad_norm": 0.45937997102737427,
      "learning_rate": 9.479709295881693e-06,
      "loss": 0.1698,
      "step": 3286
    },
    {
      "epoch": 0.0520449039694729,
      "grad_norm": 0.36658263206481934,
      "learning_rate": 9.479550960305272e-06,
      "loss": 0.1378,
      "step": 3287
    },
    {
      "epoch": 0.052060737527114966,
      "grad_norm": 0.003464343026280403,
      "learning_rate": 9.479392624728851e-06,
      "loss": 0.0002,
      "step": 3288
    },
    {
      "epoch": 0.05207657108475704,
      "grad_norm": 0.05124850571155548,
      "learning_rate": 9.47923428915243e-06,
      "loss": 0.0029,
      "step": 3289
    },
    {
      "epoch": 0.0520924046423991,
      "grad_norm": 0.3949817717075348,
      "learning_rate": 9.47907595357601e-06,
      "loss": 0.663,
      "step": 3290
    },
    {
      "epoch": 0.052108238200041165,
      "grad_norm": 0.013857278972864151,
      "learning_rate": 9.478917617999589e-06,
      "loss": 0.0003,
      "step": 3291
    },
    {
      "epoch": 0.05212407175768324,
      "grad_norm": 0.1627240926027298,
      "learning_rate": 9.47875928242317e-06,
      "loss": 0.0603,
      "step": 3292
    },
    {
      "epoch": 0.0521399053153253,
      "grad_norm": 0.2879994213581085,
      "learning_rate": 9.478600946846748e-06,
      "loss": 0.2305,
      "step": 3293
    },
    {
      "epoch": 0.052155738872967365,
      "grad_norm": 9.874806710286066e-05,
      "learning_rate": 9.478442611270327e-06,
      "loss": 0.0,
      "step": 3294
    },
    {
      "epoch": 0.052171572430609436,
      "grad_norm": 0.20484380424022675,
      "learning_rate": 9.478284275693907e-06,
      "loss": 0.506,
      "step": 3295
    },
    {
      "epoch": 0.0521874059882515,
      "grad_norm": 0.359108030796051,
      "learning_rate": 9.478125940117486e-06,
      "loss": 0.1191,
      "step": 3296
    },
    {
      "epoch": 0.052203239545893565,
      "grad_norm": 0.03059733472764492,
      "learning_rate": 9.477967604541065e-06,
      "loss": 0.0024,
      "step": 3297
    },
    {
      "epoch": 0.052219073103535636,
      "grad_norm": 0.25689059495925903,
      "learning_rate": 9.477809268964644e-06,
      "loss": 0.074,
      "step": 3298
    },
    {
      "epoch": 0.0522349066611777,
      "grad_norm": 0.1786472201347351,
      "learning_rate": 9.477650933388225e-06,
      "loss": 0.008,
      "step": 3299
    },
    {
      "epoch": 0.052250740218819765,
      "grad_norm": 0.00022920977789908648,
      "learning_rate": 9.477492597811802e-06,
      "loss": 0.0,
      "step": 3300
    },
    {
      "epoch": 0.052266573776461836,
      "grad_norm": 0.09143888205289841,
      "learning_rate": 9.477334262235383e-06,
      "loss": 0.041,
      "step": 3301
    },
    {
      "epoch": 0.0522824073341039,
      "grad_norm": 0.022311775013804436,
      "learning_rate": 9.477175926658962e-06,
      "loss": 0.0015,
      "step": 3302
    },
    {
      "epoch": 0.052298240891745965,
      "grad_norm": 0.6724856495857239,
      "learning_rate": 9.477017591082541e-06,
      "loss": 0.3607,
      "step": 3303
    },
    {
      "epoch": 0.052314074449388036,
      "grad_norm": 0.3705679178237915,
      "learning_rate": 9.47685925550612e-06,
      "loss": 0.1137,
      "step": 3304
    },
    {
      "epoch": 0.0523299080070301,
      "grad_norm": 0.19791066646575928,
      "learning_rate": 9.4767009199297e-06,
      "loss": 0.1271,
      "step": 3305
    },
    {
      "epoch": 0.052345741564672164,
      "grad_norm": 0.22743403911590576,
      "learning_rate": 9.476542584353278e-06,
      "loss": 0.2528,
      "step": 3306
    },
    {
      "epoch": 0.052361575122314236,
      "grad_norm": 0.1734829992055893,
      "learning_rate": 9.476384248776859e-06,
      "loss": 0.1127,
      "step": 3307
    },
    {
      "epoch": 0.0523774086799563,
      "grad_norm": 0.29277676343917847,
      "learning_rate": 9.476225913200438e-06,
      "loss": 0.4952,
      "step": 3308
    },
    {
      "epoch": 0.052393242237598364,
      "grad_norm": 0.40515443682670593,
      "learning_rate": 9.476067577624017e-06,
      "loss": 0.6533,
      "step": 3309
    },
    {
      "epoch": 0.052409075795240435,
      "grad_norm": 0.2307879626750946,
      "learning_rate": 9.475909242047596e-06,
      "loss": 0.6684,
      "step": 3310
    },
    {
      "epoch": 0.0524249093528825,
      "grad_norm": 0.32317858934402466,
      "learning_rate": 9.475750906471177e-06,
      "loss": 0.2392,
      "step": 3311
    },
    {
      "epoch": 0.052440742910524564,
      "grad_norm": 0.9028863906860352,
      "learning_rate": 9.475592570894754e-06,
      "loss": 0.0179,
      "step": 3312
    },
    {
      "epoch": 0.052456576468166635,
      "grad_norm": 0.2606945335865021,
      "learning_rate": 9.475434235318335e-06,
      "loss": 0.1553,
      "step": 3313
    },
    {
      "epoch": 0.0524724100258087,
      "grad_norm": 0.33400389552116394,
      "learning_rate": 9.475275899741914e-06,
      "loss": 0.1324,
      "step": 3314
    },
    {
      "epoch": 0.052488243583450764,
      "grad_norm": 0.17442232370376587,
      "learning_rate": 9.475117564165493e-06,
      "loss": 0.2632,
      "step": 3315
    },
    {
      "epoch": 0.052504077141092835,
      "grad_norm": 0.009174744598567486,
      "learning_rate": 9.474959228589072e-06,
      "loss": 0.0005,
      "step": 3316
    },
    {
      "epoch": 0.0525199106987349,
      "grad_norm": 0.29779717326164246,
      "learning_rate": 9.474800893012653e-06,
      "loss": 0.141,
      "step": 3317
    },
    {
      "epoch": 0.052535744256376964,
      "grad_norm": 0.14373545348644257,
      "learning_rate": 9.47464255743623e-06,
      "loss": 0.0601,
      "step": 3318
    },
    {
      "epoch": 0.052551577814019035,
      "grad_norm": 0.11137892305850983,
      "learning_rate": 9.474484221859811e-06,
      "loss": 0.0526,
      "step": 3319
    },
    {
      "epoch": 0.0525674113716611,
      "grad_norm": 0.3754464387893677,
      "learning_rate": 9.47432588628339e-06,
      "loss": 0.2271,
      "step": 3320
    },
    {
      "epoch": 0.05258324492930316,
      "grad_norm": 0.17908664047718048,
      "learning_rate": 9.47416755070697e-06,
      "loss": 0.0843,
      "step": 3321
    },
    {
      "epoch": 0.052599078486945235,
      "grad_norm": 0.9644784331321716,
      "learning_rate": 9.474009215130548e-06,
      "loss": 0.0168,
      "step": 3322
    },
    {
      "epoch": 0.0526149120445873,
      "grad_norm": 0.7141648530960083,
      "learning_rate": 9.473850879554128e-06,
      "loss": 0.2374,
      "step": 3323
    },
    {
      "epoch": 0.05263074560222936,
      "grad_norm": 0.006790468469262123,
      "learning_rate": 9.473692543977707e-06,
      "loss": 0.0003,
      "step": 3324
    },
    {
      "epoch": 0.052646579159871434,
      "grad_norm": 0.20793600380420685,
      "learning_rate": 9.473534208401286e-06,
      "loss": 0.0869,
      "step": 3325
    },
    {
      "epoch": 0.0526624127175135,
      "grad_norm": 0.0002778543857857585,
      "learning_rate": 9.473375872824866e-06,
      "loss": 0.0,
      "step": 3326
    },
    {
      "epoch": 0.05267824627515556,
      "grad_norm": 0.22211405634880066,
      "learning_rate": 9.473217537248446e-06,
      "loss": 0.1231,
      "step": 3327
    },
    {
      "epoch": 0.052694079832797634,
      "grad_norm": 0.23746536672115326,
      "learning_rate": 9.473059201672025e-06,
      "loss": 0.3111,
      "step": 3328
    },
    {
      "epoch": 0.0527099133904397,
      "grad_norm": 0.21958187222480774,
      "learning_rate": 9.472900866095604e-06,
      "loss": 0.0825,
      "step": 3329
    },
    {
      "epoch": 0.05272574694808176,
      "grad_norm": 0.02061632089316845,
      "learning_rate": 9.472742530519183e-06,
      "loss": 0.0013,
      "step": 3330
    },
    {
      "epoch": 0.052741580505723834,
      "grad_norm": 0.42113396525382996,
      "learning_rate": 9.472584194942762e-06,
      "loss": 0.1866,
      "step": 3331
    },
    {
      "epoch": 0.0527574140633659,
      "grad_norm": 0.0028281742706894875,
      "learning_rate": 9.472425859366343e-06,
      "loss": 0.0001,
      "step": 3332
    },
    {
      "epoch": 0.05277324762100796,
      "grad_norm": 0.26652488112449646,
      "learning_rate": 9.472267523789922e-06,
      "loss": 0.0329,
      "step": 3333
    },
    {
      "epoch": 0.052789081178650034,
      "grad_norm": 0.004905117210000753,
      "learning_rate": 9.4721091882135e-06,
      "loss": 0.0003,
      "step": 3334
    },
    {
      "epoch": 0.0528049147362921,
      "grad_norm": 0.15341734886169434,
      "learning_rate": 9.47195085263708e-06,
      "loss": 0.0369,
      "step": 3335
    },
    {
      "epoch": 0.05282074829393416,
      "grad_norm": 0.01944231614470482,
      "learning_rate": 9.471792517060659e-06,
      "loss": 0.001,
      "step": 3336
    },
    {
      "epoch": 0.052836581851576234,
      "grad_norm": 0.36804479360580444,
      "learning_rate": 9.471634181484238e-06,
      "loss": 0.3303,
      "step": 3337
    },
    {
      "epoch": 0.0528524154092183,
      "grad_norm": 0.7045053243637085,
      "learning_rate": 9.471475845907819e-06,
      "loss": 0.2478,
      "step": 3338
    },
    {
      "epoch": 0.05286824896686036,
      "grad_norm": 0.035869475454092026,
      "learning_rate": 9.471317510331396e-06,
      "loss": 0.0019,
      "step": 3339
    },
    {
      "epoch": 0.05288408252450243,
      "grad_norm": 0.39224353432655334,
      "learning_rate": 9.471159174754977e-06,
      "loss": 0.067,
      "step": 3340
    },
    {
      "epoch": 0.0528999160821445,
      "grad_norm": 0.22762876749038696,
      "learning_rate": 9.471000839178556e-06,
      "loss": 0.072,
      "step": 3341
    },
    {
      "epoch": 0.05291574963978656,
      "grad_norm": 0.3562603294849396,
      "learning_rate": 9.470842503602135e-06,
      "loss": 0.1759,
      "step": 3342
    },
    {
      "epoch": 0.05293158319742863,
      "grad_norm": 0.2810809910297394,
      "learning_rate": 9.470684168025714e-06,
      "loss": 0.286,
      "step": 3343
    },
    {
      "epoch": 0.0529474167550707,
      "grad_norm": 0.13586211204528809,
      "learning_rate": 9.470525832449295e-06,
      "loss": 0.052,
      "step": 3344
    },
    {
      "epoch": 0.05296325031271276,
      "grad_norm": 0.06299912184476852,
      "learning_rate": 9.470367496872872e-06,
      "loss": 0.0056,
      "step": 3345
    },
    {
      "epoch": 0.05297908387035483,
      "grad_norm": 0.4455914795398712,
      "learning_rate": 9.470209161296451e-06,
      "loss": 0.4998,
      "step": 3346
    },
    {
      "epoch": 0.0529949174279969,
      "grad_norm": 0.010662511922419071,
      "learning_rate": 9.470050825720032e-06,
      "loss": 0.0007,
      "step": 3347
    },
    {
      "epoch": 0.05301075098563896,
      "grad_norm": 0.14499399065971375,
      "learning_rate": 9.469892490143611e-06,
      "loss": 0.2582,
      "step": 3348
    },
    {
      "epoch": 0.05302658454328103,
      "grad_norm": 0.04029856622219086,
      "learning_rate": 9.46973415456719e-06,
      "loss": 0.0022,
      "step": 3349
    },
    {
      "epoch": 0.0530424181009231,
      "grad_norm": 0.19121095538139343,
      "learning_rate": 9.46957581899077e-06,
      "loss": 0.0506,
      "step": 3350
    },
    {
      "epoch": 0.05305825165856516,
      "grad_norm": 0.010440438985824585,
      "learning_rate": 9.469417483414349e-06,
      "loss": 0.0008,
      "step": 3351
    },
    {
      "epoch": 0.05307408521620723,
      "grad_norm": 0.027654452249407768,
      "learning_rate": 9.469259147837928e-06,
      "loss": 0.0022,
      "step": 3352
    },
    {
      "epoch": 0.0530899187738493,
      "grad_norm": 1.1731258630752563,
      "learning_rate": 9.469100812261508e-06,
      "loss": 0.1651,
      "step": 3353
    },
    {
      "epoch": 0.05310575233149136,
      "grad_norm": 0.42863723635673523,
      "learning_rate": 9.468942476685087e-06,
      "loss": 0.6933,
      "step": 3354
    },
    {
      "epoch": 0.05312158588913343,
      "grad_norm": 0.21039706468582153,
      "learning_rate": 9.468784141108667e-06,
      "loss": 0.1726,
      "step": 3355
    },
    {
      "epoch": 0.0531374194467755,
      "grad_norm": 0.22253523766994476,
      "learning_rate": 9.468625805532246e-06,
      "loss": 0.0754,
      "step": 3356
    },
    {
      "epoch": 0.05315325300441756,
      "grad_norm": 0.28395381569862366,
      "learning_rate": 9.468467469955825e-06,
      "loss": 0.2399,
      "step": 3357
    },
    {
      "epoch": 0.05316908656205963,
      "grad_norm": 0.19118358194828033,
      "learning_rate": 9.468309134379404e-06,
      "loss": 0.1456,
      "step": 3358
    },
    {
      "epoch": 0.0531849201197017,
      "grad_norm": 0.20842517912387848,
      "learning_rate": 9.468150798802985e-06,
      "loss": 0.2301,
      "step": 3359
    },
    {
      "epoch": 0.05320075367734376,
      "grad_norm": 0.0607139952480793,
      "learning_rate": 9.467992463226564e-06,
      "loss": 0.0203,
      "step": 3360
    },
    {
      "epoch": 0.05321658723498583,
      "grad_norm": 0.013417815789580345,
      "learning_rate": 9.467834127650143e-06,
      "loss": 0.001,
      "step": 3361
    },
    {
      "epoch": 0.053232420792627896,
      "grad_norm": 0.3692377209663391,
      "learning_rate": 9.467675792073722e-06,
      "loss": 0.1732,
      "step": 3362
    },
    {
      "epoch": 0.05324825435026996,
      "grad_norm": 0.2860056161880493,
      "learning_rate": 9.467517456497301e-06,
      "loss": 0.6251,
      "step": 3363
    },
    {
      "epoch": 0.05326408790791203,
      "grad_norm": 0.2964978814125061,
      "learning_rate": 9.46735912092088e-06,
      "loss": 0.4276,
      "step": 3364
    },
    {
      "epoch": 0.053279921465554096,
      "grad_norm": 0.18459561467170715,
      "learning_rate": 9.46720078534446e-06,
      "loss": 0.0723,
      "step": 3365
    },
    {
      "epoch": 0.05329575502319616,
      "grad_norm": 0.2318374067544937,
      "learning_rate": 9.46704244976804e-06,
      "loss": 0.1127,
      "step": 3366
    },
    {
      "epoch": 0.05331158858083823,
      "grad_norm": 0.009403361938893795,
      "learning_rate": 9.466884114191619e-06,
      "loss": 0.0006,
      "step": 3367
    },
    {
      "epoch": 0.053327422138480296,
      "grad_norm": 0.21742185950279236,
      "learning_rate": 9.466725778615198e-06,
      "loss": 0.1089,
      "step": 3368
    },
    {
      "epoch": 0.05334325569612236,
      "grad_norm": 0.0027499927673488855,
      "learning_rate": 9.466567443038777e-06,
      "loss": 0.0002,
      "step": 3369
    },
    {
      "epoch": 0.05335908925376443,
      "grad_norm": 0.06328864395618439,
      "learning_rate": 9.466409107462356e-06,
      "loss": 0.0014,
      "step": 3370
    },
    {
      "epoch": 0.053374922811406496,
      "grad_norm": 0.19652855396270752,
      "learning_rate": 9.466250771885935e-06,
      "loss": 0.1076,
      "step": 3371
    },
    {
      "epoch": 0.05339075636904856,
      "grad_norm": 0.25421470403671265,
      "learning_rate": 9.466092436309516e-06,
      "loss": 0.1889,
      "step": 3372
    },
    {
      "epoch": 0.05340658992669063,
      "grad_norm": 0.005549000110477209,
      "learning_rate": 9.465934100733093e-06,
      "loss": 0.0004,
      "step": 3373
    },
    {
      "epoch": 0.053422423484332696,
      "grad_norm": 0.3289337158203125,
      "learning_rate": 9.465775765156674e-06,
      "loss": 0.297,
      "step": 3374
    },
    {
      "epoch": 0.05343825704197476,
      "grad_norm": 0.04874136298894882,
      "learning_rate": 9.465617429580253e-06,
      "loss": 0.0011,
      "step": 3375
    },
    {
      "epoch": 0.05345409059961683,
      "grad_norm": 0.28329646587371826,
      "learning_rate": 9.465459094003832e-06,
      "loss": 0.256,
      "step": 3376
    },
    {
      "epoch": 0.053469924157258895,
      "grad_norm": 0.3302610218524933,
      "learning_rate": 9.465300758427411e-06,
      "loss": 0.1221,
      "step": 3377
    },
    {
      "epoch": 0.05348575771490096,
      "grad_norm": 0.008238221518695354,
      "learning_rate": 9.465142422850992e-06,
      "loss": 0.0005,
      "step": 3378
    },
    {
      "epoch": 0.05350159127254303,
      "grad_norm": 0.00519780907779932,
      "learning_rate": 9.46498408727457e-06,
      "loss": 0.0002,
      "step": 3379
    },
    {
      "epoch": 0.053517424830185095,
      "grad_norm": 0.5174258351325989,
      "learning_rate": 9.46482575169815e-06,
      "loss": 0.143,
      "step": 3380
    },
    {
      "epoch": 0.05353325838782716,
      "grad_norm": 0.05823134258389473,
      "learning_rate": 9.46466741612173e-06,
      "loss": 0.0014,
      "step": 3381
    },
    {
      "epoch": 0.05354909194546923,
      "grad_norm": 9.942927863448858e-05,
      "learning_rate": 9.464509080545308e-06,
      "loss": 0.0,
      "step": 3382
    },
    {
      "epoch": 0.053564925503111295,
      "grad_norm": 0.02712281234562397,
      "learning_rate": 9.464350744968888e-06,
      "loss": 0.0021,
      "step": 3383
    },
    {
      "epoch": 0.05358075906075336,
      "grad_norm": 0.2875592112541199,
      "learning_rate": 9.464192409392468e-06,
      "loss": 0.1997,
      "step": 3384
    },
    {
      "epoch": 0.05359659261839543,
      "grad_norm": 0.4021095335483551,
      "learning_rate": 9.464034073816046e-06,
      "loss": 0.1392,
      "step": 3385
    },
    {
      "epoch": 0.053612426176037495,
      "grad_norm": 0.18111440539360046,
      "learning_rate": 9.463875738239626e-06,
      "loss": 0.085,
      "step": 3386
    },
    {
      "epoch": 0.05362825973367956,
      "grad_norm": 0.1932944655418396,
      "learning_rate": 9.463717402663206e-06,
      "loss": 0.35,
      "step": 3387
    },
    {
      "epoch": 0.05364409329132163,
      "grad_norm": 0.26686161756515503,
      "learning_rate": 9.463559067086785e-06,
      "loss": 0.076,
      "step": 3388
    },
    {
      "epoch": 0.053659926848963695,
      "grad_norm": 0.3150869607925415,
      "learning_rate": 9.463400731510364e-06,
      "loss": 0.1411,
      "step": 3389
    },
    {
      "epoch": 0.05367576040660576,
      "grad_norm": 0.21629241108894348,
      "learning_rate": 9.463242395933944e-06,
      "loss": 0.0471,
      "step": 3390
    },
    {
      "epoch": 0.05369159396424783,
      "grad_norm": 0.14948299527168274,
      "learning_rate": 9.463084060357522e-06,
      "loss": 0.1025,
      "step": 3391
    },
    {
      "epoch": 0.053707427521889894,
      "grad_norm": 0.19874268770217896,
      "learning_rate": 9.462925724781103e-06,
      "loss": 0.1629,
      "step": 3392
    },
    {
      "epoch": 0.05372326107953196,
      "grad_norm": 0.7951536774635315,
      "learning_rate": 9.462767389204682e-06,
      "loss": 1.0916,
      "step": 3393
    },
    {
      "epoch": 0.05373909463717403,
      "grad_norm": 1.8763181287795305e-05,
      "learning_rate": 9.46260905362826e-06,
      "loss": 0.0,
      "step": 3394
    },
    {
      "epoch": 0.053754928194816094,
      "grad_norm": 0.0008156736148521304,
      "learning_rate": 9.46245071805184e-06,
      "loss": 0.0,
      "step": 3395
    },
    {
      "epoch": 0.05377076175245816,
      "grad_norm": 0.19205600023269653,
      "learning_rate": 9.462292382475419e-06,
      "loss": 0.3113,
      "step": 3396
    },
    {
      "epoch": 0.05378659531010023,
      "grad_norm": 0.183590367436409,
      "learning_rate": 9.462134046898998e-06,
      "loss": 0.1421,
      "step": 3397
    },
    {
      "epoch": 0.053802428867742294,
      "grad_norm": 0.000113706111733336,
      "learning_rate": 9.461975711322577e-06,
      "loss": 0.0,
      "step": 3398
    },
    {
      "epoch": 0.05381826242538436,
      "grad_norm": 0.04032919928431511,
      "learning_rate": 9.461817375746158e-06,
      "loss": 0.0029,
      "step": 3399
    },
    {
      "epoch": 0.05383409598302643,
      "grad_norm": 0.1972665637731552,
      "learning_rate": 9.461659040169735e-06,
      "loss": 0.1499,
      "step": 3400
    },
    {
      "epoch": 0.053849929540668494,
      "grad_norm": 0.17057988047599792,
      "learning_rate": 9.461500704593316e-06,
      "loss": 0.0536,
      "step": 3401
    },
    {
      "epoch": 0.05386576309831056,
      "grad_norm": 0.19964206218719482,
      "learning_rate": 9.461342369016895e-06,
      "loss": 0.0582,
      "step": 3402
    },
    {
      "epoch": 0.05388159665595263,
      "grad_norm": 0.3963404893875122,
      "learning_rate": 9.461184033440474e-06,
      "loss": 0.6335,
      "step": 3403
    },
    {
      "epoch": 0.053897430213594694,
      "grad_norm": 0.16120922565460205,
      "learning_rate": 9.461025697864053e-06,
      "loss": 0.0498,
      "step": 3404
    },
    {
      "epoch": 0.05391326377123676,
      "grad_norm": 0.26542025804519653,
      "learning_rate": 9.460867362287634e-06,
      "loss": 0.3245,
      "step": 3405
    },
    {
      "epoch": 0.05392909732887883,
      "grad_norm": 0.19840216636657715,
      "learning_rate": 9.460709026711211e-06,
      "loss": 0.0779,
      "step": 3406
    },
    {
      "epoch": 0.05394493088652089,
      "grad_norm": 0.1858646124601364,
      "learning_rate": 9.460550691134792e-06,
      "loss": 0.0456,
      "step": 3407
    },
    {
      "epoch": 0.05396076444416296,
      "grad_norm": 0.32303962111473083,
      "learning_rate": 9.460392355558371e-06,
      "loss": 0.3054,
      "step": 3408
    },
    {
      "epoch": 0.05397659800180503,
      "grad_norm": 0.01337018795311451,
      "learning_rate": 9.46023401998195e-06,
      "loss": 0.0009,
      "step": 3409
    },
    {
      "epoch": 0.05399243155944709,
      "grad_norm": 9.023794700624421e-05,
      "learning_rate": 9.46007568440553e-06,
      "loss": 0.0,
      "step": 3410
    },
    {
      "epoch": 0.05400826511708916,
      "grad_norm": 0.195468932390213,
      "learning_rate": 9.45991734882911e-06,
      "loss": 0.36,
      "step": 3411
    },
    {
      "epoch": 0.05402409867473123,
      "grad_norm": 0.2912103831768036,
      "learning_rate": 9.459759013252688e-06,
      "loss": 0.4317,
      "step": 3412
    },
    {
      "epoch": 0.05403993223237329,
      "grad_norm": 0.1905677765607834,
      "learning_rate": 9.459600677676268e-06,
      "loss": 0.1184,
      "step": 3413
    },
    {
      "epoch": 0.05405576579001536,
      "grad_norm": 0.03338906541466713,
      "learning_rate": 9.459442342099847e-06,
      "loss": 0.0022,
      "step": 3414
    },
    {
      "epoch": 0.05407159934765743,
      "grad_norm": 0.02015237882733345,
      "learning_rate": 9.459284006523427e-06,
      "loss": 0.001,
      "step": 3415
    },
    {
      "epoch": 0.05408743290529949,
      "grad_norm": 0.17823971807956696,
      "learning_rate": 9.459125670947006e-06,
      "loss": 0.3199,
      "step": 3416
    },
    {
      "epoch": 0.05410326646294156,
      "grad_norm": 0.41988855600357056,
      "learning_rate": 9.458967335370585e-06,
      "loss": 0.6145,
      "step": 3417
    },
    {
      "epoch": 0.05411910002058363,
      "grad_norm": 0.345779687166214,
      "learning_rate": 9.458808999794164e-06,
      "loss": 0.0954,
      "step": 3418
    },
    {
      "epoch": 0.05413493357822569,
      "grad_norm": 0.043829090893268585,
      "learning_rate": 9.458650664217743e-06,
      "loss": 0.002,
      "step": 3419
    },
    {
      "epoch": 0.05415076713586776,
      "grad_norm": 0.4405054450035095,
      "learning_rate": 9.458492328641324e-06,
      "loss": 0.1269,
      "step": 3420
    },
    {
      "epoch": 0.05416660069350982,
      "grad_norm": 0.35966747999191284,
      "learning_rate": 9.458333993064903e-06,
      "loss": 0.634,
      "step": 3421
    },
    {
      "epoch": 0.05418243425115189,
      "grad_norm": 0.2144044190645218,
      "learning_rate": 9.458175657488482e-06,
      "loss": 0.1078,
      "step": 3422
    },
    {
      "epoch": 0.05419826780879396,
      "grad_norm": 0.31813716888427734,
      "learning_rate": 9.458017321912061e-06,
      "loss": 0.3199,
      "step": 3423
    },
    {
      "epoch": 0.05421410136643602,
      "grad_norm": 9.31637769099325e-05,
      "learning_rate": 9.45785898633564e-06,
      "loss": 0.0,
      "step": 3424
    },
    {
      "epoch": 0.05422993492407809,
      "grad_norm": 0.03044871613383293,
      "learning_rate": 9.457700650759219e-06,
      "loss": 0.0019,
      "step": 3425
    },
    {
      "epoch": 0.05424576848172016,
      "grad_norm": 0.046295296400785446,
      "learning_rate": 9.4575423151828e-06,
      "loss": 0.0066,
      "step": 3426
    },
    {
      "epoch": 0.05426160203936222,
      "grad_norm": 0.0034352699294686317,
      "learning_rate": 9.457383979606379e-06,
      "loss": 0.0001,
      "step": 3427
    },
    {
      "epoch": 0.05427743559700429,
      "grad_norm": 0.1176881492137909,
      "learning_rate": 9.457225644029958e-06,
      "loss": 0.0092,
      "step": 3428
    },
    {
      "epoch": 0.054293269154646356,
      "grad_norm": 3.155332088470459,
      "learning_rate": 9.457067308453537e-06,
      "loss": 0.3764,
      "step": 3429
    },
    {
      "epoch": 0.05430910271228842,
      "grad_norm": 0.024058610200881958,
      "learning_rate": 9.456908972877116e-06,
      "loss": 0.0024,
      "step": 3430
    },
    {
      "epoch": 0.05432493626993049,
      "grad_norm": 0.051477428525686264,
      "learning_rate": 9.456750637300695e-06,
      "loss": 0.0045,
      "step": 3431
    },
    {
      "epoch": 0.054340769827572556,
      "grad_norm": 0.3156699240207672,
      "learning_rate": 9.456592301724276e-06,
      "loss": 0.2793,
      "step": 3432
    },
    {
      "epoch": 0.05435660338521462,
      "grad_norm": 0.031120477244257927,
      "learning_rate": 9.456433966147855e-06,
      "loss": 0.0022,
      "step": 3433
    },
    {
      "epoch": 0.05437243694285669,
      "grad_norm": 0.19842784106731415,
      "learning_rate": 9.456275630571434e-06,
      "loss": 0.0928,
      "step": 3434
    },
    {
      "epoch": 0.054388270500498756,
      "grad_norm": 0.18263229727745056,
      "learning_rate": 9.456117294995013e-06,
      "loss": 0.1701,
      "step": 3435
    },
    {
      "epoch": 0.05440410405814082,
      "grad_norm": 0.3791162073612213,
      "learning_rate": 9.455958959418592e-06,
      "loss": 0.1294,
      "step": 3436
    },
    {
      "epoch": 0.05441993761578289,
      "grad_norm": 0.13480712473392487,
      "learning_rate": 9.455800623842171e-06,
      "loss": 0.0553,
      "step": 3437
    },
    {
      "epoch": 0.054435771173424956,
      "grad_norm": 0.22544974088668823,
      "learning_rate": 9.455642288265752e-06,
      "loss": 0.1008,
      "step": 3438
    },
    {
      "epoch": 0.05445160473106702,
      "grad_norm": 0.27362632751464844,
      "learning_rate": 9.455483952689331e-06,
      "loss": 0.1242,
      "step": 3439
    },
    {
      "epoch": 0.05446743828870909,
      "grad_norm": 0.21786905825138092,
      "learning_rate": 9.45532561711291e-06,
      "loss": 0.162,
      "step": 3440
    },
    {
      "epoch": 0.054483271846351156,
      "grad_norm": 0.0442824587225914,
      "learning_rate": 9.45516728153649e-06,
      "loss": 0.0019,
      "step": 3441
    },
    {
      "epoch": 0.05449910540399322,
      "grad_norm": 0.2491322159767151,
      "learning_rate": 9.455008945960068e-06,
      "loss": 0.1491,
      "step": 3442
    },
    {
      "epoch": 0.05451493896163529,
      "grad_norm": 0.29656025767326355,
      "learning_rate": 9.454850610383648e-06,
      "loss": 0.2436,
      "step": 3443
    },
    {
      "epoch": 0.054530772519277355,
      "grad_norm": 0.01649281196296215,
      "learning_rate": 9.454692274807227e-06,
      "loss": 0.0011,
      "step": 3444
    },
    {
      "epoch": 0.05454660607691942,
      "grad_norm": 0.26039692759513855,
      "learning_rate": 9.454533939230807e-06,
      "loss": 0.2538,
      "step": 3445
    },
    {
      "epoch": 0.05456243963456149,
      "grad_norm": 0.26260659098625183,
      "learning_rate": 9.454375603654385e-06,
      "loss": 0.1344,
      "step": 3446
    },
    {
      "epoch": 0.054578273192203555,
      "grad_norm": 0.32390618324279785,
      "learning_rate": 9.454217268077966e-06,
      "loss": 0.6331,
      "step": 3447
    },
    {
      "epoch": 0.05459410674984562,
      "grad_norm": 0.6191461086273193,
      "learning_rate": 9.454058932501545e-06,
      "loss": 0.202,
      "step": 3448
    },
    {
      "epoch": 0.05460994030748769,
      "grad_norm": 0.14366143941879272,
      "learning_rate": 9.453900596925124e-06,
      "loss": 0.0661,
      "step": 3449
    },
    {
      "epoch": 0.054625773865129755,
      "grad_norm": 0.22064432501792908,
      "learning_rate": 9.453742261348703e-06,
      "loss": 0.2492,
      "step": 3450
    },
    {
      "epoch": 0.05464160742277182,
      "grad_norm": 0.0237590279430151,
      "learning_rate": 9.453583925772284e-06,
      "loss": 0.0016,
      "step": 3451
    },
    {
      "epoch": 0.05465744098041389,
      "grad_norm": 0.17881059646606445,
      "learning_rate": 9.453425590195861e-06,
      "loss": 0.0521,
      "step": 3452
    },
    {
      "epoch": 0.054673274538055955,
      "grad_norm": 0.2579561769962311,
      "learning_rate": 9.453267254619442e-06,
      "loss": 0.417,
      "step": 3453
    },
    {
      "epoch": 0.05468910809569802,
      "grad_norm": 0.28247198462486267,
      "learning_rate": 9.45310891904302e-06,
      "loss": 0.3894,
      "step": 3454
    },
    {
      "epoch": 0.05470494165334009,
      "grad_norm": 0.19211861491203308,
      "learning_rate": 9.4529505834666e-06,
      "loss": 0.0851,
      "step": 3455
    },
    {
      "epoch": 0.054720775210982155,
      "grad_norm": 0.24150219559669495,
      "learning_rate": 9.452792247890179e-06,
      "loss": 0.0526,
      "step": 3456
    },
    {
      "epoch": 0.05473660876862422,
      "grad_norm": 0.14847438037395477,
      "learning_rate": 9.45263391231376e-06,
      "loss": 0.0773,
      "step": 3457
    },
    {
      "epoch": 0.05475244232626629,
      "grad_norm": 0.36468714475631714,
      "learning_rate": 9.452475576737337e-06,
      "loss": 0.3411,
      "step": 3458
    },
    {
      "epoch": 0.054768275883908354,
      "grad_norm": 0.23618508875370026,
      "learning_rate": 9.452317241160918e-06,
      "loss": 0.0428,
      "step": 3459
    },
    {
      "epoch": 0.05478410944155042,
      "grad_norm": 0.259801983833313,
      "learning_rate": 9.452158905584497e-06,
      "loss": 0.1362,
      "step": 3460
    },
    {
      "epoch": 0.05479994299919249,
      "grad_norm": 0.33723342418670654,
      "learning_rate": 9.452000570008076e-06,
      "loss": 0.1071,
      "step": 3461
    },
    {
      "epoch": 0.054815776556834554,
      "grad_norm": 0.13774122297763824,
      "learning_rate": 9.451842234431655e-06,
      "loss": 0.0522,
      "step": 3462
    },
    {
      "epoch": 0.05483161011447662,
      "grad_norm": 0.003313651541247964,
      "learning_rate": 9.451683898855234e-06,
      "loss": 0.0001,
      "step": 3463
    },
    {
      "epoch": 0.05484744367211869,
      "grad_norm": 0.20478014647960663,
      "learning_rate": 9.451525563278813e-06,
      "loss": 0.2064,
      "step": 3464
    },
    {
      "epoch": 0.054863277229760754,
      "grad_norm": 0.18377885222434998,
      "learning_rate": 9.451367227702392e-06,
      "loss": 0.4797,
      "step": 3465
    },
    {
      "epoch": 0.05487911078740282,
      "grad_norm": 0.14217425882816315,
      "learning_rate": 9.451208892125973e-06,
      "loss": 0.0668,
      "step": 3466
    },
    {
      "epoch": 0.05489494434504489,
      "grad_norm": 0.18780842423439026,
      "learning_rate": 9.45105055654955e-06,
      "loss": 0.1373,
      "step": 3467
    },
    {
      "epoch": 0.054910777902686954,
      "grad_norm": 0.00016221325495280325,
      "learning_rate": 9.450892220973131e-06,
      "loss": 0.0,
      "step": 3468
    },
    {
      "epoch": 0.05492661146032902,
      "grad_norm": 0.16522277891635895,
      "learning_rate": 9.45073388539671e-06,
      "loss": 0.2676,
      "step": 3469
    },
    {
      "epoch": 0.05494244501797109,
      "grad_norm": 0.007927236147224903,
      "learning_rate": 9.45057554982029e-06,
      "loss": 0.0005,
      "step": 3470
    },
    {
      "epoch": 0.054958278575613154,
      "grad_norm": 0.44925200939178467,
      "learning_rate": 9.450417214243869e-06,
      "loss": 0.2529,
      "step": 3471
    },
    {
      "epoch": 0.05497411213325522,
      "grad_norm": 0.23134943842887878,
      "learning_rate": 9.45025887866745e-06,
      "loss": 0.1532,
      "step": 3472
    },
    {
      "epoch": 0.05498994569089729,
      "grad_norm": 0.3001256287097931,
      "learning_rate": 9.450100543091027e-06,
      "loss": 0.0695,
      "step": 3473
    },
    {
      "epoch": 0.05500577924853935,
      "grad_norm": 0.002082584425806999,
      "learning_rate": 9.449942207514608e-06,
      "loss": 0.0001,
      "step": 3474
    },
    {
      "epoch": 0.05502161280618142,
      "grad_norm": 0.5625311732292175,
      "learning_rate": 9.449783871938187e-06,
      "loss": 0.3797,
      "step": 3475
    },
    {
      "epoch": 0.05503744636382349,
      "grad_norm": 0.006013139616698027,
      "learning_rate": 9.449625536361766e-06,
      "loss": 0.0003,
      "step": 3476
    },
    {
      "epoch": 0.05505327992146555,
      "grad_norm": 0.02080937661230564,
      "learning_rate": 9.449467200785345e-06,
      "loss": 0.0012,
      "step": 3477
    },
    {
      "epoch": 0.05506911347910762,
      "grad_norm": 0.16362296044826508,
      "learning_rate": 9.449308865208926e-06,
      "loss": 0.0661,
      "step": 3478
    },
    {
      "epoch": 0.05508494703674969,
      "grad_norm": 0.28283554315567017,
      "learning_rate": 9.449150529632503e-06,
      "loss": 0.5089,
      "step": 3479
    },
    {
      "epoch": 0.05510078059439175,
      "grad_norm": 0.42609190940856934,
      "learning_rate": 9.448992194056084e-06,
      "loss": 0.1106,
      "step": 3480
    },
    {
      "epoch": 0.05511661415203382,
      "grad_norm": 0.34248048067092896,
      "learning_rate": 9.448833858479663e-06,
      "loss": 0.1794,
      "step": 3481
    },
    {
      "epoch": 0.05513244770967589,
      "grad_norm": 0.17238351702690125,
      "learning_rate": 9.448675522903242e-06,
      "loss": 0.0029,
      "step": 3482
    },
    {
      "epoch": 0.05514828126731795,
      "grad_norm": 0.5857111811637878,
      "learning_rate": 9.448517187326821e-06,
      "loss": 0.0781,
      "step": 3483
    },
    {
      "epoch": 0.05516411482496002,
      "grad_norm": 0.4041357636451721,
      "learning_rate": 9.448358851750402e-06,
      "loss": 0.1023,
      "step": 3484
    },
    {
      "epoch": 0.05517994838260209,
      "grad_norm": 0.26857009530067444,
      "learning_rate": 9.448200516173979e-06,
      "loss": 0.1535,
      "step": 3485
    },
    {
      "epoch": 0.05519578194024415,
      "grad_norm": 5.1649276429088786e-05,
      "learning_rate": 9.44804218059756e-06,
      "loss": 0.0,
      "step": 3486
    },
    {
      "epoch": 0.05521161549788622,
      "grad_norm": 7.898746967315674,
      "learning_rate": 9.447883845021139e-06,
      "loss": 0.2552,
      "step": 3487
    },
    {
      "epoch": 0.05522744905552829,
      "grad_norm": 0.004078978206962347,
      "learning_rate": 9.447725509444718e-06,
      "loss": 0.0002,
      "step": 3488
    },
    {
      "epoch": 0.05524328261317035,
      "grad_norm": 0.7558526992797852,
      "learning_rate": 9.447567173868297e-06,
      "loss": 0.1058,
      "step": 3489
    },
    {
      "epoch": 0.05525911617081242,
      "grad_norm": 0.8134300112724304,
      "learning_rate": 9.447408838291876e-06,
      "loss": 0.0501,
      "step": 3490
    },
    {
      "epoch": 0.05527494972845449,
      "grad_norm": 0.26197874546051025,
      "learning_rate": 9.447250502715455e-06,
      "loss": 0.0407,
      "step": 3491
    },
    {
      "epoch": 0.05529078328609655,
      "grad_norm": 0.1807786524295807,
      "learning_rate": 9.447092167139034e-06,
      "loss": 0.1858,
      "step": 3492
    },
    {
      "epoch": 0.05530661684373862,
      "grad_norm": 0.002508638659492135,
      "learning_rate": 9.446933831562615e-06,
      "loss": 0.0,
      "step": 3493
    },
    {
      "epoch": 0.05532245040138069,
      "grad_norm": 0.3198380470275879,
      "learning_rate": 9.446775495986194e-06,
      "loss": 0.2033,
      "step": 3494
    },
    {
      "epoch": 0.05533828395902275,
      "grad_norm": 0.1911734789609909,
      "learning_rate": 9.446617160409773e-06,
      "loss": 0.1349,
      "step": 3495
    },
    {
      "epoch": 0.055354117516664816,
      "grad_norm": 0.36027395725250244,
      "learning_rate": 9.446458824833352e-06,
      "loss": 0.0971,
      "step": 3496
    },
    {
      "epoch": 0.05536995107430689,
      "grad_norm": 0.01892121508717537,
      "learning_rate": 9.446300489256931e-06,
      "loss": 0.0012,
      "step": 3497
    },
    {
      "epoch": 0.05538578463194895,
      "grad_norm": 0.12997524440288544,
      "learning_rate": 9.44614215368051e-06,
      "loss": 0.039,
      "step": 3498
    },
    {
      "epoch": 0.055401618189591016,
      "grad_norm": 0.19205829501152039,
      "learning_rate": 9.445983818104091e-06,
      "loss": 0.2719,
      "step": 3499
    },
    {
      "epoch": 0.05541745174723309,
      "grad_norm": 0.28622230887413025,
      "learning_rate": 9.44582548252767e-06,
      "loss": 0.3017,
      "step": 3500
    },
    {
      "epoch": 0.05543328530487515,
      "grad_norm": 0.053900331258773804,
      "learning_rate": 9.44566714695125e-06,
      "loss": 0.0074,
      "step": 3501
    },
    {
      "epoch": 0.055449118862517216,
      "grad_norm": 0.14273105561733246,
      "learning_rate": 9.445508811374829e-06,
      "loss": 0.0884,
      "step": 3502
    },
    {
      "epoch": 0.05546495242015929,
      "grad_norm": 0.16950419545173645,
      "learning_rate": 9.445350475798408e-06,
      "loss": 0.2859,
      "step": 3503
    },
    {
      "epoch": 0.05548078597780135,
      "grad_norm": 0.011178413406014442,
      "learning_rate": 9.445192140221987e-06,
      "loss": 0.0006,
      "step": 3504
    },
    {
      "epoch": 0.055496619535443416,
      "grad_norm": 0.4074665606021881,
      "learning_rate": 9.445033804645567e-06,
      "loss": 0.8856,
      "step": 3505
    },
    {
      "epoch": 0.05551245309308549,
      "grad_norm": 0.4818117916584015,
      "learning_rate": 9.444875469069147e-06,
      "loss": 0.375,
      "step": 3506
    },
    {
      "epoch": 0.05552828665072755,
      "grad_norm": 0.0025187579449266195,
      "learning_rate": 9.444717133492726e-06,
      "loss": 0.0001,
      "step": 3507
    },
    {
      "epoch": 0.055544120208369616,
      "grad_norm": 0.22221575677394867,
      "learning_rate": 9.444558797916305e-06,
      "loss": 0.2398,
      "step": 3508
    },
    {
      "epoch": 0.05555995376601169,
      "grad_norm": 0.30706021189689636,
      "learning_rate": 9.444400462339884e-06,
      "loss": 0.0102,
      "step": 3509
    },
    {
      "epoch": 0.05557578732365375,
      "grad_norm": 9.659965144237503e-05,
      "learning_rate": 9.444242126763463e-06,
      "loss": 0.0,
      "step": 3510
    },
    {
      "epoch": 0.055591620881295815,
      "grad_norm": 0.2533029019832611,
      "learning_rate": 9.444083791187044e-06,
      "loss": 0.0764,
      "step": 3511
    },
    {
      "epoch": 0.05560745443893789,
      "grad_norm": 0.442693829536438,
      "learning_rate": 9.443925455610623e-06,
      "loss": 0.1969,
      "step": 3512
    },
    {
      "epoch": 0.05562328799657995,
      "grad_norm": 0.015994084998965263,
      "learning_rate": 9.4437671200342e-06,
      "loss": 0.001,
      "step": 3513
    },
    {
      "epoch": 0.055639121554222015,
      "grad_norm": 0.01431951392441988,
      "learning_rate": 9.443608784457781e-06,
      "loss": 0.0009,
      "step": 3514
    },
    {
      "epoch": 0.055654955111864086,
      "grad_norm": 0.013470347039401531,
      "learning_rate": 9.44345044888136e-06,
      "loss": 0.0008,
      "step": 3515
    },
    {
      "epoch": 0.05567078866950615,
      "grad_norm": 0.004873139783740044,
      "learning_rate": 9.443292113304939e-06,
      "loss": 0.0002,
      "step": 3516
    },
    {
      "epoch": 0.055686622227148215,
      "grad_norm": 0.0002473352069500834,
      "learning_rate": 9.443133777728518e-06,
      "loss": 0.0,
      "step": 3517
    },
    {
      "epoch": 0.055702455784790286,
      "grad_norm": 0.17551378905773163,
      "learning_rate": 9.442975442152099e-06,
      "loss": 0.3352,
      "step": 3518
    },
    {
      "epoch": 0.05571828934243235,
      "grad_norm": 0.2528208792209625,
      "learning_rate": 9.442817106575676e-06,
      "loss": 0.1356,
      "step": 3519
    },
    {
      "epoch": 0.055734122900074415,
      "grad_norm": 0.03129332885146141,
      "learning_rate": 9.442658770999257e-06,
      "loss": 0.0008,
      "step": 3520
    },
    {
      "epoch": 0.055749956457716486,
      "grad_norm": 0.1732327789068222,
      "learning_rate": 9.442500435422836e-06,
      "loss": 0.1645,
      "step": 3521
    },
    {
      "epoch": 0.05576579001535855,
      "grad_norm": 0.7172510027885437,
      "learning_rate": 9.442342099846415e-06,
      "loss": 0.0956,
      "step": 3522
    },
    {
      "epoch": 0.055781623573000615,
      "grad_norm": 0.18738576769828796,
      "learning_rate": 9.442183764269994e-06,
      "loss": 0.0092,
      "step": 3523
    },
    {
      "epoch": 0.055797457130642686,
      "grad_norm": 6.343495624605566e-05,
      "learning_rate": 9.442025428693575e-06,
      "loss": 0.0,
      "step": 3524
    },
    {
      "epoch": 0.05581329068828475,
      "grad_norm": 0.46862050890922546,
      "learning_rate": 9.441867093117152e-06,
      "loss": 0.6778,
      "step": 3525
    },
    {
      "epoch": 0.055829124245926814,
      "grad_norm": 0.13058781623840332,
      "learning_rate": 9.441708757540733e-06,
      "loss": 0.0504,
      "step": 3526
    },
    {
      "epoch": 0.055844957803568886,
      "grad_norm": 0.19064989686012268,
      "learning_rate": 9.441550421964312e-06,
      "loss": 0.0959,
      "step": 3527
    },
    {
      "epoch": 0.05586079136121095,
      "grad_norm": 0.006185241974890232,
      "learning_rate": 9.441392086387891e-06,
      "loss": 0.0003,
      "step": 3528
    },
    {
      "epoch": 0.055876624918853014,
      "grad_norm": 0.013256008736789227,
      "learning_rate": 9.44123375081147e-06,
      "loss": 0.0005,
      "step": 3529
    },
    {
      "epoch": 0.055892458476495085,
      "grad_norm": 0.31843751668930054,
      "learning_rate": 9.44107541523505e-06,
      "loss": 0.1674,
      "step": 3530
    },
    {
      "epoch": 0.05590829203413715,
      "grad_norm": 0.17077159881591797,
      "learning_rate": 9.440917079658629e-06,
      "loss": 0.1526,
      "step": 3531
    },
    {
      "epoch": 0.055924125591779214,
      "grad_norm": 0.14118921756744385,
      "learning_rate": 9.44075874408221e-06,
      "loss": 0.0573,
      "step": 3532
    },
    {
      "epoch": 0.055939959149421285,
      "grad_norm": 0.31561416387557983,
      "learning_rate": 9.440600408505788e-06,
      "loss": 0.263,
      "step": 3533
    },
    {
      "epoch": 0.05595579270706335,
      "grad_norm": 0.01808815449476242,
      "learning_rate": 9.440442072929368e-06,
      "loss": 0.0009,
      "step": 3534
    },
    {
      "epoch": 0.055971626264705414,
      "grad_norm": 0.011967746540904045,
      "learning_rate": 9.440283737352947e-06,
      "loss": 0.0007,
      "step": 3535
    },
    {
      "epoch": 0.055987459822347485,
      "grad_norm": 0.26227474212646484,
      "learning_rate": 9.440125401776526e-06,
      "loss": 0.487,
      "step": 3536
    },
    {
      "epoch": 0.05600329337998955,
      "grad_norm": 0.14896312355995178,
      "learning_rate": 9.439967066200105e-06,
      "loss": 0.0911,
      "step": 3537
    },
    {
      "epoch": 0.056019126937631614,
      "grad_norm": 0.424805611371994,
      "learning_rate": 9.439808730623684e-06,
      "loss": 0.4071,
      "step": 3538
    },
    {
      "epoch": 0.056034960495273685,
      "grad_norm": 0.12433633208274841,
      "learning_rate": 9.439650395047265e-06,
      "loss": 0.0502,
      "step": 3539
    },
    {
      "epoch": 0.05605079405291575,
      "grad_norm": 0.8235902190208435,
      "learning_rate": 9.439492059470842e-06,
      "loss": 0.6858,
      "step": 3540
    },
    {
      "epoch": 0.05606662761055781,
      "grad_norm": 0.49171680212020874,
      "learning_rate": 9.439333723894423e-06,
      "loss": 0.5691,
      "step": 3541
    },
    {
      "epoch": 0.056082461168199885,
      "grad_norm": 0.4303925633430481,
      "learning_rate": 9.439175388318002e-06,
      "loss": 0.6412,
      "step": 3542
    },
    {
      "epoch": 0.05609829472584195,
      "grad_norm": 0.09903369098901749,
      "learning_rate": 9.439017052741581e-06,
      "loss": 0.0484,
      "step": 3543
    },
    {
      "epoch": 0.05611412828348401,
      "grad_norm": 0.2390260249376297,
      "learning_rate": 9.43885871716516e-06,
      "loss": 0.1601,
      "step": 3544
    },
    {
      "epoch": 0.056129961841126084,
      "grad_norm": 0.026289187371730804,
      "learning_rate": 9.43870038158874e-06,
      "loss": 0.0021,
      "step": 3545
    },
    {
      "epoch": 0.05614579539876815,
      "grad_norm": 0.3439216911792755,
      "learning_rate": 9.438542046012318e-06,
      "loss": 0.6925,
      "step": 3546
    },
    {
      "epoch": 0.05616162895641021,
      "grad_norm": 0.49038687348365784,
      "learning_rate": 9.438383710435899e-06,
      "loss": 0.2084,
      "step": 3547
    },
    {
      "epoch": 0.056177462514052284,
      "grad_norm": 0.29508793354034424,
      "learning_rate": 9.438225374859478e-06,
      "loss": 0.1786,
      "step": 3548
    },
    {
      "epoch": 0.05619329607169435,
      "grad_norm": 0.001107859774492681,
      "learning_rate": 9.438067039283057e-06,
      "loss": 0.0,
      "step": 3549
    },
    {
      "epoch": 0.05620912962933641,
      "grad_norm": 0.203241229057312,
      "learning_rate": 9.437908703706636e-06,
      "loss": 0.571,
      "step": 3550
    },
    {
      "epoch": 0.056224963186978484,
      "grad_norm": 0.0062557109631598,
      "learning_rate": 9.437750368130217e-06,
      "loss": 0.0003,
      "step": 3551
    },
    {
      "epoch": 0.05624079674462055,
      "grad_norm": 0.02199411764740944,
      "learning_rate": 9.437592032553794e-06,
      "loss": 0.0017,
      "step": 3552
    },
    {
      "epoch": 0.05625663030226261,
      "grad_norm": 0.4745028614997864,
      "learning_rate": 9.437433696977375e-06,
      "loss": 0.2549,
      "step": 3553
    },
    {
      "epoch": 0.056272463859904684,
      "grad_norm": 0.15455344319343567,
      "learning_rate": 9.437275361400954e-06,
      "loss": 0.0647,
      "step": 3554
    },
    {
      "epoch": 0.05628829741754675,
      "grad_norm": 0.17911481857299805,
      "learning_rate": 9.437117025824533e-06,
      "loss": 0.0302,
      "step": 3555
    },
    {
      "epoch": 0.05630413097518881,
      "grad_norm": 0.188189297914505,
      "learning_rate": 9.436958690248112e-06,
      "loss": 0.092,
      "step": 3556
    },
    {
      "epoch": 0.056319964532830884,
      "grad_norm": 0.268009215593338,
      "learning_rate": 9.436800354671693e-06,
      "loss": 0.4855,
      "step": 3557
    },
    {
      "epoch": 0.05633579809047295,
      "grad_norm": 0.20523130893707275,
      "learning_rate": 9.43664201909527e-06,
      "loss": 0.0848,
      "step": 3558
    },
    {
      "epoch": 0.05635163164811501,
      "grad_norm": 0.4772661030292511,
      "learning_rate": 9.436483683518851e-06,
      "loss": 1.0994,
      "step": 3559
    },
    {
      "epoch": 0.056367465205757084,
      "grad_norm": 0.3653634488582611,
      "learning_rate": 9.43632534794243e-06,
      "loss": 0.3547,
      "step": 3560
    },
    {
      "epoch": 0.05638329876339915,
      "grad_norm": 0.5744121074676514,
      "learning_rate": 9.43616701236601e-06,
      "loss": 0.3235,
      "step": 3561
    },
    {
      "epoch": 0.05639913232104121,
      "grad_norm": 0.2666742503643036,
      "learning_rate": 9.436008676789589e-06,
      "loss": 0.1646,
      "step": 3562
    },
    {
      "epoch": 0.05641496587868328,
      "grad_norm": 0.10805090516805649,
      "learning_rate": 9.435850341213168e-06,
      "loss": 0.0047,
      "step": 3563
    },
    {
      "epoch": 0.05643079943632535,
      "grad_norm": 0.3359188139438629,
      "learning_rate": 9.435692005636747e-06,
      "loss": 0.2676,
      "step": 3564
    },
    {
      "epoch": 0.05644663299396741,
      "grad_norm": 0.22805725038051605,
      "learning_rate": 9.435533670060326e-06,
      "loss": 0.124,
      "step": 3565
    },
    {
      "epoch": 0.05646246655160948,
      "grad_norm": 0.009311248548328876,
      "learning_rate": 9.435375334483907e-06,
      "loss": 0.0005,
      "step": 3566
    },
    {
      "epoch": 0.05647830010925155,
      "grad_norm": 0.11996836960315704,
      "learning_rate": 9.435216998907486e-06,
      "loss": 0.0192,
      "step": 3567
    },
    {
      "epoch": 0.05649413366689361,
      "grad_norm": 0.31131625175476074,
      "learning_rate": 9.435058663331065e-06,
      "loss": 0.1641,
      "step": 3568
    },
    {
      "epoch": 0.05650996722453568,
      "grad_norm": 0.006351866759359837,
      "learning_rate": 9.434900327754644e-06,
      "loss": 0.0003,
      "step": 3569
    },
    {
      "epoch": 0.05652580078217775,
      "grad_norm": 0.15520866215229034,
      "learning_rate": 9.434741992178223e-06,
      "loss": 0.0491,
      "step": 3570
    },
    {
      "epoch": 0.05654163433981981,
      "grad_norm": 0.24156427383422852,
      "learning_rate": 9.434583656601802e-06,
      "loss": 0.3197,
      "step": 3571
    },
    {
      "epoch": 0.05655746789746188,
      "grad_norm": 0.00019221461843699217,
      "learning_rate": 9.434425321025383e-06,
      "loss": 0.0,
      "step": 3572
    },
    {
      "epoch": 0.05657330145510395,
      "grad_norm": 0.5878669023513794,
      "learning_rate": 9.434266985448962e-06,
      "loss": 0.1396,
      "step": 3573
    },
    {
      "epoch": 0.05658913501274601,
      "grad_norm": 0.1371145397424698,
      "learning_rate": 9.434108649872541e-06,
      "loss": 0.1175,
      "step": 3574
    },
    {
      "epoch": 0.05660496857038808,
      "grad_norm": 0.1800488829612732,
      "learning_rate": 9.43395031429612e-06,
      "loss": 0.0569,
      "step": 3575
    },
    {
      "epoch": 0.05662080212803015,
      "grad_norm": 0.35042229294776917,
      "learning_rate": 9.433791978719699e-06,
      "loss": 0.2185,
      "step": 3576
    },
    {
      "epoch": 0.05663663568567221,
      "grad_norm": 0.025806717574596405,
      "learning_rate": 9.433633643143278e-06,
      "loss": 0.0022,
      "step": 3577
    },
    {
      "epoch": 0.05665246924331428,
      "grad_norm": 0.011353575624525547,
      "learning_rate": 9.433475307566859e-06,
      "loss": 0.0006,
      "step": 3578
    },
    {
      "epoch": 0.05666830280095635,
      "grad_norm": 0.1401538997888565,
      "learning_rate": 9.433316971990438e-06,
      "loss": 0.117,
      "step": 3579
    },
    {
      "epoch": 0.05668413635859841,
      "grad_norm": 0.11763651669025421,
      "learning_rate": 9.433158636414017e-06,
      "loss": 0.0127,
      "step": 3580
    },
    {
      "epoch": 0.05669996991624048,
      "grad_norm": 0.5139588117599487,
      "learning_rate": 9.433000300837596e-06,
      "loss": 0.4033,
      "step": 3581
    },
    {
      "epoch": 0.056715803473882546,
      "grad_norm": 0.3617266118526459,
      "learning_rate": 9.432841965261175e-06,
      "loss": 0.0759,
      "step": 3582
    },
    {
      "epoch": 0.05673163703152461,
      "grad_norm": 0.02062324434518814,
      "learning_rate": 9.432683629684754e-06,
      "loss": 0.0028,
      "step": 3583
    },
    {
      "epoch": 0.05674747058916668,
      "grad_norm": 0.5094500184059143,
      "learning_rate": 9.432525294108335e-06,
      "loss": 0.1025,
      "step": 3584
    },
    {
      "epoch": 0.056763304146808746,
      "grad_norm": 0.1390254944562912,
      "learning_rate": 9.432366958531914e-06,
      "loss": 0.0299,
      "step": 3585
    },
    {
      "epoch": 0.05677913770445081,
      "grad_norm": 9.578585741110146e-05,
      "learning_rate": 9.432208622955492e-06,
      "loss": 0.0,
      "step": 3586
    },
    {
      "epoch": 0.05679497126209288,
      "grad_norm": 0.24588827788829803,
      "learning_rate": 9.432050287379072e-06,
      "loss": 0.1314,
      "step": 3587
    },
    {
      "epoch": 0.056810804819734946,
      "grad_norm": 0.011654476635158062,
      "learning_rate": 9.431891951802651e-06,
      "loss": 0.0007,
      "step": 3588
    },
    {
      "epoch": 0.05682663837737701,
      "grad_norm": 0.2578181326389313,
      "learning_rate": 9.43173361622623e-06,
      "loss": 0.1185,
      "step": 3589
    },
    {
      "epoch": 0.05684247193501908,
      "grad_norm": 0.002922080922871828,
      "learning_rate": 9.43157528064981e-06,
      "loss": 0.0001,
      "step": 3590
    },
    {
      "epoch": 0.056858305492661146,
      "grad_norm": 0.3204590082168579,
      "learning_rate": 9.431416945073389e-06,
      "loss": 0.2684,
      "step": 3591
    },
    {
      "epoch": 0.05687413905030321,
      "grad_norm": 0.09225279092788696,
      "learning_rate": 9.431258609496968e-06,
      "loss": 0.0697,
      "step": 3592
    },
    {
      "epoch": 0.05688997260794528,
      "grad_norm": 0.3783979117870331,
      "learning_rate": 9.431100273920548e-06,
      "loss": 0.9282,
      "step": 3593
    },
    {
      "epoch": 0.056905806165587346,
      "grad_norm": 0.3226949870586395,
      "learning_rate": 9.430941938344128e-06,
      "loss": 0.21,
      "step": 3594
    },
    {
      "epoch": 0.05692163972322941,
      "grad_norm": 0.426537424325943,
      "learning_rate": 9.430783602767707e-06,
      "loss": 0.3638,
      "step": 3595
    },
    {
      "epoch": 0.05693747328087148,
      "grad_norm": 0.11329386383295059,
      "learning_rate": 9.430625267191286e-06,
      "loss": 0.0123,
      "step": 3596
    },
    {
      "epoch": 0.056953306838513545,
      "grad_norm": 0.22644157707691193,
      "learning_rate": 9.430466931614865e-06,
      "loss": 0.1753,
      "step": 3597
    },
    {
      "epoch": 0.05696914039615561,
      "grad_norm": 0.015796774998307228,
      "learning_rate": 9.430308596038444e-06,
      "loss": 0.0008,
      "step": 3598
    },
    {
      "epoch": 0.05698497395379768,
      "grad_norm": 0.3102082312107086,
      "learning_rate": 9.430150260462025e-06,
      "loss": 0.0978,
      "step": 3599
    },
    {
      "epoch": 0.057000807511439745,
      "grad_norm": 0.4148620367050171,
      "learning_rate": 9.429991924885604e-06,
      "loss": 0.5357,
      "step": 3600
    },
    {
      "epoch": 0.05701664106908181,
      "grad_norm": 0.12311948835849762,
      "learning_rate": 9.429833589309183e-06,
      "loss": 0.0085,
      "step": 3601
    },
    {
      "epoch": 0.05703247462672388,
      "grad_norm": 0.0001676834945101291,
      "learning_rate": 9.429675253732762e-06,
      "loss": 0.0,
      "step": 3602
    },
    {
      "epoch": 0.057048308184365945,
      "grad_norm": 0.44018927216529846,
      "learning_rate": 9.429516918156341e-06,
      "loss": 0.0835,
      "step": 3603
    },
    {
      "epoch": 0.05706414174200801,
      "grad_norm": 0.308912456035614,
      "learning_rate": 9.42935858257992e-06,
      "loss": 0.2353,
      "step": 3604
    },
    {
      "epoch": 0.05707997529965008,
      "grad_norm": 0.3848230540752411,
      "learning_rate": 9.4292002470035e-06,
      "loss": 0.5928,
      "step": 3605
    },
    {
      "epoch": 0.057095808857292145,
      "grad_norm": 0.42420879006385803,
      "learning_rate": 9.42904191142708e-06,
      "loss": 0.046,
      "step": 3606
    },
    {
      "epoch": 0.05711164241493421,
      "grad_norm": 0.4007910490036011,
      "learning_rate": 9.428883575850659e-06,
      "loss": 0.3674,
      "step": 3607
    },
    {
      "epoch": 0.05712747597257628,
      "grad_norm": 0.20209935307502747,
      "learning_rate": 9.428725240274238e-06,
      "loss": 0.2901,
      "step": 3608
    },
    {
      "epoch": 0.057143309530218345,
      "grad_norm": 0.0012100618332624435,
      "learning_rate": 9.428566904697817e-06,
      "loss": 0.0001,
      "step": 3609
    },
    {
      "epoch": 0.05715914308786041,
      "grad_norm": 0.13698498904705048,
      "learning_rate": 9.428408569121396e-06,
      "loss": 0.0355,
      "step": 3610
    },
    {
      "epoch": 0.05717497664550248,
      "grad_norm": 0.30622097849845886,
      "learning_rate": 9.428250233544975e-06,
      "loss": 0.1821,
      "step": 3611
    },
    {
      "epoch": 0.057190810203144544,
      "grad_norm": 0.007524773012846708,
      "learning_rate": 9.428091897968556e-06,
      "loss": 0.0004,
      "step": 3612
    },
    {
      "epoch": 0.05720664376078661,
      "grad_norm": 0.0017621505539864302,
      "learning_rate": 9.427933562392133e-06,
      "loss": 0.0001,
      "step": 3613
    },
    {
      "epoch": 0.05722247731842868,
      "grad_norm": 0.21943533420562744,
      "learning_rate": 9.427775226815714e-06,
      "loss": 0.1806,
      "step": 3614
    },
    {
      "epoch": 0.057238310876070744,
      "grad_norm": 0.007020101882517338,
      "learning_rate": 9.427616891239293e-06,
      "loss": 0.0003,
      "step": 3615
    },
    {
      "epoch": 0.05725414443371281,
      "grad_norm": 0.4663848578929901,
      "learning_rate": 9.427458555662872e-06,
      "loss": 0.3517,
      "step": 3616
    },
    {
      "epoch": 0.05726997799135488,
      "grad_norm": 0.274734228849411,
      "learning_rate": 9.427300220086451e-06,
      "loss": 0.2012,
      "step": 3617
    },
    {
      "epoch": 0.057285811548996944,
      "grad_norm": 0.018050307407975197,
      "learning_rate": 9.427141884510032e-06,
      "loss": 0.001,
      "step": 3618
    },
    {
      "epoch": 0.05730164510663901,
      "grad_norm": 0.09305021166801453,
      "learning_rate": 9.42698354893361e-06,
      "loss": 0.0329,
      "step": 3619
    },
    {
      "epoch": 0.05731747866428108,
      "grad_norm": 0.022766519337892532,
      "learning_rate": 9.42682521335719e-06,
      "loss": 0.0015,
      "step": 3620
    },
    {
      "epoch": 0.057333312221923144,
      "grad_norm": 0.5102868676185608,
      "learning_rate": 9.42666687778077e-06,
      "loss": 0.2059,
      "step": 3621
    },
    {
      "epoch": 0.05734914577956521,
      "grad_norm": 0.6979836225509644,
      "learning_rate": 9.426508542204349e-06,
      "loss": 0.1248,
      "step": 3622
    },
    {
      "epoch": 0.05736497933720728,
      "grad_norm": 0.021876327693462372,
      "learning_rate": 9.426350206627928e-06,
      "loss": 0.0014,
      "step": 3623
    },
    {
      "epoch": 0.057380812894849344,
      "grad_norm": 3.750854969024658,
      "learning_rate": 9.426191871051508e-06,
      "loss": 0.0814,
      "step": 3624
    },
    {
      "epoch": 0.05739664645249141,
      "grad_norm": 0.2814846634864807,
      "learning_rate": 9.426033535475086e-06,
      "loss": 0.1364,
      "step": 3625
    },
    {
      "epoch": 0.05741248001013348,
      "grad_norm": 0.27761614322662354,
      "learning_rate": 9.425875199898667e-06,
      "loss": 0.1982,
      "step": 3626
    },
    {
      "epoch": 0.057428313567775544,
      "grad_norm": 0.2502862215042114,
      "learning_rate": 9.425716864322246e-06,
      "loss": 0.2165,
      "step": 3627
    },
    {
      "epoch": 0.05744414712541761,
      "grad_norm": 0.25855058431625366,
      "learning_rate": 9.425558528745825e-06,
      "loss": 0.0437,
      "step": 3628
    },
    {
      "epoch": 0.05745998068305968,
      "grad_norm": 0.3332817852497101,
      "learning_rate": 9.425400193169404e-06,
      "loss": 0.4008,
      "step": 3629
    },
    {
      "epoch": 0.05747581424070174,
      "grad_norm": 0.3037518858909607,
      "learning_rate": 9.425241857592985e-06,
      "loss": 0.2082,
      "step": 3630
    },
    {
      "epoch": 0.05749164779834381,
      "grad_norm": 0.05574093014001846,
      "learning_rate": 9.425083522016562e-06,
      "loss": 0.0062,
      "step": 3631
    },
    {
      "epoch": 0.05750748135598588,
      "grad_norm": 0.2911357581615448,
      "learning_rate": 9.424925186440143e-06,
      "loss": 0.1488,
      "step": 3632
    },
    {
      "epoch": 0.05752331491362794,
      "grad_norm": 0.23703131079673767,
      "learning_rate": 9.424766850863722e-06,
      "loss": 0.2263,
      "step": 3633
    },
    {
      "epoch": 0.05753914847127001,
      "grad_norm": 0.13801543414592743,
      "learning_rate": 9.424608515287301e-06,
      "loss": 0.0467,
      "step": 3634
    },
    {
      "epoch": 0.05755498202891208,
      "grad_norm": 0.24239112436771393,
      "learning_rate": 9.42445017971088e-06,
      "loss": 0.1683,
      "step": 3635
    },
    {
      "epoch": 0.05757081558655414,
      "grad_norm": 0.006341941654682159,
      "learning_rate": 9.424291844134459e-06,
      "loss": 0.0004,
      "step": 3636
    },
    {
      "epoch": 0.05758664914419621,
      "grad_norm": 0.3256123661994934,
      "learning_rate": 9.424133508558038e-06,
      "loss": 0.0419,
      "step": 3637
    },
    {
      "epoch": 0.05760248270183828,
      "grad_norm": 0.2049756646156311,
      "learning_rate": 9.423975172981617e-06,
      "loss": 0.4443,
      "step": 3638
    },
    {
      "epoch": 0.05761831625948034,
      "grad_norm": 0.3160145878791809,
      "learning_rate": 9.423816837405198e-06,
      "loss": 0.6797,
      "step": 3639
    },
    {
      "epoch": 0.05763414981712241,
      "grad_norm": 0.20259420573711395,
      "learning_rate": 9.423658501828777e-06,
      "loss": 0.0732,
      "step": 3640
    },
    {
      "epoch": 0.05764998337476448,
      "grad_norm": 0.2349012792110443,
      "learning_rate": 9.423500166252356e-06,
      "loss": 0.2777,
      "step": 3641
    },
    {
      "epoch": 0.05766581693240654,
      "grad_norm": 0.36133840680122375,
      "learning_rate": 9.423341830675935e-06,
      "loss": 0.1021,
      "step": 3642
    },
    {
      "epoch": 0.05768165049004861,
      "grad_norm": 0.0220938827842474,
      "learning_rate": 9.423183495099514e-06,
      "loss": 0.0015,
      "step": 3643
    },
    {
      "epoch": 0.05769748404769068,
      "grad_norm": 0.005010717082768679,
      "learning_rate": 9.423025159523093e-06,
      "loss": 0.0003,
      "step": 3644
    },
    {
      "epoch": 0.05771331760533274,
      "grad_norm": 0.5049583315849304,
      "learning_rate": 9.422866823946674e-06,
      "loss": 0.4504,
      "step": 3645
    },
    {
      "epoch": 0.05772915116297481,
      "grad_norm": 0.29983896017074585,
      "learning_rate": 9.422708488370253e-06,
      "loss": 0.186,
      "step": 3646
    },
    {
      "epoch": 0.05774498472061688,
      "grad_norm": 0.4857485294342041,
      "learning_rate": 9.422550152793832e-06,
      "loss": 0.064,
      "step": 3647
    },
    {
      "epoch": 0.05776081827825894,
      "grad_norm": 0.23706568777561188,
      "learning_rate": 9.422391817217411e-06,
      "loss": 0.0403,
      "step": 3648
    },
    {
      "epoch": 0.057776651835901006,
      "grad_norm": 0.26255273818969727,
      "learning_rate": 9.42223348164099e-06,
      "loss": 0.2526,
      "step": 3649
    },
    {
      "epoch": 0.05779248539354308,
      "grad_norm": 0.14497238397598267,
      "learning_rate": 9.42207514606457e-06,
      "loss": 0.112,
      "step": 3650
    },
    {
      "epoch": 0.05780831895118514,
      "grad_norm": 0.006176151800900698,
      "learning_rate": 9.42191681048815e-06,
      "loss": 0.0004,
      "step": 3651
    },
    {
      "epoch": 0.057824152508827206,
      "grad_norm": 0.47209957242012024,
      "learning_rate": 9.42175847491173e-06,
      "loss": 0.1696,
      "step": 3652
    },
    {
      "epoch": 0.05783998606646928,
      "grad_norm": 0.22231604158878326,
      "learning_rate": 9.421600139335308e-06,
      "loss": 0.4528,
      "step": 3653
    },
    {
      "epoch": 0.05785581962411134,
      "grad_norm": 0.2978239953517914,
      "learning_rate": 9.421441803758888e-06,
      "loss": 0.0431,
      "step": 3654
    },
    {
      "epoch": 0.057871653181753406,
      "grad_norm": 0.35163918137550354,
      "learning_rate": 9.421283468182467e-06,
      "loss": 0.0331,
      "step": 3655
    },
    {
      "epoch": 0.05788748673939548,
      "grad_norm": 0.20986106991767883,
      "learning_rate": 9.421125132606046e-06,
      "loss": 0.2941,
      "step": 3656
    },
    {
      "epoch": 0.05790332029703754,
      "grad_norm": 0.251790851354599,
      "learning_rate": 9.420966797029626e-06,
      "loss": 0.0565,
      "step": 3657
    },
    {
      "epoch": 0.057919153854679606,
      "grad_norm": 0.5616403818130493,
      "learning_rate": 9.420808461453204e-06,
      "loss": 0.6475,
      "step": 3658
    },
    {
      "epoch": 0.05793498741232168,
      "grad_norm": 0.18472838401794434,
      "learning_rate": 9.420650125876783e-06,
      "loss": 0.3294,
      "step": 3659
    },
    {
      "epoch": 0.05795082096996374,
      "grad_norm": 0.336902916431427,
      "learning_rate": 9.420491790300364e-06,
      "loss": 0.0292,
      "step": 3660
    },
    {
      "epoch": 0.057966654527605806,
      "grad_norm": 0.2854618430137634,
      "learning_rate": 9.420333454723943e-06,
      "loss": 0.5923,
      "step": 3661
    },
    {
      "epoch": 0.05798248808524788,
      "grad_norm": 0.010154848918318748,
      "learning_rate": 9.420175119147522e-06,
      "loss": 0.0008,
      "step": 3662
    },
    {
      "epoch": 0.05799832164288994,
      "grad_norm": 0.017831815406680107,
      "learning_rate": 9.420016783571101e-06,
      "loss": 0.0011,
      "step": 3663
    },
    {
      "epoch": 0.058014155200532005,
      "grad_norm": 0.0020312312990427017,
      "learning_rate": 9.41985844799468e-06,
      "loss": 0.0001,
      "step": 3664
    },
    {
      "epoch": 0.05802998875817408,
      "grad_norm": 0.0910395085811615,
      "learning_rate": 9.419700112418259e-06,
      "loss": 0.0055,
      "step": 3665
    },
    {
      "epoch": 0.05804582231581614,
      "grad_norm": 0.27957770228385925,
      "learning_rate": 9.41954177684184e-06,
      "loss": 0.0576,
      "step": 3666
    },
    {
      "epoch": 0.058061655873458205,
      "grad_norm": 0.48845240473747253,
      "learning_rate": 9.419383441265419e-06,
      "loss": 0.2988,
      "step": 3667
    },
    {
      "epoch": 0.058077489431100277,
      "grad_norm": 0.3065060079097748,
      "learning_rate": 9.419225105688998e-06,
      "loss": 0.0434,
      "step": 3668
    },
    {
      "epoch": 0.05809332298874234,
      "grad_norm": 0.5826291441917419,
      "learning_rate": 9.419066770112577e-06,
      "loss": 0.255,
      "step": 3669
    },
    {
      "epoch": 0.058109156546384405,
      "grad_norm": 0.19883877038955688,
      "learning_rate": 9.418908434536156e-06,
      "loss": 0.0575,
      "step": 3670
    },
    {
      "epoch": 0.058124990104026476,
      "grad_norm": 0.2143358290195465,
      "learning_rate": 9.418750098959735e-06,
      "loss": 0.1024,
      "step": 3671
    },
    {
      "epoch": 0.05814082366166854,
      "grad_norm": 0.19235648214817047,
      "learning_rate": 9.418591763383316e-06,
      "loss": 0.296,
      "step": 3672
    },
    {
      "epoch": 0.058156657219310605,
      "grad_norm": 0.0002508030738681555,
      "learning_rate": 9.418433427806895e-06,
      "loss": 0.0,
      "step": 3673
    },
    {
      "epoch": 0.058172490776952676,
      "grad_norm": 0.26873570680618286,
      "learning_rate": 9.418275092230474e-06,
      "loss": 0.6966,
      "step": 3674
    },
    {
      "epoch": 0.05818832433459474,
      "grad_norm": 0.4030352532863617,
      "learning_rate": 9.418116756654053e-06,
      "loss": 0.2869,
      "step": 3675
    },
    {
      "epoch": 0.058204157892236805,
      "grad_norm": 0.1953803449869156,
      "learning_rate": 9.417958421077632e-06,
      "loss": 0.1183,
      "step": 3676
    },
    {
      "epoch": 0.058219991449878876,
      "grad_norm": 0.29964300990104675,
      "learning_rate": 9.417800085501211e-06,
      "loss": 0.113,
      "step": 3677
    },
    {
      "epoch": 0.05823582500752094,
      "grad_norm": 0.035687003284692764,
      "learning_rate": 9.417641749924792e-06,
      "loss": 0.0024,
      "step": 3678
    },
    {
      "epoch": 0.058251658565163004,
      "grad_norm": 0.4557175934314728,
      "learning_rate": 9.417483414348371e-06,
      "loss": 0.5027,
      "step": 3679
    },
    {
      "epoch": 0.058267492122805076,
      "grad_norm": 0.15468856692314148,
      "learning_rate": 9.41732507877195e-06,
      "loss": 0.1339,
      "step": 3680
    },
    {
      "epoch": 0.05828332568044714,
      "grad_norm": 0.29192814230918884,
      "learning_rate": 9.41716674319553e-06,
      "loss": 0.0269,
      "step": 3681
    },
    {
      "epoch": 0.058299159238089204,
      "grad_norm": 0.8943203091621399,
      "learning_rate": 9.417008407619109e-06,
      "loss": 0.3666,
      "step": 3682
    },
    {
      "epoch": 0.058314992795731276,
      "grad_norm": 0.23288390040397644,
      "learning_rate": 9.416850072042688e-06,
      "loss": 0.059,
      "step": 3683
    },
    {
      "epoch": 0.05833082635337334,
      "grad_norm": 4.5161868911236525e-05,
      "learning_rate": 9.416691736466267e-06,
      "loss": 0.0,
      "step": 3684
    },
    {
      "epoch": 0.058346659911015404,
      "grad_norm": 0.011277991347014904,
      "learning_rate": 9.416533400889847e-06,
      "loss": 0.0005,
      "step": 3685
    },
    {
      "epoch": 0.058362493468657475,
      "grad_norm": 0.21141745150089264,
      "learning_rate": 9.416375065313425e-06,
      "loss": 0.0724,
      "step": 3686
    },
    {
      "epoch": 0.05837832702629954,
      "grad_norm": 0.6432041525840759,
      "learning_rate": 9.416216729737006e-06,
      "loss": 0.6402,
      "step": 3687
    },
    {
      "epoch": 0.058394160583941604,
      "grad_norm": 0.3400830924510956,
      "learning_rate": 9.416058394160585e-06,
      "loss": 0.3759,
      "step": 3688
    },
    {
      "epoch": 0.058409994141583675,
      "grad_norm": 0.22397799789905548,
      "learning_rate": 9.415900058584164e-06,
      "loss": 0.1199,
      "step": 3689
    },
    {
      "epoch": 0.05842582769922574,
      "grad_norm": 0.33638641238212585,
      "learning_rate": 9.415741723007743e-06,
      "loss": 0.1861,
      "step": 3690
    },
    {
      "epoch": 0.058441661256867804,
      "grad_norm": 0.19980676472187042,
      "learning_rate": 9.415583387431324e-06,
      "loss": 0.0502,
      "step": 3691
    },
    {
      "epoch": 0.058457494814509875,
      "grad_norm": 0.36136165261268616,
      "learning_rate": 9.415425051854901e-06,
      "loss": 0.0403,
      "step": 3692
    },
    {
      "epoch": 0.05847332837215194,
      "grad_norm": 0.06877899914979935,
      "learning_rate": 9.415266716278482e-06,
      "loss": 0.0059,
      "step": 3693
    },
    {
      "epoch": 0.058489161929794004,
      "grad_norm": 0.1931696981191635,
      "learning_rate": 9.415108380702061e-06,
      "loss": 0.0543,
      "step": 3694
    },
    {
      "epoch": 0.058504995487436075,
      "grad_norm": 0.23995403945446014,
      "learning_rate": 9.41495004512564e-06,
      "loss": 0.142,
      "step": 3695
    },
    {
      "epoch": 0.05852082904507814,
      "grad_norm": 0.4247558116912842,
      "learning_rate": 9.414791709549219e-06,
      "loss": 0.1505,
      "step": 3696
    },
    {
      "epoch": 0.0585366626027202,
      "grad_norm": 0.7226775884628296,
      "learning_rate": 9.4146333739728e-06,
      "loss": 1.0616,
      "step": 3697
    },
    {
      "epoch": 0.058552496160362275,
      "grad_norm": 0.4213804304599762,
      "learning_rate": 9.414475038396377e-06,
      "loss": 0.1601,
      "step": 3698
    },
    {
      "epoch": 0.05856832971800434,
      "grad_norm": 0.00011795275349868461,
      "learning_rate": 9.414316702819958e-06,
      "loss": 0.0,
      "step": 3699
    },
    {
      "epoch": 0.0585841632756464,
      "grad_norm": 0.2224385142326355,
      "learning_rate": 9.414158367243537e-06,
      "loss": 0.0729,
      "step": 3700
    },
    {
      "epoch": 0.058599996833288474,
      "grad_norm": 0.35071203112602234,
      "learning_rate": 9.414000031667116e-06,
      "loss": 0.162,
      "step": 3701
    },
    {
      "epoch": 0.05861583039093054,
      "grad_norm": 0.288116455078125,
      "learning_rate": 9.413841696090695e-06,
      "loss": 0.1195,
      "step": 3702
    },
    {
      "epoch": 0.0586316639485726,
      "grad_norm": 1.1660938262939453,
      "learning_rate": 9.413683360514276e-06,
      "loss": 0.0263,
      "step": 3703
    },
    {
      "epoch": 0.058647497506214674,
      "grad_norm": 0.013677839189767838,
      "learning_rate": 9.413525024937853e-06,
      "loss": 0.0007,
      "step": 3704
    },
    {
      "epoch": 0.05866333106385674,
      "grad_norm": 0.20646654069423676,
      "learning_rate": 9.413366689361434e-06,
      "loss": 0.2131,
      "step": 3705
    },
    {
      "epoch": 0.0586791646214988,
      "grad_norm": 0.2349117547273636,
      "learning_rate": 9.413208353785013e-06,
      "loss": 0.1639,
      "step": 3706
    },
    {
      "epoch": 0.058694998179140874,
      "grad_norm": 0.09474142640829086,
      "learning_rate": 9.413050018208592e-06,
      "loss": 0.0473,
      "step": 3707
    },
    {
      "epoch": 0.05871083173678294,
      "grad_norm": 0.017055755481123924,
      "learning_rate": 9.412891682632171e-06,
      "loss": 0.0011,
      "step": 3708
    },
    {
      "epoch": 0.058726665294425,
      "grad_norm": 0.35176974534988403,
      "learning_rate": 9.41273334705575e-06,
      "loss": 0.2657,
      "step": 3709
    },
    {
      "epoch": 0.058742498852067074,
      "grad_norm": 0.23964764177799225,
      "learning_rate": 9.41257501147933e-06,
      "loss": 0.1849,
      "step": 3710
    },
    {
      "epoch": 0.05875833240970914,
      "grad_norm": 0.40371936559677124,
      "learning_rate": 9.412416675902909e-06,
      "loss": 0.0437,
      "step": 3711
    },
    {
      "epoch": 0.0587741659673512,
      "grad_norm": 0.2890546917915344,
      "learning_rate": 9.41225834032649e-06,
      "loss": 0.1473,
      "step": 3712
    },
    {
      "epoch": 0.058789999524993274,
      "grad_norm": 0.003772428957745433,
      "learning_rate": 9.412100004750069e-06,
      "loss": 0.0001,
      "step": 3713
    },
    {
      "epoch": 0.05880583308263534,
      "grad_norm": 0.32766193151474,
      "learning_rate": 9.411941669173648e-06,
      "loss": 0.173,
      "step": 3714
    },
    {
      "epoch": 0.0588216666402774,
      "grad_norm": 0.17067934572696686,
      "learning_rate": 9.411783333597227e-06,
      "loss": 0.2354,
      "step": 3715
    },
    {
      "epoch": 0.05883750019791947,
      "grad_norm": 0.27586954832077026,
      "learning_rate": 9.411624998020806e-06,
      "loss": 0.1683,
      "step": 3716
    },
    {
      "epoch": 0.05885333375556154,
      "grad_norm": 0.2344599813222885,
      "learning_rate": 9.411466662444385e-06,
      "loss": 0.1991,
      "step": 3717
    },
    {
      "epoch": 0.0588691673132036,
      "grad_norm": 0.0026309771928936243,
      "learning_rate": 9.411308326867966e-06,
      "loss": 0.0001,
      "step": 3718
    },
    {
      "epoch": 0.05888500087084567,
      "grad_norm": 0.0053760698065161705,
      "learning_rate": 9.411149991291545e-06,
      "loss": 0.0001,
      "step": 3719
    },
    {
      "epoch": 0.05890083442848774,
      "grad_norm": 0.3102704584598541,
      "learning_rate": 9.410991655715124e-06,
      "loss": 0.461,
      "step": 3720
    },
    {
      "epoch": 0.0589166679861298,
      "grad_norm": 0.019329167902469635,
      "learning_rate": 9.410833320138703e-06,
      "loss": 0.001,
      "step": 3721
    },
    {
      "epoch": 0.05893250154377187,
      "grad_norm": 0.016230124980211258,
      "learning_rate": 9.410674984562282e-06,
      "loss": 0.001,
      "step": 3722
    },
    {
      "epoch": 0.05894833510141394,
      "grad_norm": 0.0019499707268550992,
      "learning_rate": 9.410516648985861e-06,
      "loss": 0.0,
      "step": 3723
    },
    {
      "epoch": 0.058964168659056,
      "grad_norm": 0.2908933162689209,
      "learning_rate": 9.410358313409442e-06,
      "loss": 0.11,
      "step": 3724
    },
    {
      "epoch": 0.05898000221669807,
      "grad_norm": 0.19306233525276184,
      "learning_rate": 9.410199977833019e-06,
      "loss": 0.1038,
      "step": 3725
    },
    {
      "epoch": 0.05899583577434014,
      "grad_norm": 0.1328095942735672,
      "learning_rate": 9.4100416422566e-06,
      "loss": 0.049,
      "step": 3726
    },
    {
      "epoch": 0.0590116693319822,
      "grad_norm": 0.5436438918113708,
      "learning_rate": 9.409883306680179e-06,
      "loss": 0.7596,
      "step": 3727
    },
    {
      "epoch": 0.05902750288962427,
      "grad_norm": 0.10573560744524002,
      "learning_rate": 9.409724971103758e-06,
      "loss": 0.0725,
      "step": 3728
    },
    {
      "epoch": 0.05904333644726634,
      "grad_norm": 0.0023519035894423723,
      "learning_rate": 9.409566635527337e-06,
      "loss": 0.0,
      "step": 3729
    },
    {
      "epoch": 0.0590591700049084,
      "grad_norm": 0.6066360473632812,
      "learning_rate": 9.409408299950916e-06,
      "loss": 0.0138,
      "step": 3730
    },
    {
      "epoch": 0.05907500356255047,
      "grad_norm": 0.12105739861726761,
      "learning_rate": 9.409249964374495e-06,
      "loss": 0.0207,
      "step": 3731
    },
    {
      "epoch": 0.05909083712019254,
      "grad_norm": 0.3195386230945587,
      "learning_rate": 9.409091628798074e-06,
      "loss": 0.0814,
      "step": 3732
    },
    {
      "epoch": 0.0591066706778346,
      "grad_norm": 1.594754934310913,
      "learning_rate": 9.408933293221655e-06,
      "loss": 0.0738,
      "step": 3733
    },
    {
      "epoch": 0.05912250423547667,
      "grad_norm": 0.29593926668167114,
      "learning_rate": 9.408774957645234e-06,
      "loss": 0.2505,
      "step": 3734
    },
    {
      "epoch": 0.059138337793118737,
      "grad_norm": 0.18642012774944305,
      "learning_rate": 9.408616622068813e-06,
      "loss": 0.0548,
      "step": 3735
    },
    {
      "epoch": 0.0591541713507608,
      "grad_norm": 0.00010759376164060086,
      "learning_rate": 9.408458286492392e-06,
      "loss": 0.0,
      "step": 3736
    },
    {
      "epoch": 0.05917000490840287,
      "grad_norm": 0.005471395794302225,
      "learning_rate": 9.408299950915971e-06,
      "loss": 0.0003,
      "step": 3737
    },
    {
      "epoch": 0.059185838466044936,
      "grad_norm": 0.27386799454689026,
      "learning_rate": 9.40814161533955e-06,
      "loss": 0.3564,
      "step": 3738
    },
    {
      "epoch": 0.059201672023687,
      "grad_norm": 0.3214533030986786,
      "learning_rate": 9.407983279763131e-06,
      "loss": 0.386,
      "step": 3739
    },
    {
      "epoch": 0.05921750558132907,
      "grad_norm": 0.02847268432378769,
      "learning_rate": 9.40782494418671e-06,
      "loss": 0.0012,
      "step": 3740
    },
    {
      "epoch": 0.059233339138971136,
      "grad_norm": 3.004585232702084e-05,
      "learning_rate": 9.40766660861029e-06,
      "loss": 0.0,
      "step": 3741
    },
    {
      "epoch": 0.0592491726966132,
      "grad_norm": 0.23371411859989166,
      "learning_rate": 9.407508273033869e-06,
      "loss": 0.1315,
      "step": 3742
    },
    {
      "epoch": 0.05926500625425527,
      "grad_norm": 0.40955761075019836,
      "learning_rate": 9.407349937457448e-06,
      "loss": 0.17,
      "step": 3743
    },
    {
      "epoch": 0.059280839811897336,
      "grad_norm": 0.4408082962036133,
      "learning_rate": 9.407191601881027e-06,
      "loss": 0.2471,
      "step": 3744
    },
    {
      "epoch": 0.0592966733695394,
      "grad_norm": 0.14016589522361755,
      "learning_rate": 9.407033266304608e-06,
      "loss": 0.0518,
      "step": 3745
    },
    {
      "epoch": 0.05931250692718147,
      "grad_norm": 0.006533911917358637,
      "learning_rate": 9.406874930728187e-06,
      "loss": 0.0001,
      "step": 3746
    },
    {
      "epoch": 0.059328340484823536,
      "grad_norm": 0.24688932299613953,
      "learning_rate": 9.406716595151766e-06,
      "loss": 0.0887,
      "step": 3747
    },
    {
      "epoch": 0.0593441740424656,
      "grad_norm": 0.41771942377090454,
      "learning_rate": 9.406558259575345e-06,
      "loss": 0.2953,
      "step": 3748
    },
    {
      "epoch": 0.05936000760010767,
      "grad_norm": 0.0715363398194313,
      "learning_rate": 9.406399923998924e-06,
      "loss": 0.0015,
      "step": 3749
    },
    {
      "epoch": 0.059375841157749736,
      "grad_norm": 0.0009680192451924086,
      "learning_rate": 9.406241588422503e-06,
      "loss": 0.0,
      "step": 3750
    },
    {
      "epoch": 0.0593916747153918,
      "grad_norm": 0.2044486105442047,
      "learning_rate": 9.406083252846084e-06,
      "loss": 0.0169,
      "step": 3751
    },
    {
      "epoch": 0.05940750827303387,
      "grad_norm": 0.002024140441790223,
      "learning_rate": 9.405924917269663e-06,
      "loss": 0.0,
      "step": 3752
    },
    {
      "epoch": 0.059423341830675935,
      "grad_norm": 0.014726473018527031,
      "learning_rate": 9.405766581693242e-06,
      "loss": 0.0008,
      "step": 3753
    },
    {
      "epoch": 0.059439175388318,
      "grad_norm": 0.8642147779464722,
      "learning_rate": 9.405608246116821e-06,
      "loss": 0.0996,
      "step": 3754
    },
    {
      "epoch": 0.05945500894596007,
      "grad_norm": 0.231632262468338,
      "learning_rate": 9.4054499105404e-06,
      "loss": 0.3318,
      "step": 3755
    },
    {
      "epoch": 0.059470842503602135,
      "grad_norm": 0.09837011247873306,
      "learning_rate": 9.405291574963979e-06,
      "loss": 0.0087,
      "step": 3756
    },
    {
      "epoch": 0.0594866760612442,
      "grad_norm": 0.22036954760551453,
      "learning_rate": 9.405133239387558e-06,
      "loss": 0.2863,
      "step": 3757
    },
    {
      "epoch": 0.05950250961888627,
      "grad_norm": 0.3364049196243286,
      "learning_rate": 9.404974903811139e-06,
      "loss": 0.8991,
      "step": 3758
    },
    {
      "epoch": 0.059518343176528335,
      "grad_norm": 0.006616545841097832,
      "learning_rate": 9.404816568234716e-06,
      "loss": 0.0003,
      "step": 3759
    },
    {
      "epoch": 0.0595341767341704,
      "grad_norm": 0.007059467025101185,
      "learning_rate": 9.404658232658297e-06,
      "loss": 0.0004,
      "step": 3760
    },
    {
      "epoch": 0.05955001029181247,
      "grad_norm": 0.3639408051967621,
      "learning_rate": 9.404499897081876e-06,
      "loss": 0.0505,
      "step": 3761
    },
    {
      "epoch": 0.059565843849454535,
      "grad_norm": 0.5039525628089905,
      "learning_rate": 9.404341561505455e-06,
      "loss": 0.179,
      "step": 3762
    },
    {
      "epoch": 0.0595816774070966,
      "grad_norm": 5.254705905914307,
      "learning_rate": 9.404183225929034e-06,
      "loss": 0.1978,
      "step": 3763
    },
    {
      "epoch": 0.05959751096473867,
      "grad_norm": 0.03728640079498291,
      "learning_rate": 9.404024890352615e-06,
      "loss": 0.0019,
      "step": 3764
    },
    {
      "epoch": 0.059613344522380735,
      "grad_norm": 0.3662351369857788,
      "learning_rate": 9.403866554776192e-06,
      "loss": 0.0783,
      "step": 3765
    },
    {
      "epoch": 0.0596291780800228,
      "grad_norm": 0.3927861452102661,
      "learning_rate": 9.403708219199773e-06,
      "loss": 0.0586,
      "step": 3766
    },
    {
      "epoch": 0.05964501163766487,
      "grad_norm": 0.21525061130523682,
      "learning_rate": 9.403549883623352e-06,
      "loss": 0.1454,
      "step": 3767
    },
    {
      "epoch": 0.059660845195306934,
      "grad_norm": 0.34506604075431824,
      "learning_rate": 9.403391548046931e-06,
      "loss": 0.263,
      "step": 3768
    },
    {
      "epoch": 0.059676678752949,
      "grad_norm": 0.0003545107028912753,
      "learning_rate": 9.40323321247051e-06,
      "loss": 0.0,
      "step": 3769
    },
    {
      "epoch": 0.05969251231059107,
      "grad_norm": 0.024134714156389236,
      "learning_rate": 9.403074876894091e-06,
      "loss": 0.0021,
      "step": 3770
    },
    {
      "epoch": 0.059708345868233134,
      "grad_norm": 0.25855016708374023,
      "learning_rate": 9.402916541317669e-06,
      "loss": 0.1566,
      "step": 3771
    },
    {
      "epoch": 0.0597241794258752,
      "grad_norm": 5.507135938387364e-05,
      "learning_rate": 9.40275820574125e-06,
      "loss": 0.0,
      "step": 3772
    },
    {
      "epoch": 0.05974001298351727,
      "grad_norm": 0.005804781801998615,
      "learning_rate": 9.402599870164829e-06,
      "loss": 0.0003,
      "step": 3773
    },
    {
      "epoch": 0.059755846541159334,
      "grad_norm": 0.6338958144187927,
      "learning_rate": 9.402441534588408e-06,
      "loss": 0.3775,
      "step": 3774
    },
    {
      "epoch": 0.0597716800988014,
      "grad_norm": 0.17291243374347687,
      "learning_rate": 9.402283199011987e-06,
      "loss": 0.2957,
      "step": 3775
    },
    {
      "epoch": 0.05978751365644347,
      "grad_norm": 0.314142644405365,
      "learning_rate": 9.402124863435567e-06,
      "loss": 0.1157,
      "step": 3776
    },
    {
      "epoch": 0.059803347214085534,
      "grad_norm": 0.4336627423763275,
      "learning_rate": 9.401966527859145e-06,
      "loss": 0.3633,
      "step": 3777
    },
    {
      "epoch": 0.0598191807717276,
      "grad_norm": 0.4700326919555664,
      "learning_rate": 9.401808192282724e-06,
      "loss": 0.3597,
      "step": 3778
    },
    {
      "epoch": 0.05983501432936967,
      "grad_norm": 0.041070424020290375,
      "learning_rate": 9.401649856706305e-06,
      "loss": 0.0024,
      "step": 3779
    },
    {
      "epoch": 0.059850847887011734,
      "grad_norm": 0.1558462381362915,
      "learning_rate": 9.401491521129884e-06,
      "loss": 0.0464,
      "step": 3780
    },
    {
      "epoch": 0.0598666814446538,
      "grad_norm": 0.12419337779283524,
      "learning_rate": 9.401333185553463e-06,
      "loss": 0.102,
      "step": 3781
    },
    {
      "epoch": 0.05988251500229587,
      "grad_norm": 0.44598937034606934,
      "learning_rate": 9.401174849977042e-06,
      "loss": 0.3402,
      "step": 3782
    },
    {
      "epoch": 0.05989834855993793,
      "grad_norm": 3.903533797711134e-05,
      "learning_rate": 9.401016514400621e-06,
      "loss": 0.0,
      "step": 3783
    },
    {
      "epoch": 0.05991418211758,
      "grad_norm": 0.02155282348394394,
      "learning_rate": 9.4008581788242e-06,
      "loss": 0.0014,
      "step": 3784
    },
    {
      "epoch": 0.05993001567522207,
      "grad_norm": 0.23516184091567993,
      "learning_rate": 9.400699843247781e-06,
      "loss": 0.0548,
      "step": 3785
    },
    {
      "epoch": 0.05994584923286413,
      "grad_norm": 0.13410934805870056,
      "learning_rate": 9.400541507671358e-06,
      "loss": 0.0324,
      "step": 3786
    },
    {
      "epoch": 0.0599616827905062,
      "grad_norm": 0.5516802072525024,
      "learning_rate": 9.400383172094939e-06,
      "loss": 0.1287,
      "step": 3787
    },
    {
      "epoch": 0.05997751634814827,
      "grad_norm": 0.28350457549095154,
      "learning_rate": 9.400224836518518e-06,
      "loss": 0.043,
      "step": 3788
    },
    {
      "epoch": 0.05999334990579033,
      "grad_norm": 0.2060972899198532,
      "learning_rate": 9.400066500942097e-06,
      "loss": 0.1716,
      "step": 3789
    },
    {
      "epoch": 0.0600091834634324,
      "grad_norm": 0.6711511611938477,
      "learning_rate": 9.399908165365676e-06,
      "loss": 0.2785,
      "step": 3790
    },
    {
      "epoch": 0.06002501702107447,
      "grad_norm": 0.3305024802684784,
      "learning_rate": 9.399749829789257e-06,
      "loss": 0.1422,
      "step": 3791
    },
    {
      "epoch": 0.06004085057871653,
      "grad_norm": 0.2853080928325653,
      "learning_rate": 9.399591494212834e-06,
      "loss": 0.51,
      "step": 3792
    },
    {
      "epoch": 0.0600566841363586,
      "grad_norm": 0.2476661503314972,
      "learning_rate": 9.399433158636415e-06,
      "loss": 0.0467,
      "step": 3793
    },
    {
      "epoch": 0.06007251769400067,
      "grad_norm": 0.3156886696815491,
      "learning_rate": 9.399274823059994e-06,
      "loss": 0.0676,
      "step": 3794
    },
    {
      "epoch": 0.06008835125164273,
      "grad_norm": 0.18996880948543549,
      "learning_rate": 9.399116487483573e-06,
      "loss": 0.1293,
      "step": 3795
    },
    {
      "epoch": 0.0601041848092848,
      "grad_norm": 0.26356497406959534,
      "learning_rate": 9.398958151907152e-06,
      "loss": 0.9458,
      "step": 3796
    },
    {
      "epoch": 0.06012001836692687,
      "grad_norm": 0.26048603653907776,
      "learning_rate": 9.398799816330733e-06,
      "loss": 0.0333,
      "step": 3797
    },
    {
      "epoch": 0.06013585192456893,
      "grad_norm": 0.1474277526140213,
      "learning_rate": 9.39864148075431e-06,
      "loss": 0.0471,
      "step": 3798
    },
    {
      "epoch": 0.060151685482211,
      "grad_norm": 0.15660984814167023,
      "learning_rate": 9.398483145177891e-06,
      "loss": 0.0439,
      "step": 3799
    },
    {
      "epoch": 0.06016751903985307,
      "grad_norm": 0.30688315629959106,
      "learning_rate": 9.39832480960147e-06,
      "loss": 0.2958,
      "step": 3800
    },
    {
      "epoch": 0.06018335259749513,
      "grad_norm": 0.14262323081493378,
      "learning_rate": 9.39816647402505e-06,
      "loss": 0.042,
      "step": 3801
    },
    {
      "epoch": 0.060199186155137197,
      "grad_norm": 0.16002492606639862,
      "learning_rate": 9.398008138448629e-06,
      "loss": 0.1313,
      "step": 3802
    },
    {
      "epoch": 0.06021501971277927,
      "grad_norm": 0.05747320130467415,
      "learning_rate": 9.397849802872208e-06,
      "loss": 0.0049,
      "step": 3803
    },
    {
      "epoch": 0.06023085327042133,
      "grad_norm": 0.010773505084216595,
      "learning_rate": 9.397691467295787e-06,
      "loss": 0.0003,
      "step": 3804
    },
    {
      "epoch": 0.060246686828063396,
      "grad_norm": 0.1794978231191635,
      "learning_rate": 9.397533131719366e-06,
      "loss": 0.0609,
      "step": 3805
    },
    {
      "epoch": 0.06026252038570547,
      "grad_norm": 0.21010610461235046,
      "learning_rate": 9.397374796142947e-06,
      "loss": 0.0324,
      "step": 3806
    },
    {
      "epoch": 0.06027835394334753,
      "grad_norm": 0.639830470085144,
      "learning_rate": 9.397216460566526e-06,
      "loss": 0.3138,
      "step": 3807
    },
    {
      "epoch": 0.060294187500989596,
      "grad_norm": 0.2572617530822754,
      "learning_rate": 9.397058124990105e-06,
      "loss": 0.0759,
      "step": 3808
    },
    {
      "epoch": 0.06031002105863167,
      "grad_norm": 0.05726368725299835,
      "learning_rate": 9.396899789413684e-06,
      "loss": 0.0078,
      "step": 3809
    },
    {
      "epoch": 0.06032585461627373,
      "grad_norm": 0.5629478096961975,
      "learning_rate": 9.396741453837263e-06,
      "loss": 0.0919,
      "step": 3810
    },
    {
      "epoch": 0.060341688173915796,
      "grad_norm": 0.6459384560585022,
      "learning_rate": 9.396583118260842e-06,
      "loss": 0.2038,
      "step": 3811
    },
    {
      "epoch": 0.06035752173155787,
      "grad_norm": 0.31249234080314636,
      "learning_rate": 9.396424782684423e-06,
      "loss": 0.1926,
      "step": 3812
    },
    {
      "epoch": 0.06037335528919993,
      "grad_norm": 0.20466335117816925,
      "learning_rate": 9.396266447108002e-06,
      "loss": 0.008,
      "step": 3813
    },
    {
      "epoch": 0.060389188846841996,
      "grad_norm": 0.19419723749160767,
      "learning_rate": 9.396108111531581e-06,
      "loss": 0.0603,
      "step": 3814
    },
    {
      "epoch": 0.06040502240448407,
      "grad_norm": 0.03868354484438896,
      "learning_rate": 9.39594977595516e-06,
      "loss": 0.0056,
      "step": 3815
    },
    {
      "epoch": 0.06042085596212613,
      "grad_norm": 0.27516037225723267,
      "learning_rate": 9.395791440378739e-06,
      "loss": 0.1639,
      "step": 3816
    },
    {
      "epoch": 0.060436689519768196,
      "grad_norm": 0.1576165109872818,
      "learning_rate": 9.395633104802318e-06,
      "loss": 0.0685,
      "step": 3817
    },
    {
      "epoch": 0.06045252307741027,
      "grad_norm": 0.25833582878112793,
      "learning_rate": 9.395474769225899e-06,
      "loss": 0.1171,
      "step": 3818
    },
    {
      "epoch": 0.06046835663505233,
      "grad_norm": 0.18392659723758698,
      "learning_rate": 9.395316433649478e-06,
      "loss": 0.0848,
      "step": 3819
    },
    {
      "epoch": 0.060484190192694395,
      "grad_norm": 0.19822341203689575,
      "learning_rate": 9.395158098073057e-06,
      "loss": 0.0651,
      "step": 3820
    },
    {
      "epoch": 0.06050002375033647,
      "grad_norm": 0.12381041795015335,
      "learning_rate": 9.394999762496636e-06,
      "loss": 0.0449,
      "step": 3821
    },
    {
      "epoch": 0.06051585730797853,
      "grad_norm": 0.01001045759767294,
      "learning_rate": 9.394841426920215e-06,
      "loss": 0.0005,
      "step": 3822
    },
    {
      "epoch": 0.060531690865620595,
      "grad_norm": 0.16973844170570374,
      "learning_rate": 9.394683091343794e-06,
      "loss": 0.042,
      "step": 3823
    },
    {
      "epoch": 0.06054752442326266,
      "grad_norm": 0.36800840497016907,
      "learning_rate": 9.394524755767375e-06,
      "loss": 0.6008,
      "step": 3824
    },
    {
      "epoch": 0.06056335798090473,
      "grad_norm": 0.8653287887573242,
      "learning_rate": 9.394366420190954e-06,
      "loss": 0.82,
      "step": 3825
    },
    {
      "epoch": 0.060579191538546795,
      "grad_norm": 0.061598341912031174,
      "learning_rate": 9.394208084614532e-06,
      "loss": 0.0021,
      "step": 3826
    },
    {
      "epoch": 0.06059502509618886,
      "grad_norm": 0.19244569540023804,
      "learning_rate": 9.394049749038112e-06,
      "loss": 0.095,
      "step": 3827
    },
    {
      "epoch": 0.06061085865383093,
      "grad_norm": 0.0027165429200977087,
      "learning_rate": 9.393891413461691e-06,
      "loss": 0.0001,
      "step": 3828
    },
    {
      "epoch": 0.060626692211472995,
      "grad_norm": 0.004245849791914225,
      "learning_rate": 9.39373307788527e-06,
      "loss": 0.0002,
      "step": 3829
    },
    {
      "epoch": 0.06064252576911506,
      "grad_norm": 0.5340732932090759,
      "learning_rate": 9.39357474230885e-06,
      "loss": 0.0138,
      "step": 3830
    },
    {
      "epoch": 0.06065835932675713,
      "grad_norm": 0.6268967390060425,
      "learning_rate": 9.39341640673243e-06,
      "loss": 0.3533,
      "step": 3831
    },
    {
      "epoch": 0.060674192884399195,
      "grad_norm": 0.3274461328983307,
      "learning_rate": 9.393258071156008e-06,
      "loss": 0.2209,
      "step": 3832
    },
    {
      "epoch": 0.06069002644204126,
      "grad_norm": 0.008170046843588352,
      "learning_rate": 9.393099735579589e-06,
      "loss": 0.0005,
      "step": 3833
    },
    {
      "epoch": 0.06070585999968333,
      "grad_norm": 0.011558057740330696,
      "learning_rate": 9.392941400003168e-06,
      "loss": 0.0006,
      "step": 3834
    },
    {
      "epoch": 0.060721693557325394,
      "grad_norm": 0.22632238268852234,
      "learning_rate": 9.392783064426747e-06,
      "loss": 0.0581,
      "step": 3835
    },
    {
      "epoch": 0.06073752711496746,
      "grad_norm": 0.6736129522323608,
      "learning_rate": 9.392624728850326e-06,
      "loss": 0.1757,
      "step": 3836
    },
    {
      "epoch": 0.06075336067260953,
      "grad_norm": 0.735246479511261,
      "learning_rate": 9.392466393273907e-06,
      "loss": 0.0294,
      "step": 3837
    },
    {
      "epoch": 0.060769194230251594,
      "grad_norm": 0.2575858235359192,
      "learning_rate": 9.392308057697484e-06,
      "loss": 0.1302,
      "step": 3838
    },
    {
      "epoch": 0.06078502778789366,
      "grad_norm": 0.17485357820987701,
      "learning_rate": 9.392149722121065e-06,
      "loss": 0.0244,
      "step": 3839
    },
    {
      "epoch": 0.06080086134553573,
      "grad_norm": 0.24596482515335083,
      "learning_rate": 9.391991386544644e-06,
      "loss": 0.3534,
      "step": 3840
    },
    {
      "epoch": 0.060816694903177794,
      "grad_norm": 0.2013540118932724,
      "learning_rate": 9.391833050968223e-06,
      "loss": 0.0494,
      "step": 3841
    },
    {
      "epoch": 0.06083252846081986,
      "grad_norm": 0.021784966811537743,
      "learning_rate": 9.391674715391802e-06,
      "loss": 0.0021,
      "step": 3842
    },
    {
      "epoch": 0.06084836201846193,
      "grad_norm": 0.44200921058654785,
      "learning_rate": 9.391516379815383e-06,
      "loss": 0.1072,
      "step": 3843
    },
    {
      "epoch": 0.060864195576103994,
      "grad_norm": 0.0026807915419340134,
      "learning_rate": 9.39135804423896e-06,
      "loss": 0.0001,
      "step": 3844
    },
    {
      "epoch": 0.06088002913374606,
      "grad_norm": 0.2737043797969818,
      "learning_rate": 9.391199708662541e-06,
      "loss": 0.3389,
      "step": 3845
    },
    {
      "epoch": 0.06089586269138813,
      "grad_norm": 0.34583914279937744,
      "learning_rate": 9.39104137308612e-06,
      "loss": 0.0761,
      "step": 3846
    },
    {
      "epoch": 0.060911696249030194,
      "grad_norm": 5.620341471512802e-05,
      "learning_rate": 9.390883037509699e-06,
      "loss": 0.0,
      "step": 3847
    },
    {
      "epoch": 0.06092752980667226,
      "grad_norm": 0.35240036249160767,
      "learning_rate": 9.390724701933278e-06,
      "loss": 0.3993,
      "step": 3848
    },
    {
      "epoch": 0.06094336336431433,
      "grad_norm": 0.003868505824357271,
      "learning_rate": 9.390566366356857e-06,
      "loss": 0.0002,
      "step": 3849
    },
    {
      "epoch": 0.06095919692195639,
      "grad_norm": 0.23380768299102783,
      "learning_rate": 9.390408030780436e-06,
      "loss": 0.0975,
      "step": 3850
    },
    {
      "epoch": 0.06097503047959846,
      "grad_norm": 0.5038753747940063,
      "learning_rate": 9.390249695204015e-06,
      "loss": 0.0102,
      "step": 3851
    },
    {
      "epoch": 0.06099086403724053,
      "grad_norm": 0.3878551423549652,
      "learning_rate": 9.390091359627596e-06,
      "loss": 0.0115,
      "step": 3852
    },
    {
      "epoch": 0.06100669759488259,
      "grad_norm": 0.6064432859420776,
      "learning_rate": 9.389933024051174e-06,
      "loss": 0.2552,
      "step": 3853
    },
    {
      "epoch": 0.06102253115252466,
      "grad_norm": 0.1473228931427002,
      "learning_rate": 9.389774688474754e-06,
      "loss": 0.0395,
      "step": 3854
    },
    {
      "epoch": 0.06103836471016673,
      "grad_norm": 0.08176089078187943,
      "learning_rate": 9.389616352898333e-06,
      "loss": 0.0076,
      "step": 3855
    },
    {
      "epoch": 0.06105419826780879,
      "grad_norm": 0.28968554735183716,
      "learning_rate": 9.389458017321912e-06,
      "loss": 0.0944,
      "step": 3856
    },
    {
      "epoch": 0.06107003182545086,
      "grad_norm": 0.183569997549057,
      "learning_rate": 9.389299681745492e-06,
      "loss": 0.0746,
      "step": 3857
    },
    {
      "epoch": 0.06108586538309293,
      "grad_norm": 0.21863484382629395,
      "learning_rate": 9.389141346169072e-06,
      "loss": 0.1094,
      "step": 3858
    },
    {
      "epoch": 0.06110169894073499,
      "grad_norm": 0.37719419598579407,
      "learning_rate": 9.38898301059265e-06,
      "loss": 0.3029,
      "step": 3859
    },
    {
      "epoch": 0.06111753249837706,
      "grad_norm": 0.19588106870651245,
      "learning_rate": 9.38882467501623e-06,
      "loss": 0.183,
      "step": 3860
    },
    {
      "epoch": 0.06113336605601913,
      "grad_norm": 0.2784881591796875,
      "learning_rate": 9.38866633943981e-06,
      "loss": 0.2168,
      "step": 3861
    },
    {
      "epoch": 0.06114919961366119,
      "grad_norm": 0.03257901221513748,
      "learning_rate": 9.388508003863389e-06,
      "loss": 0.0018,
      "step": 3862
    },
    {
      "epoch": 0.06116503317130326,
      "grad_norm": 0.32910415530204773,
      "learning_rate": 9.388349668286968e-06,
      "loss": 0.4023,
      "step": 3863
    },
    {
      "epoch": 0.06118086672894533,
      "grad_norm": 0.4092034697532654,
      "learning_rate": 9.388191332710548e-06,
      "loss": 0.5099,
      "step": 3864
    },
    {
      "epoch": 0.06119670028658739,
      "grad_norm": 0.34828320145606995,
      "learning_rate": 9.388032997134126e-06,
      "loss": 0.3972,
      "step": 3865
    },
    {
      "epoch": 0.06121253384422946,
      "grad_norm": 3.270620107650757,
      "learning_rate": 9.387874661557707e-06,
      "loss": 0.5517,
      "step": 3866
    },
    {
      "epoch": 0.06122836740187153,
      "grad_norm": 0.5262516140937805,
      "learning_rate": 9.387716325981286e-06,
      "loss": 1.093,
      "step": 3867
    },
    {
      "epoch": 0.06124420095951359,
      "grad_norm": 0.48222583532333374,
      "learning_rate": 9.387557990404865e-06,
      "loss": 0.3543,
      "step": 3868
    },
    {
      "epoch": 0.061260034517155657,
      "grad_norm": 1.071112871170044,
      "learning_rate": 9.387399654828444e-06,
      "loss": 0.2369,
      "step": 3869
    },
    {
      "epoch": 0.06127586807479773,
      "grad_norm": 0.024978032335639,
      "learning_rate": 9.387241319252025e-06,
      "loss": 0.0017,
      "step": 3870
    },
    {
      "epoch": 0.06129170163243979,
      "grad_norm": 0.2568660080432892,
      "learning_rate": 9.387082983675602e-06,
      "loss": 0.1436,
      "step": 3871
    },
    {
      "epoch": 0.061307535190081856,
      "grad_norm": 0.3220796287059784,
      "learning_rate": 9.386924648099183e-06,
      "loss": 0.1005,
      "step": 3872
    },
    {
      "epoch": 0.06132336874772393,
      "grad_norm": 0.5227346420288086,
      "learning_rate": 9.386766312522762e-06,
      "loss": 0.0674,
      "step": 3873
    },
    {
      "epoch": 0.06133920230536599,
      "grad_norm": 0.1770126074552536,
      "learning_rate": 9.386607976946341e-06,
      "loss": 0.1075,
      "step": 3874
    },
    {
      "epoch": 0.061355035863008056,
      "grad_norm": 0.4106267988681793,
      "learning_rate": 9.38644964136992e-06,
      "loss": 0.013,
      "step": 3875
    },
    {
      "epoch": 0.06137086942065013,
      "grad_norm": 0.12568363547325134,
      "learning_rate": 9.386291305793499e-06,
      "loss": 0.0246,
      "step": 3876
    },
    {
      "epoch": 0.06138670297829219,
      "grad_norm": 0.12153270095586777,
      "learning_rate": 9.386132970217078e-06,
      "loss": 0.0496,
      "step": 3877
    },
    {
      "epoch": 0.061402536535934256,
      "grad_norm": 0.1411268562078476,
      "learning_rate": 9.385974634640657e-06,
      "loss": 0.0606,
      "step": 3878
    },
    {
      "epoch": 0.06141837009357633,
      "grad_norm": 0.26589298248291016,
      "learning_rate": 9.385816299064238e-06,
      "loss": 0.049,
      "step": 3879
    },
    {
      "epoch": 0.06143420365121839,
      "grad_norm": 0.41602224111557007,
      "learning_rate": 9.385657963487817e-06,
      "loss": 0.4035,
      "step": 3880
    },
    {
      "epoch": 0.061450037208860456,
      "grad_norm": 0.4536891281604767,
      "learning_rate": 9.385499627911396e-06,
      "loss": 0.0716,
      "step": 3881
    },
    {
      "epoch": 0.06146587076650253,
      "grad_norm": 0.04840497300028801,
      "learning_rate": 9.385341292334975e-06,
      "loss": 0.0039,
      "step": 3882
    },
    {
      "epoch": 0.06148170432414459,
      "grad_norm": 0.13722768425941467,
      "learning_rate": 9.385182956758554e-06,
      "loss": 0.0762,
      "step": 3883
    },
    {
      "epoch": 0.061497537881786656,
      "grad_norm": 0.1862131655216217,
      "learning_rate": 9.385024621182133e-06,
      "loss": 0.083,
      "step": 3884
    },
    {
      "epoch": 0.06151337143942873,
      "grad_norm": 0.4339420795440674,
      "learning_rate": 9.384866285605714e-06,
      "loss": 0.0985,
      "step": 3885
    },
    {
      "epoch": 0.06152920499707079,
      "grad_norm": 0.8890191316604614,
      "learning_rate": 9.384707950029293e-06,
      "loss": 0.0292,
      "step": 3886
    },
    {
      "epoch": 0.061545038554712855,
      "grad_norm": 0.34624263644218445,
      "learning_rate": 9.384549614452872e-06,
      "loss": 0.1261,
      "step": 3887
    },
    {
      "epoch": 0.06156087211235493,
      "grad_norm": 0.061354439705610275,
      "learning_rate": 9.384391278876451e-06,
      "loss": 0.0009,
      "step": 3888
    },
    {
      "epoch": 0.06157670566999699,
      "grad_norm": 0.07908385246992111,
      "learning_rate": 9.38423294330003e-06,
      "loss": 0.0034,
      "step": 3889
    },
    {
      "epoch": 0.061592539227639055,
      "grad_norm": 0.23197318613529205,
      "learning_rate": 9.38407460772361e-06,
      "loss": 0.0861,
      "step": 3890
    },
    {
      "epoch": 0.061608372785281126,
      "grad_norm": 0.40241116285324097,
      "learning_rate": 9.38391627214719e-06,
      "loss": 0.3849,
      "step": 3891
    },
    {
      "epoch": 0.06162420634292319,
      "grad_norm": 0.24957607686519623,
      "learning_rate": 9.38375793657077e-06,
      "loss": 0.0999,
      "step": 3892
    },
    {
      "epoch": 0.061640039900565255,
      "grad_norm": 0.012161332182586193,
      "learning_rate": 9.383599600994349e-06,
      "loss": 0.0006,
      "step": 3893
    },
    {
      "epoch": 0.061655873458207326,
      "grad_norm": 0.16936880350112915,
      "learning_rate": 9.383441265417928e-06,
      "loss": 0.0542,
      "step": 3894
    },
    {
      "epoch": 0.06167170701584939,
      "grad_norm": 0.3863488733768463,
      "learning_rate": 9.383282929841507e-06,
      "loss": 0.125,
      "step": 3895
    },
    {
      "epoch": 0.061687540573491455,
      "grad_norm": 0.02056640014052391,
      "learning_rate": 9.383124594265086e-06,
      "loss": 0.0013,
      "step": 3896
    },
    {
      "epoch": 0.061703374131133526,
      "grad_norm": 0.4198968708515167,
      "learning_rate": 9.382966258688667e-06,
      "loss": 0.6077,
      "step": 3897
    },
    {
      "epoch": 0.06171920768877559,
      "grad_norm": 0.05719615891575813,
      "learning_rate": 9.382807923112246e-06,
      "loss": 0.0084,
      "step": 3898
    },
    {
      "epoch": 0.061735041246417655,
      "grad_norm": 0.3083769679069519,
      "learning_rate": 9.382649587535823e-06,
      "loss": 0.2197,
      "step": 3899
    },
    {
      "epoch": 0.061750874804059726,
      "grad_norm": 0.481081485748291,
      "learning_rate": 9.382491251959404e-06,
      "loss": 0.1582,
      "step": 3900
    },
    {
      "epoch": 0.06176670836170179,
      "grad_norm": 0.37929069995880127,
      "learning_rate": 9.382332916382983e-06,
      "loss": 0.2188,
      "step": 3901
    },
    {
      "epoch": 0.061782541919343854,
      "grad_norm": 0.5099631547927856,
      "learning_rate": 9.382174580806562e-06,
      "loss": 0.2486,
      "step": 3902
    },
    {
      "epoch": 0.061798375476985926,
      "grad_norm": 0.20621080696582794,
      "learning_rate": 9.382016245230141e-06,
      "loss": 0.1488,
      "step": 3903
    },
    {
      "epoch": 0.06181420903462799,
      "grad_norm": 0.8524501919746399,
      "learning_rate": 9.381857909653722e-06,
      "loss": 0.0324,
      "step": 3904
    },
    {
      "epoch": 0.061830042592270054,
      "grad_norm": 0.4780985116958618,
      "learning_rate": 9.3816995740773e-06,
      "loss": 0.6578,
      "step": 3905
    },
    {
      "epoch": 0.061845876149912125,
      "grad_norm": 0.00015949193038977683,
      "learning_rate": 9.38154123850088e-06,
      "loss": 0.0,
      "step": 3906
    },
    {
      "epoch": 0.06186170970755419,
      "grad_norm": 0.17143261432647705,
      "learning_rate": 9.381382902924459e-06,
      "loss": 0.0672,
      "step": 3907
    },
    {
      "epoch": 0.061877543265196254,
      "grad_norm": 0.013143840245902538,
      "learning_rate": 9.381224567348038e-06,
      "loss": 0.0008,
      "step": 3908
    },
    {
      "epoch": 0.061893376822838325,
      "grad_norm": 0.3539162278175354,
      "learning_rate": 9.381066231771617e-06,
      "loss": 0.2153,
      "step": 3909
    },
    {
      "epoch": 0.06190921038048039,
      "grad_norm": 0.11330044269561768,
      "learning_rate": 9.380907896195198e-06,
      "loss": 0.0511,
      "step": 3910
    },
    {
      "epoch": 0.061925043938122454,
      "grad_norm": 0.2856988310813904,
      "learning_rate": 9.380749560618775e-06,
      "loss": 0.0788,
      "step": 3911
    },
    {
      "epoch": 0.061940877495764525,
      "grad_norm": 0.26793181896209717,
      "learning_rate": 9.380591225042356e-06,
      "loss": 0.1654,
      "step": 3912
    },
    {
      "epoch": 0.06195671105340659,
      "grad_norm": 0.008838471956551075,
      "learning_rate": 9.380432889465935e-06,
      "loss": 0.0005,
      "step": 3913
    },
    {
      "epoch": 0.061972544611048654,
      "grad_norm": 0.2559114992618561,
      "learning_rate": 9.380274553889514e-06,
      "loss": 0.1435,
      "step": 3914
    },
    {
      "epoch": 0.061988378168690725,
      "grad_norm": 0.1524578183889389,
      "learning_rate": 9.380116218313093e-06,
      "loss": 0.0824,
      "step": 3915
    },
    {
      "epoch": 0.06200421172633279,
      "grad_norm": 0.038543593138456345,
      "learning_rate": 9.379957882736672e-06,
      "loss": 0.0033,
      "step": 3916
    },
    {
      "epoch": 0.06202004528397485,
      "grad_norm": 0.18871504068374634,
      "learning_rate": 9.379799547160252e-06,
      "loss": 0.2527,
      "step": 3917
    },
    {
      "epoch": 0.062035878841616925,
      "grad_norm": 0.3374054431915283,
      "learning_rate": 9.379641211583832e-06,
      "loss": 0.0853,
      "step": 3918
    },
    {
      "epoch": 0.06205171239925899,
      "grad_norm": 0.22843201458454132,
      "learning_rate": 9.379482876007411e-06,
      "loss": 0.0793,
      "step": 3919
    },
    {
      "epoch": 0.06206754595690105,
      "grad_norm": 0.4690471887588501,
      "learning_rate": 9.37932454043099e-06,
      "loss": 0.7996,
      "step": 3920
    },
    {
      "epoch": 0.062083379514543124,
      "grad_norm": 0.35375598073005676,
      "learning_rate": 9.37916620485457e-06,
      "loss": 0.0502,
      "step": 3921
    },
    {
      "epoch": 0.06209921307218519,
      "grad_norm": 0.28378140926361084,
      "learning_rate": 9.379007869278149e-06,
      "loss": 0.2213,
      "step": 3922
    },
    {
      "epoch": 0.06211504662982725,
      "grad_norm": 0.12802310287952423,
      "learning_rate": 9.378849533701728e-06,
      "loss": 0.0196,
      "step": 3923
    },
    {
      "epoch": 0.062130880187469324,
      "grad_norm": 0.3458057940006256,
      "learning_rate": 9.378691198125307e-06,
      "loss": 0.3723,
      "step": 3924
    },
    {
      "epoch": 0.06214671374511139,
      "grad_norm": 0.03219585120677948,
      "learning_rate": 9.378532862548888e-06,
      "loss": 0.0009,
      "step": 3925
    },
    {
      "epoch": 0.06216254730275345,
      "grad_norm": 0.3117055594921112,
      "learning_rate": 9.378374526972465e-06,
      "loss": 0.2654,
      "step": 3926
    },
    {
      "epoch": 0.062178380860395524,
      "grad_norm": 0.010016690008342266,
      "learning_rate": 9.378216191396046e-06,
      "loss": 0.0005,
      "step": 3927
    },
    {
      "epoch": 0.06219421441803759,
      "grad_norm": 0.21073183417320251,
      "learning_rate": 9.378057855819625e-06,
      "loss": 0.0993,
      "step": 3928
    },
    {
      "epoch": 0.06221004797567965,
      "grad_norm": 0.016845298931002617,
      "learning_rate": 9.377899520243204e-06,
      "loss": 0.0011,
      "step": 3929
    },
    {
      "epoch": 0.062225881533321724,
      "grad_norm": 0.03359502926468849,
      "learning_rate": 9.377741184666783e-06,
      "loss": 0.0022,
      "step": 3930
    },
    {
      "epoch": 0.06224171509096379,
      "grad_norm": 0.3699225187301636,
      "learning_rate": 9.377582849090364e-06,
      "loss": 0.2556,
      "step": 3931
    },
    {
      "epoch": 0.06225754864860585,
      "grad_norm": 0.6288018226623535,
      "learning_rate": 9.377424513513941e-06,
      "loss": 0.1458,
      "step": 3932
    },
    {
      "epoch": 0.062273382206247924,
      "grad_norm": 0.35667258501052856,
      "learning_rate": 9.377266177937522e-06,
      "loss": 0.2008,
      "step": 3933
    },
    {
      "epoch": 0.06228921576388999,
      "grad_norm": 0.31973153352737427,
      "learning_rate": 9.377107842361101e-06,
      "loss": 0.5558,
      "step": 3934
    },
    {
      "epoch": 0.06230504932153205,
      "grad_norm": 0.37573736906051636,
      "learning_rate": 9.37694950678468e-06,
      "loss": 0.2883,
      "step": 3935
    },
    {
      "epoch": 0.06232088287917412,
      "grad_norm": 0.25730985403060913,
      "learning_rate": 9.376791171208259e-06,
      "loss": 0.1141,
      "step": 3936
    },
    {
      "epoch": 0.06233671643681619,
      "grad_norm": 0.14328718185424805,
      "learning_rate": 9.37663283563184e-06,
      "loss": 0.059,
      "step": 3937
    },
    {
      "epoch": 0.06235254999445825,
      "grad_norm": 0.05833081528544426,
      "learning_rate": 9.376474500055417e-06,
      "loss": 0.004,
      "step": 3938
    },
    {
      "epoch": 0.06236838355210032,
      "grad_norm": 0.20175327360630035,
      "learning_rate": 9.376316164478998e-06,
      "loss": 0.0698,
      "step": 3939
    },
    {
      "epoch": 0.06238421710974239,
      "grad_norm": 0.526698887348175,
      "learning_rate": 9.376157828902577e-06,
      "loss": 0.8092,
      "step": 3940
    },
    {
      "epoch": 0.06240005066738445,
      "grad_norm": 0.20553134381771088,
      "learning_rate": 9.375999493326156e-06,
      "loss": 0.2002,
      "step": 3941
    },
    {
      "epoch": 0.06241588422502652,
      "grad_norm": 0.11269223690032959,
      "learning_rate": 9.375841157749735e-06,
      "loss": 0.0428,
      "step": 3942
    },
    {
      "epoch": 0.06243171778266859,
      "grad_norm": 0.5593494176864624,
      "learning_rate": 9.375682822173316e-06,
      "loss": 0.2456,
      "step": 3943
    },
    {
      "epoch": 0.06244755134031065,
      "grad_norm": 0.5447542667388916,
      "learning_rate": 9.375524486596893e-06,
      "loss": 0.0454,
      "step": 3944
    },
    {
      "epoch": 0.06246338489795272,
      "grad_norm": 0.02716005966067314,
      "learning_rate": 9.375366151020474e-06,
      "loss": 0.0015,
      "step": 3945
    },
    {
      "epoch": 0.06247921845559479,
      "grad_norm": 0.3457581400871277,
      "learning_rate": 9.375207815444053e-06,
      "loss": 0.2376,
      "step": 3946
    },
    {
      "epoch": 0.06249505201323685,
      "grad_norm": 0.00465686758980155,
      "learning_rate": 9.375049479867632e-06,
      "loss": 0.0002,
      "step": 3947
    },
    {
      "epoch": 0.06251088557087892,
      "grad_norm": 0.4293231666088104,
      "learning_rate": 9.374891144291211e-06,
      "loss": 0.4029,
      "step": 3948
    },
    {
      "epoch": 0.062526719128521,
      "grad_norm": 0.1462019979953766,
      "learning_rate": 9.37473280871479e-06,
      "loss": 0.0087,
      "step": 3949
    },
    {
      "epoch": 0.06254255268616306,
      "grad_norm": 0.24935966730117798,
      "learning_rate": 9.37457447313837e-06,
      "loss": 0.2035,
      "step": 3950
    },
    {
      "epoch": 0.06255838624380512,
      "grad_norm": 0.003531702794134617,
      "learning_rate": 9.374416137561949e-06,
      "loss": 0.0002,
      "step": 3951
    },
    {
      "epoch": 0.06257421980144719,
      "grad_norm": 0.21756984293460846,
      "learning_rate": 9.37425780198553e-06,
      "loss": 0.2841,
      "step": 3952
    },
    {
      "epoch": 0.06259005335908925,
      "grad_norm": 0.008886423893272877,
      "learning_rate": 9.374099466409109e-06,
      "loss": 0.0006,
      "step": 3953
    },
    {
      "epoch": 0.06260588691673132,
      "grad_norm": 0.13108442723751068,
      "learning_rate": 9.373941130832688e-06,
      "loss": 0.0203,
      "step": 3954
    },
    {
      "epoch": 0.0626217204743734,
      "grad_norm": 0.11936287581920624,
      "learning_rate": 9.373782795256267e-06,
      "loss": 0.0706,
      "step": 3955
    },
    {
      "epoch": 0.06263755403201546,
      "grad_norm": 0.19321885704994202,
      "learning_rate": 9.373624459679846e-06,
      "loss": 0.0437,
      "step": 3956
    },
    {
      "epoch": 0.06265338758965752,
      "grad_norm": 0.24060843884944916,
      "learning_rate": 9.373466124103425e-06,
      "loss": 0.3285,
      "step": 3957
    },
    {
      "epoch": 0.06266922114729959,
      "grad_norm": 1.4117445945739746,
      "learning_rate": 9.373307788527006e-06,
      "loss": 0.1444,
      "step": 3958
    },
    {
      "epoch": 0.06268505470494165,
      "grad_norm": 0.23657791316509247,
      "learning_rate": 9.373149452950585e-06,
      "loss": 0.1198,
      "step": 3959
    },
    {
      "epoch": 0.06270088826258371,
      "grad_norm": 0.2856088876724243,
      "learning_rate": 9.372991117374164e-06,
      "loss": 0.0506,
      "step": 3960
    },
    {
      "epoch": 0.0627167218202258,
      "grad_norm": 0.0803474709391594,
      "learning_rate": 9.372832781797743e-06,
      "loss": 0.0102,
      "step": 3961
    },
    {
      "epoch": 0.06273255537786786,
      "grad_norm": 0.16106447577476501,
      "learning_rate": 9.372674446221322e-06,
      "loss": 0.0337,
      "step": 3962
    },
    {
      "epoch": 0.06274838893550992,
      "grad_norm": 0.010435459204018116,
      "learning_rate": 9.372516110644901e-06,
      "loss": 0.0009,
      "step": 3963
    },
    {
      "epoch": 0.06276422249315199,
      "grad_norm": 7.452621503034607e-05,
      "learning_rate": 9.372357775068482e-06,
      "loss": 0.0,
      "step": 3964
    },
    {
      "epoch": 0.06278005605079405,
      "grad_norm": 0.18912489712238312,
      "learning_rate": 9.372199439492061e-06,
      "loss": 0.2479,
      "step": 3965
    },
    {
      "epoch": 0.06279588960843611,
      "grad_norm": 0.00656973198056221,
      "learning_rate": 9.37204110391564e-06,
      "loss": 0.0004,
      "step": 3966
    },
    {
      "epoch": 0.06281172316607819,
      "grad_norm": 0.2686408460140228,
      "learning_rate": 9.371882768339219e-06,
      "loss": 0.0749,
      "step": 3967
    },
    {
      "epoch": 0.06282755672372026,
      "grad_norm": 3.531740730977617e-05,
      "learning_rate": 9.371724432762798e-06,
      "loss": 0.0,
      "step": 3968
    },
    {
      "epoch": 0.06284339028136232,
      "grad_norm": 0.28071266412734985,
      "learning_rate": 9.371566097186377e-06,
      "loss": 0.0448,
      "step": 3969
    },
    {
      "epoch": 0.06285922383900439,
      "grad_norm": 0.04272167757153511,
      "learning_rate": 9.371407761609956e-06,
      "loss": 0.0039,
      "step": 3970
    },
    {
      "epoch": 0.06287505739664645,
      "grad_norm": 1.1764230728149414,
      "learning_rate": 9.371249426033537e-06,
      "loss": 0.0698,
      "step": 3971
    },
    {
      "epoch": 0.06289089095428851,
      "grad_norm": 0.03522904962301254,
      "learning_rate": 9.371091090457114e-06,
      "loss": 0.0026,
      "step": 3972
    },
    {
      "epoch": 0.06290672451193059,
      "grad_norm": 0.07946357876062393,
      "learning_rate": 9.370932754880695e-06,
      "loss": 0.0119,
      "step": 3973
    },
    {
      "epoch": 0.06292255806957266,
      "grad_norm": 0.00016933587903622538,
      "learning_rate": 9.370774419304274e-06,
      "loss": 0.0,
      "step": 3974
    },
    {
      "epoch": 0.06293839162721472,
      "grad_norm": 0.07538609206676483,
      "learning_rate": 9.370616083727853e-06,
      "loss": 0.0375,
      "step": 3975
    },
    {
      "epoch": 0.06295422518485679,
      "grad_norm": 0.4067666828632355,
      "learning_rate": 9.370457748151432e-06,
      "loss": 0.4764,
      "step": 3976
    },
    {
      "epoch": 0.06297005874249885,
      "grad_norm": 0.5498349070549011,
      "learning_rate": 9.370299412575012e-06,
      "loss": 0.6426,
      "step": 3977
    },
    {
      "epoch": 0.06298589230014091,
      "grad_norm": 0.21309995651245117,
      "learning_rate": 9.37014107699859e-06,
      "loss": 0.2947,
      "step": 3978
    },
    {
      "epoch": 0.06300172585778299,
      "grad_norm": 0.0022524914238601923,
      "learning_rate": 9.369982741422171e-06,
      "loss": 0.0,
      "step": 3979
    },
    {
      "epoch": 0.06301755941542506,
      "grad_norm": 0.024895107373595238,
      "learning_rate": 9.36982440584575e-06,
      "loss": 0.0017,
      "step": 3980
    },
    {
      "epoch": 0.06303339297306712,
      "grad_norm": 0.1848120391368866,
      "learning_rate": 9.36966607026933e-06,
      "loss": 0.0854,
      "step": 3981
    },
    {
      "epoch": 0.06304922653070918,
      "grad_norm": 0.00744311697781086,
      "learning_rate": 9.369507734692909e-06,
      "loss": 0.0003,
      "step": 3982
    },
    {
      "epoch": 0.06306506008835125,
      "grad_norm": 0.22826965153217316,
      "learning_rate": 9.369349399116488e-06,
      "loss": 0.0069,
      "step": 3983
    },
    {
      "epoch": 0.06308089364599331,
      "grad_norm": 0.010888900607824326,
      "learning_rate": 9.369191063540067e-06,
      "loss": 0.0002,
      "step": 3984
    },
    {
      "epoch": 0.06309672720363539,
      "grad_norm": 1.1703866720199585,
      "learning_rate": 9.369032727963648e-06,
      "loss": 0.0554,
      "step": 3985
    },
    {
      "epoch": 0.06311256076127746,
      "grad_norm": 0.0035107408184558153,
      "learning_rate": 9.368874392387227e-06,
      "loss": 0.0001,
      "step": 3986
    },
    {
      "epoch": 0.06312839431891952,
      "grad_norm": 0.09574314951896667,
      "learning_rate": 9.368716056810806e-06,
      "loss": 0.0309,
      "step": 3987
    },
    {
      "epoch": 0.06314422787656158,
      "grad_norm": 0.11686699092388153,
      "learning_rate": 9.368557721234385e-06,
      "loss": 0.037,
      "step": 3988
    },
    {
      "epoch": 0.06316006143420365,
      "grad_norm": 0.13994275033473969,
      "learning_rate": 9.368399385657964e-06,
      "loss": 0.0741,
      "step": 3989
    },
    {
      "epoch": 0.06317589499184571,
      "grad_norm": 0.5975670218467712,
      "learning_rate": 9.368241050081543e-06,
      "loss": 0.3246,
      "step": 3990
    },
    {
      "epoch": 0.06319172854948779,
      "grad_norm": 0.5257788300514221,
      "learning_rate": 9.368082714505124e-06,
      "loss": 0.116,
      "step": 3991
    },
    {
      "epoch": 0.06320756210712986,
      "grad_norm": 0.02199244312942028,
      "learning_rate": 9.367924378928703e-06,
      "loss": 0.0016,
      "step": 3992
    },
    {
      "epoch": 0.06322339566477192,
      "grad_norm": 0.13586705923080444,
      "learning_rate": 9.367766043352282e-06,
      "loss": 0.1375,
      "step": 3993
    },
    {
      "epoch": 0.06323922922241398,
      "grad_norm": 0.23518012464046478,
      "learning_rate": 9.367607707775861e-06,
      "loss": 0.4292,
      "step": 3994
    },
    {
      "epoch": 0.06325506278005605,
      "grad_norm": 0.01131520327180624,
      "learning_rate": 9.36744937219944e-06,
      "loss": 0.0008,
      "step": 3995
    },
    {
      "epoch": 0.06327089633769811,
      "grad_norm": 0.32217535376548767,
      "learning_rate": 9.36729103662302e-06,
      "loss": 0.6364,
      "step": 3996
    },
    {
      "epoch": 0.06328672989534019,
      "grad_norm": 0.20265436172485352,
      "learning_rate": 9.367132701046598e-06,
      "loss": 0.5835,
      "step": 3997
    },
    {
      "epoch": 0.06330256345298226,
      "grad_norm": 0.43287771940231323,
      "learning_rate": 9.366974365470179e-06,
      "loss": 0.0101,
      "step": 3998
    },
    {
      "epoch": 0.06331839701062432,
      "grad_norm": 0.16451270878314972,
      "learning_rate": 9.366816029893756e-06,
      "loss": 0.0827,
      "step": 3999
    },
    {
      "epoch": 0.06333423056826638,
      "grad_norm": 0.33960700035095215,
      "learning_rate": 9.366657694317337e-06,
      "loss": 0.1494,
      "step": 4000
    },
    {
      "epoch": 0.06335006412590845,
      "grad_norm": 7.590375753352419e-05,
      "learning_rate": 9.366499358740916e-06,
      "loss": 0.0,
      "step": 4001
    },
    {
      "epoch": 0.06336589768355051,
      "grad_norm": 0.43934547901153564,
      "learning_rate": 9.366341023164495e-06,
      "loss": 0.1046,
      "step": 4002
    },
    {
      "epoch": 0.06338173124119259,
      "grad_norm": 0.18029607832431793,
      "learning_rate": 9.366182687588074e-06,
      "loss": 0.1098,
      "step": 4003
    },
    {
      "epoch": 0.06339756479883465,
      "grad_norm": 0.012374033220112324,
      "learning_rate": 9.366024352011655e-06,
      "loss": 0.001,
      "step": 4004
    },
    {
      "epoch": 0.06341339835647672,
      "grad_norm": 0.021605342626571655,
      "learning_rate": 9.365866016435233e-06,
      "loss": 0.0016,
      "step": 4005
    },
    {
      "epoch": 0.06342923191411878,
      "grad_norm": 0.6058555841445923,
      "learning_rate": 9.365707680858813e-06,
      "loss": 0.1831,
      "step": 4006
    },
    {
      "epoch": 0.06344506547176085,
      "grad_norm": 0.27982738614082336,
      "learning_rate": 9.365549345282392e-06,
      "loss": 0.0515,
      "step": 4007
    },
    {
      "epoch": 0.06346089902940291,
      "grad_norm": 0.3056641221046448,
      "learning_rate": 9.365391009705972e-06,
      "loss": 0.0979,
      "step": 4008
    },
    {
      "epoch": 0.06347673258704499,
      "grad_norm": 0.6188998818397522,
      "learning_rate": 9.36523267412955e-06,
      "loss": 0.3361,
      "step": 4009
    },
    {
      "epoch": 0.06349256614468705,
      "grad_norm": 0.19949054718017578,
      "learning_rate": 9.365074338553131e-06,
      "loss": 0.0672,
      "step": 4010
    },
    {
      "epoch": 0.06350839970232912,
      "grad_norm": 0.17453093826770782,
      "learning_rate": 9.364916002976709e-06,
      "loss": 0.0554,
      "step": 4011
    },
    {
      "epoch": 0.06352423325997118,
      "grad_norm": 0.16970109939575195,
      "learning_rate": 9.36475766740029e-06,
      "loss": 0.0782,
      "step": 4012
    },
    {
      "epoch": 0.06354006681761325,
      "grad_norm": 0.8423722982406616,
      "learning_rate": 9.364599331823869e-06,
      "loss": 0.7016,
      "step": 4013
    },
    {
      "epoch": 0.06355590037525531,
      "grad_norm": 0.3831770718097687,
      "learning_rate": 9.364440996247448e-06,
      "loss": 0.6439,
      "step": 4014
    },
    {
      "epoch": 0.06357173393289739,
      "grad_norm": 0.15710516273975372,
      "learning_rate": 9.364282660671027e-06,
      "loss": 0.0674,
      "step": 4015
    },
    {
      "epoch": 0.06358756749053945,
      "grad_norm": 0.00014085085422266275,
      "learning_rate": 9.364124325094608e-06,
      "loss": 0.0,
      "step": 4016
    },
    {
      "epoch": 0.06360340104818152,
      "grad_norm": 0.000494139501824975,
      "learning_rate": 9.363965989518185e-06,
      "loss": 0.0,
      "step": 4017
    },
    {
      "epoch": 0.06361923460582358,
      "grad_norm": 0.006847502663731575,
      "learning_rate": 9.363807653941764e-06,
      "loss": 0.0003,
      "step": 4018
    },
    {
      "epoch": 0.06363506816346565,
      "grad_norm": 0.24429842829704285,
      "learning_rate": 9.363649318365345e-06,
      "loss": 0.4489,
      "step": 4019
    },
    {
      "epoch": 0.06365090172110771,
      "grad_norm": 0.006630051415413618,
      "learning_rate": 9.363490982788924e-06,
      "loss": 0.0003,
      "step": 4020
    },
    {
      "epoch": 0.06366673527874979,
      "grad_norm": 0.35901889204978943,
      "learning_rate": 9.363332647212503e-06,
      "loss": 0.1766,
      "step": 4021
    },
    {
      "epoch": 0.06368256883639185,
      "grad_norm": 0.017706695944070816,
      "learning_rate": 9.363174311636082e-06,
      "loss": 0.0004,
      "step": 4022
    },
    {
      "epoch": 0.06369840239403392,
      "grad_norm": 0.1068262830376625,
      "learning_rate": 9.363015976059661e-06,
      "loss": 0.0614,
      "step": 4023
    },
    {
      "epoch": 0.06371423595167598,
      "grad_norm": 0.3073250949382782,
      "learning_rate": 9.36285764048324e-06,
      "loss": 0.0246,
      "step": 4024
    },
    {
      "epoch": 0.06373006950931805,
      "grad_norm": 0.3443407416343689,
      "learning_rate": 9.362699304906821e-06,
      "loss": 0.3602,
      "step": 4025
    },
    {
      "epoch": 0.06374590306696011,
      "grad_norm": 0.18415458500385284,
      "learning_rate": 9.3625409693304e-06,
      "loss": 0.2326,
      "step": 4026
    },
    {
      "epoch": 0.06376173662460217,
      "grad_norm": 0.011773123405873775,
      "learning_rate": 9.362382633753979e-06,
      "loss": 0.0006,
      "step": 4027
    },
    {
      "epoch": 0.06377757018224425,
      "grad_norm": 0.3576243817806244,
      "learning_rate": 9.362224298177558e-06,
      "loss": 0.0916,
      "step": 4028
    },
    {
      "epoch": 0.06379340373988632,
      "grad_norm": 0.0015122322365641594,
      "learning_rate": 9.362065962601137e-06,
      "loss": 0.0,
      "step": 4029
    },
    {
      "epoch": 0.06380923729752838,
      "grad_norm": 0.014856697991490364,
      "learning_rate": 9.361907627024716e-06,
      "loss": 0.0008,
      "step": 4030
    },
    {
      "epoch": 0.06382507085517045,
      "grad_norm": 0.00022005484788678586,
      "learning_rate": 9.361749291448297e-06,
      "loss": 0.0,
      "step": 4031
    },
    {
      "epoch": 0.06384090441281251,
      "grad_norm": 0.5043952465057373,
      "learning_rate": 9.361590955871876e-06,
      "loss": 0.1173,
      "step": 4032
    },
    {
      "epoch": 0.06385673797045457,
      "grad_norm": 0.1610422134399414,
      "learning_rate": 9.361432620295455e-06,
      "loss": 0.0567,
      "step": 4033
    },
    {
      "epoch": 0.06387257152809665,
      "grad_norm": 0.05944884568452835,
      "learning_rate": 9.361274284719034e-06,
      "loss": 0.0148,
      "step": 4034
    },
    {
      "epoch": 0.06388840508573872,
      "grad_norm": 0.199691042304039,
      "learning_rate": 9.361115949142613e-06,
      "loss": 0.0856,
      "step": 4035
    },
    {
      "epoch": 0.06390423864338078,
      "grad_norm": 0.4266897737979889,
      "learning_rate": 9.360957613566193e-06,
      "loss": 0.7349,
      "step": 4036
    },
    {
      "epoch": 0.06392007220102285,
      "grad_norm": 0.3924228549003601,
      "learning_rate": 9.360799277989773e-06,
      "loss": 0.1887,
      "step": 4037
    },
    {
      "epoch": 0.06393590575866491,
      "grad_norm": 0.28441324830055237,
      "learning_rate": 9.360640942413352e-06,
      "loss": 0.1181,
      "step": 4038
    },
    {
      "epoch": 0.06395173931630697,
      "grad_norm": 0.00013702140131499618,
      "learning_rate": 9.360482606836931e-06,
      "loss": 0.0,
      "step": 4039
    },
    {
      "epoch": 0.06396757287394905,
      "grad_norm": 0.008268584497272968,
      "learning_rate": 9.36032427126051e-06,
      "loss": 0.0004,
      "step": 4040
    },
    {
      "epoch": 0.06398340643159112,
      "grad_norm": 0.2609015703201294,
      "learning_rate": 9.36016593568409e-06,
      "loss": 0.2931,
      "step": 4041
    },
    {
      "epoch": 0.06399923998923318,
      "grad_norm": 0.27559182047843933,
      "learning_rate": 9.360007600107669e-06,
      "loss": 0.2869,
      "step": 4042
    },
    {
      "epoch": 0.06401507354687525,
      "grad_norm": 0.36964982748031616,
      "learning_rate": 9.359849264531248e-06,
      "loss": 0.2516,
      "step": 4043
    },
    {
      "epoch": 0.06403090710451731,
      "grad_norm": 0.2723338007926941,
      "learning_rate": 9.359690928954827e-06,
      "loss": 0.1023,
      "step": 4044
    },
    {
      "epoch": 0.06404674066215937,
      "grad_norm": 0.23731426894664764,
      "learning_rate": 9.359532593378406e-06,
      "loss": 0.0867,
      "step": 4045
    },
    {
      "epoch": 0.06406257421980145,
      "grad_norm": 4.2149426008109e-05,
      "learning_rate": 9.359374257801987e-06,
      "loss": 0.0,
      "step": 4046
    },
    {
      "epoch": 0.06407840777744352,
      "grad_norm": 0.018448468297719955,
      "learning_rate": 9.359215922225566e-06,
      "loss": 0.0013,
      "step": 4047
    },
    {
      "epoch": 0.06409424133508558,
      "grad_norm": 0.17599759995937347,
      "learning_rate": 9.359057586649145e-06,
      "loss": 0.1915,
      "step": 4048
    },
    {
      "epoch": 0.06411007489272764,
      "grad_norm": 0.39016300439834595,
      "learning_rate": 9.358899251072724e-06,
      "loss": 0.6065,
      "step": 4049
    },
    {
      "epoch": 0.06412590845036971,
      "grad_norm": 0.28021374344825745,
      "learning_rate": 9.358740915496303e-06,
      "loss": 0.0859,
      "step": 4050
    },
    {
      "epoch": 0.06414174200801177,
      "grad_norm": 0.29719117283821106,
      "learning_rate": 9.358582579919882e-06,
      "loss": 0.3978,
      "step": 4051
    },
    {
      "epoch": 0.06415757556565385,
      "grad_norm": 0.29766273498535156,
      "learning_rate": 9.358424244343463e-06,
      "loss": 0.04,
      "step": 4052
    },
    {
      "epoch": 0.06417340912329592,
      "grad_norm": 0.7586886882781982,
      "learning_rate": 9.358265908767042e-06,
      "loss": 0.4456,
      "step": 4053
    },
    {
      "epoch": 0.06418924268093798,
      "grad_norm": 0.3111509084701538,
      "learning_rate": 9.358107573190621e-06,
      "loss": 0.1644,
      "step": 4054
    },
    {
      "epoch": 0.06420507623858004,
      "grad_norm": 0.22413136065006256,
      "learning_rate": 9.3579492376142e-06,
      "loss": 0.1018,
      "step": 4055
    },
    {
      "epoch": 0.06422090979622211,
      "grad_norm": 0.3932746350765228,
      "learning_rate": 9.35779090203778e-06,
      "loss": 0.2326,
      "step": 4056
    },
    {
      "epoch": 0.06423674335386417,
      "grad_norm": 0.226392924785614,
      "learning_rate": 9.357632566461358e-06,
      "loss": 0.0829,
      "step": 4057
    },
    {
      "epoch": 0.06425257691150625,
      "grad_norm": 0.23303402960300446,
      "learning_rate": 9.357474230884939e-06,
      "loss": 0.0654,
      "step": 4058
    },
    {
      "epoch": 0.06426841046914832,
      "grad_norm": 0.4397757947444916,
      "learning_rate": 9.357315895308518e-06,
      "loss": 0.5834,
      "step": 4059
    },
    {
      "epoch": 0.06428424402679038,
      "grad_norm": 0.31234753131866455,
      "learning_rate": 9.357157559732097e-06,
      "loss": 0.1402,
      "step": 4060
    },
    {
      "epoch": 0.06430007758443244,
      "grad_norm": 0.0034230402670800686,
      "learning_rate": 9.356999224155676e-06,
      "loss": 0.0001,
      "step": 4061
    },
    {
      "epoch": 0.06431591114207451,
      "grad_norm": 0.2326464056968689,
      "learning_rate": 9.356840888579255e-06,
      "loss": 0.1035,
      "step": 4062
    },
    {
      "epoch": 0.06433174469971657,
      "grad_norm": 0.26267048716545105,
      "learning_rate": 9.356682553002834e-06,
      "loss": 0.0751,
      "step": 4063
    },
    {
      "epoch": 0.06434757825735865,
      "grad_norm": 0.44738563895225525,
      "learning_rate": 9.356524217426415e-06,
      "loss": 0.5819,
      "step": 4064
    },
    {
      "epoch": 0.06436341181500072,
      "grad_norm": 0.23949652910232544,
      "learning_rate": 9.356365881849994e-06,
      "loss": 0.0588,
      "step": 4065
    },
    {
      "epoch": 0.06437924537264278,
      "grad_norm": 0.5039908289909363,
      "learning_rate": 9.356207546273573e-06,
      "loss": 0.5461,
      "step": 4066
    },
    {
      "epoch": 0.06439507893028484,
      "grad_norm": 0.20796138048171997,
      "learning_rate": 9.356049210697152e-06,
      "loss": 0.0934,
      "step": 4067
    },
    {
      "epoch": 0.06441091248792691,
      "grad_norm": 0.247730553150177,
      "learning_rate": 9.355890875120732e-06,
      "loss": 0.1203,
      "step": 4068
    },
    {
      "epoch": 0.06442674604556897,
      "grad_norm": 5.8692148741101846e-05,
      "learning_rate": 9.35573253954431e-06,
      "loss": 0.0,
      "step": 4069
    },
    {
      "epoch": 0.06444257960321105,
      "grad_norm": 0.019079463556408882,
      "learning_rate": 9.35557420396789e-06,
      "loss": 0.001,
      "step": 4070
    },
    {
      "epoch": 0.06445841316085311,
      "grad_norm": 0.3018921911716461,
      "learning_rate": 9.35541586839147e-06,
      "loss": 0.0233,
      "step": 4071
    },
    {
      "epoch": 0.06447424671849518,
      "grad_norm": 0.1794130951166153,
      "learning_rate": 9.355257532815048e-06,
      "loss": 0.0669,
      "step": 4072
    },
    {
      "epoch": 0.06449008027613724,
      "grad_norm": 1.0146173238754272,
      "learning_rate": 9.355099197238629e-06,
      "loss": 0.4848,
      "step": 4073
    },
    {
      "epoch": 0.06450591383377931,
      "grad_norm": 0.40515637397766113,
      "learning_rate": 9.354940861662208e-06,
      "loss": 0.2925,
      "step": 4074
    },
    {
      "epoch": 0.06452174739142137,
      "grad_norm": 0.21885643899440765,
      "learning_rate": 9.354782526085787e-06,
      "loss": 0.0619,
      "step": 4075
    },
    {
      "epoch": 0.06453758094906345,
      "grad_norm": 0.0002646429929882288,
      "learning_rate": 9.354624190509366e-06,
      "loss": 0.0,
      "step": 4076
    },
    {
      "epoch": 0.06455341450670551,
      "grad_norm": 0.3576735556125641,
      "learning_rate": 9.354465854932947e-06,
      "loss": 0.3319,
      "step": 4077
    },
    {
      "epoch": 0.06456924806434758,
      "grad_norm": 0.394701212644577,
      "learning_rate": 9.354307519356524e-06,
      "loss": 0.0356,
      "step": 4078
    },
    {
      "epoch": 0.06458508162198964,
      "grad_norm": 0.009679926559329033,
      "learning_rate": 9.354149183780105e-06,
      "loss": 0.0005,
      "step": 4079
    },
    {
      "epoch": 0.06460091517963171,
      "grad_norm": 0.32403475046157837,
      "learning_rate": 9.353990848203684e-06,
      "loss": 0.2646,
      "step": 4080
    },
    {
      "epoch": 0.06461674873727377,
      "grad_norm": 0.3060954809188843,
      "learning_rate": 9.353832512627263e-06,
      "loss": 0.0705,
      "step": 4081
    },
    {
      "epoch": 0.06463258229491585,
      "grad_norm": 0.15417686104774475,
      "learning_rate": 9.353674177050842e-06,
      "loss": 0.0564,
      "step": 4082
    },
    {
      "epoch": 0.06464841585255791,
      "grad_norm": 0.2705274820327759,
      "learning_rate": 9.353515841474423e-06,
      "loss": 0.1132,
      "step": 4083
    },
    {
      "epoch": 0.06466424941019998,
      "grad_norm": 0.23676681518554688,
      "learning_rate": 9.353357505898e-06,
      "loss": 0.2001,
      "step": 4084
    },
    {
      "epoch": 0.06468008296784204,
      "grad_norm": 0.3440946638584137,
      "learning_rate": 9.353199170321581e-06,
      "loss": 0.2218,
      "step": 4085
    },
    {
      "epoch": 0.0646959165254841,
      "grad_norm": 0.43194445967674255,
      "learning_rate": 9.35304083474516e-06,
      "loss": 0.3197,
      "step": 4086
    },
    {
      "epoch": 0.06471175008312617,
      "grad_norm": 0.013835925608873367,
      "learning_rate": 9.352882499168739e-06,
      "loss": 0.0006,
      "step": 4087
    },
    {
      "epoch": 0.06472758364076825,
      "grad_norm": 4.229092883178964e-05,
      "learning_rate": 9.352724163592318e-06,
      "loss": 0.0,
      "step": 4088
    },
    {
      "epoch": 0.06474341719841031,
      "grad_norm": 0.17197184264659882,
      "learning_rate": 9.352565828015899e-06,
      "loss": 0.1421,
      "step": 4089
    },
    {
      "epoch": 0.06475925075605238,
      "grad_norm": 0.0019357859855517745,
      "learning_rate": 9.352407492439476e-06,
      "loss": 0.0,
      "step": 4090
    },
    {
      "epoch": 0.06477508431369444,
      "grad_norm": 0.701881468296051,
      "learning_rate": 9.352249156863055e-06,
      "loss": 0.3549,
      "step": 4091
    },
    {
      "epoch": 0.0647909178713365,
      "grad_norm": 0.21172116696834564,
      "learning_rate": 9.352090821286636e-06,
      "loss": 0.0468,
      "step": 4092
    },
    {
      "epoch": 0.06480675142897857,
      "grad_norm": 0.09906335175037384,
      "learning_rate": 9.351932485710215e-06,
      "loss": 0.0032,
      "step": 4093
    },
    {
      "epoch": 0.06482258498662065,
      "grad_norm": 0.06964525580406189,
      "learning_rate": 9.351774150133794e-06,
      "loss": 0.0033,
      "step": 4094
    },
    {
      "epoch": 0.06483841854426271,
      "grad_norm": 0.19375097751617432,
      "learning_rate": 9.351615814557373e-06,
      "loss": 0.0295,
      "step": 4095
    },
    {
      "epoch": 0.06485425210190478,
      "grad_norm": 0.5005019307136536,
      "learning_rate": 9.351457478980953e-06,
      "loss": 0.5751,
      "step": 4096
    },
    {
      "epoch": 0.06487008565954684,
      "grad_norm": 0.00010536410991335288,
      "learning_rate": 9.351299143404532e-06,
      "loss": 0.0,
      "step": 4097
    },
    {
      "epoch": 0.0648859192171889,
      "grad_norm": 0.5313959717750549,
      "learning_rate": 9.351140807828112e-06,
      "loss": 0.5438,
      "step": 4098
    },
    {
      "epoch": 0.06490175277483097,
      "grad_norm": 0.018718605861067772,
      "learning_rate": 9.350982472251691e-06,
      "loss": 0.001,
      "step": 4099
    },
    {
      "epoch": 0.06491758633247305,
      "grad_norm": 0.03562355041503906,
      "learning_rate": 9.35082413667527e-06,
      "loss": 0.0071,
      "step": 4100
    },
    {
      "epoch": 0.06493341989011511,
      "grad_norm": 0.924060046672821,
      "learning_rate": 9.35066580109885e-06,
      "loss": 0.2978,
      "step": 4101
    },
    {
      "epoch": 0.06494925344775718,
      "grad_norm": 0.576721727848053,
      "learning_rate": 9.350507465522429e-06,
      "loss": 0.3753,
      "step": 4102
    },
    {
      "epoch": 0.06496508700539924,
      "grad_norm": 0.3811706304550171,
      "learning_rate": 9.350349129946008e-06,
      "loss": 0.2937,
      "step": 4103
    },
    {
      "epoch": 0.0649809205630413,
      "grad_norm": 0.00031629332806915045,
      "learning_rate": 9.350190794369589e-06,
      "loss": 0.0,
      "step": 4104
    },
    {
      "epoch": 0.06499675412068337,
      "grad_norm": 8.194205292966217e-05,
      "learning_rate": 9.350032458793166e-06,
      "loss": 0.0,
      "step": 4105
    },
    {
      "epoch": 0.06501258767832545,
      "grad_norm": 0.9437423944473267,
      "learning_rate": 9.349874123216747e-06,
      "loss": 0.5991,
      "step": 4106
    },
    {
      "epoch": 0.06502842123596751,
      "grad_norm": 0.4150114059448242,
      "learning_rate": 9.349715787640326e-06,
      "loss": 0.7206,
      "step": 4107
    },
    {
      "epoch": 0.06504425479360958,
      "grad_norm": 0.21615280210971832,
      "learning_rate": 9.349557452063905e-06,
      "loss": 0.2451,
      "step": 4108
    },
    {
      "epoch": 0.06506008835125164,
      "grad_norm": 8.959625120041892e-05,
      "learning_rate": 9.349399116487484e-06,
      "loss": 0.0,
      "step": 4109
    },
    {
      "epoch": 0.0650759219088937,
      "grad_norm": 0.4006172716617584,
      "learning_rate": 9.349240780911065e-06,
      "loss": 0.1899,
      "step": 4110
    },
    {
      "epoch": 0.06509175546653577,
      "grad_norm": 0.009877316653728485,
      "learning_rate": 9.349082445334642e-06,
      "loss": 0.0004,
      "step": 4111
    },
    {
      "epoch": 0.06510758902417785,
      "grad_norm": 0.0027903076261281967,
      "learning_rate": 9.348924109758223e-06,
      "loss": 0.0002,
      "step": 4112
    },
    {
      "epoch": 0.06512342258181991,
      "grad_norm": 0.3768403232097626,
      "learning_rate": 9.348765774181802e-06,
      "loss": 0.0835,
      "step": 4113
    },
    {
      "epoch": 0.06513925613946198,
      "grad_norm": 0.656783401966095,
      "learning_rate": 9.348607438605381e-06,
      "loss": 0.1322,
      "step": 4114
    },
    {
      "epoch": 0.06515508969710404,
      "grad_norm": 0.22782279551029205,
      "learning_rate": 9.34844910302896e-06,
      "loss": 0.0396,
      "step": 4115
    },
    {
      "epoch": 0.0651709232547461,
      "grad_norm": 0.12608036398887634,
      "learning_rate": 9.34829076745254e-06,
      "loss": 0.0458,
      "step": 4116
    },
    {
      "epoch": 0.06518675681238817,
      "grad_norm": 0.5734068751335144,
      "learning_rate": 9.348132431876118e-06,
      "loss": 0.2346,
      "step": 4117
    },
    {
      "epoch": 0.06520259037003025,
      "grad_norm": 0.00024401361588388681,
      "learning_rate": 9.347974096299697e-06,
      "loss": 0.0,
      "step": 4118
    },
    {
      "epoch": 0.06521842392767231,
      "grad_norm": 0.0002533718361519277,
      "learning_rate": 9.347815760723278e-06,
      "loss": 0.0,
      "step": 4119
    },
    {
      "epoch": 0.06523425748531438,
      "grad_norm": 0.3167949318885803,
      "learning_rate": 9.347657425146857e-06,
      "loss": 0.1119,
      "step": 4120
    },
    {
      "epoch": 0.06525009104295644,
      "grad_norm": 0.25961118936538696,
      "learning_rate": 9.347499089570436e-06,
      "loss": 0.1303,
      "step": 4121
    },
    {
      "epoch": 0.0652659246005985,
      "grad_norm": 0.363655149936676,
      "learning_rate": 9.347340753994015e-06,
      "loss": 1.0694,
      "step": 4122
    },
    {
      "epoch": 0.06528175815824057,
      "grad_norm": 0.0002920563565567136,
      "learning_rate": 9.347182418417594e-06,
      "loss": 0.0,
      "step": 4123
    },
    {
      "epoch": 0.06529759171588265,
      "grad_norm": 0.14368058741092682,
      "learning_rate": 9.347024082841174e-06,
      "loss": 0.0812,
      "step": 4124
    },
    {
      "epoch": 0.06531342527352471,
      "grad_norm": 0.00045513082295656204,
      "learning_rate": 9.346865747264754e-06,
      "loss": 0.0,
      "step": 4125
    },
    {
      "epoch": 0.06532925883116678,
      "grad_norm": 0.16469965875148773,
      "learning_rate": 9.346707411688333e-06,
      "loss": 0.0794,
      "step": 4126
    },
    {
      "epoch": 0.06534509238880884,
      "grad_norm": 0.14746396243572235,
      "learning_rate": 9.346549076111912e-06,
      "loss": 0.0843,
      "step": 4127
    },
    {
      "epoch": 0.0653609259464509,
      "grad_norm": 0.006484694313257933,
      "learning_rate": 9.346390740535492e-06,
      "loss": 0.0004,
      "step": 4128
    },
    {
      "epoch": 0.06537675950409297,
      "grad_norm": 0.33007198572158813,
      "learning_rate": 9.34623240495907e-06,
      "loss": 0.0113,
      "step": 4129
    },
    {
      "epoch": 0.06539259306173505,
      "grad_norm": 0.2725336253643036,
      "learning_rate": 9.34607406938265e-06,
      "loss": 0.5202,
      "step": 4130
    },
    {
      "epoch": 0.06540842661937711,
      "grad_norm": 0.41421186923980713,
      "learning_rate": 9.34591573380623e-06,
      "loss": 0.3295,
      "step": 4131
    },
    {
      "epoch": 0.06542426017701918,
      "grad_norm": 0.00022761263244319707,
      "learning_rate": 9.34575739822981e-06,
      "loss": 0.0,
      "step": 4132
    },
    {
      "epoch": 0.06544009373466124,
      "grad_norm": 0.007761109154671431,
      "learning_rate": 9.345599062653389e-06,
      "loss": 0.0004,
      "step": 4133
    },
    {
      "epoch": 0.0654559272923033,
      "grad_norm": 0.30713126063346863,
      "learning_rate": 9.345440727076968e-06,
      "loss": 0.2765,
      "step": 4134
    },
    {
      "epoch": 0.06547176084994537,
      "grad_norm": 0.18192820250988007,
      "learning_rate": 9.345282391500547e-06,
      "loss": 0.4214,
      "step": 4135
    },
    {
      "epoch": 0.06548759440758745,
      "grad_norm": 0.18959401547908783,
      "learning_rate": 9.345124055924126e-06,
      "loss": 0.0628,
      "step": 4136
    },
    {
      "epoch": 0.06550342796522951,
      "grad_norm": 0.0007892458233982325,
      "learning_rate": 9.344965720347707e-06,
      "loss": 0.0,
      "step": 4137
    },
    {
      "epoch": 0.06551926152287157,
      "grad_norm": 0.16824615001678467,
      "learning_rate": 9.344807384771286e-06,
      "loss": 0.0912,
      "step": 4138
    },
    {
      "epoch": 0.06553509508051364,
      "grad_norm": 0.012680604122579098,
      "learning_rate": 9.344649049194863e-06,
      "loss": 0.0007,
      "step": 4139
    },
    {
      "epoch": 0.0655509286381557,
      "grad_norm": 0.007195174228399992,
      "learning_rate": 9.344490713618444e-06,
      "loss": 0.0004,
      "step": 4140
    },
    {
      "epoch": 0.06556676219579777,
      "grad_norm": 0.39608436822891235,
      "learning_rate": 9.344332378042023e-06,
      "loss": 0.2008,
      "step": 4141
    },
    {
      "epoch": 0.06558259575343985,
      "grad_norm": 0.11521320044994354,
      "learning_rate": 9.344174042465602e-06,
      "loss": 0.0445,
      "step": 4142
    },
    {
      "epoch": 0.06559842931108191,
      "grad_norm": 0.7843912839889526,
      "learning_rate": 9.344015706889181e-06,
      "loss": 0.7578,
      "step": 4143
    },
    {
      "epoch": 0.06561426286872397,
      "grad_norm": 0.2042495757341385,
      "learning_rate": 9.343857371312762e-06,
      "loss": 0.1192,
      "step": 4144
    },
    {
      "epoch": 0.06563009642636604,
      "grad_norm": 0.22509722411632538,
      "learning_rate": 9.34369903573634e-06,
      "loss": 0.1302,
      "step": 4145
    },
    {
      "epoch": 0.0656459299840081,
      "grad_norm": 0.3948742747306824,
      "learning_rate": 9.34354070015992e-06,
      "loss": 0.6591,
      "step": 4146
    },
    {
      "epoch": 0.06566176354165017,
      "grad_norm": 0.217484250664711,
      "learning_rate": 9.343382364583499e-06,
      "loss": 0.1131,
      "step": 4147
    },
    {
      "epoch": 0.06567759709929225,
      "grad_norm": 0.36663517355918884,
      "learning_rate": 9.343224029007078e-06,
      "loss": 0.1285,
      "step": 4148
    },
    {
      "epoch": 0.06569343065693431,
      "grad_norm": 0.012120652943849564,
      "learning_rate": 9.343065693430657e-06,
      "loss": 0.0007,
      "step": 4149
    },
    {
      "epoch": 0.06570926421457637,
      "grad_norm": 0.4514422118663788,
      "learning_rate": 9.342907357854238e-06,
      "loss": 0.0324,
      "step": 4150
    },
    {
      "epoch": 0.06572509777221844,
      "grad_norm": 0.2926446199417114,
      "learning_rate": 9.342749022277815e-06,
      "loss": 0.1799,
      "step": 4151
    },
    {
      "epoch": 0.0657409313298605,
      "grad_norm": 0.31268948316574097,
      "learning_rate": 9.342590686701396e-06,
      "loss": 0.1678,
      "step": 4152
    },
    {
      "epoch": 0.06575676488750257,
      "grad_norm": 0.20646154880523682,
      "learning_rate": 9.342432351124975e-06,
      "loss": 0.1957,
      "step": 4153
    },
    {
      "epoch": 0.06577259844514464,
      "grad_norm": 0.19480696320533752,
      "learning_rate": 9.342274015548554e-06,
      "loss": 0.0974,
      "step": 4154
    },
    {
      "epoch": 0.06578843200278671,
      "grad_norm": 0.025037478655576706,
      "learning_rate": 9.342115679972133e-06,
      "loss": 0.0005,
      "step": 4155
    },
    {
      "epoch": 0.06580426556042877,
      "grad_norm": 0.00047931261360645294,
      "learning_rate": 9.341957344395714e-06,
      "loss": 0.0,
      "step": 4156
    },
    {
      "epoch": 0.06582009911807084,
      "grad_norm": 0.25995880365371704,
      "learning_rate": 9.341799008819292e-06,
      "loss": 0.1963,
      "step": 4157
    },
    {
      "epoch": 0.0658359326757129,
      "grad_norm": 0.4399672746658325,
      "learning_rate": 9.341640673242872e-06,
      "loss": 0.3483,
      "step": 4158
    },
    {
      "epoch": 0.06585176623335497,
      "grad_norm": 0.30365389585494995,
      "learning_rate": 9.341482337666451e-06,
      "loss": 0.4148,
      "step": 4159
    },
    {
      "epoch": 0.06586759979099704,
      "grad_norm": 0.23483547568321228,
      "learning_rate": 9.34132400209003e-06,
      "loss": 0.0636,
      "step": 4160
    },
    {
      "epoch": 0.06588343334863911,
      "grad_norm": 0.39647284150123596,
      "learning_rate": 9.34116566651361e-06,
      "loss": 0.1532,
      "step": 4161
    },
    {
      "epoch": 0.06589926690628117,
      "grad_norm": 0.17948900163173676,
      "learning_rate": 9.34100733093719e-06,
      "loss": 0.086,
      "step": 4162
    },
    {
      "epoch": 0.06591510046392324,
      "grad_norm": 0.2863740921020508,
      "learning_rate": 9.340848995360768e-06,
      "loss": 0.134,
      "step": 4163
    },
    {
      "epoch": 0.0659309340215653,
      "grad_norm": 0.029150478541851044,
      "learning_rate": 9.340690659784347e-06,
      "loss": 0.0018,
      "step": 4164
    },
    {
      "epoch": 0.06594676757920737,
      "grad_norm": 0.7365180253982544,
      "learning_rate": 9.340532324207928e-06,
      "loss": 0.241,
      "step": 4165
    },
    {
      "epoch": 0.06596260113684944,
      "grad_norm": 0.6414923667907715,
      "learning_rate": 9.340373988631507e-06,
      "loss": 0.1081,
      "step": 4166
    },
    {
      "epoch": 0.06597843469449151,
      "grad_norm": 0.04594406113028526,
      "learning_rate": 9.340215653055086e-06,
      "loss": 0.005,
      "step": 4167
    },
    {
      "epoch": 0.06599426825213357,
      "grad_norm": 0.19656215608119965,
      "learning_rate": 9.340057317478665e-06,
      "loss": 0.1664,
      "step": 4168
    },
    {
      "epoch": 0.06601010180977564,
      "grad_norm": 0.020426331087946892,
      "learning_rate": 9.339898981902244e-06,
      "loss": 0.0011,
      "step": 4169
    },
    {
      "epoch": 0.0660259353674177,
      "grad_norm": 0.4384108781814575,
      "learning_rate": 9.339740646325823e-06,
      "loss": 0.0795,
      "step": 4170
    },
    {
      "epoch": 0.06604176892505977,
      "grad_norm": 0.27601170539855957,
      "learning_rate": 9.339582310749404e-06,
      "loss": 0.2897,
      "step": 4171
    },
    {
      "epoch": 0.06605760248270184,
      "grad_norm": 0.4323424696922302,
      "learning_rate": 9.339423975172981e-06,
      "loss": 0.3339,
      "step": 4172
    },
    {
      "epoch": 0.06607343604034391,
      "grad_norm": 0.3184138834476471,
      "learning_rate": 9.339265639596562e-06,
      "loss": 0.3349,
      "step": 4173
    },
    {
      "epoch": 0.06608926959798597,
      "grad_norm": 0.00023807433899492025,
      "learning_rate": 9.339107304020141e-06,
      "loss": 0.0,
      "step": 4174
    },
    {
      "epoch": 0.06610510315562804,
      "grad_norm": 0.27197811007499695,
      "learning_rate": 9.33894896844372e-06,
      "loss": 0.1301,
      "step": 4175
    },
    {
      "epoch": 0.0661209367132701,
      "grad_norm": 0.3377479314804077,
      "learning_rate": 9.3387906328673e-06,
      "loss": 0.5759,
      "step": 4176
    },
    {
      "epoch": 0.06613677027091217,
      "grad_norm": 0.3038674294948578,
      "learning_rate": 9.33863229729088e-06,
      "loss": 0.126,
      "step": 4177
    },
    {
      "epoch": 0.06615260382855424,
      "grad_norm": 0.0019243003334850073,
      "learning_rate": 9.338473961714457e-06,
      "loss": 0.0,
      "step": 4178
    },
    {
      "epoch": 0.06616843738619631,
      "grad_norm": 0.45015713572502136,
      "learning_rate": 9.338315626138038e-06,
      "loss": 0.2687,
      "step": 4179
    },
    {
      "epoch": 0.06618427094383837,
      "grad_norm": 0.5652197003364563,
      "learning_rate": 9.338157290561617e-06,
      "loss": 0.147,
      "step": 4180
    },
    {
      "epoch": 0.06620010450148044,
      "grad_norm": 0.4556371867656708,
      "learning_rate": 9.337998954985196e-06,
      "loss": 0.1481,
      "step": 4181
    },
    {
      "epoch": 0.0662159380591225,
      "grad_norm": 0.21927587687969208,
      "learning_rate": 9.337840619408775e-06,
      "loss": 0.0626,
      "step": 4182
    },
    {
      "epoch": 0.06623177161676456,
      "grad_norm": 0.21786284446716309,
      "learning_rate": 9.337682283832356e-06,
      "loss": 0.0608,
      "step": 4183
    },
    {
      "epoch": 0.06624760517440664,
      "grad_norm": 0.22697819769382477,
      "learning_rate": 9.337523948255934e-06,
      "loss": 0.1996,
      "step": 4184
    },
    {
      "epoch": 0.06626343873204871,
      "grad_norm": 0.49586915969848633,
      "learning_rate": 9.337365612679514e-06,
      "loss": 0.562,
      "step": 4185
    },
    {
      "epoch": 0.06627927228969077,
      "grad_norm": 0.10238143056631088,
      "learning_rate": 9.337207277103093e-06,
      "loss": 0.0482,
      "step": 4186
    },
    {
      "epoch": 0.06629510584733284,
      "grad_norm": 0.13540783524513245,
      "learning_rate": 9.337048941526672e-06,
      "loss": 0.0036,
      "step": 4187
    },
    {
      "epoch": 0.0663109394049749,
      "grad_norm": 0.11547785252332687,
      "learning_rate": 9.336890605950252e-06,
      "loss": 0.0634,
      "step": 4188
    },
    {
      "epoch": 0.06632677296261696,
      "grad_norm": 0.24694949388504028,
      "learning_rate": 9.33673227037383e-06,
      "loss": 0.2913,
      "step": 4189
    },
    {
      "epoch": 0.06634260652025904,
      "grad_norm": 0.0069851805455982685,
      "learning_rate": 9.33657393479741e-06,
      "loss": 0.0004,
      "step": 4190
    },
    {
      "epoch": 0.0663584400779011,
      "grad_norm": 0.007074191700667143,
      "learning_rate": 9.336415599220989e-06,
      "loss": 0.0004,
      "step": 4191
    },
    {
      "epoch": 0.06637427363554317,
      "grad_norm": 0.09719973802566528,
      "learning_rate": 9.33625726364457e-06,
      "loss": 0.012,
      "step": 4192
    },
    {
      "epoch": 0.06639010719318524,
      "grad_norm": 0.007295122370123863,
      "learning_rate": 9.336098928068149e-06,
      "loss": 0.0005,
      "step": 4193
    },
    {
      "epoch": 0.0664059407508273,
      "grad_norm": 0.015635119751095772,
      "learning_rate": 9.335940592491728e-06,
      "loss": 0.0008,
      "step": 4194
    },
    {
      "epoch": 0.06642177430846936,
      "grad_norm": 0.10604830086231232,
      "learning_rate": 9.335782256915307e-06,
      "loss": 0.0409,
      "step": 4195
    },
    {
      "epoch": 0.06643760786611144,
      "grad_norm": 0.2805369198322296,
      "learning_rate": 9.335623921338886e-06,
      "loss": 0.4592,
      "step": 4196
    },
    {
      "epoch": 0.0664534414237535,
      "grad_norm": 0.39161059260368347,
      "learning_rate": 9.335465585762465e-06,
      "loss": 0.5136,
      "step": 4197
    },
    {
      "epoch": 0.06646927498139557,
      "grad_norm": 0.15598763525485992,
      "learning_rate": 9.335307250186046e-06,
      "loss": 0.0533,
      "step": 4198
    },
    {
      "epoch": 0.06648510853903764,
      "grad_norm": 0.18730634450912476,
      "learning_rate": 9.335148914609625e-06,
      "loss": 0.1737,
      "step": 4199
    },
    {
      "epoch": 0.0665009420966797,
      "grad_norm": 0.5662516355514526,
      "learning_rate": 9.334990579033204e-06,
      "loss": 0.4819,
      "step": 4200
    },
    {
      "epoch": 0.06651677565432176,
      "grad_norm": 0.4772419035434723,
      "learning_rate": 9.334832243456783e-06,
      "loss": 0.5067,
      "step": 4201
    },
    {
      "epoch": 0.06653260921196384,
      "grad_norm": 0.22175389528274536,
      "learning_rate": 9.334673907880362e-06,
      "loss": 0.0422,
      "step": 4202
    },
    {
      "epoch": 0.0665484427696059,
      "grad_norm": 0.2878338694572449,
      "learning_rate": 9.334515572303941e-06,
      "loss": 0.1531,
      "step": 4203
    },
    {
      "epoch": 0.06656427632724797,
      "grad_norm": 0.5034818649291992,
      "learning_rate": 9.334357236727522e-06,
      "loss": 0.2573,
      "step": 4204
    },
    {
      "epoch": 0.06658010988489003,
      "grad_norm": 0.0003601779171731323,
      "learning_rate": 9.334198901151101e-06,
      "loss": 0.0,
      "step": 4205
    },
    {
      "epoch": 0.0665959434425321,
      "grad_norm": 0.14858105778694153,
      "learning_rate": 9.33404056557468e-06,
      "loss": 0.0517,
      "step": 4206
    },
    {
      "epoch": 0.06661177700017416,
      "grad_norm": 0.16324011981487274,
      "learning_rate": 9.33388222999826e-06,
      "loss": 0.0179,
      "step": 4207
    },
    {
      "epoch": 0.06662761055781624,
      "grad_norm": 0.0008694845018908381,
      "learning_rate": 9.333723894421838e-06,
      "loss": 0.0,
      "step": 4208
    },
    {
      "epoch": 0.0666434441154583,
      "grad_norm": 0.2894516587257385,
      "learning_rate": 9.333565558845417e-06,
      "loss": 0.1953,
      "step": 4209
    },
    {
      "epoch": 0.06665927767310037,
      "grad_norm": 0.009465008042752743,
      "learning_rate": 9.333407223268998e-06,
      "loss": 0.0005,
      "step": 4210
    },
    {
      "epoch": 0.06667511123074243,
      "grad_norm": 0.06137876212596893,
      "learning_rate": 9.333248887692577e-06,
      "loss": 0.0033,
      "step": 4211
    },
    {
      "epoch": 0.0666909447883845,
      "grad_norm": 0.02456771954894066,
      "learning_rate": 9.333090552116155e-06,
      "loss": 0.0013,
      "step": 4212
    },
    {
      "epoch": 0.06670677834602656,
      "grad_norm": 0.3838564157485962,
      "learning_rate": 9.332932216539735e-06,
      "loss": 0.5196,
      "step": 4213
    },
    {
      "epoch": 0.06672261190366864,
      "grad_norm": 0.8546320199966431,
      "learning_rate": 9.332773880963314e-06,
      "loss": 0.2389,
      "step": 4214
    },
    {
      "epoch": 0.0667384454613107,
      "grad_norm": 0.3973640501499176,
      "learning_rate": 9.332615545386893e-06,
      "loss": 0.5313,
      "step": 4215
    },
    {
      "epoch": 0.06675427901895277,
      "grad_norm": 0.013014671392738819,
      "learning_rate": 9.332457209810473e-06,
      "loss": 0.0007,
      "step": 4216
    },
    {
      "epoch": 0.06677011257659483,
      "grad_norm": 0.4019361734390259,
      "learning_rate": 9.332298874234053e-06,
      "loss": 0.2502,
      "step": 4217
    },
    {
      "epoch": 0.0667859461342369,
      "grad_norm": 0.2228512316942215,
      "learning_rate": 9.33214053865763e-06,
      "loss": 0.1069,
      "step": 4218
    },
    {
      "epoch": 0.06680177969187896,
      "grad_norm": 0.2540700435638428,
      "learning_rate": 9.331982203081212e-06,
      "loss": 0.0761,
      "step": 4219
    },
    {
      "epoch": 0.06681761324952104,
      "grad_norm": 0.4124617576599121,
      "learning_rate": 9.33182386750479e-06,
      "loss": 0.1747,
      "step": 4220
    },
    {
      "epoch": 0.0668334468071631,
      "grad_norm": 0.05593098700046539,
      "learning_rate": 9.33166553192837e-06,
      "loss": 0.0109,
      "step": 4221
    },
    {
      "epoch": 0.06684928036480517,
      "grad_norm": 0.020159753039479256,
      "learning_rate": 9.331507196351949e-06,
      "loss": 0.0009,
      "step": 4222
    },
    {
      "epoch": 0.06686511392244723,
      "grad_norm": 0.008836260996758938,
      "learning_rate": 9.33134886077553e-06,
      "loss": 0.0004,
      "step": 4223
    },
    {
      "epoch": 0.0668809474800893,
      "grad_norm": 0.024472441524267197,
      "learning_rate": 9.331190525199107e-06,
      "loss": 0.0015,
      "step": 4224
    },
    {
      "epoch": 0.06689678103773136,
      "grad_norm": 0.44721513986587524,
      "learning_rate": 9.331032189622688e-06,
      "loss": 0.2402,
      "step": 4225
    },
    {
      "epoch": 0.06691261459537344,
      "grad_norm": 0.01762811839580536,
      "learning_rate": 9.330873854046267e-06,
      "loss": 0.0009,
      "step": 4226
    },
    {
      "epoch": 0.0669284481530155,
      "grad_norm": 0.2663585841655731,
      "learning_rate": 9.330715518469846e-06,
      "loss": 0.2861,
      "step": 4227
    },
    {
      "epoch": 0.06694428171065757,
      "grad_norm": 0.9955976605415344,
      "learning_rate": 9.330557182893425e-06,
      "loss": 0.0508,
      "step": 4228
    },
    {
      "epoch": 0.06696011526829963,
      "grad_norm": 0.0009796081576496363,
      "learning_rate": 9.330398847317006e-06,
      "loss": 0.0,
      "step": 4229
    },
    {
      "epoch": 0.0669759488259417,
      "grad_norm": 0.24858258664608002,
      "learning_rate": 9.330240511740583e-06,
      "loss": 0.3923,
      "step": 4230
    },
    {
      "epoch": 0.06699178238358376,
      "grad_norm": 0.303279846906662,
      "learning_rate": 9.330082176164164e-06,
      "loss": 0.1104,
      "step": 4231
    },
    {
      "epoch": 0.06700761594122584,
      "grad_norm": 0.4448421001434326,
      "learning_rate": 9.329923840587743e-06,
      "loss": 0.1346,
      "step": 4232
    },
    {
      "epoch": 0.0670234494988679,
      "grad_norm": 0.020885974168777466,
      "learning_rate": 9.329765505011322e-06,
      "loss": 0.001,
      "step": 4233
    },
    {
      "epoch": 0.06703928305650997,
      "grad_norm": 0.023092519491910934,
      "learning_rate": 9.329607169434901e-06,
      "loss": 0.0014,
      "step": 4234
    },
    {
      "epoch": 0.06705511661415203,
      "grad_norm": 0.1867394745349884,
      "learning_rate": 9.32944883385848e-06,
      "loss": 0.0438,
      "step": 4235
    },
    {
      "epoch": 0.0670709501717941,
      "grad_norm": 0.2689587473869324,
      "learning_rate": 9.32929049828206e-06,
      "loss": 0.6712,
      "step": 4236
    },
    {
      "epoch": 0.06708678372943616,
      "grad_norm": 0.32804661989212036,
      "learning_rate": 9.329132162705638e-06,
      "loss": 0.3367,
      "step": 4237
    },
    {
      "epoch": 0.06710261728707824,
      "grad_norm": 0.27710816264152527,
      "learning_rate": 9.328973827129219e-06,
      "loss": 0.101,
      "step": 4238
    },
    {
      "epoch": 0.0671184508447203,
      "grad_norm": 0.006132760550826788,
      "learning_rate": 9.328815491552796e-06,
      "loss": 0.0002,
      "step": 4239
    },
    {
      "epoch": 0.06713428440236237,
      "grad_norm": 0.06272929906845093,
      "learning_rate": 9.328657155976377e-06,
      "loss": 0.0032,
      "step": 4240
    },
    {
      "epoch": 0.06715011796000443,
      "grad_norm": 0.001980283297598362,
      "learning_rate": 9.328498820399956e-06,
      "loss": 0.0001,
      "step": 4241
    },
    {
      "epoch": 0.0671659515176465,
      "grad_norm": 0.0006083126063458622,
      "learning_rate": 9.328340484823535e-06,
      "loss": 0.0,
      "step": 4242
    },
    {
      "epoch": 0.06718178507528856,
      "grad_norm": 0.008861442096531391,
      "learning_rate": 9.328182149247114e-06,
      "loss": 0.0004,
      "step": 4243
    },
    {
      "epoch": 0.06719761863293064,
      "grad_norm": 0.32328304648399353,
      "learning_rate": 9.328023813670695e-06,
      "loss": 0.1503,
      "step": 4244
    },
    {
      "epoch": 0.0672134521905727,
      "grad_norm": 0.0001169492315966636,
      "learning_rate": 9.327865478094273e-06,
      "loss": 0.0,
      "step": 4245
    },
    {
      "epoch": 0.06722928574821477,
      "grad_norm": 0.5537222623825073,
      "learning_rate": 9.327707142517853e-06,
      "loss": 0.078,
      "step": 4246
    },
    {
      "epoch": 0.06724511930585683,
      "grad_norm": 0.4254867434501648,
      "learning_rate": 9.327548806941433e-06,
      "loss": 0.1004,
      "step": 4247
    },
    {
      "epoch": 0.0672609528634989,
      "grad_norm": 0.019770918413996696,
      "learning_rate": 9.327390471365012e-06,
      "loss": 0.0012,
      "step": 4248
    },
    {
      "epoch": 0.06727678642114096,
      "grad_norm": 0.5449270606040955,
      "learning_rate": 9.32723213578859e-06,
      "loss": 0.3207,
      "step": 4249
    },
    {
      "epoch": 0.06729261997878304,
      "grad_norm": 0.017505913972854614,
      "learning_rate": 9.327073800212171e-06,
      "loss": 0.0007,
      "step": 4250
    },
    {
      "epoch": 0.0673084535364251,
      "grad_norm": 0.19744092226028442,
      "learning_rate": 9.326915464635749e-06,
      "loss": 0.0568,
      "step": 4251
    },
    {
      "epoch": 0.06732428709406717,
      "grad_norm": 0.47491806745529175,
      "learning_rate": 9.32675712905933e-06,
      "loss": 0.2937,
      "step": 4252
    },
    {
      "epoch": 0.06734012065170923,
      "grad_norm": 1.1703455448150635,
      "learning_rate": 9.326598793482909e-06,
      "loss": 0.1121,
      "step": 4253
    },
    {
      "epoch": 0.0673559542093513,
      "grad_norm": 0.46385085582733154,
      "learning_rate": 9.326440457906488e-06,
      "loss": 0.1188,
      "step": 4254
    },
    {
      "epoch": 0.06737178776699336,
      "grad_norm": 0.023097490891814232,
      "learning_rate": 9.326282122330067e-06,
      "loss": 0.0009,
      "step": 4255
    },
    {
      "epoch": 0.06738762132463544,
      "grad_norm": 0.0001922247902257368,
      "learning_rate": 9.326123786753648e-06,
      "loss": 0.0,
      "step": 4256
    },
    {
      "epoch": 0.0674034548822775,
      "grad_norm": 0.00041536299977451563,
      "learning_rate": 9.325965451177225e-06,
      "loss": 0.0,
      "step": 4257
    },
    {
      "epoch": 0.06741928843991957,
      "grad_norm": 0.46425777673721313,
      "learning_rate": 9.325807115600806e-06,
      "loss": 0.0891,
      "step": 4258
    },
    {
      "epoch": 0.06743512199756163,
      "grad_norm": 0.08089748024940491,
      "learning_rate": 9.325648780024385e-06,
      "loss": 0.0079,
      "step": 4259
    },
    {
      "epoch": 0.0674509555552037,
      "grad_norm": 0.02150500752031803,
      "learning_rate": 9.325490444447964e-06,
      "loss": 0.0006,
      "step": 4260
    },
    {
      "epoch": 0.06746678911284576,
      "grad_norm": 0.219082772731781,
      "learning_rate": 9.325332108871543e-06,
      "loss": 0.1126,
      "step": 4261
    },
    {
      "epoch": 0.06748262267048784,
      "grad_norm": 0.31990158557891846,
      "learning_rate": 9.325173773295122e-06,
      "loss": 0.1555,
      "step": 4262
    },
    {
      "epoch": 0.0674984562281299,
      "grad_norm": 0.00038085755659267306,
      "learning_rate": 9.325015437718701e-06,
      "loss": 0.0,
      "step": 4263
    },
    {
      "epoch": 0.06751428978577197,
      "grad_norm": 0.2357243150472641,
      "learning_rate": 9.32485710214228e-06,
      "loss": 0.3141,
      "step": 4264
    },
    {
      "epoch": 0.06753012334341403,
      "grad_norm": 0.2865573465824127,
      "learning_rate": 9.324698766565861e-06,
      "loss": 0.3763,
      "step": 4265
    },
    {
      "epoch": 0.0675459569010561,
      "grad_norm": 0.24886739253997803,
      "learning_rate": 9.32454043098944e-06,
      "loss": 0.0445,
      "step": 4266
    },
    {
      "epoch": 0.06756179045869816,
      "grad_norm": 0.00020681375463027507,
      "learning_rate": 9.32438209541302e-06,
      "loss": 0.0,
      "step": 4267
    },
    {
      "epoch": 0.06757762401634024,
      "grad_norm": 0.7769109010696411,
      "learning_rate": 9.324223759836598e-06,
      "loss": 0.5815,
      "step": 4268
    },
    {
      "epoch": 0.0675934575739823,
      "grad_norm": 0.10116798430681229,
      "learning_rate": 9.324065424260177e-06,
      "loss": 0.0019,
      "step": 4269
    },
    {
      "epoch": 0.06760929113162437,
      "grad_norm": 0.70123291015625,
      "learning_rate": 9.323907088683756e-06,
      "loss": 0.6073,
      "step": 4270
    },
    {
      "epoch": 0.06762512468926643,
      "grad_norm": 0.008873814716935158,
      "learning_rate": 9.323748753107337e-06,
      "loss": 0.0003,
      "step": 4271
    },
    {
      "epoch": 0.0676409582469085,
      "grad_norm": 0.003080203663557768,
      "learning_rate": 9.323590417530916e-06,
      "loss": 0.0001,
      "step": 4272
    },
    {
      "epoch": 0.06765679180455056,
      "grad_norm": 0.30868780612945557,
      "learning_rate": 9.323432081954495e-06,
      "loss": 0.162,
      "step": 4273
    },
    {
      "epoch": 0.06767262536219264,
      "grad_norm": 0.012048712931573391,
      "learning_rate": 9.323273746378074e-06,
      "loss": 0.0005,
      "step": 4274
    },
    {
      "epoch": 0.0676884589198347,
      "grad_norm": 0.3459072411060333,
      "learning_rate": 9.323115410801654e-06,
      "loss": 0.0196,
      "step": 4275
    },
    {
      "epoch": 0.06770429247747677,
      "grad_norm": 0.18154367804527283,
      "learning_rate": 9.322957075225233e-06,
      "loss": 0.1149,
      "step": 4276
    },
    {
      "epoch": 0.06772012603511883,
      "grad_norm": 0.19121567904949188,
      "learning_rate": 9.322798739648813e-06,
      "loss": 0.0039,
      "step": 4277
    },
    {
      "epoch": 0.0677359595927609,
      "grad_norm": 0.2564276456832886,
      "learning_rate": 9.322640404072392e-06,
      "loss": 0.1924,
      "step": 4278
    },
    {
      "epoch": 0.06775179315040296,
      "grad_norm": 0.4188845157623291,
      "learning_rate": 9.322482068495972e-06,
      "loss": 0.1946,
      "step": 4279
    },
    {
      "epoch": 0.06776762670804504,
      "grad_norm": 0.004138322081416845,
      "learning_rate": 9.32232373291955e-06,
      "loss": 0.0002,
      "step": 4280
    },
    {
      "epoch": 0.0677834602656871,
      "grad_norm": 0.2578960359096527,
      "learning_rate": 9.32216539734313e-06,
      "loss": 0.0606,
      "step": 4281
    },
    {
      "epoch": 0.06779929382332917,
      "grad_norm": 0.00031714627402834594,
      "learning_rate": 9.322007061766709e-06,
      "loss": 0.0,
      "step": 4282
    },
    {
      "epoch": 0.06781512738097123,
      "grad_norm": 0.17012812197208405,
      "learning_rate": 9.321848726190288e-06,
      "loss": 0.0985,
      "step": 4283
    },
    {
      "epoch": 0.0678309609386133,
      "grad_norm": 0.0002795201726257801,
      "learning_rate": 9.321690390613869e-06,
      "loss": 0.0,
      "step": 4284
    },
    {
      "epoch": 0.06784679449625536,
      "grad_norm": 0.1217031180858612,
      "learning_rate": 9.321532055037446e-06,
      "loss": 0.0787,
      "step": 4285
    },
    {
      "epoch": 0.06786262805389744,
      "grad_norm": 0.2738969624042511,
      "learning_rate": 9.321373719461027e-06,
      "loss": 0.1086,
      "step": 4286
    },
    {
      "epoch": 0.0678784616115395,
      "grad_norm": 0.1647726595401764,
      "learning_rate": 9.321215383884606e-06,
      "loss": 0.004,
      "step": 4287
    },
    {
      "epoch": 0.06789429516918156,
      "grad_norm": 0.26521527767181396,
      "learning_rate": 9.321057048308185e-06,
      "loss": 0.1126,
      "step": 4288
    },
    {
      "epoch": 0.06791012872682363,
      "grad_norm": 0.00010839698370546103,
      "learning_rate": 9.320898712731764e-06,
      "loss": 0.0,
      "step": 4289
    },
    {
      "epoch": 0.0679259622844657,
      "grad_norm": 0.19846847653388977,
      "learning_rate": 9.320740377155345e-06,
      "loss": 0.0882,
      "step": 4290
    },
    {
      "epoch": 0.06794179584210776,
      "grad_norm": 0.009078985080122948,
      "learning_rate": 9.320582041578922e-06,
      "loss": 0.0005,
      "step": 4291
    },
    {
      "epoch": 0.06795762939974984,
      "grad_norm": 0.6774230003356934,
      "learning_rate": 9.320423706002503e-06,
      "loss": 0.4761,
      "step": 4292
    },
    {
      "epoch": 0.0679734629573919,
      "grad_norm": 4.942022800445557,
      "learning_rate": 9.320265370426082e-06,
      "loss": 0.3173,
      "step": 4293
    },
    {
      "epoch": 0.06798929651503396,
      "grad_norm": 0.12882183492183685,
      "learning_rate": 9.320107034849661e-06,
      "loss": 0.0575,
      "step": 4294
    },
    {
      "epoch": 0.06800513007267603,
      "grad_norm": 0.256472647190094,
      "learning_rate": 9.31994869927324e-06,
      "loss": 0.6057,
      "step": 4295
    },
    {
      "epoch": 0.0680209636303181,
      "grad_norm": 0.1678859442472458,
      "learning_rate": 9.31979036369682e-06,
      "loss": 0.085,
      "step": 4296
    },
    {
      "epoch": 0.06803679718796016,
      "grad_norm": 0.01583457924425602,
      "learning_rate": 9.319632028120398e-06,
      "loss": 0.0012,
      "step": 4297
    },
    {
      "epoch": 0.06805263074560224,
      "grad_norm": 0.07052848488092422,
      "learning_rate": 9.319473692543979e-06,
      "loss": 0.0033,
      "step": 4298
    },
    {
      "epoch": 0.0680684643032443,
      "grad_norm": 0.5564801692962646,
      "learning_rate": 9.319315356967558e-06,
      "loss": 0.3268,
      "step": 4299
    },
    {
      "epoch": 0.06808429786088636,
      "grad_norm": 0.011590455658733845,
      "learning_rate": 9.319157021391137e-06,
      "loss": 0.0006,
      "step": 4300
    },
    {
      "epoch": 0.06810013141852843,
      "grad_norm": 0.04496588185429573,
      "learning_rate": 9.318998685814716e-06,
      "loss": 0.0025,
      "step": 4301
    },
    {
      "epoch": 0.06811596497617049,
      "grad_norm": 0.06710422039031982,
      "learning_rate": 9.318840350238295e-06,
      "loss": 0.0052,
      "step": 4302
    },
    {
      "epoch": 0.06813179853381256,
      "grad_norm": 0.00033922045258805156,
      "learning_rate": 9.318682014661875e-06,
      "loss": 0.0,
      "step": 4303
    },
    {
      "epoch": 0.06814763209145464,
      "grad_norm": 0.08819681406021118,
      "learning_rate": 9.318523679085455e-06,
      "loss": 0.0145,
      "step": 4304
    },
    {
      "epoch": 0.0681634656490967,
      "grad_norm": 0.2784889042377472,
      "learning_rate": 9.318365343509034e-06,
      "loss": 0.1513,
      "step": 4305
    },
    {
      "epoch": 0.06817929920673876,
      "grad_norm": 0.33806660771369934,
      "learning_rate": 9.318207007932613e-06,
      "loss": 0.7572,
      "step": 4306
    },
    {
      "epoch": 0.06819513276438083,
      "grad_norm": 0.011162611655890942,
      "learning_rate": 9.318048672356193e-06,
      "loss": 0.0005,
      "step": 4307
    },
    {
      "epoch": 0.06821096632202289,
      "grad_norm": 0.008518240414559841,
      "learning_rate": 9.317890336779772e-06,
      "loss": 0.0004,
      "step": 4308
    },
    {
      "epoch": 0.06822679987966496,
      "grad_norm": 0.5567498803138733,
      "learning_rate": 9.31773200120335e-06,
      "loss": 0.7404,
      "step": 4309
    },
    {
      "epoch": 0.06824263343730703,
      "grad_norm": 0.29255303740501404,
      "learning_rate": 9.31757366562693e-06,
      "loss": 0.2066,
      "step": 4310
    },
    {
      "epoch": 0.0682584669949491,
      "grad_norm": 0.00011486974835861474,
      "learning_rate": 9.31741533005051e-06,
      "loss": 0.0,
      "step": 4311
    },
    {
      "epoch": 0.06827430055259116,
      "grad_norm": 0.15186530351638794,
      "learning_rate": 9.317256994474088e-06,
      "loss": 0.1053,
      "step": 4312
    },
    {
      "epoch": 0.06829013411023323,
      "grad_norm": 0.00010241343261441216,
      "learning_rate": 9.317098658897669e-06,
      "loss": 0.0,
      "step": 4313
    },
    {
      "epoch": 0.06830596766787529,
      "grad_norm": 0.03303888067603111,
      "learning_rate": 9.316940323321248e-06,
      "loss": 0.0021,
      "step": 4314
    },
    {
      "epoch": 0.06832180122551736,
      "grad_norm": 0.20677287876605988,
      "learning_rate": 9.316781987744827e-06,
      "loss": 0.1028,
      "step": 4315
    },
    {
      "epoch": 0.06833763478315943,
      "grad_norm": 0.1652238965034485,
      "learning_rate": 9.316623652168406e-06,
      "loss": 0.0383,
      "step": 4316
    },
    {
      "epoch": 0.0683534683408015,
      "grad_norm": 0.448843389749527,
      "learning_rate": 9.316465316591987e-06,
      "loss": 0.0397,
      "step": 4317
    },
    {
      "epoch": 0.06836930189844356,
      "grad_norm": 0.2891272306442261,
      "learning_rate": 9.316306981015564e-06,
      "loss": 0.2226,
      "step": 4318
    },
    {
      "epoch": 0.06838513545608563,
      "grad_norm": 0.21548540890216827,
      "learning_rate": 9.316148645439145e-06,
      "loss": 0.2151,
      "step": 4319
    },
    {
      "epoch": 0.06840096901372769,
      "grad_norm": 0.00027527380734682083,
      "learning_rate": 9.315990309862724e-06,
      "loss": 0.0,
      "step": 4320
    },
    {
      "epoch": 0.06841680257136976,
      "grad_norm": 0.5346307158470154,
      "learning_rate": 9.315831974286303e-06,
      "loss": 0.6409,
      "step": 4321
    },
    {
      "epoch": 0.06843263612901183,
      "grad_norm": 0.2791980803012848,
      "learning_rate": 9.315673638709882e-06,
      "loss": 0.0651,
      "step": 4322
    },
    {
      "epoch": 0.0684484696866539,
      "grad_norm": 0.006382335908710957,
      "learning_rate": 9.315515303133463e-06,
      "loss": 0.0003,
      "step": 4323
    },
    {
      "epoch": 0.06846430324429596,
      "grad_norm": 0.24663704633712769,
      "learning_rate": 9.31535696755704e-06,
      "loss": 0.194,
      "step": 4324
    },
    {
      "epoch": 0.06848013680193803,
      "grad_norm": 0.0005017005023546517,
      "learning_rate": 9.315198631980621e-06,
      "loss": 0.0,
      "step": 4325
    },
    {
      "epoch": 0.06849597035958009,
      "grad_norm": 0.3964652121067047,
      "learning_rate": 9.3150402964042e-06,
      "loss": 0.6902,
      "step": 4326
    },
    {
      "epoch": 0.06851180391722216,
      "grad_norm": 0.245501309633255,
      "learning_rate": 9.31488196082778e-06,
      "loss": 0.1919,
      "step": 4327
    },
    {
      "epoch": 0.06852763747486423,
      "grad_norm": 0.00335508119314909,
      "learning_rate": 9.314723625251358e-06,
      "loss": 0.0002,
      "step": 4328
    },
    {
      "epoch": 0.0685434710325063,
      "grad_norm": 0.0001732672390062362,
      "learning_rate": 9.314565289674939e-06,
      "loss": 0.0,
      "step": 4329
    },
    {
      "epoch": 0.06855930459014836,
      "grad_norm": 0.29265403747558594,
      "learning_rate": 9.314406954098516e-06,
      "loss": 0.0715,
      "step": 4330
    },
    {
      "epoch": 0.06857513814779043,
      "grad_norm": 0.16115324199199677,
      "learning_rate": 9.314248618522096e-06,
      "loss": 0.0511,
      "step": 4331
    },
    {
      "epoch": 0.06859097170543249,
      "grad_norm": 0.3377697467803955,
      "learning_rate": 9.314090282945676e-06,
      "loss": 0.3941,
      "step": 4332
    },
    {
      "epoch": 0.06860680526307456,
      "grad_norm": 0.04636551812291145,
      "learning_rate": 9.313931947369255e-06,
      "loss": 0.0007,
      "step": 4333
    },
    {
      "epoch": 0.06862263882071663,
      "grad_norm": 1.6701778173446655,
      "learning_rate": 9.313773611792834e-06,
      "loss": 0.7557,
      "step": 4334
    },
    {
      "epoch": 0.0686384723783587,
      "grad_norm": 0.0628037303686142,
      "learning_rate": 9.313615276216414e-06,
      "loss": 0.0029,
      "step": 4335
    },
    {
      "epoch": 0.06865430593600076,
      "grad_norm": 0.2650963366031647,
      "learning_rate": 9.313456940639993e-06,
      "loss": 0.346,
      "step": 4336
    },
    {
      "epoch": 0.06867013949364283,
      "grad_norm": 0.21742209792137146,
      "learning_rate": 9.313298605063572e-06,
      "loss": 0.1078,
      "step": 4337
    },
    {
      "epoch": 0.06868597305128489,
      "grad_norm": 0.006426901090890169,
      "learning_rate": 9.313140269487152e-06,
      "loss": 0.0004,
      "step": 4338
    },
    {
      "epoch": 0.06870180660892695,
      "grad_norm": 0.1944754719734192,
      "learning_rate": 9.312981933910732e-06,
      "loss": 0.0742,
      "step": 4339
    },
    {
      "epoch": 0.06871764016656903,
      "grad_norm": 0.20966659486293793,
      "learning_rate": 9.31282359833431e-06,
      "loss": 0.0966,
      "step": 4340
    },
    {
      "epoch": 0.0687334737242111,
      "grad_norm": 0.15321367979049683,
      "learning_rate": 9.31266526275789e-06,
      "loss": 0.0114,
      "step": 4341
    },
    {
      "epoch": 0.06874930728185316,
      "grad_norm": 0.27152150869369507,
      "learning_rate": 9.312506927181469e-06,
      "loss": 0.0901,
      "step": 4342
    },
    {
      "epoch": 0.06876514083949523,
      "grad_norm": 0.48928049206733704,
      "learning_rate": 9.312348591605048e-06,
      "loss": 0.6961,
      "step": 4343
    },
    {
      "epoch": 0.06878097439713729,
      "grad_norm": 0.033319104462862015,
      "learning_rate": 9.312190256028629e-06,
      "loss": 0.0019,
      "step": 4344
    },
    {
      "epoch": 0.06879680795477935,
      "grad_norm": 0.09119877219200134,
      "learning_rate": 9.312031920452208e-06,
      "loss": 0.0077,
      "step": 4345
    },
    {
      "epoch": 0.06881264151242143,
      "grad_norm": 0.37460070848464966,
      "learning_rate": 9.311873584875787e-06,
      "loss": 0.1038,
      "step": 4346
    },
    {
      "epoch": 0.0688284750700635,
      "grad_norm": 0.0017458742950111628,
      "learning_rate": 9.311715249299366e-06,
      "loss": 0.0001,
      "step": 4347
    },
    {
      "epoch": 0.06884430862770556,
      "grad_norm": 0.3296549916267395,
      "learning_rate": 9.311556913722945e-06,
      "loss": 0.1646,
      "step": 4348
    },
    {
      "epoch": 0.06886014218534763,
      "grad_norm": 0.2007635235786438,
      "learning_rate": 9.311398578146524e-06,
      "loss": 0.0279,
      "step": 4349
    },
    {
      "epoch": 0.06887597574298969,
      "grad_norm": 0.0035653547383844852,
      "learning_rate": 9.311240242570105e-06,
      "loss": 0.0001,
      "step": 4350
    },
    {
      "epoch": 0.06889180930063175,
      "grad_norm": 0.42731958627700806,
      "learning_rate": 9.311081906993684e-06,
      "loss": 0.241,
      "step": 4351
    },
    {
      "epoch": 0.06890764285827383,
      "grad_norm": 0.6742885708808899,
      "learning_rate": 9.310923571417263e-06,
      "loss": 0.2062,
      "step": 4352
    },
    {
      "epoch": 0.0689234764159159,
      "grad_norm": 0.002963688690215349,
      "learning_rate": 9.310765235840842e-06,
      "loss": 0.0002,
      "step": 4353
    },
    {
      "epoch": 0.06893930997355796,
      "grad_norm": 0.12526176869869232,
      "learning_rate": 9.310606900264421e-06,
      "loss": 0.0914,
      "step": 4354
    },
    {
      "epoch": 0.06895514353120002,
      "grad_norm": 0.014557369984686375,
      "learning_rate": 9.310448564688e-06,
      "loss": 0.0005,
      "step": 4355
    },
    {
      "epoch": 0.06897097708884209,
      "grad_norm": 0.14188455045223236,
      "learning_rate": 9.31029022911158e-06,
      "loss": 0.0652,
      "step": 4356
    },
    {
      "epoch": 0.06898681064648415,
      "grad_norm": 0.008121710270643234,
      "learning_rate": 9.31013189353516e-06,
      "loss": 0.0004,
      "step": 4357
    },
    {
      "epoch": 0.06900264420412623,
      "grad_norm": 0.0012655251193791628,
      "learning_rate": 9.309973557958737e-06,
      "loss": 0.0,
      "step": 4358
    },
    {
      "epoch": 0.0690184777617683,
      "grad_norm": 0.14109398424625397,
      "learning_rate": 9.309815222382318e-06,
      "loss": 0.0518,
      "step": 4359
    },
    {
      "epoch": 0.06903431131941036,
      "grad_norm": 0.2186834067106247,
      "learning_rate": 9.309656886805897e-06,
      "loss": 0.2091,
      "step": 4360
    },
    {
      "epoch": 0.06905014487705242,
      "grad_norm": 0.43937814235687256,
      "learning_rate": 9.309498551229476e-06,
      "loss": 0.2981,
      "step": 4361
    },
    {
      "epoch": 0.06906597843469449,
      "grad_norm": 0.0007547453860752285,
      "learning_rate": 9.309340215653055e-06,
      "loss": 0.0,
      "step": 4362
    },
    {
      "epoch": 0.06908181199233655,
      "grad_norm": 0.11650510132312775,
      "learning_rate": 9.309181880076635e-06,
      "loss": 0.1946,
      "step": 4363
    },
    {
      "epoch": 0.06909764554997863,
      "grad_norm": 0.00018641586939338595,
      "learning_rate": 9.309023544500214e-06,
      "loss": 0.0,
      "step": 4364
    },
    {
      "epoch": 0.0691134791076207,
      "grad_norm": 0.312203049659729,
      "learning_rate": 9.308865208923794e-06,
      "loss": 0.1385,
      "step": 4365
    },
    {
      "epoch": 0.06912931266526276,
      "grad_norm": 0.18990476429462433,
      "learning_rate": 9.308706873347373e-06,
      "loss": 0.0353,
      "step": 4366
    },
    {
      "epoch": 0.06914514622290482,
      "grad_norm": 0.17807482182979584,
      "learning_rate": 9.308548537770953e-06,
      "loss": 0.0839,
      "step": 4367
    },
    {
      "epoch": 0.06916097978054689,
      "grad_norm": 0.13257770240306854,
      "learning_rate": 9.308390202194532e-06,
      "loss": 0.0674,
      "step": 4368
    },
    {
      "epoch": 0.06917681333818895,
      "grad_norm": 0.043822724372148514,
      "learning_rate": 9.30823186661811e-06,
      "loss": 0.0026,
      "step": 4369
    },
    {
      "epoch": 0.06919264689583103,
      "grad_norm": 0.008173107169568539,
      "learning_rate": 9.30807353104169e-06,
      "loss": 0.0002,
      "step": 4370
    },
    {
      "epoch": 0.0692084804534731,
      "grad_norm": 0.00018028072372544557,
      "learning_rate": 9.30791519546527e-06,
      "loss": 0.0,
      "step": 4371
    },
    {
      "epoch": 0.06922431401111516,
      "grad_norm": 0.27797406911849976,
      "learning_rate": 9.30775685988885e-06,
      "loss": 0.6538,
      "step": 4372
    },
    {
      "epoch": 0.06924014756875722,
      "grad_norm": 0.18072333931922913,
      "learning_rate": 9.307598524312429e-06,
      "loss": 0.0652,
      "step": 4373
    },
    {
      "epoch": 0.06925598112639929,
      "grad_norm": 0.4364873170852661,
      "learning_rate": 9.307440188736008e-06,
      "loss": 0.0322,
      "step": 4374
    },
    {
      "epoch": 0.06927181468404135,
      "grad_norm": 0.17686738073825836,
      "learning_rate": 9.307281853159587e-06,
      "loss": 0.0333,
      "step": 4375
    },
    {
      "epoch": 0.06928764824168343,
      "grad_norm": 0.17507623136043549,
      "learning_rate": 9.307123517583166e-06,
      "loss": 0.1019,
      "step": 4376
    },
    {
      "epoch": 0.0693034817993255,
      "grad_norm": 0.0005733692669309676,
      "learning_rate": 9.306965182006747e-06,
      "loss": 0.0,
      "step": 4377
    },
    {
      "epoch": 0.06931931535696756,
      "grad_norm": 0.2760917842388153,
      "learning_rate": 9.306806846430326e-06,
      "loss": 0.0492,
      "step": 4378
    },
    {
      "epoch": 0.06933514891460962,
      "grad_norm": 0.0028996351175010204,
      "learning_rate": 9.306648510853903e-06,
      "loss": 0.0002,
      "step": 4379
    },
    {
      "epoch": 0.06935098247225169,
      "grad_norm": 0.2039431482553482,
      "learning_rate": 9.306490175277484e-06,
      "loss": 0.1977,
      "step": 4380
    },
    {
      "epoch": 0.06936681602989375,
      "grad_norm": 0.26532068848609924,
      "learning_rate": 9.306331839701063e-06,
      "loss": 0.0694,
      "step": 4381
    },
    {
      "epoch": 0.06938264958753583,
      "grad_norm": 0.0006092839757911861,
      "learning_rate": 9.306173504124642e-06,
      "loss": 0.0,
      "step": 4382
    },
    {
      "epoch": 0.0693984831451779,
      "grad_norm": 0.2229020595550537,
      "learning_rate": 9.306015168548221e-06,
      "loss": 0.1858,
      "step": 4383
    },
    {
      "epoch": 0.06941431670281996,
      "grad_norm": 0.013604494743049145,
      "learning_rate": 9.305856832971802e-06,
      "loss": 0.0008,
      "step": 4384
    },
    {
      "epoch": 0.06943015026046202,
      "grad_norm": 0.3936171531677246,
      "learning_rate": 9.30569849739538e-06,
      "loss": 0.0835,
      "step": 4385
    },
    {
      "epoch": 0.06944598381810409,
      "grad_norm": 0.004322613589465618,
      "learning_rate": 9.30554016181896e-06,
      "loss": 0.0002,
      "step": 4386
    },
    {
      "epoch": 0.06946181737574615,
      "grad_norm": 0.012804587371647358,
      "learning_rate": 9.30538182624254e-06,
      "loss": 0.0006,
      "step": 4387
    },
    {
      "epoch": 0.06947765093338823,
      "grad_norm": 0.00046495551941916347,
      "learning_rate": 9.305223490666118e-06,
      "loss": 0.0,
      "step": 4388
    },
    {
      "epoch": 0.0694934844910303,
      "grad_norm": 0.2995244264602661,
      "learning_rate": 9.305065155089697e-06,
      "loss": 0.095,
      "step": 4389
    },
    {
      "epoch": 0.06950931804867236,
      "grad_norm": 0.27910658717155457,
      "learning_rate": 9.304906819513278e-06,
      "loss": 0.0814,
      "step": 4390
    },
    {
      "epoch": 0.06952515160631442,
      "grad_norm": 0.4194961488246918,
      "learning_rate": 9.304748483936856e-06,
      "loss": 0.3193,
      "step": 4391
    },
    {
      "epoch": 0.06954098516395649,
      "grad_norm": 0.2898971140384674,
      "learning_rate": 9.304590148360436e-06,
      "loss": 0.0914,
      "step": 4392
    },
    {
      "epoch": 0.06955681872159855,
      "grad_norm": 0.013365182094275951,
      "learning_rate": 9.304431812784015e-06,
      "loss": 0.0013,
      "step": 4393
    },
    {
      "epoch": 0.06957265227924063,
      "grad_norm": 0.20832529664039612,
      "learning_rate": 9.304273477207594e-06,
      "loss": 0.162,
      "step": 4394
    },
    {
      "epoch": 0.0695884858368827,
      "grad_norm": 0.21357180178165436,
      "learning_rate": 9.304115141631174e-06,
      "loss": 0.0834,
      "step": 4395
    },
    {
      "epoch": 0.06960431939452476,
      "grad_norm": 0.04249883070588112,
      "learning_rate": 9.303956806054754e-06,
      "loss": 0.0007,
      "step": 4396
    },
    {
      "epoch": 0.06962015295216682,
      "grad_norm": 0.18742001056671143,
      "learning_rate": 9.303798470478332e-06,
      "loss": 0.0593,
      "step": 4397
    },
    {
      "epoch": 0.06963598650980889,
      "grad_norm": 0.35433194041252136,
      "learning_rate": 9.303640134901912e-06,
      "loss": 0.0823,
      "step": 4398
    },
    {
      "epoch": 0.06965182006745095,
      "grad_norm": 0.011350274085998535,
      "learning_rate": 9.303481799325492e-06,
      "loss": 0.0006,
      "step": 4399
    },
    {
      "epoch": 0.06966765362509303,
      "grad_norm": 0.33288633823394775,
      "learning_rate": 9.30332346374907e-06,
      "loss": 0.4602,
      "step": 4400
    },
    {
      "epoch": 0.0696834871827351,
      "grad_norm": 0.5227235555648804,
      "learning_rate": 9.30316512817265e-06,
      "loss": 0.4022,
      "step": 4401
    },
    {
      "epoch": 0.06969932074037716,
      "grad_norm": 0.3069831132888794,
      "learning_rate": 9.30300679259623e-06,
      "loss": 0.2627,
      "step": 4402
    },
    {
      "epoch": 0.06971515429801922,
      "grad_norm": 0.11839550733566284,
      "learning_rate": 9.302848457019808e-06,
      "loss": 0.0311,
      "step": 4403
    },
    {
      "epoch": 0.06973098785566129,
      "grad_norm": 0.0004723839520011097,
      "learning_rate": 9.302690121443387e-06,
      "loss": 0.0,
      "step": 4404
    },
    {
      "epoch": 0.06974682141330335,
      "grad_norm": 0.26702621579170227,
      "learning_rate": 9.302531785866968e-06,
      "loss": 0.2122,
      "step": 4405
    },
    {
      "epoch": 0.06976265497094543,
      "grad_norm": 0.15085576474666595,
      "learning_rate": 9.302373450290547e-06,
      "loss": 0.054,
      "step": 4406
    },
    {
      "epoch": 0.06977848852858749,
      "grad_norm": 0.20919185876846313,
      "learning_rate": 9.302215114714126e-06,
      "loss": 0.006,
      "step": 4407
    },
    {
      "epoch": 0.06979432208622956,
      "grad_norm": 0.0004961001686751842,
      "learning_rate": 9.302056779137705e-06,
      "loss": 0.0,
      "step": 4408
    },
    {
      "epoch": 0.06981015564387162,
      "grad_norm": 0.20107433199882507,
      "learning_rate": 9.301898443561284e-06,
      "loss": 0.0891,
      "step": 4409
    },
    {
      "epoch": 0.06982598920151369,
      "grad_norm": 0.6844995617866516,
      "learning_rate": 9.301740107984863e-06,
      "loss": 0.0269,
      "step": 4410
    },
    {
      "epoch": 0.06984182275915575,
      "grad_norm": 0.13759301602840424,
      "learning_rate": 9.301581772408444e-06,
      "loss": 0.0936,
      "step": 4411
    },
    {
      "epoch": 0.06985765631679783,
      "grad_norm": 0.25996366143226624,
      "learning_rate": 9.301423436832023e-06,
      "loss": 0.3821,
      "step": 4412
    },
    {
      "epoch": 0.06987348987443989,
      "grad_norm": 0.6083376407623291,
      "learning_rate": 9.301265101255602e-06,
      "loss": 0.0491,
      "step": 4413
    },
    {
      "epoch": 0.06988932343208196,
      "grad_norm": 0.009021615609526634,
      "learning_rate": 9.301106765679181e-06,
      "loss": 0.0006,
      "step": 4414
    },
    {
      "epoch": 0.06990515698972402,
      "grad_norm": 0.1798398643732071,
      "learning_rate": 9.30094843010276e-06,
      "loss": 0.0954,
      "step": 4415
    },
    {
      "epoch": 0.06992099054736609,
      "grad_norm": 0.34314945340156555,
      "learning_rate": 9.30079009452634e-06,
      "loss": 0.2127,
      "step": 4416
    },
    {
      "epoch": 0.06993682410500815,
      "grad_norm": 0.0013563017128035426,
      "learning_rate": 9.30063175894992e-06,
      "loss": 0.0001,
      "step": 4417
    },
    {
      "epoch": 0.06995265766265023,
      "grad_norm": 0.007316007278859615,
      "learning_rate": 9.3004734233735e-06,
      "loss": 0.0003,
      "step": 4418
    },
    {
      "epoch": 0.06996849122029229,
      "grad_norm": 0.1398492157459259,
      "learning_rate": 9.300315087797078e-06,
      "loss": 0.0583,
      "step": 4419
    },
    {
      "epoch": 0.06998432477793436,
      "grad_norm": 0.3988648056983948,
      "learning_rate": 9.300156752220657e-06,
      "loss": 0.013,
      "step": 4420
    },
    {
      "epoch": 0.07000015833557642,
      "grad_norm": 0.03519033268094063,
      "learning_rate": 9.299998416644236e-06,
      "loss": 0.0018,
      "step": 4421
    },
    {
      "epoch": 0.07001599189321848,
      "grad_norm": 0.1513431966304779,
      "learning_rate": 9.299840081067815e-06,
      "loss": 0.0824,
      "step": 4422
    },
    {
      "epoch": 0.07003182545086055,
      "grad_norm": 0.43514546751976013,
      "learning_rate": 9.299681745491396e-06,
      "loss": 0.1194,
      "step": 4423
    },
    {
      "epoch": 0.07004765900850263,
      "grad_norm": 0.20025348663330078,
      "learning_rate": 9.299523409914975e-06,
      "loss": 0.1126,
      "step": 4424
    },
    {
      "epoch": 0.07006349256614469,
      "grad_norm": 0.16563118994235992,
      "learning_rate": 9.299365074338554e-06,
      "loss": 0.0723,
      "step": 4425
    },
    {
      "epoch": 0.07007932612378676,
      "grad_norm": 0.0032842424698174,
      "learning_rate": 9.299206738762133e-06,
      "loss": 0.0002,
      "step": 4426
    },
    {
      "epoch": 0.07009515968142882,
      "grad_norm": 0.00011902240657946095,
      "learning_rate": 9.299048403185713e-06,
      "loss": 0.0,
      "step": 4427
    },
    {
      "epoch": 0.07011099323907088,
      "grad_norm": 0.13452307879924774,
      "learning_rate": 9.298890067609292e-06,
      "loss": 0.0162,
      "step": 4428
    },
    {
      "epoch": 0.07012682679671295,
      "grad_norm": 0.6092796921730042,
      "learning_rate": 9.29873173203287e-06,
      "loss": 0.4684,
      "step": 4429
    },
    {
      "epoch": 0.07014266035435501,
      "grad_norm": 6.871859659440815e-05,
      "learning_rate": 9.29857339645645e-06,
      "loss": 0.0,
      "step": 4430
    },
    {
      "epoch": 0.07015849391199709,
      "grad_norm": 0.2087942659854889,
      "learning_rate": 9.298415060880029e-06,
      "loss": 0.0796,
      "step": 4431
    },
    {
      "epoch": 0.07017432746963916,
      "grad_norm": 0.34871402382850647,
      "learning_rate": 9.29825672530361e-06,
      "loss": 0.4638,
      "step": 4432
    },
    {
      "epoch": 0.07019016102728122,
      "grad_norm": 0.006683968473225832,
      "learning_rate": 9.298098389727189e-06,
      "loss": 0.0002,
      "step": 4433
    },
    {
      "epoch": 0.07020599458492328,
      "grad_norm": 0.6952570080757141,
      "learning_rate": 9.297940054150768e-06,
      "loss": 0.0611,
      "step": 4434
    },
    {
      "epoch": 0.07022182814256535,
      "grad_norm": 0.039236925542354584,
      "learning_rate": 9.297781718574347e-06,
      "loss": 0.0021,
      "step": 4435
    },
    {
      "epoch": 0.07023766170020741,
      "grad_norm": 0.006787124555557966,
      "learning_rate": 9.297623382997926e-06,
      "loss": 0.0003,
      "step": 4436
    },
    {
      "epoch": 0.07025349525784949,
      "grad_norm": 0.1665227711200714,
      "learning_rate": 9.297465047421505e-06,
      "loss": 0.0047,
      "step": 4437
    },
    {
      "epoch": 0.07026932881549156,
      "grad_norm": 0.1653217226266861,
      "learning_rate": 9.297306711845086e-06,
      "loss": 0.0878,
      "step": 4438
    },
    {
      "epoch": 0.07028516237313362,
      "grad_norm": 0.18419259786605835,
      "learning_rate": 9.297148376268665e-06,
      "loss": 0.0807,
      "step": 4439
    },
    {
      "epoch": 0.07030099593077568,
      "grad_norm": 0.31200456619262695,
      "learning_rate": 9.296990040692244e-06,
      "loss": 0.1547,
      "step": 4440
    },
    {
      "epoch": 0.07031682948841775,
      "grad_norm": 0.01308570709079504,
      "learning_rate": 9.296831705115823e-06,
      "loss": 0.0008,
      "step": 4441
    },
    {
      "epoch": 0.07033266304605981,
      "grad_norm": 0.5750662684440613,
      "learning_rate": 9.296673369539402e-06,
      "loss": 0.2707,
      "step": 4442
    },
    {
      "epoch": 0.07034849660370189,
      "grad_norm": 0.013214172795414925,
      "learning_rate": 9.296515033962981e-06,
      "loss": 0.0007,
      "step": 4443
    },
    {
      "epoch": 0.07036433016134395,
      "grad_norm": 0.8027545213699341,
      "learning_rate": 9.296356698386562e-06,
      "loss": 0.1922,
      "step": 4444
    },
    {
      "epoch": 0.07038016371898602,
      "grad_norm": 0.4719853699207306,
      "learning_rate": 9.296198362810141e-06,
      "loss": 0.2548,
      "step": 4445
    },
    {
      "epoch": 0.07039599727662808,
      "grad_norm": 0.23893465101718903,
      "learning_rate": 9.29604002723372e-06,
      "loss": 0.1884,
      "step": 4446
    },
    {
      "epoch": 0.07041183083427015,
      "grad_norm": 0.20920692384243011,
      "learning_rate": 9.2958816916573e-06,
      "loss": 0.0847,
      "step": 4447
    },
    {
      "epoch": 0.07042766439191221,
      "grad_norm": 0.0005500360275618732,
      "learning_rate": 9.295723356080878e-06,
      "loss": 0.0,
      "step": 4448
    },
    {
      "epoch": 0.07044349794955429,
      "grad_norm": 0.4511182904243469,
      "learning_rate": 9.295565020504457e-06,
      "loss": 0.3208,
      "step": 4449
    },
    {
      "epoch": 0.07045933150719635,
      "grad_norm": 0.4504566788673401,
      "learning_rate": 9.295406684928038e-06,
      "loss": 0.1579,
      "step": 4450
    },
    {
      "epoch": 0.07047516506483842,
      "grad_norm": 0.23035284876823425,
      "learning_rate": 9.295248349351617e-06,
      "loss": 0.1253,
      "step": 4451
    },
    {
      "epoch": 0.07049099862248048,
      "grad_norm": 0.37307438254356384,
      "learning_rate": 9.295090013775195e-06,
      "loss": 0.1281,
      "step": 4452
    },
    {
      "epoch": 0.07050683218012255,
      "grad_norm": 0.3994351029396057,
      "learning_rate": 9.294931678198775e-06,
      "loss": 0.0682,
      "step": 4453
    },
    {
      "epoch": 0.07052266573776461,
      "grad_norm": 0.2642732262611389,
      "learning_rate": 9.294773342622354e-06,
      "loss": 0.1438,
      "step": 4454
    },
    {
      "epoch": 0.07053849929540669,
      "grad_norm": 0.47264158725738525,
      "learning_rate": 9.294615007045934e-06,
      "loss": 0.0266,
      "step": 4455
    },
    {
      "epoch": 0.07055433285304875,
      "grad_norm": 0.4139178395271301,
      "learning_rate": 9.294456671469513e-06,
      "loss": 0.2734,
      "step": 4456
    },
    {
      "epoch": 0.07057016641069082,
      "grad_norm": 0.0021281512454152107,
      "learning_rate": 9.294298335893093e-06,
      "loss": 0.0001,
      "step": 4457
    },
    {
      "epoch": 0.07058599996833288,
      "grad_norm": 0.014744045212864876,
      "learning_rate": 9.29414000031667e-06,
      "loss": 0.0006,
      "step": 4458
    },
    {
      "epoch": 0.07060183352597495,
      "grad_norm": 0.11338665336370468,
      "learning_rate": 9.293981664740252e-06,
      "loss": 0.0726,
      "step": 4459
    },
    {
      "epoch": 0.07061766708361701,
      "grad_norm": 0.0008438777294941247,
      "learning_rate": 9.29382332916383e-06,
      "loss": 0.0,
      "step": 4460
    },
    {
      "epoch": 0.07063350064125909,
      "grad_norm": 0.20218400657176971,
      "learning_rate": 9.29366499358741e-06,
      "loss": 0.1413,
      "step": 4461
    },
    {
      "epoch": 0.07064933419890115,
      "grad_norm": 0.3872023820877075,
      "learning_rate": 9.293506658010989e-06,
      "loss": 0.2635,
      "step": 4462
    },
    {
      "epoch": 0.07066516775654322,
      "grad_norm": 0.23414526879787445,
      "learning_rate": 9.29334832243457e-06,
      "loss": 0.0361,
      "step": 4463
    },
    {
      "epoch": 0.07068100131418528,
      "grad_norm": 0.1604437381029129,
      "learning_rate": 9.293189986858147e-06,
      "loss": 0.064,
      "step": 4464
    },
    {
      "epoch": 0.07069683487182735,
      "grad_norm": 0.23413634300231934,
      "learning_rate": 9.293031651281728e-06,
      "loss": 0.0628,
      "step": 4465
    },
    {
      "epoch": 0.07071266842946941,
      "grad_norm": 0.07263675332069397,
      "learning_rate": 9.292873315705307e-06,
      "loss": 0.0056,
      "step": 4466
    },
    {
      "epoch": 0.07072850198711149,
      "grad_norm": 0.18645265698432922,
      "learning_rate": 9.292714980128886e-06,
      "loss": 0.0857,
      "step": 4467
    },
    {
      "epoch": 0.07074433554475355,
      "grad_norm": 0.40640154480934143,
      "learning_rate": 9.292556644552465e-06,
      "loss": 0.2457,
      "step": 4468
    },
    {
      "epoch": 0.07076016910239562,
      "grad_norm": 0.320052832365036,
      "learning_rate": 9.292398308976046e-06,
      "loss": 0.0479,
      "step": 4469
    },
    {
      "epoch": 0.07077600266003768,
      "grad_norm": 0.2554054260253906,
      "learning_rate": 9.292239973399623e-06,
      "loss": 0.0775,
      "step": 4470
    },
    {
      "epoch": 0.07079183621767975,
      "grad_norm": 0.18612949550151825,
      "learning_rate": 9.292081637823204e-06,
      "loss": 0.0735,
      "step": 4471
    },
    {
      "epoch": 0.07080766977532181,
      "grad_norm": 0.2971772253513336,
      "learning_rate": 9.291923302246783e-06,
      "loss": 0.3158,
      "step": 4472
    },
    {
      "epoch": 0.07082350333296389,
      "grad_norm": 0.10504749417304993,
      "learning_rate": 9.291764966670362e-06,
      "loss": 0.0375,
      "step": 4473
    },
    {
      "epoch": 0.07083933689060595,
      "grad_norm": 0.3034217655658722,
      "learning_rate": 9.291606631093941e-06,
      "loss": 0.0774,
      "step": 4474
    },
    {
      "epoch": 0.07085517044824802,
      "grad_norm": 0.010226557962596416,
      "learning_rate": 9.291448295517522e-06,
      "loss": 0.0004,
      "step": 4475
    },
    {
      "epoch": 0.07087100400589008,
      "grad_norm": 0.2733875513076782,
      "learning_rate": 9.2912899599411e-06,
      "loss": 0.0061,
      "step": 4476
    },
    {
      "epoch": 0.07088683756353215,
      "grad_norm": 0.2154654860496521,
      "learning_rate": 9.291131624364678e-06,
      "loss": 0.1667,
      "step": 4477
    },
    {
      "epoch": 0.07090267112117421,
      "grad_norm": 0.2984786927700043,
      "learning_rate": 9.29097328878826e-06,
      "loss": 0.3308,
      "step": 4478
    },
    {
      "epoch": 0.07091850467881629,
      "grad_norm": 0.20757880806922913,
      "learning_rate": 9.290814953211838e-06,
      "loss": 0.1001,
      "step": 4479
    },
    {
      "epoch": 0.07093433823645835,
      "grad_norm": 0.2671177089214325,
      "learning_rate": 9.290656617635417e-06,
      "loss": 0.1811,
      "step": 4480
    },
    {
      "epoch": 0.07095017179410042,
      "grad_norm": 0.568147599697113,
      "learning_rate": 9.290498282058996e-06,
      "loss": 0.019,
      "step": 4481
    },
    {
      "epoch": 0.07096600535174248,
      "grad_norm": 0.0013162180548533797,
      "learning_rate": 9.290339946482575e-06,
      "loss": 0.0,
      "step": 4482
    },
    {
      "epoch": 0.07098183890938455,
      "grad_norm": 0.23904770612716675,
      "learning_rate": 9.290181610906155e-06,
      "loss": 0.2063,
      "step": 4483
    },
    {
      "epoch": 0.07099767246702661,
      "grad_norm": 0.3463263511657715,
      "learning_rate": 9.290023275329735e-06,
      "loss": 0.2021,
      "step": 4484
    },
    {
      "epoch": 0.07101350602466869,
      "grad_norm": 0.2873398959636688,
      "learning_rate": 9.289864939753314e-06,
      "loss": 0.1717,
      "step": 4485
    },
    {
      "epoch": 0.07102933958231075,
      "grad_norm": 0.5423697233200073,
      "learning_rate": 9.289706604176894e-06,
      "loss": 0.4062,
      "step": 4486
    },
    {
      "epoch": 0.07104517313995282,
      "grad_norm": 0.0011998639674857259,
      "learning_rate": 9.289548268600473e-06,
      "loss": 0.0,
      "step": 4487
    },
    {
      "epoch": 0.07106100669759488,
      "grad_norm": 0.5709480047225952,
      "learning_rate": 9.289389933024052e-06,
      "loss": 1.0159,
      "step": 4488
    },
    {
      "epoch": 0.07107684025523694,
      "grad_norm": 0.9925618767738342,
      "learning_rate": 9.28923159744763e-06,
      "loss": 0.0538,
      "step": 4489
    },
    {
      "epoch": 0.07109267381287901,
      "grad_norm": 0.4273871183395386,
      "learning_rate": 9.289073261871212e-06,
      "loss": 0.2159,
      "step": 4490
    },
    {
      "epoch": 0.07110850737052109,
      "grad_norm": 0.12073656916618347,
      "learning_rate": 9.288914926294789e-06,
      "loss": 0.0158,
      "step": 4491
    },
    {
      "epoch": 0.07112434092816315,
      "grad_norm": 0.2559122145175934,
      "learning_rate": 9.28875659071837e-06,
      "loss": 0.1046,
      "step": 4492
    },
    {
      "epoch": 0.07114017448580522,
      "grad_norm": 0.03152807429432869,
      "learning_rate": 9.288598255141949e-06,
      "loss": 0.0018,
      "step": 4493
    },
    {
      "epoch": 0.07115600804344728,
      "grad_norm": 0.35506901144981384,
      "learning_rate": 9.288439919565528e-06,
      "loss": 0.0266,
      "step": 4494
    },
    {
      "epoch": 0.07117184160108934,
      "grad_norm": 0.055573057383298874,
      "learning_rate": 9.288281583989107e-06,
      "loss": 0.0212,
      "step": 4495
    },
    {
      "epoch": 0.07118767515873141,
      "grad_norm": 0.1462550014257431,
      "learning_rate": 9.288123248412688e-06,
      "loss": 0.0043,
      "step": 4496
    },
    {
      "epoch": 0.07120350871637349,
      "grad_norm": 0.25524482131004333,
      "learning_rate": 9.287964912836265e-06,
      "loss": 0.1076,
      "step": 4497
    },
    {
      "epoch": 0.07121934227401555,
      "grad_norm": 0.36768868565559387,
      "learning_rate": 9.287806577259846e-06,
      "loss": 0.4716,
      "step": 4498
    },
    {
      "epoch": 0.07123517583165762,
      "grad_norm": 0.38674023747444153,
      "learning_rate": 9.287648241683425e-06,
      "loss": 0.5321,
      "step": 4499
    },
    {
      "epoch": 0.07125100938929968,
      "grad_norm": 0.3665146231651306,
      "learning_rate": 9.287489906107004e-06,
      "loss": 0.3536,
      "step": 4500
    },
    {
      "epoch": 0.07126684294694174,
      "grad_norm": 0.010211295448243618,
      "learning_rate": 9.287331570530583e-06,
      "loss": 0.0004,
      "step": 4501
    },
    {
      "epoch": 0.07128267650458381,
      "grad_norm": 0.4703945517539978,
      "learning_rate": 9.287173234954162e-06,
      "loss": 0.1189,
      "step": 4502
    },
    {
      "epoch": 0.07129851006222589,
      "grad_norm": 0.36653172969818115,
      "learning_rate": 9.287014899377741e-06,
      "loss": 0.4149,
      "step": 4503
    },
    {
      "epoch": 0.07131434361986795,
      "grad_norm": 0.1709926873445511,
      "learning_rate": 9.28685656380132e-06,
      "loss": 0.0569,
      "step": 4504
    },
    {
      "epoch": 0.07133017717751002,
      "grad_norm": 0.3451896905899048,
      "learning_rate": 9.286698228224901e-06,
      "loss": 0.1443,
      "step": 4505
    },
    {
      "epoch": 0.07134601073515208,
      "grad_norm": 0.006582451052963734,
      "learning_rate": 9.28653989264848e-06,
      "loss": 0.0005,
      "step": 4506
    },
    {
      "epoch": 0.07136184429279414,
      "grad_norm": 0.17453984916210175,
      "learning_rate": 9.28638155707206e-06,
      "loss": 0.0667,
      "step": 4507
    },
    {
      "epoch": 0.07137767785043621,
      "grad_norm": 0.03633734956383705,
      "learning_rate": 9.286223221495638e-06,
      "loss": 0.0017,
      "step": 4508
    },
    {
      "epoch": 0.07139351140807829,
      "grad_norm": 0.4945312440395355,
      "learning_rate": 9.286064885919217e-06,
      "loss": 0.2619,
      "step": 4509
    },
    {
      "epoch": 0.07140934496572035,
      "grad_norm": 0.35275208950042725,
      "learning_rate": 9.285906550342797e-06,
      "loss": 0.3555,
      "step": 4510
    },
    {
      "epoch": 0.07142517852336241,
      "grad_norm": 0.3388577699661255,
      "learning_rate": 9.285748214766377e-06,
      "loss": 0.1341,
      "step": 4511
    },
    {
      "epoch": 0.07144101208100448,
      "grad_norm": 0.5881205201148987,
      "learning_rate": 9.285589879189956e-06,
      "loss": 0.1614,
      "step": 4512
    },
    {
      "epoch": 0.07145684563864654,
      "grad_norm": 0.2322888821363449,
      "learning_rate": 9.285431543613535e-06,
      "loss": 0.2446,
      "step": 4513
    },
    {
      "epoch": 0.07147267919628861,
      "grad_norm": 0.004292285535484552,
      "learning_rate": 9.285273208037115e-06,
      "loss": 0.0002,
      "step": 4514
    },
    {
      "epoch": 0.07148851275393069,
      "grad_norm": 1.5488834381103516,
      "learning_rate": 9.285114872460694e-06,
      "loss": 0.199,
      "step": 4515
    },
    {
      "epoch": 0.07150434631157275,
      "grad_norm": 0.1877276450395584,
      "learning_rate": 9.284956536884273e-06,
      "loss": 0.0516,
      "step": 4516
    },
    {
      "epoch": 0.07152017986921481,
      "grad_norm": 0.47252318263053894,
      "learning_rate": 9.284798201307853e-06,
      "loss": 0.1539,
      "step": 4517
    },
    {
      "epoch": 0.07153601342685688,
      "grad_norm": 0.21755318343639374,
      "learning_rate": 9.284639865731433e-06,
      "loss": 0.1177,
      "step": 4518
    },
    {
      "epoch": 0.07155184698449894,
      "grad_norm": 0.001601868076249957,
      "learning_rate": 9.284481530155012e-06,
      "loss": 0.0,
      "step": 4519
    },
    {
      "epoch": 0.07156768054214101,
      "grad_norm": 0.4097434878349304,
      "learning_rate": 9.28432319457859e-06,
      "loss": 0.4456,
      "step": 4520
    },
    {
      "epoch": 0.07158351409978309,
      "grad_norm": 0.09900175780057907,
      "learning_rate": 9.28416485900217e-06,
      "loss": 0.0091,
      "step": 4521
    },
    {
      "epoch": 0.07159934765742515,
      "grad_norm": 0.001948372577317059,
      "learning_rate": 9.284006523425749e-06,
      "loss": 0.0,
      "step": 4522
    },
    {
      "epoch": 0.07161518121506721,
      "grad_norm": 0.030529577285051346,
      "learning_rate": 9.28384818784933e-06,
      "loss": 0.0017,
      "step": 4523
    },
    {
      "epoch": 0.07163101477270928,
      "grad_norm": 0.3329116404056549,
      "learning_rate": 9.283689852272909e-06,
      "loss": 0.0338,
      "step": 4524
    },
    {
      "epoch": 0.07164684833035134,
      "grad_norm": 0.14845257997512817,
      "learning_rate": 9.283531516696486e-06,
      "loss": 0.1668,
      "step": 4525
    },
    {
      "epoch": 0.0716626818879934,
      "grad_norm": 0.18337778747081757,
      "learning_rate": 9.283373181120067e-06,
      "loss": 0.0712,
      "step": 4526
    },
    {
      "epoch": 0.07167851544563549,
      "grad_norm": 0.43788713216781616,
      "learning_rate": 9.283214845543646e-06,
      "loss": 0.1017,
      "step": 4527
    },
    {
      "epoch": 0.07169434900327755,
      "grad_norm": 0.27590763568878174,
      "learning_rate": 9.283056509967225e-06,
      "loss": 0.2214,
      "step": 4528
    },
    {
      "epoch": 0.07171018256091961,
      "grad_norm": 0.7823191285133362,
      "learning_rate": 9.282898174390804e-06,
      "loss": 0.0632,
      "step": 4529
    },
    {
      "epoch": 0.07172601611856168,
      "grad_norm": 0.21816474199295044,
      "learning_rate": 9.282739838814385e-06,
      "loss": 0.0103,
      "step": 4530
    },
    {
      "epoch": 0.07174184967620374,
      "grad_norm": 0.03284381330013275,
      "learning_rate": 9.282581503237962e-06,
      "loss": 0.0011,
      "step": 4531
    },
    {
      "epoch": 0.0717576832338458,
      "grad_norm": 0.19320057332515717,
      "learning_rate": 9.282423167661543e-06,
      "loss": 0.1052,
      "step": 4532
    },
    {
      "epoch": 0.07177351679148788,
      "grad_norm": 0.0139332115650177,
      "learning_rate": 9.282264832085122e-06,
      "loss": 0.0006,
      "step": 4533
    },
    {
      "epoch": 0.07178935034912995,
      "grad_norm": 0.4471241235733032,
      "learning_rate": 9.282106496508701e-06,
      "loss": 0.1291,
      "step": 4534
    },
    {
      "epoch": 0.07180518390677201,
      "grad_norm": 0.007331589236855507,
      "learning_rate": 9.28194816093228e-06,
      "loss": 0.0002,
      "step": 4535
    },
    {
      "epoch": 0.07182101746441408,
      "grad_norm": 0.0001199539692606777,
      "learning_rate": 9.281789825355861e-06,
      "loss": 0.0,
      "step": 4536
    },
    {
      "epoch": 0.07183685102205614,
      "grad_norm": 0.10689514130353928,
      "learning_rate": 9.281631489779438e-06,
      "loss": 0.0027,
      "step": 4537
    },
    {
      "epoch": 0.0718526845796982,
      "grad_norm": 0.2817056477069855,
      "learning_rate": 9.28147315420302e-06,
      "loss": 0.1627,
      "step": 4538
    },
    {
      "epoch": 0.07186851813734028,
      "grad_norm": 0.3188032805919647,
      "learning_rate": 9.281314818626598e-06,
      "loss": 0.0634,
      "step": 4539
    },
    {
      "epoch": 0.07188435169498235,
      "grad_norm": 0.8518829941749573,
      "learning_rate": 9.281156483050177e-06,
      "loss": 0.3368,
      "step": 4540
    },
    {
      "epoch": 0.07190018525262441,
      "grad_norm": 0.35380396246910095,
      "learning_rate": 9.280998147473756e-06,
      "loss": 0.2391,
      "step": 4541
    },
    {
      "epoch": 0.07191601881026648,
      "grad_norm": 0.0013802823377773166,
      "learning_rate": 9.280839811897337e-06,
      "loss": 0.0,
      "step": 4542
    },
    {
      "epoch": 0.07193185236790854,
      "grad_norm": 0.27401259541511536,
      "learning_rate": 9.280681476320915e-06,
      "loss": 0.1443,
      "step": 4543
    },
    {
      "epoch": 0.0719476859255506,
      "grad_norm": 0.0029136950615793467,
      "learning_rate": 9.280523140744495e-06,
      "loss": 0.0001,
      "step": 4544
    },
    {
      "epoch": 0.07196351948319268,
      "grad_norm": 0.1676429659128189,
      "learning_rate": 9.280364805168074e-06,
      "loss": 0.1328,
      "step": 4545
    },
    {
      "epoch": 0.07197935304083475,
      "grad_norm": 0.002847054973244667,
      "learning_rate": 9.280206469591654e-06,
      "loss": 0.0001,
      "step": 4546
    },
    {
      "epoch": 0.07199518659847681,
      "grad_norm": 0.27964597940444946,
      "learning_rate": 9.280048134015233e-06,
      "loss": 0.6043,
      "step": 4547
    },
    {
      "epoch": 0.07201102015611888,
      "grad_norm": 1.4756433963775635,
      "learning_rate": 9.279889798438812e-06,
      "loss": 0.1642,
      "step": 4548
    },
    {
      "epoch": 0.07202685371376094,
      "grad_norm": 0.28378432989120483,
      "learning_rate": 9.27973146286239e-06,
      "loss": 0.1507,
      "step": 4549
    },
    {
      "epoch": 0.072042687271403,
      "grad_norm": 0.8476998209953308,
      "learning_rate": 9.27957312728597e-06,
      "loss": 0.6832,
      "step": 4550
    },
    {
      "epoch": 0.07205852082904508,
      "grad_norm": 0.27551335096359253,
      "learning_rate": 9.27941479170955e-06,
      "loss": 0.0337,
      "step": 4551
    },
    {
      "epoch": 0.07207435438668715,
      "grad_norm": 0.01628473959863186,
      "learning_rate": 9.27925645613313e-06,
      "loss": 0.0007,
      "step": 4552
    },
    {
      "epoch": 0.07209018794432921,
      "grad_norm": 1.3632580041885376,
      "learning_rate": 9.279098120556709e-06,
      "loss": 0.1918,
      "step": 4553
    },
    {
      "epoch": 0.07210602150197128,
      "grad_norm": 0.3807145953178406,
      "learning_rate": 9.278939784980288e-06,
      "loss": 0.0247,
      "step": 4554
    },
    {
      "epoch": 0.07212185505961334,
      "grad_norm": 0.29604077339172363,
      "learning_rate": 9.278781449403867e-06,
      "loss": 0.1749,
      "step": 4555
    },
    {
      "epoch": 0.0721376886172554,
      "grad_norm": 0.31277117133140564,
      "learning_rate": 9.278623113827446e-06,
      "loss": 0.1486,
      "step": 4556
    },
    {
      "epoch": 0.07215352217489748,
      "grad_norm": 0.00025747623294591904,
      "learning_rate": 9.278464778251027e-06,
      "loss": 0.0,
      "step": 4557
    },
    {
      "epoch": 0.07216935573253955,
      "grad_norm": 0.34832197427749634,
      "learning_rate": 9.278306442674604e-06,
      "loss": 0.1963,
      "step": 4558
    },
    {
      "epoch": 0.07218518929018161,
      "grad_norm": 0.20932288467884064,
      "learning_rate": 9.278148107098185e-06,
      "loss": 0.0354,
      "step": 4559
    },
    {
      "epoch": 0.07220102284782368,
      "grad_norm": 0.23668527603149414,
      "learning_rate": 9.277989771521764e-06,
      "loss": 0.0791,
      "step": 4560
    },
    {
      "epoch": 0.07221685640546574,
      "grad_norm": 0.027713891118764877,
      "learning_rate": 9.277831435945343e-06,
      "loss": 0.0006,
      "step": 4561
    },
    {
      "epoch": 0.0722326899631078,
      "grad_norm": 0.36332398653030396,
      "learning_rate": 9.277673100368922e-06,
      "loss": 0.3229,
      "step": 4562
    },
    {
      "epoch": 0.07224852352074988,
      "grad_norm": 0.17503589391708374,
      "learning_rate": 9.277514764792503e-06,
      "loss": 0.0546,
      "step": 4563
    },
    {
      "epoch": 0.07226435707839195,
      "grad_norm": 0.014563655480742455,
      "learning_rate": 9.27735642921608e-06,
      "loss": 0.0007,
      "step": 4564
    },
    {
      "epoch": 0.07228019063603401,
      "grad_norm": 0.0001285560429096222,
      "learning_rate": 9.277198093639661e-06,
      "loss": 0.0,
      "step": 4565
    },
    {
      "epoch": 0.07229602419367608,
      "grad_norm": 0.00013793434482067823,
      "learning_rate": 9.27703975806324e-06,
      "loss": 0.0,
      "step": 4566
    },
    {
      "epoch": 0.07231185775131814,
      "grad_norm": 0.013983705081045628,
      "learning_rate": 9.27688142248682e-06,
      "loss": 0.0006,
      "step": 4567
    },
    {
      "epoch": 0.0723276913089602,
      "grad_norm": 0.1574244648218155,
      "learning_rate": 9.276723086910398e-06,
      "loss": 0.0517,
      "step": 4568
    },
    {
      "epoch": 0.07234352486660228,
      "grad_norm": 0.3291718363761902,
      "learning_rate": 9.276564751333979e-06,
      "loss": 0.0225,
      "step": 4569
    },
    {
      "epoch": 0.07235935842424435,
      "grad_norm": 0.037674278020858765,
      "learning_rate": 9.276406415757557e-06,
      "loss": 0.002,
      "step": 4570
    },
    {
      "epoch": 0.07237519198188641,
      "grad_norm": 0.011022859252989292,
      "learning_rate": 9.276248080181137e-06,
      "loss": 0.0005,
      "step": 4571
    },
    {
      "epoch": 0.07239102553952848,
      "grad_norm": 0.45164620876312256,
      "learning_rate": 9.276089744604716e-06,
      "loss": 0.0849,
      "step": 4572
    },
    {
      "epoch": 0.07240685909717054,
      "grad_norm": 0.1965133398771286,
      "learning_rate": 9.275931409028295e-06,
      "loss": 0.1394,
      "step": 4573
    },
    {
      "epoch": 0.0724226926548126,
      "grad_norm": 0.00021926022600382566,
      "learning_rate": 9.275773073451875e-06,
      "loss": 0.0,
      "step": 4574
    },
    {
      "epoch": 0.07243852621245468,
      "grad_norm": 0.2737444341182709,
      "learning_rate": 9.275614737875454e-06,
      "loss": 0.1093,
      "step": 4575
    },
    {
      "epoch": 0.07245435977009675,
      "grad_norm": 0.1356058120727539,
      "learning_rate": 9.275456402299033e-06,
      "loss": 0.041,
      "step": 4576
    },
    {
      "epoch": 0.07247019332773881,
      "grad_norm": 0.18811072409152985,
      "learning_rate": 9.275298066722612e-06,
      "loss": 0.0672,
      "step": 4577
    },
    {
      "epoch": 0.07248602688538087,
      "grad_norm": 0.29509520530700684,
      "learning_rate": 9.275139731146193e-06,
      "loss": 0.3764,
      "step": 4578
    },
    {
      "epoch": 0.07250186044302294,
      "grad_norm": 0.012533102184534073,
      "learning_rate": 9.274981395569772e-06,
      "loss": 0.0004,
      "step": 4579
    },
    {
      "epoch": 0.072517694000665,
      "grad_norm": 0.2211833894252777,
      "learning_rate": 9.27482305999335e-06,
      "loss": 0.1237,
      "step": 4580
    },
    {
      "epoch": 0.07253352755830708,
      "grad_norm": 0.44802576303482056,
      "learning_rate": 9.27466472441693e-06,
      "loss": 0.1143,
      "step": 4581
    },
    {
      "epoch": 0.07254936111594915,
      "grad_norm": 0.39427080750465393,
      "learning_rate": 9.274506388840509e-06,
      "loss": 0.4021,
      "step": 4582
    },
    {
      "epoch": 0.07256519467359121,
      "grad_norm": 2.0912387371063232,
      "learning_rate": 9.274348053264088e-06,
      "loss": 0.0182,
      "step": 4583
    },
    {
      "epoch": 0.07258102823123327,
      "grad_norm": 0.09005629271268845,
      "learning_rate": 9.274189717687669e-06,
      "loss": 0.0069,
      "step": 4584
    },
    {
      "epoch": 0.07259686178887534,
      "grad_norm": 0.00197312468662858,
      "learning_rate": 9.274031382111248e-06,
      "loss": 0.0001,
      "step": 4585
    },
    {
      "epoch": 0.0726126953465174,
      "grad_norm": 0.028858328238129616,
      "learning_rate": 9.273873046534827e-06,
      "loss": 0.0017,
      "step": 4586
    },
    {
      "epoch": 0.07262852890415948,
      "grad_norm": 0.2535867989063263,
      "learning_rate": 9.273714710958406e-06,
      "loss": 0.3303,
      "step": 4587
    },
    {
      "epoch": 0.07264436246180155,
      "grad_norm": 0.2690235376358032,
      "learning_rate": 9.273556375381985e-06,
      "loss": 0.3448,
      "step": 4588
    },
    {
      "epoch": 0.07266019601944361,
      "grad_norm": 0.008770515210926533,
      "learning_rate": 9.273398039805564e-06,
      "loss": 0.0004,
      "step": 4589
    },
    {
      "epoch": 0.07267602957708567,
      "grad_norm": 0.21859490871429443,
      "learning_rate": 9.273239704229145e-06,
      "loss": 0.1604,
      "step": 4590
    },
    {
      "epoch": 0.07269186313472774,
      "grad_norm": 0.2401042878627777,
      "learning_rate": 9.273081368652724e-06,
      "loss": 0.6324,
      "step": 4591
    },
    {
      "epoch": 0.0727076966923698,
      "grad_norm": 0.2719295918941498,
      "learning_rate": 9.272923033076303e-06,
      "loss": 0.2108,
      "step": 4592
    },
    {
      "epoch": 0.07272353025001188,
      "grad_norm": 0.010996364057064056,
      "learning_rate": 9.272764697499882e-06,
      "loss": 0.0005,
      "step": 4593
    },
    {
      "epoch": 0.07273936380765395,
      "grad_norm": 0.14796759188175201,
      "learning_rate": 9.272606361923461e-06,
      "loss": 0.0555,
      "step": 4594
    },
    {
      "epoch": 0.07275519736529601,
      "grad_norm": 0.24286945164203644,
      "learning_rate": 9.27244802634704e-06,
      "loss": 0.0789,
      "step": 4595
    },
    {
      "epoch": 0.07277103092293807,
      "grad_norm": 7.90459816926159e-05,
      "learning_rate": 9.27228969077062e-06,
      "loss": 0.0,
      "step": 4596
    },
    {
      "epoch": 0.07278686448058014,
      "grad_norm": 0.46586233377456665,
      "learning_rate": 9.2721313551942e-06,
      "loss": 0.8312,
      "step": 4597
    },
    {
      "epoch": 0.0728026980382222,
      "grad_norm": 0.015650587156414986,
      "learning_rate": 9.271973019617778e-06,
      "loss": 0.0009,
      "step": 4598
    },
    {
      "epoch": 0.07281853159586428,
      "grad_norm": 0.3890959918498993,
      "learning_rate": 9.271814684041358e-06,
      "loss": 0.4735,
      "step": 4599
    },
    {
      "epoch": 0.07283436515350634,
      "grad_norm": 0.2164936661720276,
      "learning_rate": 9.271656348464937e-06,
      "loss": 0.0117,
      "step": 4600
    },
    {
      "epoch": 0.07285019871114841,
      "grad_norm": 0.4375769793987274,
      "learning_rate": 9.271498012888516e-06,
      "loss": 0.2467,
      "step": 4601
    },
    {
      "epoch": 0.07286603226879047,
      "grad_norm": 0.0006726729916408658,
      "learning_rate": 9.271339677312096e-06,
      "loss": 0.0,
      "step": 4602
    },
    {
      "epoch": 0.07288186582643254,
      "grad_norm": 0.004283608868718147,
      "learning_rate": 9.271181341735676e-06,
      "loss": 0.0002,
      "step": 4603
    },
    {
      "epoch": 0.0728976993840746,
      "grad_norm": 1.3057684898376465,
      "learning_rate": 9.271023006159254e-06,
      "loss": 1.5143,
      "step": 4604
    },
    {
      "epoch": 0.07291353294171668,
      "grad_norm": 0.4946271777153015,
      "learning_rate": 9.270864670582834e-06,
      "loss": 0.0127,
      "step": 4605
    },
    {
      "epoch": 0.07292936649935874,
      "grad_norm": 0.33272626996040344,
      "learning_rate": 9.270706335006414e-06,
      "loss": 0.071,
      "step": 4606
    },
    {
      "epoch": 0.07294520005700081,
      "grad_norm": 1.888516902923584,
      "learning_rate": 9.270547999429993e-06,
      "loss": 0.2757,
      "step": 4607
    },
    {
      "epoch": 0.07296103361464287,
      "grad_norm": 0.444374144077301,
      "learning_rate": 9.270389663853572e-06,
      "loss": 0.1599,
      "step": 4608
    },
    {
      "epoch": 0.07297686717228494,
      "grad_norm": 0.35024309158325195,
      "learning_rate": 9.270231328277152e-06,
      "loss": 0.085,
      "step": 4609
    },
    {
      "epoch": 0.072992700729927,
      "grad_norm": 0.28409838676452637,
      "learning_rate": 9.27007299270073e-06,
      "loss": 0.1111,
      "step": 4610
    },
    {
      "epoch": 0.07300853428756908,
      "grad_norm": 0.036404456943273544,
      "learning_rate": 9.26991465712431e-06,
      "loss": 0.0018,
      "step": 4611
    },
    {
      "epoch": 0.07302436784521114,
      "grad_norm": 0.01171925850212574,
      "learning_rate": 9.26975632154789e-06,
      "loss": 0.0003,
      "step": 4612
    },
    {
      "epoch": 0.07304020140285321,
      "grad_norm": 0.23608563840389252,
      "learning_rate": 9.269597985971469e-06,
      "loss": 0.098,
      "step": 4613
    },
    {
      "epoch": 0.07305603496049527,
      "grad_norm": 0.2796548902988434,
      "learning_rate": 9.269439650395048e-06,
      "loss": 0.0129,
      "step": 4614
    },
    {
      "epoch": 0.07307186851813734,
      "grad_norm": 0.2211718112230301,
      "learning_rate": 9.269281314818627e-06,
      "loss": 0.045,
      "step": 4615
    },
    {
      "epoch": 0.0730877020757794,
      "grad_norm": 0.3063511550426483,
      "learning_rate": 9.269122979242206e-06,
      "loss": 0.0139,
      "step": 4616
    },
    {
      "epoch": 0.07310353563342148,
      "grad_norm": 0.2957567274570465,
      "learning_rate": 9.268964643665787e-06,
      "loss": 0.2343,
      "step": 4617
    },
    {
      "epoch": 0.07311936919106354,
      "grad_norm": 0.19587023556232452,
      "learning_rate": 9.268806308089366e-06,
      "loss": 0.1471,
      "step": 4618
    },
    {
      "epoch": 0.07313520274870561,
      "grad_norm": 0.010588796809315681,
      "learning_rate": 9.268647972512945e-06,
      "loss": 0.0005,
      "step": 4619
    },
    {
      "epoch": 0.07315103630634767,
      "grad_norm": 0.47800129652023315,
      "learning_rate": 9.268489636936524e-06,
      "loss": 0.093,
      "step": 4620
    },
    {
      "epoch": 0.07316686986398974,
      "grad_norm": 0.2084602415561676,
      "learning_rate": 9.268331301360103e-06,
      "loss": 0.0568,
      "step": 4621
    },
    {
      "epoch": 0.0731827034216318,
      "grad_norm": 0.4076617956161499,
      "learning_rate": 9.268172965783682e-06,
      "loss": 0.7058,
      "step": 4622
    },
    {
      "epoch": 0.07319853697927388,
      "grad_norm": 0.36743032932281494,
      "learning_rate": 9.268014630207261e-06,
      "loss": 0.2819,
      "step": 4623
    },
    {
      "epoch": 0.07321437053691594,
      "grad_norm": 0.3937070071697235,
      "learning_rate": 9.267856294630842e-06,
      "loss": 0.0777,
      "step": 4624
    },
    {
      "epoch": 0.07323020409455801,
      "grad_norm": 0.23917265236377716,
      "learning_rate": 9.26769795905442e-06,
      "loss": 0.1,
      "step": 4625
    },
    {
      "epoch": 0.07324603765220007,
      "grad_norm": 0.2703951895236969,
      "learning_rate": 9.267539623478e-06,
      "loss": 0.2225,
      "step": 4626
    },
    {
      "epoch": 0.07326187120984214,
      "grad_norm": 0.29628416895866394,
      "learning_rate": 9.26738128790158e-06,
      "loss": 0.3157,
      "step": 4627
    },
    {
      "epoch": 0.0732777047674842,
      "grad_norm": 0.2998657822608948,
      "learning_rate": 9.267222952325158e-06,
      "loss": 0.3789,
      "step": 4628
    },
    {
      "epoch": 0.07329353832512628,
      "grad_norm": 0.43095481395721436,
      "learning_rate": 9.267064616748737e-06,
      "loss": 0.2063,
      "step": 4629
    },
    {
      "epoch": 0.07330937188276834,
      "grad_norm": 0.029330283403396606,
      "learning_rate": 9.266906281172318e-06,
      "loss": 0.0014,
      "step": 4630
    },
    {
      "epoch": 0.07332520544041041,
      "grad_norm": 0.40459734201431274,
      "learning_rate": 9.266747945595896e-06,
      "loss": 0.2172,
      "step": 4631
    },
    {
      "epoch": 0.07334103899805247,
      "grad_norm": 0.3649061620235443,
      "learning_rate": 9.266589610019476e-06,
      "loss": 0.289,
      "step": 4632
    },
    {
      "epoch": 0.07335687255569454,
      "grad_norm": 0.3488945960998535,
      "learning_rate": 9.266431274443055e-06,
      "loss": 0.2438,
      "step": 4633
    },
    {
      "epoch": 0.0733727061133366,
      "grad_norm": 0.24726520478725433,
      "learning_rate": 9.266272938866635e-06,
      "loss": 0.1155,
      "step": 4634
    },
    {
      "epoch": 0.07338853967097868,
      "grad_norm": 0.0036362307146191597,
      "learning_rate": 9.266114603290214e-06,
      "loss": 0.0001,
      "step": 4635
    },
    {
      "epoch": 0.07340437322862074,
      "grad_norm": 0.18442387878894806,
      "learning_rate": 9.265956267713794e-06,
      "loss": 0.1387,
      "step": 4636
    },
    {
      "epoch": 0.0734202067862628,
      "grad_norm": 0.5176772475242615,
      "learning_rate": 9.265797932137372e-06,
      "loss": 0.0193,
      "step": 4637
    },
    {
      "epoch": 0.07343604034390487,
      "grad_norm": 0.18837375938892365,
      "learning_rate": 9.265639596560953e-06,
      "loss": 0.0504,
      "step": 4638
    },
    {
      "epoch": 0.07345187390154694,
      "grad_norm": 0.3843373954296112,
      "learning_rate": 9.265481260984532e-06,
      "loss": 0.2596,
      "step": 4639
    },
    {
      "epoch": 0.073467707459189,
      "grad_norm": 0.42918846011161804,
      "learning_rate": 9.26532292540811e-06,
      "loss": 0.3425,
      "step": 4640
    },
    {
      "epoch": 0.07348354101683108,
      "grad_norm": 0.016796523705124855,
      "learning_rate": 9.26516458983169e-06,
      "loss": 0.0003,
      "step": 4641
    },
    {
      "epoch": 0.07349937457447314,
      "grad_norm": 0.05468912422657013,
      "learning_rate": 9.26500625425527e-06,
      "loss": 0.002,
      "step": 4642
    },
    {
      "epoch": 0.0735152081321152,
      "grad_norm": 0.04539060220122337,
      "learning_rate": 9.264847918678848e-06,
      "loss": 0.0013,
      "step": 4643
    },
    {
      "epoch": 0.07353104168975727,
      "grad_norm": 0.294540673494339,
      "learning_rate": 9.264689583102427e-06,
      "loss": 0.4605,
      "step": 4644
    },
    {
      "epoch": 0.07354687524739933,
      "grad_norm": 0.03431426361203194,
      "learning_rate": 9.264531247526008e-06,
      "loss": 0.0006,
      "step": 4645
    },
    {
      "epoch": 0.0735627088050414,
      "grad_norm": 0.4608953297138214,
      "learning_rate": 9.264372911949587e-06,
      "loss": 0.1967,
      "step": 4646
    },
    {
      "epoch": 0.07357854236268348,
      "grad_norm": 0.41090577840805054,
      "learning_rate": 9.264214576373166e-06,
      "loss": 0.1028,
      "step": 4647
    },
    {
      "epoch": 0.07359437592032554,
      "grad_norm": 0.9273951649665833,
      "learning_rate": 9.264056240796745e-06,
      "loss": 0.4877,
      "step": 4648
    },
    {
      "epoch": 0.0736102094779676,
      "grad_norm": 0.17013397812843323,
      "learning_rate": 9.263897905220324e-06,
      "loss": 0.0199,
      "step": 4649
    },
    {
      "epoch": 0.07362604303560967,
      "grad_norm": 0.3372335731983185,
      "learning_rate": 9.263739569643903e-06,
      "loss": 0.2396,
      "step": 4650
    },
    {
      "epoch": 0.07364187659325173,
      "grad_norm": 0.2558270990848541,
      "learning_rate": 9.263581234067484e-06,
      "loss": 0.1383,
      "step": 4651
    },
    {
      "epoch": 0.0736577101508938,
      "grad_norm": 0.26895350217819214,
      "learning_rate": 9.263422898491063e-06,
      "loss": 0.0676,
      "step": 4652
    },
    {
      "epoch": 0.07367354370853588,
      "grad_norm": 0.27609631419181824,
      "learning_rate": 9.263264562914642e-06,
      "loss": 0.1497,
      "step": 4653
    },
    {
      "epoch": 0.07368937726617794,
      "grad_norm": 0.344978004693985,
      "learning_rate": 9.263106227338221e-06,
      "loss": 0.1628,
      "step": 4654
    },
    {
      "epoch": 0.07370521082382,
      "grad_norm": 0.020295754075050354,
      "learning_rate": 9.2629478917618e-06,
      "loss": 0.0009,
      "step": 4655
    },
    {
      "epoch": 0.07372104438146207,
      "grad_norm": 0.20981533825397491,
      "learning_rate": 9.26278955618538e-06,
      "loss": 0.1266,
      "step": 4656
    },
    {
      "epoch": 0.07373687793910413,
      "grad_norm": 0.010930108837783337,
      "learning_rate": 9.26263122060896e-06,
      "loss": 0.0005,
      "step": 4657
    },
    {
      "epoch": 0.0737527114967462,
      "grad_norm": 0.061246566474437714,
      "learning_rate": 9.26247288503254e-06,
      "loss": 0.0022,
      "step": 4658
    },
    {
      "epoch": 0.07376854505438828,
      "grad_norm": 0.2366483509540558,
      "learning_rate": 9.262314549456118e-06,
      "loss": 0.0153,
      "step": 4659
    },
    {
      "epoch": 0.07378437861203034,
      "grad_norm": 0.4806267023086548,
      "learning_rate": 9.262156213879697e-06,
      "loss": 0.6573,
      "step": 4660
    },
    {
      "epoch": 0.0738002121696724,
      "grad_norm": 0.1385229080915451,
      "learning_rate": 9.261997878303276e-06,
      "loss": 0.0381,
      "step": 4661
    },
    {
      "epoch": 0.07381604572731447,
      "grad_norm": 0.263602077960968,
      "learning_rate": 9.261839542726856e-06,
      "loss": 0.0331,
      "step": 4662
    },
    {
      "epoch": 0.07383187928495653,
      "grad_norm": 0.2508193552494049,
      "learning_rate": 9.261681207150436e-06,
      "loss": 0.3443,
      "step": 4663
    },
    {
      "epoch": 0.0738477128425986,
      "grad_norm": 0.19793200492858887,
      "learning_rate": 9.261522871574015e-06,
      "loss": 0.0485,
      "step": 4664
    },
    {
      "epoch": 0.07386354640024068,
      "grad_norm": 0.22980545461177826,
      "learning_rate": 9.261364535997594e-06,
      "loss": 0.1191,
      "step": 4665
    },
    {
      "epoch": 0.07387937995788274,
      "grad_norm": 0.7406411170959473,
      "learning_rate": 9.261206200421174e-06,
      "loss": 0.4883,
      "step": 4666
    },
    {
      "epoch": 0.0738952135155248,
      "grad_norm": 0.1822412610054016,
      "learning_rate": 9.261047864844753e-06,
      "loss": 0.0635,
      "step": 4667
    },
    {
      "epoch": 0.07391104707316687,
      "grad_norm": 0.5655703544616699,
      "learning_rate": 9.260889529268332e-06,
      "loss": 0.0571,
      "step": 4668
    },
    {
      "epoch": 0.07392688063080893,
      "grad_norm": 0.009191102348268032,
      "learning_rate": 9.26073119369191e-06,
      "loss": 0.0004,
      "step": 4669
    },
    {
      "epoch": 0.073942714188451,
      "grad_norm": 0.006275716237723827,
      "learning_rate": 9.260572858115492e-06,
      "loss": 0.0004,
      "step": 4670
    },
    {
      "epoch": 0.07395854774609308,
      "grad_norm": 0.013983205892145634,
      "learning_rate": 9.260414522539069e-06,
      "loss": 0.0009,
      "step": 4671
    },
    {
      "epoch": 0.07397438130373514,
      "grad_norm": 0.06335299462080002,
      "learning_rate": 9.26025618696265e-06,
      "loss": 0.0114,
      "step": 4672
    },
    {
      "epoch": 0.0739902148613772,
      "grad_norm": 0.27727818489074707,
      "learning_rate": 9.260097851386229e-06,
      "loss": 0.1746,
      "step": 4673
    },
    {
      "epoch": 0.07400604841901927,
      "grad_norm": 0.00022636698849964887,
      "learning_rate": 9.259939515809808e-06,
      "loss": 0.0,
      "step": 4674
    },
    {
      "epoch": 0.07402188197666133,
      "grad_norm": 0.48886579275131226,
      "learning_rate": 9.259781180233387e-06,
      "loss": 0.9616,
      "step": 4675
    },
    {
      "epoch": 0.0740377155343034,
      "grad_norm": 0.4746393859386444,
      "learning_rate": 9.259622844656968e-06,
      "loss": 0.4522,
      "step": 4676
    },
    {
      "epoch": 0.07405354909194548,
      "grad_norm": 0.2086164951324463,
      "learning_rate": 9.259464509080545e-06,
      "loss": 0.1465,
      "step": 4677
    },
    {
      "epoch": 0.07406938264958754,
      "grad_norm": 0.3260677754878998,
      "learning_rate": 9.259306173504126e-06,
      "loss": 0.1296,
      "step": 4678
    },
    {
      "epoch": 0.0740852162072296,
      "grad_norm": 0.40009984374046326,
      "learning_rate": 9.259147837927705e-06,
      "loss": 0.2362,
      "step": 4679
    },
    {
      "epoch": 0.07410104976487167,
      "grad_norm": 0.18854543566703796,
      "learning_rate": 9.258989502351284e-06,
      "loss": 0.0716,
      "step": 4680
    },
    {
      "epoch": 0.07411688332251373,
      "grad_norm": 0.3976670205593109,
      "learning_rate": 9.258831166774863e-06,
      "loss": 0.2301,
      "step": 4681
    },
    {
      "epoch": 0.0741327168801558,
      "grad_norm": 0.20765183866024017,
      "learning_rate": 9.258672831198442e-06,
      "loss": 0.1003,
      "step": 4682
    },
    {
      "epoch": 0.07414855043779787,
      "grad_norm": 0.0014517931267619133,
      "learning_rate": 9.258514495622021e-06,
      "loss": 0.0001,
      "step": 4683
    },
    {
      "epoch": 0.07416438399543994,
      "grad_norm": 0.21863026916980743,
      "learning_rate": 9.258356160045602e-06,
      "loss": 0.1127,
      "step": 4684
    },
    {
      "epoch": 0.074180217553082,
      "grad_norm": 0.33366408944129944,
      "learning_rate": 9.258197824469181e-06,
      "loss": 0.1789,
      "step": 4685
    },
    {
      "epoch": 0.07419605111072407,
      "grad_norm": 0.004542632959783077,
      "learning_rate": 9.25803948889276e-06,
      "loss": 0.0003,
      "step": 4686
    },
    {
      "epoch": 0.07421188466836613,
      "grad_norm": 0.010713770985603333,
      "learning_rate": 9.25788115331634e-06,
      "loss": 0.0005,
      "step": 4687
    },
    {
      "epoch": 0.0742277182260082,
      "grad_norm": 0.16438467800617218,
      "learning_rate": 9.257722817739918e-06,
      "loss": 0.0183,
      "step": 4688
    },
    {
      "epoch": 0.07424355178365027,
      "grad_norm": 0.6588646173477173,
      "learning_rate": 9.257564482163497e-06,
      "loss": 0.2015,
      "step": 4689
    },
    {
      "epoch": 0.07425938534129234,
      "grad_norm": 0.0089492192491889,
      "learning_rate": 9.257406146587078e-06,
      "loss": 0.0002,
      "step": 4690
    },
    {
      "epoch": 0.0742752188989344,
      "grad_norm": 0.0168322566896677,
      "learning_rate": 9.257247811010657e-06,
      "loss": 0.0009,
      "step": 4691
    },
    {
      "epoch": 0.07429105245657647,
      "grad_norm": 0.1790088415145874,
      "learning_rate": 9.257089475434235e-06,
      "loss": 0.0618,
      "step": 4692
    },
    {
      "epoch": 0.07430688601421853,
      "grad_norm": 0.2593948245048523,
      "learning_rate": 9.256931139857815e-06,
      "loss": 0.0235,
      "step": 4693
    },
    {
      "epoch": 0.0743227195718606,
      "grad_norm": 0.03320327401161194,
      "learning_rate": 9.256772804281395e-06,
      "loss": 0.0025,
      "step": 4694
    },
    {
      "epoch": 0.07433855312950267,
      "grad_norm": 0.5031522512435913,
      "learning_rate": 9.256614468704974e-06,
      "loss": 0.4352,
      "step": 4695
    },
    {
      "epoch": 0.07435438668714474,
      "grad_norm": 0.2201613336801529,
      "learning_rate": 9.256456133128553e-06,
      "loss": 0.0399,
      "step": 4696
    },
    {
      "epoch": 0.0743702202447868,
      "grad_norm": 0.38476330041885376,
      "learning_rate": 9.256297797552134e-06,
      "loss": 0.0112,
      "step": 4697
    },
    {
      "epoch": 0.07438605380242887,
      "grad_norm": 0.28509971499443054,
      "learning_rate": 9.256139461975711e-06,
      "loss": 0.2075,
      "step": 4698
    },
    {
      "epoch": 0.07440188736007093,
      "grad_norm": 2.9321221518330276e-05,
      "learning_rate": 9.255981126399292e-06,
      "loss": 0.0,
      "step": 4699
    },
    {
      "epoch": 0.074417720917713,
      "grad_norm": 0.1293569654226303,
      "learning_rate": 9.25582279082287e-06,
      "loss": 0.0483,
      "step": 4700
    },
    {
      "epoch": 0.07443355447535507,
      "grad_norm": 0.3011379539966583,
      "learning_rate": 9.25566445524645e-06,
      "loss": 0.3573,
      "step": 4701
    },
    {
      "epoch": 0.07444938803299714,
      "grad_norm": 0.0001684866874711588,
      "learning_rate": 9.255506119670029e-06,
      "loss": 0.0,
      "step": 4702
    },
    {
      "epoch": 0.0744652215906392,
      "grad_norm": 0.00504664471372962,
      "learning_rate": 9.25534778409361e-06,
      "loss": 0.0001,
      "step": 4703
    },
    {
      "epoch": 0.07448105514828127,
      "grad_norm": 0.287119060754776,
      "learning_rate": 9.255189448517187e-06,
      "loss": 0.2598,
      "step": 4704
    },
    {
      "epoch": 0.07449688870592333,
      "grad_norm": 0.10742001235485077,
      "learning_rate": 9.255031112940768e-06,
      "loss": 0.0068,
      "step": 4705
    },
    {
      "epoch": 0.0745127222635654,
      "grad_norm": 0.18730992078781128,
      "learning_rate": 9.254872777364347e-06,
      "loss": 0.1295,
      "step": 4706
    },
    {
      "epoch": 0.07452855582120747,
      "grad_norm": 0.00033751115552149713,
      "learning_rate": 9.254714441787926e-06,
      "loss": 0.0,
      "step": 4707
    },
    {
      "epoch": 0.07454438937884954,
      "grad_norm": 0.029135344550013542,
      "learning_rate": 9.254556106211505e-06,
      "loss": 0.0014,
      "step": 4708
    },
    {
      "epoch": 0.0745602229364916,
      "grad_norm": 0.004460432101041079,
      "learning_rate": 9.254397770635086e-06,
      "loss": 0.0002,
      "step": 4709
    },
    {
      "epoch": 0.07457605649413367,
      "grad_norm": 0.4678909182548523,
      "learning_rate": 9.254239435058663e-06,
      "loss": 0.2321,
      "step": 4710
    },
    {
      "epoch": 0.07459189005177573,
      "grad_norm": 0.5420030355453491,
      "learning_rate": 9.254081099482244e-06,
      "loss": 0.1727,
      "step": 4711
    },
    {
      "epoch": 0.0746077236094178,
      "grad_norm": 0.2943621277809143,
      "learning_rate": 9.253922763905823e-06,
      "loss": 0.1045,
      "step": 4712
    },
    {
      "epoch": 0.07462355716705987,
      "grad_norm": 0.215159609913826,
      "learning_rate": 9.253764428329402e-06,
      "loss": 0.1031,
      "step": 4713
    },
    {
      "epoch": 0.07463939072470194,
      "grad_norm": 0.13570615649223328,
      "learning_rate": 9.253606092752981e-06,
      "loss": 0.0508,
      "step": 4714
    },
    {
      "epoch": 0.074655224282344,
      "grad_norm": 0.2642197012901306,
      "learning_rate": 9.253447757176562e-06,
      "loss": 0.1526,
      "step": 4715
    },
    {
      "epoch": 0.07467105783998607,
      "grad_norm": 0.140349343419075,
      "learning_rate": 9.25328942160014e-06,
      "loss": 0.0628,
      "step": 4716
    },
    {
      "epoch": 0.07468689139762813,
      "grad_norm": 0.4004634618759155,
      "learning_rate": 9.253131086023718e-06,
      "loss": 0.1761,
      "step": 4717
    },
    {
      "epoch": 0.0747027249552702,
      "grad_norm": 0.1859002411365509,
      "learning_rate": 9.2529727504473e-06,
      "loss": 0.0402,
      "step": 4718
    },
    {
      "epoch": 0.07471855851291227,
      "grad_norm": 0.15591983497142792,
      "learning_rate": 9.252814414870878e-06,
      "loss": 0.0386,
      "step": 4719
    },
    {
      "epoch": 0.07473439207055434,
      "grad_norm": 0.3146519362926483,
      "learning_rate": 9.252656079294457e-06,
      "loss": 0.1366,
      "step": 4720
    },
    {
      "epoch": 0.0747502256281964,
      "grad_norm": 0.000129092630231753,
      "learning_rate": 9.252497743718036e-06,
      "loss": 0.0,
      "step": 4721
    },
    {
      "epoch": 0.07476605918583847,
      "grad_norm": 0.5336833000183105,
      "learning_rate": 9.252339408141616e-06,
      "loss": 0.0731,
      "step": 4722
    },
    {
      "epoch": 0.07478189274348053,
      "grad_norm": 0.446232408285141,
      "learning_rate": 9.252181072565195e-06,
      "loss": 0.1766,
      "step": 4723
    },
    {
      "epoch": 0.0747977263011226,
      "grad_norm": 0.32136809825897217,
      "learning_rate": 9.252022736988775e-06,
      "loss": 0.1183,
      "step": 4724
    },
    {
      "epoch": 0.07481355985876467,
      "grad_norm": 0.3520892262458801,
      "learning_rate": 9.251864401412355e-06,
      "loss": 0.4167,
      "step": 4725
    },
    {
      "epoch": 0.07482939341640674,
      "grad_norm": 0.6416807770729065,
      "learning_rate": 9.251706065835934e-06,
      "loss": 0.0406,
      "step": 4726
    },
    {
      "epoch": 0.0748452269740488,
      "grad_norm": 0.39578571915626526,
      "learning_rate": 9.251547730259513e-06,
      "loss": 0.1178,
      "step": 4727
    },
    {
      "epoch": 0.07486106053169087,
      "grad_norm": 0.18181556463241577,
      "learning_rate": 9.251389394683092e-06,
      "loss": 0.0986,
      "step": 4728
    },
    {
      "epoch": 0.07487689408933293,
      "grad_norm": 0.3444109261035919,
      "learning_rate": 9.25123105910667e-06,
      "loss": 0.184,
      "step": 4729
    },
    {
      "epoch": 0.074892727646975,
      "grad_norm": 0.20604655146598816,
      "learning_rate": 9.251072723530252e-06,
      "loss": 0.1062,
      "step": 4730
    },
    {
      "epoch": 0.07490856120461707,
      "grad_norm": 0.04584496095776558,
      "learning_rate": 9.25091438795383e-06,
      "loss": 0.001,
      "step": 4731
    },
    {
      "epoch": 0.07492439476225914,
      "grad_norm": 0.00014399419887922704,
      "learning_rate": 9.25075605237741e-06,
      "loss": 0.0,
      "step": 4732
    },
    {
      "epoch": 0.0749402283199012,
      "grad_norm": 0.00020716914150398225,
      "learning_rate": 9.250597716800989e-06,
      "loss": 0.0,
      "step": 4733
    },
    {
      "epoch": 0.07495606187754326,
      "grad_norm": 0.3774930536746979,
      "learning_rate": 9.250439381224568e-06,
      "loss": 0.8053,
      "step": 4734
    },
    {
      "epoch": 0.07497189543518533,
      "grad_norm": 0.2958763837814331,
      "learning_rate": 9.250281045648147e-06,
      "loss": 0.1243,
      "step": 4735
    },
    {
      "epoch": 0.0749877289928274,
      "grad_norm": 0.20053860545158386,
      "learning_rate": 9.250122710071728e-06,
      "loss": 0.5051,
      "step": 4736
    },
    {
      "epoch": 0.07500356255046947,
      "grad_norm": 0.4116858243942261,
      "learning_rate": 9.249964374495307e-06,
      "loss": 0.5761,
      "step": 4737
    },
    {
      "epoch": 0.07501939610811154,
      "grad_norm": 9.329221211373806e-05,
      "learning_rate": 9.249806038918886e-06,
      "loss": 0.0,
      "step": 4738
    },
    {
      "epoch": 0.0750352296657536,
      "grad_norm": 0.03790516406297684,
      "learning_rate": 9.249647703342465e-06,
      "loss": 0.0026,
      "step": 4739
    },
    {
      "epoch": 0.07505106322339566,
      "grad_norm": 1.4948899745941162,
      "learning_rate": 9.249489367766044e-06,
      "loss": 0.3189,
      "step": 4740
    },
    {
      "epoch": 0.07506689678103773,
      "grad_norm": 0.4576707184314728,
      "learning_rate": 9.249331032189623e-06,
      "loss": 0.0651,
      "step": 4741
    },
    {
      "epoch": 0.07508273033867979,
      "grad_norm": 0.4542628526687622,
      "learning_rate": 9.249172696613202e-06,
      "loss": 0.1039,
      "step": 4742
    },
    {
      "epoch": 0.07509856389632187,
      "grad_norm": 0.3569367527961731,
      "learning_rate": 9.249014361036783e-06,
      "loss": 0.3173,
      "step": 4743
    },
    {
      "epoch": 0.07511439745396394,
      "grad_norm": 0.005788509268313646,
      "learning_rate": 9.24885602546036e-06,
      "loss": 0.0002,
      "step": 4744
    },
    {
      "epoch": 0.075130231011606,
      "grad_norm": 0.2894921898841858,
      "learning_rate": 9.248697689883941e-06,
      "loss": 0.1978,
      "step": 4745
    },
    {
      "epoch": 0.07514606456924806,
      "grad_norm": 0.011330971494317055,
      "learning_rate": 9.24853935430752e-06,
      "loss": 0.0005,
      "step": 4746
    },
    {
      "epoch": 0.07516189812689013,
      "grad_norm": 0.1393541395664215,
      "learning_rate": 9.2483810187311e-06,
      "loss": 0.0743,
      "step": 4747
    },
    {
      "epoch": 0.07517773168453219,
      "grad_norm": 0.2056209146976471,
      "learning_rate": 9.248222683154678e-06,
      "loss": 0.2222,
      "step": 4748
    },
    {
      "epoch": 0.07519356524217427,
      "grad_norm": 0.26813217997550964,
      "learning_rate": 9.248064347578258e-06,
      "loss": 0.1181,
      "step": 4749
    },
    {
      "epoch": 0.07520939879981633,
      "grad_norm": 0.21508607268333435,
      "learning_rate": 9.247906012001837e-06,
      "loss": 0.1977,
      "step": 4750
    },
    {
      "epoch": 0.0752252323574584,
      "grad_norm": 0.2429255098104477,
      "learning_rate": 9.247747676425417e-06,
      "loss": 0.0225,
      "step": 4751
    },
    {
      "epoch": 0.07524106591510046,
      "grad_norm": 0.00019179166702087969,
      "learning_rate": 9.247589340848996e-06,
      "loss": 0.0,
      "step": 4752
    },
    {
      "epoch": 0.07525689947274253,
      "grad_norm": 0.26532965898513794,
      "learning_rate": 9.247431005272576e-06,
      "loss": 0.2448,
      "step": 4753
    },
    {
      "epoch": 0.07527273303038459,
      "grad_norm": 0.015919215977191925,
      "learning_rate": 9.247272669696155e-06,
      "loss": 0.0007,
      "step": 4754
    },
    {
      "epoch": 0.07528856658802667,
      "grad_norm": 0.2726336121559143,
      "learning_rate": 9.247114334119734e-06,
      "loss": 0.149,
      "step": 4755
    },
    {
      "epoch": 0.07530440014566873,
      "grad_norm": 0.40563398599624634,
      "learning_rate": 9.246955998543313e-06,
      "loss": 0.2689,
      "step": 4756
    },
    {
      "epoch": 0.0753202337033108,
      "grad_norm": 0.00037106144009158015,
      "learning_rate": 9.246797662966894e-06,
      "loss": 0.0,
      "step": 4757
    },
    {
      "epoch": 0.07533606726095286,
      "grad_norm": 0.05900353565812111,
      "learning_rate": 9.246639327390473e-06,
      "loss": 0.0079,
      "step": 4758
    },
    {
      "epoch": 0.07535190081859493,
      "grad_norm": 1.0662574768066406,
      "learning_rate": 9.246480991814052e-06,
      "loss": 0.1189,
      "step": 4759
    },
    {
      "epoch": 0.07536773437623699,
      "grad_norm": 0.024970795959234238,
      "learning_rate": 9.24632265623763e-06,
      "loss": 0.0014,
      "step": 4760
    },
    {
      "epoch": 0.07538356793387907,
      "grad_norm": 0.3556983470916748,
      "learning_rate": 9.24616432066121e-06,
      "loss": 0.1979,
      "step": 4761
    },
    {
      "epoch": 0.07539940149152113,
      "grad_norm": 0.5361297726631165,
      "learning_rate": 9.246005985084789e-06,
      "loss": 0.1055,
      "step": 4762
    },
    {
      "epoch": 0.0754152350491632,
      "grad_norm": 0.019188739359378815,
      "learning_rate": 9.24584764950837e-06,
      "loss": 0.0021,
      "step": 4763
    },
    {
      "epoch": 0.07543106860680526,
      "grad_norm": 0.2521708011627197,
      "learning_rate": 9.245689313931949e-06,
      "loss": 0.1228,
      "step": 4764
    },
    {
      "epoch": 0.07544690216444733,
      "grad_norm": 0.426054447889328,
      "learning_rate": 9.245530978355526e-06,
      "loss": 0.1001,
      "step": 4765
    },
    {
      "epoch": 0.07546273572208939,
      "grad_norm": 0.2768668234348297,
      "learning_rate": 9.245372642779107e-06,
      "loss": 0.2509,
      "step": 4766
    },
    {
      "epoch": 0.07547856927973147,
      "grad_norm": 0.06200487166643143,
      "learning_rate": 9.245214307202686e-06,
      "loss": 0.0076,
      "step": 4767
    },
    {
      "epoch": 0.07549440283737353,
      "grad_norm": 0.18416710197925568,
      "learning_rate": 9.245055971626265e-06,
      "loss": 0.2104,
      "step": 4768
    },
    {
      "epoch": 0.0755102363950156,
      "grad_norm": 0.1469154953956604,
      "learning_rate": 9.244897636049844e-06,
      "loss": 0.1362,
      "step": 4769
    },
    {
      "epoch": 0.07552606995265766,
      "grad_norm": 0.505236029624939,
      "learning_rate": 9.244739300473425e-06,
      "loss": 0.1325,
      "step": 4770
    },
    {
      "epoch": 0.07554190351029973,
      "grad_norm": 0.5261582732200623,
      "learning_rate": 9.244580964897002e-06,
      "loss": 0.0158,
      "step": 4771
    },
    {
      "epoch": 0.07555773706794179,
      "grad_norm": 0.42989686131477356,
      "learning_rate": 9.244422629320583e-06,
      "loss": 0.0778,
      "step": 4772
    },
    {
      "epoch": 0.07557357062558387,
      "grad_norm": 0.24392463266849518,
      "learning_rate": 9.244264293744162e-06,
      "loss": 0.1675,
      "step": 4773
    },
    {
      "epoch": 0.07558940418322593,
      "grad_norm": 0.26267147064208984,
      "learning_rate": 9.244105958167741e-06,
      "loss": 0.266,
      "step": 4774
    },
    {
      "epoch": 0.075605237740868,
      "grad_norm": 0.3451005816459656,
      "learning_rate": 9.24394762259132e-06,
      "loss": 1.1438,
      "step": 4775
    },
    {
      "epoch": 0.07562107129851006,
      "grad_norm": 0.2678188383579254,
      "learning_rate": 9.243789287014901e-06,
      "loss": 0.3714,
      "step": 4776
    },
    {
      "epoch": 0.07563690485615213,
      "grad_norm": 0.0005204955232329667,
      "learning_rate": 9.243630951438479e-06,
      "loss": 0.0,
      "step": 4777
    },
    {
      "epoch": 0.07565273841379419,
      "grad_norm": 0.3397988975048065,
      "learning_rate": 9.24347261586206e-06,
      "loss": 0.0772,
      "step": 4778
    },
    {
      "epoch": 0.07566857197143627,
      "grad_norm": 0.4190324544906616,
      "learning_rate": 9.243314280285638e-06,
      "loss": 0.2205,
      "step": 4779
    },
    {
      "epoch": 0.07568440552907833,
      "grad_norm": 0.15381738543510437,
      "learning_rate": 9.243155944709217e-06,
      "loss": 0.0667,
      "step": 4780
    },
    {
      "epoch": 0.0757002390867204,
      "grad_norm": 0.3478794991970062,
      "learning_rate": 9.242997609132797e-06,
      "loss": 0.0615,
      "step": 4781
    },
    {
      "epoch": 0.07571607264436246,
      "grad_norm": 0.26512983441352844,
      "learning_rate": 9.242839273556377e-06,
      "loss": 0.1722,
      "step": 4782
    },
    {
      "epoch": 0.07573190620200453,
      "grad_norm": 0.2058562934398651,
      "learning_rate": 9.242680937979955e-06,
      "loss": 0.1088,
      "step": 4783
    },
    {
      "epoch": 0.07574773975964659,
      "grad_norm": 0.27240949869155884,
      "learning_rate": 9.242522602403535e-06,
      "loss": 0.2482,
      "step": 4784
    },
    {
      "epoch": 0.07576357331728867,
      "grad_norm": 0.14153777062892914,
      "learning_rate": 9.242364266827115e-06,
      "loss": 0.0129,
      "step": 4785
    },
    {
      "epoch": 0.07577940687493073,
      "grad_norm": 0.3858907222747803,
      "learning_rate": 9.242205931250694e-06,
      "loss": 0.394,
      "step": 4786
    },
    {
      "epoch": 0.0757952404325728,
      "grad_norm": 0.36638587713241577,
      "learning_rate": 9.242047595674273e-06,
      "loss": 0.0667,
      "step": 4787
    },
    {
      "epoch": 0.07581107399021486,
      "grad_norm": 0.46904340386390686,
      "learning_rate": 9.241889260097852e-06,
      "loss": 0.1746,
      "step": 4788
    },
    {
      "epoch": 0.07582690754785693,
      "grad_norm": 0.21097931265830994,
      "learning_rate": 9.241730924521431e-06,
      "loss": 0.0692,
      "step": 4789
    },
    {
      "epoch": 0.07584274110549899,
      "grad_norm": 0.006992675829678774,
      "learning_rate": 9.24157258894501e-06,
      "loss": 0.0003,
      "step": 4790
    },
    {
      "epoch": 0.07585857466314107,
      "grad_norm": 0.0794726088643074,
      "learning_rate": 9.24141425336859e-06,
      "loss": 0.0048,
      "step": 4791
    },
    {
      "epoch": 0.07587440822078313,
      "grad_norm": 0.2035001963376999,
      "learning_rate": 9.24125591779217e-06,
      "loss": 0.1222,
      "step": 4792
    },
    {
      "epoch": 0.0758902417784252,
      "grad_norm": 0.22328084707260132,
      "learning_rate": 9.241097582215749e-06,
      "loss": 0.1182,
      "step": 4793
    },
    {
      "epoch": 0.07590607533606726,
      "grad_norm": 0.14648696780204773,
      "learning_rate": 9.240939246639328e-06,
      "loss": 0.0615,
      "step": 4794
    },
    {
      "epoch": 0.07592190889370933,
      "grad_norm": 0.00817856378853321,
      "learning_rate": 9.240780911062907e-06,
      "loss": 0.0005,
      "step": 4795
    },
    {
      "epoch": 0.07593774245135139,
      "grad_norm": 0.0007778815343044698,
      "learning_rate": 9.240622575486486e-06,
      "loss": 0.0,
      "step": 4796
    },
    {
      "epoch": 0.07595357600899347,
      "grad_norm": 0.24395908415317535,
      "learning_rate": 9.240464239910067e-06,
      "loss": 0.0049,
      "step": 4797
    },
    {
      "epoch": 0.07596940956663553,
      "grad_norm": 0.29036715626716614,
      "learning_rate": 9.240305904333646e-06,
      "loss": 0.2869,
      "step": 4798
    },
    {
      "epoch": 0.0759852431242776,
      "grad_norm": 0.36899885535240173,
      "learning_rate": 9.240147568757225e-06,
      "loss": 0.4457,
      "step": 4799
    },
    {
      "epoch": 0.07600107668191966,
      "grad_norm": 0.05446527153253555,
      "learning_rate": 9.239989233180804e-06,
      "loss": 0.0051,
      "step": 4800
    },
    {
      "epoch": 0.07601691023956172,
      "grad_norm": 0.008781291544437408,
      "learning_rate": 9.239830897604383e-06,
      "loss": 0.0004,
      "step": 4801
    },
    {
      "epoch": 0.07603274379720379,
      "grad_norm": 0.3939720094203949,
      "learning_rate": 9.239672562027962e-06,
      "loss": 0.2325,
      "step": 4802
    },
    {
      "epoch": 0.07604857735484587,
      "grad_norm": 0.40590226650238037,
      "learning_rate": 9.239514226451543e-06,
      "loss": 0.2812,
      "step": 4803
    },
    {
      "epoch": 0.07606441091248793,
      "grad_norm": 6.595769809791818e-05,
      "learning_rate": 9.239355890875122e-06,
      "loss": 0.0,
      "step": 4804
    },
    {
      "epoch": 0.07608024447013,
      "grad_norm": 0.2823778986930847,
      "learning_rate": 9.239197555298701e-06,
      "loss": 0.4665,
      "step": 4805
    },
    {
      "epoch": 0.07609607802777206,
      "grad_norm": 1.110823154449463,
      "learning_rate": 9.23903921972228e-06,
      "loss": 0.3997,
      "step": 4806
    },
    {
      "epoch": 0.07611191158541412,
      "grad_norm": 0.012432853691279888,
      "learning_rate": 9.23888088414586e-06,
      "loss": 0.0005,
      "step": 4807
    },
    {
      "epoch": 0.07612774514305619,
      "grad_norm": 0.948373556137085,
      "learning_rate": 9.238722548569438e-06,
      "loss": 0.0322,
      "step": 4808
    },
    {
      "epoch": 0.07614357870069827,
      "grad_norm": 0.0032059387303888798,
      "learning_rate": 9.23856421299302e-06,
      "loss": 0.0001,
      "step": 4809
    },
    {
      "epoch": 0.07615941225834033,
      "grad_norm": 0.39123281836509705,
      "learning_rate": 9.238405877416597e-06,
      "loss": 0.1974,
      "step": 4810
    },
    {
      "epoch": 0.0761752458159824,
      "grad_norm": 0.2167770117521286,
      "learning_rate": 9.238247541840177e-06,
      "loss": 0.0711,
      "step": 4811
    },
    {
      "epoch": 0.07619107937362446,
      "grad_norm": 0.04803185537457466,
      "learning_rate": 9.238089206263756e-06,
      "loss": 0.0024,
      "step": 4812
    },
    {
      "epoch": 0.07620691293126652,
      "grad_norm": 0.4954727590084076,
      "learning_rate": 9.237930870687336e-06,
      "loss": 0.0742,
      "step": 4813
    },
    {
      "epoch": 0.07622274648890859,
      "grad_norm": 0.3072119951248169,
      "learning_rate": 9.237772535110915e-06,
      "loss": 0.0871,
      "step": 4814
    },
    {
      "epoch": 0.07623858004655067,
      "grad_norm": 0.14359337091445923,
      "learning_rate": 9.237614199534494e-06,
      "loss": 0.0497,
      "step": 4815
    },
    {
      "epoch": 0.07625441360419273,
      "grad_norm": 0.511741042137146,
      "learning_rate": 9.237455863958073e-06,
      "loss": 0.0333,
      "step": 4816
    },
    {
      "epoch": 0.0762702471618348,
      "grad_norm": 0.2537190318107605,
      "learning_rate": 9.237297528381652e-06,
      "loss": 0.0889,
      "step": 4817
    },
    {
      "epoch": 0.07628608071947686,
      "grad_norm": 0.5527316331863403,
      "learning_rate": 9.237139192805233e-06,
      "loss": 0.1829,
      "step": 4818
    },
    {
      "epoch": 0.07630191427711892,
      "grad_norm": 0.43905869126319885,
      "learning_rate": 9.236980857228812e-06,
      "loss": 0.269,
      "step": 4819
    },
    {
      "epoch": 0.07631774783476099,
      "grad_norm": 0.21387328207492828,
      "learning_rate": 9.23682252165239e-06,
      "loss": 0.1166,
      "step": 4820
    },
    {
      "epoch": 0.07633358139240307,
      "grad_norm": 0.4284328818321228,
      "learning_rate": 9.23666418607597e-06,
      "loss": 0.324,
      "step": 4821
    },
    {
      "epoch": 0.07634941495004513,
      "grad_norm": 0.21186836063861847,
      "learning_rate": 9.236505850499549e-06,
      "loss": 0.1053,
      "step": 4822
    },
    {
      "epoch": 0.0763652485076872,
      "grad_norm": 0.5942054390907288,
      "learning_rate": 9.236347514923128e-06,
      "loss": 0.0782,
      "step": 4823
    },
    {
      "epoch": 0.07638108206532926,
      "grad_norm": 0.3591577410697937,
      "learning_rate": 9.236189179346709e-06,
      "loss": 0.4636,
      "step": 4824
    },
    {
      "epoch": 0.07639691562297132,
      "grad_norm": 0.5311927795410156,
      "learning_rate": 9.236030843770288e-06,
      "loss": 0.3546,
      "step": 4825
    },
    {
      "epoch": 0.07641274918061339,
      "grad_norm": 0.13240574300289154,
      "learning_rate": 9.235872508193867e-06,
      "loss": 0.057,
      "step": 4826
    },
    {
      "epoch": 0.07642858273825547,
      "grad_norm": 0.1876172125339508,
      "learning_rate": 9.235714172617446e-06,
      "loss": 0.0308,
      "step": 4827
    },
    {
      "epoch": 0.07644441629589753,
      "grad_norm": 0.01255441177636385,
      "learning_rate": 9.235555837041025e-06,
      "loss": 0.0007,
      "step": 4828
    },
    {
      "epoch": 0.0764602498535396,
      "grad_norm": 0.006788039579987526,
      "learning_rate": 9.235397501464604e-06,
      "loss": 0.0003,
      "step": 4829
    },
    {
      "epoch": 0.07647608341118166,
      "grad_norm": 0.23491448163986206,
      "learning_rate": 9.235239165888185e-06,
      "loss": 0.2165,
      "step": 4830
    },
    {
      "epoch": 0.07649191696882372,
      "grad_norm": 0.4127614200115204,
      "learning_rate": 9.235080830311764e-06,
      "loss": 0.1306,
      "step": 4831
    },
    {
      "epoch": 0.07650775052646579,
      "grad_norm": 0.029593555256724358,
      "learning_rate": 9.234922494735343e-06,
      "loss": 0.0016,
      "step": 4832
    },
    {
      "epoch": 0.07652358408410785,
      "grad_norm": 0.2912701666355133,
      "learning_rate": 9.234764159158922e-06,
      "loss": 0.1956,
      "step": 4833
    },
    {
      "epoch": 0.07653941764174993,
      "grad_norm": 0.6530787348747253,
      "learning_rate": 9.234605823582501e-06,
      "loss": 1.0288,
      "step": 4834
    },
    {
      "epoch": 0.076555251199392,
      "grad_norm": 0.16557665169239044,
      "learning_rate": 9.23444748800608e-06,
      "loss": 0.0313,
      "step": 4835
    },
    {
      "epoch": 0.07657108475703406,
      "grad_norm": 0.15701614320278168,
      "learning_rate": 9.234289152429661e-06,
      "loss": 0.2807,
      "step": 4836
    },
    {
      "epoch": 0.07658691831467612,
      "grad_norm": 0.016145814210176468,
      "learning_rate": 9.23413081685324e-06,
      "loss": 0.0008,
      "step": 4837
    },
    {
      "epoch": 0.07660275187231819,
      "grad_norm": 0.03983621299266815,
      "learning_rate": 9.233972481276818e-06,
      "loss": 0.0025,
      "step": 4838
    },
    {
      "epoch": 0.07661858542996025,
      "grad_norm": 0.11860332638025284,
      "learning_rate": 9.233814145700398e-06,
      "loss": 0.1635,
      "step": 4839
    },
    {
      "epoch": 0.07663441898760233,
      "grad_norm": 0.3415888249874115,
      "learning_rate": 9.233655810123977e-06,
      "loss": 0.0919,
      "step": 4840
    },
    {
      "epoch": 0.0766502525452444,
      "grad_norm": 0.0025047380477190018,
      "learning_rate": 9.233497474547557e-06,
      "loss": 0.0001,
      "step": 4841
    },
    {
      "epoch": 0.07666608610288646,
      "grad_norm": 0.1778406798839569,
      "learning_rate": 9.233339138971136e-06,
      "loss": 0.2441,
      "step": 4842
    },
    {
      "epoch": 0.07668191966052852,
      "grad_norm": 0.6246013045310974,
      "learning_rate": 9.233180803394716e-06,
      "loss": 0.3477,
      "step": 4843
    },
    {
      "epoch": 0.07669775321817059,
      "grad_norm": 0.248815655708313,
      "learning_rate": 9.233022467818294e-06,
      "loss": 0.0704,
      "step": 4844
    },
    {
      "epoch": 0.07671358677581265,
      "grad_norm": 0.3118155300617218,
      "learning_rate": 9.232864132241875e-06,
      "loss": 0.0749,
      "step": 4845
    },
    {
      "epoch": 0.07672942033345473,
      "grad_norm": 0.26985520124435425,
      "learning_rate": 9.232705796665454e-06,
      "loss": 0.3038,
      "step": 4846
    },
    {
      "epoch": 0.07674525389109679,
      "grad_norm": 0.028046950697898865,
      "learning_rate": 9.232547461089033e-06,
      "loss": 0.0017,
      "step": 4847
    },
    {
      "epoch": 0.07676108744873886,
      "grad_norm": 0.04228702932596207,
      "learning_rate": 9.232389125512612e-06,
      "loss": 0.0058,
      "step": 4848
    },
    {
      "epoch": 0.07677692100638092,
      "grad_norm": 0.10830087214708328,
      "learning_rate": 9.232230789936193e-06,
      "loss": 0.0416,
      "step": 4849
    },
    {
      "epoch": 0.07679275456402299,
      "grad_norm": 0.028834886848926544,
      "learning_rate": 9.23207245435977e-06,
      "loss": 0.002,
      "step": 4850
    },
    {
      "epoch": 0.07680858812166505,
      "grad_norm": 0.29404181241989136,
      "learning_rate": 9.23191411878335e-06,
      "loss": 0.2128,
      "step": 4851
    },
    {
      "epoch": 0.07682442167930713,
      "grad_norm": 0.017066696658730507,
      "learning_rate": 9.23175578320693e-06,
      "loss": 0.001,
      "step": 4852
    },
    {
      "epoch": 0.07684025523694919,
      "grad_norm": 0.16122272610664368,
      "learning_rate": 9.231597447630509e-06,
      "loss": 0.0431,
      "step": 4853
    },
    {
      "epoch": 0.07685608879459126,
      "grad_norm": 0.0002776490291580558,
      "learning_rate": 9.231439112054088e-06,
      "loss": 0.0,
      "step": 4854
    },
    {
      "epoch": 0.07687192235223332,
      "grad_norm": 0.011785482987761497,
      "learning_rate": 9.231280776477669e-06,
      "loss": 0.0007,
      "step": 4855
    },
    {
      "epoch": 0.07688775590987539,
      "grad_norm": 0.08748846501111984,
      "learning_rate": 9.231122440901246e-06,
      "loss": 0.0073,
      "step": 4856
    },
    {
      "epoch": 0.07690358946751745,
      "grad_norm": 0.36646783351898193,
      "learning_rate": 9.230964105324827e-06,
      "loss": 0.4112,
      "step": 4857
    },
    {
      "epoch": 0.07691942302515953,
      "grad_norm": 0.271450400352478,
      "learning_rate": 9.230805769748406e-06,
      "loss": 0.0312,
      "step": 4858
    },
    {
      "epoch": 0.07693525658280159,
      "grad_norm": 0.12880706787109375,
      "learning_rate": 9.230647434171985e-06,
      "loss": 0.0474,
      "step": 4859
    },
    {
      "epoch": 0.07695109014044366,
      "grad_norm": 0.19318130612373352,
      "learning_rate": 9.230489098595564e-06,
      "loss": 0.1237,
      "step": 4860
    },
    {
      "epoch": 0.07696692369808572,
      "grad_norm": 0.025134917348623276,
      "learning_rate": 9.230330763019143e-06,
      "loss": 0.0015,
      "step": 4861
    },
    {
      "epoch": 0.07698275725572779,
      "grad_norm": 9.646027319831774e-05,
      "learning_rate": 9.230172427442722e-06,
      "loss": 0.0,
      "step": 4862
    },
    {
      "epoch": 0.07699859081336985,
      "grad_norm": 0.23588985204696655,
      "learning_rate": 9.230014091866301e-06,
      "loss": 0.1236,
      "step": 4863
    },
    {
      "epoch": 0.07701442437101193,
      "grad_norm": 0.026083704084157944,
      "learning_rate": 9.229855756289882e-06,
      "loss": 0.0012,
      "step": 4864
    },
    {
      "epoch": 0.07703025792865399,
      "grad_norm": 0.2282390594482422,
      "learning_rate": 9.229697420713461e-06,
      "loss": 0.056,
      "step": 4865
    },
    {
      "epoch": 0.07704609148629606,
      "grad_norm": 0.01676495373249054,
      "learning_rate": 9.22953908513704e-06,
      "loss": 0.0009,
      "step": 4866
    },
    {
      "epoch": 0.07706192504393812,
      "grad_norm": 0.3853208124637604,
      "learning_rate": 9.22938074956062e-06,
      "loss": 0.8375,
      "step": 4867
    },
    {
      "epoch": 0.07707775860158018,
      "grad_norm": 0.2012299746274948,
      "learning_rate": 9.229222413984198e-06,
      "loss": 0.0533,
      "step": 4868
    },
    {
      "epoch": 0.07709359215922225,
      "grad_norm": 0.20049117505550385,
      "learning_rate": 9.229064078407778e-06,
      "loss": 0.1111,
      "step": 4869
    },
    {
      "epoch": 0.07710942571686433,
      "grad_norm": 0.5787917971611023,
      "learning_rate": 9.228905742831358e-06,
      "loss": 0.4016,
      "step": 4870
    },
    {
      "epoch": 0.07712525927450639,
      "grad_norm": 0.0026104324497282505,
      "learning_rate": 9.228747407254937e-06,
      "loss": 0.0001,
      "step": 4871
    },
    {
      "epoch": 0.07714109283214846,
      "grad_norm": 0.14169670641422272,
      "learning_rate": 9.228589071678516e-06,
      "loss": 0.0049,
      "step": 4872
    },
    {
      "epoch": 0.07715692638979052,
      "grad_norm": 0.1611718386411667,
      "learning_rate": 9.228430736102096e-06,
      "loss": 0.0792,
      "step": 4873
    },
    {
      "epoch": 0.07717275994743258,
      "grad_norm": 0.9376377463340759,
      "learning_rate": 9.228272400525675e-06,
      "loss": 0.0184,
      "step": 4874
    },
    {
      "epoch": 0.07718859350507465,
      "grad_norm": 0.3708331286907196,
      "learning_rate": 9.228114064949254e-06,
      "loss": 0.4089,
      "step": 4875
    },
    {
      "epoch": 0.07720442706271673,
      "grad_norm": 0.01517209317535162,
      "learning_rate": 9.227955729372834e-06,
      "loss": 0.0004,
      "step": 4876
    },
    {
      "epoch": 0.07722026062035879,
      "grad_norm": 0.18187952041625977,
      "learning_rate": 9.227797393796412e-06,
      "loss": 0.263,
      "step": 4877
    },
    {
      "epoch": 0.07723609417800086,
      "grad_norm": 0.381330668926239,
      "learning_rate": 9.227639058219993e-06,
      "loss": 0.2251,
      "step": 4878
    },
    {
      "epoch": 0.07725192773564292,
      "grad_norm": 0.37357091903686523,
      "learning_rate": 9.227480722643572e-06,
      "loss": 0.1414,
      "step": 4879
    },
    {
      "epoch": 0.07726776129328498,
      "grad_norm": 0.20174290239810944,
      "learning_rate": 9.22732238706715e-06,
      "loss": 0.0619,
      "step": 4880
    },
    {
      "epoch": 0.07728359485092705,
      "grad_norm": 0.31813642382621765,
      "learning_rate": 9.22716405149073e-06,
      "loss": 0.0665,
      "step": 4881
    },
    {
      "epoch": 0.07729942840856913,
      "grad_norm": 0.15286597609519958,
      "learning_rate": 9.22700571591431e-06,
      "loss": 0.0153,
      "step": 4882
    },
    {
      "epoch": 0.07731526196621119,
      "grad_norm": 0.4902177155017853,
      "learning_rate": 9.226847380337888e-06,
      "loss": 0.2174,
      "step": 4883
    },
    {
      "epoch": 0.07733109552385325,
      "grad_norm": 0.26796722412109375,
      "learning_rate": 9.226689044761469e-06,
      "loss": 0.0437,
      "step": 4884
    },
    {
      "epoch": 0.07734692908149532,
      "grad_norm": 0.363800972700119,
      "learning_rate": 9.226530709185048e-06,
      "loss": 0.2797,
      "step": 4885
    },
    {
      "epoch": 0.07736276263913738,
      "grad_norm": 0.006158797070384026,
      "learning_rate": 9.226372373608627e-06,
      "loss": 0.0001,
      "step": 4886
    },
    {
      "epoch": 0.07737859619677945,
      "grad_norm": 0.035625066608190536,
      "learning_rate": 9.226214038032206e-06,
      "loss": 0.0016,
      "step": 4887
    },
    {
      "epoch": 0.07739442975442153,
      "grad_norm": 0.160244882106781,
      "learning_rate": 9.226055702455785e-06,
      "loss": 0.0349,
      "step": 4888
    },
    {
      "epoch": 0.07741026331206359,
      "grad_norm": 0.17692242562770844,
      "learning_rate": 9.225897366879364e-06,
      "loss": 0.1478,
      "step": 4889
    },
    {
      "epoch": 0.07742609686970565,
      "grad_norm": 0.22018207609653473,
      "learning_rate": 9.225739031302943e-06,
      "loss": 0.0523,
      "step": 4890
    },
    {
      "epoch": 0.07744193042734772,
      "grad_norm": 0.018348781391978264,
      "learning_rate": 9.225580695726524e-06,
      "loss": 0.0006,
      "step": 4891
    },
    {
      "epoch": 0.07745776398498978,
      "grad_norm": 0.018384627997875214,
      "learning_rate": 9.225422360150103e-06,
      "loss": 0.0008,
      "step": 4892
    },
    {
      "epoch": 0.07747359754263185,
      "grad_norm": 0.2051709145307541,
      "learning_rate": 9.225264024573682e-06,
      "loss": 0.1196,
      "step": 4893
    },
    {
      "epoch": 0.07748943110027393,
      "grad_norm": 0.3491176664829254,
      "learning_rate": 9.225105688997261e-06,
      "loss": 0.2954,
      "step": 4894
    },
    {
      "epoch": 0.07750526465791599,
      "grad_norm": 0.0351058654487133,
      "learning_rate": 9.22494735342084e-06,
      "loss": 0.0024,
      "step": 4895
    },
    {
      "epoch": 0.07752109821555805,
      "grad_norm": 0.19832023978233337,
      "learning_rate": 9.22478901784442e-06,
      "loss": 0.0783,
      "step": 4896
    },
    {
      "epoch": 0.07753693177320012,
      "grad_norm": 0.16868729889392853,
      "learning_rate": 9.224630682268e-06,
      "loss": 0.0602,
      "step": 4897
    },
    {
      "epoch": 0.07755276533084218,
      "grad_norm": 0.21762406826019287,
      "learning_rate": 9.22447234669158e-06,
      "loss": 0.2747,
      "step": 4898
    },
    {
      "epoch": 0.07756859888848425,
      "grad_norm": 0.1863638311624527,
      "learning_rate": 9.224314011115158e-06,
      "loss": 0.0308,
      "step": 4899
    },
    {
      "epoch": 0.07758443244612633,
      "grad_norm": 0.005648194812238216,
      "learning_rate": 9.224155675538737e-06,
      "loss": 0.0002,
      "step": 4900
    },
    {
      "epoch": 0.07760026600376839,
      "grad_norm": 0.22734254598617554,
      "learning_rate": 9.223997339962317e-06,
      "loss": 0.1219,
      "step": 4901
    },
    {
      "epoch": 0.07761609956141045,
      "grad_norm": 0.2956627905368805,
      "learning_rate": 9.223839004385896e-06,
      "loss": 0.3862,
      "step": 4902
    },
    {
      "epoch": 0.07763193311905252,
      "grad_norm": 0.010916495695710182,
      "learning_rate": 9.223680668809476e-06,
      "loss": 0.0005,
      "step": 4903
    },
    {
      "epoch": 0.07764776667669458,
      "grad_norm": 0.007207266986370087,
      "learning_rate": 9.223522333233055e-06,
      "loss": 0.0002,
      "step": 4904
    },
    {
      "epoch": 0.07766360023433665,
      "grad_norm": 0.12099501490592957,
      "learning_rate": 9.223363997656635e-06,
      "loss": 0.067,
      "step": 4905
    },
    {
      "epoch": 0.07767943379197872,
      "grad_norm": 0.1626715213060379,
      "learning_rate": 9.223205662080214e-06,
      "loss": 0.0678,
      "step": 4906
    },
    {
      "epoch": 0.07769526734962079,
      "grad_norm": 0.14742515981197357,
      "learning_rate": 9.223047326503793e-06,
      "loss": 0.062,
      "step": 4907
    },
    {
      "epoch": 0.07771110090726285,
      "grad_norm": 0.6296247839927673,
      "learning_rate": 9.222888990927372e-06,
      "loss": 0.1871,
      "step": 4908
    },
    {
      "epoch": 0.07772693446490492,
      "grad_norm": 0.23069003224372864,
      "learning_rate": 9.222730655350951e-06,
      "loss": 0.1145,
      "step": 4909
    },
    {
      "epoch": 0.07774276802254698,
      "grad_norm": 0.003301945747807622,
      "learning_rate": 9.222572319774532e-06,
      "loss": 0.0001,
      "step": 4910
    },
    {
      "epoch": 0.07775860158018905,
      "grad_norm": 0.24728304147720337,
      "learning_rate": 9.222413984198109e-06,
      "loss": 0.0376,
      "step": 4911
    },
    {
      "epoch": 0.07777443513783112,
      "grad_norm": 0.2579995095729828,
      "learning_rate": 9.22225564862169e-06,
      "loss": 0.0784,
      "step": 4912
    },
    {
      "epoch": 0.07779026869547319,
      "grad_norm": 0.2929125130176544,
      "learning_rate": 9.222097313045269e-06,
      "loss": 0.1397,
      "step": 4913
    },
    {
      "epoch": 0.07780610225311525,
      "grad_norm": 0.3003394901752472,
      "learning_rate": 9.221938977468848e-06,
      "loss": 0.1112,
      "step": 4914
    },
    {
      "epoch": 0.07782193581075732,
      "grad_norm": 0.2958095073699951,
      "learning_rate": 9.221780641892427e-06,
      "loss": 0.057,
      "step": 4915
    },
    {
      "epoch": 0.07783776936839938,
      "grad_norm": 0.004208422265946865,
      "learning_rate": 9.221622306316008e-06,
      "loss": 0.0001,
      "step": 4916
    },
    {
      "epoch": 0.07785360292604145,
      "grad_norm": 0.18913480639457703,
      "learning_rate": 9.221463970739585e-06,
      "loss": 0.0737,
      "step": 4917
    },
    {
      "epoch": 0.07786943648368352,
      "grad_norm": 0.38700011372566223,
      "learning_rate": 9.221305635163166e-06,
      "loss": 0.1885,
      "step": 4918
    },
    {
      "epoch": 0.07788527004132559,
      "grad_norm": 0.0314113050699234,
      "learning_rate": 9.221147299586745e-06,
      "loss": 0.0014,
      "step": 4919
    },
    {
      "epoch": 0.07790110359896765,
      "grad_norm": 0.0025363494642078876,
      "learning_rate": 9.220988964010324e-06,
      "loss": 0.0001,
      "step": 4920
    },
    {
      "epoch": 0.07791693715660972,
      "grad_norm": 0.3753318786621094,
      "learning_rate": 9.220830628433903e-06,
      "loss": 0.2855,
      "step": 4921
    },
    {
      "epoch": 0.07793277071425178,
      "grad_norm": 0.424917608499527,
      "learning_rate": 9.220672292857484e-06,
      "loss": 0.327,
      "step": 4922
    },
    {
      "epoch": 0.07794860427189385,
      "grad_norm": 0.3214416801929474,
      "learning_rate": 9.220513957281061e-06,
      "loss": 0.3748,
      "step": 4923
    },
    {
      "epoch": 0.07796443782953592,
      "grad_norm": 0.02967684343457222,
      "learning_rate": 9.220355621704642e-06,
      "loss": 0.001,
      "step": 4924
    },
    {
      "epoch": 0.07798027138717799,
      "grad_norm": 0.008014635182917118,
      "learning_rate": 9.220197286128221e-06,
      "loss": 0.0003,
      "step": 4925
    },
    {
      "epoch": 0.07799610494482005,
      "grad_norm": 0.011466722004115582,
      "learning_rate": 9.2200389505518e-06,
      "loss": 0.0003,
      "step": 4926
    },
    {
      "epoch": 0.07801193850246212,
      "grad_norm": 0.024750608950853348,
      "learning_rate": 9.21988061497538e-06,
      "loss": 0.001,
      "step": 4927
    },
    {
      "epoch": 0.07802777206010418,
      "grad_norm": 0.6346613764762878,
      "learning_rate": 9.21972227939896e-06,
      "loss": 0.191,
      "step": 4928
    },
    {
      "epoch": 0.07804360561774625,
      "grad_norm": 0.0330205112695694,
      "learning_rate": 9.219563943822538e-06,
      "loss": 0.0016,
      "step": 4929
    },
    {
      "epoch": 0.07805943917538832,
      "grad_norm": 0.18480409681797028,
      "learning_rate": 9.219405608246118e-06,
      "loss": 0.0182,
      "step": 4930
    },
    {
      "epoch": 0.07807527273303039,
      "grad_norm": 0.014225899241864681,
      "learning_rate": 9.219247272669697e-06,
      "loss": 0.0007,
      "step": 4931
    },
    {
      "epoch": 0.07809110629067245,
      "grad_norm": 0.12572264671325684,
      "learning_rate": 9.219088937093276e-06,
      "loss": 0.0571,
      "step": 4932
    },
    {
      "epoch": 0.07810693984831452,
      "grad_norm": 0.0028968716505914927,
      "learning_rate": 9.218930601516856e-06,
      "loss": 0.0001,
      "step": 4933
    },
    {
      "epoch": 0.07812277340595658,
      "grad_norm": 0.0001642287679715082,
      "learning_rate": 9.218772265940435e-06,
      "loss": 0.0,
      "step": 4934
    },
    {
      "epoch": 0.07813860696359864,
      "grad_norm": 0.37555432319641113,
      "learning_rate": 9.218613930364014e-06,
      "loss": 0.1097,
      "step": 4935
    },
    {
      "epoch": 0.07815444052124072,
      "grad_norm": 0.014766234904527664,
      "learning_rate": 9.218455594787593e-06,
      "loss": 0.0006,
      "step": 4936
    },
    {
      "epoch": 0.07817027407888279,
      "grad_norm": 0.23153764009475708,
      "learning_rate": 9.218297259211174e-06,
      "loss": 0.0674,
      "step": 4937
    },
    {
      "epoch": 0.07818610763652485,
      "grad_norm": 0.022146206349134445,
      "learning_rate": 9.218138923634753e-06,
      "loss": 0.0011,
      "step": 4938
    },
    {
      "epoch": 0.07820194119416692,
      "grad_norm": 0.3716859519481659,
      "learning_rate": 9.217980588058332e-06,
      "loss": 0.1285,
      "step": 4939
    },
    {
      "epoch": 0.07821777475180898,
      "grad_norm": 0.4454847276210785,
      "learning_rate": 9.21782225248191e-06,
      "loss": 0.0463,
      "step": 4940
    },
    {
      "epoch": 0.07823360830945104,
      "grad_norm": 0.5814757943153381,
      "learning_rate": 9.21766391690549e-06,
      "loss": 0.4714,
      "step": 4941
    },
    {
      "epoch": 0.07824944186709312,
      "grad_norm": 0.4822233319282532,
      "learning_rate": 9.217505581329069e-06,
      "loss": 0.2365,
      "step": 4942
    },
    {
      "epoch": 0.07826527542473519,
      "grad_norm": 0.801615297794342,
      "learning_rate": 9.21734724575265e-06,
      "loss": 0.2397,
      "step": 4943
    },
    {
      "epoch": 0.07828110898237725,
      "grad_norm": 0.4005994200706482,
      "learning_rate": 9.217188910176227e-06,
      "loss": 0.4098,
      "step": 4944
    },
    {
      "epoch": 0.07829694254001932,
      "grad_norm": 0.3218221068382263,
      "learning_rate": 9.217030574599808e-06,
      "loss": 0.1191,
      "step": 4945
    },
    {
      "epoch": 0.07831277609766138,
      "grad_norm": 0.3523876667022705,
      "learning_rate": 9.216872239023387e-06,
      "loss": 0.1925,
      "step": 4946
    },
    {
      "epoch": 0.07832860965530344,
      "grad_norm": 0.05579762905836105,
      "learning_rate": 9.216713903446966e-06,
      "loss": 0.006,
      "step": 4947
    },
    {
      "epoch": 0.07834444321294552,
      "grad_norm": 0.616655170917511,
      "learning_rate": 9.216555567870545e-06,
      "loss": 0.2501,
      "step": 4948
    },
    {
      "epoch": 0.07836027677058759,
      "grad_norm": 0.005548072978854179,
      "learning_rate": 9.216397232294126e-06,
      "loss": 0.0002,
      "step": 4949
    },
    {
      "epoch": 0.07837611032822965,
      "grad_norm": 0.17090579867362976,
      "learning_rate": 9.216238896717703e-06,
      "loss": 0.0276,
      "step": 4950
    },
    {
      "epoch": 0.07839194388587171,
      "grad_norm": 0.0012105535715818405,
      "learning_rate": 9.216080561141284e-06,
      "loss": 0.0,
      "step": 4951
    },
    {
      "epoch": 0.07840777744351378,
      "grad_norm": 0.0005377937341108918,
      "learning_rate": 9.215922225564863e-06,
      "loss": 0.0,
      "step": 4952
    },
    {
      "epoch": 0.07842361100115584,
      "grad_norm": 0.39740613102912903,
      "learning_rate": 9.215763889988442e-06,
      "loss": 0.125,
      "step": 4953
    },
    {
      "epoch": 0.07843944455879792,
      "grad_norm": 0.3401947319507599,
      "learning_rate": 9.215605554412021e-06,
      "loss": 0.4596,
      "step": 4954
    },
    {
      "epoch": 0.07845527811643999,
      "grad_norm": 0.5190455913543701,
      "learning_rate": 9.215447218835602e-06,
      "loss": 0.4286,
      "step": 4955
    },
    {
      "epoch": 0.07847111167408205,
      "grad_norm": 0.5142607092857361,
      "learning_rate": 9.21528888325918e-06,
      "loss": 0.2545,
      "step": 4956
    },
    {
      "epoch": 0.07848694523172411,
      "grad_norm": 0.47541362047195435,
      "learning_rate": 9.215130547682759e-06,
      "loss": 0.2179,
      "step": 4957
    },
    {
      "epoch": 0.07850277878936618,
      "grad_norm": 0.011996516957879066,
      "learning_rate": 9.21497221210634e-06,
      "loss": 0.0005,
      "step": 4958
    },
    {
      "epoch": 0.07851861234700824,
      "grad_norm": 6.847654731245711e-05,
      "learning_rate": 9.214813876529918e-06,
      "loss": 0.0,
      "step": 4959
    },
    {
      "epoch": 0.07853444590465032,
      "grad_norm": 0.01253659836947918,
      "learning_rate": 9.214655540953497e-06,
      "loss": 0.0006,
      "step": 4960
    },
    {
      "epoch": 0.07855027946229239,
      "grad_norm": 0.2711659073829651,
      "learning_rate": 9.214497205377077e-06,
      "loss": 0.0447,
      "step": 4961
    },
    {
      "epoch": 0.07856611301993445,
      "grad_norm": 0.25405409932136536,
      "learning_rate": 9.214338869800656e-06,
      "loss": 0.0925,
      "step": 4962
    },
    {
      "epoch": 0.07858194657757651,
      "grad_norm": 0.0005365134566091001,
      "learning_rate": 9.214180534224235e-06,
      "loss": 0.0,
      "step": 4963
    },
    {
      "epoch": 0.07859778013521858,
      "grad_norm": 0.09329601377248764,
      "learning_rate": 9.214022198647816e-06,
      "loss": 0.0097,
      "step": 4964
    },
    {
      "epoch": 0.07861361369286064,
      "grad_norm": 0.005492253229022026,
      "learning_rate": 9.213863863071395e-06,
      "loss": 0.0002,
      "step": 4965
    },
    {
      "epoch": 0.07862944725050272,
      "grad_norm": 0.11632100492715836,
      "learning_rate": 9.213705527494974e-06,
      "loss": 0.0372,
      "step": 4966
    },
    {
      "epoch": 0.07864528080814479,
      "grad_norm": 0.10257375240325928,
      "learning_rate": 9.213547191918553e-06,
      "loss": 0.0456,
      "step": 4967
    },
    {
      "epoch": 0.07866111436578685,
      "grad_norm": 0.41017287969589233,
      "learning_rate": 9.213388856342132e-06,
      "loss": 0.8127,
      "step": 4968
    },
    {
      "epoch": 0.07867694792342891,
      "grad_norm": 0.22515042126178741,
      "learning_rate": 9.213230520765711e-06,
      "loss": 0.1754,
      "step": 4969
    },
    {
      "epoch": 0.07869278148107098,
      "grad_norm": 0.3173486590385437,
      "learning_rate": 9.213072185189292e-06,
      "loss": 0.0966,
      "step": 4970
    },
    {
      "epoch": 0.07870861503871304,
      "grad_norm": 0.46715500950813293,
      "learning_rate": 9.21291384961287e-06,
      "loss": 0.3474,
      "step": 4971
    },
    {
      "epoch": 0.07872444859635512,
      "grad_norm": 0.12538078427314758,
      "learning_rate": 9.21275551403645e-06,
      "loss": 0.0604,
      "step": 4972
    },
    {
      "epoch": 0.07874028215399718,
      "grad_norm": 0.0030207715462893248,
      "learning_rate": 9.212597178460029e-06,
      "loss": 0.0001,
      "step": 4973
    },
    {
      "epoch": 0.07875611571163925,
      "grad_norm": 0.43029162287712097,
      "learning_rate": 9.212438842883608e-06,
      "loss": 0.5367,
      "step": 4974
    },
    {
      "epoch": 0.07877194926928131,
      "grad_norm": 0.34079235792160034,
      "learning_rate": 9.212280507307187e-06,
      "loss": 0.156,
      "step": 4975
    },
    {
      "epoch": 0.07878778282692338,
      "grad_norm": 0.008797692134976387,
      "learning_rate": 9.212122171730768e-06,
      "loss": 0.0002,
      "step": 4976
    },
    {
      "epoch": 0.07880361638456544,
      "grad_norm": 0.41926345229148865,
      "learning_rate": 9.211963836154347e-06,
      "loss": 0.2706,
      "step": 4977
    },
    {
      "epoch": 0.07881944994220752,
      "grad_norm": 0.19307591021060944,
      "learning_rate": 9.211805500577926e-06,
      "loss": 0.1262,
      "step": 4978
    },
    {
      "epoch": 0.07883528349984958,
      "grad_norm": 0.28478771448135376,
      "learning_rate": 9.211647165001505e-06,
      "loss": 0.4214,
      "step": 4979
    },
    {
      "epoch": 0.07885111705749165,
      "grad_norm": 0.021137695759534836,
      "learning_rate": 9.211488829425084e-06,
      "loss": 0.0007,
      "step": 4980
    },
    {
      "epoch": 0.07886695061513371,
      "grad_norm": 0.14608483016490936,
      "learning_rate": 9.211330493848663e-06,
      "loss": 0.0562,
      "step": 4981
    },
    {
      "epoch": 0.07888278417277578,
      "grad_norm": 0.22776386141777039,
      "learning_rate": 9.211172158272242e-06,
      "loss": 0.2213,
      "step": 4982
    },
    {
      "epoch": 0.07889861773041784,
      "grad_norm": 0.3258604407310486,
      "learning_rate": 9.211013822695823e-06,
      "loss": 0.3531,
      "step": 4983
    },
    {
      "epoch": 0.07891445128805992,
      "grad_norm": 0.20248863101005554,
      "learning_rate": 9.2108554871194e-06,
      "loss": 0.0866,
      "step": 4984
    },
    {
      "epoch": 0.07893028484570198,
      "grad_norm": 0.00013126057456247509,
      "learning_rate": 9.210697151542981e-06,
      "loss": 0.0,
      "step": 4985
    },
    {
      "epoch": 0.07894611840334405,
      "grad_norm": 0.22005529701709747,
      "learning_rate": 9.21053881596656e-06,
      "loss": 0.1498,
      "step": 4986
    },
    {
      "epoch": 0.07896195196098611,
      "grad_norm": 0.2607173025608063,
      "learning_rate": 9.21038048039014e-06,
      "loss": 0.2129,
      "step": 4987
    },
    {
      "epoch": 0.07897778551862818,
      "grad_norm": 0.24500976502895355,
      "learning_rate": 9.210222144813719e-06,
      "loss": 0.5317,
      "step": 4988
    },
    {
      "epoch": 0.07899361907627024,
      "grad_norm": 0.20827563107013702,
      "learning_rate": 9.2100638092373e-06,
      "loss": 0.0534,
      "step": 4989
    },
    {
      "epoch": 0.07900945263391232,
      "grad_norm": 0.360937237739563,
      "learning_rate": 9.209905473660877e-06,
      "loss": 0.1778,
      "step": 4990
    },
    {
      "epoch": 0.07902528619155438,
      "grad_norm": 0.2578868269920349,
      "learning_rate": 9.209747138084457e-06,
      "loss": 0.1234,
      "step": 4991
    },
    {
      "epoch": 0.07904111974919645,
      "grad_norm": 0.010676100850105286,
      "learning_rate": 9.209588802508037e-06,
      "loss": 0.0006,
      "step": 4992
    },
    {
      "epoch": 0.07905695330683851,
      "grad_norm": 0.023013757541775703,
      "learning_rate": 9.209430466931616e-06,
      "loss": 0.001,
      "step": 4993
    },
    {
      "epoch": 0.07907278686448058,
      "grad_norm": 0.2967606484889984,
      "learning_rate": 9.209272131355195e-06,
      "loss": 0.1438,
      "step": 4994
    },
    {
      "epoch": 0.07908862042212264,
      "grad_norm": 0.00011663527402561158,
      "learning_rate": 9.209113795778775e-06,
      "loss": 0.0,
      "step": 4995
    },
    {
      "epoch": 0.07910445397976472,
      "grad_norm": 0.18290646374225616,
      "learning_rate": 9.208955460202353e-06,
      "loss": 0.1125,
      "step": 4996
    },
    {
      "epoch": 0.07912028753740678,
      "grad_norm": 0.32303452491760254,
      "learning_rate": 9.208797124625934e-06,
      "loss": 0.2863,
      "step": 4997
    },
    {
      "epoch": 0.07913612109504885,
      "grad_norm": 1.6064708232879639,
      "learning_rate": 9.208638789049513e-06,
      "loss": 0.1304,
      "step": 4998
    },
    {
      "epoch": 0.07915195465269091,
      "grad_norm": 0.22026550769805908,
      "learning_rate": 9.208480453473092e-06,
      "loss": 0.1935,
      "step": 4999
    },
    {
      "epoch": 0.07916778821033298,
      "grad_norm": 0.24409860372543335,
      "learning_rate": 9.20832211789667e-06,
      "loss": 0.0793,
      "step": 5000
    },
    {
      "epoch": 0.07918362176797504,
      "grad_norm": 0.17006812989711761,
      "learning_rate": 9.20816378232025e-06,
      "loss": 0.1548,
      "step": 5001
    },
    {
      "epoch": 0.07919945532561712,
      "grad_norm": 0.22312912344932556,
      "learning_rate": 9.208005446743829e-06,
      "loss": 0.0887,
      "step": 5002
    },
    {
      "epoch": 0.07921528888325918,
      "grad_norm": 0.2760586440563202,
      "learning_rate": 9.20784711116741e-06,
      "loss": 0.1608,
      "step": 5003
    },
    {
      "epoch": 0.07923112244090125,
      "grad_norm": 0.19769784808158875,
      "learning_rate": 9.207688775590989e-06,
      "loss": 0.08,
      "step": 5004
    },
    {
      "epoch": 0.07924695599854331,
      "grad_norm": 0.4144383668899536,
      "learning_rate": 9.207530440014566e-06,
      "loss": 0.1991,
      "step": 5005
    },
    {
      "epoch": 0.07926278955618538,
      "grad_norm": 0.3514942228794098,
      "learning_rate": 9.207372104438147e-06,
      "loss": 0.7575,
      "step": 5006
    },
    {
      "epoch": 0.07927862311382744,
      "grad_norm": 0.488211065530777,
      "learning_rate": 9.207213768861726e-06,
      "loss": 0.1568,
      "step": 5007
    },
    {
      "epoch": 0.07929445667146952,
      "grad_norm": 0.4638679027557373,
      "learning_rate": 9.207055433285305e-06,
      "loss": 0.0693,
      "step": 5008
    },
    {
      "epoch": 0.07931029022911158,
      "grad_norm": 0.2323344349861145,
      "learning_rate": 9.206897097708884e-06,
      "loss": 0.3235,
      "step": 5009
    },
    {
      "epoch": 0.07932612378675365,
      "grad_norm": 0.0029896877240389585,
      "learning_rate": 9.206738762132465e-06,
      "loss": 0.0001,
      "step": 5010
    },
    {
      "epoch": 0.07934195734439571,
      "grad_norm": 0.1777004897594452,
      "learning_rate": 9.206580426556042e-06,
      "loss": 0.2901,
      "step": 5011
    },
    {
      "epoch": 0.07935779090203778,
      "grad_norm": 0.23425936698913574,
      "learning_rate": 9.206422090979623e-06,
      "loss": 0.2408,
      "step": 5012
    },
    {
      "epoch": 0.07937362445967984,
      "grad_norm": 0.19205357134342194,
      "learning_rate": 9.206263755403202e-06,
      "loss": 0.0961,
      "step": 5013
    },
    {
      "epoch": 0.07938945801732192,
      "grad_norm": 0.36000800132751465,
      "learning_rate": 9.206105419826781e-06,
      "loss": 0.4018,
      "step": 5014
    },
    {
      "epoch": 0.07940529157496398,
      "grad_norm": 0.23753145337104797,
      "learning_rate": 9.20594708425036e-06,
      "loss": 0.0834,
      "step": 5015
    },
    {
      "epoch": 0.07942112513260605,
      "grad_norm": 0.23573951423168182,
      "learning_rate": 9.205788748673941e-06,
      "loss": 0.1184,
      "step": 5016
    },
    {
      "epoch": 0.07943695869024811,
      "grad_norm": 0.29888418316841125,
      "learning_rate": 9.205630413097519e-06,
      "loss": 0.0271,
      "step": 5017
    },
    {
      "epoch": 0.07945279224789017,
      "grad_norm": 0.005061215255409479,
      "learning_rate": 9.2054720775211e-06,
      "loss": 0.0002,
      "step": 5018
    },
    {
      "epoch": 0.07946862580553224,
      "grad_norm": 0.24490132927894592,
      "learning_rate": 9.205313741944678e-06,
      "loss": 0.3059,
      "step": 5019
    },
    {
      "epoch": 0.07948445936317432,
      "grad_norm": 0.23014870285987854,
      "learning_rate": 9.205155406368258e-06,
      "loss": 0.0532,
      "step": 5020
    },
    {
      "epoch": 0.07950029292081638,
      "grad_norm": 0.01073627918958664,
      "learning_rate": 9.204997070791837e-06,
      "loss": 0.0001,
      "step": 5021
    },
    {
      "epoch": 0.07951612647845845,
      "grad_norm": 0.016757722944021225,
      "learning_rate": 9.204838735215417e-06,
      "loss": 0.0011,
      "step": 5022
    },
    {
      "epoch": 0.07953196003610051,
      "grad_norm": 0.0006005825125612319,
      "learning_rate": 9.204680399638995e-06,
      "loss": 0.0,
      "step": 5023
    },
    {
      "epoch": 0.07954779359374257,
      "grad_norm": 0.4690602421760559,
      "learning_rate": 9.204522064062576e-06,
      "loss": 0.0589,
      "step": 5024
    },
    {
      "epoch": 0.07956362715138464,
      "grad_norm": 0.013196941465139389,
      "learning_rate": 9.204363728486155e-06,
      "loss": 0.0007,
      "step": 5025
    },
    {
      "epoch": 0.07957946070902672,
      "grad_norm": 0.0027189950924366713,
      "learning_rate": 9.204205392909734e-06,
      "loss": 0.0001,
      "step": 5026
    },
    {
      "epoch": 0.07959529426666878,
      "grad_norm": 0.009736883454024792,
      "learning_rate": 9.204047057333313e-06,
      "loss": 0.0005,
      "step": 5027
    },
    {
      "epoch": 0.07961112782431085,
      "grad_norm": 0.28020215034484863,
      "learning_rate": 9.203888721756894e-06,
      "loss": 0.3835,
      "step": 5028
    },
    {
      "epoch": 0.07962696138195291,
      "grad_norm": 0.43708914518356323,
      "learning_rate": 9.203730386180471e-06,
      "loss": 0.2956,
      "step": 5029
    },
    {
      "epoch": 0.07964279493959497,
      "grad_norm": 0.022371571511030197,
      "learning_rate": 9.20357205060405e-06,
      "loss": 0.0013,
      "step": 5030
    },
    {
      "epoch": 0.07965862849723704,
      "grad_norm": 0.015801481902599335,
      "learning_rate": 9.20341371502763e-06,
      "loss": 0.0007,
      "step": 5031
    },
    {
      "epoch": 0.07967446205487912,
      "grad_norm": 0.42881667613983154,
      "learning_rate": 9.20325537945121e-06,
      "loss": 0.0108,
      "step": 5032
    },
    {
      "epoch": 0.07969029561252118,
      "grad_norm": 0.0003982737543992698,
      "learning_rate": 9.203097043874789e-06,
      "loss": 0.0,
      "step": 5033
    },
    {
      "epoch": 0.07970612917016325,
      "grad_norm": 0.011992927640676498,
      "learning_rate": 9.202938708298368e-06,
      "loss": 0.0005,
      "step": 5034
    },
    {
      "epoch": 0.07972196272780531,
      "grad_norm": 0.24582093954086304,
      "learning_rate": 9.202780372721947e-06,
      "loss": 0.1439,
      "step": 5035
    },
    {
      "epoch": 0.07973779628544737,
      "grad_norm": 0.5916411876678467,
      "learning_rate": 9.202622037145526e-06,
      "loss": 0.3285,
      "step": 5036
    },
    {
      "epoch": 0.07975362984308944,
      "grad_norm": 0.007859278470277786,
      "learning_rate": 9.202463701569107e-06,
      "loss": 0.0003,
      "step": 5037
    },
    {
      "epoch": 0.07976946340073152,
      "grad_norm": 4.134210757911205e-05,
      "learning_rate": 9.202305365992686e-06,
      "loss": 0.0,
      "step": 5038
    },
    {
      "epoch": 0.07978529695837358,
      "grad_norm": 0.3887452781200409,
      "learning_rate": 9.202147030416265e-06,
      "loss": 0.0903,
      "step": 5039
    },
    {
      "epoch": 0.07980113051601564,
      "grad_norm": 0.3458107113838196,
      "learning_rate": 9.201988694839844e-06,
      "loss": 0.0092,
      "step": 5040
    },
    {
      "epoch": 0.07981696407365771,
      "grad_norm": 0.4608345329761505,
      "learning_rate": 9.201830359263423e-06,
      "loss": 0.0692,
      "step": 5041
    },
    {
      "epoch": 0.07983279763129977,
      "grad_norm": 0.028546221554279327,
      "learning_rate": 9.201672023687002e-06,
      "loss": 0.0014,
      "step": 5042
    },
    {
      "epoch": 0.07984863118894184,
      "grad_norm": 0.37744930386543274,
      "learning_rate": 9.201513688110583e-06,
      "loss": 0.3815,
      "step": 5043
    },
    {
      "epoch": 0.07986446474658392,
      "grad_norm": 0.013292383402585983,
      "learning_rate": 9.201355352534162e-06,
      "loss": 0.0006,
      "step": 5044
    },
    {
      "epoch": 0.07988029830422598,
      "grad_norm": 0.007981165312230587,
      "learning_rate": 9.201197016957741e-06,
      "loss": 0.0003,
      "step": 5045
    },
    {
      "epoch": 0.07989613186186804,
      "grad_norm": 0.39281511306762695,
      "learning_rate": 9.20103868138132e-06,
      "loss": 0.1591,
      "step": 5046
    },
    {
      "epoch": 0.07991196541951011,
      "grad_norm": 0.12987977266311646,
      "learning_rate": 9.2008803458049e-06,
      "loss": 0.002,
      "step": 5047
    },
    {
      "epoch": 0.07992779897715217,
      "grad_norm": 0.2421666532754898,
      "learning_rate": 9.200722010228479e-06,
      "loss": 0.069,
      "step": 5048
    },
    {
      "epoch": 0.07994363253479424,
      "grad_norm": 0.2527317702770233,
      "learning_rate": 9.20056367465206e-06,
      "loss": 0.1945,
      "step": 5049
    },
    {
      "epoch": 0.07995946609243632,
      "grad_norm": 0.4304102063179016,
      "learning_rate": 9.200405339075638e-06,
      "loss": 0.2441,
      "step": 5050
    },
    {
      "epoch": 0.07997529965007838,
      "grad_norm": 0.0076143499463796616,
      "learning_rate": 9.200247003499217e-06,
      "loss": 0.0003,
      "step": 5051
    },
    {
      "epoch": 0.07999113320772044,
      "grad_norm": 0.5141039490699768,
      "learning_rate": 9.200088667922797e-06,
      "loss": 0.1758,
      "step": 5052
    },
    {
      "epoch": 0.08000696676536251,
      "grad_norm": 0.42807894945144653,
      "learning_rate": 9.199930332346376e-06,
      "loss": 0.5503,
      "step": 5053
    },
    {
      "epoch": 0.08002280032300457,
      "grad_norm": 0.233133003115654,
      "learning_rate": 9.199771996769955e-06,
      "loss": 0.1039,
      "step": 5054
    },
    {
      "epoch": 0.08003863388064664,
      "grad_norm": 0.4780886471271515,
      "learning_rate": 9.199613661193534e-06,
      "loss": 0.1954,
      "step": 5055
    },
    {
      "epoch": 0.08005446743828872,
      "grad_norm": 0.2320072203874588,
      "learning_rate": 9.199455325617115e-06,
      "loss": 0.1192,
      "step": 5056
    },
    {
      "epoch": 0.08007030099593078,
      "grad_norm": 0.181627556681633,
      "learning_rate": 9.199296990040692e-06,
      "loss": 0.0874,
      "step": 5057
    },
    {
      "epoch": 0.08008613455357284,
      "grad_norm": 0.6475256681442261,
      "learning_rate": 9.199138654464273e-06,
      "loss": 0.2114,
      "step": 5058
    },
    {
      "epoch": 0.08010196811121491,
      "grad_norm": 0.0024975910782814026,
      "learning_rate": 9.198980318887852e-06,
      "loss": 0.0001,
      "step": 5059
    },
    {
      "epoch": 0.08011780166885697,
      "grad_norm": 0.16291090846061707,
      "learning_rate": 9.198821983311431e-06,
      "loss": 0.0446,
      "step": 5060
    },
    {
      "epoch": 0.08013363522649904,
      "grad_norm": 0.2782640755176544,
      "learning_rate": 9.19866364773501e-06,
      "loss": 0.2273,
      "step": 5061
    },
    {
      "epoch": 0.08014946878414111,
      "grad_norm": 0.36320286989212036,
      "learning_rate": 9.19850531215859e-06,
      "loss": 0.3947,
      "step": 5062
    },
    {
      "epoch": 0.08016530234178318,
      "grad_norm": 0.09199587255716324,
      "learning_rate": 9.198346976582168e-06,
      "loss": 0.0035,
      "step": 5063
    },
    {
      "epoch": 0.08018113589942524,
      "grad_norm": 0.2406850904226303,
      "learning_rate": 9.198188641005749e-06,
      "loss": 0.1468,
      "step": 5064
    },
    {
      "epoch": 0.08019696945706731,
      "grad_norm": 0.003890024498105049,
      "learning_rate": 9.198030305429328e-06,
      "loss": 0.0001,
      "step": 5065
    },
    {
      "epoch": 0.08021280301470937,
      "grad_norm": 0.38835880160331726,
      "learning_rate": 9.197871969852907e-06,
      "loss": 0.2078,
      "step": 5066
    },
    {
      "epoch": 0.08022863657235144,
      "grad_norm": 0.1289464235305786,
      "learning_rate": 9.197713634276486e-06,
      "loss": 0.0565,
      "step": 5067
    },
    {
      "epoch": 0.08024447012999351,
      "grad_norm": 0.11282406747341156,
      "learning_rate": 9.197555298700065e-06,
      "loss": 0.0375,
      "step": 5068
    },
    {
      "epoch": 0.08026030368763558,
      "grad_norm": 0.267997682094574,
      "learning_rate": 9.197396963123644e-06,
      "loss": 0.6513,
      "step": 5069
    },
    {
      "epoch": 0.08027613724527764,
      "grad_norm": 0.21306094527244568,
      "learning_rate": 9.197238627547225e-06,
      "loss": 0.1786,
      "step": 5070
    },
    {
      "epoch": 0.08029197080291971,
      "grad_norm": 0.512269914150238,
      "learning_rate": 9.197080291970804e-06,
      "loss": 0.1276,
      "step": 5071
    },
    {
      "epoch": 0.08030780436056177,
      "grad_norm": 0.28651347756385803,
      "learning_rate": 9.196921956394383e-06,
      "loss": 0.2195,
      "step": 5072
    },
    {
      "epoch": 0.08032363791820384,
      "grad_norm": 0.3579435348510742,
      "learning_rate": 9.196763620817962e-06,
      "loss": 0.2463,
      "step": 5073
    },
    {
      "epoch": 0.08033947147584591,
      "grad_norm": 0.34250015020370483,
      "learning_rate": 9.196605285241541e-06,
      "loss": 0.1601,
      "step": 5074
    },
    {
      "epoch": 0.08035530503348798,
      "grad_norm": 0.18570898473262787,
      "learning_rate": 9.19644694966512e-06,
      "loss": 0.0569,
      "step": 5075
    },
    {
      "epoch": 0.08037113859113004,
      "grad_norm": 0.23237504065036774,
      "learning_rate": 9.196288614088701e-06,
      "loss": 0.091,
      "step": 5076
    },
    {
      "epoch": 0.0803869721487721,
      "grad_norm": 0.2820090055465698,
      "learning_rate": 9.19613027851228e-06,
      "loss": 0.2317,
      "step": 5077
    },
    {
      "epoch": 0.08040280570641417,
      "grad_norm": 0.9725014567375183,
      "learning_rate": 9.195971942935858e-06,
      "loss": 0.0639,
      "step": 5078
    },
    {
      "epoch": 0.08041863926405624,
      "grad_norm": 0.19200719892978668,
      "learning_rate": 9.195813607359438e-06,
      "loss": 0.0125,
      "step": 5079
    },
    {
      "epoch": 0.08043447282169831,
      "grad_norm": 0.2592640817165375,
      "learning_rate": 9.195655271783018e-06,
      "loss": 0.0368,
      "step": 5080
    },
    {
      "epoch": 0.08045030637934038,
      "grad_norm": 0.4496266543865204,
      "learning_rate": 9.195496936206597e-06,
      "loss": 0.0591,
      "step": 5081
    },
    {
      "epoch": 0.08046613993698244,
      "grad_norm": 0.02710157446563244,
      "learning_rate": 9.195338600630176e-06,
      "loss": 0.0019,
      "step": 5082
    },
    {
      "epoch": 0.0804819734946245,
      "grad_norm": 0.19393889605998993,
      "learning_rate": 9.195180265053756e-06,
      "loss": 0.1478,
      "step": 5083
    },
    {
      "epoch": 0.08049780705226657,
      "grad_norm": 0.3316037952899933,
      "learning_rate": 9.195021929477334e-06,
      "loss": 0.7018,
      "step": 5084
    },
    {
      "epoch": 0.08051364060990863,
      "grad_norm": 0.057526737451553345,
      "learning_rate": 9.194863593900915e-06,
      "loss": 0.0037,
      "step": 5085
    },
    {
      "epoch": 0.08052947416755071,
      "grad_norm": 0.22657127678394318,
      "learning_rate": 9.194705258324494e-06,
      "loss": 0.1052,
      "step": 5086
    },
    {
      "epoch": 0.08054530772519278,
      "grad_norm": 6.489836960099638e-05,
      "learning_rate": 9.194546922748073e-06,
      "loss": 0.0,
      "step": 5087
    },
    {
      "epoch": 0.08056114128283484,
      "grad_norm": 0.4263940453529358,
      "learning_rate": 9.194388587171652e-06,
      "loss": 0.3575,
      "step": 5088
    },
    {
      "epoch": 0.0805769748404769,
      "grad_norm": 0.00013472288264892995,
      "learning_rate": 9.194230251595233e-06,
      "loss": 0.0,
      "step": 5089
    },
    {
      "epoch": 0.08059280839811897,
      "grad_norm": 0.0032100528478622437,
      "learning_rate": 9.19407191601881e-06,
      "loss": 0.0001,
      "step": 5090
    },
    {
      "epoch": 0.08060864195576103,
      "grad_norm": 0.511999249458313,
      "learning_rate": 9.19391358044239e-06,
      "loss": 0.0628,
      "step": 5091
    },
    {
      "epoch": 0.08062447551340311,
      "grad_norm": 0.4737358093261719,
      "learning_rate": 9.19375524486597e-06,
      "loss": 0.1133,
      "step": 5092
    },
    {
      "epoch": 0.08064030907104518,
      "grad_norm": 0.008233150467276573,
      "learning_rate": 9.193596909289549e-06,
      "loss": 0.0004,
      "step": 5093
    },
    {
      "epoch": 0.08065614262868724,
      "grad_norm": 0.9437735080718994,
      "learning_rate": 9.193438573713128e-06,
      "loss": 0.4086,
      "step": 5094
    },
    {
      "epoch": 0.0806719761863293,
      "grad_norm": 0.5479037165641785,
      "learning_rate": 9.193280238136709e-06,
      "loss": 0.4793,
      "step": 5095
    },
    {
      "epoch": 0.08068780974397137,
      "grad_norm": 0.00012166875967523083,
      "learning_rate": 9.193121902560286e-06,
      "loss": 0.0,
      "step": 5096
    },
    {
      "epoch": 0.08070364330161343,
      "grad_norm": 0.3023897707462311,
      "learning_rate": 9.192963566983867e-06,
      "loss": 0.1909,
      "step": 5097
    },
    {
      "epoch": 0.08071947685925551,
      "grad_norm": 0.5125902891159058,
      "learning_rate": 9.192805231407446e-06,
      "loss": 0.1925,
      "step": 5098
    },
    {
      "epoch": 0.08073531041689758,
      "grad_norm": 1.4834308624267578,
      "learning_rate": 9.192646895831025e-06,
      "loss": 0.0847,
      "step": 5099
    },
    {
      "epoch": 0.08075114397453964,
      "grad_norm": 0.17431485652923584,
      "learning_rate": 9.192488560254604e-06,
      "loss": 0.0529,
      "step": 5100
    },
    {
      "epoch": 0.0807669775321817,
      "grad_norm": 0.00012133087875554338,
      "learning_rate": 9.192330224678183e-06,
      "loss": 0.0,
      "step": 5101
    },
    {
      "epoch": 0.08078281108982377,
      "grad_norm": 0.19282905757427216,
      "learning_rate": 9.192171889101762e-06,
      "loss": 0.0875,
      "step": 5102
    },
    {
      "epoch": 0.08079864464746583,
      "grad_norm": 0.5015248656272888,
      "learning_rate": 9.192013553525341e-06,
      "loss": 0.4363,
      "step": 5103
    },
    {
      "epoch": 0.08081447820510791,
      "grad_norm": 0.25570622086524963,
      "learning_rate": 9.191855217948922e-06,
      "loss": 0.0454,
      "step": 5104
    },
    {
      "epoch": 0.08083031176274998,
      "grad_norm": 0.013895408250391483,
      "learning_rate": 9.191696882372501e-06,
      "loss": 0.0007,
      "step": 5105
    },
    {
      "epoch": 0.08084614532039204,
      "grad_norm": 0.002926388755440712,
      "learning_rate": 9.19153854679608e-06,
      "loss": 0.0001,
      "step": 5106
    },
    {
      "epoch": 0.0808619788780341,
      "grad_norm": 0.2670229971408844,
      "learning_rate": 9.19138021121966e-06,
      "loss": 0.1208,
      "step": 5107
    },
    {
      "epoch": 0.08087781243567617,
      "grad_norm": 0.0018322065006941557,
      "learning_rate": 9.191221875643239e-06,
      "loss": 0.0,
      "step": 5108
    },
    {
      "epoch": 0.08089364599331823,
      "grad_norm": 0.18332654237747192,
      "learning_rate": 9.191063540066818e-06,
      "loss": 0.0573,
      "step": 5109
    },
    {
      "epoch": 0.08090947955096031,
      "grad_norm": 0.009854002855718136,
      "learning_rate": 9.190905204490398e-06,
      "loss": 0.0006,
      "step": 5110
    },
    {
      "epoch": 0.08092531310860238,
      "grad_norm": 0.5720303654670715,
      "learning_rate": 9.190746868913977e-06,
      "loss": 0.6632,
      "step": 5111
    },
    {
      "epoch": 0.08094114666624444,
      "grad_norm": 1.767014503479004,
      "learning_rate": 9.190588533337557e-06,
      "loss": 0.1847,
      "step": 5112
    },
    {
      "epoch": 0.0809569802238865,
      "grad_norm": 0.04876630753278732,
      "learning_rate": 9.190430197761136e-06,
      "loss": 0.0012,
      "step": 5113
    },
    {
      "epoch": 0.08097281378152857,
      "grad_norm": 0.4266219735145569,
      "learning_rate": 9.190271862184715e-06,
      "loss": 0.2675,
      "step": 5114
    },
    {
      "epoch": 0.08098864733917063,
      "grad_norm": 0.5271288752555847,
      "learning_rate": 9.190113526608294e-06,
      "loss": 0.1056,
      "step": 5115
    },
    {
      "epoch": 0.08100448089681271,
      "grad_norm": 0.3612763285636902,
      "learning_rate": 9.189955191031875e-06,
      "loss": 0.8375,
      "step": 5116
    },
    {
      "epoch": 0.08102031445445478,
      "grad_norm": 0.000627379457000643,
      "learning_rate": 9.189796855455454e-06,
      "loss": 0.0,
      "step": 5117
    },
    {
      "epoch": 0.08103614801209684,
      "grad_norm": 0.0005131929647177458,
      "learning_rate": 9.189638519879033e-06,
      "loss": 0.0,
      "step": 5118
    },
    {
      "epoch": 0.0810519815697389,
      "grad_norm": 0.21389606595039368,
      "learning_rate": 9.189480184302612e-06,
      "loss": 0.6233,
      "step": 5119
    },
    {
      "epoch": 0.08106781512738097,
      "grad_norm": 0.23662270605564117,
      "learning_rate": 9.189321848726191e-06,
      "loss": 0.0894,
      "step": 5120
    },
    {
      "epoch": 0.08108364868502303,
      "grad_norm": 0.1405160129070282,
      "learning_rate": 9.18916351314977e-06,
      "loss": 0.0054,
      "step": 5121
    },
    {
      "epoch": 0.08109948224266511,
      "grad_norm": 0.33843928575515747,
      "learning_rate": 9.18900517757335e-06,
      "loss": 0.2047,
      "step": 5122
    },
    {
      "epoch": 0.08111531580030718,
      "grad_norm": 0.12181027233600616,
      "learning_rate": 9.18884684199693e-06,
      "loss": 0.0471,
      "step": 5123
    },
    {
      "epoch": 0.08113114935794924,
      "grad_norm": 0.36126473546028137,
      "learning_rate": 9.188688506420509e-06,
      "loss": 0.0472,
      "step": 5124
    },
    {
      "epoch": 0.0811469829155913,
      "grad_norm": 0.01858753338456154,
      "learning_rate": 9.188530170844088e-06,
      "loss": 0.0009,
      "step": 5125
    },
    {
      "epoch": 0.08116281647323337,
      "grad_norm": 0.0005667706136591733,
      "learning_rate": 9.188371835267667e-06,
      "loss": 0.0,
      "step": 5126
    },
    {
      "epoch": 0.08117865003087543,
      "grad_norm": 0.2058967649936676,
      "learning_rate": 9.188213499691246e-06,
      "loss": 0.1361,
      "step": 5127
    },
    {
      "epoch": 0.08119448358851751,
      "grad_norm": 0.11987142264842987,
      "learning_rate": 9.188055164114825e-06,
      "loss": 0.0226,
      "step": 5128
    },
    {
      "epoch": 0.08121031714615957,
      "grad_norm": 0.37866637110710144,
      "learning_rate": 9.187896828538406e-06,
      "loss": 0.6411,
      "step": 5129
    },
    {
      "epoch": 0.08122615070380164,
      "grad_norm": 0.004758932162076235,
      "learning_rate": 9.187738492961983e-06,
      "loss": 0.0002,
      "step": 5130
    },
    {
      "epoch": 0.0812419842614437,
      "grad_norm": 0.5042507648468018,
      "learning_rate": 9.187580157385564e-06,
      "loss": 0.241,
      "step": 5131
    },
    {
      "epoch": 0.08125781781908577,
      "grad_norm": 0.00016371370293200016,
      "learning_rate": 9.187421821809143e-06,
      "loss": 0.0,
      "step": 5132
    },
    {
      "epoch": 0.08127365137672783,
      "grad_norm": 0.7319903373718262,
      "learning_rate": 9.187263486232722e-06,
      "loss": 0.3551,
      "step": 5133
    },
    {
      "epoch": 0.08128948493436991,
      "grad_norm": 0.20213784277439117,
      "learning_rate": 9.187105150656301e-06,
      "loss": 0.3006,
      "step": 5134
    },
    {
      "epoch": 0.08130531849201197,
      "grad_norm": 0.019276408478617668,
      "learning_rate": 9.18694681507988e-06,
      "loss": 0.0008,
      "step": 5135
    },
    {
      "epoch": 0.08132115204965404,
      "grad_norm": 0.12485352903604507,
      "learning_rate": 9.18678847950346e-06,
      "loss": 0.0209,
      "step": 5136
    },
    {
      "epoch": 0.0813369856072961,
      "grad_norm": 0.37277457118034363,
      "learning_rate": 9.18663014392704e-06,
      "loss": 0.5525,
      "step": 5137
    },
    {
      "epoch": 0.08135281916493817,
      "grad_norm": 0.20262983441352844,
      "learning_rate": 9.18647180835062e-06,
      "loss": 0.1493,
      "step": 5138
    },
    {
      "epoch": 0.08136865272258023,
      "grad_norm": 0.4308881163597107,
      "learning_rate": 9.186313472774198e-06,
      "loss": 0.0169,
      "step": 5139
    },
    {
      "epoch": 0.08138448628022231,
      "grad_norm": 0.2526066303253174,
      "learning_rate": 9.186155137197778e-06,
      "loss": 0.1232,
      "step": 5140
    },
    {
      "epoch": 0.08140031983786437,
      "grad_norm": 0.23132160305976868,
      "learning_rate": 9.185996801621357e-06,
      "loss": 0.1463,
      "step": 5141
    },
    {
      "epoch": 0.08141615339550644,
      "grad_norm": 0.1877426654100418,
      "learning_rate": 9.185838466044936e-06,
      "loss": 0.0607,
      "step": 5142
    },
    {
      "epoch": 0.0814319869531485,
      "grad_norm": 0.47587648034095764,
      "learning_rate": 9.185680130468516e-06,
      "loss": 0.3557,
      "step": 5143
    },
    {
      "epoch": 0.08144782051079057,
      "grad_norm": 0.3022184371948242,
      "learning_rate": 9.185521794892096e-06,
      "loss": 0.17,
      "step": 5144
    },
    {
      "epoch": 0.08146365406843263,
      "grad_norm": 0.07277040928602219,
      "learning_rate": 9.185363459315675e-06,
      "loss": 0.0091,
      "step": 5145
    },
    {
      "epoch": 0.08147948762607471,
      "grad_norm": 0.3421320915222168,
      "learning_rate": 9.185205123739254e-06,
      "loss": 0.5716,
      "step": 5146
    },
    {
      "epoch": 0.08149532118371677,
      "grad_norm": 0.11237204074859619,
      "learning_rate": 9.185046788162833e-06,
      "loss": 0.0336,
      "step": 5147
    },
    {
      "epoch": 0.08151115474135884,
      "grad_norm": 0.4280300736427307,
      "learning_rate": 9.184888452586412e-06,
      "loss": 0.0167,
      "step": 5148
    },
    {
      "epoch": 0.0815269882990009,
      "grad_norm": 0.04584366828203201,
      "learning_rate": 9.184730117009991e-06,
      "loss": 0.0004,
      "step": 5149
    },
    {
      "epoch": 0.08154282185664297,
      "grad_norm": 0.06510046869516373,
      "learning_rate": 9.184571781433572e-06,
      "loss": 0.005,
      "step": 5150
    },
    {
      "epoch": 0.08155865541428503,
      "grad_norm": 0.1898120790719986,
      "learning_rate": 9.184413445857149e-06,
      "loss": 0.0566,
      "step": 5151
    },
    {
      "epoch": 0.08157448897192711,
      "grad_norm": 0.0002233566192444414,
      "learning_rate": 9.18425511028073e-06,
      "loss": 0.0,
      "step": 5152
    },
    {
      "epoch": 0.08159032252956917,
      "grad_norm": 0.21226592361927032,
      "learning_rate": 9.184096774704309e-06,
      "loss": 0.0878,
      "step": 5153
    },
    {
      "epoch": 0.08160615608721124,
      "grad_norm": 0.324924111366272,
      "learning_rate": 9.183938439127888e-06,
      "loss": 0.1278,
      "step": 5154
    },
    {
      "epoch": 0.0816219896448533,
      "grad_norm": 0.48888126015663147,
      "learning_rate": 9.183780103551467e-06,
      "loss": 0.1349,
      "step": 5155
    },
    {
      "epoch": 0.08163782320249537,
      "grad_norm": 0.4157557189464569,
      "learning_rate": 9.183621767975048e-06,
      "loss": 0.1055,
      "step": 5156
    },
    {
      "epoch": 0.08165365676013743,
      "grad_norm": 0.23561722040176392,
      "learning_rate": 9.183463432398625e-06,
      "loss": 0.1484,
      "step": 5157
    },
    {
      "epoch": 0.08166949031777951,
      "grad_norm": 0.11116344481706619,
      "learning_rate": 9.183305096822206e-06,
      "loss": 0.0147,
      "step": 5158
    },
    {
      "epoch": 0.08168532387542157,
      "grad_norm": 0.011766061186790466,
      "learning_rate": 9.183146761245785e-06,
      "loss": 0.0007,
      "step": 5159
    },
    {
      "epoch": 0.08170115743306364,
      "grad_norm": 0.0067344652488827705,
      "learning_rate": 9.182988425669364e-06,
      "loss": 0.0004,
      "step": 5160
    },
    {
      "epoch": 0.0817169909907057,
      "grad_norm": 0.11528553813695908,
      "learning_rate": 9.182830090092943e-06,
      "loss": 0.031,
      "step": 5161
    },
    {
      "epoch": 0.08173282454834777,
      "grad_norm": 0.26181888580322266,
      "learning_rate": 9.182671754516524e-06,
      "loss": 0.1338,
      "step": 5162
    },
    {
      "epoch": 0.08174865810598983,
      "grad_norm": 0.3406796157360077,
      "learning_rate": 9.182513418940101e-06,
      "loss": 0.1142,
      "step": 5163
    },
    {
      "epoch": 0.08176449166363191,
      "grad_norm": 0.020098160952329636,
      "learning_rate": 9.182355083363682e-06,
      "loss": 0.0012,
      "step": 5164
    },
    {
      "epoch": 0.08178032522127397,
      "grad_norm": 0.22234377264976501,
      "learning_rate": 9.182196747787261e-06,
      "loss": 0.0697,
      "step": 5165
    },
    {
      "epoch": 0.08179615877891604,
      "grad_norm": 0.08917063474655151,
      "learning_rate": 9.18203841221084e-06,
      "loss": 0.0046,
      "step": 5166
    },
    {
      "epoch": 0.0818119923365581,
      "grad_norm": 0.29910191893577576,
      "learning_rate": 9.18188007663442e-06,
      "loss": 0.1483,
      "step": 5167
    },
    {
      "epoch": 0.08182782589420017,
      "grad_norm": 0.5348455905914307,
      "learning_rate": 9.181721741058e-06,
      "loss": 1.0122,
      "step": 5168
    },
    {
      "epoch": 0.08184365945184223,
      "grad_norm": 0.11550173908472061,
      "learning_rate": 9.181563405481578e-06,
      "loss": 0.0742,
      "step": 5169
    },
    {
      "epoch": 0.08185949300948431,
      "grad_norm": 0.25063586235046387,
      "learning_rate": 9.181405069905158e-06,
      "loss": 0.1814,
      "step": 5170
    },
    {
      "epoch": 0.08187532656712637,
      "grad_norm": 0.27974772453308105,
      "learning_rate": 9.181246734328737e-06,
      "loss": 0.1981,
      "step": 5171
    },
    {
      "epoch": 0.08189116012476844,
      "grad_norm": 0.2994391918182373,
      "learning_rate": 9.181088398752317e-06,
      "loss": 0.1693,
      "step": 5172
    },
    {
      "epoch": 0.0819069936824105,
      "grad_norm": 0.008907495997846127,
      "learning_rate": 9.180930063175896e-06,
      "loss": 0.0005,
      "step": 5173
    },
    {
      "epoch": 0.08192282724005256,
      "grad_norm": 0.8137582540512085,
      "learning_rate": 9.180771727599475e-06,
      "loss": 0.1777,
      "step": 5174
    },
    {
      "epoch": 0.08193866079769463,
      "grad_norm": 0.19307248294353485,
      "learning_rate": 9.180613392023054e-06,
      "loss": 0.0054,
      "step": 5175
    },
    {
      "epoch": 0.08195449435533671,
      "grad_norm": 0.3194161057472229,
      "learning_rate": 9.180455056446633e-06,
      "loss": 0.224,
      "step": 5176
    },
    {
      "epoch": 0.08197032791297877,
      "grad_norm": 0.22355785965919495,
      "learning_rate": 9.180296720870214e-06,
      "loss": 0.1654,
      "step": 5177
    },
    {
      "epoch": 0.08198616147062084,
      "grad_norm": 0.030798157677054405,
      "learning_rate": 9.180138385293793e-06,
      "loss": 0.0014,
      "step": 5178
    },
    {
      "epoch": 0.0820019950282629,
      "grad_norm": 0.4696160852909088,
      "learning_rate": 9.179980049717372e-06,
      "loss": 0.1462,
      "step": 5179
    },
    {
      "epoch": 0.08201782858590496,
      "grad_norm": 0.31950855255126953,
      "learning_rate": 9.179821714140951e-06,
      "loss": 0.1217,
      "step": 5180
    },
    {
      "epoch": 0.08203366214354703,
      "grad_norm": 0.4637540578842163,
      "learning_rate": 9.17966337856453e-06,
      "loss": 0.2054,
      "step": 5181
    },
    {
      "epoch": 0.0820494957011891,
      "grad_norm": 0.3568383753299713,
      "learning_rate": 9.179505042988109e-06,
      "loss": 0.1503,
      "step": 5182
    },
    {
      "epoch": 0.08206532925883117,
      "grad_norm": 0.0047632744535803795,
      "learning_rate": 9.17934670741169e-06,
      "loss": 0.0002,
      "step": 5183
    },
    {
      "epoch": 0.08208116281647324,
      "grad_norm": 0.01953541859984398,
      "learning_rate": 9.179188371835269e-06,
      "loss": 0.0013,
      "step": 5184
    },
    {
      "epoch": 0.0820969963741153,
      "grad_norm": 0.15095731616020203,
      "learning_rate": 9.179030036258848e-06,
      "loss": 0.0671,
      "step": 5185
    },
    {
      "epoch": 0.08211282993175736,
      "grad_norm": 0.020506978034973145,
      "learning_rate": 9.178871700682427e-06,
      "loss": 0.0008,
      "step": 5186
    },
    {
      "epoch": 0.08212866348939943,
      "grad_norm": 0.0002826412965077907,
      "learning_rate": 9.178713365106006e-06,
      "loss": 0.0,
      "step": 5187
    },
    {
      "epoch": 0.0821444970470415,
      "grad_norm": 0.5369424819946289,
      "learning_rate": 9.178555029529585e-06,
      "loss": 0.276,
      "step": 5188
    },
    {
      "epoch": 0.08216033060468357,
      "grad_norm": 0.2732592523097992,
      "learning_rate": 9.178396693953166e-06,
      "loss": 0.1448,
      "step": 5189
    },
    {
      "epoch": 0.08217616416232564,
      "grad_norm": 0.012751275673508644,
      "learning_rate": 9.178238358376745e-06,
      "loss": 0.0005,
      "step": 5190
    },
    {
      "epoch": 0.0821919977199677,
      "grad_norm": 0.16383236646652222,
      "learning_rate": 9.178080022800324e-06,
      "loss": 0.0615,
      "step": 5191
    },
    {
      "epoch": 0.08220783127760976,
      "grad_norm": 0.49103084206581116,
      "learning_rate": 9.177921687223903e-06,
      "loss": 0.1103,
      "step": 5192
    },
    {
      "epoch": 0.08222366483525183,
      "grad_norm": 0.3802379071712494,
      "learning_rate": 9.177763351647482e-06,
      "loss": 0.1858,
      "step": 5193
    },
    {
      "epoch": 0.0822394983928939,
      "grad_norm": 0.01735750399529934,
      "learning_rate": 9.177605016071061e-06,
      "loss": 0.0008,
      "step": 5194
    },
    {
      "epoch": 0.08225533195053597,
      "grad_norm": 0.20185698568820953,
      "learning_rate": 9.177446680494642e-06,
      "loss": 0.1076,
      "step": 5195
    },
    {
      "epoch": 0.08227116550817803,
      "grad_norm": 0.028790311887860298,
      "learning_rate": 9.17728834491822e-06,
      "loss": 0.0015,
      "step": 5196
    },
    {
      "epoch": 0.0822869990658201,
      "grad_norm": 0.3399122357368469,
      "learning_rate": 9.177130009341799e-06,
      "loss": 0.1895,
      "step": 5197
    },
    {
      "epoch": 0.08230283262346216,
      "grad_norm": 0.2504417598247528,
      "learning_rate": 9.17697167376538e-06,
      "loss": 0.0507,
      "step": 5198
    },
    {
      "epoch": 0.08231866618110423,
      "grad_norm": 0.21630819141864777,
      "learning_rate": 9.176813338188959e-06,
      "loss": 0.0546,
      "step": 5199
    },
    {
      "epoch": 0.0823344997387463,
      "grad_norm": 9.596840391168371e-05,
      "learning_rate": 9.176655002612538e-06,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 0.08235033329638837,
      "grad_norm": 0.2900415360927582,
      "learning_rate": 9.176496667036117e-06,
      "loss": 0.1446,
      "step": 5201
    },
    {
      "epoch": 0.08236616685403043,
      "grad_norm": 0.37496358156204224,
      "learning_rate": 9.176338331459696e-06,
      "loss": 0.7114,
      "step": 5202
    },
    {
      "epoch": 0.0823820004116725,
      "grad_norm": 0.00744239054620266,
      "learning_rate": 9.176179995883275e-06,
      "loss": 0.0003,
      "step": 5203
    },
    {
      "epoch": 0.08239783396931456,
      "grad_norm": 0.14190375804901123,
      "learning_rate": 9.176021660306856e-06,
      "loss": 0.002,
      "step": 5204
    },
    {
      "epoch": 0.08241366752695663,
      "grad_norm": 0.2807164192199707,
      "learning_rate": 9.175863324730435e-06,
      "loss": 0.1423,
      "step": 5205
    },
    {
      "epoch": 0.0824295010845987,
      "grad_norm": 0.2764241099357605,
      "learning_rate": 9.175704989154014e-06,
      "loss": 0.2784,
      "step": 5206
    },
    {
      "epoch": 0.08244533464224077,
      "grad_norm": 0.5774295926094055,
      "learning_rate": 9.175546653577593e-06,
      "loss": 0.0123,
      "step": 5207
    },
    {
      "epoch": 0.08246116819988283,
      "grad_norm": 0.09629764407873154,
      "learning_rate": 9.175388318001172e-06,
      "loss": 0.0111,
      "step": 5208
    },
    {
      "epoch": 0.0824770017575249,
      "grad_norm": 0.013060083612799644,
      "learning_rate": 9.175229982424751e-06,
      "loss": 0.0007,
      "step": 5209
    },
    {
      "epoch": 0.08249283531516696,
      "grad_norm": 0.1231154352426529,
      "learning_rate": 9.175071646848332e-06,
      "loss": 0.0496,
      "step": 5210
    },
    {
      "epoch": 0.08250866887280903,
      "grad_norm": 0.021681733429431915,
      "learning_rate": 9.17491331127191e-06,
      "loss": 0.0013,
      "step": 5211
    },
    {
      "epoch": 0.0825245024304511,
      "grad_norm": 0.35716819763183594,
      "learning_rate": 9.17475497569549e-06,
      "loss": 0.054,
      "step": 5212
    },
    {
      "epoch": 0.08254033598809317,
      "grad_norm": 0.28735318779945374,
      "learning_rate": 9.174596640119069e-06,
      "loss": 0.2183,
      "step": 5213
    },
    {
      "epoch": 0.08255616954573523,
      "grad_norm": 0.19302792847156525,
      "learning_rate": 9.174438304542648e-06,
      "loss": 0.0311,
      "step": 5214
    },
    {
      "epoch": 0.0825720031033773,
      "grad_norm": 0.16586323082447052,
      "learning_rate": 9.174279968966227e-06,
      "loss": 0.0547,
      "step": 5215
    },
    {
      "epoch": 0.08258783666101936,
      "grad_norm": 0.05270086228847504,
      "learning_rate": 9.174121633389808e-06,
      "loss": 0.0028,
      "step": 5216
    },
    {
      "epoch": 0.08260367021866143,
      "grad_norm": 0.011568454094231129,
      "learning_rate": 9.173963297813387e-06,
      "loss": 0.0006,
      "step": 5217
    },
    {
      "epoch": 0.0826195037763035,
      "grad_norm": 0.05549980327486992,
      "learning_rate": 9.173804962236966e-06,
      "loss": 0.0051,
      "step": 5218
    },
    {
      "epoch": 0.08263533733394557,
      "grad_norm": 0.2343611717224121,
      "learning_rate": 9.173646626660545e-06,
      "loss": 0.0971,
      "step": 5219
    },
    {
      "epoch": 0.08265117089158763,
      "grad_norm": 0.24256499111652374,
      "learning_rate": 9.173488291084124e-06,
      "loss": 0.1066,
      "step": 5220
    },
    {
      "epoch": 0.0826670044492297,
      "grad_norm": 0.0003321215626783669,
      "learning_rate": 9.173329955507703e-06,
      "loss": 0.0,
      "step": 5221
    },
    {
      "epoch": 0.08268283800687176,
      "grad_norm": 0.03831331059336662,
      "learning_rate": 9.173171619931282e-06,
      "loss": 0.002,
      "step": 5222
    },
    {
      "epoch": 0.08269867156451383,
      "grad_norm": 0.24148230254650116,
      "learning_rate": 9.173013284354863e-06,
      "loss": 0.2499,
      "step": 5223
    },
    {
      "epoch": 0.0827145051221559,
      "grad_norm": 0.007324518635869026,
      "learning_rate": 9.17285494877844e-06,
      "loss": 0.0003,
      "step": 5224
    },
    {
      "epoch": 0.08273033867979797,
      "grad_norm": 0.2460017055273056,
      "learning_rate": 9.172696613202021e-06,
      "loss": 0.2347,
      "step": 5225
    },
    {
      "epoch": 0.08274617223744003,
      "grad_norm": 0.3533971607685089,
      "learning_rate": 9.1725382776256e-06,
      "loss": 0.2429,
      "step": 5226
    },
    {
      "epoch": 0.0827620057950821,
      "grad_norm": 0.13685032725334167,
      "learning_rate": 9.17237994204918e-06,
      "loss": 0.0642,
      "step": 5227
    },
    {
      "epoch": 0.08277783935272416,
      "grad_norm": 0.4931919574737549,
      "learning_rate": 9.172221606472759e-06,
      "loss": 0.9295,
      "step": 5228
    },
    {
      "epoch": 0.08279367291036623,
      "grad_norm": 0.2510641813278198,
      "learning_rate": 9.17206327089634e-06,
      "loss": 0.1316,
      "step": 5229
    },
    {
      "epoch": 0.08280950646800829,
      "grad_norm": 0.4944540858268738,
      "learning_rate": 9.171904935319917e-06,
      "loss": 0.2268,
      "step": 5230
    },
    {
      "epoch": 0.08282534002565037,
      "grad_norm": 0.557182252407074,
      "learning_rate": 9.171746599743498e-06,
      "loss": 0.6204,
      "step": 5231
    },
    {
      "epoch": 0.08284117358329243,
      "grad_norm": 0.15765199065208435,
      "learning_rate": 9.171588264167077e-06,
      "loss": 0.014,
      "step": 5232
    },
    {
      "epoch": 0.0828570071409345,
      "grad_norm": 0.08758246898651123,
      "learning_rate": 9.171429928590656e-06,
      "loss": 0.0029,
      "step": 5233
    },
    {
      "epoch": 0.08287284069857656,
      "grad_norm": 0.27950429916381836,
      "learning_rate": 9.171271593014235e-06,
      "loss": 0.3973,
      "step": 5234
    },
    {
      "epoch": 0.08288867425621863,
      "grad_norm": 0.018100552260875702,
      "learning_rate": 9.171113257437816e-06,
      "loss": 0.0007,
      "step": 5235
    },
    {
      "epoch": 0.08290450781386069,
      "grad_norm": 0.19412609934806824,
      "learning_rate": 9.170954921861393e-06,
      "loss": 0.2218,
      "step": 5236
    },
    {
      "epoch": 0.08292034137150277,
      "grad_norm": 0.007206308655440807,
      "learning_rate": 9.170796586284974e-06,
      "loss": 0.0003,
      "step": 5237
    },
    {
      "epoch": 0.08293617492914483,
      "grad_norm": 0.012489904649555683,
      "learning_rate": 9.170638250708553e-06,
      "loss": 0.0006,
      "step": 5238
    },
    {
      "epoch": 0.0829520084867869,
      "grad_norm": 0.3432047665119171,
      "learning_rate": 9.170479915132132e-06,
      "loss": 0.0873,
      "step": 5239
    },
    {
      "epoch": 0.08296784204442896,
      "grad_norm": 0.4748428761959076,
      "learning_rate": 9.170321579555711e-06,
      "loss": 0.7505,
      "step": 5240
    },
    {
      "epoch": 0.08298367560207102,
      "grad_norm": 0.4299161732196808,
      "learning_rate": 9.170163243979292e-06,
      "loss": 0.2012,
      "step": 5241
    },
    {
      "epoch": 0.08299950915971309,
      "grad_norm": 0.009111142717301846,
      "learning_rate": 9.170004908402869e-06,
      "loss": 0.0005,
      "step": 5242
    },
    {
      "epoch": 0.08301534271735517,
      "grad_norm": 0.3609004616737366,
      "learning_rate": 9.16984657282645e-06,
      "loss": 0.2353,
      "step": 5243
    },
    {
      "epoch": 0.08303117627499723,
      "grad_norm": 0.6337813138961792,
      "learning_rate": 9.169688237250029e-06,
      "loss": 0.7056,
      "step": 5244
    },
    {
      "epoch": 0.0830470098326393,
      "grad_norm": 0.04170766845345497,
      "learning_rate": 9.169529901673608e-06,
      "loss": 0.0023,
      "step": 5245
    },
    {
      "epoch": 0.08306284339028136,
      "grad_norm": 0.30017295479774475,
      "learning_rate": 9.169371566097187e-06,
      "loss": 0.2783,
      "step": 5246
    },
    {
      "epoch": 0.08307867694792342,
      "grad_norm": 0.023795176297426224,
      "learning_rate": 9.169213230520766e-06,
      "loss": 0.0013,
      "step": 5247
    },
    {
      "epoch": 0.08309451050556549,
      "grad_norm": 0.33694297075271606,
      "learning_rate": 9.169054894944345e-06,
      "loss": 0.0983,
      "step": 5248
    },
    {
      "epoch": 0.08311034406320757,
      "grad_norm": 0.2856391668319702,
      "learning_rate": 9.168896559367924e-06,
      "loss": 0.0849,
      "step": 5249
    },
    {
      "epoch": 0.08312617762084963,
      "grad_norm": 0.20368248224258423,
      "learning_rate": 9.168738223791505e-06,
      "loss": 0.0805,
      "step": 5250
    },
    {
      "epoch": 0.0831420111784917,
      "grad_norm": 0.0005327408434823155,
      "learning_rate": 9.168579888215084e-06,
      "loss": 0.0,
      "step": 5251
    },
    {
      "epoch": 0.08315784473613376,
      "grad_norm": 0.39487412571907043,
      "learning_rate": 9.168421552638663e-06,
      "loss": 0.5188,
      "step": 5252
    },
    {
      "epoch": 0.08317367829377582,
      "grad_norm": 1.1501116752624512,
      "learning_rate": 9.168263217062242e-06,
      "loss": 0.206,
      "step": 5253
    },
    {
      "epoch": 0.08318951185141789,
      "grad_norm": 0.004836518317461014,
      "learning_rate": 9.168104881485821e-06,
      "loss": 0.0002,
      "step": 5254
    },
    {
      "epoch": 0.08320534540905997,
      "grad_norm": 0.3792423903942108,
      "learning_rate": 9.1679465459094e-06,
      "loss": 0.5319,
      "step": 5255
    },
    {
      "epoch": 0.08322117896670203,
      "grad_norm": 0.4134223461151123,
      "learning_rate": 9.167788210332981e-06,
      "loss": 0.0883,
      "step": 5256
    },
    {
      "epoch": 0.0832370125243441,
      "grad_norm": 0.268474817276001,
      "learning_rate": 9.16762987475656e-06,
      "loss": 0.2447,
      "step": 5257
    },
    {
      "epoch": 0.08325284608198616,
      "grad_norm": 0.00029017054475843906,
      "learning_rate": 9.16747153918014e-06,
      "loss": 0.0,
      "step": 5258
    },
    {
      "epoch": 0.08326867963962822,
      "grad_norm": 0.26440784335136414,
      "learning_rate": 9.167313203603719e-06,
      "loss": 0.0429,
      "step": 5259
    },
    {
      "epoch": 0.08328451319727029,
      "grad_norm": 0.19656409323215485,
      "learning_rate": 9.167154868027298e-06,
      "loss": 0.1004,
      "step": 5260
    },
    {
      "epoch": 0.08330034675491237,
      "grad_norm": 0.03607969731092453,
      "learning_rate": 9.166996532450877e-06,
      "loss": 0.0014,
      "step": 5261
    },
    {
      "epoch": 0.08331618031255443,
      "grad_norm": 0.00033759258803911507,
      "learning_rate": 9.166838196874457e-06,
      "loss": 0.0,
      "step": 5262
    },
    {
      "epoch": 0.0833320138701965,
      "grad_norm": 0.5852545499801636,
      "learning_rate": 9.166679861298035e-06,
      "loss": 0.5296,
      "step": 5263
    },
    {
      "epoch": 0.08334784742783856,
      "grad_norm": 0.0034500574693083763,
      "learning_rate": 9.166521525721616e-06,
      "loss": 0.0001,
      "step": 5264
    },
    {
      "epoch": 0.08336368098548062,
      "grad_norm": 0.0002277575695188716,
      "learning_rate": 9.166363190145195e-06,
      "loss": 0.0,
      "step": 5265
    },
    {
      "epoch": 0.08337951454312269,
      "grad_norm": 5.829513247590512e-05,
      "learning_rate": 9.166204854568774e-06,
      "loss": 0.0,
      "step": 5266
    },
    {
      "epoch": 0.08339534810076477,
      "grad_norm": 0.37027862668037415,
      "learning_rate": 9.166046518992353e-06,
      "loss": 0.4135,
      "step": 5267
    },
    {
      "epoch": 0.08341118165840683,
      "grad_norm": 0.26252487301826477,
      "learning_rate": 9.165888183415934e-06,
      "loss": 0.1869,
      "step": 5268
    },
    {
      "epoch": 0.0834270152160489,
      "grad_norm": 0.6311300992965698,
      "learning_rate": 9.165729847839511e-06,
      "loss": 0.1004,
      "step": 5269
    },
    {
      "epoch": 0.08344284877369096,
      "grad_norm": 0.24334484338760376,
      "learning_rate": 9.16557151226309e-06,
      "loss": 0.0097,
      "step": 5270
    },
    {
      "epoch": 0.08345868233133302,
      "grad_norm": 0.8459810614585876,
      "learning_rate": 9.165413176686671e-06,
      "loss": 0.2062,
      "step": 5271
    },
    {
      "epoch": 0.08347451588897509,
      "grad_norm": 0.38156142830848694,
      "learning_rate": 9.16525484111025e-06,
      "loss": 0.3007,
      "step": 5272
    },
    {
      "epoch": 0.08349034944661717,
      "grad_norm": 0.34792637825012207,
      "learning_rate": 9.165096505533829e-06,
      "loss": 0.0897,
      "step": 5273
    },
    {
      "epoch": 0.08350618300425923,
      "grad_norm": 0.31691011786460876,
      "learning_rate": 9.164938169957408e-06,
      "loss": 0.0549,
      "step": 5274
    },
    {
      "epoch": 0.0835220165619013,
      "grad_norm": 0.0338633693754673,
      "learning_rate": 9.164779834380987e-06,
      "loss": 0.0021,
      "step": 5275
    },
    {
      "epoch": 0.08353785011954336,
      "grad_norm": 0.22344234585762024,
      "learning_rate": 9.164621498804566e-06,
      "loss": 0.0824,
      "step": 5276
    },
    {
      "epoch": 0.08355368367718542,
      "grad_norm": 0.4127153158187866,
      "learning_rate": 9.164463163228147e-06,
      "loss": 0.5785,
      "step": 5277
    },
    {
      "epoch": 0.08356951723482749,
      "grad_norm": 0.3874788284301758,
      "learning_rate": 9.164304827651726e-06,
      "loss": 0.5896,
      "step": 5278
    },
    {
      "epoch": 0.08358535079246956,
      "grad_norm": 0.2981296181678772,
      "learning_rate": 9.164146492075305e-06,
      "loss": 0.1085,
      "step": 5279
    },
    {
      "epoch": 0.08360118435011163,
      "grad_norm": 0.26636403799057007,
      "learning_rate": 9.163988156498884e-06,
      "loss": 0.0511,
      "step": 5280
    },
    {
      "epoch": 0.0836170179077537,
      "grad_norm": 0.5209909677505493,
      "learning_rate": 9.163829820922463e-06,
      "loss": 0.3155,
      "step": 5281
    },
    {
      "epoch": 0.08363285146539576,
      "grad_norm": 0.2292347550392151,
      "learning_rate": 9.163671485346042e-06,
      "loss": 0.1567,
      "step": 5282
    },
    {
      "epoch": 0.08364868502303782,
      "grad_norm": 0.02918037585914135,
      "learning_rate": 9.163513149769623e-06,
      "loss": 0.0019,
      "step": 5283
    },
    {
      "epoch": 0.08366451858067989,
      "grad_norm": 0.00951374601572752,
      "learning_rate": 9.163354814193202e-06,
      "loss": 0.0002,
      "step": 5284
    },
    {
      "epoch": 0.08368035213832196,
      "grad_norm": 0.051371123641729355,
      "learning_rate": 9.163196478616781e-06,
      "loss": 0.0033,
      "step": 5285
    },
    {
      "epoch": 0.08369618569596403,
      "grad_norm": 0.3081640899181366,
      "learning_rate": 9.16303814304036e-06,
      "loss": 0.0711,
      "step": 5286
    },
    {
      "epoch": 0.0837120192536061,
      "grad_norm": 0.22119995951652527,
      "learning_rate": 9.16287980746394e-06,
      "loss": 0.0826,
      "step": 5287
    },
    {
      "epoch": 0.08372785281124816,
      "grad_norm": 0.22731080651283264,
      "learning_rate": 9.162721471887519e-06,
      "loss": 0.0139,
      "step": 5288
    },
    {
      "epoch": 0.08374368636889022,
      "grad_norm": 0.015254462137818336,
      "learning_rate": 9.1625631363111e-06,
      "loss": 0.0006,
      "step": 5289
    },
    {
      "epoch": 0.08375951992653229,
      "grad_norm": 0.9879387021064758,
      "learning_rate": 9.162404800734678e-06,
      "loss": 1.4635,
      "step": 5290
    },
    {
      "epoch": 0.08377535348417436,
      "grad_norm": 0.8351003527641296,
      "learning_rate": 9.162246465158258e-06,
      "loss": 0.0796,
      "step": 5291
    },
    {
      "epoch": 0.08379118704181643,
      "grad_norm": 0.2456752508878708,
      "learning_rate": 9.162088129581837e-06,
      "loss": 0.1695,
      "step": 5292
    },
    {
      "epoch": 0.08380702059945849,
      "grad_norm": 0.3536009192466736,
      "learning_rate": 9.161929794005416e-06,
      "loss": 0.082,
      "step": 5293
    },
    {
      "epoch": 0.08382285415710056,
      "grad_norm": 0.6939553022384644,
      "learning_rate": 9.161771458428995e-06,
      "loss": 0.7782,
      "step": 5294
    },
    {
      "epoch": 0.08383868771474262,
      "grad_norm": 0.00014227883366402239,
      "learning_rate": 9.161613122852574e-06,
      "loss": 0.0,
      "step": 5295
    },
    {
      "epoch": 0.08385452127238469,
      "grad_norm": 0.0023070485331118107,
      "learning_rate": 9.161454787276155e-06,
      "loss": 0.0001,
      "step": 5296
    },
    {
      "epoch": 0.08387035483002676,
      "grad_norm": 0.31635478138923645,
      "learning_rate": 9.161296451699732e-06,
      "loss": 0.0651,
      "step": 5297
    },
    {
      "epoch": 0.08388618838766883,
      "grad_norm": 0.00038751811371184886,
      "learning_rate": 9.161138116123313e-06,
      "loss": 0.0,
      "step": 5298
    },
    {
      "epoch": 0.08390202194531089,
      "grad_norm": 0.4168018400669098,
      "learning_rate": 9.160979780546892e-06,
      "loss": 0.1859,
      "step": 5299
    },
    {
      "epoch": 0.08391785550295296,
      "grad_norm": 0.13073360919952393,
      "learning_rate": 9.160821444970471e-06,
      "loss": 0.0099,
      "step": 5300
    },
    {
      "epoch": 0.08393368906059502,
      "grad_norm": 0.24614179134368896,
      "learning_rate": 9.16066310939405e-06,
      "loss": 0.1925,
      "step": 5301
    },
    {
      "epoch": 0.08394952261823709,
      "grad_norm": 0.4518938660621643,
      "learning_rate": 9.16050477381763e-06,
      "loss": 0.5691,
      "step": 5302
    },
    {
      "epoch": 0.08396535617587916,
      "grad_norm": 0.3787941634654999,
      "learning_rate": 9.160346438241208e-06,
      "loss": 0.8377,
      "step": 5303
    },
    {
      "epoch": 0.08398118973352123,
      "grad_norm": 0.5275964140892029,
      "learning_rate": 9.160188102664789e-06,
      "loss": 0.4642,
      "step": 5304
    },
    {
      "epoch": 0.08399702329116329,
      "grad_norm": 0.3054542541503906,
      "learning_rate": 9.160029767088368e-06,
      "loss": 0.1772,
      "step": 5305
    },
    {
      "epoch": 0.08401285684880536,
      "grad_norm": 0.29410460591316223,
      "learning_rate": 9.159871431511947e-06,
      "loss": 0.1028,
      "step": 5306
    },
    {
      "epoch": 0.08402869040644742,
      "grad_norm": 0.22313708066940308,
      "learning_rate": 9.159713095935526e-06,
      "loss": 0.0587,
      "step": 5307
    },
    {
      "epoch": 0.08404452396408948,
      "grad_norm": 0.5171745419502258,
      "learning_rate": 9.159554760359107e-06,
      "loss": 0.0038,
      "step": 5308
    },
    {
      "epoch": 0.08406035752173156,
      "grad_norm": 0.3293599784374237,
      "learning_rate": 9.159396424782684e-06,
      "loss": 0.0236,
      "step": 5309
    },
    {
      "epoch": 0.08407619107937363,
      "grad_norm": 0.4618490934371948,
      "learning_rate": 9.159238089206265e-06,
      "loss": 0.2274,
      "step": 5310
    },
    {
      "epoch": 0.08409202463701569,
      "grad_norm": 0.18121495842933655,
      "learning_rate": 9.159079753629844e-06,
      "loss": 0.0407,
      "step": 5311
    },
    {
      "epoch": 0.08410785819465776,
      "grad_norm": 0.00017026982095558196,
      "learning_rate": 9.158921418053423e-06,
      "loss": 0.0,
      "step": 5312
    },
    {
      "epoch": 0.08412369175229982,
      "grad_norm": 0.021689170971512794,
      "learning_rate": 9.158763082477002e-06,
      "loss": 0.0022,
      "step": 5313
    },
    {
      "epoch": 0.08413952530994188,
      "grad_norm": 0.2250269502401352,
      "learning_rate": 9.158604746900583e-06,
      "loss": 0.0934,
      "step": 5314
    },
    {
      "epoch": 0.08415535886758396,
      "grad_norm": 0.5582466125488281,
      "learning_rate": 9.15844641132416e-06,
      "loss": 0.1229,
      "step": 5315
    },
    {
      "epoch": 0.08417119242522603,
      "grad_norm": 0.025844460353255272,
      "learning_rate": 9.158288075747741e-06,
      "loss": 0.0024,
      "step": 5316
    },
    {
      "epoch": 0.08418702598286809,
      "grad_norm": 0.3483882248401642,
      "learning_rate": 9.15812974017132e-06,
      "loss": 0.3446,
      "step": 5317
    },
    {
      "epoch": 0.08420285954051016,
      "grad_norm": 0.05586788058280945,
      "learning_rate": 9.1579714045949e-06,
      "loss": 0.0004,
      "step": 5318
    },
    {
      "epoch": 0.08421869309815222,
      "grad_norm": 0.4070039689540863,
      "learning_rate": 9.157813069018479e-06,
      "loss": 0.5241,
      "step": 5319
    },
    {
      "epoch": 0.08423452665579428,
      "grad_norm": 0.1799144446849823,
      "learning_rate": 9.157654733442058e-06,
      "loss": 0.0886,
      "step": 5320
    },
    {
      "epoch": 0.08425036021343636,
      "grad_norm": 0.00024387903977185488,
      "learning_rate": 9.157496397865637e-06,
      "loss": 0.0,
      "step": 5321
    },
    {
      "epoch": 0.08426619377107843,
      "grad_norm": 0.0039717936888337135,
      "learning_rate": 9.157338062289216e-06,
      "loss": 0.0001,
      "step": 5322
    },
    {
      "epoch": 0.08428202732872049,
      "grad_norm": 0.2325512319803238,
      "learning_rate": 9.157179726712797e-06,
      "loss": 0.1574,
      "step": 5323
    },
    {
      "epoch": 0.08429786088636256,
      "grad_norm": 0.33052000403404236,
      "learning_rate": 9.157021391136374e-06,
      "loss": 0.7453,
      "step": 5324
    },
    {
      "epoch": 0.08431369444400462,
      "grad_norm": 0.19874338805675507,
      "learning_rate": 9.156863055559955e-06,
      "loss": 0.0539,
      "step": 5325
    },
    {
      "epoch": 0.08432952800164668,
      "grad_norm": 0.008694388903677464,
      "learning_rate": 9.156704719983534e-06,
      "loss": 0.0004,
      "step": 5326
    },
    {
      "epoch": 0.08434536155928876,
      "grad_norm": 0.10268086940050125,
      "learning_rate": 9.156546384407113e-06,
      "loss": 0.0534,
      "step": 5327
    },
    {
      "epoch": 0.08436119511693083,
      "grad_norm": 0.21458540856838226,
      "learning_rate": 9.156388048830692e-06,
      "loss": 0.0645,
      "step": 5328
    },
    {
      "epoch": 0.08437702867457289,
      "grad_norm": 0.15630429983139038,
      "learning_rate": 9.156229713254273e-06,
      "loss": 0.058,
      "step": 5329
    },
    {
      "epoch": 0.08439286223221495,
      "grad_norm": 0.022959956899285316,
      "learning_rate": 9.15607137767785e-06,
      "loss": 0.0032,
      "step": 5330
    },
    {
      "epoch": 0.08440869578985702,
      "grad_norm": 0.3986890912055969,
      "learning_rate": 9.155913042101431e-06,
      "loss": 0.2413,
      "step": 5331
    },
    {
      "epoch": 0.08442452934749908,
      "grad_norm": 0.2172234207391739,
      "learning_rate": 9.15575470652501e-06,
      "loss": 0.1927,
      "step": 5332
    },
    {
      "epoch": 0.08444036290514116,
      "grad_norm": 0.2221236377954483,
      "learning_rate": 9.155596370948589e-06,
      "loss": 0.1011,
      "step": 5333
    },
    {
      "epoch": 0.08445619646278323,
      "grad_norm": 0.2855198085308075,
      "learning_rate": 9.155438035372168e-06,
      "loss": 0.0588,
      "step": 5334
    },
    {
      "epoch": 0.08447203002042529,
      "grad_norm": 0.009706063196063042,
      "learning_rate": 9.155279699795749e-06,
      "loss": 0.0005,
      "step": 5335
    },
    {
      "epoch": 0.08448786357806735,
      "grad_norm": 0.04274873062968254,
      "learning_rate": 9.155121364219326e-06,
      "loss": 0.0006,
      "step": 5336
    },
    {
      "epoch": 0.08450369713570942,
      "grad_norm": 0.5858988165855408,
      "learning_rate": 9.154963028642907e-06,
      "loss": 0.0618,
      "step": 5337
    },
    {
      "epoch": 0.08451953069335148,
      "grad_norm": 0.6258258819580078,
      "learning_rate": 9.154804693066486e-06,
      "loss": 0.2145,
      "step": 5338
    },
    {
      "epoch": 0.08453536425099356,
      "grad_norm": 0.005582010373473167,
      "learning_rate": 9.154646357490065e-06,
      "loss": 0.0004,
      "step": 5339
    },
    {
      "epoch": 0.08455119780863563,
      "grad_norm": 0.20070885121822357,
      "learning_rate": 9.154488021913644e-06,
      "loss": 0.0459,
      "step": 5340
    },
    {
      "epoch": 0.08456703136627769,
      "grad_norm": 0.2921510934829712,
      "learning_rate": 9.154329686337225e-06,
      "loss": 0.163,
      "step": 5341
    },
    {
      "epoch": 0.08458286492391975,
      "grad_norm": 0.14010462164878845,
      "learning_rate": 9.154171350760802e-06,
      "loss": 0.069,
      "step": 5342
    },
    {
      "epoch": 0.08459869848156182,
      "grad_norm": 0.023936759680509567,
      "learning_rate": 9.154013015184382e-06,
      "loss": 0.0009,
      "step": 5343
    },
    {
      "epoch": 0.08461453203920388,
      "grad_norm": 0.8831839561462402,
      "learning_rate": 9.153854679607962e-06,
      "loss": 0.7995,
      "step": 5344
    },
    {
      "epoch": 0.08463036559684596,
      "grad_norm": 0.24313031136989594,
      "learning_rate": 9.153696344031541e-06,
      "loss": 0.1871,
      "step": 5345
    },
    {
      "epoch": 0.08464619915448802,
      "grad_norm": 0.44186878204345703,
      "learning_rate": 9.15353800845512e-06,
      "loss": 0.0892,
      "step": 5346
    },
    {
      "epoch": 0.08466203271213009,
      "grad_norm": 0.0024686045944690704,
      "learning_rate": 9.1533796728787e-06,
      "loss": 0.0001,
      "step": 5347
    },
    {
      "epoch": 0.08467786626977215,
      "grad_norm": 0.0009840650018304586,
      "learning_rate": 9.153221337302279e-06,
      "loss": 0.0001,
      "step": 5348
    },
    {
      "epoch": 0.08469369982741422,
      "grad_norm": 0.024584714323282242,
      "learning_rate": 9.153063001725858e-06,
      "loss": 0.0011,
      "step": 5349
    },
    {
      "epoch": 0.08470953338505628,
      "grad_norm": 0.17357255518436432,
      "learning_rate": 9.152904666149438e-06,
      "loss": 0.0326,
      "step": 5350
    },
    {
      "epoch": 0.08472536694269836,
      "grad_norm": 0.2428651601076126,
      "learning_rate": 9.152746330573018e-06,
      "loss": 0.1446,
      "step": 5351
    },
    {
      "epoch": 0.08474120050034042,
      "grad_norm": 0.00015224066737573594,
      "learning_rate": 9.152587994996597e-06,
      "loss": 0.0,
      "step": 5352
    },
    {
      "epoch": 0.08475703405798249,
      "grad_norm": 0.1343529224395752,
      "learning_rate": 9.152429659420176e-06,
      "loss": 0.0681,
      "step": 5353
    },
    {
      "epoch": 0.08477286761562455,
      "grad_norm": 0.1864895522594452,
      "learning_rate": 9.152271323843755e-06,
      "loss": 0.0609,
      "step": 5354
    },
    {
      "epoch": 0.08478870117326662,
      "grad_norm": 0.26176485419273376,
      "learning_rate": 9.152112988267334e-06,
      "loss": 0.1449,
      "step": 5355
    },
    {
      "epoch": 0.08480453473090868,
      "grad_norm": 0.45053988695144653,
      "learning_rate": 9.151954652690915e-06,
      "loss": 0.3721,
      "step": 5356
    },
    {
      "epoch": 0.08482036828855076,
      "grad_norm": 0.24305832386016846,
      "learning_rate": 9.151796317114494e-06,
      "loss": 0.1304,
      "step": 5357
    },
    {
      "epoch": 0.08483620184619282,
      "grad_norm": 0.6043103933334351,
      "learning_rate": 9.151637981538073e-06,
      "loss": 0.2951,
      "step": 5358
    },
    {
      "epoch": 0.08485203540383489,
      "grad_norm": 0.3165460228919983,
      "learning_rate": 9.151479645961652e-06,
      "loss": 0.4736,
      "step": 5359
    },
    {
      "epoch": 0.08486786896147695,
      "grad_norm": 0.0008851454476825893,
      "learning_rate": 9.151321310385231e-06,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 0.08488370251911902,
      "grad_norm": 0.24659106135368347,
      "learning_rate": 9.15116297480881e-06,
      "loss": 0.1408,
      "step": 5361
    },
    {
      "epoch": 0.08489953607676108,
      "grad_norm": 0.3684181869029999,
      "learning_rate": 9.15100463923239e-06,
      "loss": 0.3368,
      "step": 5362
    },
    {
      "epoch": 0.08491536963440316,
      "grad_norm": 0.3548656404018402,
      "learning_rate": 9.15084630365597e-06,
      "loss": 0.1346,
      "step": 5363
    },
    {
      "epoch": 0.08493120319204522,
      "grad_norm": 0.18075565993785858,
      "learning_rate": 9.150687968079549e-06,
      "loss": 0.0974,
      "step": 5364
    },
    {
      "epoch": 0.08494703674968729,
      "grad_norm": 0.23321202397346497,
      "learning_rate": 9.150529632503128e-06,
      "loss": 0.0445,
      "step": 5365
    },
    {
      "epoch": 0.08496287030732935,
      "grad_norm": 0.2826474905014038,
      "learning_rate": 9.150371296926707e-06,
      "loss": 0.0475,
      "step": 5366
    },
    {
      "epoch": 0.08497870386497142,
      "grad_norm": 0.4033825993537903,
      "learning_rate": 9.150212961350286e-06,
      "loss": 0.1894,
      "step": 5367
    },
    {
      "epoch": 0.08499453742261348,
      "grad_norm": 0.24535030126571655,
      "learning_rate": 9.150054625773865e-06,
      "loss": 0.1119,
      "step": 5368
    },
    {
      "epoch": 0.08501037098025556,
      "grad_norm": 0.01988108642399311,
      "learning_rate": 9.149896290197446e-06,
      "loss": 0.001,
      "step": 5369
    },
    {
      "epoch": 0.08502620453789762,
      "grad_norm": 0.05584939941763878,
      "learning_rate": 9.149737954621023e-06,
      "loss": 0.0008,
      "step": 5370
    },
    {
      "epoch": 0.08504203809553969,
      "grad_norm": 0.005313345231115818,
      "learning_rate": 9.149579619044604e-06,
      "loss": 0.0002,
      "step": 5371
    },
    {
      "epoch": 0.08505787165318175,
      "grad_norm": 0.055955588817596436,
      "learning_rate": 9.149421283468183e-06,
      "loss": 0.0024,
      "step": 5372
    },
    {
      "epoch": 0.08507370521082382,
      "grad_norm": 0.2843658924102783,
      "learning_rate": 9.149262947891762e-06,
      "loss": 0.0469,
      "step": 5373
    },
    {
      "epoch": 0.08508953876846588,
      "grad_norm": 0.000454524444648996,
      "learning_rate": 9.149104612315341e-06,
      "loss": 0.0,
      "step": 5374
    },
    {
      "epoch": 0.08510537232610796,
      "grad_norm": 0.416973352432251,
      "learning_rate": 9.148946276738922e-06,
      "loss": 0.1805,
      "step": 5375
    },
    {
      "epoch": 0.08512120588375002,
      "grad_norm": 0.2535545825958252,
      "learning_rate": 9.1487879411625e-06,
      "loss": 0.1611,
      "step": 5376
    },
    {
      "epoch": 0.08513703944139209,
      "grad_norm": 0.2832801043987274,
      "learning_rate": 9.14862960558608e-06,
      "loss": 0.1561,
      "step": 5377
    },
    {
      "epoch": 0.08515287299903415,
      "grad_norm": 0.21483725309371948,
      "learning_rate": 9.14847127000966e-06,
      "loss": 0.1436,
      "step": 5378
    },
    {
      "epoch": 0.08516870655667622,
      "grad_norm": 9.566013613948599e-05,
      "learning_rate": 9.148312934433239e-06,
      "loss": 0.0,
      "step": 5379
    },
    {
      "epoch": 0.08518454011431828,
      "grad_norm": 0.02298087067902088,
      "learning_rate": 9.148154598856818e-06,
      "loss": 0.001,
      "step": 5380
    },
    {
      "epoch": 0.08520037367196036,
      "grad_norm": 0.003846314735710621,
      "learning_rate": 9.147996263280398e-06,
      "loss": 0.0002,
      "step": 5381
    },
    {
      "epoch": 0.08521620722960242,
      "grad_norm": 0.01047348789870739,
      "learning_rate": 9.147837927703976e-06,
      "loss": 0.0001,
      "step": 5382
    },
    {
      "epoch": 0.08523204078724449,
      "grad_norm": 0.3895280063152313,
      "learning_rate": 9.147679592127557e-06,
      "loss": 0.0768,
      "step": 5383
    },
    {
      "epoch": 0.08524787434488655,
      "grad_norm": 1.1051948070526123,
      "learning_rate": 9.147521256551136e-06,
      "loss": 0.0464,
      "step": 5384
    },
    {
      "epoch": 0.08526370790252862,
      "grad_norm": 0.2301746904850006,
      "learning_rate": 9.147362920974715e-06,
      "loss": 0.1288,
      "step": 5385
    },
    {
      "epoch": 0.08527954146017068,
      "grad_norm": 0.0036897012032568455,
      "learning_rate": 9.147204585398294e-06,
      "loss": 0.0001,
      "step": 5386
    },
    {
      "epoch": 0.08529537501781276,
      "grad_norm": 0.04092645272612572,
      "learning_rate": 9.147046249821873e-06,
      "loss": 0.0026,
      "step": 5387
    },
    {
      "epoch": 0.08531120857545482,
      "grad_norm": 0.2009081393480301,
      "learning_rate": 9.146887914245452e-06,
      "loss": 0.0946,
      "step": 5388
    },
    {
      "epoch": 0.08532704213309689,
      "grad_norm": 0.4240402579307556,
      "learning_rate": 9.146729578669033e-06,
      "loss": 0.0823,
      "step": 5389
    },
    {
      "epoch": 0.08534287569073895,
      "grad_norm": 0.04351115599274635,
      "learning_rate": 9.146571243092612e-06,
      "loss": 0.0039,
      "step": 5390
    },
    {
      "epoch": 0.08535870924838102,
      "grad_norm": 0.46755293011665344,
      "learning_rate": 9.14641290751619e-06,
      "loss": 0.1259,
      "step": 5391
    },
    {
      "epoch": 0.08537454280602308,
      "grad_norm": 0.6990203261375427,
      "learning_rate": 9.14625457193977e-06,
      "loss": 0.1556,
      "step": 5392
    },
    {
      "epoch": 0.08539037636366516,
      "grad_norm": 0.0007946835830807686,
      "learning_rate": 9.146096236363349e-06,
      "loss": 0.0,
      "step": 5393
    },
    {
      "epoch": 0.08540620992130722,
      "grad_norm": 0.2452978491783142,
      "learning_rate": 9.145937900786928e-06,
      "loss": 0.1663,
      "step": 5394
    },
    {
      "epoch": 0.08542204347894929,
      "grad_norm": 0.16939806938171387,
      "learning_rate": 9.145779565210507e-06,
      "loss": 0.0703,
      "step": 5395
    },
    {
      "epoch": 0.08543787703659135,
      "grad_norm": 9.777512605069205e-05,
      "learning_rate": 9.145621229634088e-06,
      "loss": 0.0,
      "step": 5396
    },
    {
      "epoch": 0.08545371059423341,
      "grad_norm": 0.3252071440219879,
      "learning_rate": 9.145462894057665e-06,
      "loss": 0.3809,
      "step": 5397
    },
    {
      "epoch": 0.08546954415187548,
      "grad_norm": 0.2593696415424347,
      "learning_rate": 9.145304558481246e-06,
      "loss": 0.1208,
      "step": 5398
    },
    {
      "epoch": 0.08548537770951756,
      "grad_norm": 0.16556905210018158,
      "learning_rate": 9.145146222904825e-06,
      "loss": 0.0547,
      "step": 5399
    },
    {
      "epoch": 0.08550121126715962,
      "grad_norm": 0.015453020110726357,
      "learning_rate": 9.144987887328404e-06,
      "loss": 0.0006,
      "step": 5400
    },
    {
      "epoch": 0.08551704482480169,
      "grad_norm": 0.15046657621860504,
      "learning_rate": 9.144829551751983e-06,
      "loss": 0.0672,
      "step": 5401
    },
    {
      "epoch": 0.08553287838244375,
      "grad_norm": 0.19118283689022064,
      "learning_rate": 9.144671216175564e-06,
      "loss": 0.0479,
      "step": 5402
    },
    {
      "epoch": 0.08554871194008581,
      "grad_norm": 0.767470121383667,
      "learning_rate": 9.144512880599142e-06,
      "loss": 0.5121,
      "step": 5403
    },
    {
      "epoch": 0.08556454549772788,
      "grad_norm": 0.0001629907637834549,
      "learning_rate": 9.144354545022722e-06,
      "loss": 0.0,
      "step": 5404
    },
    {
      "epoch": 0.08558037905536996,
      "grad_norm": 0.21748730540275574,
      "learning_rate": 9.144196209446301e-06,
      "loss": 0.1074,
      "step": 5405
    },
    {
      "epoch": 0.08559621261301202,
      "grad_norm": 0.25836801528930664,
      "learning_rate": 9.14403787386988e-06,
      "loss": 0.2002,
      "step": 5406
    },
    {
      "epoch": 0.08561204617065409,
      "grad_norm": 0.4176535904407501,
      "learning_rate": 9.14387953829346e-06,
      "loss": 0.8074,
      "step": 5407
    },
    {
      "epoch": 0.08562787972829615,
      "grad_norm": 0.24436399340629578,
      "learning_rate": 9.14372120271704e-06,
      "loss": 0.0274,
      "step": 5408
    },
    {
      "epoch": 0.08564371328593821,
      "grad_norm": 0.1574198454618454,
      "learning_rate": 9.143562867140618e-06,
      "loss": 0.0739,
      "step": 5409
    },
    {
      "epoch": 0.08565954684358028,
      "grad_norm": 0.000452206440968439,
      "learning_rate": 9.143404531564198e-06,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 0.08567538040122236,
      "grad_norm": 0.13618028163909912,
      "learning_rate": 9.143246195987778e-06,
      "loss": 0.0579,
      "step": 5411
    },
    {
      "epoch": 0.08569121395886442,
      "grad_norm": 0.28731483221054077,
      "learning_rate": 9.143087860411357e-06,
      "loss": 0.3058,
      "step": 5412
    },
    {
      "epoch": 0.08570704751650648,
      "grad_norm": 0.38953712582588196,
      "learning_rate": 9.142929524834936e-06,
      "loss": 0.144,
      "step": 5413
    },
    {
      "epoch": 0.08572288107414855,
      "grad_norm": 0.4500477612018585,
      "learning_rate": 9.142771189258515e-06,
      "loss": 0.2853,
      "step": 5414
    },
    {
      "epoch": 0.08573871463179061,
      "grad_norm": 0.0004920520004816353,
      "learning_rate": 9.142612853682094e-06,
      "loss": 0.0,
      "step": 5415
    },
    {
      "epoch": 0.08575454818943268,
      "grad_norm": 0.1249367892742157,
      "learning_rate": 9.142454518105673e-06,
      "loss": 0.064,
      "step": 5416
    },
    {
      "epoch": 0.08577038174707476,
      "grad_norm": 0.04557039961218834,
      "learning_rate": 9.142296182529254e-06,
      "loss": 0.0023,
      "step": 5417
    },
    {
      "epoch": 0.08578621530471682,
      "grad_norm": 0.33333057165145874,
      "learning_rate": 9.142137846952833e-06,
      "loss": 0.5001,
      "step": 5418
    },
    {
      "epoch": 0.08580204886235888,
      "grad_norm": 0.07257454842329025,
      "learning_rate": 9.141979511376412e-06,
      "loss": 0.0021,
      "step": 5419
    },
    {
      "epoch": 0.08581788242000095,
      "grad_norm": 0.350558876991272,
      "learning_rate": 9.141821175799991e-06,
      "loss": 0.1254,
      "step": 5420
    },
    {
      "epoch": 0.08583371597764301,
      "grad_norm": 0.4523274302482605,
      "learning_rate": 9.14166284022357e-06,
      "loss": 0.0729,
      "step": 5421
    },
    {
      "epoch": 0.08584954953528508,
      "grad_norm": 0.38860806822776794,
      "learning_rate": 9.141504504647149e-06,
      "loss": 0.0763,
      "step": 5422
    },
    {
      "epoch": 0.08586538309292716,
      "grad_norm": 0.2846994698047638,
      "learning_rate": 9.14134616907073e-06,
      "loss": 0.1646,
      "step": 5423
    },
    {
      "epoch": 0.08588121665056922,
      "grad_norm": 0.049148302525281906,
      "learning_rate": 9.141187833494309e-06,
      "loss": 0.0018,
      "step": 5424
    },
    {
      "epoch": 0.08589705020821128,
      "grad_norm": 0.27904364466667175,
      "learning_rate": 9.141029497917888e-06,
      "loss": 0.1525,
      "step": 5425
    },
    {
      "epoch": 0.08591288376585335,
      "grad_norm": 0.0010843969648703933,
      "learning_rate": 9.140871162341467e-06,
      "loss": 0.0,
      "step": 5426
    },
    {
      "epoch": 0.08592871732349541,
      "grad_norm": 0.3324815332889557,
      "learning_rate": 9.140712826765046e-06,
      "loss": 0.0099,
      "step": 5427
    },
    {
      "epoch": 0.08594455088113748,
      "grad_norm": 0.012686377391219139,
      "learning_rate": 9.140554491188625e-06,
      "loss": 0.0005,
      "step": 5428
    },
    {
      "epoch": 0.08596038443877956,
      "grad_norm": 0.3539709746837616,
      "learning_rate": 9.140396155612206e-06,
      "loss": 0.0507,
      "step": 5429
    },
    {
      "epoch": 0.08597621799642162,
      "grad_norm": 6.255557673284784e-05,
      "learning_rate": 9.140237820035785e-06,
      "loss": 0.0,
      "step": 5430
    },
    {
      "epoch": 0.08599205155406368,
      "grad_norm": 0.23132029175758362,
      "learning_rate": 9.140079484459364e-06,
      "loss": 0.2582,
      "step": 5431
    },
    {
      "epoch": 0.08600788511170575,
      "grad_norm": 0.03576325252652168,
      "learning_rate": 9.139921148882943e-06,
      "loss": 0.0019,
      "step": 5432
    },
    {
      "epoch": 0.08602371866934781,
      "grad_norm": 0.20912058651447296,
      "learning_rate": 9.139762813306522e-06,
      "loss": 0.1421,
      "step": 5433
    },
    {
      "epoch": 0.08603955222698988,
      "grad_norm": 0.6359484195709229,
      "learning_rate": 9.139604477730101e-06,
      "loss": 0.1713,
      "step": 5434
    },
    {
      "epoch": 0.08605538578463195,
      "grad_norm": 0.21101780235767365,
      "learning_rate": 9.139446142153682e-06,
      "loss": 0.1085,
      "step": 5435
    },
    {
      "epoch": 0.08607121934227402,
      "grad_norm": 0.24936780333518982,
      "learning_rate": 9.139287806577261e-06,
      "loss": 0.0904,
      "step": 5436
    },
    {
      "epoch": 0.08608705289991608,
      "grad_norm": 0.019740838557481766,
      "learning_rate": 9.13912947100084e-06,
      "loss": 0.0011,
      "step": 5437
    },
    {
      "epoch": 0.08610288645755815,
      "grad_norm": 0.35614752769470215,
      "learning_rate": 9.13897113542442e-06,
      "loss": 0.0602,
      "step": 5438
    },
    {
      "epoch": 0.08611872001520021,
      "grad_norm": 3.4259079257026315e-05,
      "learning_rate": 9.138812799847999e-06,
      "loss": 0.0,
      "step": 5439
    },
    {
      "epoch": 0.08613455357284228,
      "grad_norm": 0.02707376889884472,
      "learning_rate": 9.138654464271578e-06,
      "loss": 0.0011,
      "step": 5440
    },
    {
      "epoch": 0.08615038713048435,
      "grad_norm": 0.3368019163608551,
      "learning_rate": 9.138496128695157e-06,
      "loss": 0.3742,
      "step": 5441
    },
    {
      "epoch": 0.08616622068812642,
      "grad_norm": 0.22631971538066864,
      "learning_rate": 9.138337793118738e-06,
      "loss": 0.1111,
      "step": 5442
    },
    {
      "epoch": 0.08618205424576848,
      "grad_norm": 0.2886805236339569,
      "learning_rate": 9.138179457542315e-06,
      "loss": 0.1619,
      "step": 5443
    },
    {
      "epoch": 0.08619788780341055,
      "grad_norm": 0.2775610685348511,
      "learning_rate": 9.138021121965896e-06,
      "loss": 0.2486,
      "step": 5444
    },
    {
      "epoch": 0.08621372136105261,
      "grad_norm": 0.3293134570121765,
      "learning_rate": 9.137862786389475e-06,
      "loss": 0.1103,
      "step": 5445
    },
    {
      "epoch": 0.08622955491869468,
      "grad_norm": 0.31824442744255066,
      "learning_rate": 9.137704450813054e-06,
      "loss": 0.0236,
      "step": 5446
    },
    {
      "epoch": 0.08624538847633675,
      "grad_norm": 0.4046071469783783,
      "learning_rate": 9.137546115236633e-06,
      "loss": 0.0563,
      "step": 5447
    },
    {
      "epoch": 0.08626122203397882,
      "grad_norm": 0.3537955582141876,
      "learning_rate": 9.137387779660214e-06,
      "loss": 0.0826,
      "step": 5448
    },
    {
      "epoch": 0.08627705559162088,
      "grad_norm": 0.1825101524591446,
      "learning_rate": 9.137229444083791e-06,
      "loss": 0.0581,
      "step": 5449
    },
    {
      "epoch": 0.08629288914926295,
      "grad_norm": 0.308033287525177,
      "learning_rate": 9.137071108507372e-06,
      "loss": 0.0791,
      "step": 5450
    },
    {
      "epoch": 0.08630872270690501,
      "grad_norm": 0.38147035241127014,
      "learning_rate": 9.136912772930951e-06,
      "loss": 0.1711,
      "step": 5451
    },
    {
      "epoch": 0.08632455626454708,
      "grad_norm": 0.18476836383342743,
      "learning_rate": 9.13675443735453e-06,
      "loss": 0.0543,
      "step": 5452
    },
    {
      "epoch": 0.08634038982218915,
      "grad_norm": 0.19536103308200836,
      "learning_rate": 9.136596101778109e-06,
      "loss": 0.1144,
      "step": 5453
    },
    {
      "epoch": 0.08635622337983122,
      "grad_norm": 2.484938383102417,
      "learning_rate": 9.136437766201688e-06,
      "loss": 0.2836,
      "step": 5454
    },
    {
      "epoch": 0.08637205693747328,
      "grad_norm": 0.0097257811576128,
      "learning_rate": 9.136279430625267e-06,
      "loss": 0.0005,
      "step": 5455
    },
    {
      "epoch": 0.08638789049511535,
      "grad_norm": 0.00014989067858550698,
      "learning_rate": 9.136121095048848e-06,
      "loss": 0.0,
      "step": 5456
    },
    {
      "epoch": 0.08640372405275741,
      "grad_norm": 0.4042203426361084,
      "learning_rate": 9.135962759472427e-06,
      "loss": 0.04,
      "step": 5457
    },
    {
      "epoch": 0.08641955761039948,
      "grad_norm": 0.5480037927627563,
      "learning_rate": 9.135804423896006e-06,
      "loss": 0.5984,
      "step": 5458
    },
    {
      "epoch": 0.08643539116804155,
      "grad_norm": 0.0029167651664465666,
      "learning_rate": 9.135646088319585e-06,
      "loss": 0.0002,
      "step": 5459
    },
    {
      "epoch": 0.08645122472568362,
      "grad_norm": 4.4370157411322e-05,
      "learning_rate": 9.135487752743164e-06,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 0.08646705828332568,
      "grad_norm": 0.00017136185488197953,
      "learning_rate": 9.135329417166743e-06,
      "loss": 0.0,
      "step": 5461
    },
    {
      "epoch": 0.08648289184096775,
      "grad_norm": 0.19598866999149323,
      "learning_rate": 9.135171081590322e-06,
      "loss": 0.2477,
      "step": 5462
    },
    {
      "epoch": 0.08649872539860981,
      "grad_norm": 0.003871303051710129,
      "learning_rate": 9.135012746013903e-06,
      "loss": 0.0002,
      "step": 5463
    },
    {
      "epoch": 0.08651455895625187,
      "grad_norm": 0.23502713441848755,
      "learning_rate": 9.13485441043748e-06,
      "loss": 0.1517,
      "step": 5464
    },
    {
      "epoch": 0.08653039251389395,
      "grad_norm": 0.24185383319854736,
      "learning_rate": 9.134696074861061e-06,
      "loss": 0.1271,
      "step": 5465
    },
    {
      "epoch": 0.08654622607153602,
      "grad_norm": 0.35547569394111633,
      "learning_rate": 9.13453773928464e-06,
      "loss": 0.1022,
      "step": 5466
    },
    {
      "epoch": 0.08656205962917808,
      "grad_norm": 0.38678380846977234,
      "learning_rate": 9.13437940370822e-06,
      "loss": 0.1107,
      "step": 5467
    },
    {
      "epoch": 0.08657789318682015,
      "grad_norm": 0.23957553505897522,
      "learning_rate": 9.134221068131799e-06,
      "loss": 0.0862,
      "step": 5468
    },
    {
      "epoch": 0.08659372674446221,
      "grad_norm": 0.3867385685443878,
      "learning_rate": 9.13406273255538e-06,
      "loss": 0.3883,
      "step": 5469
    },
    {
      "epoch": 0.08660956030210427,
      "grad_norm": 0.00189046876039356,
      "learning_rate": 9.133904396978957e-06,
      "loss": 0.0001,
      "step": 5470
    },
    {
      "epoch": 0.08662539385974635,
      "grad_norm": 0.614645779132843,
      "learning_rate": 9.133746061402538e-06,
      "loss": 0.1961,
      "step": 5471
    },
    {
      "epoch": 0.08664122741738842,
      "grad_norm": 0.3552679717540741,
      "learning_rate": 9.133587725826117e-06,
      "loss": 0.2265,
      "step": 5472
    },
    {
      "epoch": 0.08665706097503048,
      "grad_norm": 0.32258883118629456,
      "learning_rate": 9.133429390249696e-06,
      "loss": 0.1451,
      "step": 5473
    },
    {
      "epoch": 0.08667289453267255,
      "grad_norm": 0.003045748919248581,
      "learning_rate": 9.133271054673275e-06,
      "loss": 0.0001,
      "step": 5474
    },
    {
      "epoch": 0.08668872809031461,
      "grad_norm": 0.0002256243024021387,
      "learning_rate": 9.133112719096856e-06,
      "loss": 0.0,
      "step": 5475
    },
    {
      "epoch": 0.08670456164795667,
      "grad_norm": 0.7529743909835815,
      "learning_rate": 9.132954383520433e-06,
      "loss": 0.2694,
      "step": 5476
    },
    {
      "epoch": 0.08672039520559875,
      "grad_norm": 0.15447954833507538,
      "learning_rate": 9.132796047944014e-06,
      "loss": 0.0699,
      "step": 5477
    },
    {
      "epoch": 0.08673622876324082,
      "grad_norm": 0.3240836560726166,
      "learning_rate": 9.132637712367593e-06,
      "loss": 0.05,
      "step": 5478
    },
    {
      "epoch": 0.08675206232088288,
      "grad_norm": 0.2764265537261963,
      "learning_rate": 9.132479376791172e-06,
      "loss": 0.0927,
      "step": 5479
    },
    {
      "epoch": 0.08676789587852494,
      "grad_norm": 0.4084721505641937,
      "learning_rate": 9.132321041214751e-06,
      "loss": 0.0798,
      "step": 5480
    },
    {
      "epoch": 0.08678372943616701,
      "grad_norm": 0.00010687723261071369,
      "learning_rate": 9.132162705638332e-06,
      "loss": 0.0,
      "step": 5481
    },
    {
      "epoch": 0.08679956299380907,
      "grad_norm": 5.451144897961058e-05,
      "learning_rate": 9.13200437006191e-06,
      "loss": 0.0,
      "step": 5482
    },
    {
      "epoch": 0.08681539655145115,
      "grad_norm": 7.554690819233656e-05,
      "learning_rate": 9.13184603448549e-06,
      "loss": 0.0,
      "step": 5483
    },
    {
      "epoch": 0.08683123010909322,
      "grad_norm": 0.1587599813938141,
      "learning_rate": 9.131687698909069e-06,
      "loss": 0.0708,
      "step": 5484
    },
    {
      "epoch": 0.08684706366673528,
      "grad_norm": 0.22498692572116852,
      "learning_rate": 9.131529363332648e-06,
      "loss": 0.1327,
      "step": 5485
    },
    {
      "epoch": 0.08686289722437734,
      "grad_norm": 0.30727171897888184,
      "learning_rate": 9.131371027756227e-06,
      "loss": 0.0679,
      "step": 5486
    },
    {
      "epoch": 0.08687873078201941,
      "grad_norm": 0.008053160272538662,
      "learning_rate": 9.131212692179806e-06,
      "loss": 0.0004,
      "step": 5487
    },
    {
      "epoch": 0.08689456433966147,
      "grad_norm": 0.5434385538101196,
      "learning_rate": 9.131054356603385e-06,
      "loss": 0.2557,
      "step": 5488
    },
    {
      "epoch": 0.08691039789730355,
      "grad_norm": 0.6192545890808105,
      "learning_rate": 9.130896021026964e-06,
      "loss": 0.7719,
      "step": 5489
    },
    {
      "epoch": 0.08692623145494562,
      "grad_norm": 0.5282269716262817,
      "learning_rate": 9.130737685450545e-06,
      "loss": 0.1517,
      "step": 5490
    },
    {
      "epoch": 0.08694206501258768,
      "grad_norm": 0.3934730887413025,
      "learning_rate": 9.130579349874124e-06,
      "loss": 0.5027,
      "step": 5491
    },
    {
      "epoch": 0.08695789857022974,
      "grad_norm": 0.012455025687813759,
      "learning_rate": 9.130421014297703e-06,
      "loss": 0.0007,
      "step": 5492
    },
    {
      "epoch": 0.08697373212787181,
      "grad_norm": 0.26546451449394226,
      "learning_rate": 9.130262678721282e-06,
      "loss": 0.5553,
      "step": 5493
    },
    {
      "epoch": 0.08698956568551387,
      "grad_norm": 0.0003256367635913193,
      "learning_rate": 9.130104343144862e-06,
      "loss": 0.0,
      "step": 5494
    },
    {
      "epoch": 0.08700539924315595,
      "grad_norm": 0.2277737408876419,
      "learning_rate": 9.12994600756844e-06,
      "loss": 0.1238,
      "step": 5495
    },
    {
      "epoch": 0.08702123280079802,
      "grad_norm": 0.13839544355869293,
      "learning_rate": 9.129787671992021e-06,
      "loss": 0.0531,
      "step": 5496
    },
    {
      "epoch": 0.08703706635844008,
      "grad_norm": 0.4473657011985779,
      "learning_rate": 9.1296293364156e-06,
      "loss": 0.2581,
      "step": 5497
    },
    {
      "epoch": 0.08705289991608214,
      "grad_norm": 0.20695270597934723,
      "learning_rate": 9.12947100083918e-06,
      "loss": 0.1193,
      "step": 5498
    },
    {
      "epoch": 0.08706873347372421,
      "grad_norm": 0.23509517312049866,
      "learning_rate": 9.129312665262759e-06,
      "loss": 0.1125,
      "step": 5499
    },
    {
      "epoch": 0.08708456703136627,
      "grad_norm": 0.9346280097961426,
      "learning_rate": 9.129154329686338e-06,
      "loss": 1.0362,
      "step": 5500
    },
    {
      "epoch": 0.08710040058900835,
      "grad_norm": 2.7491724491119385,
      "learning_rate": 9.128995994109917e-06,
      "loss": 0.4801,
      "step": 5501
    },
    {
      "epoch": 0.08711623414665041,
      "grad_norm": 0.26073339581489563,
      "learning_rate": 9.128837658533498e-06,
      "loss": 0.3718,
      "step": 5502
    },
    {
      "epoch": 0.08713206770429248,
      "grad_norm": 0.010898633860051632,
      "learning_rate": 9.128679322957077e-06,
      "loss": 0.0006,
      "step": 5503
    },
    {
      "epoch": 0.08714790126193454,
      "grad_norm": 0.3504226803779602,
      "learning_rate": 9.128520987380656e-06,
      "loss": 0.3551,
      "step": 5504
    },
    {
      "epoch": 0.08716373481957661,
      "grad_norm": 0.33155709505081177,
      "learning_rate": 9.128362651804235e-06,
      "loss": 0.4729,
      "step": 5505
    },
    {
      "epoch": 0.08717956837721867,
      "grad_norm": 0.24062445759773254,
      "learning_rate": 9.128204316227814e-06,
      "loss": 0.1863,
      "step": 5506
    },
    {
      "epoch": 0.08719540193486075,
      "grad_norm": 0.04550374671816826,
      "learning_rate": 9.128045980651393e-06,
      "loss": 0.003,
      "step": 5507
    },
    {
      "epoch": 0.08721123549250281,
      "grad_norm": 0.0029655734542757273,
      "learning_rate": 9.127887645074974e-06,
      "loss": 0.0001,
      "step": 5508
    },
    {
      "epoch": 0.08722706905014488,
      "grad_norm": 0.4209648370742798,
      "learning_rate": 9.127729309498553e-06,
      "loss": 0.0931,
      "step": 5509
    },
    {
      "epoch": 0.08724290260778694,
      "grad_norm": 0.5611530542373657,
      "learning_rate": 9.12757097392213e-06,
      "loss": 0.0359,
      "step": 5510
    },
    {
      "epoch": 0.08725873616542901,
      "grad_norm": 0.005133769009262323,
      "learning_rate": 9.127412638345711e-06,
      "loss": 0.0002,
      "step": 5511
    },
    {
      "epoch": 0.08727456972307107,
      "grad_norm": 0.0007096377667039633,
      "learning_rate": 9.12725430276929e-06,
      "loss": 0.0,
      "step": 5512
    },
    {
      "epoch": 0.08729040328071315,
      "grad_norm": 0.28093430399894714,
      "learning_rate": 9.127095967192869e-06,
      "loss": 0.1734,
      "step": 5513
    },
    {
      "epoch": 0.08730623683835521,
      "grad_norm": 0.16616204380989075,
      "learning_rate": 9.126937631616448e-06,
      "loss": 0.0408,
      "step": 5514
    },
    {
      "epoch": 0.08732207039599728,
      "grad_norm": 0.35114791989326477,
      "learning_rate": 9.126779296040027e-06,
      "loss": 0.0724,
      "step": 5515
    },
    {
      "epoch": 0.08733790395363934,
      "grad_norm": 0.016929131001234055,
      "learning_rate": 9.126620960463606e-06,
      "loss": 0.0008,
      "step": 5516
    },
    {
      "epoch": 0.0873537375112814,
      "grad_norm": 0.1544640213251114,
      "learning_rate": 9.126462624887187e-06,
      "loss": 0.0633,
      "step": 5517
    },
    {
      "epoch": 0.08736957106892347,
      "grad_norm": 0.20086687803268433,
      "learning_rate": 9.126304289310766e-06,
      "loss": 0.1147,
      "step": 5518
    },
    {
      "epoch": 0.08738540462656555,
      "grad_norm": 0.437750905752182,
      "learning_rate": 9.126145953734345e-06,
      "loss": 0.4404,
      "step": 5519
    },
    {
      "epoch": 0.08740123818420761,
      "grad_norm": 0.4227297008037567,
      "learning_rate": 9.125987618157924e-06,
      "loss": 0.0905,
      "step": 5520
    },
    {
      "epoch": 0.08741707174184968,
      "grad_norm": 0.29025906324386597,
      "learning_rate": 9.125829282581503e-06,
      "loss": 0.1175,
      "step": 5521
    },
    {
      "epoch": 0.08743290529949174,
      "grad_norm": 0.3002965748310089,
      "learning_rate": 9.125670947005083e-06,
      "loss": 0.0793,
      "step": 5522
    },
    {
      "epoch": 0.0874487388571338,
      "grad_norm": 0.5666307210922241,
      "learning_rate": 9.125512611428663e-06,
      "loss": 0.0505,
      "step": 5523
    },
    {
      "epoch": 0.08746457241477587,
      "grad_norm": 0.40868011116981506,
      "learning_rate": 9.125354275852242e-06,
      "loss": 2.0742,
      "step": 5524
    },
    {
      "epoch": 0.08748040597241795,
      "grad_norm": 0.13282032310962677,
      "learning_rate": 9.125195940275821e-06,
      "loss": 0.0541,
      "step": 5525
    },
    {
      "epoch": 0.08749623953006001,
      "grad_norm": 0.40528741478919983,
      "learning_rate": 9.1250376046994e-06,
      "loss": 0.1139,
      "step": 5526
    },
    {
      "epoch": 0.08751207308770208,
      "grad_norm": 0.2453279048204422,
      "learning_rate": 9.12487926912298e-06,
      "loss": 0.1284,
      "step": 5527
    },
    {
      "epoch": 0.08752790664534414,
      "grad_norm": 0.034293804317712784,
      "learning_rate": 9.124720933546559e-06,
      "loss": 0.0024,
      "step": 5528
    },
    {
      "epoch": 0.0875437402029862,
      "grad_norm": 0.005648362450301647,
      "learning_rate": 9.12456259797014e-06,
      "loss": 0.0002,
      "step": 5529
    },
    {
      "epoch": 0.08755957376062827,
      "grad_norm": 0.37312790751457214,
      "learning_rate": 9.124404262393719e-06,
      "loss": 0.2087,
      "step": 5530
    },
    {
      "epoch": 0.08757540731827035,
      "grad_norm": 0.0021534522529691458,
      "learning_rate": 9.124245926817298e-06,
      "loss": 0.0001,
      "step": 5531
    },
    {
      "epoch": 0.08759124087591241,
      "grad_norm": 0.016696514561772346,
      "learning_rate": 9.124087591240877e-06,
      "loss": 0.0009,
      "step": 5532
    },
    {
      "epoch": 0.08760707443355448,
      "grad_norm": 0.1436855047941208,
      "learning_rate": 9.123929255664456e-06,
      "loss": 0.0596,
      "step": 5533
    },
    {
      "epoch": 0.08762290799119654,
      "grad_norm": 0.32146427035331726,
      "learning_rate": 9.123770920088035e-06,
      "loss": 0.1311,
      "step": 5534
    },
    {
      "epoch": 0.0876387415488386,
      "grad_norm": 0.4542737603187561,
      "learning_rate": 9.123612584511614e-06,
      "loss": 0.7362,
      "step": 5535
    },
    {
      "epoch": 0.08765457510648067,
      "grad_norm": 0.6909570693969727,
      "learning_rate": 9.123454248935195e-06,
      "loss": 0.4632,
      "step": 5536
    },
    {
      "epoch": 0.08767040866412275,
      "grad_norm": 0.00015180990158114582,
      "learning_rate": 9.123295913358772e-06,
      "loss": 0.0,
      "step": 5537
    },
    {
      "epoch": 0.08768624222176481,
      "grad_norm": 0.14986473321914673,
      "learning_rate": 9.123137577782353e-06,
      "loss": 0.0589,
      "step": 5538
    },
    {
      "epoch": 0.08770207577940688,
      "grad_norm": 0.5830324292182922,
      "learning_rate": 9.122979242205932e-06,
      "loss": 0.0656,
      "step": 5539
    },
    {
      "epoch": 0.08771790933704894,
      "grad_norm": 0.35870450735092163,
      "learning_rate": 9.122820906629511e-06,
      "loss": 0.2042,
      "step": 5540
    },
    {
      "epoch": 0.087733742894691,
      "grad_norm": 0.613903820514679,
      "learning_rate": 9.12266257105309e-06,
      "loss": 0.4361,
      "step": 5541
    },
    {
      "epoch": 0.08774957645233307,
      "grad_norm": 0.019684284925460815,
      "learning_rate": 9.122504235476671e-06,
      "loss": 0.0006,
      "step": 5542
    },
    {
      "epoch": 0.08776541000997515,
      "grad_norm": 0.2465372383594513,
      "learning_rate": 9.122345899900248e-06,
      "loss": 0.1866,
      "step": 5543
    },
    {
      "epoch": 0.08778124356761721,
      "grad_norm": 0.9202368855476379,
      "learning_rate": 9.122187564323829e-06,
      "loss": 0.1583,
      "step": 5544
    },
    {
      "epoch": 0.08779707712525928,
      "grad_norm": 0.03074272722005844,
      "learning_rate": 9.122029228747408e-06,
      "loss": 0.0013,
      "step": 5545
    },
    {
      "epoch": 0.08781291068290134,
      "grad_norm": 0.07968200743198395,
      "learning_rate": 9.121870893170987e-06,
      "loss": 0.0106,
      "step": 5546
    },
    {
      "epoch": 0.0878287442405434,
      "grad_norm": 0.002193273277953267,
      "learning_rate": 9.121712557594566e-06,
      "loss": 0.0,
      "step": 5547
    },
    {
      "epoch": 0.08784457779818547,
      "grad_norm": 0.26738762855529785,
      "learning_rate": 9.121554222018147e-06,
      "loss": 0.1742,
      "step": 5548
    },
    {
      "epoch": 0.08786041135582755,
      "grad_norm": 0.04311013221740723,
      "learning_rate": 9.121395886441724e-06,
      "loss": 0.0066,
      "step": 5549
    },
    {
      "epoch": 0.08787624491346961,
      "grad_norm": 0.7720202207565308,
      "learning_rate": 9.121237550865305e-06,
      "loss": 0.2313,
      "step": 5550
    },
    {
      "epoch": 0.08789207847111168,
      "grad_norm": 0.0012532839318737388,
      "learning_rate": 9.121079215288884e-06,
      "loss": 0.0,
      "step": 5551
    },
    {
      "epoch": 0.08790791202875374,
      "grad_norm": 0.32757943868637085,
      "learning_rate": 9.120920879712463e-06,
      "loss": 0.1909,
      "step": 5552
    },
    {
      "epoch": 0.0879237455863958,
      "grad_norm": 0.3143359422683716,
      "learning_rate": 9.120762544136042e-06,
      "loss": 0.1131,
      "step": 5553
    },
    {
      "epoch": 0.08793957914403787,
      "grad_norm": 0.0001502253144280985,
      "learning_rate": 9.120604208559623e-06,
      "loss": 0.0,
      "step": 5554
    },
    {
      "epoch": 0.08795541270167995,
      "grad_norm": 0.02736288495361805,
      "learning_rate": 9.1204458729832e-06,
      "loss": 0.0015,
      "step": 5555
    },
    {
      "epoch": 0.08797124625932201,
      "grad_norm": 0.01205176580697298,
      "learning_rate": 9.120287537406781e-06,
      "loss": 0.0006,
      "step": 5556
    },
    {
      "epoch": 0.08798707981696408,
      "grad_norm": 0.21454563736915588,
      "learning_rate": 9.12012920183036e-06,
      "loss": 0.15,
      "step": 5557
    },
    {
      "epoch": 0.08800291337460614,
      "grad_norm": 0.3153746724128723,
      "learning_rate": 9.11997086625394e-06,
      "loss": 0.0678,
      "step": 5558
    },
    {
      "epoch": 0.0880187469322482,
      "grad_norm": 0.28716787695884705,
      "learning_rate": 9.119812530677519e-06,
      "loss": 0.7596,
      "step": 5559
    },
    {
      "epoch": 0.08803458048989027,
      "grad_norm": 0.16376993060112,
      "learning_rate": 9.119654195101098e-06,
      "loss": 0.1322,
      "step": 5560
    },
    {
      "epoch": 0.08805041404753235,
      "grad_norm": 0.46997901797294617,
      "learning_rate": 9.119495859524677e-06,
      "loss": 0.1407,
      "step": 5561
    },
    {
      "epoch": 0.08806624760517441,
      "grad_norm": 0.3564887046813965,
      "learning_rate": 9.119337523948256e-06,
      "loss": 0.3029,
      "step": 5562
    },
    {
      "epoch": 0.08808208116281648,
      "grad_norm": 0.025954455137252808,
      "learning_rate": 9.119179188371837e-06,
      "loss": 0.0007,
      "step": 5563
    },
    {
      "epoch": 0.08809791472045854,
      "grad_norm": 0.00019478198373690248,
      "learning_rate": 9.119020852795416e-06,
      "loss": 0.0,
      "step": 5564
    },
    {
      "epoch": 0.0881137482781006,
      "grad_norm": 0.21861596405506134,
      "learning_rate": 9.118862517218995e-06,
      "loss": 0.0912,
      "step": 5565
    },
    {
      "epoch": 0.08812958183574267,
      "grad_norm": 0.15989841520786285,
      "learning_rate": 9.118704181642574e-06,
      "loss": 0.0833,
      "step": 5566
    },
    {
      "epoch": 0.08814541539338475,
      "grad_norm": 0.009698265232145786,
      "learning_rate": 9.118545846066153e-06,
      "loss": 0.0003,
      "step": 5567
    },
    {
      "epoch": 0.08816124895102681,
      "grad_norm": 0.17193937301635742,
      "learning_rate": 9.118387510489732e-06,
      "loss": 0.0297,
      "step": 5568
    },
    {
      "epoch": 0.08817708250866887,
      "grad_norm": 0.003699801629409194,
      "learning_rate": 9.118229174913313e-06,
      "loss": 0.0001,
      "step": 5569
    },
    {
      "epoch": 0.08819291606631094,
      "grad_norm": 0.20203591883182526,
      "learning_rate": 9.118070839336892e-06,
      "loss": 0.0919,
      "step": 5570
    },
    {
      "epoch": 0.088208749623953,
      "grad_norm": 0.2622535228729248,
      "learning_rate": 9.117912503760471e-06,
      "loss": 0.1653,
      "step": 5571
    },
    {
      "epoch": 0.08822458318159507,
      "grad_norm": 1.075243353843689,
      "learning_rate": 9.11775416818405e-06,
      "loss": 0.1535,
      "step": 5572
    },
    {
      "epoch": 0.08824041673923715,
      "grad_norm": 0.43173089623451233,
      "learning_rate": 9.117595832607629e-06,
      "loss": 1.0402,
      "step": 5573
    },
    {
      "epoch": 0.08825625029687921,
      "grad_norm": 0.11064528673887253,
      "learning_rate": 9.117437497031208e-06,
      "loss": 0.0069,
      "step": 5574
    },
    {
      "epoch": 0.08827208385452127,
      "grad_norm": 0.3975319266319275,
      "learning_rate": 9.117279161454789e-06,
      "loss": 0.1551,
      "step": 5575
    },
    {
      "epoch": 0.08828791741216334,
      "grad_norm": 0.3570253849029541,
      "learning_rate": 9.117120825878368e-06,
      "loss": 0.5509,
      "step": 5576
    },
    {
      "epoch": 0.0883037509698054,
      "grad_norm": 0.39449718594551086,
      "learning_rate": 9.116962490301947e-06,
      "loss": 0.3764,
      "step": 5577
    },
    {
      "epoch": 0.08831958452744747,
      "grad_norm": 0.3051920235157013,
      "learning_rate": 9.116804154725526e-06,
      "loss": 0.4344,
      "step": 5578
    },
    {
      "epoch": 0.08833541808508955,
      "grad_norm": 0.3046642243862152,
      "learning_rate": 9.116645819149105e-06,
      "loss": 0.2133,
      "step": 5579
    },
    {
      "epoch": 0.08835125164273161,
      "grad_norm": 0.02036581002175808,
      "learning_rate": 9.116487483572684e-06,
      "loss": 0.0011,
      "step": 5580
    },
    {
      "epoch": 0.08836708520037367,
      "grad_norm": 0.1759779006242752,
      "learning_rate": 9.116329147996265e-06,
      "loss": 0.0438,
      "step": 5581
    },
    {
      "epoch": 0.08838291875801574,
      "grad_norm": 0.33016708493232727,
      "learning_rate": 9.116170812419843e-06,
      "loss": 0.1808,
      "step": 5582
    },
    {
      "epoch": 0.0883987523156578,
      "grad_norm": 0.6298999190330505,
      "learning_rate": 9.116012476843422e-06,
      "loss": 0.4045,
      "step": 5583
    },
    {
      "epoch": 0.08841458587329987,
      "grad_norm": 0.19955995678901672,
      "learning_rate": 9.115854141267002e-06,
      "loss": 0.1603,
      "step": 5584
    },
    {
      "epoch": 0.08843041943094195,
      "grad_norm": 0.22401297092437744,
      "learning_rate": 9.115695805690581e-06,
      "loss": 0.1753,
      "step": 5585
    },
    {
      "epoch": 0.08844625298858401,
      "grad_norm": 0.11686310172080994,
      "learning_rate": 9.11553747011416e-06,
      "loss": 0.1117,
      "step": 5586
    },
    {
      "epoch": 0.08846208654622607,
      "grad_norm": 0.03880731388926506,
      "learning_rate": 9.11537913453774e-06,
      "loss": 0.0022,
      "step": 5587
    },
    {
      "epoch": 0.08847792010386814,
      "grad_norm": 0.4069405794143677,
      "learning_rate": 9.115220798961319e-06,
      "loss": 0.1702,
      "step": 5588
    },
    {
      "epoch": 0.0884937536615102,
      "grad_norm": 0.18607617914676666,
      "learning_rate": 9.115062463384898e-06,
      "loss": 0.1609,
      "step": 5589
    },
    {
      "epoch": 0.08850958721915227,
      "grad_norm": 0.41741737723350525,
      "learning_rate": 9.114904127808479e-06,
      "loss": 0.5347,
      "step": 5590
    },
    {
      "epoch": 0.08852542077679434,
      "grad_norm": 0.013313126750290394,
      "learning_rate": 9.114745792232058e-06,
      "loss": 0.0008,
      "step": 5591
    },
    {
      "epoch": 0.08854125433443641,
      "grad_norm": 0.49094218015670776,
      "learning_rate": 9.114587456655637e-06,
      "loss": 0.0718,
      "step": 5592
    },
    {
      "epoch": 0.08855708789207847,
      "grad_norm": 0.5306506156921387,
      "learning_rate": 9.114429121079216e-06,
      "loss": 0.1922,
      "step": 5593
    },
    {
      "epoch": 0.08857292144972054,
      "grad_norm": 0.38541892170906067,
      "learning_rate": 9.114270785502795e-06,
      "loss": 0.3073,
      "step": 5594
    },
    {
      "epoch": 0.0885887550073626,
      "grad_norm": 0.1745900958776474,
      "learning_rate": 9.114112449926374e-06,
      "loss": 0.0745,
      "step": 5595
    },
    {
      "epoch": 0.08860458856500467,
      "grad_norm": 0.437310129404068,
      "learning_rate": 9.113954114349955e-06,
      "loss": 0.2161,
      "step": 5596
    },
    {
      "epoch": 0.08862042212264674,
      "grad_norm": 0.06725147366523743,
      "learning_rate": 9.113795778773534e-06,
      "loss": 0.0011,
      "step": 5597
    },
    {
      "epoch": 0.08863625568028881,
      "grad_norm": 3.2746778742875904e-05,
      "learning_rate": 9.113637443197113e-06,
      "loss": 0.0,
      "step": 5598
    },
    {
      "epoch": 0.08865208923793087,
      "grad_norm": 0.05106212571263313,
      "learning_rate": 9.113479107620692e-06,
      "loss": 0.005,
      "step": 5599
    },
    {
      "epoch": 0.08866792279557294,
      "grad_norm": 1.7942719459533691,
      "learning_rate": 9.113320772044271e-06,
      "loss": 0.2264,
      "step": 5600
    },
    {
      "epoch": 0.088683756353215,
      "grad_norm": 0.04653019458055496,
      "learning_rate": 9.11316243646785e-06,
      "loss": 0.0034,
      "step": 5601
    },
    {
      "epoch": 0.08869958991085707,
      "grad_norm": 0.028302744030952454,
      "learning_rate": 9.113004100891431e-06,
      "loss": 0.0013,
      "step": 5602
    },
    {
      "epoch": 0.08871542346849914,
      "grad_norm": 0.48178282380104065,
      "learning_rate": 9.11284576531501e-06,
      "loss": 0.3288,
      "step": 5603
    },
    {
      "epoch": 0.08873125702614121,
      "grad_norm": 0.19602154195308685,
      "learning_rate": 9.112687429738589e-06,
      "loss": 0.0027,
      "step": 5604
    },
    {
      "epoch": 0.08874709058378327,
      "grad_norm": 0.2340545952320099,
      "learning_rate": 9.112529094162168e-06,
      "loss": 0.1176,
      "step": 5605
    },
    {
      "epoch": 0.08876292414142534,
      "grad_norm": 0.0001768414513207972,
      "learning_rate": 9.112370758585747e-06,
      "loss": 0.0,
      "step": 5606
    },
    {
      "epoch": 0.0887787576990674,
      "grad_norm": 0.07241503149271011,
      "learning_rate": 9.112212423009326e-06,
      "loss": 0.0163,
      "step": 5607
    },
    {
      "epoch": 0.08879459125670947,
      "grad_norm": 0.11258896440267563,
      "learning_rate": 9.112054087432905e-06,
      "loss": 0.0238,
      "step": 5608
    },
    {
      "epoch": 0.08881042481435154,
      "grad_norm": 0.6578502058982849,
      "learning_rate": 9.111895751856486e-06,
      "loss": 0.4998,
      "step": 5609
    },
    {
      "epoch": 0.08882625837199361,
      "grad_norm": 0.5099201202392578,
      "learning_rate": 9.111737416280064e-06,
      "loss": 0.3302,
      "step": 5610
    },
    {
      "epoch": 0.08884209192963567,
      "grad_norm": 0.4186899960041046,
      "learning_rate": 9.111579080703644e-06,
      "loss": 0.4998,
      "step": 5611
    },
    {
      "epoch": 0.08885792548727774,
      "grad_norm": 0.47664177417755127,
      "learning_rate": 9.111420745127223e-06,
      "loss": 0.2303,
      "step": 5612
    },
    {
      "epoch": 0.0888737590449198,
      "grad_norm": 0.03486936539411545,
      "learning_rate": 9.111262409550802e-06,
      "loss": 0.0023,
      "step": 5613
    },
    {
      "epoch": 0.08888959260256186,
      "grad_norm": 0.03221843019127846,
      "learning_rate": 9.111104073974382e-06,
      "loss": 0.0018,
      "step": 5614
    },
    {
      "epoch": 0.08890542616020394,
      "grad_norm": 0.15238521993160248,
      "learning_rate": 9.110945738397962e-06,
      "loss": 0.0733,
      "step": 5615
    },
    {
      "epoch": 0.08892125971784601,
      "grad_norm": 0.2697770297527313,
      "learning_rate": 9.11078740282154e-06,
      "loss": 0.1222,
      "step": 5616
    },
    {
      "epoch": 0.08893709327548807,
      "grad_norm": 0.19655488431453705,
      "learning_rate": 9.11062906724512e-06,
      "loss": 0.0751,
      "step": 5617
    },
    {
      "epoch": 0.08895292683313014,
      "grad_norm": 0.25383707880973816,
      "learning_rate": 9.1104707316687e-06,
      "loss": 0.2579,
      "step": 5618
    },
    {
      "epoch": 0.0889687603907722,
      "grad_norm": 0.17493392527103424,
      "learning_rate": 9.110312396092279e-06,
      "loss": 0.067,
      "step": 5619
    },
    {
      "epoch": 0.08898459394841426,
      "grad_norm": 0.46576419472694397,
      "learning_rate": 9.110154060515858e-06,
      "loss": 0.1923,
      "step": 5620
    },
    {
      "epoch": 0.08900042750605634,
      "grad_norm": 0.20281389355659485,
      "learning_rate": 9.109995724939438e-06,
      "loss": 0.0907,
      "step": 5621
    },
    {
      "epoch": 0.08901626106369841,
      "grad_norm": 0.19773617386817932,
      "learning_rate": 9.109837389363016e-06,
      "loss": 0.0437,
      "step": 5622
    },
    {
      "epoch": 0.08903209462134047,
      "grad_norm": 0.052334193140268326,
      "learning_rate": 9.109679053786597e-06,
      "loss": 0.0032,
      "step": 5623
    },
    {
      "epoch": 0.08904792817898254,
      "grad_norm": 0.1632828712463379,
      "learning_rate": 9.109520718210176e-06,
      "loss": 0.0574,
      "step": 5624
    },
    {
      "epoch": 0.0890637617366246,
      "grad_norm": 0.11702457815408707,
      "learning_rate": 9.109362382633755e-06,
      "loss": 0.051,
      "step": 5625
    },
    {
      "epoch": 0.08907959529426666,
      "grad_norm": 0.35498014092445374,
      "learning_rate": 9.109204047057334e-06,
      "loss": 0.1449,
      "step": 5626
    },
    {
      "epoch": 0.08909542885190874,
      "grad_norm": 0.04848852753639221,
      "learning_rate": 9.109045711480915e-06,
      "loss": 0.002,
      "step": 5627
    },
    {
      "epoch": 0.0891112624095508,
      "grad_norm": 0.7049124836921692,
      "learning_rate": 9.108887375904492e-06,
      "loss": 0.4922,
      "step": 5628
    },
    {
      "epoch": 0.08912709596719287,
      "grad_norm": 0.19566912949085236,
      "learning_rate": 9.108729040328073e-06,
      "loss": 0.0719,
      "step": 5629
    },
    {
      "epoch": 0.08914292952483494,
      "grad_norm": 0.14385242760181427,
      "learning_rate": 9.108570704751652e-06,
      "loss": 0.0409,
      "step": 5630
    },
    {
      "epoch": 0.089158763082477,
      "grad_norm": 0.14691492915153503,
      "learning_rate": 9.108412369175231e-06,
      "loss": 0.0773,
      "step": 5631
    },
    {
      "epoch": 0.08917459664011906,
      "grad_norm": 0.21374385058879852,
      "learning_rate": 9.10825403359881e-06,
      "loss": 0.3471,
      "step": 5632
    },
    {
      "epoch": 0.08919043019776113,
      "grad_norm": 0.21439413726329803,
      "learning_rate": 9.108095698022389e-06,
      "loss": 0.1632,
      "step": 5633
    },
    {
      "epoch": 0.0892062637554032,
      "grad_norm": 2.8486077785491943,
      "learning_rate": 9.107937362445968e-06,
      "loss": 0.0888,
      "step": 5634
    },
    {
      "epoch": 0.08922209731304527,
      "grad_norm": 0.07086006551980972,
      "learning_rate": 9.107779026869547e-06,
      "loss": 0.002,
      "step": 5635
    },
    {
      "epoch": 0.08923793087068733,
      "grad_norm": 0.40750938653945923,
      "learning_rate": 9.107620691293128e-06,
      "loss": 0.0612,
      "step": 5636
    },
    {
      "epoch": 0.0892537644283294,
      "grad_norm": 0.278354287147522,
      "learning_rate": 9.107462355716707e-06,
      "loss": 0.0725,
      "step": 5637
    },
    {
      "epoch": 0.08926959798597146,
      "grad_norm": 0.2109740823507309,
      "learning_rate": 9.107304020140286e-06,
      "loss": 0.1812,
      "step": 5638
    },
    {
      "epoch": 0.08928543154361353,
      "grad_norm": 0.1406598836183548,
      "learning_rate": 9.107145684563865e-06,
      "loss": 0.0082,
      "step": 5639
    },
    {
      "epoch": 0.0893012651012556,
      "grad_norm": 0.0005297219031490386,
      "learning_rate": 9.106987348987444e-06,
      "loss": 0.0,
      "step": 5640
    },
    {
      "epoch": 0.08931709865889767,
      "grad_norm": 0.005763145163655281,
      "learning_rate": 9.106829013411023e-06,
      "loss": 0.0002,
      "step": 5641
    },
    {
      "epoch": 0.08933293221653973,
      "grad_norm": 0.24665561318397522,
      "learning_rate": 9.106670677834604e-06,
      "loss": 0.0054,
      "step": 5642
    },
    {
      "epoch": 0.0893487657741818,
      "grad_norm": 0.15701399743556976,
      "learning_rate": 9.106512342258183e-06,
      "loss": 0.0201,
      "step": 5643
    },
    {
      "epoch": 0.08936459933182386,
      "grad_norm": 0.8320066928863525,
      "learning_rate": 9.106354006681762e-06,
      "loss": 0.2726,
      "step": 5644
    },
    {
      "epoch": 0.08938043288946593,
      "grad_norm": 0.29201117157936096,
      "learning_rate": 9.106195671105341e-06,
      "loss": 0.0326,
      "step": 5645
    },
    {
      "epoch": 0.089396266447108,
      "grad_norm": 6.951740942895412e-05,
      "learning_rate": 9.10603733552892e-06,
      "loss": 0.0,
      "step": 5646
    },
    {
      "epoch": 0.08941210000475007,
      "grad_norm": 0.41203147172927856,
      "learning_rate": 9.1058789999525e-06,
      "loss": 0.4166,
      "step": 5647
    },
    {
      "epoch": 0.08942793356239213,
      "grad_norm": 0.22711791098117828,
      "learning_rate": 9.10572066437608e-06,
      "loss": 0.0189,
      "step": 5648
    },
    {
      "epoch": 0.0894437671200342,
      "grad_norm": 0.39252275228500366,
      "learning_rate": 9.105562328799658e-06,
      "loss": 0.2372,
      "step": 5649
    },
    {
      "epoch": 0.08945960067767626,
      "grad_norm": 0.16615872085094452,
      "learning_rate": 9.105403993223239e-06,
      "loss": 0.0032,
      "step": 5650
    },
    {
      "epoch": 0.08947543423531833,
      "grad_norm": 0.20522426068782806,
      "learning_rate": 9.105245657646818e-06,
      "loss": 0.2827,
      "step": 5651
    },
    {
      "epoch": 0.0894912677929604,
      "grad_norm": 0.40409624576568604,
      "learning_rate": 9.105087322070397e-06,
      "loss": 0.1855,
      "step": 5652
    },
    {
      "epoch": 0.08950710135060247,
      "grad_norm": 0.2406604140996933,
      "learning_rate": 9.104928986493976e-06,
      "loss": 0.0582,
      "step": 5653
    },
    {
      "epoch": 0.08952293490824453,
      "grad_norm": 0.3979114294052124,
      "learning_rate": 9.104770650917557e-06,
      "loss": 0.3968,
      "step": 5654
    },
    {
      "epoch": 0.0895387684658866,
      "grad_norm": 0.00044837972382083535,
      "learning_rate": 9.104612315341134e-06,
      "loss": 0.0,
      "step": 5655
    },
    {
      "epoch": 0.08955460202352866,
      "grad_norm": 0.4849660396575928,
      "learning_rate": 9.104453979764713e-06,
      "loss": 0.2149,
      "step": 5656
    },
    {
      "epoch": 0.08957043558117073,
      "grad_norm": 0.4833742380142212,
      "learning_rate": 9.104295644188294e-06,
      "loss": 0.6455,
      "step": 5657
    },
    {
      "epoch": 0.0895862691388128,
      "grad_norm": 0.5252143144607544,
      "learning_rate": 9.104137308611873e-06,
      "loss": 0.6511,
      "step": 5658
    },
    {
      "epoch": 0.08960210269645487,
      "grad_norm": 0.17912444472312927,
      "learning_rate": 9.103978973035452e-06,
      "loss": 0.0587,
      "step": 5659
    },
    {
      "epoch": 0.08961793625409693,
      "grad_norm": 0.48026394844055176,
      "learning_rate": 9.103820637459031e-06,
      "loss": 0.1224,
      "step": 5660
    },
    {
      "epoch": 0.089633769811739,
      "grad_norm": 0.5605505704879761,
      "learning_rate": 9.10366230188261e-06,
      "loss": 0.6114,
      "step": 5661
    },
    {
      "epoch": 0.08964960336938106,
      "grad_norm": 0.3784463703632355,
      "learning_rate": 9.10350396630619e-06,
      "loss": 0.1462,
      "step": 5662
    },
    {
      "epoch": 0.08966543692702313,
      "grad_norm": 0.22817644476890564,
      "learning_rate": 9.10334563072977e-06,
      "loss": 0.049,
      "step": 5663
    },
    {
      "epoch": 0.0896812704846652,
      "grad_norm": 0.0126157496124506,
      "learning_rate": 9.103187295153349e-06,
      "loss": 0.0004,
      "step": 5664
    },
    {
      "epoch": 0.08969710404230727,
      "grad_norm": 0.03187759965658188,
      "learning_rate": 9.103028959576928e-06,
      "loss": 0.0009,
      "step": 5665
    },
    {
      "epoch": 0.08971293759994933,
      "grad_norm": 0.05578775703907013,
      "learning_rate": 9.102870624000507e-06,
      "loss": 0.0018,
      "step": 5666
    },
    {
      "epoch": 0.0897287711575914,
      "grad_norm": 0.6061838865280151,
      "learning_rate": 9.102712288424086e-06,
      "loss": 0.428,
      "step": 5667
    },
    {
      "epoch": 0.08974460471523346,
      "grad_norm": 0.5943474769592285,
      "learning_rate": 9.102553952847665e-06,
      "loss": 0.1131,
      "step": 5668
    },
    {
      "epoch": 0.08976043827287553,
      "grad_norm": 0.3654324412345886,
      "learning_rate": 9.102395617271246e-06,
      "loss": 0.0547,
      "step": 5669
    },
    {
      "epoch": 0.0897762718305176,
      "grad_norm": 0.3171839416027069,
      "learning_rate": 9.102237281694825e-06,
      "loss": 0.4727,
      "step": 5670
    },
    {
      "epoch": 0.08979210538815967,
      "grad_norm": 0.32600855827331543,
      "learning_rate": 9.102078946118404e-06,
      "loss": 0.2024,
      "step": 5671
    },
    {
      "epoch": 0.08980793894580173,
      "grad_norm": 0.40466195344924927,
      "learning_rate": 9.101920610541983e-06,
      "loss": 0.0376,
      "step": 5672
    },
    {
      "epoch": 0.0898237725034438,
      "grad_norm": 0.6711241006851196,
      "learning_rate": 9.101762274965562e-06,
      "loss": 0.0828,
      "step": 5673
    },
    {
      "epoch": 0.08983960606108586,
      "grad_norm": 0.30910757184028625,
      "learning_rate": 9.101603939389142e-06,
      "loss": 0.0566,
      "step": 5674
    },
    {
      "epoch": 0.08985543961872793,
      "grad_norm": 0.7583175897598267,
      "learning_rate": 9.101445603812722e-06,
      "loss": 0.5377,
      "step": 5675
    },
    {
      "epoch": 0.08987127317637,
      "grad_norm": 0.4130851924419403,
      "learning_rate": 9.101287268236301e-06,
      "loss": 0.1298,
      "step": 5676
    },
    {
      "epoch": 0.08988710673401207,
      "grad_norm": 0.02859812043607235,
      "learning_rate": 9.10112893265988e-06,
      "loss": 0.0017,
      "step": 5677
    },
    {
      "epoch": 0.08990294029165413,
      "grad_norm": 0.7179145216941833,
      "learning_rate": 9.10097059708346e-06,
      "loss": 0.2829,
      "step": 5678
    },
    {
      "epoch": 0.0899187738492962,
      "grad_norm": 0.31620320677757263,
      "learning_rate": 9.100812261507039e-06,
      "loss": 0.5399,
      "step": 5679
    },
    {
      "epoch": 0.08993460740693826,
      "grad_norm": 0.022888988256454468,
      "learning_rate": 9.100653925930618e-06,
      "loss": 0.0011,
      "step": 5680
    },
    {
      "epoch": 0.08995044096458032,
      "grad_norm": 0.19608436524868011,
      "learning_rate": 9.100495590354197e-06,
      "loss": 0.086,
      "step": 5681
    },
    {
      "epoch": 0.0899662745222224,
      "grad_norm": 0.335688978433609,
      "learning_rate": 9.100337254777778e-06,
      "loss": 0.0481,
      "step": 5682
    },
    {
      "epoch": 0.08998210807986447,
      "grad_norm": 0.19504296779632568,
      "learning_rate": 9.100178919201355e-06,
      "loss": 0.072,
      "step": 5683
    },
    {
      "epoch": 0.08999794163750653,
      "grad_norm": 0.6935084462165833,
      "learning_rate": 9.100020583624936e-06,
      "loss": 0.76,
      "step": 5684
    },
    {
      "epoch": 0.0900137751951486,
      "grad_norm": 1.067596673965454,
      "learning_rate": 9.099862248048515e-06,
      "loss": 0.4965,
      "step": 5685
    },
    {
      "epoch": 0.09002960875279066,
      "grad_norm": 0.3584855794906616,
      "learning_rate": 9.099703912472094e-06,
      "loss": 0.0551,
      "step": 5686
    },
    {
      "epoch": 0.09004544231043272,
      "grad_norm": 0.003799829864874482,
      "learning_rate": 9.099545576895673e-06,
      "loss": 0.0001,
      "step": 5687
    },
    {
      "epoch": 0.0900612758680748,
      "grad_norm": 0.7218289375305176,
      "learning_rate": 9.099387241319254e-06,
      "loss": 0.3193,
      "step": 5688
    },
    {
      "epoch": 0.09007710942571687,
      "grad_norm": 0.2740188241004944,
      "learning_rate": 9.099228905742831e-06,
      "loss": 0.1207,
      "step": 5689
    },
    {
      "epoch": 0.09009294298335893,
      "grad_norm": 5.756852624472231e-05,
      "learning_rate": 9.099070570166412e-06,
      "loss": 0.0,
      "step": 5690
    },
    {
      "epoch": 0.090108776541001,
      "grad_norm": 0.13854055106639862,
      "learning_rate": 9.098912234589991e-06,
      "loss": 0.0079,
      "step": 5691
    },
    {
      "epoch": 0.09012461009864306,
      "grad_norm": 0.6396028399467468,
      "learning_rate": 9.09875389901357e-06,
      "loss": 0.0539,
      "step": 5692
    },
    {
      "epoch": 0.09014044365628512,
      "grad_norm": 0.7274644374847412,
      "learning_rate": 9.09859556343715e-06,
      "loss": 0.1432,
      "step": 5693
    },
    {
      "epoch": 0.0901562772139272,
      "grad_norm": 0.6753001809120178,
      "learning_rate": 9.09843722786073e-06,
      "loss": 0.2995,
      "step": 5694
    },
    {
      "epoch": 0.09017211077156927,
      "grad_norm": 1.8274213075637817,
      "learning_rate": 9.098278892284307e-06,
      "loss": 0.0242,
      "step": 5695
    },
    {
      "epoch": 0.09018794432921133,
      "grad_norm": 1.632965326309204,
      "learning_rate": 9.098120556707888e-06,
      "loss": 0.7572,
      "step": 5696
    },
    {
      "epoch": 0.0902037778868534,
      "grad_norm": 0.14548765122890472,
      "learning_rate": 9.097962221131467e-06,
      "loss": 0.0465,
      "step": 5697
    },
    {
      "epoch": 0.09021961144449546,
      "grad_norm": 0.38057470321655273,
      "learning_rate": 9.097803885555046e-06,
      "loss": 0.171,
      "step": 5698
    },
    {
      "epoch": 0.09023544500213752,
      "grad_norm": 0.20654551684856415,
      "learning_rate": 9.097645549978625e-06,
      "loss": 0.1021,
      "step": 5699
    },
    {
      "epoch": 0.0902512785597796,
      "grad_norm": 0.026969455182552338,
      "learning_rate": 9.097487214402206e-06,
      "loss": 0.0013,
      "step": 5700
    },
    {
      "epoch": 0.09026711211742167,
      "grad_norm": 0.06986550241708755,
      "learning_rate": 9.097328878825783e-06,
      "loss": 0.004,
      "step": 5701
    },
    {
      "epoch": 0.09028294567506373,
      "grad_norm": 0.015140505507588387,
      "learning_rate": 9.097170543249364e-06,
      "loss": 0.0008,
      "step": 5702
    },
    {
      "epoch": 0.0902987792327058,
      "grad_norm": 0.5821849703788757,
      "learning_rate": 9.097012207672943e-06,
      "loss": 0.0929,
      "step": 5703
    },
    {
      "epoch": 0.09031461279034786,
      "grad_norm": 0.34286266565322876,
      "learning_rate": 9.096853872096522e-06,
      "loss": 0.0712,
      "step": 5704
    },
    {
      "epoch": 0.09033044634798992,
      "grad_norm": 0.42788487672805786,
      "learning_rate": 9.096695536520102e-06,
      "loss": 0.1915,
      "step": 5705
    },
    {
      "epoch": 0.090346279905632,
      "grad_norm": 0.22031255066394806,
      "learning_rate": 9.09653720094368e-06,
      "loss": 0.077,
      "step": 5706
    },
    {
      "epoch": 0.09036211346327407,
      "grad_norm": 0.598578155040741,
      "learning_rate": 9.09637886536726e-06,
      "loss": 0.2419,
      "step": 5707
    },
    {
      "epoch": 0.09037794702091613,
      "grad_norm": 0.6947870254516602,
      "learning_rate": 9.096220529790839e-06,
      "loss": 0.078,
      "step": 5708
    },
    {
      "epoch": 0.0903937805785582,
      "grad_norm": 0.38748982548713684,
      "learning_rate": 9.09606219421442e-06,
      "loss": 0.1749,
      "step": 5709
    },
    {
      "epoch": 0.09040961413620026,
      "grad_norm": 0.30884283781051636,
      "learning_rate": 9.095903858637997e-06,
      "loss": 0.0602,
      "step": 5710
    },
    {
      "epoch": 0.09042544769384232,
      "grad_norm": 0.11411137133836746,
      "learning_rate": 9.095745523061578e-06,
      "loss": 0.0026,
      "step": 5711
    },
    {
      "epoch": 0.0904412812514844,
      "grad_norm": 0.3061297833919525,
      "learning_rate": 9.095587187485157e-06,
      "loss": 0.4091,
      "step": 5712
    },
    {
      "epoch": 0.09045711480912647,
      "grad_norm": 0.000308550224872306,
      "learning_rate": 9.095428851908736e-06,
      "loss": 0.0,
      "step": 5713
    },
    {
      "epoch": 0.09047294836676853,
      "grad_norm": 0.4294414222240448,
      "learning_rate": 9.095270516332315e-06,
      "loss": 0.0999,
      "step": 5714
    },
    {
      "epoch": 0.0904887819244106,
      "grad_norm": 0.0381331741809845,
      "learning_rate": 9.095112180755896e-06,
      "loss": 0.002,
      "step": 5715
    },
    {
      "epoch": 0.09050461548205266,
      "grad_norm": 0.20066650211811066,
      "learning_rate": 9.094953845179473e-06,
      "loss": 0.0938,
      "step": 5716
    },
    {
      "epoch": 0.09052044903969472,
      "grad_norm": 0.6066994667053223,
      "learning_rate": 9.094795509603054e-06,
      "loss": 0.1528,
      "step": 5717
    },
    {
      "epoch": 0.0905362825973368,
      "grad_norm": 0.01254079770296812,
      "learning_rate": 9.094637174026633e-06,
      "loss": 0.0007,
      "step": 5718
    },
    {
      "epoch": 0.09055211615497887,
      "grad_norm": 0.3523259460926056,
      "learning_rate": 9.094478838450212e-06,
      "loss": 0.7043,
      "step": 5719
    },
    {
      "epoch": 0.09056794971262093,
      "grad_norm": 0.4872118830680847,
      "learning_rate": 9.094320502873791e-06,
      "loss": 0.1251,
      "step": 5720
    },
    {
      "epoch": 0.090583783270263,
      "grad_norm": 0.2652900218963623,
      "learning_rate": 9.094162167297372e-06,
      "loss": 0.1314,
      "step": 5721
    },
    {
      "epoch": 0.09059961682790506,
      "grad_norm": 0.21948079764842987,
      "learning_rate": 9.09400383172095e-06,
      "loss": 0.0836,
      "step": 5722
    },
    {
      "epoch": 0.09061545038554712,
      "grad_norm": 0.4132666289806366,
      "learning_rate": 9.09384549614453e-06,
      "loss": 0.1109,
      "step": 5723
    },
    {
      "epoch": 0.0906312839431892,
      "grad_norm": 0.26451125741004944,
      "learning_rate": 9.093687160568109e-06,
      "loss": 0.1335,
      "step": 5724
    },
    {
      "epoch": 0.09064711750083126,
      "grad_norm": 0.0004639483813662082,
      "learning_rate": 9.093528824991688e-06,
      "loss": 0.0,
      "step": 5725
    },
    {
      "epoch": 0.09066295105847333,
      "grad_norm": 0.24323174357414246,
      "learning_rate": 9.093370489415267e-06,
      "loss": 0.1213,
      "step": 5726
    },
    {
      "epoch": 0.0906787846161154,
      "grad_norm": 0.03833441063761711,
      "learning_rate": 9.093212153838846e-06,
      "loss": 0.0025,
      "step": 5727
    },
    {
      "epoch": 0.09069461817375746,
      "grad_norm": 0.442392498254776,
      "learning_rate": 9.093053818262425e-06,
      "loss": 0.2737,
      "step": 5728
    },
    {
      "epoch": 0.09071045173139952,
      "grad_norm": 0.20398610830307007,
      "learning_rate": 9.092895482686004e-06,
      "loss": 0.0761,
      "step": 5729
    },
    {
      "epoch": 0.0907262852890416,
      "grad_norm": 0.2068149745464325,
      "learning_rate": 9.092737147109585e-06,
      "loss": 0.0054,
      "step": 5730
    },
    {
      "epoch": 0.09074211884668366,
      "grad_norm": 0.2290963977575302,
      "learning_rate": 9.092578811533164e-06,
      "loss": 0.0759,
      "step": 5731
    },
    {
      "epoch": 0.09075795240432573,
      "grad_norm": 0.6007131338119507,
      "learning_rate": 9.092420475956743e-06,
      "loss": 0.6457,
      "step": 5732
    },
    {
      "epoch": 0.09077378596196779,
      "grad_norm": 0.2389889359474182,
      "learning_rate": 9.092262140380323e-06,
      "loss": 0.0311,
      "step": 5733
    },
    {
      "epoch": 0.09078961951960986,
      "grad_norm": 0.44880568981170654,
      "learning_rate": 9.092103804803902e-06,
      "loss": 0.1029,
      "step": 5734
    },
    {
      "epoch": 0.09080545307725192,
      "grad_norm": 0.00013012901763431728,
      "learning_rate": 9.09194546922748e-06,
      "loss": 0.0,
      "step": 5735
    },
    {
      "epoch": 0.090821286634894,
      "grad_norm": 0.03099021688103676,
      "learning_rate": 9.091787133651061e-06,
      "loss": 0.0016,
      "step": 5736
    },
    {
      "epoch": 0.09083712019253606,
      "grad_norm": 0.3285142183303833,
      "learning_rate": 9.09162879807464e-06,
      "loss": 0.2428,
      "step": 5737
    },
    {
      "epoch": 0.09085295375017813,
      "grad_norm": 0.7437935471534729,
      "learning_rate": 9.09147046249822e-06,
      "loss": 0.2858,
      "step": 5738
    },
    {
      "epoch": 0.09086878730782019,
      "grad_norm": 0.09568680077791214,
      "learning_rate": 9.091312126921799e-06,
      "loss": 0.0032,
      "step": 5739
    },
    {
      "epoch": 0.09088462086546226,
      "grad_norm": 0.31204453110694885,
      "learning_rate": 9.091153791345378e-06,
      "loss": 0.4376,
      "step": 5740
    },
    {
      "epoch": 0.09090045442310432,
      "grad_norm": 0.1779465675354004,
      "learning_rate": 9.090995455768957e-06,
      "loss": 0.0274,
      "step": 5741
    },
    {
      "epoch": 0.0909162879807464,
      "grad_norm": 0.02886422723531723,
      "learning_rate": 9.090837120192538e-06,
      "loss": 0.0018,
      "step": 5742
    },
    {
      "epoch": 0.09093212153838846,
      "grad_norm": 0.18495765328407288,
      "learning_rate": 9.090678784616117e-06,
      "loss": 0.1198,
      "step": 5743
    },
    {
      "epoch": 0.09094795509603053,
      "grad_norm": 0.0232506413012743,
      "learning_rate": 9.090520449039696e-06,
      "loss": 0.0011,
      "step": 5744
    },
    {
      "epoch": 0.09096378865367259,
      "grad_norm": 0.07447954267263412,
      "learning_rate": 9.090362113463275e-06,
      "loss": 0.004,
      "step": 5745
    },
    {
      "epoch": 0.09097962221131466,
      "grad_norm": 0.3942655026912689,
      "learning_rate": 9.090203777886854e-06,
      "loss": 0.0698,
      "step": 5746
    },
    {
      "epoch": 0.09099545576895672,
      "grad_norm": 0.00022737917606718838,
      "learning_rate": 9.090045442310433e-06,
      "loss": 0.0,
      "step": 5747
    },
    {
      "epoch": 0.0910112893265988,
      "grad_norm": 0.2504061758518219,
      "learning_rate": 9.089887106734014e-06,
      "loss": 0.0726,
      "step": 5748
    },
    {
      "epoch": 0.09102712288424086,
      "grad_norm": 0.29181110858917236,
      "learning_rate": 9.089728771157593e-06,
      "loss": 0.1328,
      "step": 5749
    },
    {
      "epoch": 0.09104295644188293,
      "grad_norm": 0.14084021747112274,
      "learning_rate": 9.089570435581172e-06,
      "loss": 0.0685,
      "step": 5750
    },
    {
      "epoch": 0.09105878999952499,
      "grad_norm": 0.14724208414554596,
      "learning_rate": 9.089412100004751e-06,
      "loss": 0.0576,
      "step": 5751
    },
    {
      "epoch": 0.09107462355716706,
      "grad_norm": 0.5300858020782471,
      "learning_rate": 9.08925376442833e-06,
      "loss": 0.243,
      "step": 5752
    },
    {
      "epoch": 0.09109045711480912,
      "grad_norm": 0.35308733582496643,
      "learning_rate": 9.08909542885191e-06,
      "loss": 0.1532,
      "step": 5753
    },
    {
      "epoch": 0.0911062906724512,
      "grad_norm": 0.04648188501596451,
      "learning_rate": 9.088937093275488e-06,
      "loss": 0.003,
      "step": 5754
    },
    {
      "epoch": 0.09112212423009326,
      "grad_norm": 0.010416976176202297,
      "learning_rate": 9.088778757699069e-06,
      "loss": 0.0006,
      "step": 5755
    },
    {
      "epoch": 0.09113795778773533,
      "grad_norm": 0.0650307759642601,
      "learning_rate": 9.088620422122646e-06,
      "loss": 0.004,
      "step": 5756
    },
    {
      "epoch": 0.09115379134537739,
      "grad_norm": 0.0794135183095932,
      "learning_rate": 9.088462086546227e-06,
      "loss": 0.0023,
      "step": 5757
    },
    {
      "epoch": 0.09116962490301946,
      "grad_norm": 0.0008400598890148103,
      "learning_rate": 9.088303750969806e-06,
      "loss": 0.0,
      "step": 5758
    },
    {
      "epoch": 0.09118545846066152,
      "grad_norm": 0.01852574199438095,
      "learning_rate": 9.088145415393385e-06,
      "loss": 0.0012,
      "step": 5759
    },
    {
      "epoch": 0.0912012920183036,
      "grad_norm": 0.00020597994443960488,
      "learning_rate": 9.087987079816964e-06,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 0.09121712557594566,
      "grad_norm": 0.5501928329467773,
      "learning_rate": 9.087828744240545e-06,
      "loss": 0.1625,
      "step": 5761
    },
    {
      "epoch": 0.09123295913358773,
      "grad_norm": 0.8005174398422241,
      "learning_rate": 9.087670408664123e-06,
      "loss": 0.1413,
      "step": 5762
    },
    {
      "epoch": 0.09124879269122979,
      "grad_norm": 0.3125816583633423,
      "learning_rate": 9.087512073087703e-06,
      "loss": 0.1063,
      "step": 5763
    },
    {
      "epoch": 0.09126462624887186,
      "grad_norm": 0.15327009558677673,
      "learning_rate": 9.087353737511282e-06,
      "loss": 0.0757,
      "step": 5764
    },
    {
      "epoch": 0.09128045980651392,
      "grad_norm": 0.061875153332948685,
      "learning_rate": 9.087195401934862e-06,
      "loss": 0.0046,
      "step": 5765
    },
    {
      "epoch": 0.091296293364156,
      "grad_norm": 0.087650828063488,
      "learning_rate": 9.08703706635844e-06,
      "loss": 0.0041,
      "step": 5766
    },
    {
      "epoch": 0.09131212692179806,
      "grad_norm": 0.3698630928993225,
      "learning_rate": 9.086878730782021e-06,
      "loss": 0.1083,
      "step": 5767
    },
    {
      "epoch": 0.09132796047944013,
      "grad_norm": 0.025434672832489014,
      "learning_rate": 9.086720395205599e-06,
      "loss": 0.0015,
      "step": 5768
    },
    {
      "epoch": 0.09134379403708219,
      "grad_norm": 0.4147333800792694,
      "learning_rate": 9.08656205962918e-06,
      "loss": 0.3207,
      "step": 5769
    },
    {
      "epoch": 0.09135962759472425,
      "grad_norm": 0.0033899859990924597,
      "learning_rate": 9.086403724052759e-06,
      "loss": 0.0001,
      "step": 5770
    },
    {
      "epoch": 0.09137546115236632,
      "grad_norm": 0.2612074911594391,
      "learning_rate": 9.086245388476338e-06,
      "loss": 0.0881,
      "step": 5771
    },
    {
      "epoch": 0.0913912947100084,
      "grad_norm": 0.026464015245437622,
      "learning_rate": 9.086087052899917e-06,
      "loss": 0.0014,
      "step": 5772
    },
    {
      "epoch": 0.09140712826765046,
      "grad_norm": 0.024513602256774902,
      "learning_rate": 9.085928717323496e-06,
      "loss": 0.0012,
      "step": 5773
    },
    {
      "epoch": 0.09142296182529253,
      "grad_norm": 0.2271909862756729,
      "learning_rate": 9.085770381747075e-06,
      "loss": 0.1994,
      "step": 5774
    },
    {
      "epoch": 0.09143879538293459,
      "grad_norm": 0.3073270320892334,
      "learning_rate": 9.085612046170654e-06,
      "loss": 0.1668,
      "step": 5775
    },
    {
      "epoch": 0.09145462894057665,
      "grad_norm": 0.350655734539032,
      "learning_rate": 9.085453710594235e-06,
      "loss": 0.6534,
      "step": 5776
    },
    {
      "epoch": 0.09147046249821872,
      "grad_norm": 0.00027562706964090466,
      "learning_rate": 9.085295375017812e-06,
      "loss": 0.0,
      "step": 5777
    },
    {
      "epoch": 0.0914862960558608,
      "grad_norm": 0.2861775755882263,
      "learning_rate": 9.085137039441393e-06,
      "loss": 0.0923,
      "step": 5778
    },
    {
      "epoch": 0.09150212961350286,
      "grad_norm": 0.32059937715530396,
      "learning_rate": 9.084978703864972e-06,
      "loss": 0.1863,
      "step": 5779
    },
    {
      "epoch": 0.09151796317114493,
      "grad_norm": 0.32655492424964905,
      "learning_rate": 9.084820368288551e-06,
      "loss": 0.1071,
      "step": 5780
    },
    {
      "epoch": 0.09153379672878699,
      "grad_norm": 0.3350878059864044,
      "learning_rate": 9.08466203271213e-06,
      "loss": 0.0996,
      "step": 5781
    },
    {
      "epoch": 0.09154963028642905,
      "grad_norm": 0.29400256276130676,
      "learning_rate": 9.084503697135711e-06,
      "loss": 0.0516,
      "step": 5782
    },
    {
      "epoch": 0.09156546384407112,
      "grad_norm": 0.0625259280204773,
      "learning_rate": 9.084345361559288e-06,
      "loss": 0.0068,
      "step": 5783
    },
    {
      "epoch": 0.0915812974017132,
      "grad_norm": 0.36492374539375305,
      "learning_rate": 9.084187025982869e-06,
      "loss": 0.3532,
      "step": 5784
    },
    {
      "epoch": 0.09159713095935526,
      "grad_norm": 0.04057013615965843,
      "learning_rate": 9.084028690406448e-06,
      "loss": 0.0022,
      "step": 5785
    },
    {
      "epoch": 0.09161296451699733,
      "grad_norm": 0.002320922678336501,
      "learning_rate": 9.083870354830027e-06,
      "loss": 0.0,
      "step": 5786
    },
    {
      "epoch": 0.09162879807463939,
      "grad_norm": 0.23898188769817352,
      "learning_rate": 9.083712019253606e-06,
      "loss": 0.1869,
      "step": 5787
    },
    {
      "epoch": 0.09164463163228145,
      "grad_norm": 0.05794275924563408,
      "learning_rate": 9.083553683677187e-06,
      "loss": 0.0058,
      "step": 5788
    },
    {
      "epoch": 0.09166046518992352,
      "grad_norm": 0.3319404721260071,
      "learning_rate": 9.083395348100765e-06,
      "loss": 0.1712,
      "step": 5789
    },
    {
      "epoch": 0.0916762987475656,
      "grad_norm": 0.348500519990921,
      "learning_rate": 9.083237012524345e-06,
      "loss": 0.0678,
      "step": 5790
    },
    {
      "epoch": 0.09169213230520766,
      "grad_norm": 0.22229665517807007,
      "learning_rate": 9.083078676947924e-06,
      "loss": 0.088,
      "step": 5791
    },
    {
      "epoch": 0.09170796586284972,
      "grad_norm": 0.24129538238048553,
      "learning_rate": 9.082920341371503e-06,
      "loss": 0.1065,
      "step": 5792
    },
    {
      "epoch": 0.09172379942049179,
      "grad_norm": 0.337557315826416,
      "learning_rate": 9.082762005795083e-06,
      "loss": 0.1294,
      "step": 5793
    },
    {
      "epoch": 0.09173963297813385,
      "grad_norm": 0.1454983651638031,
      "learning_rate": 9.082603670218663e-06,
      "loss": 0.0179,
      "step": 5794
    },
    {
      "epoch": 0.09175546653577592,
      "grad_norm": 0.5497968792915344,
      "learning_rate": 9.08244533464224e-06,
      "loss": 0.4069,
      "step": 5795
    },
    {
      "epoch": 0.091771300093418,
      "grad_norm": 0.027852050960063934,
      "learning_rate": 9.082286999065821e-06,
      "loss": 0.0015,
      "step": 5796
    },
    {
      "epoch": 0.09178713365106006,
      "grad_norm": 0.3351980745792389,
      "learning_rate": 9.0821286634894e-06,
      "loss": 0.1843,
      "step": 5797
    },
    {
      "epoch": 0.09180296720870212,
      "grad_norm": 0.32787179946899414,
      "learning_rate": 9.08197032791298e-06,
      "loss": 0.5787,
      "step": 5798
    },
    {
      "epoch": 0.09181880076634419,
      "grad_norm": 0.2966645061969757,
      "learning_rate": 9.081811992336559e-06,
      "loss": 0.1646,
      "step": 5799
    },
    {
      "epoch": 0.09183463432398625,
      "grad_norm": 0.45071256160736084,
      "learning_rate": 9.081653656760138e-06,
      "loss": 0.0816,
      "step": 5800
    },
    {
      "epoch": 0.09185046788162832,
      "grad_norm": 0.8074995875358582,
      "learning_rate": 9.081495321183717e-06,
      "loss": 0.7021,
      "step": 5801
    },
    {
      "epoch": 0.0918663014392704,
      "grad_norm": 0.479740172624588,
      "learning_rate": 9.081336985607296e-06,
      "loss": 0.5351,
      "step": 5802
    },
    {
      "epoch": 0.09188213499691246,
      "grad_norm": 0.16095533967018127,
      "learning_rate": 9.081178650030877e-06,
      "loss": 0.0699,
      "step": 5803
    },
    {
      "epoch": 0.09189796855455452,
      "grad_norm": 0.19188715517520905,
      "learning_rate": 9.081020314454456e-06,
      "loss": 0.1262,
      "step": 5804
    },
    {
      "epoch": 0.09191380211219659,
      "grad_norm": 3.695248960866593e-05,
      "learning_rate": 9.080861978878035e-06,
      "loss": 0.0,
      "step": 5805
    },
    {
      "epoch": 0.09192963566983865,
      "grad_norm": 0.0036513099912554026,
      "learning_rate": 9.080703643301614e-06,
      "loss": 0.0002,
      "step": 5806
    },
    {
      "epoch": 0.09194546922748072,
      "grad_norm": 0.6124995350837708,
      "learning_rate": 9.080545307725193e-06,
      "loss": 0.1832,
      "step": 5807
    },
    {
      "epoch": 0.0919613027851228,
      "grad_norm": 0.6809757351875305,
      "learning_rate": 9.080386972148772e-06,
      "loss": 0.3574,
      "step": 5808
    },
    {
      "epoch": 0.09197713634276486,
      "grad_norm": 0.7021874189376831,
      "learning_rate": 9.080228636572353e-06,
      "loss": 0.2444,
      "step": 5809
    },
    {
      "epoch": 0.09199296990040692,
      "grad_norm": 0.31081944704055786,
      "learning_rate": 9.080070300995932e-06,
      "loss": 0.4748,
      "step": 5810
    },
    {
      "epoch": 0.09200880345804899,
      "grad_norm": 0.20535334944725037,
      "learning_rate": 9.079911965419511e-06,
      "loss": 0.1535,
      "step": 5811
    },
    {
      "epoch": 0.09202463701569105,
      "grad_norm": 0.03226092830300331,
      "learning_rate": 9.07975362984309e-06,
      "loss": 0.0013,
      "step": 5812
    },
    {
      "epoch": 0.09204047057333312,
      "grad_norm": 0.5873685479164124,
      "learning_rate": 9.07959529426667e-06,
      "loss": 0.384,
      "step": 5813
    },
    {
      "epoch": 0.0920563041309752,
      "grad_norm": 0.03621519356966019,
      "learning_rate": 9.079436958690248e-06,
      "loss": 0.0021,
      "step": 5814
    },
    {
      "epoch": 0.09207213768861726,
      "grad_norm": 0.5052183866500854,
      "learning_rate": 9.079278623113829e-06,
      "loss": 1.0119,
      "step": 5815
    },
    {
      "epoch": 0.09208797124625932,
      "grad_norm": 0.13194307684898376,
      "learning_rate": 9.079120287537408e-06,
      "loss": 0.0069,
      "step": 5816
    },
    {
      "epoch": 0.09210380480390139,
      "grad_norm": 0.0002731524873524904,
      "learning_rate": 9.078961951960987e-06,
      "loss": 0.0,
      "step": 5817
    },
    {
      "epoch": 0.09211963836154345,
      "grad_norm": 0.23097282648086548,
      "learning_rate": 9.078803616384566e-06,
      "loss": 0.1667,
      "step": 5818
    },
    {
      "epoch": 0.09213547191918552,
      "grad_norm": 0.2502373158931732,
      "learning_rate": 9.078645280808145e-06,
      "loss": 0.1052,
      "step": 5819
    },
    {
      "epoch": 0.0921513054768276,
      "grad_norm": 0.2685559391975403,
      "learning_rate": 9.078486945231724e-06,
      "loss": 0.1033,
      "step": 5820
    },
    {
      "epoch": 0.09216713903446966,
      "grad_norm": 5.257368087768555,
      "learning_rate": 9.078328609655305e-06,
      "loss": 0.5252,
      "step": 5821
    },
    {
      "epoch": 0.09218297259211172,
      "grad_norm": 0.2669738233089447,
      "learning_rate": 9.078170274078884e-06,
      "loss": 0.1972,
      "step": 5822
    },
    {
      "epoch": 0.09219880614975379,
      "grad_norm": 0.5087182521820068,
      "learning_rate": 9.078011938502462e-06,
      "loss": 0.3545,
      "step": 5823
    },
    {
      "epoch": 0.09221463970739585,
      "grad_norm": 0.0003345929435454309,
      "learning_rate": 9.077853602926042e-06,
      "loss": 0.0,
      "step": 5824
    },
    {
      "epoch": 0.09223047326503792,
      "grad_norm": 0.48733189702033997,
      "learning_rate": 9.077695267349622e-06,
      "loss": 0.2223,
      "step": 5825
    },
    {
      "epoch": 0.09224630682268,
      "grad_norm": 0.42174097895622253,
      "learning_rate": 9.0775369317732e-06,
      "loss": 0.069,
      "step": 5826
    },
    {
      "epoch": 0.09226214038032206,
      "grad_norm": 0.04113880544900894,
      "learning_rate": 9.07737859619678e-06,
      "loss": 0.0014,
      "step": 5827
    },
    {
      "epoch": 0.09227797393796412,
      "grad_norm": 0.12967528402805328,
      "learning_rate": 9.07722026062036e-06,
      "loss": 0.0024,
      "step": 5828
    },
    {
      "epoch": 0.09229380749560619,
      "grad_norm": 0.6084480881690979,
      "learning_rate": 9.077061925043938e-06,
      "loss": 0.1672,
      "step": 5829
    },
    {
      "epoch": 0.09230964105324825,
      "grad_norm": 0.39170992374420166,
      "learning_rate": 9.076903589467519e-06,
      "loss": 0.362,
      "step": 5830
    },
    {
      "epoch": 0.09232547461089032,
      "grad_norm": 0.24421659111976624,
      "learning_rate": 9.076745253891098e-06,
      "loss": 0.1298,
      "step": 5831
    },
    {
      "epoch": 0.0923413081685324,
      "grad_norm": 0.19337162375450134,
      "learning_rate": 9.076586918314677e-06,
      "loss": 0.0194,
      "step": 5832
    },
    {
      "epoch": 0.09235714172617446,
      "grad_norm": 0.28408578038215637,
      "learning_rate": 9.076428582738256e-06,
      "loss": 0.1364,
      "step": 5833
    },
    {
      "epoch": 0.09237297528381652,
      "grad_norm": 0.3022677004337311,
      "learning_rate": 9.076270247161835e-06,
      "loss": 0.2851,
      "step": 5834
    },
    {
      "epoch": 0.09238880884145859,
      "grad_norm": 0.36872994899749756,
      "learning_rate": 9.076111911585414e-06,
      "loss": 0.1438,
      "step": 5835
    },
    {
      "epoch": 0.09240464239910065,
      "grad_norm": 0.25492218136787415,
      "learning_rate": 9.075953576008995e-06,
      "loss": 0.2153,
      "step": 5836
    },
    {
      "epoch": 0.09242047595674271,
      "grad_norm": 0.2481958270072937,
      "learning_rate": 9.075795240432574e-06,
      "loss": 0.1051,
      "step": 5837
    },
    {
      "epoch": 0.09243630951438479,
      "grad_norm": 0.3493894636631012,
      "learning_rate": 9.075636904856153e-06,
      "loss": 0.0617,
      "step": 5838
    },
    {
      "epoch": 0.09245214307202686,
      "grad_norm": 0.4348447322845459,
      "learning_rate": 9.075478569279732e-06,
      "loss": 0.4374,
      "step": 5839
    },
    {
      "epoch": 0.09246797662966892,
      "grad_norm": 0.0006521448958665133,
      "learning_rate": 9.075320233703311e-06,
      "loss": 0.0,
      "step": 5840
    },
    {
      "epoch": 0.09248381018731099,
      "grad_norm": 0.23080721497535706,
      "learning_rate": 9.07516189812689e-06,
      "loss": 0.0534,
      "step": 5841
    },
    {
      "epoch": 0.09249964374495305,
      "grad_norm": 0.24341118335723877,
      "learning_rate": 9.075003562550471e-06,
      "loss": 0.0674,
      "step": 5842
    },
    {
      "epoch": 0.09251547730259511,
      "grad_norm": 0.33761927485466003,
      "learning_rate": 9.07484522697405e-06,
      "loss": 0.1126,
      "step": 5843
    },
    {
      "epoch": 0.09253131086023719,
      "grad_norm": 0.02561218850314617,
      "learning_rate": 9.074686891397629e-06,
      "loss": 0.0018,
      "step": 5844
    },
    {
      "epoch": 0.09254714441787926,
      "grad_norm": 0.3063696026802063,
      "learning_rate": 9.074528555821208e-06,
      "loss": 0.7147,
      "step": 5845
    },
    {
      "epoch": 0.09256297797552132,
      "grad_norm": 0.3578980267047882,
      "learning_rate": 9.074370220244787e-06,
      "loss": 0.3735,
      "step": 5846
    },
    {
      "epoch": 0.09257881153316339,
      "grad_norm": 0.023352457210421562,
      "learning_rate": 9.074211884668366e-06,
      "loss": 0.0014,
      "step": 5847
    },
    {
      "epoch": 0.09259464509080545,
      "grad_norm": 0.43163836002349854,
      "learning_rate": 9.074053549091945e-06,
      "loss": 0.1349,
      "step": 5848
    },
    {
      "epoch": 0.09261047864844751,
      "grad_norm": 0.1451423615217209,
      "learning_rate": 9.073895213515526e-06,
      "loss": 0.0432,
      "step": 5849
    },
    {
      "epoch": 0.09262631220608959,
      "grad_norm": 0.004443335812538862,
      "learning_rate": 9.073736877939104e-06,
      "loss": 0.0002,
      "step": 5850
    },
    {
      "epoch": 0.09264214576373166,
      "grad_norm": 0.2633116841316223,
      "learning_rate": 9.073578542362684e-06,
      "loss": 0.0464,
      "step": 5851
    },
    {
      "epoch": 0.09265797932137372,
      "grad_norm": 0.0005003447877243161,
      "learning_rate": 9.073420206786263e-06,
      "loss": 0.0,
      "step": 5852
    },
    {
      "epoch": 0.09267381287901579,
      "grad_norm": 0.016760317608714104,
      "learning_rate": 9.073261871209843e-06,
      "loss": 0.001,
      "step": 5853
    },
    {
      "epoch": 0.09268964643665785,
      "grad_norm": 0.26327502727508545,
      "learning_rate": 9.073103535633422e-06,
      "loss": 0.1257,
      "step": 5854
    },
    {
      "epoch": 0.09270547999429991,
      "grad_norm": 0.4409800171852112,
      "learning_rate": 9.072945200057002e-06,
      "loss": 0.3075,
      "step": 5855
    },
    {
      "epoch": 0.09272131355194199,
      "grad_norm": 0.23281371593475342,
      "learning_rate": 9.07278686448058e-06,
      "loss": 0.0943,
      "step": 5856
    },
    {
      "epoch": 0.09273714710958406,
      "grad_norm": 0.0454276017844677,
      "learning_rate": 9.07262852890416e-06,
      "loss": 0.0026,
      "step": 5857
    },
    {
      "epoch": 0.09275298066722612,
      "grad_norm": 0.3677877187728882,
      "learning_rate": 9.07247019332774e-06,
      "loss": 0.1285,
      "step": 5858
    },
    {
      "epoch": 0.09276881422486818,
      "grad_norm": 0.4270484745502472,
      "learning_rate": 9.072311857751319e-06,
      "loss": 0.2076,
      "step": 5859
    },
    {
      "epoch": 0.09278464778251025,
      "grad_norm": 0.28889310359954834,
      "learning_rate": 9.072153522174898e-06,
      "loss": 0.2777,
      "step": 5860
    },
    {
      "epoch": 0.09280048134015231,
      "grad_norm": 0.3740634024143219,
      "learning_rate": 9.071995186598479e-06,
      "loss": 0.016,
      "step": 5861
    },
    {
      "epoch": 0.09281631489779439,
      "grad_norm": 0.23775656521320343,
      "learning_rate": 9.071836851022056e-06,
      "loss": 0.0782,
      "step": 5862
    },
    {
      "epoch": 0.09283214845543646,
      "grad_norm": 0.27634307742118835,
      "learning_rate": 9.071678515445637e-06,
      "loss": 0.075,
      "step": 5863
    },
    {
      "epoch": 0.09284798201307852,
      "grad_norm": 0.0016147253336384892,
      "learning_rate": 9.071520179869216e-06,
      "loss": 0.0,
      "step": 5864
    },
    {
      "epoch": 0.09286381557072058,
      "grad_norm": 0.4297201633453369,
      "learning_rate": 9.071361844292795e-06,
      "loss": 0.5084,
      "step": 5865
    },
    {
      "epoch": 0.09287964912836265,
      "grad_norm": 0.40806853771209717,
      "learning_rate": 9.071203508716374e-06,
      "loss": 0.4536,
      "step": 5866
    },
    {
      "epoch": 0.09289548268600471,
      "grad_norm": 0.3242713212966919,
      "learning_rate": 9.071045173139955e-06,
      "loss": 0.1597,
      "step": 5867
    },
    {
      "epoch": 0.09291131624364679,
      "grad_norm": 0.48114970326423645,
      "learning_rate": 9.070886837563532e-06,
      "loss": 0.6177,
      "step": 5868
    },
    {
      "epoch": 0.09292714980128886,
      "grad_norm": 0.3152215778827667,
      "learning_rate": 9.070728501987113e-06,
      "loss": 0.1153,
      "step": 5869
    },
    {
      "epoch": 0.09294298335893092,
      "grad_norm": 0.034606825560331345,
      "learning_rate": 9.070570166410692e-06,
      "loss": 0.0023,
      "step": 5870
    },
    {
      "epoch": 0.09295881691657298,
      "grad_norm": 0.10399846732616425,
      "learning_rate": 9.070411830834271e-06,
      "loss": 0.0266,
      "step": 5871
    },
    {
      "epoch": 0.09297465047421505,
      "grad_norm": 0.012476969510316849,
      "learning_rate": 9.07025349525785e-06,
      "loss": 0.0008,
      "step": 5872
    },
    {
      "epoch": 0.09299048403185711,
      "grad_norm": 0.023636283352971077,
      "learning_rate": 9.07009515968143e-06,
      "loss": 0.0015,
      "step": 5873
    },
    {
      "epoch": 0.09300631758949919,
      "grad_norm": 0.4025680422782898,
      "learning_rate": 9.069936824105008e-06,
      "loss": 0.0229,
      "step": 5874
    },
    {
      "epoch": 0.09302215114714125,
      "grad_norm": 0.40621674060821533,
      "learning_rate": 9.069778488528587e-06,
      "loss": 0.1765,
      "step": 5875
    },
    {
      "epoch": 0.09303798470478332,
      "grad_norm": 0.2597918212413788,
      "learning_rate": 9.069620152952168e-06,
      "loss": 0.0897,
      "step": 5876
    },
    {
      "epoch": 0.09305381826242538,
      "grad_norm": 0.034470703452825546,
      "learning_rate": 9.069461817375747e-06,
      "loss": 0.0018,
      "step": 5877
    },
    {
      "epoch": 0.09306965182006745,
      "grad_norm": 8.53712554089725e-05,
      "learning_rate": 9.069303481799326e-06,
      "loss": 0.0,
      "step": 5878
    },
    {
      "epoch": 0.09308548537770951,
      "grad_norm": 0.3944384753704071,
      "learning_rate": 9.069145146222905e-06,
      "loss": 0.309,
      "step": 5879
    },
    {
      "epoch": 0.09310131893535159,
      "grad_norm": 0.14567042887210846,
      "learning_rate": 9.068986810646484e-06,
      "loss": 0.0484,
      "step": 5880
    },
    {
      "epoch": 0.09311715249299365,
      "grad_norm": 0.5861096978187561,
      "learning_rate": 9.068828475070064e-06,
      "loss": 0.1177,
      "step": 5881
    },
    {
      "epoch": 0.09313298605063572,
      "grad_norm": 0.009005493484437466,
      "learning_rate": 9.068670139493644e-06,
      "loss": 0.0006,
      "step": 5882
    },
    {
      "epoch": 0.09314881960827778,
      "grad_norm": 0.47654297947883606,
      "learning_rate": 9.068511803917223e-06,
      "loss": 0.3736,
      "step": 5883
    },
    {
      "epoch": 0.09316465316591985,
      "grad_norm": 0.5630017518997192,
      "learning_rate": 9.068353468340802e-06,
      "loss": 0.2068,
      "step": 5884
    },
    {
      "epoch": 0.09318048672356191,
      "grad_norm": 0.3085215985774994,
      "learning_rate": 9.068195132764382e-06,
      "loss": 0.2158,
      "step": 5885
    },
    {
      "epoch": 0.09319632028120399,
      "grad_norm": 0.3679243326187134,
      "learning_rate": 9.06803679718796e-06,
      "loss": 0.2252,
      "step": 5886
    },
    {
      "epoch": 0.09321215383884605,
      "grad_norm": 1.4730308055877686,
      "learning_rate": 9.06787846161154e-06,
      "loss": 0.3224,
      "step": 5887
    },
    {
      "epoch": 0.09322798739648812,
      "grad_norm": 0.26275599002838135,
      "learning_rate": 9.06772012603512e-06,
      "loss": 0.0441,
      "step": 5888
    },
    {
      "epoch": 0.09324382095413018,
      "grad_norm": 0.01614355482161045,
      "learning_rate": 9.0675617904587e-06,
      "loss": 0.0009,
      "step": 5889
    },
    {
      "epoch": 0.09325965451177225,
      "grad_norm": 0.33520957827568054,
      "learning_rate": 9.067403454882279e-06,
      "loss": 0.2208,
      "step": 5890
    },
    {
      "epoch": 0.09327548806941431,
      "grad_norm": 0.12166319787502289,
      "learning_rate": 9.067245119305858e-06,
      "loss": 0.0025,
      "step": 5891
    },
    {
      "epoch": 0.09329132162705639,
      "grad_norm": 0.016173003241419792,
      "learning_rate": 9.067086783729437e-06,
      "loss": 0.0008,
      "step": 5892
    },
    {
      "epoch": 0.09330715518469845,
      "grad_norm": 8.261462789960206e-05,
      "learning_rate": 9.066928448153016e-06,
      "loss": 0.0,
      "step": 5893
    },
    {
      "epoch": 0.09332298874234052,
      "grad_norm": 0.08521303534507751,
      "learning_rate": 9.066770112576597e-06,
      "loss": 0.0047,
      "step": 5894
    },
    {
      "epoch": 0.09333882229998258,
      "grad_norm": 0.3752993047237396,
      "learning_rate": 9.066611777000176e-06,
      "loss": 0.6698,
      "step": 5895
    },
    {
      "epoch": 0.09335465585762465,
      "grad_norm": 0.17556217312812805,
      "learning_rate": 9.066453441423753e-06,
      "loss": 0.0594,
      "step": 5896
    },
    {
      "epoch": 0.09337048941526671,
      "grad_norm": 0.34119510650634766,
      "learning_rate": 9.066295105847334e-06,
      "loss": 0.2729,
      "step": 5897
    },
    {
      "epoch": 0.09338632297290879,
      "grad_norm": 0.4599049985408783,
      "learning_rate": 9.066136770270913e-06,
      "loss": 0.4173,
      "step": 5898
    },
    {
      "epoch": 0.09340215653055085,
      "grad_norm": 0.26808831095695496,
      "learning_rate": 9.065978434694492e-06,
      "loss": 0.3251,
      "step": 5899
    },
    {
      "epoch": 0.09341799008819292,
      "grad_norm": 0.3016541302204132,
      "learning_rate": 9.065820099118071e-06,
      "loss": 0.0143,
      "step": 5900
    },
    {
      "epoch": 0.09343382364583498,
      "grad_norm": 0.2431187629699707,
      "learning_rate": 9.06566176354165e-06,
      "loss": 0.3362,
      "step": 5901
    },
    {
      "epoch": 0.09344965720347705,
      "grad_norm": 0.4620019495487213,
      "learning_rate": 9.06550342796523e-06,
      "loss": 0.401,
      "step": 5902
    },
    {
      "epoch": 0.09346549076111911,
      "grad_norm": 0.3770463168621063,
      "learning_rate": 9.06534509238881e-06,
      "loss": 0.1933,
      "step": 5903
    },
    {
      "epoch": 0.09348132431876119,
      "grad_norm": 0.36941465735435486,
      "learning_rate": 9.06518675681239e-06,
      "loss": 0.5631,
      "step": 5904
    },
    {
      "epoch": 0.09349715787640325,
      "grad_norm": 0.44824454188346863,
      "learning_rate": 9.065028421235968e-06,
      "loss": 0.012,
      "step": 5905
    },
    {
      "epoch": 0.09351299143404532,
      "grad_norm": 0.19072754681110382,
      "learning_rate": 9.064870085659547e-06,
      "loss": 0.0442,
      "step": 5906
    },
    {
      "epoch": 0.09352882499168738,
      "grad_norm": 0.45736831426620483,
      "learning_rate": 9.064711750083126e-06,
      "loss": 0.4807,
      "step": 5907
    },
    {
      "epoch": 0.09354465854932945,
      "grad_norm": 0.024608129635453224,
      "learning_rate": 9.064553414506705e-06,
      "loss": 0.0012,
      "step": 5908
    },
    {
      "epoch": 0.09356049210697151,
      "grad_norm": 0.8915692567825317,
      "learning_rate": 9.064395078930286e-06,
      "loss": 0.1285,
      "step": 5909
    },
    {
      "epoch": 0.09357632566461359,
      "grad_norm": 0.4764368534088135,
      "learning_rate": 9.064236743353865e-06,
      "loss": 0.0902,
      "step": 5910
    },
    {
      "epoch": 0.09359215922225565,
      "grad_norm": 0.23792462050914764,
      "learning_rate": 9.064078407777444e-06,
      "loss": 0.0517,
      "step": 5911
    },
    {
      "epoch": 0.09360799277989772,
      "grad_norm": 0.494779109954834,
      "learning_rate": 9.063920072201023e-06,
      "loss": 0.0695,
      "step": 5912
    },
    {
      "epoch": 0.09362382633753978,
      "grad_norm": 0.019819581881165504,
      "learning_rate": 9.063761736624603e-06,
      "loss": 0.0011,
      "step": 5913
    },
    {
      "epoch": 0.09363965989518185,
      "grad_norm": 0.018428975716233253,
      "learning_rate": 9.063603401048182e-06,
      "loss": 0.001,
      "step": 5914
    },
    {
      "epoch": 0.09365549345282391,
      "grad_norm": 0.17932604253292084,
      "learning_rate": 9.063445065471762e-06,
      "loss": 0.0519,
      "step": 5915
    },
    {
      "epoch": 0.09367132701046599,
      "grad_norm": 0.31340280175209045,
      "learning_rate": 9.063286729895342e-06,
      "loss": 0.0272,
      "step": 5916
    },
    {
      "epoch": 0.09368716056810805,
      "grad_norm": 0.3870863914489746,
      "learning_rate": 9.06312839431892e-06,
      "loss": 0.1832,
      "step": 5917
    },
    {
      "epoch": 0.09370299412575012,
      "grad_norm": 0.0642470121383667,
      "learning_rate": 9.0629700587425e-06,
      "loss": 0.0038,
      "step": 5918
    },
    {
      "epoch": 0.09371882768339218,
      "grad_norm": 0.2635810375213623,
      "learning_rate": 9.062811723166079e-06,
      "loss": 0.1727,
      "step": 5919
    },
    {
      "epoch": 0.09373466124103425,
      "grad_norm": 0.7215189337730408,
      "learning_rate": 9.062653387589658e-06,
      "loss": 0.0468,
      "step": 5920
    },
    {
      "epoch": 0.09375049479867631,
      "grad_norm": 0.2727029621601105,
      "learning_rate": 9.062495052013237e-06,
      "loss": 0.1894,
      "step": 5921
    },
    {
      "epoch": 0.09376632835631839,
      "grad_norm": 0.23507775366306305,
      "learning_rate": 9.062336716436818e-06,
      "loss": 0.0991,
      "step": 5922
    },
    {
      "epoch": 0.09378216191396045,
      "grad_norm": 0.154717355966568,
      "learning_rate": 9.062178380860395e-06,
      "loss": 0.06,
      "step": 5923
    },
    {
      "epoch": 0.09379799547160252,
      "grad_norm": 0.01383710466325283,
      "learning_rate": 9.062020045283976e-06,
      "loss": 0.0007,
      "step": 5924
    },
    {
      "epoch": 0.09381382902924458,
      "grad_norm": 0.17246732115745544,
      "learning_rate": 9.061861709707555e-06,
      "loss": 0.0096,
      "step": 5925
    },
    {
      "epoch": 0.09382966258688664,
      "grad_norm": 0.009045890532433987,
      "learning_rate": 9.061703374131134e-06,
      "loss": 0.0004,
      "step": 5926
    },
    {
      "epoch": 0.09384549614452871,
      "grad_norm": 0.19514741003513336,
      "learning_rate": 9.061545038554713e-06,
      "loss": 0.2034,
      "step": 5927
    },
    {
      "epoch": 0.09386132970217079,
      "grad_norm": 0.3352556824684143,
      "learning_rate": 9.061386702978294e-06,
      "loss": 0.3649,
      "step": 5928
    },
    {
      "epoch": 0.09387716325981285,
      "grad_norm": 0.04026595503091812,
      "learning_rate": 9.061228367401871e-06,
      "loss": 0.0024,
      "step": 5929
    },
    {
      "epoch": 0.09389299681745492,
      "grad_norm": 0.40604230761528015,
      "learning_rate": 9.061070031825452e-06,
      "loss": 0.2079,
      "step": 5930
    },
    {
      "epoch": 0.09390883037509698,
      "grad_norm": 0.32527095079421997,
      "learning_rate": 9.060911696249031e-06,
      "loss": 0.034,
      "step": 5931
    },
    {
      "epoch": 0.09392466393273904,
      "grad_norm": 0.3017144203186035,
      "learning_rate": 9.06075336067261e-06,
      "loss": 0.0668,
      "step": 5932
    },
    {
      "epoch": 0.09394049749038111,
      "grad_norm": 0.030416199937462807,
      "learning_rate": 9.06059502509619e-06,
      "loss": 0.0019,
      "step": 5933
    },
    {
      "epoch": 0.09395633104802319,
      "grad_norm": 0.005396407563239336,
      "learning_rate": 9.06043668951977e-06,
      "loss": 0.0003,
      "step": 5934
    },
    {
      "epoch": 0.09397216460566525,
      "grad_norm": 0.01287212036550045,
      "learning_rate": 9.060278353943347e-06,
      "loss": 0.0006,
      "step": 5935
    },
    {
      "epoch": 0.09398799816330732,
      "grad_norm": 0.2817995250225067,
      "learning_rate": 9.060120018366928e-06,
      "loss": 0.2053,
      "step": 5936
    },
    {
      "epoch": 0.09400383172094938,
      "grad_norm": 0.3651367425918579,
      "learning_rate": 9.059961682790507e-06,
      "loss": 0.1746,
      "step": 5937
    },
    {
      "epoch": 0.09401966527859144,
      "grad_norm": 0.26229560375213623,
      "learning_rate": 9.059803347214086e-06,
      "loss": 0.0529,
      "step": 5938
    },
    {
      "epoch": 0.09403549883623351,
      "grad_norm": 0.08429966866970062,
      "learning_rate": 9.059645011637665e-06,
      "loss": 0.0042,
      "step": 5939
    },
    {
      "epoch": 0.09405133239387559,
      "grad_norm": 0.013630121946334839,
      "learning_rate": 9.059486676061246e-06,
      "loss": 0.0007,
      "step": 5940
    },
    {
      "epoch": 0.09406716595151765,
      "grad_norm": 0.1835833638906479,
      "learning_rate": 9.059328340484824e-06,
      "loss": 0.0403,
      "step": 5941
    },
    {
      "epoch": 0.09408299950915971,
      "grad_norm": 0.05037631466984749,
      "learning_rate": 9.059170004908404e-06,
      "loss": 0.0031,
      "step": 5942
    },
    {
      "epoch": 0.09409883306680178,
      "grad_norm": 0.3079792261123657,
      "learning_rate": 9.059011669331983e-06,
      "loss": 0.1377,
      "step": 5943
    },
    {
      "epoch": 0.09411466662444384,
      "grad_norm": 0.023620177060365677,
      "learning_rate": 9.058853333755563e-06,
      "loss": 0.0012,
      "step": 5944
    },
    {
      "epoch": 0.09413050018208591,
      "grad_norm": 0.24038825929164886,
      "learning_rate": 9.058694998179142e-06,
      "loss": 0.1594,
      "step": 5945
    },
    {
      "epoch": 0.09414633373972799,
      "grad_norm": 0.00020682261674664915,
      "learning_rate": 9.05853666260272e-06,
      "loss": 0.0,
      "step": 5946
    },
    {
      "epoch": 0.09416216729737005,
      "grad_norm": 0.3746286630630493,
      "learning_rate": 9.0583783270263e-06,
      "loss": 0.1321,
      "step": 5947
    },
    {
      "epoch": 0.09417800085501211,
      "grad_norm": 0.5073646903038025,
      "learning_rate": 9.058219991449879e-06,
      "loss": 0.1978,
      "step": 5948
    },
    {
      "epoch": 0.09419383441265418,
      "grad_norm": 0.26682254672050476,
      "learning_rate": 9.05806165587346e-06,
      "loss": 0.1418,
      "step": 5949
    },
    {
      "epoch": 0.09420966797029624,
      "grad_norm": 0.11715646833181381,
      "learning_rate": 9.057903320297039e-06,
      "loss": 0.0065,
      "step": 5950
    },
    {
      "epoch": 0.09422550152793831,
      "grad_norm": 0.191183939576149,
      "learning_rate": 9.057744984720618e-06,
      "loss": 0.0501,
      "step": 5951
    },
    {
      "epoch": 0.09424133508558039,
      "grad_norm": 0.4336414933204651,
      "learning_rate": 9.057586649144197e-06,
      "loss": 0.0152,
      "step": 5952
    },
    {
      "epoch": 0.09425716864322245,
      "grad_norm": 0.8271386027336121,
      "learning_rate": 9.057428313567776e-06,
      "loss": 0.4536,
      "step": 5953
    },
    {
      "epoch": 0.09427300220086451,
      "grad_norm": 0.01290454063564539,
      "learning_rate": 9.057269977991355e-06,
      "loss": 0.0007,
      "step": 5954
    },
    {
      "epoch": 0.09428883575850658,
      "grad_norm": 0.012672223150730133,
      "learning_rate": 9.057111642414936e-06,
      "loss": 0.0007,
      "step": 5955
    },
    {
      "epoch": 0.09430466931614864,
      "grad_norm": 0.051447901874780655,
      "learning_rate": 9.056953306838515e-06,
      "loss": 0.0007,
      "step": 5956
    },
    {
      "epoch": 0.09432050287379071,
      "grad_norm": 0.03677435964345932,
      "learning_rate": 9.056794971262094e-06,
      "loss": 0.0037,
      "step": 5957
    },
    {
      "epoch": 0.09433633643143279,
      "grad_norm": 0.31221121549606323,
      "learning_rate": 9.056636635685673e-06,
      "loss": 0.2095,
      "step": 5958
    },
    {
      "epoch": 0.09435216998907485,
      "grad_norm": 0.19038604199886322,
      "learning_rate": 9.056478300109252e-06,
      "loss": 0.1321,
      "step": 5959
    },
    {
      "epoch": 0.09436800354671691,
      "grad_norm": 0.27054694294929504,
      "learning_rate": 9.056319964532831e-06,
      "loss": 0.2313,
      "step": 5960
    },
    {
      "epoch": 0.09438383710435898,
      "grad_norm": 0.26062649488449097,
      "learning_rate": 9.056161628956412e-06,
      "loss": 0.0588,
      "step": 5961
    },
    {
      "epoch": 0.09439967066200104,
      "grad_norm": 0.21205268800258636,
      "learning_rate": 9.056003293379991e-06,
      "loss": 0.0874,
      "step": 5962
    },
    {
      "epoch": 0.0944155042196431,
      "grad_norm": 0.013323236256837845,
      "learning_rate": 9.05584495780357e-06,
      "loss": 0.0008,
      "step": 5963
    },
    {
      "epoch": 0.09443133777728518,
      "grad_norm": 0.1783408224582672,
      "learning_rate": 9.05568662222715e-06,
      "loss": 0.2377,
      "step": 5964
    },
    {
      "epoch": 0.09444717133492725,
      "grad_norm": 0.16492201387882233,
      "learning_rate": 9.055528286650728e-06,
      "loss": 0.0614,
      "step": 5965
    },
    {
      "epoch": 0.09446300489256931,
      "grad_norm": 0.439527302980423,
      "learning_rate": 9.055369951074307e-06,
      "loss": 0.1326,
      "step": 5966
    },
    {
      "epoch": 0.09447883845021138,
      "grad_norm": 4.9429341743234545e-05,
      "learning_rate": 9.055211615497886e-06,
      "loss": 0.0,
      "step": 5967
    },
    {
      "epoch": 0.09449467200785344,
      "grad_norm": 0.02249862439930439,
      "learning_rate": 9.055053279921465e-06,
      "loss": 0.0013,
      "step": 5968
    },
    {
      "epoch": 0.0945105055654955,
      "grad_norm": 0.37215152382850647,
      "learning_rate": 9.054894944345045e-06,
      "loss": 0.0715,
      "step": 5969
    },
    {
      "epoch": 0.09452633912313758,
      "grad_norm": 0.14474010467529297,
      "learning_rate": 9.054736608768625e-06,
      "loss": 0.0355,
      "step": 5970
    },
    {
      "epoch": 0.09454217268077965,
      "grad_norm": 0.17772530019283295,
      "learning_rate": 9.054578273192204e-06,
      "loss": 0.2508,
      "step": 5971
    },
    {
      "epoch": 0.09455800623842171,
      "grad_norm": 0.18240809440612793,
      "learning_rate": 9.054419937615784e-06,
      "loss": 0.1023,
      "step": 5972
    },
    {
      "epoch": 0.09457383979606378,
      "grad_norm": 0.22682686150074005,
      "learning_rate": 9.054261602039363e-06,
      "loss": 0.0899,
      "step": 5973
    },
    {
      "epoch": 0.09458967335370584,
      "grad_norm": 0.29164695739746094,
      "learning_rate": 9.054103266462942e-06,
      "loss": 0.2176,
      "step": 5974
    },
    {
      "epoch": 0.0946055069113479,
      "grad_norm": 0.3111112415790558,
      "learning_rate": 9.05394493088652e-06,
      "loss": 0.385,
      "step": 5975
    },
    {
      "epoch": 0.09462134046898998,
      "grad_norm": 0.3035200834274292,
      "learning_rate": 9.053786595310102e-06,
      "loss": 0.4113,
      "step": 5976
    },
    {
      "epoch": 0.09463717402663205,
      "grad_norm": 0.22806569933891296,
      "learning_rate": 9.05362825973368e-06,
      "loss": 0.1283,
      "step": 5977
    },
    {
      "epoch": 0.09465300758427411,
      "grad_norm": 0.0002063308929791674,
      "learning_rate": 9.05346992415726e-06,
      "loss": 0.0,
      "step": 5978
    },
    {
      "epoch": 0.09466884114191618,
      "grad_norm": 0.23159366846084595,
      "learning_rate": 9.053311588580839e-06,
      "loss": 0.3203,
      "step": 5979
    },
    {
      "epoch": 0.09468467469955824,
      "grad_norm": 0.17513076961040497,
      "learning_rate": 9.053153253004418e-06,
      "loss": 0.1069,
      "step": 5980
    },
    {
      "epoch": 0.0947005082572003,
      "grad_norm": 0.11716502159833908,
      "learning_rate": 9.052994917427997e-06,
      "loss": 0.0291,
      "step": 5981
    },
    {
      "epoch": 0.09471634181484238,
      "grad_norm": 0.02090396359562874,
      "learning_rate": 9.052836581851578e-06,
      "loss": 0.0012,
      "step": 5982
    },
    {
      "epoch": 0.09473217537248445,
      "grad_norm": 0.009892064146697521,
      "learning_rate": 9.052678246275157e-06,
      "loss": 0.0005,
      "step": 5983
    },
    {
      "epoch": 0.09474800893012651,
      "grad_norm": 0.23280690610408783,
      "learning_rate": 9.052519910698736e-06,
      "loss": 0.1077,
      "step": 5984
    },
    {
      "epoch": 0.09476384248776858,
      "grad_norm": 0.5040754079818726,
      "learning_rate": 9.052361575122315e-06,
      "loss": 0.2684,
      "step": 5985
    },
    {
      "epoch": 0.09477967604541064,
      "grad_norm": 0.2958456575870514,
      "learning_rate": 9.052203239545894e-06,
      "loss": 0.0677,
      "step": 5986
    },
    {
      "epoch": 0.0947955096030527,
      "grad_norm": 0.016990114003419876,
      "learning_rate": 9.052044903969473e-06,
      "loss": 0.0009,
      "step": 5987
    },
    {
      "epoch": 0.09481134316069478,
      "grad_norm": 0.012229307554662228,
      "learning_rate": 9.051886568393054e-06,
      "loss": 0.0008,
      "step": 5988
    },
    {
      "epoch": 0.09482717671833685,
      "grad_norm": 0.00017991149798035622,
      "learning_rate": 9.051728232816633e-06,
      "loss": 0.0,
      "step": 5989
    },
    {
      "epoch": 0.09484301027597891,
      "grad_norm": 0.3089560568332672,
      "learning_rate": 9.051569897240212e-06,
      "loss": 0.1969,
      "step": 5990
    },
    {
      "epoch": 0.09485884383362098,
      "grad_norm": 0.24616682529449463,
      "learning_rate": 9.051411561663791e-06,
      "loss": 0.1288,
      "step": 5991
    },
    {
      "epoch": 0.09487467739126304,
      "grad_norm": 6.148899410618469e-05,
      "learning_rate": 9.05125322608737e-06,
      "loss": 0.0,
      "step": 5992
    },
    {
      "epoch": 0.0948905109489051,
      "grad_norm": 0.7908863425254822,
      "learning_rate": 9.05109489051095e-06,
      "loss": 0.4983,
      "step": 5993
    },
    {
      "epoch": 0.09490634450654718,
      "grad_norm": 0.36982253193855286,
      "learning_rate": 9.050936554934528e-06,
      "loss": 0.1176,
      "step": 5994
    },
    {
      "epoch": 0.09492217806418925,
      "grad_norm": 0.574577808380127,
      "learning_rate": 9.050778219358109e-06,
      "loss": 0.1954,
      "step": 5995
    },
    {
      "epoch": 0.09493801162183131,
      "grad_norm": 0.2735643982887268,
      "learning_rate": 9.050619883781687e-06,
      "loss": 0.0598,
      "step": 5996
    },
    {
      "epoch": 0.09495384517947338,
      "grad_norm": 0.005515549331903458,
      "learning_rate": 9.050461548205267e-06,
      "loss": 0.0001,
      "step": 5997
    },
    {
      "epoch": 0.09496967873711544,
      "grad_norm": 0.1772613525390625,
      "learning_rate": 9.050303212628846e-06,
      "loss": 0.0674,
      "step": 5998
    },
    {
      "epoch": 0.0949855122947575,
      "grad_norm": 0.4493388235569,
      "learning_rate": 9.050144877052425e-06,
      "loss": 0.0815,
      "step": 5999
    },
    {
      "epoch": 0.09500134585239958,
      "grad_norm": 0.31077560782432556,
      "learning_rate": 9.049986541476005e-06,
      "loss": 0.2268,
      "step": 6000
    },
    {
      "epoch": 0.09501717941004165,
      "grad_norm": 0.23569993674755096,
      "learning_rate": 9.049828205899585e-06,
      "loss": 0.148,
      "step": 6001
    },
    {
      "epoch": 0.09503301296768371,
      "grad_norm": 0.01206611841917038,
      "learning_rate": 9.049669870323163e-06,
      "loss": 0.0007,
      "step": 6002
    },
    {
      "epoch": 0.09504884652532578,
      "grad_norm": 0.2786259055137634,
      "learning_rate": 9.049511534746743e-06,
      "loss": 0.2218,
      "step": 6003
    },
    {
      "epoch": 0.09506468008296784,
      "grad_norm": 0.1993049681186676,
      "learning_rate": 9.049353199170323e-06,
      "loss": 0.026,
      "step": 6004
    },
    {
      "epoch": 0.0950805136406099,
      "grad_norm": 0.498510479927063,
      "learning_rate": 9.049194863593902e-06,
      "loss": 0.2137,
      "step": 6005
    },
    {
      "epoch": 0.09509634719825198,
      "grad_norm": 0.020502381026744843,
      "learning_rate": 9.04903652801748e-06,
      "loss": 0.0012,
      "step": 6006
    },
    {
      "epoch": 0.09511218075589405,
      "grad_norm": 0.3549404740333557,
      "learning_rate": 9.048878192441061e-06,
      "loss": 0.2785,
      "step": 6007
    },
    {
      "epoch": 0.09512801431353611,
      "grad_norm": 0.5248619318008423,
      "learning_rate": 9.048719856864639e-06,
      "loss": 0.3229,
      "step": 6008
    },
    {
      "epoch": 0.09514384787117817,
      "grad_norm": 0.32372668385505676,
      "learning_rate": 9.04856152128822e-06,
      "loss": 0.0466,
      "step": 6009
    },
    {
      "epoch": 0.09515968142882024,
      "grad_norm": 0.2451012134552002,
      "learning_rate": 9.048403185711799e-06,
      "loss": 0.1056,
      "step": 6010
    },
    {
      "epoch": 0.0951755149864623,
      "grad_norm": 0.302077054977417,
      "learning_rate": 9.048244850135378e-06,
      "loss": 0.1454,
      "step": 6011
    },
    {
      "epoch": 0.09519134854410438,
      "grad_norm": 0.324809730052948,
      "learning_rate": 9.048086514558957e-06,
      "loss": 0.0986,
      "step": 6012
    },
    {
      "epoch": 0.09520718210174645,
      "grad_norm": 0.3061233460903168,
      "learning_rate": 9.047928178982538e-06,
      "loss": 0.2443,
      "step": 6013
    },
    {
      "epoch": 0.09522301565938851,
      "grad_norm": 1.0518198013305664,
      "learning_rate": 9.047769843406115e-06,
      "loss": 0.0671,
      "step": 6014
    },
    {
      "epoch": 0.09523884921703057,
      "grad_norm": 0.8722178936004639,
      "learning_rate": 9.047611507829694e-06,
      "loss": 0.3145,
      "step": 6015
    },
    {
      "epoch": 0.09525468277467264,
      "grad_norm": 0.2277473360300064,
      "learning_rate": 9.047453172253275e-06,
      "loss": 0.0471,
      "step": 6016
    },
    {
      "epoch": 0.0952705163323147,
      "grad_norm": 0.4145934581756592,
      "learning_rate": 9.047294836676854e-06,
      "loss": 0.4174,
      "step": 6017
    },
    {
      "epoch": 0.09528634988995678,
      "grad_norm": 0.030236639082431793,
      "learning_rate": 9.047136501100433e-06,
      "loss": 0.002,
      "step": 6018
    },
    {
      "epoch": 0.09530218344759885,
      "grad_norm": 0.023961713537573814,
      "learning_rate": 9.046978165524012e-06,
      "loss": 0.0014,
      "step": 6019
    },
    {
      "epoch": 0.09531801700524091,
      "grad_norm": 0.35406041145324707,
      "learning_rate": 9.046819829947591e-06,
      "loss": 0.2143,
      "step": 6020
    },
    {
      "epoch": 0.09533385056288297,
      "grad_norm": 0.24824251234531403,
      "learning_rate": 9.04666149437117e-06,
      "loss": 0.0803,
      "step": 6021
    },
    {
      "epoch": 0.09534968412052504,
      "grad_norm": 0.0012578436871990561,
      "learning_rate": 9.046503158794751e-06,
      "loss": 0.0001,
      "step": 6022
    },
    {
      "epoch": 0.0953655176781671,
      "grad_norm": 0.38214144110679626,
      "learning_rate": 9.04634482321833e-06,
      "loss": 0.061,
      "step": 6023
    },
    {
      "epoch": 0.09538135123580918,
      "grad_norm": 0.3561802804470062,
      "learning_rate": 9.04618648764191e-06,
      "loss": 0.0891,
      "step": 6024
    },
    {
      "epoch": 0.09539718479345125,
      "grad_norm": 0.2360638678073883,
      "learning_rate": 9.046028152065488e-06,
      "loss": 0.0829,
      "step": 6025
    },
    {
      "epoch": 0.09541301835109331,
      "grad_norm": 0.0172519963234663,
      "learning_rate": 9.045869816489067e-06,
      "loss": 0.001,
      "step": 6026
    },
    {
      "epoch": 0.09542885190873537,
      "grad_norm": 0.48112115263938904,
      "learning_rate": 9.045711480912646e-06,
      "loss": 0.3169,
      "step": 6027
    },
    {
      "epoch": 0.09544468546637744,
      "grad_norm": 0.39632168412208557,
      "learning_rate": 9.045553145336227e-06,
      "loss": 0.2053,
      "step": 6028
    },
    {
      "epoch": 0.0954605190240195,
      "grad_norm": 0.2770843505859375,
      "learning_rate": 9.045394809759805e-06,
      "loss": 0.1236,
      "step": 6029
    },
    {
      "epoch": 0.09547635258166158,
      "grad_norm": 0.00010347361967433244,
      "learning_rate": 9.045236474183385e-06,
      "loss": 0.0,
      "step": 6030
    },
    {
      "epoch": 0.09549218613930364,
      "grad_norm": 2.224571466445923,
      "learning_rate": 9.045078138606964e-06,
      "loss": 0.1055,
      "step": 6031
    },
    {
      "epoch": 0.09550801969694571,
      "grad_norm": 0.23755478858947754,
      "learning_rate": 9.044919803030544e-06,
      "loss": 0.0998,
      "step": 6032
    },
    {
      "epoch": 0.09552385325458777,
      "grad_norm": 0.2362399399280548,
      "learning_rate": 9.044761467454123e-06,
      "loss": 0.0471,
      "step": 6033
    },
    {
      "epoch": 0.09553968681222984,
      "grad_norm": 0.5262191295623779,
      "learning_rate": 9.044603131877703e-06,
      "loss": 0.5377,
      "step": 6034
    },
    {
      "epoch": 0.0955555203698719,
      "grad_norm": 0.25404828786849976,
      "learning_rate": 9.04444479630128e-06,
      "loss": 0.0945,
      "step": 6035
    },
    {
      "epoch": 0.09557135392751397,
      "grad_norm": 0.27392059564590454,
      "learning_rate": 9.044286460724862e-06,
      "loss": 0.057,
      "step": 6036
    },
    {
      "epoch": 0.09558718748515604,
      "grad_norm": 0.38990527391433716,
      "learning_rate": 9.04412812514844e-06,
      "loss": 0.1274,
      "step": 6037
    },
    {
      "epoch": 0.09560302104279811,
      "grad_norm": 0.00529828853905201,
      "learning_rate": 9.04396978957202e-06,
      "loss": 0.0003,
      "step": 6038
    },
    {
      "epoch": 0.09561885460044017,
      "grad_norm": 0.3100326955318451,
      "learning_rate": 9.043811453995599e-06,
      "loss": 0.2429,
      "step": 6039
    },
    {
      "epoch": 0.09563468815808224,
      "grad_norm": 0.6746481657028198,
      "learning_rate": 9.043653118419178e-06,
      "loss": 0.1875,
      "step": 6040
    },
    {
      "epoch": 0.0956505217157243,
      "grad_norm": 0.20283883810043335,
      "learning_rate": 9.043494782842757e-06,
      "loss": 0.0514,
      "step": 6041
    },
    {
      "epoch": 0.09566635527336637,
      "grad_norm": 0.34220778942108154,
      "learning_rate": 9.043336447266336e-06,
      "loss": 0.1423,
      "step": 6042
    },
    {
      "epoch": 0.09568218883100844,
      "grad_norm": 0.03380274400115013,
      "learning_rate": 9.043178111689917e-06,
      "loss": 0.0018,
      "step": 6043
    },
    {
      "epoch": 0.09569802238865051,
      "grad_norm": 0.614657461643219,
      "learning_rate": 9.043019776113496e-06,
      "loss": 0.0952,
      "step": 6044
    },
    {
      "epoch": 0.09571385594629257,
      "grad_norm": 0.2281530499458313,
      "learning_rate": 9.042861440537075e-06,
      "loss": 0.137,
      "step": 6045
    },
    {
      "epoch": 0.09572968950393464,
      "grad_norm": 0.2167336344718933,
      "learning_rate": 9.042703104960654e-06,
      "loss": 0.1769,
      "step": 6046
    },
    {
      "epoch": 0.0957455230615767,
      "grad_norm": 0.41487833857536316,
      "learning_rate": 9.042544769384233e-06,
      "loss": 0.3489,
      "step": 6047
    },
    {
      "epoch": 0.09576135661921877,
      "grad_norm": 0.6323045492172241,
      "learning_rate": 9.042386433807812e-06,
      "loss": 0.2065,
      "step": 6048
    },
    {
      "epoch": 0.09577719017686084,
      "grad_norm": 0.034201692789793015,
      "learning_rate": 9.042228098231393e-06,
      "loss": 0.0017,
      "step": 6049
    },
    {
      "epoch": 0.09579302373450291,
      "grad_norm": 0.00015700187941547483,
      "learning_rate": 9.042069762654972e-06,
      "loss": 0.0,
      "step": 6050
    },
    {
      "epoch": 0.09580885729214497,
      "grad_norm": 0.5585838556289673,
      "learning_rate": 9.041911427078551e-06,
      "loss": 0.3455,
      "step": 6051
    },
    {
      "epoch": 0.09582469084978704,
      "grad_norm": 0.18786604702472687,
      "learning_rate": 9.04175309150213e-06,
      "loss": 0.0814,
      "step": 6052
    },
    {
      "epoch": 0.0958405244074291,
      "grad_norm": 0.0807119756937027,
      "learning_rate": 9.04159475592571e-06,
      "loss": 0.0043,
      "step": 6053
    },
    {
      "epoch": 0.09585635796507117,
      "grad_norm": 0.20714573562145233,
      "learning_rate": 9.041436420349288e-06,
      "loss": 0.102,
      "step": 6054
    },
    {
      "epoch": 0.09587219152271324,
      "grad_norm": 0.303749144077301,
      "learning_rate": 9.041278084772869e-06,
      "loss": 0.1327,
      "step": 6055
    },
    {
      "epoch": 0.09588802508035531,
      "grad_norm": 0.0029925135895609856,
      "learning_rate": 9.041119749196448e-06,
      "loss": 0.0001,
      "step": 6056
    },
    {
      "epoch": 0.09590385863799737,
      "grad_norm": 0.41964197158813477,
      "learning_rate": 9.040961413620027e-06,
      "loss": 0.0882,
      "step": 6057
    },
    {
      "epoch": 0.09591969219563944,
      "grad_norm": 0.0980868712067604,
      "learning_rate": 9.040803078043606e-06,
      "loss": 0.0585,
      "step": 6058
    },
    {
      "epoch": 0.0959355257532815,
      "grad_norm": 0.002327215624973178,
      "learning_rate": 9.040644742467185e-06,
      "loss": 0.0001,
      "step": 6059
    },
    {
      "epoch": 0.09595135931092356,
      "grad_norm": 0.05441732332110405,
      "learning_rate": 9.040486406890765e-06,
      "loss": 0.0159,
      "step": 6060
    },
    {
      "epoch": 0.09596719286856564,
      "grad_norm": 0.6230672001838684,
      "learning_rate": 9.040328071314345e-06,
      "loss": 0.1158,
      "step": 6061
    },
    {
      "epoch": 0.09598302642620771,
      "grad_norm": 0.2105530947446823,
      "learning_rate": 9.040169735737924e-06,
      "loss": 0.0637,
      "step": 6062
    },
    {
      "epoch": 0.09599885998384977,
      "grad_norm": 0.25423842668533325,
      "learning_rate": 9.040011400161503e-06,
      "loss": 0.1051,
      "step": 6063
    },
    {
      "epoch": 0.09601469354149184,
      "grad_norm": 0.05322975665330887,
      "learning_rate": 9.039853064585083e-06,
      "loss": 0.0044,
      "step": 6064
    },
    {
      "epoch": 0.0960305270991339,
      "grad_norm": 0.5522472262382507,
      "learning_rate": 9.039694729008662e-06,
      "loss": 0.2199,
      "step": 6065
    },
    {
      "epoch": 0.09604636065677596,
      "grad_norm": 0.2879888117313385,
      "learning_rate": 9.03953639343224e-06,
      "loss": 0.1453,
      "step": 6066
    },
    {
      "epoch": 0.09606219421441804,
      "grad_norm": 0.1868080198764801,
      "learning_rate": 9.03937805785582e-06,
      "loss": 0.0664,
      "step": 6067
    },
    {
      "epoch": 0.0960780277720601,
      "grad_norm": 0.012568934820592403,
      "learning_rate": 9.0392197222794e-06,
      "loss": 0.0008,
      "step": 6068
    },
    {
      "epoch": 0.09609386132970217,
      "grad_norm": 0.007430593948811293,
      "learning_rate": 9.039061386702978e-06,
      "loss": 0.0004,
      "step": 6069
    },
    {
      "epoch": 0.09610969488734424,
      "grad_norm": 0.0005025033606216311,
      "learning_rate": 9.038903051126559e-06,
      "loss": 0.0,
      "step": 6070
    },
    {
      "epoch": 0.0961255284449863,
      "grad_norm": 0.016160989180207253,
      "learning_rate": 9.038744715550138e-06,
      "loss": 0.001,
      "step": 6071
    },
    {
      "epoch": 0.09614136200262836,
      "grad_norm": 0.24012689292430878,
      "learning_rate": 9.038586379973717e-06,
      "loss": 0.1535,
      "step": 6072
    },
    {
      "epoch": 0.09615719556027044,
      "grad_norm": 0.9384850263595581,
      "learning_rate": 9.038428044397296e-06,
      "loss": 0.1129,
      "step": 6073
    },
    {
      "epoch": 0.0961730291179125,
      "grad_norm": 0.03920228034257889,
      "learning_rate": 9.038269708820877e-06,
      "loss": 0.0009,
      "step": 6074
    },
    {
      "epoch": 0.09618886267555457,
      "grad_norm": 0.00014259670570027083,
      "learning_rate": 9.038111373244454e-06,
      "loss": 0.0,
      "step": 6075
    },
    {
      "epoch": 0.09620469623319663,
      "grad_norm": 0.24300147593021393,
      "learning_rate": 9.037953037668035e-06,
      "loss": 0.1815,
      "step": 6076
    },
    {
      "epoch": 0.0962205297908387,
      "grad_norm": 0.08478035032749176,
      "learning_rate": 9.037794702091614e-06,
      "loss": 0.01,
      "step": 6077
    },
    {
      "epoch": 0.09623636334848076,
      "grad_norm": 0.18197740614414215,
      "learning_rate": 9.037636366515193e-06,
      "loss": 0.0703,
      "step": 6078
    },
    {
      "epoch": 0.09625219690612284,
      "grad_norm": 0.17734037339687347,
      "learning_rate": 9.037478030938772e-06,
      "loss": 0.1142,
      "step": 6079
    },
    {
      "epoch": 0.0962680304637649,
      "grad_norm": 0.000498536042869091,
      "learning_rate": 9.037319695362353e-06,
      "loss": 0.0,
      "step": 6080
    },
    {
      "epoch": 0.09628386402140697,
      "grad_norm": 0.0025889065582305193,
      "learning_rate": 9.03716135978593e-06,
      "loss": 0.0,
      "step": 6081
    },
    {
      "epoch": 0.09629969757904903,
      "grad_norm": 0.12370293587446213,
      "learning_rate": 9.037003024209511e-06,
      "loss": 0.0313,
      "step": 6082
    },
    {
      "epoch": 0.0963155311366911,
      "grad_norm": 0.5611580014228821,
      "learning_rate": 9.03684468863309e-06,
      "loss": 1.2536,
      "step": 6083
    },
    {
      "epoch": 0.09633136469433316,
      "grad_norm": 0.3597012758255005,
      "learning_rate": 9.03668635305667e-06,
      "loss": 0.2543,
      "step": 6084
    },
    {
      "epoch": 0.09634719825197524,
      "grad_norm": 0.3210659325122833,
      "learning_rate": 9.036528017480248e-06,
      "loss": 0.2001,
      "step": 6085
    },
    {
      "epoch": 0.0963630318096173,
      "grad_norm": 0.3810935914516449,
      "learning_rate": 9.036369681903829e-06,
      "loss": 0.1042,
      "step": 6086
    },
    {
      "epoch": 0.09637886536725937,
      "grad_norm": 0.3393075466156006,
      "learning_rate": 9.036211346327406e-06,
      "loss": 0.3196,
      "step": 6087
    },
    {
      "epoch": 0.09639469892490143,
      "grad_norm": 0.9438132643699646,
      "learning_rate": 9.036053010750986e-06,
      "loss": 1.0048,
      "step": 6088
    },
    {
      "epoch": 0.0964105324825435,
      "grad_norm": 1.1572179794311523,
      "learning_rate": 9.035894675174566e-06,
      "loss": 1.2358,
      "step": 6089
    },
    {
      "epoch": 0.09642636604018556,
      "grad_norm": 0.489299476146698,
      "learning_rate": 9.035736339598145e-06,
      "loss": 0.0787,
      "step": 6090
    },
    {
      "epoch": 0.09644219959782764,
      "grad_norm": 0.14820654690265656,
      "learning_rate": 9.035578004021724e-06,
      "loss": 0.0901,
      "step": 6091
    },
    {
      "epoch": 0.0964580331554697,
      "grad_norm": 0.019596586003899574,
      "learning_rate": 9.035419668445304e-06,
      "loss": 0.0013,
      "step": 6092
    },
    {
      "epoch": 0.09647386671311177,
      "grad_norm": 0.2848913073539734,
      "learning_rate": 9.035261332868883e-06,
      "loss": 0.115,
      "step": 6093
    },
    {
      "epoch": 0.09648970027075383,
      "grad_norm": 0.21933545172214508,
      "learning_rate": 9.035102997292462e-06,
      "loss": 0.1837,
      "step": 6094
    },
    {
      "epoch": 0.0965055338283959,
      "grad_norm": 0.2205103635787964,
      "learning_rate": 9.034944661716042e-06,
      "loss": 0.135,
      "step": 6095
    },
    {
      "epoch": 0.09652136738603796,
      "grad_norm": 0.2361420840024948,
      "learning_rate": 9.03478632613962e-06,
      "loss": 0.1029,
      "step": 6096
    },
    {
      "epoch": 0.09653720094368004,
      "grad_norm": 0.27375438809394836,
      "learning_rate": 9.0346279905632e-06,
      "loss": 0.1469,
      "step": 6097
    },
    {
      "epoch": 0.0965530345013221,
      "grad_norm": 0.012045162729918957,
      "learning_rate": 9.03446965498678e-06,
      "loss": 0.0006,
      "step": 6098
    },
    {
      "epoch": 0.09656886805896417,
      "grad_norm": 0.2132333219051361,
      "learning_rate": 9.034311319410359e-06,
      "loss": 0.0272,
      "step": 6099
    },
    {
      "epoch": 0.09658470161660623,
      "grad_norm": 0.01121042761951685,
      "learning_rate": 9.034152983833938e-06,
      "loss": 0.0008,
      "step": 6100
    },
    {
      "epoch": 0.0966005351742483,
      "grad_norm": 0.18096235394477844,
      "learning_rate": 9.033994648257519e-06,
      "loss": 0.0198,
      "step": 6101
    },
    {
      "epoch": 0.09661636873189036,
      "grad_norm": 0.4647926688194275,
      "learning_rate": 9.033836312681096e-06,
      "loss": 0.1616,
      "step": 6102
    },
    {
      "epoch": 0.09663220228953244,
      "grad_norm": 0.23007608950138092,
      "learning_rate": 9.033677977104677e-06,
      "loss": 0.1076,
      "step": 6103
    },
    {
      "epoch": 0.0966480358471745,
      "grad_norm": 0.25888171792030334,
      "learning_rate": 9.033519641528256e-06,
      "loss": 0.1673,
      "step": 6104
    },
    {
      "epoch": 0.09666386940481657,
      "grad_norm": 0.24535198509693146,
      "learning_rate": 9.033361305951835e-06,
      "loss": 0.1436,
      "step": 6105
    },
    {
      "epoch": 0.09667970296245863,
      "grad_norm": 0.16968046128749847,
      "learning_rate": 9.033202970375414e-06,
      "loss": 0.0875,
      "step": 6106
    },
    {
      "epoch": 0.0966955365201007,
      "grad_norm": 0.5161249041557312,
      "learning_rate": 9.033044634798995e-06,
      "loss": 0.3811,
      "step": 6107
    },
    {
      "epoch": 0.09671137007774276,
      "grad_norm": 0.2663915157318115,
      "learning_rate": 9.032886299222572e-06,
      "loss": 0.1654,
      "step": 6108
    },
    {
      "epoch": 0.09672720363538484,
      "grad_norm": 0.37371471524238586,
      "learning_rate": 9.032727963646153e-06,
      "loss": 0.2353,
      "step": 6109
    },
    {
      "epoch": 0.0967430371930269,
      "grad_norm": 0.2012779712677002,
      "learning_rate": 9.032569628069732e-06,
      "loss": 0.1576,
      "step": 6110
    },
    {
      "epoch": 0.09675887075066897,
      "grad_norm": 0.014732559211552143,
      "learning_rate": 9.032411292493311e-06,
      "loss": 0.0008,
      "step": 6111
    },
    {
      "epoch": 0.09677470430831103,
      "grad_norm": 0.3121284544467926,
      "learning_rate": 9.03225295691689e-06,
      "loss": 0.1415,
      "step": 6112
    },
    {
      "epoch": 0.0967905378659531,
      "grad_norm": 0.1929328292608261,
      "learning_rate": 9.03209462134047e-06,
      "loss": 0.0644,
      "step": 6113
    },
    {
      "epoch": 0.09680637142359516,
      "grad_norm": 1.6054483652114868,
      "learning_rate": 9.031936285764048e-06,
      "loss": 0.0293,
      "step": 6114
    },
    {
      "epoch": 0.09682220498123724,
      "grad_norm": 0.3811565637588501,
      "learning_rate": 9.031777950187627e-06,
      "loss": 0.0499,
      "step": 6115
    },
    {
      "epoch": 0.0968380385388793,
      "grad_norm": 0.04892337694764137,
      "learning_rate": 9.031619614611208e-06,
      "loss": 0.0028,
      "step": 6116
    },
    {
      "epoch": 0.09685387209652137,
      "grad_norm": 0.419807106256485,
      "learning_rate": 9.031461279034787e-06,
      "loss": 0.1556,
      "step": 6117
    },
    {
      "epoch": 0.09686970565416343,
      "grad_norm": 0.588877260684967,
      "learning_rate": 9.031302943458366e-06,
      "loss": 0.0311,
      "step": 6118
    },
    {
      "epoch": 0.0968855392118055,
      "grad_norm": 0.25234267115592957,
      "learning_rate": 9.031144607881945e-06,
      "loss": 0.2062,
      "step": 6119
    },
    {
      "epoch": 0.09690137276944756,
      "grad_norm": 0.0004667233442887664,
      "learning_rate": 9.030986272305525e-06,
      "loss": 0.0,
      "step": 6120
    },
    {
      "epoch": 0.09691720632708964,
      "grad_norm": 0.15164168179035187,
      "learning_rate": 9.030827936729104e-06,
      "loss": 0.03,
      "step": 6121
    },
    {
      "epoch": 0.0969330398847317,
      "grad_norm": 0.13712471723556519,
      "learning_rate": 9.030669601152684e-06,
      "loss": 0.0698,
      "step": 6122
    },
    {
      "epoch": 0.09694887344237377,
      "grad_norm": 0.5442533493041992,
      "learning_rate": 9.030511265576263e-06,
      "loss": 0.1095,
      "step": 6123
    },
    {
      "epoch": 0.09696470700001583,
      "grad_norm": 0.07923586666584015,
      "learning_rate": 9.030352929999843e-06,
      "loss": 0.0081,
      "step": 6124
    },
    {
      "epoch": 0.0969805405576579,
      "grad_norm": 0.09639634937047958,
      "learning_rate": 9.030194594423422e-06,
      "loss": 0.0115,
      "step": 6125
    },
    {
      "epoch": 0.09699637411529996,
      "grad_norm": 0.064958356320858,
      "learning_rate": 9.030036258847e-06,
      "loss": 0.0107,
      "step": 6126
    },
    {
      "epoch": 0.09701220767294204,
      "grad_norm": 0.01059659942984581,
      "learning_rate": 9.02987792327058e-06,
      "loss": 0.0006,
      "step": 6127
    },
    {
      "epoch": 0.0970280412305841,
      "grad_norm": 0.3219563961029053,
      "learning_rate": 9.02971958769416e-06,
      "loss": 0.3746,
      "step": 6128
    },
    {
      "epoch": 0.09704387478822617,
      "grad_norm": 0.013478338718414307,
      "learning_rate": 9.02956125211774e-06,
      "loss": 0.0009,
      "step": 6129
    },
    {
      "epoch": 0.09705970834586823,
      "grad_norm": 0.2306678742170334,
      "learning_rate": 9.029402916541319e-06,
      "loss": 0.1129,
      "step": 6130
    },
    {
      "epoch": 0.0970755419035103,
      "grad_norm": 0.28636154532432556,
      "learning_rate": 9.029244580964898e-06,
      "loss": 0.2298,
      "step": 6131
    },
    {
      "epoch": 0.09709137546115236,
      "grad_norm": 0.18551987409591675,
      "learning_rate": 9.029086245388477e-06,
      "loss": 0.0993,
      "step": 6132
    },
    {
      "epoch": 0.09710720901879444,
      "grad_norm": 0.010934630408883095,
      "learning_rate": 9.028927909812056e-06,
      "loss": 0.0006,
      "step": 6133
    },
    {
      "epoch": 0.0971230425764365,
      "grad_norm": 0.1793818324804306,
      "learning_rate": 9.028769574235637e-06,
      "loss": 0.0544,
      "step": 6134
    },
    {
      "epoch": 0.09713887613407857,
      "grad_norm": 0.04523009434342384,
      "learning_rate": 9.028611238659216e-06,
      "loss": 0.0039,
      "step": 6135
    },
    {
      "epoch": 0.09715470969172063,
      "grad_norm": 0.00841267965734005,
      "learning_rate": 9.028452903082793e-06,
      "loss": 0.0004,
      "step": 6136
    },
    {
      "epoch": 0.0971705432493627,
      "grad_norm": 0.0001672753569437191,
      "learning_rate": 9.028294567506374e-06,
      "loss": 0.0,
      "step": 6137
    },
    {
      "epoch": 0.09718637680700476,
      "grad_norm": 0.3060021698474884,
      "learning_rate": 9.028136231929953e-06,
      "loss": 0.2036,
      "step": 6138
    },
    {
      "epoch": 0.09720221036464684,
      "grad_norm": 0.2346041351556778,
      "learning_rate": 9.027977896353532e-06,
      "loss": 0.0813,
      "step": 6139
    },
    {
      "epoch": 0.0972180439222889,
      "grad_norm": 0.2478322684764862,
      "learning_rate": 9.027819560777111e-06,
      "loss": 0.0493,
      "step": 6140
    },
    {
      "epoch": 0.09723387747993097,
      "grad_norm": 0.1951613426208496,
      "learning_rate": 9.027661225200692e-06,
      "loss": 0.1232,
      "step": 6141
    },
    {
      "epoch": 0.09724971103757303,
      "grad_norm": 0.26278895139694214,
      "learning_rate": 9.02750288962427e-06,
      "loss": 0.1477,
      "step": 6142
    },
    {
      "epoch": 0.0972655445952151,
      "grad_norm": 0.3836963176727295,
      "learning_rate": 9.02734455404785e-06,
      "loss": 0.2038,
      "step": 6143
    },
    {
      "epoch": 0.09728137815285716,
      "grad_norm": 0.421808660030365,
      "learning_rate": 9.02718621847143e-06,
      "loss": 0.3633,
      "step": 6144
    },
    {
      "epoch": 0.09729721171049924,
      "grad_norm": 0.25306758284568787,
      "learning_rate": 9.027027882895008e-06,
      "loss": 0.0725,
      "step": 6145
    },
    {
      "epoch": 0.0973130452681413,
      "grad_norm": 0.00016967453120741993,
      "learning_rate": 9.026869547318587e-06,
      "loss": 0.0,
      "step": 6146
    },
    {
      "epoch": 0.09732887882578337,
      "grad_norm": 1.1316232681274414,
      "learning_rate": 9.026711211742168e-06,
      "loss": 0.3027,
      "step": 6147
    },
    {
      "epoch": 0.09734471238342543,
      "grad_norm": 0.28471478819847107,
      "learning_rate": 9.026552876165746e-06,
      "loss": 0.0403,
      "step": 6148
    },
    {
      "epoch": 0.0973605459410675,
      "grad_norm": 0.214259535074234,
      "learning_rate": 9.026394540589326e-06,
      "loss": 0.0587,
      "step": 6149
    },
    {
      "epoch": 0.09737637949870956,
      "grad_norm": 0.2654092609882355,
      "learning_rate": 9.026236205012905e-06,
      "loss": 0.1041,
      "step": 6150
    },
    {
      "epoch": 0.09739221305635164,
      "grad_norm": 0.9878187775611877,
      "learning_rate": 9.026077869436484e-06,
      "loss": 0.0507,
      "step": 6151
    },
    {
      "epoch": 0.0974080466139937,
      "grad_norm": 0.5545571446418762,
      "learning_rate": 9.025919533860064e-06,
      "loss": 0.7575,
      "step": 6152
    },
    {
      "epoch": 0.09742388017163577,
      "grad_norm": 0.004630229435861111,
      "learning_rate": 9.025761198283644e-06,
      "loss": 0.0003,
      "step": 6153
    },
    {
      "epoch": 0.09743971372927783,
      "grad_norm": 0.46794745326042175,
      "learning_rate": 9.025602862707222e-06,
      "loss": 0.153,
      "step": 6154
    },
    {
      "epoch": 0.0974555472869199,
      "grad_norm": 0.005107771139591932,
      "learning_rate": 9.025444527130803e-06,
      "loss": 0.0001,
      "step": 6155
    },
    {
      "epoch": 0.09747138084456196,
      "grad_norm": 0.3720613121986389,
      "learning_rate": 9.025286191554382e-06,
      "loss": 0.0402,
      "step": 6156
    },
    {
      "epoch": 0.09748721440220404,
      "grad_norm": 0.0030837280210107565,
      "learning_rate": 9.02512785597796e-06,
      "loss": 0.0001,
      "step": 6157
    },
    {
      "epoch": 0.0975030479598461,
      "grad_norm": 0.2923755943775177,
      "learning_rate": 9.02496952040154e-06,
      "loss": 0.32,
      "step": 6158
    },
    {
      "epoch": 0.09751888151748817,
      "grad_norm": 4.838469249079935e-05,
      "learning_rate": 9.024811184825119e-06,
      "loss": 0.0,
      "step": 6159
    },
    {
      "epoch": 0.09753471507513023,
      "grad_norm": 0.2546415627002716,
      "learning_rate": 9.024652849248698e-06,
      "loss": 0.1328,
      "step": 6160
    },
    {
      "epoch": 0.0975505486327723,
      "grad_norm": 0.28623268008232117,
      "learning_rate": 9.024494513672277e-06,
      "loss": 0.1315,
      "step": 6161
    },
    {
      "epoch": 0.09756638219041436,
      "grad_norm": 0.17414352297782898,
      "learning_rate": 9.024336178095858e-06,
      "loss": 0.0451,
      "step": 6162
    },
    {
      "epoch": 0.09758221574805644,
      "grad_norm": 0.3778725266456604,
      "learning_rate": 9.024177842519435e-06,
      "loss": 0.1015,
      "step": 6163
    },
    {
      "epoch": 0.0975980493056985,
      "grad_norm": 0.037414729595184326,
      "learning_rate": 9.024019506943016e-06,
      "loss": 0.0024,
      "step": 6164
    },
    {
      "epoch": 0.09761388286334056,
      "grad_norm": 0.40105482935905457,
      "learning_rate": 9.023861171366595e-06,
      "loss": 0.3105,
      "step": 6165
    },
    {
      "epoch": 0.09762971642098263,
      "grad_norm": 0.3482997417449951,
      "learning_rate": 9.023702835790174e-06,
      "loss": 0.0703,
      "step": 6166
    },
    {
      "epoch": 0.0976455499786247,
      "grad_norm": 0.26885759830474854,
      "learning_rate": 9.023544500213753e-06,
      "loss": 0.0505,
      "step": 6167
    },
    {
      "epoch": 0.09766138353626676,
      "grad_norm": 0.9387511610984802,
      "learning_rate": 9.023386164637334e-06,
      "loss": 0.2197,
      "step": 6168
    },
    {
      "epoch": 0.09767721709390884,
      "grad_norm": 0.4706960916519165,
      "learning_rate": 9.023227829060911e-06,
      "loss": 0.067,
      "step": 6169
    },
    {
      "epoch": 0.0976930506515509,
      "grad_norm": 0.13773515820503235,
      "learning_rate": 9.023069493484492e-06,
      "loss": 0.0549,
      "step": 6170
    },
    {
      "epoch": 0.09770888420919296,
      "grad_norm": 0.36171281337738037,
      "learning_rate": 9.022911157908071e-06,
      "loss": 0.0538,
      "step": 6171
    },
    {
      "epoch": 0.09772471776683503,
      "grad_norm": 0.47910192608833313,
      "learning_rate": 9.02275282233165e-06,
      "loss": 0.289,
      "step": 6172
    },
    {
      "epoch": 0.09774055132447709,
      "grad_norm": 0.6275389790534973,
      "learning_rate": 9.02259448675523e-06,
      "loss": 0.3105,
      "step": 6173
    },
    {
      "epoch": 0.09775638488211916,
      "grad_norm": 0.2913684546947479,
      "learning_rate": 9.02243615117881e-06,
      "loss": 0.1654,
      "step": 6174
    },
    {
      "epoch": 0.09777221843976124,
      "grad_norm": 0.015159811824560165,
      "learning_rate": 9.022277815602387e-06,
      "loss": 0.0003,
      "step": 6175
    },
    {
      "epoch": 0.0977880519974033,
      "grad_norm": 0.4270031750202179,
      "learning_rate": 9.022119480025968e-06,
      "loss": 0.3895,
      "step": 6176
    },
    {
      "epoch": 0.09780388555504536,
      "grad_norm": 0.17611537873744965,
      "learning_rate": 9.021961144449547e-06,
      "loss": 0.1108,
      "step": 6177
    },
    {
      "epoch": 0.09781971911268743,
      "grad_norm": 0.27907493710517883,
      "learning_rate": 9.021802808873126e-06,
      "loss": 0.2065,
      "step": 6178
    },
    {
      "epoch": 0.09783555267032949,
      "grad_norm": 0.00017530241166241467,
      "learning_rate": 9.021644473296705e-06,
      "loss": 0.0,
      "step": 6179
    },
    {
      "epoch": 0.09785138622797156,
      "grad_norm": 0.2595332860946655,
      "learning_rate": 9.021486137720286e-06,
      "loss": 0.1953,
      "step": 6180
    },
    {
      "epoch": 0.09786721978561363,
      "grad_norm": 0.4622271955013275,
      "learning_rate": 9.021327802143864e-06,
      "loss": 0.2479,
      "step": 6181
    },
    {
      "epoch": 0.0978830533432557,
      "grad_norm": 0.03988829627633095,
      "learning_rate": 9.021169466567444e-06,
      "loss": 0.0072,
      "step": 6182
    },
    {
      "epoch": 0.09789888690089776,
      "grad_norm": 0.020509835332632065,
      "learning_rate": 9.021011130991024e-06,
      "loss": 0.0012,
      "step": 6183
    },
    {
      "epoch": 0.09791472045853983,
      "grad_norm": 0.5985223650932312,
      "learning_rate": 9.020852795414603e-06,
      "loss": 0.1194,
      "step": 6184
    },
    {
      "epoch": 0.09793055401618189,
      "grad_norm": 0.1288127899169922,
      "learning_rate": 9.020694459838182e-06,
      "loss": 0.0165,
      "step": 6185
    },
    {
      "epoch": 0.09794638757382396,
      "grad_norm": 0.2542615234851837,
      "learning_rate": 9.02053612426176e-06,
      "loss": 0.4037,
      "step": 6186
    },
    {
      "epoch": 0.09796222113146603,
      "grad_norm": 0.33186209201812744,
      "learning_rate": 9.02037778868534e-06,
      "loss": 0.1493,
      "step": 6187
    },
    {
      "epoch": 0.0979780546891081,
      "grad_norm": 0.007142354268580675,
      "learning_rate": 9.020219453108919e-06,
      "loss": 0.0004,
      "step": 6188
    },
    {
      "epoch": 0.09799388824675016,
      "grad_norm": 0.3978719711303711,
      "learning_rate": 9.0200611175325e-06,
      "loss": 0.1838,
      "step": 6189
    },
    {
      "epoch": 0.09800972180439223,
      "grad_norm": 0.03878350555896759,
      "learning_rate": 9.019902781956079e-06,
      "loss": 0.0059,
      "step": 6190
    },
    {
      "epoch": 0.09802555536203429,
      "grad_norm": 0.4595044255256653,
      "learning_rate": 9.019744446379658e-06,
      "loss": 0.3494,
      "step": 6191
    },
    {
      "epoch": 0.09804138891967636,
      "grad_norm": 0.03551669046282768,
      "learning_rate": 9.019586110803237e-06,
      "loss": 0.0018,
      "step": 6192
    },
    {
      "epoch": 0.09805722247731843,
      "grad_norm": 0.4636828899383545,
      "learning_rate": 9.019427775226816e-06,
      "loss": 0.5197,
      "step": 6193
    },
    {
      "epoch": 0.0980730560349605,
      "grad_norm": 0.16134344041347504,
      "learning_rate": 9.019269439650395e-06,
      "loss": 0.0818,
      "step": 6194
    },
    {
      "epoch": 0.09808888959260256,
      "grad_norm": 0.12822939455509186,
      "learning_rate": 9.019111104073976e-06,
      "loss": 0.0517,
      "step": 6195
    },
    {
      "epoch": 0.09810472315024463,
      "grad_norm": 0.3658200204372406,
      "learning_rate": 9.018952768497555e-06,
      "loss": 0.3472,
      "step": 6196
    },
    {
      "epoch": 0.09812055670788669,
      "grad_norm": 0.0509086512029171,
      "learning_rate": 9.018794432921134e-06,
      "loss": 0.0023,
      "step": 6197
    },
    {
      "epoch": 0.09813639026552876,
      "grad_norm": 0.42936253547668457,
      "learning_rate": 9.018636097344713e-06,
      "loss": 0.1347,
      "step": 6198
    },
    {
      "epoch": 0.09815222382317083,
      "grad_norm": 0.021584339439868927,
      "learning_rate": 9.018477761768292e-06,
      "loss": 0.0012,
      "step": 6199
    },
    {
      "epoch": 0.0981680573808129,
      "grad_norm": 0.09984354674816132,
      "learning_rate": 9.018319426191871e-06,
      "loss": 0.0116,
      "step": 6200
    },
    {
      "epoch": 0.09818389093845496,
      "grad_norm": 0.4820712208747864,
      "learning_rate": 9.018161090615452e-06,
      "loss": 0.659,
      "step": 6201
    },
    {
      "epoch": 0.09819972449609703,
      "grad_norm": 0.00020658982975874096,
      "learning_rate": 9.018002755039031e-06,
      "loss": 0.0,
      "step": 6202
    },
    {
      "epoch": 0.09821555805373909,
      "grad_norm": 0.1434026062488556,
      "learning_rate": 9.01784441946261e-06,
      "loss": 0.0121,
      "step": 6203
    },
    {
      "epoch": 0.09823139161138116,
      "grad_norm": 0.04341677203774452,
      "learning_rate": 9.01768608388619e-06,
      "loss": 0.0029,
      "step": 6204
    },
    {
      "epoch": 0.09824722516902323,
      "grad_norm": 0.2861112654209137,
      "learning_rate": 9.017527748309768e-06,
      "loss": 0.1946,
      "step": 6205
    },
    {
      "epoch": 0.0982630587266653,
      "grad_norm": 0.2764476537704468,
      "learning_rate": 9.017369412733347e-06,
      "loss": 0.1766,
      "step": 6206
    },
    {
      "epoch": 0.09827889228430736,
      "grad_norm": 0.14332187175750732,
      "learning_rate": 9.017211077156928e-06,
      "loss": 0.0997,
      "step": 6207
    },
    {
      "epoch": 0.09829472584194943,
      "grad_norm": 0.09267512708902359,
      "learning_rate": 9.017052741580507e-06,
      "loss": 0.0028,
      "step": 6208
    },
    {
      "epoch": 0.09831055939959149,
      "grad_norm": 0.4948953092098236,
      "learning_rate": 9.016894406004085e-06,
      "loss": 0.1205,
      "step": 6209
    },
    {
      "epoch": 0.09832639295723355,
      "grad_norm": 0.323596715927124,
      "learning_rate": 9.016736070427665e-06,
      "loss": 0.27,
      "step": 6210
    },
    {
      "epoch": 0.09834222651487563,
      "grad_norm": 0.2570343315601349,
      "learning_rate": 9.016577734851245e-06,
      "loss": 0.0677,
      "step": 6211
    },
    {
      "epoch": 0.0983580600725177,
      "grad_norm": 0.07675467431545258,
      "learning_rate": 9.016419399274824e-06,
      "loss": 0.0113,
      "step": 6212
    },
    {
      "epoch": 0.09837389363015976,
      "grad_norm": 0.3162689507007599,
      "learning_rate": 9.016261063698403e-06,
      "loss": 0.1953,
      "step": 6213
    },
    {
      "epoch": 0.09838972718780183,
      "grad_norm": 0.29112547636032104,
      "learning_rate": 9.016102728121983e-06,
      "loss": 0.2,
      "step": 6214
    },
    {
      "epoch": 0.09840556074544389,
      "grad_norm": 0.29223623871803284,
      "learning_rate": 9.01594439254556e-06,
      "loss": 0.1616,
      "step": 6215
    },
    {
      "epoch": 0.09842139430308595,
      "grad_norm": 0.42483779788017273,
      "learning_rate": 9.015786056969142e-06,
      "loss": 0.1185,
      "step": 6216
    },
    {
      "epoch": 0.09843722786072803,
      "grad_norm": 0.19223995506763458,
      "learning_rate": 9.01562772139272e-06,
      "loss": 0.0906,
      "step": 6217
    },
    {
      "epoch": 0.0984530614183701,
      "grad_norm": 0.00035373939317651093,
      "learning_rate": 9.0154693858163e-06,
      "loss": 0.0,
      "step": 6218
    },
    {
      "epoch": 0.09846889497601216,
      "grad_norm": 0.3134836256504059,
      "learning_rate": 9.015311050239879e-06,
      "loss": 0.1524,
      "step": 6219
    },
    {
      "epoch": 0.09848472853365423,
      "grad_norm": 0.488122820854187,
      "learning_rate": 9.015152714663458e-06,
      "loss": 0.0431,
      "step": 6220
    },
    {
      "epoch": 0.09850056209129629,
      "grad_norm": 0.00047177993110381067,
      "learning_rate": 9.014994379087037e-06,
      "loss": 0.0,
      "step": 6221
    },
    {
      "epoch": 0.09851639564893835,
      "grad_norm": 0.07139195501804352,
      "learning_rate": 9.014836043510618e-06,
      "loss": 0.021,
      "step": 6222
    },
    {
      "epoch": 0.09853222920658043,
      "grad_norm": 0.03657263144850731,
      "learning_rate": 9.014677707934197e-06,
      "loss": 0.0024,
      "step": 6223
    },
    {
      "epoch": 0.0985480627642225,
      "grad_norm": 0.12181965261697769,
      "learning_rate": 9.014519372357776e-06,
      "loss": 0.0522,
      "step": 6224
    },
    {
      "epoch": 0.09856389632186456,
      "grad_norm": 0.2980692386627197,
      "learning_rate": 9.014361036781355e-06,
      "loss": 0.0628,
      "step": 6225
    },
    {
      "epoch": 0.09857972987950663,
      "grad_norm": 0.7464076280593872,
      "learning_rate": 9.014202701204934e-06,
      "loss": 0.1161,
      "step": 6226
    },
    {
      "epoch": 0.09859556343714869,
      "grad_norm": 0.6666051149368286,
      "learning_rate": 9.014044365628513e-06,
      "loss": 0.0916,
      "step": 6227
    },
    {
      "epoch": 0.09861139699479075,
      "grad_norm": 0.04010261595249176,
      "learning_rate": 9.013886030052094e-06,
      "loss": 0.001,
      "step": 6228
    },
    {
      "epoch": 0.09862723055243283,
      "grad_norm": 0.08317381888628006,
      "learning_rate": 9.013727694475673e-06,
      "loss": 0.005,
      "step": 6229
    },
    {
      "epoch": 0.0986430641100749,
      "grad_norm": 0.4276309013366699,
      "learning_rate": 9.013569358899252e-06,
      "loss": 0.2166,
      "step": 6230
    },
    {
      "epoch": 0.09865889766771696,
      "grad_norm": 0.3175608813762665,
      "learning_rate": 9.013411023322831e-06,
      "loss": 0.1429,
      "step": 6231
    },
    {
      "epoch": 0.09867473122535902,
      "grad_norm": 0.23395586013793945,
      "learning_rate": 9.01325268774641e-06,
      "loss": 0.2004,
      "step": 6232
    },
    {
      "epoch": 0.09869056478300109,
      "grad_norm": 0.40100806951522827,
      "learning_rate": 9.01309435216999e-06,
      "loss": 0.1706,
      "step": 6233
    },
    {
      "epoch": 0.09870639834064315,
      "grad_norm": 0.47796034812927246,
      "learning_rate": 9.012936016593568e-06,
      "loss": 0.6374,
      "step": 6234
    },
    {
      "epoch": 0.09872223189828523,
      "grad_norm": 0.09704726934432983,
      "learning_rate": 9.01277768101715e-06,
      "loss": 0.0024,
      "step": 6235
    },
    {
      "epoch": 0.0987380654559273,
      "grad_norm": 0.20846492052078247,
      "learning_rate": 9.012619345440727e-06,
      "loss": 0.1126,
      "step": 6236
    },
    {
      "epoch": 0.09875389901356936,
      "grad_norm": 0.2837198078632355,
      "learning_rate": 9.012461009864307e-06,
      "loss": 0.0763,
      "step": 6237
    },
    {
      "epoch": 0.09876973257121142,
      "grad_norm": 0.559339702129364,
      "learning_rate": 9.012302674287886e-06,
      "loss": 0.4519,
      "step": 6238
    },
    {
      "epoch": 0.09878556612885349,
      "grad_norm": 0.149931401014328,
      "learning_rate": 9.012144338711466e-06,
      "loss": 0.0056,
      "step": 6239
    },
    {
      "epoch": 0.09880139968649555,
      "grad_norm": 0.0005089720361866057,
      "learning_rate": 9.011986003135045e-06,
      "loss": 0.0,
      "step": 6240
    },
    {
      "epoch": 0.09881723324413763,
      "grad_norm": 0.25857263803482056,
      "learning_rate": 9.011827667558625e-06,
      "loss": 0.2107,
      "step": 6241
    },
    {
      "epoch": 0.0988330668017797,
      "grad_norm": 0.40199124813079834,
      "learning_rate": 9.011669331982203e-06,
      "loss": 0.4108,
      "step": 6242
    },
    {
      "epoch": 0.09884890035942176,
      "grad_norm": 0.012037589214742184,
      "learning_rate": 9.011510996405784e-06,
      "loss": 0.0007,
      "step": 6243
    },
    {
      "epoch": 0.09886473391706382,
      "grad_norm": 0.00022387283388525248,
      "learning_rate": 9.011352660829363e-06,
      "loss": 0.0,
      "step": 6244
    },
    {
      "epoch": 0.09888056747470589,
      "grad_norm": 0.32239678502082825,
      "learning_rate": 9.011194325252942e-06,
      "loss": 0.2081,
      "step": 6245
    },
    {
      "epoch": 0.09889640103234795,
      "grad_norm": 0.4114382863044739,
      "learning_rate": 9.01103598967652e-06,
      "loss": 0.201,
      "step": 6246
    },
    {
      "epoch": 0.09891223458999003,
      "grad_norm": 0.13573376834392548,
      "learning_rate": 9.010877654100102e-06,
      "loss": 0.0446,
      "step": 6247
    },
    {
      "epoch": 0.0989280681476321,
      "grad_norm": 0.014006957411766052,
      "learning_rate": 9.010719318523679e-06,
      "loss": 0.0005,
      "step": 6248
    },
    {
      "epoch": 0.09894390170527416,
      "grad_norm": 0.04777282103896141,
      "learning_rate": 9.01056098294726e-06,
      "loss": 0.0013,
      "step": 6249
    },
    {
      "epoch": 0.09895973526291622,
      "grad_norm": 0.20792099833488464,
      "learning_rate": 9.010402647370839e-06,
      "loss": 0.0973,
      "step": 6250
    },
    {
      "epoch": 0.09897556882055829,
      "grad_norm": 0.00032060215016826987,
      "learning_rate": 9.010244311794418e-06,
      "loss": 0.0,
      "step": 6251
    },
    {
      "epoch": 0.09899140237820035,
      "grad_norm": 0.3235965967178345,
      "learning_rate": 9.010085976217997e-06,
      "loss": 0.1072,
      "step": 6252
    },
    {
      "epoch": 0.09900723593584243,
      "grad_norm": 0.030355099588632584,
      "learning_rate": 9.009927640641578e-06,
      "loss": 0.0017,
      "step": 6253
    },
    {
      "epoch": 0.0990230694934845,
      "grad_norm": 0.022387409582734108,
      "learning_rate": 9.009769305065155e-06,
      "loss": 0.0002,
      "step": 6254
    },
    {
      "epoch": 0.09903890305112656,
      "grad_norm": 0.006870317738503218,
      "learning_rate": 9.009610969488736e-06,
      "loss": 0.0004,
      "step": 6255
    },
    {
      "epoch": 0.09905473660876862,
      "grad_norm": 0.38468149304389954,
      "learning_rate": 9.009452633912315e-06,
      "loss": 0.5136,
      "step": 6256
    },
    {
      "epoch": 0.09907057016641069,
      "grad_norm": 0.6393344402313232,
      "learning_rate": 9.009294298335894e-06,
      "loss": 0.8955,
      "step": 6257
    },
    {
      "epoch": 0.09908640372405275,
      "grad_norm": 0.024501213803887367,
      "learning_rate": 9.009135962759473e-06,
      "loss": 0.0013,
      "step": 6258
    },
    {
      "epoch": 0.09910223728169483,
      "grad_norm": 0.15300533175468445,
      "learning_rate": 9.008977627183052e-06,
      "loss": 0.0486,
      "step": 6259
    },
    {
      "epoch": 0.0991180708393369,
      "grad_norm": 0.586739182472229,
      "learning_rate": 9.008819291606631e-06,
      "loss": 0.0583,
      "step": 6260
    },
    {
      "epoch": 0.09913390439697896,
      "grad_norm": 0.28302785754203796,
      "learning_rate": 9.00866095603021e-06,
      "loss": 0.1946,
      "step": 6261
    },
    {
      "epoch": 0.09914973795462102,
      "grad_norm": 0.03969438374042511,
      "learning_rate": 9.008502620453791e-06,
      "loss": 0.0026,
      "step": 6262
    },
    {
      "epoch": 0.09916557151226309,
      "grad_norm": 0.32305577397346497,
      "learning_rate": 9.00834428487737e-06,
      "loss": 0.2183,
      "step": 6263
    },
    {
      "epoch": 0.09918140506990515,
      "grad_norm": 0.31357795000076294,
      "learning_rate": 9.00818594930095e-06,
      "loss": 0.7033,
      "step": 6264
    },
    {
      "epoch": 0.09919723862754723,
      "grad_norm": 0.16502702236175537,
      "learning_rate": 9.008027613724528e-06,
      "loss": 0.0495,
      "step": 6265
    },
    {
      "epoch": 0.0992130721851893,
      "grad_norm": 0.21978957951068878,
      "learning_rate": 9.007869278148107e-06,
      "loss": 0.0479,
      "step": 6266
    },
    {
      "epoch": 0.09922890574283136,
      "grad_norm": 0.1567992866039276,
      "learning_rate": 9.007710942571687e-06,
      "loss": 0.0681,
      "step": 6267
    },
    {
      "epoch": 0.09924473930047342,
      "grad_norm": 0.440727174282074,
      "learning_rate": 9.007552606995267e-06,
      "loss": 0.4562,
      "step": 6268
    },
    {
      "epoch": 0.09926057285811549,
      "grad_norm": 0.0028251803014427423,
      "learning_rate": 9.007394271418846e-06,
      "loss": 0.0001,
      "step": 6269
    },
    {
      "epoch": 0.09927640641575755,
      "grad_norm": 0.9315571784973145,
      "learning_rate": 9.007235935842425e-06,
      "loss": 0.7577,
      "step": 6270
    },
    {
      "epoch": 0.09929223997339963,
      "grad_norm": 0.0018692855956032872,
      "learning_rate": 9.007077600266005e-06,
      "loss": 0.0001,
      "step": 6271
    },
    {
      "epoch": 0.0993080735310417,
      "grad_norm": 0.25358378887176514,
      "learning_rate": 9.006919264689584e-06,
      "loss": 0.1206,
      "step": 6272
    },
    {
      "epoch": 0.09932390708868376,
      "grad_norm": 0.005466708447784185,
      "learning_rate": 9.006760929113163e-06,
      "loss": 0.0002,
      "step": 6273
    },
    {
      "epoch": 0.09933974064632582,
      "grad_norm": 0.42535266280174255,
      "learning_rate": 9.006602593536743e-06,
      "loss": 0.2759,
      "step": 6274
    },
    {
      "epoch": 0.09935557420396789,
      "grad_norm": 0.07958308607339859,
      "learning_rate": 9.006444257960323e-06,
      "loss": 0.0089,
      "step": 6275
    },
    {
      "epoch": 0.09937140776160995,
      "grad_norm": 0.15866316854953766,
      "learning_rate": 9.006285922383902e-06,
      "loss": 0.023,
      "step": 6276
    },
    {
      "epoch": 0.09938724131925203,
      "grad_norm": 0.03126838058233261,
      "learning_rate": 9.00612758680748e-06,
      "loss": 0.0019,
      "step": 6277
    },
    {
      "epoch": 0.09940307487689409,
      "grad_norm": 0.19535957276821136,
      "learning_rate": 9.00596925123106e-06,
      "loss": 0.0205,
      "step": 6278
    },
    {
      "epoch": 0.09941890843453616,
      "grad_norm": 0.4166700541973114,
      "learning_rate": 9.005810915654639e-06,
      "loss": 0.5471,
      "step": 6279
    },
    {
      "epoch": 0.09943474199217822,
      "grad_norm": 0.37771323323249817,
      "learning_rate": 9.005652580078218e-06,
      "loss": 0.8691,
      "step": 6280
    },
    {
      "epoch": 0.09945057554982029,
      "grad_norm": 0.4909697473049164,
      "learning_rate": 9.005494244501799e-06,
      "loss": 0.2439,
      "step": 6281
    },
    {
      "epoch": 0.09946640910746235,
      "grad_norm": 0.00020243703329470009,
      "learning_rate": 9.005335908925376e-06,
      "loss": 0.0,
      "step": 6282
    },
    {
      "epoch": 0.09948224266510443,
      "grad_norm": 0.047554343938827515,
      "learning_rate": 9.005177573348957e-06,
      "loss": 0.0028,
      "step": 6283
    },
    {
      "epoch": 0.09949807622274649,
      "grad_norm": 0.14206789433956146,
      "learning_rate": 9.005019237772536e-06,
      "loss": 0.0599,
      "step": 6284
    },
    {
      "epoch": 0.09951390978038856,
      "grad_norm": 0.03090360388159752,
      "learning_rate": 9.004860902196115e-06,
      "loss": 0.0023,
      "step": 6285
    },
    {
      "epoch": 0.09952974333803062,
      "grad_norm": 0.10049375891685486,
      "learning_rate": 9.004702566619694e-06,
      "loss": 0.0031,
      "step": 6286
    },
    {
      "epoch": 0.09954557689567269,
      "grad_norm": 0.374611496925354,
      "learning_rate": 9.004544231043273e-06,
      "loss": 0.1362,
      "step": 6287
    },
    {
      "epoch": 0.09956141045331475,
      "grad_norm": 0.3071529269218445,
      "learning_rate": 9.004385895466852e-06,
      "loss": 0.0809,
      "step": 6288
    },
    {
      "epoch": 0.09957724401095683,
      "grad_norm": 0.06417806446552277,
      "learning_rate": 9.004227559890433e-06,
      "loss": 0.0017,
      "step": 6289
    },
    {
      "epoch": 0.09959307756859889,
      "grad_norm": 0.2060805708169937,
      "learning_rate": 9.004069224314012e-06,
      "loss": 0.0681,
      "step": 6290
    },
    {
      "epoch": 0.09960891112624096,
      "grad_norm": 0.00010280551941832528,
      "learning_rate": 9.003910888737591e-06,
      "loss": 0.0,
      "step": 6291
    },
    {
      "epoch": 0.09962474468388302,
      "grad_norm": 0.26185089349746704,
      "learning_rate": 9.00375255316117e-06,
      "loss": 0.0977,
      "step": 6292
    },
    {
      "epoch": 0.09964057824152509,
      "grad_norm": 1.1867433786392212,
      "learning_rate": 9.00359421758475e-06,
      "loss": 0.3132,
      "step": 6293
    },
    {
      "epoch": 0.09965641179916715,
      "grad_norm": 0.005500170402228832,
      "learning_rate": 9.003435882008328e-06,
      "loss": 0.0001,
      "step": 6294
    },
    {
      "epoch": 0.09967224535680923,
      "grad_norm": 0.098712258040905,
      "learning_rate": 9.00327754643191e-06,
      "loss": 0.0029,
      "step": 6295
    },
    {
      "epoch": 0.09968807891445129,
      "grad_norm": 0.3664725124835968,
      "learning_rate": 9.003119210855488e-06,
      "loss": 0.1109,
      "step": 6296
    },
    {
      "epoch": 0.09970391247209336,
      "grad_norm": 0.3684976100921631,
      "learning_rate": 9.002960875279067e-06,
      "loss": 0.1176,
      "step": 6297
    },
    {
      "epoch": 0.09971974602973542,
      "grad_norm": 0.19000118970870972,
      "learning_rate": 9.002802539702646e-06,
      "loss": 0.0148,
      "step": 6298
    },
    {
      "epoch": 0.09973557958737748,
      "grad_norm": 0.11843173950910568,
      "learning_rate": 9.002644204126226e-06,
      "loss": 0.0445,
      "step": 6299
    },
    {
      "epoch": 0.09975141314501955,
      "grad_norm": 0.5868614315986633,
      "learning_rate": 9.002485868549805e-06,
      "loss": 0.4545,
      "step": 6300
    },
    {
      "epoch": 0.09976724670266163,
      "grad_norm": 0.3918284773826599,
      "learning_rate": 9.002327532973385e-06,
      "loss": 0.1989,
      "step": 6301
    },
    {
      "epoch": 0.09978308026030369,
      "grad_norm": 0.330161452293396,
      "learning_rate": 9.002169197396964e-06,
      "loss": 0.0347,
      "step": 6302
    },
    {
      "epoch": 0.09979891381794576,
      "grad_norm": 0.00036846910370513797,
      "learning_rate": 9.002010861820544e-06,
      "loss": 0.0,
      "step": 6303
    },
    {
      "epoch": 0.09981474737558782,
      "grad_norm": 9.345080616185442e-05,
      "learning_rate": 9.001852526244123e-06,
      "loss": 0.0,
      "step": 6304
    },
    {
      "epoch": 0.09983058093322988,
      "grad_norm": 0.22438538074493408,
      "learning_rate": 9.001694190667702e-06,
      "loss": 0.0953,
      "step": 6305
    },
    {
      "epoch": 0.09984641449087195,
      "grad_norm": 0.4223189651966095,
      "learning_rate": 9.00153585509128e-06,
      "loss": 0.015,
      "step": 6306
    },
    {
      "epoch": 0.09986224804851403,
      "grad_norm": 0.18774354457855225,
      "learning_rate": 9.00137751951486e-06,
      "loss": 0.123,
      "step": 6307
    },
    {
      "epoch": 0.09987808160615609,
      "grad_norm": 0.5281735062599182,
      "learning_rate": 9.00121918393844e-06,
      "loss": 0.208,
      "step": 6308
    },
    {
      "epoch": 0.09989391516379816,
      "grad_norm": 0.2429928481578827,
      "learning_rate": 9.001060848362018e-06,
      "loss": 0.0817,
      "step": 6309
    },
    {
      "epoch": 0.09990974872144022,
      "grad_norm": 0.023411711677908897,
      "learning_rate": 9.000902512785599e-06,
      "loss": 0.0011,
      "step": 6310
    },
    {
      "epoch": 0.09992558227908228,
      "grad_norm": 0.4774479568004608,
      "learning_rate": 9.000744177209178e-06,
      "loss": 0.1608,
      "step": 6311
    },
    {
      "epoch": 0.09994141583672435,
      "grad_norm": 0.31440436840057373,
      "learning_rate": 9.000585841632757e-06,
      "loss": 0.1023,
      "step": 6312
    },
    {
      "epoch": 0.09995724939436643,
      "grad_norm": 0.49939247965812683,
      "learning_rate": 9.000427506056336e-06,
      "loss": 0.1085,
      "step": 6313
    },
    {
      "epoch": 0.09997308295200849,
      "grad_norm": 0.6186599731445312,
      "learning_rate": 9.000269170479917e-06,
      "loss": 0.2609,
      "step": 6314
    },
    {
      "epoch": 0.09998891650965055,
      "grad_norm": 0.20435208082199097,
      "learning_rate": 9.000110834903494e-06,
      "loss": 0.0495,
      "step": 6315
    },
    {
      "epoch": 0.10000475006729262,
      "grad_norm": 0.41094887256622314,
      "learning_rate": 8.999952499327075e-06,
      "loss": 0.5588,
      "step": 6316
    },
    {
      "epoch": 0.10002058362493468,
      "grad_norm": 0.34636199474334717,
      "learning_rate": 8.999794163750654e-06,
      "loss": 0.2009,
      "step": 6317
    },
    {
      "epoch": 0.10003641718257675,
      "grad_norm": 0.0001293108653044328,
      "learning_rate": 8.999635828174233e-06,
      "loss": 0.0,
      "step": 6318
    },
    {
      "epoch": 0.10005225074021883,
      "grad_norm": 0.39854857325553894,
      "learning_rate": 8.999477492597812e-06,
      "loss": 0.6756,
      "step": 6319
    },
    {
      "epoch": 0.10006808429786089,
      "grad_norm": 0.008980026468634605,
      "learning_rate": 8.999319157021393e-06,
      "loss": 0.0005,
      "step": 6320
    },
    {
      "epoch": 0.10008391785550295,
      "grad_norm": 0.33142781257629395,
      "learning_rate": 8.99916082144497e-06,
      "loss": 0.2285,
      "step": 6321
    },
    {
      "epoch": 0.10009975141314502,
      "grad_norm": 0.0005427182768471539,
      "learning_rate": 8.999002485868551e-06,
      "loss": 0.0,
      "step": 6322
    },
    {
      "epoch": 0.10011558497078708,
      "grad_norm": 0.2964540421962738,
      "learning_rate": 8.99884415029213e-06,
      "loss": 0.0485,
      "step": 6323
    },
    {
      "epoch": 0.10013141852842915,
      "grad_norm": 0.0002295336889801547,
      "learning_rate": 8.99868581471571e-06,
      "loss": 0.0,
      "step": 6324
    },
    {
      "epoch": 0.10014725208607123,
      "grad_norm": 0.8250855803489685,
      "learning_rate": 8.998527479139288e-06,
      "loss": 0.1992,
      "step": 6325
    },
    {
      "epoch": 0.10016308564371329,
      "grad_norm": 0.009594212286174297,
      "learning_rate": 8.998369143562869e-06,
      "loss": 0.0005,
      "step": 6326
    },
    {
      "epoch": 0.10017891920135535,
      "grad_norm": 0.43106818199157715,
      "learning_rate": 8.998210807986447e-06,
      "loss": 0.1306,
      "step": 6327
    },
    {
      "epoch": 0.10019475275899742,
      "grad_norm": 0.2863118648529053,
      "learning_rate": 8.998052472410026e-06,
      "loss": 0.0375,
      "step": 6328
    },
    {
      "epoch": 0.10021058631663948,
      "grad_norm": 0.0644250214099884,
      "learning_rate": 8.997894136833606e-06,
      "loss": 0.0027,
      "step": 6329
    },
    {
      "epoch": 0.10022641987428155,
      "grad_norm": 0.17259974777698517,
      "learning_rate": 8.997735801257185e-06,
      "loss": 0.0693,
      "step": 6330
    },
    {
      "epoch": 0.10024225343192363,
      "grad_norm": 0.4878336191177368,
      "learning_rate": 8.997577465680765e-06,
      "loss": 0.2432,
      "step": 6331
    },
    {
      "epoch": 0.10025808698956569,
      "grad_norm": 0.2988819479942322,
      "learning_rate": 8.997419130104344e-06,
      "loss": 0.0494,
      "step": 6332
    },
    {
      "epoch": 0.10027392054720775,
      "grad_norm": 0.014112292788922787,
      "learning_rate": 8.997260794527923e-06,
      "loss": 0.0006,
      "step": 6333
    },
    {
      "epoch": 0.10028975410484982,
      "grad_norm": 0.40428072214126587,
      "learning_rate": 8.997102458951502e-06,
      "loss": 0.2505,
      "step": 6334
    },
    {
      "epoch": 0.10030558766249188,
      "grad_norm": 0.11852753907442093,
      "learning_rate": 8.996944123375083e-06,
      "loss": 0.0452,
      "step": 6335
    },
    {
      "epoch": 0.10032142122013395,
      "grad_norm": 0.32573753595352173,
      "learning_rate": 8.996785787798662e-06,
      "loss": 0.1238,
      "step": 6336
    },
    {
      "epoch": 0.10033725477777602,
      "grad_norm": 0.4746648967266083,
      "learning_rate": 8.99662745222224e-06,
      "loss": 0.328,
      "step": 6337
    },
    {
      "epoch": 0.10035308833541809,
      "grad_norm": 0.2573259174823761,
      "learning_rate": 8.99646911664582e-06,
      "loss": 0.1108,
      "step": 6338
    },
    {
      "epoch": 0.10036892189306015,
      "grad_norm": 0.0014538399409502745,
      "learning_rate": 8.996310781069399e-06,
      "loss": 0.0,
      "step": 6339
    },
    {
      "epoch": 0.10038475545070222,
      "grad_norm": 0.21616323292255402,
      "learning_rate": 8.996152445492978e-06,
      "loss": 0.0982,
      "step": 6340
    },
    {
      "epoch": 0.10040058900834428,
      "grad_norm": 0.3766420781612396,
      "learning_rate": 8.995994109916559e-06,
      "loss": 0.4886,
      "step": 6341
    },
    {
      "epoch": 0.10041642256598635,
      "grad_norm": 0.2769160270690918,
      "learning_rate": 8.995835774340138e-06,
      "loss": 0.1182,
      "step": 6342
    },
    {
      "epoch": 0.10043225612362842,
      "grad_norm": 0.40976035594940186,
      "learning_rate": 8.995677438763717e-06,
      "loss": 0.2499,
      "step": 6343
    },
    {
      "epoch": 0.10044808968127049,
      "grad_norm": 0.4780957102775574,
      "learning_rate": 8.995519103187296e-06,
      "loss": 0.4852,
      "step": 6344
    },
    {
      "epoch": 0.10046392323891255,
      "grad_norm": 0.05042428895831108,
      "learning_rate": 8.995360767610875e-06,
      "loss": 0.0033,
      "step": 6345
    },
    {
      "epoch": 0.10047975679655462,
      "grad_norm": 0.1555670201778412,
      "learning_rate": 8.995202432034454e-06,
      "loss": 0.0495,
      "step": 6346
    },
    {
      "epoch": 0.10049559035419668,
      "grad_norm": 0.23220957815647125,
      "learning_rate": 8.995044096458035e-06,
      "loss": 0.2384,
      "step": 6347
    },
    {
      "epoch": 0.10051142391183875,
      "grad_norm": 0.4172797203063965,
      "learning_rate": 8.994885760881614e-06,
      "loss": 0.0564,
      "step": 6348
    },
    {
      "epoch": 0.10052725746948082,
      "grad_norm": 0.29012274742126465,
      "learning_rate": 8.994727425305193e-06,
      "loss": 0.0405,
      "step": 6349
    },
    {
      "epoch": 0.10054309102712289,
      "grad_norm": 0.3856595754623413,
      "learning_rate": 8.994569089728772e-06,
      "loss": 0.2543,
      "step": 6350
    },
    {
      "epoch": 0.10055892458476495,
      "grad_norm": 0.035267848521471024,
      "learning_rate": 8.994410754152351e-06,
      "loss": 0.0004,
      "step": 6351
    },
    {
      "epoch": 0.10057475814240702,
      "grad_norm": 0.31277596950531006,
      "learning_rate": 8.99425241857593e-06,
      "loss": 0.2507,
      "step": 6352
    },
    {
      "epoch": 0.10059059170004908,
      "grad_norm": 0.21454063057899475,
      "learning_rate": 8.99409408299951e-06,
      "loss": 0.0883,
      "step": 6353
    },
    {
      "epoch": 0.10060642525769115,
      "grad_norm": 0.10580253601074219,
      "learning_rate": 8.993935747423088e-06,
      "loss": 0.0039,
      "step": 6354
    },
    {
      "epoch": 0.10062225881533322,
      "grad_norm": 0.22230865061283112,
      "learning_rate": 8.993777411846668e-06,
      "loss": 0.0931,
      "step": 6355
    },
    {
      "epoch": 0.10063809237297529,
      "grad_norm": 0.2375379204750061,
      "learning_rate": 8.993619076270248e-06,
      "loss": 0.113,
      "step": 6356
    },
    {
      "epoch": 0.10065392593061735,
      "grad_norm": 6.81304227327928e-05,
      "learning_rate": 8.993460740693827e-06,
      "loss": 0.0,
      "step": 6357
    },
    {
      "epoch": 0.10066975948825942,
      "grad_norm": 0.5471953749656677,
      "learning_rate": 8.993302405117406e-06,
      "loss": 0.4028,
      "step": 6358
    },
    {
      "epoch": 0.10068559304590148,
      "grad_norm": 0.8411252498626709,
      "learning_rate": 8.993144069540986e-06,
      "loss": 0.3926,
      "step": 6359
    },
    {
      "epoch": 0.10070142660354355,
      "grad_norm": 0.4237256944179535,
      "learning_rate": 8.992985733964565e-06,
      "loss": 0.1664,
      "step": 6360
    },
    {
      "epoch": 0.10071726016118562,
      "grad_norm": 0.22277016937732697,
      "learning_rate": 8.992827398388144e-06,
      "loss": 0.0194,
      "step": 6361
    },
    {
      "epoch": 0.10073309371882769,
      "grad_norm": 0.31572073698043823,
      "learning_rate": 8.992669062811724e-06,
      "loss": 0.0591,
      "step": 6362
    },
    {
      "epoch": 0.10074892727646975,
      "grad_norm": 0.5739403367042542,
      "learning_rate": 8.992510727235304e-06,
      "loss": 0.4691,
      "step": 6363
    },
    {
      "epoch": 0.10076476083411182,
      "grad_norm": 0.3049217164516449,
      "learning_rate": 8.992352391658883e-06,
      "loss": 0.1671,
      "step": 6364
    },
    {
      "epoch": 0.10078059439175388,
      "grad_norm": 0.21554483473300934,
      "learning_rate": 8.992194056082462e-06,
      "loss": 0.0187,
      "step": 6365
    },
    {
      "epoch": 0.10079642794939594,
      "grad_norm": 0.3743615746498108,
      "learning_rate": 8.99203572050604e-06,
      "loss": 0.1398,
      "step": 6366
    },
    {
      "epoch": 0.10081226150703802,
      "grad_norm": 0.21106676757335663,
      "learning_rate": 8.99187738492962e-06,
      "loss": 0.1536,
      "step": 6367
    },
    {
      "epoch": 0.10082809506468009,
      "grad_norm": 0.20352232456207275,
      "learning_rate": 8.9917190493532e-06,
      "loss": 0.0621,
      "step": 6368
    },
    {
      "epoch": 0.10084392862232215,
      "grad_norm": 0.0001419488398823887,
      "learning_rate": 8.99156071377678e-06,
      "loss": 0.0,
      "step": 6369
    },
    {
      "epoch": 0.10085976217996422,
      "grad_norm": 0.2989419102668762,
      "learning_rate": 8.991402378200359e-06,
      "loss": 0.1081,
      "step": 6370
    },
    {
      "epoch": 0.10087559573760628,
      "grad_norm": 0.4188919961452484,
      "learning_rate": 8.991244042623938e-06,
      "loss": 0.6431,
      "step": 6371
    },
    {
      "epoch": 0.10089142929524834,
      "grad_norm": 0.6045914888381958,
      "learning_rate": 8.991085707047517e-06,
      "loss": 0.146,
      "step": 6372
    },
    {
      "epoch": 0.10090726285289042,
      "grad_norm": 0.11584386974573135,
      "learning_rate": 8.990927371471096e-06,
      "loss": 0.0361,
      "step": 6373
    },
    {
      "epoch": 0.10092309641053249,
      "grad_norm": 0.4451870918273926,
      "learning_rate": 8.990769035894677e-06,
      "loss": 0.1673,
      "step": 6374
    },
    {
      "epoch": 0.10093892996817455,
      "grad_norm": 0.2920602560043335,
      "learning_rate": 8.990610700318256e-06,
      "loss": 0.2132,
      "step": 6375
    },
    {
      "epoch": 0.10095476352581662,
      "grad_norm": 0.13556163012981415,
      "learning_rate": 8.990452364741833e-06,
      "loss": 0.0344,
      "step": 6376
    },
    {
      "epoch": 0.10097059708345868,
      "grad_norm": 0.28720858693122864,
      "learning_rate": 8.990294029165414e-06,
      "loss": 0.0542,
      "step": 6377
    },
    {
      "epoch": 0.10098643064110074,
      "grad_norm": 0.2835906445980072,
      "learning_rate": 8.990135693588993e-06,
      "loss": 0.2339,
      "step": 6378
    },
    {
      "epoch": 0.10100226419874282,
      "grad_norm": 0.009014012292027473,
      "learning_rate": 8.989977358012572e-06,
      "loss": 0.0004,
      "step": 6379
    },
    {
      "epoch": 0.10101809775638489,
      "grad_norm": 0.17043255269527435,
      "learning_rate": 8.989819022436151e-06,
      "loss": 0.06,
      "step": 6380
    },
    {
      "epoch": 0.10103393131402695,
      "grad_norm": 0.0001868520921561867,
      "learning_rate": 8.989660686859732e-06,
      "loss": 0.0,
      "step": 6381
    },
    {
      "epoch": 0.10104976487166901,
      "grad_norm": 0.00013112369924783707,
      "learning_rate": 8.98950235128331e-06,
      "loss": 0.0,
      "step": 6382
    },
    {
      "epoch": 0.10106559842931108,
      "grad_norm": 0.2245793640613556,
      "learning_rate": 8.98934401570689e-06,
      "loss": 0.0776,
      "step": 6383
    },
    {
      "epoch": 0.10108143198695314,
      "grad_norm": 0.12787586450576782,
      "learning_rate": 8.98918568013047e-06,
      "loss": 0.0037,
      "step": 6384
    },
    {
      "epoch": 0.10109726554459522,
      "grad_norm": 0.37486082315444946,
      "learning_rate": 8.989027344554048e-06,
      "loss": 0.2364,
      "step": 6385
    },
    {
      "epoch": 0.10111309910223729,
      "grad_norm": 0.37010419368743896,
      "learning_rate": 8.988869008977627e-06,
      "loss": 0.7553,
      "step": 6386
    },
    {
      "epoch": 0.10112893265987935,
      "grad_norm": 0.40965086221694946,
      "learning_rate": 8.988710673401208e-06,
      "loss": 0.0259,
      "step": 6387
    },
    {
      "epoch": 0.10114476621752141,
      "grad_norm": 0.39785462617874146,
      "learning_rate": 8.988552337824786e-06,
      "loss": 0.2489,
      "step": 6388
    },
    {
      "epoch": 0.10116059977516348,
      "grad_norm": 0.011137129738926888,
      "learning_rate": 8.988394002248366e-06,
      "loss": 0.0006,
      "step": 6389
    },
    {
      "epoch": 0.10117643333280554,
      "grad_norm": 0.21717111766338348,
      "learning_rate": 8.988235666671945e-06,
      "loss": 0.104,
      "step": 6390
    },
    {
      "epoch": 0.10119226689044762,
      "grad_norm": 0.16580034792423248,
      "learning_rate": 8.988077331095525e-06,
      "loss": 0.0426,
      "step": 6391
    },
    {
      "epoch": 0.10120810044808969,
      "grad_norm": 0.00013527440023608506,
      "learning_rate": 8.987918995519104e-06,
      "loss": 0.0,
      "step": 6392
    },
    {
      "epoch": 0.10122393400573175,
      "grad_norm": 0.14728543162345886,
      "learning_rate": 8.987760659942684e-06,
      "loss": 0.0673,
      "step": 6393
    },
    {
      "epoch": 0.10123976756337381,
      "grad_norm": 0.013100695796310902,
      "learning_rate": 8.987602324366262e-06,
      "loss": 0.0008,
      "step": 6394
    },
    {
      "epoch": 0.10125560112101588,
      "grad_norm": 0.1285059005022049,
      "learning_rate": 8.987443988789843e-06,
      "loss": 0.0421,
      "step": 6395
    },
    {
      "epoch": 0.10127143467865794,
      "grad_norm": 5.2915213018422946e-05,
      "learning_rate": 8.987285653213422e-06,
      "loss": 0.0,
      "step": 6396
    },
    {
      "epoch": 0.10128726823630002,
      "grad_norm": 0.1537879854440689,
      "learning_rate": 8.987127317637e-06,
      "loss": 0.0602,
      "step": 6397
    },
    {
      "epoch": 0.10130310179394209,
      "grad_norm": 0.05571677163243294,
      "learning_rate": 8.98696898206058e-06,
      "loss": 0.0016,
      "step": 6398
    },
    {
      "epoch": 0.10131893535158415,
      "grad_norm": 0.3580660820007324,
      "learning_rate": 8.98681064648416e-06,
      "loss": 0.0555,
      "step": 6399
    },
    {
      "epoch": 0.10133476890922621,
      "grad_norm": 0.5432137846946716,
      "learning_rate": 8.986652310907738e-06,
      "loss": 0.2127,
      "step": 6400
    },
    {
      "epoch": 0.10135060246686828,
      "grad_norm": 0.10783028602600098,
      "learning_rate": 8.986493975331317e-06,
      "loss": 0.0036,
      "step": 6401
    },
    {
      "epoch": 0.10136643602451034,
      "grad_norm": 0.29677829146385193,
      "learning_rate": 8.986335639754898e-06,
      "loss": 0.0683,
      "step": 6402
    },
    {
      "epoch": 0.10138226958215242,
      "grad_norm": 0.19651702046394348,
      "learning_rate": 8.986177304178477e-06,
      "loss": 0.1135,
      "step": 6403
    },
    {
      "epoch": 0.10139810313979448,
      "grad_norm": 0.050035469233989716,
      "learning_rate": 8.986018968602056e-06,
      "loss": 0.0036,
      "step": 6404
    },
    {
      "epoch": 0.10141393669743655,
      "grad_norm": 0.5079336762428284,
      "learning_rate": 8.985860633025635e-06,
      "loss": 0.3048,
      "step": 6405
    },
    {
      "epoch": 0.10142977025507861,
      "grad_norm": 0.2912117540836334,
      "learning_rate": 8.985702297449214e-06,
      "loss": 0.5688,
      "step": 6406
    },
    {
      "epoch": 0.10144560381272068,
      "grad_norm": 0.211408331990242,
      "learning_rate": 8.985543961872793e-06,
      "loss": 0.0465,
      "step": 6407
    },
    {
      "epoch": 0.10146143737036274,
      "grad_norm": 0.01455654576420784,
      "learning_rate": 8.985385626296374e-06,
      "loss": 0.0007,
      "step": 6408
    },
    {
      "epoch": 0.10147727092800482,
      "grad_norm": 0.049271274358034134,
      "learning_rate": 8.985227290719953e-06,
      "loss": 0.0035,
      "step": 6409
    },
    {
      "epoch": 0.10149310448564688,
      "grad_norm": 0.1430036425590515,
      "learning_rate": 8.985068955143532e-06,
      "loss": 0.0901,
      "step": 6410
    },
    {
      "epoch": 0.10150893804328895,
      "grad_norm": 0.48783984780311584,
      "learning_rate": 8.984910619567111e-06,
      "loss": 0.3064,
      "step": 6411
    },
    {
      "epoch": 0.10152477160093101,
      "grad_norm": 0.015154673717916012,
      "learning_rate": 8.98475228399069e-06,
      "loss": 0.0011,
      "step": 6412
    },
    {
      "epoch": 0.10154060515857308,
      "grad_norm": 0.0001769865775713697,
      "learning_rate": 8.98459394841427e-06,
      "loss": 0.0,
      "step": 6413
    },
    {
      "epoch": 0.10155643871621514,
      "grad_norm": 0.5451224446296692,
      "learning_rate": 8.98443561283785e-06,
      "loss": 0.8738,
      "step": 6414
    },
    {
      "epoch": 0.10157227227385722,
      "grad_norm": 0.02088531106710434,
      "learning_rate": 8.984277277261428e-06,
      "loss": 0.0012,
      "step": 6415
    },
    {
      "epoch": 0.10158810583149928,
      "grad_norm": 0.011303707957267761,
      "learning_rate": 8.984118941685008e-06,
      "loss": 0.0006,
      "step": 6416
    },
    {
      "epoch": 0.10160393938914135,
      "grad_norm": 0.21325574815273285,
      "learning_rate": 8.983960606108587e-06,
      "loss": 0.0751,
      "step": 6417
    },
    {
      "epoch": 0.10161977294678341,
      "grad_norm": 0.04522085189819336,
      "learning_rate": 8.983802270532166e-06,
      "loss": 0.0038,
      "step": 6418
    },
    {
      "epoch": 0.10163560650442548,
      "grad_norm": 0.007567246910184622,
      "learning_rate": 8.983643934955746e-06,
      "loss": 0.0004,
      "step": 6419
    },
    {
      "epoch": 0.10165144006206754,
      "grad_norm": 0.20896802842617035,
      "learning_rate": 8.983485599379326e-06,
      "loss": 0.0375,
      "step": 6420
    },
    {
      "epoch": 0.10166727361970962,
      "grad_norm": 0.0002325672103324905,
      "learning_rate": 8.983327263802904e-06,
      "loss": 0.0,
      "step": 6421
    },
    {
      "epoch": 0.10168310717735168,
      "grad_norm": 0.5533760786056519,
      "learning_rate": 8.983168928226485e-06,
      "loss": 0.7961,
      "step": 6422
    },
    {
      "epoch": 0.10169894073499375,
      "grad_norm": 0.6479066014289856,
      "learning_rate": 8.983010592650064e-06,
      "loss": 0.0681,
      "step": 6423
    },
    {
      "epoch": 0.10171477429263581,
      "grad_norm": 0.010274344123899937,
      "learning_rate": 8.982852257073643e-06,
      "loss": 0.0006,
      "step": 6424
    },
    {
      "epoch": 0.10173060785027788,
      "grad_norm": 0.28799089789390564,
      "learning_rate": 8.982693921497222e-06,
      "loss": 0.1001,
      "step": 6425
    },
    {
      "epoch": 0.10174644140791994,
      "grad_norm": 0.09593598544597626,
      "learning_rate": 8.9825355859208e-06,
      "loss": 0.0284,
      "step": 6426
    },
    {
      "epoch": 0.10176227496556202,
      "grad_norm": 0.7715091705322266,
      "learning_rate": 8.98237725034438e-06,
      "loss": 0.0977,
      "step": 6427
    },
    {
      "epoch": 0.10177810852320408,
      "grad_norm": 0.0007153907208703458,
      "learning_rate": 8.982218914767959e-06,
      "loss": 0.0,
      "step": 6428
    },
    {
      "epoch": 0.10179394208084615,
      "grad_norm": 0.024669930338859558,
      "learning_rate": 8.98206057919154e-06,
      "loss": 0.0013,
      "step": 6429
    },
    {
      "epoch": 0.10180977563848821,
      "grad_norm": 0.0008444731356576085,
      "learning_rate": 8.981902243615119e-06,
      "loss": 0.0,
      "step": 6430
    },
    {
      "epoch": 0.10182560919613028,
      "grad_norm": 0.25391241908073425,
      "learning_rate": 8.981743908038698e-06,
      "loss": 0.1564,
      "step": 6431
    },
    {
      "epoch": 0.10184144275377234,
      "grad_norm": 0.5415154695510864,
      "learning_rate": 8.981585572462277e-06,
      "loss": 0.0749,
      "step": 6432
    },
    {
      "epoch": 0.10185727631141442,
      "grad_norm": 0.46506527066230774,
      "learning_rate": 8.981427236885856e-06,
      "loss": 0.1595,
      "step": 6433
    },
    {
      "epoch": 0.10187310986905648,
      "grad_norm": 0.04038665443658829,
      "learning_rate": 8.981268901309435e-06,
      "loss": 0.0022,
      "step": 6434
    },
    {
      "epoch": 0.10188894342669855,
      "grad_norm": 0.2928345799446106,
      "learning_rate": 8.981110565733016e-06,
      "loss": 0.1296,
      "step": 6435
    },
    {
      "epoch": 0.10190477698434061,
      "grad_norm": 0.36226198077201843,
      "learning_rate": 8.980952230156595e-06,
      "loss": 0.1723,
      "step": 6436
    },
    {
      "epoch": 0.10192061054198268,
      "grad_norm": 0.27508774399757385,
      "learning_rate": 8.980793894580174e-06,
      "loss": 0.106,
      "step": 6437
    },
    {
      "epoch": 0.10193644409962474,
      "grad_norm": 0.02220979705452919,
      "learning_rate": 8.980635559003753e-06,
      "loss": 0.0012,
      "step": 6438
    },
    {
      "epoch": 0.1019522776572668,
      "grad_norm": 0.3434184789657593,
      "learning_rate": 8.980477223427332e-06,
      "loss": 0.1765,
      "step": 6439
    },
    {
      "epoch": 0.10196811121490888,
      "grad_norm": 0.2956083118915558,
      "learning_rate": 8.980318887850911e-06,
      "loss": 0.0962,
      "step": 6440
    },
    {
      "epoch": 0.10198394477255095,
      "grad_norm": 0.02937469072639942,
      "learning_rate": 8.980160552274492e-06,
      "loss": 0.002,
      "step": 6441
    },
    {
      "epoch": 0.10199977833019301,
      "grad_norm": 0.23286569118499756,
      "learning_rate": 8.980002216698071e-06,
      "loss": 0.1117,
      "step": 6442
    },
    {
      "epoch": 0.10201561188783508,
      "grad_norm": 0.006102383136749268,
      "learning_rate": 8.97984388112165e-06,
      "loss": 0.0002,
      "step": 6443
    },
    {
      "epoch": 0.10203144544547714,
      "grad_norm": 0.3301890194416046,
      "learning_rate": 8.97968554554523e-06,
      "loss": 0.2634,
      "step": 6444
    },
    {
      "epoch": 0.1020472790031192,
      "grad_norm": 0.14143531024456024,
      "learning_rate": 8.979527209968808e-06,
      "loss": 0.0722,
      "step": 6445
    },
    {
      "epoch": 0.10206311256076128,
      "grad_norm": 0.42349526286125183,
      "learning_rate": 8.979368874392387e-06,
      "loss": 0.0974,
      "step": 6446
    },
    {
      "epoch": 0.10207894611840335,
      "grad_norm": 0.014854613691568375,
      "learning_rate": 8.979210538815968e-06,
      "loss": 0.0009,
      "step": 6447
    },
    {
      "epoch": 0.10209477967604541,
      "grad_norm": 0.37895506620407104,
      "learning_rate": 8.979052203239547e-06,
      "loss": 0.0539,
      "step": 6448
    },
    {
      "epoch": 0.10211061323368747,
      "grad_norm": 0.00020134936494287103,
      "learning_rate": 8.978893867663125e-06,
      "loss": 0.0,
      "step": 6449
    },
    {
      "epoch": 0.10212644679132954,
      "grad_norm": 0.28956398367881775,
      "learning_rate": 8.978735532086706e-06,
      "loss": 0.2793,
      "step": 6450
    },
    {
      "epoch": 0.1021422803489716,
      "grad_norm": 0.0060827406123280525,
      "learning_rate": 8.978577196510285e-06,
      "loss": 0.0004,
      "step": 6451
    },
    {
      "epoch": 0.10215811390661368,
      "grad_norm": 0.00018776385695673525,
      "learning_rate": 8.978418860933864e-06,
      "loss": 0.0,
      "step": 6452
    },
    {
      "epoch": 0.10217394746425575,
      "grad_norm": 0.00015985565551090986,
      "learning_rate": 8.978260525357443e-06,
      "loss": 0.0,
      "step": 6453
    },
    {
      "epoch": 0.10218978102189781,
      "grad_norm": 0.012768205255270004,
      "learning_rate": 8.978102189781024e-06,
      "loss": 0.0006,
      "step": 6454
    },
    {
      "epoch": 0.10220561457953987,
      "grad_norm": 0.08647580444812775,
      "learning_rate": 8.977943854204601e-06,
      "loss": 0.0125,
      "step": 6455
    },
    {
      "epoch": 0.10222144813718194,
      "grad_norm": 0.04366361349821091,
      "learning_rate": 8.977785518628182e-06,
      "loss": 0.0027,
      "step": 6456
    },
    {
      "epoch": 0.102237281694824,
      "grad_norm": 0.3463134765625,
      "learning_rate": 8.97762718305176e-06,
      "loss": 0.0752,
      "step": 6457
    },
    {
      "epoch": 0.10225311525246608,
      "grad_norm": 0.000671974616125226,
      "learning_rate": 8.97746884747534e-06,
      "loss": 0.0,
      "step": 6458
    },
    {
      "epoch": 0.10226894881010815,
      "grad_norm": 0.3230215311050415,
      "learning_rate": 8.977310511898919e-06,
      "loss": 0.1435,
      "step": 6459
    },
    {
      "epoch": 0.10228478236775021,
      "grad_norm": 0.3561517596244812,
      "learning_rate": 8.9771521763225e-06,
      "loss": 0.0908,
      "step": 6460
    },
    {
      "epoch": 0.10230061592539227,
      "grad_norm": 0.009253542870283127,
      "learning_rate": 8.976993840746077e-06,
      "loss": 0.0005,
      "step": 6461
    },
    {
      "epoch": 0.10231644948303434,
      "grad_norm": 0.36669689416885376,
      "learning_rate": 8.976835505169658e-06,
      "loss": 0.2136,
      "step": 6462
    },
    {
      "epoch": 0.1023322830406764,
      "grad_norm": 0.00024658182519488037,
      "learning_rate": 8.976677169593237e-06,
      "loss": 0.0,
      "step": 6463
    },
    {
      "epoch": 0.10234811659831848,
      "grad_norm": 0.5792586803436279,
      "learning_rate": 8.976518834016816e-06,
      "loss": 0.0832,
      "step": 6464
    },
    {
      "epoch": 0.10236395015596055,
      "grad_norm": 0.3248654901981354,
      "learning_rate": 8.976360498440395e-06,
      "loss": 0.2536,
      "step": 6465
    },
    {
      "epoch": 0.10237978371360261,
      "grad_norm": 0.2839621901512146,
      "learning_rate": 8.976202162863976e-06,
      "loss": 0.1054,
      "step": 6466
    },
    {
      "epoch": 0.10239561727124467,
      "grad_norm": 0.019760707393288612,
      "learning_rate": 8.976043827287553e-06,
      "loss": 0.001,
      "step": 6467
    },
    {
      "epoch": 0.10241145082888674,
      "grad_norm": 0.5095376372337341,
      "learning_rate": 8.975885491711134e-06,
      "loss": 0.5754,
      "step": 6468
    },
    {
      "epoch": 0.1024272843865288,
      "grad_norm": 0.0002904292196035385,
      "learning_rate": 8.975727156134713e-06,
      "loss": 0.0,
      "step": 6469
    },
    {
      "epoch": 0.10244311794417088,
      "grad_norm": 0.4358268082141876,
      "learning_rate": 8.975568820558292e-06,
      "loss": 0.2543,
      "step": 6470
    },
    {
      "epoch": 0.10245895150181294,
      "grad_norm": 0.9763841032981873,
      "learning_rate": 8.975410484981871e-06,
      "loss": 1.0611,
      "step": 6471
    },
    {
      "epoch": 0.10247478505945501,
      "grad_norm": 0.268185555934906,
      "learning_rate": 8.975252149405452e-06,
      "loss": 0.0703,
      "step": 6472
    },
    {
      "epoch": 0.10249061861709707,
      "grad_norm": 0.23025286197662354,
      "learning_rate": 8.97509381382903e-06,
      "loss": 0.076,
      "step": 6473
    },
    {
      "epoch": 0.10250645217473914,
      "grad_norm": 0.01738710328936577,
      "learning_rate": 8.974935478252609e-06,
      "loss": 0.001,
      "step": 6474
    },
    {
      "epoch": 0.1025222857323812,
      "grad_norm": 0.37345555424690247,
      "learning_rate": 8.97477714267619e-06,
      "loss": 0.2183,
      "step": 6475
    },
    {
      "epoch": 0.10253811929002328,
      "grad_norm": 0.29106032848358154,
      "learning_rate": 8.974618807099768e-06,
      "loss": 0.203,
      "step": 6476
    },
    {
      "epoch": 0.10255395284766534,
      "grad_norm": 0.27124345302581787,
      "learning_rate": 8.974460471523347e-06,
      "loss": 0.0893,
      "step": 6477
    },
    {
      "epoch": 0.10256978640530741,
      "grad_norm": 0.4519219994544983,
      "learning_rate": 8.974302135946927e-06,
      "loss": 0.0284,
      "step": 6478
    },
    {
      "epoch": 0.10258561996294947,
      "grad_norm": 0.1344359964132309,
      "learning_rate": 8.974143800370506e-06,
      "loss": 0.0115,
      "step": 6479
    },
    {
      "epoch": 0.10260145352059154,
      "grad_norm": 0.01625458151102066,
      "learning_rate": 8.973985464794085e-06,
      "loss": 0.0009,
      "step": 6480
    },
    {
      "epoch": 0.1026172870782336,
      "grad_norm": 6.60300866002217e-05,
      "learning_rate": 8.973827129217665e-06,
      "loss": 0.0,
      "step": 6481
    },
    {
      "epoch": 0.10263312063587568,
      "grad_norm": 0.2603486180305481,
      "learning_rate": 8.973668793641243e-06,
      "loss": 0.0527,
      "step": 6482
    },
    {
      "epoch": 0.10264895419351774,
      "grad_norm": 0.06185685098171234,
      "learning_rate": 8.973510458064824e-06,
      "loss": 0.0114,
      "step": 6483
    },
    {
      "epoch": 0.10266478775115981,
      "grad_norm": 0.9536263346672058,
      "learning_rate": 8.973352122488403e-06,
      "loss": 0.1167,
      "step": 6484
    },
    {
      "epoch": 0.10268062130880187,
      "grad_norm": 0.3276187479496002,
      "learning_rate": 8.973193786911982e-06,
      "loss": 0.3992,
      "step": 6485
    },
    {
      "epoch": 0.10269645486644394,
      "grad_norm": 0.4444882273674011,
      "learning_rate": 8.97303545133556e-06,
      "loss": 0.18,
      "step": 6486
    },
    {
      "epoch": 0.102712288424086,
      "grad_norm": 0.2451266497373581,
      "learning_rate": 8.972877115759142e-06,
      "loss": 0.1256,
      "step": 6487
    },
    {
      "epoch": 0.10272812198172808,
      "grad_norm": 0.1775689274072647,
      "learning_rate": 8.972718780182719e-06,
      "loss": 0.0123,
      "step": 6488
    },
    {
      "epoch": 0.10274395553937014,
      "grad_norm": 0.016234302893280983,
      "learning_rate": 8.9725604446063e-06,
      "loss": 0.001,
      "step": 6489
    },
    {
      "epoch": 0.10275978909701221,
      "grad_norm": 3.6071796785108745e-05,
      "learning_rate": 8.972402109029879e-06,
      "loss": 0.0,
      "step": 6490
    },
    {
      "epoch": 0.10277562265465427,
      "grad_norm": 0.0034309483598917723,
      "learning_rate": 8.972243773453458e-06,
      "loss": 0.0002,
      "step": 6491
    },
    {
      "epoch": 0.10279145621229634,
      "grad_norm": 0.49854469299316406,
      "learning_rate": 8.972085437877037e-06,
      "loss": 0.648,
      "step": 6492
    },
    {
      "epoch": 0.1028072897699384,
      "grad_norm": 0.0009933958062902093,
      "learning_rate": 8.971927102300618e-06,
      "loss": 0.0,
      "step": 6493
    },
    {
      "epoch": 0.10282312332758048,
      "grad_norm": 0.07146739214658737,
      "learning_rate": 8.971768766724195e-06,
      "loss": 0.0118,
      "step": 6494
    },
    {
      "epoch": 0.10283895688522254,
      "grad_norm": 0.33663371205329895,
      "learning_rate": 8.971610431147776e-06,
      "loss": 0.2886,
      "step": 6495
    },
    {
      "epoch": 0.10285479044286461,
      "grad_norm": 0.03622619807720184,
      "learning_rate": 8.971452095571355e-06,
      "loss": 0.0019,
      "step": 6496
    },
    {
      "epoch": 0.10287062400050667,
      "grad_norm": 0.15510597825050354,
      "learning_rate": 8.971293759994934e-06,
      "loss": 0.074,
      "step": 6497
    },
    {
      "epoch": 0.10288645755814874,
      "grad_norm": 0.386321485042572,
      "learning_rate": 8.971135424418513e-06,
      "loss": 0.6516,
      "step": 6498
    },
    {
      "epoch": 0.1029022911157908,
      "grad_norm": 0.02248428389430046,
      "learning_rate": 8.970977088842092e-06,
      "loss": 0.0014,
      "step": 6499
    },
    {
      "epoch": 0.10291812467343288,
      "grad_norm": 0.24625848233699799,
      "learning_rate": 8.970818753265671e-06,
      "loss": 0.0834,
      "step": 6500
    },
    {
      "epoch": 0.10293395823107494,
      "grad_norm": 0.3539576530456543,
      "learning_rate": 8.97066041768925e-06,
      "loss": 0.0879,
      "step": 6501
    },
    {
      "epoch": 0.10294979178871701,
      "grad_norm": 0.5146613717079163,
      "learning_rate": 8.970502082112831e-06,
      "loss": 0.0824,
      "step": 6502
    },
    {
      "epoch": 0.10296562534635907,
      "grad_norm": 0.19491150975227356,
      "learning_rate": 8.97034374653641e-06,
      "loss": 0.07,
      "step": 6503
    },
    {
      "epoch": 0.10298145890400114,
      "grad_norm": 0.04668072238564491,
      "learning_rate": 8.97018541095999e-06,
      "loss": 0.0033,
      "step": 6504
    },
    {
      "epoch": 0.1029972924616432,
      "grad_norm": 0.07526221871376038,
      "learning_rate": 8.970027075383568e-06,
      "loss": 0.0022,
      "step": 6505
    },
    {
      "epoch": 0.10301312601928528,
      "grad_norm": 0.011380262672901154,
      "learning_rate": 8.969868739807148e-06,
      "loss": 0.0005,
      "step": 6506
    },
    {
      "epoch": 0.10302895957692734,
      "grad_norm": 0.007327171973884106,
      "learning_rate": 8.969710404230727e-06,
      "loss": 0.0004,
      "step": 6507
    },
    {
      "epoch": 0.1030447931345694,
      "grad_norm": 0.25743719935417175,
      "learning_rate": 8.969552068654307e-06,
      "loss": 0.089,
      "step": 6508
    },
    {
      "epoch": 0.10306062669221147,
      "grad_norm": 1.2077900171279907,
      "learning_rate": 8.969393733077886e-06,
      "loss": 0.4642,
      "step": 6509
    },
    {
      "epoch": 0.10307646024985354,
      "grad_norm": 0.9134909510612488,
      "learning_rate": 8.969235397501466e-06,
      "loss": 0.0432,
      "step": 6510
    },
    {
      "epoch": 0.1030922938074956,
      "grad_norm": 0.3544016182422638,
      "learning_rate": 8.969077061925045e-06,
      "loss": 0.1709,
      "step": 6511
    },
    {
      "epoch": 0.10310812736513768,
      "grad_norm": 0.5072917342185974,
      "learning_rate": 8.968918726348624e-06,
      "loss": 0.6071,
      "step": 6512
    },
    {
      "epoch": 0.10312396092277974,
      "grad_norm": 0.142095148563385,
      "learning_rate": 8.968760390772203e-06,
      "loss": 0.1305,
      "step": 6513
    },
    {
      "epoch": 0.1031397944804218,
      "grad_norm": 0.013231961987912655,
      "learning_rate": 8.968602055195784e-06,
      "loss": 0.0006,
      "step": 6514
    },
    {
      "epoch": 0.10315562803806387,
      "grad_norm": 0.15662063658237457,
      "learning_rate": 8.968443719619363e-06,
      "loss": 0.0207,
      "step": 6515
    },
    {
      "epoch": 0.10317146159570593,
      "grad_norm": 0.13196097314357758,
      "learning_rate": 8.968285384042942e-06,
      "loss": 0.0055,
      "step": 6516
    },
    {
      "epoch": 0.103187295153348,
      "grad_norm": 0.29740896821022034,
      "learning_rate": 8.96812704846652e-06,
      "loss": 0.318,
      "step": 6517
    },
    {
      "epoch": 0.10320312871099008,
      "grad_norm": 0.29648342728614807,
      "learning_rate": 8.9679687128901e-06,
      "loss": 0.1517,
      "step": 6518
    },
    {
      "epoch": 0.10321896226863214,
      "grad_norm": 0.01886715181171894,
      "learning_rate": 8.967810377313679e-06,
      "loss": 0.0012,
      "step": 6519
    },
    {
      "epoch": 0.1032347958262742,
      "grad_norm": 0.029950208961963654,
      "learning_rate": 8.96765204173726e-06,
      "loss": 0.0024,
      "step": 6520
    },
    {
      "epoch": 0.10325062938391627,
      "grad_norm": 0.4363568425178528,
      "learning_rate": 8.967493706160839e-06,
      "loss": 0.1773,
      "step": 6521
    },
    {
      "epoch": 0.10326646294155833,
      "grad_norm": 0.14634743332862854,
      "learning_rate": 8.967335370584416e-06,
      "loss": 0.0568,
      "step": 6522
    },
    {
      "epoch": 0.1032822964992004,
      "grad_norm": 0.13752028346061707,
      "learning_rate": 8.967177035007997e-06,
      "loss": 0.0292,
      "step": 6523
    },
    {
      "epoch": 0.10329813005684248,
      "grad_norm": 0.0001231380010722205,
      "learning_rate": 8.967018699431576e-06,
      "loss": 0.0,
      "step": 6524
    },
    {
      "epoch": 0.10331396361448454,
      "grad_norm": 0.2087726593017578,
      "learning_rate": 8.966860363855155e-06,
      "loss": 0.0145,
      "step": 6525
    },
    {
      "epoch": 0.1033297971721266,
      "grad_norm": 0.7020038366317749,
      "learning_rate": 8.966702028278734e-06,
      "loss": 0.2601,
      "step": 6526
    },
    {
      "epoch": 0.10334563072976867,
      "grad_norm": 0.20728829503059387,
      "learning_rate": 8.966543692702315e-06,
      "loss": 0.0679,
      "step": 6527
    },
    {
      "epoch": 0.10336146428741073,
      "grad_norm": 0.21055960655212402,
      "learning_rate": 8.966385357125892e-06,
      "loss": 0.1624,
      "step": 6528
    },
    {
      "epoch": 0.1033772978450528,
      "grad_norm": 0.11639313399791718,
      "learning_rate": 8.966227021549473e-06,
      "loss": 0.062,
      "step": 6529
    },
    {
      "epoch": 0.10339313140269488,
      "grad_norm": 4.132949834456667e-05,
      "learning_rate": 8.966068685973052e-06,
      "loss": 0.0,
      "step": 6530
    },
    {
      "epoch": 0.10340896496033694,
      "grad_norm": 0.023039020597934723,
      "learning_rate": 8.965910350396631e-06,
      "loss": 0.0015,
      "step": 6531
    },
    {
      "epoch": 0.103424798517979,
      "grad_norm": 0.23623378574848175,
      "learning_rate": 8.96575201482021e-06,
      "loss": 0.1152,
      "step": 6532
    },
    {
      "epoch": 0.10344063207562107,
      "grad_norm": 8.287527452921495e-05,
      "learning_rate": 8.965593679243791e-06,
      "loss": 0.0,
      "step": 6533
    },
    {
      "epoch": 0.10345646563326313,
      "grad_norm": 0.12086256593465805,
      "learning_rate": 8.965435343667369e-06,
      "loss": 0.0495,
      "step": 6534
    },
    {
      "epoch": 0.1034722991909052,
      "grad_norm": 0.000137545692268759,
      "learning_rate": 8.96527700809095e-06,
      "loss": 0.0,
      "step": 6535
    },
    {
      "epoch": 0.10348813274854728,
      "grad_norm": 0.2929218113422394,
      "learning_rate": 8.965118672514528e-06,
      "loss": 0.191,
      "step": 6536
    },
    {
      "epoch": 0.10350396630618934,
      "grad_norm": 0.3191084861755371,
      "learning_rate": 8.964960336938107e-06,
      "loss": 0.1078,
      "step": 6537
    },
    {
      "epoch": 0.1035197998638314,
      "grad_norm": 0.3624535799026489,
      "learning_rate": 8.964802001361687e-06,
      "loss": 0.3948,
      "step": 6538
    },
    {
      "epoch": 0.10353563342147347,
      "grad_norm": 0.20157597959041595,
      "learning_rate": 8.964643665785266e-06,
      "loss": 0.1345,
      "step": 6539
    },
    {
      "epoch": 0.10355146697911553,
      "grad_norm": 0.0196556206792593,
      "learning_rate": 8.964485330208845e-06,
      "loss": 0.0011,
      "step": 6540
    },
    {
      "epoch": 0.1035673005367576,
      "grad_norm": 1.0216811895370483,
      "learning_rate": 8.964326994632425e-06,
      "loss": 0.9188,
      "step": 6541
    },
    {
      "epoch": 0.10358313409439968,
      "grad_norm": 0.25105488300323486,
      "learning_rate": 8.964168659056005e-06,
      "loss": 0.0374,
      "step": 6542
    },
    {
      "epoch": 0.10359896765204174,
      "grad_norm": 0.020749958232045174,
      "learning_rate": 8.964010323479584e-06,
      "loss": 0.0013,
      "step": 6543
    },
    {
      "epoch": 0.1036148012096838,
      "grad_norm": 0.03538209944963455,
      "learning_rate": 8.963851987903163e-06,
      "loss": 0.0028,
      "step": 6544
    },
    {
      "epoch": 0.10363063476732587,
      "grad_norm": 0.40270185470581055,
      "learning_rate": 8.963693652326742e-06,
      "loss": 0.1305,
      "step": 6545
    },
    {
      "epoch": 0.10364646832496793,
      "grad_norm": 0.00017758589820005,
      "learning_rate": 8.963535316750321e-06,
      "loss": 0.0,
      "step": 6546
    },
    {
      "epoch": 0.10366230188261,
      "grad_norm": 0.022523166611790657,
      "learning_rate": 8.9633769811739e-06,
      "loss": 0.0014,
      "step": 6547
    },
    {
      "epoch": 0.10367813544025208,
      "grad_norm": 0.4544590711593628,
      "learning_rate": 8.96321864559748e-06,
      "loss": 0.1263,
      "step": 6548
    },
    {
      "epoch": 0.10369396899789414,
      "grad_norm": 0.15784107148647308,
      "learning_rate": 8.963060310021058e-06,
      "loss": 0.0867,
      "step": 6549
    },
    {
      "epoch": 0.1037098025555362,
      "grad_norm": 0.006929965689778328,
      "learning_rate": 8.962901974444639e-06,
      "loss": 0.0005,
      "step": 6550
    },
    {
      "epoch": 0.10372563611317827,
      "grad_norm": 0.4555698037147522,
      "learning_rate": 8.962743638868218e-06,
      "loss": 0.0446,
      "step": 6551
    },
    {
      "epoch": 0.10374146967082033,
      "grad_norm": 0.23440465331077576,
      "learning_rate": 8.962585303291797e-06,
      "loss": 0.053,
      "step": 6552
    },
    {
      "epoch": 0.1037573032284624,
      "grad_norm": 0.2609785199165344,
      "learning_rate": 8.962426967715376e-06,
      "loss": 0.0507,
      "step": 6553
    },
    {
      "epoch": 0.10377313678610448,
      "grad_norm": 0.0001732787786750123,
      "learning_rate": 8.962268632138957e-06,
      "loss": 0.0,
      "step": 6554
    },
    {
      "epoch": 0.10378897034374654,
      "grad_norm": 0.22076378762722015,
      "learning_rate": 8.962110296562534e-06,
      "loss": 0.0718,
      "step": 6555
    },
    {
      "epoch": 0.1038048039013886,
      "grad_norm": 0.2794106900691986,
      "learning_rate": 8.961951960986115e-06,
      "loss": 0.3072,
      "step": 6556
    },
    {
      "epoch": 0.10382063745903067,
      "grad_norm": 0.0021816894877701998,
      "learning_rate": 8.961793625409694e-06,
      "loss": 0.0001,
      "step": 6557
    },
    {
      "epoch": 0.10383647101667273,
      "grad_norm": 0.6258739233016968,
      "learning_rate": 8.961635289833273e-06,
      "loss": 0.3511,
      "step": 6558
    },
    {
      "epoch": 0.1038523045743148,
      "grad_norm": 0.3477526009082794,
      "learning_rate": 8.961476954256852e-06,
      "loss": 0.181,
      "step": 6559
    },
    {
      "epoch": 0.10386813813195687,
      "grad_norm": 0.6135740876197815,
      "learning_rate": 8.961318618680433e-06,
      "loss": 0.2381,
      "step": 6560
    },
    {
      "epoch": 0.10388397168959894,
      "grad_norm": 0.11208371073007584,
      "learning_rate": 8.96116028310401e-06,
      "loss": 0.028,
      "step": 6561
    },
    {
      "epoch": 0.103899805247241,
      "grad_norm": 0.25865933299064636,
      "learning_rate": 8.961001947527591e-06,
      "loss": 0.036,
      "step": 6562
    },
    {
      "epoch": 0.10391563880488307,
      "grad_norm": 0.32507309317588806,
      "learning_rate": 8.96084361195117e-06,
      "loss": 0.1098,
      "step": 6563
    },
    {
      "epoch": 0.10393147236252513,
      "grad_norm": 0.28698211908340454,
      "learning_rate": 8.96068527637475e-06,
      "loss": 0.3602,
      "step": 6564
    },
    {
      "epoch": 0.1039473059201672,
      "grad_norm": 0.42743176221847534,
      "learning_rate": 8.960526940798328e-06,
      "loss": 0.4538,
      "step": 6565
    },
    {
      "epoch": 0.10396313947780927,
      "grad_norm": 0.3056522607803345,
      "learning_rate": 8.96036860522191e-06,
      "loss": 0.1491,
      "step": 6566
    },
    {
      "epoch": 0.10397897303545134,
      "grad_norm": 0.00023865335970185697,
      "learning_rate": 8.960210269645487e-06,
      "loss": 0.0,
      "step": 6567
    },
    {
      "epoch": 0.1039948065930934,
      "grad_norm": 0.21344894170761108,
      "learning_rate": 8.960051934069067e-06,
      "loss": 0.1403,
      "step": 6568
    },
    {
      "epoch": 0.10401064015073547,
      "grad_norm": 9.188883268507197e-05,
      "learning_rate": 8.959893598492646e-06,
      "loss": 0.0,
      "step": 6569
    },
    {
      "epoch": 0.10402647370837753,
      "grad_norm": 0.3303675353527069,
      "learning_rate": 8.959735262916226e-06,
      "loss": 0.064,
      "step": 6570
    },
    {
      "epoch": 0.1040423072660196,
      "grad_norm": 0.022460170090198517,
      "learning_rate": 8.959576927339805e-06,
      "loss": 0.0015,
      "step": 6571
    },
    {
      "epoch": 0.10405814082366167,
      "grad_norm": 0.015789171680808067,
      "learning_rate": 8.959418591763384e-06,
      "loss": 0.0009,
      "step": 6572
    },
    {
      "epoch": 0.10407397438130374,
      "grad_norm": 0.01912197284400463,
      "learning_rate": 8.959260256186963e-06,
      "loss": 0.0012,
      "step": 6573
    },
    {
      "epoch": 0.1040898079389458,
      "grad_norm": 2.5681986808776855,
      "learning_rate": 8.959101920610542e-06,
      "loss": 0.0669,
      "step": 6574
    },
    {
      "epoch": 0.10410564149658787,
      "grad_norm": 0.23795294761657715,
      "learning_rate": 8.958943585034123e-06,
      "loss": 0.5578,
      "step": 6575
    },
    {
      "epoch": 0.10412147505422993,
      "grad_norm": 0.9261712431907654,
      "learning_rate": 8.958785249457702e-06,
      "loss": 0.1718,
      "step": 6576
    },
    {
      "epoch": 0.104137308611872,
      "grad_norm": 0.21078228950500488,
      "learning_rate": 8.95862691388128e-06,
      "loss": 0.0542,
      "step": 6577
    },
    {
      "epoch": 0.10415314216951407,
      "grad_norm": 0.4108344316482544,
      "learning_rate": 8.95846857830486e-06,
      "loss": 0.191,
      "step": 6578
    },
    {
      "epoch": 0.10416897572715614,
      "grad_norm": 0.3787524402141571,
      "learning_rate": 8.958310242728439e-06,
      "loss": 0.4216,
      "step": 6579
    },
    {
      "epoch": 0.1041848092847982,
      "grad_norm": 0.4739779829978943,
      "learning_rate": 8.958151907152018e-06,
      "loss": 0.5675,
      "step": 6580
    },
    {
      "epoch": 0.10420064284244027,
      "grad_norm": 0.2952221632003784,
      "learning_rate": 8.957993571575599e-06,
      "loss": 0.1342,
      "step": 6581
    },
    {
      "epoch": 0.10421647640008233,
      "grad_norm": 0.0046707941219210625,
      "learning_rate": 8.957835235999178e-06,
      "loss": 0.0003,
      "step": 6582
    },
    {
      "epoch": 0.1042323099577244,
      "grad_norm": 0.16880589723587036,
      "learning_rate": 8.957676900422757e-06,
      "loss": 0.024,
      "step": 6583
    },
    {
      "epoch": 0.10424814351536647,
      "grad_norm": 0.5539256930351257,
      "learning_rate": 8.957518564846336e-06,
      "loss": 0.067,
      "step": 6584
    },
    {
      "epoch": 0.10426397707300854,
      "grad_norm": 0.6074572205543518,
      "learning_rate": 8.957360229269915e-06,
      "loss": 0.3038,
      "step": 6585
    },
    {
      "epoch": 0.1042798106306506,
      "grad_norm": 0.40886127948760986,
      "learning_rate": 8.957201893693494e-06,
      "loss": 0.1321,
      "step": 6586
    },
    {
      "epoch": 0.10429564418829267,
      "grad_norm": 0.1525154709815979,
      "learning_rate": 8.957043558117075e-06,
      "loss": 0.0387,
      "step": 6587
    },
    {
      "epoch": 0.10431147774593473,
      "grad_norm": 0.07216353714466095,
      "learning_rate": 8.956885222540654e-06,
      "loss": 0.001,
      "step": 6588
    },
    {
      "epoch": 0.1043273113035768,
      "grad_norm": 0.1756398230791092,
      "learning_rate": 8.956726886964233e-06,
      "loss": 0.0639,
      "step": 6589
    },
    {
      "epoch": 0.10434314486121887,
      "grad_norm": 0.13124452531337738,
      "learning_rate": 8.956568551387812e-06,
      "loss": 0.0634,
      "step": 6590
    },
    {
      "epoch": 0.10435897841886094,
      "grad_norm": 0.2779429256916046,
      "learning_rate": 8.956410215811391e-06,
      "loss": 0.4618,
      "step": 6591
    },
    {
      "epoch": 0.104374811976503,
      "grad_norm": 0.25706231594085693,
      "learning_rate": 8.95625188023497e-06,
      "loss": 0.1168,
      "step": 6592
    },
    {
      "epoch": 0.10439064553414507,
      "grad_norm": 0.09464842081069946,
      "learning_rate": 8.95609354465855e-06,
      "loss": 0.0012,
      "step": 6593
    },
    {
      "epoch": 0.10440647909178713,
      "grad_norm": 0.2840489447116852,
      "learning_rate": 8.95593520908213e-06,
      "loss": 0.1361,
      "step": 6594
    },
    {
      "epoch": 0.1044223126494292,
      "grad_norm": 0.011428541503846645,
      "learning_rate": 8.955776873505708e-06,
      "loss": 0.0002,
      "step": 6595
    },
    {
      "epoch": 0.10443814620707127,
      "grad_norm": 0.3095196783542633,
      "learning_rate": 8.955618537929288e-06,
      "loss": 0.3522,
      "step": 6596
    },
    {
      "epoch": 0.10445397976471334,
      "grad_norm": 0.433060884475708,
      "learning_rate": 8.955460202352867e-06,
      "loss": 0.0979,
      "step": 6597
    },
    {
      "epoch": 0.1044698133223554,
      "grad_norm": 0.4284650981426239,
      "learning_rate": 8.955301866776447e-06,
      "loss": 0.3461,
      "step": 6598
    },
    {
      "epoch": 0.10448564687999747,
      "grad_norm": 0.253397673368454,
      "learning_rate": 8.955143531200026e-06,
      "loss": 0.2042,
      "step": 6599
    },
    {
      "epoch": 0.10450148043763953,
      "grad_norm": 0.21775193512439728,
      "learning_rate": 8.954985195623606e-06,
      "loss": 0.0842,
      "step": 6600
    },
    {
      "epoch": 0.1045173139952816,
      "grad_norm": 7.285163883352652e-05,
      "learning_rate": 8.954826860047184e-06,
      "loss": 0.0,
      "step": 6601
    },
    {
      "epoch": 0.10453314755292367,
      "grad_norm": 0.46450361609458923,
      "learning_rate": 8.954668524470765e-06,
      "loss": 0.067,
      "step": 6602
    },
    {
      "epoch": 0.10454898111056574,
      "grad_norm": 0.37993210554122925,
      "learning_rate": 8.954510188894344e-06,
      "loss": 0.3625,
      "step": 6603
    },
    {
      "epoch": 0.1045648146682078,
      "grad_norm": 0.009644618257880211,
      "learning_rate": 8.954351853317923e-06,
      "loss": 0.0006,
      "step": 6604
    },
    {
      "epoch": 0.10458064822584986,
      "grad_norm": 0.4973452389240265,
      "learning_rate": 8.954193517741502e-06,
      "loss": 0.2753,
      "step": 6605
    },
    {
      "epoch": 0.10459648178349193,
      "grad_norm": 0.18718364834785461,
      "learning_rate": 8.954035182165081e-06,
      "loss": 0.072,
      "step": 6606
    },
    {
      "epoch": 0.104612315341134,
      "grad_norm": 0.7301672101020813,
      "learning_rate": 8.95387684658866e-06,
      "loss": 0.0119,
      "step": 6607
    },
    {
      "epoch": 0.10462814889877607,
      "grad_norm": 0.5570672750473022,
      "learning_rate": 8.95371851101224e-06,
      "loss": 0.2205,
      "step": 6608
    },
    {
      "epoch": 0.10464398245641814,
      "grad_norm": 0.2642788887023926,
      "learning_rate": 8.95356017543582e-06,
      "loss": 0.0939,
      "step": 6609
    },
    {
      "epoch": 0.1046598160140602,
      "grad_norm": 0.33562925457954407,
      "learning_rate": 8.953401839859399e-06,
      "loss": 0.6617,
      "step": 6610
    },
    {
      "epoch": 0.10467564957170226,
      "grad_norm": 0.18613606691360474,
      "learning_rate": 8.953243504282978e-06,
      "loss": 0.0786,
      "step": 6611
    },
    {
      "epoch": 0.10469148312934433,
      "grad_norm": 0.16554121673107147,
      "learning_rate": 8.953085168706557e-06,
      "loss": 0.0635,
      "step": 6612
    },
    {
      "epoch": 0.10470731668698639,
      "grad_norm": 0.22518447041511536,
      "learning_rate": 8.952926833130136e-06,
      "loss": 0.0533,
      "step": 6613
    },
    {
      "epoch": 0.10472315024462847,
      "grad_norm": 0.3910805881023407,
      "learning_rate": 8.952768497553717e-06,
      "loss": 0.3607,
      "step": 6614
    },
    {
      "epoch": 0.10473898380227054,
      "grad_norm": 0.25792965292930603,
      "learning_rate": 8.952610161977296e-06,
      "loss": 0.064,
      "step": 6615
    },
    {
      "epoch": 0.1047548173599126,
      "grad_norm": 0.3196820914745331,
      "learning_rate": 8.952451826400875e-06,
      "loss": 0.0493,
      "step": 6616
    },
    {
      "epoch": 0.10477065091755466,
      "grad_norm": 0.055030494928359985,
      "learning_rate": 8.952293490824454e-06,
      "loss": 0.0042,
      "step": 6617
    },
    {
      "epoch": 0.10478648447519673,
      "grad_norm": 0.4061797857284546,
      "learning_rate": 8.952135155248033e-06,
      "loss": 0.3119,
      "step": 6618
    },
    {
      "epoch": 0.10480231803283879,
      "grad_norm": 0.2671706974506378,
      "learning_rate": 8.951976819671612e-06,
      "loss": 0.0917,
      "step": 6619
    },
    {
      "epoch": 0.10481815159048087,
      "grad_norm": 0.21000570058822632,
      "learning_rate": 8.951818484095191e-06,
      "loss": 0.1326,
      "step": 6620
    },
    {
      "epoch": 0.10483398514812294,
      "grad_norm": 0.28923800587654114,
      "learning_rate": 8.951660148518772e-06,
      "loss": 0.2821,
      "step": 6621
    },
    {
      "epoch": 0.104849818705765,
      "grad_norm": 0.008272143080830574,
      "learning_rate": 8.95150181294235e-06,
      "loss": 0.0001,
      "step": 6622
    },
    {
      "epoch": 0.10486565226340706,
      "grad_norm": 0.00275671249255538,
      "learning_rate": 8.95134347736593e-06,
      "loss": 0.0001,
      "step": 6623
    },
    {
      "epoch": 0.10488148582104913,
      "grad_norm": 0.35855206847190857,
      "learning_rate": 8.95118514178951e-06,
      "loss": 0.095,
      "step": 6624
    },
    {
      "epoch": 0.10489731937869119,
      "grad_norm": 0.18302622437477112,
      "learning_rate": 8.951026806213088e-06,
      "loss": 0.0616,
      "step": 6625
    },
    {
      "epoch": 0.10491315293633327,
      "grad_norm": 0.43966835737228394,
      "learning_rate": 8.950868470636668e-06,
      "loss": 0.2392,
      "step": 6626
    },
    {
      "epoch": 0.10492898649397533,
      "grad_norm": 0.017098937183618546,
      "learning_rate": 8.950710135060248e-06,
      "loss": 0.0009,
      "step": 6627
    },
    {
      "epoch": 0.1049448200516174,
      "grad_norm": 0.7333496809005737,
      "learning_rate": 8.950551799483826e-06,
      "loss": 0.3826,
      "step": 6628
    },
    {
      "epoch": 0.10496065360925946,
      "grad_norm": 0.0007950409781187773,
      "learning_rate": 8.950393463907406e-06,
      "loss": 0.0,
      "step": 6629
    },
    {
      "epoch": 0.10497648716690153,
      "grad_norm": 0.01634349673986435,
      "learning_rate": 8.950235128330986e-06,
      "loss": 0.0009,
      "step": 6630
    },
    {
      "epoch": 0.10499232072454359,
      "grad_norm": 0.5546898245811462,
      "learning_rate": 8.950076792754565e-06,
      "loss": 0.2525,
      "step": 6631
    },
    {
      "epoch": 0.10500815428218567,
      "grad_norm": 0.1596575230360031,
      "learning_rate": 8.949918457178144e-06,
      "loss": 0.0419,
      "step": 6632
    },
    {
      "epoch": 0.10502398783982773,
      "grad_norm": 0.5245582461357117,
      "learning_rate": 8.949760121601725e-06,
      "loss": 0.5574,
      "step": 6633
    },
    {
      "epoch": 0.1050398213974698,
      "grad_norm": 0.00441468833014369,
      "learning_rate": 8.949601786025302e-06,
      "loss": 0.0002,
      "step": 6634
    },
    {
      "epoch": 0.10505565495511186,
      "grad_norm": 0.3429831266403198,
      "learning_rate": 8.949443450448883e-06,
      "loss": 0.1647,
      "step": 6635
    },
    {
      "epoch": 0.10507148851275393,
      "grad_norm": 0.00022252167400438339,
      "learning_rate": 8.949285114872462e-06,
      "loss": 0.0,
      "step": 6636
    },
    {
      "epoch": 0.10508732207039599,
      "grad_norm": 0.4724196493625641,
      "learning_rate": 8.94912677929604e-06,
      "loss": 0.2118,
      "step": 6637
    },
    {
      "epoch": 0.10510315562803807,
      "grad_norm": 0.2721337080001831,
      "learning_rate": 8.94896844371962e-06,
      "loss": 0.5766,
      "step": 6638
    },
    {
      "epoch": 0.10511898918568013,
      "grad_norm": 0.28408244252204895,
      "learning_rate": 8.9488101081432e-06,
      "loss": 0.0484,
      "step": 6639
    },
    {
      "epoch": 0.1051348227433222,
      "grad_norm": 0.22139593958854675,
      "learning_rate": 8.948651772566778e-06,
      "loss": 0.0574,
      "step": 6640
    },
    {
      "epoch": 0.10515065630096426,
      "grad_norm": 0.3248574137687683,
      "learning_rate": 8.948493436990357e-06,
      "loss": 0.0684,
      "step": 6641
    },
    {
      "epoch": 0.10516648985860633,
      "grad_norm": 0.6420885920524597,
      "learning_rate": 8.948335101413938e-06,
      "loss": 0.6071,
      "step": 6642
    },
    {
      "epoch": 0.10518232341624839,
      "grad_norm": 0.2447831630706787,
      "learning_rate": 8.948176765837517e-06,
      "loss": 0.061,
      "step": 6643
    },
    {
      "epoch": 0.10519815697389047,
      "grad_norm": 0.4411640465259552,
      "learning_rate": 8.948018430261096e-06,
      "loss": 0.1745,
      "step": 6644
    },
    {
      "epoch": 0.10521399053153253,
      "grad_norm": 0.02307569980621338,
      "learning_rate": 8.947860094684675e-06,
      "loss": 0.001,
      "step": 6645
    },
    {
      "epoch": 0.1052298240891746,
      "grad_norm": 0.02513674646615982,
      "learning_rate": 8.947701759108254e-06,
      "loss": 0.0014,
      "step": 6646
    },
    {
      "epoch": 0.10524565764681666,
      "grad_norm": 0.4618140161037445,
      "learning_rate": 8.947543423531833e-06,
      "loss": 0.6026,
      "step": 6647
    },
    {
      "epoch": 0.10526149120445873,
      "grad_norm": 0.24279719591140747,
      "learning_rate": 8.947385087955414e-06,
      "loss": 0.1526,
      "step": 6648
    },
    {
      "epoch": 0.10527732476210079,
      "grad_norm": 0.29644402861595154,
      "learning_rate": 8.947226752378993e-06,
      "loss": 0.0955,
      "step": 6649
    },
    {
      "epoch": 0.10529315831974287,
      "grad_norm": 0.28795957565307617,
      "learning_rate": 8.947068416802572e-06,
      "loss": 0.1149,
      "step": 6650
    },
    {
      "epoch": 0.10530899187738493,
      "grad_norm": 0.47112923860549927,
      "learning_rate": 8.946910081226151e-06,
      "loss": 0.3158,
      "step": 6651
    },
    {
      "epoch": 0.105324825435027,
      "grad_norm": 0.15054211020469666,
      "learning_rate": 8.94675174564973e-06,
      "loss": 0.0144,
      "step": 6652
    },
    {
      "epoch": 0.10534065899266906,
      "grad_norm": 6.268017023103312e-05,
      "learning_rate": 8.94659341007331e-06,
      "loss": 0.0,
      "step": 6653
    },
    {
      "epoch": 0.10535649255031113,
      "grad_norm": 0.004207860678434372,
      "learning_rate": 8.94643507449689e-06,
      "loss": 0.0001,
      "step": 6654
    },
    {
      "epoch": 0.10537232610795319,
      "grad_norm": 0.2026534527540207,
      "learning_rate": 8.94627673892047e-06,
      "loss": 0.0683,
      "step": 6655
    },
    {
      "epoch": 0.10538815966559527,
      "grad_norm": 0.40197280049324036,
      "learning_rate": 8.946118403344048e-06,
      "loss": 0.1148,
      "step": 6656
    },
    {
      "epoch": 0.10540399322323733,
      "grad_norm": 0.8316909670829773,
      "learning_rate": 8.945960067767627e-06,
      "loss": 0.1489,
      "step": 6657
    },
    {
      "epoch": 0.1054198267808794,
      "grad_norm": 0.02583734691143036,
      "learning_rate": 8.945801732191207e-06,
      "loss": 0.0018,
      "step": 6658
    },
    {
      "epoch": 0.10543566033852146,
      "grad_norm": 0.5558094382286072,
      "learning_rate": 8.945643396614786e-06,
      "loss": 0.0768,
      "step": 6659
    },
    {
      "epoch": 0.10545149389616353,
      "grad_norm": 0.27920371294021606,
      "learning_rate": 8.945485061038366e-06,
      "loss": 0.066,
      "step": 6660
    },
    {
      "epoch": 0.10546732745380559,
      "grad_norm": 0.8677597641944885,
      "learning_rate": 8.945326725461946e-06,
      "loss": 0.3611,
      "step": 6661
    },
    {
      "epoch": 0.10548316101144767,
      "grad_norm": 0.012287582270801067,
      "learning_rate": 8.945168389885525e-06,
      "loss": 0.0006,
      "step": 6662
    },
    {
      "epoch": 0.10549899456908973,
      "grad_norm": 0.01969277486205101,
      "learning_rate": 8.945010054309104e-06,
      "loss": 0.0008,
      "step": 6663
    },
    {
      "epoch": 0.1055148281267318,
      "grad_norm": 0.03437726944684982,
      "learning_rate": 8.944851718732683e-06,
      "loss": 0.002,
      "step": 6664
    },
    {
      "epoch": 0.10553066168437386,
      "grad_norm": 0.27719563245773315,
      "learning_rate": 8.944693383156262e-06,
      "loss": 0.0697,
      "step": 6665
    },
    {
      "epoch": 0.10554649524201593,
      "grad_norm": 0.2724049985408783,
      "learning_rate": 8.944535047579841e-06,
      "loss": 0.0555,
      "step": 6666
    },
    {
      "epoch": 0.10556232879965799,
      "grad_norm": 0.2979262173175812,
      "learning_rate": 8.944376712003422e-06,
      "loss": 0.1741,
      "step": 6667
    },
    {
      "epoch": 0.10557816235730007,
      "grad_norm": 0.32623639702796936,
      "learning_rate": 8.944218376426999e-06,
      "loss": 0.1433,
      "step": 6668
    },
    {
      "epoch": 0.10559399591494213,
      "grad_norm": 0.23222926259040833,
      "learning_rate": 8.94406004085058e-06,
      "loss": 0.1306,
      "step": 6669
    },
    {
      "epoch": 0.1056098294725842,
      "grad_norm": 0.04712998494505882,
      "learning_rate": 8.943901705274159e-06,
      "loss": 0.0023,
      "step": 6670
    },
    {
      "epoch": 0.10562566303022626,
      "grad_norm": 0.35787343978881836,
      "learning_rate": 8.943743369697738e-06,
      "loss": 0.0354,
      "step": 6671
    },
    {
      "epoch": 0.10564149658786832,
      "grad_norm": 0.33090102672576904,
      "learning_rate": 8.943585034121317e-06,
      "loss": 0.1339,
      "step": 6672
    },
    {
      "epoch": 0.10565733014551039,
      "grad_norm": 0.015677735209465027,
      "learning_rate": 8.943426698544896e-06,
      "loss": 0.0009,
      "step": 6673
    },
    {
      "epoch": 0.10567316370315247,
      "grad_norm": 0.16995474696159363,
      "learning_rate": 8.943268362968475e-06,
      "loss": 0.145,
      "step": 6674
    },
    {
      "epoch": 0.10568899726079453,
      "grad_norm": 0.21950310468673706,
      "learning_rate": 8.943110027392056e-06,
      "loss": 0.0943,
      "step": 6675
    },
    {
      "epoch": 0.1057048308184366,
      "grad_norm": 0.002412032103165984,
      "learning_rate": 8.942951691815635e-06,
      "loss": 0.0001,
      "step": 6676
    },
    {
      "epoch": 0.10572066437607866,
      "grad_norm": 1.0675426721572876,
      "learning_rate": 8.942793356239214e-06,
      "loss": 0.4429,
      "step": 6677
    },
    {
      "epoch": 0.10573649793372072,
      "grad_norm": 0.007134000305086374,
      "learning_rate": 8.942635020662793e-06,
      "loss": 0.0003,
      "step": 6678
    },
    {
      "epoch": 0.10575233149136279,
      "grad_norm": 0.00010201294207945466,
      "learning_rate": 8.942476685086372e-06,
      "loss": 0.0,
      "step": 6679
    },
    {
      "epoch": 0.10576816504900487,
      "grad_norm": 0.016332687810063362,
      "learning_rate": 8.942318349509951e-06,
      "loss": 0.0009,
      "step": 6680
    },
    {
      "epoch": 0.10578399860664693,
      "grad_norm": 0.007910153828561306,
      "learning_rate": 8.942160013933532e-06,
      "loss": 0.0001,
      "step": 6681
    },
    {
      "epoch": 0.105799832164289,
      "grad_norm": 0.29644158482551575,
      "learning_rate": 8.942001678357111e-06,
      "loss": 0.0763,
      "step": 6682
    },
    {
      "epoch": 0.10581566572193106,
      "grad_norm": 0.3604125380516052,
      "learning_rate": 8.94184334278069e-06,
      "loss": 0.0452,
      "step": 6683
    },
    {
      "epoch": 0.10583149927957312,
      "grad_norm": 0.29903244972229004,
      "learning_rate": 8.94168500720427e-06,
      "loss": 0.1202,
      "step": 6684
    },
    {
      "epoch": 0.10584733283721519,
      "grad_norm": 0.028142694383859634,
      "learning_rate": 8.941526671627848e-06,
      "loss": 0.0016,
      "step": 6685
    },
    {
      "epoch": 0.10586316639485727,
      "grad_norm": 0.3255418539047241,
      "learning_rate": 8.941368336051428e-06,
      "loss": 0.2095,
      "step": 6686
    },
    {
      "epoch": 0.10587899995249933,
      "grad_norm": 0.040250975638628006,
      "learning_rate": 8.941210000475008e-06,
      "loss": 0.0016,
      "step": 6687
    },
    {
      "epoch": 0.1058948335101414,
      "grad_norm": 0.2847473621368408,
      "learning_rate": 8.941051664898587e-06,
      "loss": 0.08,
      "step": 6688
    },
    {
      "epoch": 0.10591066706778346,
      "grad_norm": 0.24262410402297974,
      "learning_rate": 8.940893329322165e-06,
      "loss": 0.1644,
      "step": 6689
    },
    {
      "epoch": 0.10592650062542552,
      "grad_norm": 0.3818311393260956,
      "learning_rate": 8.940734993745746e-06,
      "loss": 0.1294,
      "step": 6690
    },
    {
      "epoch": 0.10594233418306759,
      "grad_norm": 0.18664100766181946,
      "learning_rate": 8.940576658169325e-06,
      "loss": 0.0357,
      "step": 6691
    },
    {
      "epoch": 0.10595816774070967,
      "grad_norm": 0.47223126888275146,
      "learning_rate": 8.940418322592904e-06,
      "loss": 0.7352,
      "step": 6692
    },
    {
      "epoch": 0.10597400129835173,
      "grad_norm": 0.14430852234363556,
      "learning_rate": 8.940259987016483e-06,
      "loss": 0.0077,
      "step": 6693
    },
    {
      "epoch": 0.1059898348559938,
      "grad_norm": 0.33130958676338196,
      "learning_rate": 8.940101651440064e-06,
      "loss": 0.2144,
      "step": 6694
    },
    {
      "epoch": 0.10600566841363586,
      "grad_norm": 0.5290124416351318,
      "learning_rate": 8.939943315863641e-06,
      "loss": 0.9573,
      "step": 6695
    },
    {
      "epoch": 0.10602150197127792,
      "grad_norm": 0.35470351576805115,
      "learning_rate": 8.939784980287222e-06,
      "loss": 0.2197,
      "step": 6696
    },
    {
      "epoch": 0.10603733552891999,
      "grad_norm": 0.1575280874967575,
      "learning_rate": 8.9396266447108e-06,
      "loss": 0.0217,
      "step": 6697
    },
    {
      "epoch": 0.10605316908656207,
      "grad_norm": 0.5085982084274292,
      "learning_rate": 8.93946830913438e-06,
      "loss": 0.6803,
      "step": 6698
    },
    {
      "epoch": 0.10606900264420413,
      "grad_norm": 0.2780337929725647,
      "learning_rate": 8.939309973557959e-06,
      "loss": 0.2176,
      "step": 6699
    },
    {
      "epoch": 0.1060848362018462,
      "grad_norm": 0.1683802455663681,
      "learning_rate": 8.93915163798154e-06,
      "loss": 0.0042,
      "step": 6700
    },
    {
      "epoch": 0.10610066975948826,
      "grad_norm": 0.21283738315105438,
      "learning_rate": 8.938993302405117e-06,
      "loss": 0.0982,
      "step": 6701
    },
    {
      "epoch": 0.10611650331713032,
      "grad_norm": 0.4303188621997833,
      "learning_rate": 8.938834966828698e-06,
      "loss": 0.4515,
      "step": 6702
    },
    {
      "epoch": 0.10613233687477239,
      "grad_norm": 0.25074079632759094,
      "learning_rate": 8.938676631252277e-06,
      "loss": 0.0983,
      "step": 6703
    },
    {
      "epoch": 0.10614817043241447,
      "grad_norm": 0.23089416325092316,
      "learning_rate": 8.938518295675856e-06,
      "loss": 0.1103,
      "step": 6704
    },
    {
      "epoch": 0.10616400399005653,
      "grad_norm": 3.8048809074098244e-05,
      "learning_rate": 8.938359960099435e-06,
      "loss": 0.0,
      "step": 6705
    },
    {
      "epoch": 0.1061798375476986,
      "grad_norm": 0.23932670056819916,
      "learning_rate": 8.938201624523016e-06,
      "loss": 0.1677,
      "step": 6706
    },
    {
      "epoch": 0.10619567110534066,
      "grad_norm": 0.24142643809318542,
      "learning_rate": 8.938043288946593e-06,
      "loss": 0.0972,
      "step": 6707
    },
    {
      "epoch": 0.10621150466298272,
      "grad_norm": 0.41334259510040283,
      "learning_rate": 8.937884953370174e-06,
      "loss": 0.4296,
      "step": 6708
    },
    {
      "epoch": 0.10622733822062479,
      "grad_norm": 0.12259159237146378,
      "learning_rate": 8.937726617793753e-06,
      "loss": 0.0341,
      "step": 6709
    },
    {
      "epoch": 0.10624317177826686,
      "grad_norm": 0.00014806042599957436,
      "learning_rate": 8.937568282217332e-06,
      "loss": 0.0,
      "step": 6710
    },
    {
      "epoch": 0.10625900533590893,
      "grad_norm": 0.00021176687732804567,
      "learning_rate": 8.937409946640911e-06,
      "loss": 0.0,
      "step": 6711
    },
    {
      "epoch": 0.106274838893551,
      "grad_norm": 0.027794091030955315,
      "learning_rate": 8.937251611064492e-06,
      "loss": 0.0013,
      "step": 6712
    },
    {
      "epoch": 0.10629067245119306,
      "grad_norm": 0.25418204069137573,
      "learning_rate": 8.93709327548807e-06,
      "loss": 0.0515,
      "step": 6713
    },
    {
      "epoch": 0.10630650600883512,
      "grad_norm": 0.8503859043121338,
      "learning_rate": 8.936934939911649e-06,
      "loss": 0.0261,
      "step": 6714
    },
    {
      "epoch": 0.10632233956647719,
      "grad_norm": 0.20703686773777008,
      "learning_rate": 8.93677660433523e-06,
      "loss": 0.0664,
      "step": 6715
    },
    {
      "epoch": 0.10633817312411926,
      "grad_norm": 0.14128802716732025,
      "learning_rate": 8.936618268758808e-06,
      "loss": 0.0346,
      "step": 6716
    },
    {
      "epoch": 0.10635400668176133,
      "grad_norm": 0.00012641315697692335,
      "learning_rate": 8.936459933182388e-06,
      "loss": 0.0,
      "step": 6717
    },
    {
      "epoch": 0.1063698402394034,
      "grad_norm": 0.2644961178302765,
      "learning_rate": 8.936301597605967e-06,
      "loss": 0.2934,
      "step": 6718
    },
    {
      "epoch": 0.10638567379704546,
      "grad_norm": 0.14351384341716766,
      "learning_rate": 8.936143262029546e-06,
      "loss": 0.0293,
      "step": 6719
    },
    {
      "epoch": 0.10640150735468752,
      "grad_norm": 0.2203962206840515,
      "learning_rate": 8.935984926453125e-06,
      "loss": 0.1332,
      "step": 6720
    },
    {
      "epoch": 0.10641734091232959,
      "grad_norm": 0.19303031265735626,
      "learning_rate": 8.935826590876706e-06,
      "loss": 0.0124,
      "step": 6721
    },
    {
      "epoch": 0.10643317446997166,
      "grad_norm": 0.000418553565395996,
      "learning_rate": 8.935668255300285e-06,
      "loss": 0.0,
      "step": 6722
    },
    {
      "epoch": 0.10644900802761373,
      "grad_norm": 0.013760445639491081,
      "learning_rate": 8.935509919723864e-06,
      "loss": 0.0006,
      "step": 6723
    },
    {
      "epoch": 0.10646484158525579,
      "grad_norm": 0.5644180774688721,
      "learning_rate": 8.935351584147443e-06,
      "loss": 0.0613,
      "step": 6724
    },
    {
      "epoch": 0.10648067514289786,
      "grad_norm": 0.5181608200073242,
      "learning_rate": 8.935193248571022e-06,
      "loss": 0.1837,
      "step": 6725
    },
    {
      "epoch": 0.10649650870053992,
      "grad_norm": 0.26818183064460754,
      "learning_rate": 8.935034912994601e-06,
      "loss": 0.0323,
      "step": 6726
    },
    {
      "epoch": 0.10651234225818199,
      "grad_norm": 0.3691476881504059,
      "learning_rate": 8.934876577418182e-06,
      "loss": 0.0773,
      "step": 6727
    },
    {
      "epoch": 0.10652817581582406,
      "grad_norm": 0.8295297622680664,
      "learning_rate": 8.93471824184176e-06,
      "loss": 0.7653,
      "step": 6728
    },
    {
      "epoch": 0.10654400937346613,
      "grad_norm": 0.45300570130348206,
      "learning_rate": 8.93455990626534e-06,
      "loss": 0.5,
      "step": 6729
    },
    {
      "epoch": 0.10655984293110819,
      "grad_norm": 7.430720143020153e-05,
      "learning_rate": 8.934401570688919e-06,
      "loss": 0.0,
      "step": 6730
    },
    {
      "epoch": 0.10657567648875026,
      "grad_norm": 0.6838234663009644,
      "learning_rate": 8.934243235112498e-06,
      "loss": 0.5789,
      "step": 6731
    },
    {
      "epoch": 0.10659151004639232,
      "grad_norm": 0.6271321177482605,
      "learning_rate": 8.934084899536077e-06,
      "loss": 0.9917,
      "step": 6732
    },
    {
      "epoch": 0.10660734360403439,
      "grad_norm": 0.005766826216131449,
      "learning_rate": 8.933926563959658e-06,
      "loss": 0.0001,
      "step": 6733
    },
    {
      "epoch": 0.10662317716167646,
      "grad_norm": 0.525950014591217,
      "learning_rate": 8.933768228383235e-06,
      "loss": 0.0073,
      "step": 6734
    },
    {
      "epoch": 0.10663901071931853,
      "grad_norm": 0.41885414719581604,
      "learning_rate": 8.933609892806816e-06,
      "loss": 0.1907,
      "step": 6735
    },
    {
      "epoch": 0.10665484427696059,
      "grad_norm": 0.015543658286333084,
      "learning_rate": 8.933451557230395e-06,
      "loss": 0.0009,
      "step": 6736
    },
    {
      "epoch": 0.10667067783460266,
      "grad_norm": 0.022539978846907616,
      "learning_rate": 8.933293221653974e-06,
      "loss": 0.0012,
      "step": 6737
    },
    {
      "epoch": 0.10668651139224472,
      "grad_norm": 0.32044652104377747,
      "learning_rate": 8.933134886077553e-06,
      "loss": 0.1168,
      "step": 6738
    },
    {
      "epoch": 0.10670234494988678,
      "grad_norm": 0.17522183060646057,
      "learning_rate": 8.932976550501132e-06,
      "loss": 0.0463,
      "step": 6739
    },
    {
      "epoch": 0.10671817850752886,
      "grad_norm": 0.40038028359413147,
      "learning_rate": 8.932818214924711e-06,
      "loss": 0.1601,
      "step": 6740
    },
    {
      "epoch": 0.10673401206517093,
      "grad_norm": 0.22117888927459717,
      "learning_rate": 8.93265987934829e-06,
      "loss": 0.1024,
      "step": 6741
    },
    {
      "epoch": 0.10674984562281299,
      "grad_norm": 0.5101818442344666,
      "learning_rate": 8.932501543771871e-06,
      "loss": 0.3511,
      "step": 6742
    },
    {
      "epoch": 0.10676567918045506,
      "grad_norm": 0.24334579706192017,
      "learning_rate": 8.93234320819545e-06,
      "loss": 0.0748,
      "step": 6743
    },
    {
      "epoch": 0.10678151273809712,
      "grad_norm": 0.39356282353401184,
      "learning_rate": 8.93218487261903e-06,
      "loss": 0.374,
      "step": 6744
    },
    {
      "epoch": 0.10679734629573918,
      "grad_norm": 0.42397740483283997,
      "learning_rate": 8.932026537042609e-06,
      "loss": 0.4599,
      "step": 6745
    },
    {
      "epoch": 0.10681317985338126,
      "grad_norm": 0.13875114917755127,
      "learning_rate": 8.931868201466188e-06,
      "loss": 0.0232,
      "step": 6746
    },
    {
      "epoch": 0.10682901341102333,
      "grad_norm": 0.030131321400403976,
      "learning_rate": 8.931709865889767e-06,
      "loss": 0.0019,
      "step": 6747
    },
    {
      "epoch": 0.10684484696866539,
      "grad_norm": 0.03645646199584007,
      "learning_rate": 8.931551530313347e-06,
      "loss": 0.0022,
      "step": 6748
    },
    {
      "epoch": 0.10686068052630746,
      "grad_norm": 9.655940812081099e-05,
      "learning_rate": 8.931393194736927e-06,
      "loss": 0.0,
      "step": 6749
    },
    {
      "epoch": 0.10687651408394952,
      "grad_norm": 0.3128759264945984,
      "learning_rate": 8.931234859160506e-06,
      "loss": 0.2801,
      "step": 6750
    },
    {
      "epoch": 0.10689234764159158,
      "grad_norm": 0.386849045753479,
      "learning_rate": 8.931076523584085e-06,
      "loss": 0.1406,
      "step": 6751
    },
    {
      "epoch": 0.10690818119923366,
      "grad_norm": 0.0007351890671998262,
      "learning_rate": 8.930918188007664e-06,
      "loss": 0.0001,
      "step": 6752
    },
    {
      "epoch": 0.10692401475687573,
      "grad_norm": 0.6122233867645264,
      "learning_rate": 8.930759852431243e-06,
      "loss": 0.3449,
      "step": 6753
    },
    {
      "epoch": 0.10693984831451779,
      "grad_norm": 0.25144392251968384,
      "learning_rate": 8.930601516854824e-06,
      "loss": 0.1624,
      "step": 6754
    },
    {
      "epoch": 0.10695568187215986,
      "grad_norm": 0.136821448802948,
      "learning_rate": 8.930443181278403e-06,
      "loss": 0.0657,
      "step": 6755
    },
    {
      "epoch": 0.10697151542980192,
      "grad_norm": 0.21691446006298065,
      "learning_rate": 8.930284845701982e-06,
      "loss": 0.1128,
      "step": 6756
    },
    {
      "epoch": 0.10698734898744398,
      "grad_norm": 0.043724823743104935,
      "learning_rate": 8.930126510125561e-06,
      "loss": 0.0022,
      "step": 6757
    },
    {
      "epoch": 0.10700318254508606,
      "grad_norm": 0.27325868606567383,
      "learning_rate": 8.92996817454914e-06,
      "loss": 0.0958,
      "step": 6758
    },
    {
      "epoch": 0.10701901610272813,
      "grad_norm": 0.5901439189910889,
      "learning_rate": 8.929809838972719e-06,
      "loss": 0.0077,
      "step": 6759
    },
    {
      "epoch": 0.10703484966037019,
      "grad_norm": 0.30793634057044983,
      "learning_rate": 8.9296515033963e-06,
      "loss": 0.1403,
      "step": 6760
    },
    {
      "epoch": 0.10705068321801225,
      "grad_norm": 0.010775490663945675,
      "learning_rate": 8.929493167819879e-06,
      "loss": 0.0003,
      "step": 6761
    },
    {
      "epoch": 0.10706651677565432,
      "grad_norm": 0.0001841911143856123,
      "learning_rate": 8.929334832243456e-06,
      "loss": 0.0,
      "step": 6762
    },
    {
      "epoch": 0.10708235033329638,
      "grad_norm": 0.2667900621891022,
      "learning_rate": 8.929176496667037e-06,
      "loss": 0.1374,
      "step": 6763
    },
    {
      "epoch": 0.10709818389093846,
      "grad_norm": 6.567583477590233e-05,
      "learning_rate": 8.929018161090616e-06,
      "loss": 0.0,
      "step": 6764
    },
    {
      "epoch": 0.10711401744858053,
      "grad_norm": 0.18892230093479156,
      "learning_rate": 8.928859825514195e-06,
      "loss": 0.0337,
      "step": 6765
    },
    {
      "epoch": 0.10712985100622259,
      "grad_norm": 0.19781553745269775,
      "learning_rate": 8.928701489937774e-06,
      "loss": 0.0461,
      "step": 6766
    },
    {
      "epoch": 0.10714568456386465,
      "grad_norm": 0.5742936730384827,
      "learning_rate": 8.928543154361355e-06,
      "loss": 0.1128,
      "step": 6767
    },
    {
      "epoch": 0.10716151812150672,
      "grad_norm": 0.2765716016292572,
      "learning_rate": 8.928384818784932e-06,
      "loss": 0.1722,
      "step": 6768
    },
    {
      "epoch": 0.10717735167914878,
      "grad_norm": 0.0007729142671450973,
      "learning_rate": 8.928226483208513e-06,
      "loss": 0.0,
      "step": 6769
    },
    {
      "epoch": 0.10719318523679086,
      "grad_norm": 0.05085207521915436,
      "learning_rate": 8.928068147632092e-06,
      "loss": 0.002,
      "step": 6770
    },
    {
      "epoch": 0.10720901879443293,
      "grad_norm": 0.009564503096044064,
      "learning_rate": 8.927909812055671e-06,
      "loss": 0.0005,
      "step": 6771
    },
    {
      "epoch": 0.10722485235207499,
      "grad_norm": 0.4008844196796417,
      "learning_rate": 8.92775147647925e-06,
      "loss": 0.2631,
      "step": 6772
    },
    {
      "epoch": 0.10724068590971705,
      "grad_norm": 0.031868431717157364,
      "learning_rate": 8.927593140902831e-06,
      "loss": 0.0018,
      "step": 6773
    },
    {
      "epoch": 0.10725651946735912,
      "grad_norm": 0.4390951097011566,
      "learning_rate": 8.927434805326409e-06,
      "loss": 0.5611,
      "step": 6774
    },
    {
      "epoch": 0.10727235302500118,
      "grad_norm": 0.20952017605304718,
      "learning_rate": 8.92727646974999e-06,
      "loss": 0.0906,
      "step": 6775
    },
    {
      "epoch": 0.10728818658264326,
      "grad_norm": 0.28282520174980164,
      "learning_rate": 8.927118134173568e-06,
      "loss": 0.6373,
      "step": 6776
    },
    {
      "epoch": 0.10730402014028532,
      "grad_norm": 2.1102703612996265e-05,
      "learning_rate": 8.926959798597148e-06,
      "loss": 0.0,
      "step": 6777
    },
    {
      "epoch": 0.10731985369792739,
      "grad_norm": 0.22667375206947327,
      "learning_rate": 8.926801463020727e-06,
      "loss": 0.007,
      "step": 6778
    },
    {
      "epoch": 0.10733568725556945,
      "grad_norm": 0.03940612077713013,
      "learning_rate": 8.926643127444307e-06,
      "loss": 0.0029,
      "step": 6779
    },
    {
      "epoch": 0.10735152081321152,
      "grad_norm": 1.3434451818466187,
      "learning_rate": 8.926484791867885e-06,
      "loss": 0.1442,
      "step": 6780
    },
    {
      "epoch": 0.10736735437085358,
      "grad_norm": 0.00887878704816103,
      "learning_rate": 8.926326456291466e-06,
      "loss": 0.0004,
      "step": 6781
    },
    {
      "epoch": 0.10738318792849566,
      "grad_norm": 0.24659770727157593,
      "learning_rate": 8.926168120715045e-06,
      "loss": 0.0075,
      "step": 6782
    },
    {
      "epoch": 0.10739902148613772,
      "grad_norm": 0.35467347502708435,
      "learning_rate": 8.926009785138624e-06,
      "loss": 0.0234,
      "step": 6783
    },
    {
      "epoch": 0.10741485504377979,
      "grad_norm": 0.6480320692062378,
      "learning_rate": 8.925851449562203e-06,
      "loss": 0.13,
      "step": 6784
    },
    {
      "epoch": 0.10743068860142185,
      "grad_norm": 0.45055675506591797,
      "learning_rate": 8.925693113985782e-06,
      "loss": 0.0795,
      "step": 6785
    },
    {
      "epoch": 0.10744652215906392,
      "grad_norm": 0.016275322064757347,
      "learning_rate": 8.925534778409361e-06,
      "loss": 0.0009,
      "step": 6786
    },
    {
      "epoch": 0.10746235571670598,
      "grad_norm": 0.17449887096881866,
      "learning_rate": 8.92537644283294e-06,
      "loss": 0.0805,
      "step": 6787
    },
    {
      "epoch": 0.10747818927434806,
      "grad_norm": 0.2703951597213745,
      "learning_rate": 8.92521810725652e-06,
      "loss": 0.0736,
      "step": 6788
    },
    {
      "epoch": 0.10749402283199012,
      "grad_norm": 0.01821259595453739,
      "learning_rate": 8.9250597716801e-06,
      "loss": 0.0009,
      "step": 6789
    },
    {
      "epoch": 0.10750985638963219,
      "grad_norm": 0.01878538355231285,
      "learning_rate": 8.924901436103679e-06,
      "loss": 0.001,
      "step": 6790
    },
    {
      "epoch": 0.10752568994727425,
      "grad_norm": 0.1587931215763092,
      "learning_rate": 8.924743100527258e-06,
      "loss": 0.046,
      "step": 6791
    },
    {
      "epoch": 0.10754152350491632,
      "grad_norm": 0.0006336323567666113,
      "learning_rate": 8.924584764950837e-06,
      "loss": 0.0,
      "step": 6792
    },
    {
      "epoch": 0.10755735706255838,
      "grad_norm": 0.2171107977628708,
      "learning_rate": 8.924426429374416e-06,
      "loss": 0.0048,
      "step": 6793
    },
    {
      "epoch": 0.10757319062020046,
      "grad_norm": 0.16589663922786713,
      "learning_rate": 8.924268093797997e-06,
      "loss": 0.1119,
      "step": 6794
    },
    {
      "epoch": 0.10758902417784252,
      "grad_norm": 0.5046569108963013,
      "learning_rate": 8.924109758221576e-06,
      "loss": 0.5851,
      "step": 6795
    },
    {
      "epoch": 0.10760485773548459,
      "grad_norm": 0.2587627172470093,
      "learning_rate": 8.923951422645155e-06,
      "loss": 0.1015,
      "step": 6796
    },
    {
      "epoch": 0.10762069129312665,
      "grad_norm": 0.39626166224479675,
      "learning_rate": 8.923793087068734e-06,
      "loss": 0.7416,
      "step": 6797
    },
    {
      "epoch": 0.10763652485076872,
      "grad_norm": 0.1390926092863083,
      "learning_rate": 8.923634751492313e-06,
      "loss": 0.0579,
      "step": 6798
    },
    {
      "epoch": 0.10765235840841078,
      "grad_norm": 0.4855715036392212,
      "learning_rate": 8.923476415915892e-06,
      "loss": 0.019,
      "step": 6799
    },
    {
      "epoch": 0.10766819196605286,
      "grad_norm": 0.00017743765783961862,
      "learning_rate": 8.923318080339473e-06,
      "loss": 0.0,
      "step": 6800
    },
    {
      "epoch": 0.10768402552369492,
      "grad_norm": 0.30695176124572754,
      "learning_rate": 8.92315974476305e-06,
      "loss": 0.1182,
      "step": 6801
    },
    {
      "epoch": 0.10769985908133699,
      "grad_norm": 0.29050371050834656,
      "learning_rate": 8.923001409186631e-06,
      "loss": 0.3538,
      "step": 6802
    },
    {
      "epoch": 0.10771569263897905,
      "grad_norm": 0.6136249303817749,
      "learning_rate": 8.92284307361021e-06,
      "loss": 0.149,
      "step": 6803
    },
    {
      "epoch": 0.10773152619662112,
      "grad_norm": 0.29736995697021484,
      "learning_rate": 8.92268473803379e-06,
      "loss": 0.2627,
      "step": 6804
    },
    {
      "epoch": 0.10774735975426318,
      "grad_norm": 0.19315031170845032,
      "learning_rate": 8.922526402457369e-06,
      "loss": 0.0827,
      "step": 6805
    },
    {
      "epoch": 0.10776319331190526,
      "grad_norm": 0.37572869658470154,
      "learning_rate": 8.92236806688095e-06,
      "loss": 0.3886,
      "step": 6806
    },
    {
      "epoch": 0.10777902686954732,
      "grad_norm": 0.4481651484966278,
      "learning_rate": 8.922209731304527e-06,
      "loss": 0.4979,
      "step": 6807
    },
    {
      "epoch": 0.10779486042718939,
      "grad_norm": 0.3198331892490387,
      "learning_rate": 8.922051395728107e-06,
      "loss": 0.0342,
      "step": 6808
    },
    {
      "epoch": 0.10781069398483145,
      "grad_norm": 0.0199113879352808,
      "learning_rate": 8.921893060151687e-06,
      "loss": 0.001,
      "step": 6809
    },
    {
      "epoch": 0.10782652754247352,
      "grad_norm": 0.00020002310338895768,
      "learning_rate": 8.921734724575266e-06,
      "loss": 0.0,
      "step": 6810
    },
    {
      "epoch": 0.10784236110011558,
      "grad_norm": 0.015633977949619293,
      "learning_rate": 8.921576388998845e-06,
      "loss": 0.0002,
      "step": 6811
    },
    {
      "epoch": 0.10785819465775766,
      "grad_norm": 0.6311742067337036,
      "learning_rate": 8.921418053422424e-06,
      "loss": 0.2439,
      "step": 6812
    },
    {
      "epoch": 0.10787402821539972,
      "grad_norm": 0.9596884846687317,
      "learning_rate": 8.921259717846003e-06,
      "loss": 0.1137,
      "step": 6813
    },
    {
      "epoch": 0.10788986177304179,
      "grad_norm": 0.658647358417511,
      "learning_rate": 8.921101382269582e-06,
      "loss": 0.3601,
      "step": 6814
    },
    {
      "epoch": 0.10790569533068385,
      "grad_norm": 0.4997839629650116,
      "learning_rate": 8.920943046693163e-06,
      "loss": 0.4211,
      "step": 6815
    },
    {
      "epoch": 0.10792152888832592,
      "grad_norm": 0.5533300638198853,
      "learning_rate": 8.920784711116742e-06,
      "loss": 1.0122,
      "step": 6816
    },
    {
      "epoch": 0.10793736244596798,
      "grad_norm": 0.49071216583251953,
      "learning_rate": 8.920626375540321e-06,
      "loss": 0.1554,
      "step": 6817
    },
    {
      "epoch": 0.10795319600361006,
      "grad_norm": 0.22891034185886383,
      "learning_rate": 8.9204680399639e-06,
      "loss": 0.2253,
      "step": 6818
    },
    {
      "epoch": 0.10796902956125212,
      "grad_norm": 0.22431719303131104,
      "learning_rate": 8.920309704387479e-06,
      "loss": 0.1357,
      "step": 6819
    },
    {
      "epoch": 0.10798486311889419,
      "grad_norm": 0.030808407813310623,
      "learning_rate": 8.920151368811058e-06,
      "loss": 0.0018,
      "step": 6820
    },
    {
      "epoch": 0.10800069667653625,
      "grad_norm": 0.49804919958114624,
      "learning_rate": 8.919993033234639e-06,
      "loss": 0.431,
      "step": 6821
    },
    {
      "epoch": 0.10801653023417832,
      "grad_norm": 0.42335590720176697,
      "learning_rate": 8.919834697658218e-06,
      "loss": 0.0535,
      "step": 6822
    },
    {
      "epoch": 0.10803236379182038,
      "grad_norm": 0.046683184802532196,
      "learning_rate": 8.919676362081797e-06,
      "loss": 0.004,
      "step": 6823
    },
    {
      "epoch": 0.10804819734946246,
      "grad_norm": 0.48404306173324585,
      "learning_rate": 8.919518026505376e-06,
      "loss": 0.0514,
      "step": 6824
    },
    {
      "epoch": 0.10806403090710452,
      "grad_norm": 0.06842531263828278,
      "learning_rate": 8.919359690928955e-06,
      "loss": 0.0027,
      "step": 6825
    },
    {
      "epoch": 0.10807986446474659,
      "grad_norm": 9.755175415193662e-05,
      "learning_rate": 8.919201355352534e-06,
      "loss": 0.0,
      "step": 6826
    },
    {
      "epoch": 0.10809569802238865,
      "grad_norm": 0.03220377862453461,
      "learning_rate": 8.919043019776115e-06,
      "loss": 0.0018,
      "step": 6827
    },
    {
      "epoch": 0.10811153158003071,
      "grad_norm": 0.27158844470977783,
      "learning_rate": 8.918884684199694e-06,
      "loss": 0.1194,
      "step": 6828
    },
    {
      "epoch": 0.10812736513767278,
      "grad_norm": 0.3047063648700714,
      "learning_rate": 8.918726348623273e-06,
      "loss": 0.1511,
      "step": 6829
    },
    {
      "epoch": 0.10814319869531486,
      "grad_norm": 0.5574204921722412,
      "learning_rate": 8.918568013046852e-06,
      "loss": 0.0565,
      "step": 6830
    },
    {
      "epoch": 0.10815903225295692,
      "grad_norm": 0.1876642256975174,
      "learning_rate": 8.918409677470431e-06,
      "loss": 0.0674,
      "step": 6831
    },
    {
      "epoch": 0.10817486581059899,
      "grad_norm": 0.3568030595779419,
      "learning_rate": 8.91825134189401e-06,
      "loss": 0.2995,
      "step": 6832
    },
    {
      "epoch": 0.10819069936824105,
      "grad_norm": 0.19638870656490326,
      "learning_rate": 8.91809300631759e-06,
      "loss": 0.0904,
      "step": 6833
    },
    {
      "epoch": 0.10820653292588311,
      "grad_norm": 0.01728522777557373,
      "learning_rate": 8.91793467074117e-06,
      "loss": 0.0004,
      "step": 6834
    },
    {
      "epoch": 0.10822236648352518,
      "grad_norm": 0.18610481917858124,
      "learning_rate": 8.917776335164748e-06,
      "loss": 0.0708,
      "step": 6835
    },
    {
      "epoch": 0.10823820004116726,
      "grad_norm": 0.4515998363494873,
      "learning_rate": 8.917617999588328e-06,
      "loss": 0.2849,
      "step": 6836
    },
    {
      "epoch": 0.10825403359880932,
      "grad_norm": 0.22720472514629364,
      "learning_rate": 8.917459664011908e-06,
      "loss": 0.0631,
      "step": 6837
    },
    {
      "epoch": 0.10826986715645139,
      "grad_norm": 0.31792956590652466,
      "learning_rate": 8.917301328435487e-06,
      "loss": 0.5175,
      "step": 6838
    },
    {
      "epoch": 0.10828570071409345,
      "grad_norm": 0.19177104532718658,
      "learning_rate": 8.917142992859066e-06,
      "loss": 0.098,
      "step": 6839
    },
    {
      "epoch": 0.10830153427173551,
      "grad_norm": 0.00010020247282227501,
      "learning_rate": 8.916984657282646e-06,
      "loss": 0.0,
      "step": 6840
    },
    {
      "epoch": 0.10831736782937758,
      "grad_norm": 0.006795153021812439,
      "learning_rate": 8.916826321706224e-06,
      "loss": 0.0003,
      "step": 6841
    },
    {
      "epoch": 0.10833320138701964,
      "grad_norm": 0.25129401683807373,
      "learning_rate": 8.916667986129805e-06,
      "loss": 0.0478,
      "step": 6842
    },
    {
      "epoch": 0.10834903494466172,
      "grad_norm": 0.3354836106300354,
      "learning_rate": 8.916509650553384e-06,
      "loss": 0.31,
      "step": 6843
    },
    {
      "epoch": 0.10836486850230378,
      "grad_norm": 0.18960988521575928,
      "learning_rate": 8.916351314976963e-06,
      "loss": 0.0868,
      "step": 6844
    },
    {
      "epoch": 0.10838070205994585,
      "grad_norm": 0.22736811637878418,
      "learning_rate": 8.916192979400542e-06,
      "loss": 0.0114,
      "step": 6845
    },
    {
      "epoch": 0.10839653561758791,
      "grad_norm": 0.337001234292984,
      "learning_rate": 8.916034643824123e-06,
      "loss": 0.0988,
      "step": 6846
    },
    {
      "epoch": 0.10841236917522998,
      "grad_norm": 0.4524233043193817,
      "learning_rate": 8.9158763082477e-06,
      "loss": 0.081,
      "step": 6847
    },
    {
      "epoch": 0.10842820273287204,
      "grad_norm": 0.07217478007078171,
      "learning_rate": 8.91571797267128e-06,
      "loss": 0.0028,
      "step": 6848
    },
    {
      "epoch": 0.10844403629051412,
      "grad_norm": 0.028645101934671402,
      "learning_rate": 8.91555963709486e-06,
      "loss": 0.0016,
      "step": 6849
    },
    {
      "epoch": 0.10845986984815618,
      "grad_norm": 0.30065953731536865,
      "learning_rate": 8.915401301518439e-06,
      "loss": 0.1565,
      "step": 6850
    },
    {
      "epoch": 0.10847570340579825,
      "grad_norm": 0.773141086101532,
      "learning_rate": 8.915242965942018e-06,
      "loss": 0.6453,
      "step": 6851
    },
    {
      "epoch": 0.10849153696344031,
      "grad_norm": 0.6109775304794312,
      "learning_rate": 8.915084630365599e-06,
      "loss": 0.1269,
      "step": 6852
    },
    {
      "epoch": 0.10850737052108238,
      "grad_norm": 0.2028496116399765,
      "learning_rate": 8.914926294789176e-06,
      "loss": 0.0487,
      "step": 6853
    },
    {
      "epoch": 0.10852320407872444,
      "grad_norm": 0.20913143455982208,
      "learning_rate": 8.914767959212757e-06,
      "loss": 0.0645,
      "step": 6854
    },
    {
      "epoch": 0.10853903763636652,
      "grad_norm": 0.15875568985939026,
      "learning_rate": 8.914609623636336e-06,
      "loss": 0.0631,
      "step": 6855
    },
    {
      "epoch": 0.10855487119400858,
      "grad_norm": 0.45819878578186035,
      "learning_rate": 8.914451288059915e-06,
      "loss": 0.2461,
      "step": 6856
    },
    {
      "epoch": 0.10857070475165065,
      "grad_norm": 0.13873226940631866,
      "learning_rate": 8.914292952483494e-06,
      "loss": 0.0431,
      "step": 6857
    },
    {
      "epoch": 0.10858653830929271,
      "grad_norm": 0.7889082431793213,
      "learning_rate": 8.914134616907073e-06,
      "loss": 0.113,
      "step": 6858
    },
    {
      "epoch": 0.10860237186693478,
      "grad_norm": 0.02601751498878002,
      "learning_rate": 8.913976281330652e-06,
      "loss": 0.0013,
      "step": 6859
    },
    {
      "epoch": 0.10861820542457684,
      "grad_norm": 0.001089943922124803,
      "learning_rate": 8.913817945754231e-06,
      "loss": 0.0,
      "step": 6860
    },
    {
      "epoch": 0.10863403898221892,
      "grad_norm": 0.33528226613998413,
      "learning_rate": 8.913659610177812e-06,
      "loss": 0.1905,
      "step": 6861
    },
    {
      "epoch": 0.10864987253986098,
      "grad_norm": 0.1506572961807251,
      "learning_rate": 8.913501274601391e-06,
      "loss": 0.0494,
      "step": 6862
    },
    {
      "epoch": 0.10866570609750305,
      "grad_norm": 0.21827110648155212,
      "learning_rate": 8.91334293902497e-06,
      "loss": 0.0499,
      "step": 6863
    },
    {
      "epoch": 0.10868153965514511,
      "grad_norm": 0.0003351521154399961,
      "learning_rate": 8.91318460344855e-06,
      "loss": 0.0,
      "step": 6864
    },
    {
      "epoch": 0.10869737321278718,
      "grad_norm": 0.034552332013845444,
      "learning_rate": 8.913026267872129e-06,
      "loss": 0.002,
      "step": 6865
    },
    {
      "epoch": 0.10871320677042924,
      "grad_norm": 0.00013034044241067022,
      "learning_rate": 8.912867932295708e-06,
      "loss": 0.0,
      "step": 6866
    },
    {
      "epoch": 0.10872904032807132,
      "grad_norm": 0.6354120373725891,
      "learning_rate": 8.912709596719288e-06,
      "loss": 0.2487,
      "step": 6867
    },
    {
      "epoch": 0.10874487388571338,
      "grad_norm": 0.21931219100952148,
      "learning_rate": 8.912551261142866e-06,
      "loss": 0.0504,
      "step": 6868
    },
    {
      "epoch": 0.10876070744335545,
      "grad_norm": 0.31282347440719604,
      "learning_rate": 8.912392925566447e-06,
      "loss": 0.6033,
      "step": 6869
    },
    {
      "epoch": 0.10877654100099751,
      "grad_norm": 0.48124074935913086,
      "learning_rate": 8.912234589990026e-06,
      "loss": 0.3203,
      "step": 6870
    },
    {
      "epoch": 0.10879237455863958,
      "grad_norm": 1.000041127204895,
      "learning_rate": 8.912076254413605e-06,
      "loss": 0.2964,
      "step": 6871
    },
    {
      "epoch": 0.10880820811628164,
      "grad_norm": 0.0002956062962766737,
      "learning_rate": 8.911917918837184e-06,
      "loss": 0.0,
      "step": 6872
    },
    {
      "epoch": 0.10882404167392372,
      "grad_norm": 0.4929989278316498,
      "learning_rate": 8.911759583260765e-06,
      "loss": 0.2376,
      "step": 6873
    },
    {
      "epoch": 0.10883987523156578,
      "grad_norm": 0.39714232087135315,
      "learning_rate": 8.911601247684342e-06,
      "loss": 0.113,
      "step": 6874
    },
    {
      "epoch": 0.10885570878920785,
      "grad_norm": 0.2472998946905136,
      "learning_rate": 8.911442912107923e-06,
      "loss": 0.1243,
      "step": 6875
    },
    {
      "epoch": 0.10887154234684991,
      "grad_norm": 0.10099094361066818,
      "learning_rate": 8.911284576531502e-06,
      "loss": 0.0019,
      "step": 6876
    },
    {
      "epoch": 0.10888737590449198,
      "grad_norm": 0.44783392548561096,
      "learning_rate": 8.911126240955081e-06,
      "loss": 0.4572,
      "step": 6877
    },
    {
      "epoch": 0.10890320946213404,
      "grad_norm": 0.0005662132753059268,
      "learning_rate": 8.91096790537866e-06,
      "loss": 0.0,
      "step": 6878
    },
    {
      "epoch": 0.10891904301977612,
      "grad_norm": 0.2837323248386383,
      "learning_rate": 8.91080956980224e-06,
      "loss": 0.0828,
      "step": 6879
    },
    {
      "epoch": 0.10893487657741818,
      "grad_norm": 0.22285571694374084,
      "learning_rate": 8.910651234225818e-06,
      "loss": 0.0589,
      "step": 6880
    },
    {
      "epoch": 0.10895071013506025,
      "grad_norm": 0.31410637497901917,
      "learning_rate": 8.910492898649399e-06,
      "loss": 0.1455,
      "step": 6881
    },
    {
      "epoch": 0.10896654369270231,
      "grad_norm": 0.2695140540599823,
      "learning_rate": 8.910334563072978e-06,
      "loss": 0.2958,
      "step": 6882
    },
    {
      "epoch": 0.10898237725034438,
      "grad_norm": 0.19269941747188568,
      "learning_rate": 8.910176227496557e-06,
      "loss": 0.0991,
      "step": 6883
    },
    {
      "epoch": 0.10899821080798644,
      "grad_norm": 0.016251733526587486,
      "learning_rate": 8.910017891920136e-06,
      "loss": 0.0009,
      "step": 6884
    },
    {
      "epoch": 0.10901404436562852,
      "grad_norm": 0.4852226674556732,
      "learning_rate": 8.909859556343715e-06,
      "loss": 0.3601,
      "step": 6885
    },
    {
      "epoch": 0.10902987792327058,
      "grad_norm": 0.5460600852966309,
      "learning_rate": 8.909701220767294e-06,
      "loss": 0.6641,
      "step": 6886
    },
    {
      "epoch": 0.10904571148091265,
      "grad_norm": 0.12502430379390717,
      "learning_rate": 8.909542885190873e-06,
      "loss": 0.0085,
      "step": 6887
    },
    {
      "epoch": 0.10906154503855471,
      "grad_norm": 0.973433792591095,
      "learning_rate": 8.909384549614454e-06,
      "loss": 0.1624,
      "step": 6888
    },
    {
      "epoch": 0.10907737859619678,
      "grad_norm": 0.35581615567207336,
      "learning_rate": 8.909226214038033e-06,
      "loss": 0.123,
      "step": 6889
    },
    {
      "epoch": 0.10909321215383884,
      "grad_norm": 0.7620685696601868,
      "learning_rate": 8.909067878461612e-06,
      "loss": 0.3853,
      "step": 6890
    },
    {
      "epoch": 0.10910904571148092,
      "grad_norm": 0.36021193861961365,
      "learning_rate": 8.908909542885191e-06,
      "loss": 0.3322,
      "step": 6891
    },
    {
      "epoch": 0.10912487926912298,
      "grad_norm": 0.3628001809120178,
      "learning_rate": 8.90875120730877e-06,
      "loss": 0.4532,
      "step": 6892
    },
    {
      "epoch": 0.10914071282676505,
      "grad_norm": 0.18528369069099426,
      "learning_rate": 8.90859287173235e-06,
      "loss": 0.0788,
      "step": 6893
    },
    {
      "epoch": 0.10915654638440711,
      "grad_norm": 0.29989612102508545,
      "learning_rate": 8.90843453615593e-06,
      "loss": 0.2718,
      "step": 6894
    },
    {
      "epoch": 0.10917237994204917,
      "grad_norm": 0.1822485625743866,
      "learning_rate": 8.90827620057951e-06,
      "loss": 0.1435,
      "step": 6895
    },
    {
      "epoch": 0.10918821349969124,
      "grad_norm": 0.3527382016181946,
      "learning_rate": 8.908117865003088e-06,
      "loss": 0.236,
      "step": 6896
    },
    {
      "epoch": 0.10920404705733332,
      "grad_norm": 0.007853522896766663,
      "learning_rate": 8.907959529426668e-06,
      "loss": 0.0003,
      "step": 6897
    },
    {
      "epoch": 0.10921988061497538,
      "grad_norm": 0.021018540486693382,
      "learning_rate": 8.907801193850247e-06,
      "loss": 0.0012,
      "step": 6898
    },
    {
      "epoch": 0.10923571417261745,
      "grad_norm": 0.20421847701072693,
      "learning_rate": 8.907642858273826e-06,
      "loss": 0.0036,
      "step": 6899
    },
    {
      "epoch": 0.10925154773025951,
      "grad_norm": 0.0017311389092355967,
      "learning_rate": 8.907484522697407e-06,
      "loss": 0.0,
      "step": 6900
    },
    {
      "epoch": 0.10926738128790157,
      "grad_norm": 0.22835484147071838,
      "learning_rate": 8.907326187120986e-06,
      "loss": 0.0795,
      "step": 6901
    },
    {
      "epoch": 0.10928321484554364,
      "grad_norm": 0.024142447859048843,
      "learning_rate": 8.907167851544565e-06,
      "loss": 0.0014,
      "step": 6902
    },
    {
      "epoch": 0.10929904840318572,
      "grad_norm": 0.0005558072007261217,
      "learning_rate": 8.907009515968144e-06,
      "loss": 0.0,
      "step": 6903
    },
    {
      "epoch": 0.10931488196082778,
      "grad_norm": 0.11679471284151077,
      "learning_rate": 8.906851180391723e-06,
      "loss": 0.0023,
      "step": 6904
    },
    {
      "epoch": 0.10933071551846985,
      "grad_norm": 0.23714099824428558,
      "learning_rate": 8.906692844815302e-06,
      "loss": 0.1028,
      "step": 6905
    },
    {
      "epoch": 0.10934654907611191,
      "grad_norm": 0.0002587309863884002,
      "learning_rate": 8.906534509238881e-06,
      "loss": 0.0,
      "step": 6906
    },
    {
      "epoch": 0.10936238263375397,
      "grad_norm": 0.3093526363372803,
      "learning_rate": 8.906376173662462e-06,
      "loss": 0.1937,
      "step": 6907
    },
    {
      "epoch": 0.10937821619139604,
      "grad_norm": 0.39053624868392944,
      "learning_rate": 8.906217838086039e-06,
      "loss": 0.0812,
      "step": 6908
    },
    {
      "epoch": 0.10939404974903812,
      "grad_norm": 0.20585545897483826,
      "learning_rate": 8.90605950250962e-06,
      "loss": 0.0974,
      "step": 6909
    },
    {
      "epoch": 0.10940988330668018,
      "grad_norm": 0.31127506494522095,
      "learning_rate": 8.905901166933199e-06,
      "loss": 0.1023,
      "step": 6910
    },
    {
      "epoch": 0.10942571686432224,
      "grad_norm": 0.34167230129241943,
      "learning_rate": 8.905742831356778e-06,
      "loss": 0.127,
      "step": 6911
    },
    {
      "epoch": 0.10944155042196431,
      "grad_norm": 0.4286126494407654,
      "learning_rate": 8.905584495780357e-06,
      "loss": 0.5232,
      "step": 6912
    },
    {
      "epoch": 0.10945738397960637,
      "grad_norm": 0.24816089868545532,
      "learning_rate": 8.905426160203938e-06,
      "loss": 0.0615,
      "step": 6913
    },
    {
      "epoch": 0.10947321753724844,
      "grad_norm": 0.03957192972302437,
      "learning_rate": 8.905267824627515e-06,
      "loss": 0.0023,
      "step": 6914
    },
    {
      "epoch": 0.10948905109489052,
      "grad_norm": 0.7632730603218079,
      "learning_rate": 8.905109489051096e-06,
      "loss": 0.6215,
      "step": 6915
    },
    {
      "epoch": 0.10950488465253258,
      "grad_norm": 0.4314371943473816,
      "learning_rate": 8.904951153474675e-06,
      "loss": 0.1111,
      "step": 6916
    },
    {
      "epoch": 0.10952071821017464,
      "grad_norm": 0.24503222107887268,
      "learning_rate": 8.904792817898254e-06,
      "loss": 0.118,
      "step": 6917
    },
    {
      "epoch": 0.10953655176781671,
      "grad_norm": 0.37519699335098267,
      "learning_rate": 8.904634482321833e-06,
      "loss": 0.24,
      "step": 6918
    },
    {
      "epoch": 0.10955238532545877,
      "grad_norm": 0.2644384801387787,
      "learning_rate": 8.904476146745414e-06,
      "loss": 0.1103,
      "step": 6919
    },
    {
      "epoch": 0.10956821888310084,
      "grad_norm": 0.5887815356254578,
      "learning_rate": 8.904317811168991e-06,
      "loss": 0.6517,
      "step": 6920
    },
    {
      "epoch": 0.10958405244074292,
      "grad_norm": 0.12441497296094894,
      "learning_rate": 8.904159475592572e-06,
      "loss": 0.0398,
      "step": 6921
    },
    {
      "epoch": 0.10959988599838498,
      "grad_norm": 0.410564661026001,
      "learning_rate": 8.904001140016151e-06,
      "loss": 0.2643,
      "step": 6922
    },
    {
      "epoch": 0.10961571955602704,
      "grad_norm": 0.416171669960022,
      "learning_rate": 8.90384280443973e-06,
      "loss": 0.0733,
      "step": 6923
    },
    {
      "epoch": 0.10963155311366911,
      "grad_norm": 0.00022984127281233668,
      "learning_rate": 8.90368446886331e-06,
      "loss": 0.0,
      "step": 6924
    },
    {
      "epoch": 0.10964738667131117,
      "grad_norm": 0.3698318600654602,
      "learning_rate": 8.903526133286889e-06,
      "loss": 0.1785,
      "step": 6925
    },
    {
      "epoch": 0.10966322022895324,
      "grad_norm": 0.32379353046417236,
      "learning_rate": 8.903367797710468e-06,
      "loss": 0.436,
      "step": 6926
    },
    {
      "epoch": 0.10967905378659532,
      "grad_norm": 0.021746143698692322,
      "learning_rate": 8.903209462134048e-06,
      "loss": 0.0017,
      "step": 6927
    },
    {
      "epoch": 0.10969488734423738,
      "grad_norm": 0.4286773204803467,
      "learning_rate": 8.903051126557628e-06,
      "loss": 0.07,
      "step": 6928
    },
    {
      "epoch": 0.10971072090187944,
      "grad_norm": 0.6502350568771362,
      "learning_rate": 8.902892790981207e-06,
      "loss": 0.2793,
      "step": 6929
    },
    {
      "epoch": 0.10972655445952151,
      "grad_norm": 0.3888164758682251,
      "learning_rate": 8.902734455404786e-06,
      "loss": 0.2006,
      "step": 6930
    },
    {
      "epoch": 0.10974238801716357,
      "grad_norm": 0.1971094012260437,
      "learning_rate": 8.902576119828365e-06,
      "loss": 0.0538,
      "step": 6931
    },
    {
      "epoch": 0.10975822157480564,
      "grad_norm": 0.3939545154571533,
      "learning_rate": 8.902417784251944e-06,
      "loss": 0.1552,
      "step": 6932
    },
    {
      "epoch": 0.10977405513244771,
      "grad_norm": 0.5450108647346497,
      "learning_rate": 8.902259448675523e-06,
      "loss": 0.0182,
      "step": 6933
    },
    {
      "epoch": 0.10978988869008978,
      "grad_norm": 0.2484874129295349,
      "learning_rate": 8.902101113099104e-06,
      "loss": 0.0576,
      "step": 6934
    },
    {
      "epoch": 0.10980572224773184,
      "grad_norm": 0.028535520657896996,
      "learning_rate": 8.901942777522681e-06,
      "loss": 0.0016,
      "step": 6935
    },
    {
      "epoch": 0.10982155580537391,
      "grad_norm": 0.3277340531349182,
      "learning_rate": 8.901784441946262e-06,
      "loss": 0.1799,
      "step": 6936
    },
    {
      "epoch": 0.10983738936301597,
      "grad_norm": 1.5917786359786987,
      "learning_rate": 8.901626106369841e-06,
      "loss": 0.2681,
      "step": 6937
    },
    {
      "epoch": 0.10985322292065804,
      "grad_norm": 0.0006476292619481683,
      "learning_rate": 8.90146777079342e-06,
      "loss": 0.0,
      "step": 6938
    },
    {
      "epoch": 0.10986905647830011,
      "grad_norm": 0.36246827244758606,
      "learning_rate": 8.901309435216999e-06,
      "loss": 0.4975,
      "step": 6939
    },
    {
      "epoch": 0.10988489003594218,
      "grad_norm": 0.07319879531860352,
      "learning_rate": 8.90115109964058e-06,
      "loss": 0.003,
      "step": 6940
    },
    {
      "epoch": 0.10990072359358424,
      "grad_norm": 0.21120290458202362,
      "learning_rate": 8.900992764064157e-06,
      "loss": 0.0562,
      "step": 6941
    },
    {
      "epoch": 0.10991655715122631,
      "grad_norm": 0.007535711862146854,
      "learning_rate": 8.900834428487738e-06,
      "loss": 0.0004,
      "step": 6942
    },
    {
      "epoch": 0.10993239070886837,
      "grad_norm": 0.32159966230392456,
      "learning_rate": 8.900676092911317e-06,
      "loss": 0.0432,
      "step": 6943
    },
    {
      "epoch": 0.10994822426651044,
      "grad_norm": 0.5700368881225586,
      "learning_rate": 8.900517757334896e-06,
      "loss": 0.6993,
      "step": 6944
    },
    {
      "epoch": 0.10996405782415251,
      "grad_norm": 0.3410378694534302,
      "learning_rate": 8.900359421758475e-06,
      "loss": 0.325,
      "step": 6945
    },
    {
      "epoch": 0.10997989138179458,
      "grad_norm": 0.3149202764034271,
      "learning_rate": 8.900201086182056e-06,
      "loss": 0.3582,
      "step": 6946
    },
    {
      "epoch": 0.10999572493943664,
      "grad_norm": 0.16030773520469666,
      "learning_rate": 8.900042750605633e-06,
      "loss": 0.0385,
      "step": 6947
    },
    {
      "epoch": 0.1100115584970787,
      "grad_norm": 0.6037896275520325,
      "learning_rate": 8.899884415029214e-06,
      "loss": 0.2021,
      "step": 6948
    },
    {
      "epoch": 0.11002739205472077,
      "grad_norm": 0.13030050694942474,
      "learning_rate": 8.899726079452793e-06,
      "loss": 0.0076,
      "step": 6949
    },
    {
      "epoch": 0.11004322561236284,
      "grad_norm": 0.2245105355978012,
      "learning_rate": 8.899567743876372e-06,
      "loss": 0.0246,
      "step": 6950
    },
    {
      "epoch": 0.11005905917000491,
      "grad_norm": 0.25877079367637634,
      "learning_rate": 8.899409408299951e-06,
      "loss": 0.0545,
      "step": 6951
    },
    {
      "epoch": 0.11007489272764698,
      "grad_norm": 0.23110511898994446,
      "learning_rate": 8.899251072723532e-06,
      "loss": 0.0818,
      "step": 6952
    },
    {
      "epoch": 0.11009072628528904,
      "grad_norm": 0.23018892109394073,
      "learning_rate": 8.89909273714711e-06,
      "loss": 0.0819,
      "step": 6953
    },
    {
      "epoch": 0.1101065598429311,
      "grad_norm": 0.23460781574249268,
      "learning_rate": 8.898934401570689e-06,
      "loss": 0.0476,
      "step": 6954
    },
    {
      "epoch": 0.11012239340057317,
      "grad_norm": 0.3368208408355713,
      "learning_rate": 8.89877606599427e-06,
      "loss": 0.1129,
      "step": 6955
    },
    {
      "epoch": 0.11013822695821524,
      "grad_norm": 0.2245928943157196,
      "learning_rate": 8.898617730417849e-06,
      "loss": 0.0721,
      "step": 6956
    },
    {
      "epoch": 0.11015406051585731,
      "grad_norm": 0.058581821620464325,
      "learning_rate": 8.898459394841428e-06,
      "loss": 0.0062,
      "step": 6957
    },
    {
      "epoch": 0.11016989407349938,
      "grad_norm": 0.02568196691572666,
      "learning_rate": 8.898301059265007e-06,
      "loss": 0.0016,
      "step": 6958
    },
    {
      "epoch": 0.11018572763114144,
      "grad_norm": 0.008698060177266598,
      "learning_rate": 8.898142723688586e-06,
      "loss": 0.0005,
      "step": 6959
    },
    {
      "epoch": 0.1102015611887835,
      "grad_norm": 0.2539716362953186,
      "learning_rate": 8.897984388112165e-06,
      "loss": 0.232,
      "step": 6960
    },
    {
      "epoch": 0.11021739474642557,
      "grad_norm": 0.599755048751831,
      "learning_rate": 8.897826052535746e-06,
      "loss": 0.0753,
      "step": 6961
    },
    {
      "epoch": 0.11023322830406763,
      "grad_norm": 0.0003255154879298061,
      "learning_rate": 8.897667716959325e-06,
      "loss": 0.0,
      "step": 6962
    },
    {
      "epoch": 0.11024906186170971,
      "grad_norm": 0.2788107693195343,
      "learning_rate": 8.897509381382904e-06,
      "loss": 0.0158,
      "step": 6963
    },
    {
      "epoch": 0.11026489541935178,
      "grad_norm": 12.02585220336914,
      "learning_rate": 8.897351045806483e-06,
      "loss": 0.5091,
      "step": 6964
    },
    {
      "epoch": 0.11028072897699384,
      "grad_norm": 0.2916555404663086,
      "learning_rate": 8.897192710230062e-06,
      "loss": 0.1449,
      "step": 6965
    },
    {
      "epoch": 0.1102965625346359,
      "grad_norm": 0.7883243560791016,
      "learning_rate": 8.897034374653641e-06,
      "loss": 0.4185,
      "step": 6966
    },
    {
      "epoch": 0.11031239609227797,
      "grad_norm": 0.010044741444289684,
      "learning_rate": 8.896876039077222e-06,
      "loss": 0.0005,
      "step": 6967
    },
    {
      "epoch": 0.11032822964992003,
      "grad_norm": 0.21202121675014496,
      "learning_rate": 8.896717703500801e-06,
      "loss": 0.0748,
      "step": 6968
    },
    {
      "epoch": 0.11034406320756211,
      "grad_norm": 0.016627755016088486,
      "learning_rate": 8.89655936792438e-06,
      "loss": 0.0016,
      "step": 6969
    },
    {
      "epoch": 0.11035989676520418,
      "grad_norm": 0.024920033290982246,
      "learning_rate": 8.896401032347959e-06,
      "loss": 0.0015,
      "step": 6970
    },
    {
      "epoch": 0.11037573032284624,
      "grad_norm": 0.0064788744784891605,
      "learning_rate": 8.896242696771538e-06,
      "loss": 0.0003,
      "step": 6971
    },
    {
      "epoch": 0.1103915638804883,
      "grad_norm": 0.8244412541389465,
      "learning_rate": 8.896084361195117e-06,
      "loss": 0.1568,
      "step": 6972
    },
    {
      "epoch": 0.11040739743813037,
      "grad_norm": 0.33747148513793945,
      "learning_rate": 8.895926025618698e-06,
      "loss": 0.1236,
      "step": 6973
    },
    {
      "epoch": 0.11042323099577243,
      "grad_norm": 0.028276018798351288,
      "learning_rate": 8.895767690042277e-06,
      "loss": 0.0018,
      "step": 6974
    },
    {
      "epoch": 0.11043906455341451,
      "grad_norm": 0.00935483630746603,
      "learning_rate": 8.895609354465856e-06,
      "loss": 0.0006,
      "step": 6975
    },
    {
      "epoch": 0.11045489811105658,
      "grad_norm": 0.2293916791677475,
      "learning_rate": 8.895451018889435e-06,
      "loss": 0.0035,
      "step": 6976
    },
    {
      "epoch": 0.11047073166869864,
      "grad_norm": 0.021382717415690422,
      "learning_rate": 8.895292683313014e-06,
      "loss": 0.0012,
      "step": 6977
    },
    {
      "epoch": 0.1104865652263407,
      "grad_norm": 0.2753181457519531,
      "learning_rate": 8.895134347736593e-06,
      "loss": 0.0614,
      "step": 6978
    },
    {
      "epoch": 0.11050239878398277,
      "grad_norm": 0.19066213071346283,
      "learning_rate": 8.894976012160172e-06,
      "loss": 0.0528,
      "step": 6979
    },
    {
      "epoch": 0.11051823234162483,
      "grad_norm": 1.2345954179763794,
      "learning_rate": 8.894817676583753e-06,
      "loss": 0.2714,
      "step": 6980
    },
    {
      "epoch": 0.11053406589926691,
      "grad_norm": 0.4370604455471039,
      "learning_rate": 8.89465934100733e-06,
      "loss": 0.0478,
      "step": 6981
    },
    {
      "epoch": 0.11054989945690898,
      "grad_norm": 0.00040118032484315336,
      "learning_rate": 8.894501005430911e-06,
      "loss": 0.0,
      "step": 6982
    },
    {
      "epoch": 0.11056573301455104,
      "grad_norm": 0.420086145401001,
      "learning_rate": 8.89434266985449e-06,
      "loss": 0.1601,
      "step": 6983
    },
    {
      "epoch": 0.1105815665721931,
      "grad_norm": 0.0005003801779821515,
      "learning_rate": 8.89418433427807e-06,
      "loss": 0.0,
      "step": 6984
    },
    {
      "epoch": 0.11059740012983517,
      "grad_norm": 0.1453615128993988,
      "learning_rate": 8.894025998701649e-06,
      "loss": 0.0828,
      "step": 6985
    },
    {
      "epoch": 0.11061323368747723,
      "grad_norm": 0.23724496364593506,
      "learning_rate": 8.89386766312523e-06,
      "loss": 0.0815,
      "step": 6986
    },
    {
      "epoch": 0.11062906724511931,
      "grad_norm": 0.00531930522993207,
      "learning_rate": 8.893709327548807e-06,
      "loss": 0.0003,
      "step": 6987
    },
    {
      "epoch": 0.11064490080276138,
      "grad_norm": 0.27784812450408936,
      "learning_rate": 8.893550991972388e-06,
      "loss": 0.021,
      "step": 6988
    },
    {
      "epoch": 0.11066073436040344,
      "grad_norm": 0.25785142183303833,
      "learning_rate": 8.893392656395967e-06,
      "loss": 0.438,
      "step": 6989
    },
    {
      "epoch": 0.1106765679180455,
      "grad_norm": 0.2746477425098419,
      "learning_rate": 8.893234320819546e-06,
      "loss": 0.1087,
      "step": 6990
    },
    {
      "epoch": 0.11069240147568757,
      "grad_norm": 0.3071039319038391,
      "learning_rate": 8.893075985243125e-06,
      "loss": 0.3186,
      "step": 6991
    },
    {
      "epoch": 0.11070823503332963,
      "grad_norm": 0.6217493414878845,
      "learning_rate": 8.892917649666704e-06,
      "loss": 0.4244,
      "step": 6992
    },
    {
      "epoch": 0.11072406859097171,
      "grad_norm": 0.13068632781505585,
      "learning_rate": 8.892759314090283e-06,
      "loss": 0.0459,
      "step": 6993
    },
    {
      "epoch": 0.11073990214861378,
      "grad_norm": 0.060960203409194946,
      "learning_rate": 8.892600978513864e-06,
      "loss": 0.0048,
      "step": 6994
    },
    {
      "epoch": 0.11075573570625584,
      "grad_norm": 0.001600557705387473,
      "learning_rate": 8.892442642937443e-06,
      "loss": 0.0001,
      "step": 6995
    },
    {
      "epoch": 0.1107715692638979,
      "grad_norm": 0.0025352893862873316,
      "learning_rate": 8.892284307361022e-06,
      "loss": 0.0001,
      "step": 6996
    },
    {
      "epoch": 0.11078740282153997,
      "grad_norm": 0.3715643584728241,
      "learning_rate": 8.892125971784601e-06,
      "loss": 0.0806,
      "step": 6997
    },
    {
      "epoch": 0.11080323637918203,
      "grad_norm": 0.2691090703010559,
      "learning_rate": 8.89196763620818e-06,
      "loss": 0.0894,
      "step": 6998
    },
    {
      "epoch": 0.11081906993682411,
      "grad_norm": 0.19397862255573273,
      "learning_rate": 8.891809300631759e-06,
      "loss": 0.0899,
      "step": 6999
    },
    {
      "epoch": 0.11083490349446617,
      "grad_norm": 0.5464333891868591,
      "learning_rate": 8.89165096505534e-06,
      "loss": 0.1568,
      "step": 7000
    },
    {
      "epoch": 0.11085073705210824,
      "grad_norm": 0.1589728444814682,
      "learning_rate": 8.891492629478919e-06,
      "loss": 0.0557,
      "step": 7001
    },
    {
      "epoch": 0.1108665706097503,
      "grad_norm": 1.1884936094284058,
      "learning_rate": 8.891334293902496e-06,
      "loss": 0.1017,
      "step": 7002
    },
    {
      "epoch": 0.11088240416739237,
      "grad_norm": 0.28212523460388184,
      "learning_rate": 8.891175958326077e-06,
      "loss": 0.1546,
      "step": 7003
    },
    {
      "epoch": 0.11089823772503443,
      "grad_norm": 0.0006325579597614706,
      "learning_rate": 8.891017622749656e-06,
      "loss": 0.0,
      "step": 7004
    },
    {
      "epoch": 0.11091407128267651,
      "grad_norm": 0.026037439703941345,
      "learning_rate": 8.890859287173235e-06,
      "loss": 0.0013,
      "step": 7005
    },
    {
      "epoch": 0.11092990484031857,
      "grad_norm": 0.3804605007171631,
      "learning_rate": 8.890700951596814e-06,
      "loss": 0.3792,
      "step": 7006
    },
    {
      "epoch": 0.11094573839796064,
      "grad_norm": 0.0005011238972656429,
      "learning_rate": 8.890542616020395e-06,
      "loss": 0.0,
      "step": 7007
    },
    {
      "epoch": 0.1109615719556027,
      "grad_norm": 0.17356400191783905,
      "learning_rate": 8.890384280443973e-06,
      "loss": 0.0265,
      "step": 7008
    },
    {
      "epoch": 0.11097740551324477,
      "grad_norm": 0.0003785620501730591,
      "learning_rate": 8.890225944867553e-06,
      "loss": 0.0,
      "step": 7009
    },
    {
      "epoch": 0.11099323907088683,
      "grad_norm": 0.1694219708442688,
      "learning_rate": 8.890067609291132e-06,
      "loss": 0.0637,
      "step": 7010
    },
    {
      "epoch": 0.11100907262852891,
      "grad_norm": 0.2454044222831726,
      "learning_rate": 8.889909273714711e-06,
      "loss": 0.1939,
      "step": 7011
    },
    {
      "epoch": 0.11102490618617097,
      "grad_norm": 0.3715118169784546,
      "learning_rate": 8.88975093813829e-06,
      "loss": 0.2263,
      "step": 7012
    },
    {
      "epoch": 0.11104073974381304,
      "grad_norm": 0.21878688037395477,
      "learning_rate": 8.889592602561871e-06,
      "loss": 0.0726,
      "step": 7013
    },
    {
      "epoch": 0.1110565733014551,
      "grad_norm": 0.3075765073299408,
      "learning_rate": 8.889434266985449e-06,
      "loss": 0.0599,
      "step": 7014
    },
    {
      "epoch": 0.11107240685909717,
      "grad_norm": 0.1828518956899643,
      "learning_rate": 8.88927593140903e-06,
      "loss": 0.1031,
      "step": 7015
    },
    {
      "epoch": 0.11108824041673923,
      "grad_norm": 0.4901905357837677,
      "learning_rate": 8.889117595832609e-06,
      "loss": 0.7045,
      "step": 7016
    },
    {
      "epoch": 0.11110407397438131,
      "grad_norm": 0.17768411338329315,
      "learning_rate": 8.888959260256188e-06,
      "loss": 0.0662,
      "step": 7017
    },
    {
      "epoch": 0.11111990753202337,
      "grad_norm": 0.00046313440543599427,
      "learning_rate": 8.888800924679767e-06,
      "loss": 0.0,
      "step": 7018
    },
    {
      "epoch": 0.11113574108966544,
      "grad_norm": 0.0003429871576372534,
      "learning_rate": 8.888642589103347e-06,
      "loss": 0.0,
      "step": 7019
    },
    {
      "epoch": 0.1111515746473075,
      "grad_norm": 0.344483345746994,
      "learning_rate": 8.888484253526925e-06,
      "loss": 0.0926,
      "step": 7020
    },
    {
      "epoch": 0.11116740820494957,
      "grad_norm": 0.21135376393795013,
      "learning_rate": 8.888325917950506e-06,
      "loss": 0.1366,
      "step": 7021
    },
    {
      "epoch": 0.11118324176259163,
      "grad_norm": 0.000748274615034461,
      "learning_rate": 8.888167582374085e-06,
      "loss": 0.0,
      "step": 7022
    },
    {
      "epoch": 0.11119907532023371,
      "grad_norm": 0.00552420224994421,
      "learning_rate": 8.888009246797664e-06,
      "loss": 0.0004,
      "step": 7023
    },
    {
      "epoch": 0.11121490887787577,
      "grad_norm": 0.6696069240570068,
      "learning_rate": 8.887850911221243e-06,
      "loss": 0.5013,
      "step": 7024
    },
    {
      "epoch": 0.11123074243551784,
      "grad_norm": 0.30698084831237793,
      "learning_rate": 8.887692575644824e-06,
      "loss": 0.2886,
      "step": 7025
    },
    {
      "epoch": 0.1112465759931599,
      "grad_norm": 0.3809652328491211,
      "learning_rate": 8.887534240068401e-06,
      "loss": 0.6465,
      "step": 7026
    },
    {
      "epoch": 0.11126240955080197,
      "grad_norm": 0.27350178360939026,
      "learning_rate": 8.88737590449198e-06,
      "loss": 0.0933,
      "step": 7027
    },
    {
      "epoch": 0.11127824310844403,
      "grad_norm": 0.23168940842151642,
      "learning_rate": 8.887217568915561e-06,
      "loss": 0.1102,
      "step": 7028
    },
    {
      "epoch": 0.11129407666608611,
      "grad_norm": 0.12976980209350586,
      "learning_rate": 8.88705923333914e-06,
      "loss": 0.0502,
      "step": 7029
    },
    {
      "epoch": 0.11130991022372817,
      "grad_norm": 0.1668952852487564,
      "learning_rate": 8.886900897762719e-06,
      "loss": 0.0316,
      "step": 7030
    },
    {
      "epoch": 0.11132574378137024,
      "grad_norm": 0.18409475684165955,
      "learning_rate": 8.886742562186298e-06,
      "loss": 0.0081,
      "step": 7031
    },
    {
      "epoch": 0.1113415773390123,
      "grad_norm": 0.29327595233917236,
      "learning_rate": 8.886584226609877e-06,
      "loss": 0.0822,
      "step": 7032
    },
    {
      "epoch": 0.11135741089665437,
      "grad_norm": 0.011432248167693615,
      "learning_rate": 8.886425891033456e-06,
      "loss": 0.0007,
      "step": 7033
    },
    {
      "epoch": 0.11137324445429643,
      "grad_norm": 0.1208147406578064,
      "learning_rate": 8.886267555457037e-06,
      "loss": 0.0302,
      "step": 7034
    },
    {
      "epoch": 0.11138907801193851,
      "grad_norm": 0.39330339431762695,
      "learning_rate": 8.886109219880616e-06,
      "loss": 0.62,
      "step": 7035
    },
    {
      "epoch": 0.11140491156958057,
      "grad_norm": 0.3015775680541992,
      "learning_rate": 8.885950884304195e-06,
      "loss": 0.0552,
      "step": 7036
    },
    {
      "epoch": 0.11142074512722264,
      "grad_norm": 0.4310759902000427,
      "learning_rate": 8.885792548727774e-06,
      "loss": 0.1207,
      "step": 7037
    },
    {
      "epoch": 0.1114365786848647,
      "grad_norm": 0.4784090220928192,
      "learning_rate": 8.885634213151353e-06,
      "loss": 0.5301,
      "step": 7038
    },
    {
      "epoch": 0.11145241224250677,
      "grad_norm": 0.0002506955643184483,
      "learning_rate": 8.885475877574932e-06,
      "loss": 0.0,
      "step": 7039
    },
    {
      "epoch": 0.11146824580014883,
      "grad_norm": 0.027431583032011986,
      "learning_rate": 8.885317541998513e-06,
      "loss": 0.0019,
      "step": 7040
    },
    {
      "epoch": 0.11148407935779091,
      "grad_norm": 0.14919085800647736,
      "learning_rate": 8.885159206422092e-06,
      "loss": 0.0646,
      "step": 7041
    },
    {
      "epoch": 0.11149991291543297,
      "grad_norm": 0.42998677492141724,
      "learning_rate": 8.885000870845671e-06,
      "loss": 0.3359,
      "step": 7042
    },
    {
      "epoch": 0.11151574647307504,
      "grad_norm": 0.17734427750110626,
      "learning_rate": 8.88484253526925e-06,
      "loss": 0.1613,
      "step": 7043
    },
    {
      "epoch": 0.1115315800307171,
      "grad_norm": 0.022869817912578583,
      "learning_rate": 8.88468419969283e-06,
      "loss": 0.0017,
      "step": 7044
    },
    {
      "epoch": 0.11154741358835916,
      "grad_norm": 0.010829984210431576,
      "learning_rate": 8.884525864116409e-06,
      "loss": 0.0006,
      "step": 7045
    },
    {
      "epoch": 0.11156324714600123,
      "grad_norm": 0.09481406956911087,
      "learning_rate": 8.88436752853999e-06,
      "loss": 0.0176,
      "step": 7046
    },
    {
      "epoch": 0.11157908070364331,
      "grad_norm": 0.36920782923698425,
      "learning_rate": 8.884209192963568e-06,
      "loss": 0.378,
      "step": 7047
    },
    {
      "epoch": 0.11159491426128537,
      "grad_norm": 0.313017874956131,
      "learning_rate": 8.884050857387148e-06,
      "loss": 0.0746,
      "step": 7048
    },
    {
      "epoch": 0.11161074781892744,
      "grad_norm": 0.20263703167438507,
      "learning_rate": 8.883892521810727e-06,
      "loss": 0.08,
      "step": 7049
    },
    {
      "epoch": 0.1116265813765695,
      "grad_norm": 0.3928851783275604,
      "learning_rate": 8.883734186234306e-06,
      "loss": 0.2318,
      "step": 7050
    },
    {
      "epoch": 0.11164241493421156,
      "grad_norm": 0.011815800331532955,
      "learning_rate": 8.883575850657885e-06,
      "loss": 0.0005,
      "step": 7051
    },
    {
      "epoch": 0.11165824849185363,
      "grad_norm": 8.900015382096171e-05,
      "learning_rate": 8.883417515081464e-06,
      "loss": 0.0,
      "step": 7052
    },
    {
      "epoch": 0.11167408204949571,
      "grad_norm": 0.3762110769748688,
      "learning_rate": 8.883259179505043e-06,
      "loss": 0.4622,
      "step": 7053
    },
    {
      "epoch": 0.11168991560713777,
      "grad_norm": 0.25111228227615356,
      "learning_rate": 8.883100843928622e-06,
      "loss": 0.0797,
      "step": 7054
    },
    {
      "epoch": 0.11170574916477984,
      "grad_norm": 0.6386998295783997,
      "learning_rate": 8.882942508352203e-06,
      "loss": 0.1049,
      "step": 7055
    },
    {
      "epoch": 0.1117215827224219,
      "grad_norm": 0.28007787466049194,
      "learning_rate": 8.882784172775782e-06,
      "loss": 0.2115,
      "step": 7056
    },
    {
      "epoch": 0.11173741628006396,
      "grad_norm": 0.007778991479426622,
      "learning_rate": 8.882625837199361e-06,
      "loss": 0.0003,
      "step": 7057
    },
    {
      "epoch": 0.11175324983770603,
      "grad_norm": 0.013555037789046764,
      "learning_rate": 8.88246750162294e-06,
      "loss": 0.0007,
      "step": 7058
    },
    {
      "epoch": 0.1117690833953481,
      "grad_norm": 0.32016685605049133,
      "learning_rate": 8.882309166046519e-06,
      "loss": 0.0691,
      "step": 7059
    },
    {
      "epoch": 0.11178491695299017,
      "grad_norm": 0.4818119704723358,
      "learning_rate": 8.882150830470098e-06,
      "loss": 0.0973,
      "step": 7060
    },
    {
      "epoch": 0.11180075051063224,
      "grad_norm": 0.011903275735676289,
      "learning_rate": 8.881992494893679e-06,
      "loss": 0.0008,
      "step": 7061
    },
    {
      "epoch": 0.1118165840682743,
      "grad_norm": 0.3883002996444702,
      "learning_rate": 8.881834159317258e-06,
      "loss": 0.2841,
      "step": 7062
    },
    {
      "epoch": 0.11183241762591636,
      "grad_norm": 0.01300143077969551,
      "learning_rate": 8.881675823740837e-06,
      "loss": 0.0007,
      "step": 7063
    },
    {
      "epoch": 0.11184825118355843,
      "grad_norm": 0.049108751118183136,
      "learning_rate": 8.881517488164416e-06,
      "loss": 0.003,
      "step": 7064
    },
    {
      "epoch": 0.1118640847412005,
      "grad_norm": 0.1330568492412567,
      "learning_rate": 8.881359152587995e-06,
      "loss": 0.0316,
      "step": 7065
    },
    {
      "epoch": 0.11187991829884257,
      "grad_norm": 0.0967390164732933,
      "learning_rate": 8.881200817011574e-06,
      "loss": 0.0321,
      "step": 7066
    },
    {
      "epoch": 0.11189575185648463,
      "grad_norm": 0.030386531725525856,
      "learning_rate": 8.881042481435155e-06,
      "loss": 0.0017,
      "step": 7067
    },
    {
      "epoch": 0.1119115854141267,
      "grad_norm": 0.3539581298828125,
      "learning_rate": 8.880884145858734e-06,
      "loss": 0.1266,
      "step": 7068
    },
    {
      "epoch": 0.11192741897176876,
      "grad_norm": 0.41464880108833313,
      "learning_rate": 8.880725810282313e-06,
      "loss": 0.1348,
      "step": 7069
    },
    {
      "epoch": 0.11194325252941083,
      "grad_norm": 0.3936523199081421,
      "learning_rate": 8.880567474705892e-06,
      "loss": 0.0184,
      "step": 7070
    },
    {
      "epoch": 0.1119590860870529,
      "grad_norm": 0.24021925032138824,
      "learning_rate": 8.880409139129471e-06,
      "loss": 0.102,
      "step": 7071
    },
    {
      "epoch": 0.11197491964469497,
      "grad_norm": 0.43747758865356445,
      "learning_rate": 8.88025080355305e-06,
      "loss": 0.2044,
      "step": 7072
    },
    {
      "epoch": 0.11199075320233703,
      "grad_norm": 0.005935771856456995,
      "learning_rate": 8.880092467976631e-06,
      "loss": 0.0002,
      "step": 7073
    },
    {
      "epoch": 0.1120065867599791,
      "grad_norm": 0.24555248022079468,
      "learning_rate": 8.87993413240021e-06,
      "loss": 0.0398,
      "step": 7074
    },
    {
      "epoch": 0.11202242031762116,
      "grad_norm": 0.42831575870513916,
      "learning_rate": 8.879775796823788e-06,
      "loss": 0.013,
      "step": 7075
    },
    {
      "epoch": 0.11203825387526323,
      "grad_norm": 0.23285415768623352,
      "learning_rate": 8.879617461247369e-06,
      "loss": 0.0338,
      "step": 7076
    },
    {
      "epoch": 0.1120540874329053,
      "grad_norm": 0.2322399765253067,
      "learning_rate": 8.879459125670948e-06,
      "loss": 0.0637,
      "step": 7077
    },
    {
      "epoch": 0.11206992099054737,
      "grad_norm": 0.4054013192653656,
      "learning_rate": 8.879300790094527e-06,
      "loss": 0.0823,
      "step": 7078
    },
    {
      "epoch": 0.11208575454818943,
      "grad_norm": 0.3830890655517578,
      "learning_rate": 8.879142454518106e-06,
      "loss": 0.1002,
      "step": 7079
    },
    {
      "epoch": 0.1121015881058315,
      "grad_norm": 0.747948408126831,
      "learning_rate": 8.878984118941687e-06,
      "loss": 0.2286,
      "step": 7080
    },
    {
      "epoch": 0.11211742166347356,
      "grad_norm": 0.18977370858192444,
      "learning_rate": 8.878825783365264e-06,
      "loss": 0.0607,
      "step": 7081
    },
    {
      "epoch": 0.11213325522111563,
      "grad_norm": 0.004887963645160198,
      "learning_rate": 8.878667447788845e-06,
      "loss": 0.0003,
      "step": 7082
    },
    {
      "epoch": 0.1121490887787577,
      "grad_norm": 0.13309159874916077,
      "learning_rate": 8.878509112212424e-06,
      "loss": 0.0461,
      "step": 7083
    },
    {
      "epoch": 0.11216492233639977,
      "grad_norm": 0.5297773480415344,
      "learning_rate": 8.878350776636003e-06,
      "loss": 0.2699,
      "step": 7084
    },
    {
      "epoch": 0.11218075589404183,
      "grad_norm": 0.0056137097999453545,
      "learning_rate": 8.878192441059582e-06,
      "loss": 0.0002,
      "step": 7085
    },
    {
      "epoch": 0.1121965894516839,
      "grad_norm": 0.007689402438700199,
      "learning_rate": 8.878034105483163e-06,
      "loss": 0.0004,
      "step": 7086
    },
    {
      "epoch": 0.11221242300932596,
      "grad_norm": 0.5103203654289246,
      "learning_rate": 8.87787576990674e-06,
      "loss": 0.25,
      "step": 7087
    },
    {
      "epoch": 0.11222825656696803,
      "grad_norm": 0.20252028107643127,
      "learning_rate": 8.877717434330321e-06,
      "loss": 0.0464,
      "step": 7088
    },
    {
      "epoch": 0.1122440901246101,
      "grad_norm": 0.005900022108107805,
      "learning_rate": 8.8775590987539e-06,
      "loss": 0.0003,
      "step": 7089
    },
    {
      "epoch": 0.11225992368225217,
      "grad_norm": 0.177372008562088,
      "learning_rate": 8.877400763177479e-06,
      "loss": 0.0362,
      "step": 7090
    },
    {
      "epoch": 0.11227575723989423,
      "grad_norm": 0.26688432693481445,
      "learning_rate": 8.877242427601058e-06,
      "loss": 0.1156,
      "step": 7091
    },
    {
      "epoch": 0.1122915907975363,
      "grad_norm": 0.3344757556915283,
      "learning_rate": 8.877084092024639e-06,
      "loss": 0.1466,
      "step": 7092
    },
    {
      "epoch": 0.11230742435517836,
      "grad_norm": 0.23657968640327454,
      "learning_rate": 8.876925756448216e-06,
      "loss": 0.0526,
      "step": 7093
    },
    {
      "epoch": 0.11232325791282043,
      "grad_norm": 0.02129734307527542,
      "learning_rate": 8.876767420871797e-06,
      "loss": 0.0009,
      "step": 7094
    },
    {
      "epoch": 0.1123390914704625,
      "grad_norm": 0.006493996363133192,
      "learning_rate": 8.876609085295376e-06,
      "loss": 0.0003,
      "step": 7095
    },
    {
      "epoch": 0.11235492502810457,
      "grad_norm": 0.1860923022031784,
      "learning_rate": 8.876450749718955e-06,
      "loss": 0.0609,
      "step": 7096
    },
    {
      "epoch": 0.11237075858574663,
      "grad_norm": 0.740945041179657,
      "learning_rate": 8.876292414142534e-06,
      "loss": 0.3183,
      "step": 7097
    },
    {
      "epoch": 0.1123865921433887,
      "grad_norm": 0.19507735967636108,
      "learning_rate": 8.876134078566113e-06,
      "loss": 0.0564,
      "step": 7098
    },
    {
      "epoch": 0.11240242570103076,
      "grad_norm": 0.14730416238307953,
      "learning_rate": 8.875975742989692e-06,
      "loss": 0.0464,
      "step": 7099
    },
    {
      "epoch": 0.11241825925867283,
      "grad_norm": 0.0005930543411523104,
      "learning_rate": 8.875817407413272e-06,
      "loss": 0.0,
      "step": 7100
    },
    {
      "epoch": 0.1124340928163149,
      "grad_norm": 0.40200379490852356,
      "learning_rate": 8.875659071836852e-06,
      "loss": 0.0873,
      "step": 7101
    },
    {
      "epoch": 0.11244992637395697,
      "grad_norm": 0.3834512531757355,
      "learning_rate": 8.875500736260431e-06,
      "loss": 0.3461,
      "step": 7102
    },
    {
      "epoch": 0.11246575993159903,
      "grad_norm": 0.008894979022443295,
      "learning_rate": 8.87534240068401e-06,
      "loss": 0.0003,
      "step": 7103
    },
    {
      "epoch": 0.1124815934892411,
      "grad_norm": 0.37352293729782104,
      "learning_rate": 8.87518406510759e-06,
      "loss": 0.1952,
      "step": 7104
    },
    {
      "epoch": 0.11249742704688316,
      "grad_norm": 0.20470522344112396,
      "learning_rate": 8.875025729531169e-06,
      "loss": 0.0913,
      "step": 7105
    },
    {
      "epoch": 0.11251326060452523,
      "grad_norm": 0.19705326855182648,
      "learning_rate": 8.874867393954748e-06,
      "loss": 0.0774,
      "step": 7106
    },
    {
      "epoch": 0.1125290941621673,
      "grad_norm": 0.34886670112609863,
      "learning_rate": 8.874709058378328e-06,
      "loss": 0.1514,
      "step": 7107
    },
    {
      "epoch": 0.11254492771980937,
      "grad_norm": 0.38014617562294006,
      "learning_rate": 8.874550722801908e-06,
      "loss": 0.2057,
      "step": 7108
    },
    {
      "epoch": 0.11256076127745143,
      "grad_norm": 0.44613951444625854,
      "learning_rate": 8.874392387225487e-06,
      "loss": 0.1024,
      "step": 7109
    },
    {
      "epoch": 0.1125765948350935,
      "grad_norm": 0.003353866282850504,
      "learning_rate": 8.874234051649066e-06,
      "loss": 0.0001,
      "step": 7110
    },
    {
      "epoch": 0.11259242839273556,
      "grad_norm": 0.3291833698749542,
      "learning_rate": 8.874075716072645e-06,
      "loss": 0.0638,
      "step": 7111
    },
    {
      "epoch": 0.11260826195037762,
      "grad_norm": 0.3437000513076782,
      "learning_rate": 8.873917380496224e-06,
      "loss": 0.0901,
      "step": 7112
    },
    {
      "epoch": 0.1126240955080197,
      "grad_norm": 0.17025786638259888,
      "learning_rate": 8.873759044919805e-06,
      "loss": 0.0302,
      "step": 7113
    },
    {
      "epoch": 0.11263992906566177,
      "grad_norm": 0.5019017457962036,
      "learning_rate": 8.873600709343384e-06,
      "loss": 0.1538,
      "step": 7114
    },
    {
      "epoch": 0.11265576262330383,
      "grad_norm": 0.4174324572086334,
      "learning_rate": 8.873442373766963e-06,
      "loss": 0.0507,
      "step": 7115
    },
    {
      "epoch": 0.1126715961809459,
      "grad_norm": 0.5659021139144897,
      "learning_rate": 8.873284038190542e-06,
      "loss": 0.2856,
      "step": 7116
    },
    {
      "epoch": 0.11268742973858796,
      "grad_norm": 0.523364245891571,
      "learning_rate": 8.873125702614121e-06,
      "loss": 0.0727,
      "step": 7117
    },
    {
      "epoch": 0.11270326329623002,
      "grad_norm": 0.7173853516578674,
      "learning_rate": 8.8729673670377e-06,
      "loss": 0.2419,
      "step": 7118
    },
    {
      "epoch": 0.1127190968538721,
      "grad_norm": 0.35706743597984314,
      "learning_rate": 8.87280903146128e-06,
      "loss": 0.088,
      "step": 7119
    },
    {
      "epoch": 0.11273493041151417,
      "grad_norm": 0.006269895471632481,
      "learning_rate": 8.872650695884858e-06,
      "loss": 0.0002,
      "step": 7120
    },
    {
      "epoch": 0.11275076396915623,
      "grad_norm": 0.5764251351356506,
      "learning_rate": 8.872492360308439e-06,
      "loss": 0.6057,
      "step": 7121
    },
    {
      "epoch": 0.1127665975267983,
      "grad_norm": 0.18967671692371368,
      "learning_rate": 8.872334024732018e-06,
      "loss": 0.0332,
      "step": 7122
    },
    {
      "epoch": 0.11278243108444036,
      "grad_norm": 0.33022037148475647,
      "learning_rate": 8.872175689155597e-06,
      "loss": 0.1977,
      "step": 7123
    },
    {
      "epoch": 0.11279826464208242,
      "grad_norm": 0.3469533920288086,
      "learning_rate": 8.872017353579176e-06,
      "loss": 0.2312,
      "step": 7124
    },
    {
      "epoch": 0.1128140981997245,
      "grad_norm": 0.1422804892063141,
      "learning_rate": 8.871859018002755e-06,
      "loss": 0.0669,
      "step": 7125
    },
    {
      "epoch": 0.11282993175736657,
      "grad_norm": 0.17444688081741333,
      "learning_rate": 8.871700682426334e-06,
      "loss": 0.0393,
      "step": 7126
    },
    {
      "epoch": 0.11284576531500863,
      "grad_norm": 0.040147729218006134,
      "learning_rate": 8.871542346849913e-06,
      "loss": 0.0025,
      "step": 7127
    },
    {
      "epoch": 0.1128615988726507,
      "grad_norm": 0.36560043692588806,
      "learning_rate": 8.871384011273494e-06,
      "loss": 0.0687,
      "step": 7128
    },
    {
      "epoch": 0.11287743243029276,
      "grad_norm": 0.5019574165344238,
      "learning_rate": 8.871225675697073e-06,
      "loss": 0.6153,
      "step": 7129
    },
    {
      "epoch": 0.11289326598793482,
      "grad_norm": 0.20890069007873535,
      "learning_rate": 8.871067340120652e-06,
      "loss": 0.0884,
      "step": 7130
    },
    {
      "epoch": 0.1129090995455769,
      "grad_norm": 0.3140837848186493,
      "learning_rate": 8.870909004544231e-06,
      "loss": 0.1914,
      "step": 7131
    },
    {
      "epoch": 0.11292493310321897,
      "grad_norm": 0.315032035112381,
      "learning_rate": 8.87075066896781e-06,
      "loss": 0.0825,
      "step": 7132
    },
    {
      "epoch": 0.11294076666086103,
      "grad_norm": 0.2769836485385895,
      "learning_rate": 8.87059233339139e-06,
      "loss": 0.2028,
      "step": 7133
    },
    {
      "epoch": 0.1129566002185031,
      "grad_norm": 0.20871105790138245,
      "learning_rate": 8.87043399781497e-06,
      "loss": 0.0826,
      "step": 7134
    },
    {
      "epoch": 0.11297243377614516,
      "grad_norm": 0.24138687551021576,
      "learning_rate": 8.87027566223855e-06,
      "loss": 0.1378,
      "step": 7135
    },
    {
      "epoch": 0.11298826733378722,
      "grad_norm": 0.5809608697891235,
      "learning_rate": 8.870117326662129e-06,
      "loss": 0.8711,
      "step": 7136
    },
    {
      "epoch": 0.1130041008914293,
      "grad_norm": 0.31770825386047363,
      "learning_rate": 8.869958991085708e-06,
      "loss": 0.1792,
      "step": 7137
    },
    {
      "epoch": 0.11301993444907137,
      "grad_norm": 0.03931603208184242,
      "learning_rate": 8.869800655509287e-06,
      "loss": 0.0023,
      "step": 7138
    },
    {
      "epoch": 0.11303576800671343,
      "grad_norm": 0.46206092834472656,
      "learning_rate": 8.869642319932866e-06,
      "loss": 0.1267,
      "step": 7139
    },
    {
      "epoch": 0.1130516015643555,
      "grad_norm": 0.012237988412380219,
      "learning_rate": 8.869483984356447e-06,
      "loss": 0.0006,
      "step": 7140
    },
    {
      "epoch": 0.11306743512199756,
      "grad_norm": 0.24246183037757874,
      "learning_rate": 8.869325648780026e-06,
      "loss": 0.0151,
      "step": 7141
    },
    {
      "epoch": 0.11308326867963962,
      "grad_norm": 0.1605013757944107,
      "learning_rate": 8.869167313203605e-06,
      "loss": 0.015,
      "step": 7142
    },
    {
      "epoch": 0.1130991022372817,
      "grad_norm": 0.48450967669487,
      "learning_rate": 8.869008977627184e-06,
      "loss": 0.6367,
      "step": 7143
    },
    {
      "epoch": 0.11311493579492377,
      "grad_norm": 0.15120410919189453,
      "learning_rate": 8.868850642050763e-06,
      "loss": 0.0502,
      "step": 7144
    },
    {
      "epoch": 0.11313076935256583,
      "grad_norm": 0.0009821108542382717,
      "learning_rate": 8.868692306474342e-06,
      "loss": 0.0,
      "step": 7145
    },
    {
      "epoch": 0.1131466029102079,
      "grad_norm": 0.26130178570747375,
      "learning_rate": 8.868533970897921e-06,
      "loss": 0.0806,
      "step": 7146
    },
    {
      "epoch": 0.11316243646784996,
      "grad_norm": 0.21154829859733582,
      "learning_rate": 8.868375635321502e-06,
      "loss": 0.0458,
      "step": 7147
    },
    {
      "epoch": 0.11317827002549202,
      "grad_norm": 0.013606719672679901,
      "learning_rate": 8.86821729974508e-06,
      "loss": 0.0006,
      "step": 7148
    },
    {
      "epoch": 0.1131941035831341,
      "grad_norm": 3.153059244155884,
      "learning_rate": 8.86805896416866e-06,
      "loss": 0.1816,
      "step": 7149
    },
    {
      "epoch": 0.11320993714077617,
      "grad_norm": 0.06393267959356308,
      "learning_rate": 8.867900628592239e-06,
      "loss": 0.0074,
      "step": 7150
    },
    {
      "epoch": 0.11322577069841823,
      "grad_norm": 0.0011595258256420493,
      "learning_rate": 8.867742293015818e-06,
      "loss": 0.0,
      "step": 7151
    },
    {
      "epoch": 0.1132416042560603,
      "grad_norm": 0.15095262229442596,
      "learning_rate": 8.867583957439397e-06,
      "loss": 0.0224,
      "step": 7152
    },
    {
      "epoch": 0.11325743781370236,
      "grad_norm": 0.2055593729019165,
      "learning_rate": 8.867425621862978e-06,
      "loss": 0.0349,
      "step": 7153
    },
    {
      "epoch": 0.11327327137134442,
      "grad_norm": 0.6802806258201599,
      "learning_rate": 8.867267286286555e-06,
      "loss": 0.2451,
      "step": 7154
    },
    {
      "epoch": 0.1132891049289865,
      "grad_norm": 0.24656988680362701,
      "learning_rate": 8.867108950710136e-06,
      "loss": 0.1434,
      "step": 7155
    },
    {
      "epoch": 0.11330493848662856,
      "grad_norm": 0.40323740243911743,
      "learning_rate": 8.866950615133715e-06,
      "loss": 0.1407,
      "step": 7156
    },
    {
      "epoch": 0.11332077204427063,
      "grad_norm": 0.15205880999565125,
      "learning_rate": 8.866792279557294e-06,
      "loss": 0.0511,
      "step": 7157
    },
    {
      "epoch": 0.1133366056019127,
      "grad_norm": 0.01027846708893776,
      "learning_rate": 8.866633943980873e-06,
      "loss": 0.0006,
      "step": 7158
    },
    {
      "epoch": 0.11335243915955476,
      "grad_norm": 0.12926962971687317,
      "learning_rate": 8.866475608404454e-06,
      "loss": 0.0178,
      "step": 7159
    },
    {
      "epoch": 0.11336827271719682,
      "grad_norm": 0.011597076430916786,
      "learning_rate": 8.866317272828032e-06,
      "loss": 0.0005,
      "step": 7160
    },
    {
      "epoch": 0.1133841062748389,
      "grad_norm": 0.007539829239249229,
      "learning_rate": 8.866158937251612e-06,
      "loss": 0.0002,
      "step": 7161
    },
    {
      "epoch": 0.11339993983248096,
      "grad_norm": 0.43157073855400085,
      "learning_rate": 8.866000601675191e-06,
      "loss": 0.2739,
      "step": 7162
    },
    {
      "epoch": 0.11341577339012303,
      "grad_norm": 0.4257681369781494,
      "learning_rate": 8.86584226609877e-06,
      "loss": 0.2422,
      "step": 7163
    },
    {
      "epoch": 0.11343160694776509,
      "grad_norm": 0.6081326007843018,
      "learning_rate": 8.86568393052235e-06,
      "loss": 0.1241,
      "step": 7164
    },
    {
      "epoch": 0.11344744050540716,
      "grad_norm": 0.006478426046669483,
      "learning_rate": 8.86552559494593e-06,
      "loss": 0.0002,
      "step": 7165
    },
    {
      "epoch": 0.11346327406304922,
      "grad_norm": 0.014781909063458443,
      "learning_rate": 8.865367259369508e-06,
      "loss": 0.0008,
      "step": 7166
    },
    {
      "epoch": 0.1134791076206913,
      "grad_norm": 0.021480396389961243,
      "learning_rate": 8.865208923793089e-06,
      "loss": 0.0013,
      "step": 7167
    },
    {
      "epoch": 0.11349494117833336,
      "grad_norm": 0.25770679116249084,
      "learning_rate": 8.865050588216668e-06,
      "loss": 0.0987,
      "step": 7168
    },
    {
      "epoch": 0.11351077473597543,
      "grad_norm": 0.00448849331587553,
      "learning_rate": 8.864892252640247e-06,
      "loss": 0.0001,
      "step": 7169
    },
    {
      "epoch": 0.11352660829361749,
      "grad_norm": 0.5476671457290649,
      "learning_rate": 8.864733917063826e-06,
      "loss": 0.2365,
      "step": 7170
    },
    {
      "epoch": 0.11354244185125956,
      "grad_norm": 0.7341412901878357,
      "learning_rate": 8.864575581487405e-06,
      "loss": 0.775,
      "step": 7171
    },
    {
      "epoch": 0.11355827540890162,
      "grad_norm": 0.30548492074012756,
      "learning_rate": 8.864417245910984e-06,
      "loss": 0.124,
      "step": 7172
    },
    {
      "epoch": 0.1135741089665437,
      "grad_norm": 0.031143296509981155,
      "learning_rate": 8.864258910334563e-06,
      "loss": 0.0015,
      "step": 7173
    },
    {
      "epoch": 0.11358994252418576,
      "grad_norm": 0.3154444992542267,
      "learning_rate": 8.864100574758144e-06,
      "loss": 0.0888,
      "step": 7174
    },
    {
      "epoch": 0.11360577608182783,
      "grad_norm": 0.01773235946893692,
      "learning_rate": 8.863942239181723e-06,
      "loss": 0.0007,
      "step": 7175
    },
    {
      "epoch": 0.11362160963946989,
      "grad_norm": 0.007613332476466894,
      "learning_rate": 8.863783903605302e-06,
      "loss": 0.0004,
      "step": 7176
    },
    {
      "epoch": 0.11363744319711196,
      "grad_norm": 0.3048252761363983,
      "learning_rate": 8.863625568028881e-06,
      "loss": 0.1758,
      "step": 7177
    },
    {
      "epoch": 0.11365327675475402,
      "grad_norm": 0.0027014196384698153,
      "learning_rate": 8.86346723245246e-06,
      "loss": 0.0001,
      "step": 7178
    },
    {
      "epoch": 0.1136691103123961,
      "grad_norm": 0.04570203274488449,
      "learning_rate": 8.86330889687604e-06,
      "loss": 0.0005,
      "step": 7179
    },
    {
      "epoch": 0.11368494387003816,
      "grad_norm": 0.3737703561782837,
      "learning_rate": 8.86315056129962e-06,
      "loss": 0.1156,
      "step": 7180
    },
    {
      "epoch": 0.11370077742768023,
      "grad_norm": 0.00042571709491312504,
      "learning_rate": 8.862992225723199e-06,
      "loss": 0.0,
      "step": 7181
    },
    {
      "epoch": 0.11371661098532229,
      "grad_norm": 0.027211664244532585,
      "learning_rate": 8.862833890146778e-06,
      "loss": 0.0013,
      "step": 7182
    },
    {
      "epoch": 0.11373244454296436,
      "grad_norm": 1.587220549583435,
      "learning_rate": 8.862675554570357e-06,
      "loss": 0.233,
      "step": 7183
    },
    {
      "epoch": 0.11374827810060642,
      "grad_norm": 0.18317000567913055,
      "learning_rate": 8.862517218993936e-06,
      "loss": 0.0547,
      "step": 7184
    },
    {
      "epoch": 0.1137641116582485,
      "grad_norm": 0.2066119760274887,
      "learning_rate": 8.862358883417515e-06,
      "loss": 0.2429,
      "step": 7185
    },
    {
      "epoch": 0.11377994521589056,
      "grad_norm": 0.677924394607544,
      "learning_rate": 8.862200547841096e-06,
      "loss": 0.1782,
      "step": 7186
    },
    {
      "epoch": 0.11379577877353263,
      "grad_norm": 0.12750715017318726,
      "learning_rate": 8.862042212264673e-06,
      "loss": 0.0215,
      "step": 7187
    },
    {
      "epoch": 0.11381161233117469,
      "grad_norm": 0.029207875952124596,
      "learning_rate": 8.861883876688254e-06,
      "loss": 0.0017,
      "step": 7188
    },
    {
      "epoch": 0.11382744588881676,
      "grad_norm": 0.18063323199748993,
      "learning_rate": 8.861725541111833e-06,
      "loss": 0.0519,
      "step": 7189
    },
    {
      "epoch": 0.11384327944645882,
      "grad_norm": 0.5599538087844849,
      "learning_rate": 8.861567205535412e-06,
      "loss": 0.2181,
      "step": 7190
    },
    {
      "epoch": 0.1138591130041009,
      "grad_norm": 0.041446954011917114,
      "learning_rate": 8.861408869958992e-06,
      "loss": 0.0023,
      "step": 7191
    },
    {
      "epoch": 0.11387494656174296,
      "grad_norm": 0.000985630671493709,
      "learning_rate": 8.861250534382572e-06,
      "loss": 0.0,
      "step": 7192
    },
    {
      "epoch": 0.11389078011938503,
      "grad_norm": 0.12915919721126556,
      "learning_rate": 8.86109219880615e-06,
      "loss": 0.0019,
      "step": 7193
    },
    {
      "epoch": 0.11390661367702709,
      "grad_norm": 0.3100544512271881,
      "learning_rate": 8.860933863229729e-06,
      "loss": 0.2267,
      "step": 7194
    },
    {
      "epoch": 0.11392244723466916,
      "grad_norm": 0.2087613046169281,
      "learning_rate": 8.86077552765331e-06,
      "loss": 0.0495,
      "step": 7195
    },
    {
      "epoch": 0.11393828079231122,
      "grad_norm": 0.0024653275031596422,
      "learning_rate": 8.860617192076889e-06,
      "loss": 0.0,
      "step": 7196
    },
    {
      "epoch": 0.1139541143499533,
      "grad_norm": 0.49865540862083435,
      "learning_rate": 8.860458856500468e-06,
      "loss": 0.4257,
      "step": 7197
    },
    {
      "epoch": 0.11396994790759536,
      "grad_norm": 0.012548547238111496,
      "learning_rate": 8.860300520924047e-06,
      "loss": 0.0005,
      "step": 7198
    },
    {
      "epoch": 0.11398578146523743,
      "grad_norm": 0.0019076444441452622,
      "learning_rate": 8.860142185347626e-06,
      "loss": 0.0,
      "step": 7199
    },
    {
      "epoch": 0.11400161502287949,
      "grad_norm": 0.000606286630500108,
      "learning_rate": 8.859983849771205e-06,
      "loss": 0.0,
      "step": 7200
    },
    {
      "epoch": 0.11401744858052155,
      "grad_norm": 0.001528946217149496,
      "learning_rate": 8.859825514194786e-06,
      "loss": 0.0,
      "step": 7201
    },
    {
      "epoch": 0.11403328213816362,
      "grad_norm": 0.3087317645549774,
      "learning_rate": 8.859667178618365e-06,
      "loss": 0.2524,
      "step": 7202
    },
    {
      "epoch": 0.1140491156958057,
      "grad_norm": 0.3147810697555542,
      "learning_rate": 8.859508843041944e-06,
      "loss": 0.1177,
      "step": 7203
    },
    {
      "epoch": 0.11406494925344776,
      "grad_norm": 0.36335447430610657,
      "learning_rate": 8.859350507465523e-06,
      "loss": 0.3719,
      "step": 7204
    },
    {
      "epoch": 0.11408078281108983,
      "grad_norm": 0.013224436901509762,
      "learning_rate": 8.859192171889102e-06,
      "loss": 0.0006,
      "step": 7205
    },
    {
      "epoch": 0.11409661636873189,
      "grad_norm": 0.05004660412669182,
      "learning_rate": 8.859033836312681e-06,
      "loss": 0.003,
      "step": 7206
    },
    {
      "epoch": 0.11411244992637395,
      "grad_norm": 0.6110788583755493,
      "learning_rate": 8.858875500736262e-06,
      "loss": 0.2404,
      "step": 7207
    },
    {
      "epoch": 0.11412828348401602,
      "grad_norm": 0.30458974838256836,
      "learning_rate": 8.858717165159841e-06,
      "loss": 0.1074,
      "step": 7208
    },
    {
      "epoch": 0.1141441170416581,
      "grad_norm": 0.23975740373134613,
      "learning_rate": 8.85855882958342e-06,
      "loss": 0.0853,
      "step": 7209
    },
    {
      "epoch": 0.11415995059930016,
      "grad_norm": 0.11336185038089752,
      "learning_rate": 8.858400494006999e-06,
      "loss": 0.0028,
      "step": 7210
    },
    {
      "epoch": 0.11417578415694223,
      "grad_norm": 0.2984966039657593,
      "learning_rate": 8.858242158430578e-06,
      "loss": 0.0692,
      "step": 7211
    },
    {
      "epoch": 0.11419161771458429,
      "grad_norm": 0.28820574283599854,
      "learning_rate": 8.858083822854157e-06,
      "loss": 0.2385,
      "step": 7212
    },
    {
      "epoch": 0.11420745127222635,
      "grad_norm": 0.21472260355949402,
      "learning_rate": 8.857925487277738e-06,
      "loss": 0.0707,
      "step": 7213
    },
    {
      "epoch": 0.11422328482986842,
      "grad_norm": 0.41894984245300293,
      "learning_rate": 8.857767151701317e-06,
      "loss": 0.2438,
      "step": 7214
    },
    {
      "epoch": 0.1142391183875105,
      "grad_norm": 0.014703329652547836,
      "learning_rate": 8.857608816124896e-06,
      "loss": 0.0007,
      "step": 7215
    },
    {
      "epoch": 0.11425495194515256,
      "grad_norm": 0.2911780774593353,
      "learning_rate": 8.857450480548475e-06,
      "loss": 0.163,
      "step": 7216
    },
    {
      "epoch": 0.11427078550279463,
      "grad_norm": 0.7569453716278076,
      "learning_rate": 8.857292144972054e-06,
      "loss": 0.1338,
      "step": 7217
    },
    {
      "epoch": 0.11428661906043669,
      "grad_norm": 0.004391780123114586,
      "learning_rate": 8.857133809395633e-06,
      "loss": 0.0001,
      "step": 7218
    },
    {
      "epoch": 0.11430245261807875,
      "grad_norm": 0.3796107769012451,
      "learning_rate": 8.856975473819213e-06,
      "loss": 0.0429,
      "step": 7219
    },
    {
      "epoch": 0.11431828617572082,
      "grad_norm": 0.588554859161377,
      "learning_rate": 8.856817138242793e-06,
      "loss": 0.486,
      "step": 7220
    },
    {
      "epoch": 0.1143341197333629,
      "grad_norm": 0.2185654193162918,
      "learning_rate": 8.85665880266637e-06,
      "loss": 0.0857,
      "step": 7221
    },
    {
      "epoch": 0.11434995329100496,
      "grad_norm": 0.5639085173606873,
      "learning_rate": 8.856500467089951e-06,
      "loss": 0.5644,
      "step": 7222
    },
    {
      "epoch": 0.11436578684864702,
      "grad_norm": 0.46864622831344604,
      "learning_rate": 8.85634213151353e-06,
      "loss": 0.1106,
      "step": 7223
    },
    {
      "epoch": 0.11438162040628909,
      "grad_norm": 0.38542449474334717,
      "learning_rate": 8.85618379593711e-06,
      "loss": 0.14,
      "step": 7224
    },
    {
      "epoch": 0.11439745396393115,
      "grad_norm": 0.41101667284965515,
      "learning_rate": 8.856025460360689e-06,
      "loss": 0.3816,
      "step": 7225
    },
    {
      "epoch": 0.11441328752157322,
      "grad_norm": 0.02049744874238968,
      "learning_rate": 8.85586712478427e-06,
      "loss": 0.001,
      "step": 7226
    },
    {
      "epoch": 0.1144291210792153,
      "grad_norm": 0.14856041967868805,
      "learning_rate": 8.855708789207847e-06,
      "loss": 0.0059,
      "step": 7227
    },
    {
      "epoch": 0.11444495463685736,
      "grad_norm": 0.5803296566009521,
      "learning_rate": 8.855550453631428e-06,
      "loss": 0.2823,
      "step": 7228
    },
    {
      "epoch": 0.11446078819449942,
      "grad_norm": 0.018382837995886803,
      "learning_rate": 8.855392118055007e-06,
      "loss": 0.0008,
      "step": 7229
    },
    {
      "epoch": 0.11447662175214149,
      "grad_norm": 0.0060724844224750996,
      "learning_rate": 8.855233782478586e-06,
      "loss": 0.0001,
      "step": 7230
    },
    {
      "epoch": 0.11449245530978355,
      "grad_norm": 0.3202911615371704,
      "learning_rate": 8.855075446902165e-06,
      "loss": 0.1122,
      "step": 7231
    },
    {
      "epoch": 0.11450828886742562,
      "grad_norm": 0.5646175742149353,
      "learning_rate": 8.854917111325746e-06,
      "loss": 0.1484,
      "step": 7232
    },
    {
      "epoch": 0.1145241224250677,
      "grad_norm": 0.21423572301864624,
      "learning_rate": 8.854758775749323e-06,
      "loss": 0.1548,
      "step": 7233
    },
    {
      "epoch": 0.11453995598270976,
      "grad_norm": 0.2652663290500641,
      "learning_rate": 8.854600440172904e-06,
      "loss": 0.0073,
      "step": 7234
    },
    {
      "epoch": 0.11455578954035182,
      "grad_norm": 0.5088845491409302,
      "learning_rate": 8.854442104596483e-06,
      "loss": 0.403,
      "step": 7235
    },
    {
      "epoch": 0.11457162309799389,
      "grad_norm": 0.2407539188861847,
      "learning_rate": 8.854283769020062e-06,
      "loss": 0.0422,
      "step": 7236
    },
    {
      "epoch": 0.11458745665563595,
      "grad_norm": 0.3897629678249359,
      "learning_rate": 8.854125433443641e-06,
      "loss": 0.3044,
      "step": 7237
    },
    {
      "epoch": 0.11460329021327802,
      "grad_norm": 0.8575767874717712,
      "learning_rate": 8.853967097867222e-06,
      "loss": 0.1568,
      "step": 7238
    },
    {
      "epoch": 0.1146191237709201,
      "grad_norm": 0.012921062298119068,
      "learning_rate": 8.8538087622908e-06,
      "loss": 0.0005,
      "step": 7239
    },
    {
      "epoch": 0.11463495732856216,
      "grad_norm": 0.31087353825569153,
      "learning_rate": 8.85365042671438e-06,
      "loss": 0.1667,
      "step": 7240
    },
    {
      "epoch": 0.11465079088620422,
      "grad_norm": 0.4714677929878235,
      "learning_rate": 8.853492091137959e-06,
      "loss": 0.5277,
      "step": 7241
    },
    {
      "epoch": 0.11466662444384629,
      "grad_norm": 0.019817987456917763,
      "learning_rate": 8.853333755561538e-06,
      "loss": 0.0007,
      "step": 7242
    },
    {
      "epoch": 0.11468245800148835,
      "grad_norm": 0.2606624364852905,
      "learning_rate": 8.853175419985117e-06,
      "loss": 0.1087,
      "step": 7243
    },
    {
      "epoch": 0.11469829155913042,
      "grad_norm": 0.030052514746785164,
      "learning_rate": 8.853017084408696e-06,
      "loss": 0.0014,
      "step": 7244
    },
    {
      "epoch": 0.11471412511677248,
      "grad_norm": 1.0817855596542358,
      "learning_rate": 8.852858748832275e-06,
      "loss": 0.1249,
      "step": 7245
    },
    {
      "epoch": 0.11472995867441456,
      "grad_norm": 0.5478289723396301,
      "learning_rate": 8.852700413255854e-06,
      "loss": 0.1122,
      "step": 7246
    },
    {
      "epoch": 0.11474579223205662,
      "grad_norm": 0.013086174614727497,
      "learning_rate": 8.852542077679435e-06,
      "loss": 0.0005,
      "step": 7247
    },
    {
      "epoch": 0.11476162578969869,
      "grad_norm": 0.018817510455846786,
      "learning_rate": 8.852383742103013e-06,
      "loss": 0.001,
      "step": 7248
    },
    {
      "epoch": 0.11477745934734075,
      "grad_norm": 0.20984788239002228,
      "learning_rate": 8.852225406526593e-06,
      "loss": 0.1026,
      "step": 7249
    },
    {
      "epoch": 0.11479329290498282,
      "grad_norm": 0.004417088348418474,
      "learning_rate": 8.852067070950172e-06,
      "loss": 0.0002,
      "step": 7250
    },
    {
      "epoch": 0.11480912646262488,
      "grad_norm": 0.014469200745224953,
      "learning_rate": 8.851908735373752e-06,
      "loss": 0.0005,
      "step": 7251
    },
    {
      "epoch": 0.11482496002026696,
      "grad_norm": 0.38233867287635803,
      "learning_rate": 8.85175039979733e-06,
      "loss": 0.0822,
      "step": 7252
    },
    {
      "epoch": 0.11484079357790902,
      "grad_norm": 0.14106883108615875,
      "learning_rate": 8.851592064220911e-06,
      "loss": 0.0162,
      "step": 7253
    },
    {
      "epoch": 0.11485662713555109,
      "grad_norm": 0.6209306120872498,
      "learning_rate": 8.851433728644489e-06,
      "loss": 0.7429,
      "step": 7254
    },
    {
      "epoch": 0.11487246069319315,
      "grad_norm": 0.013792706653475761,
      "learning_rate": 8.85127539306807e-06,
      "loss": 0.0007,
      "step": 7255
    },
    {
      "epoch": 0.11488829425083522,
      "grad_norm": 0.20561105012893677,
      "learning_rate": 8.851117057491649e-06,
      "loss": 0.5132,
      "step": 7256
    },
    {
      "epoch": 0.11490412780847728,
      "grad_norm": 0.37780335545539856,
      "learning_rate": 8.850958721915228e-06,
      "loss": 0.1995,
      "step": 7257
    },
    {
      "epoch": 0.11491996136611936,
      "grad_norm": 0.5887352228164673,
      "learning_rate": 8.850800386338807e-06,
      "loss": 0.0676,
      "step": 7258
    },
    {
      "epoch": 0.11493579492376142,
      "grad_norm": 0.2844381034374237,
      "learning_rate": 8.850642050762388e-06,
      "loss": 0.051,
      "step": 7259
    },
    {
      "epoch": 0.11495162848140349,
      "grad_norm": 0.1591930091381073,
      "learning_rate": 8.850483715185965e-06,
      "loss": 0.0622,
      "step": 7260
    },
    {
      "epoch": 0.11496746203904555,
      "grad_norm": 0.3462294936180115,
      "learning_rate": 8.850325379609546e-06,
      "loss": 0.2667,
      "step": 7261
    },
    {
      "epoch": 0.11498329559668762,
      "grad_norm": 0.659242570400238,
      "learning_rate": 8.850167044033125e-06,
      "loss": 0.1424,
      "step": 7262
    },
    {
      "epoch": 0.11499912915432968,
      "grad_norm": 0.36196279525756836,
      "learning_rate": 8.850008708456704e-06,
      "loss": 0.2425,
      "step": 7263
    },
    {
      "epoch": 0.11501496271197176,
      "grad_norm": 0.4764438569545746,
      "learning_rate": 8.849850372880283e-06,
      "loss": 0.184,
      "step": 7264
    },
    {
      "epoch": 0.11503079626961382,
      "grad_norm": 0.2851223647594452,
      "learning_rate": 8.849692037303864e-06,
      "loss": 0.111,
      "step": 7265
    },
    {
      "epoch": 0.11504662982725589,
      "grad_norm": 0.2749035954475403,
      "learning_rate": 8.849533701727441e-06,
      "loss": 0.0713,
      "step": 7266
    },
    {
      "epoch": 0.11506246338489795,
      "grad_norm": 0.016871687024831772,
      "learning_rate": 8.84937536615102e-06,
      "loss": 0.0008,
      "step": 7267
    },
    {
      "epoch": 0.11507829694254001,
      "grad_norm": 0.24463053047657013,
      "learning_rate": 8.849217030574601e-06,
      "loss": 0.0372,
      "step": 7268
    },
    {
      "epoch": 0.11509413050018208,
      "grad_norm": 0.2309246063232422,
      "learning_rate": 8.84905869499818e-06,
      "loss": 0.0813,
      "step": 7269
    },
    {
      "epoch": 0.11510996405782416,
      "grad_norm": 0.39823436737060547,
      "learning_rate": 8.848900359421759e-06,
      "loss": 0.1728,
      "step": 7270
    },
    {
      "epoch": 0.11512579761546622,
      "grad_norm": 0.5319722294807434,
      "learning_rate": 8.848742023845338e-06,
      "loss": 0.0261,
      "step": 7271
    },
    {
      "epoch": 0.11514163117310829,
      "grad_norm": 0.6076722741127014,
      "learning_rate": 8.848583688268917e-06,
      "loss": 0.602,
      "step": 7272
    },
    {
      "epoch": 0.11515746473075035,
      "grad_norm": 0.0007588771404698491,
      "learning_rate": 8.848425352692496e-06,
      "loss": 0.0,
      "step": 7273
    },
    {
      "epoch": 0.11517329828839241,
      "grad_norm": 0.7903068661689758,
      "learning_rate": 8.848267017116077e-06,
      "loss": 0.6573,
      "step": 7274
    },
    {
      "epoch": 0.11518913184603448,
      "grad_norm": 0.43975260853767395,
      "learning_rate": 8.848108681539656e-06,
      "loss": 0.297,
      "step": 7275
    },
    {
      "epoch": 0.11520496540367656,
      "grad_norm": 0.29315125942230225,
      "learning_rate": 8.847950345963235e-06,
      "loss": 0.1193,
      "step": 7276
    },
    {
      "epoch": 0.11522079896131862,
      "grad_norm": 0.43508875370025635,
      "learning_rate": 8.847792010386814e-06,
      "loss": 0.6066,
      "step": 7277
    },
    {
      "epoch": 0.11523663251896069,
      "grad_norm": 0.24763080477714539,
      "learning_rate": 8.847633674810393e-06,
      "loss": 0.0706,
      "step": 7278
    },
    {
      "epoch": 0.11525246607660275,
      "grad_norm": 0.00173779611941427,
      "learning_rate": 8.847475339233973e-06,
      "loss": 0.0,
      "step": 7279
    },
    {
      "epoch": 0.11526829963424481,
      "grad_norm": 0.24038133025169373,
      "learning_rate": 8.847317003657553e-06,
      "loss": 0.0751,
      "step": 7280
    },
    {
      "epoch": 0.11528413319188688,
      "grad_norm": 0.3611150085926056,
      "learning_rate": 8.847158668081132e-06,
      "loss": 0.0466,
      "step": 7281
    },
    {
      "epoch": 0.11529996674952896,
      "grad_norm": 0.0011871315073221922,
      "learning_rate": 8.847000332504711e-06,
      "loss": 0.0,
      "step": 7282
    },
    {
      "epoch": 0.11531580030717102,
      "grad_norm": 0.365398645401001,
      "learning_rate": 8.84684199692829e-06,
      "loss": 0.3868,
      "step": 7283
    },
    {
      "epoch": 0.11533163386481309,
      "grad_norm": 0.7663768529891968,
      "learning_rate": 8.84668366135187e-06,
      "loss": 0.2086,
      "step": 7284
    },
    {
      "epoch": 0.11534746742245515,
      "grad_norm": 0.2429913431406021,
      "learning_rate": 8.846525325775449e-06,
      "loss": 0.0136,
      "step": 7285
    },
    {
      "epoch": 0.11536330098009721,
      "grad_norm": 0.22558754682540894,
      "learning_rate": 8.84636699019903e-06,
      "loss": 0.0433,
      "step": 7286
    },
    {
      "epoch": 0.11537913453773928,
      "grad_norm": 0.14465847611427307,
      "learning_rate": 8.846208654622609e-06,
      "loss": 0.0585,
      "step": 7287
    },
    {
      "epoch": 0.11539496809538136,
      "grad_norm": 0.003358613234013319,
      "learning_rate": 8.846050319046188e-06,
      "loss": 0.0001,
      "step": 7288
    },
    {
      "epoch": 0.11541080165302342,
      "grad_norm": 0.10847435146570206,
      "learning_rate": 8.845891983469767e-06,
      "loss": 0.0034,
      "step": 7289
    },
    {
      "epoch": 0.11542663521066548,
      "grad_norm": 0.3448922038078308,
      "learning_rate": 8.845733647893346e-06,
      "loss": 0.1157,
      "step": 7290
    },
    {
      "epoch": 0.11544246876830755,
      "grad_norm": 0.5251159071922302,
      "learning_rate": 8.845575312316925e-06,
      "loss": 0.2146,
      "step": 7291
    },
    {
      "epoch": 0.11545830232594961,
      "grad_norm": 0.33740249276161194,
      "learning_rate": 8.845416976740504e-06,
      "loss": 0.4792,
      "step": 7292
    },
    {
      "epoch": 0.11547413588359168,
      "grad_norm": 0.4337749481201172,
      "learning_rate": 8.845258641164085e-06,
      "loss": 0.2079,
      "step": 7293
    },
    {
      "epoch": 0.11548996944123376,
      "grad_norm": 0.24477413296699524,
      "learning_rate": 8.845100305587662e-06,
      "loss": 0.0771,
      "step": 7294
    },
    {
      "epoch": 0.11550580299887582,
      "grad_norm": 0.24267876148223877,
      "learning_rate": 8.844941970011243e-06,
      "loss": 0.0569,
      "step": 7295
    },
    {
      "epoch": 0.11552163655651788,
      "grad_norm": 0.20410093665122986,
      "learning_rate": 8.844783634434822e-06,
      "loss": 0.0712,
      "step": 7296
    },
    {
      "epoch": 0.11553747011415995,
      "grad_norm": 0.1788853108882904,
      "learning_rate": 8.844625298858401e-06,
      "loss": 0.0608,
      "step": 7297
    },
    {
      "epoch": 0.11555330367180201,
      "grad_norm": 0.4105941355228424,
      "learning_rate": 8.84446696328198e-06,
      "loss": 0.2189,
      "step": 7298
    },
    {
      "epoch": 0.11556913722944408,
      "grad_norm": 0.023429252207279205,
      "learning_rate": 8.844308627705561e-06,
      "loss": 0.0009,
      "step": 7299
    },
    {
      "epoch": 0.11558497078708616,
      "grad_norm": 0.376675546169281,
      "learning_rate": 8.844150292129138e-06,
      "loss": 0.0436,
      "step": 7300
    },
    {
      "epoch": 0.11560080434472822,
      "grad_norm": 0.2013031542301178,
      "learning_rate": 8.843991956552719e-06,
      "loss": 0.0693,
      "step": 7301
    },
    {
      "epoch": 0.11561663790237028,
      "grad_norm": 0.0010055835591629148,
      "learning_rate": 8.843833620976298e-06,
      "loss": 0.0,
      "step": 7302
    },
    {
      "epoch": 0.11563247146001235,
      "grad_norm": 0.46924108266830444,
      "learning_rate": 8.843675285399877e-06,
      "loss": 0.2906,
      "step": 7303
    },
    {
      "epoch": 0.11564830501765441,
      "grad_norm": 0.28904613852500916,
      "learning_rate": 8.843516949823456e-06,
      "loss": 0.0656,
      "step": 7304
    },
    {
      "epoch": 0.11566413857529648,
      "grad_norm": 0.29269939661026,
      "learning_rate": 8.843358614247037e-06,
      "loss": 0.2123,
      "step": 7305
    },
    {
      "epoch": 0.11567997213293855,
      "grad_norm": 0.5242514610290527,
      "learning_rate": 8.843200278670614e-06,
      "loss": 0.1134,
      "step": 7306
    },
    {
      "epoch": 0.11569580569058062,
      "grad_norm": 0.01957886666059494,
      "learning_rate": 8.843041943094195e-06,
      "loss": 0.0007,
      "step": 7307
    },
    {
      "epoch": 0.11571163924822268,
      "grad_norm": 0.3674063980579376,
      "learning_rate": 8.842883607517774e-06,
      "loss": 0.1946,
      "step": 7308
    },
    {
      "epoch": 0.11572747280586475,
      "grad_norm": 0.19400456547737122,
      "learning_rate": 8.842725271941353e-06,
      "loss": 0.1497,
      "step": 7309
    },
    {
      "epoch": 0.11574330636350681,
      "grad_norm": 0.1699295938014984,
      "learning_rate": 8.842566936364932e-06,
      "loss": 0.1098,
      "step": 7310
    },
    {
      "epoch": 0.11575913992114888,
      "grad_norm": 0.427182674407959,
      "learning_rate": 8.842408600788512e-06,
      "loss": 0.3419,
      "step": 7311
    },
    {
      "epoch": 0.11577497347879095,
      "grad_norm": 0.3466981053352356,
      "learning_rate": 8.84225026521209e-06,
      "loss": 0.168,
      "step": 7312
    },
    {
      "epoch": 0.11579080703643302,
      "grad_norm": 0.37532839179039,
      "learning_rate": 8.842091929635671e-06,
      "loss": 0.2154,
      "step": 7313
    },
    {
      "epoch": 0.11580664059407508,
      "grad_norm": 0.20467518270015717,
      "learning_rate": 8.84193359405925e-06,
      "loss": 0.0261,
      "step": 7314
    },
    {
      "epoch": 0.11582247415171715,
      "grad_norm": 0.09881415963172913,
      "learning_rate": 8.841775258482828e-06,
      "loss": 0.0025,
      "step": 7315
    },
    {
      "epoch": 0.11583830770935921,
      "grad_norm": 0.42570292949676514,
      "learning_rate": 8.841616922906409e-06,
      "loss": 0.2189,
      "step": 7316
    },
    {
      "epoch": 0.11585414126700128,
      "grad_norm": 0.029472772032022476,
      "learning_rate": 8.841458587329988e-06,
      "loss": 0.0029,
      "step": 7317
    },
    {
      "epoch": 0.11586997482464335,
      "grad_norm": 0.005903799552470446,
      "learning_rate": 8.841300251753567e-06,
      "loss": 0.0001,
      "step": 7318
    },
    {
      "epoch": 0.11588580838228542,
      "grad_norm": 0.15126755833625793,
      "learning_rate": 8.841141916177146e-06,
      "loss": 0.0218,
      "step": 7319
    },
    {
      "epoch": 0.11590164193992748,
      "grad_norm": 0.33504992723464966,
      "learning_rate": 8.840983580600727e-06,
      "loss": 0.0538,
      "step": 7320
    },
    {
      "epoch": 0.11591747549756955,
      "grad_norm": 0.2959785461425781,
      "learning_rate": 8.840825245024304e-06,
      "loss": 0.1319,
      "step": 7321
    },
    {
      "epoch": 0.11593330905521161,
      "grad_norm": 0.3310742676258087,
      "learning_rate": 8.840666909447885e-06,
      "loss": 0.1324,
      "step": 7322
    },
    {
      "epoch": 0.11594914261285368,
      "grad_norm": 0.05148809403181076,
      "learning_rate": 8.840508573871464e-06,
      "loss": 0.0015,
      "step": 7323
    },
    {
      "epoch": 0.11596497617049575,
      "grad_norm": 0.4529828727245331,
      "learning_rate": 8.840350238295043e-06,
      "loss": 0.0562,
      "step": 7324
    },
    {
      "epoch": 0.11598080972813782,
      "grad_norm": 0.3552139103412628,
      "learning_rate": 8.840191902718622e-06,
      "loss": 0.4298,
      "step": 7325
    },
    {
      "epoch": 0.11599664328577988,
      "grad_norm": 0.3099091947078705,
      "learning_rate": 8.840033567142203e-06,
      "loss": 0.1171,
      "step": 7326
    },
    {
      "epoch": 0.11601247684342195,
      "grad_norm": 0.41574081778526306,
      "learning_rate": 8.83987523156578e-06,
      "loss": 0.3293,
      "step": 7327
    },
    {
      "epoch": 0.11602831040106401,
      "grad_norm": 0.005611363332718611,
      "learning_rate": 8.839716895989361e-06,
      "loss": 0.0001,
      "step": 7328
    },
    {
      "epoch": 0.11604414395870608,
      "grad_norm": 0.008396370336413383,
      "learning_rate": 8.83955856041294e-06,
      "loss": 0.0004,
      "step": 7329
    },
    {
      "epoch": 0.11605997751634815,
      "grad_norm": 0.005802650470286608,
      "learning_rate": 8.839400224836519e-06,
      "loss": 0.0003,
      "step": 7330
    },
    {
      "epoch": 0.11607581107399022,
      "grad_norm": 0.002811546204611659,
      "learning_rate": 8.839241889260098e-06,
      "loss": 0.0001,
      "step": 7331
    },
    {
      "epoch": 0.11609164463163228,
      "grad_norm": 0.19397437572479248,
      "learning_rate": 8.839083553683679e-06,
      "loss": 0.0701,
      "step": 7332
    },
    {
      "epoch": 0.11610747818927435,
      "grad_norm": 0.3320005536079407,
      "learning_rate": 8.838925218107256e-06,
      "loss": 0.0599,
      "step": 7333
    },
    {
      "epoch": 0.11612331174691641,
      "grad_norm": 0.4374646842479706,
      "learning_rate": 8.838766882530837e-06,
      "loss": 0.6221,
      "step": 7334
    },
    {
      "epoch": 0.11613914530455847,
      "grad_norm": 0.2456495463848114,
      "learning_rate": 8.838608546954416e-06,
      "loss": 0.0515,
      "step": 7335
    },
    {
      "epoch": 0.11615497886220055,
      "grad_norm": 0.4241921007633209,
      "learning_rate": 8.838450211377995e-06,
      "loss": 0.4238,
      "step": 7336
    },
    {
      "epoch": 0.11617081241984262,
      "grad_norm": 0.25609225034713745,
      "learning_rate": 8.838291875801574e-06,
      "loss": 0.1319,
      "step": 7337
    },
    {
      "epoch": 0.11618664597748468,
      "grad_norm": 0.020880253985524178,
      "learning_rate": 8.838133540225155e-06,
      "loss": 0.001,
      "step": 7338
    },
    {
      "epoch": 0.11620247953512675,
      "grad_norm": 0.017282066866755486,
      "learning_rate": 8.837975204648733e-06,
      "loss": 0.001,
      "step": 7339
    },
    {
      "epoch": 0.11621831309276881,
      "grad_norm": 0.5116052031517029,
      "learning_rate": 8.837816869072312e-06,
      "loss": 0.2506,
      "step": 7340
    },
    {
      "epoch": 0.11623414665041087,
      "grad_norm": 0.12346803396940231,
      "learning_rate": 8.837658533495892e-06,
      "loss": 0.0215,
      "step": 7341
    },
    {
      "epoch": 0.11624998020805295,
      "grad_norm": 0.2599189877510071,
      "learning_rate": 8.837500197919471e-06,
      "loss": 0.1672,
      "step": 7342
    },
    {
      "epoch": 0.11626581376569502,
      "grad_norm": 0.288366436958313,
      "learning_rate": 8.83734186234305e-06,
      "loss": 0.1374,
      "step": 7343
    },
    {
      "epoch": 0.11628164732333708,
      "grad_norm": 0.32777345180511475,
      "learning_rate": 8.83718352676663e-06,
      "loss": 0.1254,
      "step": 7344
    },
    {
      "epoch": 0.11629748088097915,
      "grad_norm": 0.018690014258027077,
      "learning_rate": 8.837025191190209e-06,
      "loss": 0.0008,
      "step": 7345
    },
    {
      "epoch": 0.11631331443862121,
      "grad_norm": 0.8221426606178284,
      "learning_rate": 8.836866855613788e-06,
      "loss": 0.1168,
      "step": 7346
    },
    {
      "epoch": 0.11632914799626327,
      "grad_norm": 0.2218708097934723,
      "learning_rate": 8.836708520037369e-06,
      "loss": 0.0395,
      "step": 7347
    },
    {
      "epoch": 0.11634498155390535,
      "grad_norm": 0.23347817361354828,
      "learning_rate": 8.836550184460948e-06,
      "loss": 0.137,
      "step": 7348
    },
    {
      "epoch": 0.11636081511154742,
      "grad_norm": 0.14074859023094177,
      "learning_rate": 8.836391848884527e-06,
      "loss": 0.0472,
      "step": 7349
    },
    {
      "epoch": 0.11637664866918948,
      "grad_norm": 0.5012726783752441,
      "learning_rate": 8.836233513308106e-06,
      "loss": 0.5167,
      "step": 7350
    },
    {
      "epoch": 0.11639248222683155,
      "grad_norm": 0.4393389821052551,
      "learning_rate": 8.836075177731685e-06,
      "loss": 0.006,
      "step": 7351
    },
    {
      "epoch": 0.11640831578447361,
      "grad_norm": 0.34790492057800293,
      "learning_rate": 8.835916842155264e-06,
      "loss": 0.2523,
      "step": 7352
    },
    {
      "epoch": 0.11642414934211567,
      "grad_norm": 0.44316402077674866,
      "learning_rate": 8.835758506578845e-06,
      "loss": 0.524,
      "step": 7353
    },
    {
      "epoch": 0.11643998289975775,
      "grad_norm": 0.009334612637758255,
      "learning_rate": 8.835600171002424e-06,
      "loss": 0.0005,
      "step": 7354
    },
    {
      "epoch": 0.11645581645739982,
      "grad_norm": 0.0012207641266286373,
      "learning_rate": 8.835441835426003e-06,
      "loss": 0.0,
      "step": 7355
    },
    {
      "epoch": 0.11647165001504188,
      "grad_norm": 0.14050863683223724,
      "learning_rate": 8.835283499849582e-06,
      "loss": 0.0317,
      "step": 7356
    },
    {
      "epoch": 0.11648748357268394,
      "grad_norm": 0.3942788243293762,
      "learning_rate": 8.835125164273161e-06,
      "loss": 0.0375,
      "step": 7357
    },
    {
      "epoch": 0.11650331713032601,
      "grad_norm": 0.014486316591501236,
      "learning_rate": 8.83496682869674e-06,
      "loss": 0.0003,
      "step": 7358
    },
    {
      "epoch": 0.11651915068796807,
      "grad_norm": 0.39612990617752075,
      "learning_rate": 8.834808493120321e-06,
      "loss": 0.5327,
      "step": 7359
    },
    {
      "epoch": 0.11653498424561015,
      "grad_norm": 0.013412967324256897,
      "learning_rate": 8.8346501575439e-06,
      "loss": 0.0015,
      "step": 7360
    },
    {
      "epoch": 0.11655081780325222,
      "grad_norm": 0.5861220359802246,
      "learning_rate": 8.834491821967479e-06,
      "loss": 0.3048,
      "step": 7361
    },
    {
      "epoch": 0.11656665136089428,
      "grad_norm": 0.25063714385032654,
      "learning_rate": 8.834333486391058e-06,
      "loss": 0.0923,
      "step": 7362
    },
    {
      "epoch": 0.11658248491853634,
      "grad_norm": 0.3628859519958496,
      "learning_rate": 8.834175150814637e-06,
      "loss": 0.0934,
      "step": 7363
    },
    {
      "epoch": 0.11659831847617841,
      "grad_norm": 0.4857110381126404,
      "learning_rate": 8.834016815238216e-06,
      "loss": 0.5464,
      "step": 7364
    },
    {
      "epoch": 0.11661415203382047,
      "grad_norm": 0.28787708282470703,
      "learning_rate": 8.833858479661795e-06,
      "loss": 0.239,
      "step": 7365
    },
    {
      "epoch": 0.11662998559146255,
      "grad_norm": 0.010677986778318882,
      "learning_rate": 8.833700144085376e-06,
      "loss": 0.0002,
      "step": 7366
    },
    {
      "epoch": 0.11664581914910462,
      "grad_norm": 0.540644109249115,
      "learning_rate": 8.833541808508954e-06,
      "loss": 0.0524,
      "step": 7367
    },
    {
      "epoch": 0.11666165270674668,
      "grad_norm": 0.24026797711849213,
      "learning_rate": 8.833383472932534e-06,
      "loss": 0.1809,
      "step": 7368
    },
    {
      "epoch": 0.11667748626438874,
      "grad_norm": 0.23870915174484253,
      "learning_rate": 8.833225137356113e-06,
      "loss": 0.0659,
      "step": 7369
    },
    {
      "epoch": 0.11669331982203081,
      "grad_norm": 0.19831618666648865,
      "learning_rate": 8.833066801779692e-06,
      "loss": 0.0061,
      "step": 7370
    },
    {
      "epoch": 0.11670915337967287,
      "grad_norm": 0.3866181969642639,
      "learning_rate": 8.832908466203272e-06,
      "loss": 0.2144,
      "step": 7371
    },
    {
      "epoch": 0.11672498693731495,
      "grad_norm": 0.01753411628305912,
      "learning_rate": 8.832750130626852e-06,
      "loss": 0.001,
      "step": 7372
    },
    {
      "epoch": 0.11674082049495701,
      "grad_norm": 0.006682087201625109,
      "learning_rate": 8.83259179505043e-06,
      "loss": 0.0005,
      "step": 7373
    },
    {
      "epoch": 0.11675665405259908,
      "grad_norm": 0.4290255010128021,
      "learning_rate": 8.83243345947401e-06,
      "loss": 0.3901,
      "step": 7374
    },
    {
      "epoch": 0.11677248761024114,
      "grad_norm": 0.028102731332182884,
      "learning_rate": 8.83227512389759e-06,
      "loss": 0.0011,
      "step": 7375
    },
    {
      "epoch": 0.11678832116788321,
      "grad_norm": 0.3464651107788086,
      "learning_rate": 8.832116788321169e-06,
      "loss": 0.3432,
      "step": 7376
    },
    {
      "epoch": 0.11680415472552527,
      "grad_norm": 0.2511195242404938,
      "learning_rate": 8.831958452744748e-06,
      "loss": 0.0997,
      "step": 7377
    },
    {
      "epoch": 0.11681998828316735,
      "grad_norm": 0.23811674118041992,
      "learning_rate": 8.831800117168327e-06,
      "loss": 0.1261,
      "step": 7378
    },
    {
      "epoch": 0.11683582184080941,
      "grad_norm": 0.18548962473869324,
      "learning_rate": 8.831641781591906e-06,
      "loss": 0.0513,
      "step": 7379
    },
    {
      "epoch": 0.11685165539845148,
      "grad_norm": 0.4170117974281311,
      "learning_rate": 8.831483446015487e-06,
      "loss": 0.1042,
      "step": 7380
    },
    {
      "epoch": 0.11686748895609354,
      "grad_norm": 0.22202789783477783,
      "learning_rate": 8.831325110439066e-06,
      "loss": 0.09,
      "step": 7381
    },
    {
      "epoch": 0.11688332251373561,
      "grad_norm": 0.622238278388977,
      "learning_rate": 8.831166774862645e-06,
      "loss": 0.5517,
      "step": 7382
    },
    {
      "epoch": 0.11689915607137767,
      "grad_norm": 0.302110493183136,
      "learning_rate": 8.831008439286224e-06,
      "loss": 0.0693,
      "step": 7383
    },
    {
      "epoch": 0.11691498962901975,
      "grad_norm": 0.4951505959033966,
      "learning_rate": 8.830850103709803e-06,
      "loss": 0.1657,
      "step": 7384
    },
    {
      "epoch": 0.11693082318666181,
      "grad_norm": 0.3712103068828583,
      "learning_rate": 8.830691768133382e-06,
      "loss": 0.3202,
      "step": 7385
    },
    {
      "epoch": 0.11694665674430388,
      "grad_norm": 0.2299327701330185,
      "learning_rate": 8.830533432556963e-06,
      "loss": 0.0183,
      "step": 7386
    },
    {
      "epoch": 0.11696249030194594,
      "grad_norm": 0.3284660875797272,
      "learning_rate": 8.830375096980542e-06,
      "loss": 0.0571,
      "step": 7387
    },
    {
      "epoch": 0.11697832385958801,
      "grad_norm": 0.002039814367890358,
      "learning_rate": 8.83021676140412e-06,
      "loss": 0.0001,
      "step": 7388
    },
    {
      "epoch": 0.11699415741723007,
      "grad_norm": 0.18287238478660583,
      "learning_rate": 8.8300584258277e-06,
      "loss": 0.0323,
      "step": 7389
    },
    {
      "epoch": 0.11700999097487215,
      "grad_norm": 0.6753209233283997,
      "learning_rate": 8.82990009025128e-06,
      "loss": 0.8187,
      "step": 7390
    },
    {
      "epoch": 0.11702582453251421,
      "grad_norm": 0.2296333909034729,
      "learning_rate": 8.829741754674858e-06,
      "loss": 0.1266,
      "step": 7391
    },
    {
      "epoch": 0.11704165809015628,
      "grad_norm": 0.0004183826094958931,
      "learning_rate": 8.829583419098437e-06,
      "loss": 0.0,
      "step": 7392
    },
    {
      "epoch": 0.11705749164779834,
      "grad_norm": 0.4610387980937958,
      "learning_rate": 8.829425083522018e-06,
      "loss": 0.2289,
      "step": 7393
    },
    {
      "epoch": 0.1170733252054404,
      "grad_norm": 0.6454416513442993,
      "learning_rate": 8.829266747945595e-06,
      "loss": 0.1214,
      "step": 7394
    },
    {
      "epoch": 0.11708915876308247,
      "grad_norm": 0.09608855843544006,
      "learning_rate": 8.829108412369176e-06,
      "loss": 0.0075,
      "step": 7395
    },
    {
      "epoch": 0.11710499232072455,
      "grad_norm": 0.45807892084121704,
      "learning_rate": 8.828950076792755e-06,
      "loss": 0.0708,
      "step": 7396
    },
    {
      "epoch": 0.11712082587836661,
      "grad_norm": 0.01281747780740261,
      "learning_rate": 8.828791741216334e-06,
      "loss": 0.0005,
      "step": 7397
    },
    {
      "epoch": 0.11713665943600868,
      "grad_norm": 0.0019420890603214502,
      "learning_rate": 8.828633405639913e-06,
      "loss": 0.0,
      "step": 7398
    },
    {
      "epoch": 0.11715249299365074,
      "grad_norm": 0.12436837702989578,
      "learning_rate": 8.828475070063494e-06,
      "loss": 0.0102,
      "step": 7399
    },
    {
      "epoch": 0.1171683265512928,
      "grad_norm": 0.2851964235305786,
      "learning_rate": 8.828316734487072e-06,
      "loss": 0.3043,
      "step": 7400
    },
    {
      "epoch": 0.11718416010893487,
      "grad_norm": 0.2559429705142975,
      "learning_rate": 8.828158398910652e-06,
      "loss": 0.0771,
      "step": 7401
    },
    {
      "epoch": 0.11719999366657695,
      "grad_norm": 0.49378088116645813,
      "learning_rate": 8.828000063334231e-06,
      "loss": 0.6296,
      "step": 7402
    },
    {
      "epoch": 0.11721582722421901,
      "grad_norm": 0.5564534068107605,
      "learning_rate": 8.82784172775781e-06,
      "loss": 0.0996,
      "step": 7403
    },
    {
      "epoch": 0.11723166078186108,
      "grad_norm": 0.008407814428210258,
      "learning_rate": 8.82768339218139e-06,
      "loss": 0.0003,
      "step": 7404
    },
    {
      "epoch": 0.11724749433950314,
      "grad_norm": 0.010548725724220276,
      "learning_rate": 8.82752505660497e-06,
      "loss": 0.0003,
      "step": 7405
    },
    {
      "epoch": 0.1172633278971452,
      "grad_norm": 0.022029120475053787,
      "learning_rate": 8.827366721028548e-06,
      "loss": 0.0011,
      "step": 7406
    },
    {
      "epoch": 0.11727916145478727,
      "grad_norm": 0.25935816764831543,
      "learning_rate": 8.827208385452129e-06,
      "loss": 0.2374,
      "step": 7407
    },
    {
      "epoch": 0.11729499501242935,
      "grad_norm": 0.45327675342559814,
      "learning_rate": 8.827050049875708e-06,
      "loss": 0.1247,
      "step": 7408
    },
    {
      "epoch": 0.11731082857007141,
      "grad_norm": 0.1658758670091629,
      "learning_rate": 8.826891714299287e-06,
      "loss": 0.0379,
      "step": 7409
    },
    {
      "epoch": 0.11732666212771348,
      "grad_norm": 0.2734619677066803,
      "learning_rate": 8.826733378722866e-06,
      "loss": 0.136,
      "step": 7410
    },
    {
      "epoch": 0.11734249568535554,
      "grad_norm": 0.007264258340001106,
      "learning_rate": 8.826575043146445e-06,
      "loss": 0.0002,
      "step": 7411
    },
    {
      "epoch": 0.1173583292429976,
      "grad_norm": 0.015023868530988693,
      "learning_rate": 8.826416707570024e-06,
      "loss": 0.0007,
      "step": 7412
    },
    {
      "epoch": 0.11737416280063967,
      "grad_norm": 1.042474389076233,
      "learning_rate": 8.826258371993603e-06,
      "loss": 0.9425,
      "step": 7413
    },
    {
      "epoch": 0.11738999635828175,
      "grad_norm": 0.29405900835990906,
      "learning_rate": 8.826100036417184e-06,
      "loss": 0.0717,
      "step": 7414
    },
    {
      "epoch": 0.11740582991592381,
      "grad_norm": 1.1350797414779663,
      "learning_rate": 8.825941700840763e-06,
      "loss": 0.0344,
      "step": 7415
    },
    {
      "epoch": 0.11742166347356588,
      "grad_norm": 0.9616442918777466,
      "learning_rate": 8.825783365264342e-06,
      "loss": 0.0848,
      "step": 7416
    },
    {
      "epoch": 0.11743749703120794,
      "grad_norm": 0.6037731766700745,
      "learning_rate": 8.825625029687921e-06,
      "loss": 0.076,
      "step": 7417
    },
    {
      "epoch": 0.11745333058885,
      "grad_norm": 0.19739416241645813,
      "learning_rate": 8.8254666941115e-06,
      "loss": 0.08,
      "step": 7418
    },
    {
      "epoch": 0.11746916414649207,
      "grad_norm": 0.4296334981918335,
      "learning_rate": 8.82530835853508e-06,
      "loss": 0.5848,
      "step": 7419
    },
    {
      "epoch": 0.11748499770413415,
      "grad_norm": 0.008676345460116863,
      "learning_rate": 8.82515002295866e-06,
      "loss": 0.0003,
      "step": 7420
    },
    {
      "epoch": 0.11750083126177621,
      "grad_norm": 0.005836040712893009,
      "learning_rate": 8.824991687382239e-06,
      "loss": 0.0003,
      "step": 7421
    },
    {
      "epoch": 0.11751666481941828,
      "grad_norm": 0.5624034404754639,
      "learning_rate": 8.824833351805818e-06,
      "loss": 0.0809,
      "step": 7422
    },
    {
      "epoch": 0.11753249837706034,
      "grad_norm": 0.0050887977704405785,
      "learning_rate": 8.824675016229397e-06,
      "loss": 0.0002,
      "step": 7423
    },
    {
      "epoch": 0.1175483319347024,
      "grad_norm": 0.18860305845737457,
      "learning_rate": 8.824516680652976e-06,
      "loss": 0.0354,
      "step": 7424
    },
    {
      "epoch": 0.11756416549234447,
      "grad_norm": 0.37556755542755127,
      "learning_rate": 8.824358345076555e-06,
      "loss": 0.2409,
      "step": 7425
    },
    {
      "epoch": 0.11757999904998655,
      "grad_norm": 0.13144010305404663,
      "learning_rate": 8.824200009500136e-06,
      "loss": 0.0578,
      "step": 7426
    },
    {
      "epoch": 0.11759583260762861,
      "grad_norm": 0.019702797755599022,
      "learning_rate": 8.824041673923715e-06,
      "loss": 0.0007,
      "step": 7427
    },
    {
      "epoch": 0.11761166616527068,
      "grad_norm": 0.20020464062690735,
      "learning_rate": 8.823883338347294e-06,
      "loss": 0.0369,
      "step": 7428
    },
    {
      "epoch": 0.11762749972291274,
      "grad_norm": 0.46774598956108093,
      "learning_rate": 8.823725002770873e-06,
      "loss": 0.4828,
      "step": 7429
    },
    {
      "epoch": 0.1176433332805548,
      "grad_norm": 0.1511957049369812,
      "learning_rate": 8.823566667194453e-06,
      "loss": 0.0684,
      "step": 7430
    },
    {
      "epoch": 0.11765916683819687,
      "grad_norm": 0.5966616272926331,
      "learning_rate": 8.823408331618032e-06,
      "loss": 0.6508,
      "step": 7431
    },
    {
      "epoch": 0.11767500039583895,
      "grad_norm": 0.2849491238594055,
      "learning_rate": 8.823249996041612e-06,
      "loss": 0.1323,
      "step": 7432
    },
    {
      "epoch": 0.11769083395348101,
      "grad_norm": 0.4049961566925049,
      "learning_rate": 8.823091660465191e-06,
      "loss": 0.3664,
      "step": 7433
    },
    {
      "epoch": 0.11770666751112308,
      "grad_norm": 0.2961120009422302,
      "learning_rate": 8.82293332488877e-06,
      "loss": 0.064,
      "step": 7434
    },
    {
      "epoch": 0.11772250106876514,
      "grad_norm": 0.2579551935195923,
      "learning_rate": 8.82277498931235e-06,
      "loss": 0.0896,
      "step": 7435
    },
    {
      "epoch": 0.1177383346264072,
      "grad_norm": 0.11190056800842285,
      "learning_rate": 8.822616653735929e-06,
      "loss": 0.0444,
      "step": 7436
    },
    {
      "epoch": 0.11775416818404927,
      "grad_norm": 0.13181467354297638,
      "learning_rate": 8.822458318159508e-06,
      "loss": 0.0326,
      "step": 7437
    },
    {
      "epoch": 0.11777000174169135,
      "grad_norm": 0.3270203471183777,
      "learning_rate": 8.822299982583087e-06,
      "loss": 0.4693,
      "step": 7438
    },
    {
      "epoch": 0.11778583529933341,
      "grad_norm": 0.5041112303733826,
      "learning_rate": 8.822141647006666e-06,
      "loss": 0.5839,
      "step": 7439
    },
    {
      "epoch": 0.11780166885697547,
      "grad_norm": 0.5079879760742188,
      "learning_rate": 8.821983311430245e-06,
      "loss": 0.0661,
      "step": 7440
    },
    {
      "epoch": 0.11781750241461754,
      "grad_norm": 0.23889771103858948,
      "learning_rate": 8.821824975853826e-06,
      "loss": 0.1324,
      "step": 7441
    },
    {
      "epoch": 0.1178333359722596,
      "grad_norm": 0.27818942070007324,
      "learning_rate": 8.821666640277405e-06,
      "loss": 0.1122,
      "step": 7442
    },
    {
      "epoch": 0.11784916952990167,
      "grad_norm": 0.0012068620417267084,
      "learning_rate": 8.821508304700984e-06,
      "loss": 0.0,
      "step": 7443
    },
    {
      "epoch": 0.11786500308754375,
      "grad_norm": 0.15314802527427673,
      "learning_rate": 8.821349969124563e-06,
      "loss": 0.0329,
      "step": 7444
    },
    {
      "epoch": 0.11788083664518581,
      "grad_norm": 0.03092949464917183,
      "learning_rate": 8.821191633548142e-06,
      "loss": 0.0013,
      "step": 7445
    },
    {
      "epoch": 0.11789667020282787,
      "grad_norm": 0.05785989761352539,
      "learning_rate": 8.821033297971721e-06,
      "loss": 0.001,
      "step": 7446
    },
    {
      "epoch": 0.11791250376046994,
      "grad_norm": 0.25805872678756714,
      "learning_rate": 8.820874962395302e-06,
      "loss": 0.0997,
      "step": 7447
    },
    {
      "epoch": 0.117928337318112,
      "grad_norm": 0.33848342299461365,
      "learning_rate": 8.820716626818881e-06,
      "loss": 0.1752,
      "step": 7448
    },
    {
      "epoch": 0.11794417087575407,
      "grad_norm": 0.5218943953514099,
      "learning_rate": 8.82055829124246e-06,
      "loss": 0.5124,
      "step": 7449
    },
    {
      "epoch": 0.11796000443339615,
      "grad_norm": 0.5025465488433838,
      "learning_rate": 8.82039995566604e-06,
      "loss": 0.5461,
      "step": 7450
    },
    {
      "epoch": 0.11797583799103821,
      "grad_norm": 0.389619380235672,
      "learning_rate": 8.820241620089618e-06,
      "loss": 0.3478,
      "step": 7451
    },
    {
      "epoch": 0.11799167154868027,
      "grad_norm": 0.37737834453582764,
      "learning_rate": 8.820083284513197e-06,
      "loss": 0.1411,
      "step": 7452
    },
    {
      "epoch": 0.11800750510632234,
      "grad_norm": 0.22509869933128357,
      "learning_rate": 8.819924948936778e-06,
      "loss": 0.0704,
      "step": 7453
    },
    {
      "epoch": 0.1180233386639644,
      "grad_norm": 0.004976213909685612,
      "learning_rate": 8.819766613360357e-06,
      "loss": 0.0002,
      "step": 7454
    },
    {
      "epoch": 0.11803917222160647,
      "grad_norm": 0.5201186537742615,
      "learning_rate": 8.819608277783936e-06,
      "loss": 0.3092,
      "step": 7455
    },
    {
      "epoch": 0.11805500577924855,
      "grad_norm": 0.1864526867866516,
      "learning_rate": 8.819449942207515e-06,
      "loss": 0.0427,
      "step": 7456
    },
    {
      "epoch": 0.11807083933689061,
      "grad_norm": 0.36895766854286194,
      "learning_rate": 8.819291606631094e-06,
      "loss": 0.2632,
      "step": 7457
    },
    {
      "epoch": 0.11808667289453267,
      "grad_norm": 0.45441222190856934,
      "learning_rate": 8.819133271054674e-06,
      "loss": 0.147,
      "step": 7458
    },
    {
      "epoch": 0.11810250645217474,
      "grad_norm": 0.312824010848999,
      "learning_rate": 8.818974935478253e-06,
      "loss": 0.1832,
      "step": 7459
    },
    {
      "epoch": 0.1181183400098168,
      "grad_norm": 0.2925304174423218,
      "learning_rate": 8.818816599901833e-06,
      "loss": 0.0237,
      "step": 7460
    },
    {
      "epoch": 0.11813417356745887,
      "grad_norm": 0.7459614276885986,
      "learning_rate": 8.81865826432541e-06,
      "loss": 0.0465,
      "step": 7461
    },
    {
      "epoch": 0.11815000712510094,
      "grad_norm": 0.00048699454055167735,
      "learning_rate": 8.818499928748992e-06,
      "loss": 0.0,
      "step": 7462
    },
    {
      "epoch": 0.11816584068274301,
      "grad_norm": 0.3089464604854584,
      "learning_rate": 8.81834159317257e-06,
      "loss": 0.0195,
      "step": 7463
    },
    {
      "epoch": 0.11818167424038507,
      "grad_norm": 0.46417373418807983,
      "learning_rate": 8.81818325759615e-06,
      "loss": 0.1088,
      "step": 7464
    },
    {
      "epoch": 0.11819750779802714,
      "grad_norm": 0.9480305314064026,
      "learning_rate": 8.818024922019729e-06,
      "loss": 0.2792,
      "step": 7465
    },
    {
      "epoch": 0.1182133413556692,
      "grad_norm": 0.0011448821751400828,
      "learning_rate": 8.81786658644331e-06,
      "loss": 0.0,
      "step": 7466
    },
    {
      "epoch": 0.11822917491331127,
      "grad_norm": 0.9985100626945496,
      "learning_rate": 8.817708250866887e-06,
      "loss": 0.3988,
      "step": 7467
    },
    {
      "epoch": 0.11824500847095334,
      "grad_norm": 0.43847930431365967,
      "learning_rate": 8.817549915290468e-06,
      "loss": 0.211,
      "step": 7468
    },
    {
      "epoch": 0.11826084202859541,
      "grad_norm": 0.0014173092786222696,
      "learning_rate": 8.817391579714047e-06,
      "loss": 0.0,
      "step": 7469
    },
    {
      "epoch": 0.11827667558623747,
      "grad_norm": 0.0017001025844365358,
      "learning_rate": 8.817233244137626e-06,
      "loss": 0.0,
      "step": 7470
    },
    {
      "epoch": 0.11829250914387954,
      "grad_norm": 0.5035515427589417,
      "learning_rate": 8.817074908561205e-06,
      "loss": 0.1507,
      "step": 7471
    },
    {
      "epoch": 0.1183083427015216,
      "grad_norm": 0.0026091451290994883,
      "learning_rate": 8.816916572984786e-06,
      "loss": 0.0001,
      "step": 7472
    },
    {
      "epoch": 0.11832417625916367,
      "grad_norm": 0.42212021350860596,
      "learning_rate": 8.816758237408363e-06,
      "loss": 0.0968,
      "step": 7473
    },
    {
      "epoch": 0.11834000981680574,
      "grad_norm": 0.38903820514678955,
      "learning_rate": 8.816599901831944e-06,
      "loss": 0.1443,
      "step": 7474
    },
    {
      "epoch": 0.11835584337444781,
      "grad_norm": 0.6035163402557373,
      "learning_rate": 8.816441566255523e-06,
      "loss": 0.2971,
      "step": 7475
    },
    {
      "epoch": 0.11837167693208987,
      "grad_norm": 0.0014774554874747992,
      "learning_rate": 8.816283230679102e-06,
      "loss": 0.0,
      "step": 7476
    },
    {
      "epoch": 0.11838751048973194,
      "grad_norm": 0.004793637897819281,
      "learning_rate": 8.816124895102681e-06,
      "loss": 0.0001,
      "step": 7477
    },
    {
      "epoch": 0.118403344047374,
      "grad_norm": 0.2915498614311218,
      "learning_rate": 8.815966559526262e-06,
      "loss": 0.0573,
      "step": 7478
    },
    {
      "epoch": 0.11841917760501607,
      "grad_norm": 0.3380235731601715,
      "learning_rate": 8.81580822394984e-06,
      "loss": 0.0981,
      "step": 7479
    },
    {
      "epoch": 0.11843501116265814,
      "grad_norm": 0.23467467725276947,
      "learning_rate": 8.81564988837342e-06,
      "loss": 0.1002,
      "step": 7480
    },
    {
      "epoch": 0.11845084472030021,
      "grad_norm": 0.3823685348033905,
      "learning_rate": 8.815491552796999e-06,
      "loss": 0.1754,
      "step": 7481
    },
    {
      "epoch": 0.11846667827794227,
      "grad_norm": 0.7238128185272217,
      "learning_rate": 8.815333217220578e-06,
      "loss": 0.1557,
      "step": 7482
    },
    {
      "epoch": 0.11848251183558434,
      "grad_norm": 0.7348341941833496,
      "learning_rate": 8.815174881644157e-06,
      "loss": 0.8135,
      "step": 7483
    },
    {
      "epoch": 0.1184983453932264,
      "grad_norm": 0.38418760895729065,
      "learning_rate": 8.815016546067736e-06,
      "loss": 0.1227,
      "step": 7484
    },
    {
      "epoch": 0.11851417895086847,
      "grad_norm": 0.5289455652236938,
      "learning_rate": 8.814858210491315e-06,
      "loss": 0.1345,
      "step": 7485
    },
    {
      "epoch": 0.11853001250851054,
      "grad_norm": 0.25233444571495056,
      "learning_rate": 8.814699874914895e-06,
      "loss": 0.23,
      "step": 7486
    },
    {
      "epoch": 0.11854584606615261,
      "grad_norm": 0.252802312374115,
      "learning_rate": 8.814541539338475e-06,
      "loss": 0.1336,
      "step": 7487
    },
    {
      "epoch": 0.11856167962379467,
      "grad_norm": 0.23869745433330536,
      "learning_rate": 8.814383203762054e-06,
      "loss": 0.1142,
      "step": 7488
    },
    {
      "epoch": 0.11857751318143674,
      "grad_norm": 0.32753312587738037,
      "learning_rate": 8.814224868185633e-06,
      "loss": 0.4015,
      "step": 7489
    },
    {
      "epoch": 0.1185933467390788,
      "grad_norm": 0.22659605741500854,
      "learning_rate": 8.814066532609213e-06,
      "loss": 0.0499,
      "step": 7490
    },
    {
      "epoch": 0.11860918029672086,
      "grad_norm": 0.33975037932395935,
      "learning_rate": 8.813908197032792e-06,
      "loss": 0.0857,
      "step": 7491
    },
    {
      "epoch": 0.11862501385436294,
      "grad_norm": 0.013280493207275867,
      "learning_rate": 8.81374986145637e-06,
      "loss": 0.0006,
      "step": 7492
    },
    {
      "epoch": 0.11864084741200501,
      "grad_norm": 0.012632097117602825,
      "learning_rate": 8.813591525879951e-06,
      "loss": 0.0006,
      "step": 7493
    },
    {
      "epoch": 0.11865668096964707,
      "grad_norm": 0.3073030412197113,
      "learning_rate": 8.81343319030353e-06,
      "loss": 0.1284,
      "step": 7494
    },
    {
      "epoch": 0.11867251452728914,
      "grad_norm": 0.44569358229637146,
      "learning_rate": 8.81327485472711e-06,
      "loss": 0.8568,
      "step": 7495
    },
    {
      "epoch": 0.1186883480849312,
      "grad_norm": 0.4002586603164673,
      "learning_rate": 8.813116519150689e-06,
      "loss": 0.1367,
      "step": 7496
    },
    {
      "epoch": 0.11870418164257326,
      "grad_norm": 0.27828511595726013,
      "learning_rate": 8.812958183574268e-06,
      "loss": 0.1612,
      "step": 7497
    },
    {
      "epoch": 0.11872001520021534,
      "grad_norm": 0.4520975351333618,
      "learning_rate": 8.812799847997847e-06,
      "loss": 0.4394,
      "step": 7498
    },
    {
      "epoch": 0.1187358487578574,
      "grad_norm": 0.0011708330130204558,
      "learning_rate": 8.812641512421428e-06,
      "loss": 0.0,
      "step": 7499
    },
    {
      "epoch": 0.11875168231549947,
      "grad_norm": 0.31653907895088196,
      "learning_rate": 8.812483176845007e-06,
      "loss": 0.2107,
      "step": 7500
    },
    {
      "epoch": 0.11876751587314154,
      "grad_norm": 0.1366567313671112,
      "learning_rate": 8.812324841268586e-06,
      "loss": 0.0423,
      "step": 7501
    },
    {
      "epoch": 0.1187833494307836,
      "grad_norm": 0.28098711371421814,
      "learning_rate": 8.812166505692165e-06,
      "loss": 0.0709,
      "step": 7502
    },
    {
      "epoch": 0.11879918298842566,
      "grad_norm": 0.2800966203212738,
      "learning_rate": 8.812008170115744e-06,
      "loss": 0.1766,
      "step": 7503
    },
    {
      "epoch": 0.11881501654606774,
      "grad_norm": 0.24063774943351746,
      "learning_rate": 8.811849834539323e-06,
      "loss": 0.053,
      "step": 7504
    },
    {
      "epoch": 0.1188308501037098,
      "grad_norm": 0.00549272308126092,
      "learning_rate": 8.811691498962904e-06,
      "loss": 0.0001,
      "step": 7505
    },
    {
      "epoch": 0.11884668366135187,
      "grad_norm": 0.009105686098337173,
      "learning_rate": 8.811533163386481e-06,
      "loss": 0.0003,
      "step": 7506
    },
    {
      "epoch": 0.11886251721899393,
      "grad_norm": 0.022382019087672234,
      "learning_rate": 8.81137482781006e-06,
      "loss": 0.0013,
      "step": 7507
    },
    {
      "epoch": 0.118878350776636,
      "grad_norm": 0.490327924489975,
      "learning_rate": 8.811216492233641e-06,
      "loss": 0.1933,
      "step": 7508
    },
    {
      "epoch": 0.11889418433427806,
      "grad_norm": 0.008834542706608772,
      "learning_rate": 8.81105815665722e-06,
      "loss": 0.0004,
      "step": 7509
    },
    {
      "epoch": 0.11891001789192014,
      "grad_norm": 0.34316492080688477,
      "learning_rate": 8.8108998210808e-06,
      "loss": 0.2509,
      "step": 7510
    },
    {
      "epoch": 0.1189258514495622,
      "grad_norm": 0.022479146718978882,
      "learning_rate": 8.810741485504378e-06,
      "loss": 0.0011,
      "step": 7511
    },
    {
      "epoch": 0.11894168500720427,
      "grad_norm": 0.43713054060935974,
      "learning_rate": 8.810583149927957e-06,
      "loss": 0.2079,
      "step": 7512
    },
    {
      "epoch": 0.11895751856484633,
      "grad_norm": 0.5198626518249512,
      "learning_rate": 8.810424814351536e-06,
      "loss": 0.5197,
      "step": 7513
    },
    {
      "epoch": 0.1189733521224884,
      "grad_norm": 0.37228506803512573,
      "learning_rate": 8.810266478775117e-06,
      "loss": 0.143,
      "step": 7514
    },
    {
      "epoch": 0.11898918568013046,
      "grad_norm": 0.42024385929107666,
      "learning_rate": 8.810108143198696e-06,
      "loss": 0.2364,
      "step": 7515
    },
    {
      "epoch": 0.11900501923777254,
      "grad_norm": 0.16266793012619019,
      "learning_rate": 8.809949807622275e-06,
      "loss": 0.049,
      "step": 7516
    },
    {
      "epoch": 0.1190208527954146,
      "grad_norm": 0.961854875087738,
      "learning_rate": 8.809791472045854e-06,
      "loss": 0.3209,
      "step": 7517
    },
    {
      "epoch": 0.11903668635305667,
      "grad_norm": 0.19648878276348114,
      "learning_rate": 8.809633136469434e-06,
      "loss": 0.0545,
      "step": 7518
    },
    {
      "epoch": 0.11905251991069873,
      "grad_norm": 0.7603561282157898,
      "learning_rate": 8.809474800893013e-06,
      "loss": 0.5943,
      "step": 7519
    },
    {
      "epoch": 0.1190683534683408,
      "grad_norm": 0.07506262511014938,
      "learning_rate": 8.809316465316593e-06,
      "loss": 0.0049,
      "step": 7520
    },
    {
      "epoch": 0.11908418702598286,
      "grad_norm": 0.3603043854236603,
      "learning_rate": 8.809158129740172e-06,
      "loss": 0.2764,
      "step": 7521
    },
    {
      "epoch": 0.11910002058362494,
      "grad_norm": 0.0005813822499476373,
      "learning_rate": 8.808999794163752e-06,
      "loss": 0.0,
      "step": 7522
    },
    {
      "epoch": 0.119115854141267,
      "grad_norm": 0.23818887770175934,
      "learning_rate": 8.80884145858733e-06,
      "loss": 0.1101,
      "step": 7523
    },
    {
      "epoch": 0.11913168769890907,
      "grad_norm": 0.2403673678636551,
      "learning_rate": 8.80868312301091e-06,
      "loss": 0.0914,
      "step": 7524
    },
    {
      "epoch": 0.11914752125655113,
      "grad_norm": 0.4189966022968292,
      "learning_rate": 8.808524787434489e-06,
      "loss": 0.6219,
      "step": 7525
    },
    {
      "epoch": 0.1191633548141932,
      "grad_norm": 0.026579704135656357,
      "learning_rate": 8.80836645185807e-06,
      "loss": 0.0014,
      "step": 7526
    },
    {
      "epoch": 0.11917918837183526,
      "grad_norm": 0.30680081248283386,
      "learning_rate": 8.808208116281649e-06,
      "loss": 0.1283,
      "step": 7527
    },
    {
      "epoch": 0.11919502192947734,
      "grad_norm": 0.02166471630334854,
      "learning_rate": 8.808049780705228e-06,
      "loss": 0.0011,
      "step": 7528
    },
    {
      "epoch": 0.1192108554871194,
      "grad_norm": 0.45570412278175354,
      "learning_rate": 8.807891445128807e-06,
      "loss": 0.4839,
      "step": 7529
    },
    {
      "epoch": 0.11922668904476147,
      "grad_norm": 0.1981050819158554,
      "learning_rate": 8.807733109552386e-06,
      "loss": 0.0964,
      "step": 7530
    },
    {
      "epoch": 0.11924252260240353,
      "grad_norm": 0.2510518431663513,
      "learning_rate": 8.807574773975965e-06,
      "loss": 0.0549,
      "step": 7531
    },
    {
      "epoch": 0.1192583561600456,
      "grad_norm": 0.33923712372779846,
      "learning_rate": 8.807416438399544e-06,
      "loss": 0.4049,
      "step": 7532
    },
    {
      "epoch": 0.11927418971768766,
      "grad_norm": 0.2736542522907257,
      "learning_rate": 8.807258102823125e-06,
      "loss": 0.0231,
      "step": 7533
    },
    {
      "epoch": 0.11929002327532974,
      "grad_norm": 0.21463024616241455,
      "learning_rate": 8.807099767246702e-06,
      "loss": 0.0606,
      "step": 7534
    },
    {
      "epoch": 0.1193058568329718,
      "grad_norm": 0.18437142670154572,
      "learning_rate": 8.806941431670283e-06,
      "loss": 0.0051,
      "step": 7535
    },
    {
      "epoch": 0.11932169039061387,
      "grad_norm": 0.21356086432933807,
      "learning_rate": 8.806783096093862e-06,
      "loss": 0.0966,
      "step": 7536
    },
    {
      "epoch": 0.11933752394825593,
      "grad_norm": 0.3965708017349243,
      "learning_rate": 8.806624760517441e-06,
      "loss": 0.0798,
      "step": 7537
    },
    {
      "epoch": 0.119353357505898,
      "grad_norm": 0.0005362732918001711,
      "learning_rate": 8.80646642494102e-06,
      "loss": 0.0,
      "step": 7538
    },
    {
      "epoch": 0.11936919106354006,
      "grad_norm": 0.1902133822441101,
      "learning_rate": 8.806308089364601e-06,
      "loss": 0.1245,
      "step": 7539
    },
    {
      "epoch": 0.11938502462118214,
      "grad_norm": 0.5433982014656067,
      "learning_rate": 8.806149753788178e-06,
      "loss": 0.0669,
      "step": 7540
    },
    {
      "epoch": 0.1194008581788242,
      "grad_norm": 0.06221925467252731,
      "learning_rate": 8.805991418211759e-06,
      "loss": 0.0047,
      "step": 7541
    },
    {
      "epoch": 0.11941669173646627,
      "grad_norm": 0.5213580131530762,
      "learning_rate": 8.805833082635338e-06,
      "loss": 0.5092,
      "step": 7542
    },
    {
      "epoch": 0.11943252529410833,
      "grad_norm": 0.14025640487670898,
      "learning_rate": 8.805674747058917e-06,
      "loss": 0.0445,
      "step": 7543
    },
    {
      "epoch": 0.1194483588517504,
      "grad_norm": 0.2599671185016632,
      "learning_rate": 8.805516411482496e-06,
      "loss": 0.0463,
      "step": 7544
    },
    {
      "epoch": 0.11946419240939246,
      "grad_norm": 0.661095380783081,
      "learning_rate": 8.805358075906077e-06,
      "loss": 0.6433,
      "step": 7545
    },
    {
      "epoch": 0.11948002596703454,
      "grad_norm": 0.1882474273443222,
      "learning_rate": 8.805199740329655e-06,
      "loss": 0.0765,
      "step": 7546
    },
    {
      "epoch": 0.1194958595246766,
      "grad_norm": 0.2983022630214691,
      "learning_rate": 8.805041404753235e-06,
      "loss": 0.0582,
      "step": 7547
    },
    {
      "epoch": 0.11951169308231867,
      "grad_norm": 0.22333388030529022,
      "learning_rate": 8.804883069176814e-06,
      "loss": 0.072,
      "step": 7548
    },
    {
      "epoch": 0.11952752663996073,
      "grad_norm": 0.172649085521698,
      "learning_rate": 8.804724733600393e-06,
      "loss": 0.0502,
      "step": 7549
    },
    {
      "epoch": 0.1195433601976028,
      "grad_norm": 0.4744971692562103,
      "learning_rate": 8.804566398023973e-06,
      "loss": 0.8525,
      "step": 7550
    },
    {
      "epoch": 0.11955919375524486,
      "grad_norm": 0.4026559889316559,
      "learning_rate": 8.804408062447553e-06,
      "loss": 0.0421,
      "step": 7551
    },
    {
      "epoch": 0.11957502731288694,
      "grad_norm": 0.0142636988312006,
      "learning_rate": 8.80424972687113e-06,
      "loss": 0.0007,
      "step": 7552
    },
    {
      "epoch": 0.119590860870529,
      "grad_norm": 0.6414732933044434,
      "learning_rate": 8.804091391294711e-06,
      "loss": 1.1623,
      "step": 7553
    },
    {
      "epoch": 0.11960669442817107,
      "grad_norm": 0.35328003764152527,
      "learning_rate": 8.80393305571829e-06,
      "loss": 0.1076,
      "step": 7554
    },
    {
      "epoch": 0.11962252798581313,
      "grad_norm": 0.5565827488899231,
      "learning_rate": 8.80377472014187e-06,
      "loss": 0.0788,
      "step": 7555
    },
    {
      "epoch": 0.1196383615434552,
      "grad_norm": 0.0008577796397730708,
      "learning_rate": 8.803616384565449e-06,
      "loss": 0.0,
      "step": 7556
    },
    {
      "epoch": 0.11965419510109726,
      "grad_norm": 0.3162449300289154,
      "learning_rate": 8.803458048989028e-06,
      "loss": 0.1453,
      "step": 7557
    },
    {
      "epoch": 0.11967002865873934,
      "grad_norm": 0.03079860284924507,
      "learning_rate": 8.803299713412607e-06,
      "loss": 0.0033,
      "step": 7558
    },
    {
      "epoch": 0.1196858622163814,
      "grad_norm": 0.0030278696212917566,
      "learning_rate": 8.803141377836186e-06,
      "loss": 0.0001,
      "step": 7559
    },
    {
      "epoch": 0.11970169577402347,
      "grad_norm": 0.00026783227804116905,
      "learning_rate": 8.802983042259767e-06,
      "loss": 0.0,
      "step": 7560
    },
    {
      "epoch": 0.11971752933166553,
      "grad_norm": 0.0006386410677805543,
      "learning_rate": 8.802824706683346e-06,
      "loss": 0.0,
      "step": 7561
    },
    {
      "epoch": 0.1197333628893076,
      "grad_norm": 0.21122495830059052,
      "learning_rate": 8.802666371106925e-06,
      "loss": 0.0655,
      "step": 7562
    },
    {
      "epoch": 0.11974919644694966,
      "grad_norm": 0.016055386513471603,
      "learning_rate": 8.802508035530504e-06,
      "loss": 0.0007,
      "step": 7563
    },
    {
      "epoch": 0.11976503000459174,
      "grad_norm": 0.49340710043907166,
      "learning_rate": 8.802349699954083e-06,
      "loss": 0.4366,
      "step": 7564
    },
    {
      "epoch": 0.1197808635622338,
      "grad_norm": 0.37788793444633484,
      "learning_rate": 8.802191364377662e-06,
      "loss": 0.0633,
      "step": 7565
    },
    {
      "epoch": 0.11979669711987587,
      "grad_norm": 0.36906546354293823,
      "learning_rate": 8.802033028801243e-06,
      "loss": 0.0578,
      "step": 7566
    },
    {
      "epoch": 0.11981253067751793,
      "grad_norm": 0.9346694946289062,
      "learning_rate": 8.801874693224822e-06,
      "loss": 0.8283,
      "step": 7567
    },
    {
      "epoch": 0.11982836423516,
      "grad_norm": 0.003828258952125907,
      "learning_rate": 8.801716357648401e-06,
      "loss": 0.0,
      "step": 7568
    },
    {
      "epoch": 0.11984419779280206,
      "grad_norm": 0.09851647168397903,
      "learning_rate": 8.80155802207198e-06,
      "loss": 0.0039,
      "step": 7569
    },
    {
      "epoch": 0.11986003135044414,
      "grad_norm": 0.3003438711166382,
      "learning_rate": 8.80139968649556e-06,
      "loss": 0.104,
      "step": 7570
    },
    {
      "epoch": 0.1198758649080862,
      "grad_norm": 0.16131214797496796,
      "learning_rate": 8.801241350919138e-06,
      "loss": 0.03,
      "step": 7571
    },
    {
      "epoch": 0.11989169846572827,
      "grad_norm": 0.03231295198202133,
      "learning_rate": 8.801083015342719e-06,
      "loss": 0.0017,
      "step": 7572
    },
    {
      "epoch": 0.11990753202337033,
      "grad_norm": 0.5035085082054138,
      "learning_rate": 8.800924679766296e-06,
      "loss": 0.3569,
      "step": 7573
    },
    {
      "epoch": 0.1199233655810124,
      "grad_norm": 0.19032754004001617,
      "learning_rate": 8.800766344189877e-06,
      "loss": 0.0015,
      "step": 7574
    },
    {
      "epoch": 0.11993919913865446,
      "grad_norm": 0.007677615620195866,
      "learning_rate": 8.800608008613456e-06,
      "loss": 0.0004,
      "step": 7575
    },
    {
      "epoch": 0.11995503269629654,
      "grad_norm": 0.34822070598602295,
      "learning_rate": 8.800449673037035e-06,
      "loss": 0.089,
      "step": 7576
    },
    {
      "epoch": 0.1199708662539386,
      "grad_norm": 0.00408486882224679,
      "learning_rate": 8.800291337460614e-06,
      "loss": 0.0002,
      "step": 7577
    },
    {
      "epoch": 0.11998669981158067,
      "grad_norm": 0.46505919098854065,
      "learning_rate": 8.800133001884195e-06,
      "loss": 0.5982,
      "step": 7578
    },
    {
      "epoch": 0.12000253336922273,
      "grad_norm": 0.242357537150383,
      "learning_rate": 8.799974666307773e-06,
      "loss": 0.0363,
      "step": 7579
    },
    {
      "epoch": 0.1200183669268648,
      "grad_norm": 0.5174199342727661,
      "learning_rate": 8.799816330731352e-06,
      "loss": 0.0715,
      "step": 7580
    },
    {
      "epoch": 0.12003420048450686,
      "grad_norm": 0.23926368355751038,
      "learning_rate": 8.799657995154932e-06,
      "loss": 0.0723,
      "step": 7581
    },
    {
      "epoch": 0.12005003404214894,
      "grad_norm": 0.020720496773719788,
      "learning_rate": 8.799499659578512e-06,
      "loss": 0.0011,
      "step": 7582
    },
    {
      "epoch": 0.120065867599791,
      "grad_norm": 0.0005840033991262317,
      "learning_rate": 8.79934132400209e-06,
      "loss": 0.0,
      "step": 7583
    },
    {
      "epoch": 0.12008170115743307,
      "grad_norm": 0.45367273688316345,
      "learning_rate": 8.79918298842567e-06,
      "loss": 0.4609,
      "step": 7584
    },
    {
      "epoch": 0.12009753471507513,
      "grad_norm": 1.4027217626571655,
      "learning_rate": 8.799024652849249e-06,
      "loss": 0.3111,
      "step": 7585
    },
    {
      "epoch": 0.1201133682727172,
      "grad_norm": 0.12883292138576508,
      "learning_rate": 8.798866317272828e-06,
      "loss": 0.0391,
      "step": 7586
    },
    {
      "epoch": 0.12012920183035926,
      "grad_norm": 0.011211872100830078,
      "learning_rate": 8.798707981696409e-06,
      "loss": 0.0005,
      "step": 7587
    },
    {
      "epoch": 0.12014503538800134,
      "grad_norm": 0.2264065146446228,
      "learning_rate": 8.798549646119988e-06,
      "loss": 0.044,
      "step": 7588
    },
    {
      "epoch": 0.1201608689456434,
      "grad_norm": 0.029612362384796143,
      "learning_rate": 8.798391310543567e-06,
      "loss": 0.0013,
      "step": 7589
    },
    {
      "epoch": 0.12017670250328547,
      "grad_norm": 0.01347630750387907,
      "learning_rate": 8.798232974967146e-06,
      "loss": 0.0007,
      "step": 7590
    },
    {
      "epoch": 0.12019253606092753,
      "grad_norm": 0.2959389090538025,
      "learning_rate": 8.798074639390725e-06,
      "loss": 0.0413,
      "step": 7591
    },
    {
      "epoch": 0.1202083696185696,
      "grad_norm": 0.12488703429698944,
      "learning_rate": 8.797916303814304e-06,
      "loss": 0.0374,
      "step": 7592
    },
    {
      "epoch": 0.12022420317621166,
      "grad_norm": 0.29067113995552063,
      "learning_rate": 8.797757968237885e-06,
      "loss": 0.1758,
      "step": 7593
    },
    {
      "epoch": 0.12024003673385374,
      "grad_norm": 0.45634734630584717,
      "learning_rate": 8.797599632661464e-06,
      "loss": 0.1136,
      "step": 7594
    },
    {
      "epoch": 0.1202558702914958,
      "grad_norm": 0.3749144673347473,
      "learning_rate": 8.797441297085043e-06,
      "loss": 0.3878,
      "step": 7595
    },
    {
      "epoch": 0.12027170384913786,
      "grad_norm": 0.4715641140937805,
      "learning_rate": 8.797282961508622e-06,
      "loss": 0.1709,
      "step": 7596
    },
    {
      "epoch": 0.12028753740677993,
      "grad_norm": 0.027271326631307602,
      "learning_rate": 8.797124625932201e-06,
      "loss": 0.0013,
      "step": 7597
    },
    {
      "epoch": 0.120303370964422,
      "grad_norm": 0.0012196718016639352,
      "learning_rate": 8.79696629035578e-06,
      "loss": 0.0,
      "step": 7598
    },
    {
      "epoch": 0.12031920452206406,
      "grad_norm": 0.3286363184452057,
      "learning_rate": 8.796807954779361e-06,
      "loss": 0.2522,
      "step": 7599
    },
    {
      "epoch": 0.12033503807970614,
      "grad_norm": 0.3664674460887909,
      "learning_rate": 8.79664961920294e-06,
      "loss": 0.0786,
      "step": 7600
    },
    {
      "epoch": 0.1203508716373482,
      "grad_norm": 0.0783582553267479,
      "learning_rate": 8.79649128362652e-06,
      "loss": 0.0029,
      "step": 7601
    },
    {
      "epoch": 0.12036670519499026,
      "grad_norm": 0.24688081443309784,
      "learning_rate": 8.796332948050098e-06,
      "loss": 0.1115,
      "step": 7602
    },
    {
      "epoch": 0.12038253875263233,
      "grad_norm": 0.0003727759758476168,
      "learning_rate": 8.796174612473677e-06,
      "loss": 0.0,
      "step": 7603
    },
    {
      "epoch": 0.12039837231027439,
      "grad_norm": 0.4818076491355896,
      "learning_rate": 8.796016276897256e-06,
      "loss": 0.0683,
      "step": 7604
    },
    {
      "epoch": 0.12041420586791646,
      "grad_norm": 0.05997566133737564,
      "learning_rate": 8.795857941320835e-06,
      "loss": 0.0091,
      "step": 7605
    },
    {
      "epoch": 0.12043003942555854,
      "grad_norm": 0.4215826094150543,
      "learning_rate": 8.795699605744416e-06,
      "loss": 0.2755,
      "step": 7606
    },
    {
      "epoch": 0.1204458729832006,
      "grad_norm": 0.01739581488072872,
      "learning_rate": 8.795541270167994e-06,
      "loss": 0.0008,
      "step": 7607
    },
    {
      "epoch": 0.12046170654084266,
      "grad_norm": 0.29257825016975403,
      "learning_rate": 8.795382934591574e-06,
      "loss": 0.0648,
      "step": 7608
    },
    {
      "epoch": 0.12047754009848473,
      "grad_norm": 0.44416484236717224,
      "learning_rate": 8.795224599015153e-06,
      "loss": 0.5659,
      "step": 7609
    },
    {
      "epoch": 0.12049337365612679,
      "grad_norm": 0.002364266896620393,
      "learning_rate": 8.795066263438733e-06,
      "loss": 0.0,
      "step": 7610
    },
    {
      "epoch": 0.12050920721376886,
      "grad_norm": 0.41428130865097046,
      "learning_rate": 8.794907927862312e-06,
      "loss": 0.6098,
      "step": 7611
    },
    {
      "epoch": 0.12052504077141094,
      "grad_norm": 0.7984018921852112,
      "learning_rate": 8.794749592285892e-06,
      "loss": 0.6241,
      "step": 7612
    },
    {
      "epoch": 0.120540874329053,
      "grad_norm": 0.0007864781655371189,
      "learning_rate": 8.79459125670947e-06,
      "loss": 0.0,
      "step": 7613
    },
    {
      "epoch": 0.12055670788669506,
      "grad_norm": 0.4752691388130188,
      "learning_rate": 8.79443292113305e-06,
      "loss": 0.168,
      "step": 7614
    },
    {
      "epoch": 0.12057254144433713,
      "grad_norm": 0.2895427644252777,
      "learning_rate": 8.79427458555663e-06,
      "loss": 0.0802,
      "step": 7615
    },
    {
      "epoch": 0.12058837500197919,
      "grad_norm": 0.00210465001873672,
      "learning_rate": 8.794116249980209e-06,
      "loss": 0.0001,
      "step": 7616
    },
    {
      "epoch": 0.12060420855962126,
      "grad_norm": 0.01026465930044651,
      "learning_rate": 8.793957914403788e-06,
      "loss": 0.0004,
      "step": 7617
    },
    {
      "epoch": 0.12062004211726333,
      "grad_norm": 0.012321299873292446,
      "learning_rate": 8.793799578827369e-06,
      "loss": 0.0006,
      "step": 7618
    },
    {
      "epoch": 0.1206358756749054,
      "grad_norm": 0.3843457102775574,
      "learning_rate": 8.793641243250946e-06,
      "loss": 0.3322,
      "step": 7619
    },
    {
      "epoch": 0.12065170923254746,
      "grad_norm": 0.005555605515837669,
      "learning_rate": 8.793482907674527e-06,
      "loss": 0.0003,
      "step": 7620
    },
    {
      "epoch": 0.12066754279018953,
      "grad_norm": 0.28078579902648926,
      "learning_rate": 8.793324572098106e-06,
      "loss": 0.024,
      "step": 7621
    },
    {
      "epoch": 0.12068337634783159,
      "grad_norm": 0.20150288939476013,
      "learning_rate": 8.793166236521685e-06,
      "loss": 0.0875,
      "step": 7622
    },
    {
      "epoch": 0.12069920990547366,
      "grad_norm": 0.3303714692592621,
      "learning_rate": 8.793007900945264e-06,
      "loss": 0.1239,
      "step": 7623
    },
    {
      "epoch": 0.12071504346311573,
      "grad_norm": 0.5011574029922485,
      "learning_rate": 8.792849565368845e-06,
      "loss": 0.0638,
      "step": 7624
    },
    {
      "epoch": 0.1207308770207578,
      "grad_norm": 1.9605274200439453,
      "learning_rate": 8.792691229792422e-06,
      "loss": 0.1949,
      "step": 7625
    },
    {
      "epoch": 0.12074671057839986,
      "grad_norm": 0.24551023542881012,
      "learning_rate": 8.792532894216003e-06,
      "loss": 0.0848,
      "step": 7626
    },
    {
      "epoch": 0.12076254413604193,
      "grad_norm": 0.24823835492134094,
      "learning_rate": 8.792374558639582e-06,
      "loss": 0.0551,
      "step": 7627
    },
    {
      "epoch": 0.12077837769368399,
      "grad_norm": 0.21948319673538208,
      "learning_rate": 8.792216223063161e-06,
      "loss": 0.073,
      "step": 7628
    },
    {
      "epoch": 0.12079421125132606,
      "grad_norm": 0.18618600070476532,
      "learning_rate": 8.79205788748674e-06,
      "loss": 0.1424,
      "step": 7629
    },
    {
      "epoch": 0.12081004480896813,
      "grad_norm": 0.49766895174980164,
      "learning_rate": 8.79189955191032e-06,
      "loss": 0.1886,
      "step": 7630
    },
    {
      "epoch": 0.1208258783666102,
      "grad_norm": 0.00912871491163969,
      "learning_rate": 8.791741216333898e-06,
      "loss": 0.0005,
      "step": 7631
    },
    {
      "epoch": 0.12084171192425226,
      "grad_norm": 1.634267807006836,
      "learning_rate": 8.791582880757477e-06,
      "loss": 0.4508,
      "step": 7632
    },
    {
      "epoch": 0.12085754548189433,
      "grad_norm": 0.05961909517645836,
      "learning_rate": 8.791424545181058e-06,
      "loss": 0.0045,
      "step": 7633
    },
    {
      "epoch": 0.12087337903953639,
      "grad_norm": 0.4760010838508606,
      "learning_rate": 8.791266209604636e-06,
      "loss": 0.6312,
      "step": 7634
    },
    {
      "epoch": 0.12088921259717846,
      "grad_norm": 0.2220045030117035,
      "learning_rate": 8.791107874028216e-06,
      "loss": 0.0944,
      "step": 7635
    },
    {
      "epoch": 0.12090504615482053,
      "grad_norm": 0.2543063759803772,
      "learning_rate": 8.790949538451795e-06,
      "loss": 0.0574,
      "step": 7636
    },
    {
      "epoch": 0.1209208797124626,
      "grad_norm": 0.6145641803741455,
      "learning_rate": 8.790791202875374e-06,
      "loss": 0.0673,
      "step": 7637
    },
    {
      "epoch": 0.12093671327010466,
      "grad_norm": 0.04357535019516945,
      "learning_rate": 8.790632867298954e-06,
      "loss": 0.0056,
      "step": 7638
    },
    {
      "epoch": 0.12095254682774673,
      "grad_norm": 0.8664155602455139,
      "learning_rate": 8.790474531722534e-06,
      "loss": 0.1546,
      "step": 7639
    },
    {
      "epoch": 0.12096838038538879,
      "grad_norm": 0.20355801284313202,
      "learning_rate": 8.790316196146112e-06,
      "loss": 0.0557,
      "step": 7640
    },
    {
      "epoch": 0.12098421394303085,
      "grad_norm": 0.43155938386917114,
      "learning_rate": 8.790157860569693e-06,
      "loss": 0.4858,
      "step": 7641
    },
    {
      "epoch": 0.12100004750067293,
      "grad_norm": 0.3884277045726776,
      "learning_rate": 8.789999524993272e-06,
      "loss": 0.3338,
      "step": 7642
    },
    {
      "epoch": 0.121015881058315,
      "grad_norm": 0.0006494848057627678,
      "learning_rate": 8.78984118941685e-06,
      "loss": 0.0,
      "step": 7643
    },
    {
      "epoch": 0.12103171461595706,
      "grad_norm": 0.39523354172706604,
      "learning_rate": 8.78968285384043e-06,
      "loss": 0.3054,
      "step": 7644
    },
    {
      "epoch": 0.12104754817359913,
      "grad_norm": 0.023034067824482918,
      "learning_rate": 8.78952451826401e-06,
      "loss": 0.0011,
      "step": 7645
    },
    {
      "epoch": 0.12106338173124119,
      "grad_norm": 0.2962439954280853,
      "learning_rate": 8.789366182687588e-06,
      "loss": 0.051,
      "step": 7646
    },
    {
      "epoch": 0.12107921528888325,
      "grad_norm": 0.31904691457748413,
      "learning_rate": 8.789207847111169e-06,
      "loss": 0.1946,
      "step": 7647
    },
    {
      "epoch": 0.12109504884652532,
      "grad_norm": 0.39505431056022644,
      "learning_rate": 8.789049511534748e-06,
      "loss": 0.6033,
      "step": 7648
    },
    {
      "epoch": 0.1211108824041674,
      "grad_norm": 0.1545225828886032,
      "learning_rate": 8.788891175958327e-06,
      "loss": 0.0566,
      "step": 7649
    },
    {
      "epoch": 0.12112671596180946,
      "grad_norm": 0.2741597890853882,
      "learning_rate": 8.788732840381906e-06,
      "loss": 0.3646,
      "step": 7650
    },
    {
      "epoch": 0.12114254951945153,
      "grad_norm": 0.025768952444195747,
      "learning_rate": 8.788574504805487e-06,
      "loss": 0.0019,
      "step": 7651
    },
    {
      "epoch": 0.12115838307709359,
      "grad_norm": 0.46143972873687744,
      "learning_rate": 8.788416169229064e-06,
      "loss": 0.3345,
      "step": 7652
    },
    {
      "epoch": 0.12117421663473565,
      "grad_norm": 0.21134904026985168,
      "learning_rate": 8.788257833652643e-06,
      "loss": 0.0629,
      "step": 7653
    },
    {
      "epoch": 0.12119005019237772,
      "grad_norm": 0.03571392223238945,
      "learning_rate": 8.788099498076224e-06,
      "loss": 0.0021,
      "step": 7654
    },
    {
      "epoch": 0.1212058837500198,
      "grad_norm": 0.501044511795044,
      "learning_rate": 8.787941162499803e-06,
      "loss": 0.1101,
      "step": 7655
    },
    {
      "epoch": 0.12122171730766186,
      "grad_norm": 0.007213628850877285,
      "learning_rate": 8.787782826923382e-06,
      "loss": 0.0004,
      "step": 7656
    },
    {
      "epoch": 0.12123755086530393,
      "grad_norm": 0.14955788850784302,
      "learning_rate": 8.787624491346961e-06,
      "loss": 0.0535,
      "step": 7657
    },
    {
      "epoch": 0.12125338442294599,
      "grad_norm": 0.5759254693984985,
      "learning_rate": 8.78746615577054e-06,
      "loss": 0.1168,
      "step": 7658
    },
    {
      "epoch": 0.12126921798058805,
      "grad_norm": 0.00039328919956460595,
      "learning_rate": 8.78730782019412e-06,
      "loss": 0.0,
      "step": 7659
    },
    {
      "epoch": 0.12128505153823012,
      "grad_norm": 0.288665771484375,
      "learning_rate": 8.7871494846177e-06,
      "loss": 0.0984,
      "step": 7660
    },
    {
      "epoch": 0.1213008850958722,
      "grad_norm": 0.003385473508387804,
      "learning_rate": 8.78699114904128e-06,
      "loss": 0.0001,
      "step": 7661
    },
    {
      "epoch": 0.12131671865351426,
      "grad_norm": 0.3366010785102844,
      "learning_rate": 8.786832813464858e-06,
      "loss": 0.199,
      "step": 7662
    },
    {
      "epoch": 0.12133255221115632,
      "grad_norm": 0.32521888613700867,
      "learning_rate": 8.786674477888437e-06,
      "loss": 0.1154,
      "step": 7663
    },
    {
      "epoch": 0.12134838576879839,
      "grad_norm": 0.03666415438055992,
      "learning_rate": 8.786516142312016e-06,
      "loss": 0.0021,
      "step": 7664
    },
    {
      "epoch": 0.12136421932644045,
      "grad_norm": 0.57979816198349,
      "learning_rate": 8.786357806735595e-06,
      "loss": 0.9055,
      "step": 7665
    },
    {
      "epoch": 0.12138005288408252,
      "grad_norm": 1.9987164735794067,
      "learning_rate": 8.786199471159176e-06,
      "loss": 0.0187,
      "step": 7666
    },
    {
      "epoch": 0.1213958864417246,
      "grad_norm": 0.008590967394411564,
      "learning_rate": 8.786041135582755e-06,
      "loss": 0.0004,
      "step": 7667
    },
    {
      "epoch": 0.12141171999936666,
      "grad_norm": 0.0053702606819570065,
      "learning_rate": 8.785882800006334e-06,
      "loss": 0.0002,
      "step": 7668
    },
    {
      "epoch": 0.12142755355700872,
      "grad_norm": 0.02830488234758377,
      "learning_rate": 8.785724464429914e-06,
      "loss": 0.0013,
      "step": 7669
    },
    {
      "epoch": 0.12144338711465079,
      "grad_norm": 0.9685587286949158,
      "learning_rate": 8.785566128853493e-06,
      "loss": 0.2394,
      "step": 7670
    },
    {
      "epoch": 0.12145922067229285,
      "grad_norm": 0.00028682712581939995,
      "learning_rate": 8.785407793277072e-06,
      "loss": 0.0,
      "step": 7671
    },
    {
      "epoch": 0.12147505422993492,
      "grad_norm": 0.26586687564849854,
      "learning_rate": 8.785249457700652e-06,
      "loss": 0.1395,
      "step": 7672
    },
    {
      "epoch": 0.121490887787577,
      "grad_norm": 0.030815226957201958,
      "learning_rate": 8.785091122124232e-06,
      "loss": 0.0019,
      "step": 7673
    },
    {
      "epoch": 0.12150672134521906,
      "grad_norm": 0.000590964627917856,
      "learning_rate": 8.78493278654781e-06,
      "loss": 0.0,
      "step": 7674
    },
    {
      "epoch": 0.12152255490286112,
      "grad_norm": 0.21185538172721863,
      "learning_rate": 8.78477445097139e-06,
      "loss": 0.0678,
      "step": 7675
    },
    {
      "epoch": 0.12153838846050319,
      "grad_norm": 0.39192038774490356,
      "learning_rate": 8.784616115394969e-06,
      "loss": 0.0826,
      "step": 7676
    },
    {
      "epoch": 0.12155422201814525,
      "grad_norm": 0.1345704346895218,
      "learning_rate": 8.784457779818548e-06,
      "loss": 0.0067,
      "step": 7677
    },
    {
      "epoch": 0.12157005557578732,
      "grad_norm": 0.06204405054450035,
      "learning_rate": 8.784299444242127e-06,
      "loss": 0.0013,
      "step": 7678
    },
    {
      "epoch": 0.1215858891334294,
      "grad_norm": 0.15011143684387207,
      "learning_rate": 8.784141108665708e-06,
      "loss": 0.0345,
      "step": 7679
    },
    {
      "epoch": 0.12160172269107146,
      "grad_norm": 0.022124454379081726,
      "learning_rate": 8.783982773089285e-06,
      "loss": 0.0014,
      "step": 7680
    },
    {
      "epoch": 0.12161755624871352,
      "grad_norm": 0.2575828731060028,
      "learning_rate": 8.783824437512866e-06,
      "loss": 0.1138,
      "step": 7681
    },
    {
      "epoch": 0.12163338980635559,
      "grad_norm": 0.008405923843383789,
      "learning_rate": 8.783666101936445e-06,
      "loss": 0.0003,
      "step": 7682
    },
    {
      "epoch": 0.12164922336399765,
      "grad_norm": 0.6996546387672424,
      "learning_rate": 8.783507766360024e-06,
      "loss": 0.0623,
      "step": 7683
    },
    {
      "epoch": 0.12166505692163972,
      "grad_norm": 0.20279604196548462,
      "learning_rate": 8.783349430783603e-06,
      "loss": 0.0351,
      "step": 7684
    },
    {
      "epoch": 0.1216808904792818,
      "grad_norm": 0.0033151747193187475,
      "learning_rate": 8.783191095207184e-06,
      "loss": 0.0001,
      "step": 7685
    },
    {
      "epoch": 0.12169672403692386,
      "grad_norm": 0.28634893894195557,
      "learning_rate": 8.783032759630761e-06,
      "loss": 0.2435,
      "step": 7686
    },
    {
      "epoch": 0.12171255759456592,
      "grad_norm": 0.28891628980636597,
      "learning_rate": 8.782874424054342e-06,
      "loss": 0.1885,
      "step": 7687
    },
    {
      "epoch": 0.12172839115220799,
      "grad_norm": 0.2009446918964386,
      "learning_rate": 8.782716088477921e-06,
      "loss": 0.1164,
      "step": 7688
    },
    {
      "epoch": 0.12174422470985005,
      "grad_norm": 0.29263216257095337,
      "learning_rate": 8.7825577529015e-06,
      "loss": 0.1261,
      "step": 7689
    },
    {
      "epoch": 0.12176005826749212,
      "grad_norm": 0.33223557472229004,
      "learning_rate": 8.78239941732508e-06,
      "loss": 0.0913,
      "step": 7690
    },
    {
      "epoch": 0.1217758918251342,
      "grad_norm": 0.20363228023052216,
      "learning_rate": 8.78224108174866e-06,
      "loss": 0.0784,
      "step": 7691
    },
    {
      "epoch": 0.12179172538277626,
      "grad_norm": 0.3754378855228424,
      "learning_rate": 8.782082746172237e-06,
      "loss": 0.2547,
      "step": 7692
    },
    {
      "epoch": 0.12180755894041832,
      "grad_norm": 0.32742688059806824,
      "learning_rate": 8.781924410595818e-06,
      "loss": 0.4293,
      "step": 7693
    },
    {
      "epoch": 0.12182339249806039,
      "grad_norm": 0.2019212692975998,
      "learning_rate": 8.781766075019397e-06,
      "loss": 0.0565,
      "step": 7694
    },
    {
      "epoch": 0.12183922605570245,
      "grad_norm": 0.049368053674697876,
      "learning_rate": 8.781607739442976e-06,
      "loss": 0.002,
      "step": 7695
    },
    {
      "epoch": 0.12185505961334452,
      "grad_norm": 0.2682015001773834,
      "learning_rate": 8.781449403866555e-06,
      "loss": 0.0824,
      "step": 7696
    },
    {
      "epoch": 0.1218708931709866,
      "grad_norm": 0.1925767958164215,
      "learning_rate": 8.781291068290135e-06,
      "loss": 0.0989,
      "step": 7697
    },
    {
      "epoch": 0.12188672672862866,
      "grad_norm": 0.0002267280506202951,
      "learning_rate": 8.781132732713714e-06,
      "loss": 0.0,
      "step": 7698
    },
    {
      "epoch": 0.12190256028627072,
      "grad_norm": 0.25345751643180847,
      "learning_rate": 8.780974397137294e-06,
      "loss": 0.2593,
      "step": 7699
    },
    {
      "epoch": 0.12191839384391279,
      "grad_norm": 0.01049859169870615,
      "learning_rate": 8.780816061560873e-06,
      "loss": 0.0004,
      "step": 7700
    },
    {
      "epoch": 0.12193422740155485,
      "grad_norm": 0.8734391331672668,
      "learning_rate": 8.78065772598445e-06,
      "loss": 0.1641,
      "step": 7701
    },
    {
      "epoch": 0.12195006095919692,
      "grad_norm": 0.7143464684486389,
      "learning_rate": 8.780499390408032e-06,
      "loss": 0.1182,
      "step": 7702
    },
    {
      "epoch": 0.121965894516839,
      "grad_norm": 0.31416577100753784,
      "learning_rate": 8.78034105483161e-06,
      "loss": 0.0766,
      "step": 7703
    },
    {
      "epoch": 0.12198172807448106,
      "grad_norm": 0.3106022775173187,
      "learning_rate": 8.78018271925519e-06,
      "loss": 0.1754,
      "step": 7704
    },
    {
      "epoch": 0.12199756163212312,
      "grad_norm": 0.19104787707328796,
      "learning_rate": 8.780024383678769e-06,
      "loss": 0.099,
      "step": 7705
    },
    {
      "epoch": 0.12201339518976519,
      "grad_norm": 0.4189457893371582,
      "learning_rate": 8.77986604810235e-06,
      "loss": 0.5447,
      "step": 7706
    },
    {
      "epoch": 0.12202922874740725,
      "grad_norm": 0.09279186278581619,
      "learning_rate": 8.779707712525927e-06,
      "loss": 0.0133,
      "step": 7707
    },
    {
      "epoch": 0.12204506230504931,
      "grad_norm": 0.08340416103601456,
      "learning_rate": 8.779549376949508e-06,
      "loss": 0.0122,
      "step": 7708
    },
    {
      "epoch": 0.1220608958626914,
      "grad_norm": 0.03075135126709938,
      "learning_rate": 8.779391041373087e-06,
      "loss": 0.0016,
      "step": 7709
    },
    {
      "epoch": 0.12207672942033346,
      "grad_norm": 0.40023496747016907,
      "learning_rate": 8.779232705796666e-06,
      "loss": 0.2275,
      "step": 7710
    },
    {
      "epoch": 0.12209256297797552,
      "grad_norm": 1.9819931983947754,
      "learning_rate": 8.779074370220245e-06,
      "loss": 0.0972,
      "step": 7711
    },
    {
      "epoch": 0.12210839653561759,
      "grad_norm": 0.17304550111293793,
      "learning_rate": 8.778916034643826e-06,
      "loss": 0.0427,
      "step": 7712
    },
    {
      "epoch": 0.12212423009325965,
      "grad_norm": 0.4184456765651703,
      "learning_rate": 8.778757699067403e-06,
      "loss": 0.0604,
      "step": 7713
    },
    {
      "epoch": 0.12214006365090171,
      "grad_norm": 0.19811446964740753,
      "learning_rate": 8.778599363490984e-06,
      "loss": 0.1752,
      "step": 7714
    },
    {
      "epoch": 0.12215589720854379,
      "grad_norm": 0.07287701964378357,
      "learning_rate": 8.778441027914563e-06,
      "loss": 0.0013,
      "step": 7715
    },
    {
      "epoch": 0.12217173076618586,
      "grad_norm": 0.4123254418373108,
      "learning_rate": 8.778282692338142e-06,
      "loss": 0.4098,
      "step": 7716
    },
    {
      "epoch": 0.12218756432382792,
      "grad_norm": 0.01692011207342148,
      "learning_rate": 8.778124356761721e-06,
      "loss": 0.0003,
      "step": 7717
    },
    {
      "epoch": 0.12220339788146999,
      "grad_norm": 0.40107619762420654,
      "learning_rate": 8.777966021185302e-06,
      "loss": 0.1484,
      "step": 7718
    },
    {
      "epoch": 0.12221923143911205,
      "grad_norm": 1.03362238407135,
      "learning_rate": 8.77780768560888e-06,
      "loss": 0.1119,
      "step": 7719
    },
    {
      "epoch": 0.12223506499675411,
      "grad_norm": 0.14675258100032806,
      "learning_rate": 8.77764935003246e-06,
      "loss": 0.0089,
      "step": 7720
    },
    {
      "epoch": 0.12225089855439619,
      "grad_norm": 0.7373061776161194,
      "learning_rate": 8.77749101445604e-06,
      "loss": 0.1436,
      "step": 7721
    },
    {
      "epoch": 0.12226673211203826,
      "grad_norm": 0.24357229471206665,
      "learning_rate": 8.777332678879618e-06,
      "loss": 0.0941,
      "step": 7722
    },
    {
      "epoch": 0.12228256566968032,
      "grad_norm": 0.034684814512729645,
      "learning_rate": 8.777174343303197e-06,
      "loss": 0.0021,
      "step": 7723
    },
    {
      "epoch": 0.12229839922732239,
      "grad_norm": 0.45487120747566223,
      "learning_rate": 8.777016007726776e-06,
      "loss": 0.088,
      "step": 7724
    },
    {
      "epoch": 0.12231423278496445,
      "grad_norm": 0.11410997807979584,
      "learning_rate": 8.776857672150356e-06,
      "loss": 0.0323,
      "step": 7725
    },
    {
      "epoch": 0.12233006634260651,
      "grad_norm": 1.2640841007232666,
      "learning_rate": 8.776699336573935e-06,
      "loss": 0.1189,
      "step": 7726
    },
    {
      "epoch": 0.12234589990024859,
      "grad_norm": 0.24084864556789398,
      "learning_rate": 8.776541000997515e-06,
      "loss": 0.1155,
      "step": 7727
    },
    {
      "epoch": 0.12236173345789066,
      "grad_norm": 0.15676800906658173,
      "learning_rate": 8.776382665421094e-06,
      "loss": 0.0507,
      "step": 7728
    },
    {
      "epoch": 0.12237756701553272,
      "grad_norm": 0.3592097759246826,
      "learning_rate": 8.776224329844674e-06,
      "loss": 0.079,
      "step": 7729
    },
    {
      "epoch": 0.12239340057317478,
      "grad_norm": 0.05483665689826012,
      "learning_rate": 8.776065994268253e-06,
      "loss": 0.0013,
      "step": 7730
    },
    {
      "epoch": 0.12240923413081685,
      "grad_norm": 0.34990355372428894,
      "learning_rate": 8.775907658691832e-06,
      "loss": 0.0825,
      "step": 7731
    },
    {
      "epoch": 0.12242506768845891,
      "grad_norm": 0.4391564130783081,
      "learning_rate": 8.77574932311541e-06,
      "loss": 0.1026,
      "step": 7732
    },
    {
      "epoch": 0.12244090124610099,
      "grad_norm": 0.3971727788448334,
      "learning_rate": 8.775590987538992e-06,
      "loss": 0.1959,
      "step": 7733
    },
    {
      "epoch": 0.12245673480374306,
      "grad_norm": 0.009347775019705296,
      "learning_rate": 8.77543265196257e-06,
      "loss": 0.0003,
      "step": 7734
    },
    {
      "epoch": 0.12247256836138512,
      "grad_norm": 0.6028191447257996,
      "learning_rate": 8.77527431638615e-06,
      "loss": 0.3147,
      "step": 7735
    },
    {
      "epoch": 0.12248840191902718,
      "grad_norm": 0.4308048188686371,
      "learning_rate": 8.775115980809729e-06,
      "loss": 0.2393,
      "step": 7736
    },
    {
      "epoch": 0.12250423547666925,
      "grad_norm": 0.07373487949371338,
      "learning_rate": 8.774957645233308e-06,
      "loss": 0.0059,
      "step": 7737
    },
    {
      "epoch": 0.12252006903431131,
      "grad_norm": 0.4915477931499481,
      "learning_rate": 8.774799309656887e-06,
      "loss": 0.4731,
      "step": 7738
    },
    {
      "epoch": 0.12253590259195339,
      "grad_norm": 0.27202048897743225,
      "learning_rate": 8.774640974080468e-06,
      "loss": 0.2782,
      "step": 7739
    },
    {
      "epoch": 0.12255173614959546,
      "grad_norm": 0.006965150590986013,
      "learning_rate": 8.774482638504047e-06,
      "loss": 0.0003,
      "step": 7740
    },
    {
      "epoch": 0.12256756970723752,
      "grad_norm": 0.015157287940382957,
      "learning_rate": 8.774324302927626e-06,
      "loss": 0.0008,
      "step": 7741
    },
    {
      "epoch": 0.12258340326487958,
      "grad_norm": 0.28357329964637756,
      "learning_rate": 8.774165967351205e-06,
      "loss": 0.1347,
      "step": 7742
    },
    {
      "epoch": 0.12259923682252165,
      "grad_norm": 0.30276554822921753,
      "learning_rate": 8.774007631774784e-06,
      "loss": 0.1184,
      "step": 7743
    },
    {
      "epoch": 0.12261507038016371,
      "grad_norm": 0.1824258714914322,
      "learning_rate": 8.773849296198363e-06,
      "loss": 0.0559,
      "step": 7744
    },
    {
      "epoch": 0.12263090393780579,
      "grad_norm": 0.16384200751781464,
      "learning_rate": 8.773690960621944e-06,
      "loss": 0.0101,
      "step": 7745
    },
    {
      "epoch": 0.12264673749544786,
      "grad_norm": 0.26340359449386597,
      "learning_rate": 8.773532625045523e-06,
      "loss": 0.1193,
      "step": 7746
    },
    {
      "epoch": 0.12266257105308992,
      "grad_norm": 0.0023068911395967007,
      "learning_rate": 8.773374289469102e-06,
      "loss": 0.0001,
      "step": 7747
    },
    {
      "epoch": 0.12267840461073198,
      "grad_norm": 0.0002695721632335335,
      "learning_rate": 8.773215953892681e-06,
      "loss": 0.0,
      "step": 7748
    },
    {
      "epoch": 0.12269423816837405,
      "grad_norm": 0.481433629989624,
      "learning_rate": 8.77305761831626e-06,
      "loss": 0.2045,
      "step": 7749
    },
    {
      "epoch": 0.12271007172601611,
      "grad_norm": 0.3677472472190857,
      "learning_rate": 8.77289928273984e-06,
      "loss": 0.154,
      "step": 7750
    },
    {
      "epoch": 0.12272590528365819,
      "grad_norm": 0.2317831963300705,
      "learning_rate": 8.772740947163418e-06,
      "loss": 0.0565,
      "step": 7751
    },
    {
      "epoch": 0.12274173884130025,
      "grad_norm": 0.009089844301342964,
      "learning_rate": 8.772582611586999e-06,
      "loss": 0.0005,
      "step": 7752
    },
    {
      "epoch": 0.12275757239894232,
      "grad_norm": 0.42780622839927673,
      "learning_rate": 8.772424276010577e-06,
      "loss": 0.1873,
      "step": 7753
    },
    {
      "epoch": 0.12277340595658438,
      "grad_norm": 0.2908993661403656,
      "learning_rate": 8.772265940434157e-06,
      "loss": 0.0654,
      "step": 7754
    },
    {
      "epoch": 0.12278923951422645,
      "grad_norm": 0.33486831188201904,
      "learning_rate": 8.772107604857736e-06,
      "loss": 0.1282,
      "step": 7755
    },
    {
      "epoch": 0.12280507307186851,
      "grad_norm": 0.5502244830131531,
      "learning_rate": 8.771949269281315e-06,
      "loss": 0.1524,
      "step": 7756
    },
    {
      "epoch": 0.12282090662951059,
      "grad_norm": 0.02884369157254696,
      "learning_rate": 8.771790933704895e-06,
      "loss": 0.0007,
      "step": 7757
    },
    {
      "epoch": 0.12283674018715265,
      "grad_norm": 0.5167048573493958,
      "learning_rate": 8.771632598128474e-06,
      "loss": 0.1617,
      "step": 7758
    },
    {
      "epoch": 0.12285257374479472,
      "grad_norm": 0.23188044130802155,
      "learning_rate": 8.771474262552053e-06,
      "loss": 0.0306,
      "step": 7759
    },
    {
      "epoch": 0.12286840730243678,
      "grad_norm": 0.2298249900341034,
      "learning_rate": 8.771315926975633e-06,
      "loss": 0.246,
      "step": 7760
    },
    {
      "epoch": 0.12288424086007885,
      "grad_norm": 0.15855583548545837,
      "learning_rate": 8.771157591399213e-06,
      "loss": 0.1008,
      "step": 7761
    },
    {
      "epoch": 0.12290007441772091,
      "grad_norm": 0.0007301539299078286,
      "learning_rate": 8.770999255822792e-06,
      "loss": 0.0,
      "step": 7762
    },
    {
      "epoch": 0.12291590797536299,
      "grad_norm": 0.40491512417793274,
      "learning_rate": 8.77084092024637e-06,
      "loss": 0.1967,
      "step": 7763
    },
    {
      "epoch": 0.12293174153300505,
      "grad_norm": 0.25495287775993347,
      "learning_rate": 8.77068258466995e-06,
      "loss": 0.0581,
      "step": 7764
    },
    {
      "epoch": 0.12294757509064712,
      "grad_norm": 0.002908103633671999,
      "learning_rate": 8.770524249093529e-06,
      "loss": 0.0001,
      "step": 7765
    },
    {
      "epoch": 0.12296340864828918,
      "grad_norm": 0.33694061636924744,
      "learning_rate": 8.77036591351711e-06,
      "loss": 0.0995,
      "step": 7766
    },
    {
      "epoch": 0.12297924220593125,
      "grad_norm": 0.27038007974624634,
      "learning_rate": 8.770207577940689e-06,
      "loss": 0.1714,
      "step": 7767
    },
    {
      "epoch": 0.12299507576357331,
      "grad_norm": 0.039291657507419586,
      "learning_rate": 8.770049242364268e-06,
      "loss": 0.0021,
      "step": 7768
    },
    {
      "epoch": 0.12301090932121539,
      "grad_norm": 0.40128272771835327,
      "learning_rate": 8.769890906787847e-06,
      "loss": 0.3326,
      "step": 7769
    },
    {
      "epoch": 0.12302674287885745,
      "grad_norm": 0.3459365665912628,
      "learning_rate": 8.769732571211426e-06,
      "loss": 0.2799,
      "step": 7770
    },
    {
      "epoch": 0.12304257643649952,
      "grad_norm": 0.7240477204322815,
      "learning_rate": 8.769574235635005e-06,
      "loss": 0.2228,
      "step": 7771
    },
    {
      "epoch": 0.12305840999414158,
      "grad_norm": 0.33022233843803406,
      "learning_rate": 8.769415900058584e-06,
      "loss": 0.1123,
      "step": 7772
    },
    {
      "epoch": 0.12307424355178365,
      "grad_norm": 0.5887868404388428,
      "learning_rate": 8.769257564482165e-06,
      "loss": 0.0894,
      "step": 7773
    },
    {
      "epoch": 0.12309007710942571,
      "grad_norm": 0.2890167236328125,
      "learning_rate": 8.769099228905742e-06,
      "loss": 0.1995,
      "step": 7774
    },
    {
      "epoch": 0.12310591066706779,
      "grad_norm": 0.3193072974681854,
      "learning_rate": 8.768940893329323e-06,
      "loss": 0.056,
      "step": 7775
    },
    {
      "epoch": 0.12312174422470985,
      "grad_norm": 0.00029303328483365476,
      "learning_rate": 8.768782557752902e-06,
      "loss": 0.0,
      "step": 7776
    },
    {
      "epoch": 0.12313757778235192,
      "grad_norm": 0.26963281631469727,
      "learning_rate": 8.768624222176481e-06,
      "loss": 0.1365,
      "step": 7777
    },
    {
      "epoch": 0.12315341133999398,
      "grad_norm": 0.4166487455368042,
      "learning_rate": 8.76846588660006e-06,
      "loss": 0.081,
      "step": 7778
    },
    {
      "epoch": 0.12316924489763605,
      "grad_norm": 0.3573283553123474,
      "learning_rate": 8.768307551023641e-06,
      "loss": 0.2337,
      "step": 7779
    },
    {
      "epoch": 0.12318507845527811,
      "grad_norm": 0.24203571677207947,
      "learning_rate": 8.768149215447218e-06,
      "loss": 0.2075,
      "step": 7780
    },
    {
      "epoch": 0.12320091201292019,
      "grad_norm": 0.5299738645553589,
      "learning_rate": 8.7679908798708e-06,
      "loss": 0.1588,
      "step": 7781
    },
    {
      "epoch": 0.12321674557056225,
      "grad_norm": 0.3324469327926636,
      "learning_rate": 8.767832544294378e-06,
      "loss": 0.0813,
      "step": 7782
    },
    {
      "epoch": 0.12323257912820432,
      "grad_norm": 0.09580939263105392,
      "learning_rate": 8.767674208717957e-06,
      "loss": 0.0106,
      "step": 7783
    },
    {
      "epoch": 0.12324841268584638,
      "grad_norm": 0.004284095950424671,
      "learning_rate": 8.767515873141536e-06,
      "loss": 0.0001,
      "step": 7784
    },
    {
      "epoch": 0.12326424624348845,
      "grad_norm": 0.21660460531711578,
      "learning_rate": 8.767357537565117e-06,
      "loss": 0.131,
      "step": 7785
    },
    {
      "epoch": 0.12328007980113051,
      "grad_norm": 0.0037901452742516994,
      "learning_rate": 8.767199201988695e-06,
      "loss": 0.0002,
      "step": 7786
    },
    {
      "epoch": 0.12329591335877259,
      "grad_norm": 0.2673686444759369,
      "learning_rate": 8.767040866412275e-06,
      "loss": 0.0786,
      "step": 7787
    },
    {
      "epoch": 0.12331174691641465,
      "grad_norm": 0.15959098935127258,
      "learning_rate": 8.766882530835854e-06,
      "loss": 0.0857,
      "step": 7788
    },
    {
      "epoch": 0.12332758047405672,
      "grad_norm": 0.17882730066776276,
      "learning_rate": 8.766724195259434e-06,
      "loss": 0.0387,
      "step": 7789
    },
    {
      "epoch": 0.12334341403169878,
      "grad_norm": 0.47374314069747925,
      "learning_rate": 8.766565859683013e-06,
      "loss": 0.1831,
      "step": 7790
    },
    {
      "epoch": 0.12335924758934085,
      "grad_norm": 0.38968315720558167,
      "learning_rate": 8.766407524106593e-06,
      "loss": 0.224,
      "step": 7791
    },
    {
      "epoch": 0.12337508114698291,
      "grad_norm": 0.4285637438297272,
      "learning_rate": 8.76624918853017e-06,
      "loss": 0.1463,
      "step": 7792
    },
    {
      "epoch": 0.12339091470462499,
      "grad_norm": 0.2585511803627014,
      "learning_rate": 8.766090852953752e-06,
      "loss": 0.0758,
      "step": 7793
    },
    {
      "epoch": 0.12340674826226705,
      "grad_norm": 0.5366451740264893,
      "learning_rate": 8.76593251737733e-06,
      "loss": 0.3712,
      "step": 7794
    },
    {
      "epoch": 0.12342258181990912,
      "grad_norm": 0.23754307627677917,
      "learning_rate": 8.76577418180091e-06,
      "loss": 0.0666,
      "step": 7795
    },
    {
      "epoch": 0.12343841537755118,
      "grad_norm": 0.5691354274749756,
      "learning_rate": 8.765615846224489e-06,
      "loss": 0.6373,
      "step": 7796
    },
    {
      "epoch": 0.12345424893519324,
      "grad_norm": 0.30189236998558044,
      "learning_rate": 8.765457510648068e-06,
      "loss": 0.1593,
      "step": 7797
    },
    {
      "epoch": 0.12347008249283531,
      "grad_norm": 0.46431031823158264,
      "learning_rate": 8.765299175071647e-06,
      "loss": 0.1704,
      "step": 7798
    },
    {
      "epoch": 0.12348591605047739,
      "grad_norm": 0.7936842441558838,
      "learning_rate": 8.765140839495226e-06,
      "loss": 0.1224,
      "step": 7799
    },
    {
      "epoch": 0.12350174960811945,
      "grad_norm": 0.3757667541503906,
      "learning_rate": 8.764982503918807e-06,
      "loss": 0.1273,
      "step": 7800
    },
    {
      "epoch": 0.12351758316576152,
      "grad_norm": 0.5168113708496094,
      "learning_rate": 8.764824168342386e-06,
      "loss": 0.2652,
      "step": 7801
    },
    {
      "epoch": 0.12353341672340358,
      "grad_norm": 0.5021792054176331,
      "learning_rate": 8.764665832765965e-06,
      "loss": 0.162,
      "step": 7802
    },
    {
      "epoch": 0.12354925028104564,
      "grad_norm": 0.46181055903434753,
      "learning_rate": 8.764507497189544e-06,
      "loss": 0.8728,
      "step": 7803
    },
    {
      "epoch": 0.12356508383868771,
      "grad_norm": 0.29999634623527527,
      "learning_rate": 8.764349161613123e-06,
      "loss": 0.1143,
      "step": 7804
    },
    {
      "epoch": 0.12358091739632979,
      "grad_norm": 0.34913092851638794,
      "learning_rate": 8.764190826036702e-06,
      "loss": 0.1522,
      "step": 7805
    },
    {
      "epoch": 0.12359675095397185,
      "grad_norm": 0.001464903587475419,
      "learning_rate": 8.764032490460283e-06,
      "loss": 0.0001,
      "step": 7806
    },
    {
      "epoch": 0.12361258451161392,
      "grad_norm": 0.5201112627983093,
      "learning_rate": 8.763874154883862e-06,
      "loss": 0.2845,
      "step": 7807
    },
    {
      "epoch": 0.12362841806925598,
      "grad_norm": 0.014497033320367336,
      "learning_rate": 8.763715819307441e-06,
      "loss": 0.0008,
      "step": 7808
    },
    {
      "epoch": 0.12364425162689804,
      "grad_norm": 0.22721776366233826,
      "learning_rate": 8.76355748373102e-06,
      "loss": 0.2166,
      "step": 7809
    },
    {
      "epoch": 0.12366008518454011,
      "grad_norm": 0.022561348974704742,
      "learning_rate": 8.7633991481546e-06,
      "loss": 0.0013,
      "step": 7810
    },
    {
      "epoch": 0.12367591874218219,
      "grad_norm": 0.004138201009482145,
      "learning_rate": 8.763240812578178e-06,
      "loss": 0.0002,
      "step": 7811
    },
    {
      "epoch": 0.12369175229982425,
      "grad_norm": 0.22376586496829987,
      "learning_rate": 8.763082477001759e-06,
      "loss": 0.1498,
      "step": 7812
    },
    {
      "epoch": 0.12370758585746632,
      "grad_norm": 0.4217142164707184,
      "learning_rate": 8.762924141425338e-06,
      "loss": 0.1371,
      "step": 7813
    },
    {
      "epoch": 0.12372341941510838,
      "grad_norm": 0.36760643124580383,
      "learning_rate": 8.762765805848917e-06,
      "loss": 0.3309,
      "step": 7814
    },
    {
      "epoch": 0.12373925297275044,
      "grad_norm": 0.47440406680107117,
      "learning_rate": 8.762607470272496e-06,
      "loss": 0.1066,
      "step": 7815
    },
    {
      "epoch": 0.12375508653039251,
      "grad_norm": 0.4712429642677307,
      "learning_rate": 8.762449134696075e-06,
      "loss": 0.2951,
      "step": 7816
    },
    {
      "epoch": 0.12377092008803459,
      "grad_norm": 0.11660047620534897,
      "learning_rate": 8.762290799119655e-06,
      "loss": 0.012,
      "step": 7817
    },
    {
      "epoch": 0.12378675364567665,
      "grad_norm": 0.015774093568325043,
      "learning_rate": 8.762132463543235e-06,
      "loss": 0.0005,
      "step": 7818
    },
    {
      "epoch": 0.12380258720331871,
      "grad_norm": 0.3763853907585144,
      "learning_rate": 8.761974127966814e-06,
      "loss": 0.0307,
      "step": 7819
    },
    {
      "epoch": 0.12381842076096078,
      "grad_norm": 0.22350305318832397,
      "learning_rate": 8.761815792390392e-06,
      "loss": 0.0639,
      "step": 7820
    },
    {
      "epoch": 0.12383425431860284,
      "grad_norm": 0.6677566170692444,
      "learning_rate": 8.761657456813973e-06,
      "loss": 1.0208,
      "step": 7821
    },
    {
      "epoch": 0.12385008787624491,
      "grad_norm": 0.4335014522075653,
      "learning_rate": 8.761499121237552e-06,
      "loss": 0.0757,
      "step": 7822
    },
    {
      "epoch": 0.12386592143388699,
      "grad_norm": 0.15787652134895325,
      "learning_rate": 8.76134078566113e-06,
      "loss": 0.0036,
      "step": 7823
    },
    {
      "epoch": 0.12388175499152905,
      "grad_norm": 3.7797627449035645,
      "learning_rate": 8.76118245008471e-06,
      "loss": 1.2986,
      "step": 7824
    },
    {
      "epoch": 0.12389758854917111,
      "grad_norm": 0.021433798596262932,
      "learning_rate": 8.761024114508289e-06,
      "loss": 0.0011,
      "step": 7825
    },
    {
      "epoch": 0.12391342210681318,
      "grad_norm": 0.0255600456148386,
      "learning_rate": 8.760865778931868e-06,
      "loss": 0.0015,
      "step": 7826
    },
    {
      "epoch": 0.12392925566445524,
      "grad_norm": 0.13123451173305511,
      "learning_rate": 8.760707443355449e-06,
      "loss": 0.054,
      "step": 7827
    },
    {
      "epoch": 0.12394508922209731,
      "grad_norm": 0.016389718279242516,
      "learning_rate": 8.760549107779028e-06,
      "loss": 0.0008,
      "step": 7828
    },
    {
      "epoch": 0.12396092277973939,
      "grad_norm": 0.013379978947341442,
      "learning_rate": 8.760390772202607e-06,
      "loss": 0.0007,
      "step": 7829
    },
    {
      "epoch": 0.12397675633738145,
      "grad_norm": 0.2978709042072296,
      "learning_rate": 8.760232436626186e-06,
      "loss": 0.1274,
      "step": 7830
    },
    {
      "epoch": 0.12399258989502351,
      "grad_norm": 0.0007090867147780955,
      "learning_rate": 8.760074101049765e-06,
      "loss": 0.0,
      "step": 7831
    },
    {
      "epoch": 0.12400842345266558,
      "grad_norm": 0.0002163834433304146,
      "learning_rate": 8.759915765473344e-06,
      "loss": 0.0,
      "step": 7832
    },
    {
      "epoch": 0.12402425701030764,
      "grad_norm": 0.004055938217788935,
      "learning_rate": 8.759757429896925e-06,
      "loss": 0.0001,
      "step": 7833
    },
    {
      "epoch": 0.1240400905679497,
      "grad_norm": 0.03168219327926636,
      "learning_rate": 8.759599094320504e-06,
      "loss": 0.002,
      "step": 7834
    },
    {
      "epoch": 0.12405592412559178,
      "grad_norm": 0.4778050482273102,
      "learning_rate": 8.759440758744083e-06,
      "loss": 0.3963,
      "step": 7835
    },
    {
      "epoch": 0.12407175768323385,
      "grad_norm": 0.5866037011146545,
      "learning_rate": 8.759282423167662e-06,
      "loss": 0.0931,
      "step": 7836
    },
    {
      "epoch": 0.12408759124087591,
      "grad_norm": 0.4054797887802124,
      "learning_rate": 8.759124087591241e-06,
      "loss": 0.3648,
      "step": 7837
    },
    {
      "epoch": 0.12410342479851798,
      "grad_norm": 0.21230973303318024,
      "learning_rate": 8.75896575201482e-06,
      "loss": 0.1243,
      "step": 7838
    },
    {
      "epoch": 0.12411925835616004,
      "grad_norm": 0.18609718978405,
      "learning_rate": 8.758807416438401e-06,
      "loss": 0.0862,
      "step": 7839
    },
    {
      "epoch": 0.1241350919138021,
      "grad_norm": 0.35280755162239075,
      "learning_rate": 8.75864908086198e-06,
      "loss": 0.1062,
      "step": 7840
    },
    {
      "epoch": 0.12415092547144418,
      "grad_norm": 0.001119876280426979,
      "learning_rate": 8.75849074528556e-06,
      "loss": 0.0,
      "step": 7841
    },
    {
      "epoch": 0.12416675902908625,
      "grad_norm": 0.13926242291927338,
      "learning_rate": 8.758332409709138e-06,
      "loss": 0.0333,
      "step": 7842
    },
    {
      "epoch": 0.12418259258672831,
      "grad_norm": 0.7067343592643738,
      "learning_rate": 8.758174074132717e-06,
      "loss": 0.1409,
      "step": 7843
    },
    {
      "epoch": 0.12419842614437038,
      "grad_norm": 0.3177104592323303,
      "learning_rate": 8.758015738556296e-06,
      "loss": 0.0653,
      "step": 7844
    },
    {
      "epoch": 0.12421425970201244,
      "grad_norm": 0.5070948004722595,
      "learning_rate": 8.757857402979876e-06,
      "loss": 0.8492,
      "step": 7845
    },
    {
      "epoch": 0.1242300932596545,
      "grad_norm": 0.21041271090507507,
      "learning_rate": 8.757699067403456e-06,
      "loss": 0.1369,
      "step": 7846
    },
    {
      "epoch": 0.12424592681729658,
      "grad_norm": 0.023025993257761,
      "learning_rate": 8.757540731827034e-06,
      "loss": 0.0013,
      "step": 7847
    },
    {
      "epoch": 0.12426176037493865,
      "grad_norm": 0.16804897785186768,
      "learning_rate": 8.757382396250614e-06,
      "loss": 0.0617,
      "step": 7848
    },
    {
      "epoch": 0.12427759393258071,
      "grad_norm": 0.17113973200321198,
      "learning_rate": 8.757224060674194e-06,
      "loss": 0.0858,
      "step": 7849
    },
    {
      "epoch": 0.12429342749022278,
      "grad_norm": 0.33171364665031433,
      "learning_rate": 8.757065725097773e-06,
      "loss": 0.1565,
      "step": 7850
    },
    {
      "epoch": 0.12430926104786484,
      "grad_norm": 0.23357844352722168,
      "learning_rate": 8.756907389521352e-06,
      "loss": 0.0966,
      "step": 7851
    },
    {
      "epoch": 0.1243250946055069,
      "grad_norm": 0.5808621644973755,
      "learning_rate": 8.756749053944932e-06,
      "loss": 0.7656,
      "step": 7852
    },
    {
      "epoch": 0.12434092816314898,
      "grad_norm": 0.28179317712783813,
      "learning_rate": 8.75659071836851e-06,
      "loss": 0.1581,
      "step": 7853
    },
    {
      "epoch": 0.12435676172079105,
      "grad_norm": 0.47802165150642395,
      "learning_rate": 8.75643238279209e-06,
      "loss": 0.3219,
      "step": 7854
    },
    {
      "epoch": 0.12437259527843311,
      "grad_norm": 0.6865314841270447,
      "learning_rate": 8.75627404721567e-06,
      "loss": 0.1051,
      "step": 7855
    },
    {
      "epoch": 0.12438842883607518,
      "grad_norm": 0.2955970764160156,
      "learning_rate": 8.756115711639249e-06,
      "loss": 0.1837,
      "step": 7856
    },
    {
      "epoch": 0.12440426239371724,
      "grad_norm": 0.17169499397277832,
      "learning_rate": 8.755957376062828e-06,
      "loss": 0.0584,
      "step": 7857
    },
    {
      "epoch": 0.1244200959513593,
      "grad_norm": 0.01839565485715866,
      "learning_rate": 8.755799040486409e-06,
      "loss": 0.0011,
      "step": 7858
    },
    {
      "epoch": 0.12443592950900138,
      "grad_norm": 0.012007810175418854,
      "learning_rate": 8.755640704909986e-06,
      "loss": 0.0002,
      "step": 7859
    },
    {
      "epoch": 0.12445176306664345,
      "grad_norm": 0.4057391285896301,
      "learning_rate": 8.755482369333567e-06,
      "loss": 0.6067,
      "step": 7860
    },
    {
      "epoch": 0.12446759662428551,
      "grad_norm": 0.20783746242523193,
      "learning_rate": 8.755324033757146e-06,
      "loss": 0.0105,
      "step": 7861
    },
    {
      "epoch": 0.12448343018192758,
      "grad_norm": 0.47036877274513245,
      "learning_rate": 8.755165698180725e-06,
      "loss": 0.1923,
      "step": 7862
    },
    {
      "epoch": 0.12449926373956964,
      "grad_norm": 0.43993470072746277,
      "learning_rate": 8.755007362604304e-06,
      "loss": 0.2,
      "step": 7863
    },
    {
      "epoch": 0.1245150972972117,
      "grad_norm": 0.5716586112976074,
      "learning_rate": 8.754849027027885e-06,
      "loss": 0.0108,
      "step": 7864
    },
    {
      "epoch": 0.12453093085485378,
      "grad_norm": 0.2552909851074219,
      "learning_rate": 8.754690691451462e-06,
      "loss": 0.0412,
      "step": 7865
    },
    {
      "epoch": 0.12454676441249585,
      "grad_norm": 0.28397026658058167,
      "learning_rate": 8.754532355875043e-06,
      "loss": 0.1007,
      "step": 7866
    },
    {
      "epoch": 0.12456259797013791,
      "grad_norm": 0.024573246017098427,
      "learning_rate": 8.754374020298622e-06,
      "loss": 0.0012,
      "step": 7867
    },
    {
      "epoch": 0.12457843152777998,
      "grad_norm": 0.2336779683828354,
      "learning_rate": 8.754215684722201e-06,
      "loss": 0.1257,
      "step": 7868
    },
    {
      "epoch": 0.12459426508542204,
      "grad_norm": 0.00039360442315228283,
      "learning_rate": 8.75405734914578e-06,
      "loss": 0.0,
      "step": 7869
    },
    {
      "epoch": 0.1246100986430641,
      "grad_norm": 0.1375560313463211,
      "learning_rate": 8.75389901356936e-06,
      "loss": 0.0389,
      "step": 7870
    },
    {
      "epoch": 0.12462593220070618,
      "grad_norm": 0.0003684025432448834,
      "learning_rate": 8.753740677992938e-06,
      "loss": 0.0,
      "step": 7871
    },
    {
      "epoch": 0.12464176575834825,
      "grad_norm": 0.1775071769952774,
      "learning_rate": 8.753582342416517e-06,
      "loss": 0.0659,
      "step": 7872
    },
    {
      "epoch": 0.12465759931599031,
      "grad_norm": 0.5617572665214539,
      "learning_rate": 8.753424006840098e-06,
      "loss": 0.1859,
      "step": 7873
    },
    {
      "epoch": 0.12467343287363238,
      "grad_norm": 0.31663015484809875,
      "learning_rate": 8.753265671263677e-06,
      "loss": 0.2542,
      "step": 7874
    },
    {
      "epoch": 0.12468926643127444,
      "grad_norm": 0.013519392348825932,
      "learning_rate": 8.753107335687256e-06,
      "loss": 0.0006,
      "step": 7875
    },
    {
      "epoch": 0.1247050999889165,
      "grad_norm": 0.412239134311676,
      "learning_rate": 8.752949000110835e-06,
      "loss": 0.2266,
      "step": 7876
    },
    {
      "epoch": 0.12472093354655858,
      "grad_norm": 0.31756213307380676,
      "learning_rate": 8.752790664534415e-06,
      "loss": 0.0883,
      "step": 7877
    },
    {
      "epoch": 0.12473676710420065,
      "grad_norm": 0.003395538544282317,
      "learning_rate": 8.752632328957994e-06,
      "loss": 0.0001,
      "step": 7878
    },
    {
      "epoch": 0.12475260066184271,
      "grad_norm": 0.21620497107505798,
      "learning_rate": 8.752473993381574e-06,
      "loss": 0.0819,
      "step": 7879
    },
    {
      "epoch": 0.12476843421948478,
      "grad_norm": 0.3367249369621277,
      "learning_rate": 8.752315657805154e-06,
      "loss": 0.0607,
      "step": 7880
    },
    {
      "epoch": 0.12478426777712684,
      "grad_norm": 0.6073775291442871,
      "learning_rate": 8.752157322228733e-06,
      "loss": 0.858,
      "step": 7881
    },
    {
      "epoch": 0.1248001013347689,
      "grad_norm": 0.23008565604686737,
      "learning_rate": 8.751998986652312e-06,
      "loss": 0.0382,
      "step": 7882
    },
    {
      "epoch": 0.12481593489241098,
      "grad_norm": 0.31353288888931274,
      "learning_rate": 8.75184065107589e-06,
      "loss": 0.6119,
      "step": 7883
    },
    {
      "epoch": 0.12483176845005305,
      "grad_norm": 0.49698421359062195,
      "learning_rate": 8.75168231549947e-06,
      "loss": 0.0255,
      "step": 7884
    },
    {
      "epoch": 0.12484760200769511,
      "grad_norm": 0.37328580021858215,
      "learning_rate": 8.75152397992305e-06,
      "loss": 0.323,
      "step": 7885
    },
    {
      "epoch": 0.12486343556533717,
      "grad_norm": 0.3873628079891205,
      "learning_rate": 8.75136564434663e-06,
      "loss": 0.0822,
      "step": 7886
    },
    {
      "epoch": 0.12487926912297924,
      "grad_norm": 0.0021974160335958004,
      "learning_rate": 8.751207308770209e-06,
      "loss": 0.0,
      "step": 7887
    },
    {
      "epoch": 0.1248951026806213,
      "grad_norm": 0.013011950999498367,
      "learning_rate": 8.751048973193788e-06,
      "loss": 0.0005,
      "step": 7888
    },
    {
      "epoch": 0.12491093623826338,
      "grad_norm": 0.40870264172554016,
      "learning_rate": 8.750890637617367e-06,
      "loss": 0.1259,
      "step": 7889
    },
    {
      "epoch": 0.12492676979590545,
      "grad_norm": 0.6304326057434082,
      "learning_rate": 8.750732302040946e-06,
      "loss": 0.2368,
      "step": 7890
    },
    {
      "epoch": 0.12494260335354751,
      "grad_norm": 0.00015116168651729822,
      "learning_rate": 8.750573966464527e-06,
      "loss": 0.0,
      "step": 7891
    },
    {
      "epoch": 0.12495843691118957,
      "grad_norm": 0.5836857557296753,
      "learning_rate": 8.750415630888104e-06,
      "loss": 0.0489,
      "step": 7892
    },
    {
      "epoch": 0.12497427046883164,
      "grad_norm": 0.0323668047785759,
      "learning_rate": 8.750257295311683e-06,
      "loss": 0.0016,
      "step": 7893
    },
    {
      "epoch": 0.1249901040264737,
      "grad_norm": 0.004952958784997463,
      "learning_rate": 8.750098959735264e-06,
      "loss": 0.0001,
      "step": 7894
    },
    {
      "epoch": 0.12500593758411577,
      "grad_norm": 0.2643182873725891,
      "learning_rate": 8.749940624158843e-06,
      "loss": 0.1103,
      "step": 7895
    },
    {
      "epoch": 0.12502177114175783,
      "grad_norm": 0.15359637141227722,
      "learning_rate": 8.749782288582422e-06,
      "loss": 0.0405,
      "step": 7896
    },
    {
      "epoch": 0.1250376046993999,
      "grad_norm": 0.3282984495162964,
      "learning_rate": 8.749623953006001e-06,
      "loss": 0.1978,
      "step": 7897
    },
    {
      "epoch": 0.125053438257042,
      "grad_norm": 0.4381406009197235,
      "learning_rate": 8.74946561742958e-06,
      "loss": 0.146,
      "step": 7898
    },
    {
      "epoch": 0.12506927181468405,
      "grad_norm": 0.5359471440315247,
      "learning_rate": 8.74930728185316e-06,
      "loss": 0.1718,
      "step": 7899
    },
    {
      "epoch": 0.12508510537232612,
      "grad_norm": 0.1749984472990036,
      "learning_rate": 8.74914894627674e-06,
      "loss": 0.0541,
      "step": 7900
    },
    {
      "epoch": 0.12510093892996818,
      "grad_norm": 0.006235682871192694,
      "learning_rate": 8.74899061070032e-06,
      "loss": 0.0002,
      "step": 7901
    },
    {
      "epoch": 0.12511677248761024,
      "grad_norm": 0.0005304870428517461,
      "learning_rate": 8.748832275123898e-06,
      "loss": 0.0,
      "step": 7902
    },
    {
      "epoch": 0.1251326060452523,
      "grad_norm": 0.22244316339492798,
      "learning_rate": 8.748673939547477e-06,
      "loss": 0.0519,
      "step": 7903
    },
    {
      "epoch": 0.12514843960289437,
      "grad_norm": 0.3845677971839905,
      "learning_rate": 8.748515603971056e-06,
      "loss": 0.1001,
      "step": 7904
    },
    {
      "epoch": 0.12516427316053644,
      "grad_norm": 0.36368295550346375,
      "learning_rate": 8.748357268394636e-06,
      "loss": 0.1454,
      "step": 7905
    },
    {
      "epoch": 0.1251801067181785,
      "grad_norm": 0.5322925448417664,
      "learning_rate": 8.748198932818216e-06,
      "loss": 0.1858,
      "step": 7906
    },
    {
      "epoch": 0.12519594027582057,
      "grad_norm": 0.5473551750183105,
      "learning_rate": 8.748040597241795e-06,
      "loss": 0.4456,
      "step": 7907
    },
    {
      "epoch": 0.12521177383346263,
      "grad_norm": 0.24215024709701538,
      "learning_rate": 8.747882261665375e-06,
      "loss": 0.0779,
      "step": 7908
    },
    {
      "epoch": 0.1252276073911047,
      "grad_norm": 0.6576984524726868,
      "learning_rate": 8.747723926088954e-06,
      "loss": 0.0754,
      "step": 7909
    },
    {
      "epoch": 0.1252434409487468,
      "grad_norm": 1.2719827890396118,
      "learning_rate": 8.747565590512533e-06,
      "loss": 0.5938,
      "step": 7910
    },
    {
      "epoch": 0.12525927450638885,
      "grad_norm": 0.2251168042421341,
      "learning_rate": 8.747407254936112e-06,
      "loss": 0.1047,
      "step": 7911
    },
    {
      "epoch": 0.12527510806403092,
      "grad_norm": 0.2882445156574249,
      "learning_rate": 8.747248919359693e-06,
      "loss": 0.0911,
      "step": 7912
    },
    {
      "epoch": 0.12529094162167298,
      "grad_norm": 0.1463584005832672,
      "learning_rate": 8.747090583783272e-06,
      "loss": 0.0637,
      "step": 7913
    },
    {
      "epoch": 0.12530677517931504,
      "grad_norm": 0.3625599145889282,
      "learning_rate": 8.74693224820685e-06,
      "loss": 0.0376,
      "step": 7914
    },
    {
      "epoch": 0.1253226087369571,
      "grad_norm": 0.5951473712921143,
      "learning_rate": 8.74677391263043e-06,
      "loss": 0.628,
      "step": 7915
    },
    {
      "epoch": 0.12533844229459917,
      "grad_norm": 0.3288695216178894,
      "learning_rate": 8.746615577054009e-06,
      "loss": 0.052,
      "step": 7916
    },
    {
      "epoch": 0.12535427585224124,
      "grad_norm": 0.45590081810951233,
      "learning_rate": 8.746457241477588e-06,
      "loss": 0.0749,
      "step": 7917
    },
    {
      "epoch": 0.1253701094098833,
      "grad_norm": 0.7534515261650085,
      "learning_rate": 8.746298905901167e-06,
      "loss": 0.3544,
      "step": 7918
    },
    {
      "epoch": 0.12538594296752537,
      "grad_norm": 0.2498766928911209,
      "learning_rate": 8.746140570324748e-06,
      "loss": 0.0481,
      "step": 7919
    },
    {
      "epoch": 0.12540177652516743,
      "grad_norm": 0.626910388469696,
      "learning_rate": 8.745982234748325e-06,
      "loss": 0.0536,
      "step": 7920
    },
    {
      "epoch": 0.1254176100828095,
      "grad_norm": 0.3710100054740906,
      "learning_rate": 8.745823899171906e-06,
      "loss": 0.2708,
      "step": 7921
    },
    {
      "epoch": 0.1254334436404516,
      "grad_norm": 0.041845474392175674,
      "learning_rate": 8.745665563595485e-06,
      "loss": 0.0021,
      "step": 7922
    },
    {
      "epoch": 0.12544927719809365,
      "grad_norm": 0.47753092646598816,
      "learning_rate": 8.745507228019064e-06,
      "loss": 0.1573,
      "step": 7923
    },
    {
      "epoch": 0.12546511075573571,
      "grad_norm": 0.23879018425941467,
      "learning_rate": 8.745348892442643e-06,
      "loss": 0.0417,
      "step": 7924
    },
    {
      "epoch": 0.12548094431337778,
      "grad_norm": 0.2386355698108673,
      "learning_rate": 8.745190556866224e-06,
      "loss": 0.0991,
      "step": 7925
    },
    {
      "epoch": 0.12549677787101984,
      "grad_norm": 0.3983123004436493,
      "learning_rate": 8.745032221289801e-06,
      "loss": 0.1093,
      "step": 7926
    },
    {
      "epoch": 0.1255126114286619,
      "grad_norm": 0.23869097232818604,
      "learning_rate": 8.744873885713382e-06,
      "loss": 0.1078,
      "step": 7927
    },
    {
      "epoch": 0.12552844498630397,
      "grad_norm": 0.5975512266159058,
      "learning_rate": 8.744715550136961e-06,
      "loss": 0.5153,
      "step": 7928
    },
    {
      "epoch": 0.12554427854394604,
      "grad_norm": 0.38025790452957153,
      "learning_rate": 8.74455721456054e-06,
      "loss": 0.0907,
      "step": 7929
    },
    {
      "epoch": 0.1255601121015881,
      "grad_norm": 0.48237088322639465,
      "learning_rate": 8.74439887898412e-06,
      "loss": 0.1662,
      "step": 7930
    },
    {
      "epoch": 0.12557594565923016,
      "grad_norm": 0.005517873447388411,
      "learning_rate": 8.7442405434077e-06,
      "loss": 0.0002,
      "step": 7931
    },
    {
      "epoch": 0.12559177921687223,
      "grad_norm": 0.002894426928833127,
      "learning_rate": 8.744082207831277e-06,
      "loss": 0.0001,
      "step": 7932
    },
    {
      "epoch": 0.1256076127745143,
      "grad_norm": 0.3933607041835785,
      "learning_rate": 8.743923872254858e-06,
      "loss": 0.5778,
      "step": 7933
    },
    {
      "epoch": 0.12562344633215639,
      "grad_norm": 0.5612041354179382,
      "learning_rate": 8.743765536678437e-06,
      "loss": 0.5722,
      "step": 7934
    },
    {
      "epoch": 0.12563927988979845,
      "grad_norm": 0.036923643201589584,
      "learning_rate": 8.743607201102016e-06,
      "loss": 0.0027,
      "step": 7935
    },
    {
      "epoch": 0.12565511344744051,
      "grad_norm": 0.008599583990871906,
      "learning_rate": 8.743448865525596e-06,
      "loss": 0.0004,
      "step": 7936
    },
    {
      "epoch": 0.12567094700508258,
      "grad_norm": 0.038502369076013565,
      "learning_rate": 8.743290529949176e-06,
      "loss": 0.0064,
      "step": 7937
    },
    {
      "epoch": 0.12568678056272464,
      "grad_norm": 0.4376431107521057,
      "learning_rate": 8.743132194372754e-06,
      "loss": 0.4867,
      "step": 7938
    },
    {
      "epoch": 0.1257026141203667,
      "grad_norm": 0.013049354776740074,
      "learning_rate": 8.742973858796334e-06,
      "loss": 0.0006,
      "step": 7939
    },
    {
      "epoch": 0.12571844767800877,
      "grad_norm": 0.28756460547447205,
      "learning_rate": 8.742815523219914e-06,
      "loss": 0.0881,
      "step": 7940
    },
    {
      "epoch": 0.12573428123565084,
      "grad_norm": 0.2527984082698822,
      "learning_rate": 8.742657187643493e-06,
      "loss": 0.0885,
      "step": 7941
    },
    {
      "epoch": 0.1257501147932929,
      "grad_norm": 0.5240026116371155,
      "learning_rate": 8.742498852067072e-06,
      "loss": 0.7137,
      "step": 7942
    },
    {
      "epoch": 0.12576594835093496,
      "grad_norm": 0.013607527129352093,
      "learning_rate": 8.74234051649065e-06,
      "loss": 0.0006,
      "step": 7943
    },
    {
      "epoch": 0.12578178190857703,
      "grad_norm": 0.2425018846988678,
      "learning_rate": 8.74218218091423e-06,
      "loss": 0.2128,
      "step": 7944
    },
    {
      "epoch": 0.1257976154662191,
      "grad_norm": 0.4733317494392395,
      "learning_rate": 8.742023845337809e-06,
      "loss": 0.1048,
      "step": 7945
    },
    {
      "epoch": 0.12581344902386118,
      "grad_norm": 0.4595417380332947,
      "learning_rate": 8.74186550976139e-06,
      "loss": 0.45,
      "step": 7946
    },
    {
      "epoch": 0.12582928258150325,
      "grad_norm": 0.5972611308097839,
      "learning_rate": 8.741707174184969e-06,
      "loss": 0.8259,
      "step": 7947
    },
    {
      "epoch": 0.1258451161391453,
      "grad_norm": 0.23088747262954712,
      "learning_rate": 8.741548838608548e-06,
      "loss": 0.1094,
      "step": 7948
    },
    {
      "epoch": 0.12586094969678738,
      "grad_norm": 0.007205337751656771,
      "learning_rate": 8.741390503032127e-06,
      "loss": 0.0002,
      "step": 7949
    },
    {
      "epoch": 0.12587678325442944,
      "grad_norm": 0.22254939377307892,
      "learning_rate": 8.741232167455706e-06,
      "loss": 0.0799,
      "step": 7950
    },
    {
      "epoch": 0.1258926168120715,
      "grad_norm": 0.4066106081008911,
      "learning_rate": 8.741073831879285e-06,
      "loss": 0.1176,
      "step": 7951
    },
    {
      "epoch": 0.12590845036971357,
      "grad_norm": 0.13519331812858582,
      "learning_rate": 8.740915496302866e-06,
      "loss": 0.0286,
      "step": 7952
    },
    {
      "epoch": 0.12592428392735563,
      "grad_norm": 0.10933724045753479,
      "learning_rate": 8.740757160726443e-06,
      "loss": 0.0176,
      "step": 7953
    },
    {
      "epoch": 0.1259401174849977,
      "grad_norm": 0.00637168250977993,
      "learning_rate": 8.740598825150024e-06,
      "loss": 0.0003,
      "step": 7954
    },
    {
      "epoch": 0.12595595104263976,
      "grad_norm": 0.25859543681144714,
      "learning_rate": 8.740440489573603e-06,
      "loss": 0.193,
      "step": 7955
    },
    {
      "epoch": 0.12597178460028183,
      "grad_norm": 0.16164472699165344,
      "learning_rate": 8.740282153997182e-06,
      "loss": 0.0025,
      "step": 7956
    },
    {
      "epoch": 0.1259876181579239,
      "grad_norm": 0.35715872049331665,
      "learning_rate": 8.740123818420761e-06,
      "loss": 0.0702,
      "step": 7957
    },
    {
      "epoch": 0.12600345171556598,
      "grad_norm": 0.5742789506912231,
      "learning_rate": 8.739965482844342e-06,
      "loss": 0.1943,
      "step": 7958
    },
    {
      "epoch": 0.12601928527320805,
      "grad_norm": 0.0075265346094965935,
      "learning_rate": 8.73980714726792e-06,
      "loss": 0.0004,
      "step": 7959
    },
    {
      "epoch": 0.1260351188308501,
      "grad_norm": 0.37974902987480164,
      "learning_rate": 8.7396488116915e-06,
      "loss": 0.0425,
      "step": 7960
    },
    {
      "epoch": 0.12605095238849218,
      "grad_norm": 0.1997140496969223,
      "learning_rate": 8.73949047611508e-06,
      "loss": 0.1012,
      "step": 7961
    },
    {
      "epoch": 0.12606678594613424,
      "grad_norm": 0.18801195919513702,
      "learning_rate": 8.739332140538658e-06,
      "loss": 0.0323,
      "step": 7962
    },
    {
      "epoch": 0.1260826195037763,
      "grad_norm": 0.346659392118454,
      "learning_rate": 8.739173804962237e-06,
      "loss": 0.1258,
      "step": 7963
    },
    {
      "epoch": 0.12609845306141837,
      "grad_norm": 0.3562510013580322,
      "learning_rate": 8.739015469385817e-06,
      "loss": 0.0526,
      "step": 7964
    },
    {
      "epoch": 0.12611428661906043,
      "grad_norm": 0.32113662362098694,
      "learning_rate": 8.738857133809396e-06,
      "loss": 0.0922,
      "step": 7965
    },
    {
      "epoch": 0.1261301201767025,
      "grad_norm": 0.49378135800361633,
      "learning_rate": 8.738698798232975e-06,
      "loss": 0.1326,
      "step": 7966
    },
    {
      "epoch": 0.12614595373434456,
      "grad_norm": 0.3450739085674286,
      "learning_rate": 8.738540462656555e-06,
      "loss": 0.1954,
      "step": 7967
    },
    {
      "epoch": 0.12616178729198663,
      "grad_norm": 0.18794837594032288,
      "learning_rate": 8.738382127080135e-06,
      "loss": 0.0492,
      "step": 7968
    },
    {
      "epoch": 0.1261776208496287,
      "grad_norm": 0.021794691681861877,
      "learning_rate": 8.738223791503714e-06,
      "loss": 0.0011,
      "step": 7969
    },
    {
      "epoch": 0.12619345440727078,
      "grad_norm": 0.2967912256717682,
      "learning_rate": 8.738065455927293e-06,
      "loss": 0.0453,
      "step": 7970
    },
    {
      "epoch": 0.12620928796491285,
      "grad_norm": 0.49246475100517273,
      "learning_rate": 8.737907120350872e-06,
      "loss": 0.1968,
      "step": 7971
    },
    {
      "epoch": 0.1262251215225549,
      "grad_norm": 0.3884626030921936,
      "learning_rate": 8.73774878477445e-06,
      "loss": 0.3791,
      "step": 7972
    },
    {
      "epoch": 0.12624095508019698,
      "grad_norm": 0.522734522819519,
      "learning_rate": 8.737590449198032e-06,
      "loss": 0.2056,
      "step": 7973
    },
    {
      "epoch": 0.12625678863783904,
      "grad_norm": 0.41615667939186096,
      "learning_rate": 8.73743211362161e-06,
      "loss": 0.1921,
      "step": 7974
    },
    {
      "epoch": 0.1262726221954811,
      "grad_norm": 0.26553627848625183,
      "learning_rate": 8.73727377804519e-06,
      "loss": 0.126,
      "step": 7975
    },
    {
      "epoch": 0.12628845575312317,
      "grad_norm": 0.022609949111938477,
      "learning_rate": 8.737115442468769e-06,
      "loss": 0.0013,
      "step": 7976
    },
    {
      "epoch": 0.12630428931076523,
      "grad_norm": 0.0002575686085037887,
      "learning_rate": 8.736957106892348e-06,
      "loss": 0.0,
      "step": 7977
    },
    {
      "epoch": 0.1263201228684073,
      "grad_norm": 0.41797196865081787,
      "learning_rate": 8.736798771315927e-06,
      "loss": 0.0157,
      "step": 7978
    },
    {
      "epoch": 0.12633595642604936,
      "grad_norm": 0.0006283850525505841,
      "learning_rate": 8.736640435739508e-06,
      "loss": 0.0,
      "step": 7979
    },
    {
      "epoch": 0.12635178998369143,
      "grad_norm": 0.16597937047481537,
      "learning_rate": 8.736482100163087e-06,
      "loss": 0.0332,
      "step": 7980
    },
    {
      "epoch": 0.1263676235413335,
      "grad_norm": 0.42392754554748535,
      "learning_rate": 8.736323764586666e-06,
      "loss": 0.2399,
      "step": 7981
    },
    {
      "epoch": 0.12638345709897558,
      "grad_norm": 0.5039827227592468,
      "learning_rate": 8.736165429010245e-06,
      "loss": 0.1701,
      "step": 7982
    },
    {
      "epoch": 0.12639929065661765,
      "grad_norm": 0.40334397554397583,
      "learning_rate": 8.736007093433824e-06,
      "loss": 0.1596,
      "step": 7983
    },
    {
      "epoch": 0.1264151242142597,
      "grad_norm": 0.3628562390804291,
      "learning_rate": 8.735848757857403e-06,
      "loss": 0.1665,
      "step": 7984
    },
    {
      "epoch": 0.12643095777190178,
      "grad_norm": 0.21992312371730804,
      "learning_rate": 8.735690422280984e-06,
      "loss": 0.0666,
      "step": 7985
    },
    {
      "epoch": 0.12644679132954384,
      "grad_norm": 0.18355250358581543,
      "learning_rate": 8.735532086704563e-06,
      "loss": 0.0727,
      "step": 7986
    },
    {
      "epoch": 0.1264626248871859,
      "grad_norm": 0.022519707679748535,
      "learning_rate": 8.735373751128142e-06,
      "loss": 0.0014,
      "step": 7987
    },
    {
      "epoch": 0.12647845844482797,
      "grad_norm": 0.4509735405445099,
      "learning_rate": 8.735215415551721e-06,
      "loss": 0.0862,
      "step": 7988
    },
    {
      "epoch": 0.12649429200247003,
      "grad_norm": 0.005014858674257994,
      "learning_rate": 8.7350570799753e-06,
      "loss": 0.0002,
      "step": 7989
    },
    {
      "epoch": 0.1265101255601121,
      "grad_norm": 0.00829064566642046,
      "learning_rate": 8.73489874439888e-06,
      "loss": 0.0002,
      "step": 7990
    },
    {
      "epoch": 0.12652595911775416,
      "grad_norm": 0.34695953130722046,
      "learning_rate": 8.734740408822458e-06,
      "loss": 0.1557,
      "step": 7991
    },
    {
      "epoch": 0.12654179267539623,
      "grad_norm": 2.1403403282165527,
      "learning_rate": 8.73458207324604e-06,
      "loss": 0.1081,
      "step": 7992
    },
    {
      "epoch": 0.1265576262330383,
      "grad_norm": 0.4215499460697174,
      "learning_rate": 8.734423737669617e-06,
      "loss": 0.3144,
      "step": 7993
    },
    {
      "epoch": 0.12657345979068038,
      "grad_norm": 0.3838723301887512,
      "learning_rate": 8.734265402093197e-06,
      "loss": 0.1528,
      "step": 7994
    },
    {
      "epoch": 0.12658929334832245,
      "grad_norm": 0.9104094505310059,
      "learning_rate": 8.734107066516776e-06,
      "loss": 0.4438,
      "step": 7995
    },
    {
      "epoch": 0.1266051269059645,
      "grad_norm": 0.7524694800376892,
      "learning_rate": 8.733948730940356e-06,
      "loss": 0.5763,
      "step": 7996
    },
    {
      "epoch": 0.12662096046360657,
      "grad_norm": 0.08441824465990067,
      "learning_rate": 8.733790395363935e-06,
      "loss": 0.0053,
      "step": 7997
    },
    {
      "epoch": 0.12663679402124864,
      "grad_norm": 0.0003394899540580809,
      "learning_rate": 8.733632059787515e-06,
      "loss": 0.0,
      "step": 7998
    },
    {
      "epoch": 0.1266526275788907,
      "grad_norm": 0.657279908657074,
      "learning_rate": 8.733473724211093e-06,
      "loss": 0.9472,
      "step": 7999
    },
    {
      "epoch": 0.12666846113653277,
      "grad_norm": 0.5373344421386719,
      "learning_rate": 8.733315388634674e-06,
      "loss": 0.5758,
      "step": 8000
    },
    {
      "epoch": 0.12668429469417483,
      "grad_norm": 0.020630979910492897,
      "learning_rate": 8.733157053058253e-06,
      "loss": 0.0009,
      "step": 8001
    },
    {
      "epoch": 0.1267001282518169,
      "grad_norm": 0.29724565148353577,
      "learning_rate": 8.732998717481832e-06,
      "loss": 0.058,
      "step": 8002
    },
    {
      "epoch": 0.12671596180945896,
      "grad_norm": 0.010476353578269482,
      "learning_rate": 8.73284038190541e-06,
      "loss": 0.0006,
      "step": 8003
    },
    {
      "epoch": 0.12673179536710102,
      "grad_norm": 0.01166723482310772,
      "learning_rate": 8.732682046328992e-06,
      "loss": 0.0005,
      "step": 8004
    },
    {
      "epoch": 0.1267476289247431,
      "grad_norm": 0.41675645112991333,
      "learning_rate": 8.732523710752569e-06,
      "loss": 0.2603,
      "step": 8005
    },
    {
      "epoch": 0.12676346248238518,
      "grad_norm": 0.24653935432434082,
      "learning_rate": 8.73236537517615e-06,
      "loss": 0.0693,
      "step": 8006
    },
    {
      "epoch": 0.12677929604002725,
      "grad_norm": 1.6609809398651123,
      "learning_rate": 8.732207039599729e-06,
      "loss": 0.2333,
      "step": 8007
    },
    {
      "epoch": 0.1267951295976693,
      "grad_norm": 0.0031258531380444765,
      "learning_rate": 8.732048704023308e-06,
      "loss": 0.0001,
      "step": 8008
    },
    {
      "epoch": 0.12681096315531137,
      "grad_norm": 0.21910665929317474,
      "learning_rate": 8.731890368446887e-06,
      "loss": 0.0701,
      "step": 8009
    },
    {
      "epoch": 0.12682679671295344,
      "grad_norm": 0.6135678887367249,
      "learning_rate": 8.731732032870468e-06,
      "loss": 0.0482,
      "step": 8010
    },
    {
      "epoch": 0.1268426302705955,
      "grad_norm": 0.02585877664387226,
      "learning_rate": 8.731573697294045e-06,
      "loss": 0.0018,
      "step": 8011
    },
    {
      "epoch": 0.12685846382823757,
      "grad_norm": 0.5304602384567261,
      "learning_rate": 8.731415361717624e-06,
      "loss": 0.1413,
      "step": 8012
    },
    {
      "epoch": 0.12687429738587963,
      "grad_norm": 0.6521150469779968,
      "learning_rate": 8.731257026141205e-06,
      "loss": 0.2518,
      "step": 8013
    },
    {
      "epoch": 0.1268901309435217,
      "grad_norm": 0.2077641487121582,
      "learning_rate": 8.731098690564784e-06,
      "loss": 0.1923,
      "step": 8014
    },
    {
      "epoch": 0.12690596450116376,
      "grad_norm": 0.4572408199310303,
      "learning_rate": 8.730940354988363e-06,
      "loss": 0.2689,
      "step": 8015
    },
    {
      "epoch": 0.12692179805880582,
      "grad_norm": 0.21852385997772217,
      "learning_rate": 8.730782019411942e-06,
      "loss": 0.1204,
      "step": 8016
    },
    {
      "epoch": 0.1269376316164479,
      "grad_norm": 0.6011595726013184,
      "learning_rate": 8.730623683835521e-06,
      "loss": 0.9403,
      "step": 8017
    },
    {
      "epoch": 0.12695346517408998,
      "grad_norm": 0.3169472813606262,
      "learning_rate": 8.7304653482591e-06,
      "loss": 0.0849,
      "step": 8018
    },
    {
      "epoch": 0.12696929873173204,
      "grad_norm": 1.1469320058822632,
      "learning_rate": 8.730307012682681e-06,
      "loss": 0.0681,
      "step": 8019
    },
    {
      "epoch": 0.1269851322893741,
      "grad_norm": 0.33849355578422546,
      "learning_rate": 8.730148677106259e-06,
      "loss": 0.3286,
      "step": 8020
    },
    {
      "epoch": 0.12700096584701617,
      "grad_norm": 0.0756680965423584,
      "learning_rate": 8.72999034152984e-06,
      "loss": 0.0037,
      "step": 8021
    },
    {
      "epoch": 0.12701679940465824,
      "grad_norm": 0.4369211196899414,
      "learning_rate": 8.729832005953418e-06,
      "loss": 0.3264,
      "step": 8022
    },
    {
      "epoch": 0.1270326329623003,
      "grad_norm": 0.5724565386772156,
      "learning_rate": 8.729673670376997e-06,
      "loss": 0.1874,
      "step": 8023
    },
    {
      "epoch": 0.12704846651994237,
      "grad_norm": 0.5297031998634338,
      "learning_rate": 8.729515334800577e-06,
      "loss": 0.1484,
      "step": 8024
    },
    {
      "epoch": 0.12706430007758443,
      "grad_norm": 0.84964519739151,
      "learning_rate": 8.729356999224157e-06,
      "loss": 0.0507,
      "step": 8025
    },
    {
      "epoch": 0.1270801336352265,
      "grad_norm": 0.19892781972885132,
      "learning_rate": 8.729198663647735e-06,
      "loss": 0.1162,
      "step": 8026
    },
    {
      "epoch": 0.12709596719286856,
      "grad_norm": 0.3692832291126251,
      "learning_rate": 8.729040328071315e-06,
      "loss": 0.1481,
      "step": 8027
    },
    {
      "epoch": 0.12711180075051062,
      "grad_norm": 0.16973695158958435,
      "learning_rate": 8.728881992494895e-06,
      "loss": 0.0857,
      "step": 8028
    },
    {
      "epoch": 0.1271276343081527,
      "grad_norm": 0.5176761746406555,
      "learning_rate": 8.728723656918474e-06,
      "loss": 0.5261,
      "step": 8029
    },
    {
      "epoch": 0.12714346786579478,
      "grad_norm": 1.1196008920669556,
      "learning_rate": 8.728565321342053e-06,
      "loss": 0.4033,
      "step": 8030
    },
    {
      "epoch": 0.12715930142343684,
      "grad_norm": 0.004335158038884401,
      "learning_rate": 8.728406985765633e-06,
      "loss": 0.0002,
      "step": 8031
    },
    {
      "epoch": 0.1271751349810789,
      "grad_norm": 0.017957178875803947,
      "learning_rate": 8.728248650189211e-06,
      "loss": 0.0011,
      "step": 8032
    },
    {
      "epoch": 0.12719096853872097,
      "grad_norm": 0.41535189747810364,
      "learning_rate": 8.728090314612792e-06,
      "loss": 0.5377,
      "step": 8033
    },
    {
      "epoch": 0.12720680209636304,
      "grad_norm": 0.0027302922680974007,
      "learning_rate": 8.72793197903637e-06,
      "loss": 0.0001,
      "step": 8034
    },
    {
      "epoch": 0.1272226356540051,
      "grad_norm": 0.5898780822753906,
      "learning_rate": 8.72777364345995e-06,
      "loss": 0.4249,
      "step": 8035
    },
    {
      "epoch": 0.12723846921164716,
      "grad_norm": 0.023604797199368477,
      "learning_rate": 8.727615307883529e-06,
      "loss": 0.0003,
      "step": 8036
    },
    {
      "epoch": 0.12725430276928923,
      "grad_norm": 0.5435915589332581,
      "learning_rate": 8.727456972307108e-06,
      "loss": 0.6916,
      "step": 8037
    },
    {
      "epoch": 0.1272701363269313,
      "grad_norm": 0.3355911076068878,
      "learning_rate": 8.727298636730687e-06,
      "loss": 0.1085,
      "step": 8038
    },
    {
      "epoch": 0.12728596988457336,
      "grad_norm": 0.04194860905408859,
      "learning_rate": 8.727140301154266e-06,
      "loss": 0.0024,
      "step": 8039
    },
    {
      "epoch": 0.12730180344221542,
      "grad_norm": 0.3100157678127289,
      "learning_rate": 8.726981965577847e-06,
      "loss": 0.1911,
      "step": 8040
    },
    {
      "epoch": 0.1273176369998575,
      "grad_norm": 0.2745993435382843,
      "learning_rate": 8.726823630001426e-06,
      "loss": 0.2235,
      "step": 8041
    },
    {
      "epoch": 0.12733347055749958,
      "grad_norm": 0.2520812749862671,
      "learning_rate": 8.726665294425005e-06,
      "loss": 0.2467,
      "step": 8042
    },
    {
      "epoch": 0.12734930411514164,
      "grad_norm": 0.15980927646160126,
      "learning_rate": 8.726506958848584e-06,
      "loss": 0.0454,
      "step": 8043
    },
    {
      "epoch": 0.1273651376727837,
      "grad_norm": 0.10400982201099396,
      "learning_rate": 8.726348623272163e-06,
      "loss": 0.0513,
      "step": 8044
    },
    {
      "epoch": 0.12738097123042577,
      "grad_norm": 0.5111856460571289,
      "learning_rate": 8.726190287695742e-06,
      "loss": 0.7394,
      "step": 8045
    },
    {
      "epoch": 0.12739680478806784,
      "grad_norm": 0.010503842495381832,
      "learning_rate": 8.726031952119323e-06,
      "loss": 0.0006,
      "step": 8046
    },
    {
      "epoch": 0.1274126383457099,
      "grad_norm": 0.27836960554122925,
      "learning_rate": 8.725873616542902e-06,
      "loss": 0.1178,
      "step": 8047
    },
    {
      "epoch": 0.12742847190335196,
      "grad_norm": 0.6474708318710327,
      "learning_rate": 8.725715280966481e-06,
      "loss": 0.0621,
      "step": 8048
    },
    {
      "epoch": 0.12744430546099403,
      "grad_norm": 0.17553137242794037,
      "learning_rate": 8.72555694539006e-06,
      "loss": 0.0634,
      "step": 8049
    },
    {
      "epoch": 0.1274601390186361,
      "grad_norm": 0.26936060190200806,
      "learning_rate": 8.72539860981364e-06,
      "loss": 0.2484,
      "step": 8050
    },
    {
      "epoch": 0.12747597257627816,
      "grad_norm": 0.0004269867204129696,
      "learning_rate": 8.725240274237218e-06,
      "loss": 0.0,
      "step": 8051
    },
    {
      "epoch": 0.12749180613392022,
      "grad_norm": 0.14797092974185944,
      "learning_rate": 8.7250819386608e-06,
      "loss": 0.0559,
      "step": 8052
    },
    {
      "epoch": 0.12750763969156229,
      "grad_norm": 0.01919187419116497,
      "learning_rate": 8.724923603084378e-06,
      "loss": 0.0008,
      "step": 8053
    },
    {
      "epoch": 0.12752347324920435,
      "grad_norm": 0.42630496621131897,
      "learning_rate": 8.724765267507957e-06,
      "loss": 0.1726,
      "step": 8054
    },
    {
      "epoch": 0.12753930680684644,
      "grad_norm": 0.34537288546562195,
      "learning_rate": 8.724606931931536e-06,
      "loss": 0.0606,
      "step": 8055
    },
    {
      "epoch": 0.1275551403644885,
      "grad_norm": 0.02118079923093319,
      "learning_rate": 8.724448596355116e-06,
      "loss": 0.001,
      "step": 8056
    },
    {
      "epoch": 0.12757097392213057,
      "grad_norm": 0.39701470732688904,
      "learning_rate": 8.724290260778695e-06,
      "loss": 0.1092,
      "step": 8057
    },
    {
      "epoch": 0.12758680747977263,
      "grad_norm": 0.21218006312847137,
      "learning_rate": 8.724131925202275e-06,
      "loss": 0.0925,
      "step": 8058
    },
    {
      "epoch": 0.1276026410374147,
      "grad_norm": 0.43042662739753723,
      "learning_rate": 8.723973589625854e-06,
      "loss": 0.6052,
      "step": 8059
    },
    {
      "epoch": 0.12761847459505676,
      "grad_norm": 0.6675362586975098,
      "learning_rate": 8.723815254049434e-06,
      "loss": 0.3481,
      "step": 8060
    },
    {
      "epoch": 0.12763430815269883,
      "grad_norm": 0.3184407949447632,
      "learning_rate": 8.723656918473013e-06,
      "loss": 0.1334,
      "step": 8061
    },
    {
      "epoch": 0.1276501417103409,
      "grad_norm": 0.4223078787326813,
      "learning_rate": 8.723498582896592e-06,
      "loss": 0.1562,
      "step": 8062
    },
    {
      "epoch": 0.12766597526798296,
      "grad_norm": 0.1491900086402893,
      "learning_rate": 8.72334024732017e-06,
      "loss": 0.0602,
      "step": 8063
    },
    {
      "epoch": 0.12768180882562502,
      "grad_norm": 0.39069873094558716,
      "learning_rate": 8.72318191174375e-06,
      "loss": 0.1906,
      "step": 8064
    },
    {
      "epoch": 0.12769764238326708,
      "grad_norm": 0.41259193420410156,
      "learning_rate": 8.72302357616733e-06,
      "loss": 0.5912,
      "step": 8065
    },
    {
      "epoch": 0.12771347594090915,
      "grad_norm": 0.19467765092849731,
      "learning_rate": 8.722865240590908e-06,
      "loss": 0.0311,
      "step": 8066
    },
    {
      "epoch": 0.12772930949855124,
      "grad_norm": 0.009191298857331276,
      "learning_rate": 8.722706905014489e-06,
      "loss": 0.0005,
      "step": 8067
    },
    {
      "epoch": 0.1277451430561933,
      "grad_norm": 0.000252052879659459,
      "learning_rate": 8.722548569438068e-06,
      "loss": 0.0,
      "step": 8068
    },
    {
      "epoch": 0.12776097661383537,
      "grad_norm": 0.05655127763748169,
      "learning_rate": 8.722390233861647e-06,
      "loss": 0.0031,
      "step": 8069
    },
    {
      "epoch": 0.12777681017147743,
      "grad_norm": 0.19822576642036438,
      "learning_rate": 8.722231898285226e-06,
      "loss": 0.1114,
      "step": 8070
    },
    {
      "epoch": 0.1277926437291195,
      "grad_norm": 0.3503980040550232,
      "learning_rate": 8.722073562708807e-06,
      "loss": 0.0235,
      "step": 8071
    },
    {
      "epoch": 0.12780847728676156,
      "grad_norm": 0.022769803181290627,
      "learning_rate": 8.721915227132384e-06,
      "loss": 0.0012,
      "step": 8072
    },
    {
      "epoch": 0.12782431084440363,
      "grad_norm": 0.22115862369537354,
      "learning_rate": 8.721756891555965e-06,
      "loss": 0.0379,
      "step": 8073
    },
    {
      "epoch": 0.1278401444020457,
      "grad_norm": 0.0418558269739151,
      "learning_rate": 8.721598555979544e-06,
      "loss": 0.0021,
      "step": 8074
    },
    {
      "epoch": 0.12785597795968776,
      "grad_norm": 0.3695933520793915,
      "learning_rate": 8.721440220403123e-06,
      "loss": 0.2379,
      "step": 8075
    },
    {
      "epoch": 0.12787181151732982,
      "grad_norm": 0.23128020763397217,
      "learning_rate": 8.721281884826702e-06,
      "loss": 0.1502,
      "step": 8076
    },
    {
      "epoch": 0.12788764507497188,
      "grad_norm": 0.0004336647398304194,
      "learning_rate": 8.721123549250283e-06,
      "loss": 0.0,
      "step": 8077
    },
    {
      "epoch": 0.12790347863261395,
      "grad_norm": 0.0008009672746993601,
      "learning_rate": 8.72096521367386e-06,
      "loss": 0.0,
      "step": 8078
    },
    {
      "epoch": 0.12791931219025604,
      "grad_norm": 0.45581352710723877,
      "learning_rate": 8.720806878097441e-06,
      "loss": 0.2758,
      "step": 8079
    },
    {
      "epoch": 0.1279351457478981,
      "grad_norm": 0.13950702548027039,
      "learning_rate": 8.72064854252102e-06,
      "loss": 0.0581,
      "step": 8080
    },
    {
      "epoch": 0.12795097930554017,
      "grad_norm": 0.008455499075353146,
      "learning_rate": 8.7204902069446e-06,
      "loss": 0.0005,
      "step": 8081
    },
    {
      "epoch": 0.12796681286318223,
      "grad_norm": 0.19034959375858307,
      "learning_rate": 8.720331871368178e-06,
      "loss": 0.0175,
      "step": 8082
    },
    {
      "epoch": 0.1279826464208243,
      "grad_norm": 0.011086209677159786,
      "learning_rate": 8.720173535791757e-06,
      "loss": 0.0009,
      "step": 8083
    },
    {
      "epoch": 0.12799847997846636,
      "grad_norm": 0.40554946660995483,
      "learning_rate": 8.720015200215337e-06,
      "loss": 0.7012,
      "step": 8084
    },
    {
      "epoch": 0.12801431353610843,
      "grad_norm": 0.26857900619506836,
      "learning_rate": 8.719856864638916e-06,
      "loss": 0.1058,
      "step": 8085
    },
    {
      "epoch": 0.1280301470937505,
      "grad_norm": 0.4748172163963318,
      "learning_rate": 8.719698529062496e-06,
      "loss": 0.3443,
      "step": 8086
    },
    {
      "epoch": 0.12804598065139255,
      "grad_norm": 0.46971315145492554,
      "learning_rate": 8.719540193486074e-06,
      "loss": 1.7715,
      "step": 8087
    },
    {
      "epoch": 0.12806181420903462,
      "grad_norm": 0.34992218017578125,
      "learning_rate": 8.719381857909655e-06,
      "loss": 0.0628,
      "step": 8088
    },
    {
      "epoch": 0.12807764776667668,
      "grad_norm": 0.26165276765823364,
      "learning_rate": 8.719223522333234e-06,
      "loss": 0.0722,
      "step": 8089
    },
    {
      "epoch": 0.12809348132431875,
      "grad_norm": 0.22069653868675232,
      "learning_rate": 8.719065186756813e-06,
      "loss": 0.071,
      "step": 8090
    },
    {
      "epoch": 0.12810931488196084,
      "grad_norm": 0.012042790651321411,
      "learning_rate": 8.718906851180392e-06,
      "loss": 0.0005,
      "step": 8091
    },
    {
      "epoch": 0.1281251484396029,
      "grad_norm": 0.41968509554862976,
      "learning_rate": 8.718748515603973e-06,
      "loss": 0.0381,
      "step": 8092
    },
    {
      "epoch": 0.12814098199724497,
      "grad_norm": 0.18889611959457397,
      "learning_rate": 8.71859018002755e-06,
      "loss": 0.0438,
      "step": 8093
    },
    {
      "epoch": 0.12815681555488703,
      "grad_norm": 0.48097875714302063,
      "learning_rate": 8.71843184445113e-06,
      "loss": 0.4653,
      "step": 8094
    },
    {
      "epoch": 0.1281726491125291,
      "grad_norm": 0.032122060656547546,
      "learning_rate": 8.71827350887471e-06,
      "loss": 0.0016,
      "step": 8095
    },
    {
      "epoch": 0.12818848267017116,
      "grad_norm": 0.049280766397714615,
      "learning_rate": 8.718115173298289e-06,
      "loss": 0.003,
      "step": 8096
    },
    {
      "epoch": 0.12820431622781323,
      "grad_norm": 0.2691045105457306,
      "learning_rate": 8.717956837721868e-06,
      "loss": 0.1484,
      "step": 8097
    },
    {
      "epoch": 0.1282201497854553,
      "grad_norm": 0.016868339851498604,
      "learning_rate": 8.717798502145449e-06,
      "loss": 0.0009,
      "step": 8098
    },
    {
      "epoch": 0.12823598334309735,
      "grad_norm": 0.26694056391716003,
      "learning_rate": 8.717640166569026e-06,
      "loss": 0.1103,
      "step": 8099
    },
    {
      "epoch": 0.12825181690073942,
      "grad_norm": 0.2520312964916229,
      "learning_rate": 8.717481830992607e-06,
      "loss": 0.0923,
      "step": 8100
    },
    {
      "epoch": 0.12826765045838148,
      "grad_norm": 0.07959068566560745,
      "learning_rate": 8.717323495416186e-06,
      "loss": 0.0066,
      "step": 8101
    },
    {
      "epoch": 0.12828348401602355,
      "grad_norm": 0.925503134727478,
      "learning_rate": 8.717165159839765e-06,
      "loss": 0.1134,
      "step": 8102
    },
    {
      "epoch": 0.12829931757366564,
      "grad_norm": 0.11562829464673996,
      "learning_rate": 8.717006824263344e-06,
      "loss": 0.0187,
      "step": 8103
    },
    {
      "epoch": 0.1283151511313077,
      "grad_norm": 1.0564039945602417,
      "learning_rate": 8.716848488686925e-06,
      "loss": 0.6465,
      "step": 8104
    },
    {
      "epoch": 0.12833098468894977,
      "grad_norm": 0.036525189876556396,
      "learning_rate": 8.716690153110502e-06,
      "loss": 0.0022,
      "step": 8105
    },
    {
      "epoch": 0.12834681824659183,
      "grad_norm": 0.4032560884952545,
      "learning_rate": 8.716531817534083e-06,
      "loss": 0.1531,
      "step": 8106
    },
    {
      "epoch": 0.1283626518042339,
      "grad_norm": 0.0004431887937244028,
      "learning_rate": 8.716373481957662e-06,
      "loss": 0.0,
      "step": 8107
    },
    {
      "epoch": 0.12837848536187596,
      "grad_norm": 0.27033066749572754,
      "learning_rate": 8.716215146381241e-06,
      "loss": 0.1495,
      "step": 8108
    },
    {
      "epoch": 0.12839431891951802,
      "grad_norm": 1.5451264381408691,
      "learning_rate": 8.71605681080482e-06,
      "loss": 0.1508,
      "step": 8109
    },
    {
      "epoch": 0.1284101524771601,
      "grad_norm": 0.00025157027994282544,
      "learning_rate": 8.7158984752284e-06,
      "loss": 0.0,
      "step": 8110
    },
    {
      "epoch": 0.12842598603480215,
      "grad_norm": 0.24269257485866547,
      "learning_rate": 8.715740139651978e-06,
      "loss": 0.0937,
      "step": 8111
    },
    {
      "epoch": 0.12844181959244422,
      "grad_norm": 0.2918584942817688,
      "learning_rate": 8.715581804075558e-06,
      "loss": 0.1314,
      "step": 8112
    },
    {
      "epoch": 0.12845765315008628,
      "grad_norm": 0.3423955738544464,
      "learning_rate": 8.715423468499138e-06,
      "loss": 0.6365,
      "step": 8113
    },
    {
      "epoch": 0.12847348670772835,
      "grad_norm": 0.0018547407817095518,
      "learning_rate": 8.715265132922717e-06,
      "loss": 0.0001,
      "step": 8114
    },
    {
      "epoch": 0.12848932026537044,
      "grad_norm": 0.004975601099431515,
      "learning_rate": 8.715106797346296e-06,
      "loss": 0.0002,
      "step": 8115
    },
    {
      "epoch": 0.1285051538230125,
      "grad_norm": 0.2939964532852173,
      "learning_rate": 8.714948461769876e-06,
      "loss": 0.0944,
      "step": 8116
    },
    {
      "epoch": 0.12852098738065457,
      "grad_norm": 0.03659690544009209,
      "learning_rate": 8.714790126193455e-06,
      "loss": 0.0018,
      "step": 8117
    },
    {
      "epoch": 0.12853682093829663,
      "grad_norm": 0.29358774423599243,
      "learning_rate": 8.714631790617034e-06,
      "loss": 0.0873,
      "step": 8118
    },
    {
      "epoch": 0.1285526544959387,
      "grad_norm": 0.41123437881469727,
      "learning_rate": 8.714473455040615e-06,
      "loss": 0.5257,
      "step": 8119
    },
    {
      "epoch": 0.12856848805358076,
      "grad_norm": 0.5591293573379517,
      "learning_rate": 8.714315119464194e-06,
      "loss": 0.103,
      "step": 8120
    },
    {
      "epoch": 0.12858432161122282,
      "grad_norm": 0.8291918039321899,
      "learning_rate": 8.714156783887773e-06,
      "loss": 0.2041,
      "step": 8121
    },
    {
      "epoch": 0.1286001551688649,
      "grad_norm": 0.10519535094499588,
      "learning_rate": 8.713998448311352e-06,
      "loss": 0.0024,
      "step": 8122
    },
    {
      "epoch": 0.12861598872650695,
      "grad_norm": 0.0005712659913115203,
      "learning_rate": 8.71384011273493e-06,
      "loss": 0.0,
      "step": 8123
    },
    {
      "epoch": 0.12863182228414902,
      "grad_norm": 0.6624022126197815,
      "learning_rate": 8.71368177715851e-06,
      "loss": 0.6597,
      "step": 8124
    },
    {
      "epoch": 0.12864765584179108,
      "grad_norm": 0.2945932447910309,
      "learning_rate": 8.71352344158209e-06,
      "loss": 0.2463,
      "step": 8125
    },
    {
      "epoch": 0.12866348939943315,
      "grad_norm": 0.382303923368454,
      "learning_rate": 8.71336510600567e-06,
      "loss": 0.2791,
      "step": 8126
    },
    {
      "epoch": 0.12867932295707524,
      "grad_norm": 0.19318410754203796,
      "learning_rate": 8.713206770429249e-06,
      "loss": 0.0983,
      "step": 8127
    },
    {
      "epoch": 0.1286951565147173,
      "grad_norm": 0.504589319229126,
      "learning_rate": 8.713048434852828e-06,
      "loss": 0.303,
      "step": 8128
    },
    {
      "epoch": 0.12871099007235937,
      "grad_norm": 0.3857075273990631,
      "learning_rate": 8.712890099276407e-06,
      "loss": 0.1033,
      "step": 8129
    },
    {
      "epoch": 0.12872682363000143,
      "grad_norm": 0.35067155957221985,
      "learning_rate": 8.712731763699986e-06,
      "loss": 0.0434,
      "step": 8130
    },
    {
      "epoch": 0.1287426571876435,
      "grad_norm": 0.013275613076984882,
      "learning_rate": 8.712573428123567e-06,
      "loss": 0.0006,
      "step": 8131
    },
    {
      "epoch": 0.12875849074528556,
      "grad_norm": 0.3132549226284027,
      "learning_rate": 8.712415092547146e-06,
      "loss": 0.0455,
      "step": 8132
    },
    {
      "epoch": 0.12877432430292762,
      "grad_norm": 0.30885401368141174,
      "learning_rate": 8.712256756970723e-06,
      "loss": 0.065,
      "step": 8133
    },
    {
      "epoch": 0.1287901578605697,
      "grad_norm": 0.40413278341293335,
      "learning_rate": 8.712098421394304e-06,
      "loss": 0.4655,
      "step": 8134
    },
    {
      "epoch": 0.12880599141821175,
      "grad_norm": 0.02586263231933117,
      "learning_rate": 8.711940085817883e-06,
      "loss": 0.0014,
      "step": 8135
    },
    {
      "epoch": 0.12882182497585382,
      "grad_norm": 0.2529999911785126,
      "learning_rate": 8.711781750241462e-06,
      "loss": 0.0916,
      "step": 8136
    },
    {
      "epoch": 0.12883765853349588,
      "grad_norm": 0.37067899107933044,
      "learning_rate": 8.711623414665041e-06,
      "loss": 0.1372,
      "step": 8137
    },
    {
      "epoch": 0.12885349209113794,
      "grad_norm": 0.40158236026763916,
      "learning_rate": 8.711465079088622e-06,
      "loss": 0.0832,
      "step": 8138
    },
    {
      "epoch": 0.12886932564878004,
      "grad_norm": 0.04556212201714516,
      "learning_rate": 8.7113067435122e-06,
      "loss": 0.0023,
      "step": 8139
    },
    {
      "epoch": 0.1288851592064221,
      "grad_norm": 0.29464367032051086,
      "learning_rate": 8.71114840793578e-06,
      "loss": 0.0679,
      "step": 8140
    },
    {
      "epoch": 0.12890099276406417,
      "grad_norm": 0.3210592269897461,
      "learning_rate": 8.71099007235936e-06,
      "loss": 0.035,
      "step": 8141
    },
    {
      "epoch": 0.12891682632170623,
      "grad_norm": 0.32624703645706177,
      "learning_rate": 8.710831736782938e-06,
      "loss": 0.0419,
      "step": 8142
    },
    {
      "epoch": 0.1289326598793483,
      "grad_norm": 0.017311278730630875,
      "learning_rate": 8.710673401206517e-06,
      "loss": 0.0004,
      "step": 8143
    },
    {
      "epoch": 0.12894849343699036,
      "grad_norm": 0.3510203957557678,
      "learning_rate": 8.710515065630097e-06,
      "loss": 0.1439,
      "step": 8144
    },
    {
      "epoch": 0.12896432699463242,
      "grad_norm": 0.0005384460091590881,
      "learning_rate": 8.710356730053676e-06,
      "loss": 0.0,
      "step": 8145
    },
    {
      "epoch": 0.1289801605522745,
      "grad_norm": 0.21001292765140533,
      "learning_rate": 8.710198394477256e-06,
      "loss": 0.0579,
      "step": 8146
    },
    {
      "epoch": 0.12899599410991655,
      "grad_norm": 0.0005143408779986203,
      "learning_rate": 8.710040058900836e-06,
      "loss": 0.0,
      "step": 8147
    },
    {
      "epoch": 0.12901182766755862,
      "grad_norm": 0.06735381484031677,
      "learning_rate": 8.709881723324415e-06,
      "loss": 0.0038,
      "step": 8148
    },
    {
      "epoch": 0.12902766122520068,
      "grad_norm": 0.4024451673030853,
      "learning_rate": 8.709723387747994e-06,
      "loss": 0.0982,
      "step": 8149
    },
    {
      "epoch": 0.12904349478284274,
      "grad_norm": 0.2537369430065155,
      "learning_rate": 8.709565052171573e-06,
      "loss": 0.0717,
      "step": 8150
    },
    {
      "epoch": 0.12905932834048484,
      "grad_norm": 0.34274375438690186,
      "learning_rate": 8.709406716595152e-06,
      "loss": 0.0532,
      "step": 8151
    },
    {
      "epoch": 0.1290751618981269,
      "grad_norm": 0.206265389919281,
      "learning_rate": 8.709248381018733e-06,
      "loss": 0.0595,
      "step": 8152
    },
    {
      "epoch": 0.12909099545576896,
      "grad_norm": 0.0004881555214524269,
      "learning_rate": 8.709090045442312e-06,
      "loss": 0.0,
      "step": 8153
    },
    {
      "epoch": 0.12910682901341103,
      "grad_norm": 0.5761194229125977,
      "learning_rate": 8.70893170986589e-06,
      "loss": 0.3703,
      "step": 8154
    },
    {
      "epoch": 0.1291226625710531,
      "grad_norm": 0.019040515646338463,
      "learning_rate": 8.70877337428947e-06,
      "loss": 0.0006,
      "step": 8155
    },
    {
      "epoch": 0.12913849612869516,
      "grad_norm": 0.574821412563324,
      "learning_rate": 8.708615038713049e-06,
      "loss": 0.8496,
      "step": 8156
    },
    {
      "epoch": 0.12915432968633722,
      "grad_norm": 0.014234231784939766,
      "learning_rate": 8.708456703136628e-06,
      "loss": 0.0006,
      "step": 8157
    },
    {
      "epoch": 0.12917016324397929,
      "grad_norm": 0.6089038252830505,
      "learning_rate": 8.708298367560207e-06,
      "loss": 0.1521,
      "step": 8158
    },
    {
      "epoch": 0.12918599680162135,
      "grad_norm": 0.011424481868743896,
      "learning_rate": 8.708140031983788e-06,
      "loss": 0.0003,
      "step": 8159
    },
    {
      "epoch": 0.12920183035926341,
      "grad_norm": 0.23320813477039337,
      "learning_rate": 8.707981696407365e-06,
      "loss": 0.0631,
      "step": 8160
    },
    {
      "epoch": 0.12921766391690548,
      "grad_norm": 0.009851345792412758,
      "learning_rate": 8.707823360830946e-06,
      "loss": 0.0005,
      "step": 8161
    },
    {
      "epoch": 0.12923349747454754,
      "grad_norm": 0.00562779838219285,
      "learning_rate": 8.707665025254525e-06,
      "loss": 0.0002,
      "step": 8162
    },
    {
      "epoch": 0.12924933103218963,
      "grad_norm": 0.009580009616911411,
      "learning_rate": 8.707506689678104e-06,
      "loss": 0.0004,
      "step": 8163
    },
    {
      "epoch": 0.1292651645898317,
      "grad_norm": 0.4931986629962921,
      "learning_rate": 8.707348354101683e-06,
      "loss": 0.205,
      "step": 8164
    },
    {
      "epoch": 0.12928099814747376,
      "grad_norm": 0.1774183064699173,
      "learning_rate": 8.707190018525264e-06,
      "loss": 0.0648,
      "step": 8165
    },
    {
      "epoch": 0.12929683170511583,
      "grad_norm": 0.0015656913165003061,
      "learning_rate": 8.707031682948841e-06,
      "loss": 0.0001,
      "step": 8166
    },
    {
      "epoch": 0.1293126652627579,
      "grad_norm": 0.264517605304718,
      "learning_rate": 8.706873347372422e-06,
      "loss": 0.1333,
      "step": 8167
    },
    {
      "epoch": 0.12932849882039996,
      "grad_norm": 0.2546463906764984,
      "learning_rate": 8.706715011796001e-06,
      "loss": 0.0575,
      "step": 8168
    },
    {
      "epoch": 0.12934433237804202,
      "grad_norm": 0.03677321597933769,
      "learning_rate": 8.70655667621958e-06,
      "loss": 0.0018,
      "step": 8169
    },
    {
      "epoch": 0.12936016593568408,
      "grad_norm": 0.0003204178938176483,
      "learning_rate": 8.70639834064316e-06,
      "loss": 0.0,
      "step": 8170
    },
    {
      "epoch": 0.12937599949332615,
      "grad_norm": 0.5185298323631287,
      "learning_rate": 8.70624000506674e-06,
      "loss": 0.3764,
      "step": 8171
    },
    {
      "epoch": 0.1293918330509682,
      "grad_norm": 0.02595514990389347,
      "learning_rate": 8.706081669490318e-06,
      "loss": 0.0013,
      "step": 8172
    },
    {
      "epoch": 0.12940766660861028,
      "grad_norm": 0.011586342938244343,
      "learning_rate": 8.705923333913898e-06,
      "loss": 0.0005,
      "step": 8173
    },
    {
      "epoch": 0.12942350016625234,
      "grad_norm": 0.478120893239975,
      "learning_rate": 8.705764998337477e-06,
      "loss": 0.1718,
      "step": 8174
    },
    {
      "epoch": 0.12943933372389443,
      "grad_norm": 0.8627516627311707,
      "learning_rate": 8.705606662761057e-06,
      "loss": 0.0295,
      "step": 8175
    },
    {
      "epoch": 0.1294551672815365,
      "grad_norm": 0.3046315312385559,
      "learning_rate": 8.705448327184636e-06,
      "loss": 0.0408,
      "step": 8176
    },
    {
      "epoch": 0.12947100083917856,
      "grad_norm": 0.0005327247781679034,
      "learning_rate": 8.705289991608216e-06,
      "loss": 0.0,
      "step": 8177
    },
    {
      "epoch": 0.12948683439682063,
      "grad_norm": 0.0020608766935765743,
      "learning_rate": 8.705131656031794e-06,
      "loss": 0.0,
      "step": 8178
    },
    {
      "epoch": 0.1295026679544627,
      "grad_norm": 0.3709407150745392,
      "learning_rate": 8.704973320455375e-06,
      "loss": 0.1141,
      "step": 8179
    },
    {
      "epoch": 0.12951850151210476,
      "grad_norm": 0.05666010081768036,
      "learning_rate": 8.704814984878954e-06,
      "loss": 0.0035,
      "step": 8180
    },
    {
      "epoch": 0.12953433506974682,
      "grad_norm": 0.29386618733406067,
      "learning_rate": 8.704656649302533e-06,
      "loss": 0.1184,
      "step": 8181
    },
    {
      "epoch": 0.12955016862738888,
      "grad_norm": 1.041406273841858,
      "learning_rate": 8.704498313726112e-06,
      "loss": 1.1231,
      "step": 8182
    },
    {
      "epoch": 0.12956600218503095,
      "grad_norm": 0.008404480293393135,
      "learning_rate": 8.70433997814969e-06,
      "loss": 0.0004,
      "step": 8183
    },
    {
      "epoch": 0.129581835742673,
      "grad_norm": 0.5865883231163025,
      "learning_rate": 8.70418164257327e-06,
      "loss": 0.0879,
      "step": 8184
    },
    {
      "epoch": 0.12959766930031508,
      "grad_norm": 0.32479995489120483,
      "learning_rate": 8.704023306996849e-06,
      "loss": 0.0763,
      "step": 8185
    },
    {
      "epoch": 0.12961350285795714,
      "grad_norm": 0.4859764575958252,
      "learning_rate": 8.70386497142043e-06,
      "loss": 0.2047,
      "step": 8186
    },
    {
      "epoch": 0.12962933641559923,
      "grad_norm": 0.28386640548706055,
      "learning_rate": 8.703706635844009e-06,
      "loss": 0.1639,
      "step": 8187
    },
    {
      "epoch": 0.1296451699732413,
      "grad_norm": 0.012989085167646408,
      "learning_rate": 8.703548300267588e-06,
      "loss": 0.0005,
      "step": 8188
    },
    {
      "epoch": 0.12966100353088336,
      "grad_norm": 0.6346915364265442,
      "learning_rate": 8.703389964691167e-06,
      "loss": 0.1123,
      "step": 8189
    },
    {
      "epoch": 0.12967683708852543,
      "grad_norm": 0.0002437382354401052,
      "learning_rate": 8.703231629114746e-06,
      "loss": 0.0,
      "step": 8190
    },
    {
      "epoch": 0.1296926706461675,
      "grad_norm": 0.693610429763794,
      "learning_rate": 8.703073293538325e-06,
      "loss": 0.5365,
      "step": 8191
    },
    {
      "epoch": 0.12970850420380955,
      "grad_norm": 0.2629503309726715,
      "learning_rate": 8.702914957961906e-06,
      "loss": 0.1142,
      "step": 8192
    },
    {
      "epoch": 0.12972433776145162,
      "grad_norm": 0.47893449664115906,
      "learning_rate": 8.702756622385485e-06,
      "loss": 0.0874,
      "step": 8193
    },
    {
      "epoch": 0.12974017131909368,
      "grad_norm": 0.24193109571933746,
      "learning_rate": 8.702598286809064e-06,
      "loss": 0.0564,
      "step": 8194
    },
    {
      "epoch": 0.12975600487673575,
      "grad_norm": 0.0040212771855294704,
      "learning_rate": 8.702439951232643e-06,
      "loss": 0.0002,
      "step": 8195
    },
    {
      "epoch": 0.1297718384343778,
      "grad_norm": 0.016616927459836006,
      "learning_rate": 8.702281615656222e-06,
      "loss": 0.0009,
      "step": 8196
    },
    {
      "epoch": 0.12978767199201988,
      "grad_norm": 0.3176177144050598,
      "learning_rate": 8.702123280079801e-06,
      "loss": 0.308,
      "step": 8197
    },
    {
      "epoch": 0.12980350554966194,
      "grad_norm": 1.0689115524291992,
      "learning_rate": 8.701964944503382e-06,
      "loss": 0.0052,
      "step": 8198
    },
    {
      "epoch": 0.12981933910730403,
      "grad_norm": 0.5639280080795288,
      "learning_rate": 8.701806608926961e-06,
      "loss": 0.2347,
      "step": 8199
    },
    {
      "epoch": 0.1298351726649461,
      "grad_norm": 0.4146757125854492,
      "learning_rate": 8.70164827335054e-06,
      "loss": 0.2496,
      "step": 8200
    },
    {
      "epoch": 0.12985100622258816,
      "grad_norm": 0.6264491677284241,
      "learning_rate": 8.70148993777412e-06,
      "loss": 0.1403,
      "step": 8201
    },
    {
      "epoch": 0.12986683978023023,
      "grad_norm": 0.6404018402099609,
      "learning_rate": 8.701331602197698e-06,
      "loss": 0.4081,
      "step": 8202
    },
    {
      "epoch": 0.1298826733378723,
      "grad_norm": 0.4231736660003662,
      "learning_rate": 8.701173266621278e-06,
      "loss": 0.2368,
      "step": 8203
    },
    {
      "epoch": 0.12989850689551435,
      "grad_norm": 0.1941346824169159,
      "learning_rate": 8.701014931044858e-06,
      "loss": 0.0477,
      "step": 8204
    },
    {
      "epoch": 0.12991434045315642,
      "grad_norm": 0.48144546151161194,
      "learning_rate": 8.700856595468437e-06,
      "loss": 0.5789,
      "step": 8205
    },
    {
      "epoch": 0.12993017401079848,
      "grad_norm": 0.00013681130076292902,
      "learning_rate": 8.700698259892015e-06,
      "loss": 0.0,
      "step": 8206
    },
    {
      "epoch": 0.12994600756844055,
      "grad_norm": 0.3344416916370392,
      "learning_rate": 8.700539924315596e-06,
      "loss": 0.1949,
      "step": 8207
    },
    {
      "epoch": 0.1299618411260826,
      "grad_norm": 0.30045583844184875,
      "learning_rate": 8.700381588739175e-06,
      "loss": 0.0843,
      "step": 8208
    },
    {
      "epoch": 0.12997767468372468,
      "grad_norm": 0.0067877029068768024,
      "learning_rate": 8.700223253162754e-06,
      "loss": 0.0002,
      "step": 8209
    },
    {
      "epoch": 0.12999350824136674,
      "grad_norm": 0.40400686860084534,
      "learning_rate": 8.700064917586333e-06,
      "loss": 0.5092,
      "step": 8210
    },
    {
      "epoch": 0.13000934179900883,
      "grad_norm": 0.6913201808929443,
      "learning_rate": 8.699906582009912e-06,
      "loss": 0.8555,
      "step": 8211
    },
    {
      "epoch": 0.1300251753566509,
      "grad_norm": 0.2223215401172638,
      "learning_rate": 8.699748246433491e-06,
      "loss": 0.0698,
      "step": 8212
    },
    {
      "epoch": 0.13004100891429296,
      "grad_norm": 0.019936079159379005,
      "learning_rate": 8.699589910857072e-06,
      "loss": 0.0009,
      "step": 8213
    },
    {
      "epoch": 0.13005684247193502,
      "grad_norm": 0.6361702084541321,
      "learning_rate": 8.69943157528065e-06,
      "loss": 0.0343,
      "step": 8214
    },
    {
      "epoch": 0.1300726760295771,
      "grad_norm": 0.2827419340610504,
      "learning_rate": 8.69927323970423e-06,
      "loss": 0.0051,
      "step": 8215
    },
    {
      "epoch": 0.13008850958721915,
      "grad_norm": 0.26118990778923035,
      "learning_rate": 8.699114904127809e-06,
      "loss": 0.3472,
      "step": 8216
    },
    {
      "epoch": 0.13010434314486122,
      "grad_norm": 0.14774174988269806,
      "learning_rate": 8.698956568551388e-06,
      "loss": 0.0333,
      "step": 8217
    },
    {
      "epoch": 0.13012017670250328,
      "grad_norm": 0.0013324877945706248,
      "learning_rate": 8.698798232974967e-06,
      "loss": 0.0,
      "step": 8218
    },
    {
      "epoch": 0.13013601026014535,
      "grad_norm": 0.6756018400192261,
      "learning_rate": 8.698639897398548e-06,
      "loss": 0.2602,
      "step": 8219
    },
    {
      "epoch": 0.1301518438177874,
      "grad_norm": 0.6752921938896179,
      "learning_rate": 8.698481561822127e-06,
      "loss": 0.0567,
      "step": 8220
    },
    {
      "epoch": 0.13016767737542947,
      "grad_norm": 0.25800731778144836,
      "learning_rate": 8.698323226245706e-06,
      "loss": 0.1585,
      "step": 8221
    },
    {
      "epoch": 0.13018351093307154,
      "grad_norm": 0.2608742117881775,
      "learning_rate": 8.698164890669285e-06,
      "loss": 0.1045,
      "step": 8222
    },
    {
      "epoch": 0.13019934449071363,
      "grad_norm": 2.7208139896392822,
      "learning_rate": 8.698006555092864e-06,
      "loss": 0.1497,
      "step": 8223
    },
    {
      "epoch": 0.1302151780483557,
      "grad_norm": 0.002125507453456521,
      "learning_rate": 8.697848219516443e-06,
      "loss": 0.0,
      "step": 8224
    },
    {
      "epoch": 0.13023101160599776,
      "grad_norm": 0.00033412480843253434,
      "learning_rate": 8.697689883940024e-06,
      "loss": 0.0,
      "step": 8225
    },
    {
      "epoch": 0.13024684516363982,
      "grad_norm": 0.25255534052848816,
      "learning_rate": 8.697531548363603e-06,
      "loss": 0.0652,
      "step": 8226
    },
    {
      "epoch": 0.1302626787212819,
      "grad_norm": 0.7349052429199219,
      "learning_rate": 8.697373212787182e-06,
      "loss": 0.1628,
      "step": 8227
    },
    {
      "epoch": 0.13027851227892395,
      "grad_norm": 0.5144540667533875,
      "learning_rate": 8.697214877210761e-06,
      "loss": 0.2899,
      "step": 8228
    },
    {
      "epoch": 0.13029434583656602,
      "grad_norm": 0.5598294138908386,
      "learning_rate": 8.69705654163434e-06,
      "loss": 0.1323,
      "step": 8229
    },
    {
      "epoch": 0.13031017939420808,
      "grad_norm": 0.4150261878967285,
      "learning_rate": 8.69689820605792e-06,
      "loss": 0.3464,
      "step": 8230
    },
    {
      "epoch": 0.13032601295185015,
      "grad_norm": 0.09514741599559784,
      "learning_rate": 8.696739870481499e-06,
      "loss": 0.0081,
      "step": 8231
    },
    {
      "epoch": 0.1303418465094922,
      "grad_norm": 0.4954863488674164,
      "learning_rate": 8.69658153490508e-06,
      "loss": 0.5175,
      "step": 8232
    },
    {
      "epoch": 0.13035768006713427,
      "grad_norm": 0.009521601721644402,
      "learning_rate": 8.696423199328657e-06,
      "loss": 0.0003,
      "step": 8233
    },
    {
      "epoch": 0.13037351362477634,
      "grad_norm": 0.01841340772807598,
      "learning_rate": 8.696264863752237e-06,
      "loss": 0.001,
      "step": 8234
    },
    {
      "epoch": 0.13038934718241843,
      "grad_norm": 0.016952699050307274,
      "learning_rate": 8.696106528175817e-06,
      "loss": 0.0007,
      "step": 8235
    },
    {
      "epoch": 0.1304051807400605,
      "grad_norm": 0.6772618889808655,
      "learning_rate": 8.695948192599396e-06,
      "loss": 1.0121,
      "step": 8236
    },
    {
      "epoch": 0.13042101429770256,
      "grad_norm": 0.3086591362953186,
      "learning_rate": 8.695789857022975e-06,
      "loss": 0.0947,
      "step": 8237
    },
    {
      "epoch": 0.13043684785534462,
      "grad_norm": 0.5907362699508667,
      "learning_rate": 8.695631521446555e-06,
      "loss": 0.5338,
      "step": 8238
    },
    {
      "epoch": 0.1304526814129867,
      "grad_norm": 0.2567349076271057,
      "learning_rate": 8.695473185870133e-06,
      "loss": 0.1407,
      "step": 8239
    },
    {
      "epoch": 0.13046851497062875,
      "grad_norm": 0.2697027027606964,
      "learning_rate": 8.695314850293714e-06,
      "loss": 0.1214,
      "step": 8240
    },
    {
      "epoch": 0.13048434852827082,
      "grad_norm": 0.9207455515861511,
      "learning_rate": 8.695156514717293e-06,
      "loss": 0.0438,
      "step": 8241
    },
    {
      "epoch": 0.13050018208591288,
      "grad_norm": 0.2505856454372406,
      "learning_rate": 8.694998179140872e-06,
      "loss": 0.0769,
      "step": 8242
    },
    {
      "epoch": 0.13051601564355494,
      "grad_norm": 3.657839059829712,
      "learning_rate": 8.694839843564451e-06,
      "loss": 0.5404,
      "step": 8243
    },
    {
      "epoch": 0.130531849201197,
      "grad_norm": 0.3862842917442322,
      "learning_rate": 8.694681507988032e-06,
      "loss": 0.4107,
      "step": 8244
    },
    {
      "epoch": 0.13054768275883907,
      "grad_norm": 0.1620383858680725,
      "learning_rate": 8.694523172411609e-06,
      "loss": 0.0837,
      "step": 8245
    },
    {
      "epoch": 0.13056351631648114,
      "grad_norm": 0.329311728477478,
      "learning_rate": 8.69436483683519e-06,
      "loss": 0.4726,
      "step": 8246
    },
    {
      "epoch": 0.13057934987412323,
      "grad_norm": 0.44652795791625977,
      "learning_rate": 8.694206501258769e-06,
      "loss": 0.3132,
      "step": 8247
    },
    {
      "epoch": 0.1305951834317653,
      "grad_norm": 0.000849859497975558,
      "learning_rate": 8.694048165682348e-06,
      "loss": 0.0,
      "step": 8248
    },
    {
      "epoch": 0.13061101698940736,
      "grad_norm": 0.004109095316380262,
      "learning_rate": 8.693889830105927e-06,
      "loss": 0.0001,
      "step": 8249
    },
    {
      "epoch": 0.13062685054704942,
      "grad_norm": 0.20365455746650696,
      "learning_rate": 8.693731494529508e-06,
      "loss": 0.0376,
      "step": 8250
    },
    {
      "epoch": 0.1306426841046915,
      "grad_norm": 0.005958567373454571,
      "learning_rate": 8.693573158953085e-06,
      "loss": 0.0002,
      "step": 8251
    },
    {
      "epoch": 0.13065851766233355,
      "grad_norm": 0.5964998602867126,
      "learning_rate": 8.693414823376666e-06,
      "loss": 0.332,
      "step": 8252
    },
    {
      "epoch": 0.13067435121997562,
      "grad_norm": 0.25557002425193787,
      "learning_rate": 8.693256487800245e-06,
      "loss": 0.0802,
      "step": 8253
    },
    {
      "epoch": 0.13069018477761768,
      "grad_norm": 0.2241477221250534,
      "learning_rate": 8.693098152223824e-06,
      "loss": 0.0208,
      "step": 8254
    },
    {
      "epoch": 0.13070601833525974,
      "grad_norm": 0.39837488532066345,
      "learning_rate": 8.692939816647403e-06,
      "loss": 0.5491,
      "step": 8255
    },
    {
      "epoch": 0.1307218518929018,
      "grad_norm": 0.0007808181690052152,
      "learning_rate": 8.692781481070982e-06,
      "loss": 0.0,
      "step": 8256
    },
    {
      "epoch": 0.13073768545054387,
      "grad_norm": 0.8491278886795044,
      "learning_rate": 8.692623145494561e-06,
      "loss": 0.0945,
      "step": 8257
    },
    {
      "epoch": 0.13075351900818594,
      "grad_norm": 0.3354746401309967,
      "learning_rate": 8.69246480991814e-06,
      "loss": 0.0756,
      "step": 8258
    },
    {
      "epoch": 0.13076935256582803,
      "grad_norm": 0.4875522553920746,
      "learning_rate": 8.692306474341721e-06,
      "loss": 0.1961,
      "step": 8259
    },
    {
      "epoch": 0.1307851861234701,
      "grad_norm": 0.01117466576397419,
      "learning_rate": 8.6921481387653e-06,
      "loss": 0.0005,
      "step": 8260
    },
    {
      "epoch": 0.13080101968111216,
      "grad_norm": 0.26092514395713806,
      "learning_rate": 8.69198980318888e-06,
      "loss": 0.0293,
      "step": 8261
    },
    {
      "epoch": 0.13081685323875422,
      "grad_norm": 0.5475245118141174,
      "learning_rate": 8.691831467612458e-06,
      "loss": 0.4358,
      "step": 8262
    },
    {
      "epoch": 0.13083268679639629,
      "grad_norm": 0.43254101276397705,
      "learning_rate": 8.691673132036038e-06,
      "loss": 0.0422,
      "step": 8263
    },
    {
      "epoch": 0.13084852035403835,
      "grad_norm": 0.03611087054014206,
      "learning_rate": 8.691514796459617e-06,
      "loss": 0.0014,
      "step": 8264
    },
    {
      "epoch": 0.13086435391168041,
      "grad_norm": 0.6791473627090454,
      "learning_rate": 8.691356460883197e-06,
      "loss": 0.0181,
      "step": 8265
    },
    {
      "epoch": 0.13088018746932248,
      "grad_norm": 0.005575196817517281,
      "learning_rate": 8.691198125306776e-06,
      "loss": 0.0003,
      "step": 8266
    },
    {
      "epoch": 0.13089602102696454,
      "grad_norm": 0.23657172918319702,
      "learning_rate": 8.691039789730356e-06,
      "loss": 0.1086,
      "step": 8267
    },
    {
      "epoch": 0.1309118545846066,
      "grad_norm": 0.44128885865211487,
      "learning_rate": 8.690881454153935e-06,
      "loss": 0.3185,
      "step": 8268
    },
    {
      "epoch": 0.13092768814224867,
      "grad_norm": 0.5313898324966431,
      "learning_rate": 8.690723118577514e-06,
      "loss": 0.3247,
      "step": 8269
    },
    {
      "epoch": 0.13094352169989074,
      "grad_norm": 0.6273871660232544,
      "learning_rate": 8.690564783001093e-06,
      "loss": 0.1728,
      "step": 8270
    },
    {
      "epoch": 0.13095935525753283,
      "grad_norm": 0.5341108441352844,
      "learning_rate": 8.690406447424674e-06,
      "loss": 0.0481,
      "step": 8271
    },
    {
      "epoch": 0.1309751888151749,
      "grad_norm": 0.2654759883880615,
      "learning_rate": 8.690248111848251e-06,
      "loss": 0.1453,
      "step": 8272
    },
    {
      "epoch": 0.13099102237281696,
      "grad_norm": 0.34947654604911804,
      "learning_rate": 8.690089776271832e-06,
      "loss": 0.0821,
      "step": 8273
    },
    {
      "epoch": 0.13100685593045902,
      "grad_norm": 0.43860167264938354,
      "learning_rate": 8.68993144069541e-06,
      "loss": 0.1256,
      "step": 8274
    },
    {
      "epoch": 0.13102268948810109,
      "grad_norm": 0.5055347084999084,
      "learning_rate": 8.68977310511899e-06,
      "loss": 0.0905,
      "step": 8275
    },
    {
      "epoch": 0.13103852304574315,
      "grad_norm": 0.3089953064918518,
      "learning_rate": 8.689614769542569e-06,
      "loss": 0.0877,
      "step": 8276
    },
    {
      "epoch": 0.1310543566033852,
      "grad_norm": 1.090539813041687,
      "learning_rate": 8.689456433966148e-06,
      "loss": 0.5509,
      "step": 8277
    },
    {
      "epoch": 0.13107019016102728,
      "grad_norm": 0.014906550757586956,
      "learning_rate": 8.689298098389727e-06,
      "loss": 0.0006,
      "step": 8278
    },
    {
      "epoch": 0.13108602371866934,
      "grad_norm": 0.5294075608253479,
      "learning_rate": 8.689139762813306e-06,
      "loss": 0.2401,
      "step": 8279
    },
    {
      "epoch": 0.1311018572763114,
      "grad_norm": 0.3303259611129761,
      "learning_rate": 8.688981427236887e-06,
      "loss": 0.3946,
      "step": 8280
    },
    {
      "epoch": 0.13111769083395347,
      "grad_norm": 0.01792065240442753,
      "learning_rate": 8.688823091660466e-06,
      "loss": 0.001,
      "step": 8281
    },
    {
      "epoch": 0.13113352439159554,
      "grad_norm": 0.1500418335199356,
      "learning_rate": 8.688664756084045e-06,
      "loss": 0.0482,
      "step": 8282
    },
    {
      "epoch": 0.13114935794923763,
      "grad_norm": 0.2920500934123993,
      "learning_rate": 8.688506420507624e-06,
      "loss": 0.1771,
      "step": 8283
    },
    {
      "epoch": 0.1311651915068797,
      "grad_norm": 0.20679567754268646,
      "learning_rate": 8.688348084931203e-06,
      "loss": 0.0314,
      "step": 8284
    },
    {
      "epoch": 0.13118102506452176,
      "grad_norm": 0.13508696854114532,
      "learning_rate": 8.688189749354782e-06,
      "loss": 0.0101,
      "step": 8285
    },
    {
      "epoch": 0.13119685862216382,
      "grad_norm": 0.006392191629856825,
      "learning_rate": 8.688031413778363e-06,
      "loss": 0.0003,
      "step": 8286
    },
    {
      "epoch": 0.13121269217980588,
      "grad_norm": 0.42408376932144165,
      "learning_rate": 8.687873078201942e-06,
      "loss": 0.6817,
      "step": 8287
    },
    {
      "epoch": 0.13122852573744795,
      "grad_norm": 0.14901019632816315,
      "learning_rate": 8.687714742625521e-06,
      "loss": 0.0711,
      "step": 8288
    },
    {
      "epoch": 0.13124435929509,
      "grad_norm": 0.677651584148407,
      "learning_rate": 8.6875564070491e-06,
      "loss": 0.2053,
      "step": 8289
    },
    {
      "epoch": 0.13126019285273208,
      "grad_norm": 0.3227796256542206,
      "learning_rate": 8.68739807147268e-06,
      "loss": 0.0976,
      "step": 8290
    },
    {
      "epoch": 0.13127602641037414,
      "grad_norm": 0.27871009707450867,
      "learning_rate": 8.687239735896259e-06,
      "loss": 0.2911,
      "step": 8291
    },
    {
      "epoch": 0.1312918599680162,
      "grad_norm": 0.4065690338611603,
      "learning_rate": 8.68708140031984e-06,
      "loss": 0.0527,
      "step": 8292
    },
    {
      "epoch": 0.13130769352565827,
      "grad_norm": 0.29829737544059753,
      "learning_rate": 8.686923064743418e-06,
      "loss": 0.2178,
      "step": 8293
    },
    {
      "epoch": 0.13132352708330033,
      "grad_norm": 0.004868974443525076,
      "learning_rate": 8.686764729166997e-06,
      "loss": 0.0001,
      "step": 8294
    },
    {
      "epoch": 0.13133936064094243,
      "grad_norm": 0.4170897901058197,
      "learning_rate": 8.686606393590577e-06,
      "loss": 0.5433,
      "step": 8295
    },
    {
      "epoch": 0.1313551941985845,
      "grad_norm": 0.38927310705184937,
      "learning_rate": 8.686448058014156e-06,
      "loss": 0.0907,
      "step": 8296
    },
    {
      "epoch": 0.13137102775622655,
      "grad_norm": 0.26551732420921326,
      "learning_rate": 8.686289722437735e-06,
      "loss": 0.1305,
      "step": 8297
    },
    {
      "epoch": 0.13138686131386862,
      "grad_norm": 0.009937414899468422,
      "learning_rate": 8.686131386861315e-06,
      "loss": 0.0005,
      "step": 8298
    },
    {
      "epoch": 0.13140269487151068,
      "grad_norm": 0.24602943658828735,
      "learning_rate": 8.685973051284895e-06,
      "loss": 0.1344,
      "step": 8299
    },
    {
      "epoch": 0.13141852842915275,
      "grad_norm": 0.0006130696274340153,
      "learning_rate": 8.685814715708474e-06,
      "loss": 0.0,
      "step": 8300
    },
    {
      "epoch": 0.1314343619867948,
      "grad_norm": 0.5804966688156128,
      "learning_rate": 8.685656380132053e-06,
      "loss": 0.4216,
      "step": 8301
    },
    {
      "epoch": 0.13145019554443688,
      "grad_norm": 0.37834247946739197,
      "learning_rate": 8.685498044555632e-06,
      "loss": 0.1828,
      "step": 8302
    },
    {
      "epoch": 0.13146602910207894,
      "grad_norm": 0.4557780623435974,
      "learning_rate": 8.685339708979211e-06,
      "loss": 0.1788,
      "step": 8303
    },
    {
      "epoch": 0.131481862659721,
      "grad_norm": 0.2999153733253479,
      "learning_rate": 8.68518137340279e-06,
      "loss": 0.1297,
      "step": 8304
    },
    {
      "epoch": 0.13149769621736307,
      "grad_norm": 0.5391750931739807,
      "learning_rate": 8.68502303782637e-06,
      "loss": 0.1504,
      "step": 8305
    },
    {
      "epoch": 0.13151352977500513,
      "grad_norm": 0.3387605845928192,
      "learning_rate": 8.684864702249948e-06,
      "loss": 0.0883,
      "step": 8306
    },
    {
      "epoch": 0.13152936333264723,
      "grad_norm": 0.4628494381904602,
      "learning_rate": 8.684706366673529e-06,
      "loss": 0.1407,
      "step": 8307
    },
    {
      "epoch": 0.1315451968902893,
      "grad_norm": 0.05680805817246437,
      "learning_rate": 8.684548031097108e-06,
      "loss": 0.0032,
      "step": 8308
    },
    {
      "epoch": 0.13156103044793135,
      "grad_norm": 0.41441482305526733,
      "learning_rate": 8.684389695520687e-06,
      "loss": 0.7216,
      "step": 8309
    },
    {
      "epoch": 0.13157686400557342,
      "grad_norm": 0.0004958556382916868,
      "learning_rate": 8.684231359944266e-06,
      "loss": 0.0,
      "step": 8310
    },
    {
      "epoch": 0.13159269756321548,
      "grad_norm": 0.25903695821762085,
      "learning_rate": 8.684073024367847e-06,
      "loss": 0.0106,
      "step": 8311
    },
    {
      "epoch": 0.13160853112085755,
      "grad_norm": 0.5926883220672607,
      "learning_rate": 8.683914688791424e-06,
      "loss": 0.9152,
      "step": 8312
    },
    {
      "epoch": 0.1316243646784996,
      "grad_norm": 0.003500570310279727,
      "learning_rate": 8.683756353215005e-06,
      "loss": 0.0001,
      "step": 8313
    },
    {
      "epoch": 0.13164019823614168,
      "grad_norm": 0.019059862941503525,
      "learning_rate": 8.683598017638584e-06,
      "loss": 0.0011,
      "step": 8314
    },
    {
      "epoch": 0.13165603179378374,
      "grad_norm": 0.5905865430831909,
      "learning_rate": 8.683439682062163e-06,
      "loss": 0.2759,
      "step": 8315
    },
    {
      "epoch": 0.1316718653514258,
      "grad_norm": 0.2831220030784607,
      "learning_rate": 8.683281346485742e-06,
      "loss": 0.1565,
      "step": 8316
    },
    {
      "epoch": 0.13168769890906787,
      "grad_norm": 0.24517634510993958,
      "learning_rate": 8.683123010909323e-06,
      "loss": 0.0956,
      "step": 8317
    },
    {
      "epoch": 0.13170353246670993,
      "grad_norm": 0.06387946754693985,
      "learning_rate": 8.6829646753329e-06,
      "loss": 0.0027,
      "step": 8318
    },
    {
      "epoch": 0.13171936602435202,
      "grad_norm": 0.0710483267903328,
      "learning_rate": 8.682806339756481e-06,
      "loss": 0.0056,
      "step": 8319
    },
    {
      "epoch": 0.1317351995819941,
      "grad_norm": 0.3476846516132355,
      "learning_rate": 8.68264800418006e-06,
      "loss": 0.0382,
      "step": 8320
    },
    {
      "epoch": 0.13175103313963615,
      "grad_norm": 0.009625674225389957,
      "learning_rate": 8.68248966860364e-06,
      "loss": 0.0004,
      "step": 8321
    },
    {
      "epoch": 0.13176686669727822,
      "grad_norm": 0.29481709003448486,
      "learning_rate": 8.682331333027218e-06,
      "loss": 0.104,
      "step": 8322
    },
    {
      "epoch": 0.13178270025492028,
      "grad_norm": 0.4695683717727661,
      "learning_rate": 8.6821729974508e-06,
      "loss": 0.2155,
      "step": 8323
    },
    {
      "epoch": 0.13179853381256235,
      "grad_norm": 0.28325316309928894,
      "learning_rate": 8.682014661874377e-06,
      "loss": 0.0904,
      "step": 8324
    },
    {
      "epoch": 0.1318143673702044,
      "grad_norm": 0.47016867995262146,
      "learning_rate": 8.681856326297956e-06,
      "loss": 0.0714,
      "step": 8325
    },
    {
      "epoch": 0.13183020092784647,
      "grad_norm": 0.8834402561187744,
      "learning_rate": 8.681697990721536e-06,
      "loss": 0.1166,
      "step": 8326
    },
    {
      "epoch": 0.13184603448548854,
      "grad_norm": 0.17531520128250122,
      "learning_rate": 8.681539655145116e-06,
      "loss": 0.0558,
      "step": 8327
    },
    {
      "epoch": 0.1318618680431306,
      "grad_norm": 0.21117077767848969,
      "learning_rate": 8.681381319568695e-06,
      "loss": 0.1668,
      "step": 8328
    },
    {
      "epoch": 0.13187770160077267,
      "grad_norm": 0.3399542272090912,
      "learning_rate": 8.681222983992274e-06,
      "loss": 0.1642,
      "step": 8329
    },
    {
      "epoch": 0.13189353515841473,
      "grad_norm": 0.37444764375686646,
      "learning_rate": 8.681064648415853e-06,
      "loss": 0.1018,
      "step": 8330
    },
    {
      "epoch": 0.13190936871605682,
      "grad_norm": 0.003975181840360165,
      "learning_rate": 8.680906312839432e-06,
      "loss": 0.0002,
      "step": 8331
    },
    {
      "epoch": 0.1319252022736989,
      "grad_norm": 9.208969277096912e-05,
      "learning_rate": 8.680747977263013e-06,
      "loss": 0.0,
      "step": 8332
    },
    {
      "epoch": 0.13194103583134095,
      "grad_norm": 0.46660640835762024,
      "learning_rate": 8.680589641686592e-06,
      "loss": 0.0757,
      "step": 8333
    },
    {
      "epoch": 0.13195686938898302,
      "grad_norm": 0.00022605010599363595,
      "learning_rate": 8.68043130611017e-06,
      "loss": 0.0,
      "step": 8334
    },
    {
      "epoch": 0.13197270294662508,
      "grad_norm": 0.2733934223651886,
      "learning_rate": 8.68027297053375e-06,
      "loss": 0.0863,
      "step": 8335
    },
    {
      "epoch": 0.13198853650426715,
      "grad_norm": 0.7941942811012268,
      "learning_rate": 8.680114634957329e-06,
      "loss": 0.4099,
      "step": 8336
    },
    {
      "epoch": 0.1320043700619092,
      "grad_norm": 0.2671813666820526,
      "learning_rate": 8.679956299380908e-06,
      "loss": 0.2909,
      "step": 8337
    },
    {
      "epoch": 0.13202020361955127,
      "grad_norm": 0.49181637167930603,
      "learning_rate": 8.679797963804489e-06,
      "loss": 0.4246,
      "step": 8338
    },
    {
      "epoch": 0.13203603717719334,
      "grad_norm": 0.4220915138721466,
      "learning_rate": 8.679639628228066e-06,
      "loss": 0.0857,
      "step": 8339
    },
    {
      "epoch": 0.1320518707348354,
      "grad_norm": 0.0022095104213804007,
      "learning_rate": 8.679481292651647e-06,
      "loss": 0.0001,
      "step": 8340
    },
    {
      "epoch": 0.13206770429247747,
      "grad_norm": 0.28208649158477783,
      "learning_rate": 8.679322957075226e-06,
      "loss": 0.0657,
      "step": 8341
    },
    {
      "epoch": 0.13208353785011953,
      "grad_norm": 0.35923150181770325,
      "learning_rate": 8.679164621498805e-06,
      "loss": 0.1911,
      "step": 8342
    },
    {
      "epoch": 0.13209937140776162,
      "grad_norm": 0.000419404124841094,
      "learning_rate": 8.679006285922384e-06,
      "loss": 0.0,
      "step": 8343
    },
    {
      "epoch": 0.1321152049654037,
      "grad_norm": 0.42216745018959045,
      "learning_rate": 8.678847950345965e-06,
      "loss": 0.2498,
      "step": 8344
    },
    {
      "epoch": 0.13213103852304575,
      "grad_norm": 0.981109082698822,
      "learning_rate": 8.678689614769542e-06,
      "loss": 0.6406,
      "step": 8345
    },
    {
      "epoch": 0.13214687208068782,
      "grad_norm": 0.012202826328575611,
      "learning_rate": 8.678531279193123e-06,
      "loss": 0.0005,
      "step": 8346
    },
    {
      "epoch": 0.13216270563832988,
      "grad_norm": 0.1420363336801529,
      "learning_rate": 8.678372943616702e-06,
      "loss": 0.0417,
      "step": 8347
    },
    {
      "epoch": 0.13217853919597194,
      "grad_norm": 0.18038766086101532,
      "learning_rate": 8.678214608040281e-06,
      "loss": 0.0828,
      "step": 8348
    },
    {
      "epoch": 0.132194372753614,
      "grad_norm": 0.18979506194591522,
      "learning_rate": 8.67805627246386e-06,
      "loss": 0.0489,
      "step": 8349
    },
    {
      "epoch": 0.13221020631125607,
      "grad_norm": 0.7440815567970276,
      "learning_rate": 8.67789793688744e-06,
      "loss": 0.284,
      "step": 8350
    },
    {
      "epoch": 0.13222603986889814,
      "grad_norm": 0.37414732575416565,
      "learning_rate": 8.677739601311019e-06,
      "loss": 0.117,
      "step": 8351
    },
    {
      "epoch": 0.1322418734265402,
      "grad_norm": 0.2871374189853668,
      "learning_rate": 8.677581265734598e-06,
      "loss": 0.0741,
      "step": 8352
    },
    {
      "epoch": 0.13225770698418227,
      "grad_norm": 0.42084911465644836,
      "learning_rate": 8.677422930158178e-06,
      "loss": 0.1152,
      "step": 8353
    },
    {
      "epoch": 0.13227354054182433,
      "grad_norm": 0.5795340538024902,
      "learning_rate": 8.677264594581757e-06,
      "loss": 0.2351,
      "step": 8354
    },
    {
      "epoch": 0.13228937409946642,
      "grad_norm": 1.234002947807312,
      "learning_rate": 8.677106259005337e-06,
      "loss": 0.024,
      "step": 8355
    },
    {
      "epoch": 0.1323052076571085,
      "grad_norm": 0.00021341527462936938,
      "learning_rate": 8.676947923428916e-06,
      "loss": 0.0,
      "step": 8356
    },
    {
      "epoch": 0.13232104121475055,
      "grad_norm": 0.4032639265060425,
      "learning_rate": 8.676789587852495e-06,
      "loss": 0.4702,
      "step": 8357
    },
    {
      "epoch": 0.13233687477239262,
      "grad_norm": 0.3219579756259918,
      "learning_rate": 8.676631252276074e-06,
      "loss": 0.6059,
      "step": 8358
    },
    {
      "epoch": 0.13235270833003468,
      "grad_norm": 0.12513898313045502,
      "learning_rate": 8.676472916699655e-06,
      "loss": 0.0539,
      "step": 8359
    },
    {
      "epoch": 0.13236854188767674,
      "grad_norm": 0.31451985239982605,
      "learning_rate": 8.676314581123234e-06,
      "loss": 0.0804,
      "step": 8360
    },
    {
      "epoch": 0.1323843754453188,
      "grad_norm": 0.0013950193533673882,
      "learning_rate": 8.676156245546813e-06,
      "loss": 0.0,
      "step": 8361
    },
    {
      "epoch": 0.13240020900296087,
      "grad_norm": 0.3358851969242096,
      "learning_rate": 8.675997909970392e-06,
      "loss": 0.1107,
      "step": 8362
    },
    {
      "epoch": 0.13241604256060294,
      "grad_norm": 0.2280903160572052,
      "learning_rate": 8.675839574393971e-06,
      "loss": 0.0375,
      "step": 8363
    },
    {
      "epoch": 0.132431876118245,
      "grad_norm": 0.021371375769376755,
      "learning_rate": 8.67568123881755e-06,
      "loss": 0.0011,
      "step": 8364
    },
    {
      "epoch": 0.13244770967588707,
      "grad_norm": 0.24987514317035675,
      "learning_rate": 8.67552290324113e-06,
      "loss": 0.0944,
      "step": 8365
    },
    {
      "epoch": 0.13246354323352913,
      "grad_norm": 0.006018944550305605,
      "learning_rate": 8.67536456766471e-06,
      "loss": 0.0002,
      "step": 8366
    },
    {
      "epoch": 0.13247937679117122,
      "grad_norm": 0.301201730966568,
      "learning_rate": 8.675206232088289e-06,
      "loss": 0.1663,
      "step": 8367
    },
    {
      "epoch": 0.13249521034881329,
      "grad_norm": 0.28344497084617615,
      "learning_rate": 8.675047896511868e-06,
      "loss": 0.0473,
      "step": 8368
    },
    {
      "epoch": 0.13251104390645535,
      "grad_norm": 0.3942604959011078,
      "learning_rate": 8.674889560935447e-06,
      "loss": 0.109,
      "step": 8369
    },
    {
      "epoch": 0.13252687746409741,
      "grad_norm": 0.2517523765563965,
      "learning_rate": 8.674731225359026e-06,
      "loss": 0.061,
      "step": 8370
    },
    {
      "epoch": 0.13254271102173948,
      "grad_norm": 0.04541116952896118,
      "learning_rate": 8.674572889782607e-06,
      "loss": 0.0012,
      "step": 8371
    },
    {
      "epoch": 0.13255854457938154,
      "grad_norm": 0.3289043605327606,
      "learning_rate": 8.674414554206186e-06,
      "loss": 0.0957,
      "step": 8372
    },
    {
      "epoch": 0.1325743781370236,
      "grad_norm": 0.273896187543869,
      "learning_rate": 8.674256218629763e-06,
      "loss": 0.0952,
      "step": 8373
    },
    {
      "epoch": 0.13259021169466567,
      "grad_norm": 0.5652058720588684,
      "learning_rate": 8.674097883053344e-06,
      "loss": 0.1641,
      "step": 8374
    },
    {
      "epoch": 0.13260604525230774,
      "grad_norm": 0.012005507946014404,
      "learning_rate": 8.673939547476923e-06,
      "loss": 0.0006,
      "step": 8375
    },
    {
      "epoch": 0.1326218788099498,
      "grad_norm": 0.297638863325119,
      "learning_rate": 8.673781211900502e-06,
      "loss": 0.219,
      "step": 8376
    },
    {
      "epoch": 0.13263771236759186,
      "grad_norm": 0.46323710680007935,
      "learning_rate": 8.673622876324081e-06,
      "loss": 0.3218,
      "step": 8377
    },
    {
      "epoch": 0.13265354592523393,
      "grad_norm": 0.22567133605480194,
      "learning_rate": 8.673464540747662e-06,
      "loss": 0.0786,
      "step": 8378
    },
    {
      "epoch": 0.13266937948287602,
      "grad_norm": 0.01961652562022209,
      "learning_rate": 8.67330620517124e-06,
      "loss": 0.0008,
      "step": 8379
    },
    {
      "epoch": 0.13268521304051809,
      "grad_norm": 0.12816369533538818,
      "learning_rate": 8.67314786959482e-06,
      "loss": 0.0288,
      "step": 8380
    },
    {
      "epoch": 0.13270104659816015,
      "grad_norm": 0.26546770334243774,
      "learning_rate": 8.6729895340184e-06,
      "loss": 0.077,
      "step": 8381
    },
    {
      "epoch": 0.1327168801558022,
      "grad_norm": 0.012953403405845165,
      "learning_rate": 8.672831198441978e-06,
      "loss": 0.0006,
      "step": 8382
    },
    {
      "epoch": 0.13273271371344428,
      "grad_norm": 0.27251896262168884,
      "learning_rate": 8.672672862865558e-06,
      "loss": 0.1138,
      "step": 8383
    },
    {
      "epoch": 0.13274854727108634,
      "grad_norm": 0.6559261679649353,
      "learning_rate": 8.672514527289138e-06,
      "loss": 0.2158,
      "step": 8384
    },
    {
      "epoch": 0.1327643808287284,
      "grad_norm": 0.36684855818748474,
      "learning_rate": 8.672356191712716e-06,
      "loss": 0.2011,
      "step": 8385
    },
    {
      "epoch": 0.13278021438637047,
      "grad_norm": 0.48745158314704895,
      "learning_rate": 8.672197856136297e-06,
      "loss": 0.0995,
      "step": 8386
    },
    {
      "epoch": 0.13279604794401254,
      "grad_norm": 0.31995484232902527,
      "learning_rate": 8.672039520559876e-06,
      "loss": 0.1521,
      "step": 8387
    },
    {
      "epoch": 0.1328118815016546,
      "grad_norm": 0.0006752106128260493,
      "learning_rate": 8.671881184983455e-06,
      "loss": 0.0,
      "step": 8388
    },
    {
      "epoch": 0.13282771505929666,
      "grad_norm": 1.1682586669921875,
      "learning_rate": 8.671722849407034e-06,
      "loss": 0.1277,
      "step": 8389
    },
    {
      "epoch": 0.13284354861693873,
      "grad_norm": 0.37886425852775574,
      "learning_rate": 8.671564513830615e-06,
      "loss": 0.1832,
      "step": 8390
    },
    {
      "epoch": 0.13285938217458082,
      "grad_norm": 0.10977549105882645,
      "learning_rate": 8.671406178254192e-06,
      "loss": 0.014,
      "step": 8391
    },
    {
      "epoch": 0.13287521573222288,
      "grad_norm": 0.7688464522361755,
      "learning_rate": 8.671247842677773e-06,
      "loss": 0.2095,
      "step": 8392
    },
    {
      "epoch": 0.13289104928986495,
      "grad_norm": 0.30313459038734436,
      "learning_rate": 8.671089507101352e-06,
      "loss": 0.1223,
      "step": 8393
    },
    {
      "epoch": 0.132906882847507,
      "grad_norm": 0.3843415081501007,
      "learning_rate": 8.67093117152493e-06,
      "loss": 0.2631,
      "step": 8394
    },
    {
      "epoch": 0.13292271640514908,
      "grad_norm": 0.2596156895160675,
      "learning_rate": 8.67077283594851e-06,
      "loss": 0.0694,
      "step": 8395
    },
    {
      "epoch": 0.13293854996279114,
      "grad_norm": 0.36100369691848755,
      "learning_rate": 8.67061450037209e-06,
      "loss": 0.1929,
      "step": 8396
    },
    {
      "epoch": 0.1329543835204332,
      "grad_norm": 0.07046383619308472,
      "learning_rate": 8.670456164795668e-06,
      "loss": 0.0032,
      "step": 8397
    },
    {
      "epoch": 0.13297021707807527,
      "grad_norm": 0.1851537674665451,
      "learning_rate": 8.670297829219247e-06,
      "loss": 0.0261,
      "step": 8398
    },
    {
      "epoch": 0.13298605063571733,
      "grad_norm": 0.5510131120681763,
      "learning_rate": 8.670139493642828e-06,
      "loss": 0.8809,
      "step": 8399
    },
    {
      "epoch": 0.1330018841933594,
      "grad_norm": 0.36010169982910156,
      "learning_rate": 8.669981158066407e-06,
      "loss": 0.1245,
      "step": 8400
    },
    {
      "epoch": 0.13301771775100146,
      "grad_norm": 0.019044620916247368,
      "learning_rate": 8.669822822489986e-06,
      "loss": 0.0008,
      "step": 8401
    },
    {
      "epoch": 0.13303355130864353,
      "grad_norm": 0.2945345640182495,
      "learning_rate": 8.669664486913565e-06,
      "loss": 0.0779,
      "step": 8402
    },
    {
      "epoch": 0.13304938486628562,
      "grad_norm": 0.2641146779060364,
      "learning_rate": 8.669506151337144e-06,
      "loss": 0.0956,
      "step": 8403
    },
    {
      "epoch": 0.13306521842392768,
      "grad_norm": 0.1987462341785431,
      "learning_rate": 8.669347815760723e-06,
      "loss": 0.0421,
      "step": 8404
    },
    {
      "epoch": 0.13308105198156975,
      "grad_norm": 0.15684694051742554,
      "learning_rate": 8.669189480184304e-06,
      "loss": 0.039,
      "step": 8405
    },
    {
      "epoch": 0.1330968855392118,
      "grad_norm": 0.6791397929191589,
      "learning_rate": 8.669031144607881e-06,
      "loss": 0.0789,
      "step": 8406
    },
    {
      "epoch": 0.13311271909685388,
      "grad_norm": 0.5383045673370361,
      "learning_rate": 8.668872809031462e-06,
      "loss": 0.425,
      "step": 8407
    },
    {
      "epoch": 0.13312855265449594,
      "grad_norm": 0.5510823130607605,
      "learning_rate": 8.668714473455041e-06,
      "loss": 0.6812,
      "step": 8408
    },
    {
      "epoch": 0.133144386212138,
      "grad_norm": 0.31691619753837585,
      "learning_rate": 8.66855613787862e-06,
      "loss": 0.1527,
      "step": 8409
    },
    {
      "epoch": 0.13316021976978007,
      "grad_norm": 0.37060073018074036,
      "learning_rate": 8.6683978023022e-06,
      "loss": 0.2277,
      "step": 8410
    },
    {
      "epoch": 0.13317605332742213,
      "grad_norm": 6.719498634338379,
      "learning_rate": 8.66823946672578e-06,
      "loss": 0.3352,
      "step": 8411
    },
    {
      "epoch": 0.1331918868850642,
      "grad_norm": 0.6462041139602661,
      "learning_rate": 8.668081131149358e-06,
      "loss": 0.099,
      "step": 8412
    },
    {
      "epoch": 0.13320772044270626,
      "grad_norm": 0.46986865997314453,
      "learning_rate": 8.667922795572938e-06,
      "loss": 0.1948,
      "step": 8413
    },
    {
      "epoch": 0.13322355400034833,
      "grad_norm": 0.008970316499471664,
      "learning_rate": 8.667764459996518e-06,
      "loss": 0.0003,
      "step": 8414
    },
    {
      "epoch": 0.13323938755799042,
      "grad_norm": 0.45639127492904663,
      "learning_rate": 8.667606124420097e-06,
      "loss": 0.261,
      "step": 8415
    },
    {
      "epoch": 0.13325522111563248,
      "grad_norm": 0.44514426589012146,
      "learning_rate": 8.667447788843676e-06,
      "loss": 0.1507,
      "step": 8416
    },
    {
      "epoch": 0.13327105467327455,
      "grad_norm": 0.2852851450443268,
      "learning_rate": 8.667289453267256e-06,
      "loss": 0.0477,
      "step": 8417
    },
    {
      "epoch": 0.1332868882309166,
      "grad_norm": 0.13529108464717865,
      "learning_rate": 8.667131117690834e-06,
      "loss": 0.0502,
      "step": 8418
    },
    {
      "epoch": 0.13330272178855868,
      "grad_norm": 0.30116283893585205,
      "learning_rate": 8.666972782114415e-06,
      "loss": 0.1596,
      "step": 8419
    },
    {
      "epoch": 0.13331855534620074,
      "grad_norm": 0.04156512767076492,
      "learning_rate": 8.666814446537994e-06,
      "loss": 0.0008,
      "step": 8420
    },
    {
      "epoch": 0.1333343889038428,
      "grad_norm": 0.5235193371772766,
      "learning_rate": 8.666656110961573e-06,
      "loss": 0.4997,
      "step": 8421
    },
    {
      "epoch": 0.13335022246148487,
      "grad_norm": 0.30481433868408203,
      "learning_rate": 8.666497775385152e-06,
      "loss": 0.2401,
      "step": 8422
    },
    {
      "epoch": 0.13336605601912693,
      "grad_norm": 0.0003799562400672585,
      "learning_rate": 8.666339439808731e-06,
      "loss": 0.0,
      "step": 8423
    },
    {
      "epoch": 0.133381889576769,
      "grad_norm": 0.2762567400932312,
      "learning_rate": 8.66618110423231e-06,
      "loss": 0.0877,
      "step": 8424
    },
    {
      "epoch": 0.13339772313441106,
      "grad_norm": 0.411482036113739,
      "learning_rate": 8.666022768655889e-06,
      "loss": 0.0554,
      "step": 8425
    },
    {
      "epoch": 0.13341355669205313,
      "grad_norm": 0.38808730244636536,
      "learning_rate": 8.66586443307947e-06,
      "loss": 0.083,
      "step": 8426
    },
    {
      "epoch": 0.13342939024969522,
      "grad_norm": 0.022349972277879715,
      "learning_rate": 8.665706097503049e-06,
      "loss": 0.0011,
      "step": 8427
    },
    {
      "epoch": 0.13344522380733728,
      "grad_norm": 0.09236765652894974,
      "learning_rate": 8.665547761926628e-06,
      "loss": 0.0095,
      "step": 8428
    },
    {
      "epoch": 0.13346105736497935,
      "grad_norm": 0.6435990929603577,
      "learning_rate": 8.665389426350207e-06,
      "loss": 0.313,
      "step": 8429
    },
    {
      "epoch": 0.1334768909226214,
      "grad_norm": 0.0004498787166085094,
      "learning_rate": 8.665231090773786e-06,
      "loss": 0.0,
      "step": 8430
    },
    {
      "epoch": 0.13349272448026347,
      "grad_norm": 0.840199887752533,
      "learning_rate": 8.665072755197365e-06,
      "loss": 0.184,
      "step": 8431
    },
    {
      "epoch": 0.13350855803790554,
      "grad_norm": 0.547723114490509,
      "learning_rate": 8.664914419620946e-06,
      "loss": 0.1574,
      "step": 8432
    },
    {
      "epoch": 0.1335243915955476,
      "grad_norm": 0.23850221931934357,
      "learning_rate": 8.664756084044525e-06,
      "loss": 0.1064,
      "step": 8433
    },
    {
      "epoch": 0.13354022515318967,
      "grad_norm": 0.29495498538017273,
      "learning_rate": 8.664597748468104e-06,
      "loss": 0.1425,
      "step": 8434
    },
    {
      "epoch": 0.13355605871083173,
      "grad_norm": 0.19465021789073944,
      "learning_rate": 8.664439412891683e-06,
      "loss": 0.012,
      "step": 8435
    },
    {
      "epoch": 0.1335718922684738,
      "grad_norm": 0.30937787890434265,
      "learning_rate": 8.664281077315262e-06,
      "loss": 0.1876,
      "step": 8436
    },
    {
      "epoch": 0.13358772582611586,
      "grad_norm": 0.3374907076358795,
      "learning_rate": 8.664122741738841e-06,
      "loss": 0.0311,
      "step": 8437
    },
    {
      "epoch": 0.13360355938375792,
      "grad_norm": 0.4766077697277069,
      "learning_rate": 8.663964406162422e-06,
      "loss": 0.3264,
      "step": 8438
    },
    {
      "epoch": 0.13361939294140002,
      "grad_norm": 0.016064515337347984,
      "learning_rate": 8.663806070586001e-06,
      "loss": 0.001,
      "step": 8439
    },
    {
      "epoch": 0.13363522649904208,
      "grad_norm": 0.4151016175746918,
      "learning_rate": 8.66364773500958e-06,
      "loss": 0.1248,
      "step": 8440
    },
    {
      "epoch": 0.13365106005668415,
      "grad_norm": 0.1351788192987442,
      "learning_rate": 8.66348939943316e-06,
      "loss": 0.0326,
      "step": 8441
    },
    {
      "epoch": 0.1336668936143262,
      "grad_norm": 1.2041229009628296,
      "learning_rate": 8.663331063856739e-06,
      "loss": 0.0144,
      "step": 8442
    },
    {
      "epoch": 0.13368272717196827,
      "grad_norm": 0.199617400765419,
      "learning_rate": 8.663172728280318e-06,
      "loss": 0.0416,
      "step": 8443
    },
    {
      "epoch": 0.13369856072961034,
      "grad_norm": 0.021004298701882362,
      "learning_rate": 8.663014392703898e-06,
      "loss": 0.0011,
      "step": 8444
    },
    {
      "epoch": 0.1337143942872524,
      "grad_norm": 0.547562837600708,
      "learning_rate": 8.662856057127477e-06,
      "loss": 0.1443,
      "step": 8445
    },
    {
      "epoch": 0.13373022784489447,
      "grad_norm": 0.016236357390880585,
      "learning_rate": 8.662697721551055e-06,
      "loss": 0.0008,
      "step": 8446
    },
    {
      "epoch": 0.13374606140253653,
      "grad_norm": 0.4803644120693207,
      "learning_rate": 8.662539385974636e-06,
      "loss": 0.1708,
      "step": 8447
    },
    {
      "epoch": 0.1337618949601786,
      "grad_norm": 0.542343258857727,
      "learning_rate": 8.662381050398215e-06,
      "loss": 0.245,
      "step": 8448
    },
    {
      "epoch": 0.13377772851782066,
      "grad_norm": 0.0006958332960493863,
      "learning_rate": 8.662222714821794e-06,
      "loss": 0.0,
      "step": 8449
    },
    {
      "epoch": 0.13379356207546272,
      "grad_norm": 0.3186657726764679,
      "learning_rate": 8.662064379245373e-06,
      "loss": 0.13,
      "step": 8450
    },
    {
      "epoch": 0.1338093956331048,
      "grad_norm": 0.08145496994256973,
      "learning_rate": 8.661906043668954e-06,
      "loss": 0.0022,
      "step": 8451
    },
    {
      "epoch": 0.13382522919074688,
      "grad_norm": 0.33391690254211426,
      "learning_rate": 8.661747708092531e-06,
      "loss": 0.6945,
      "step": 8452
    },
    {
      "epoch": 0.13384106274838894,
      "grad_norm": 0.3944331407546997,
      "learning_rate": 8.661589372516112e-06,
      "loss": 0.2027,
      "step": 8453
    },
    {
      "epoch": 0.133856896306031,
      "grad_norm": 0.43767616152763367,
      "learning_rate": 8.661431036939691e-06,
      "loss": 0.2048,
      "step": 8454
    },
    {
      "epoch": 0.13387272986367307,
      "grad_norm": 0.431027352809906,
      "learning_rate": 8.66127270136327e-06,
      "loss": 0.362,
      "step": 8455
    },
    {
      "epoch": 0.13388856342131514,
      "grad_norm": 1.128892183303833,
      "learning_rate": 8.661114365786849e-06,
      "loss": 0.384,
      "step": 8456
    },
    {
      "epoch": 0.1339043969789572,
      "grad_norm": 0.4133719205856323,
      "learning_rate": 8.66095603021043e-06,
      "loss": 0.1103,
      "step": 8457
    },
    {
      "epoch": 0.13392023053659927,
      "grad_norm": 0.34233200550079346,
      "learning_rate": 8.660797694634007e-06,
      "loss": 0.1287,
      "step": 8458
    },
    {
      "epoch": 0.13393606409424133,
      "grad_norm": 0.2485070824623108,
      "learning_rate": 8.660639359057588e-06,
      "loss": 0.0295,
      "step": 8459
    },
    {
      "epoch": 0.1339518976518834,
      "grad_norm": 0.23747694492340088,
      "learning_rate": 8.660481023481167e-06,
      "loss": 0.0252,
      "step": 8460
    },
    {
      "epoch": 0.13396773120952546,
      "grad_norm": 0.30729353427886963,
      "learning_rate": 8.660322687904746e-06,
      "loss": 0.0233,
      "step": 8461
    },
    {
      "epoch": 0.13398356476716752,
      "grad_norm": 0.5325820446014404,
      "learning_rate": 8.660164352328325e-06,
      "loss": 0.3956,
      "step": 8462
    },
    {
      "epoch": 0.1339993983248096,
      "grad_norm": 0.17272426187992096,
      "learning_rate": 8.660006016751904e-06,
      "loss": 0.0535,
      "step": 8463
    },
    {
      "epoch": 0.13401523188245168,
      "grad_norm": 0.30405503511428833,
      "learning_rate": 8.659847681175483e-06,
      "loss": 0.0544,
      "step": 8464
    },
    {
      "epoch": 0.13403106544009374,
      "grad_norm": 0.3081548511981964,
      "learning_rate": 8.659689345599064e-06,
      "loss": 0.1663,
      "step": 8465
    },
    {
      "epoch": 0.1340468989977358,
      "grad_norm": 0.2814043164253235,
      "learning_rate": 8.659531010022643e-06,
      "loss": 0.2523,
      "step": 8466
    },
    {
      "epoch": 0.13406273255537787,
      "grad_norm": 0.004546895157545805,
      "learning_rate": 8.659372674446222e-06,
      "loss": 0.0001,
      "step": 8467
    },
    {
      "epoch": 0.13407856611301994,
      "grad_norm": 0.24031966924667358,
      "learning_rate": 8.659214338869801e-06,
      "loss": 0.0728,
      "step": 8468
    },
    {
      "epoch": 0.134094399670662,
      "grad_norm": 0.030250413343310356,
      "learning_rate": 8.65905600329338e-06,
      "loss": 0.0013,
      "step": 8469
    },
    {
      "epoch": 0.13411023322830407,
      "grad_norm": 0.024872377514839172,
      "learning_rate": 8.65889766771696e-06,
      "loss": 0.0013,
      "step": 8470
    },
    {
      "epoch": 0.13412606678594613,
      "grad_norm": 0.38494935631752014,
      "learning_rate": 8.658739332140539e-06,
      "loss": 0.1582,
      "step": 8471
    },
    {
      "epoch": 0.1341419003435882,
      "grad_norm": 0.2923087477684021,
      "learning_rate": 8.65858099656412e-06,
      "loss": 0.1985,
      "step": 8472
    },
    {
      "epoch": 0.13415773390123026,
      "grad_norm": 0.0003647278936114162,
      "learning_rate": 8.658422660987697e-06,
      "loss": 0.0,
      "step": 8473
    },
    {
      "epoch": 0.13417356745887232,
      "grad_norm": 0.29336434602737427,
      "learning_rate": 8.658264325411278e-06,
      "loss": 0.3628,
      "step": 8474
    },
    {
      "epoch": 0.1341894010165144,
      "grad_norm": 0.37626099586486816,
      "learning_rate": 8.658105989834857e-06,
      "loss": 0.2301,
      "step": 8475
    },
    {
      "epoch": 0.13420523457415648,
      "grad_norm": 0.4328480362892151,
      "learning_rate": 8.657947654258436e-06,
      "loss": 0.3125,
      "step": 8476
    },
    {
      "epoch": 0.13422106813179854,
      "grad_norm": 0.6151220798492432,
      "learning_rate": 8.657789318682015e-06,
      "loss": 0.1556,
      "step": 8477
    },
    {
      "epoch": 0.1342369016894406,
      "grad_norm": 0.2823752164840698,
      "learning_rate": 8.657630983105596e-06,
      "loss": 0.2365,
      "step": 8478
    },
    {
      "epoch": 0.13425273524708267,
      "grad_norm": 0.00046659293002448976,
      "learning_rate": 8.657472647529173e-06,
      "loss": 0.0,
      "step": 8479
    },
    {
      "epoch": 0.13426856880472474,
      "grad_norm": 0.5665479302406311,
      "learning_rate": 8.657314311952754e-06,
      "loss": 0.6551,
      "step": 8480
    },
    {
      "epoch": 0.1342844023623668,
      "grad_norm": 0.5174292325973511,
      "learning_rate": 8.657155976376333e-06,
      "loss": 0.6397,
      "step": 8481
    },
    {
      "epoch": 0.13430023592000886,
      "grad_norm": 1.6812975406646729,
      "learning_rate": 8.656997640799912e-06,
      "loss": 0.2403,
      "step": 8482
    },
    {
      "epoch": 0.13431606947765093,
      "grad_norm": 0.3092089891433716,
      "learning_rate": 8.656839305223491e-06,
      "loss": 0.2018,
      "step": 8483
    },
    {
      "epoch": 0.134331903035293,
      "grad_norm": 0.013334342278540134,
      "learning_rate": 8.656680969647072e-06,
      "loss": 0.0008,
      "step": 8484
    },
    {
      "epoch": 0.13434773659293506,
      "grad_norm": 0.2878175973892212,
      "learning_rate": 8.656522634070649e-06,
      "loss": 0.0365,
      "step": 8485
    },
    {
      "epoch": 0.13436357015057712,
      "grad_norm": 0.36156609654426575,
      "learning_rate": 8.65636429849423e-06,
      "loss": 0.2005,
      "step": 8486
    },
    {
      "epoch": 0.13437940370821919,
      "grad_norm": 0.2142702043056488,
      "learning_rate": 8.656205962917809e-06,
      "loss": 0.0423,
      "step": 8487
    },
    {
      "epoch": 0.13439523726586128,
      "grad_norm": 0.6081252098083496,
      "learning_rate": 8.656047627341388e-06,
      "loss": 0.5258,
      "step": 8488
    },
    {
      "epoch": 0.13441107082350334,
      "grad_norm": 0.30133384466171265,
      "learning_rate": 8.655889291764967e-06,
      "loss": 0.1533,
      "step": 8489
    },
    {
      "epoch": 0.1344269043811454,
      "grad_norm": 0.03638528287410736,
      "learning_rate": 8.655730956188548e-06,
      "loss": 0.0021,
      "step": 8490
    },
    {
      "epoch": 0.13444273793878747,
      "grad_norm": 0.03811738267540932,
      "learning_rate": 8.655572620612125e-06,
      "loss": 0.0027,
      "step": 8491
    },
    {
      "epoch": 0.13445857149642954,
      "grad_norm": 0.32657960057258606,
      "learning_rate": 8.655414285035706e-06,
      "loss": 0.1113,
      "step": 8492
    },
    {
      "epoch": 0.1344744050540716,
      "grad_norm": 0.36931443214416504,
      "learning_rate": 8.655255949459285e-06,
      "loss": 0.3997,
      "step": 8493
    },
    {
      "epoch": 0.13449023861171366,
      "grad_norm": 0.0003795971570070833,
      "learning_rate": 8.655097613882864e-06,
      "loss": 0.0,
      "step": 8494
    },
    {
      "epoch": 0.13450607216935573,
      "grad_norm": 0.4730840027332306,
      "learning_rate": 8.654939278306443e-06,
      "loss": 0.5311,
      "step": 8495
    },
    {
      "epoch": 0.1345219057269978,
      "grad_norm": 0.24040533602237701,
      "learning_rate": 8.654780942730022e-06,
      "loss": 0.2557,
      "step": 8496
    },
    {
      "epoch": 0.13453773928463986,
      "grad_norm": 1.2880921363830566,
      "learning_rate": 8.654622607153601e-06,
      "loss": 0.1866,
      "step": 8497
    },
    {
      "epoch": 0.13455357284228192,
      "grad_norm": 0.02054169587790966,
      "learning_rate": 8.65446427157718e-06,
      "loss": 0.0011,
      "step": 8498
    },
    {
      "epoch": 0.13456940639992399,
      "grad_norm": 0.24773816764354706,
      "learning_rate": 8.654305936000761e-06,
      "loss": 0.0323,
      "step": 8499
    },
    {
      "epoch": 0.13458523995756608,
      "grad_norm": 0.46130236983299255,
      "learning_rate": 8.65414760042434e-06,
      "loss": 0.0909,
      "step": 8500
    },
    {
      "epoch": 0.13460107351520814,
      "grad_norm": 0.013149849139153957,
      "learning_rate": 8.65398926484792e-06,
      "loss": 0.0005,
      "step": 8501
    },
    {
      "epoch": 0.1346169070728502,
      "grad_norm": 0.0002893266500905156,
      "learning_rate": 8.653830929271499e-06,
      "loss": 0.0,
      "step": 8502
    },
    {
      "epoch": 0.13463274063049227,
      "grad_norm": 0.0005979527486488223,
      "learning_rate": 8.653672593695078e-06,
      "loss": 0.0,
      "step": 8503
    },
    {
      "epoch": 0.13464857418813433,
      "grad_norm": 0.5117812156677246,
      "learning_rate": 8.653514258118657e-06,
      "loss": 0.5076,
      "step": 8504
    },
    {
      "epoch": 0.1346644077457764,
      "grad_norm": 0.033715806901454926,
      "learning_rate": 8.653355922542237e-06,
      "loss": 0.0006,
      "step": 8505
    },
    {
      "epoch": 0.13468024130341846,
      "grad_norm": 0.4063294529914856,
      "learning_rate": 8.653197586965817e-06,
      "loss": 0.1049,
      "step": 8506
    },
    {
      "epoch": 0.13469607486106053,
      "grad_norm": 0.2248060256242752,
      "learning_rate": 8.653039251389396e-06,
      "loss": 0.104,
      "step": 8507
    },
    {
      "epoch": 0.1347119084187026,
      "grad_norm": 0.16645650565624237,
      "learning_rate": 8.652880915812975e-06,
      "loss": 0.056,
      "step": 8508
    },
    {
      "epoch": 0.13472774197634466,
      "grad_norm": 0.0034683288540691137,
      "learning_rate": 8.652722580236554e-06,
      "loss": 0.0002,
      "step": 8509
    },
    {
      "epoch": 0.13474357553398672,
      "grad_norm": 0.0003173853037878871,
      "learning_rate": 8.652564244660133e-06,
      "loss": 0.0,
      "step": 8510
    },
    {
      "epoch": 0.13475940909162878,
      "grad_norm": 0.42327019572257996,
      "learning_rate": 8.652405909083714e-06,
      "loss": 0.1601,
      "step": 8511
    },
    {
      "epoch": 0.13477524264927088,
      "grad_norm": 0.3280664086341858,
      "learning_rate": 8.652247573507293e-06,
      "loss": 0.17,
      "step": 8512
    },
    {
      "epoch": 0.13479107620691294,
      "grad_norm": 0.2922542989253998,
      "learning_rate": 8.652089237930872e-06,
      "loss": 0.1379,
      "step": 8513
    },
    {
      "epoch": 0.134806909764555,
      "grad_norm": 0.005637906026095152,
      "learning_rate": 8.651930902354451e-06,
      "loss": 0.0002,
      "step": 8514
    },
    {
      "epoch": 0.13482274332219707,
      "grad_norm": 0.21817900240421295,
      "learning_rate": 8.65177256677803e-06,
      "loss": 0.2653,
      "step": 8515
    },
    {
      "epoch": 0.13483857687983913,
      "grad_norm": 0.46603623032569885,
      "learning_rate": 8.651614231201609e-06,
      "loss": 0.3736,
      "step": 8516
    },
    {
      "epoch": 0.1348544104374812,
      "grad_norm": 0.01924273557960987,
      "learning_rate": 8.65145589562519e-06,
      "loss": 0.0009,
      "step": 8517
    },
    {
      "epoch": 0.13487024399512326,
      "grad_norm": 0.28341975808143616,
      "learning_rate": 8.651297560048769e-06,
      "loss": 0.0752,
      "step": 8518
    },
    {
      "epoch": 0.13488607755276533,
      "grad_norm": 0.24328923225402832,
      "learning_rate": 8.651139224472346e-06,
      "loss": 0.1313,
      "step": 8519
    },
    {
      "epoch": 0.1349019111104074,
      "grad_norm": 0.5859659910202026,
      "learning_rate": 8.650980888895927e-06,
      "loss": 0.1954,
      "step": 8520
    },
    {
      "epoch": 0.13491774466804946,
      "grad_norm": 0.0005327541148290038,
      "learning_rate": 8.650822553319506e-06,
      "loss": 0.0,
      "step": 8521
    },
    {
      "epoch": 0.13493357822569152,
      "grad_norm": 0.42310258746147156,
      "learning_rate": 8.650664217743085e-06,
      "loss": 0.1658,
      "step": 8522
    },
    {
      "epoch": 0.13494941178333358,
      "grad_norm": 0.0011261089239269495,
      "learning_rate": 8.650505882166664e-06,
      "loss": 0.0,
      "step": 8523
    },
    {
      "epoch": 0.13496524534097568,
      "grad_norm": 0.2701151967048645,
      "learning_rate": 8.650347546590245e-06,
      "loss": 0.1003,
      "step": 8524
    },
    {
      "epoch": 0.13498107889861774,
      "grad_norm": 0.1136142686009407,
      "learning_rate": 8.650189211013822e-06,
      "loss": 0.002,
      "step": 8525
    },
    {
      "epoch": 0.1349969124562598,
      "grad_norm": 0.26299798488616943,
      "learning_rate": 8.650030875437403e-06,
      "loss": 0.0865,
      "step": 8526
    },
    {
      "epoch": 0.13501274601390187,
      "grad_norm": 0.43704524636268616,
      "learning_rate": 8.649872539860982e-06,
      "loss": 0.1631,
      "step": 8527
    },
    {
      "epoch": 0.13502857957154393,
      "grad_norm": 0.35352468490600586,
      "learning_rate": 8.649714204284561e-06,
      "loss": 0.1111,
      "step": 8528
    },
    {
      "epoch": 0.135044413129186,
      "grad_norm": 0.48987600207328796,
      "learning_rate": 8.64955586870814e-06,
      "loss": 0.2374,
      "step": 8529
    },
    {
      "epoch": 0.13506024668682806,
      "grad_norm": 0.23369677364826202,
      "learning_rate": 8.64939753313172e-06,
      "loss": 0.099,
      "step": 8530
    },
    {
      "epoch": 0.13507608024447013,
      "grad_norm": 0.1541951447725296,
      "learning_rate": 8.649239197555299e-06,
      "loss": 0.0041,
      "step": 8531
    },
    {
      "epoch": 0.1350919138021122,
      "grad_norm": 1.3452668190002441,
      "learning_rate": 8.64908086197888e-06,
      "loss": 1.0875,
      "step": 8532
    },
    {
      "epoch": 0.13510774735975425,
      "grad_norm": 0.0003233336901757866,
      "learning_rate": 8.648922526402458e-06,
      "loss": 0.0,
      "step": 8533
    },
    {
      "epoch": 0.13512358091739632,
      "grad_norm": 0.3871762752532959,
      "learning_rate": 8.648764190826038e-06,
      "loss": 0.3147,
      "step": 8534
    },
    {
      "epoch": 0.13513941447503838,
      "grad_norm": 0.39145582914352417,
      "learning_rate": 8.648605855249617e-06,
      "loss": 0.3275,
      "step": 8535
    },
    {
      "epoch": 0.13515524803268048,
      "grad_norm": 0.00044495565816760063,
      "learning_rate": 8.648447519673196e-06,
      "loss": 0.0,
      "step": 8536
    },
    {
      "epoch": 0.13517108159032254,
      "grad_norm": 1.260294795036316,
      "learning_rate": 8.648289184096775e-06,
      "loss": 0.0461,
      "step": 8537
    },
    {
      "epoch": 0.1351869151479646,
      "grad_norm": 0.548442542552948,
      "learning_rate": 8.648130848520356e-06,
      "loss": 0.2331,
      "step": 8538
    },
    {
      "epoch": 0.13520274870560667,
      "grad_norm": 0.6965072751045227,
      "learning_rate": 8.647972512943935e-06,
      "loss": 0.2669,
      "step": 8539
    },
    {
      "epoch": 0.13521858226324873,
      "grad_norm": 0.223317950963974,
      "learning_rate": 8.647814177367514e-06,
      "loss": 0.0078,
      "step": 8540
    },
    {
      "epoch": 0.1352344158208908,
      "grad_norm": 0.6654508113861084,
      "learning_rate": 8.647655841791093e-06,
      "loss": 0.439,
      "step": 8541
    },
    {
      "epoch": 0.13525024937853286,
      "grad_norm": 0.00020679316367022693,
      "learning_rate": 8.647497506214672e-06,
      "loss": 0.0,
      "step": 8542
    },
    {
      "epoch": 0.13526608293617493,
      "grad_norm": 0.3111797571182251,
      "learning_rate": 8.647339170638251e-06,
      "loss": 0.1521,
      "step": 8543
    },
    {
      "epoch": 0.135281916493817,
      "grad_norm": 0.4768936336040497,
      "learning_rate": 8.64718083506183e-06,
      "loss": 0.3687,
      "step": 8544
    },
    {
      "epoch": 0.13529775005145905,
      "grad_norm": 0.21864517033100128,
      "learning_rate": 8.64702249948541e-06,
      "loss": 0.0297,
      "step": 8545
    },
    {
      "epoch": 0.13531358360910112,
      "grad_norm": 0.0201974269002676,
      "learning_rate": 8.646864163908988e-06,
      "loss": 0.0011,
      "step": 8546
    },
    {
      "epoch": 0.13532941716674318,
      "grad_norm": 0.239124596118927,
      "learning_rate": 8.646705828332569e-06,
      "loss": 0.1483,
      "step": 8547
    },
    {
      "epoch": 0.13534525072438527,
      "grad_norm": 0.38464978337287903,
      "learning_rate": 8.646547492756148e-06,
      "loss": 0.1821,
      "step": 8548
    },
    {
      "epoch": 0.13536108428202734,
      "grad_norm": 0.2509256899356842,
      "learning_rate": 8.646389157179727e-06,
      "loss": 0.1106,
      "step": 8549
    },
    {
      "epoch": 0.1353769178396694,
      "grad_norm": 0.014097110368311405,
      "learning_rate": 8.646230821603306e-06,
      "loss": 0.0007,
      "step": 8550
    },
    {
      "epoch": 0.13539275139731147,
      "grad_norm": 0.3964630961418152,
      "learning_rate": 8.646072486026887e-06,
      "loss": 0.0573,
      "step": 8551
    },
    {
      "epoch": 0.13540858495495353,
      "grad_norm": 0.05665111541748047,
      "learning_rate": 8.645914150450464e-06,
      "loss": 0.0024,
      "step": 8552
    },
    {
      "epoch": 0.1354244185125956,
      "grad_norm": 0.41958099603652954,
      "learning_rate": 8.645755814874045e-06,
      "loss": 0.1176,
      "step": 8553
    },
    {
      "epoch": 0.13544025207023766,
      "grad_norm": 0.0001816922886064276,
      "learning_rate": 8.645597479297624e-06,
      "loss": 0.0,
      "step": 8554
    },
    {
      "epoch": 0.13545608562787972,
      "grad_norm": 0.2280651330947876,
      "learning_rate": 8.645439143721203e-06,
      "loss": 0.0169,
      "step": 8555
    },
    {
      "epoch": 0.1354719191855218,
      "grad_norm": 0.16472913324832916,
      "learning_rate": 8.645280808144782e-06,
      "loss": 0.0532,
      "step": 8556
    },
    {
      "epoch": 0.13548775274316385,
      "grad_norm": 0.002558330073952675,
      "learning_rate": 8.645122472568363e-06,
      "loss": 0.0001,
      "step": 8557
    },
    {
      "epoch": 0.13550358630080592,
      "grad_norm": 0.24736681580543518,
      "learning_rate": 8.64496413699194e-06,
      "loss": 0.0821,
      "step": 8558
    },
    {
      "epoch": 0.13551941985844798,
      "grad_norm": 0.6670584082603455,
      "learning_rate": 8.644805801415521e-06,
      "loss": 0.2739,
      "step": 8559
    },
    {
      "epoch": 0.13553525341609007,
      "grad_norm": 0.7518883347511292,
      "learning_rate": 8.6446474658391e-06,
      "loss": 0.3776,
      "step": 8560
    },
    {
      "epoch": 0.13555108697373214,
      "grad_norm": 0.40364742279052734,
      "learning_rate": 8.64448913026268e-06,
      "loss": 0.121,
      "step": 8561
    },
    {
      "epoch": 0.1355669205313742,
      "grad_norm": 0.2319086790084839,
      "learning_rate": 8.644330794686259e-06,
      "loss": 0.1019,
      "step": 8562
    },
    {
      "epoch": 0.13558275408901627,
      "grad_norm": 0.6082508563995361,
      "learning_rate": 8.64417245910984e-06,
      "loss": 0.0667,
      "step": 8563
    },
    {
      "epoch": 0.13559858764665833,
      "grad_norm": 0.13507047295570374,
      "learning_rate": 8.644014123533417e-06,
      "loss": 0.0374,
      "step": 8564
    },
    {
      "epoch": 0.1356144212043004,
      "grad_norm": 0.5703637003898621,
      "learning_rate": 8.643855787956997e-06,
      "loss": 0.0801,
      "step": 8565
    },
    {
      "epoch": 0.13563025476194246,
      "grad_norm": 0.024529991671442986,
      "learning_rate": 8.643697452380577e-06,
      "loss": 0.0018,
      "step": 8566
    },
    {
      "epoch": 0.13564608831958452,
      "grad_norm": 0.599640965461731,
      "learning_rate": 8.643539116804156e-06,
      "loss": 0.7553,
      "step": 8567
    },
    {
      "epoch": 0.1356619218772266,
      "grad_norm": 0.0518852174282074,
      "learning_rate": 8.643380781227735e-06,
      "loss": 0.0009,
      "step": 8568
    },
    {
      "epoch": 0.13567775543486865,
      "grad_norm": 0.3795678913593292,
      "learning_rate": 8.643222445651314e-06,
      "loss": 0.128,
      "step": 8569
    },
    {
      "epoch": 0.13569358899251072,
      "grad_norm": 0.4934593141078949,
      "learning_rate": 8.643064110074893e-06,
      "loss": 0.739,
      "step": 8570
    },
    {
      "epoch": 0.13570942255015278,
      "grad_norm": 0.3141469657421112,
      "learning_rate": 8.642905774498472e-06,
      "loss": 0.119,
      "step": 8571
    },
    {
      "epoch": 0.13572525610779487,
      "grad_norm": 0.24123579263687134,
      "learning_rate": 8.642747438922053e-06,
      "loss": 0.0637,
      "step": 8572
    },
    {
      "epoch": 0.13574108966543694,
      "grad_norm": 0.3417268991470337,
      "learning_rate": 8.642589103345632e-06,
      "loss": 0.1139,
      "step": 8573
    },
    {
      "epoch": 0.135756923223079,
      "grad_norm": 0.27214786410331726,
      "learning_rate": 8.642430767769211e-06,
      "loss": 0.172,
      "step": 8574
    },
    {
      "epoch": 0.13577275678072107,
      "grad_norm": 0.003390665864571929,
      "learning_rate": 8.64227243219279e-06,
      "loss": 0.0001,
      "step": 8575
    },
    {
      "epoch": 0.13578859033836313,
      "grad_norm": 0.26987066864967346,
      "learning_rate": 8.642114096616369e-06,
      "loss": 0.1276,
      "step": 8576
    },
    {
      "epoch": 0.1358044238960052,
      "grad_norm": 0.37288838624954224,
      "learning_rate": 8.641955761039948e-06,
      "loss": 0.1483,
      "step": 8577
    },
    {
      "epoch": 0.13582025745364726,
      "grad_norm": 0.5325227379798889,
      "learning_rate": 8.641797425463529e-06,
      "loss": 0.2912,
      "step": 8578
    },
    {
      "epoch": 0.13583609101128932,
      "grad_norm": 0.11332806199789047,
      "learning_rate": 8.641639089887108e-06,
      "loss": 0.0395,
      "step": 8579
    },
    {
      "epoch": 0.1358519245689314,
      "grad_norm": 0.2357998788356781,
      "learning_rate": 8.641480754310687e-06,
      "loss": 0.1248,
      "step": 8580
    },
    {
      "epoch": 0.13586775812657345,
      "grad_norm": 1.7228896617889404,
      "learning_rate": 8.641322418734266e-06,
      "loss": 0.6487,
      "step": 8581
    },
    {
      "epoch": 0.13588359168421552,
      "grad_norm": 1.0392117500305176,
      "learning_rate": 8.641164083157845e-06,
      "loss": 0.5891,
      "step": 8582
    },
    {
      "epoch": 0.13589942524185758,
      "grad_norm": 0.0001831991976359859,
      "learning_rate": 8.641005747581424e-06,
      "loss": 0.0,
      "step": 8583
    },
    {
      "epoch": 0.13591525879949967,
      "grad_norm": 0.42035236954689026,
      "learning_rate": 8.640847412005005e-06,
      "loss": 0.4272,
      "step": 8584
    },
    {
      "epoch": 0.13593109235714174,
      "grad_norm": 0.18162688612937927,
      "learning_rate": 8.640689076428584e-06,
      "loss": 0.0165,
      "step": 8585
    },
    {
      "epoch": 0.1359469259147838,
      "grad_norm": 0.024545656517148018,
      "learning_rate": 8.640530740852163e-06,
      "loss": 0.0015,
      "step": 8586
    },
    {
      "epoch": 0.13596275947242586,
      "grad_norm": 1.5188926458358765,
      "learning_rate": 8.640372405275742e-06,
      "loss": 0.2494,
      "step": 8587
    },
    {
      "epoch": 0.13597859303006793,
      "grad_norm": 0.2938869297504425,
      "learning_rate": 8.640214069699321e-06,
      "loss": 0.1329,
      "step": 8588
    },
    {
      "epoch": 0.13599442658771,
      "grad_norm": 1.227275013923645,
      "learning_rate": 8.6400557341229e-06,
      "loss": 0.2059,
      "step": 8589
    },
    {
      "epoch": 0.13601026014535206,
      "grad_norm": 0.010976018384099007,
      "learning_rate": 8.63989739854648e-06,
      "loss": 0.0006,
      "step": 8590
    },
    {
      "epoch": 0.13602609370299412,
      "grad_norm": 0.0008553987718187273,
      "learning_rate": 8.63973906297006e-06,
      "loss": 0.0,
      "step": 8591
    },
    {
      "epoch": 0.1360419272606362,
      "grad_norm": 0.29276517033576965,
      "learning_rate": 8.639580727393638e-06,
      "loss": 0.0697,
      "step": 8592
    },
    {
      "epoch": 0.13605776081827825,
      "grad_norm": 0.011802825145423412,
      "learning_rate": 8.639422391817218e-06,
      "loss": 0.0003,
      "step": 8593
    },
    {
      "epoch": 0.13607359437592031,
      "grad_norm": 0.37253233790397644,
      "learning_rate": 8.639264056240798e-06,
      "loss": 0.1223,
      "step": 8594
    },
    {
      "epoch": 0.13608942793356238,
      "grad_norm": 0.22157400846481323,
      "learning_rate": 8.639105720664377e-06,
      "loss": 0.0861,
      "step": 8595
    },
    {
      "epoch": 0.13610526149120447,
      "grad_norm": 0.208885058760643,
      "learning_rate": 8.638947385087956e-06,
      "loss": 0.0615,
      "step": 8596
    },
    {
      "epoch": 0.13612109504884654,
      "grad_norm": 0.14158226549625397,
      "learning_rate": 8.638789049511535e-06,
      "loss": 0.0216,
      "step": 8597
    },
    {
      "epoch": 0.1361369286064886,
      "grad_norm": 0.23462529480457306,
      "learning_rate": 8.638630713935114e-06,
      "loss": 0.0367,
      "step": 8598
    },
    {
      "epoch": 0.13615276216413066,
      "grad_norm": 0.22122682631015778,
      "learning_rate": 8.638472378358695e-06,
      "loss": 0.1329,
      "step": 8599
    },
    {
      "epoch": 0.13616859572177273,
      "grad_norm": 0.18738499283790588,
      "learning_rate": 8.638314042782274e-06,
      "loss": 0.0379,
      "step": 8600
    },
    {
      "epoch": 0.1361844292794148,
      "grad_norm": 0.5963304042816162,
      "learning_rate": 8.638155707205853e-06,
      "loss": 0.5851,
      "step": 8601
    },
    {
      "epoch": 0.13620026283705686,
      "grad_norm": 0.460359662771225,
      "learning_rate": 8.637997371629432e-06,
      "loss": 0.1411,
      "step": 8602
    },
    {
      "epoch": 0.13621609639469892,
      "grad_norm": 0.5056143999099731,
      "learning_rate": 8.637839036053011e-06,
      "loss": 0.2975,
      "step": 8603
    },
    {
      "epoch": 0.13623192995234099,
      "grad_norm": 0.17063607275485992,
      "learning_rate": 8.63768070047659e-06,
      "loss": 0.0572,
      "step": 8604
    },
    {
      "epoch": 0.13624776350998305,
      "grad_norm": 0.0002052785421255976,
      "learning_rate": 8.63752236490017e-06,
      "loss": 0.0,
      "step": 8605
    },
    {
      "epoch": 0.13626359706762511,
      "grad_norm": 1.814904808998108,
      "learning_rate": 8.63736402932375e-06,
      "loss": 0.3617,
      "step": 8606
    },
    {
      "epoch": 0.13627943062526718,
      "grad_norm": 0.09361723810434341,
      "learning_rate": 8.637205693747329e-06,
      "loss": 0.0261,
      "step": 8607
    },
    {
      "epoch": 0.13629526418290927,
      "grad_norm": 0.47745281457901,
      "learning_rate": 8.637047358170908e-06,
      "loss": 0.1692,
      "step": 8608
    },
    {
      "epoch": 0.13631109774055133,
      "grad_norm": 0.05411485955119133,
      "learning_rate": 8.636889022594487e-06,
      "loss": 0.0104,
      "step": 8609
    },
    {
      "epoch": 0.1363269312981934,
      "grad_norm": 0.17987461388111115,
      "learning_rate": 8.636730687018066e-06,
      "loss": 0.071,
      "step": 8610
    },
    {
      "epoch": 0.13634276485583546,
      "grad_norm": 0.31056156754493713,
      "learning_rate": 8.636572351441647e-06,
      "loss": 0.0418,
      "step": 8611
    },
    {
      "epoch": 0.13635859841347753,
      "grad_norm": 0.008798176422715187,
      "learning_rate": 8.636414015865226e-06,
      "loss": 0.0006,
      "step": 8612
    },
    {
      "epoch": 0.1363744319711196,
      "grad_norm": 0.6828254461288452,
      "learning_rate": 8.636255680288805e-06,
      "loss": 0.0808,
      "step": 8613
    },
    {
      "epoch": 0.13639026552876166,
      "grad_norm": 0.1597651243209839,
      "learning_rate": 8.636097344712384e-06,
      "loss": 0.0829,
      "step": 8614
    },
    {
      "epoch": 0.13640609908640372,
      "grad_norm": 0.39510995149612427,
      "learning_rate": 8.635939009135963e-06,
      "loss": 0.0735,
      "step": 8615
    },
    {
      "epoch": 0.13642193264404578,
      "grad_norm": 0.009816857054829597,
      "learning_rate": 8.635780673559542e-06,
      "loss": 0.0004,
      "step": 8616
    },
    {
      "epoch": 0.13643776620168785,
      "grad_norm": 0.3995703458786011,
      "learning_rate": 8.635622337983121e-06,
      "loss": 0.5927,
      "step": 8617
    },
    {
      "epoch": 0.1364535997593299,
      "grad_norm": 0.10913755744695663,
      "learning_rate": 8.635464002406702e-06,
      "loss": 0.0031,
      "step": 8618
    },
    {
      "epoch": 0.13646943331697198,
      "grad_norm": 0.545768141746521,
      "learning_rate": 8.63530566683028e-06,
      "loss": 0.4047,
      "step": 8619
    },
    {
      "epoch": 0.13648526687461407,
      "grad_norm": 0.1644592434167862,
      "learning_rate": 8.63514733125386e-06,
      "loss": 0.0637,
      "step": 8620
    },
    {
      "epoch": 0.13650110043225613,
      "grad_norm": 0.39023470878601074,
      "learning_rate": 8.63498899567744e-06,
      "loss": 0.5239,
      "step": 8621
    },
    {
      "epoch": 0.1365169339898982,
      "grad_norm": 0.3085736930370331,
      "learning_rate": 8.634830660101019e-06,
      "loss": 0.4589,
      "step": 8622
    },
    {
      "epoch": 0.13653276754754026,
      "grad_norm": 0.24036060273647308,
      "learning_rate": 8.634672324524598e-06,
      "loss": 0.118,
      "step": 8623
    },
    {
      "epoch": 0.13654860110518233,
      "grad_norm": 0.2959577441215515,
      "learning_rate": 8.634513988948178e-06,
      "loss": 0.0753,
      "step": 8624
    },
    {
      "epoch": 0.1365644346628244,
      "grad_norm": 0.00021779767121188343,
      "learning_rate": 8.634355653371756e-06,
      "loss": 0.0,
      "step": 8625
    },
    {
      "epoch": 0.13658026822046646,
      "grad_norm": 0.1380268931388855,
      "learning_rate": 8.634197317795337e-06,
      "loss": 0.0281,
      "step": 8626
    },
    {
      "epoch": 0.13659610177810852,
      "grad_norm": 0.000536867999471724,
      "learning_rate": 8.634038982218916e-06,
      "loss": 0.0,
      "step": 8627
    },
    {
      "epoch": 0.13661193533575058,
      "grad_norm": 0.8891377449035645,
      "learning_rate": 8.633880646642495e-06,
      "loss": 0.1091,
      "step": 8628
    },
    {
      "epoch": 0.13662776889339265,
      "grad_norm": 0.3344951868057251,
      "learning_rate": 8.633722311066074e-06,
      "loss": 0.187,
      "step": 8629
    },
    {
      "epoch": 0.1366436024510347,
      "grad_norm": 0.042269282042980194,
      "learning_rate": 8.633563975489655e-06,
      "loss": 0.0036,
      "step": 8630
    },
    {
      "epoch": 0.13665943600867678,
      "grad_norm": 0.3042638599872589,
      "learning_rate": 8.633405639913232e-06,
      "loss": 0.0952,
      "step": 8631
    },
    {
      "epoch": 0.13667526956631887,
      "grad_norm": 0.5695451498031616,
      "learning_rate": 8.633247304336813e-06,
      "loss": 0.386,
      "step": 8632
    },
    {
      "epoch": 0.13669110312396093,
      "grad_norm": 0.3923526406288147,
      "learning_rate": 8.633088968760392e-06,
      "loss": 0.1393,
      "step": 8633
    },
    {
      "epoch": 0.136706936681603,
      "grad_norm": 0.03174334019422531,
      "learning_rate": 8.632930633183971e-06,
      "loss": 0.0012,
      "step": 8634
    },
    {
      "epoch": 0.13672277023924506,
      "grad_norm": 0.33915579319000244,
      "learning_rate": 8.63277229760755e-06,
      "loss": 0.2797,
      "step": 8635
    },
    {
      "epoch": 0.13673860379688713,
      "grad_norm": 0.2216511070728302,
      "learning_rate": 8.63261396203113e-06,
      "loss": 0.0456,
      "step": 8636
    },
    {
      "epoch": 0.1367544373545292,
      "grad_norm": 0.01316782832145691,
      "learning_rate": 8.632455626454708e-06,
      "loss": 0.0009,
      "step": 8637
    },
    {
      "epoch": 0.13677027091217125,
      "grad_norm": 0.31518590450286865,
      "learning_rate": 8.632297290878287e-06,
      "loss": 0.1687,
      "step": 8638
    },
    {
      "epoch": 0.13678610446981332,
      "grad_norm": 0.509845495223999,
      "learning_rate": 8.632138955301868e-06,
      "loss": 0.1574,
      "step": 8639
    },
    {
      "epoch": 0.13680193802745538,
      "grad_norm": 0.016254572197794914,
      "learning_rate": 8.631980619725447e-06,
      "loss": 0.001,
      "step": 8640
    },
    {
      "epoch": 0.13681777158509745,
      "grad_norm": 0.010228813625872135,
      "learning_rate": 8.631822284149026e-06,
      "loss": 0.0006,
      "step": 8641
    },
    {
      "epoch": 0.1368336051427395,
      "grad_norm": 0.6347423195838928,
      "learning_rate": 8.631663948572605e-06,
      "loss": 0.2985,
      "step": 8642
    },
    {
      "epoch": 0.13684943870038158,
      "grad_norm": 0.1411145031452179,
      "learning_rate": 8.631505612996184e-06,
      "loss": 0.0072,
      "step": 8643
    },
    {
      "epoch": 0.13686527225802367,
      "grad_norm": 0.1568709909915924,
      "learning_rate": 8.631347277419763e-06,
      "loss": 0.075,
      "step": 8644
    },
    {
      "epoch": 0.13688110581566573,
      "grad_norm": 0.23105652630329132,
      "learning_rate": 8.631188941843344e-06,
      "loss": 0.0783,
      "step": 8645
    },
    {
      "epoch": 0.1368969393733078,
      "grad_norm": 0.030112892389297485,
      "learning_rate": 8.631030606266923e-06,
      "loss": 0.0018,
      "step": 8646
    },
    {
      "epoch": 0.13691277293094986,
      "grad_norm": 0.5533607006072998,
      "learning_rate": 8.630872270690502e-06,
      "loss": 0.1689,
      "step": 8647
    },
    {
      "epoch": 0.13692860648859193,
      "grad_norm": 0.01711033657193184,
      "learning_rate": 8.630713935114081e-06,
      "loss": 0.0009,
      "step": 8648
    },
    {
      "epoch": 0.136944440046234,
      "grad_norm": 0.4919010102748871,
      "learning_rate": 8.63055559953766e-06,
      "loss": 0.6494,
      "step": 8649
    },
    {
      "epoch": 0.13696027360387605,
      "grad_norm": 0.27407321333885193,
      "learning_rate": 8.63039726396124e-06,
      "loss": 0.0711,
      "step": 8650
    },
    {
      "epoch": 0.13697610716151812,
      "grad_norm": 0.47276997566223145,
      "learning_rate": 8.63023892838482e-06,
      "loss": 0.3545,
      "step": 8651
    },
    {
      "epoch": 0.13699194071916018,
      "grad_norm": 0.00029752322006970644,
      "learning_rate": 8.6300805928084e-06,
      "loss": 0.0,
      "step": 8652
    },
    {
      "epoch": 0.13700777427680225,
      "grad_norm": 0.2987159490585327,
      "learning_rate": 8.629922257231979e-06,
      "loss": 0.0595,
      "step": 8653
    },
    {
      "epoch": 0.1370236078344443,
      "grad_norm": 0.09019706398248672,
      "learning_rate": 8.629763921655558e-06,
      "loss": 0.01,
      "step": 8654
    },
    {
      "epoch": 0.13703944139208638,
      "grad_norm": 0.3067123293876648,
      "learning_rate": 8.629605586079137e-06,
      "loss": 0.1253,
      "step": 8655
    },
    {
      "epoch": 0.13705527494972847,
      "grad_norm": 0.53310626745224,
      "learning_rate": 8.629447250502716e-06,
      "loss": 0.5472,
      "step": 8656
    },
    {
      "epoch": 0.13707110850737053,
      "grad_norm": 0.8669619560241699,
      "learning_rate": 8.629288914926297e-06,
      "loss": 0.2454,
      "step": 8657
    },
    {
      "epoch": 0.1370869420650126,
      "grad_norm": 0.00025963186635635793,
      "learning_rate": 8.629130579349874e-06,
      "loss": 0.0,
      "step": 8658
    },
    {
      "epoch": 0.13710277562265466,
      "grad_norm": 0.18237103521823883,
      "learning_rate": 8.628972243773455e-06,
      "loss": 0.0457,
      "step": 8659
    },
    {
      "epoch": 0.13711860918029672,
      "grad_norm": 0.45787227153778076,
      "learning_rate": 8.628813908197034e-06,
      "loss": 0.219,
      "step": 8660
    },
    {
      "epoch": 0.1371344427379388,
      "grad_norm": 0.5125414729118347,
      "learning_rate": 8.628655572620613e-06,
      "loss": 0.105,
      "step": 8661
    },
    {
      "epoch": 0.13715027629558085,
      "grad_norm": 1.7739611864089966,
      "learning_rate": 8.628497237044192e-06,
      "loss": 0.0201,
      "step": 8662
    },
    {
      "epoch": 0.13716610985322292,
      "grad_norm": 0.5702723264694214,
      "learning_rate": 8.628338901467771e-06,
      "loss": 0.5201,
      "step": 8663
    },
    {
      "epoch": 0.13718194341086498,
      "grad_norm": 0.29441359639167786,
      "learning_rate": 8.62818056589135e-06,
      "loss": 0.1191,
      "step": 8664
    },
    {
      "epoch": 0.13719777696850705,
      "grad_norm": 0.30990052223205566,
      "learning_rate": 8.62802223031493e-06,
      "loss": 0.2215,
      "step": 8665
    },
    {
      "epoch": 0.1372136105261491,
      "grad_norm": 0.014705387875437737,
      "learning_rate": 8.62786389473851e-06,
      "loss": 0.0007,
      "step": 8666
    },
    {
      "epoch": 0.13722944408379117,
      "grad_norm": 0.179090678691864,
      "learning_rate": 8.627705559162089e-06,
      "loss": 0.0808,
      "step": 8667
    },
    {
      "epoch": 0.13724527764143327,
      "grad_norm": 0.38554292917251587,
      "learning_rate": 8.627547223585668e-06,
      "loss": 0.5951,
      "step": 8668
    },
    {
      "epoch": 0.13726111119907533,
      "grad_norm": 0.4714651107788086,
      "learning_rate": 8.627388888009247e-06,
      "loss": 0.0969,
      "step": 8669
    },
    {
      "epoch": 0.1372769447567174,
      "grad_norm": 0.24049979448318481,
      "learning_rate": 8.627230552432826e-06,
      "loss": 0.0599,
      "step": 8670
    },
    {
      "epoch": 0.13729277831435946,
      "grad_norm": 0.3562980890274048,
      "learning_rate": 8.627072216856405e-06,
      "loss": 0.0605,
      "step": 8671
    },
    {
      "epoch": 0.13730861187200152,
      "grad_norm": 0.2125360369682312,
      "learning_rate": 8.626913881279986e-06,
      "loss": 0.1429,
      "step": 8672
    },
    {
      "epoch": 0.1373244454296436,
      "grad_norm": 0.00019445622456260026,
      "learning_rate": 8.626755545703565e-06,
      "loss": 0.0,
      "step": 8673
    },
    {
      "epoch": 0.13734027898728565,
      "grad_norm": 0.00011320496560074389,
      "learning_rate": 8.626597210127144e-06,
      "loss": 0.0,
      "step": 8674
    },
    {
      "epoch": 0.13735611254492772,
      "grad_norm": 0.2520928382873535,
      "learning_rate": 8.626438874550723e-06,
      "loss": 0.142,
      "step": 8675
    },
    {
      "epoch": 0.13737194610256978,
      "grad_norm": 0.32339155673980713,
      "learning_rate": 8.626280538974302e-06,
      "loss": 0.2542,
      "step": 8676
    },
    {
      "epoch": 0.13738777966021185,
      "grad_norm": 0.2348894625902176,
      "learning_rate": 8.626122203397882e-06,
      "loss": 0.0623,
      "step": 8677
    },
    {
      "epoch": 0.1374036132178539,
      "grad_norm": 0.7297148704528809,
      "learning_rate": 8.625963867821462e-06,
      "loss": 0.4287,
      "step": 8678
    },
    {
      "epoch": 0.13741944677549597,
      "grad_norm": 0.021735331043601036,
      "learning_rate": 8.625805532245041e-06,
      "loss": 0.0013,
      "step": 8679
    },
    {
      "epoch": 0.13743528033313807,
      "grad_norm": 0.24279026687145233,
      "learning_rate": 8.62564719666862e-06,
      "loss": 0.1232,
      "step": 8680
    },
    {
      "epoch": 0.13745111389078013,
      "grad_norm": 0.1644848734140396,
      "learning_rate": 8.6254888610922e-06,
      "loss": 0.0277,
      "step": 8681
    },
    {
      "epoch": 0.1374669474484222,
      "grad_norm": 0.5717608332633972,
      "learning_rate": 8.625330525515779e-06,
      "loss": 0.2597,
      "step": 8682
    },
    {
      "epoch": 0.13748278100606426,
      "grad_norm": 0.7770843505859375,
      "learning_rate": 8.625172189939358e-06,
      "loss": 0.2045,
      "step": 8683
    },
    {
      "epoch": 0.13749861456370632,
      "grad_norm": 0.474761962890625,
      "learning_rate": 8.625013854362938e-06,
      "loss": 0.194,
      "step": 8684
    },
    {
      "epoch": 0.1375144481213484,
      "grad_norm": 0.011217364110052586,
      "learning_rate": 8.624855518786518e-06,
      "loss": 0.0007,
      "step": 8685
    },
    {
      "epoch": 0.13753028167899045,
      "grad_norm": 0.15449897944927216,
      "learning_rate": 8.624697183210095e-06,
      "loss": 0.0086,
      "step": 8686
    },
    {
      "epoch": 0.13754611523663252,
      "grad_norm": 0.14574407041072845,
      "learning_rate": 8.624538847633676e-06,
      "loss": 0.0376,
      "step": 8687
    },
    {
      "epoch": 0.13756194879427458,
      "grad_norm": 0.00018259913485962898,
      "learning_rate": 8.624380512057255e-06,
      "loss": 0.0,
      "step": 8688
    },
    {
      "epoch": 0.13757778235191664,
      "grad_norm": 0.00017440412193536758,
      "learning_rate": 8.624222176480834e-06,
      "loss": 0.0,
      "step": 8689
    },
    {
      "epoch": 0.1375936159095587,
      "grad_norm": 1.8677171468734741,
      "learning_rate": 8.624063840904413e-06,
      "loss": 0.5501,
      "step": 8690
    },
    {
      "epoch": 0.13760944946720077,
      "grad_norm": 0.3098827004432678,
      "learning_rate": 8.623905505327994e-06,
      "loss": 0.0772,
      "step": 8691
    },
    {
      "epoch": 0.13762528302484286,
      "grad_norm": 0.00044406286906450987,
      "learning_rate": 8.623747169751571e-06,
      "loss": 0.0,
      "step": 8692
    },
    {
      "epoch": 0.13764111658248493,
      "grad_norm": 0.3093807101249695,
      "learning_rate": 8.623588834175152e-06,
      "loss": 0.1095,
      "step": 8693
    },
    {
      "epoch": 0.137656950140127,
      "grad_norm": 0.30976179242134094,
      "learning_rate": 8.623430498598731e-06,
      "loss": 0.2092,
      "step": 8694
    },
    {
      "epoch": 0.13767278369776906,
      "grad_norm": 0.35502588748931885,
      "learning_rate": 8.62327216302231e-06,
      "loss": 0.2321,
      "step": 8695
    },
    {
      "epoch": 0.13768861725541112,
      "grad_norm": 0.01624998450279236,
      "learning_rate": 8.623113827445889e-06,
      "loss": 0.0007,
      "step": 8696
    },
    {
      "epoch": 0.1377044508130532,
      "grad_norm": 0.34951505064964294,
      "learning_rate": 8.62295549186947e-06,
      "loss": 0.2314,
      "step": 8697
    },
    {
      "epoch": 0.13772028437069525,
      "grad_norm": 0.2661706805229187,
      "learning_rate": 8.622797156293047e-06,
      "loss": 0.1142,
      "step": 8698
    },
    {
      "epoch": 0.13773611792833731,
      "grad_norm": 0.004835218656808138,
      "learning_rate": 8.622638820716628e-06,
      "loss": 0.0002,
      "step": 8699
    },
    {
      "epoch": 0.13775195148597938,
      "grad_norm": 0.015860967338085175,
      "learning_rate": 8.622480485140207e-06,
      "loss": 0.0008,
      "step": 8700
    },
    {
      "epoch": 0.13776778504362144,
      "grad_norm": 0.007326868362724781,
      "learning_rate": 8.622322149563786e-06,
      "loss": 0.0004,
      "step": 8701
    },
    {
      "epoch": 0.1377836186012635,
      "grad_norm": 0.04625860974192619,
      "learning_rate": 8.622163813987365e-06,
      "loss": 0.0024,
      "step": 8702
    },
    {
      "epoch": 0.13779945215890557,
      "grad_norm": 0.0006211731233634055,
      "learning_rate": 8.622005478410946e-06,
      "loss": 0.0,
      "step": 8703
    },
    {
      "epoch": 0.13781528571654766,
      "grad_norm": 0.35369718074798584,
      "learning_rate": 8.621847142834523e-06,
      "loss": 0.2196,
      "step": 8704
    },
    {
      "epoch": 0.13783111927418973,
      "grad_norm": 0.1710488647222519,
      "learning_rate": 8.621688807258104e-06,
      "loss": 0.1579,
      "step": 8705
    },
    {
      "epoch": 0.1378469528318318,
      "grad_norm": 0.23590543866157532,
      "learning_rate": 8.621530471681683e-06,
      "loss": 0.0904,
      "step": 8706
    },
    {
      "epoch": 0.13786278638947386,
      "grad_norm": 0.27247947454452515,
      "learning_rate": 8.621372136105262e-06,
      "loss": 0.0757,
      "step": 8707
    },
    {
      "epoch": 0.13787861994711592,
      "grad_norm": 0.4581224322319031,
      "learning_rate": 8.621213800528841e-06,
      "loss": 0.2763,
      "step": 8708
    },
    {
      "epoch": 0.13789445350475799,
      "grad_norm": 0.030878541991114616,
      "learning_rate": 8.621055464952422e-06,
      "loss": 0.0017,
      "step": 8709
    },
    {
      "epoch": 0.13791028706240005,
      "grad_norm": 0.6007600426673889,
      "learning_rate": 8.620897129376e-06,
      "loss": 0.3327,
      "step": 8710
    },
    {
      "epoch": 0.13792612062004211,
      "grad_norm": 0.20837995409965515,
      "learning_rate": 8.620738793799579e-06,
      "loss": 0.0896,
      "step": 8711
    },
    {
      "epoch": 0.13794195417768418,
      "grad_norm": 0.9034695625305176,
      "learning_rate": 8.62058045822316e-06,
      "loss": 0.4135,
      "step": 8712
    },
    {
      "epoch": 0.13795778773532624,
      "grad_norm": 0.2982417047023773,
      "learning_rate": 8.620422122646739e-06,
      "loss": 0.1912,
      "step": 8713
    },
    {
      "epoch": 0.1379736212929683,
      "grad_norm": 0.0014601506991311908,
      "learning_rate": 8.620263787070318e-06,
      "loss": 0.0,
      "step": 8714
    },
    {
      "epoch": 0.13798945485061037,
      "grad_norm": 0.42931827902793884,
      "learning_rate": 8.620105451493897e-06,
      "loss": 0.0291,
      "step": 8715
    },
    {
      "epoch": 0.13800528840825246,
      "grad_norm": 0.4637133777141571,
      "learning_rate": 8.619947115917476e-06,
      "loss": 0.417,
      "step": 8716
    },
    {
      "epoch": 0.13802112196589453,
      "grad_norm": 0.15865325927734375,
      "learning_rate": 8.619788780341055e-06,
      "loss": 0.0133,
      "step": 8717
    },
    {
      "epoch": 0.1380369555235366,
      "grad_norm": 0.00026882035308517516,
      "learning_rate": 8.619630444764636e-06,
      "loss": 0.0,
      "step": 8718
    },
    {
      "epoch": 0.13805278908117866,
      "grad_norm": 0.08906380087137222,
      "learning_rate": 8.619472109188215e-06,
      "loss": 0.0163,
      "step": 8719
    },
    {
      "epoch": 0.13806862263882072,
      "grad_norm": 0.017072070389986038,
      "learning_rate": 8.619313773611794e-06,
      "loss": 0.0005,
      "step": 8720
    },
    {
      "epoch": 0.13808445619646278,
      "grad_norm": 0.17005594074726105,
      "learning_rate": 8.619155438035373e-06,
      "loss": 0.0577,
      "step": 8721
    },
    {
      "epoch": 0.13810028975410485,
      "grad_norm": 0.36165568232536316,
      "learning_rate": 8.618997102458952e-06,
      "loss": 0.3051,
      "step": 8722
    },
    {
      "epoch": 0.1381161233117469,
      "grad_norm": 0.035216446965932846,
      "learning_rate": 8.618838766882531e-06,
      "loss": 0.002,
      "step": 8723
    },
    {
      "epoch": 0.13813195686938898,
      "grad_norm": 0.4375019371509552,
      "learning_rate": 8.618680431306112e-06,
      "loss": 0.2162,
      "step": 8724
    },
    {
      "epoch": 0.13814779042703104,
      "grad_norm": 0.5981873869895935,
      "learning_rate": 8.61852209572969e-06,
      "loss": 0.0463,
      "step": 8725
    },
    {
      "epoch": 0.1381636239846731,
      "grad_norm": 0.2551928460597992,
      "learning_rate": 8.61836376015327e-06,
      "loss": 0.0914,
      "step": 8726
    },
    {
      "epoch": 0.13817945754231517,
      "grad_norm": 0.4900088608264923,
      "learning_rate": 8.618205424576849e-06,
      "loss": 0.3091,
      "step": 8727
    },
    {
      "epoch": 0.13819529109995726,
      "grad_norm": 0.18027614057064056,
      "learning_rate": 8.618047089000428e-06,
      "loss": 0.0101,
      "step": 8728
    },
    {
      "epoch": 0.13821112465759933,
      "grad_norm": 0.43178537487983704,
      "learning_rate": 8.617888753424007e-06,
      "loss": 0.4101,
      "step": 8729
    },
    {
      "epoch": 0.1382269582152414,
      "grad_norm": 0.038890812546014786,
      "learning_rate": 8.617730417847588e-06,
      "loss": 0.0022,
      "step": 8730
    },
    {
      "epoch": 0.13824279177288346,
      "grad_norm": 0.012239313684403896,
      "learning_rate": 8.617572082271165e-06,
      "loss": 0.0006,
      "step": 8731
    },
    {
      "epoch": 0.13825862533052552,
      "grad_norm": 0.28041568398475647,
      "learning_rate": 8.617413746694746e-06,
      "loss": 0.1048,
      "step": 8732
    },
    {
      "epoch": 0.13827445888816758,
      "grad_norm": 0.36231541633605957,
      "learning_rate": 8.617255411118325e-06,
      "loss": 0.0061,
      "step": 8733
    },
    {
      "epoch": 0.13829029244580965,
      "grad_norm": 7.840820762794465e-05,
      "learning_rate": 8.617097075541904e-06,
      "loss": 0.0,
      "step": 8734
    },
    {
      "epoch": 0.1383061260034517,
      "grad_norm": 0.17276854813098907,
      "learning_rate": 8.616938739965483e-06,
      "loss": 0.0588,
      "step": 8735
    },
    {
      "epoch": 0.13832195956109378,
      "grad_norm": 0.30403608083724976,
      "learning_rate": 8.616780404389062e-06,
      "loss": 0.0378,
      "step": 8736
    },
    {
      "epoch": 0.13833779311873584,
      "grad_norm": 0.00035979965468868613,
      "learning_rate": 8.616622068812642e-06,
      "loss": 0.0,
      "step": 8737
    },
    {
      "epoch": 0.1383536266763779,
      "grad_norm": 0.235409215092659,
      "learning_rate": 8.61646373323622e-06,
      "loss": 0.0877,
      "step": 8738
    },
    {
      "epoch": 0.13836946023401997,
      "grad_norm": 0.00034934081486426294,
      "learning_rate": 8.616305397659801e-06,
      "loss": 0.0,
      "step": 8739
    },
    {
      "epoch": 0.13838529379166206,
      "grad_norm": 0.015935778617858887,
      "learning_rate": 8.61614706208338e-06,
      "loss": 0.0006,
      "step": 8740
    },
    {
      "epoch": 0.13840112734930413,
      "grad_norm": 0.26518821716308594,
      "learning_rate": 8.61598872650696e-06,
      "loss": 0.0505,
      "step": 8741
    },
    {
      "epoch": 0.1384169609069462,
      "grad_norm": 0.24317848682403564,
      "learning_rate": 8.615830390930539e-06,
      "loss": 0.0889,
      "step": 8742
    },
    {
      "epoch": 0.13843279446458825,
      "grad_norm": 0.3496777415275574,
      "learning_rate": 8.615672055354118e-06,
      "loss": 0.1253,
      "step": 8743
    },
    {
      "epoch": 0.13844862802223032,
      "grad_norm": 0.3649355173110962,
      "learning_rate": 8.615513719777697e-06,
      "loss": 0.1873,
      "step": 8744
    },
    {
      "epoch": 0.13846446157987238,
      "grad_norm": 0.20091669261455536,
      "learning_rate": 8.615355384201278e-06,
      "loss": 0.0528,
      "step": 8745
    },
    {
      "epoch": 0.13848029513751445,
      "grad_norm": 0.22723925113677979,
      "learning_rate": 8.615197048624857e-06,
      "loss": 0.0507,
      "step": 8746
    },
    {
      "epoch": 0.1384961286951565,
      "grad_norm": 0.8367419242858887,
      "learning_rate": 8.615038713048436e-06,
      "loss": 0.5083,
      "step": 8747
    },
    {
      "epoch": 0.13851196225279858,
      "grad_norm": 0.27229464054107666,
      "learning_rate": 8.614880377472015e-06,
      "loss": 0.0467,
      "step": 8748
    },
    {
      "epoch": 0.13852779581044064,
      "grad_norm": 0.37164872884750366,
      "learning_rate": 8.614722041895594e-06,
      "loss": 0.3585,
      "step": 8749
    },
    {
      "epoch": 0.1385436293680827,
      "grad_norm": 0.6228930950164795,
      "learning_rate": 8.614563706319173e-06,
      "loss": 0.676,
      "step": 8750
    },
    {
      "epoch": 0.13855946292572477,
      "grad_norm": 0.2564541697502136,
      "learning_rate": 8.614405370742754e-06,
      "loss": 0.0935,
      "step": 8751
    },
    {
      "epoch": 0.13857529648336686,
      "grad_norm": 0.1434788554906845,
      "learning_rate": 8.614247035166333e-06,
      "loss": 0.0052,
      "step": 8752
    },
    {
      "epoch": 0.13859113004100893,
      "grad_norm": 0.46649742126464844,
      "learning_rate": 8.614088699589912e-06,
      "loss": 0.2177,
      "step": 8753
    },
    {
      "epoch": 0.138606963598651,
      "grad_norm": 0.5480311512947083,
      "learning_rate": 8.613930364013491e-06,
      "loss": 0.21,
      "step": 8754
    },
    {
      "epoch": 0.13862279715629305,
      "grad_norm": 0.2176605761051178,
      "learning_rate": 8.61377202843707e-06,
      "loss": 0.061,
      "step": 8755
    },
    {
      "epoch": 0.13863863071393512,
      "grad_norm": 0.5400980114936829,
      "learning_rate": 8.613613692860649e-06,
      "loss": 0.5925,
      "step": 8756
    },
    {
      "epoch": 0.13865446427157718,
      "grad_norm": 0.8812183141708374,
      "learning_rate": 8.61345535728423e-06,
      "loss": 0.1809,
      "step": 8757
    },
    {
      "epoch": 0.13867029782921925,
      "grad_norm": 0.3318640887737274,
      "learning_rate": 8.613297021707809e-06,
      "loss": 0.4815,
      "step": 8758
    },
    {
      "epoch": 0.1386861313868613,
      "grad_norm": 0.5187178254127502,
      "learning_rate": 8.613138686131386e-06,
      "loss": 0.0724,
      "step": 8759
    },
    {
      "epoch": 0.13870196494450338,
      "grad_norm": 0.6830779910087585,
      "learning_rate": 8.612980350554967e-06,
      "loss": 0.0513,
      "step": 8760
    },
    {
      "epoch": 0.13871779850214544,
      "grad_norm": 0.017306948080658913,
      "learning_rate": 8.612822014978546e-06,
      "loss": 0.0008,
      "step": 8761
    },
    {
      "epoch": 0.1387336320597875,
      "grad_norm": 0.004225871060043573,
      "learning_rate": 8.612663679402125e-06,
      "loss": 0.0002,
      "step": 8762
    },
    {
      "epoch": 0.13874946561742957,
      "grad_norm": 0.40283888578414917,
      "learning_rate": 8.612505343825704e-06,
      "loss": 0.1344,
      "step": 8763
    },
    {
      "epoch": 0.13876529917507166,
      "grad_norm": 0.5899559855461121,
      "learning_rate": 8.612347008249285e-06,
      "loss": 0.7278,
      "step": 8764
    },
    {
      "epoch": 0.13878113273271372,
      "grad_norm": 0.0369250513613224,
      "learning_rate": 8.612188672672863e-06,
      "loss": 0.0032,
      "step": 8765
    },
    {
      "epoch": 0.1387969662903558,
      "grad_norm": 0.2684032618999481,
      "learning_rate": 8.612030337096443e-06,
      "loss": 0.1002,
      "step": 8766
    },
    {
      "epoch": 0.13881279984799785,
      "grad_norm": 0.5154104828834534,
      "learning_rate": 8.611872001520022e-06,
      "loss": 0.4491,
      "step": 8767
    },
    {
      "epoch": 0.13882863340563992,
      "grad_norm": 0.13048283755779266,
      "learning_rate": 8.611713665943601e-06,
      "loss": 0.0123,
      "step": 8768
    },
    {
      "epoch": 0.13884446696328198,
      "grad_norm": 0.39563876390457153,
      "learning_rate": 8.61155533036718e-06,
      "loss": 0.1661,
      "step": 8769
    },
    {
      "epoch": 0.13886030052092405,
      "grad_norm": 0.4019738435745239,
      "learning_rate": 8.611396994790761e-06,
      "loss": 0.1471,
      "step": 8770
    },
    {
      "epoch": 0.1388761340785661,
      "grad_norm": 0.08544126152992249,
      "learning_rate": 8.611238659214339e-06,
      "loss": 0.0295,
      "step": 8771
    },
    {
      "epoch": 0.13889196763620817,
      "grad_norm": 0.0055703530088067055,
      "learning_rate": 8.61108032363792e-06,
      "loss": 0.0002,
      "step": 8772
    },
    {
      "epoch": 0.13890780119385024,
      "grad_norm": 0.46982958912849426,
      "learning_rate": 8.610921988061499e-06,
      "loss": 0.1382,
      "step": 8773
    },
    {
      "epoch": 0.1389236347514923,
      "grad_norm": 0.04374348372220993,
      "learning_rate": 8.610763652485078e-06,
      "loss": 0.003,
      "step": 8774
    },
    {
      "epoch": 0.13893946830913437,
      "grad_norm": 0.19893082976341248,
      "learning_rate": 8.610605316908657e-06,
      "loss": 0.0886,
      "step": 8775
    },
    {
      "epoch": 0.13895530186677646,
      "grad_norm": 0.36202189326286316,
      "learning_rate": 8.610446981332237e-06,
      "loss": 0.1438,
      "step": 8776
    },
    {
      "epoch": 0.13897113542441852,
      "grad_norm": 0.5844693183898926,
      "learning_rate": 8.610288645755815e-06,
      "loss": 0.5286,
      "step": 8777
    },
    {
      "epoch": 0.1389869689820606,
      "grad_norm": 0.9439413547515869,
      "learning_rate": 8.610130310179396e-06,
      "loss": 0.3036,
      "step": 8778
    },
    {
      "epoch": 0.13900280253970265,
      "grad_norm": 0.5623286962509155,
      "learning_rate": 8.609971974602975e-06,
      "loss": 0.4422,
      "step": 8779
    },
    {
      "epoch": 0.13901863609734472,
      "grad_norm": 0.5689572691917419,
      "learning_rate": 8.609813639026554e-06,
      "loss": 0.2121,
      "step": 8780
    },
    {
      "epoch": 0.13903446965498678,
      "grad_norm": 0.32823294401168823,
      "learning_rate": 8.609655303450133e-06,
      "loss": 0.1048,
      "step": 8781
    },
    {
      "epoch": 0.13905030321262885,
      "grad_norm": 0.3708394169807434,
      "learning_rate": 8.609496967873712e-06,
      "loss": 0.0511,
      "step": 8782
    },
    {
      "epoch": 0.1390661367702709,
      "grad_norm": 0.03896556422114372,
      "learning_rate": 8.609338632297291e-06,
      "loss": 0.0055,
      "step": 8783
    },
    {
      "epoch": 0.13908197032791297,
      "grad_norm": 0.36657196283340454,
      "learning_rate": 8.60918029672087e-06,
      "loss": 0.0859,
      "step": 8784
    },
    {
      "epoch": 0.13909780388555504,
      "grad_norm": 0.3128112554550171,
      "learning_rate": 8.609021961144451e-06,
      "loss": 0.0578,
      "step": 8785
    },
    {
      "epoch": 0.1391136374431971,
      "grad_norm": 0.43630656599998474,
      "learning_rate": 8.60886362556803e-06,
      "loss": 0.1709,
      "step": 8786
    },
    {
      "epoch": 0.13912947100083917,
      "grad_norm": 0.019627006724476814,
      "learning_rate": 8.608705289991609e-06,
      "loss": 0.001,
      "step": 8787
    },
    {
      "epoch": 0.13914530455848126,
      "grad_norm": 0.43779534101486206,
      "learning_rate": 8.608546954415188e-06,
      "loss": 0.2811,
      "step": 8788
    },
    {
      "epoch": 0.13916113811612332,
      "grad_norm": 0.4529789686203003,
      "learning_rate": 8.608388618838767e-06,
      "loss": 0.3575,
      "step": 8789
    },
    {
      "epoch": 0.1391769716737654,
      "grad_norm": 0.007283409591764212,
      "learning_rate": 8.608230283262346e-06,
      "loss": 0.0003,
      "step": 8790
    },
    {
      "epoch": 0.13919280523140745,
      "grad_norm": 1.5502508878707886,
      "learning_rate": 8.608071947685927e-06,
      "loss": 0.1033,
      "step": 8791
    },
    {
      "epoch": 0.13920863878904952,
      "grad_norm": 0.1218913197517395,
      "learning_rate": 8.607913612109504e-06,
      "loss": 0.0446,
      "step": 8792
    },
    {
      "epoch": 0.13922447234669158,
      "grad_norm": 0.3092484772205353,
      "learning_rate": 8.607755276533085e-06,
      "loss": 0.1772,
      "step": 8793
    },
    {
      "epoch": 0.13924030590433364,
      "grad_norm": 0.17336741089820862,
      "learning_rate": 8.607596940956664e-06,
      "loss": 0.0585,
      "step": 8794
    },
    {
      "epoch": 0.1392561394619757,
      "grad_norm": 0.42861345410346985,
      "learning_rate": 8.607438605380243e-06,
      "loss": 0.1371,
      "step": 8795
    },
    {
      "epoch": 0.13927197301961777,
      "grad_norm": 0.5489407777786255,
      "learning_rate": 8.607280269803822e-06,
      "loss": 0.7671,
      "step": 8796
    },
    {
      "epoch": 0.13928780657725984,
      "grad_norm": 0.0005925446166656911,
      "learning_rate": 8.607121934227403e-06,
      "loss": 0.0,
      "step": 8797
    },
    {
      "epoch": 0.1393036401349019,
      "grad_norm": 0.44733738899230957,
      "learning_rate": 8.60696359865098e-06,
      "loss": 0.1327,
      "step": 8798
    },
    {
      "epoch": 0.13931947369254397,
      "grad_norm": 0.629722535610199,
      "learning_rate": 8.606805263074561e-06,
      "loss": 0.313,
      "step": 8799
    },
    {
      "epoch": 0.13933530725018606,
      "grad_norm": 0.008756672032177448,
      "learning_rate": 8.60664692749814e-06,
      "loss": 0.0005,
      "step": 8800
    },
    {
      "epoch": 0.13935114080782812,
      "grad_norm": 0.0008047302253544331,
      "learning_rate": 8.60648859192172e-06,
      "loss": 0.0,
      "step": 8801
    },
    {
      "epoch": 0.1393669743654702,
      "grad_norm": 0.3902841806411743,
      "learning_rate": 8.606330256345299e-06,
      "loss": 0.3247,
      "step": 8802
    },
    {
      "epoch": 0.13938280792311225,
      "grad_norm": 0.019165243953466415,
      "learning_rate": 8.60617192076888e-06,
      "loss": 0.0005,
      "step": 8803
    },
    {
      "epoch": 0.13939864148075432,
      "grad_norm": 0.45163631439208984,
      "learning_rate": 8.606013585192457e-06,
      "loss": 0.3179,
      "step": 8804
    },
    {
      "epoch": 0.13941447503839638,
      "grad_norm": 0.01965365558862686,
      "learning_rate": 8.605855249616038e-06,
      "loss": 0.0011,
      "step": 8805
    },
    {
      "epoch": 0.13943030859603844,
      "grad_norm": 0.25059670209884644,
      "learning_rate": 8.605696914039617e-06,
      "loss": 0.1066,
      "step": 8806
    },
    {
      "epoch": 0.1394461421536805,
      "grad_norm": 0.6834216713905334,
      "learning_rate": 8.605538578463196e-06,
      "loss": 0.9804,
      "step": 8807
    },
    {
      "epoch": 0.13946197571132257,
      "grad_norm": 0.019127678126096725,
      "learning_rate": 8.605380242886775e-06,
      "loss": 0.0015,
      "step": 8808
    },
    {
      "epoch": 0.13947780926896464,
      "grad_norm": 0.0813407450914383,
      "learning_rate": 8.605221907310354e-06,
      "loss": 0.0013,
      "step": 8809
    },
    {
      "epoch": 0.1394936428266067,
      "grad_norm": 0.4257424473762512,
      "learning_rate": 8.605063571733933e-06,
      "loss": 0.2831,
      "step": 8810
    },
    {
      "epoch": 0.13950947638424877,
      "grad_norm": 0.4843013882637024,
      "learning_rate": 8.604905236157512e-06,
      "loss": 0.6664,
      "step": 8811
    },
    {
      "epoch": 0.13952530994189086,
      "grad_norm": 0.4014061689376831,
      "learning_rate": 8.604746900581093e-06,
      "loss": 0.1556,
      "step": 8812
    },
    {
      "epoch": 0.13954114349953292,
      "grad_norm": 0.3190624713897705,
      "learning_rate": 8.604588565004672e-06,
      "loss": 0.1551,
      "step": 8813
    },
    {
      "epoch": 0.13955697705717499,
      "grad_norm": 0.25157925486564636,
      "learning_rate": 8.604430229428251e-06,
      "loss": 0.169,
      "step": 8814
    },
    {
      "epoch": 0.13957281061481705,
      "grad_norm": 0.022013399749994278,
      "learning_rate": 8.60427189385183e-06,
      "loss": 0.0013,
      "step": 8815
    },
    {
      "epoch": 0.13958864417245911,
      "grad_norm": 0.004897803999483585,
      "learning_rate": 8.604113558275409e-06,
      "loss": 0.0002,
      "step": 8816
    },
    {
      "epoch": 0.13960447773010118,
      "grad_norm": 0.3797513246536255,
      "learning_rate": 8.603955222698988e-06,
      "loss": 0.0915,
      "step": 8817
    },
    {
      "epoch": 0.13962031128774324,
      "grad_norm": 0.0032603468280285597,
      "learning_rate": 8.603796887122569e-06,
      "loss": 0.0002,
      "step": 8818
    },
    {
      "epoch": 0.1396361448453853,
      "grad_norm": 0.20704008638858795,
      "learning_rate": 8.603638551546148e-06,
      "loss": 0.0249,
      "step": 8819
    },
    {
      "epoch": 0.13965197840302737,
      "grad_norm": 0.07610630244016647,
      "learning_rate": 8.603480215969727e-06,
      "loss": 0.0033,
      "step": 8820
    },
    {
      "epoch": 0.13966781196066944,
      "grad_norm": 0.2868069112300873,
      "learning_rate": 8.603321880393306e-06,
      "loss": 0.2479,
      "step": 8821
    },
    {
      "epoch": 0.1396836455183115,
      "grad_norm": 0.14212539792060852,
      "learning_rate": 8.603163544816885e-06,
      "loss": 0.0031,
      "step": 8822
    },
    {
      "epoch": 0.13969947907595356,
      "grad_norm": 0.6524120569229126,
      "learning_rate": 8.603005209240464e-06,
      "loss": 0.1329,
      "step": 8823
    },
    {
      "epoch": 0.13971531263359566,
      "grad_norm": 0.3967336118221283,
      "learning_rate": 8.602846873664045e-06,
      "loss": 0.0773,
      "step": 8824
    },
    {
      "epoch": 0.13973114619123772,
      "grad_norm": 0.205335795879364,
      "learning_rate": 8.602688538087624e-06,
      "loss": 0.0697,
      "step": 8825
    },
    {
      "epoch": 0.13974697974887978,
      "grad_norm": 0.002584730042144656,
      "learning_rate": 8.602530202511203e-06,
      "loss": 0.0001,
      "step": 8826
    },
    {
      "epoch": 0.13976281330652185,
      "grad_norm": 0.14797092974185944,
      "learning_rate": 8.602371866934782e-06,
      "loss": 0.0551,
      "step": 8827
    },
    {
      "epoch": 0.1397786468641639,
      "grad_norm": 0.014909864403307438,
      "learning_rate": 8.602213531358361e-06,
      "loss": 0.0008,
      "step": 8828
    },
    {
      "epoch": 0.13979448042180598,
      "grad_norm": 0.007634492591023445,
      "learning_rate": 8.60205519578194e-06,
      "loss": 0.0004,
      "step": 8829
    },
    {
      "epoch": 0.13981031397944804,
      "grad_norm": 0.00021327545982785523,
      "learning_rate": 8.60189686020552e-06,
      "loss": 0.0,
      "step": 8830
    },
    {
      "epoch": 0.1398261475370901,
      "grad_norm": 0.5392312407493591,
      "learning_rate": 8.6017385246291e-06,
      "loss": 0.8206,
      "step": 8831
    },
    {
      "epoch": 0.13984198109473217,
      "grad_norm": 0.0002909528266172856,
      "learning_rate": 8.601580189052678e-06,
      "loss": 0.0,
      "step": 8832
    },
    {
      "epoch": 0.13985781465237423,
      "grad_norm": 0.12929195165634155,
      "learning_rate": 8.601421853476259e-06,
      "loss": 0.0029,
      "step": 8833
    },
    {
      "epoch": 0.1398736482100163,
      "grad_norm": 0.5368341207504272,
      "learning_rate": 8.601263517899838e-06,
      "loss": 0.1104,
      "step": 8834
    },
    {
      "epoch": 0.13988948176765836,
      "grad_norm": 0.4211227595806122,
      "learning_rate": 8.601105182323417e-06,
      "loss": 0.2251,
      "step": 8835
    },
    {
      "epoch": 0.13990531532530046,
      "grad_norm": 0.008943610824644566,
      "learning_rate": 8.600946846746996e-06,
      "loss": 0.0005,
      "step": 8836
    },
    {
      "epoch": 0.13992114888294252,
      "grad_norm": 0.2762909233570099,
      "learning_rate": 8.600788511170577e-06,
      "loss": 0.158,
      "step": 8837
    },
    {
      "epoch": 0.13993698244058458,
      "grad_norm": 0.17901740968227386,
      "learning_rate": 8.600630175594154e-06,
      "loss": 0.0364,
      "step": 8838
    },
    {
      "epoch": 0.13995281599822665,
      "grad_norm": 0.2331129014492035,
      "learning_rate": 8.600471840017735e-06,
      "loss": 0.1061,
      "step": 8839
    },
    {
      "epoch": 0.1399686495558687,
      "grad_norm": 0.010557626374065876,
      "learning_rate": 8.600313504441314e-06,
      "loss": 0.0006,
      "step": 8840
    },
    {
      "epoch": 0.13998448311351078,
      "grad_norm": 0.04058276116847992,
      "learning_rate": 8.600155168864893e-06,
      "loss": 0.0018,
      "step": 8841
    },
    {
      "epoch": 0.14000031667115284,
      "grad_norm": 0.31861019134521484,
      "learning_rate": 8.599996833288472e-06,
      "loss": 0.1248,
      "step": 8842
    },
    {
      "epoch": 0.1400161502287949,
      "grad_norm": 1.0043591260910034,
      "learning_rate": 8.599838497712053e-06,
      "loss": 0.1434,
      "step": 8843
    },
    {
      "epoch": 0.14003198378643697,
      "grad_norm": 0.137888103723526,
      "learning_rate": 8.59968016213563e-06,
      "loss": 0.0606,
      "step": 8844
    },
    {
      "epoch": 0.14004781734407903,
      "grad_norm": 0.013838118873536587,
      "learning_rate": 8.599521826559211e-06,
      "loss": 0.0008,
      "step": 8845
    },
    {
      "epoch": 0.1400636509017211,
      "grad_norm": 0.3083392083644867,
      "learning_rate": 8.59936349098279e-06,
      "loss": 0.1123,
      "step": 8846
    },
    {
      "epoch": 0.14007948445936316,
      "grad_norm": 1.1087363958358765,
      "learning_rate": 8.599205155406369e-06,
      "loss": 0.5014,
      "step": 8847
    },
    {
      "epoch": 0.14009531801700525,
      "grad_norm": 0.2927679419517517,
      "learning_rate": 8.599046819829948e-06,
      "loss": 0.1946,
      "step": 8848
    },
    {
      "epoch": 0.14011115157464732,
      "grad_norm": 0.28831055760383606,
      "learning_rate": 8.598888484253527e-06,
      "loss": 0.2768,
      "step": 8849
    },
    {
      "epoch": 0.14012698513228938,
      "grad_norm": 0.013122113421559334,
      "learning_rate": 8.598730148677106e-06,
      "loss": 0.0006,
      "step": 8850
    },
    {
      "epoch": 0.14014281868993145,
      "grad_norm": 0.11864005774259567,
      "learning_rate": 8.598571813100687e-06,
      "loss": 0.0434,
      "step": 8851
    },
    {
      "epoch": 0.1401586522475735,
      "grad_norm": 0.49263083934783936,
      "learning_rate": 8.598413477524266e-06,
      "loss": 0.2832,
      "step": 8852
    },
    {
      "epoch": 0.14017448580521558,
      "grad_norm": 0.3027053475379944,
      "learning_rate": 8.598255141947845e-06,
      "loss": 0.4127,
      "step": 8853
    },
    {
      "epoch": 0.14019031936285764,
      "grad_norm": 0.2513045370578766,
      "learning_rate": 8.598096806371424e-06,
      "loss": 0.0909,
      "step": 8854
    },
    {
      "epoch": 0.1402061529204997,
      "grad_norm": 0.40322956442832947,
      "learning_rate": 8.597938470795003e-06,
      "loss": 0.1435,
      "step": 8855
    },
    {
      "epoch": 0.14022198647814177,
      "grad_norm": 0.015394925139844418,
      "learning_rate": 8.597780135218582e-06,
      "loss": 0.0008,
      "step": 8856
    },
    {
      "epoch": 0.14023782003578383,
      "grad_norm": 0.44487088918685913,
      "learning_rate": 8.597621799642162e-06,
      "loss": 0.1653,
      "step": 8857
    },
    {
      "epoch": 0.1402536535934259,
      "grad_norm": 0.20886869728565216,
      "learning_rate": 8.597463464065742e-06,
      "loss": 0.068,
      "step": 8858
    },
    {
      "epoch": 0.14026948715106796,
      "grad_norm": 0.5017836093902588,
      "learning_rate": 8.59730512848932e-06,
      "loss": 0.0156,
      "step": 8859
    },
    {
      "epoch": 0.14028532070871003,
      "grad_norm": 0.013756189495325089,
      "learning_rate": 8.5971467929129e-06,
      "loss": 0.0005,
      "step": 8860
    },
    {
      "epoch": 0.14030115426635212,
      "grad_norm": 0.013511153869330883,
      "learning_rate": 8.59698845733648e-06,
      "loss": 0.0008,
      "step": 8861
    },
    {
      "epoch": 0.14031698782399418,
      "grad_norm": 0.4372520446777344,
      "learning_rate": 8.596830121760059e-06,
      "loss": 0.6045,
      "step": 8862
    },
    {
      "epoch": 0.14033282138163625,
      "grad_norm": 0.27309516072273254,
      "learning_rate": 8.596671786183638e-06,
      "loss": 0.0863,
      "step": 8863
    },
    {
      "epoch": 0.1403486549392783,
      "grad_norm": 0.7239201068878174,
      "learning_rate": 8.596513450607219e-06,
      "loss": 0.3875,
      "step": 8864
    },
    {
      "epoch": 0.14036448849692038,
      "grad_norm": 0.10163477063179016,
      "learning_rate": 8.596355115030796e-06,
      "loss": 0.0288,
      "step": 8865
    },
    {
      "epoch": 0.14038032205456244,
      "grad_norm": 0.19693472981452942,
      "learning_rate": 8.596196779454377e-06,
      "loss": 0.0488,
      "step": 8866
    },
    {
      "epoch": 0.1403961556122045,
      "grad_norm": 0.2844347059726715,
      "learning_rate": 8.596038443877956e-06,
      "loss": 0.1885,
      "step": 8867
    },
    {
      "epoch": 0.14041198916984657,
      "grad_norm": 0.13633809983730316,
      "learning_rate": 8.595880108301535e-06,
      "loss": 0.0044,
      "step": 8868
    },
    {
      "epoch": 0.14042782272748863,
      "grad_norm": 0.23543870449066162,
      "learning_rate": 8.595721772725114e-06,
      "loss": 0.2108,
      "step": 8869
    },
    {
      "epoch": 0.1404436562851307,
      "grad_norm": 0.2555110454559326,
      "learning_rate": 8.595563437148695e-06,
      "loss": 0.0531,
      "step": 8870
    },
    {
      "epoch": 0.14045948984277276,
      "grad_norm": 0.015227193012833595,
      "learning_rate": 8.595405101572272e-06,
      "loss": 0.0009,
      "step": 8871
    },
    {
      "epoch": 0.14047532340041483,
      "grad_norm": 0.2590082585811615,
      "learning_rate": 8.595246765995853e-06,
      "loss": 0.1085,
      "step": 8872
    },
    {
      "epoch": 0.14049115695805692,
      "grad_norm": 0.0004862738132942468,
      "learning_rate": 8.595088430419432e-06,
      "loss": 0.0,
      "step": 8873
    },
    {
      "epoch": 0.14050699051569898,
      "grad_norm": 0.4389602839946747,
      "learning_rate": 8.594930094843011e-06,
      "loss": 0.1358,
      "step": 8874
    },
    {
      "epoch": 0.14052282407334105,
      "grad_norm": 0.013878731057047844,
      "learning_rate": 8.59477175926659e-06,
      "loss": 0.0007,
      "step": 8875
    },
    {
      "epoch": 0.1405386576309831,
      "grad_norm": 0.10970591753721237,
      "learning_rate": 8.594613423690171e-06,
      "loss": 0.0539,
      "step": 8876
    },
    {
      "epoch": 0.14055449118862517,
      "grad_norm": 0.4145166575908661,
      "learning_rate": 8.594455088113748e-06,
      "loss": 0.4988,
      "step": 8877
    },
    {
      "epoch": 0.14057032474626724,
      "grad_norm": 0.000698457530234009,
      "learning_rate": 8.594296752537329e-06,
      "loss": 0.0,
      "step": 8878
    },
    {
      "epoch": 0.1405861583039093,
      "grad_norm": 0.005410115700215101,
      "learning_rate": 8.594138416960908e-06,
      "loss": 0.0003,
      "step": 8879
    },
    {
      "epoch": 0.14060199186155137,
      "grad_norm": 0.33100005984306335,
      "learning_rate": 8.593980081384487e-06,
      "loss": 0.2458,
      "step": 8880
    },
    {
      "epoch": 0.14061782541919343,
      "grad_norm": 0.6293632984161377,
      "learning_rate": 8.593821745808066e-06,
      "loss": 0.0901,
      "step": 8881
    },
    {
      "epoch": 0.1406336589768355,
      "grad_norm": 0.00018742184329312295,
      "learning_rate": 8.593663410231645e-06,
      "loss": 0.0,
      "step": 8882
    },
    {
      "epoch": 0.14064949253447756,
      "grad_norm": 0.35883623361587524,
      "learning_rate": 8.593505074655224e-06,
      "loss": 0.0952,
      "step": 8883
    },
    {
      "epoch": 0.14066532609211962,
      "grad_norm": 0.5826972126960754,
      "learning_rate": 8.593346739078803e-06,
      "loss": 0.3256,
      "step": 8884
    },
    {
      "epoch": 0.14068115964976172,
      "grad_norm": 0.4413972795009613,
      "learning_rate": 8.593188403502384e-06,
      "loss": 0.4889,
      "step": 8885
    },
    {
      "epoch": 0.14069699320740378,
      "grad_norm": 0.00020998381660319865,
      "learning_rate": 8.593030067925963e-06,
      "loss": 0.0,
      "step": 8886
    },
    {
      "epoch": 0.14071282676504585,
      "grad_norm": 0.6382533311843872,
      "learning_rate": 8.592871732349542e-06,
      "loss": 0.4167,
      "step": 8887
    },
    {
      "epoch": 0.1407286603226879,
      "grad_norm": 6.438461423385888e-05,
      "learning_rate": 8.592713396773121e-06,
      "loss": 0.0,
      "step": 8888
    },
    {
      "epoch": 0.14074449388032997,
      "grad_norm": 0.27407118678092957,
      "learning_rate": 8.5925550611967e-06,
      "loss": 0.0744,
      "step": 8889
    },
    {
      "epoch": 0.14076032743797204,
      "grad_norm": 0.4462887942790985,
      "learning_rate": 8.59239672562028e-06,
      "loss": 0.3135,
      "step": 8890
    },
    {
      "epoch": 0.1407761609956141,
      "grad_norm": 0.0006717865471728146,
      "learning_rate": 8.59223839004386e-06,
      "loss": 0.0,
      "step": 8891
    },
    {
      "epoch": 0.14079199455325617,
      "grad_norm": 0.19751177728176117,
      "learning_rate": 8.59208005446744e-06,
      "loss": 0.093,
      "step": 8892
    },
    {
      "epoch": 0.14080782811089823,
      "grad_norm": 0.607703685760498,
      "learning_rate": 8.591921718891019e-06,
      "loss": 0.7816,
      "step": 8893
    },
    {
      "epoch": 0.1408236616685403,
      "grad_norm": 0.13126806914806366,
      "learning_rate": 8.591763383314598e-06,
      "loss": 0.0464,
      "step": 8894
    },
    {
      "epoch": 0.14083949522618236,
      "grad_norm": 0.0004115485935471952,
      "learning_rate": 8.591605047738177e-06,
      "loss": 0.0,
      "step": 8895
    },
    {
      "epoch": 0.14085532878382442,
      "grad_norm": 0.5315563678741455,
      "learning_rate": 8.591446712161756e-06,
      "loss": 0.1371,
      "step": 8896
    },
    {
      "epoch": 0.14087116234146652,
      "grad_norm": 0.0008221992757171392,
      "learning_rate": 8.591288376585337e-06,
      "loss": 0.0,
      "step": 8897
    },
    {
      "epoch": 0.14088699589910858,
      "grad_norm": 0.22473683953285217,
      "learning_rate": 8.591130041008916e-06,
      "loss": 0.1366,
      "step": 8898
    },
    {
      "epoch": 0.14090282945675064,
      "grad_norm": 0.40324869751930237,
      "learning_rate": 8.590971705432495e-06,
      "loss": 0.6727,
      "step": 8899
    },
    {
      "epoch": 0.1409186630143927,
      "grad_norm": 0.009394871070981026,
      "learning_rate": 8.590813369856074e-06,
      "loss": 0.0005,
      "step": 8900
    },
    {
      "epoch": 0.14093449657203477,
      "grad_norm": 0.16511447727680206,
      "learning_rate": 8.590655034279653e-06,
      "loss": 0.0393,
      "step": 8901
    },
    {
      "epoch": 0.14095033012967684,
      "grad_norm": 0.00044672549120150506,
      "learning_rate": 8.590496698703232e-06,
      "loss": 0.0,
      "step": 8902
    },
    {
      "epoch": 0.1409661636873189,
      "grad_norm": 0.01817169040441513,
      "learning_rate": 8.590338363126811e-06,
      "loss": 0.001,
      "step": 8903
    },
    {
      "epoch": 0.14098199724496097,
      "grad_norm": 0.5017858743667603,
      "learning_rate": 8.590180027550392e-06,
      "loss": 0.6185,
      "step": 8904
    },
    {
      "epoch": 0.14099783080260303,
      "grad_norm": 0.0001402688940288499,
      "learning_rate": 8.59002169197397e-06,
      "loss": 0.0,
      "step": 8905
    },
    {
      "epoch": 0.1410136643602451,
      "grad_norm": 0.5299234986305237,
      "learning_rate": 8.58986335639755e-06,
      "loss": 0.534,
      "step": 8906
    },
    {
      "epoch": 0.14102949791788716,
      "grad_norm": 0.01712328940629959,
      "learning_rate": 8.589705020821129e-06,
      "loss": 0.001,
      "step": 8907
    },
    {
      "epoch": 0.14104533147552922,
      "grad_norm": 0.44512850046157837,
      "learning_rate": 8.589546685244708e-06,
      "loss": 0.1993,
      "step": 8908
    },
    {
      "epoch": 0.14106116503317132,
      "grad_norm": 0.25939062237739563,
      "learning_rate": 8.589388349668287e-06,
      "loss": 0.0751,
      "step": 8909
    },
    {
      "epoch": 0.14107699859081338,
      "grad_norm": 0.44248679280281067,
      "learning_rate": 8.589230014091868e-06,
      "loss": 0.1334,
      "step": 8910
    },
    {
      "epoch": 0.14109283214845544,
      "grad_norm": 0.48052871227264404,
      "learning_rate": 8.589071678515445e-06,
      "loss": 0.5113,
      "step": 8911
    },
    {
      "epoch": 0.1411086657060975,
      "grad_norm": 0.16664165258407593,
      "learning_rate": 8.588913342939026e-06,
      "loss": 0.0239,
      "step": 8912
    },
    {
      "epoch": 0.14112449926373957,
      "grad_norm": 0.0006397883989848197,
      "learning_rate": 8.588755007362605e-06,
      "loss": 0.0,
      "step": 8913
    },
    {
      "epoch": 0.14114033282138164,
      "grad_norm": 0.35101184248924255,
      "learning_rate": 8.588596671786184e-06,
      "loss": 0.121,
      "step": 8914
    },
    {
      "epoch": 0.1411561663790237,
      "grad_norm": 0.6127483248710632,
      "learning_rate": 8.588438336209763e-06,
      "loss": 0.374,
      "step": 8915
    },
    {
      "epoch": 0.14117199993666577,
      "grad_norm": 0.46622082591056824,
      "learning_rate": 8.588280000633343e-06,
      "loss": 0.517,
      "step": 8916
    },
    {
      "epoch": 0.14118783349430783,
      "grad_norm": 0.013702617026865482,
      "learning_rate": 8.588121665056922e-06,
      "loss": 0.0008,
      "step": 8917
    },
    {
      "epoch": 0.1412036670519499,
      "grad_norm": 0.00021829291654285043,
      "learning_rate": 8.587963329480502e-06,
      "loss": 0.0,
      "step": 8918
    },
    {
      "epoch": 0.14121950060959196,
      "grad_norm": 0.24873115122318268,
      "learning_rate": 8.587804993904081e-06,
      "loss": 0.1172,
      "step": 8919
    },
    {
      "epoch": 0.14123533416723402,
      "grad_norm": 0.005055421497672796,
      "learning_rate": 8.58764665832766e-06,
      "loss": 0.0002,
      "step": 8920
    },
    {
      "epoch": 0.14125116772487611,
      "grad_norm": 0.2293744683265686,
      "learning_rate": 8.58748832275124e-06,
      "loss": 0.0354,
      "step": 8921
    },
    {
      "epoch": 0.14126700128251818,
      "grad_norm": 0.20699594914913177,
      "learning_rate": 8.587329987174819e-06,
      "loss": 0.0933,
      "step": 8922
    },
    {
      "epoch": 0.14128283484016024,
      "grad_norm": 0.06857883185148239,
      "learning_rate": 8.587171651598398e-06,
      "loss": 0.0027,
      "step": 8923
    },
    {
      "epoch": 0.1412986683978023,
      "grad_norm": 0.17744362354278564,
      "learning_rate": 8.587013316021979e-06,
      "loss": 0.0416,
      "step": 8924
    },
    {
      "epoch": 0.14131450195544437,
      "grad_norm": 0.7087235450744629,
      "learning_rate": 8.586854980445558e-06,
      "loss": 0.6101,
      "step": 8925
    },
    {
      "epoch": 0.14133033551308644,
      "grad_norm": 0.05585214123129845,
      "learning_rate": 8.586696644869137e-06,
      "loss": 0.0013,
      "step": 8926
    },
    {
      "epoch": 0.1413461690707285,
      "grad_norm": 0.013930387794971466,
      "learning_rate": 8.586538309292716e-06,
      "loss": 0.0007,
      "step": 8927
    },
    {
      "epoch": 0.14136200262837056,
      "grad_norm": 0.4688136875629425,
      "learning_rate": 8.586379973716295e-06,
      "loss": 0.2072,
      "step": 8928
    },
    {
      "epoch": 0.14137783618601263,
      "grad_norm": 0.005334367044270039,
      "learning_rate": 8.586221638139874e-06,
      "loss": 0.0002,
      "step": 8929
    },
    {
      "epoch": 0.1413936697436547,
      "grad_norm": 0.3639076352119446,
      "learning_rate": 8.586063302563453e-06,
      "loss": 0.0681,
      "step": 8930
    },
    {
      "epoch": 0.14140950330129676,
      "grad_norm": 0.19474905729293823,
      "learning_rate": 8.585904966987034e-06,
      "loss": 0.0927,
      "step": 8931
    },
    {
      "epoch": 0.14142533685893882,
      "grad_norm": 0.015342471189796925,
      "learning_rate": 8.585746631410611e-06,
      "loss": 0.0007,
      "step": 8932
    },
    {
      "epoch": 0.1414411704165809,
      "grad_norm": 0.004305244889110327,
      "learning_rate": 8.585588295834192e-06,
      "loss": 0.0002,
      "step": 8933
    },
    {
      "epoch": 0.14145700397422298,
      "grad_norm": 0.39506444334983826,
      "learning_rate": 8.585429960257771e-06,
      "loss": 0.041,
      "step": 8934
    },
    {
      "epoch": 0.14147283753186504,
      "grad_norm": 0.48901820182800293,
      "learning_rate": 8.58527162468135e-06,
      "loss": 0.6023,
      "step": 8935
    },
    {
      "epoch": 0.1414886710895071,
      "grad_norm": 0.006797450594604015,
      "learning_rate": 8.58511328910493e-06,
      "loss": 0.0003,
      "step": 8936
    },
    {
      "epoch": 0.14150450464714917,
      "grad_norm": 0.40486910939216614,
      "learning_rate": 8.58495495352851e-06,
      "loss": 0.3958,
      "step": 8937
    },
    {
      "epoch": 0.14152033820479124,
      "grad_norm": 0.8393898010253906,
      "learning_rate": 8.584796617952087e-06,
      "loss": 0.1206,
      "step": 8938
    },
    {
      "epoch": 0.1415361717624333,
      "grad_norm": 0.366513729095459,
      "learning_rate": 8.584638282375668e-06,
      "loss": 0.2135,
      "step": 8939
    },
    {
      "epoch": 0.14155200532007536,
      "grad_norm": 0.41082844138145447,
      "learning_rate": 8.584479946799247e-06,
      "loss": 0.0094,
      "step": 8940
    },
    {
      "epoch": 0.14156783887771743,
      "grad_norm": 0.006027926690876484,
      "learning_rate": 8.584321611222826e-06,
      "loss": 0.0003,
      "step": 8941
    },
    {
      "epoch": 0.1415836724353595,
      "grad_norm": 0.46243590116500854,
      "learning_rate": 8.584163275646405e-06,
      "loss": 0.3673,
      "step": 8942
    },
    {
      "epoch": 0.14159950599300156,
      "grad_norm": 0.2143658995628357,
      "learning_rate": 8.584004940069986e-06,
      "loss": 0.1645,
      "step": 8943
    },
    {
      "epoch": 0.14161533955064362,
      "grad_norm": 0.016303258016705513,
      "learning_rate": 8.583846604493564e-06,
      "loss": 0.0006,
      "step": 8944
    },
    {
      "epoch": 0.1416311731082857,
      "grad_norm": 0.43334484100341797,
      "learning_rate": 8.583688268917144e-06,
      "loss": 0.1575,
      "step": 8945
    },
    {
      "epoch": 0.14164700666592778,
      "grad_norm": 0.5572533011436462,
      "learning_rate": 8.583529933340723e-06,
      "loss": 0.2184,
      "step": 8946
    },
    {
      "epoch": 0.14166284022356984,
      "grad_norm": 0.2034037560224533,
      "learning_rate": 8.583371597764302e-06,
      "loss": 0.0688,
      "step": 8947
    },
    {
      "epoch": 0.1416786737812119,
      "grad_norm": 0.39020833373069763,
      "learning_rate": 8.583213262187882e-06,
      "loss": 0.0823,
      "step": 8948
    },
    {
      "epoch": 0.14169450733885397,
      "grad_norm": 0.259515643119812,
      "learning_rate": 8.583054926611462e-06,
      "loss": 0.1157,
      "step": 8949
    },
    {
      "epoch": 0.14171034089649603,
      "grad_norm": 0.36132100224494934,
      "learning_rate": 8.58289659103504e-06,
      "loss": 0.191,
      "step": 8950
    },
    {
      "epoch": 0.1417261744541381,
      "grad_norm": 0.00013085566752124578,
      "learning_rate": 8.582738255458619e-06,
      "loss": 0.0,
      "step": 8951
    },
    {
      "epoch": 0.14174200801178016,
      "grad_norm": 0.43774649500846863,
      "learning_rate": 8.5825799198822e-06,
      "loss": 0.103,
      "step": 8952
    },
    {
      "epoch": 0.14175784156942223,
      "grad_norm": 0.011854210868477821,
      "learning_rate": 8.582421584305779e-06,
      "loss": 0.0007,
      "step": 8953
    },
    {
      "epoch": 0.1417736751270643,
      "grad_norm": 0.33158305287361145,
      "learning_rate": 8.582263248729358e-06,
      "loss": 0.1969,
      "step": 8954
    },
    {
      "epoch": 0.14178950868470636,
      "grad_norm": 0.01582466810941696,
      "learning_rate": 8.582104913152937e-06,
      "loss": 0.0002,
      "step": 8955
    },
    {
      "epoch": 0.14180534224234842,
      "grad_norm": 0.30669689178466797,
      "learning_rate": 8.581946577576516e-06,
      "loss": 0.1633,
      "step": 8956
    },
    {
      "epoch": 0.1418211757999905,
      "grad_norm": 0.41559967398643494,
      "learning_rate": 8.581788242000095e-06,
      "loss": 0.2664,
      "step": 8957
    },
    {
      "epoch": 0.14183700935763258,
      "grad_norm": 0.174236461520195,
      "learning_rate": 8.581629906423676e-06,
      "loss": 0.0242,
      "step": 8958
    },
    {
      "epoch": 0.14185284291527464,
      "grad_norm": 0.15202312171459198,
      "learning_rate": 8.581471570847255e-06,
      "loss": 0.0355,
      "step": 8959
    },
    {
      "epoch": 0.1418686764729167,
      "grad_norm": 0.16853031516075134,
      "learning_rate": 8.581313235270834e-06,
      "loss": 0.0543,
      "step": 8960
    },
    {
      "epoch": 0.14188451003055877,
      "grad_norm": 0.7613052725791931,
      "learning_rate": 8.581154899694413e-06,
      "loss": 0.0898,
      "step": 8961
    },
    {
      "epoch": 0.14190034358820083,
      "grad_norm": 0.4991030991077423,
      "learning_rate": 8.580996564117992e-06,
      "loss": 0.2915,
      "step": 8962
    },
    {
      "epoch": 0.1419161771458429,
      "grad_norm": 0.01674067974090576,
      "learning_rate": 8.580838228541571e-06,
      "loss": 0.0009,
      "step": 8963
    },
    {
      "epoch": 0.14193201070348496,
      "grad_norm": 0.5018807053565979,
      "learning_rate": 8.580679892965152e-06,
      "loss": 0.1311,
      "step": 8964
    },
    {
      "epoch": 0.14194784426112703,
      "grad_norm": 0.3274681866168976,
      "learning_rate": 8.580521557388731e-06,
      "loss": 0.272,
      "step": 8965
    },
    {
      "epoch": 0.1419636778187691,
      "grad_norm": 0.00927154440432787,
      "learning_rate": 8.58036322181231e-06,
      "loss": 0.0004,
      "step": 8966
    },
    {
      "epoch": 0.14197951137641115,
      "grad_norm": 0.3471481204032898,
      "learning_rate": 8.580204886235889e-06,
      "loss": 0.0688,
      "step": 8967
    },
    {
      "epoch": 0.14199534493405322,
      "grad_norm": 0.36039018630981445,
      "learning_rate": 8.580046550659468e-06,
      "loss": 0.1551,
      "step": 8968
    },
    {
      "epoch": 0.1420111784916953,
      "grad_norm": 0.02185782976448536,
      "learning_rate": 8.579888215083047e-06,
      "loss": 0.0014,
      "step": 8969
    },
    {
      "epoch": 0.14202701204933738,
      "grad_norm": 0.0001398510066792369,
      "learning_rate": 8.579729879506628e-06,
      "loss": 0.0,
      "step": 8970
    },
    {
      "epoch": 0.14204284560697944,
      "grad_norm": 0.3901238739490509,
      "learning_rate": 8.579571543930207e-06,
      "loss": 0.1347,
      "step": 8971
    },
    {
      "epoch": 0.1420586791646215,
      "grad_norm": 0.1950656920671463,
      "learning_rate": 8.579413208353786e-06,
      "loss": 0.0607,
      "step": 8972
    },
    {
      "epoch": 0.14207451272226357,
      "grad_norm": 0.14330936968326569,
      "learning_rate": 8.579254872777365e-06,
      "loss": 0.0738,
      "step": 8973
    },
    {
      "epoch": 0.14209034627990563,
      "grad_norm": 0.28229665756225586,
      "learning_rate": 8.579096537200944e-06,
      "loss": 0.0463,
      "step": 8974
    },
    {
      "epoch": 0.1421061798375477,
      "grad_norm": 0.24225017428398132,
      "learning_rate": 8.578938201624523e-06,
      "loss": 0.1748,
      "step": 8975
    },
    {
      "epoch": 0.14212201339518976,
      "grad_norm": 0.1593901365995407,
      "learning_rate": 8.578779866048103e-06,
      "loss": 0.0579,
      "step": 8976
    },
    {
      "epoch": 0.14213784695283183,
      "grad_norm": 0.2203378826379776,
      "learning_rate": 8.578621530471682e-06,
      "loss": 0.1119,
      "step": 8977
    },
    {
      "epoch": 0.1421536805104739,
      "grad_norm": 0.13545618951320648,
      "learning_rate": 8.57846319489526e-06,
      "loss": 0.0674,
      "step": 8978
    },
    {
      "epoch": 0.14216951406811595,
      "grad_norm": 0.5117617249488831,
      "learning_rate": 8.578304859318841e-06,
      "loss": 0.097,
      "step": 8979
    },
    {
      "epoch": 0.14218534762575802,
      "grad_norm": 0.10668209940195084,
      "learning_rate": 8.57814652374242e-06,
      "loss": 0.061,
      "step": 8980
    },
    {
      "epoch": 0.1422011811834001,
      "grad_norm": 0.25940752029418945,
      "learning_rate": 8.577988188166e-06,
      "loss": 0.0902,
      "step": 8981
    },
    {
      "epoch": 0.14221701474104217,
      "grad_norm": 0.21036069095134735,
      "learning_rate": 8.577829852589579e-06,
      "loss": 0.0805,
      "step": 8982
    },
    {
      "epoch": 0.14223284829868424,
      "grad_norm": 0.0002300424821441993,
      "learning_rate": 8.577671517013158e-06,
      "loss": 0.0,
      "step": 8983
    },
    {
      "epoch": 0.1422486818563263,
      "grad_norm": 0.5002239346504211,
      "learning_rate": 8.577513181436737e-06,
      "loss": 0.0804,
      "step": 8984
    },
    {
      "epoch": 0.14226451541396837,
      "grad_norm": 0.2501427233219147,
      "learning_rate": 8.577354845860318e-06,
      "loss": 0.0718,
      "step": 8985
    },
    {
      "epoch": 0.14228034897161043,
      "grad_norm": 0.4501730501651764,
      "learning_rate": 8.577196510283897e-06,
      "loss": 0.1244,
      "step": 8986
    },
    {
      "epoch": 0.1422961825292525,
      "grad_norm": 0.1233256533741951,
      "learning_rate": 8.577038174707476e-06,
      "loss": 0.0396,
      "step": 8987
    },
    {
      "epoch": 0.14231201608689456,
      "grad_norm": 0.3657739758491516,
      "learning_rate": 8.576879839131055e-06,
      "loss": 0.0892,
      "step": 8988
    },
    {
      "epoch": 0.14232784964453662,
      "grad_norm": 0.2168339341878891,
      "learning_rate": 8.576721503554634e-06,
      "loss": 0.0601,
      "step": 8989
    },
    {
      "epoch": 0.1423436832021787,
      "grad_norm": 8.043389243539423e-05,
      "learning_rate": 8.576563167978213e-06,
      "loss": 0.0,
      "step": 8990
    },
    {
      "epoch": 0.14235951675982075,
      "grad_norm": 0.5102462768554688,
      "learning_rate": 8.576404832401794e-06,
      "loss": 0.8267,
      "step": 8991
    },
    {
      "epoch": 0.14237535031746282,
      "grad_norm": 0.4845048785209656,
      "learning_rate": 8.576246496825373e-06,
      "loss": 0.2091,
      "step": 8992
    },
    {
      "epoch": 0.1423911838751049,
      "grad_norm": 0.43960773944854736,
      "learning_rate": 8.576088161248952e-06,
      "loss": 0.1818,
      "step": 8993
    },
    {
      "epoch": 0.14240701743274697,
      "grad_norm": 0.5131067633628845,
      "learning_rate": 8.575929825672531e-06,
      "loss": 0.3348,
      "step": 8994
    },
    {
      "epoch": 0.14242285099038904,
      "grad_norm": 0.4366549551486969,
      "learning_rate": 8.57577149009611e-06,
      "loss": 0.0352,
      "step": 8995
    },
    {
      "epoch": 0.1424386845480311,
      "grad_norm": 0.5047526359558105,
      "learning_rate": 8.57561315451969e-06,
      "loss": 0.6764,
      "step": 8996
    },
    {
      "epoch": 0.14245451810567317,
      "grad_norm": 0.22484295070171356,
      "learning_rate": 8.57545481894327e-06,
      "loss": 0.0959,
      "step": 8997
    },
    {
      "epoch": 0.14247035166331523,
      "grad_norm": 0.12775443494319916,
      "learning_rate": 8.575296483366849e-06,
      "loss": 0.0218,
      "step": 8998
    },
    {
      "epoch": 0.1424861852209573,
      "grad_norm": 0.5330497026443481,
      "learning_rate": 8.575138147790426e-06,
      "loss": 0.094,
      "step": 8999
    },
    {
      "epoch": 0.14250201877859936,
      "grad_norm": 0.0022780706640332937,
      "learning_rate": 8.574979812214007e-06,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 0.14251785233624142,
      "grad_norm": 0.35227566957473755,
      "learning_rate": 8.574821476637586e-06,
      "loss": 0.0922,
      "step": 9001
    },
    {
      "epoch": 0.1425336858938835,
      "grad_norm": 0.5343432426452637,
      "learning_rate": 8.574663141061165e-06,
      "loss": 0.4778,
      "step": 9002
    },
    {
      "epoch": 0.14254951945152555,
      "grad_norm": 0.602097749710083,
      "learning_rate": 8.574504805484744e-06,
      "loss": 0.0592,
      "step": 9003
    },
    {
      "epoch": 0.14256535300916762,
      "grad_norm": 0.3735736012458801,
      "learning_rate": 8.574346469908325e-06,
      "loss": 0.1191,
      "step": 9004
    },
    {
      "epoch": 0.1425811865668097,
      "grad_norm": 0.22633445262908936,
      "learning_rate": 8.574188134331903e-06,
      "loss": 0.2088,
      "step": 9005
    },
    {
      "epoch": 0.14259702012445177,
      "grad_norm": 0.007974158972501755,
      "learning_rate": 8.574029798755483e-06,
      "loss": 0.0003,
      "step": 9006
    },
    {
      "epoch": 0.14261285368209384,
      "grad_norm": 0.5751082897186279,
      "learning_rate": 8.573871463179062e-06,
      "loss": 0.2492,
      "step": 9007
    },
    {
      "epoch": 0.1426286872397359,
      "grad_norm": 0.022848697379231453,
      "learning_rate": 8.573713127602642e-06,
      "loss": 0.0013,
      "step": 9008
    },
    {
      "epoch": 0.14264452079737797,
      "grad_norm": 0.4547296166419983,
      "learning_rate": 8.57355479202622e-06,
      "loss": 0.2969,
      "step": 9009
    },
    {
      "epoch": 0.14266035435502003,
      "grad_norm": 0.22422192990779877,
      "learning_rate": 8.573396456449801e-06,
      "loss": 0.0798,
      "step": 9010
    },
    {
      "epoch": 0.1426761879126621,
      "grad_norm": 0.6405558586120605,
      "learning_rate": 8.573238120873379e-06,
      "loss": 0.3929,
      "step": 9011
    },
    {
      "epoch": 0.14269202147030416,
      "grad_norm": 0.01894262060523033,
      "learning_rate": 8.57307978529696e-06,
      "loss": 0.0009,
      "step": 9012
    },
    {
      "epoch": 0.14270785502794622,
      "grad_norm": 0.3946975767612457,
      "learning_rate": 8.572921449720539e-06,
      "loss": 0.5645,
      "step": 9013
    },
    {
      "epoch": 0.1427236885855883,
      "grad_norm": 0.3511946201324463,
      "learning_rate": 8.572763114144118e-06,
      "loss": 0.1328,
      "step": 9014
    },
    {
      "epoch": 0.14273952214323035,
      "grad_norm": 0.020237987861037254,
      "learning_rate": 8.572604778567697e-06,
      "loss": 0.001,
      "step": 9015
    },
    {
      "epoch": 0.14275535570087242,
      "grad_norm": 0.0013464675284922123,
      "learning_rate": 8.572446442991278e-06,
      "loss": 0.0,
      "step": 9016
    },
    {
      "epoch": 0.1427711892585145,
      "grad_norm": 0.1159273236989975,
      "learning_rate": 8.572288107414855e-06,
      "loss": 0.0311,
      "step": 9017
    },
    {
      "epoch": 0.14278702281615657,
      "grad_norm": 0.20400911569595337,
      "learning_rate": 8.572129771838436e-06,
      "loss": 0.0653,
      "step": 9018
    },
    {
      "epoch": 0.14280285637379864,
      "grad_norm": 0.6261057257652283,
      "learning_rate": 8.571971436262015e-06,
      "loss": 0.3135,
      "step": 9019
    },
    {
      "epoch": 0.1428186899314407,
      "grad_norm": 0.2600972652435303,
      "learning_rate": 8.571813100685594e-06,
      "loss": 0.1239,
      "step": 9020
    },
    {
      "epoch": 0.14283452348908277,
      "grad_norm": 0.4098531901836395,
      "learning_rate": 8.571654765109173e-06,
      "loss": 0.6327,
      "step": 9021
    },
    {
      "epoch": 0.14285035704672483,
      "grad_norm": 0.352954626083374,
      "learning_rate": 8.571496429532754e-06,
      "loss": 0.2266,
      "step": 9022
    },
    {
      "epoch": 0.1428661906043669,
      "grad_norm": 0.25811511278152466,
      "learning_rate": 8.571338093956331e-06,
      "loss": 0.0997,
      "step": 9023
    },
    {
      "epoch": 0.14288202416200896,
      "grad_norm": 0.38992318511009216,
      "learning_rate": 8.57117975837991e-06,
      "loss": 0.0877,
      "step": 9024
    },
    {
      "epoch": 0.14289785771965102,
      "grad_norm": 0.35556092858314514,
      "learning_rate": 8.571021422803491e-06,
      "loss": 0.0996,
      "step": 9025
    },
    {
      "epoch": 0.1429136912772931,
      "grad_norm": 0.4842482805252075,
      "learning_rate": 8.57086308722707e-06,
      "loss": 0.4437,
      "step": 9026
    },
    {
      "epoch": 0.14292952483493515,
      "grad_norm": 0.2580583095550537,
      "learning_rate": 8.570704751650649e-06,
      "loss": 0.1073,
      "step": 9027
    },
    {
      "epoch": 0.14294535839257722,
      "grad_norm": 0.23926742374897003,
      "learning_rate": 8.570546416074228e-06,
      "loss": 0.1242,
      "step": 9028
    },
    {
      "epoch": 0.1429611919502193,
      "grad_norm": 0.05871017277240753,
      "learning_rate": 8.570388080497807e-06,
      "loss": 0.0106,
      "step": 9029
    },
    {
      "epoch": 0.14297702550786137,
      "grad_norm": 0.00029043934773653746,
      "learning_rate": 8.570229744921386e-06,
      "loss": 0.0,
      "step": 9030
    },
    {
      "epoch": 0.14299285906550344,
      "grad_norm": 0.13548079133033752,
      "learning_rate": 8.570071409344967e-06,
      "loss": 0.012,
      "step": 9031
    },
    {
      "epoch": 0.1430086926231455,
      "grad_norm": 0.24622724950313568,
      "learning_rate": 8.569913073768546e-06,
      "loss": 0.1181,
      "step": 9032
    },
    {
      "epoch": 0.14302452618078756,
      "grad_norm": 0.3601384460926056,
      "learning_rate": 8.569754738192125e-06,
      "loss": 0.0315,
      "step": 9033
    },
    {
      "epoch": 0.14304035973842963,
      "grad_norm": 0.25486308336257935,
      "learning_rate": 8.569596402615704e-06,
      "loss": 0.0732,
      "step": 9034
    },
    {
      "epoch": 0.1430561932960717,
      "grad_norm": 0.5335816144943237,
      "learning_rate": 8.569438067039283e-06,
      "loss": 0.6098,
      "step": 9035
    },
    {
      "epoch": 0.14307202685371376,
      "grad_norm": 0.1579471379518509,
      "learning_rate": 8.569279731462863e-06,
      "loss": 0.0621,
      "step": 9036
    },
    {
      "epoch": 0.14308786041135582,
      "grad_norm": 0.00023164201411418617,
      "learning_rate": 8.569121395886443e-06,
      "loss": 0.0,
      "step": 9037
    },
    {
      "epoch": 0.14310369396899789,
      "grad_norm": 1.267210841178894,
      "learning_rate": 8.568963060310022e-06,
      "loss": 0.4573,
      "step": 9038
    },
    {
      "epoch": 0.14311952752663995,
      "grad_norm": 0.26482272148132324,
      "learning_rate": 8.568804724733601e-06,
      "loss": 0.1063,
      "step": 9039
    },
    {
      "epoch": 0.14313536108428201,
      "grad_norm": 0.24120467901229858,
      "learning_rate": 8.56864638915718e-06,
      "loss": 0.0508,
      "step": 9040
    },
    {
      "epoch": 0.1431511946419241,
      "grad_norm": 0.8291908502578735,
      "learning_rate": 8.56848805358076e-06,
      "loss": 0.1674,
      "step": 9041
    },
    {
      "epoch": 0.14316702819956617,
      "grad_norm": 0.2943938672542572,
      "learning_rate": 8.568329718004339e-06,
      "loss": 0.0564,
      "step": 9042
    },
    {
      "epoch": 0.14318286175720824,
      "grad_norm": 0.6758292317390442,
      "learning_rate": 8.56817138242792e-06,
      "loss": 0.0716,
      "step": 9043
    },
    {
      "epoch": 0.1431986953148503,
      "grad_norm": 0.2737504541873932,
      "learning_rate": 8.568013046851497e-06,
      "loss": 0.0553,
      "step": 9044
    },
    {
      "epoch": 0.14321452887249236,
      "grad_norm": 0.11980413645505905,
      "learning_rate": 8.567854711275078e-06,
      "loss": 0.0151,
      "step": 9045
    },
    {
      "epoch": 0.14323036243013443,
      "grad_norm": 3.7908570766448975,
      "learning_rate": 8.567696375698657e-06,
      "loss": 0.2017,
      "step": 9046
    },
    {
      "epoch": 0.1432461959877765,
      "grad_norm": 0.5772420763969421,
      "learning_rate": 8.567538040122236e-06,
      "loss": 0.5892,
      "step": 9047
    },
    {
      "epoch": 0.14326202954541856,
      "grad_norm": 0.051224347203969955,
      "learning_rate": 8.567379704545815e-06,
      "loss": 0.0072,
      "step": 9048
    },
    {
      "epoch": 0.14327786310306062,
      "grad_norm": 0.34464168548583984,
      "learning_rate": 8.567221368969394e-06,
      "loss": 0.2932,
      "step": 9049
    },
    {
      "epoch": 0.14329369666070269,
      "grad_norm": 0.14485079050064087,
      "learning_rate": 8.567063033392973e-06,
      "loss": 0.0392,
      "step": 9050
    },
    {
      "epoch": 0.14330953021834475,
      "grad_norm": 0.04132755473256111,
      "learning_rate": 8.566904697816552e-06,
      "loss": 0.0023,
      "step": 9051
    },
    {
      "epoch": 0.1433253637759868,
      "grad_norm": 0.009936532936990261,
      "learning_rate": 8.566746362240133e-06,
      "loss": 0.0006,
      "step": 9052
    },
    {
      "epoch": 0.1433411973336289,
      "grad_norm": 0.32277658581733704,
      "learning_rate": 8.566588026663712e-06,
      "loss": 0.2908,
      "step": 9053
    },
    {
      "epoch": 0.14335703089127097,
      "grad_norm": 0.2959024906158447,
      "learning_rate": 8.566429691087291e-06,
      "loss": 0.2144,
      "step": 9054
    },
    {
      "epoch": 0.14337286444891303,
      "grad_norm": 0.06681567430496216,
      "learning_rate": 8.56627135551087e-06,
      "loss": 0.0013,
      "step": 9055
    },
    {
      "epoch": 0.1433886980065551,
      "grad_norm": 0.13649138808250427,
      "learning_rate": 8.56611301993445e-06,
      "loss": 0.0501,
      "step": 9056
    },
    {
      "epoch": 0.14340453156419716,
      "grad_norm": 0.15384069085121155,
      "learning_rate": 8.565954684358028e-06,
      "loss": 0.0613,
      "step": 9057
    },
    {
      "epoch": 0.14342036512183923,
      "grad_norm": 0.4399792551994324,
      "learning_rate": 8.565796348781609e-06,
      "loss": 0.1637,
      "step": 9058
    },
    {
      "epoch": 0.1434361986794813,
      "grad_norm": 0.35369694232940674,
      "learning_rate": 8.565638013205188e-06,
      "loss": 0.0087,
      "step": 9059
    },
    {
      "epoch": 0.14345203223712336,
      "grad_norm": 0.2636660039424896,
      "learning_rate": 8.565479677628767e-06,
      "loss": 0.0628,
      "step": 9060
    },
    {
      "epoch": 0.14346786579476542,
      "grad_norm": 0.602445662021637,
      "learning_rate": 8.565321342052346e-06,
      "loss": 0.7023,
      "step": 9061
    },
    {
      "epoch": 0.14348369935240748,
      "grad_norm": 0.0004767525242641568,
      "learning_rate": 8.565163006475925e-06,
      "loss": 0.0,
      "step": 9062
    },
    {
      "epoch": 0.14349953291004955,
      "grad_norm": 0.298739492893219,
      "learning_rate": 8.565004670899504e-06,
      "loss": 0.1649,
      "step": 9063
    },
    {
      "epoch": 0.1435153664676916,
      "grad_norm": 0.18324211239814758,
      "learning_rate": 8.564846335323085e-06,
      "loss": 0.0496,
      "step": 9064
    },
    {
      "epoch": 0.1435312000253337,
      "grad_norm": 0.8452017903327942,
      "learning_rate": 8.564687999746664e-06,
      "loss": 0.3647,
      "step": 9065
    },
    {
      "epoch": 0.14354703358297577,
      "grad_norm": 0.41865605115890503,
      "learning_rate": 8.564529664170243e-06,
      "loss": 0.1289,
      "step": 9066
    },
    {
      "epoch": 0.14356286714061783,
      "grad_norm": 0.003623059019446373,
      "learning_rate": 8.564371328593822e-06,
      "loss": 0.0002,
      "step": 9067
    },
    {
      "epoch": 0.1435787006982599,
      "grad_norm": 0.2767201066017151,
      "learning_rate": 8.564212993017402e-06,
      "loss": 0.1055,
      "step": 9068
    },
    {
      "epoch": 0.14359453425590196,
      "grad_norm": 0.00814078375697136,
      "learning_rate": 8.56405465744098e-06,
      "loss": 0.0004,
      "step": 9069
    },
    {
      "epoch": 0.14361036781354403,
      "grad_norm": 0.28305062651634216,
      "learning_rate": 8.563896321864561e-06,
      "loss": 0.2153,
      "step": 9070
    },
    {
      "epoch": 0.1436262013711861,
      "grad_norm": 0.20675289630889893,
      "learning_rate": 8.56373798628814e-06,
      "loss": 0.0666,
      "step": 9071
    },
    {
      "epoch": 0.14364203492882816,
      "grad_norm": 0.44445809721946716,
      "learning_rate": 8.563579650711718e-06,
      "loss": 0.1721,
      "step": 9072
    },
    {
      "epoch": 0.14365786848647022,
      "grad_norm": 0.22634312510490417,
      "learning_rate": 8.563421315135299e-06,
      "loss": 0.1712,
      "step": 9073
    },
    {
      "epoch": 0.14367370204411228,
      "grad_norm": 0.21388380229473114,
      "learning_rate": 8.563262979558878e-06,
      "loss": 0.0879,
      "step": 9074
    },
    {
      "epoch": 0.14368953560175435,
      "grad_norm": 0.33153271675109863,
      "learning_rate": 8.563104643982457e-06,
      "loss": 0.1214,
      "step": 9075
    },
    {
      "epoch": 0.1437053691593964,
      "grad_norm": 0.21150371432304382,
      "learning_rate": 8.562946308406036e-06,
      "loss": 0.1731,
      "step": 9076
    },
    {
      "epoch": 0.1437212027170385,
      "grad_norm": 0.3292035460472107,
      "learning_rate": 8.562787972829617e-06,
      "loss": 0.0536,
      "step": 9077
    },
    {
      "epoch": 0.14373703627468057,
      "grad_norm": 0.5941116809844971,
      "learning_rate": 8.562629637253194e-06,
      "loss": 0.2867,
      "step": 9078
    },
    {
      "epoch": 0.14375286983232263,
      "grad_norm": 0.3414331078529358,
      "learning_rate": 8.562471301676775e-06,
      "loss": 0.2232,
      "step": 9079
    },
    {
      "epoch": 0.1437687033899647,
      "grad_norm": 0.022987861186265945,
      "learning_rate": 8.562312966100354e-06,
      "loss": 0.0013,
      "step": 9080
    },
    {
      "epoch": 0.14378453694760676,
      "grad_norm": 0.003485739231109619,
      "learning_rate": 8.562154630523933e-06,
      "loss": 0.0002,
      "step": 9081
    },
    {
      "epoch": 0.14380037050524883,
      "grad_norm": 0.030208464711904526,
      "learning_rate": 8.561996294947512e-06,
      "loss": 0.0015,
      "step": 9082
    },
    {
      "epoch": 0.1438162040628909,
      "grad_norm": 0.3514728248119354,
      "learning_rate": 8.561837959371093e-06,
      "loss": 0.1269,
      "step": 9083
    },
    {
      "epoch": 0.14383203762053295,
      "grad_norm": 0.0001075031395885162,
      "learning_rate": 8.56167962379467e-06,
      "loss": 0.0,
      "step": 9084
    },
    {
      "epoch": 0.14384787117817502,
      "grad_norm": 0.2915615141391754,
      "learning_rate": 8.561521288218251e-06,
      "loss": 0.0777,
      "step": 9085
    },
    {
      "epoch": 0.14386370473581708,
      "grad_norm": 0.011532379314303398,
      "learning_rate": 8.56136295264183e-06,
      "loss": 0.0013,
      "step": 9086
    },
    {
      "epoch": 0.14387953829345915,
      "grad_norm": 0.00032135529909282923,
      "learning_rate": 8.561204617065409e-06,
      "loss": 0.0,
      "step": 9087
    },
    {
      "epoch": 0.1438953718511012,
      "grad_norm": 0.3142266571521759,
      "learning_rate": 8.561046281488988e-06,
      "loss": 0.2324,
      "step": 9088
    },
    {
      "epoch": 0.1439112054087433,
      "grad_norm": 0.4431076645851135,
      "learning_rate": 8.560887945912569e-06,
      "loss": 0.1547,
      "step": 9089
    },
    {
      "epoch": 0.14392703896638537,
      "grad_norm": 0.545826256275177,
      "learning_rate": 8.560729610336146e-06,
      "loss": 0.0654,
      "step": 9090
    },
    {
      "epoch": 0.14394287252402743,
      "grad_norm": 0.242864727973938,
      "learning_rate": 8.560571274759727e-06,
      "loss": 0.103,
      "step": 9091
    },
    {
      "epoch": 0.1439587060816695,
      "grad_norm": 0.21195046603679657,
      "learning_rate": 8.560412939183306e-06,
      "loss": 0.0998,
      "step": 9092
    },
    {
      "epoch": 0.14397453963931156,
      "grad_norm": 0.32847997546195984,
      "learning_rate": 8.560254603606885e-06,
      "loss": 0.0762,
      "step": 9093
    },
    {
      "epoch": 0.14399037319695362,
      "grad_norm": 0.0418599471449852,
      "learning_rate": 8.560096268030464e-06,
      "loss": 0.0024,
      "step": 9094
    },
    {
      "epoch": 0.1440062067545957,
      "grad_norm": 0.16685153543949127,
      "learning_rate": 8.559937932454043e-06,
      "loss": 0.0559,
      "step": 9095
    },
    {
      "epoch": 0.14402204031223775,
      "grad_norm": 0.38710400462150574,
      "learning_rate": 8.559779596877623e-06,
      "loss": 0.2813,
      "step": 9096
    },
    {
      "epoch": 0.14403787386987982,
      "grad_norm": 0.1773800104856491,
      "learning_rate": 8.559621261301202e-06,
      "loss": 0.0952,
      "step": 9097
    },
    {
      "epoch": 0.14405370742752188,
      "grad_norm": 0.27248939871788025,
      "learning_rate": 8.559462925724782e-06,
      "loss": 0.0063,
      "step": 9098
    },
    {
      "epoch": 0.14406954098516395,
      "grad_norm": 0.542416512966156,
      "learning_rate": 8.559304590148361e-06,
      "loss": 0.2254,
      "step": 9099
    },
    {
      "epoch": 0.144085374542806,
      "grad_norm": 0.23801934719085693,
      "learning_rate": 8.55914625457194e-06,
      "loss": 0.0285,
      "step": 9100
    },
    {
      "epoch": 0.1441012081004481,
      "grad_norm": 0.09942405670881271,
      "learning_rate": 8.55898791899552e-06,
      "loss": 0.0105,
      "step": 9101
    },
    {
      "epoch": 0.14411704165809017,
      "grad_norm": 0.19762010872364044,
      "learning_rate": 8.558829583419099e-06,
      "loss": 0.0758,
      "step": 9102
    },
    {
      "epoch": 0.14413287521573223,
      "grad_norm": 0.21117104589939117,
      "learning_rate": 8.558671247842678e-06,
      "loss": 0.0953,
      "step": 9103
    },
    {
      "epoch": 0.1441487087733743,
      "grad_norm": 0.004847430624067783,
      "learning_rate": 8.558512912266259e-06,
      "loss": 0.0002,
      "step": 9104
    },
    {
      "epoch": 0.14416454233101636,
      "grad_norm": 0.2940448820590973,
      "learning_rate": 8.558354576689838e-06,
      "loss": 0.1236,
      "step": 9105
    },
    {
      "epoch": 0.14418037588865842,
      "grad_norm": 0.005267065949738026,
      "learning_rate": 8.558196241113417e-06,
      "loss": 0.0002,
      "step": 9106
    },
    {
      "epoch": 0.1441962094463005,
      "grad_norm": 0.44917264580726624,
      "learning_rate": 8.558037905536996e-06,
      "loss": 0.545,
      "step": 9107
    },
    {
      "epoch": 0.14421204300394255,
      "grad_norm": 0.40233027935028076,
      "learning_rate": 8.557879569960575e-06,
      "loss": 0.1238,
      "step": 9108
    },
    {
      "epoch": 0.14422787656158462,
      "grad_norm": 0.10592494159936905,
      "learning_rate": 8.557721234384154e-06,
      "loss": 0.0027,
      "step": 9109
    },
    {
      "epoch": 0.14424371011922668,
      "grad_norm": 0.0007715059909969568,
      "learning_rate": 8.557562898807735e-06,
      "loss": 0.0,
      "step": 9110
    },
    {
      "epoch": 0.14425954367686875,
      "grad_norm": 0.5923798084259033,
      "learning_rate": 8.557404563231312e-06,
      "loss": 0.1378,
      "step": 9111
    },
    {
      "epoch": 0.1442753772345108,
      "grad_norm": 0.10588692128658295,
      "learning_rate": 8.557246227654893e-06,
      "loss": 0.0509,
      "step": 9112
    },
    {
      "epoch": 0.1442912107921529,
      "grad_norm": 0.00015757034998387098,
      "learning_rate": 8.557087892078472e-06,
      "loss": 0.0,
      "step": 9113
    },
    {
      "epoch": 0.14430704434979497,
      "grad_norm": 0.4759478271007538,
      "learning_rate": 8.556929556502051e-06,
      "loss": 0.1351,
      "step": 9114
    },
    {
      "epoch": 0.14432287790743703,
      "grad_norm": 0.009098079986870289,
      "learning_rate": 8.55677122092563e-06,
      "loss": 0.0004,
      "step": 9115
    },
    {
      "epoch": 0.1443387114650791,
      "grad_norm": 0.27032479643821716,
      "learning_rate": 8.556612885349211e-06,
      "loss": 0.064,
      "step": 9116
    },
    {
      "epoch": 0.14435454502272116,
      "grad_norm": 0.26407894492149353,
      "learning_rate": 8.556454549772788e-06,
      "loss": 0.0357,
      "step": 9117
    },
    {
      "epoch": 0.14437037858036322,
      "grad_norm": 0.2702498435974121,
      "learning_rate": 8.556296214196369e-06,
      "loss": 0.1731,
      "step": 9118
    },
    {
      "epoch": 0.1443862121380053,
      "grad_norm": 0.8445292711257935,
      "learning_rate": 8.556137878619948e-06,
      "loss": 0.2849,
      "step": 9119
    },
    {
      "epoch": 0.14440204569564735,
      "grad_norm": 0.22369761765003204,
      "learning_rate": 8.555979543043527e-06,
      "loss": 0.0263,
      "step": 9120
    },
    {
      "epoch": 0.14441787925328942,
      "grad_norm": 0.19739362597465515,
      "learning_rate": 8.555821207467106e-06,
      "loss": 0.0419,
      "step": 9121
    },
    {
      "epoch": 0.14443371281093148,
      "grad_norm": 0.3917427062988281,
      "learning_rate": 8.555662871890685e-06,
      "loss": 0.0204,
      "step": 9122
    },
    {
      "epoch": 0.14444954636857354,
      "grad_norm": 0.16138510406017303,
      "learning_rate": 8.555504536314264e-06,
      "loss": 0.0093,
      "step": 9123
    },
    {
      "epoch": 0.1444653799262156,
      "grad_norm": 0.333842009305954,
      "learning_rate": 8.555346200737844e-06,
      "loss": 0.1113,
      "step": 9124
    },
    {
      "epoch": 0.1444812134838577,
      "grad_norm": 0.0001232958456967026,
      "learning_rate": 8.555187865161424e-06,
      "loss": 0.0,
      "step": 9125
    },
    {
      "epoch": 0.14449704704149977,
      "grad_norm": 0.2498587667942047,
      "learning_rate": 8.555029529585003e-06,
      "loss": 0.1082,
      "step": 9126
    },
    {
      "epoch": 0.14451288059914183,
      "grad_norm": 0.2862333655357361,
      "learning_rate": 8.554871194008582e-06,
      "loss": 0.0665,
      "step": 9127
    },
    {
      "epoch": 0.1445287141567839,
      "grad_norm": 0.2034682035446167,
      "learning_rate": 8.554712858432162e-06,
      "loss": 0.085,
      "step": 9128
    },
    {
      "epoch": 0.14454454771442596,
      "grad_norm": 0.005167702678591013,
      "learning_rate": 8.55455452285574e-06,
      "loss": 0.0002,
      "step": 9129
    },
    {
      "epoch": 0.14456038127206802,
      "grad_norm": 0.2627027630805969,
      "learning_rate": 8.55439618727932e-06,
      "loss": 0.0494,
      "step": 9130
    },
    {
      "epoch": 0.1445762148297101,
      "grad_norm": 0.4729270040988922,
      "learning_rate": 8.5542378517029e-06,
      "loss": 0.4907,
      "step": 9131
    },
    {
      "epoch": 0.14459204838735215,
      "grad_norm": 0.7211268544197083,
      "learning_rate": 8.55407951612648e-06,
      "loss": 0.9044,
      "step": 9132
    },
    {
      "epoch": 0.14460788194499422,
      "grad_norm": 0.4027007222175598,
      "learning_rate": 8.553921180550059e-06,
      "loss": 0.0652,
      "step": 9133
    },
    {
      "epoch": 0.14462371550263628,
      "grad_norm": 0.45274972915649414,
      "learning_rate": 8.553762844973638e-06,
      "loss": 0.3018,
      "step": 9134
    },
    {
      "epoch": 0.14463954906027834,
      "grad_norm": 0.2939439117908478,
      "learning_rate": 8.553604509397217e-06,
      "loss": 0.5827,
      "step": 9135
    },
    {
      "epoch": 0.1446553826179204,
      "grad_norm": 0.5244138240814209,
      "learning_rate": 8.553446173820796e-06,
      "loss": 0.103,
      "step": 9136
    },
    {
      "epoch": 0.1446712161755625,
      "grad_norm": 0.3139064311981201,
      "learning_rate": 8.553287838244377e-06,
      "loss": 0.0877,
      "step": 9137
    },
    {
      "epoch": 0.14468704973320456,
      "grad_norm": 0.5052341222763062,
      "learning_rate": 8.553129502667956e-06,
      "loss": 0.5573,
      "step": 9138
    },
    {
      "epoch": 0.14470288329084663,
      "grad_norm": 0.020023135468363762,
      "learning_rate": 8.552971167091535e-06,
      "loss": 0.0011,
      "step": 9139
    },
    {
      "epoch": 0.1447187168484887,
      "grad_norm": 0.864043116569519,
      "learning_rate": 8.552812831515114e-06,
      "loss": 0.6575,
      "step": 9140
    },
    {
      "epoch": 0.14473455040613076,
      "grad_norm": 0.48516881465911865,
      "learning_rate": 8.552654495938693e-06,
      "loss": 0.1305,
      "step": 9141
    },
    {
      "epoch": 0.14475038396377282,
      "grad_norm": 0.24016468226909637,
      "learning_rate": 8.552496160362272e-06,
      "loss": 0.0783,
      "step": 9142
    },
    {
      "epoch": 0.14476621752141489,
      "grad_norm": 0.3376823663711548,
      "learning_rate": 8.552337824785851e-06,
      "loss": 0.0108,
      "step": 9143
    },
    {
      "epoch": 0.14478205107905695,
      "grad_norm": 0.32054048776626587,
      "learning_rate": 8.552179489209432e-06,
      "loss": 0.1686,
      "step": 9144
    },
    {
      "epoch": 0.14479788463669901,
      "grad_norm": 0.7867344617843628,
      "learning_rate": 8.55202115363301e-06,
      "loss": 0.8746,
      "step": 9145
    },
    {
      "epoch": 0.14481371819434108,
      "grad_norm": 0.6210843920707703,
      "learning_rate": 8.55186281805659e-06,
      "loss": 0.042,
      "step": 9146
    },
    {
      "epoch": 0.14482955175198314,
      "grad_norm": 0.17543545365333557,
      "learning_rate": 8.55170448248017e-06,
      "loss": 0.0578,
      "step": 9147
    },
    {
      "epoch": 0.1448453853096252,
      "grad_norm": 0.3243313431739807,
      "learning_rate": 8.551546146903748e-06,
      "loss": 0.113,
      "step": 9148
    },
    {
      "epoch": 0.1448612188672673,
      "grad_norm": 0.5577926635742188,
      "learning_rate": 8.551387811327327e-06,
      "loss": 0.1648,
      "step": 9149
    },
    {
      "epoch": 0.14487705242490936,
      "grad_norm": 0.4884726405143738,
      "learning_rate": 8.551229475750908e-06,
      "loss": 0.725,
      "step": 9150
    },
    {
      "epoch": 0.14489288598255143,
      "grad_norm": 0.007212457712739706,
      "learning_rate": 8.551071140174485e-06,
      "loss": 0.0004,
      "step": 9151
    },
    {
      "epoch": 0.1449087195401935,
      "grad_norm": 0.18431849777698517,
      "learning_rate": 8.550912804598066e-06,
      "loss": 0.0797,
      "step": 9152
    },
    {
      "epoch": 0.14492455309783556,
      "grad_norm": 0.009813662618398666,
      "learning_rate": 8.550754469021645e-06,
      "loss": 0.0006,
      "step": 9153
    },
    {
      "epoch": 0.14494038665547762,
      "grad_norm": 0.2032822072505951,
      "learning_rate": 8.550596133445224e-06,
      "loss": 0.0749,
      "step": 9154
    },
    {
      "epoch": 0.14495622021311969,
      "grad_norm": 0.271708607673645,
      "learning_rate": 8.550437797868804e-06,
      "loss": 0.1674,
      "step": 9155
    },
    {
      "epoch": 0.14497205377076175,
      "grad_norm": 0.2050294429063797,
      "learning_rate": 8.550279462292384e-06,
      "loss": 0.0728,
      "step": 9156
    },
    {
      "epoch": 0.14498788732840381,
      "grad_norm": 0.0038331956602633,
      "learning_rate": 8.550121126715962e-06,
      "loss": 0.0002,
      "step": 9157
    },
    {
      "epoch": 0.14500372088604588,
      "grad_norm": 0.2448558658361435,
      "learning_rate": 8.549962791139542e-06,
      "loss": 0.1565,
      "step": 9158
    },
    {
      "epoch": 0.14501955444368794,
      "grad_norm": 0.28270721435546875,
      "learning_rate": 8.549804455563122e-06,
      "loss": 0.3398,
      "step": 9159
    },
    {
      "epoch": 0.14503538800133,
      "grad_norm": 0.22829094529151917,
      "learning_rate": 8.5496461199867e-06,
      "loss": 0.0128,
      "step": 9160
    },
    {
      "epoch": 0.1450512215589721,
      "grad_norm": 0.20590248703956604,
      "learning_rate": 8.54948778441028e-06,
      "loss": 0.0073,
      "step": 9161
    },
    {
      "epoch": 0.14506705511661416,
      "grad_norm": 0.44203072786331177,
      "learning_rate": 8.54932944883386e-06,
      "loss": 0.59,
      "step": 9162
    },
    {
      "epoch": 0.14508288867425623,
      "grad_norm": 0.15885378420352936,
      "learning_rate": 8.549171113257438e-06,
      "loss": 0.0203,
      "step": 9163
    },
    {
      "epoch": 0.1450987222318983,
      "grad_norm": 0.19035638868808746,
      "learning_rate": 8.549012777681019e-06,
      "loss": 0.0756,
      "step": 9164
    },
    {
      "epoch": 0.14511455578954036,
      "grad_norm": 0.43025779724121094,
      "learning_rate": 8.548854442104598e-06,
      "loss": 0.132,
      "step": 9165
    },
    {
      "epoch": 0.14513038934718242,
      "grad_norm": 0.0311154592782259,
      "learning_rate": 8.548696106528177e-06,
      "loss": 0.0022,
      "step": 9166
    },
    {
      "epoch": 0.14514622290482448,
      "grad_norm": 0.26188376545906067,
      "learning_rate": 8.548537770951756e-06,
      "loss": 0.0601,
      "step": 9167
    },
    {
      "epoch": 0.14516205646246655,
      "grad_norm": 0.27403679490089417,
      "learning_rate": 8.548379435375335e-06,
      "loss": 0.0411,
      "step": 9168
    },
    {
      "epoch": 0.1451778900201086,
      "grad_norm": 0.3835780620574951,
      "learning_rate": 8.548221099798914e-06,
      "loss": 0.1723,
      "step": 9169
    },
    {
      "epoch": 0.14519372357775068,
      "grad_norm": 0.01594562456011772,
      "learning_rate": 8.548062764222493e-06,
      "loss": 0.001,
      "step": 9170
    },
    {
      "epoch": 0.14520955713539274,
      "grad_norm": 0.017912106588482857,
      "learning_rate": 8.547904428646074e-06,
      "loss": 0.001,
      "step": 9171
    },
    {
      "epoch": 0.1452253906930348,
      "grad_norm": 0.23436230421066284,
      "learning_rate": 8.547746093069651e-06,
      "loss": 0.0827,
      "step": 9172
    },
    {
      "epoch": 0.1452412242506769,
      "grad_norm": 0.35215938091278076,
      "learning_rate": 8.547587757493232e-06,
      "loss": 0.1986,
      "step": 9173
    },
    {
      "epoch": 0.14525705780831896,
      "grad_norm": 0.31817254424095154,
      "learning_rate": 8.547429421916811e-06,
      "loss": 0.2141,
      "step": 9174
    },
    {
      "epoch": 0.14527289136596103,
      "grad_norm": 0.3363484740257263,
      "learning_rate": 8.54727108634039e-06,
      "loss": 0.4795,
      "step": 9175
    },
    {
      "epoch": 0.1452887249236031,
      "grad_norm": 0.000732608197722584,
      "learning_rate": 8.54711275076397e-06,
      "loss": 0.0,
      "step": 9176
    },
    {
      "epoch": 0.14530455848124516,
      "grad_norm": 0.28481364250183105,
      "learning_rate": 8.54695441518755e-06,
      "loss": 0.0736,
      "step": 9177
    },
    {
      "epoch": 0.14532039203888722,
      "grad_norm": 0.2016993910074234,
      "learning_rate": 8.546796079611127e-06,
      "loss": 0.0735,
      "step": 9178
    },
    {
      "epoch": 0.14533622559652928,
      "grad_norm": 0.4254591763019562,
      "learning_rate": 8.546637744034708e-06,
      "loss": 0.3697,
      "step": 9179
    },
    {
      "epoch": 0.14535205915417135,
      "grad_norm": 0.4533807933330536,
      "learning_rate": 8.546479408458287e-06,
      "loss": 0.329,
      "step": 9180
    },
    {
      "epoch": 0.1453678927118134,
      "grad_norm": 0.3206149637699127,
      "learning_rate": 8.546321072881866e-06,
      "loss": 0.1218,
      "step": 9181
    },
    {
      "epoch": 0.14538372626945548,
      "grad_norm": 0.2110709697008133,
      "learning_rate": 8.546162737305445e-06,
      "loss": 0.1204,
      "step": 9182
    },
    {
      "epoch": 0.14539955982709754,
      "grad_norm": 0.528695285320282,
      "learning_rate": 8.546004401729026e-06,
      "loss": 0.0181,
      "step": 9183
    },
    {
      "epoch": 0.1454153933847396,
      "grad_norm": 0.37736254930496216,
      "learning_rate": 8.545846066152604e-06,
      "loss": 0.1493,
      "step": 9184
    },
    {
      "epoch": 0.1454312269423817,
      "grad_norm": 0.008181310258805752,
      "learning_rate": 8.545687730576184e-06,
      "loss": 0.0009,
      "step": 9185
    },
    {
      "epoch": 0.14544706050002376,
      "grad_norm": 0.4600367546081543,
      "learning_rate": 8.545529394999763e-06,
      "loss": 0.1964,
      "step": 9186
    },
    {
      "epoch": 0.14546289405766583,
      "grad_norm": 0.21180421113967896,
      "learning_rate": 8.545371059423343e-06,
      "loss": 0.0302,
      "step": 9187
    },
    {
      "epoch": 0.1454787276153079,
      "grad_norm": 0.47827616333961487,
      "learning_rate": 8.545212723846922e-06,
      "loss": 0.568,
      "step": 9188
    },
    {
      "epoch": 0.14549456117294995,
      "grad_norm": 0.5112835764884949,
      "learning_rate": 8.545054388270502e-06,
      "loss": 0.1593,
      "step": 9189
    },
    {
      "epoch": 0.14551039473059202,
      "grad_norm": 0.36287474632263184,
      "learning_rate": 8.54489605269408e-06,
      "loss": 0.5046,
      "step": 9190
    },
    {
      "epoch": 0.14552622828823408,
      "grad_norm": 0.2806762754917145,
      "learning_rate": 8.544737717117659e-06,
      "loss": 0.1282,
      "step": 9191
    },
    {
      "epoch": 0.14554206184587615,
      "grad_norm": 0.16884878277778625,
      "learning_rate": 8.54457938154124e-06,
      "loss": 0.0588,
      "step": 9192
    },
    {
      "epoch": 0.1455578954035182,
      "grad_norm": 0.1542900800704956,
      "learning_rate": 8.544421045964819e-06,
      "loss": 0.0309,
      "step": 9193
    },
    {
      "epoch": 0.14557372896116028,
      "grad_norm": 0.3302308917045593,
      "learning_rate": 8.544262710388398e-06,
      "loss": 0.1161,
      "step": 9194
    },
    {
      "epoch": 0.14558956251880234,
      "grad_norm": 0.2472769021987915,
      "learning_rate": 8.544104374811977e-06,
      "loss": 0.0858,
      "step": 9195
    },
    {
      "epoch": 0.1456053960764444,
      "grad_norm": 0.0023770048283040524,
      "learning_rate": 8.543946039235556e-06,
      "loss": 0.0,
      "step": 9196
    },
    {
      "epoch": 0.1456212296340865,
      "grad_norm": 0.01337000634521246,
      "learning_rate": 8.543787703659135e-06,
      "loss": 0.0009,
      "step": 9197
    },
    {
      "epoch": 0.14563706319172856,
      "grad_norm": 0.17838622629642487,
      "learning_rate": 8.543629368082716e-06,
      "loss": 0.0364,
      "step": 9198
    },
    {
      "epoch": 0.14565289674937063,
      "grad_norm": 0.009460347704589367,
      "learning_rate": 8.543471032506295e-06,
      "loss": 0.0005,
      "step": 9199
    },
    {
      "epoch": 0.1456687303070127,
      "grad_norm": 0.00015198119217529893,
      "learning_rate": 8.543312696929874e-06,
      "loss": 0.0,
      "step": 9200
    },
    {
      "epoch": 0.14568456386465475,
      "grad_norm": 0.4443223476409912,
      "learning_rate": 8.543154361353453e-06,
      "loss": 0.064,
      "step": 9201
    },
    {
      "epoch": 0.14570039742229682,
      "grad_norm": 0.2106798142194748,
      "learning_rate": 8.542996025777032e-06,
      "loss": 0.0614,
      "step": 9202
    },
    {
      "epoch": 0.14571623097993888,
      "grad_norm": 0.41566917300224304,
      "learning_rate": 8.542837690200611e-06,
      "loss": 0.1612,
      "step": 9203
    },
    {
      "epoch": 0.14573206453758095,
      "grad_norm": 0.004266907926648855,
      "learning_rate": 8.542679354624192e-06,
      "loss": 0.0002,
      "step": 9204
    },
    {
      "epoch": 0.145747898095223,
      "grad_norm": 0.14082922041416168,
      "learning_rate": 8.542521019047771e-06,
      "loss": 0.073,
      "step": 9205
    },
    {
      "epoch": 0.14576373165286508,
      "grad_norm": 0.27795878052711487,
      "learning_rate": 8.54236268347135e-06,
      "loss": 0.2649,
      "step": 9206
    },
    {
      "epoch": 0.14577956521050714,
      "grad_norm": 0.3525439500808716,
      "learning_rate": 8.54220434789493e-06,
      "loss": 0.2308,
      "step": 9207
    },
    {
      "epoch": 0.1457953987681492,
      "grad_norm": 0.30768123269081116,
      "learning_rate": 8.542046012318508e-06,
      "loss": 0.106,
      "step": 9208
    },
    {
      "epoch": 0.1458112323257913,
      "grad_norm": 0.4885304570198059,
      "learning_rate": 8.541887676742087e-06,
      "loss": 0.1574,
      "step": 9209
    },
    {
      "epoch": 0.14582706588343336,
      "grad_norm": 0.297366201877594,
      "learning_rate": 8.541729341165668e-06,
      "loss": 0.3875,
      "step": 9210
    },
    {
      "epoch": 0.14584289944107542,
      "grad_norm": 4.215587615966797,
      "learning_rate": 8.541571005589247e-06,
      "loss": 0.3279,
      "step": 9211
    },
    {
      "epoch": 0.1458587329987175,
      "grad_norm": 0.6494393348693848,
      "learning_rate": 8.541412670012826e-06,
      "loss": 0.4406,
      "step": 9212
    },
    {
      "epoch": 0.14587456655635955,
      "grad_norm": 0.00027687876718118787,
      "learning_rate": 8.541254334436405e-06,
      "loss": 0.0,
      "step": 9213
    },
    {
      "epoch": 0.14589040011400162,
      "grad_norm": 0.13146059215068817,
      "learning_rate": 8.541095998859984e-06,
      "loss": 0.026,
      "step": 9214
    },
    {
      "epoch": 0.14590623367164368,
      "grad_norm": 0.0002068928733933717,
      "learning_rate": 8.540937663283564e-06,
      "loss": 0.0,
      "step": 9215
    },
    {
      "epoch": 0.14592206722928575,
      "grad_norm": 0.28604206442832947,
      "learning_rate": 8.540779327707143e-06,
      "loss": 0.115,
      "step": 9216
    },
    {
      "epoch": 0.1459379007869278,
      "grad_norm": 0.0007969794678501785,
      "learning_rate": 8.540620992130723e-06,
      "loss": 0.0,
      "step": 9217
    },
    {
      "epoch": 0.14595373434456987,
      "grad_norm": 0.01585329696536064,
      "learning_rate": 8.5404626565543e-06,
      "loss": 0.0009,
      "step": 9218
    },
    {
      "epoch": 0.14596956790221194,
      "grad_norm": 0.4374774694442749,
      "learning_rate": 8.540304320977882e-06,
      "loss": 0.2639,
      "step": 9219
    },
    {
      "epoch": 0.145985401459854,
      "grad_norm": 0.428268700838089,
      "learning_rate": 8.54014598540146e-06,
      "loss": 0.206,
      "step": 9220
    },
    {
      "epoch": 0.1460012350174961,
      "grad_norm": 0.4604741930961609,
      "learning_rate": 8.53998764982504e-06,
      "loss": 0.2243,
      "step": 9221
    },
    {
      "epoch": 0.14601706857513816,
      "grad_norm": 0.34845924377441406,
      "learning_rate": 8.539829314248619e-06,
      "loss": 0.3333,
      "step": 9222
    },
    {
      "epoch": 0.14603290213278022,
      "grad_norm": 0.0031805280596017838,
      "learning_rate": 8.5396709786722e-06,
      "loss": 0.0001,
      "step": 9223
    },
    {
      "epoch": 0.1460487356904223,
      "grad_norm": 0.270304411649704,
      "learning_rate": 8.539512643095777e-06,
      "loss": 0.0889,
      "step": 9224
    },
    {
      "epoch": 0.14606456924806435,
      "grad_norm": 0.33509591221809387,
      "learning_rate": 8.539354307519358e-06,
      "loss": 0.6538,
      "step": 9225
    },
    {
      "epoch": 0.14608040280570642,
      "grad_norm": 0.36470285058021545,
      "learning_rate": 8.539195971942937e-06,
      "loss": 0.1073,
      "step": 9226
    },
    {
      "epoch": 0.14609623636334848,
      "grad_norm": 0.22888311743736267,
      "learning_rate": 8.539037636366516e-06,
      "loss": 0.0603,
      "step": 9227
    },
    {
      "epoch": 0.14611206992099054,
      "grad_norm": 0.00014577257388737053,
      "learning_rate": 8.538879300790095e-06,
      "loss": 0.0,
      "step": 9228
    },
    {
      "epoch": 0.1461279034786326,
      "grad_norm": 0.10399933159351349,
      "learning_rate": 8.538720965213676e-06,
      "loss": 0.0011,
      "step": 9229
    },
    {
      "epoch": 0.14614373703627467,
      "grad_norm": 0.004027603659778833,
      "learning_rate": 8.538562629637253e-06,
      "loss": 0.0002,
      "step": 9230
    },
    {
      "epoch": 0.14615957059391674,
      "grad_norm": 0.16703352332115173,
      "learning_rate": 8.538404294060834e-06,
      "loss": 0.0275,
      "step": 9231
    },
    {
      "epoch": 0.1461754041515588,
      "grad_norm": 0.29989093542099,
      "learning_rate": 8.538245958484413e-06,
      "loss": 0.0826,
      "step": 9232
    },
    {
      "epoch": 0.1461912377092009,
      "grad_norm": 0.5669390559196472,
      "learning_rate": 8.538087622907992e-06,
      "loss": 0.0635,
      "step": 9233
    },
    {
      "epoch": 0.14620707126684296,
      "grad_norm": 0.46953970193862915,
      "learning_rate": 8.537929287331571e-06,
      "loss": 0.1512,
      "step": 9234
    },
    {
      "epoch": 0.14622290482448502,
      "grad_norm": 0.00031951250275596976,
      "learning_rate": 8.53777095175515e-06,
      "loss": 0.0,
      "step": 9235
    },
    {
      "epoch": 0.1462387383821271,
      "grad_norm": 0.00015788206655997783,
      "learning_rate": 8.53761261617873e-06,
      "loss": 0.0,
      "step": 9236
    },
    {
      "epoch": 0.14625457193976915,
      "grad_norm": 0.00018621129856910557,
      "learning_rate": 8.53745428060231e-06,
      "loss": 0.0,
      "step": 9237
    },
    {
      "epoch": 0.14627040549741122,
      "grad_norm": 0.2916978895664215,
      "learning_rate": 8.537295945025889e-06,
      "loss": 0.3367,
      "step": 9238
    },
    {
      "epoch": 0.14628623905505328,
      "grad_norm": 0.42223912477493286,
      "learning_rate": 8.537137609449467e-06,
      "loss": 0.1786,
      "step": 9239
    },
    {
      "epoch": 0.14630207261269534,
      "grad_norm": 1.0151183605194092,
      "learning_rate": 8.536979273873047e-06,
      "loss": 0.4474,
      "step": 9240
    },
    {
      "epoch": 0.1463179061703374,
      "grad_norm": 0.30684801936149597,
      "learning_rate": 8.536820938296626e-06,
      "loss": 0.0444,
      "step": 9241
    },
    {
      "epoch": 0.14633373972797947,
      "grad_norm": 0.5874526500701904,
      "learning_rate": 8.536662602720205e-06,
      "loss": 0.6094,
      "step": 9242
    },
    {
      "epoch": 0.14634957328562154,
      "grad_norm": 0.47395944595336914,
      "learning_rate": 8.536504267143785e-06,
      "loss": 0.1248,
      "step": 9243
    },
    {
      "epoch": 0.1463654068432636,
      "grad_norm": 0.42605748772621155,
      "learning_rate": 8.536345931567365e-06,
      "loss": 0.0725,
      "step": 9244
    },
    {
      "epoch": 0.1463812404009057,
      "grad_norm": 0.3022406995296478,
      "learning_rate": 8.536187595990943e-06,
      "loss": 0.1854,
      "step": 9245
    },
    {
      "epoch": 0.14639707395854776,
      "grad_norm": 0.024388112127780914,
      "learning_rate": 8.536029260414523e-06,
      "loss": 0.0016,
      "step": 9246
    },
    {
      "epoch": 0.14641290751618982,
      "grad_norm": 0.36162275075912476,
      "learning_rate": 8.535870924838103e-06,
      "loss": 0.2053,
      "step": 9247
    },
    {
      "epoch": 0.1464287410738319,
      "grad_norm": 0.19540727138519287,
      "learning_rate": 8.535712589261682e-06,
      "loss": 0.0817,
      "step": 9248
    },
    {
      "epoch": 0.14644457463147395,
      "grad_norm": 0.6352049112319946,
      "learning_rate": 8.53555425368526e-06,
      "loss": 0.809,
      "step": 9249
    },
    {
      "epoch": 0.14646040818911601,
      "grad_norm": 0.022122956812381744,
      "learning_rate": 8.535395918108841e-06,
      "loss": 0.0011,
      "step": 9250
    },
    {
      "epoch": 0.14647624174675808,
      "grad_norm": 0.4705062508583069,
      "learning_rate": 8.535237582532419e-06,
      "loss": 0.0827,
      "step": 9251
    },
    {
      "epoch": 0.14649207530440014,
      "grad_norm": 0.5066726803779602,
      "learning_rate": 8.535079246956e-06,
      "loss": 0.5275,
      "step": 9252
    },
    {
      "epoch": 0.1465079088620422,
      "grad_norm": 0.00014570532948710024,
      "learning_rate": 8.534920911379579e-06,
      "loss": 0.0,
      "step": 9253
    },
    {
      "epoch": 0.14652374241968427,
      "grad_norm": 0.004036732483655214,
      "learning_rate": 8.534762575803158e-06,
      "loss": 0.0002,
      "step": 9254
    },
    {
      "epoch": 0.14653957597732634,
      "grad_norm": 0.0017801738576963544,
      "learning_rate": 8.534604240226737e-06,
      "loss": 0.0,
      "step": 9255
    },
    {
      "epoch": 0.1465554095349684,
      "grad_norm": 0.007895593531429768,
      "learning_rate": 8.534445904650318e-06,
      "loss": 0.0003,
      "step": 9256
    },
    {
      "epoch": 0.14657124309261046,
      "grad_norm": 0.3920479714870453,
      "learning_rate": 8.534287569073895e-06,
      "loss": 0.1269,
      "step": 9257
    },
    {
      "epoch": 0.14658707665025256,
      "grad_norm": 0.5730164647102356,
      "learning_rate": 8.534129233497476e-06,
      "loss": 0.676,
      "step": 9258
    },
    {
      "epoch": 0.14660291020789462,
      "grad_norm": 0.17530880868434906,
      "learning_rate": 8.533970897921055e-06,
      "loss": 0.0807,
      "step": 9259
    },
    {
      "epoch": 0.14661874376553669,
      "grad_norm": 0.6245999336242676,
      "learning_rate": 8.533812562344634e-06,
      "loss": 0.9788,
      "step": 9260
    },
    {
      "epoch": 0.14663457732317875,
      "grad_norm": 0.6758704781532288,
      "learning_rate": 8.533654226768213e-06,
      "loss": 0.39,
      "step": 9261
    },
    {
      "epoch": 0.14665041088082081,
      "grad_norm": 0.03919687867164612,
      "learning_rate": 8.533495891191794e-06,
      "loss": 0.0057,
      "step": 9262
    },
    {
      "epoch": 0.14666624443846288,
      "grad_norm": 0.9017934799194336,
      "learning_rate": 8.533337555615371e-06,
      "loss": 0.0906,
      "step": 9263
    },
    {
      "epoch": 0.14668207799610494,
      "grad_norm": 0.44843146204948425,
      "learning_rate": 8.53317922003895e-06,
      "loss": 0.3738,
      "step": 9264
    },
    {
      "epoch": 0.146697911553747,
      "grad_norm": 0.376693457365036,
      "learning_rate": 8.533020884462531e-06,
      "loss": 0.0809,
      "step": 9265
    },
    {
      "epoch": 0.14671374511138907,
      "grad_norm": 0.31851980090141296,
      "learning_rate": 8.53286254888611e-06,
      "loss": 0.2504,
      "step": 9266
    },
    {
      "epoch": 0.14672957866903114,
      "grad_norm": 0.8561971783638,
      "learning_rate": 8.53270421330969e-06,
      "loss": 0.3548,
      "step": 9267
    },
    {
      "epoch": 0.1467454122266732,
      "grad_norm": 0.30709245800971985,
      "learning_rate": 8.532545877733268e-06,
      "loss": 0.1081,
      "step": 9268
    },
    {
      "epoch": 0.14676124578431526,
      "grad_norm": 0.3553861677646637,
      "learning_rate": 8.532387542156847e-06,
      "loss": 0.188,
      "step": 9269
    },
    {
      "epoch": 0.14677707934195736,
      "grad_norm": 0.2650049328804016,
      "learning_rate": 8.532229206580426e-06,
      "loss": 0.0702,
      "step": 9270
    },
    {
      "epoch": 0.14679291289959942,
      "grad_norm": 0.00011424611147958785,
      "learning_rate": 8.532070871004007e-06,
      "loss": 0.0,
      "step": 9271
    },
    {
      "epoch": 0.14680874645724148,
      "grad_norm": 0.26355987787246704,
      "learning_rate": 8.531912535427586e-06,
      "loss": 0.0215,
      "step": 9272
    },
    {
      "epoch": 0.14682458001488355,
      "grad_norm": 0.34779730439186096,
      "learning_rate": 8.531754199851165e-06,
      "loss": 0.156,
      "step": 9273
    },
    {
      "epoch": 0.1468404135725256,
      "grad_norm": 0.43695858120918274,
      "learning_rate": 8.531595864274744e-06,
      "loss": 0.2517,
      "step": 9274
    },
    {
      "epoch": 0.14685624713016768,
      "grad_norm": 0.7023575901985168,
      "learning_rate": 8.531437528698324e-06,
      "loss": 0.3398,
      "step": 9275
    },
    {
      "epoch": 0.14687208068780974,
      "grad_norm": 0.4729529023170471,
      "learning_rate": 8.531279193121903e-06,
      "loss": 0.5758,
      "step": 9276
    },
    {
      "epoch": 0.1468879142454518,
      "grad_norm": 0.010227545164525509,
      "learning_rate": 8.531120857545483e-06,
      "loss": 0.0004,
      "step": 9277
    },
    {
      "epoch": 0.14690374780309387,
      "grad_norm": 0.00020367470278870314,
      "learning_rate": 8.530962521969062e-06,
      "loss": 0.0,
      "step": 9278
    },
    {
      "epoch": 0.14691958136073593,
      "grad_norm": 0.38522136211395264,
      "learning_rate": 8.530804186392642e-06,
      "loss": 0.4708,
      "step": 9279
    },
    {
      "epoch": 0.146935414918378,
      "grad_norm": 6.2206519942265e-05,
      "learning_rate": 8.53064585081622e-06,
      "loss": 0.0,
      "step": 9280
    },
    {
      "epoch": 0.14695124847602006,
      "grad_norm": 0.024963224306702614,
      "learning_rate": 8.5304875152398e-06,
      "loss": 0.0018,
      "step": 9281
    },
    {
      "epoch": 0.14696708203366216,
      "grad_norm": 0.00011543637083377689,
      "learning_rate": 8.530329179663379e-06,
      "loss": 0.0,
      "step": 9282
    },
    {
      "epoch": 0.14698291559130422,
      "grad_norm": 0.4953942894935608,
      "learning_rate": 8.53017084408696e-06,
      "loss": 0.0737,
      "step": 9283
    },
    {
      "epoch": 0.14699874914894628,
      "grad_norm": 0.16455133259296417,
      "learning_rate": 8.530012508510539e-06,
      "loss": 0.0539,
      "step": 9284
    },
    {
      "epoch": 0.14701458270658835,
      "grad_norm": 0.1527927815914154,
      "learning_rate": 8.529854172934118e-06,
      "loss": 0.0736,
      "step": 9285
    },
    {
      "epoch": 0.1470304162642304,
      "grad_norm": 0.012182584963738918,
      "learning_rate": 8.529695837357697e-06,
      "loss": 0.0007,
      "step": 9286
    },
    {
      "epoch": 0.14704624982187248,
      "grad_norm": 0.34984251856803894,
      "learning_rate": 8.529537501781276e-06,
      "loss": 0.1044,
      "step": 9287
    },
    {
      "epoch": 0.14706208337951454,
      "grad_norm": 0.017878646031022072,
      "learning_rate": 8.529379166204855e-06,
      "loss": 0.0009,
      "step": 9288
    },
    {
      "epoch": 0.1470779169371566,
      "grad_norm": 0.1766636222600937,
      "learning_rate": 8.529220830628434e-06,
      "loss": 0.0958,
      "step": 9289
    },
    {
      "epoch": 0.14709375049479867,
      "grad_norm": 0.1422424614429474,
      "learning_rate": 8.529062495052015e-06,
      "loss": 0.0436,
      "step": 9290
    },
    {
      "epoch": 0.14710958405244073,
      "grad_norm": 0.3463476598262787,
      "learning_rate": 8.528904159475592e-06,
      "loss": 0.0963,
      "step": 9291
    },
    {
      "epoch": 0.1471254176100828,
      "grad_norm": 0.17959950864315033,
      "learning_rate": 8.528745823899173e-06,
      "loss": 0.069,
      "step": 9292
    },
    {
      "epoch": 0.14714125116772486,
      "grad_norm": 0.4836551249027252,
      "learning_rate": 8.528587488322752e-06,
      "loss": 0.7447,
      "step": 9293
    },
    {
      "epoch": 0.14715708472536695,
      "grad_norm": 0.5840476751327515,
      "learning_rate": 8.528429152746331e-06,
      "loss": 0.4699,
      "step": 9294
    },
    {
      "epoch": 0.14717291828300902,
      "grad_norm": 0.30948686599731445,
      "learning_rate": 8.52827081716991e-06,
      "loss": 0.1512,
      "step": 9295
    },
    {
      "epoch": 0.14718875184065108,
      "grad_norm": 0.00042706989916041493,
      "learning_rate": 8.528112481593491e-06,
      "loss": 0.0,
      "step": 9296
    },
    {
      "epoch": 0.14720458539829315,
      "grad_norm": 0.11605749279260635,
      "learning_rate": 8.527954146017068e-06,
      "loss": 0.016,
      "step": 9297
    },
    {
      "epoch": 0.1472204189559352,
      "grad_norm": 0.44223350286483765,
      "learning_rate": 8.527795810440649e-06,
      "loss": 0.1524,
      "step": 9298
    },
    {
      "epoch": 0.14723625251357728,
      "grad_norm": 0.5644991397857666,
      "learning_rate": 8.527637474864228e-06,
      "loss": 0.1715,
      "step": 9299
    },
    {
      "epoch": 0.14725208607121934,
      "grad_norm": 0.057059500366449356,
      "learning_rate": 8.527479139287807e-06,
      "loss": 0.0041,
      "step": 9300
    },
    {
      "epoch": 0.1472679196288614,
      "grad_norm": 0.013095634989440441,
      "learning_rate": 8.527320803711386e-06,
      "loss": 0.0008,
      "step": 9301
    },
    {
      "epoch": 0.14728375318650347,
      "grad_norm": 0.4750117063522339,
      "learning_rate": 8.527162468134965e-06,
      "loss": 0.1701,
      "step": 9302
    },
    {
      "epoch": 0.14729958674414553,
      "grad_norm": 0.025904763489961624,
      "learning_rate": 8.527004132558545e-06,
      "loss": 0.0016,
      "step": 9303
    },
    {
      "epoch": 0.1473154203017876,
      "grad_norm": 0.34684330224990845,
      "learning_rate": 8.526845796982125e-06,
      "loss": 0.2728,
      "step": 9304
    },
    {
      "epoch": 0.14733125385942966,
      "grad_norm": 0.11837448924779892,
      "learning_rate": 8.526687461405704e-06,
      "loss": 0.0364,
      "step": 9305
    },
    {
      "epoch": 0.14734708741707175,
      "grad_norm": 0.01240354310721159,
      "learning_rate": 8.526529125829283e-06,
      "loss": 0.0007,
      "step": 9306
    },
    {
      "epoch": 0.14736292097471382,
      "grad_norm": 0.6136541366577148,
      "learning_rate": 8.526370790252863e-06,
      "loss": 0.1558,
      "step": 9307
    },
    {
      "epoch": 0.14737875453235588,
      "grad_norm": 0.2534060776233673,
      "learning_rate": 8.526212454676442e-06,
      "loss": 0.0664,
      "step": 9308
    },
    {
      "epoch": 0.14739458808999795,
      "grad_norm": 0.019126279279589653,
      "learning_rate": 8.52605411910002e-06,
      "loss": 0.0018,
      "step": 9309
    },
    {
      "epoch": 0.14741042164764,
      "grad_norm": 0.3313104212284088,
      "learning_rate": 8.525895783523601e-06,
      "loss": 0.2394,
      "step": 9310
    },
    {
      "epoch": 0.14742625520528208,
      "grad_norm": 0.6360530853271484,
      "learning_rate": 8.52573744794718e-06,
      "loss": 0.1877,
      "step": 9311
    },
    {
      "epoch": 0.14744208876292414,
      "grad_norm": 0.45387861132621765,
      "learning_rate": 8.525579112370758e-06,
      "loss": 0.0739,
      "step": 9312
    },
    {
      "epoch": 0.1474579223205662,
      "grad_norm": 0.784163236618042,
      "learning_rate": 8.525420776794339e-06,
      "loss": 0.1882,
      "step": 9313
    },
    {
      "epoch": 0.14747375587820827,
      "grad_norm": 0.32380199432373047,
      "learning_rate": 8.525262441217918e-06,
      "loss": 0.2169,
      "step": 9314
    },
    {
      "epoch": 0.14748958943585033,
      "grad_norm": 0.00016967715055216104,
      "learning_rate": 8.525104105641497e-06,
      "loss": 0.0,
      "step": 9315
    },
    {
      "epoch": 0.1475054229934924,
      "grad_norm": 3.4228971004486084,
      "learning_rate": 8.524945770065076e-06,
      "loss": 0.0443,
      "step": 9316
    },
    {
      "epoch": 0.14752125655113446,
      "grad_norm": 0.39192134141921997,
      "learning_rate": 8.524787434488657e-06,
      "loss": 0.1556,
      "step": 9317
    },
    {
      "epoch": 0.14753709010877655,
      "grad_norm": 0.012310739606618881,
      "learning_rate": 8.524629098912234e-06,
      "loss": 0.0005,
      "step": 9318
    },
    {
      "epoch": 0.14755292366641862,
      "grad_norm": 0.26970168948173523,
      "learning_rate": 8.524470763335815e-06,
      "loss": 0.1538,
      "step": 9319
    },
    {
      "epoch": 0.14756875722406068,
      "grad_norm": 0.0015425195451825857,
      "learning_rate": 8.524312427759394e-06,
      "loss": 0.0,
      "step": 9320
    },
    {
      "epoch": 0.14758459078170275,
      "grad_norm": 0.0003106785879936069,
      "learning_rate": 8.524154092182973e-06,
      "loss": 0.0,
      "step": 9321
    },
    {
      "epoch": 0.1476004243393448,
      "grad_norm": 0.9096407294273376,
      "learning_rate": 8.523995756606552e-06,
      "loss": 0.4585,
      "step": 9322
    },
    {
      "epoch": 0.14761625789698687,
      "grad_norm": 0.3924899101257324,
      "learning_rate": 8.523837421030133e-06,
      "loss": 0.5858,
      "step": 9323
    },
    {
      "epoch": 0.14763209145462894,
      "grad_norm": 0.17042912542819977,
      "learning_rate": 8.52367908545371e-06,
      "loss": 0.0614,
      "step": 9324
    },
    {
      "epoch": 0.147647925012271,
      "grad_norm": 0.007233386393636465,
      "learning_rate": 8.523520749877291e-06,
      "loss": 0.0003,
      "step": 9325
    },
    {
      "epoch": 0.14766375856991307,
      "grad_norm": 0.008520866744220257,
      "learning_rate": 8.52336241430087e-06,
      "loss": 0.0004,
      "step": 9326
    },
    {
      "epoch": 0.14767959212755513,
      "grad_norm": 0.5173506736755371,
      "learning_rate": 8.52320407872445e-06,
      "loss": 0.1074,
      "step": 9327
    },
    {
      "epoch": 0.1476954256851972,
      "grad_norm": 0.5284673571586609,
      "learning_rate": 8.523045743148028e-06,
      "loss": 0.1769,
      "step": 9328
    },
    {
      "epoch": 0.14771125924283926,
      "grad_norm": 0.17405064404010773,
      "learning_rate": 8.522887407571609e-06,
      "loss": 0.0701,
      "step": 9329
    },
    {
      "epoch": 0.14772709280048135,
      "grad_norm": 0.26236099004745483,
      "learning_rate": 8.522729071995186e-06,
      "loss": 0.0925,
      "step": 9330
    },
    {
      "epoch": 0.14774292635812342,
      "grad_norm": 0.6050006151199341,
      "learning_rate": 8.522570736418767e-06,
      "loss": 0.1408,
      "step": 9331
    },
    {
      "epoch": 0.14775875991576548,
      "grad_norm": 0.0062418244779109955,
      "learning_rate": 8.522412400842346e-06,
      "loss": 0.0003,
      "step": 9332
    },
    {
      "epoch": 0.14777459347340755,
      "grad_norm": 0.03038126975297928,
      "learning_rate": 8.522254065265925e-06,
      "loss": 0.0006,
      "step": 9333
    },
    {
      "epoch": 0.1477904270310496,
      "grad_norm": 0.2816833555698395,
      "learning_rate": 8.522095729689504e-06,
      "loss": 0.1727,
      "step": 9334
    },
    {
      "epoch": 0.14780626058869167,
      "grad_norm": 0.24738924205303192,
      "learning_rate": 8.521937394113085e-06,
      "loss": 0.1024,
      "step": 9335
    },
    {
      "epoch": 0.14782209414633374,
      "grad_norm": 0.011304027400910854,
      "learning_rate": 8.521779058536663e-06,
      "loss": 0.0005,
      "step": 9336
    },
    {
      "epoch": 0.1478379277039758,
      "grad_norm": 0.679411768913269,
      "learning_rate": 8.521620722960242e-06,
      "loss": 0.1461,
      "step": 9337
    },
    {
      "epoch": 0.14785376126161787,
      "grad_norm": 0.014142312109470367,
      "learning_rate": 8.521462387383822e-06,
      "loss": 0.0006,
      "step": 9338
    },
    {
      "epoch": 0.14786959481925993,
      "grad_norm": 0.8558640480041504,
      "learning_rate": 8.521304051807402e-06,
      "loss": 0.2918,
      "step": 9339
    },
    {
      "epoch": 0.147885428376902,
      "grad_norm": 0.511439323425293,
      "learning_rate": 8.52114571623098e-06,
      "loss": 0.5512,
      "step": 9340
    },
    {
      "epoch": 0.14790126193454406,
      "grad_norm": 0.41486236453056335,
      "learning_rate": 8.52098738065456e-06,
      "loss": 0.1383,
      "step": 9341
    },
    {
      "epoch": 0.14791709549218615,
      "grad_norm": 0.0011767663527280092,
      "learning_rate": 8.520829045078139e-06,
      "loss": 0.0,
      "step": 9342
    },
    {
      "epoch": 0.14793292904982822,
      "grad_norm": 0.03375423699617386,
      "learning_rate": 8.520670709501718e-06,
      "loss": 0.0021,
      "step": 9343
    },
    {
      "epoch": 0.14794876260747028,
      "grad_norm": 0.00959243904799223,
      "learning_rate": 8.520512373925299e-06,
      "loss": 0.0005,
      "step": 9344
    },
    {
      "epoch": 0.14796459616511234,
      "grad_norm": 0.00051031110342592,
      "learning_rate": 8.520354038348878e-06,
      "loss": 0.0,
      "step": 9345
    },
    {
      "epoch": 0.1479804297227544,
      "grad_norm": 0.6344172358512878,
      "learning_rate": 8.520195702772457e-06,
      "loss": 0.3783,
      "step": 9346
    },
    {
      "epoch": 0.14799626328039647,
      "grad_norm": 0.019347980618476868,
      "learning_rate": 8.520037367196036e-06,
      "loss": 0.001,
      "step": 9347
    },
    {
      "epoch": 0.14801209683803854,
      "grad_norm": 0.4780244827270508,
      "learning_rate": 8.519879031619615e-06,
      "loss": 0.309,
      "step": 9348
    },
    {
      "epoch": 0.1480279303956806,
      "grad_norm": 0.40628400444984436,
      "learning_rate": 8.519720696043194e-06,
      "loss": 0.1917,
      "step": 9349
    },
    {
      "epoch": 0.14804376395332267,
      "grad_norm": 0.4622343182563782,
      "learning_rate": 8.519562360466775e-06,
      "loss": 0.167,
      "step": 9350
    },
    {
      "epoch": 0.14805959751096473,
      "grad_norm": 0.1353146731853485,
      "learning_rate": 8.519404024890354e-06,
      "loss": 0.0586,
      "step": 9351
    },
    {
      "epoch": 0.1480754310686068,
      "grad_norm": 0.004486498422920704,
      "learning_rate": 8.519245689313933e-06,
      "loss": 0.0001,
      "step": 9352
    },
    {
      "epoch": 0.14809126462624886,
      "grad_norm": 0.032860662788152695,
      "learning_rate": 8.519087353737512e-06,
      "loss": 0.0018,
      "step": 9353
    },
    {
      "epoch": 0.14810709818389095,
      "grad_norm": 0.00023164924641605467,
      "learning_rate": 8.518929018161091e-06,
      "loss": 0.0,
      "step": 9354
    },
    {
      "epoch": 0.14812293174153301,
      "grad_norm": 0.3805120289325714,
      "learning_rate": 8.51877068258467e-06,
      "loss": 0.133,
      "step": 9355
    },
    {
      "epoch": 0.14813876529917508,
      "grad_norm": 0.3117881417274475,
      "learning_rate": 8.518612347008251e-06,
      "loss": 0.0224,
      "step": 9356
    },
    {
      "epoch": 0.14815459885681714,
      "grad_norm": 0.37610089778900146,
      "learning_rate": 8.51845401143183e-06,
      "loss": 0.2338,
      "step": 9357
    },
    {
      "epoch": 0.1481704324144592,
      "grad_norm": 0.03490167856216431,
      "learning_rate": 8.51829567585541e-06,
      "loss": 0.002,
      "step": 9358
    },
    {
      "epoch": 0.14818626597210127,
      "grad_norm": 0.3543477952480316,
      "learning_rate": 8.518137340278988e-06,
      "loss": 0.2492,
      "step": 9359
    },
    {
      "epoch": 0.14820209952974334,
      "grad_norm": 0.0009655928006395698,
      "learning_rate": 8.517979004702567e-06,
      "loss": 0.0,
      "step": 9360
    },
    {
      "epoch": 0.1482179330873854,
      "grad_norm": 0.00014818577619735152,
      "learning_rate": 8.517820669126146e-06,
      "loss": 0.0,
      "step": 9361
    },
    {
      "epoch": 0.14823376664502746,
      "grad_norm": 0.22013643383979797,
      "learning_rate": 8.517662333549725e-06,
      "loss": 0.0676,
      "step": 9362
    },
    {
      "epoch": 0.14824960020266953,
      "grad_norm": 0.00023939103994052857,
      "learning_rate": 8.517503997973305e-06,
      "loss": 0.0,
      "step": 9363
    },
    {
      "epoch": 0.1482654337603116,
      "grad_norm": 0.04987252503633499,
      "learning_rate": 8.517345662396884e-06,
      "loss": 0.0025,
      "step": 9364
    },
    {
      "epoch": 0.14828126731795366,
      "grad_norm": 0.26091256737709045,
      "learning_rate": 8.517187326820464e-06,
      "loss": 0.0717,
      "step": 9365
    },
    {
      "epoch": 0.14829710087559575,
      "grad_norm": 0.3704603612422943,
      "learning_rate": 8.517028991244043e-06,
      "loss": 0.0732,
      "step": 9366
    },
    {
      "epoch": 0.14831293443323781,
      "grad_norm": 0.5662407875061035,
      "learning_rate": 8.516870655667623e-06,
      "loss": 0.4649,
      "step": 9367
    },
    {
      "epoch": 0.14832876799087988,
      "grad_norm": 0.023898668587207794,
      "learning_rate": 8.516712320091202e-06,
      "loss": 0.0012,
      "step": 9368
    },
    {
      "epoch": 0.14834460154852194,
      "grad_norm": 0.2318316549062729,
      "learning_rate": 8.51655398451478e-06,
      "loss": 0.0352,
      "step": 9369
    },
    {
      "epoch": 0.148360435106164,
      "grad_norm": 0.41641008853912354,
      "learning_rate": 8.51639564893836e-06,
      "loss": 0.1338,
      "step": 9370
    },
    {
      "epoch": 0.14837626866380607,
      "grad_norm": 0.007396467495709658,
      "learning_rate": 8.51623731336194e-06,
      "loss": 0.0003,
      "step": 9371
    },
    {
      "epoch": 0.14839210222144814,
      "grad_norm": 0.641728937625885,
      "learning_rate": 8.51607897778552e-06,
      "loss": 0.197,
      "step": 9372
    },
    {
      "epoch": 0.1484079357790902,
      "grad_norm": 0.8596197962760925,
      "learning_rate": 8.515920642209099e-06,
      "loss": 0.0399,
      "step": 9373
    },
    {
      "epoch": 0.14842376933673226,
      "grad_norm": 0.3956787586212158,
      "learning_rate": 8.515762306632678e-06,
      "loss": 0.119,
      "step": 9374
    },
    {
      "epoch": 0.14843960289437433,
      "grad_norm": 0.18308986723423004,
      "learning_rate": 8.515603971056257e-06,
      "loss": 0.0788,
      "step": 9375
    },
    {
      "epoch": 0.1484554364520164,
      "grad_norm": 0.13060730695724487,
      "learning_rate": 8.515445635479836e-06,
      "loss": 0.0113,
      "step": 9376
    },
    {
      "epoch": 0.14847127000965846,
      "grad_norm": 0.28695905208587646,
      "learning_rate": 8.515287299903417e-06,
      "loss": 0.1533,
      "step": 9377
    },
    {
      "epoch": 0.14848710356730055,
      "grad_norm": 0.3394550085067749,
      "learning_rate": 8.515128964326996e-06,
      "loss": 0.0839,
      "step": 9378
    },
    {
      "epoch": 0.1485029371249426,
      "grad_norm": 0.21741080284118652,
      "learning_rate": 8.514970628750575e-06,
      "loss": 0.0493,
      "step": 9379
    },
    {
      "epoch": 0.14851877068258468,
      "grad_norm": 0.18535739183425903,
      "learning_rate": 8.514812293174154e-06,
      "loss": 0.0577,
      "step": 9380
    },
    {
      "epoch": 0.14853460424022674,
      "grad_norm": 0.7850260734558105,
      "learning_rate": 8.514653957597733e-06,
      "loss": 0.2946,
      "step": 9381
    },
    {
      "epoch": 0.1485504377978688,
      "grad_norm": 0.6341562271118164,
      "learning_rate": 8.514495622021312e-06,
      "loss": 0.152,
      "step": 9382
    },
    {
      "epoch": 0.14856627135551087,
      "grad_norm": 0.4117468595504761,
      "learning_rate": 8.514337286444893e-06,
      "loss": 0.0457,
      "step": 9383
    },
    {
      "epoch": 0.14858210491315293,
      "grad_norm": 0.0008256106521002948,
      "learning_rate": 8.514178950868472e-06,
      "loss": 0.0,
      "step": 9384
    },
    {
      "epoch": 0.148597938470795,
      "grad_norm": 0.0257013700902462,
      "learning_rate": 8.51402061529205e-06,
      "loss": 0.001,
      "step": 9385
    },
    {
      "epoch": 0.14861377202843706,
      "grad_norm": 0.009878771379590034,
      "learning_rate": 8.51386227971563e-06,
      "loss": 0.0001,
      "step": 9386
    },
    {
      "epoch": 0.14862960558607913,
      "grad_norm": 0.22867703437805176,
      "learning_rate": 8.51370394413921e-06,
      "loss": 0.108,
      "step": 9387
    },
    {
      "epoch": 0.1486454391437212,
      "grad_norm": 0.00029655551770702004,
      "learning_rate": 8.513545608562788e-06,
      "loss": 0.0,
      "step": 9388
    },
    {
      "epoch": 0.14866127270136326,
      "grad_norm": 0.4095357358455658,
      "learning_rate": 8.513387272986367e-06,
      "loss": 0.0937,
      "step": 9389
    },
    {
      "epoch": 0.14867710625900535,
      "grad_norm": 0.2900632917881012,
      "learning_rate": 8.513228937409948e-06,
      "loss": 0.1433,
      "step": 9390
    },
    {
      "epoch": 0.1486929398166474,
      "grad_norm": 0.2889857590198517,
      "learning_rate": 8.513070601833526e-06,
      "loss": 0.1268,
      "step": 9391
    },
    {
      "epoch": 0.14870877337428948,
      "grad_norm": 0.274372935295105,
      "learning_rate": 8.512912266257106e-06,
      "loss": 0.1215,
      "step": 9392
    },
    {
      "epoch": 0.14872460693193154,
      "grad_norm": 0.1921267807483673,
      "learning_rate": 8.512753930680685e-06,
      "loss": 0.0764,
      "step": 9393
    },
    {
      "epoch": 0.1487404404895736,
      "grad_norm": 0.025440474972128868,
      "learning_rate": 8.512595595104265e-06,
      "loss": 0.0011,
      "step": 9394
    },
    {
      "epoch": 0.14875627404721567,
      "grad_norm": 0.37727564573287964,
      "learning_rate": 8.512437259527844e-06,
      "loss": 0.1597,
      "step": 9395
    },
    {
      "epoch": 0.14877210760485773,
      "grad_norm": 0.18324841558933258,
      "learning_rate": 8.512278923951424e-06,
      "loss": 0.057,
      "step": 9396
    },
    {
      "epoch": 0.1487879411624998,
      "grad_norm": 0.29294005036354065,
      "learning_rate": 8.512120588375002e-06,
      "loss": 0.034,
      "step": 9397
    },
    {
      "epoch": 0.14880377472014186,
      "grad_norm": 0.1721583604812622,
      "learning_rate": 8.511962252798583e-06,
      "loss": 0.1203,
      "step": 9398
    },
    {
      "epoch": 0.14881960827778393,
      "grad_norm": 0.38561782240867615,
      "learning_rate": 8.511803917222162e-06,
      "loss": 0.2139,
      "step": 9399
    },
    {
      "epoch": 0.148835441835426,
      "grad_norm": 0.33955442905426025,
      "learning_rate": 8.51164558164574e-06,
      "loss": 0.214,
      "step": 9400
    },
    {
      "epoch": 0.14885127539306806,
      "grad_norm": 0.602039098739624,
      "learning_rate": 8.51148724606932e-06,
      "loss": 0.1034,
      "step": 9401
    },
    {
      "epoch": 0.14886710895071015,
      "grad_norm": 0.22567224502563477,
      "learning_rate": 8.5113289104929e-06,
      "loss": 0.0453,
      "step": 9402
    },
    {
      "epoch": 0.1488829425083522,
      "grad_norm": 0.0022781393490731716,
      "learning_rate": 8.511170574916478e-06,
      "loss": 0.0001,
      "step": 9403
    },
    {
      "epoch": 0.14889877606599428,
      "grad_norm": 0.15512551367282867,
      "learning_rate": 8.511012239340059e-06,
      "loss": 0.092,
      "step": 9404
    },
    {
      "epoch": 0.14891460962363634,
      "grad_norm": 0.02059190534055233,
      "learning_rate": 8.510853903763638e-06,
      "loss": 0.001,
      "step": 9405
    },
    {
      "epoch": 0.1489304431812784,
      "grad_norm": 0.5690739750862122,
      "learning_rate": 8.510695568187217e-06,
      "loss": 0.097,
      "step": 9406
    },
    {
      "epoch": 0.14894627673892047,
      "grad_norm": 0.6627881526947021,
      "learning_rate": 8.510537232610796e-06,
      "loss": 0.4815,
      "step": 9407
    },
    {
      "epoch": 0.14896211029656253,
      "grad_norm": 0.22801566123962402,
      "learning_rate": 8.510378897034375e-06,
      "loss": 0.068,
      "step": 9408
    },
    {
      "epoch": 0.1489779438542046,
      "grad_norm": 0.007181995082646608,
      "learning_rate": 8.510220561457954e-06,
      "loss": 0.0004,
      "step": 9409
    },
    {
      "epoch": 0.14899377741184666,
      "grad_norm": 0.02429276891052723,
      "learning_rate": 8.510062225881533e-06,
      "loss": 0.0014,
      "step": 9410
    },
    {
      "epoch": 0.14900961096948873,
      "grad_norm": 0.16312620043754578,
      "learning_rate": 8.509903890305114e-06,
      "loss": 0.0328,
      "step": 9411
    },
    {
      "epoch": 0.1490254445271308,
      "grad_norm": 0.32223889231681824,
      "learning_rate": 8.509745554728693e-06,
      "loss": 0.1816,
      "step": 9412
    },
    {
      "epoch": 0.14904127808477285,
      "grad_norm": 1.086424469947815,
      "learning_rate": 8.509587219152272e-06,
      "loss": 0.5158,
      "step": 9413
    },
    {
      "epoch": 0.14905711164241495,
      "grad_norm": 0.25464993715286255,
      "learning_rate": 8.509428883575851e-06,
      "loss": 0.0657,
      "step": 9414
    },
    {
      "epoch": 0.149072945200057,
      "grad_norm": 0.4300641119480133,
      "learning_rate": 8.50927054799943e-06,
      "loss": 0.2227,
      "step": 9415
    },
    {
      "epoch": 0.14908877875769908,
      "grad_norm": 0.19802094995975494,
      "learning_rate": 8.50911221242301e-06,
      "loss": 0.0284,
      "step": 9416
    },
    {
      "epoch": 0.14910461231534114,
      "grad_norm": 0.38296616077423096,
      "learning_rate": 8.50895387684659e-06,
      "loss": 0.11,
      "step": 9417
    },
    {
      "epoch": 0.1491204458729832,
      "grad_norm": 0.2904609739780426,
      "learning_rate": 8.50879554127017e-06,
      "loss": 0.0155,
      "step": 9418
    },
    {
      "epoch": 0.14913627943062527,
      "grad_norm": 0.002312907250598073,
      "learning_rate": 8.508637205693748e-06,
      "loss": 0.0,
      "step": 9419
    },
    {
      "epoch": 0.14915211298826733,
      "grad_norm": 0.0250649806112051,
      "learning_rate": 8.508478870117327e-06,
      "loss": 0.0017,
      "step": 9420
    },
    {
      "epoch": 0.1491679465459094,
      "grad_norm": 0.00019120675278827548,
      "learning_rate": 8.508320534540906e-06,
      "loss": 0.0,
      "step": 9421
    },
    {
      "epoch": 0.14918378010355146,
      "grad_norm": 0.00335290958173573,
      "learning_rate": 8.508162198964486e-06,
      "loss": 0.0001,
      "step": 9422
    },
    {
      "epoch": 0.14919961366119353,
      "grad_norm": 0.2598072588443756,
      "learning_rate": 8.508003863388066e-06,
      "loss": 0.0667,
      "step": 9423
    },
    {
      "epoch": 0.1492154472188356,
      "grad_norm": 0.503280520439148,
      "learning_rate": 8.507845527811645e-06,
      "loss": 0.2715,
      "step": 9424
    },
    {
      "epoch": 0.14923128077647765,
      "grad_norm": 0.01140754297375679,
      "learning_rate": 8.507687192235224e-06,
      "loss": 0.0006,
      "step": 9425
    },
    {
      "epoch": 0.14924711433411975,
      "grad_norm": 0.6933935880661011,
      "learning_rate": 8.507528856658804e-06,
      "loss": 0.2082,
      "step": 9426
    },
    {
      "epoch": 0.1492629478917618,
      "grad_norm": 0.32314473390579224,
      "learning_rate": 8.507370521082383e-06,
      "loss": 0.2248,
      "step": 9427
    },
    {
      "epoch": 0.14927878144940387,
      "grad_norm": 0.6587781310081482,
      "learning_rate": 8.507212185505962e-06,
      "loss": 0.1003,
      "step": 9428
    },
    {
      "epoch": 0.14929461500704594,
      "grad_norm": 0.00023205090838018805,
      "learning_rate": 8.507053849929542e-06,
      "loss": 0.0,
      "step": 9429
    },
    {
      "epoch": 0.149310448564688,
      "grad_norm": 0.03732365369796753,
      "learning_rate": 8.50689551435312e-06,
      "loss": 0.0018,
      "step": 9430
    },
    {
      "epoch": 0.14932628212233007,
      "grad_norm": 0.00038743947516195476,
      "learning_rate": 8.5067371787767e-06,
      "loss": 0.0,
      "step": 9431
    },
    {
      "epoch": 0.14934211567997213,
      "grad_norm": 0.18513600528240204,
      "learning_rate": 8.50657884320028e-06,
      "loss": 0.0748,
      "step": 9432
    },
    {
      "epoch": 0.1493579492376142,
      "grad_norm": 0.5992252826690674,
      "learning_rate": 8.506420507623859e-06,
      "loss": 0.27,
      "step": 9433
    },
    {
      "epoch": 0.14937378279525626,
      "grad_norm": 0.7233476042747498,
      "learning_rate": 8.506262172047438e-06,
      "loss": 0.0355,
      "step": 9434
    },
    {
      "epoch": 0.14938961635289832,
      "grad_norm": 0.2037525326013565,
      "learning_rate": 8.506103836471017e-06,
      "loss": 0.0475,
      "step": 9435
    },
    {
      "epoch": 0.1494054499105404,
      "grad_norm": 0.019280070438981056,
      "learning_rate": 8.505945500894596e-06,
      "loss": 0.0008,
      "step": 9436
    },
    {
      "epoch": 0.14942128346818245,
      "grad_norm": 0.002407533349469304,
      "learning_rate": 8.505787165318175e-06,
      "loss": 0.0,
      "step": 9437
    },
    {
      "epoch": 0.14943711702582455,
      "grad_norm": 0.021458804607391357,
      "learning_rate": 8.505628829741756e-06,
      "loss": 0.0014,
      "step": 9438
    },
    {
      "epoch": 0.1494529505834666,
      "grad_norm": 0.2959284484386444,
      "learning_rate": 8.505470494165335e-06,
      "loss": 0.0762,
      "step": 9439
    },
    {
      "epoch": 0.14946878414110867,
      "grad_norm": 0.022693494334816933,
      "learning_rate": 8.505312158588914e-06,
      "loss": 0.0013,
      "step": 9440
    },
    {
      "epoch": 0.14948461769875074,
      "grad_norm": 0.03201661258935928,
      "learning_rate": 8.505153823012493e-06,
      "loss": 0.0023,
      "step": 9441
    },
    {
      "epoch": 0.1495004512563928,
      "grad_norm": 0.33100205659866333,
      "learning_rate": 8.504995487436072e-06,
      "loss": 0.1539,
      "step": 9442
    },
    {
      "epoch": 0.14951628481403487,
      "grad_norm": 0.35839536786079407,
      "learning_rate": 8.504837151859651e-06,
      "loss": 0.2027,
      "step": 9443
    },
    {
      "epoch": 0.14953211837167693,
      "grad_norm": 0.5353114604949951,
      "learning_rate": 8.504678816283232e-06,
      "loss": 0.1802,
      "step": 9444
    },
    {
      "epoch": 0.149547951929319,
      "grad_norm": 0.003764854744076729,
      "learning_rate": 8.504520480706811e-06,
      "loss": 0.0001,
      "step": 9445
    },
    {
      "epoch": 0.14956378548696106,
      "grad_norm": 0.8252601623535156,
      "learning_rate": 8.50436214513039e-06,
      "loss": 0.3854,
      "step": 9446
    },
    {
      "epoch": 0.14957961904460312,
      "grad_norm": 0.5877201557159424,
      "learning_rate": 8.50420380955397e-06,
      "loss": 1.0502,
      "step": 9447
    },
    {
      "epoch": 0.1495954526022452,
      "grad_norm": 0.17185194790363312,
      "learning_rate": 8.504045473977548e-06,
      "loss": 0.0363,
      "step": 9448
    },
    {
      "epoch": 0.14961128615988725,
      "grad_norm": 7.127920252969489e-05,
      "learning_rate": 8.503887138401127e-06,
      "loss": 0.0,
      "step": 9449
    },
    {
      "epoch": 0.14962711971752934,
      "grad_norm": 0.14104992151260376,
      "learning_rate": 8.503728802824708e-06,
      "loss": 0.0339,
      "step": 9450
    },
    {
      "epoch": 0.1496429532751714,
      "grad_norm": 0.48004186153411865,
      "learning_rate": 8.503570467248287e-06,
      "loss": 0.0745,
      "step": 9451
    },
    {
      "epoch": 0.14965878683281347,
      "grad_norm": 0.00011912447371287271,
      "learning_rate": 8.503412131671866e-06,
      "loss": 0.0,
      "step": 9452
    },
    {
      "epoch": 0.14967462039045554,
      "grad_norm": 0.3715016543865204,
      "learning_rate": 8.503253796095445e-06,
      "loss": 0.2979,
      "step": 9453
    },
    {
      "epoch": 0.1496904539480976,
      "grad_norm": 0.5644612908363342,
      "learning_rate": 8.503095460519025e-06,
      "loss": 0.9287,
      "step": 9454
    },
    {
      "epoch": 0.14970628750573967,
      "grad_norm": 1.7937123775482178,
      "learning_rate": 8.502937124942604e-06,
      "loss": 0.1853,
      "step": 9455
    },
    {
      "epoch": 0.14972212106338173,
      "grad_norm": 0.6597639322280884,
      "learning_rate": 8.502778789366183e-06,
      "loss": 0.2224,
      "step": 9456
    },
    {
      "epoch": 0.1497379546210238,
      "grad_norm": 0.0007885944796726108,
      "learning_rate": 8.502620453789763e-06,
      "loss": 0.0,
      "step": 9457
    },
    {
      "epoch": 0.14975378817866586,
      "grad_norm": 0.6193569898605347,
      "learning_rate": 8.50246211821334e-06,
      "loss": 0.1069,
      "step": 9458
    },
    {
      "epoch": 0.14976962173630792,
      "grad_norm": 0.1759524643421173,
      "learning_rate": 8.502303782636922e-06,
      "loss": 0.0828,
      "step": 9459
    },
    {
      "epoch": 0.14978545529395,
      "grad_norm": 0.4588935971260071,
      "learning_rate": 8.5021454470605e-06,
      "loss": 0.1697,
      "step": 9460
    },
    {
      "epoch": 0.14980128885159205,
      "grad_norm": 0.23714672029018402,
      "learning_rate": 8.50198711148408e-06,
      "loss": 0.0446,
      "step": 9461
    },
    {
      "epoch": 0.14981712240923414,
      "grad_norm": 0.31217578053474426,
      "learning_rate": 8.501828775907659e-06,
      "loss": 0.132,
      "step": 9462
    },
    {
      "epoch": 0.1498329559668762,
      "grad_norm": 0.35309335589408875,
      "learning_rate": 8.50167044033124e-06,
      "loss": 0.2102,
      "step": 9463
    },
    {
      "epoch": 0.14984878952451827,
      "grad_norm": 0.13919471204280853,
      "learning_rate": 8.501512104754817e-06,
      "loss": 0.0107,
      "step": 9464
    },
    {
      "epoch": 0.14986462308216034,
      "grad_norm": 0.5164101123809814,
      "learning_rate": 8.501353769178398e-06,
      "loss": 0.0977,
      "step": 9465
    },
    {
      "epoch": 0.1498804566398024,
      "grad_norm": 0.0072993021458387375,
      "learning_rate": 8.501195433601977e-06,
      "loss": 0.0004,
      "step": 9466
    },
    {
      "epoch": 0.14989629019744447,
      "grad_norm": 0.5739914774894714,
      "learning_rate": 8.501037098025556e-06,
      "loss": 0.2603,
      "step": 9467
    },
    {
      "epoch": 0.14991212375508653,
      "grad_norm": 0.025109831243753433,
      "learning_rate": 8.500878762449135e-06,
      "loss": 0.0014,
      "step": 9468
    },
    {
      "epoch": 0.1499279573127286,
      "grad_norm": 0.08807282894849777,
      "learning_rate": 8.500720426872716e-06,
      "loss": 0.0138,
      "step": 9469
    },
    {
      "epoch": 0.14994379087037066,
      "grad_norm": 0.05200788378715515,
      "learning_rate": 8.500562091296293e-06,
      "loss": 0.0029,
      "step": 9470
    },
    {
      "epoch": 0.14995962442801272,
      "grad_norm": 8.835227345116436e-05,
      "learning_rate": 8.500403755719874e-06,
      "loss": 0.0,
      "step": 9471
    },
    {
      "epoch": 0.1499754579856548,
      "grad_norm": 0.6443670988082886,
      "learning_rate": 8.500245420143453e-06,
      "loss": 0.1742,
      "step": 9472
    },
    {
      "epoch": 0.14999129154329685,
      "grad_norm": 0.1460525393486023,
      "learning_rate": 8.500087084567032e-06,
      "loss": 0.0297,
      "step": 9473
    },
    {
      "epoch": 0.15000712510093894,
      "grad_norm": 0.00017543746798764914,
      "learning_rate": 8.499928748990611e-06,
      "loss": 0.0,
      "step": 9474
    },
    {
      "epoch": 0.150022958658581,
      "grad_norm": 3.47283673286438,
      "learning_rate": 8.499770413414192e-06,
      "loss": 0.4382,
      "step": 9475
    },
    {
      "epoch": 0.15003879221622307,
      "grad_norm": 0.24071119725704193,
      "learning_rate": 8.49961207783777e-06,
      "loss": 0.1103,
      "step": 9476
    },
    {
      "epoch": 0.15005462577386514,
      "grad_norm": 0.3005521595478058,
      "learning_rate": 8.49945374226135e-06,
      "loss": 0.1248,
      "step": 9477
    },
    {
      "epoch": 0.1500704593315072,
      "grad_norm": 0.3370949625968933,
      "learning_rate": 8.49929540668493e-06,
      "loss": 0.0659,
      "step": 9478
    },
    {
      "epoch": 0.15008629288914926,
      "grad_norm": 0.24440902471542358,
      "learning_rate": 8.499137071108508e-06,
      "loss": 0.2772,
      "step": 9479
    },
    {
      "epoch": 0.15010212644679133,
      "grad_norm": 0.02384112775325775,
      "learning_rate": 8.498978735532087e-06,
      "loss": 0.0015,
      "step": 9480
    },
    {
      "epoch": 0.1501179600044334,
      "grad_norm": 0.8246471285820007,
      "learning_rate": 8.498820399955666e-06,
      "loss": 0.3979,
      "step": 9481
    },
    {
      "epoch": 0.15013379356207546,
      "grad_norm": 0.0158368106931448,
      "learning_rate": 8.498662064379246e-06,
      "loss": 0.0014,
      "step": 9482
    },
    {
      "epoch": 0.15014962711971752,
      "grad_norm": 0.3859270513057709,
      "learning_rate": 8.498503728802825e-06,
      "loss": 0.3541,
      "step": 9483
    },
    {
      "epoch": 0.15016546067735959,
      "grad_norm": 0.34232571721076965,
      "learning_rate": 8.498345393226405e-06,
      "loss": 0.146,
      "step": 9484
    },
    {
      "epoch": 0.15018129423500165,
      "grad_norm": 0.21744126081466675,
      "learning_rate": 8.498187057649984e-06,
      "loss": 0.0548,
      "step": 9485
    },
    {
      "epoch": 0.15019712779264374,
      "grad_norm": 0.16445696353912354,
      "learning_rate": 8.498028722073564e-06,
      "loss": 0.0167,
      "step": 9486
    },
    {
      "epoch": 0.1502129613502858,
      "grad_norm": 0.3094627261161804,
      "learning_rate": 8.497870386497143e-06,
      "loss": 0.0688,
      "step": 9487
    },
    {
      "epoch": 0.15022879490792787,
      "grad_norm": 0.26210635900497437,
      "learning_rate": 8.497712050920722e-06,
      "loss": 0.1489,
      "step": 9488
    },
    {
      "epoch": 0.15024462846556993,
      "grad_norm": 0.778006911277771,
      "learning_rate": 8.4975537153443e-06,
      "loss": 0.1643,
      "step": 9489
    },
    {
      "epoch": 0.150260462023212,
      "grad_norm": 0.08300693333148956,
      "learning_rate": 8.497395379767882e-06,
      "loss": 0.0064,
      "step": 9490
    },
    {
      "epoch": 0.15027629558085406,
      "grad_norm": 0.3806183934211731,
      "learning_rate": 8.497237044191459e-06,
      "loss": 0.0672,
      "step": 9491
    },
    {
      "epoch": 0.15029212913849613,
      "grad_norm": 0.000354410003637895,
      "learning_rate": 8.49707870861504e-06,
      "loss": 0.0,
      "step": 9492
    },
    {
      "epoch": 0.1503079626961382,
      "grad_norm": 0.5140767693519592,
      "learning_rate": 8.496920373038619e-06,
      "loss": 0.5894,
      "step": 9493
    },
    {
      "epoch": 0.15032379625378026,
      "grad_norm": 0.6675236225128174,
      "learning_rate": 8.496762037462198e-06,
      "loss": 0.8147,
      "step": 9494
    },
    {
      "epoch": 0.15033962981142232,
      "grad_norm": 0.26947617530822754,
      "learning_rate": 8.496603701885777e-06,
      "loss": 0.153,
      "step": 9495
    },
    {
      "epoch": 0.15035546336906438,
      "grad_norm": 0.20186591148376465,
      "learning_rate": 8.496445366309358e-06,
      "loss": 0.0487,
      "step": 9496
    },
    {
      "epoch": 0.15037129692670645,
      "grad_norm": 0.2702745199203491,
      "learning_rate": 8.496287030732935e-06,
      "loss": 0.3253,
      "step": 9497
    },
    {
      "epoch": 0.15038713048434854,
      "grad_norm": 0.7433911561965942,
      "learning_rate": 8.496128695156516e-06,
      "loss": 0.5061,
      "step": 9498
    },
    {
      "epoch": 0.1504029640419906,
      "grad_norm": 0.35144978761672974,
      "learning_rate": 8.495970359580095e-06,
      "loss": 0.1106,
      "step": 9499
    },
    {
      "epoch": 0.15041879759963267,
      "grad_norm": 0.2236345112323761,
      "learning_rate": 8.495812024003674e-06,
      "loss": 0.1141,
      "step": 9500
    },
    {
      "epoch": 0.15043463115727473,
      "grad_norm": 0.01520149689167738,
      "learning_rate": 8.495653688427253e-06,
      "loss": 0.0011,
      "step": 9501
    },
    {
      "epoch": 0.1504504647149168,
      "grad_norm": 0.34629055857658386,
      "learning_rate": 8.495495352850834e-06,
      "loss": 0.2381,
      "step": 9502
    },
    {
      "epoch": 0.15046629827255886,
      "grad_norm": 0.3651061952114105,
      "learning_rate": 8.495337017274411e-06,
      "loss": 0.2158,
      "step": 9503
    },
    {
      "epoch": 0.15048213183020093,
      "grad_norm": 0.013111740350723267,
      "learning_rate": 8.49517868169799e-06,
      "loss": 0.0009,
      "step": 9504
    },
    {
      "epoch": 0.150497965387843,
      "grad_norm": 0.23454377055168152,
      "learning_rate": 8.495020346121571e-06,
      "loss": 0.1394,
      "step": 9505
    },
    {
      "epoch": 0.15051379894548506,
      "grad_norm": 0.40739282965660095,
      "learning_rate": 8.49486201054515e-06,
      "loss": 0.1173,
      "step": 9506
    },
    {
      "epoch": 0.15052963250312712,
      "grad_norm": 0.26364803314208984,
      "learning_rate": 8.49470367496873e-06,
      "loss": 0.059,
      "step": 9507
    },
    {
      "epoch": 0.15054546606076918,
      "grad_norm": 0.39638620615005493,
      "learning_rate": 8.494545339392308e-06,
      "loss": 0.149,
      "step": 9508
    },
    {
      "epoch": 0.15056129961841125,
      "grad_norm": 0.24701586365699768,
      "learning_rate": 8.494387003815887e-06,
      "loss": 0.0761,
      "step": 9509
    },
    {
      "epoch": 0.15057713317605334,
      "grad_norm": 0.32100391387939453,
      "learning_rate": 8.494228668239467e-06,
      "loss": 0.1204,
      "step": 9510
    },
    {
      "epoch": 0.1505929667336954,
      "grad_norm": 0.3399296700954437,
      "learning_rate": 8.494070332663047e-06,
      "loss": 0.5546,
      "step": 9511
    },
    {
      "epoch": 0.15060880029133747,
      "grad_norm": 0.38327428698539734,
      "learning_rate": 8.493911997086626e-06,
      "loss": 0.5485,
      "step": 9512
    },
    {
      "epoch": 0.15062463384897953,
      "grad_norm": 7.070427091093734e-05,
      "learning_rate": 8.493753661510205e-06,
      "loss": 0.0,
      "step": 9513
    },
    {
      "epoch": 0.1506404674066216,
      "grad_norm": 0.5331323742866516,
      "learning_rate": 8.493595325933785e-06,
      "loss": 0.2877,
      "step": 9514
    },
    {
      "epoch": 0.15065630096426366,
      "grad_norm": 0.19303283095359802,
      "learning_rate": 8.493436990357364e-06,
      "loss": 0.0125,
      "step": 9515
    },
    {
      "epoch": 0.15067213452190573,
      "grad_norm": 0.3311147391796112,
      "learning_rate": 8.493278654780943e-06,
      "loss": 0.0934,
      "step": 9516
    },
    {
      "epoch": 0.1506879680795478,
      "grad_norm": 0.004586956929415464,
      "learning_rate": 8.493120319204523e-06,
      "loss": 0.0002,
      "step": 9517
    },
    {
      "epoch": 0.15070380163718985,
      "grad_norm": 0.6352107524871826,
      "learning_rate": 8.492961983628103e-06,
      "loss": 0.4505,
      "step": 9518
    },
    {
      "epoch": 0.15071963519483192,
      "grad_norm": 0.002695862902328372,
      "learning_rate": 8.492803648051682e-06,
      "loss": 0.0,
      "step": 9519
    },
    {
      "epoch": 0.15073546875247398,
      "grad_norm": 0.43588584661483765,
      "learning_rate": 8.49264531247526e-06,
      "loss": 0.1383,
      "step": 9520
    },
    {
      "epoch": 0.15075130231011605,
      "grad_norm": 0.22404137253761292,
      "learning_rate": 8.49248697689884e-06,
      "loss": 0.0614,
      "step": 9521
    },
    {
      "epoch": 0.15076713586775814,
      "grad_norm": 0.5992966890335083,
      "learning_rate": 8.492328641322419e-06,
      "loss": 1.2815,
      "step": 9522
    },
    {
      "epoch": 0.1507829694254002,
      "grad_norm": 0.3682016134262085,
      "learning_rate": 8.492170305746e-06,
      "loss": 0.132,
      "step": 9523
    },
    {
      "epoch": 0.15079880298304227,
      "grad_norm": 0.2580341398715973,
      "learning_rate": 8.492011970169579e-06,
      "loss": 0.0644,
      "step": 9524
    },
    {
      "epoch": 0.15081463654068433,
      "grad_norm": 0.38510218262672424,
      "learning_rate": 8.491853634593158e-06,
      "loss": 0.1459,
      "step": 9525
    },
    {
      "epoch": 0.1508304700983264,
      "grad_norm": 0.009783822111785412,
      "learning_rate": 8.491695299016737e-06,
      "loss": 0.0005,
      "step": 9526
    },
    {
      "epoch": 0.15084630365596846,
      "grad_norm": 0.14323057234287262,
      "learning_rate": 8.491536963440316e-06,
      "loss": 0.0762,
      "step": 9527
    },
    {
      "epoch": 0.15086213721361053,
      "grad_norm": 0.21743835508823395,
      "learning_rate": 8.491378627863895e-06,
      "loss": 0.0316,
      "step": 9528
    },
    {
      "epoch": 0.1508779707712526,
      "grad_norm": 0.4760313034057617,
      "learning_rate": 8.491220292287474e-06,
      "loss": 0.3475,
      "step": 9529
    },
    {
      "epoch": 0.15089380432889465,
      "grad_norm": 0.4091399013996124,
      "learning_rate": 8.491061956711055e-06,
      "loss": 0.0933,
      "step": 9530
    },
    {
      "epoch": 0.15090963788653672,
      "grad_norm": 0.5111390352249146,
      "learning_rate": 8.490903621134632e-06,
      "loss": 0.5077,
      "step": 9531
    },
    {
      "epoch": 0.15092547144417878,
      "grad_norm": 0.0002104094746755436,
      "learning_rate": 8.490745285558213e-06,
      "loss": 0.0,
      "step": 9532
    },
    {
      "epoch": 0.15094130500182085,
      "grad_norm": 0.02864290587604046,
      "learning_rate": 8.490586949981792e-06,
      "loss": 0.0017,
      "step": 9533
    },
    {
      "epoch": 0.15095713855946294,
      "grad_norm": 0.01535010989755392,
      "learning_rate": 8.490428614405371e-06,
      "loss": 0.0007,
      "step": 9534
    },
    {
      "epoch": 0.150972972117105,
      "grad_norm": 0.5986906290054321,
      "learning_rate": 8.49027027882895e-06,
      "loss": 0.3636,
      "step": 9535
    },
    {
      "epoch": 0.15098880567474707,
      "grad_norm": 0.010234744288027287,
      "learning_rate": 8.490111943252531e-06,
      "loss": 0.0006,
      "step": 9536
    },
    {
      "epoch": 0.15100463923238913,
      "grad_norm": 0.33404597640037537,
      "learning_rate": 8.489953607676108e-06,
      "loss": 0.0846,
      "step": 9537
    },
    {
      "epoch": 0.1510204727900312,
      "grad_norm": 0.6107345819473267,
      "learning_rate": 8.48979527209969e-06,
      "loss": 0.4663,
      "step": 9538
    },
    {
      "epoch": 0.15103630634767326,
      "grad_norm": 0.01200248021632433,
      "learning_rate": 8.489636936523268e-06,
      "loss": 0.0006,
      "step": 9539
    },
    {
      "epoch": 0.15105213990531532,
      "grad_norm": 0.37813347578048706,
      "learning_rate": 8.489478600946847e-06,
      "loss": 0.297,
      "step": 9540
    },
    {
      "epoch": 0.1510679734629574,
      "grad_norm": 0.6130335330963135,
      "learning_rate": 8.489320265370426e-06,
      "loss": 0.3247,
      "step": 9541
    },
    {
      "epoch": 0.15108380702059945,
      "grad_norm": 0.012694939970970154,
      "learning_rate": 8.489161929794007e-06,
      "loss": 0.0006,
      "step": 9542
    },
    {
      "epoch": 0.15109964057824152,
      "grad_norm": 0.010777702555060387,
      "learning_rate": 8.489003594217585e-06,
      "loss": 0.0006,
      "step": 9543
    },
    {
      "epoch": 0.15111547413588358,
      "grad_norm": 0.30476269125938416,
      "learning_rate": 8.488845258641165e-06,
      "loss": 0.1944,
      "step": 9544
    },
    {
      "epoch": 0.15113130769352565,
      "grad_norm": 0.7849368453025818,
      "learning_rate": 8.488686923064744e-06,
      "loss": 0.1193,
      "step": 9545
    },
    {
      "epoch": 0.15114714125116774,
      "grad_norm": 0.7041598558425903,
      "learning_rate": 8.488528587488324e-06,
      "loss": 0.183,
      "step": 9546
    },
    {
      "epoch": 0.1511629748088098,
      "grad_norm": 0.00800313800573349,
      "learning_rate": 8.488370251911903e-06,
      "loss": 0.0004,
      "step": 9547
    },
    {
      "epoch": 0.15117880836645187,
      "grad_norm": 0.2500567138195038,
      "learning_rate": 8.488211916335483e-06,
      "loss": 0.2087,
      "step": 9548
    },
    {
      "epoch": 0.15119464192409393,
      "grad_norm": 0.4682133197784424,
      "learning_rate": 8.48805358075906e-06,
      "loss": 0.1219,
      "step": 9549
    },
    {
      "epoch": 0.151210475481736,
      "grad_norm": 0.0001783423504093662,
      "learning_rate": 8.487895245182642e-06,
      "loss": 0.0,
      "step": 9550
    },
    {
      "epoch": 0.15122630903937806,
      "grad_norm": 0.0779932364821434,
      "learning_rate": 8.48773690960622e-06,
      "loss": 0.0254,
      "step": 9551
    },
    {
      "epoch": 0.15124214259702012,
      "grad_norm": 0.34964364767074585,
      "learning_rate": 8.4875785740298e-06,
      "loss": 0.1056,
      "step": 9552
    },
    {
      "epoch": 0.1512579761546622,
      "grad_norm": 0.05913541465997696,
      "learning_rate": 8.487420238453379e-06,
      "loss": 0.0034,
      "step": 9553
    },
    {
      "epoch": 0.15127380971230425,
      "grad_norm": 0.0003922542091459036,
      "learning_rate": 8.487261902876958e-06,
      "loss": 0.0,
      "step": 9554
    },
    {
      "epoch": 0.15128964326994632,
      "grad_norm": 0.04388275370001793,
      "learning_rate": 8.487103567300537e-06,
      "loss": 0.0023,
      "step": 9555
    },
    {
      "epoch": 0.15130547682758838,
      "grad_norm": 0.019246231764554977,
      "learning_rate": 8.486945231724116e-06,
      "loss": 0.0013,
      "step": 9556
    },
    {
      "epoch": 0.15132131038523045,
      "grad_norm": 0.005095474887639284,
      "learning_rate": 8.486786896147697e-06,
      "loss": 0.0003,
      "step": 9557
    },
    {
      "epoch": 0.15133714394287254,
      "grad_norm": 0.22458817064762115,
      "learning_rate": 8.486628560571274e-06,
      "loss": 0.1197,
      "step": 9558
    },
    {
      "epoch": 0.1513529775005146,
      "grad_norm": 0.6228164434432983,
      "learning_rate": 8.486470224994855e-06,
      "loss": 0.1838,
      "step": 9559
    },
    {
      "epoch": 0.15136881105815667,
      "grad_norm": 1.6065130233764648,
      "learning_rate": 8.486311889418434e-06,
      "loss": 0.7528,
      "step": 9560
    },
    {
      "epoch": 0.15138464461579873,
      "grad_norm": 0.8079283833503723,
      "learning_rate": 8.486153553842013e-06,
      "loss": 0.1464,
      "step": 9561
    },
    {
      "epoch": 0.1514004781734408,
      "grad_norm": 0.17925621569156647,
      "learning_rate": 8.485995218265592e-06,
      "loss": 0.0636,
      "step": 9562
    },
    {
      "epoch": 0.15141631173108286,
      "grad_norm": 0.3452248275279999,
      "learning_rate": 8.485836882689173e-06,
      "loss": 0.1802,
      "step": 9563
    },
    {
      "epoch": 0.15143214528872492,
      "grad_norm": 0.00832070130854845,
      "learning_rate": 8.48567854711275e-06,
      "loss": 0.0005,
      "step": 9564
    },
    {
      "epoch": 0.151447978846367,
      "grad_norm": 0.0002075886441161856,
      "learning_rate": 8.485520211536331e-06,
      "loss": 0.0,
      "step": 9565
    },
    {
      "epoch": 0.15146381240400905,
      "grad_norm": 0.4162595272064209,
      "learning_rate": 8.48536187595991e-06,
      "loss": 0.2447,
      "step": 9566
    },
    {
      "epoch": 0.15147964596165112,
      "grad_norm": 0.30925458669662476,
      "learning_rate": 8.48520354038349e-06,
      "loss": 0.0098,
      "step": 9567
    },
    {
      "epoch": 0.15149547951929318,
      "grad_norm": 0.04435628280043602,
      "learning_rate": 8.485045204807068e-06,
      "loss": 0.0031,
      "step": 9568
    },
    {
      "epoch": 0.15151131307693524,
      "grad_norm": 0.005022815894335508,
      "learning_rate": 8.48488686923065e-06,
      "loss": 0.0003,
      "step": 9569
    },
    {
      "epoch": 0.15152714663457734,
      "grad_norm": 0.07800406962633133,
      "learning_rate": 8.484728533654227e-06,
      "loss": 0.0073,
      "step": 9570
    },
    {
      "epoch": 0.1515429801922194,
      "grad_norm": 0.010288010351359844,
      "learning_rate": 8.484570198077807e-06,
      "loss": 0.0008,
      "step": 9571
    },
    {
      "epoch": 0.15155881374986147,
      "grad_norm": 0.3900465965270996,
      "learning_rate": 8.484411862501386e-06,
      "loss": 0.2031,
      "step": 9572
    },
    {
      "epoch": 0.15157464730750353,
      "grad_norm": 0.00036369398003444076,
      "learning_rate": 8.484253526924965e-06,
      "loss": 0.0,
      "step": 9573
    },
    {
      "epoch": 0.1515904808651456,
      "grad_norm": 0.5978354811668396,
      "learning_rate": 8.484095191348545e-06,
      "loss": 0.4653,
      "step": 9574
    },
    {
      "epoch": 0.15160631442278766,
      "grad_norm": 0.28448790311813354,
      "learning_rate": 8.483936855772125e-06,
      "loss": 0.2422,
      "step": 9575
    },
    {
      "epoch": 0.15162214798042972,
      "grad_norm": 0.0035493061877787113,
      "learning_rate": 8.483778520195703e-06,
      "loss": 0.0001,
      "step": 9576
    },
    {
      "epoch": 0.1516379815380718,
      "grad_norm": 0.15603221952915192,
      "learning_rate": 8.483620184619282e-06,
      "loss": 0.0553,
      "step": 9577
    },
    {
      "epoch": 0.15165381509571385,
      "grad_norm": 0.2197318971157074,
      "learning_rate": 8.483461849042863e-06,
      "loss": 0.0829,
      "step": 9578
    },
    {
      "epoch": 0.15166964865335592,
      "grad_norm": 0.0003646193945314735,
      "learning_rate": 8.483303513466442e-06,
      "loss": 0.0,
      "step": 9579
    },
    {
      "epoch": 0.15168548221099798,
      "grad_norm": 0.32697364687919617,
      "learning_rate": 8.48314517789002e-06,
      "loss": 0.0637,
      "step": 9580
    },
    {
      "epoch": 0.15170131576864004,
      "grad_norm": 0.41231417655944824,
      "learning_rate": 8.4829868423136e-06,
      "loss": 0.1815,
      "step": 9581
    },
    {
      "epoch": 0.15171714932628214,
      "grad_norm": 0.2644643783569336,
      "learning_rate": 8.482828506737179e-06,
      "loss": 0.0726,
      "step": 9582
    },
    {
      "epoch": 0.1517329828839242,
      "grad_norm": 0.4475284218788147,
      "learning_rate": 8.482670171160758e-06,
      "loss": 0.4043,
      "step": 9583
    },
    {
      "epoch": 0.15174881644156626,
      "grad_norm": 0.4665374755859375,
      "learning_rate": 8.482511835584339e-06,
      "loss": 0.5311,
      "step": 9584
    },
    {
      "epoch": 0.15176464999920833,
      "grad_norm": 0.26462069153785706,
      "learning_rate": 8.482353500007918e-06,
      "loss": 0.2303,
      "step": 9585
    },
    {
      "epoch": 0.1517804835568504,
      "grad_norm": 0.34963303804397583,
      "learning_rate": 8.482195164431497e-06,
      "loss": 0.1218,
      "step": 9586
    },
    {
      "epoch": 0.15179631711449246,
      "grad_norm": 0.2551138401031494,
      "learning_rate": 8.482036828855076e-06,
      "loss": 0.1013,
      "step": 9587
    },
    {
      "epoch": 0.15181215067213452,
      "grad_norm": 0.007466974202543497,
      "learning_rate": 8.481878493278655e-06,
      "loss": 0.0005,
      "step": 9588
    },
    {
      "epoch": 0.15182798422977659,
      "grad_norm": 0.0042232973501086235,
      "learning_rate": 8.481720157702234e-06,
      "loss": 0.0003,
      "step": 9589
    },
    {
      "epoch": 0.15184381778741865,
      "grad_norm": 0.40746256709098816,
      "learning_rate": 8.481561822125815e-06,
      "loss": 0.3742,
      "step": 9590
    },
    {
      "epoch": 0.15185965134506071,
      "grad_norm": 0.17943622171878815,
      "learning_rate": 8.481403486549394e-06,
      "loss": 0.0886,
      "step": 9591
    },
    {
      "epoch": 0.15187548490270278,
      "grad_norm": 0.03189383074641228,
      "learning_rate": 8.481245150972973e-06,
      "loss": 0.0024,
      "step": 9592
    },
    {
      "epoch": 0.15189131846034484,
      "grad_norm": 0.002369835739955306,
      "learning_rate": 8.481086815396552e-06,
      "loss": 0.0001,
      "step": 9593
    },
    {
      "epoch": 0.15190715201798694,
      "grad_norm": 0.04963565245270729,
      "learning_rate": 8.480928479820131e-06,
      "loss": 0.0025,
      "step": 9594
    },
    {
      "epoch": 0.151922985575629,
      "grad_norm": 0.0647817850112915,
      "learning_rate": 8.48077014424371e-06,
      "loss": 0.0057,
      "step": 9595
    },
    {
      "epoch": 0.15193881913327106,
      "grad_norm": 0.3334895372390747,
      "learning_rate": 8.480611808667291e-06,
      "loss": 0.1548,
      "step": 9596
    },
    {
      "epoch": 0.15195465269091313,
      "grad_norm": 0.1723627746105194,
      "learning_rate": 8.48045347309087e-06,
      "loss": 0.0132,
      "step": 9597
    },
    {
      "epoch": 0.1519704862485552,
      "grad_norm": 0.001188051188364625,
      "learning_rate": 8.48029513751445e-06,
      "loss": 0.0,
      "step": 9598
    },
    {
      "epoch": 0.15198631980619726,
      "grad_norm": 0.1788022369146347,
      "learning_rate": 8.480136801938028e-06,
      "loss": 0.1119,
      "step": 9599
    },
    {
      "epoch": 0.15200215336383932,
      "grad_norm": 0.01562479604035616,
      "learning_rate": 8.479978466361607e-06,
      "loss": 0.0009,
      "step": 9600
    },
    {
      "epoch": 0.15201798692148139,
      "grad_norm": 0.2260909378528595,
      "learning_rate": 8.479820130785186e-06,
      "loss": 0.0291,
      "step": 9601
    },
    {
      "epoch": 0.15203382047912345,
      "grad_norm": 0.00030519848223775625,
      "learning_rate": 8.479661795208766e-06,
      "loss": 0.0,
      "step": 9602
    },
    {
      "epoch": 0.1520496540367655,
      "grad_norm": 0.28340739011764526,
      "learning_rate": 8.479503459632346e-06,
      "loss": 0.0457,
      "step": 9603
    },
    {
      "epoch": 0.15206548759440758,
      "grad_norm": 0.00047720741713419557,
      "learning_rate": 8.479345124055924e-06,
      "loss": 0.0,
      "step": 9604
    },
    {
      "epoch": 0.15208132115204964,
      "grad_norm": 0.21777194738388062,
      "learning_rate": 8.479186788479504e-06,
      "loss": 0.0212,
      "step": 9605
    },
    {
      "epoch": 0.15209715470969173,
      "grad_norm": 0.00437580281868577,
      "learning_rate": 8.479028452903084e-06,
      "loss": 0.0002,
      "step": 9606
    },
    {
      "epoch": 0.1521129882673338,
      "grad_norm": 0.5520715117454529,
      "learning_rate": 8.478870117326663e-06,
      "loss": 0.4403,
      "step": 9607
    },
    {
      "epoch": 0.15212882182497586,
      "grad_norm": 0.22999097406864166,
      "learning_rate": 8.478711781750242e-06,
      "loss": 0.0782,
      "step": 9608
    },
    {
      "epoch": 0.15214465538261793,
      "grad_norm": 0.04049261659383774,
      "learning_rate": 8.478553446173823e-06,
      "loss": 0.0014,
      "step": 9609
    },
    {
      "epoch": 0.15216048894026,
      "grad_norm": 0.0003371053608134389,
      "learning_rate": 8.4783951105974e-06,
      "loss": 0.0,
      "step": 9610
    },
    {
      "epoch": 0.15217632249790206,
      "grad_norm": 0.9993274211883545,
      "learning_rate": 8.47823677502098e-06,
      "loss": 0.2562,
      "step": 9611
    },
    {
      "epoch": 0.15219215605554412,
      "grad_norm": 0.07667092233896255,
      "learning_rate": 8.47807843944456e-06,
      "loss": 0.0039,
      "step": 9612
    },
    {
      "epoch": 0.15220798961318618,
      "grad_norm": 0.5343232750892639,
      "learning_rate": 8.477920103868139e-06,
      "loss": 0.0995,
      "step": 9613
    },
    {
      "epoch": 0.15222382317082825,
      "grad_norm": 0.7316151261329651,
      "learning_rate": 8.477761768291718e-06,
      "loss": 0.3819,
      "step": 9614
    },
    {
      "epoch": 0.1522396567284703,
      "grad_norm": 0.010252140462398529,
      "learning_rate": 8.477603432715299e-06,
      "loss": 0.0006,
      "step": 9615
    },
    {
      "epoch": 0.15225549028611238,
      "grad_norm": 0.018114259466528893,
      "learning_rate": 8.477445097138876e-06,
      "loss": 0.0012,
      "step": 9616
    },
    {
      "epoch": 0.15227132384375444,
      "grad_norm": 0.01769999787211418,
      "learning_rate": 8.477286761562457e-06,
      "loss": 0.0007,
      "step": 9617
    },
    {
      "epoch": 0.15228715740139653,
      "grad_norm": 0.006579088978469372,
      "learning_rate": 8.477128425986036e-06,
      "loss": 0.0003,
      "step": 9618
    },
    {
      "epoch": 0.1523029909590386,
      "grad_norm": 0.0035772654227912426,
      "learning_rate": 8.476970090409615e-06,
      "loss": 0.0002,
      "step": 9619
    },
    {
      "epoch": 0.15231882451668066,
      "grad_norm": 0.5443078279495239,
      "learning_rate": 8.476811754833194e-06,
      "loss": 0.4423,
      "step": 9620
    },
    {
      "epoch": 0.15233465807432273,
      "grad_norm": 0.31835252046585083,
      "learning_rate": 8.476653419256773e-06,
      "loss": 0.0771,
      "step": 9621
    },
    {
      "epoch": 0.1523504916319648,
      "grad_norm": 0.5312141180038452,
      "learning_rate": 8.476495083680352e-06,
      "loss": 0.092,
      "step": 9622
    },
    {
      "epoch": 0.15236632518960685,
      "grad_norm": 0.5032494068145752,
      "learning_rate": 8.476336748103933e-06,
      "loss": 0.0436,
      "step": 9623
    },
    {
      "epoch": 0.15238215874724892,
      "grad_norm": 0.01894727535545826,
      "learning_rate": 8.476178412527512e-06,
      "loss": 0.0012,
      "step": 9624
    },
    {
      "epoch": 0.15239799230489098,
      "grad_norm": 0.6730527281761169,
      "learning_rate": 8.47602007695109e-06,
      "loss": 0.0822,
      "step": 9625
    },
    {
      "epoch": 0.15241382586253305,
      "grad_norm": 0.0016771841328591108,
      "learning_rate": 8.47586174137467e-06,
      "loss": 0.0,
      "step": 9626
    },
    {
      "epoch": 0.1524296594201751,
      "grad_norm": 0.41247162222862244,
      "learning_rate": 8.47570340579825e-06,
      "loss": 0.0584,
      "step": 9627
    },
    {
      "epoch": 0.15244549297781718,
      "grad_norm": 0.012098681181669235,
      "learning_rate": 8.475545070221828e-06,
      "loss": 0.0007,
      "step": 9628
    },
    {
      "epoch": 0.15246132653545924,
      "grad_norm": 0.011118194088339806,
      "learning_rate": 8.475386734645407e-06,
      "loss": 0.0006,
      "step": 9629
    },
    {
      "epoch": 0.15247716009310133,
      "grad_norm": 0.5009342432022095,
      "learning_rate": 8.475228399068988e-06,
      "loss": 0.0483,
      "step": 9630
    },
    {
      "epoch": 0.1524929936507434,
      "grad_norm": 0.25322723388671875,
      "learning_rate": 8.475070063492566e-06,
      "loss": 0.1672,
      "step": 9631
    },
    {
      "epoch": 0.15250882720838546,
      "grad_norm": 0.41265082359313965,
      "learning_rate": 8.474911727916146e-06,
      "loss": 0.4472,
      "step": 9632
    },
    {
      "epoch": 0.15252466076602753,
      "grad_norm": 0.30165916681289673,
      "learning_rate": 8.474753392339726e-06,
      "loss": 0.1539,
      "step": 9633
    },
    {
      "epoch": 0.1525404943236696,
      "grad_norm": 0.3481177091598511,
      "learning_rate": 8.474595056763305e-06,
      "loss": 0.0825,
      "step": 9634
    },
    {
      "epoch": 0.15255632788131165,
      "grad_norm": 0.016491180285811424,
      "learning_rate": 8.474436721186884e-06,
      "loss": 0.0009,
      "step": 9635
    },
    {
      "epoch": 0.15257216143895372,
      "grad_norm": 0.030443478375673294,
      "learning_rate": 8.474278385610464e-06,
      "loss": 0.0016,
      "step": 9636
    },
    {
      "epoch": 0.15258799499659578,
      "grad_norm": 0.2965905964374542,
      "learning_rate": 8.474120050034042e-06,
      "loss": 0.0845,
      "step": 9637
    },
    {
      "epoch": 0.15260382855423785,
      "grad_norm": 0.21210600435733795,
      "learning_rate": 8.473961714457623e-06,
      "loss": 0.0592,
      "step": 9638
    },
    {
      "epoch": 0.1526196621118799,
      "grad_norm": 0.319655179977417,
      "learning_rate": 8.473803378881202e-06,
      "loss": 0.165,
      "step": 9639
    },
    {
      "epoch": 0.15263549566952198,
      "grad_norm": 0.26868104934692383,
      "learning_rate": 8.47364504330478e-06,
      "loss": 0.1009,
      "step": 9640
    },
    {
      "epoch": 0.15265132922716404,
      "grad_norm": 0.22119848430156708,
      "learning_rate": 8.47348670772836e-06,
      "loss": 0.049,
      "step": 9641
    },
    {
      "epoch": 0.15266716278480613,
      "grad_norm": 0.3789654076099396,
      "learning_rate": 8.47332837215194e-06,
      "loss": 0.1959,
      "step": 9642
    },
    {
      "epoch": 0.1526829963424482,
      "grad_norm": 0.26049014925956726,
      "learning_rate": 8.473170036575518e-06,
      "loss": 0.2401,
      "step": 9643
    },
    {
      "epoch": 0.15269882990009026,
      "grad_norm": 0.21836751699447632,
      "learning_rate": 8.473011700999099e-06,
      "loss": 0.0544,
      "step": 9644
    },
    {
      "epoch": 0.15271466345773232,
      "grad_norm": 0.4534026086330414,
      "learning_rate": 8.472853365422678e-06,
      "loss": 0.2088,
      "step": 9645
    },
    {
      "epoch": 0.1527304970153744,
      "grad_norm": 0.22783301770687103,
      "learning_rate": 8.472695029846257e-06,
      "loss": 0.0879,
      "step": 9646
    },
    {
      "epoch": 0.15274633057301645,
      "grad_norm": 0.9268385171890259,
      "learning_rate": 8.472536694269836e-06,
      "loss": 0.2612,
      "step": 9647
    },
    {
      "epoch": 0.15276216413065852,
      "grad_norm": 0.010092124342918396,
      "learning_rate": 8.472378358693415e-06,
      "loss": 0.0005,
      "step": 9648
    },
    {
      "epoch": 0.15277799768830058,
      "grad_norm": 0.016285503283143044,
      "learning_rate": 8.472220023116994e-06,
      "loss": 0.0008,
      "step": 9649
    },
    {
      "epoch": 0.15279383124594265,
      "grad_norm": 0.3474585711956024,
      "learning_rate": 8.472061687540573e-06,
      "loss": 0.0428,
      "step": 9650
    },
    {
      "epoch": 0.1528096648035847,
      "grad_norm": 0.2144274115562439,
      "learning_rate": 8.471903351964154e-06,
      "loss": 0.101,
      "step": 9651
    },
    {
      "epoch": 0.15282549836122677,
      "grad_norm": 0.0025238445959985256,
      "learning_rate": 8.471745016387733e-06,
      "loss": 0.0001,
      "step": 9652
    },
    {
      "epoch": 0.15284133191886884,
      "grad_norm": 0.3152289092540741,
      "learning_rate": 8.471586680811312e-06,
      "loss": 0.0397,
      "step": 9653
    },
    {
      "epoch": 0.15285716547651093,
      "grad_norm": 0.42487210035324097,
      "learning_rate": 8.471428345234891e-06,
      "loss": 0.0744,
      "step": 9654
    },
    {
      "epoch": 0.152872999034153,
      "grad_norm": 0.3365195095539093,
      "learning_rate": 8.47127000965847e-06,
      "loss": 0.0324,
      "step": 9655
    },
    {
      "epoch": 0.15288883259179506,
      "grad_norm": 0.46278005838394165,
      "learning_rate": 8.47111167408205e-06,
      "loss": 0.438,
      "step": 9656
    },
    {
      "epoch": 0.15290466614943712,
      "grad_norm": 0.1833161860704422,
      "learning_rate": 8.47095333850563e-06,
      "loss": 0.0635,
      "step": 9657
    },
    {
      "epoch": 0.1529204997070792,
      "grad_norm": 0.658686637878418,
      "learning_rate": 8.47079500292921e-06,
      "loss": 0.074,
      "step": 9658
    },
    {
      "epoch": 0.15293633326472125,
      "grad_norm": 0.13013319671154022,
      "learning_rate": 8.470636667352788e-06,
      "loss": 0.0415,
      "step": 9659
    },
    {
      "epoch": 0.15295216682236332,
      "grad_norm": 0.1458083540201187,
      "learning_rate": 8.470478331776367e-06,
      "loss": 0.0404,
      "step": 9660
    },
    {
      "epoch": 0.15296800038000538,
      "grad_norm": 0.00025341511354781687,
      "learning_rate": 8.470319996199947e-06,
      "loss": 0.0,
      "step": 9661
    },
    {
      "epoch": 0.15298383393764745,
      "grad_norm": 0.0004988922155462205,
      "learning_rate": 8.470161660623526e-06,
      "loss": 0.0,
      "step": 9662
    },
    {
      "epoch": 0.1529996674952895,
      "grad_norm": 0.6963195204734802,
      "learning_rate": 8.470003325047106e-06,
      "loss": 0.5635,
      "step": 9663
    },
    {
      "epoch": 0.15301550105293157,
      "grad_norm": 0.36135709285736084,
      "learning_rate": 8.469844989470685e-06,
      "loss": 0.076,
      "step": 9664
    },
    {
      "epoch": 0.15303133461057364,
      "grad_norm": 0.27629122138023376,
      "learning_rate": 8.469686653894265e-06,
      "loss": 0.0538,
      "step": 9665
    },
    {
      "epoch": 0.1530471681682157,
      "grad_norm": 0.16766208410263062,
      "learning_rate": 8.469528318317844e-06,
      "loss": 0.0974,
      "step": 9666
    },
    {
      "epoch": 0.1530630017258578,
      "grad_norm": 0.05121355503797531,
      "learning_rate": 8.469369982741423e-06,
      "loss": 0.0022,
      "step": 9667
    },
    {
      "epoch": 0.15307883528349986,
      "grad_norm": 0.05476577579975128,
      "learning_rate": 8.469211647165002e-06,
      "loss": 0.0026,
      "step": 9668
    },
    {
      "epoch": 0.15309466884114192,
      "grad_norm": 0.15604491531848907,
      "learning_rate": 8.469053311588583e-06,
      "loss": 0.0586,
      "step": 9669
    },
    {
      "epoch": 0.153110502398784,
      "grad_norm": 0.12713703513145447,
      "learning_rate": 8.468894976012162e-06,
      "loss": 0.0445,
      "step": 9670
    },
    {
      "epoch": 0.15312633595642605,
      "grad_norm": 0.00015835583326406777,
      "learning_rate": 8.46873664043574e-06,
      "loss": 0.0,
      "step": 9671
    },
    {
      "epoch": 0.15314216951406812,
      "grad_norm": 0.4327852129936218,
      "learning_rate": 8.46857830485932e-06,
      "loss": 0.1124,
      "step": 9672
    },
    {
      "epoch": 0.15315800307171018,
      "grad_norm": 0.00045390755985863507,
      "learning_rate": 8.468419969282899e-06,
      "loss": 0.0,
      "step": 9673
    },
    {
      "epoch": 0.15317383662935224,
      "grad_norm": 0.42529061436653137,
      "learning_rate": 8.468261633706478e-06,
      "loss": 0.2687,
      "step": 9674
    },
    {
      "epoch": 0.1531896701869943,
      "grad_norm": 0.5261991024017334,
      "learning_rate": 8.468103298130057e-06,
      "loss": 0.8845,
      "step": 9675
    },
    {
      "epoch": 0.15320550374463637,
      "grad_norm": 0.012903044000267982,
      "learning_rate": 8.467944962553638e-06,
      "loss": 0.0006,
      "step": 9676
    },
    {
      "epoch": 0.15322133730227844,
      "grad_norm": 0.3324134051799774,
      "learning_rate": 8.467786626977215e-06,
      "loss": 0.1563,
      "step": 9677
    },
    {
      "epoch": 0.1532371708599205,
      "grad_norm": 0.45775339007377625,
      "learning_rate": 8.467628291400796e-06,
      "loss": 0.083,
      "step": 9678
    },
    {
      "epoch": 0.1532530044175626,
      "grad_norm": 0.46898147463798523,
      "learning_rate": 8.467469955824375e-06,
      "loss": 0.4952,
      "step": 9679
    },
    {
      "epoch": 0.15326883797520466,
      "grad_norm": 0.0008610107470303774,
      "learning_rate": 8.467311620247954e-06,
      "loss": 0.0,
      "step": 9680
    },
    {
      "epoch": 0.15328467153284672,
      "grad_norm": 0.15081146359443665,
      "learning_rate": 8.467153284671533e-06,
      "loss": 0.0392,
      "step": 9681
    },
    {
      "epoch": 0.1533005050904888,
      "grad_norm": 0.3564354479312897,
      "learning_rate": 8.466994949095112e-06,
      "loss": 0.1151,
      "step": 9682
    },
    {
      "epoch": 0.15331633864813085,
      "grad_norm": 0.1065881997346878,
      "learning_rate": 8.466836613518691e-06,
      "loss": 0.0332,
      "step": 9683
    },
    {
      "epoch": 0.15333217220577292,
      "grad_norm": 0.39315497875213623,
      "learning_rate": 8.466678277942272e-06,
      "loss": 0.0212,
      "step": 9684
    },
    {
      "epoch": 0.15334800576341498,
      "grad_norm": 0.5962719321250916,
      "learning_rate": 8.466519942365851e-06,
      "loss": 0.2499,
      "step": 9685
    },
    {
      "epoch": 0.15336383932105704,
      "grad_norm": 0.21688660979270935,
      "learning_rate": 8.46636160678943e-06,
      "loss": 0.0427,
      "step": 9686
    },
    {
      "epoch": 0.1533796728786991,
      "grad_norm": 0.24952258169651031,
      "learning_rate": 8.46620327121301e-06,
      "loss": 0.1581,
      "step": 9687
    },
    {
      "epoch": 0.15339550643634117,
      "grad_norm": 0.46951693296432495,
      "learning_rate": 8.466044935636588e-06,
      "loss": 0.1105,
      "step": 9688
    },
    {
      "epoch": 0.15341133999398324,
      "grad_norm": 0.2601688802242279,
      "learning_rate": 8.465886600060168e-06,
      "loss": 0.0638,
      "step": 9689
    },
    {
      "epoch": 0.1534271735516253,
      "grad_norm": 0.15318945050239563,
      "learning_rate": 8.465728264483748e-06,
      "loss": 0.0296,
      "step": 9690
    },
    {
      "epoch": 0.1534430071092674,
      "grad_norm": 0.7613785862922668,
      "learning_rate": 8.465569928907327e-06,
      "loss": 0.0898,
      "step": 9691
    },
    {
      "epoch": 0.15345884066690946,
      "grad_norm": 0.1993861198425293,
      "learning_rate": 8.465411593330906e-06,
      "loss": 0.0701,
      "step": 9692
    },
    {
      "epoch": 0.15347467422455152,
      "grad_norm": 0.00017691391985863447,
      "learning_rate": 8.465253257754486e-06,
      "loss": 0.0,
      "step": 9693
    },
    {
      "epoch": 0.15349050778219359,
      "grad_norm": 0.017609769478440285,
      "learning_rate": 8.465094922178065e-06,
      "loss": 0.0014,
      "step": 9694
    },
    {
      "epoch": 0.15350634133983565,
      "grad_norm": 0.34271737933158875,
      "learning_rate": 8.464936586601644e-06,
      "loss": 0.2491,
      "step": 9695
    },
    {
      "epoch": 0.15352217489747771,
      "grad_norm": 0.12431448698043823,
      "learning_rate": 8.464778251025224e-06,
      "loss": 0.0255,
      "step": 9696
    },
    {
      "epoch": 0.15353800845511978,
      "grad_norm": 0.15591517090797424,
      "learning_rate": 8.464619915448804e-06,
      "loss": 0.0604,
      "step": 9697
    },
    {
      "epoch": 0.15355384201276184,
      "grad_norm": 0.3850872218608856,
      "learning_rate": 8.464461579872381e-06,
      "loss": 0.1018,
      "step": 9698
    },
    {
      "epoch": 0.1535696755704039,
      "grad_norm": 0.11520593613386154,
      "learning_rate": 8.464303244295962e-06,
      "loss": 0.0548,
      "step": 9699
    },
    {
      "epoch": 0.15358550912804597,
      "grad_norm": 0.9805887341499329,
      "learning_rate": 8.46414490871954e-06,
      "loss": 0.2116,
      "step": 9700
    },
    {
      "epoch": 0.15360134268568804,
      "grad_norm": 0.21133491396903992,
      "learning_rate": 8.46398657314312e-06,
      "loss": 0.0547,
      "step": 9701
    },
    {
      "epoch": 0.1536171762433301,
      "grad_norm": 0.012397261336445808,
      "learning_rate": 8.463828237566699e-06,
      "loss": 0.0007,
      "step": 9702
    },
    {
      "epoch": 0.1536330098009722,
      "grad_norm": 0.5713045001029968,
      "learning_rate": 8.46366990199028e-06,
      "loss": 0.1504,
      "step": 9703
    },
    {
      "epoch": 0.15364884335861426,
      "grad_norm": 0.14912883937358856,
      "learning_rate": 8.463511566413857e-06,
      "loss": 0.0782,
      "step": 9704
    },
    {
      "epoch": 0.15366467691625632,
      "grad_norm": 0.7074523568153381,
      "learning_rate": 8.463353230837438e-06,
      "loss": 0.3487,
      "step": 9705
    },
    {
      "epoch": 0.15368051047389839,
      "grad_norm": 0.008241981267929077,
      "learning_rate": 8.463194895261017e-06,
      "loss": 0.0005,
      "step": 9706
    },
    {
      "epoch": 0.15369634403154045,
      "grad_norm": 0.43789950013160706,
      "learning_rate": 8.463036559684596e-06,
      "loss": 0.0959,
      "step": 9707
    },
    {
      "epoch": 0.1537121775891825,
      "grad_norm": 0.017687011510133743,
      "learning_rate": 8.462878224108175e-06,
      "loss": 0.001,
      "step": 9708
    },
    {
      "epoch": 0.15372801114682458,
      "grad_norm": 0.011184281669557095,
      "learning_rate": 8.462719888531756e-06,
      "loss": 0.0006,
      "step": 9709
    },
    {
      "epoch": 0.15374384470446664,
      "grad_norm": 0.8175572752952576,
      "learning_rate": 8.462561552955333e-06,
      "loss": 0.5108,
      "step": 9710
    },
    {
      "epoch": 0.1537596782621087,
      "grad_norm": 0.012594816274940968,
      "learning_rate": 8.462403217378914e-06,
      "loss": 0.0009,
      "step": 9711
    },
    {
      "epoch": 0.15377551181975077,
      "grad_norm": 0.508488655090332,
      "learning_rate": 8.462244881802493e-06,
      "loss": 0.8442,
      "step": 9712
    },
    {
      "epoch": 0.15379134537739284,
      "grad_norm": 0.3013730049133301,
      "learning_rate": 8.462086546226072e-06,
      "loss": 0.1467,
      "step": 9713
    },
    {
      "epoch": 0.1538071789350349,
      "grad_norm": 0.496573269367218,
      "learning_rate": 8.461928210649651e-06,
      "loss": 0.2002,
      "step": 9714
    },
    {
      "epoch": 0.153823012492677,
      "grad_norm": 0.014215131290256977,
      "learning_rate": 8.461769875073232e-06,
      "loss": 0.0014,
      "step": 9715
    },
    {
      "epoch": 0.15383884605031906,
      "grad_norm": 0.34953635931015015,
      "learning_rate": 8.46161153949681e-06,
      "loss": 0.2572,
      "step": 9716
    },
    {
      "epoch": 0.15385467960796112,
      "grad_norm": 0.34480488300323486,
      "learning_rate": 8.46145320392039e-06,
      "loss": 0.344,
      "step": 9717
    },
    {
      "epoch": 0.15387051316560318,
      "grad_norm": 0.6443595886230469,
      "learning_rate": 8.46129486834397e-06,
      "loss": 0.2796,
      "step": 9718
    },
    {
      "epoch": 0.15388634672324525,
      "grad_norm": 0.4201720356941223,
      "learning_rate": 8.461136532767548e-06,
      "loss": 0.1157,
      "step": 9719
    },
    {
      "epoch": 0.1539021802808873,
      "grad_norm": 0.8176178932189941,
      "learning_rate": 8.460978197191127e-06,
      "loss": 0.3289,
      "step": 9720
    },
    {
      "epoch": 0.15391801383852938,
      "grad_norm": 0.5465248823165894,
      "learning_rate": 8.460819861614707e-06,
      "loss": 0.4613,
      "step": 9721
    },
    {
      "epoch": 0.15393384739617144,
      "grad_norm": 0.0386819913983345,
      "learning_rate": 8.460661526038286e-06,
      "loss": 0.0026,
      "step": 9722
    },
    {
      "epoch": 0.1539496809538135,
      "grad_norm": 0.1815599799156189,
      "learning_rate": 8.460503190461865e-06,
      "loss": 0.0069,
      "step": 9723
    },
    {
      "epoch": 0.15396551451145557,
      "grad_norm": 0.03217129409313202,
      "learning_rate": 8.460344854885445e-06,
      "loss": 0.0021,
      "step": 9724
    },
    {
      "epoch": 0.15398134806909763,
      "grad_norm": 0.000521624693647027,
      "learning_rate": 8.460186519309025e-06,
      "loss": 0.0,
      "step": 9725
    },
    {
      "epoch": 0.1539971816267397,
      "grad_norm": 1.3452839851379395,
      "learning_rate": 8.460028183732604e-06,
      "loss": 0.2253,
      "step": 9726
    },
    {
      "epoch": 0.1540130151843818,
      "grad_norm": 0.33766573667526245,
      "learning_rate": 8.459869848156183e-06,
      "loss": 0.2588,
      "step": 9727
    },
    {
      "epoch": 0.15402884874202386,
      "grad_norm": 0.30615952610969543,
      "learning_rate": 8.459711512579762e-06,
      "loss": 0.1505,
      "step": 9728
    },
    {
      "epoch": 0.15404468229966592,
      "grad_norm": 0.5030099749565125,
      "learning_rate": 8.459553177003341e-06,
      "loss": 0.8651,
      "step": 9729
    },
    {
      "epoch": 0.15406051585730798,
      "grad_norm": 0.3450224697589874,
      "learning_rate": 8.459394841426922e-06,
      "loss": 0.1393,
      "step": 9730
    },
    {
      "epoch": 0.15407634941495005,
      "grad_norm": 0.24391640722751617,
      "learning_rate": 8.4592365058505e-06,
      "loss": 0.1367,
      "step": 9731
    },
    {
      "epoch": 0.1540921829725921,
      "grad_norm": 0.3306795358657837,
      "learning_rate": 8.45907817027408e-06,
      "loss": 0.1703,
      "step": 9732
    },
    {
      "epoch": 0.15410801653023418,
      "grad_norm": 0.0095926932990551,
      "learning_rate": 8.458919834697659e-06,
      "loss": 0.0006,
      "step": 9733
    },
    {
      "epoch": 0.15412385008787624,
      "grad_norm": 0.475481241941452,
      "learning_rate": 8.458761499121238e-06,
      "loss": 0.7036,
      "step": 9734
    },
    {
      "epoch": 0.1541396836455183,
      "grad_norm": 0.35031014680862427,
      "learning_rate": 8.458603163544817e-06,
      "loss": 0.0962,
      "step": 9735
    },
    {
      "epoch": 0.15415551720316037,
      "grad_norm": 0.37793079018592834,
      "learning_rate": 8.458444827968398e-06,
      "loss": 0.2831,
      "step": 9736
    },
    {
      "epoch": 0.15417135076080243,
      "grad_norm": 0.02366246096789837,
      "learning_rate": 8.458286492391977e-06,
      "loss": 0.0013,
      "step": 9737
    },
    {
      "epoch": 0.1541871843184445,
      "grad_norm": 0.607745349407196,
      "learning_rate": 8.458128156815556e-06,
      "loss": 0.206,
      "step": 9738
    },
    {
      "epoch": 0.1542030178760866,
      "grad_norm": 0.5446941256523132,
      "learning_rate": 8.457969821239135e-06,
      "loss": 0.3376,
      "step": 9739
    },
    {
      "epoch": 0.15421885143372865,
      "grad_norm": 0.3815706968307495,
      "learning_rate": 8.457811485662714e-06,
      "loss": 0.1109,
      "step": 9740
    },
    {
      "epoch": 0.15423468499137072,
      "grad_norm": 0.2816147208213806,
      "learning_rate": 8.457653150086293e-06,
      "loss": 0.1563,
      "step": 9741
    },
    {
      "epoch": 0.15425051854901278,
      "grad_norm": 0.6370174288749695,
      "learning_rate": 8.457494814509874e-06,
      "loss": 0.8865,
      "step": 9742
    },
    {
      "epoch": 0.15426635210665485,
      "grad_norm": 0.39696016907691956,
      "learning_rate": 8.457336478933453e-06,
      "loss": 0.2841,
      "step": 9743
    },
    {
      "epoch": 0.1542821856642969,
      "grad_norm": 0.0014377464540302753,
      "learning_rate": 8.457178143357032e-06,
      "loss": 0.0,
      "step": 9744
    },
    {
      "epoch": 0.15429801922193898,
      "grad_norm": 0.32926762104034424,
      "learning_rate": 8.457019807780611e-06,
      "loss": 0.1663,
      "step": 9745
    },
    {
      "epoch": 0.15431385277958104,
      "grad_norm": 0.23693950474262238,
      "learning_rate": 8.45686147220419e-06,
      "loss": 0.1071,
      "step": 9746
    },
    {
      "epoch": 0.1543296863372231,
      "grad_norm": 0.4425146281719208,
      "learning_rate": 8.45670313662777e-06,
      "loss": 0.0862,
      "step": 9747
    },
    {
      "epoch": 0.15434551989486517,
      "grad_norm": 0.0005763611407019198,
      "learning_rate": 8.456544801051348e-06,
      "loss": 0.0,
      "step": 9748
    },
    {
      "epoch": 0.15436135345250723,
      "grad_norm": 0.4524645209312439,
      "learning_rate": 8.456386465474928e-06,
      "loss": 0.4035,
      "step": 9749
    },
    {
      "epoch": 0.1543771870101493,
      "grad_norm": 0.3907000720500946,
      "learning_rate": 8.456228129898507e-06,
      "loss": 0.1496,
      "step": 9750
    },
    {
      "epoch": 0.1543930205677914,
      "grad_norm": 0.3858616054058075,
      "learning_rate": 8.456069794322087e-06,
      "loss": 0.0972,
      "step": 9751
    },
    {
      "epoch": 0.15440885412543345,
      "grad_norm": 0.35759034752845764,
      "learning_rate": 8.455911458745666e-06,
      "loss": 0.2027,
      "step": 9752
    },
    {
      "epoch": 0.15442468768307552,
      "grad_norm": 0.002649590838700533,
      "learning_rate": 8.455753123169246e-06,
      "loss": 0.0001,
      "step": 9753
    },
    {
      "epoch": 0.15444052124071758,
      "grad_norm": 0.7740461230278015,
      "learning_rate": 8.455594787592825e-06,
      "loss": 0.5578,
      "step": 9754
    },
    {
      "epoch": 0.15445635479835965,
      "grad_norm": 0.4727817475795746,
      "learning_rate": 8.455436452016404e-06,
      "loss": 0.1531,
      "step": 9755
    },
    {
      "epoch": 0.1544721883560017,
      "grad_norm": 0.433728963136673,
      "learning_rate": 8.455278116439983e-06,
      "loss": 0.5651,
      "step": 9756
    },
    {
      "epoch": 0.15448802191364377,
      "grad_norm": 0.3321579098701477,
      "learning_rate": 8.455119780863564e-06,
      "loss": 0.0903,
      "step": 9757
    },
    {
      "epoch": 0.15450385547128584,
      "grad_norm": 0.5781434178352356,
      "learning_rate": 8.454961445287143e-06,
      "loss": 0.0137,
      "step": 9758
    },
    {
      "epoch": 0.1545196890289279,
      "grad_norm": 0.11784680932760239,
      "learning_rate": 8.454803109710722e-06,
      "loss": 0.0067,
      "step": 9759
    },
    {
      "epoch": 0.15453552258656997,
      "grad_norm": 0.1327228546142578,
      "learning_rate": 8.4546447741343e-06,
      "loss": 0.0515,
      "step": 9760
    },
    {
      "epoch": 0.15455135614421203,
      "grad_norm": 0.0016550063155591488,
      "learning_rate": 8.45448643855788e-06,
      "loss": 0.0,
      "step": 9761
    },
    {
      "epoch": 0.1545671897018541,
      "grad_norm": 0.22198697924613953,
      "learning_rate": 8.454328102981459e-06,
      "loss": 0.0701,
      "step": 9762
    },
    {
      "epoch": 0.1545830232594962,
      "grad_norm": 0.4115927517414093,
      "learning_rate": 8.45416976740504e-06,
      "loss": 0.1547,
      "step": 9763
    },
    {
      "epoch": 0.15459885681713825,
      "grad_norm": 0.25173959136009216,
      "learning_rate": 8.454011431828619e-06,
      "loss": 0.1234,
      "step": 9764
    },
    {
      "epoch": 0.15461469037478032,
      "grad_norm": 0.8176897764205933,
      "learning_rate": 8.453853096252198e-06,
      "loss": 0.1695,
      "step": 9765
    },
    {
      "epoch": 0.15463052393242238,
      "grad_norm": 0.3639891445636749,
      "learning_rate": 8.453694760675777e-06,
      "loss": 0.0848,
      "step": 9766
    },
    {
      "epoch": 0.15464635749006445,
      "grad_norm": 0.3024521768093109,
      "learning_rate": 8.453536425099356e-06,
      "loss": 0.1594,
      "step": 9767
    },
    {
      "epoch": 0.1546621910477065,
      "grad_norm": 0.2349650263786316,
      "learning_rate": 8.453378089522935e-06,
      "loss": 0.0274,
      "step": 9768
    },
    {
      "epoch": 0.15467802460534857,
      "grad_norm": 0.021028656512498856,
      "learning_rate": 8.453219753946514e-06,
      "loss": 0.0011,
      "step": 9769
    },
    {
      "epoch": 0.15469385816299064,
      "grad_norm": 0.014656934887170792,
      "learning_rate": 8.453061418370095e-06,
      "loss": 0.0004,
      "step": 9770
    },
    {
      "epoch": 0.1547096917206327,
      "grad_norm": 0.21238219738006592,
      "learning_rate": 8.452903082793672e-06,
      "loss": 0.0602,
      "step": 9771
    },
    {
      "epoch": 0.15472552527827477,
      "grad_norm": 0.4090563654899597,
      "learning_rate": 8.452744747217253e-06,
      "loss": 0.1355,
      "step": 9772
    },
    {
      "epoch": 0.15474135883591683,
      "grad_norm": 0.0006550585967488587,
      "learning_rate": 8.452586411640832e-06,
      "loss": 0.0,
      "step": 9773
    },
    {
      "epoch": 0.1547571923935589,
      "grad_norm": 0.2409363090991974,
      "learning_rate": 8.452428076064411e-06,
      "loss": 0.0835,
      "step": 9774
    },
    {
      "epoch": 0.154773025951201,
      "grad_norm": 1.1476976871490479,
      "learning_rate": 8.45226974048799e-06,
      "loss": 0.0854,
      "step": 9775
    },
    {
      "epoch": 0.15478885950884305,
      "grad_norm": 0.3895599842071533,
      "learning_rate": 8.452111404911571e-06,
      "loss": 0.2762,
      "step": 9776
    },
    {
      "epoch": 0.15480469306648512,
      "grad_norm": 0.024380462244153023,
      "learning_rate": 8.451953069335149e-06,
      "loss": 0.0011,
      "step": 9777
    },
    {
      "epoch": 0.15482052662412718,
      "grad_norm": 0.49871551990509033,
      "learning_rate": 8.45179473375873e-06,
      "loss": 0.4355,
      "step": 9778
    },
    {
      "epoch": 0.15483636018176924,
      "grad_norm": 0.0029128058813512325,
      "learning_rate": 8.451636398182308e-06,
      "loss": 0.0001,
      "step": 9779
    },
    {
      "epoch": 0.1548521937394113,
      "grad_norm": 0.8378847241401672,
      "learning_rate": 8.451478062605887e-06,
      "loss": 0.2734,
      "step": 9780
    },
    {
      "epoch": 0.15486802729705337,
      "grad_norm": 0.3400830626487732,
      "learning_rate": 8.451319727029467e-06,
      "loss": 0.1283,
      "step": 9781
    },
    {
      "epoch": 0.15488386085469544,
      "grad_norm": 0.16732476651668549,
      "learning_rate": 8.451161391453047e-06,
      "loss": 0.0057,
      "step": 9782
    },
    {
      "epoch": 0.1548996944123375,
      "grad_norm": 0.1449066400527954,
      "learning_rate": 8.451003055876625e-06,
      "loss": 0.0648,
      "step": 9783
    },
    {
      "epoch": 0.15491552796997957,
      "grad_norm": 0.23244605958461761,
      "learning_rate": 8.450844720300205e-06,
      "loss": 0.18,
      "step": 9784
    },
    {
      "epoch": 0.15493136152762163,
      "grad_norm": 0.8544503450393677,
      "learning_rate": 8.450686384723785e-06,
      "loss": 0.8968,
      "step": 9785
    },
    {
      "epoch": 0.1549471950852637,
      "grad_norm": 0.2418254017829895,
      "learning_rate": 8.450528049147364e-06,
      "loss": 0.0252,
      "step": 9786
    },
    {
      "epoch": 0.1549630286429058,
      "grad_norm": 0.21105501055717468,
      "learning_rate": 8.450369713570943e-06,
      "loss": 0.062,
      "step": 9787
    },
    {
      "epoch": 0.15497886220054785,
      "grad_norm": 0.0011783139780163765,
      "learning_rate": 8.450211377994523e-06,
      "loss": 0.0,
      "step": 9788
    },
    {
      "epoch": 0.15499469575818992,
      "grad_norm": 0.43516743183135986,
      "learning_rate": 8.450053042418101e-06,
      "loss": 0.0332,
      "step": 9789
    },
    {
      "epoch": 0.15501052931583198,
      "grad_norm": 0.35769233107566833,
      "learning_rate": 8.449894706841682e-06,
      "loss": 0.0089,
      "step": 9790
    },
    {
      "epoch": 0.15502636287347404,
      "grad_norm": 0.37594813108444214,
      "learning_rate": 8.44973637126526e-06,
      "loss": 0.1256,
      "step": 9791
    },
    {
      "epoch": 0.1550421964311161,
      "grad_norm": 0.27309271693229675,
      "learning_rate": 8.44957803568884e-06,
      "loss": 0.1787,
      "step": 9792
    },
    {
      "epoch": 0.15505802998875817,
      "grad_norm": 0.18522320687770844,
      "learning_rate": 8.449419700112419e-06,
      "loss": 0.0674,
      "step": 9793
    },
    {
      "epoch": 0.15507386354640024,
      "grad_norm": 0.3456309735774994,
      "learning_rate": 8.449261364535998e-06,
      "loss": 0.0712,
      "step": 9794
    },
    {
      "epoch": 0.1550896971040423,
      "grad_norm": 0.046394772827625275,
      "learning_rate": 8.449103028959577e-06,
      "loss": 0.0031,
      "step": 9795
    },
    {
      "epoch": 0.15510553066168437,
      "grad_norm": 0.9425063729286194,
      "learning_rate": 8.448944693383156e-06,
      "loss": 0.1314,
      "step": 9796
    },
    {
      "epoch": 0.15512136421932643,
      "grad_norm": 0.0008093225187622011,
      "learning_rate": 8.448786357806737e-06,
      "loss": 0.0,
      "step": 9797
    },
    {
      "epoch": 0.1551371977769685,
      "grad_norm": 0.18233272433280945,
      "learning_rate": 8.448628022230316e-06,
      "loss": 0.0671,
      "step": 9798
    },
    {
      "epoch": 0.15515303133461059,
      "grad_norm": 0.012342757545411587,
      "learning_rate": 8.448469686653895e-06,
      "loss": 0.0007,
      "step": 9799
    },
    {
      "epoch": 0.15516886489225265,
      "grad_norm": 0.0008760430500842631,
      "learning_rate": 8.448311351077474e-06,
      "loss": 0.0,
      "step": 9800
    },
    {
      "epoch": 0.15518469844989471,
      "grad_norm": 0.10836564004421234,
      "learning_rate": 8.448153015501053e-06,
      "loss": 0.0041,
      "step": 9801
    },
    {
      "epoch": 0.15520053200753678,
      "grad_norm": 0.175336092710495,
      "learning_rate": 8.447994679924632e-06,
      "loss": 0.0517,
      "step": 9802
    },
    {
      "epoch": 0.15521636556517884,
      "grad_norm": 0.0034597860649228096,
      "learning_rate": 8.447836344348213e-06,
      "loss": 0.0001,
      "step": 9803
    },
    {
      "epoch": 0.1552321991228209,
      "grad_norm": 0.27750977873802185,
      "learning_rate": 8.447678008771792e-06,
      "loss": 0.0248,
      "step": 9804
    },
    {
      "epoch": 0.15524803268046297,
      "grad_norm": 0.0019438249291852117,
      "learning_rate": 8.447519673195371e-06,
      "loss": 0.0,
      "step": 9805
    },
    {
      "epoch": 0.15526386623810504,
      "grad_norm": 0.25363627076148987,
      "learning_rate": 8.44736133761895e-06,
      "loss": 0.1139,
      "step": 9806
    },
    {
      "epoch": 0.1552796997957471,
      "grad_norm": 0.014044192619621754,
      "learning_rate": 8.44720300204253e-06,
      "loss": 0.0007,
      "step": 9807
    },
    {
      "epoch": 0.15529553335338916,
      "grad_norm": 0.10616223514080048,
      "learning_rate": 8.447044666466108e-06,
      "loss": 0.0183,
      "step": 9808
    },
    {
      "epoch": 0.15531136691103123,
      "grad_norm": 0.017949245870113373,
      "learning_rate": 8.44688633088969e-06,
      "loss": 0.001,
      "step": 9809
    },
    {
      "epoch": 0.1553272004686733,
      "grad_norm": 0.3295343518257141,
      "learning_rate": 8.446727995313268e-06,
      "loss": 0.1884,
      "step": 9810
    },
    {
      "epoch": 0.15534303402631539,
      "grad_norm": 0.4615184962749481,
      "learning_rate": 8.446569659736847e-06,
      "loss": 0.188,
      "step": 9811
    },
    {
      "epoch": 0.15535886758395745,
      "grad_norm": 0.3681599795818329,
      "learning_rate": 8.446411324160426e-06,
      "loss": 0.2575,
      "step": 9812
    },
    {
      "epoch": 0.1553747011415995,
      "grad_norm": 0.5784664154052734,
      "learning_rate": 8.446252988584006e-06,
      "loss": 0.7328,
      "step": 9813
    },
    {
      "epoch": 0.15539053469924158,
      "grad_norm": 0.26603469252586365,
      "learning_rate": 8.446094653007585e-06,
      "loss": 0.0614,
      "step": 9814
    },
    {
      "epoch": 0.15540636825688364,
      "grad_norm": 0.5437546968460083,
      "learning_rate": 8.445936317431165e-06,
      "loss": 0.2159,
      "step": 9815
    },
    {
      "epoch": 0.1554222018145257,
      "grad_norm": 0.4280186593532562,
      "learning_rate": 8.445777981854743e-06,
      "loss": 0.3316,
      "step": 9816
    },
    {
      "epoch": 0.15543803537216777,
      "grad_norm": 0.6877373456954956,
      "learning_rate": 8.445619646278322e-06,
      "loss": 0.7389,
      "step": 9817
    },
    {
      "epoch": 0.15545386892980984,
      "grad_norm": 0.2495090365409851,
      "learning_rate": 8.445461310701903e-06,
      "loss": 0.2096,
      "step": 9818
    },
    {
      "epoch": 0.1554697024874519,
      "grad_norm": 0.3602297306060791,
      "learning_rate": 8.445302975125482e-06,
      "loss": 0.0066,
      "step": 9819
    },
    {
      "epoch": 0.15548553604509396,
      "grad_norm": 0.22476452589035034,
      "learning_rate": 8.44514463954906e-06,
      "loss": 0.0379,
      "step": 9820
    },
    {
      "epoch": 0.15550136960273603,
      "grad_norm": 0.2376774549484253,
      "learning_rate": 8.44498630397264e-06,
      "loss": 0.008,
      "step": 9821
    },
    {
      "epoch": 0.1555172031603781,
      "grad_norm": 0.15423214435577393,
      "learning_rate": 8.444827968396219e-06,
      "loss": 0.054,
      "step": 9822
    },
    {
      "epoch": 0.15553303671802018,
      "grad_norm": 0.29851797223091125,
      "learning_rate": 8.444669632819798e-06,
      "loss": 0.1927,
      "step": 9823
    },
    {
      "epoch": 0.15554887027566225,
      "grad_norm": 0.4919227361679077,
      "learning_rate": 8.444511297243379e-06,
      "loss": 0.0795,
      "step": 9824
    },
    {
      "epoch": 0.1555647038333043,
      "grad_norm": 0.2926434278488159,
      "learning_rate": 8.444352961666958e-06,
      "loss": 0.0722,
      "step": 9825
    },
    {
      "epoch": 0.15558053739094638,
      "grad_norm": 0.0010615438222885132,
      "learning_rate": 8.444194626090537e-06,
      "loss": 0.0,
      "step": 9826
    },
    {
      "epoch": 0.15559637094858844,
      "grad_norm": 0.4502362608909607,
      "learning_rate": 8.444036290514116e-06,
      "loss": 0.4609,
      "step": 9827
    },
    {
      "epoch": 0.1556122045062305,
      "grad_norm": 0.000465723016532138,
      "learning_rate": 8.443877954937695e-06,
      "loss": 0.0,
      "step": 9828
    },
    {
      "epoch": 0.15562803806387257,
      "grad_norm": 0.00043258050573058426,
      "learning_rate": 8.443719619361274e-06,
      "loss": 0.0,
      "step": 9829
    },
    {
      "epoch": 0.15564387162151463,
      "grad_norm": 0.013686049729585648,
      "learning_rate": 8.443561283784855e-06,
      "loss": 0.0007,
      "step": 9830
    },
    {
      "epoch": 0.1556597051791567,
      "grad_norm": 0.40252065658569336,
      "learning_rate": 8.443402948208434e-06,
      "loss": 0.2758,
      "step": 9831
    },
    {
      "epoch": 0.15567553873679876,
      "grad_norm": 0.38819360733032227,
      "learning_rate": 8.443244612632013e-06,
      "loss": 0.0817,
      "step": 9832
    },
    {
      "epoch": 0.15569137229444083,
      "grad_norm": 0.4159333109855652,
      "learning_rate": 8.443086277055592e-06,
      "loss": 0.1293,
      "step": 9833
    },
    {
      "epoch": 0.1557072058520829,
      "grad_norm": 0.3099590837955475,
      "learning_rate": 8.442927941479171e-06,
      "loss": 0.1786,
      "step": 9834
    },
    {
      "epoch": 0.15572303940972498,
      "grad_norm": 0.01833336614072323,
      "learning_rate": 8.44276960590275e-06,
      "loss": 0.0011,
      "step": 9835
    },
    {
      "epoch": 0.15573887296736705,
      "grad_norm": 0.006390003487467766,
      "learning_rate": 8.442611270326331e-06,
      "loss": 0.0004,
      "step": 9836
    },
    {
      "epoch": 0.1557547065250091,
      "grad_norm": 0.27589619159698486,
      "learning_rate": 8.44245293474991e-06,
      "loss": 0.1472,
      "step": 9837
    },
    {
      "epoch": 0.15577054008265118,
      "grad_norm": 0.6083425879478455,
      "learning_rate": 8.44229459917349e-06,
      "loss": 0.1174,
      "step": 9838
    },
    {
      "epoch": 0.15578637364029324,
      "grad_norm": 0.2534751892089844,
      "learning_rate": 8.442136263597068e-06,
      "loss": 0.047,
      "step": 9839
    },
    {
      "epoch": 0.1558022071979353,
      "grad_norm": 0.2385634332895279,
      "learning_rate": 8.441977928020647e-06,
      "loss": 0.0579,
      "step": 9840
    },
    {
      "epoch": 0.15581804075557737,
      "grad_norm": 0.07805988192558289,
      "learning_rate": 8.441819592444227e-06,
      "loss": 0.003,
      "step": 9841
    },
    {
      "epoch": 0.15583387431321943,
      "grad_norm": 0.06857676059007645,
      "learning_rate": 8.441661256867806e-06,
      "loss": 0.0049,
      "step": 9842
    },
    {
      "epoch": 0.1558497078708615,
      "grad_norm": 0.04162859544157982,
      "learning_rate": 8.441502921291386e-06,
      "loss": 0.0019,
      "step": 9843
    },
    {
      "epoch": 0.15586554142850356,
      "grad_norm": 0.37919801473617554,
      "learning_rate": 8.441344585714964e-06,
      "loss": 0.0637,
      "step": 9844
    },
    {
      "epoch": 0.15588137498614563,
      "grad_norm": 0.5341718196868896,
      "learning_rate": 8.441186250138545e-06,
      "loss": 0.0561,
      "step": 9845
    },
    {
      "epoch": 0.1558972085437877,
      "grad_norm": 0.014738818630576134,
      "learning_rate": 8.441027914562124e-06,
      "loss": 0.001,
      "step": 9846
    },
    {
      "epoch": 0.15591304210142978,
      "grad_norm": 0.14973360300064087,
      "learning_rate": 8.440869578985703e-06,
      "loss": 0.0224,
      "step": 9847
    },
    {
      "epoch": 0.15592887565907185,
      "grad_norm": 0.7798945307731628,
      "learning_rate": 8.440711243409282e-06,
      "loss": 0.0761,
      "step": 9848
    },
    {
      "epoch": 0.1559447092167139,
      "grad_norm": 0.4624551236629486,
      "learning_rate": 8.440552907832863e-06,
      "loss": 0.4557,
      "step": 9849
    },
    {
      "epoch": 0.15596054277435598,
      "grad_norm": 0.000559887383133173,
      "learning_rate": 8.44039457225644e-06,
      "loss": 0.0,
      "step": 9850
    },
    {
      "epoch": 0.15597637633199804,
      "grad_norm": 0.030990691855549812,
      "learning_rate": 8.44023623668002e-06,
      "loss": 0.0047,
      "step": 9851
    },
    {
      "epoch": 0.1559922098896401,
      "grad_norm": 0.0002767904952634126,
      "learning_rate": 8.4400779011036e-06,
      "loss": 0.0,
      "step": 9852
    },
    {
      "epoch": 0.15600804344728217,
      "grad_norm": 0.20458318293094635,
      "learning_rate": 8.439919565527179e-06,
      "loss": 0.0457,
      "step": 9853
    },
    {
      "epoch": 0.15602387700492423,
      "grad_norm": 0.00021765148267149925,
      "learning_rate": 8.439761229950758e-06,
      "loss": 0.0,
      "step": 9854
    },
    {
      "epoch": 0.1560397105625663,
      "grad_norm": 0.02234380878508091,
      "learning_rate": 8.439602894374339e-06,
      "loss": 0.0003,
      "step": 9855
    },
    {
      "epoch": 0.15605554412020836,
      "grad_norm": 0.49666568636894226,
      "learning_rate": 8.439444558797916e-06,
      "loss": 0.1916,
      "step": 9856
    },
    {
      "epoch": 0.15607137767785043,
      "grad_norm": 0.43779024481773376,
      "learning_rate": 8.439286223221497e-06,
      "loss": 0.4842,
      "step": 9857
    },
    {
      "epoch": 0.1560872112354925,
      "grad_norm": 0.0051167551428079605,
      "learning_rate": 8.439127887645076e-06,
      "loss": 0.0001,
      "step": 9858
    },
    {
      "epoch": 0.15610304479313458,
      "grad_norm": 0.005047385115176439,
      "learning_rate": 8.438969552068655e-06,
      "loss": 0.0003,
      "step": 9859
    },
    {
      "epoch": 0.15611887835077665,
      "grad_norm": 0.6509031057357788,
      "learning_rate": 8.438811216492234e-06,
      "loss": 0.1108,
      "step": 9860
    },
    {
      "epoch": 0.1561347119084187,
      "grad_norm": 0.17794570326805115,
      "learning_rate": 8.438652880915815e-06,
      "loss": 0.0841,
      "step": 9861
    },
    {
      "epoch": 0.15615054546606078,
      "grad_norm": 0.2914249300956726,
      "learning_rate": 8.438494545339392e-06,
      "loss": 0.1405,
      "step": 9862
    },
    {
      "epoch": 0.15616637902370284,
      "grad_norm": 0.00023510545725002885,
      "learning_rate": 8.438336209762973e-06,
      "loss": 0.0,
      "step": 9863
    },
    {
      "epoch": 0.1561822125813449,
      "grad_norm": 0.0007010509143583477,
      "learning_rate": 8.438177874186552e-06,
      "loss": 0.0,
      "step": 9864
    },
    {
      "epoch": 0.15619804613898697,
      "grad_norm": 0.296377956867218,
      "learning_rate": 8.438019538610131e-06,
      "loss": 0.1876,
      "step": 9865
    },
    {
      "epoch": 0.15621387969662903,
      "grad_norm": 0.3471231162548065,
      "learning_rate": 8.43786120303371e-06,
      "loss": 0.0691,
      "step": 9866
    },
    {
      "epoch": 0.1562297132542711,
      "grad_norm": 0.4021585285663605,
      "learning_rate": 8.43770286745729e-06,
      "loss": 0.1099,
      "step": 9867
    },
    {
      "epoch": 0.15624554681191316,
      "grad_norm": 0.1919202357530594,
      "learning_rate": 8.437544531880868e-06,
      "loss": 0.0741,
      "step": 9868
    },
    {
      "epoch": 0.15626138036955523,
      "grad_norm": 0.00019827218784485012,
      "learning_rate": 8.437386196304448e-06,
      "loss": 0.0,
      "step": 9869
    },
    {
      "epoch": 0.1562772139271973,
      "grad_norm": 0.3841840624809265,
      "learning_rate": 8.437227860728028e-06,
      "loss": 0.3261,
      "step": 9870
    },
    {
      "epoch": 0.15629304748483938,
      "grad_norm": 0.17308850586414337,
      "learning_rate": 8.437069525151607e-06,
      "loss": 0.0471,
      "step": 9871
    },
    {
      "epoch": 0.15630888104248145,
      "grad_norm": 0.25457340478897095,
      "learning_rate": 8.436911189575187e-06,
      "loss": 0.0543,
      "step": 9872
    },
    {
      "epoch": 0.1563247146001235,
      "grad_norm": 0.2075560986995697,
      "learning_rate": 8.436752853998766e-06,
      "loss": 0.0534,
      "step": 9873
    },
    {
      "epoch": 0.15634054815776557,
      "grad_norm": 0.35580235719680786,
      "learning_rate": 8.436594518422345e-06,
      "loss": 0.2194,
      "step": 9874
    },
    {
      "epoch": 0.15635638171540764,
      "grad_norm": 0.4052042067050934,
      "learning_rate": 8.436436182845924e-06,
      "loss": 0.1508,
      "step": 9875
    },
    {
      "epoch": 0.1563722152730497,
      "grad_norm": 0.025463657453656197,
      "learning_rate": 8.436277847269505e-06,
      "loss": 0.0014,
      "step": 9876
    },
    {
      "epoch": 0.15638804883069177,
      "grad_norm": 0.5407986044883728,
      "learning_rate": 8.436119511693082e-06,
      "loss": 0.1796,
      "step": 9877
    },
    {
      "epoch": 0.15640388238833383,
      "grad_norm": 0.25871431827545166,
      "learning_rate": 8.435961176116663e-06,
      "loss": 0.0975,
      "step": 9878
    },
    {
      "epoch": 0.1564197159459759,
      "grad_norm": 0.013849081471562386,
      "learning_rate": 8.435802840540242e-06,
      "loss": 0.0007,
      "step": 9879
    },
    {
      "epoch": 0.15643554950361796,
      "grad_norm": 0.23763519525527954,
      "learning_rate": 8.43564450496382e-06,
      "loss": 0.0716,
      "step": 9880
    },
    {
      "epoch": 0.15645138306126002,
      "grad_norm": 0.01612008549273014,
      "learning_rate": 8.4354861693874e-06,
      "loss": 0.0011,
      "step": 9881
    },
    {
      "epoch": 0.1564672166189021,
      "grad_norm": 0.1522173285484314,
      "learning_rate": 8.43532783381098e-06,
      "loss": 0.0592,
      "step": 9882
    },
    {
      "epoch": 0.15648305017654418,
      "grad_norm": 0.3794674873352051,
      "learning_rate": 8.435169498234558e-06,
      "loss": 0.1744,
      "step": 9883
    },
    {
      "epoch": 0.15649888373418624,
      "grad_norm": 0.2649516761302948,
      "learning_rate": 8.435011162658139e-06,
      "loss": 0.0465,
      "step": 9884
    },
    {
      "epoch": 0.1565147172918283,
      "grad_norm": 0.5091006755828857,
      "learning_rate": 8.434852827081718e-06,
      "loss": 0.3525,
      "step": 9885
    },
    {
      "epoch": 0.15653055084947037,
      "grad_norm": 0.01198292151093483,
      "learning_rate": 8.434694491505297e-06,
      "loss": 0.0006,
      "step": 9886
    },
    {
      "epoch": 0.15654638440711244,
      "grad_norm": 0.48106908798217773,
      "learning_rate": 8.434536155928876e-06,
      "loss": 0.0317,
      "step": 9887
    },
    {
      "epoch": 0.1565622179647545,
      "grad_norm": 0.5641463994979858,
      "learning_rate": 8.434377820352457e-06,
      "loss": 0.1755,
      "step": 9888
    },
    {
      "epoch": 0.15657805152239657,
      "grad_norm": 0.5659754872322083,
      "learning_rate": 8.434219484776034e-06,
      "loss": 0.2051,
      "step": 9889
    },
    {
      "epoch": 0.15659388508003863,
      "grad_norm": 0.424893319606781,
      "learning_rate": 8.434061149199613e-06,
      "loss": 0.0589,
      "step": 9890
    },
    {
      "epoch": 0.1566097186376807,
      "grad_norm": 0.3703862130641937,
      "learning_rate": 8.433902813623194e-06,
      "loss": 0.0841,
      "step": 9891
    },
    {
      "epoch": 0.15662555219532276,
      "grad_norm": 0.5728724002838135,
      "learning_rate": 8.433744478046773e-06,
      "loss": 0.0214,
      "step": 9892
    },
    {
      "epoch": 0.15664138575296482,
      "grad_norm": 0.2555430233478546,
      "learning_rate": 8.433586142470352e-06,
      "loss": 0.2485,
      "step": 9893
    },
    {
      "epoch": 0.1566572193106069,
      "grad_norm": 0.5723063349723816,
      "learning_rate": 8.433427806893931e-06,
      "loss": 0.5504,
      "step": 9894
    },
    {
      "epoch": 0.15667305286824898,
      "grad_norm": 0.2773657739162445,
      "learning_rate": 8.43326947131751e-06,
      "loss": 0.0591,
      "step": 9895
    },
    {
      "epoch": 0.15668888642589104,
      "grad_norm": 0.4859875738620758,
      "learning_rate": 8.43311113574109e-06,
      "loss": 0.3174,
      "step": 9896
    },
    {
      "epoch": 0.1567047199835331,
      "grad_norm": 0.005897343158721924,
      "learning_rate": 8.43295280016467e-06,
      "loss": 0.0004,
      "step": 9897
    },
    {
      "epoch": 0.15672055354117517,
      "grad_norm": 0.7406895160675049,
      "learning_rate": 8.43279446458825e-06,
      "loss": 0.7954,
      "step": 9898
    },
    {
      "epoch": 0.15673638709881724,
      "grad_norm": 0.2628939747810364,
      "learning_rate": 8.432636129011828e-06,
      "loss": 0.0771,
      "step": 9899
    },
    {
      "epoch": 0.1567522206564593,
      "grad_norm": 0.006494998000562191,
      "learning_rate": 8.432477793435408e-06,
      "loss": 0.0003,
      "step": 9900
    },
    {
      "epoch": 0.15676805421410137,
      "grad_norm": 0.6069614291191101,
      "learning_rate": 8.432319457858987e-06,
      "loss": 0.2059,
      "step": 9901
    },
    {
      "epoch": 0.15678388777174343,
      "grad_norm": 0.3650919497013092,
      "learning_rate": 8.432161122282566e-06,
      "loss": 0.1819,
      "step": 9902
    },
    {
      "epoch": 0.1567997213293855,
      "grad_norm": 0.4029443562030792,
      "learning_rate": 8.432002786706146e-06,
      "loss": 0.1487,
      "step": 9903
    },
    {
      "epoch": 0.15681555488702756,
      "grad_norm": 0.5386479496955872,
      "learning_rate": 8.431844451129726e-06,
      "loss": 0.3459,
      "step": 9904
    },
    {
      "epoch": 0.15683138844466962,
      "grad_norm": 0.10595601052045822,
      "learning_rate": 8.431686115553305e-06,
      "loss": 0.029,
      "step": 9905
    },
    {
      "epoch": 0.1568472220023117,
      "grad_norm": 0.26590779423713684,
      "learning_rate": 8.431527779976884e-06,
      "loss": 0.1157,
      "step": 9906
    },
    {
      "epoch": 0.15686305555995378,
      "grad_norm": 0.2102133184671402,
      "learning_rate": 8.431369444400463e-06,
      "loss": 0.015,
      "step": 9907
    },
    {
      "epoch": 0.15687888911759584,
      "grad_norm": 0.127646803855896,
      "learning_rate": 8.431211108824042e-06,
      "loss": 0.0518,
      "step": 9908
    },
    {
      "epoch": 0.1568947226752379,
      "grad_norm": 0.017381878569722176,
      "learning_rate": 8.431052773247623e-06,
      "loss": 0.0011,
      "step": 9909
    },
    {
      "epoch": 0.15691055623287997,
      "grad_norm": 0.29469093680381775,
      "learning_rate": 8.430894437671202e-06,
      "loss": 0.1041,
      "step": 9910
    },
    {
      "epoch": 0.15692638979052204,
      "grad_norm": 0.0073930430226027966,
      "learning_rate": 8.43073610209478e-06,
      "loss": 0.0004,
      "step": 9911
    },
    {
      "epoch": 0.1569422233481641,
      "grad_norm": 0.8512885570526123,
      "learning_rate": 8.43057776651836e-06,
      "loss": 0.9126,
      "step": 9912
    },
    {
      "epoch": 0.15695805690580616,
      "grad_norm": 0.40567871928215027,
      "learning_rate": 8.430419430941939e-06,
      "loss": 0.2463,
      "step": 9913
    },
    {
      "epoch": 0.15697389046344823,
      "grad_norm": 0.21218302845954895,
      "learning_rate": 8.430261095365518e-06,
      "loss": 0.0806,
      "step": 9914
    },
    {
      "epoch": 0.1569897240210903,
      "grad_norm": 0.022819019854068756,
      "learning_rate": 8.430102759789097e-06,
      "loss": 0.001,
      "step": 9915
    },
    {
      "epoch": 0.15700555757873236,
      "grad_norm": 0.29298871755599976,
      "learning_rate": 8.429944424212678e-06,
      "loss": 0.0979,
      "step": 9916
    },
    {
      "epoch": 0.15702139113637442,
      "grad_norm": 0.41244813799858093,
      "learning_rate": 8.429786088636255e-06,
      "loss": 0.4192,
      "step": 9917
    },
    {
      "epoch": 0.1570372246940165,
      "grad_norm": 0.9564440846443176,
      "learning_rate": 8.429627753059836e-06,
      "loss": 0.5849,
      "step": 9918
    },
    {
      "epoch": 0.15705305825165858,
      "grad_norm": 0.1667669266462326,
      "learning_rate": 8.429469417483415e-06,
      "loss": 0.0776,
      "step": 9919
    },
    {
      "epoch": 0.15706889180930064,
      "grad_norm": 0.5418466329574585,
      "learning_rate": 8.429311081906994e-06,
      "loss": 0.0273,
      "step": 9920
    },
    {
      "epoch": 0.1570847253669427,
      "grad_norm": 0.3428983688354492,
      "learning_rate": 8.429152746330573e-06,
      "loss": 0.1274,
      "step": 9921
    },
    {
      "epoch": 0.15710055892458477,
      "grad_norm": 0.037051524966955185,
      "learning_rate": 8.428994410754154e-06,
      "loss": 0.0027,
      "step": 9922
    },
    {
      "epoch": 0.15711639248222684,
      "grad_norm": 0.2808062434196472,
      "learning_rate": 8.428836075177731e-06,
      "loss": 0.0847,
      "step": 9923
    },
    {
      "epoch": 0.1571322260398689,
      "grad_norm": 0.0016860660398378968,
      "learning_rate": 8.428677739601312e-06,
      "loss": 0.0,
      "step": 9924
    },
    {
      "epoch": 0.15714805959751096,
      "grad_norm": 0.01734958030283451,
      "learning_rate": 8.428519404024891e-06,
      "loss": 0.0013,
      "step": 9925
    },
    {
      "epoch": 0.15716389315515303,
      "grad_norm": 0.5507087707519531,
      "learning_rate": 8.42836106844847e-06,
      "loss": 0.4883,
      "step": 9926
    },
    {
      "epoch": 0.1571797267127951,
      "grad_norm": 0.012836204841732979,
      "learning_rate": 8.42820273287205e-06,
      "loss": 0.0008,
      "step": 9927
    },
    {
      "epoch": 0.15719556027043716,
      "grad_norm": 0.0009317831136286259,
      "learning_rate": 8.42804439729563e-06,
      "loss": 0.0,
      "step": 9928
    },
    {
      "epoch": 0.15721139382807922,
      "grad_norm": 0.47850891947746277,
      "learning_rate": 8.427886061719208e-06,
      "loss": 0.3233,
      "step": 9929
    },
    {
      "epoch": 0.15722722738572129,
      "grad_norm": 0.129011869430542,
      "learning_rate": 8.427727726142788e-06,
      "loss": 0.0041,
      "step": 9930
    },
    {
      "epoch": 0.15724306094336338,
      "grad_norm": 0.9638670682907104,
      "learning_rate": 8.427569390566367e-06,
      "loss": 0.4746,
      "step": 9931
    },
    {
      "epoch": 0.15725889450100544,
      "grad_norm": 0.19495180249214172,
      "learning_rate": 8.427411054989947e-06,
      "loss": 0.0133,
      "step": 9932
    },
    {
      "epoch": 0.1572747280586475,
      "grad_norm": 0.18188969790935516,
      "learning_rate": 8.427252719413526e-06,
      "loss": 0.0064,
      "step": 9933
    },
    {
      "epoch": 0.15729056161628957,
      "grad_norm": 0.009762361645698547,
      "learning_rate": 8.427094383837106e-06,
      "loss": 0.0004,
      "step": 9934
    },
    {
      "epoch": 0.15730639517393163,
      "grad_norm": 0.01743246056139469,
      "learning_rate": 8.426936048260684e-06,
      "loss": 0.0011,
      "step": 9935
    },
    {
      "epoch": 0.1573222287315737,
      "grad_norm": 0.018524043262004852,
      "learning_rate": 8.426777712684265e-06,
      "loss": 0.0011,
      "step": 9936
    },
    {
      "epoch": 0.15733806228921576,
      "grad_norm": 0.005688373930752277,
      "learning_rate": 8.426619377107844e-06,
      "loss": 0.0001,
      "step": 9937
    },
    {
      "epoch": 0.15735389584685783,
      "grad_norm": 0.27637580037117004,
      "learning_rate": 8.426461041531423e-06,
      "loss": 0.2126,
      "step": 9938
    },
    {
      "epoch": 0.1573697294044999,
      "grad_norm": 0.38870155811309814,
      "learning_rate": 8.426302705955002e-06,
      "loss": 0.4924,
      "step": 9939
    },
    {
      "epoch": 0.15738556296214196,
      "grad_norm": 0.41224008798599243,
      "learning_rate": 8.426144370378581e-06,
      "loss": 0.0669,
      "step": 9940
    },
    {
      "epoch": 0.15740139651978402,
      "grad_norm": 0.021261468529701233,
      "learning_rate": 8.42598603480216e-06,
      "loss": 0.0014,
      "step": 9941
    },
    {
      "epoch": 0.15741723007742608,
      "grad_norm": 0.001675744540989399,
      "learning_rate": 8.425827699225739e-06,
      "loss": 0.0,
      "step": 9942
    },
    {
      "epoch": 0.15743306363506818,
      "grad_norm": 0.38675445318222046,
      "learning_rate": 8.42566936364932e-06,
      "loss": 0.0427,
      "step": 9943
    },
    {
      "epoch": 0.15744889719271024,
      "grad_norm": 0.27121853828430176,
      "learning_rate": 8.425511028072897e-06,
      "loss": 0.0486,
      "step": 9944
    },
    {
      "epoch": 0.1574647307503523,
      "grad_norm": 0.2615119218826294,
      "learning_rate": 8.425352692496478e-06,
      "loss": 0.0445,
      "step": 9945
    },
    {
      "epoch": 0.15748056430799437,
      "grad_norm": 0.1718808114528656,
      "learning_rate": 8.425194356920057e-06,
      "loss": 0.0677,
      "step": 9946
    },
    {
      "epoch": 0.15749639786563643,
      "grad_norm": 0.528438150882721,
      "learning_rate": 8.425036021343636e-06,
      "loss": 0.5222,
      "step": 9947
    },
    {
      "epoch": 0.1575122314232785,
      "grad_norm": 0.17856262624263763,
      "learning_rate": 8.424877685767215e-06,
      "loss": 0.0333,
      "step": 9948
    },
    {
      "epoch": 0.15752806498092056,
      "grad_norm": 2.2473626136779785,
      "learning_rate": 8.424719350190796e-06,
      "loss": 0.2563,
      "step": 9949
    },
    {
      "epoch": 0.15754389853856263,
      "grad_norm": 0.3252948224544525,
      "learning_rate": 8.424561014614373e-06,
      "loss": 0.0477,
      "step": 9950
    },
    {
      "epoch": 0.1575597320962047,
      "grad_norm": 0.24281050264835358,
      "learning_rate": 8.424402679037954e-06,
      "loss": 0.0372,
      "step": 9951
    },
    {
      "epoch": 0.15757556565384676,
      "grad_norm": 0.007273425813764334,
      "learning_rate": 8.424244343461533e-06,
      "loss": 0.0001,
      "step": 9952
    },
    {
      "epoch": 0.15759139921148882,
      "grad_norm": 0.3761703372001648,
      "learning_rate": 8.424086007885112e-06,
      "loss": 0.1332,
      "step": 9953
    },
    {
      "epoch": 0.15760723276913088,
      "grad_norm": 0.5246371626853943,
      "learning_rate": 8.423927672308691e-06,
      "loss": 0.1153,
      "step": 9954
    },
    {
      "epoch": 0.15762306632677298,
      "grad_norm": 0.5375024676322937,
      "learning_rate": 8.423769336732272e-06,
      "loss": 0.3526,
      "step": 9955
    },
    {
      "epoch": 0.15763889988441504,
      "grad_norm": 0.007854900322854519,
      "learning_rate": 8.42361100115585e-06,
      "loss": 0.0005,
      "step": 9956
    },
    {
      "epoch": 0.1576547334420571,
      "grad_norm": 0.27239251136779785,
      "learning_rate": 8.42345266557943e-06,
      "loss": 0.142,
      "step": 9957
    },
    {
      "epoch": 0.15767056699969917,
      "grad_norm": 0.0011070212349295616,
      "learning_rate": 8.42329433000301e-06,
      "loss": 0.0,
      "step": 9958
    },
    {
      "epoch": 0.15768640055734123,
      "grad_norm": 0.008271228522062302,
      "learning_rate": 8.423135994426588e-06,
      "loss": 0.0004,
      "step": 9959
    },
    {
      "epoch": 0.1577022341149833,
      "grad_norm": 0.00025326781906187534,
      "learning_rate": 8.422977658850168e-06,
      "loss": 0.0,
      "step": 9960
    },
    {
      "epoch": 0.15771806767262536,
      "grad_norm": 0.9306044578552246,
      "learning_rate": 8.422819323273747e-06,
      "loss": 1.0022,
      "step": 9961
    },
    {
      "epoch": 0.15773390123026743,
      "grad_norm": 0.28705674409866333,
      "learning_rate": 8.422660987697326e-06,
      "loss": 0.0093,
      "step": 9962
    },
    {
      "epoch": 0.1577497347879095,
      "grad_norm": 0.0030157575383782387,
      "learning_rate": 8.422502652120905e-06,
      "loss": 0.0001,
      "step": 9963
    },
    {
      "epoch": 0.15776556834555155,
      "grad_norm": 0.40512439608573914,
      "learning_rate": 8.422344316544486e-06,
      "loss": 0.0397,
      "step": 9964
    },
    {
      "epoch": 0.15778140190319362,
      "grad_norm": 0.318766325712204,
      "learning_rate": 8.422185980968065e-06,
      "loss": 0.1397,
      "step": 9965
    },
    {
      "epoch": 0.15779723546083568,
      "grad_norm": 0.1689634770154953,
      "learning_rate": 8.422027645391644e-06,
      "loss": 0.0568,
      "step": 9966
    },
    {
      "epoch": 0.15781306901847778,
      "grad_norm": 0.011517344042658806,
      "learning_rate": 8.421869309815223e-06,
      "loss": 0.0006,
      "step": 9967
    },
    {
      "epoch": 0.15782890257611984,
      "grad_norm": 0.020170442759990692,
      "learning_rate": 8.421710974238802e-06,
      "loss": 0.0012,
      "step": 9968
    },
    {
      "epoch": 0.1578447361337619,
      "grad_norm": 0.3982236385345459,
      "learning_rate": 8.421552638662381e-06,
      "loss": 0.1178,
      "step": 9969
    },
    {
      "epoch": 0.15786056969140397,
      "grad_norm": 0.014537501148879528,
      "learning_rate": 8.421394303085962e-06,
      "loss": 0.0005,
      "step": 9970
    },
    {
      "epoch": 0.15787640324904603,
      "grad_norm": 0.0003264055703766644,
      "learning_rate": 8.42123596750954e-06,
      "loss": 0.0,
      "step": 9971
    },
    {
      "epoch": 0.1578922368066881,
      "grad_norm": 0.38151490688323975,
      "learning_rate": 8.42107763193312e-06,
      "loss": 0.0901,
      "step": 9972
    },
    {
      "epoch": 0.15790807036433016,
      "grad_norm": 0.6659144163131714,
      "learning_rate": 8.420919296356699e-06,
      "loss": 0.8084,
      "step": 9973
    },
    {
      "epoch": 0.15792390392197223,
      "grad_norm": 0.05446859821677208,
      "learning_rate": 8.420760960780278e-06,
      "loss": 0.0023,
      "step": 9974
    },
    {
      "epoch": 0.1579397374796143,
      "grad_norm": 0.0002639802114572376,
      "learning_rate": 8.420602625203857e-06,
      "loss": 0.0,
      "step": 9975
    },
    {
      "epoch": 0.15795557103725635,
      "grad_norm": 0.1813594251871109,
      "learning_rate": 8.420444289627438e-06,
      "loss": 0.0781,
      "step": 9976
    },
    {
      "epoch": 0.15797140459489842,
      "grad_norm": 0.3069310486316681,
      "learning_rate": 8.420285954051017e-06,
      "loss": 0.1962,
      "step": 9977
    },
    {
      "epoch": 0.15798723815254048,
      "grad_norm": 0.27228403091430664,
      "learning_rate": 8.420127618474596e-06,
      "loss": 0.1167,
      "step": 9978
    },
    {
      "epoch": 0.15800307171018257,
      "grad_norm": 0.0020303393248468637,
      "learning_rate": 8.419969282898175e-06,
      "loss": 0.0001,
      "step": 9979
    },
    {
      "epoch": 0.15801890526782464,
      "grad_norm": 0.7545685172080994,
      "learning_rate": 8.419810947321754e-06,
      "loss": 0.2547,
      "step": 9980
    },
    {
      "epoch": 0.1580347388254667,
      "grad_norm": 1.3075549602508545,
      "learning_rate": 8.419652611745333e-06,
      "loss": 0.1475,
      "step": 9981
    },
    {
      "epoch": 0.15805057238310877,
      "grad_norm": 0.676214337348938,
      "learning_rate": 8.419494276168914e-06,
      "loss": 0.164,
      "step": 9982
    },
    {
      "epoch": 0.15806640594075083,
      "grad_norm": 0.2888876497745514,
      "learning_rate": 8.419335940592493e-06,
      "loss": 0.0545,
      "step": 9983
    },
    {
      "epoch": 0.1580822394983929,
      "grad_norm": 0.24011391401290894,
      "learning_rate": 8.419177605016072e-06,
      "loss": 0.077,
      "step": 9984
    },
    {
      "epoch": 0.15809807305603496,
      "grad_norm": 0.3575229048728943,
      "learning_rate": 8.419019269439651e-06,
      "loss": 0.0836,
      "step": 9985
    },
    {
      "epoch": 0.15811390661367702,
      "grad_norm": 0.26584112644195557,
      "learning_rate": 8.41886093386323e-06,
      "loss": 0.0562,
      "step": 9986
    },
    {
      "epoch": 0.1581297401713191,
      "grad_norm": 0.43743592500686646,
      "learning_rate": 8.41870259828681e-06,
      "loss": 0.1695,
      "step": 9987
    },
    {
      "epoch": 0.15814557372896115,
      "grad_norm": 0.32242435216903687,
      "learning_rate": 8.418544262710389e-06,
      "loss": 0.1526,
      "step": 9988
    },
    {
      "epoch": 0.15816140728660322,
      "grad_norm": 0.21449469029903412,
      "learning_rate": 8.41838592713397e-06,
      "loss": 0.06,
      "step": 9989
    },
    {
      "epoch": 0.15817724084424528,
      "grad_norm": 0.41854995489120483,
      "learning_rate": 8.418227591557547e-06,
      "loss": 0.2301,
      "step": 9990
    },
    {
      "epoch": 0.15819307440188737,
      "grad_norm": 0.0009469608194194734,
      "learning_rate": 8.418069255981127e-06,
      "loss": 0.0,
      "step": 9991
    },
    {
      "epoch": 0.15820890795952944,
      "grad_norm": 0.023222286254167557,
      "learning_rate": 8.417910920404707e-06,
      "loss": 0.0016,
      "step": 9992
    },
    {
      "epoch": 0.1582247415171715,
      "grad_norm": 0.021994205191731453,
      "learning_rate": 8.417752584828286e-06,
      "loss": 0.0008,
      "step": 9993
    },
    {
      "epoch": 0.15824057507481357,
      "grad_norm": 0.23040913045406342,
      "learning_rate": 8.417594249251865e-06,
      "loss": 0.0354,
      "step": 9994
    },
    {
      "epoch": 0.15825640863245563,
      "grad_norm": 0.5555822849273682,
      "learning_rate": 8.417435913675445e-06,
      "loss": 0.0904,
      "step": 9995
    },
    {
      "epoch": 0.1582722421900977,
      "grad_norm": 0.6248970627784729,
      "learning_rate": 8.417277578099023e-06,
      "loss": 0.058,
      "step": 9996
    },
    {
      "epoch": 0.15828807574773976,
      "grad_norm": 0.6212313771247864,
      "learning_rate": 8.417119242522604e-06,
      "loss": 0.5597,
      "step": 9997
    },
    {
      "epoch": 0.15830390930538182,
      "grad_norm": 0.18291451036930084,
      "learning_rate": 8.416960906946183e-06,
      "loss": 0.0603,
      "step": 9998
    },
    {
      "epoch": 0.1583197428630239,
      "grad_norm": 0.3708023130893707,
      "learning_rate": 8.416802571369762e-06,
      "loss": 0.381,
      "step": 9999
    },
    {
      "epoch": 0.15833557642066595,
      "grad_norm": 0.2167213261127472,
      "learning_rate": 8.416644235793341e-06,
      "loss": 0.0624,
      "step": 10000
    }
  ],
  "logging_steps": 1,
  "max_steps": 63157,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10000,
  "total_flos": 1.272839446963968e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
