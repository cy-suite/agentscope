{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.777121541809139,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 7.771215418091389e-05,
      "grad_norm": 0.2214256227016449,
      "learning_rate": 9.999611439229096e-06,
      "loss": 0.7006,
      "step": 1
    },
    {
      "epoch": 0.00015542430836182778,
      "grad_norm": 0.11325420439243317,
      "learning_rate": 9.99922287845819e-06,
      "loss": 0.2056,
      "step": 2
    },
    {
      "epoch": 0.00023313646254274168,
      "grad_norm": 0.21504034101963043,
      "learning_rate": 9.998834317687287e-06,
      "loss": 0.6356,
      "step": 3
    },
    {
      "epoch": 0.00031084861672365556,
      "grad_norm": 0.12968073785305023,
      "learning_rate": 9.998445756916382e-06,
      "loss": 0.504,
      "step": 4
    },
    {
      "epoch": 0.0003885607709045695,
      "grad_norm": 0.13861270248889923,
      "learning_rate": 9.998057196145477e-06,
      "loss": 0.1138,
      "step": 5
    },
    {
      "epoch": 0.00046627292508548337,
      "grad_norm": 0.25079450011253357,
      "learning_rate": 9.997668635374574e-06,
      "loss": 0.4052,
      "step": 6
    },
    {
      "epoch": 0.0005439850792663972,
      "grad_norm": 0.21725472807884216,
      "learning_rate": 9.997280074603669e-06,
      "loss": 0.4082,
      "step": 7
    },
    {
      "epoch": 0.0006216972334473111,
      "grad_norm": 0.17378583550453186,
      "learning_rate": 9.996891513832764e-06,
      "loss": 0.3,
      "step": 8
    },
    {
      "epoch": 0.0006994093876282251,
      "grad_norm": 0.07391942292451859,
      "learning_rate": 9.996502953061859e-06,
      "loss": 0.1763,
      "step": 9
    },
    {
      "epoch": 0.000777121541809139,
      "grad_norm": 0.14442017674446106,
      "learning_rate": 9.996114392290955e-06,
      "loss": 0.284,
      "step": 10
    },
    {
      "epoch": 0.0008548336959900529,
      "grad_norm": 0.16426338255405426,
      "learning_rate": 9.99572583152005e-06,
      "loss": 0.3743,
      "step": 11
    },
    {
      "epoch": 0.0009325458501709667,
      "grad_norm": 0.1151408851146698,
      "learning_rate": 9.995337270749145e-06,
      "loss": 0.1495,
      "step": 12
    },
    {
      "epoch": 0.0010102580043518806,
      "grad_norm": 0.20022174715995789,
      "learning_rate": 9.994948709978242e-06,
      "loss": 0.3362,
      "step": 13
    },
    {
      "epoch": 0.0010879701585327945,
      "grad_norm": 0.26036882400512695,
      "learning_rate": 9.994560149207337e-06,
      "loss": 1.0529,
      "step": 14
    },
    {
      "epoch": 0.0011656823127137084,
      "grad_norm": 0.09306538850069046,
      "learning_rate": 9.994171588436432e-06,
      "loss": 0.2439,
      "step": 15
    },
    {
      "epoch": 0.0012433944668946222,
      "grad_norm": 0.3211129605770111,
      "learning_rate": 9.993783027665528e-06,
      "loss": 0.7112,
      "step": 16
    },
    {
      "epoch": 0.0013211066210755361,
      "grad_norm": 0.1085270568728447,
      "learning_rate": 9.993394466894623e-06,
      "loss": 0.2536,
      "step": 17
    },
    {
      "epoch": 0.0013988187752564502,
      "grad_norm": 0.643956184387207,
      "learning_rate": 9.993005906123718e-06,
      "loss": 0.4426,
      "step": 18
    },
    {
      "epoch": 0.001476530929437364,
      "grad_norm": 0.23626023530960083,
      "learning_rate": 9.992617345352813e-06,
      "loss": 0.9266,
      "step": 19
    },
    {
      "epoch": 0.001554243083618278,
      "grad_norm": 0.05641040951013565,
      "learning_rate": 9.99222878458191e-06,
      "loss": 0.1305,
      "step": 20
    },
    {
      "epoch": 0.0016319552377991918,
      "grad_norm": 0.27753177285194397,
      "learning_rate": 9.991840223811005e-06,
      "loss": 0.5951,
      "step": 21
    },
    {
      "epoch": 0.0017096673919801057,
      "grad_norm": 0.36399710178375244,
      "learning_rate": 9.9914516630401e-06,
      "loss": 0.3665,
      "step": 22
    },
    {
      "epoch": 0.0017873795461610196,
      "grad_norm": 0.107342429459095,
      "learning_rate": 9.991063102269197e-06,
      "loss": 0.1727,
      "step": 23
    },
    {
      "epoch": 0.0018650917003419335,
      "grad_norm": 0.4323076903820038,
      "learning_rate": 9.990674541498291e-06,
      "loss": 0.574,
      "step": 24
    },
    {
      "epoch": 0.0019428038545228473,
      "grad_norm": 0.09699997305870056,
      "learning_rate": 9.990285980727386e-06,
      "loss": 0.2031,
      "step": 25
    },
    {
      "epoch": 0.002020516008703761,
      "grad_norm": 0.3450029194355011,
      "learning_rate": 9.989897419956483e-06,
      "loss": 0.3577,
      "step": 26
    },
    {
      "epoch": 0.002098228162884675,
      "grad_norm": 0.20984363555908203,
      "learning_rate": 9.989508859185576e-06,
      "loss": 0.2667,
      "step": 27
    },
    {
      "epoch": 0.002175940317065589,
      "grad_norm": 0.275882363319397,
      "learning_rate": 9.989120298414673e-06,
      "loss": 0.2671,
      "step": 28
    },
    {
      "epoch": 0.002253652471246503,
      "grad_norm": 0.25029125809669495,
      "learning_rate": 9.988731737643768e-06,
      "loss": 0.1548,
      "step": 29
    },
    {
      "epoch": 0.0023313646254274167,
      "grad_norm": 0.2938680052757263,
      "learning_rate": 9.988343176872863e-06,
      "loss": 1.2653,
      "step": 30
    },
    {
      "epoch": 0.0024090767796083306,
      "grad_norm": 0.28842124342918396,
      "learning_rate": 9.98795461610196e-06,
      "loss": 0.173,
      "step": 31
    },
    {
      "epoch": 0.0024867889337892445,
      "grad_norm": 0.12260326743125916,
      "learning_rate": 9.987566055331054e-06,
      "loss": 0.0474,
      "step": 32
    },
    {
      "epoch": 0.0025645010879701583,
      "grad_norm": 0.23569174110889435,
      "learning_rate": 9.98717749456015e-06,
      "loss": 0.3335,
      "step": 33
    },
    {
      "epoch": 0.0026422132421510722,
      "grad_norm": 0.44659674167633057,
      "learning_rate": 9.986788933789246e-06,
      "loss": 0.3344,
      "step": 34
    },
    {
      "epoch": 0.0027199253963319865,
      "grad_norm": 0.19444088637828827,
      "learning_rate": 9.986400373018341e-06,
      "loss": 0.6433,
      "step": 35
    },
    {
      "epoch": 0.0027976375505129004,
      "grad_norm": 0.1707882434129715,
      "learning_rate": 9.986011812247436e-06,
      "loss": 0.241,
      "step": 36
    },
    {
      "epoch": 0.0028753497046938143,
      "grad_norm": 0.16395463049411774,
      "learning_rate": 9.985623251476531e-06,
      "loss": 0.524,
      "step": 37
    },
    {
      "epoch": 0.002953061858874728,
      "grad_norm": 0.3149009644985199,
      "learning_rate": 9.985234690705628e-06,
      "loss": 0.2911,
      "step": 38
    },
    {
      "epoch": 0.003030774013055642,
      "grad_norm": 0.07931841909885406,
      "learning_rate": 9.984846129934722e-06,
      "loss": 0.0709,
      "step": 39
    },
    {
      "epoch": 0.003108486167236556,
      "grad_norm": 0.14047203958034515,
      "learning_rate": 9.984457569163817e-06,
      "loss": 0.1794,
      "step": 40
    },
    {
      "epoch": 0.00318619832141747,
      "grad_norm": 0.25653982162475586,
      "learning_rate": 9.984069008392914e-06,
      "loss": 0.1226,
      "step": 41
    },
    {
      "epoch": 0.0032639104755983837,
      "grad_norm": 1.023783564567566,
      "learning_rate": 9.983680447622009e-06,
      "loss": 0.7093,
      "step": 42
    },
    {
      "epoch": 0.0033416226297792975,
      "grad_norm": 0.25671514868736267,
      "learning_rate": 9.983291886851104e-06,
      "loss": 0.3008,
      "step": 43
    },
    {
      "epoch": 0.0034193347839602114,
      "grad_norm": 0.12696926295757294,
      "learning_rate": 9.9829033260802e-06,
      "loss": 0.1424,
      "step": 44
    },
    {
      "epoch": 0.0034970469381411253,
      "grad_norm": 0.2907988727092743,
      "learning_rate": 9.982514765309294e-06,
      "loss": 0.2406,
      "step": 45
    },
    {
      "epoch": 0.003574759092322039,
      "grad_norm": 0.20096401870250702,
      "learning_rate": 9.98212620453839e-06,
      "loss": 0.2074,
      "step": 46
    },
    {
      "epoch": 0.003652471246502953,
      "grad_norm": 0.10423679649829865,
      "learning_rate": 9.981737643767485e-06,
      "loss": 0.2222,
      "step": 47
    },
    {
      "epoch": 0.003730183400683867,
      "grad_norm": 0.23132027685642242,
      "learning_rate": 9.981349082996582e-06,
      "loss": 0.2007,
      "step": 48
    },
    {
      "epoch": 0.003807895554864781,
      "grad_norm": 0.14190995693206787,
      "learning_rate": 9.980960522225677e-06,
      "loss": 0.1281,
      "step": 49
    },
    {
      "epoch": 0.0038856077090456947,
      "grad_norm": 0.5333910584449768,
      "learning_rate": 9.980571961454772e-06,
      "loss": 0.2236,
      "step": 50
    },
    {
      "epoch": 0.003963319863226609,
      "grad_norm": 0.2027159184217453,
      "learning_rate": 9.980183400683869e-06,
      "loss": 0.4816,
      "step": 51
    },
    {
      "epoch": 0.004041032017407522,
      "grad_norm": 0.6409115791320801,
      "learning_rate": 9.979794839912964e-06,
      "loss": 0.2003,
      "step": 52
    },
    {
      "epoch": 0.004118744171588437,
      "grad_norm": 0.20566663146018982,
      "learning_rate": 9.979406279142059e-06,
      "loss": 0.1617,
      "step": 53
    },
    {
      "epoch": 0.00419645632576935,
      "grad_norm": 0.3986101746559143,
      "learning_rate": 9.979017718371155e-06,
      "loss": 0.3199,
      "step": 54
    },
    {
      "epoch": 0.0042741684799502645,
      "grad_norm": 0.1163100004196167,
      "learning_rate": 9.978629157600248e-06,
      "loss": 0.0952,
      "step": 55
    },
    {
      "epoch": 0.004351880634131178,
      "grad_norm": 0.2420162409543991,
      "learning_rate": 9.978240596829345e-06,
      "loss": 0.3276,
      "step": 56
    },
    {
      "epoch": 0.004429592788312092,
      "grad_norm": 0.2128966748714447,
      "learning_rate": 9.97785203605844e-06,
      "loss": 0.2183,
      "step": 57
    },
    {
      "epoch": 0.004507304942493006,
      "grad_norm": 0.24627093970775604,
      "learning_rate": 9.977463475287535e-06,
      "loss": 0.1414,
      "step": 58
    },
    {
      "epoch": 0.00458501709667392,
      "grad_norm": 0.3853744566440582,
      "learning_rate": 9.977074914516632e-06,
      "loss": 0.1361,
      "step": 59
    },
    {
      "epoch": 0.0046627292508548334,
      "grad_norm": 0.23129308223724365,
      "learning_rate": 9.976686353745727e-06,
      "loss": 0.0708,
      "step": 60
    },
    {
      "epoch": 0.004740441405035748,
      "grad_norm": 0.1495751440525055,
      "learning_rate": 9.976297792974822e-06,
      "loss": 0.1417,
      "step": 61
    },
    {
      "epoch": 0.004818153559216661,
      "grad_norm": 0.3315111994743347,
      "learning_rate": 9.975909232203918e-06,
      "loss": 0.9985,
      "step": 62
    },
    {
      "epoch": 0.0048958657133975755,
      "grad_norm": 0.13987670838832855,
      "learning_rate": 9.975520671433013e-06,
      "loss": 0.1298,
      "step": 63
    },
    {
      "epoch": 0.004973577867578489,
      "grad_norm": 0.35686370730400085,
      "learning_rate": 9.975132110662108e-06,
      "loss": 0.2298,
      "step": 64
    },
    {
      "epoch": 0.005051290021759403,
      "grad_norm": 0.2735859751701355,
      "learning_rate": 9.974743549891203e-06,
      "loss": 0.5272,
      "step": 65
    },
    {
      "epoch": 0.005129002175940317,
      "grad_norm": 0.11351852118968964,
      "learning_rate": 9.9743549891203e-06,
      "loss": 0.6039,
      "step": 66
    },
    {
      "epoch": 0.005206714330121231,
      "grad_norm": 0.4113835394382477,
      "learning_rate": 9.973966428349395e-06,
      "loss": 0.1962,
      "step": 67
    },
    {
      "epoch": 0.0052844264843021444,
      "grad_norm": 0.16180764138698578,
      "learning_rate": 9.97357786757849e-06,
      "loss": 0.1375,
      "step": 68
    },
    {
      "epoch": 0.005362138638483059,
      "grad_norm": 0.19228442013263702,
      "learning_rate": 9.973189306807586e-06,
      "loss": 0.1749,
      "step": 69
    },
    {
      "epoch": 0.005439850792663973,
      "grad_norm": 0.796389102935791,
      "learning_rate": 9.972800746036681e-06,
      "loss": 0.2795,
      "step": 70
    },
    {
      "epoch": 0.0055175629468448865,
      "grad_norm": 0.36275550723075867,
      "learning_rate": 9.972412185265776e-06,
      "loss": 0.576,
      "step": 71
    },
    {
      "epoch": 0.005595275101025801,
      "grad_norm": 0.7070936560630798,
      "learning_rate": 9.972023624494873e-06,
      "loss": 0.3298,
      "step": 72
    },
    {
      "epoch": 0.005672987255206714,
      "grad_norm": 0.24289831519126892,
      "learning_rate": 9.971635063723966e-06,
      "loss": 0.2693,
      "step": 73
    },
    {
      "epoch": 0.005750699409387629,
      "grad_norm": 0.1891765594482422,
      "learning_rate": 9.971246502953063e-06,
      "loss": 0.1638,
      "step": 74
    },
    {
      "epoch": 0.005828411563568542,
      "grad_norm": 0.5269400477409363,
      "learning_rate": 9.970857942182158e-06,
      "loss": 0.3671,
      "step": 75
    },
    {
      "epoch": 0.005906123717749456,
      "grad_norm": 0.1401059776544571,
      "learning_rate": 9.970469381411254e-06,
      "loss": 0.1112,
      "step": 76
    },
    {
      "epoch": 0.00598383587193037,
      "grad_norm": 0.15754334628582,
      "learning_rate": 9.97008082064035e-06,
      "loss": 0.2379,
      "step": 77
    },
    {
      "epoch": 0.006061548026111284,
      "grad_norm": 0.1553478091955185,
      "learning_rate": 9.969692259869444e-06,
      "loss": 0.2096,
      "step": 78
    },
    {
      "epoch": 0.0061392601802921975,
      "grad_norm": 0.06258516013622284,
      "learning_rate": 9.96930369909854e-06,
      "loss": 0.0886,
      "step": 79
    },
    {
      "epoch": 0.006216972334473112,
      "grad_norm": 0.27510392665863037,
      "learning_rate": 9.968915138327636e-06,
      "loss": 0.28,
      "step": 80
    },
    {
      "epoch": 0.006294684488654025,
      "grad_norm": 0.06469372659921646,
      "learning_rate": 9.96852657755673e-06,
      "loss": 0.0744,
      "step": 81
    },
    {
      "epoch": 0.00637239664283494,
      "grad_norm": 0.2643513083457947,
      "learning_rate": 9.968138016785827e-06,
      "loss": 0.191,
      "step": 82
    },
    {
      "epoch": 0.006450108797015853,
      "grad_norm": 0.18779246509075165,
      "learning_rate": 9.96774945601492e-06,
      "loss": 0.0843,
      "step": 83
    },
    {
      "epoch": 0.006527820951196767,
      "grad_norm": 0.14481042325496674,
      "learning_rate": 9.967360895244017e-06,
      "loss": 0.2754,
      "step": 84
    },
    {
      "epoch": 0.006605533105377681,
      "grad_norm": 0.1665925532579422,
      "learning_rate": 9.966972334473112e-06,
      "loss": 0.1849,
      "step": 85
    },
    {
      "epoch": 0.006683245259558595,
      "grad_norm": 0.3156093657016754,
      "learning_rate": 9.966583773702207e-06,
      "loss": 0.1523,
      "step": 86
    },
    {
      "epoch": 0.0067609574137395085,
      "grad_norm": 0.22181257605552673,
      "learning_rate": 9.966195212931304e-06,
      "loss": 0.1741,
      "step": 87
    },
    {
      "epoch": 0.006838669567920423,
      "grad_norm": 0.21658410131931305,
      "learning_rate": 9.965806652160399e-06,
      "loss": 0.2654,
      "step": 88
    },
    {
      "epoch": 0.006916381722101336,
      "grad_norm": 0.2346242368221283,
      "learning_rate": 9.965418091389494e-06,
      "loss": 0.0973,
      "step": 89
    },
    {
      "epoch": 0.006994093876282251,
      "grad_norm": 0.1793724149465561,
      "learning_rate": 9.96502953061859e-06,
      "loss": 0.0803,
      "step": 90
    },
    {
      "epoch": 0.007071806030463164,
      "grad_norm": 0.33894068002700806,
      "learning_rate": 9.964640969847685e-06,
      "loss": 0.8159,
      "step": 91
    },
    {
      "epoch": 0.007149518184644078,
      "grad_norm": 0.1899886429309845,
      "learning_rate": 9.96425240907678e-06,
      "loss": 0.167,
      "step": 92
    },
    {
      "epoch": 0.007227230338824993,
      "grad_norm": 0.31844180822372437,
      "learning_rate": 9.963863848305875e-06,
      "loss": 0.5923,
      "step": 93
    },
    {
      "epoch": 0.007304942493005906,
      "grad_norm": 0.13174575567245483,
      "learning_rate": 9.963475287534972e-06,
      "loss": 0.1046,
      "step": 94
    },
    {
      "epoch": 0.00738265464718682,
      "grad_norm": 0.10706369578838348,
      "learning_rate": 9.963086726764067e-06,
      "loss": 0.4925,
      "step": 95
    },
    {
      "epoch": 0.007460366801367734,
      "grad_norm": 0.49256831407546997,
      "learning_rate": 9.962698165993162e-06,
      "loss": 0.6524,
      "step": 96
    },
    {
      "epoch": 0.007538078955548648,
      "grad_norm": 0.2382735162973404,
      "learning_rate": 9.962309605222258e-06,
      "loss": 0.0704,
      "step": 97
    },
    {
      "epoch": 0.007615791109729562,
      "grad_norm": 0.2922145426273346,
      "learning_rate": 9.961921044451353e-06,
      "loss": 0.0827,
      "step": 98
    },
    {
      "epoch": 0.007693503263910476,
      "grad_norm": 0.061951130628585815,
      "learning_rate": 9.961532483680448e-06,
      "loss": 0.0562,
      "step": 99
    },
    {
      "epoch": 0.007771215418091389,
      "grad_norm": 0.0987272560596466,
      "learning_rate": 9.961143922909545e-06,
      "loss": 0.1628,
      "step": 100
    },
    {
      "epoch": 0.007848927572272303,
      "grad_norm": 0.2316354364156723,
      "learning_rate": 9.960755362138638e-06,
      "loss": 0.1692,
      "step": 101
    },
    {
      "epoch": 0.007926639726453218,
      "grad_norm": 0.3707481622695923,
      "learning_rate": 9.960366801367735e-06,
      "loss": 0.4203,
      "step": 102
    },
    {
      "epoch": 0.008004351880634131,
      "grad_norm": 0.3134300410747528,
      "learning_rate": 9.95997824059683e-06,
      "loss": 0.1154,
      "step": 103
    },
    {
      "epoch": 0.008082064034815045,
      "grad_norm": 0.1780293732881546,
      "learning_rate": 9.959589679825925e-06,
      "loss": 0.1118,
      "step": 104
    },
    {
      "epoch": 0.008159776188995958,
      "grad_norm": 0.037882354110479355,
      "learning_rate": 9.959201119055021e-06,
      "loss": 0.0227,
      "step": 105
    },
    {
      "epoch": 0.008237488343176873,
      "grad_norm": 0.2163611799478531,
      "learning_rate": 9.958812558284116e-06,
      "loss": 0.2982,
      "step": 106
    },
    {
      "epoch": 0.008315200497357787,
      "grad_norm": 0.07366267591714859,
      "learning_rate": 9.958423997513213e-06,
      "loss": 0.0248,
      "step": 107
    },
    {
      "epoch": 0.0083929126515387,
      "grad_norm": 0.07087940722703934,
      "learning_rate": 9.958035436742308e-06,
      "loss": 0.0857,
      "step": 108
    },
    {
      "epoch": 0.008470624805719614,
      "grad_norm": 0.539107620716095,
      "learning_rate": 9.957646875971403e-06,
      "loss": 0.2839,
      "step": 109
    },
    {
      "epoch": 0.008548336959900529,
      "grad_norm": 0.4316738545894623,
      "learning_rate": 9.9572583152005e-06,
      "loss": 0.3485,
      "step": 110
    },
    {
      "epoch": 0.008626049114081442,
      "grad_norm": 0.24422091245651245,
      "learning_rate": 9.956869754429593e-06,
      "loss": 0.1046,
      "step": 111
    },
    {
      "epoch": 0.008703761268262356,
      "grad_norm": 0.10206308960914612,
      "learning_rate": 9.95648119365869e-06,
      "loss": 0.1584,
      "step": 112
    },
    {
      "epoch": 0.00878147342244327,
      "grad_norm": 0.15456874668598175,
      "learning_rate": 9.956092632887784e-06,
      "loss": 0.0378,
      "step": 113
    },
    {
      "epoch": 0.008859185576624184,
      "grad_norm": 0.31253865361213684,
      "learning_rate": 9.95570407211688e-06,
      "loss": 0.5667,
      "step": 114
    },
    {
      "epoch": 0.008936897730805098,
      "grad_norm": 0.36124733090400696,
      "learning_rate": 9.955315511345976e-06,
      "loss": 0.1328,
      "step": 115
    },
    {
      "epoch": 0.009014609884986011,
      "grad_norm": 0.1404377669095993,
      "learning_rate": 9.954926950575071e-06,
      "loss": 0.1252,
      "step": 116
    },
    {
      "epoch": 0.009092322039166927,
      "grad_norm": 0.38761967420578003,
      "learning_rate": 9.954538389804166e-06,
      "loss": 0.2475,
      "step": 117
    },
    {
      "epoch": 0.00917003419334784,
      "grad_norm": 0.2814584970474243,
      "learning_rate": 9.954149829033262e-06,
      "loss": 0.6613,
      "step": 118
    },
    {
      "epoch": 0.009247746347528753,
      "grad_norm": 0.2122446447610855,
      "learning_rate": 9.953761268262357e-06,
      "loss": 0.1906,
      "step": 119
    },
    {
      "epoch": 0.009325458501709667,
      "grad_norm": 0.2147643268108368,
      "learning_rate": 9.953372707491452e-06,
      "loss": 0.2917,
      "step": 120
    },
    {
      "epoch": 0.009403170655890582,
      "grad_norm": 0.18167322874069214,
      "learning_rate": 9.952984146720547e-06,
      "loss": 0.5371,
      "step": 121
    },
    {
      "epoch": 0.009480882810071495,
      "grad_norm": 0.23760230839252472,
      "learning_rate": 9.952595585949644e-06,
      "loss": 0.0634,
      "step": 122
    },
    {
      "epoch": 0.009558594964252409,
      "grad_norm": 0.3763054609298706,
      "learning_rate": 9.952207025178739e-06,
      "loss": 0.1625,
      "step": 123
    },
    {
      "epoch": 0.009636307118433322,
      "grad_norm": 0.1712132692337036,
      "learning_rate": 9.951818464407834e-06,
      "loss": 0.1834,
      "step": 124
    },
    {
      "epoch": 0.009714019272614238,
      "grad_norm": 0.12803247570991516,
      "learning_rate": 9.95142990363693e-06,
      "loss": 0.0621,
      "step": 125
    },
    {
      "epoch": 0.009791731426795151,
      "grad_norm": 0.2119101732969284,
      "learning_rate": 9.951041342866025e-06,
      "loss": 0.1277,
      "step": 126
    },
    {
      "epoch": 0.009869443580976064,
      "grad_norm": 0.3349386751651764,
      "learning_rate": 9.95065278209512e-06,
      "loss": 0.0537,
      "step": 127
    },
    {
      "epoch": 0.009947155735156978,
      "grad_norm": 0.1582932025194168,
      "learning_rate": 9.950264221324215e-06,
      "loss": 0.0688,
      "step": 128
    },
    {
      "epoch": 0.010024867889337893,
      "grad_norm": 0.3608787953853607,
      "learning_rate": 9.94987566055331e-06,
      "loss": 0.1729,
      "step": 129
    },
    {
      "epoch": 0.010102580043518807,
      "grad_norm": 0.1300254911184311,
      "learning_rate": 9.949487099782407e-06,
      "loss": 0.1276,
      "step": 130
    },
    {
      "epoch": 0.01018029219769972,
      "grad_norm": 0.1649625599384308,
      "learning_rate": 9.949098539011502e-06,
      "loss": 0.2018,
      "step": 131
    },
    {
      "epoch": 0.010258004351880633,
      "grad_norm": 0.20219741761684418,
      "learning_rate": 9.948709978240597e-06,
      "loss": 0.0758,
      "step": 132
    },
    {
      "epoch": 0.010335716506061549,
      "grad_norm": 0.14809131622314453,
      "learning_rate": 9.948321417469694e-06,
      "loss": 0.2576,
      "step": 133
    },
    {
      "epoch": 0.010413428660242462,
      "grad_norm": 0.4219307601451874,
      "learning_rate": 9.947932856698788e-06,
      "loss": 0.2127,
      "step": 134
    },
    {
      "epoch": 0.010491140814423375,
      "grad_norm": 0.04863402247428894,
      "learning_rate": 9.947544295927883e-06,
      "loss": 0.0127,
      "step": 135
    },
    {
      "epoch": 0.010568852968604289,
      "grad_norm": 0.34839653968811035,
      "learning_rate": 9.947155735156978e-06,
      "loss": 0.7482,
      "step": 136
    },
    {
      "epoch": 0.010646565122785204,
      "grad_norm": 0.16495570540428162,
      "learning_rate": 9.946767174386075e-06,
      "loss": 0.1247,
      "step": 137
    },
    {
      "epoch": 0.010724277276966118,
      "grad_norm": 0.09726385027170181,
      "learning_rate": 9.94637861361517e-06,
      "loss": 0.0678,
      "step": 138
    },
    {
      "epoch": 0.010801989431147031,
      "grad_norm": 0.1494305580854416,
      "learning_rate": 9.945990052844265e-06,
      "loss": 0.0817,
      "step": 139
    },
    {
      "epoch": 0.010879701585327946,
      "grad_norm": 0.17016181349754333,
      "learning_rate": 9.945601492073362e-06,
      "loss": 0.4076,
      "step": 140
    },
    {
      "epoch": 0.01095741373950886,
      "grad_norm": 0.14625443518161774,
      "learning_rate": 9.945212931302456e-06,
      "loss": 0.0425,
      "step": 141
    },
    {
      "epoch": 0.011035125893689773,
      "grad_norm": 0.26823872327804565,
      "learning_rate": 9.944824370531551e-06,
      "loss": 0.1993,
      "step": 142
    },
    {
      "epoch": 0.011112838047870686,
      "grad_norm": 0.20134001970291138,
      "learning_rate": 9.944435809760648e-06,
      "loss": 0.1391,
      "step": 143
    },
    {
      "epoch": 0.011190550202051602,
      "grad_norm": 0.3892163634300232,
      "learning_rate": 9.944047248989743e-06,
      "loss": 0.2199,
      "step": 144
    },
    {
      "epoch": 0.011268262356232515,
      "grad_norm": 0.15642133355140686,
      "learning_rate": 9.943658688218838e-06,
      "loss": 0.2609,
      "step": 145
    },
    {
      "epoch": 0.011345974510413429,
      "grad_norm": 0.2898559868335724,
      "learning_rate": 9.943270127447933e-06,
      "loss": 0.2996,
      "step": 146
    },
    {
      "epoch": 0.011423686664594342,
      "grad_norm": 0.2734662592411041,
      "learning_rate": 9.94288156667703e-06,
      "loss": 0.0969,
      "step": 147
    },
    {
      "epoch": 0.011501398818775257,
      "grad_norm": 0.717184841632843,
      "learning_rate": 9.942493005906125e-06,
      "loss": 0.3103,
      "step": 148
    },
    {
      "epoch": 0.01157911097295617,
      "grad_norm": 0.04764099791646004,
      "learning_rate": 9.94210444513522e-06,
      "loss": 0.0165,
      "step": 149
    },
    {
      "epoch": 0.011656823127137084,
      "grad_norm": 0.3482997417449951,
      "learning_rate": 9.941715884364316e-06,
      "loss": 0.3999,
      "step": 150
    },
    {
      "epoch": 0.011734535281317997,
      "grad_norm": 0.2953164577484131,
      "learning_rate": 9.941327323593411e-06,
      "loss": 0.3796,
      "step": 151
    },
    {
      "epoch": 0.011812247435498913,
      "grad_norm": 0.30155038833618164,
      "learning_rate": 9.940938762822506e-06,
      "loss": 0.1199,
      "step": 152
    },
    {
      "epoch": 0.011889959589679826,
      "grad_norm": 0.292898565530777,
      "learning_rate": 9.940550202051603e-06,
      "loss": 0.5234,
      "step": 153
    },
    {
      "epoch": 0.01196767174386074,
      "grad_norm": 0.4905354678630829,
      "learning_rate": 9.940161641280696e-06,
      "loss": 0.1186,
      "step": 154
    },
    {
      "epoch": 0.012045383898041653,
      "grad_norm": 0.24770495295524597,
      "learning_rate": 9.939773080509793e-06,
      "loss": 0.2274,
      "step": 155
    },
    {
      "epoch": 0.012123096052222568,
      "grad_norm": 0.41571885347366333,
      "learning_rate": 9.939384519738888e-06,
      "loss": 2.2966,
      "step": 156
    },
    {
      "epoch": 0.012200808206403482,
      "grad_norm": 0.35041454434394836,
      "learning_rate": 9.938995958967982e-06,
      "loss": 0.655,
      "step": 157
    },
    {
      "epoch": 0.012278520360584395,
      "grad_norm": 0.24149006605148315,
      "learning_rate": 9.938607398197079e-06,
      "loss": 0.1374,
      "step": 158
    },
    {
      "epoch": 0.012356232514765308,
      "grad_norm": 0.12241432070732117,
      "learning_rate": 9.938218837426174e-06,
      "loss": 0.058,
      "step": 159
    },
    {
      "epoch": 0.012433944668946224,
      "grad_norm": 0.18433375656604767,
      "learning_rate": 9.937830276655269e-06,
      "loss": 0.2775,
      "step": 160
    },
    {
      "epoch": 0.012511656823127137,
      "grad_norm": 0.4147595465183258,
      "learning_rate": 9.937441715884366e-06,
      "loss": 0.156,
      "step": 161
    },
    {
      "epoch": 0.01258936897730805,
      "grad_norm": 0.31887778639793396,
      "learning_rate": 9.93705315511346e-06,
      "loss": 0.4364,
      "step": 162
    },
    {
      "epoch": 0.012667081131488966,
      "grad_norm": 0.1671028882265091,
      "learning_rate": 9.936664594342556e-06,
      "loss": 0.2509,
      "step": 163
    },
    {
      "epoch": 0.01274479328566988,
      "grad_norm": 0.4201398491859436,
      "learning_rate": 9.93627603357165e-06,
      "loss": 1.1257,
      "step": 164
    },
    {
      "epoch": 0.012822505439850793,
      "grad_norm": 0.2978348135948181,
      "learning_rate": 9.935887472800747e-06,
      "loss": 0.3494,
      "step": 165
    },
    {
      "epoch": 0.012900217594031706,
      "grad_norm": 0.5021065473556519,
      "learning_rate": 9.935498912029842e-06,
      "loss": 1.0938,
      "step": 166
    },
    {
      "epoch": 0.012977929748212621,
      "grad_norm": 0.08740897476673126,
      "learning_rate": 9.935110351258937e-06,
      "loss": 0.1234,
      "step": 167
    },
    {
      "epoch": 0.013055641902393535,
      "grad_norm": 0.1649065613746643,
      "learning_rate": 9.934721790488034e-06,
      "loss": 0.218,
      "step": 168
    },
    {
      "epoch": 0.013133354056574448,
      "grad_norm": 0.08079051226377487,
      "learning_rate": 9.934333229717129e-06,
      "loss": 0.152,
      "step": 169
    },
    {
      "epoch": 0.013211066210755362,
      "grad_norm": 0.1733066588640213,
      "learning_rate": 9.933944668946224e-06,
      "loss": 0.2592,
      "step": 170
    },
    {
      "epoch": 0.013288778364936277,
      "grad_norm": 0.15295599400997162,
      "learning_rate": 9.93355610817532e-06,
      "loss": 0.1978,
      "step": 171
    },
    {
      "epoch": 0.01336649051911719,
      "grad_norm": 0.18794061243534088,
      "learning_rate": 9.933167547404415e-06,
      "loss": 0.3049,
      "step": 172
    },
    {
      "epoch": 0.013444202673298104,
      "grad_norm": 0.13916601240634918,
      "learning_rate": 9.93277898663351e-06,
      "loss": 0.1264,
      "step": 173
    },
    {
      "epoch": 0.013521914827479017,
      "grad_norm": 0.036224424839019775,
      "learning_rate": 9.932390425862605e-06,
      "loss": 0.0364,
      "step": 174
    },
    {
      "epoch": 0.013599626981659932,
      "grad_norm": 0.27834779024124146,
      "learning_rate": 9.932001865091702e-06,
      "loss": 0.6162,
      "step": 175
    },
    {
      "epoch": 0.013677339135840846,
      "grad_norm": 0.3532849848270416,
      "learning_rate": 9.931613304320797e-06,
      "loss": 0.0828,
      "step": 176
    },
    {
      "epoch": 0.013755051290021759,
      "grad_norm": 0.2945534288883209,
      "learning_rate": 9.931224743549892e-06,
      "loss": 0.205,
      "step": 177
    },
    {
      "epoch": 0.013832763444202673,
      "grad_norm": 1.7843886613845825,
      "learning_rate": 9.930836182778988e-06,
      "loss": 2.8671,
      "step": 178
    },
    {
      "epoch": 0.013910475598383588,
      "grad_norm": 0.15604525804519653,
      "learning_rate": 9.930447622008083e-06,
      "loss": 0.044,
      "step": 179
    },
    {
      "epoch": 0.013988187752564501,
      "grad_norm": 0.15461041033267975,
      "learning_rate": 9.930059061237178e-06,
      "loss": 0.1479,
      "step": 180
    },
    {
      "epoch": 0.014065899906745415,
      "grad_norm": 0.08829308301210403,
      "learning_rate": 9.929670500466275e-06,
      "loss": 0.1029,
      "step": 181
    },
    {
      "epoch": 0.014143612060926328,
      "grad_norm": 0.13407251238822937,
      "learning_rate": 9.929281939695368e-06,
      "loss": 0.3879,
      "step": 182
    },
    {
      "epoch": 0.014221324215107243,
      "grad_norm": 0.11907169222831726,
      "learning_rate": 9.928893378924465e-06,
      "loss": 0.1138,
      "step": 183
    },
    {
      "epoch": 0.014299036369288157,
      "grad_norm": 0.13159556686878204,
      "learning_rate": 9.92850481815356e-06,
      "loss": 0.1013,
      "step": 184
    },
    {
      "epoch": 0.01437674852346907,
      "grad_norm": 0.2359185516834259,
      "learning_rate": 9.928116257382655e-06,
      "loss": 0.1416,
      "step": 185
    },
    {
      "epoch": 0.014454460677649985,
      "grad_norm": 0.3312108516693115,
      "learning_rate": 9.927727696611751e-06,
      "loss": 0.3908,
      "step": 186
    },
    {
      "epoch": 0.014532172831830899,
      "grad_norm": 0.26972436904907227,
      "learning_rate": 9.927339135840846e-06,
      "loss": 0.443,
      "step": 187
    },
    {
      "epoch": 0.014609884986011812,
      "grad_norm": 0.9766281843185425,
      "learning_rate": 9.926950575069941e-06,
      "loss": 0.4782,
      "step": 188
    },
    {
      "epoch": 0.014687597140192726,
      "grad_norm": 0.1432487964630127,
      "learning_rate": 9.926562014299038e-06,
      "loss": 0.1231,
      "step": 189
    },
    {
      "epoch": 0.01476530929437364,
      "grad_norm": 0.08772391080856323,
      "learning_rate": 9.926173453528133e-06,
      "loss": 0.0271,
      "step": 190
    },
    {
      "epoch": 0.014843021448554554,
      "grad_norm": 0.49169987440109253,
      "learning_rate": 9.925784892757228e-06,
      "loss": 0.3053,
      "step": 191
    },
    {
      "epoch": 0.014920733602735468,
      "grad_norm": 0.12663911283016205,
      "learning_rate": 9.925396331986323e-06,
      "loss": 0.1892,
      "step": 192
    },
    {
      "epoch": 0.014998445756916381,
      "grad_norm": 0.3877165913581848,
      "learning_rate": 9.92500777121542e-06,
      "loss": 0.3326,
      "step": 193
    },
    {
      "epoch": 0.015076157911097296,
      "grad_norm": 0.2465025931596756,
      "learning_rate": 9.924619210444514e-06,
      "loss": 0.2536,
      "step": 194
    },
    {
      "epoch": 0.01515387006527821,
      "grad_norm": 0.5437003374099731,
      "learning_rate": 9.92423064967361e-06,
      "loss": 0.3599,
      "step": 195
    },
    {
      "epoch": 0.015231582219459123,
      "grad_norm": 0.06047160178422928,
      "learning_rate": 9.923842088902706e-06,
      "loss": 0.0167,
      "step": 196
    },
    {
      "epoch": 0.015309294373640037,
      "grad_norm": 0.16327881813049316,
      "learning_rate": 9.9234535281318e-06,
      "loss": 0.3093,
      "step": 197
    },
    {
      "epoch": 0.015387006527820952,
      "grad_norm": 0.3733786642551422,
      "learning_rate": 9.923064967360896e-06,
      "loss": 0.1743,
      "step": 198
    },
    {
      "epoch": 0.015464718682001865,
      "grad_norm": 0.08405598253011703,
      "learning_rate": 9.922676406589992e-06,
      "loss": 0.0535,
      "step": 199
    },
    {
      "epoch": 0.015542430836182779,
      "grad_norm": 0.09016449004411697,
      "learning_rate": 9.922287845819087e-06,
      "loss": 0.0321,
      "step": 200
    },
    {
      "epoch": 0.015620142990363692,
      "grad_norm": 0.2709532380104065,
      "learning_rate": 9.921899285048182e-06,
      "loss": 1.0543,
      "step": 201
    },
    {
      "epoch": 0.015697855144544606,
      "grad_norm": 0.5631552934646606,
      "learning_rate": 9.921510724277277e-06,
      "loss": 0.3926,
      "step": 202
    },
    {
      "epoch": 0.01577556729872552,
      "grad_norm": 0.1598658263683319,
      "learning_rate": 9.921122163506374e-06,
      "loss": 0.1687,
      "step": 203
    },
    {
      "epoch": 0.015853279452906436,
      "grad_norm": 0.10474331676959991,
      "learning_rate": 9.920733602735469e-06,
      "loss": 0.1154,
      "step": 204
    },
    {
      "epoch": 0.015930991607087348,
      "grad_norm": 0.26824814081192017,
      "learning_rate": 9.920345041964564e-06,
      "loss": 0.0533,
      "step": 205
    },
    {
      "epoch": 0.016008703761268263,
      "grad_norm": 0.26556167006492615,
      "learning_rate": 9.91995648119366e-06,
      "loss": 0.3633,
      "step": 206
    },
    {
      "epoch": 0.016086415915449175,
      "grad_norm": 0.09285826981067657,
      "learning_rate": 9.919567920422755e-06,
      "loss": 0.199,
      "step": 207
    },
    {
      "epoch": 0.01616412806963009,
      "grad_norm": 0.14042501151561737,
      "learning_rate": 9.91917935965185e-06,
      "loss": 0.0617,
      "step": 208
    },
    {
      "epoch": 0.016241840223811005,
      "grad_norm": 0.30923888087272644,
      "learning_rate": 9.918790798880947e-06,
      "loss": 0.1069,
      "step": 209
    },
    {
      "epoch": 0.016319552377991917,
      "grad_norm": 0.16674838960170746,
      "learning_rate": 9.91840223811004e-06,
      "loss": 0.0464,
      "step": 210
    },
    {
      "epoch": 0.016397264532172832,
      "grad_norm": 0.06155933439731598,
      "learning_rate": 9.918013677339137e-06,
      "loss": 0.0312,
      "step": 211
    },
    {
      "epoch": 0.016474976686353747,
      "grad_norm": 0.3148004114627838,
      "learning_rate": 9.917625116568232e-06,
      "loss": 0.328,
      "step": 212
    },
    {
      "epoch": 0.01655268884053466,
      "grad_norm": 0.35077130794525146,
      "learning_rate": 9.917236555797327e-06,
      "loss": 0.2605,
      "step": 213
    },
    {
      "epoch": 0.016630400994715574,
      "grad_norm": 0.29849156737327576,
      "learning_rate": 9.916847995026423e-06,
      "loss": 0.2272,
      "step": 214
    },
    {
      "epoch": 0.01670811314889649,
      "grad_norm": 0.06077186390757561,
      "learning_rate": 9.916459434255518e-06,
      "loss": 0.0537,
      "step": 215
    },
    {
      "epoch": 0.0167858253030774,
      "grad_norm": 0.15024901926517487,
      "learning_rate": 9.916070873484613e-06,
      "loss": 0.0689,
      "step": 216
    },
    {
      "epoch": 0.016863537457258316,
      "grad_norm": 0.3326651155948639,
      "learning_rate": 9.91568231271371e-06,
      "loss": 0.3974,
      "step": 217
    },
    {
      "epoch": 0.016941249611439228,
      "grad_norm": 0.1285664141178131,
      "learning_rate": 9.915293751942805e-06,
      "loss": 0.1315,
      "step": 218
    },
    {
      "epoch": 0.017018961765620143,
      "grad_norm": 0.1416897177696228,
      "learning_rate": 9.9149051911719e-06,
      "loss": 0.1084,
      "step": 219
    },
    {
      "epoch": 0.017096673919801058,
      "grad_norm": 0.10914652794599533,
      "learning_rate": 9.914516630400995e-06,
      "loss": 0.0384,
      "step": 220
    },
    {
      "epoch": 0.01717438607398197,
      "grad_norm": 0.27947115898132324,
      "learning_rate": 9.914128069630091e-06,
      "loss": 0.2093,
      "step": 221
    },
    {
      "epoch": 0.017252098228162885,
      "grad_norm": 0.12340757250785828,
      "learning_rate": 9.913739508859186e-06,
      "loss": 0.1319,
      "step": 222
    },
    {
      "epoch": 0.0173298103823438,
      "grad_norm": 0.5091403126716614,
      "learning_rate": 9.913350948088281e-06,
      "loss": 0.1565,
      "step": 223
    },
    {
      "epoch": 0.017407522536524712,
      "grad_norm": 0.3925435543060303,
      "learning_rate": 9.912962387317378e-06,
      "loss": 0.1428,
      "step": 224
    },
    {
      "epoch": 0.017485234690705627,
      "grad_norm": 0.12126293033361435,
      "learning_rate": 9.912573826546473e-06,
      "loss": 0.0566,
      "step": 225
    },
    {
      "epoch": 0.01756294684488654,
      "grad_norm": 0.6660026907920837,
      "learning_rate": 9.912185265775568e-06,
      "loss": 0.6491,
      "step": 226
    },
    {
      "epoch": 0.017640658999067454,
      "grad_norm": 0.43673527240753174,
      "learning_rate": 9.911796705004665e-06,
      "loss": 0.2641,
      "step": 227
    },
    {
      "epoch": 0.01771837115324837,
      "grad_norm": 0.1108812466263771,
      "learning_rate": 9.91140814423376e-06,
      "loss": 0.1154,
      "step": 228
    },
    {
      "epoch": 0.01779608330742928,
      "grad_norm": 0.35961204767227173,
      "learning_rate": 9.911019583462854e-06,
      "loss": 0.2976,
      "step": 229
    },
    {
      "epoch": 0.017873795461610196,
      "grad_norm": 0.4029097855091095,
      "learning_rate": 9.91063102269195e-06,
      "loss": 0.4064,
      "step": 230
    },
    {
      "epoch": 0.01795150761579111,
      "grad_norm": 1.2528407573699951,
      "learning_rate": 9.910242461921046e-06,
      "loss": 0.9929,
      "step": 231
    },
    {
      "epoch": 0.018029219769972023,
      "grad_norm": 0.32425349950790405,
      "learning_rate": 9.909853901150141e-06,
      "loss": 0.2683,
      "step": 232
    },
    {
      "epoch": 0.018106931924152938,
      "grad_norm": 0.2692769467830658,
      "learning_rate": 9.909465340379236e-06,
      "loss": 0.1689,
      "step": 233
    },
    {
      "epoch": 0.018184644078333853,
      "grad_norm": 0.4518708884716034,
      "learning_rate": 9.909076779608333e-06,
      "loss": 0.5729,
      "step": 234
    },
    {
      "epoch": 0.018262356232514765,
      "grad_norm": 0.38452449440956116,
      "learning_rate": 9.908688218837428e-06,
      "loss": 0.4439,
      "step": 235
    },
    {
      "epoch": 0.01834006838669568,
      "grad_norm": 0.26162105798721313,
      "learning_rate": 9.908299658066522e-06,
      "loss": 0.2706,
      "step": 236
    },
    {
      "epoch": 0.01841778054087659,
      "grad_norm": 0.37246260046958923,
      "learning_rate": 9.907911097295619e-06,
      "loss": 0.695,
      "step": 237
    },
    {
      "epoch": 0.018495492695057507,
      "grad_norm": 0.24531146883964539,
      "learning_rate": 9.907522536524712e-06,
      "loss": 0.298,
      "step": 238
    },
    {
      "epoch": 0.018573204849238422,
      "grad_norm": 0.11610741168260574,
      "learning_rate": 9.907133975753809e-06,
      "loss": 0.2179,
      "step": 239
    },
    {
      "epoch": 0.018650917003419334,
      "grad_norm": 0.1055741235613823,
      "learning_rate": 9.906745414982904e-06,
      "loss": 0.1609,
      "step": 240
    },
    {
      "epoch": 0.01872862915760025,
      "grad_norm": 0.42476382851600647,
      "learning_rate": 9.906356854211999e-06,
      "loss": 0.1262,
      "step": 241
    },
    {
      "epoch": 0.018806341311781164,
      "grad_norm": 0.1913059800863266,
      "learning_rate": 9.905968293441096e-06,
      "loss": 0.2121,
      "step": 242
    },
    {
      "epoch": 0.018884053465962076,
      "grad_norm": 0.3748663365840912,
      "learning_rate": 9.90557973267019e-06,
      "loss": 0.8987,
      "step": 243
    },
    {
      "epoch": 0.01896176562014299,
      "grad_norm": 0.1757555603981018,
      "learning_rate": 9.905191171899285e-06,
      "loss": 0.0934,
      "step": 244
    },
    {
      "epoch": 0.019039477774323903,
      "grad_norm": 0.178755983710289,
      "learning_rate": 9.904802611128382e-06,
      "loss": 0.3238,
      "step": 245
    },
    {
      "epoch": 0.019117189928504818,
      "grad_norm": 0.11681023985147476,
      "learning_rate": 9.904414050357477e-06,
      "loss": 0.0388,
      "step": 246
    },
    {
      "epoch": 0.019194902082685733,
      "grad_norm": 0.058958180248737335,
      "learning_rate": 9.904025489586572e-06,
      "loss": 0.0963,
      "step": 247
    },
    {
      "epoch": 0.019272614236866645,
      "grad_norm": 0.10382818430662155,
      "learning_rate": 9.903636928815667e-06,
      "loss": 0.1159,
      "step": 248
    },
    {
      "epoch": 0.01935032639104756,
      "grad_norm": 0.21755842864513397,
      "learning_rate": 9.903248368044764e-06,
      "loss": 0.1868,
      "step": 249
    },
    {
      "epoch": 0.019428038545228475,
      "grad_norm": 0.346849262714386,
      "learning_rate": 9.902859807273859e-06,
      "loss": 0.3923,
      "step": 250
    },
    {
      "epoch": 0.019505750699409387,
      "grad_norm": 0.1078554019331932,
      "learning_rate": 9.902471246502953e-06,
      "loss": 0.0427,
      "step": 251
    },
    {
      "epoch": 0.019583462853590302,
      "grad_norm": 0.1334024965763092,
      "learning_rate": 9.90208268573205e-06,
      "loss": 0.0492,
      "step": 252
    },
    {
      "epoch": 0.019661175007771214,
      "grad_norm": 0.14518806338310242,
      "learning_rate": 9.901694124961145e-06,
      "loss": 0.0801,
      "step": 253
    },
    {
      "epoch": 0.01973888716195213,
      "grad_norm": 0.14130237698554993,
      "learning_rate": 9.90130556419024e-06,
      "loss": 0.1827,
      "step": 254
    },
    {
      "epoch": 0.019816599316133044,
      "grad_norm": 0.38231950998306274,
      "learning_rate": 9.900917003419335e-06,
      "loss": 0.0383,
      "step": 255
    },
    {
      "epoch": 0.019894311470313956,
      "grad_norm": 0.46643340587615967,
      "learning_rate": 9.90052844264843e-06,
      "loss": 0.5865,
      "step": 256
    },
    {
      "epoch": 0.01997202362449487,
      "grad_norm": 0.2914884090423584,
      "learning_rate": 9.900139881877527e-06,
      "loss": 0.3414,
      "step": 257
    },
    {
      "epoch": 0.020049735778675786,
      "grad_norm": 0.04671332985162735,
      "learning_rate": 9.899751321106622e-06,
      "loss": 0.0245,
      "step": 258
    },
    {
      "epoch": 0.020127447932856698,
      "grad_norm": 0.1251996010541916,
      "learning_rate": 9.899362760335718e-06,
      "loss": 0.1089,
      "step": 259
    },
    {
      "epoch": 0.020205160087037613,
      "grad_norm": 0.17455002665519714,
      "learning_rate": 9.898974199564813e-06,
      "loss": 0.0779,
      "step": 260
    },
    {
      "epoch": 0.020282872241218528,
      "grad_norm": 0.11576198041439056,
      "learning_rate": 9.898585638793908e-06,
      "loss": 0.0888,
      "step": 261
    },
    {
      "epoch": 0.02036058439539944,
      "grad_norm": 0.23304277658462524,
      "learning_rate": 9.898197078023005e-06,
      "loss": 0.2523,
      "step": 262
    },
    {
      "epoch": 0.020438296549580355,
      "grad_norm": 0.22530598938465118,
      "learning_rate": 9.897808517252098e-06,
      "loss": 0.1036,
      "step": 263
    },
    {
      "epoch": 0.020516008703761267,
      "grad_norm": 0.19606967270374298,
      "learning_rate": 9.897419956481195e-06,
      "loss": 0.3216,
      "step": 264
    },
    {
      "epoch": 0.020593720857942182,
      "grad_norm": 0.18931609392166138,
      "learning_rate": 9.89703139571029e-06,
      "loss": 0.2259,
      "step": 265
    },
    {
      "epoch": 0.020671433012123097,
      "grad_norm": 0.2104988694190979,
      "learning_rate": 9.896642834939385e-06,
      "loss": 0.0555,
      "step": 266
    },
    {
      "epoch": 0.02074914516630401,
      "grad_norm": 0.20686067640781403,
      "learning_rate": 9.896254274168481e-06,
      "loss": 0.2217,
      "step": 267
    },
    {
      "epoch": 0.020826857320484924,
      "grad_norm": 0.2468045949935913,
      "learning_rate": 9.895865713397576e-06,
      "loss": 0.239,
      "step": 268
    },
    {
      "epoch": 0.02090456947466584,
      "grad_norm": 0.17213159799575806,
      "learning_rate": 9.895477152626671e-06,
      "loss": 0.098,
      "step": 269
    },
    {
      "epoch": 0.02098228162884675,
      "grad_norm": 0.11861305683851242,
      "learning_rate": 9.895088591855768e-06,
      "loss": 0.1494,
      "step": 270
    },
    {
      "epoch": 0.021059993783027666,
      "grad_norm": 0.2006492167711258,
      "learning_rate": 9.894700031084863e-06,
      "loss": 0.2817,
      "step": 271
    },
    {
      "epoch": 0.021137705937208578,
      "grad_norm": 0.2657236158847809,
      "learning_rate": 9.894311470313958e-06,
      "loss": 0.6725,
      "step": 272
    },
    {
      "epoch": 0.021215418091389493,
      "grad_norm": 0.3923812806606293,
      "learning_rate": 9.893922909543053e-06,
      "loss": 0.3473,
      "step": 273
    },
    {
      "epoch": 0.021293130245570408,
      "grad_norm": 0.09700055420398712,
      "learning_rate": 9.89353434877215e-06,
      "loss": 0.1027,
      "step": 274
    },
    {
      "epoch": 0.02137084239975132,
      "grad_norm": 0.3101847469806671,
      "learning_rate": 9.893145788001244e-06,
      "loss": 0.4045,
      "step": 275
    },
    {
      "epoch": 0.021448554553932235,
      "grad_norm": 0.18236204981803894,
      "learning_rate": 9.892757227230339e-06,
      "loss": 0.154,
      "step": 276
    },
    {
      "epoch": 0.02152626670811315,
      "grad_norm": 0.06538596749305725,
      "learning_rate": 9.892368666459436e-06,
      "loss": 0.0763,
      "step": 277
    },
    {
      "epoch": 0.021603978862294062,
      "grad_norm": 0.1582062691450119,
      "learning_rate": 9.89198010568853e-06,
      "loss": 0.0902,
      "step": 278
    },
    {
      "epoch": 0.021681691016474977,
      "grad_norm": 0.38574185967445374,
      "learning_rate": 9.891591544917626e-06,
      "loss": 0.3874,
      "step": 279
    },
    {
      "epoch": 0.021759403170655892,
      "grad_norm": 0.3028804063796997,
      "learning_rate": 9.891202984146722e-06,
      "loss": 0.5979,
      "step": 280
    },
    {
      "epoch": 0.021837115324836804,
      "grad_norm": 0.09570923447608948,
      "learning_rate": 9.890814423375816e-06,
      "loss": 0.053,
      "step": 281
    },
    {
      "epoch": 0.02191482747901772,
      "grad_norm": 0.2106248289346695,
      "learning_rate": 9.890425862604912e-06,
      "loss": 0.1547,
      "step": 282
    },
    {
      "epoch": 0.02199253963319863,
      "grad_norm": 0.05703400820493698,
      "learning_rate": 9.890037301834007e-06,
      "loss": 0.0639,
      "step": 283
    },
    {
      "epoch": 0.022070251787379546,
      "grad_norm": 0.4601021111011505,
      "learning_rate": 9.889648741063102e-06,
      "loss": 0.3616,
      "step": 284
    },
    {
      "epoch": 0.02214796394156046,
      "grad_norm": 0.14631181955337524,
      "learning_rate": 9.889260180292199e-06,
      "loss": 0.4077,
      "step": 285
    },
    {
      "epoch": 0.022225676095741373,
      "grad_norm": 0.11446675658226013,
      "learning_rate": 9.888871619521294e-06,
      "loss": 0.1727,
      "step": 286
    },
    {
      "epoch": 0.022303388249922288,
      "grad_norm": 0.31378695368766785,
      "learning_rate": 9.888483058750389e-06,
      "loss": 0.1917,
      "step": 287
    },
    {
      "epoch": 0.022381100404103203,
      "grad_norm": 1.2212713956832886,
      "learning_rate": 9.888094497979485e-06,
      "loss": 0.2654,
      "step": 288
    },
    {
      "epoch": 0.022458812558284115,
      "grad_norm": 0.2708561420440674,
      "learning_rate": 9.88770593720858e-06,
      "loss": 0.2224,
      "step": 289
    },
    {
      "epoch": 0.02253652471246503,
      "grad_norm": 0.09674029797315598,
      "learning_rate": 9.887317376437677e-06,
      "loss": 0.077,
      "step": 290
    },
    {
      "epoch": 0.022614236866645942,
      "grad_norm": 0.10427173972129822,
      "learning_rate": 9.88692881566677e-06,
      "loss": 0.0867,
      "step": 291
    },
    {
      "epoch": 0.022691949020826857,
      "grad_norm": 0.18154621124267578,
      "learning_rate": 9.886540254895867e-06,
      "loss": 0.1414,
      "step": 292
    },
    {
      "epoch": 0.022769661175007772,
      "grad_norm": 0.27708160877227783,
      "learning_rate": 9.886151694124962e-06,
      "loss": 0.268,
      "step": 293
    },
    {
      "epoch": 0.022847373329188684,
      "grad_norm": 0.11340215057134628,
      "learning_rate": 9.885763133354057e-06,
      "loss": 0.0346,
      "step": 294
    },
    {
      "epoch": 0.0229250854833696,
      "grad_norm": 0.26766741275787354,
      "learning_rate": 9.885374572583153e-06,
      "loss": 0.2461,
      "step": 295
    },
    {
      "epoch": 0.023002797637550514,
      "grad_norm": 1.321624994277954,
      "learning_rate": 9.884986011812248e-06,
      "loss": 0.4817,
      "step": 296
    },
    {
      "epoch": 0.023080509791731426,
      "grad_norm": 0.28620976209640503,
      "learning_rate": 9.884597451041343e-06,
      "loss": 0.34,
      "step": 297
    },
    {
      "epoch": 0.02315822194591234,
      "grad_norm": 0.09210661053657532,
      "learning_rate": 9.88420889027044e-06,
      "loss": 0.0917,
      "step": 298
    },
    {
      "epoch": 0.023235934100093253,
      "grad_norm": 0.6687570810317993,
      "learning_rate": 9.883820329499535e-06,
      "loss": 0.4219,
      "step": 299
    },
    {
      "epoch": 0.023313646254274168,
      "grad_norm": 0.6302201151847839,
      "learning_rate": 9.88343176872863e-06,
      "loss": 0.4921,
      "step": 300
    },
    {
      "epoch": 0.023391358408455083,
      "grad_norm": 0.3335745930671692,
      "learning_rate": 9.883043207957725e-06,
      "loss": 0.2999,
      "step": 301
    },
    {
      "epoch": 0.023469070562635995,
      "grad_norm": 0.05613398179411888,
      "learning_rate": 9.882654647186821e-06,
      "loss": 0.0196,
      "step": 302
    },
    {
      "epoch": 0.02354678271681691,
      "grad_norm": 0.3024153709411621,
      "learning_rate": 9.882266086415916e-06,
      "loss": 0.3114,
      "step": 303
    },
    {
      "epoch": 0.023624494870997825,
      "grad_norm": 0.1597585380077362,
      "learning_rate": 9.881877525645011e-06,
      "loss": 0.0393,
      "step": 304
    },
    {
      "epoch": 0.023702207025178737,
      "grad_norm": 0.32496240735054016,
      "learning_rate": 9.881488964874108e-06,
      "loss": 0.4504,
      "step": 305
    },
    {
      "epoch": 0.023779919179359652,
      "grad_norm": 0.13402262330055237,
      "learning_rate": 9.881100404103203e-06,
      "loss": 0.1925,
      "step": 306
    },
    {
      "epoch": 0.023857631333540567,
      "grad_norm": 0.38143861293792725,
      "learning_rate": 9.880711843332298e-06,
      "loss": 0.4078,
      "step": 307
    },
    {
      "epoch": 0.02393534348772148,
      "grad_norm": 0.21965962648391724,
      "learning_rate": 9.880323282561394e-06,
      "loss": 0.614,
      "step": 308
    },
    {
      "epoch": 0.024013055641902394,
      "grad_norm": 0.1450093388557434,
      "learning_rate": 9.879934721790488e-06,
      "loss": 0.3002,
      "step": 309
    },
    {
      "epoch": 0.024090767796083306,
      "grad_norm": 0.4589548110961914,
      "learning_rate": 9.879546161019584e-06,
      "loss": 0.3566,
      "step": 310
    },
    {
      "epoch": 0.02416847995026422,
      "grad_norm": 0.2563250958919525,
      "learning_rate": 9.87915760024868e-06,
      "loss": 0.1085,
      "step": 311
    },
    {
      "epoch": 0.024246192104445136,
      "grad_norm": 0.20039935410022736,
      "learning_rate": 9.878769039477774e-06,
      "loss": 0.2952,
      "step": 312
    },
    {
      "epoch": 0.024323904258626048,
      "grad_norm": 0.4704281985759735,
      "learning_rate": 9.878380478706871e-06,
      "loss": 0.6909,
      "step": 313
    },
    {
      "epoch": 0.024401616412806963,
      "grad_norm": 0.034847281873226166,
      "learning_rate": 9.877991917935966e-06,
      "loss": 0.015,
      "step": 314
    },
    {
      "epoch": 0.02447932856698788,
      "grad_norm": 0.23161110281944275,
      "learning_rate": 9.87760335716506e-06,
      "loss": 0.2337,
      "step": 315
    },
    {
      "epoch": 0.02455704072116879,
      "grad_norm": 0.41252487897872925,
      "learning_rate": 9.877214796394157e-06,
      "loss": 0.3744,
      "step": 316
    },
    {
      "epoch": 0.024634752875349705,
      "grad_norm": 0.23575426638126373,
      "learning_rate": 9.876826235623252e-06,
      "loss": 0.4248,
      "step": 317
    },
    {
      "epoch": 0.024712465029530617,
      "grad_norm": 0.22740723192691803,
      "learning_rate": 9.876437674852347e-06,
      "loss": 0.3102,
      "step": 318
    },
    {
      "epoch": 0.024790177183711532,
      "grad_norm": 0.12838660180568695,
      "learning_rate": 9.876049114081442e-06,
      "loss": 0.0756,
      "step": 319
    },
    {
      "epoch": 0.024867889337892447,
      "grad_norm": 0.3632642924785614,
      "learning_rate": 9.875660553310539e-06,
      "loss": 0.7883,
      "step": 320
    },
    {
      "epoch": 0.02494560149207336,
      "grad_norm": 0.07409429550170898,
      "learning_rate": 9.875271992539634e-06,
      "loss": 0.0938,
      "step": 321
    },
    {
      "epoch": 0.025023313646254274,
      "grad_norm": 0.39895856380462646,
      "learning_rate": 9.874883431768729e-06,
      "loss": 0.1073,
      "step": 322
    },
    {
      "epoch": 0.02510102580043519,
      "grad_norm": 0.48617300391197205,
      "learning_rate": 9.874494870997825e-06,
      "loss": 0.3342,
      "step": 323
    },
    {
      "epoch": 0.0251787379546161,
      "grad_norm": 0.46871834993362427,
      "learning_rate": 9.87410631022692e-06,
      "loss": 0.2357,
      "step": 324
    },
    {
      "epoch": 0.025256450108797016,
      "grad_norm": 0.20418967306613922,
      "learning_rate": 9.873717749456015e-06,
      "loss": 0.1476,
      "step": 325
    },
    {
      "epoch": 0.02533416226297793,
      "grad_norm": 0.16786986589431763,
      "learning_rate": 9.873329188685112e-06,
      "loss": 0.3493,
      "step": 326
    },
    {
      "epoch": 0.025411874417158843,
      "grad_norm": 0.1651882827281952,
      "learning_rate": 9.872940627914207e-06,
      "loss": 0.0954,
      "step": 327
    },
    {
      "epoch": 0.02548958657133976,
      "grad_norm": 0.21775996685028076,
      "learning_rate": 9.872552067143302e-06,
      "loss": 0.569,
      "step": 328
    },
    {
      "epoch": 0.02556729872552067,
      "grad_norm": 0.12362334877252579,
      "learning_rate": 9.872163506372397e-06,
      "loss": 0.0989,
      "step": 329
    },
    {
      "epoch": 0.025645010879701585,
      "grad_norm": 0.0658334493637085,
      "learning_rate": 9.871774945601493e-06,
      "loss": 0.0263,
      "step": 330
    },
    {
      "epoch": 0.0257227230338825,
      "grad_norm": 0.05637213587760925,
      "learning_rate": 9.871386384830588e-06,
      "loss": 0.0657,
      "step": 331
    },
    {
      "epoch": 0.025800435188063412,
      "grad_norm": 0.2526310086250305,
      "learning_rate": 9.870997824059683e-06,
      "loss": 0.5363,
      "step": 332
    },
    {
      "epoch": 0.025878147342244327,
      "grad_norm": 0.1992296278476715,
      "learning_rate": 9.87060926328878e-06,
      "loss": 0.2397,
      "step": 333
    },
    {
      "epoch": 0.025955859496425242,
      "grad_norm": 0.14279887080192566,
      "learning_rate": 9.870220702517875e-06,
      "loss": 0.0527,
      "step": 334
    },
    {
      "epoch": 0.026033571650606154,
      "grad_norm": 0.05648783594369888,
      "learning_rate": 9.86983214174697e-06,
      "loss": 0.0305,
      "step": 335
    },
    {
      "epoch": 0.02611128380478707,
      "grad_norm": 0.3955810070037842,
      "learning_rate": 9.869443580976067e-06,
      "loss": 0.394,
      "step": 336
    },
    {
      "epoch": 0.02618899595896798,
      "grad_norm": 0.6387127637863159,
      "learning_rate": 9.86905502020516e-06,
      "loss": 0.6386,
      "step": 337
    },
    {
      "epoch": 0.026266708113148896,
      "grad_norm": 0.21107739210128784,
      "learning_rate": 9.868666459434256e-06,
      "loss": 0.226,
      "step": 338
    },
    {
      "epoch": 0.02634442026732981,
      "grad_norm": 0.19884677231311798,
      "learning_rate": 9.868277898663351e-06,
      "loss": 0.156,
      "step": 339
    },
    {
      "epoch": 0.026422132421510723,
      "grad_norm": 0.17536379396915436,
      "learning_rate": 9.867889337892446e-06,
      "loss": 0.129,
      "step": 340
    },
    {
      "epoch": 0.02649984457569164,
      "grad_norm": 0.0964314267039299,
      "learning_rate": 9.867500777121543e-06,
      "loss": 0.0459,
      "step": 341
    },
    {
      "epoch": 0.026577556729872553,
      "grad_norm": 0.24546243250370026,
      "learning_rate": 9.867112216350638e-06,
      "loss": 0.1117,
      "step": 342
    },
    {
      "epoch": 0.026655268884053465,
      "grad_norm": 1.0294803380966187,
      "learning_rate": 9.866723655579733e-06,
      "loss": 0.7121,
      "step": 343
    },
    {
      "epoch": 0.02673298103823438,
      "grad_norm": 0.05092126131057739,
      "learning_rate": 9.86633509480883e-06,
      "loss": 0.0181,
      "step": 344
    },
    {
      "epoch": 0.026810693192415292,
      "grad_norm": 0.14364111423492432,
      "learning_rate": 9.865946534037925e-06,
      "loss": 0.1242,
      "step": 345
    },
    {
      "epoch": 0.026888405346596207,
      "grad_norm": 0.06502986699342728,
      "learning_rate": 9.86555797326702e-06,
      "loss": 0.0357,
      "step": 346
    },
    {
      "epoch": 0.026966117500777122,
      "grad_norm": 0.18938688933849335,
      "learning_rate": 9.865169412496114e-06,
      "loss": 0.3568,
      "step": 347
    },
    {
      "epoch": 0.027043829654958034,
      "grad_norm": 0.1288590431213379,
      "learning_rate": 9.864780851725211e-06,
      "loss": 0.0464,
      "step": 348
    },
    {
      "epoch": 0.02712154180913895,
      "grad_norm": 0.44261860847473145,
      "learning_rate": 9.864392290954306e-06,
      "loss": 0.193,
      "step": 349
    },
    {
      "epoch": 0.027199253963319864,
      "grad_norm": 0.17483019828796387,
      "learning_rate": 9.864003730183401e-06,
      "loss": 0.7706,
      "step": 350
    },
    {
      "epoch": 0.027276966117500776,
      "grad_norm": 0.2274535745382309,
      "learning_rate": 9.863615169412498e-06,
      "loss": 0.2592,
      "step": 351
    },
    {
      "epoch": 0.02735467827168169,
      "grad_norm": 0.009881840087473392,
      "learning_rate": 9.863226608641593e-06,
      "loss": 0.0021,
      "step": 352
    },
    {
      "epoch": 0.027432390425862607,
      "grad_norm": 0.2672121226787567,
      "learning_rate": 9.862838047870687e-06,
      "loss": 0.2935,
      "step": 353
    },
    {
      "epoch": 0.027510102580043518,
      "grad_norm": 0.14527662098407745,
      "learning_rate": 9.862449487099784e-06,
      "loss": 0.0771,
      "step": 354
    },
    {
      "epoch": 0.027587814734224433,
      "grad_norm": 0.09194346517324448,
      "learning_rate": 9.862060926328879e-06,
      "loss": 0.1145,
      "step": 355
    },
    {
      "epoch": 0.027665526888405345,
      "grad_norm": 0.296878844499588,
      "learning_rate": 9.861672365557974e-06,
      "loss": 0.318,
      "step": 356
    },
    {
      "epoch": 0.02774323904258626,
      "grad_norm": 0.16171248257160187,
      "learning_rate": 9.861283804787069e-06,
      "loss": 0.1429,
      "step": 357
    },
    {
      "epoch": 0.027820951196767175,
      "grad_norm": 0.11260483413934708,
      "learning_rate": 9.860895244016166e-06,
      "loss": 0.1477,
      "step": 358
    },
    {
      "epoch": 0.027898663350948087,
      "grad_norm": 0.08253724873065948,
      "learning_rate": 9.86050668324526e-06,
      "loss": 0.1263,
      "step": 359
    },
    {
      "epoch": 0.027976375505129002,
      "grad_norm": 0.15323549509048462,
      "learning_rate": 9.860118122474356e-06,
      "loss": 0.0663,
      "step": 360
    },
    {
      "epoch": 0.028054087659309918,
      "grad_norm": 0.1373187154531479,
      "learning_rate": 9.859729561703452e-06,
      "loss": 0.0673,
      "step": 361
    },
    {
      "epoch": 0.02813179981349083,
      "grad_norm": 0.3224591314792633,
      "learning_rate": 9.859341000932547e-06,
      "loss": 0.5089,
      "step": 362
    },
    {
      "epoch": 0.028209511967671744,
      "grad_norm": 0.6655696034431458,
      "learning_rate": 9.858952440161642e-06,
      "loss": 2.2745,
      "step": 363
    },
    {
      "epoch": 0.028287224121852656,
      "grad_norm": 0.08349884301424026,
      "learning_rate": 9.858563879390739e-06,
      "loss": 0.0262,
      "step": 364
    },
    {
      "epoch": 0.02836493627603357,
      "grad_norm": 0.1990043967962265,
      "learning_rate": 9.858175318619832e-06,
      "loss": 0.1552,
      "step": 365
    },
    {
      "epoch": 0.028442648430214486,
      "grad_norm": 0.4982219636440277,
      "learning_rate": 9.857786757848929e-06,
      "loss": 0.2233,
      "step": 366
    },
    {
      "epoch": 0.028520360584395398,
      "grad_norm": 0.14749297499656677,
      "learning_rate": 9.857398197078024e-06,
      "loss": 0.1882,
      "step": 367
    },
    {
      "epoch": 0.028598072738576313,
      "grad_norm": 0.0739552453160286,
      "learning_rate": 9.857009636307119e-06,
      "loss": 0.0272,
      "step": 368
    },
    {
      "epoch": 0.02867578489275723,
      "grad_norm": 0.20688313245773315,
      "learning_rate": 9.856621075536215e-06,
      "loss": 0.111,
      "step": 369
    },
    {
      "epoch": 0.02875349704693814,
      "grad_norm": 0.1375185251235962,
      "learning_rate": 9.85623251476531e-06,
      "loss": 0.0711,
      "step": 370
    },
    {
      "epoch": 0.028831209201119055,
      "grad_norm": 0.7717638611793518,
      "learning_rate": 9.855843953994405e-06,
      "loss": 0.5994,
      "step": 371
    },
    {
      "epoch": 0.02890892135529997,
      "grad_norm": 0.20425748825073242,
      "learning_rate": 9.855455393223502e-06,
      "loss": 0.1989,
      "step": 372
    },
    {
      "epoch": 0.028986633509480882,
      "grad_norm": 0.03297382965683937,
      "learning_rate": 9.855066832452597e-06,
      "loss": 0.0121,
      "step": 373
    },
    {
      "epoch": 0.029064345663661798,
      "grad_norm": 0.2631717026233673,
      "learning_rate": 9.854678271681692e-06,
      "loss": 0.227,
      "step": 374
    },
    {
      "epoch": 0.02914205781784271,
      "grad_norm": 0.2342657446861267,
      "learning_rate": 9.854289710910787e-06,
      "loss": 0.1316,
      "step": 375
    },
    {
      "epoch": 0.029219769972023624,
      "grad_norm": 0.20466402173042297,
      "learning_rate": 9.853901150139883e-06,
      "loss": 0.1831,
      "step": 376
    },
    {
      "epoch": 0.02929748212620454,
      "grad_norm": 0.06415842473506927,
      "learning_rate": 9.853512589368978e-06,
      "loss": 0.0425,
      "step": 377
    },
    {
      "epoch": 0.02937519428038545,
      "grad_norm": 0.37743330001831055,
      "learning_rate": 9.853124028598073e-06,
      "loss": 0.5999,
      "step": 378
    },
    {
      "epoch": 0.029452906434566366,
      "grad_norm": 0.2122478038072586,
      "learning_rate": 9.85273546782717e-06,
      "loss": 0.146,
      "step": 379
    },
    {
      "epoch": 0.02953061858874728,
      "grad_norm": 0.808914840221405,
      "learning_rate": 9.852346907056265e-06,
      "loss": 0.6882,
      "step": 380
    },
    {
      "epoch": 0.029608330742928193,
      "grad_norm": 0.5018517374992371,
      "learning_rate": 9.85195834628536e-06,
      "loss": 0.2307,
      "step": 381
    },
    {
      "epoch": 0.02968604289710911,
      "grad_norm": 0.1309652030467987,
      "learning_rate": 9.851569785514455e-06,
      "loss": 0.2352,
      "step": 382
    },
    {
      "epoch": 0.02976375505129002,
      "grad_norm": 0.28828492760658264,
      "learning_rate": 9.851181224743551e-06,
      "loss": 0.1447,
      "step": 383
    },
    {
      "epoch": 0.029841467205470935,
      "grad_norm": 0.5994514226913452,
      "learning_rate": 9.850792663972646e-06,
      "loss": 0.3917,
      "step": 384
    },
    {
      "epoch": 0.02991917935965185,
      "grad_norm": 0.015497772954404354,
      "learning_rate": 9.850404103201741e-06,
      "loss": 0.0077,
      "step": 385
    },
    {
      "epoch": 0.029996891513832762,
      "grad_norm": 0.47288405895233154,
      "learning_rate": 9.850015542430838e-06,
      "loss": 0.4468,
      "step": 386
    },
    {
      "epoch": 0.030074603668013677,
      "grad_norm": 0.347165584564209,
      "learning_rate": 9.849626981659933e-06,
      "loss": 0.5486,
      "step": 387
    },
    {
      "epoch": 0.030152315822194593,
      "grad_norm": 0.18266835808753967,
      "learning_rate": 9.849238420889028e-06,
      "loss": 0.0928,
      "step": 388
    },
    {
      "epoch": 0.030230027976375504,
      "grad_norm": 0.3159070611000061,
      "learning_rate": 9.848849860118124e-06,
      "loss": 0.085,
      "step": 389
    },
    {
      "epoch": 0.03030774013055642,
      "grad_norm": 0.10723557323217392,
      "learning_rate": 9.848461299347218e-06,
      "loss": 0.0637,
      "step": 390
    },
    {
      "epoch": 0.03038545228473733,
      "grad_norm": 0.03535984829068184,
      "learning_rate": 9.848072738576314e-06,
      "loss": 0.0177,
      "step": 391
    },
    {
      "epoch": 0.030463164438918246,
      "grad_norm": 0.26017895340919495,
      "learning_rate": 9.84768417780541e-06,
      "loss": 0.1126,
      "step": 392
    },
    {
      "epoch": 0.03054087659309916,
      "grad_norm": 0.8900088667869568,
      "learning_rate": 9.847295617034504e-06,
      "loss": 0.1948,
      "step": 393
    },
    {
      "epoch": 0.030618588747280073,
      "grad_norm": 0.08345896005630493,
      "learning_rate": 9.8469070562636e-06,
      "loss": 0.0308,
      "step": 394
    },
    {
      "epoch": 0.03069630090146099,
      "grad_norm": 0.6536670327186584,
      "learning_rate": 9.846518495492696e-06,
      "loss": 0.594,
      "step": 395
    },
    {
      "epoch": 0.030774013055641904,
      "grad_norm": 0.3174552619457245,
      "learning_rate": 9.84612993472179e-06,
      "loss": 0.2493,
      "step": 396
    },
    {
      "epoch": 0.030851725209822815,
      "grad_norm": 0.3552177846431732,
      "learning_rate": 9.845741373950887e-06,
      "loss": 0.1446,
      "step": 397
    },
    {
      "epoch": 0.03092943736400373,
      "grad_norm": 0.1704886108636856,
      "learning_rate": 9.845352813179982e-06,
      "loss": 0.429,
      "step": 398
    },
    {
      "epoch": 0.031007149518184646,
      "grad_norm": 0.1922927349805832,
      "learning_rate": 9.844964252409077e-06,
      "loss": 0.2718,
      "step": 399
    },
    {
      "epoch": 0.031084861672365557,
      "grad_norm": 0.21687300503253937,
      "learning_rate": 9.844575691638172e-06,
      "loss": 0.0457,
      "step": 400
    },
    {
      "epoch": 0.031162573826546473,
      "grad_norm": 0.24008093774318695,
      "learning_rate": 9.844187130867269e-06,
      "loss": 0.1936,
      "step": 401
    },
    {
      "epoch": 0.031240285980727384,
      "grad_norm": 0.09960883110761642,
      "learning_rate": 9.843798570096364e-06,
      "loss": 0.094,
      "step": 402
    },
    {
      "epoch": 0.0313179981349083,
      "grad_norm": 0.08284728229045868,
      "learning_rate": 9.843410009325459e-06,
      "loss": 0.0167,
      "step": 403
    },
    {
      "epoch": 0.03139571028908921,
      "grad_norm": 0.09004189819097519,
      "learning_rate": 9.843021448554555e-06,
      "loss": 0.0607,
      "step": 404
    },
    {
      "epoch": 0.03147342244327013,
      "grad_norm": 0.2743859887123108,
      "learning_rate": 9.84263288778365e-06,
      "loss": 0.1623,
      "step": 405
    },
    {
      "epoch": 0.03155113459745104,
      "grad_norm": 0.25708484649658203,
      "learning_rate": 9.842244327012745e-06,
      "loss": 0.4988,
      "step": 406
    },
    {
      "epoch": 0.03162884675163195,
      "grad_norm": 0.15106865763664246,
      "learning_rate": 9.841855766241842e-06,
      "loss": 0.1078,
      "step": 407
    },
    {
      "epoch": 0.03170655890581287,
      "grad_norm": 0.20681127905845642,
      "learning_rate": 9.841467205470935e-06,
      "loss": 0.0636,
      "step": 408
    },
    {
      "epoch": 0.031784271059993784,
      "grad_norm": 0.34193524718284607,
      "learning_rate": 9.841078644700032e-06,
      "loss": 0.4019,
      "step": 409
    },
    {
      "epoch": 0.031861983214174695,
      "grad_norm": 0.27498459815979004,
      "learning_rate": 9.840690083929127e-06,
      "loss": 0.1723,
      "step": 410
    },
    {
      "epoch": 0.031939695368355614,
      "grad_norm": 0.08317834883928299,
      "learning_rate": 9.840301523158223e-06,
      "loss": 0.0786,
      "step": 411
    },
    {
      "epoch": 0.032017407522536526,
      "grad_norm": 0.18037836253643036,
      "learning_rate": 9.839912962387318e-06,
      "loss": 0.2136,
      "step": 412
    },
    {
      "epoch": 0.03209511967671744,
      "grad_norm": 0.14045466482639313,
      "learning_rate": 9.839524401616413e-06,
      "loss": 0.124,
      "step": 413
    },
    {
      "epoch": 0.03217283183089835,
      "grad_norm": 0.21945694088935852,
      "learning_rate": 9.83913584084551e-06,
      "loss": 0.4853,
      "step": 414
    },
    {
      "epoch": 0.03225054398507927,
      "grad_norm": 0.2613902986049652,
      "learning_rate": 9.838747280074605e-06,
      "loss": 0.2059,
      "step": 415
    },
    {
      "epoch": 0.03232825613926018,
      "grad_norm": 0.16161657869815826,
      "learning_rate": 9.8383587193037e-06,
      "loss": 0.2682,
      "step": 416
    },
    {
      "epoch": 0.03240596829344109,
      "grad_norm": 0.1580953449010849,
      "learning_rate": 9.837970158532796e-06,
      "loss": 0.0764,
      "step": 417
    },
    {
      "epoch": 0.03248368044762201,
      "grad_norm": 0.1667596846818924,
      "learning_rate": 9.83758159776189e-06,
      "loss": 0.1898,
      "step": 418
    },
    {
      "epoch": 0.03256139260180292,
      "grad_norm": 0.35117289423942566,
      "learning_rate": 9.837193036990986e-06,
      "loss": 0.3779,
      "step": 419
    },
    {
      "epoch": 0.03263910475598383,
      "grad_norm": 0.08418571949005127,
      "learning_rate": 9.836804476220081e-06,
      "loss": 0.1212,
      "step": 420
    },
    {
      "epoch": 0.03271681691016475,
      "grad_norm": 0.1685718148946762,
      "learning_rate": 9.836415915449176e-06,
      "loss": 0.1901,
      "step": 421
    },
    {
      "epoch": 0.032794529064345664,
      "grad_norm": 0.12777158617973328,
      "learning_rate": 9.836027354678273e-06,
      "loss": 0.0804,
      "step": 422
    },
    {
      "epoch": 0.032872241218526575,
      "grad_norm": 0.1535557508468628,
      "learning_rate": 9.835638793907368e-06,
      "loss": 0.0651,
      "step": 423
    },
    {
      "epoch": 0.032949953372707494,
      "grad_norm": 0.16288118064403534,
      "learning_rate": 9.835250233136463e-06,
      "loss": 0.0817,
      "step": 424
    },
    {
      "epoch": 0.033027665526888406,
      "grad_norm": 0.17720454931259155,
      "learning_rate": 9.83486167236556e-06,
      "loss": 0.1527,
      "step": 425
    },
    {
      "epoch": 0.03310537768106932,
      "grad_norm": 0.2867257297039032,
      "learning_rate": 9.834473111594654e-06,
      "loss": 0.1933,
      "step": 426
    },
    {
      "epoch": 0.033183089835250236,
      "grad_norm": 0.2369541972875595,
      "learning_rate": 9.83408455082375e-06,
      "loss": 0.2692,
      "step": 427
    },
    {
      "epoch": 0.03326080198943115,
      "grad_norm": 0.47261878848075867,
      "learning_rate": 9.833695990052844e-06,
      "loss": 0.1165,
      "step": 428
    },
    {
      "epoch": 0.03333851414361206,
      "grad_norm": 0.277336448431015,
      "learning_rate": 9.833307429281941e-06,
      "loss": 0.2369,
      "step": 429
    },
    {
      "epoch": 0.03341622629779298,
      "grad_norm": 0.12475185841321945,
      "learning_rate": 9.832918868511036e-06,
      "loss": 0.0487,
      "step": 430
    },
    {
      "epoch": 0.03349393845197389,
      "grad_norm": 0.15530189871788025,
      "learning_rate": 9.832530307740131e-06,
      "loss": 0.1574,
      "step": 431
    },
    {
      "epoch": 0.0335716506061548,
      "grad_norm": 0.07632549107074738,
      "learning_rate": 9.832141746969227e-06,
      "loss": 0.1,
      "step": 432
    },
    {
      "epoch": 0.03364936276033571,
      "grad_norm": 0.1526554524898529,
      "learning_rate": 9.831753186198322e-06,
      "loss": 0.2605,
      "step": 433
    },
    {
      "epoch": 0.03372707491451663,
      "grad_norm": 0.048579905182123184,
      "learning_rate": 9.831364625427417e-06,
      "loss": 0.0172,
      "step": 434
    },
    {
      "epoch": 0.033804787068697544,
      "grad_norm": 0.21594761312007904,
      "learning_rate": 9.830976064656514e-06,
      "loss": 0.1402,
      "step": 435
    },
    {
      "epoch": 0.033882499222878455,
      "grad_norm": 0.3223609924316406,
      "learning_rate": 9.830587503885607e-06,
      "loss": 0.371,
      "step": 436
    },
    {
      "epoch": 0.033960211377059374,
      "grad_norm": 0.27666497230529785,
      "learning_rate": 9.830198943114704e-06,
      "loss": 0.2245,
      "step": 437
    },
    {
      "epoch": 0.034037923531240286,
      "grad_norm": 0.112143374979496,
      "learning_rate": 9.829810382343799e-06,
      "loss": 0.0502,
      "step": 438
    },
    {
      "epoch": 0.0341156356854212,
      "grad_norm": 0.13922032713890076,
      "learning_rate": 9.829421821572894e-06,
      "loss": 0.2211,
      "step": 439
    },
    {
      "epoch": 0.034193347839602116,
      "grad_norm": 0.10826369374990463,
      "learning_rate": 9.82903326080199e-06,
      "loss": 0.0549,
      "step": 440
    },
    {
      "epoch": 0.03427105999378303,
      "grad_norm": 0.18336868286132812,
      "learning_rate": 9.828644700031085e-06,
      "loss": 0.1527,
      "step": 441
    },
    {
      "epoch": 0.03434877214796394,
      "grad_norm": 0.1309441477060318,
      "learning_rate": 9.828256139260182e-06,
      "loss": 0.12,
      "step": 442
    },
    {
      "epoch": 0.03442648430214486,
      "grad_norm": 0.4381161034107208,
      "learning_rate": 9.827867578489277e-06,
      "loss": 0.348,
      "step": 443
    },
    {
      "epoch": 0.03450419645632577,
      "grad_norm": 0.21476565301418304,
      "learning_rate": 9.827479017718372e-06,
      "loss": 0.3665,
      "step": 444
    },
    {
      "epoch": 0.03458190861050668,
      "grad_norm": 0.26736053824424744,
      "learning_rate": 9.827090456947469e-06,
      "loss": 0.3098,
      "step": 445
    },
    {
      "epoch": 0.0346596207646876,
      "grad_norm": 0.10147804766893387,
      "learning_rate": 9.826701896176562e-06,
      "loss": 0.0446,
      "step": 446
    },
    {
      "epoch": 0.03473733291886851,
      "grad_norm": 0.31998589634895325,
      "learning_rate": 9.826313335405659e-06,
      "loss": 0.3406,
      "step": 447
    },
    {
      "epoch": 0.034815045073049423,
      "grad_norm": 0.239583820104599,
      "learning_rate": 9.825924774634753e-06,
      "loss": 0.1347,
      "step": 448
    },
    {
      "epoch": 0.03489275722723034,
      "grad_norm": 0.058679886162281036,
      "learning_rate": 9.825536213863848e-06,
      "loss": 0.051,
      "step": 449
    },
    {
      "epoch": 0.034970469381411254,
      "grad_norm": 0.0876389741897583,
      "learning_rate": 9.825147653092945e-06,
      "loss": 0.0215,
      "step": 450
    },
    {
      "epoch": 0.035048181535592166,
      "grad_norm": 0.09790652990341187,
      "learning_rate": 9.82475909232204e-06,
      "loss": 0.1175,
      "step": 451
    },
    {
      "epoch": 0.03512589368977308,
      "grad_norm": 0.28513872623443604,
      "learning_rate": 9.824370531551135e-06,
      "loss": 0.2047,
      "step": 452
    },
    {
      "epoch": 0.035203605843953996,
      "grad_norm": 0.06832098960876465,
      "learning_rate": 9.823981970780232e-06,
      "loss": 0.063,
      "step": 453
    },
    {
      "epoch": 0.03528131799813491,
      "grad_norm": 0.11448107659816742,
      "learning_rate": 9.823593410009327e-06,
      "loss": 0.0966,
      "step": 454
    },
    {
      "epoch": 0.03535903015231582,
      "grad_norm": 0.08753572404384613,
      "learning_rate": 9.823204849238422e-06,
      "loss": 0.0727,
      "step": 455
    },
    {
      "epoch": 0.03543674230649674,
      "grad_norm": 0.21053361892700195,
      "learning_rate": 9.822816288467516e-06,
      "loss": 0.2219,
      "step": 456
    },
    {
      "epoch": 0.03551445446067765,
      "grad_norm": 0.12037412822246552,
      "learning_rate": 9.822427727696613e-06,
      "loss": 0.1029,
      "step": 457
    },
    {
      "epoch": 0.03559216661485856,
      "grad_norm": 0.2363804578781128,
      "learning_rate": 9.822039166925708e-06,
      "loss": 0.1125,
      "step": 458
    },
    {
      "epoch": 0.03566987876903948,
      "grad_norm": 0.5840532183647156,
      "learning_rate": 9.821650606154803e-06,
      "loss": 0.4005,
      "step": 459
    },
    {
      "epoch": 0.03574759092322039,
      "grad_norm": 0.15867005288600922,
      "learning_rate": 9.8212620453839e-06,
      "loss": 0.1832,
      "step": 460
    },
    {
      "epoch": 0.0358253030774013,
      "grad_norm": 0.44134873151779175,
      "learning_rate": 9.820873484612995e-06,
      "loss": 0.2609,
      "step": 461
    },
    {
      "epoch": 0.03590301523158222,
      "grad_norm": 0.18685407936573029,
      "learning_rate": 9.82048492384209e-06,
      "loss": 0.0825,
      "step": 462
    },
    {
      "epoch": 0.035980727385763134,
      "grad_norm": 0.10727149993181229,
      "learning_rate": 9.820096363071186e-06,
      "loss": 0.0504,
      "step": 463
    },
    {
      "epoch": 0.036058439539944045,
      "grad_norm": 0.21573948860168457,
      "learning_rate": 9.81970780230028e-06,
      "loss": 0.1827,
      "step": 464
    },
    {
      "epoch": 0.036136151694124964,
      "grad_norm": 0.1756429821252823,
      "learning_rate": 9.819319241529376e-06,
      "loss": 0.5453,
      "step": 465
    },
    {
      "epoch": 0.036213863848305876,
      "grad_norm": 0.1867145448923111,
      "learning_rate": 9.818930680758471e-06,
      "loss": 0.198,
      "step": 466
    },
    {
      "epoch": 0.03629157600248679,
      "grad_norm": 0.25101980566978455,
      "learning_rate": 9.818542119987566e-06,
      "loss": 0.4444,
      "step": 467
    },
    {
      "epoch": 0.036369288156667706,
      "grad_norm": 0.05181529000401497,
      "learning_rate": 9.818153559216663e-06,
      "loss": 0.0657,
      "step": 468
    },
    {
      "epoch": 0.03644700031084862,
      "grad_norm": 0.20654426515102386,
      "learning_rate": 9.817764998445758e-06,
      "loss": 0.3092,
      "step": 469
    },
    {
      "epoch": 0.03652471246502953,
      "grad_norm": 0.5875721573829651,
      "learning_rate": 9.817376437674853e-06,
      "loss": 0.4111,
      "step": 470
    },
    {
      "epoch": 0.03660242461921044,
      "grad_norm": 0.3224957287311554,
      "learning_rate": 9.81698787690395e-06,
      "loss": 0.5024,
      "step": 471
    },
    {
      "epoch": 0.03668013677339136,
      "grad_norm": 0.1444677859544754,
      "learning_rate": 9.816599316133044e-06,
      "loss": 0.1535,
      "step": 472
    },
    {
      "epoch": 0.03675784892757227,
      "grad_norm": 0.18210282921791077,
      "learning_rate": 9.81621075536214e-06,
      "loss": 0.3771,
      "step": 473
    },
    {
      "epoch": 0.03683556108175318,
      "grad_norm": 0.23166242241859436,
      "learning_rate": 9.815822194591234e-06,
      "loss": 0.1174,
      "step": 474
    },
    {
      "epoch": 0.0369132732359341,
      "grad_norm": 0.23113298416137695,
      "learning_rate": 9.81543363382033e-06,
      "loss": 0.2018,
      "step": 475
    },
    {
      "epoch": 0.036990985390115014,
      "grad_norm": 0.08723851293325424,
      "learning_rate": 9.815045073049426e-06,
      "loss": 0.0398,
      "step": 476
    },
    {
      "epoch": 0.037068697544295925,
      "grad_norm": 0.21943287551403046,
      "learning_rate": 9.81465651227852e-06,
      "loss": 0.1511,
      "step": 477
    },
    {
      "epoch": 0.037146409698476844,
      "grad_norm": 0.55238938331604,
      "learning_rate": 9.814267951507617e-06,
      "loss": 1.0795,
      "step": 478
    },
    {
      "epoch": 0.037224121852657756,
      "grad_norm": 0.28657346963882446,
      "learning_rate": 9.813879390736712e-06,
      "loss": 0.168,
      "step": 479
    },
    {
      "epoch": 0.03730183400683867,
      "grad_norm": 0.1352669596672058,
      "learning_rate": 9.813490829965807e-06,
      "loss": 0.111,
      "step": 480
    },
    {
      "epoch": 0.037379546161019586,
      "grad_norm": 0.11002194881439209,
      "learning_rate": 9.813102269194904e-06,
      "loss": 0.096,
      "step": 481
    },
    {
      "epoch": 0.0374572583152005,
      "grad_norm": 0.3114229142665863,
      "learning_rate": 9.812713708423999e-06,
      "loss": 0.1282,
      "step": 482
    },
    {
      "epoch": 0.03753497046938141,
      "grad_norm": 0.17815154790878296,
      "learning_rate": 9.812325147653094e-06,
      "loss": 0.1657,
      "step": 483
    },
    {
      "epoch": 0.03761268262356233,
      "grad_norm": 0.2257682979106903,
      "learning_rate": 9.811936586882189e-06,
      "loss": 0.1499,
      "step": 484
    },
    {
      "epoch": 0.03769039477774324,
      "grad_norm": 0.2870447337627411,
      "learning_rate": 9.811548026111285e-06,
      "loss": 0.1018,
      "step": 485
    },
    {
      "epoch": 0.03776810693192415,
      "grad_norm": 0.04284437745809555,
      "learning_rate": 9.81115946534038e-06,
      "loss": 0.07,
      "step": 486
    },
    {
      "epoch": 0.03784581908610507,
      "grad_norm": 0.590064287185669,
      "learning_rate": 9.810770904569475e-06,
      "loss": 0.2853,
      "step": 487
    },
    {
      "epoch": 0.03792353124028598,
      "grad_norm": 0.23994873464107513,
      "learning_rate": 9.810382343798572e-06,
      "loss": 0.1877,
      "step": 488
    },
    {
      "epoch": 0.038001243394466894,
      "grad_norm": 0.08288003504276276,
      "learning_rate": 9.809993783027667e-06,
      "loss": 0.0302,
      "step": 489
    },
    {
      "epoch": 0.038078955548647805,
      "grad_norm": 0.28577086329460144,
      "learning_rate": 9.809605222256762e-06,
      "loss": 0.4512,
      "step": 490
    },
    {
      "epoch": 0.038156667702828724,
      "grad_norm": 0.21308384835720062,
      "learning_rate": 9.809216661485858e-06,
      "loss": 0.1348,
      "step": 491
    },
    {
      "epoch": 0.038234379857009636,
      "grad_norm": 0.3216307461261749,
      "learning_rate": 9.808828100714952e-06,
      "loss": 0.4501,
      "step": 492
    },
    {
      "epoch": 0.03831209201119055,
      "grad_norm": 0.09349066764116287,
      "learning_rate": 9.808439539944048e-06,
      "loss": 0.0747,
      "step": 493
    },
    {
      "epoch": 0.038389804165371466,
      "grad_norm": 0.12034210562705994,
      "learning_rate": 9.808050979173143e-06,
      "loss": 0.1335,
      "step": 494
    },
    {
      "epoch": 0.03846751631955238,
      "grad_norm": 0.47796499729156494,
      "learning_rate": 9.807662418402238e-06,
      "loss": 0.2779,
      "step": 495
    },
    {
      "epoch": 0.03854522847373329,
      "grad_norm": 0.20199549198150635,
      "learning_rate": 9.807273857631335e-06,
      "loss": 0.3662,
      "step": 496
    },
    {
      "epoch": 0.03862294062791421,
      "grad_norm": 0.15851151943206787,
      "learning_rate": 9.80688529686043e-06,
      "loss": 0.1234,
      "step": 497
    },
    {
      "epoch": 0.03870065278209512,
      "grad_norm": 0.17559075355529785,
      "learning_rate": 9.806496736089525e-06,
      "loss": 0.6748,
      "step": 498
    },
    {
      "epoch": 0.03877836493627603,
      "grad_norm": 0.4056936502456665,
      "learning_rate": 9.806108175318621e-06,
      "loss": 0.1555,
      "step": 499
    },
    {
      "epoch": 0.03885607709045695,
      "grad_norm": 0.08995974063873291,
      "learning_rate": 9.805719614547716e-06,
      "loss": 0.0187,
      "step": 500
    },
    {
      "epoch": 0.03893378924463786,
      "grad_norm": 0.28856363892555237,
      "learning_rate": 9.805331053776811e-06,
      "loss": 0.2615,
      "step": 501
    },
    {
      "epoch": 0.039011501398818774,
      "grad_norm": 0.09182102233171463,
      "learning_rate": 9.804942493005906e-06,
      "loss": 0.0312,
      "step": 502
    },
    {
      "epoch": 0.03908921355299969,
      "grad_norm": 0.6343715190887451,
      "learning_rate": 9.804553932235003e-06,
      "loss": 0.356,
      "step": 503
    },
    {
      "epoch": 0.039166925707180604,
      "grad_norm": 0.12550872564315796,
      "learning_rate": 9.804165371464098e-06,
      "loss": 0.0817,
      "step": 504
    },
    {
      "epoch": 0.039244637861361516,
      "grad_norm": 0.4069913327693939,
      "learning_rate": 9.803776810693193e-06,
      "loss": 0.7045,
      "step": 505
    },
    {
      "epoch": 0.03932235001554243,
      "grad_norm": 0.12325815111398697,
      "learning_rate": 9.80338824992229e-06,
      "loss": 0.1244,
      "step": 506
    },
    {
      "epoch": 0.039400062169723346,
      "grad_norm": 0.7826159000396729,
      "learning_rate": 9.802999689151384e-06,
      "loss": 0.4775,
      "step": 507
    },
    {
      "epoch": 0.03947777432390426,
      "grad_norm": 0.11947937309741974,
      "learning_rate": 9.80261112838048e-06,
      "loss": 0.0455,
      "step": 508
    },
    {
      "epoch": 0.03955548647808517,
      "grad_norm": 0.19303067028522491,
      "learning_rate": 9.802222567609574e-06,
      "loss": 0.1241,
      "step": 509
    },
    {
      "epoch": 0.03963319863226609,
      "grad_norm": 0.5998091697692871,
      "learning_rate": 9.80183400683867e-06,
      "loss": 1.0749,
      "step": 510
    },
    {
      "epoch": 0.039710910786447,
      "grad_norm": 0.3398677408695221,
      "learning_rate": 9.801445446067766e-06,
      "loss": 0.1588,
      "step": 511
    },
    {
      "epoch": 0.03978862294062791,
      "grad_norm": 0.11673702299594879,
      "learning_rate": 9.80105688529686e-06,
      "loss": 0.0942,
      "step": 512
    },
    {
      "epoch": 0.03986633509480883,
      "grad_norm": 0.739901065826416,
      "learning_rate": 9.800668324525957e-06,
      "loss": 0.4486,
      "step": 513
    },
    {
      "epoch": 0.03994404724898974,
      "grad_norm": 0.3269282877445221,
      "learning_rate": 9.800279763755052e-06,
      "loss": 0.1973,
      "step": 514
    },
    {
      "epoch": 0.040021759403170654,
      "grad_norm": 0.5204206109046936,
      "learning_rate": 9.799891202984147e-06,
      "loss": 0.246,
      "step": 515
    },
    {
      "epoch": 0.04009947155735157,
      "grad_norm": 0.11900775134563446,
      "learning_rate": 9.799502642213244e-06,
      "loss": 0.0411,
      "step": 516
    },
    {
      "epoch": 0.040177183711532484,
      "grad_norm": 0.11792762577533722,
      "learning_rate": 9.799114081442337e-06,
      "loss": 0.0846,
      "step": 517
    },
    {
      "epoch": 0.040254895865713396,
      "grad_norm": 0.21229338645935059,
      "learning_rate": 9.798725520671434e-06,
      "loss": 0.3306,
      "step": 518
    },
    {
      "epoch": 0.040332608019894314,
      "grad_norm": 0.20147158205509186,
      "learning_rate": 9.798336959900529e-06,
      "loss": 0.1199,
      "step": 519
    },
    {
      "epoch": 0.040410320174075226,
      "grad_norm": 0.042689450085163116,
      "learning_rate": 9.797948399129624e-06,
      "loss": 0.0116,
      "step": 520
    },
    {
      "epoch": 0.04048803232825614,
      "grad_norm": 0.19771625101566315,
      "learning_rate": 9.79755983835872e-06,
      "loss": 0.2217,
      "step": 521
    },
    {
      "epoch": 0.040565744482437056,
      "grad_norm": 0.10383053869009018,
      "learning_rate": 9.797171277587815e-06,
      "loss": 0.3095,
      "step": 522
    },
    {
      "epoch": 0.04064345663661797,
      "grad_norm": 0.12561319768428802,
      "learning_rate": 9.79678271681691e-06,
      "loss": 0.04,
      "step": 523
    },
    {
      "epoch": 0.04072116879079888,
      "grad_norm": 0.14028798043727875,
      "learning_rate": 9.796394156046007e-06,
      "loss": 0.1106,
      "step": 524
    },
    {
      "epoch": 0.04079888094497979,
      "grad_norm": 0.12612226605415344,
      "learning_rate": 9.796005595275102e-06,
      "loss": 0.0735,
      "step": 525
    },
    {
      "epoch": 0.04087659309916071,
      "grad_norm": 0.5364346504211426,
      "learning_rate": 9.795617034504197e-06,
      "loss": 0.4307,
      "step": 526
    },
    {
      "epoch": 0.04095430525334162,
      "grad_norm": 0.315669983625412,
      "learning_rate": 9.795228473733292e-06,
      "loss": 0.5836,
      "step": 527
    },
    {
      "epoch": 0.041032017407522534,
      "grad_norm": 0.24701529741287231,
      "learning_rate": 9.794839912962388e-06,
      "loss": 0.2448,
      "step": 528
    },
    {
      "epoch": 0.04110972956170345,
      "grad_norm": 0.16056232154369354,
      "learning_rate": 9.794451352191483e-06,
      "loss": 0.5256,
      "step": 529
    },
    {
      "epoch": 0.041187441715884364,
      "grad_norm": 0.10094534605741501,
      "learning_rate": 9.794062791420578e-06,
      "loss": 0.0413,
      "step": 530
    },
    {
      "epoch": 0.041265153870065276,
      "grad_norm": 0.4455731213092804,
      "learning_rate": 9.793674230649675e-06,
      "loss": 0.7056,
      "step": 531
    },
    {
      "epoch": 0.041342866024246194,
      "grad_norm": 0.20368751883506775,
      "learning_rate": 9.79328566987877e-06,
      "loss": 0.2246,
      "step": 532
    },
    {
      "epoch": 0.041420578178427106,
      "grad_norm": 0.25451377034187317,
      "learning_rate": 9.792897109107865e-06,
      "loss": 0.3256,
      "step": 533
    },
    {
      "epoch": 0.04149829033260802,
      "grad_norm": 0.31752845644950867,
      "learning_rate": 9.792508548336961e-06,
      "loss": 0.1704,
      "step": 534
    },
    {
      "epoch": 0.041576002486788936,
      "grad_norm": 0.08900267630815506,
      "learning_rate": 9.792119987566056e-06,
      "loss": 0.1156,
      "step": 535
    },
    {
      "epoch": 0.04165371464096985,
      "grad_norm": 0.10375488549470901,
      "learning_rate": 9.791731426795151e-06,
      "loss": 0.204,
      "step": 536
    },
    {
      "epoch": 0.04173142679515076,
      "grad_norm": 0.19303132593631744,
      "learning_rate": 9.791342866024246e-06,
      "loss": 0.1238,
      "step": 537
    },
    {
      "epoch": 0.04180913894933168,
      "grad_norm": 0.39419668912887573,
      "learning_rate": 9.790954305253343e-06,
      "loss": 0.2775,
      "step": 538
    },
    {
      "epoch": 0.04188685110351259,
      "grad_norm": 0.06173829734325409,
      "learning_rate": 9.790565744482438e-06,
      "loss": 0.1268,
      "step": 539
    },
    {
      "epoch": 0.0419645632576935,
      "grad_norm": 0.16990308463573456,
      "learning_rate": 9.790177183711533e-06,
      "loss": 0.0564,
      "step": 540
    },
    {
      "epoch": 0.04204227541187442,
      "grad_norm": 0.20254863798618317,
      "learning_rate": 9.78978862294063e-06,
      "loss": 0.3092,
      "step": 541
    },
    {
      "epoch": 0.04211998756605533,
      "grad_norm": 0.2281845360994339,
      "learning_rate": 9.789400062169724e-06,
      "loss": 0.1492,
      "step": 542
    },
    {
      "epoch": 0.042197699720236244,
      "grad_norm": 0.2579488754272461,
      "learning_rate": 9.78901150139882e-06,
      "loss": 0.4727,
      "step": 543
    },
    {
      "epoch": 0.042275411874417156,
      "grad_norm": 0.20418858528137207,
      "learning_rate": 9.788622940627916e-06,
      "loss": 0.1975,
      "step": 544
    },
    {
      "epoch": 0.042353124028598074,
      "grad_norm": 0.18290072679519653,
      "learning_rate": 9.78823437985701e-06,
      "loss": 0.219,
      "step": 545
    },
    {
      "epoch": 0.042430836182778986,
      "grad_norm": 0.10548646748065948,
      "learning_rate": 9.787845819086106e-06,
      "loss": 0.0835,
      "step": 546
    },
    {
      "epoch": 0.0425085483369599,
      "grad_norm": 0.27761581540107727,
      "learning_rate": 9.787457258315201e-06,
      "loss": 0.2808,
      "step": 547
    },
    {
      "epoch": 0.042586260491140816,
      "grad_norm": 0.49712327122688293,
      "learning_rate": 9.787068697544296e-06,
      "loss": 0.8639,
      "step": 548
    },
    {
      "epoch": 0.04266397264532173,
      "grad_norm": 0.22206978499889374,
      "learning_rate": 9.786680136773393e-06,
      "loss": 0.2568,
      "step": 549
    },
    {
      "epoch": 0.04274168479950264,
      "grad_norm": 0.34361112117767334,
      "learning_rate": 9.786291576002487e-06,
      "loss": 0.1355,
      "step": 550
    },
    {
      "epoch": 0.04281939695368356,
      "grad_norm": 0.2273918241262436,
      "learning_rate": 9.785903015231582e-06,
      "loss": 0.4509,
      "step": 551
    },
    {
      "epoch": 0.04289710910786447,
      "grad_norm": 0.20828987658023834,
      "learning_rate": 9.785514454460679e-06,
      "loss": 0.2226,
      "step": 552
    },
    {
      "epoch": 0.04297482126204538,
      "grad_norm": 0.08664388954639435,
      "learning_rate": 9.785125893689774e-06,
      "loss": 0.1124,
      "step": 553
    },
    {
      "epoch": 0.0430525334162263,
      "grad_norm": 0.1823466718196869,
      "learning_rate": 9.784737332918869e-06,
      "loss": 0.1759,
      "step": 554
    },
    {
      "epoch": 0.04313024557040721,
      "grad_norm": 0.1331000179052353,
      "learning_rate": 9.784348772147964e-06,
      "loss": 0.0857,
      "step": 555
    },
    {
      "epoch": 0.043207957724588124,
      "grad_norm": 0.07938078790903091,
      "learning_rate": 9.78396021137706e-06,
      "loss": 0.1657,
      "step": 556
    },
    {
      "epoch": 0.04328566987876904,
      "grad_norm": 0.2351883202791214,
      "learning_rate": 9.783571650606156e-06,
      "loss": 0.0879,
      "step": 557
    },
    {
      "epoch": 0.043363382032949954,
      "grad_norm": 0.16099777817726135,
      "learning_rate": 9.78318308983525e-06,
      "loss": 0.0895,
      "step": 558
    },
    {
      "epoch": 0.043441094187130866,
      "grad_norm": 0.2716922461986542,
      "learning_rate": 9.782794529064347e-06,
      "loss": 0.4229,
      "step": 559
    },
    {
      "epoch": 0.043518806341311785,
      "grad_norm": 0.17350247502326965,
      "learning_rate": 9.782405968293442e-06,
      "loss": 0.2151,
      "step": 560
    },
    {
      "epoch": 0.043596518495492696,
      "grad_norm": 0.16330043971538544,
      "learning_rate": 9.782017407522537e-06,
      "loss": 0.1535,
      "step": 561
    },
    {
      "epoch": 0.04367423064967361,
      "grad_norm": 0.49594712257385254,
      "learning_rate": 9.781628846751634e-06,
      "loss": 0.4993,
      "step": 562
    },
    {
      "epoch": 0.04375194280385452,
      "grad_norm": 0.11257417500019073,
      "learning_rate": 9.781240285980729e-06,
      "loss": 0.1045,
      "step": 563
    },
    {
      "epoch": 0.04382965495803544,
      "grad_norm": 0.14176663756370544,
      "learning_rate": 9.780851725209824e-06,
      "loss": 0.0765,
      "step": 564
    },
    {
      "epoch": 0.04390736711221635,
      "grad_norm": 0.4372263252735138,
      "learning_rate": 9.780463164438918e-06,
      "loss": 0.3383,
      "step": 565
    },
    {
      "epoch": 0.04398507926639726,
      "grad_norm": 0.30640679597854614,
      "learning_rate": 9.780074603668015e-06,
      "loss": 0.5429,
      "step": 566
    },
    {
      "epoch": 0.04406279142057818,
      "grad_norm": 0.12338866293430328,
      "learning_rate": 9.77968604289711e-06,
      "loss": 0.1498,
      "step": 567
    },
    {
      "epoch": 0.04414050357475909,
      "grad_norm": 0.18342922627925873,
      "learning_rate": 9.779297482126205e-06,
      "loss": 0.1262,
      "step": 568
    },
    {
      "epoch": 0.044218215728940004,
      "grad_norm": 0.30646243691444397,
      "learning_rate": 9.778908921355302e-06,
      "loss": 0.0774,
      "step": 569
    },
    {
      "epoch": 0.04429592788312092,
      "grad_norm": 0.4514845311641693,
      "learning_rate": 9.778520360584397e-06,
      "loss": 0.6078,
      "step": 570
    },
    {
      "epoch": 0.044373640037301834,
      "grad_norm": 0.5410376191139221,
      "learning_rate": 9.778131799813492e-06,
      "loss": 0.3586,
      "step": 571
    },
    {
      "epoch": 0.044451352191482746,
      "grad_norm": 0.5123199820518494,
      "learning_rate": 9.777743239042588e-06,
      "loss": 0.4342,
      "step": 572
    },
    {
      "epoch": 0.044529064345663665,
      "grad_norm": 0.45562952756881714,
      "learning_rate": 9.777354678271681e-06,
      "loss": 0.5622,
      "step": 573
    },
    {
      "epoch": 0.044606776499844576,
      "grad_norm": 0.7252792716026306,
      "learning_rate": 9.776966117500778e-06,
      "loss": 0.8746,
      "step": 574
    },
    {
      "epoch": 0.04468448865402549,
      "grad_norm": 0.6745438575744629,
      "learning_rate": 9.776577556729873e-06,
      "loss": 0.606,
      "step": 575
    },
    {
      "epoch": 0.04476220080820641,
      "grad_norm": 0.12045750766992569,
      "learning_rate": 9.776188995958968e-06,
      "loss": 0.06,
      "step": 576
    },
    {
      "epoch": 0.04483991296238732,
      "grad_norm": 0.28240805864334106,
      "learning_rate": 9.775800435188065e-06,
      "loss": 0.2367,
      "step": 577
    },
    {
      "epoch": 0.04491762511656823,
      "grad_norm": 0.1608758419752121,
      "learning_rate": 9.77541187441716e-06,
      "loss": 0.1397,
      "step": 578
    },
    {
      "epoch": 0.04499533727074915,
      "grad_norm": 0.2471625953912735,
      "learning_rate": 9.775023313646255e-06,
      "loss": 0.24,
      "step": 579
    },
    {
      "epoch": 0.04507304942493006,
      "grad_norm": 0.1184525340795517,
      "learning_rate": 9.774634752875351e-06,
      "loss": 0.0914,
      "step": 580
    },
    {
      "epoch": 0.04515076157911097,
      "grad_norm": 0.25708574056625366,
      "learning_rate": 9.774246192104446e-06,
      "loss": 0.2047,
      "step": 581
    },
    {
      "epoch": 0.045228473733291884,
      "grad_norm": 0.037319477647542953,
      "learning_rate": 9.773857631333541e-06,
      "loss": 0.0281,
      "step": 582
    },
    {
      "epoch": 0.0453061858874728,
      "grad_norm": 0.21524518728256226,
      "learning_rate": 9.773469070562636e-06,
      "loss": 0.2604,
      "step": 583
    },
    {
      "epoch": 0.045383898041653714,
      "grad_norm": 0.3626478612422943,
      "learning_rate": 9.773080509791733e-06,
      "loss": 0.7208,
      "step": 584
    },
    {
      "epoch": 0.045461610195834626,
      "grad_norm": 0.438870906829834,
      "learning_rate": 9.772691949020828e-06,
      "loss": 0.5436,
      "step": 585
    },
    {
      "epoch": 0.045539322350015544,
      "grad_norm": 0.3217775225639343,
      "learning_rate": 9.772303388249923e-06,
      "loss": 0.2492,
      "step": 586
    },
    {
      "epoch": 0.045617034504196456,
      "grad_norm": 0.20439912378787994,
      "learning_rate": 9.77191482747902e-06,
      "loss": 0.2723,
      "step": 587
    },
    {
      "epoch": 0.04569474665837737,
      "grad_norm": 0.28372645378112793,
      "learning_rate": 9.771526266708114e-06,
      "loss": 0.0988,
      "step": 588
    },
    {
      "epoch": 0.045772458812558287,
      "grad_norm": 0.3053094148635864,
      "learning_rate": 9.771137705937209e-06,
      "loss": 0.7358,
      "step": 589
    },
    {
      "epoch": 0.0458501709667392,
      "grad_norm": 0.2938595712184906,
      "learning_rate": 9.770749145166306e-06,
      "loss": 0.408,
      "step": 590
    },
    {
      "epoch": 0.04592788312092011,
      "grad_norm": 0.14603376388549805,
      "learning_rate": 9.770360584395399e-06,
      "loss": 0.0307,
      "step": 591
    },
    {
      "epoch": 0.04600559527510103,
      "grad_norm": 0.13711968064308167,
      "learning_rate": 9.769972023624496e-06,
      "loss": 0.1113,
      "step": 592
    },
    {
      "epoch": 0.04608330742928194,
      "grad_norm": 0.10637202113866806,
      "learning_rate": 9.76958346285359e-06,
      "loss": 0.0394,
      "step": 593
    },
    {
      "epoch": 0.04616101958346285,
      "grad_norm": 0.1460973024368286,
      "learning_rate": 9.769194902082687e-06,
      "loss": 0.0327,
      "step": 594
    },
    {
      "epoch": 0.04623873173764377,
      "grad_norm": 0.07875348627567291,
      "learning_rate": 9.768806341311782e-06,
      "loss": 0.0477,
      "step": 595
    },
    {
      "epoch": 0.04631644389182468,
      "grad_norm": 0.34724506735801697,
      "learning_rate": 9.768417780540877e-06,
      "loss": 0.2377,
      "step": 596
    },
    {
      "epoch": 0.046394156046005594,
      "grad_norm": 0.39336955547332764,
      "learning_rate": 9.768029219769974e-06,
      "loss": 0.2307,
      "step": 597
    },
    {
      "epoch": 0.046471868200186506,
      "grad_norm": 0.05030813440680504,
      "learning_rate": 9.767640658999069e-06,
      "loss": 0.0289,
      "step": 598
    },
    {
      "epoch": 0.046549580354367424,
      "grad_norm": 0.12850059568881989,
      "learning_rate": 9.767252098228164e-06,
      "loss": 0.115,
      "step": 599
    },
    {
      "epoch": 0.046627292508548336,
      "grad_norm": 0.3612850606441498,
      "learning_rate": 9.76686353745726e-06,
      "loss": 0.2811,
      "step": 600
    },
    {
      "epoch": 0.04670500466272925,
      "grad_norm": 0.27597883343696594,
      "learning_rate": 9.766474976686354e-06,
      "loss": 0.346,
      "step": 601
    },
    {
      "epoch": 0.046782716816910166,
      "grad_norm": 0.18902036547660828,
      "learning_rate": 9.76608641591545e-06,
      "loss": 0.0493,
      "step": 602
    },
    {
      "epoch": 0.04686042897109108,
      "grad_norm": 0.46650809049606323,
      "learning_rate": 9.765697855144545e-06,
      "loss": 0.8991,
      "step": 603
    },
    {
      "epoch": 0.04693814112527199,
      "grad_norm": 0.04732467606663704,
      "learning_rate": 9.76530929437364e-06,
      "loss": 0.0091,
      "step": 604
    },
    {
      "epoch": 0.04701585327945291,
      "grad_norm": 0.1603790521621704,
      "learning_rate": 9.764920733602737e-06,
      "loss": 0.1733,
      "step": 605
    },
    {
      "epoch": 0.04709356543363382,
      "grad_norm": 0.21674248576164246,
      "learning_rate": 9.764532172831832e-06,
      "loss": 0.0894,
      "step": 606
    },
    {
      "epoch": 0.04717127758781473,
      "grad_norm": 0.1830194890499115,
      "learning_rate": 9.764143612060927e-06,
      "loss": 0.1096,
      "step": 607
    },
    {
      "epoch": 0.04724898974199565,
      "grad_norm": 0.09647779166698456,
      "learning_rate": 9.763755051290023e-06,
      "loss": 0.1061,
      "step": 608
    },
    {
      "epoch": 0.04732670189617656,
      "grad_norm": 0.18298232555389404,
      "learning_rate": 9.763366490519118e-06,
      "loss": 0.5754,
      "step": 609
    },
    {
      "epoch": 0.047404414050357474,
      "grad_norm": 0.2447732388973236,
      "learning_rate": 9.762977929748213e-06,
      "loss": 0.2605,
      "step": 610
    },
    {
      "epoch": 0.04748212620453839,
      "grad_norm": 0.05983632057905197,
      "learning_rate": 9.762589368977308e-06,
      "loss": 0.0405,
      "step": 611
    },
    {
      "epoch": 0.047559838358719304,
      "grad_norm": 0.16617351770401,
      "learning_rate": 9.762200808206405e-06,
      "loss": 0.0864,
      "step": 612
    },
    {
      "epoch": 0.047637550512900216,
      "grad_norm": 0.17172393202781677,
      "learning_rate": 9.7618122474355e-06,
      "loss": 0.5505,
      "step": 613
    },
    {
      "epoch": 0.047715262667081135,
      "grad_norm": 0.17949265241622925,
      "learning_rate": 9.761423686664595e-06,
      "loss": 0.2469,
      "step": 614
    },
    {
      "epoch": 0.047792974821262046,
      "grad_norm": 0.15233293175697327,
      "learning_rate": 9.761035125893691e-06,
      "loss": 0.0669,
      "step": 615
    },
    {
      "epoch": 0.04787068697544296,
      "grad_norm": 0.24251344799995422,
      "learning_rate": 9.760646565122786e-06,
      "loss": 0.124,
      "step": 616
    },
    {
      "epoch": 0.04794839912962387,
      "grad_norm": 0.14448101818561554,
      "learning_rate": 9.760258004351881e-06,
      "loss": 0.2203,
      "step": 617
    },
    {
      "epoch": 0.04802611128380479,
      "grad_norm": 0.2625563442707062,
      "learning_rate": 9.759869443580978e-06,
      "loss": 0.2868,
      "step": 618
    },
    {
      "epoch": 0.0481038234379857,
      "grad_norm": 0.24827048182487488,
      "learning_rate": 9.759480882810071e-06,
      "loss": 0.1819,
      "step": 619
    },
    {
      "epoch": 0.04818153559216661,
      "grad_norm": 0.26164710521698,
      "learning_rate": 9.759092322039168e-06,
      "loss": 0.3114,
      "step": 620
    },
    {
      "epoch": 0.04825924774634753,
      "grad_norm": 0.06356875598430634,
      "learning_rate": 9.758703761268263e-06,
      "loss": 0.0428,
      "step": 621
    },
    {
      "epoch": 0.04833695990052844,
      "grad_norm": 0.2351755052804947,
      "learning_rate": 9.758315200497358e-06,
      "loss": 0.2998,
      "step": 622
    },
    {
      "epoch": 0.048414672054709354,
      "grad_norm": 0.17217987775802612,
      "learning_rate": 9.757926639726454e-06,
      "loss": 0.184,
      "step": 623
    },
    {
      "epoch": 0.04849238420889027,
      "grad_norm": 0.2321896255016327,
      "learning_rate": 9.75753807895555e-06,
      "loss": 0.7012,
      "step": 624
    },
    {
      "epoch": 0.048570096363071184,
      "grad_norm": 0.46624502539634705,
      "learning_rate": 9.757149518184646e-06,
      "loss": 0.3021,
      "step": 625
    },
    {
      "epoch": 0.048647808517252096,
      "grad_norm": 0.231881245970726,
      "learning_rate": 9.756760957413741e-06,
      "loss": 0.5966,
      "step": 626
    },
    {
      "epoch": 0.048725520671433015,
      "grad_norm": 0.4488949775695801,
      "learning_rate": 9.756372396642836e-06,
      "loss": 0.0909,
      "step": 627
    },
    {
      "epoch": 0.048803232825613926,
      "grad_norm": 0.4985879957675934,
      "learning_rate": 9.75598383587193e-06,
      "loss": 0.3305,
      "step": 628
    },
    {
      "epoch": 0.04888094497979484,
      "grad_norm": 0.4302189350128174,
      "learning_rate": 9.755595275101026e-06,
      "loss": 0.8859,
      "step": 629
    },
    {
      "epoch": 0.04895865713397576,
      "grad_norm": 0.316815584897995,
      "learning_rate": 9.755206714330122e-06,
      "loss": 0.3788,
      "step": 630
    },
    {
      "epoch": 0.04903636928815667,
      "grad_norm": 0.18424950540065765,
      "learning_rate": 9.754818153559217e-06,
      "loss": 0.1102,
      "step": 631
    },
    {
      "epoch": 0.04911408144233758,
      "grad_norm": 0.22059088945388794,
      "learning_rate": 9.754429592788312e-06,
      "loss": 0.173,
      "step": 632
    },
    {
      "epoch": 0.0491917935965185,
      "grad_norm": 0.1832035332918167,
      "learning_rate": 9.754041032017409e-06,
      "loss": 0.2599,
      "step": 633
    },
    {
      "epoch": 0.04926950575069941,
      "grad_norm": 0.24220235645771027,
      "learning_rate": 9.753652471246504e-06,
      "loss": 0.2514,
      "step": 634
    },
    {
      "epoch": 0.04934721790488032,
      "grad_norm": 0.4040122628211975,
      "learning_rate": 9.753263910475599e-06,
      "loss": 0.3633,
      "step": 635
    },
    {
      "epoch": 0.049424930059061234,
      "grad_norm": 0.14486469328403473,
      "learning_rate": 9.752875349704694e-06,
      "loss": 0.0972,
      "step": 636
    },
    {
      "epoch": 0.04950264221324215,
      "grad_norm": 0.2156839817762375,
      "learning_rate": 9.75248678893379e-06,
      "loss": 0.2293,
      "step": 637
    },
    {
      "epoch": 0.049580354367423064,
      "grad_norm": 0.6476929783821106,
      "learning_rate": 9.752098228162885e-06,
      "loss": 0.3999,
      "step": 638
    },
    {
      "epoch": 0.049658066521603976,
      "grad_norm": 0.20043334364891052,
      "learning_rate": 9.75170966739198e-06,
      "loss": 0.2047,
      "step": 639
    },
    {
      "epoch": 0.049735778675784895,
      "grad_norm": 0.2342623472213745,
      "learning_rate": 9.751321106621077e-06,
      "loss": 0.1562,
      "step": 640
    },
    {
      "epoch": 0.049813490829965806,
      "grad_norm": 0.12905125319957733,
      "learning_rate": 9.750932545850172e-06,
      "loss": 0.1292,
      "step": 641
    },
    {
      "epoch": 0.04989120298414672,
      "grad_norm": 0.250386506319046,
      "learning_rate": 9.750543985079267e-06,
      "loss": 0.0806,
      "step": 642
    },
    {
      "epoch": 0.04996891513832764,
      "grad_norm": 0.19981107115745544,
      "learning_rate": 9.750155424308364e-06,
      "loss": 0.2589,
      "step": 643
    },
    {
      "epoch": 0.05004662729250855,
      "grad_norm": 0.23548109829425812,
      "learning_rate": 9.749766863537457e-06,
      "loss": 0.2205,
      "step": 644
    },
    {
      "epoch": 0.05012433944668946,
      "grad_norm": 0.13757237792015076,
      "learning_rate": 9.749378302766553e-06,
      "loss": 0.1058,
      "step": 645
    },
    {
      "epoch": 0.05020205160087038,
      "grad_norm": 0.47566208243370056,
      "learning_rate": 9.748989741995648e-06,
      "loss": 0.3233,
      "step": 646
    },
    {
      "epoch": 0.05027976375505129,
      "grad_norm": 0.6545426845550537,
      "learning_rate": 9.748601181224743e-06,
      "loss": 0.5256,
      "step": 647
    },
    {
      "epoch": 0.0503574759092322,
      "grad_norm": 0.09671635925769806,
      "learning_rate": 9.74821262045384e-06,
      "loss": 0.136,
      "step": 648
    },
    {
      "epoch": 0.05043518806341312,
      "grad_norm": 0.13413359224796295,
      "learning_rate": 9.747824059682935e-06,
      "loss": 0.1676,
      "step": 649
    },
    {
      "epoch": 0.05051290021759403,
      "grad_norm": 0.11096440255641937,
      "learning_rate": 9.74743549891203e-06,
      "loss": 0.2194,
      "step": 650
    },
    {
      "epoch": 0.050590612371774944,
      "grad_norm": 0.09579383581876755,
      "learning_rate": 9.747046938141127e-06,
      "loss": 0.0731,
      "step": 651
    },
    {
      "epoch": 0.05066832452595586,
      "grad_norm": 0.08996078372001648,
      "learning_rate": 9.746658377370221e-06,
      "loss": 0.1131,
      "step": 652
    },
    {
      "epoch": 0.050746036680136775,
      "grad_norm": 0.22420698404312134,
      "learning_rate": 9.746269816599318e-06,
      "loss": 0.0938,
      "step": 653
    },
    {
      "epoch": 0.050823748834317686,
      "grad_norm": 0.16584201157093048,
      "learning_rate": 9.745881255828411e-06,
      "loss": 0.1134,
      "step": 654
    },
    {
      "epoch": 0.0509014609884986,
      "grad_norm": 0.18706797063350677,
      "learning_rate": 9.745492695057508e-06,
      "loss": 0.0942,
      "step": 655
    },
    {
      "epoch": 0.05097917314267952,
      "grad_norm": 0.3253229260444641,
      "learning_rate": 9.745104134286603e-06,
      "loss": 0.1661,
      "step": 656
    },
    {
      "epoch": 0.05105688529686043,
      "grad_norm": 0.0868016928434372,
      "learning_rate": 9.744715573515698e-06,
      "loss": 0.0266,
      "step": 657
    },
    {
      "epoch": 0.05113459745104134,
      "grad_norm": 0.1479688435792923,
      "learning_rate": 9.744327012744795e-06,
      "loss": 0.1168,
      "step": 658
    },
    {
      "epoch": 0.05121230960522226,
      "grad_norm": 0.024646008387207985,
      "learning_rate": 9.74393845197389e-06,
      "loss": 0.0054,
      "step": 659
    },
    {
      "epoch": 0.05129002175940317,
      "grad_norm": 0.02080746740102768,
      "learning_rate": 9.743549891202984e-06,
      "loss": 0.0298,
      "step": 660
    },
    {
      "epoch": 0.05136773391358408,
      "grad_norm": 0.07984118908643723,
      "learning_rate": 9.743161330432081e-06,
      "loss": 0.0549,
      "step": 661
    },
    {
      "epoch": 0.051445446067765,
      "grad_norm": 0.18445013463497162,
      "learning_rate": 9.742772769661176e-06,
      "loss": 0.3429,
      "step": 662
    },
    {
      "epoch": 0.05152315822194591,
      "grad_norm": 0.40875113010406494,
      "learning_rate": 9.742384208890271e-06,
      "loss": 0.243,
      "step": 663
    },
    {
      "epoch": 0.051600870376126824,
      "grad_norm": 0.17095892131328583,
      "learning_rate": 9.741995648119366e-06,
      "loss": 0.2026,
      "step": 664
    },
    {
      "epoch": 0.05167858253030774,
      "grad_norm": 0.030390290543437004,
      "learning_rate": 9.741607087348463e-06,
      "loss": 0.0133,
      "step": 665
    },
    {
      "epoch": 0.051756294684488655,
      "grad_norm": 0.25176888704299927,
      "learning_rate": 9.741218526577558e-06,
      "loss": 0.3172,
      "step": 666
    },
    {
      "epoch": 0.051834006838669566,
      "grad_norm": 0.10401799529790878,
      "learning_rate": 9.740829965806652e-06,
      "loss": 0.1107,
      "step": 667
    },
    {
      "epoch": 0.051911718992850485,
      "grad_norm": 0.0782061442732811,
      "learning_rate": 9.740441405035749e-06,
      "loss": 0.0512,
      "step": 668
    },
    {
      "epoch": 0.0519894311470314,
      "grad_norm": 0.3134668171405792,
      "learning_rate": 9.740052844264844e-06,
      "loss": 0.4221,
      "step": 669
    },
    {
      "epoch": 0.05206714330121231,
      "grad_norm": 5.912886142730713,
      "learning_rate": 9.739664283493939e-06,
      "loss": 2.3295,
      "step": 670
    },
    {
      "epoch": 0.05214485545539322,
      "grad_norm": 0.058823924511671066,
      "learning_rate": 9.739275722723036e-06,
      "loss": 0.0544,
      "step": 671
    },
    {
      "epoch": 0.05222256760957414,
      "grad_norm": 0.3237478733062744,
      "learning_rate": 9.738887161952129e-06,
      "loss": 0.2145,
      "step": 672
    },
    {
      "epoch": 0.05230027976375505,
      "grad_norm": 0.33346325159072876,
      "learning_rate": 9.738498601181226e-06,
      "loss": 0.2625,
      "step": 673
    },
    {
      "epoch": 0.05237799191793596,
      "grad_norm": 0.10073620826005936,
      "learning_rate": 9.73811004041032e-06,
      "loss": 0.0986,
      "step": 674
    },
    {
      "epoch": 0.05245570407211688,
      "grad_norm": 0.046059876680374146,
      "learning_rate": 9.737721479639415e-06,
      "loss": 0.0165,
      "step": 675
    },
    {
      "epoch": 0.05253341622629779,
      "grad_norm": 0.3427366614341736,
      "learning_rate": 9.737332918868512e-06,
      "loss": 0.3532,
      "step": 676
    },
    {
      "epoch": 0.052611128380478704,
      "grad_norm": 0.25709760189056396,
      "learning_rate": 9.736944358097607e-06,
      "loss": 0.2174,
      "step": 677
    },
    {
      "epoch": 0.05268884053465962,
      "grad_norm": 0.09149991720914841,
      "learning_rate": 9.736555797326702e-06,
      "loss": 0.033,
      "step": 678
    },
    {
      "epoch": 0.052766552688840535,
      "grad_norm": 0.05035584792494774,
      "learning_rate": 9.736167236555799e-06,
      "loss": 0.0271,
      "step": 679
    },
    {
      "epoch": 0.052844264843021446,
      "grad_norm": 0.23060166835784912,
      "learning_rate": 9.735778675784894e-06,
      "loss": 0.2198,
      "step": 680
    },
    {
      "epoch": 0.052921976997202365,
      "grad_norm": 0.6634255647659302,
      "learning_rate": 9.735390115013989e-06,
      "loss": 0.6041,
      "step": 681
    },
    {
      "epoch": 0.05299968915138328,
      "grad_norm": 0.22082555294036865,
      "learning_rate": 9.735001554243084e-06,
      "loss": 0.1664,
      "step": 682
    },
    {
      "epoch": 0.05307740130556419,
      "grad_norm": 0.5724040865898132,
      "learning_rate": 9.73461299347218e-06,
      "loss": 0.4796,
      "step": 683
    },
    {
      "epoch": 0.05315511345974511,
      "grad_norm": 0.34621232748031616,
      "learning_rate": 9.734224432701275e-06,
      "loss": 0.118,
      "step": 684
    },
    {
      "epoch": 0.05323282561392602,
      "grad_norm": 0.36064252257347107,
      "learning_rate": 9.73383587193037e-06,
      "loss": 0.6953,
      "step": 685
    },
    {
      "epoch": 0.05331053776810693,
      "grad_norm": 0.1362021267414093,
      "learning_rate": 9.733447311159467e-06,
      "loss": 0.0729,
      "step": 686
    },
    {
      "epoch": 0.05338824992228785,
      "grad_norm": 0.16904309391975403,
      "learning_rate": 9.733058750388562e-06,
      "loss": 0.1284,
      "step": 687
    },
    {
      "epoch": 0.05346596207646876,
      "grad_norm": 0.37848034501075745,
      "learning_rate": 9.732670189617657e-06,
      "loss": 0.4127,
      "step": 688
    },
    {
      "epoch": 0.05354367423064967,
      "grad_norm": 0.17119529843330383,
      "learning_rate": 9.732281628846753e-06,
      "loss": 0.2027,
      "step": 689
    },
    {
      "epoch": 0.053621386384830584,
      "grad_norm": 0.1462721824645996,
      "learning_rate": 9.731893068075848e-06,
      "loss": 0.1203,
      "step": 690
    },
    {
      "epoch": 0.0536990985390115,
      "grad_norm": 0.21244952082633972,
      "learning_rate": 9.731504507304943e-06,
      "loss": 0.0633,
      "step": 691
    },
    {
      "epoch": 0.053776810693192414,
      "grad_norm": 0.0933450311422348,
      "learning_rate": 9.731115946534038e-06,
      "loss": 0.0262,
      "step": 692
    },
    {
      "epoch": 0.053854522847373326,
      "grad_norm": 0.15061168372631073,
      "learning_rate": 9.730727385763135e-06,
      "loss": 0.0876,
      "step": 693
    },
    {
      "epoch": 0.053932235001554245,
      "grad_norm": 0.17494291067123413,
      "learning_rate": 9.73033882499223e-06,
      "loss": 0.1673,
      "step": 694
    },
    {
      "epoch": 0.05400994715573516,
      "grad_norm": 0.1853131651878357,
      "learning_rate": 9.729950264221325e-06,
      "loss": 0.2032,
      "step": 695
    },
    {
      "epoch": 0.05408765930991607,
      "grad_norm": 0.22492478787899017,
      "learning_rate": 9.729561703450421e-06,
      "loss": 0.206,
      "step": 696
    },
    {
      "epoch": 0.05416537146409699,
      "grad_norm": 0.17014673352241516,
      "learning_rate": 9.729173142679516e-06,
      "loss": 0.1292,
      "step": 697
    },
    {
      "epoch": 0.0542430836182779,
      "grad_norm": 0.18620893359184265,
      "learning_rate": 9.728784581908611e-06,
      "loss": 0.2303,
      "step": 698
    },
    {
      "epoch": 0.05432079577245881,
      "grad_norm": 0.3399886190891266,
      "learning_rate": 9.728396021137708e-06,
      "loss": 0.1447,
      "step": 699
    },
    {
      "epoch": 0.05439850792663973,
      "grad_norm": 0.10832321643829346,
      "learning_rate": 9.728007460366801e-06,
      "loss": 0.0253,
      "step": 700
    },
    {
      "epoch": 0.05447622008082064,
      "grad_norm": 0.3518913984298706,
      "learning_rate": 9.727618899595898e-06,
      "loss": 0.4261,
      "step": 701
    },
    {
      "epoch": 0.05455393223500155,
      "grad_norm": 0.5662758946418762,
      "learning_rate": 9.727230338824993e-06,
      "loss": 0.387,
      "step": 702
    },
    {
      "epoch": 0.05463164438918247,
      "grad_norm": 0.2917744219303131,
      "learning_rate": 9.726841778054088e-06,
      "loss": 0.3355,
      "step": 703
    },
    {
      "epoch": 0.05470935654336338,
      "grad_norm": 0.34324678778648376,
      "learning_rate": 9.726453217283184e-06,
      "loss": 0.1384,
      "step": 704
    },
    {
      "epoch": 0.054787068697544294,
      "grad_norm": 0.09645521640777588,
      "learning_rate": 9.72606465651228e-06,
      "loss": 0.0579,
      "step": 705
    },
    {
      "epoch": 0.05486478085172521,
      "grad_norm": 1.0062060356140137,
      "learning_rate": 9.725676095741374e-06,
      "loss": 0.5063,
      "step": 706
    },
    {
      "epoch": 0.054942493005906125,
      "grad_norm": 0.13791801035404205,
      "learning_rate": 9.72528753497047e-06,
      "loss": 0.1365,
      "step": 707
    },
    {
      "epoch": 0.055020205160087036,
      "grad_norm": 0.3223525285720825,
      "learning_rate": 9.724898974199566e-06,
      "loss": 0.1179,
      "step": 708
    },
    {
      "epoch": 0.05509791731426795,
      "grad_norm": 0.4072260558605194,
      "learning_rate": 9.72451041342866e-06,
      "loss": 0.1245,
      "step": 709
    },
    {
      "epoch": 0.05517562946844887,
      "grad_norm": 0.31921902298927307,
      "learning_rate": 9.724121852657756e-06,
      "loss": 0.6801,
      "step": 710
    },
    {
      "epoch": 0.05525334162262978,
      "grad_norm": 0.21960212290287018,
      "learning_rate": 9.723733291886852e-06,
      "loss": 0.2603,
      "step": 711
    },
    {
      "epoch": 0.05533105377681069,
      "grad_norm": 0.3589567244052887,
      "learning_rate": 9.723344731115947e-06,
      "loss": 0.2281,
      "step": 712
    },
    {
      "epoch": 0.05540876593099161,
      "grad_norm": 0.47034403681755066,
      "learning_rate": 9.722956170345042e-06,
      "loss": 1.1152,
      "step": 713
    },
    {
      "epoch": 0.05548647808517252,
      "grad_norm": 0.16534391045570374,
      "learning_rate": 9.722567609574139e-06,
      "loss": 0.128,
      "step": 714
    },
    {
      "epoch": 0.05556419023935343,
      "grad_norm": 0.15874023735523224,
      "learning_rate": 9.722179048803234e-06,
      "loss": 0.131,
      "step": 715
    },
    {
      "epoch": 0.05564190239353435,
      "grad_norm": 0.05948704108595848,
      "learning_rate": 9.721790488032329e-06,
      "loss": 0.07,
      "step": 716
    },
    {
      "epoch": 0.05571961454771526,
      "grad_norm": 0.1601334661245346,
      "learning_rate": 9.721401927261425e-06,
      "loss": 0.4781,
      "step": 717
    },
    {
      "epoch": 0.055797326701896174,
      "grad_norm": 0.25851982831954956,
      "learning_rate": 9.72101336649052e-06,
      "loss": 0.3248,
      "step": 718
    },
    {
      "epoch": 0.05587503885607709,
      "grad_norm": 0.4738540053367615,
      "learning_rate": 9.720624805719615e-06,
      "loss": 0.2881,
      "step": 719
    },
    {
      "epoch": 0.055952751010258005,
      "grad_norm": 0.3921099603176117,
      "learning_rate": 9.72023624494871e-06,
      "loss": 0.3602,
      "step": 720
    },
    {
      "epoch": 0.056030463164438916,
      "grad_norm": 0.5166429281234741,
      "learning_rate": 9.719847684177807e-06,
      "loss": 0.4709,
      "step": 721
    },
    {
      "epoch": 0.056108175318619835,
      "grad_norm": 0.29328492283821106,
      "learning_rate": 9.719459123406902e-06,
      "loss": 0.4962,
      "step": 722
    },
    {
      "epoch": 0.05618588747280075,
      "grad_norm": 0.2681804597377777,
      "learning_rate": 9.719070562635997e-06,
      "loss": 0.2976,
      "step": 723
    },
    {
      "epoch": 0.05626359962698166,
      "grad_norm": 0.11901400983333588,
      "learning_rate": 9.718682001865093e-06,
      "loss": 0.0785,
      "step": 724
    },
    {
      "epoch": 0.05634131178116258,
      "grad_norm": 0.17642267048358917,
      "learning_rate": 9.718293441094188e-06,
      "loss": 0.1026,
      "step": 725
    },
    {
      "epoch": 0.05641902393534349,
      "grad_norm": 0.4541599452495575,
      "learning_rate": 9.717904880323283e-06,
      "loss": 0.43,
      "step": 726
    },
    {
      "epoch": 0.0564967360895244,
      "grad_norm": 0.24278812110424042,
      "learning_rate": 9.71751631955238e-06,
      "loss": 0.0474,
      "step": 727
    },
    {
      "epoch": 0.05657444824370531,
      "grad_norm": 0.07102510333061218,
      "learning_rate": 9.717127758781473e-06,
      "loss": 0.0797,
      "step": 728
    },
    {
      "epoch": 0.05665216039788623,
      "grad_norm": 0.36917755007743835,
      "learning_rate": 9.71673919801057e-06,
      "loss": 0.087,
      "step": 729
    },
    {
      "epoch": 0.05672987255206714,
      "grad_norm": 0.1441621482372284,
      "learning_rate": 9.716350637239665e-06,
      "loss": 0.1152,
      "step": 730
    },
    {
      "epoch": 0.056807584706248054,
      "grad_norm": 0.4008530378341675,
      "learning_rate": 9.71596207646876e-06,
      "loss": 0.3537,
      "step": 731
    },
    {
      "epoch": 0.05688529686042897,
      "grad_norm": 0.4664740264415741,
      "learning_rate": 9.715573515697856e-06,
      "loss": 0.4558,
      "step": 732
    },
    {
      "epoch": 0.056963009014609885,
      "grad_norm": 0.07907368242740631,
      "learning_rate": 9.715184954926951e-06,
      "loss": 0.0338,
      "step": 733
    },
    {
      "epoch": 0.057040721168790796,
      "grad_norm": 0.020959408953785896,
      "learning_rate": 9.714796394156046e-06,
      "loss": 0.0045,
      "step": 734
    },
    {
      "epoch": 0.057118433322971715,
      "grad_norm": 0.6945550441741943,
      "learning_rate": 9.714407833385143e-06,
      "loss": 0.175,
      "step": 735
    },
    {
      "epoch": 0.05719614547715263,
      "grad_norm": 0.17344102263450623,
      "learning_rate": 9.714019272614238e-06,
      "loss": 0.1157,
      "step": 736
    },
    {
      "epoch": 0.05727385763133354,
      "grad_norm": 0.37116914987564087,
      "learning_rate": 9.713630711843333e-06,
      "loss": 0.3363,
      "step": 737
    },
    {
      "epoch": 0.05735156978551446,
      "grad_norm": 0.17413778603076935,
      "learning_rate": 9.713242151072428e-06,
      "loss": 0.2614,
      "step": 738
    },
    {
      "epoch": 0.05742928193969537,
      "grad_norm": 0.0512884221971035,
      "learning_rate": 9.712853590301524e-06,
      "loss": 0.0241,
      "step": 739
    },
    {
      "epoch": 0.05750699409387628,
      "grad_norm": 0.14384698867797852,
      "learning_rate": 9.71246502953062e-06,
      "loss": 0.1546,
      "step": 740
    },
    {
      "epoch": 0.0575847062480572,
      "grad_norm": 0.1958511918783188,
      "learning_rate": 9.712076468759714e-06,
      "loss": 0.1368,
      "step": 741
    },
    {
      "epoch": 0.05766241840223811,
      "grad_norm": 0.41255664825439453,
      "learning_rate": 9.711687907988811e-06,
      "loss": 0.9106,
      "step": 742
    },
    {
      "epoch": 0.05774013055641902,
      "grad_norm": 0.17298762500286102,
      "learning_rate": 9.711299347217906e-06,
      "loss": 0.4122,
      "step": 743
    },
    {
      "epoch": 0.05781784271059994,
      "grad_norm": 0.1208023652434349,
      "learning_rate": 9.710910786447001e-06,
      "loss": 0.042,
      "step": 744
    },
    {
      "epoch": 0.05789555486478085,
      "grad_norm": 0.13268281519412994,
      "learning_rate": 9.710522225676098e-06,
      "loss": 0.3319,
      "step": 745
    },
    {
      "epoch": 0.057973267018961765,
      "grad_norm": 0.3515789210796356,
      "learning_rate": 9.710133664905192e-06,
      "loss": 0.1664,
      "step": 746
    },
    {
      "epoch": 0.058050979173142676,
      "grad_norm": 0.20810115337371826,
      "learning_rate": 9.709745104134287e-06,
      "loss": 0.1677,
      "step": 747
    },
    {
      "epoch": 0.058128691327323595,
      "grad_norm": 0.10699226707220078,
      "learning_rate": 9.709356543363382e-06,
      "loss": 0.1077,
      "step": 748
    },
    {
      "epoch": 0.05820640348150451,
      "grad_norm": 0.10843868553638458,
      "learning_rate": 9.708967982592479e-06,
      "loss": 0.0964,
      "step": 749
    },
    {
      "epoch": 0.05828411563568542,
      "grad_norm": 0.1649048626422882,
      "learning_rate": 9.708579421821574e-06,
      "loss": 0.1061,
      "step": 750
    },
    {
      "epoch": 0.05836182778986634,
      "grad_norm": 0.1247345432639122,
      "learning_rate": 9.708190861050669e-06,
      "loss": 0.0768,
      "step": 751
    },
    {
      "epoch": 0.05843953994404725,
      "grad_norm": 0.252832293510437,
      "learning_rate": 9.707802300279766e-06,
      "loss": 0.2669,
      "step": 752
    },
    {
      "epoch": 0.05851725209822816,
      "grad_norm": 0.5457659959793091,
      "learning_rate": 9.707413739508859e-06,
      "loss": 0.353,
      "step": 753
    },
    {
      "epoch": 0.05859496425240908,
      "grad_norm": 0.025004062801599503,
      "learning_rate": 9.707025178737955e-06,
      "loss": 0.0239,
      "step": 754
    },
    {
      "epoch": 0.05867267640658999,
      "grad_norm": 0.12658658623695374,
      "learning_rate": 9.70663661796705e-06,
      "loss": 0.0813,
      "step": 755
    },
    {
      "epoch": 0.0587503885607709,
      "grad_norm": 0.21593987941741943,
      "learning_rate": 9.706248057196145e-06,
      "loss": 0.1764,
      "step": 756
    },
    {
      "epoch": 0.05882810071495182,
      "grad_norm": 0.373857706785202,
      "learning_rate": 9.705859496425242e-06,
      "loss": 0.2761,
      "step": 757
    },
    {
      "epoch": 0.05890581286913273,
      "grad_norm": 0.1493130624294281,
      "learning_rate": 9.705470935654337e-06,
      "loss": 0.1005,
      "step": 758
    },
    {
      "epoch": 0.058983525023313645,
      "grad_norm": 0.23566056787967682,
      "learning_rate": 9.705082374883432e-06,
      "loss": 0.2875,
      "step": 759
    },
    {
      "epoch": 0.05906123717749456,
      "grad_norm": 0.2607017159461975,
      "learning_rate": 9.704693814112529e-06,
      "loss": 0.246,
      "step": 760
    },
    {
      "epoch": 0.059138949331675475,
      "grad_norm": 0.17639338970184326,
      "learning_rate": 9.704305253341624e-06,
      "loss": 0.4987,
      "step": 761
    },
    {
      "epoch": 0.05921666148585639,
      "grad_norm": 0.6803033351898193,
      "learning_rate": 9.703916692570718e-06,
      "loss": 0.291,
      "step": 762
    },
    {
      "epoch": 0.0592943736400373,
      "grad_norm": 0.5162284970283508,
      "learning_rate": 9.703528131799813e-06,
      "loss": 0.4385,
      "step": 763
    },
    {
      "epoch": 0.05937208579421822,
      "grad_norm": 0.3867737948894501,
      "learning_rate": 9.70313957102891e-06,
      "loss": 0.3959,
      "step": 764
    },
    {
      "epoch": 0.05944979794839913,
      "grad_norm": 0.1403467357158661,
      "learning_rate": 9.702751010258005e-06,
      "loss": 0.0419,
      "step": 765
    },
    {
      "epoch": 0.05952751010258004,
      "grad_norm": 0.10313908755779266,
      "learning_rate": 9.7023624494871e-06,
      "loss": 0.0982,
      "step": 766
    },
    {
      "epoch": 0.05960522225676096,
      "grad_norm": 0.30175262689590454,
      "learning_rate": 9.701973888716197e-06,
      "loss": 0.1419,
      "step": 767
    },
    {
      "epoch": 0.05968293441094187,
      "grad_norm": 0.2921190857887268,
      "learning_rate": 9.701585327945292e-06,
      "loss": 0.3049,
      "step": 768
    },
    {
      "epoch": 0.05976064656512278,
      "grad_norm": 0.29393643140792847,
      "learning_rate": 9.701196767174387e-06,
      "loss": 0.257,
      "step": 769
    },
    {
      "epoch": 0.0598383587193037,
      "grad_norm": 0.6531646847724915,
      "learning_rate": 9.700808206403483e-06,
      "loss": 0.4261,
      "step": 770
    },
    {
      "epoch": 0.05991607087348461,
      "grad_norm": 0.26455172896385193,
      "learning_rate": 9.700419645632576e-06,
      "loss": 0.6328,
      "step": 771
    },
    {
      "epoch": 0.059993783027665525,
      "grad_norm": 0.16753050684928894,
      "learning_rate": 9.700031084861673e-06,
      "loss": 0.3197,
      "step": 772
    },
    {
      "epoch": 0.06007149518184644,
      "grad_norm": 0.34527403116226196,
      "learning_rate": 9.699642524090768e-06,
      "loss": 0.1359,
      "step": 773
    },
    {
      "epoch": 0.060149207336027355,
      "grad_norm": 0.1817442625761032,
      "learning_rate": 9.699253963319865e-06,
      "loss": 0.1462,
      "step": 774
    },
    {
      "epoch": 0.06022691949020827,
      "grad_norm": 0.3954804539680481,
      "learning_rate": 9.69886540254896e-06,
      "loss": 0.6265,
      "step": 775
    },
    {
      "epoch": 0.060304631644389185,
      "grad_norm": 0.056120697408914566,
      "learning_rate": 9.698476841778055e-06,
      "loss": 0.0136,
      "step": 776
    },
    {
      "epoch": 0.0603823437985701,
      "grad_norm": 0.223948672413826,
      "learning_rate": 9.698088281007151e-06,
      "loss": 0.1082,
      "step": 777
    },
    {
      "epoch": 0.06046005595275101,
      "grad_norm": 0.30250605940818787,
      "learning_rate": 9.697699720236246e-06,
      "loss": 0.6542,
      "step": 778
    },
    {
      "epoch": 0.06053776810693193,
      "grad_norm": 0.2513701319694519,
      "learning_rate": 9.697311159465341e-06,
      "loss": 0.5942,
      "step": 779
    },
    {
      "epoch": 0.06061548026111284,
      "grad_norm": 0.20978626608848572,
      "learning_rate": 9.696922598694438e-06,
      "loss": 0.1958,
      "step": 780
    },
    {
      "epoch": 0.06069319241529375,
      "grad_norm": 0.5239572525024414,
      "learning_rate": 9.696534037923531e-06,
      "loss": 0.1181,
      "step": 781
    },
    {
      "epoch": 0.06077090456947466,
      "grad_norm": 0.09445088356733322,
      "learning_rate": 9.696145477152628e-06,
      "loss": 0.0598,
      "step": 782
    },
    {
      "epoch": 0.06084861672365558,
      "grad_norm": 0.04895385727286339,
      "learning_rate": 9.695756916381723e-06,
      "loss": 0.0143,
      "step": 783
    },
    {
      "epoch": 0.06092632887783649,
      "grad_norm": 0.29656121134757996,
      "learning_rate": 9.695368355610818e-06,
      "loss": 0.2594,
      "step": 784
    },
    {
      "epoch": 0.061004041032017405,
      "grad_norm": 0.04209425672888756,
      "learning_rate": 9.694979794839914e-06,
      "loss": 0.0087,
      "step": 785
    },
    {
      "epoch": 0.06108175318619832,
      "grad_norm": 0.15154404938220978,
      "learning_rate": 9.694591234069009e-06,
      "loss": 0.1215,
      "step": 786
    },
    {
      "epoch": 0.061159465340379235,
      "grad_norm": 0.14733587205410004,
      "learning_rate": 9.694202673298104e-06,
      "loss": 0.0786,
      "step": 787
    },
    {
      "epoch": 0.06123717749456015,
      "grad_norm": 0.09093182533979416,
      "learning_rate": 9.6938141125272e-06,
      "loss": 0.0646,
      "step": 788
    },
    {
      "epoch": 0.061314889648741065,
      "grad_norm": 0.20029675960540771,
      "learning_rate": 9.693425551756296e-06,
      "loss": 0.628,
      "step": 789
    },
    {
      "epoch": 0.06139260180292198,
      "grad_norm": 0.2585026025772095,
      "learning_rate": 9.69303699098539e-06,
      "loss": 0.3166,
      "step": 790
    },
    {
      "epoch": 0.06147031395710289,
      "grad_norm": 0.1683853715658188,
      "learning_rate": 9.692648430214486e-06,
      "loss": 0.4307,
      "step": 791
    },
    {
      "epoch": 0.06154802611128381,
      "grad_norm": 0.22373993694782257,
      "learning_rate": 9.692259869443582e-06,
      "loss": 0.479,
      "step": 792
    },
    {
      "epoch": 0.06162573826546472,
      "grad_norm": 0.08714637905359268,
      "learning_rate": 9.691871308672677e-06,
      "loss": 0.0278,
      "step": 793
    },
    {
      "epoch": 0.06170345041964563,
      "grad_norm": 0.3079690635204315,
      "learning_rate": 9.691482747901772e-06,
      "loss": 0.4652,
      "step": 794
    },
    {
      "epoch": 0.06178116257382655,
      "grad_norm": 0.1573437750339508,
      "learning_rate": 9.691094187130869e-06,
      "loss": 0.0577,
      "step": 795
    },
    {
      "epoch": 0.06185887472800746,
      "grad_norm": 0.22050899267196655,
      "learning_rate": 9.690705626359964e-06,
      "loss": 0.2831,
      "step": 796
    },
    {
      "epoch": 0.06193658688218837,
      "grad_norm": 0.08014920353889465,
      "learning_rate": 9.690317065589059e-06,
      "loss": 0.0375,
      "step": 797
    },
    {
      "epoch": 0.06201429903636929,
      "grad_norm": 0.22494199872016907,
      "learning_rate": 9.689928504818155e-06,
      "loss": 0.4366,
      "step": 798
    },
    {
      "epoch": 0.0620920111905502,
      "grad_norm": 0.15459971129894257,
      "learning_rate": 9.689539944047249e-06,
      "loss": 0.0705,
      "step": 799
    },
    {
      "epoch": 0.062169723344731115,
      "grad_norm": 0.11787553876638412,
      "learning_rate": 9.689151383276345e-06,
      "loss": 0.0336,
      "step": 800
    },
    {
      "epoch": 0.06224743549891203,
      "grad_norm": 0.4048426151275635,
      "learning_rate": 9.68876282250544e-06,
      "loss": 0.1785,
      "step": 801
    },
    {
      "epoch": 0.062325147653092945,
      "grad_norm": 0.448106586933136,
      "learning_rate": 9.688374261734535e-06,
      "loss": 0.1467,
      "step": 802
    },
    {
      "epoch": 0.06240285980727386,
      "grad_norm": 0.18037858605384827,
      "learning_rate": 9.687985700963632e-06,
      "loss": 0.1851,
      "step": 803
    },
    {
      "epoch": 0.06248057196145477,
      "grad_norm": 0.3123800754547119,
      "learning_rate": 9.687597140192727e-06,
      "loss": 0.0927,
      "step": 804
    },
    {
      "epoch": 0.06255828411563569,
      "grad_norm": 0.28268253803253174,
      "learning_rate": 9.687208579421823e-06,
      "loss": 0.2601,
      "step": 805
    },
    {
      "epoch": 0.0626359962698166,
      "grad_norm": 0.6660346984863281,
      "learning_rate": 9.686820018650918e-06,
      "loss": 0.1884,
      "step": 806
    },
    {
      "epoch": 0.06271370842399751,
      "grad_norm": 0.27632009983062744,
      "learning_rate": 9.686431457880013e-06,
      "loss": 0.3241,
      "step": 807
    },
    {
      "epoch": 0.06279142057817842,
      "grad_norm": 0.24207594990730286,
      "learning_rate": 9.68604289710911e-06,
      "loss": 0.1423,
      "step": 808
    },
    {
      "epoch": 0.06286913273235933,
      "grad_norm": 0.24196089804172516,
      "learning_rate": 9.685654336338203e-06,
      "loss": 0.1962,
      "step": 809
    },
    {
      "epoch": 0.06294684488654026,
      "grad_norm": 0.022112403064966202,
      "learning_rate": 9.6852657755673e-06,
      "loss": 0.011,
      "step": 810
    },
    {
      "epoch": 0.06302455704072117,
      "grad_norm": 0.21697577834129333,
      "learning_rate": 9.684877214796395e-06,
      "loss": 0.1568,
      "step": 811
    },
    {
      "epoch": 0.06310226919490208,
      "grad_norm": 0.18856695294380188,
      "learning_rate": 9.68448865402549e-06,
      "loss": 0.1106,
      "step": 812
    },
    {
      "epoch": 0.063179981349083,
      "grad_norm": 0.18151713907718658,
      "learning_rate": 9.684100093254586e-06,
      "loss": 0.1735,
      "step": 813
    },
    {
      "epoch": 0.0632576935032639,
      "grad_norm": 0.22007523477077484,
      "learning_rate": 9.683711532483681e-06,
      "loss": 0.1624,
      "step": 814
    },
    {
      "epoch": 0.06333540565744482,
      "grad_norm": 0.2196701169013977,
      "learning_rate": 9.683322971712776e-06,
      "loss": 0.182,
      "step": 815
    },
    {
      "epoch": 0.06341311781162574,
      "grad_norm": 0.2262018322944641,
      "learning_rate": 9.682934410941873e-06,
      "loss": 0.2446,
      "step": 816
    },
    {
      "epoch": 0.06349082996580666,
      "grad_norm": 0.24048259854316711,
      "learning_rate": 9.682545850170968e-06,
      "loss": 0.2245,
      "step": 817
    },
    {
      "epoch": 0.06356854211998757,
      "grad_norm": 0.24821507930755615,
      "learning_rate": 9.682157289400063e-06,
      "loss": 0.1611,
      "step": 818
    },
    {
      "epoch": 0.06364625427416848,
      "grad_norm": 0.11347034573554993,
      "learning_rate": 9.681768728629158e-06,
      "loss": 0.0912,
      "step": 819
    },
    {
      "epoch": 0.06372396642834939,
      "grad_norm": 0.08766134828329086,
      "learning_rate": 9.681380167858254e-06,
      "loss": 0.0614,
      "step": 820
    },
    {
      "epoch": 0.0638016785825303,
      "grad_norm": 0.25602230429649353,
      "learning_rate": 9.68099160708735e-06,
      "loss": 0.4693,
      "step": 821
    },
    {
      "epoch": 0.06387939073671123,
      "grad_norm": 0.15037643909454346,
      "learning_rate": 9.680603046316444e-06,
      "loss": 0.0546,
      "step": 822
    },
    {
      "epoch": 0.06395710289089214,
      "grad_norm": 0.11140633374452591,
      "learning_rate": 9.680214485545541e-06,
      "loss": 0.1078,
      "step": 823
    },
    {
      "epoch": 0.06403481504507305,
      "grad_norm": 0.6375483870506287,
      "learning_rate": 9.679825924774636e-06,
      "loss": 0.9998,
      "step": 824
    },
    {
      "epoch": 0.06411252719925396,
      "grad_norm": 0.16907231509685516,
      "learning_rate": 9.67943736400373e-06,
      "loss": 0.0959,
      "step": 825
    },
    {
      "epoch": 0.06419023935343487,
      "grad_norm": 0.17194652557373047,
      "learning_rate": 9.679048803232827e-06,
      "loss": 0.2104,
      "step": 826
    },
    {
      "epoch": 0.06426795150761579,
      "grad_norm": 0.08479548245668411,
      "learning_rate": 9.67866024246192e-06,
      "loss": 0.0488,
      "step": 827
    },
    {
      "epoch": 0.0643456636617967,
      "grad_norm": 0.10481109470129013,
      "learning_rate": 9.678271681691017e-06,
      "loss": 0.0874,
      "step": 828
    },
    {
      "epoch": 0.06442337581597762,
      "grad_norm": 0.1437443494796753,
      "learning_rate": 9.677883120920112e-06,
      "loss": 0.1509,
      "step": 829
    },
    {
      "epoch": 0.06450108797015854,
      "grad_norm": 0.24172206223011017,
      "learning_rate": 9.677494560149207e-06,
      "loss": 0.2859,
      "step": 830
    },
    {
      "epoch": 0.06457880012433945,
      "grad_norm": 0.2887585163116455,
      "learning_rate": 9.677105999378304e-06,
      "loss": 0.2586,
      "step": 831
    },
    {
      "epoch": 0.06465651227852036,
      "grad_norm": 0.20759496092796326,
      "learning_rate": 9.676717438607399e-06,
      "loss": 0.116,
      "step": 832
    },
    {
      "epoch": 0.06473422443270127,
      "grad_norm": 0.5069974064826965,
      "learning_rate": 9.676328877836494e-06,
      "loss": 0.3027,
      "step": 833
    },
    {
      "epoch": 0.06481193658688218,
      "grad_norm": 0.09778571873903275,
      "learning_rate": 9.67594031706559e-06,
      "loss": 0.0263,
      "step": 834
    },
    {
      "epoch": 0.06488964874106311,
      "grad_norm": 0.5002213716506958,
      "learning_rate": 9.675551756294685e-06,
      "loss": 0.2152,
      "step": 835
    },
    {
      "epoch": 0.06496736089524402,
      "grad_norm": 0.44680482149124146,
      "learning_rate": 9.675163195523782e-06,
      "loss": 0.3509,
      "step": 836
    },
    {
      "epoch": 0.06504507304942493,
      "grad_norm": 0.23141096532344818,
      "learning_rate": 9.674774634752875e-06,
      "loss": 0.0709,
      "step": 837
    },
    {
      "epoch": 0.06512278520360584,
      "grad_norm": 0.1762724667787552,
      "learning_rate": 9.674386073981972e-06,
      "loss": 0.0411,
      "step": 838
    },
    {
      "epoch": 0.06520049735778675,
      "grad_norm": 0.10293439030647278,
      "learning_rate": 9.673997513211067e-06,
      "loss": 0.2524,
      "step": 839
    },
    {
      "epoch": 0.06527820951196767,
      "grad_norm": 0.09204874187707901,
      "learning_rate": 9.673608952440162e-06,
      "loss": 0.0947,
      "step": 840
    },
    {
      "epoch": 0.06535592166614859,
      "grad_norm": 0.16407112777233124,
      "learning_rate": 9.673220391669258e-06,
      "loss": 0.1185,
      "step": 841
    },
    {
      "epoch": 0.0654336338203295,
      "grad_norm": 0.21506385505199432,
      "learning_rate": 9.672831830898353e-06,
      "loss": 0.1112,
      "step": 842
    },
    {
      "epoch": 0.06551134597451042,
      "grad_norm": 0.1534477174282074,
      "learning_rate": 9.672443270127448e-06,
      "loss": 0.1295,
      "step": 843
    },
    {
      "epoch": 0.06558905812869133,
      "grad_norm": 0.07669033855199814,
      "learning_rate": 9.672054709356545e-06,
      "loss": 0.0454,
      "step": 844
    },
    {
      "epoch": 0.06566677028287224,
      "grad_norm": 0.06559894233942032,
      "learning_rate": 9.67166614858564e-06,
      "loss": 0.0598,
      "step": 845
    },
    {
      "epoch": 0.06574448243705315,
      "grad_norm": 0.21183592081069946,
      "learning_rate": 9.671277587814735e-06,
      "loss": 0.0567,
      "step": 846
    },
    {
      "epoch": 0.06582219459123406,
      "grad_norm": 0.5263762474060059,
      "learning_rate": 9.67088902704383e-06,
      "loss": 0.3211,
      "step": 847
    },
    {
      "epoch": 0.06589990674541499,
      "grad_norm": 0.08776791393756866,
      "learning_rate": 9.670500466272926e-06,
      "loss": 0.0425,
      "step": 848
    },
    {
      "epoch": 0.0659776188995959,
      "grad_norm": 0.2363562136888504,
      "learning_rate": 9.670111905502021e-06,
      "loss": 0.176,
      "step": 849
    },
    {
      "epoch": 0.06605533105377681,
      "grad_norm": 0.1285141259431839,
      "learning_rate": 9.669723344731116e-06,
      "loss": 0.0983,
      "step": 850
    },
    {
      "epoch": 0.06613304320795772,
      "grad_norm": 0.11794309318065643,
      "learning_rate": 9.669334783960213e-06,
      "loss": 0.0457,
      "step": 851
    },
    {
      "epoch": 0.06621075536213863,
      "grad_norm": 0.1933090090751648,
      "learning_rate": 9.668946223189308e-06,
      "loss": 0.1312,
      "step": 852
    },
    {
      "epoch": 0.06628846751631955,
      "grad_norm": 0.13946616649627686,
      "learning_rate": 9.668557662418403e-06,
      "loss": 0.0683,
      "step": 853
    },
    {
      "epoch": 0.06636617967050047,
      "grad_norm": 0.06808517128229141,
      "learning_rate": 9.6681691016475e-06,
      "loss": 0.0422,
      "step": 854
    },
    {
      "epoch": 0.06644389182468138,
      "grad_norm": 0.39577537775039673,
      "learning_rate": 9.667780540876593e-06,
      "loss": 0.6947,
      "step": 855
    },
    {
      "epoch": 0.0665216039788623,
      "grad_norm": 0.1436191350221634,
      "learning_rate": 9.66739198010569e-06,
      "loss": 0.0671,
      "step": 856
    },
    {
      "epoch": 0.06659931613304321,
      "grad_norm": 0.15388061106204987,
      "learning_rate": 9.667003419334784e-06,
      "loss": 0.1025,
      "step": 857
    },
    {
      "epoch": 0.06667702828722412,
      "grad_norm": 0.7212492823600769,
      "learning_rate": 9.66661485856388e-06,
      "loss": 0.5156,
      "step": 858
    },
    {
      "epoch": 0.06675474044140503,
      "grad_norm": 0.3276079297065735,
      "learning_rate": 9.666226297792976e-06,
      "loss": 0.736,
      "step": 859
    },
    {
      "epoch": 0.06683245259558596,
      "grad_norm": 0.2845042049884796,
      "learning_rate": 9.665837737022071e-06,
      "loss": 0.2242,
      "step": 860
    },
    {
      "epoch": 0.06691016474976687,
      "grad_norm": 0.1920301467180252,
      "learning_rate": 9.665449176251166e-06,
      "loss": 0.0432,
      "step": 861
    },
    {
      "epoch": 0.06698787690394778,
      "grad_norm": 0.36761078238487244,
      "learning_rate": 9.665060615480263e-06,
      "loss": 0.2502,
      "step": 862
    },
    {
      "epoch": 0.06706558905812869,
      "grad_norm": 0.2959997057914734,
      "learning_rate": 9.664672054709358e-06,
      "loss": 0.1259,
      "step": 863
    },
    {
      "epoch": 0.0671433012123096,
      "grad_norm": 0.16738583147525787,
      "learning_rate": 9.664283493938452e-06,
      "loss": 0.102,
      "step": 864
    },
    {
      "epoch": 0.06722101336649051,
      "grad_norm": 0.2144533395767212,
      "learning_rate": 9.663894933167547e-06,
      "loss": 0.0529,
      "step": 865
    },
    {
      "epoch": 0.06729872552067143,
      "grad_norm": 0.12738850712776184,
      "learning_rate": 9.663506372396644e-06,
      "loss": 0.0832,
      "step": 866
    },
    {
      "epoch": 0.06737643767485235,
      "grad_norm": 0.7446984648704529,
      "learning_rate": 9.663117811625739e-06,
      "loss": 0.5715,
      "step": 867
    },
    {
      "epoch": 0.06745414982903326,
      "grad_norm": 0.2555656135082245,
      "learning_rate": 9.662729250854834e-06,
      "loss": 0.1032,
      "step": 868
    },
    {
      "epoch": 0.06753186198321418,
      "grad_norm": 0.09472089260816574,
      "learning_rate": 9.66234069008393e-06,
      "loss": 0.0652,
      "step": 869
    },
    {
      "epoch": 0.06760957413739509,
      "grad_norm": 0.2506923973560333,
      "learning_rate": 9.661952129313026e-06,
      "loss": 0.1231,
      "step": 870
    },
    {
      "epoch": 0.067687286291576,
      "grad_norm": 0.15559154748916626,
      "learning_rate": 9.66156356854212e-06,
      "loss": 0.0883,
      "step": 871
    },
    {
      "epoch": 0.06776499844575691,
      "grad_norm": 0.11094421148300171,
      "learning_rate": 9.661175007771217e-06,
      "loss": 0.0488,
      "step": 872
    },
    {
      "epoch": 0.06784271059993784,
      "grad_norm": 0.18922919034957886,
      "learning_rate": 9.660786447000312e-06,
      "loss": 0.3323,
      "step": 873
    },
    {
      "epoch": 0.06792042275411875,
      "grad_norm": 0.12403567880392075,
      "learning_rate": 9.660397886229407e-06,
      "loss": 0.144,
      "step": 874
    },
    {
      "epoch": 0.06799813490829966,
      "grad_norm": 0.15413311123847961,
      "learning_rate": 9.660009325458502e-06,
      "loss": 0.1631,
      "step": 875
    },
    {
      "epoch": 0.06807584706248057,
      "grad_norm": 0.10784520208835602,
      "learning_rate": 9.659620764687599e-06,
      "loss": 0.0927,
      "step": 876
    },
    {
      "epoch": 0.06815355921666148,
      "grad_norm": 0.3939865231513977,
      "learning_rate": 9.659232203916694e-06,
      "loss": 0.5446,
      "step": 877
    },
    {
      "epoch": 0.0682312713708424,
      "grad_norm": 0.24246855080127716,
      "learning_rate": 9.658843643145789e-06,
      "loss": 0.105,
      "step": 878
    },
    {
      "epoch": 0.06830898352502332,
      "grad_norm": 0.1560070961713791,
      "learning_rate": 9.658455082374885e-06,
      "loss": 0.0556,
      "step": 879
    },
    {
      "epoch": 0.06838669567920423,
      "grad_norm": 0.24783246219158173,
      "learning_rate": 9.658066521603978e-06,
      "loss": 0.1846,
      "step": 880
    },
    {
      "epoch": 0.06846440783338514,
      "grad_norm": 0.10783649235963821,
      "learning_rate": 9.657677960833075e-06,
      "loss": 0.1021,
      "step": 881
    },
    {
      "epoch": 0.06854211998756606,
      "grad_norm": 0.23466819524765015,
      "learning_rate": 9.65728940006217e-06,
      "loss": 0.4373,
      "step": 882
    },
    {
      "epoch": 0.06861983214174697,
      "grad_norm": 0.5151912569999695,
      "learning_rate": 9.656900839291265e-06,
      "loss": 0.3508,
      "step": 883
    },
    {
      "epoch": 0.06869754429592788,
      "grad_norm": 0.07631208002567291,
      "learning_rate": 9.656512278520362e-06,
      "loss": 0.0371,
      "step": 884
    },
    {
      "epoch": 0.06877525645010879,
      "grad_norm": 0.13184796273708344,
      "learning_rate": 9.656123717749457e-06,
      "loss": 0.0992,
      "step": 885
    },
    {
      "epoch": 0.06885296860428972,
      "grad_norm": 0.4244503676891327,
      "learning_rate": 9.655735156978552e-06,
      "loss": 0.3192,
      "step": 886
    },
    {
      "epoch": 0.06893068075847063,
      "grad_norm": 0.12891387939453125,
      "learning_rate": 9.655346596207648e-06,
      "loss": 0.0455,
      "step": 887
    },
    {
      "epoch": 0.06900839291265154,
      "grad_norm": 0.1545172780752182,
      "learning_rate": 9.654958035436743e-06,
      "loss": 0.0691,
      "step": 888
    },
    {
      "epoch": 0.06908610506683245,
      "grad_norm": 0.4912440776824951,
      "learning_rate": 9.654569474665838e-06,
      "loss": 0.195,
      "step": 889
    },
    {
      "epoch": 0.06916381722101336,
      "grad_norm": 0.2106555551290512,
      "learning_rate": 9.654180913894933e-06,
      "loss": 0.1603,
      "step": 890
    },
    {
      "epoch": 0.06924152937519427,
      "grad_norm": 0.09465458989143372,
      "learning_rate": 9.65379235312403e-06,
      "loss": 0.0582,
      "step": 891
    },
    {
      "epoch": 0.0693192415293752,
      "grad_norm": 0.3601393401622772,
      "learning_rate": 9.653403792353125e-06,
      "loss": 0.2428,
      "step": 892
    },
    {
      "epoch": 0.06939695368355611,
      "grad_norm": 0.05772323161363602,
      "learning_rate": 9.65301523158222e-06,
      "loss": 0.0372,
      "step": 893
    },
    {
      "epoch": 0.06947466583773702,
      "grad_norm": 0.1405719667673111,
      "learning_rate": 9.652626670811316e-06,
      "loss": 0.1511,
      "step": 894
    },
    {
      "epoch": 0.06955237799191794,
      "grad_norm": 0.20662930607795715,
      "learning_rate": 9.652238110040411e-06,
      "loss": 0.1091,
      "step": 895
    },
    {
      "epoch": 0.06963009014609885,
      "grad_norm": 0.4048295021057129,
      "learning_rate": 9.651849549269506e-06,
      "loss": 0.521,
      "step": 896
    },
    {
      "epoch": 0.06970780230027976,
      "grad_norm": 0.12726162374019623,
      "learning_rate": 9.651460988498603e-06,
      "loss": 0.1627,
      "step": 897
    },
    {
      "epoch": 0.06978551445446068,
      "grad_norm": 0.16569368541240692,
      "learning_rate": 9.651072427727698e-06,
      "loss": 0.1406,
      "step": 898
    },
    {
      "epoch": 0.0698632266086416,
      "grad_norm": 0.18189363181591034,
      "learning_rate": 9.650683866956793e-06,
      "loss": 0.2347,
      "step": 899
    },
    {
      "epoch": 0.06994093876282251,
      "grad_norm": 0.0919327661395073,
      "learning_rate": 9.650295306185888e-06,
      "loss": 0.0819,
      "step": 900
    },
    {
      "epoch": 0.07001865091700342,
      "grad_norm": 0.10062248259782791,
      "learning_rate": 9.649906745414984e-06,
      "loss": 0.0995,
      "step": 901
    },
    {
      "epoch": 0.07009636307118433,
      "grad_norm": 0.3170776665210724,
      "learning_rate": 9.64951818464408e-06,
      "loss": 0.4981,
      "step": 902
    },
    {
      "epoch": 0.07017407522536524,
      "grad_norm": 0.22490157186985016,
      "learning_rate": 9.649129623873174e-06,
      "loss": 0.1078,
      "step": 903
    },
    {
      "epoch": 0.07025178737954615,
      "grad_norm": 0.3981180489063263,
      "learning_rate": 9.64874106310227e-06,
      "loss": 0.2472,
      "step": 904
    },
    {
      "epoch": 0.07032949953372708,
      "grad_norm": 0.20134605467319489,
      "learning_rate": 9.648352502331366e-06,
      "loss": 0.1398,
      "step": 905
    },
    {
      "epoch": 0.07040721168790799,
      "grad_norm": 0.14646293222904205,
      "learning_rate": 9.64796394156046e-06,
      "loss": 0.4673,
      "step": 906
    },
    {
      "epoch": 0.0704849238420889,
      "grad_norm": 0.07276634126901627,
      "learning_rate": 9.647575380789557e-06,
      "loss": 0.0423,
      "step": 907
    },
    {
      "epoch": 0.07056263599626982,
      "grad_norm": 0.19577954709529877,
      "learning_rate": 9.64718682001865e-06,
      "loss": 0.1204,
      "step": 908
    },
    {
      "epoch": 0.07064034815045073,
      "grad_norm": 0.23439303040504456,
      "learning_rate": 9.646798259247747e-06,
      "loss": 0.3109,
      "step": 909
    },
    {
      "epoch": 0.07071806030463164,
      "grad_norm": 0.2951670289039612,
      "learning_rate": 9.646409698476842e-06,
      "loss": 0.3101,
      "step": 910
    },
    {
      "epoch": 0.07079577245881256,
      "grad_norm": 0.28481829166412354,
      "learning_rate": 9.646021137705937e-06,
      "loss": 0.3124,
      "step": 911
    },
    {
      "epoch": 0.07087348461299348,
      "grad_norm": 0.09439921379089355,
      "learning_rate": 9.645632576935034e-06,
      "loss": 0.0157,
      "step": 912
    },
    {
      "epoch": 0.07095119676717439,
      "grad_norm": 0.10379578918218613,
      "learning_rate": 9.645244016164129e-06,
      "loss": 0.0292,
      "step": 913
    },
    {
      "epoch": 0.0710289089213553,
      "grad_norm": 0.16688565909862518,
      "learning_rate": 9.644855455393224e-06,
      "loss": 0.2028,
      "step": 914
    },
    {
      "epoch": 0.07110662107553621,
      "grad_norm": 0.13001300394535065,
      "learning_rate": 9.64446689462232e-06,
      "loss": 0.0361,
      "step": 915
    },
    {
      "epoch": 0.07118433322971712,
      "grad_norm": 0.27491360902786255,
      "learning_rate": 9.644078333851415e-06,
      "loss": 0.3692,
      "step": 916
    },
    {
      "epoch": 0.07126204538389805,
      "grad_norm": 0.6503445506095886,
      "learning_rate": 9.64368977308051e-06,
      "loss": 0.8593,
      "step": 917
    },
    {
      "epoch": 0.07133975753807896,
      "grad_norm": 0.1969061642885208,
      "learning_rate": 9.643301212309605e-06,
      "loss": 0.1145,
      "step": 918
    },
    {
      "epoch": 0.07141746969225987,
      "grad_norm": 0.26644018292427063,
      "learning_rate": 9.642912651538702e-06,
      "loss": 0.2462,
      "step": 919
    },
    {
      "epoch": 0.07149518184644078,
      "grad_norm": 0.12944114208221436,
      "learning_rate": 9.642524090767797e-06,
      "loss": 0.1022,
      "step": 920
    },
    {
      "epoch": 0.0715728940006217,
      "grad_norm": 0.10017705708742142,
      "learning_rate": 9.642135529996892e-06,
      "loss": 0.131,
      "step": 921
    },
    {
      "epoch": 0.0716506061548026,
      "grad_norm": 0.15094968676567078,
      "learning_rate": 9.641746969225988e-06,
      "loss": 0.1533,
      "step": 922
    },
    {
      "epoch": 0.07172831830898352,
      "grad_norm": 0.22271177172660828,
      "learning_rate": 9.641358408455083e-06,
      "loss": 0.2056,
      "step": 923
    },
    {
      "epoch": 0.07180603046316444,
      "grad_norm": 0.2787137031555176,
      "learning_rate": 9.640969847684178e-06,
      "loss": 0.1365,
      "step": 924
    },
    {
      "epoch": 0.07188374261734536,
      "grad_norm": 0.16385409235954285,
      "learning_rate": 9.640581286913275e-06,
      "loss": 0.0643,
      "step": 925
    },
    {
      "epoch": 0.07196145477152627,
      "grad_norm": 0.33154773712158203,
      "learning_rate": 9.64019272614237e-06,
      "loss": 0.1733,
      "step": 926
    },
    {
      "epoch": 0.07203916692570718,
      "grad_norm": 0.14085157215595245,
      "learning_rate": 9.639804165371465e-06,
      "loss": 0.0203,
      "step": 927
    },
    {
      "epoch": 0.07211687907988809,
      "grad_norm": 0.12194482982158661,
      "learning_rate": 9.63941560460056e-06,
      "loss": 0.1162,
      "step": 928
    },
    {
      "epoch": 0.072194591234069,
      "grad_norm": 0.460287481546402,
      "learning_rate": 9.639027043829656e-06,
      "loss": 1.0532,
      "step": 929
    },
    {
      "epoch": 0.07227230338824993,
      "grad_norm": 0.12317561358213425,
      "learning_rate": 9.638638483058751e-06,
      "loss": 0.135,
      "step": 930
    },
    {
      "epoch": 0.07235001554243084,
      "grad_norm": 0.35457393527030945,
      "learning_rate": 9.638249922287846e-06,
      "loss": 0.1004,
      "step": 931
    },
    {
      "epoch": 0.07242772769661175,
      "grad_norm": 0.18562786281108856,
      "learning_rate": 9.637861361516943e-06,
      "loss": 0.0679,
      "step": 932
    },
    {
      "epoch": 0.07250543985079266,
      "grad_norm": 0.19964781403541565,
      "learning_rate": 9.637472800746038e-06,
      "loss": 0.3063,
      "step": 933
    },
    {
      "epoch": 0.07258315200497358,
      "grad_norm": 0.24095207452774048,
      "learning_rate": 9.637084239975133e-06,
      "loss": 0.146,
      "step": 934
    },
    {
      "epoch": 0.07266086415915449,
      "grad_norm": 0.23283852636814117,
      "learning_rate": 9.63669567920423e-06,
      "loss": 0.1388,
      "step": 935
    },
    {
      "epoch": 0.07273857631333541,
      "grad_norm": 0.09960499405860901,
      "learning_rate": 9.636307118433323e-06,
      "loss": 0.04,
      "step": 936
    },
    {
      "epoch": 0.07281628846751632,
      "grad_norm": 0.08648935705423355,
      "learning_rate": 9.63591855766242e-06,
      "loss": 0.0477,
      "step": 937
    },
    {
      "epoch": 0.07289400062169724,
      "grad_norm": 0.17834268510341644,
      "learning_rate": 9.635529996891514e-06,
      "loss": 0.1685,
      "step": 938
    },
    {
      "epoch": 0.07297171277587815,
      "grad_norm": 0.21241608262062073,
      "learning_rate": 9.63514143612061e-06,
      "loss": 0.2366,
      "step": 939
    },
    {
      "epoch": 0.07304942493005906,
      "grad_norm": 0.24528434872627258,
      "learning_rate": 9.634752875349706e-06,
      "loss": 0.0653,
      "step": 940
    },
    {
      "epoch": 0.07312713708423997,
      "grad_norm": 0.22929002344608307,
      "learning_rate": 9.634364314578801e-06,
      "loss": 0.1874,
      "step": 941
    },
    {
      "epoch": 0.07320484923842088,
      "grad_norm": 0.1384369283914566,
      "learning_rate": 9.633975753807896e-06,
      "loss": 0.1004,
      "step": 942
    },
    {
      "epoch": 0.07328256139260181,
      "grad_norm": 0.13419358432292938,
      "learning_rate": 9.633587193036992e-06,
      "loss": 0.07,
      "step": 943
    },
    {
      "epoch": 0.07336027354678272,
      "grad_norm": 0.1157076358795166,
      "learning_rate": 9.633198632266087e-06,
      "loss": 0.1455,
      "step": 944
    },
    {
      "epoch": 0.07343798570096363,
      "grad_norm": 0.10999865084886551,
      "learning_rate": 9.632810071495182e-06,
      "loss": 0.1969,
      "step": 945
    },
    {
      "epoch": 0.07351569785514454,
      "grad_norm": 0.23788288235664368,
      "learning_rate": 9.632421510724277e-06,
      "loss": 0.2339,
      "step": 946
    },
    {
      "epoch": 0.07359341000932546,
      "grad_norm": 0.026291651651263237,
      "learning_rate": 9.632032949953374e-06,
      "loss": 0.0142,
      "step": 947
    },
    {
      "epoch": 0.07367112216350637,
      "grad_norm": 0.07017719745635986,
      "learning_rate": 9.631644389182469e-06,
      "loss": 0.0476,
      "step": 948
    },
    {
      "epoch": 0.07374883431768729,
      "grad_norm": 0.17315563559532166,
      "learning_rate": 9.631255828411564e-06,
      "loss": 0.1137,
      "step": 949
    },
    {
      "epoch": 0.0738265464718682,
      "grad_norm": 0.22763735055923462,
      "learning_rate": 9.63086726764066e-06,
      "loss": 0.231,
      "step": 950
    },
    {
      "epoch": 0.07390425862604912,
      "grad_norm": 0.15381476283073425,
      "learning_rate": 9.630478706869755e-06,
      "loss": 0.1794,
      "step": 951
    },
    {
      "epoch": 0.07398197078023003,
      "grad_norm": 0.31797680258750916,
      "learning_rate": 9.63009014609885e-06,
      "loss": 0.3469,
      "step": 952
    },
    {
      "epoch": 0.07405968293441094,
      "grad_norm": 0.44480252265930176,
      "learning_rate": 9.629701585327947e-06,
      "loss": 0.2564,
      "step": 953
    },
    {
      "epoch": 0.07413739508859185,
      "grad_norm": 0.12031237781047821,
      "learning_rate": 9.62931302455704e-06,
      "loss": 0.0631,
      "step": 954
    },
    {
      "epoch": 0.07421510724277278,
      "grad_norm": 0.2013784497976303,
      "learning_rate": 9.628924463786137e-06,
      "loss": 0.2009,
      "step": 955
    },
    {
      "epoch": 0.07429281939695369,
      "grad_norm": 0.10579852014780045,
      "learning_rate": 9.628535903015232e-06,
      "loss": 0.0912,
      "step": 956
    },
    {
      "epoch": 0.0743705315511346,
      "grad_norm": 0.09832296520471573,
      "learning_rate": 9.628147342244329e-06,
      "loss": 0.0609,
      "step": 957
    },
    {
      "epoch": 0.07444824370531551,
      "grad_norm": 0.06882362067699432,
      "learning_rate": 9.627758781473423e-06,
      "loss": 0.0398,
      "step": 958
    },
    {
      "epoch": 0.07452595585949642,
      "grad_norm": 0.9056088924407959,
      "learning_rate": 9.627370220702518e-06,
      "loss": 0.1328,
      "step": 959
    },
    {
      "epoch": 0.07460366801367734,
      "grad_norm": 0.42334017157554626,
      "learning_rate": 9.626981659931615e-06,
      "loss": 0.5089,
      "step": 960
    },
    {
      "epoch": 0.07468138016785825,
      "grad_norm": 0.14970454573631287,
      "learning_rate": 9.62659309916071e-06,
      "loss": 0.034,
      "step": 961
    },
    {
      "epoch": 0.07475909232203917,
      "grad_norm": 0.15082493424415588,
      "learning_rate": 9.626204538389805e-06,
      "loss": 0.0847,
      "step": 962
    },
    {
      "epoch": 0.07483680447622008,
      "grad_norm": 0.1306019127368927,
      "learning_rate": 9.625815977618902e-06,
      "loss": 0.1301,
      "step": 963
    },
    {
      "epoch": 0.074914516630401,
      "grad_norm": 0.15592321753501892,
      "learning_rate": 9.625427416847995e-06,
      "loss": 0.0482,
      "step": 964
    },
    {
      "epoch": 0.07499222878458191,
      "grad_norm": 0.3618165850639343,
      "learning_rate": 9.625038856077092e-06,
      "loss": 0.2083,
      "step": 965
    },
    {
      "epoch": 0.07506994093876282,
      "grad_norm": 0.09153414517641068,
      "learning_rate": 9.624650295306186e-06,
      "loss": 0.0901,
      "step": 966
    },
    {
      "epoch": 0.07514765309294373,
      "grad_norm": 0.0869189202785492,
      "learning_rate": 9.624261734535281e-06,
      "loss": 0.0137,
      "step": 967
    },
    {
      "epoch": 0.07522536524712466,
      "grad_norm": 0.2653222978115082,
      "learning_rate": 9.623873173764378e-06,
      "loss": 0.1287,
      "step": 968
    },
    {
      "epoch": 0.07530307740130557,
      "grad_norm": 0.1886783093214035,
      "learning_rate": 9.623484612993473e-06,
      "loss": 0.2114,
      "step": 969
    },
    {
      "epoch": 0.07538078955548648,
      "grad_norm": 0.2694031298160553,
      "learning_rate": 9.623096052222568e-06,
      "loss": 0.2546,
      "step": 970
    },
    {
      "epoch": 0.07545850170966739,
      "grad_norm": 0.21026453375816345,
      "learning_rate": 9.622707491451665e-06,
      "loss": 0.1656,
      "step": 971
    },
    {
      "epoch": 0.0755362138638483,
      "grad_norm": 0.26217368245124817,
      "learning_rate": 9.62231893068076e-06,
      "loss": 0.2574,
      "step": 972
    },
    {
      "epoch": 0.07561392601802921,
      "grad_norm": 0.059534769505262375,
      "learning_rate": 9.621930369909855e-06,
      "loss": 0.028,
      "step": 973
    },
    {
      "epoch": 0.07569163817221014,
      "grad_norm": 0.19590865075588226,
      "learning_rate": 9.62154180913895e-06,
      "loss": 0.165,
      "step": 974
    },
    {
      "epoch": 0.07576935032639105,
      "grad_norm": 0.2830063998699188,
      "learning_rate": 9.621153248368046e-06,
      "loss": 0.1208,
      "step": 975
    },
    {
      "epoch": 0.07584706248057196,
      "grad_norm": 0.2637622356414795,
      "learning_rate": 9.620764687597141e-06,
      "loss": 0.0726,
      "step": 976
    },
    {
      "epoch": 0.07592477463475288,
      "grad_norm": 0.43537217378616333,
      "learning_rate": 9.620376126826236e-06,
      "loss": 0.3728,
      "step": 977
    },
    {
      "epoch": 0.07600248678893379,
      "grad_norm": 0.1912890076637268,
      "learning_rate": 9.619987566055333e-06,
      "loss": 0.0729,
      "step": 978
    },
    {
      "epoch": 0.0760801989431147,
      "grad_norm": 0.08234476298093796,
      "learning_rate": 9.619599005284428e-06,
      "loss": 0.1044,
      "step": 979
    },
    {
      "epoch": 0.07615791109729561,
      "grad_norm": 0.28106367588043213,
      "learning_rate": 9.619210444513523e-06,
      "loss": 0.3042,
      "step": 980
    },
    {
      "epoch": 0.07623562325147654,
      "grad_norm": 0.5018036961555481,
      "learning_rate": 9.61882188374262e-06,
      "loss": 0.4356,
      "step": 981
    },
    {
      "epoch": 0.07631333540565745,
      "grad_norm": 0.1776895970106125,
      "learning_rate": 9.618433322971712e-06,
      "loss": 0.197,
      "step": 982
    },
    {
      "epoch": 0.07639104755983836,
      "grad_norm": 0.08370494097471237,
      "learning_rate": 9.618044762200809e-06,
      "loss": 0.046,
      "step": 983
    },
    {
      "epoch": 0.07646875971401927,
      "grad_norm": 0.5490767955780029,
      "learning_rate": 9.617656201429904e-06,
      "loss": 0.2835,
      "step": 984
    },
    {
      "epoch": 0.07654647186820018,
      "grad_norm": 0.08477316796779633,
      "learning_rate": 9.617267640658999e-06,
      "loss": 0.0344,
      "step": 985
    },
    {
      "epoch": 0.0766241840223811,
      "grad_norm": 0.1496051400899887,
      "learning_rate": 9.616879079888096e-06,
      "loss": 0.0936,
      "step": 986
    },
    {
      "epoch": 0.07670189617656202,
      "grad_norm": 0.33635425567626953,
      "learning_rate": 9.61649051911719e-06,
      "loss": 0.5901,
      "step": 987
    },
    {
      "epoch": 0.07677960833074293,
      "grad_norm": 0.041585516184568405,
      "learning_rate": 9.616101958346287e-06,
      "loss": 0.0623,
      "step": 988
    },
    {
      "epoch": 0.07685732048492384,
      "grad_norm": 0.2199118286371231,
      "learning_rate": 9.615713397575382e-06,
      "loss": 0.201,
      "step": 989
    },
    {
      "epoch": 0.07693503263910476,
      "grad_norm": 0.1962323635816574,
      "learning_rate": 9.615324836804477e-06,
      "loss": 0.1262,
      "step": 990
    },
    {
      "epoch": 0.07701274479328567,
      "grad_norm": 0.20734316110610962,
      "learning_rate": 9.614936276033574e-06,
      "loss": 0.2555,
      "step": 991
    },
    {
      "epoch": 0.07709045694746658,
      "grad_norm": 0.19665060937404633,
      "learning_rate": 9.614547715262667e-06,
      "loss": 0.1622,
      "step": 992
    },
    {
      "epoch": 0.07716816910164749,
      "grad_norm": 0.10367929190397263,
      "learning_rate": 9.614159154491764e-06,
      "loss": 0.1459,
      "step": 993
    },
    {
      "epoch": 0.07724588125582842,
      "grad_norm": 0.08088721334934235,
      "learning_rate": 9.613770593720859e-06,
      "loss": 0.0618,
      "step": 994
    },
    {
      "epoch": 0.07732359341000933,
      "grad_norm": 0.1834881752729416,
      "learning_rate": 9.613382032949954e-06,
      "loss": 0.22,
      "step": 995
    },
    {
      "epoch": 0.07740130556419024,
      "grad_norm": 0.2261345386505127,
      "learning_rate": 9.61299347217905e-06,
      "loss": 0.1459,
      "step": 996
    },
    {
      "epoch": 0.07747901771837115,
      "grad_norm": 0.19801972806453705,
      "learning_rate": 9.612604911408145e-06,
      "loss": 0.1129,
      "step": 997
    },
    {
      "epoch": 0.07755672987255206,
      "grad_norm": 0.032211583107709885,
      "learning_rate": 9.61221635063724e-06,
      "loss": 0.0124,
      "step": 998
    },
    {
      "epoch": 0.07763444202673297,
      "grad_norm": 0.20539286732673645,
      "learning_rate": 9.611827789866337e-06,
      "loss": 0.0825,
      "step": 999
    },
    {
      "epoch": 0.0777121541809139,
      "grad_norm": 0.20237456262111664,
      "learning_rate": 9.611439229095432e-06,
      "loss": 0.1142,
      "step": 1000
    },
    {
      "epoch": 0.07778986633509481,
      "grad_norm": 0.1803024560213089,
      "learning_rate": 9.611050668324527e-06,
      "loss": 0.1416,
      "step": 1001
    },
    {
      "epoch": 0.07786757848927572,
      "grad_norm": 0.2117224633693695,
      "learning_rate": 9.610662107553622e-06,
      "loss": 0.1493,
      "step": 1002
    },
    {
      "epoch": 0.07794529064345664,
      "grad_norm": 0.533492922782898,
      "learning_rate": 9.610273546782718e-06,
      "loss": 0.5786,
      "step": 1003
    },
    {
      "epoch": 0.07802300279763755,
      "grad_norm": 0.1323065310716629,
      "learning_rate": 9.609884986011813e-06,
      "loss": 0.0876,
      "step": 1004
    },
    {
      "epoch": 0.07810071495181846,
      "grad_norm": 0.07348300516605377,
      "learning_rate": 9.609496425240908e-06,
      "loss": 0.0445,
      "step": 1005
    },
    {
      "epoch": 0.07817842710599938,
      "grad_norm": 0.16433921456336975,
      "learning_rate": 9.609107864470005e-06,
      "loss": 0.1749,
      "step": 1006
    },
    {
      "epoch": 0.0782561392601803,
      "grad_norm": 0.10730816423892975,
      "learning_rate": 9.608719303699098e-06,
      "loss": 0.0411,
      "step": 1007
    },
    {
      "epoch": 0.07833385141436121,
      "grad_norm": 0.2955557703971863,
      "learning_rate": 9.608330742928195e-06,
      "loss": 0.106,
      "step": 1008
    },
    {
      "epoch": 0.07841156356854212,
      "grad_norm": 0.18071813881397247,
      "learning_rate": 9.60794218215729e-06,
      "loss": 0.153,
      "step": 1009
    },
    {
      "epoch": 0.07848927572272303,
      "grad_norm": 0.14910568296909332,
      "learning_rate": 9.607553621386385e-06,
      "loss": 0.0371,
      "step": 1010
    },
    {
      "epoch": 0.07856698787690394,
      "grad_norm": 0.2466442883014679,
      "learning_rate": 9.607165060615481e-06,
      "loss": 0.2141,
      "step": 1011
    },
    {
      "epoch": 0.07864470003108485,
      "grad_norm": 0.361972451210022,
      "learning_rate": 9.606776499844576e-06,
      "loss": 0.4211,
      "step": 1012
    },
    {
      "epoch": 0.07872241218526578,
      "grad_norm": 0.17193461954593658,
      "learning_rate": 9.606387939073671e-06,
      "loss": 0.1104,
      "step": 1013
    },
    {
      "epoch": 0.07880012433944669,
      "grad_norm": 0.17228905856609344,
      "learning_rate": 9.605999378302768e-06,
      "loss": 0.1889,
      "step": 1014
    },
    {
      "epoch": 0.0788778364936276,
      "grad_norm": 0.20157115161418915,
      "learning_rate": 9.605610817531863e-06,
      "loss": 0.1425,
      "step": 1015
    },
    {
      "epoch": 0.07895554864780852,
      "grad_norm": 0.2378450483083725,
      "learning_rate": 9.605222256760958e-06,
      "loss": 0.1511,
      "step": 1016
    },
    {
      "epoch": 0.07903326080198943,
      "grad_norm": 0.07124452292919159,
      "learning_rate": 9.604833695990053e-06,
      "loss": 0.0503,
      "step": 1017
    },
    {
      "epoch": 0.07911097295617034,
      "grad_norm": 0.4234614670276642,
      "learning_rate": 9.60444513521915e-06,
      "loss": 0.3892,
      "step": 1018
    },
    {
      "epoch": 0.07918868511035126,
      "grad_norm": 0.4306228458881378,
      "learning_rate": 9.604056574448244e-06,
      "loss": 0.0508,
      "step": 1019
    },
    {
      "epoch": 0.07926639726453218,
      "grad_norm": 0.16916784644126892,
      "learning_rate": 9.60366801367734e-06,
      "loss": 0.1931,
      "step": 1020
    },
    {
      "epoch": 0.07934410941871309,
      "grad_norm": 0.15957416594028473,
      "learning_rate": 9.603279452906436e-06,
      "loss": 0.0758,
      "step": 1021
    },
    {
      "epoch": 0.079421821572894,
      "grad_norm": 1.4484388828277588,
      "learning_rate": 9.60289089213553e-06,
      "loss": 0.4963,
      "step": 1022
    },
    {
      "epoch": 0.07949953372707491,
      "grad_norm": 0.09964759647846222,
      "learning_rate": 9.602502331364626e-06,
      "loss": 0.0929,
      "step": 1023
    },
    {
      "epoch": 0.07957724588125582,
      "grad_norm": 0.35357335209846497,
      "learning_rate": 9.602113770593722e-06,
      "loss": 0.4453,
      "step": 1024
    },
    {
      "epoch": 0.07965495803543675,
      "grad_norm": 0.17724162340164185,
      "learning_rate": 9.601725209822817e-06,
      "loss": 0.1144,
      "step": 1025
    },
    {
      "epoch": 0.07973267018961766,
      "grad_norm": 0.20493607223033905,
      "learning_rate": 9.601336649051912e-06,
      "loss": 0.2384,
      "step": 1026
    },
    {
      "epoch": 0.07981038234379857,
      "grad_norm": 0.30057308077812195,
      "learning_rate": 9.600948088281007e-06,
      "loss": 0.4281,
      "step": 1027
    },
    {
      "epoch": 0.07988809449797948,
      "grad_norm": 0.17183129489421844,
      "learning_rate": 9.600559527510104e-06,
      "loss": 0.0468,
      "step": 1028
    },
    {
      "epoch": 0.0799658066521604,
      "grad_norm": 0.07103853672742844,
      "learning_rate": 9.600170966739199e-06,
      "loss": 0.0658,
      "step": 1029
    },
    {
      "epoch": 0.08004351880634131,
      "grad_norm": 0.16742853820323944,
      "learning_rate": 9.599782405968294e-06,
      "loss": 0.0989,
      "step": 1030
    },
    {
      "epoch": 0.08012123096052222,
      "grad_norm": 0.274494469165802,
      "learning_rate": 9.59939384519739e-06,
      "loss": 0.2818,
      "step": 1031
    },
    {
      "epoch": 0.08019894311470314,
      "grad_norm": 0.18364264070987701,
      "learning_rate": 9.599005284426485e-06,
      "loss": 0.2429,
      "step": 1032
    },
    {
      "epoch": 0.08027665526888406,
      "grad_norm": 0.25698885321617126,
      "learning_rate": 9.59861672365558e-06,
      "loss": 0.1761,
      "step": 1033
    },
    {
      "epoch": 0.08035436742306497,
      "grad_norm": 0.15792004764080048,
      "learning_rate": 9.598228162884677e-06,
      "loss": 0.1188,
      "step": 1034
    },
    {
      "epoch": 0.08043207957724588,
      "grad_norm": 0.1939055174589157,
      "learning_rate": 9.59783960211377e-06,
      "loss": 0.1278,
      "step": 1035
    },
    {
      "epoch": 0.08050979173142679,
      "grad_norm": 0.09857974946498871,
      "learning_rate": 9.597451041342867e-06,
      "loss": 0.1133,
      "step": 1036
    },
    {
      "epoch": 0.0805875038856077,
      "grad_norm": 0.18944142758846283,
      "learning_rate": 9.597062480571962e-06,
      "loss": 0.111,
      "step": 1037
    },
    {
      "epoch": 0.08066521603978863,
      "grad_norm": 0.41412273049354553,
      "learning_rate": 9.596673919801057e-06,
      "loss": 0.5568,
      "step": 1038
    },
    {
      "epoch": 0.08074292819396954,
      "grad_norm": 0.8084129691123962,
      "learning_rate": 9.596285359030153e-06,
      "loss": 0.48,
      "step": 1039
    },
    {
      "epoch": 0.08082064034815045,
      "grad_norm": 0.28537386655807495,
      "learning_rate": 9.595896798259248e-06,
      "loss": 0.2455,
      "step": 1040
    },
    {
      "epoch": 0.08089835250233136,
      "grad_norm": 0.13179977238178253,
      "learning_rate": 9.595508237488343e-06,
      "loss": 0.071,
      "step": 1041
    },
    {
      "epoch": 0.08097606465651228,
      "grad_norm": 0.16170229017734528,
      "learning_rate": 9.59511967671744e-06,
      "loss": 0.0415,
      "step": 1042
    },
    {
      "epoch": 0.08105377681069319,
      "grad_norm": 0.3708786964416504,
      "learning_rate": 9.594731115946535e-06,
      "loss": 0.2492,
      "step": 1043
    },
    {
      "epoch": 0.08113148896487411,
      "grad_norm": 0.19171293079853058,
      "learning_rate": 9.59434255517563e-06,
      "loss": 0.254,
      "step": 1044
    },
    {
      "epoch": 0.08120920111905502,
      "grad_norm": 0.0562136210501194,
      "learning_rate": 9.593953994404725e-06,
      "loss": 0.0149,
      "step": 1045
    },
    {
      "epoch": 0.08128691327323594,
      "grad_norm": 0.2319832146167755,
      "learning_rate": 9.593565433633821e-06,
      "loss": 0.17,
      "step": 1046
    },
    {
      "epoch": 0.08136462542741685,
      "grad_norm": 0.06901875883340836,
      "learning_rate": 9.593176872862916e-06,
      "loss": 0.0173,
      "step": 1047
    },
    {
      "epoch": 0.08144233758159776,
      "grad_norm": 0.4518153667449951,
      "learning_rate": 9.592788312092011e-06,
      "loss": 0.895,
      "step": 1048
    },
    {
      "epoch": 0.08152004973577867,
      "grad_norm": 0.037640515714883804,
      "learning_rate": 9.592399751321108e-06,
      "loss": 0.0531,
      "step": 1049
    },
    {
      "epoch": 0.08159776188995958,
      "grad_norm": 0.32491180300712585,
      "learning_rate": 9.592011190550203e-06,
      "loss": 0.1067,
      "step": 1050
    },
    {
      "epoch": 0.08167547404414051,
      "grad_norm": 0.1001572385430336,
      "learning_rate": 9.591622629779298e-06,
      "loss": 0.0739,
      "step": 1051
    },
    {
      "epoch": 0.08175318619832142,
      "grad_norm": 0.4152728021144867,
      "learning_rate": 9.591234069008395e-06,
      "loss": 0.2534,
      "step": 1052
    },
    {
      "epoch": 0.08183089835250233,
      "grad_norm": 0.19484777748584747,
      "learning_rate": 9.59084550823749e-06,
      "loss": 0.3076,
      "step": 1053
    },
    {
      "epoch": 0.08190861050668324,
      "grad_norm": 0.5744126439094543,
      "learning_rate": 9.590456947466584e-06,
      "loss": 0.2996,
      "step": 1054
    },
    {
      "epoch": 0.08198632266086416,
      "grad_norm": 0.05560539290308952,
      "learning_rate": 9.59006838669568e-06,
      "loss": 0.0363,
      "step": 1055
    },
    {
      "epoch": 0.08206403481504507,
      "grad_norm": 0.14691361784934998,
      "learning_rate": 9.589679825924776e-06,
      "loss": 0.1158,
      "step": 1056
    },
    {
      "epoch": 0.08214174696922599,
      "grad_norm": 0.06560193747282028,
      "learning_rate": 9.589291265153871e-06,
      "loss": 0.0461,
      "step": 1057
    },
    {
      "epoch": 0.0822194591234069,
      "grad_norm": 0.0936795175075531,
      "learning_rate": 9.588902704382966e-06,
      "loss": 0.0632,
      "step": 1058
    },
    {
      "epoch": 0.08229717127758782,
      "grad_norm": 0.17983557283878326,
      "learning_rate": 9.588514143612063e-06,
      "loss": 0.0399,
      "step": 1059
    },
    {
      "epoch": 0.08237488343176873,
      "grad_norm": 0.11061001569032669,
      "learning_rate": 9.588125582841157e-06,
      "loss": 0.0808,
      "step": 1060
    },
    {
      "epoch": 0.08245259558594964,
      "grad_norm": 0.073145292699337,
      "learning_rate": 9.587737022070252e-06,
      "loss": 0.0786,
      "step": 1061
    },
    {
      "epoch": 0.08253030774013055,
      "grad_norm": 0.3661814033985138,
      "learning_rate": 9.587348461299349e-06,
      "loss": 0.0795,
      "step": 1062
    },
    {
      "epoch": 0.08260801989431148,
      "grad_norm": 0.41648977994918823,
      "learning_rate": 9.586959900528442e-06,
      "loss": 0.4534,
      "step": 1063
    },
    {
      "epoch": 0.08268573204849239,
      "grad_norm": 0.1198042780160904,
      "learning_rate": 9.586571339757539e-06,
      "loss": 0.0954,
      "step": 1064
    },
    {
      "epoch": 0.0827634442026733,
      "grad_norm": 0.10771747678518295,
      "learning_rate": 9.586182778986634e-06,
      "loss": 0.042,
      "step": 1065
    },
    {
      "epoch": 0.08284115635685421,
      "grad_norm": 0.112497478723526,
      "learning_rate": 9.585794218215729e-06,
      "loss": 0.0577,
      "step": 1066
    },
    {
      "epoch": 0.08291886851103512,
      "grad_norm": 0.5533702969551086,
      "learning_rate": 9.585405657444826e-06,
      "loss": 0.4094,
      "step": 1067
    },
    {
      "epoch": 0.08299658066521604,
      "grad_norm": 0.17759914696216583,
      "learning_rate": 9.58501709667392e-06,
      "loss": 0.1281,
      "step": 1068
    },
    {
      "epoch": 0.08307429281939695,
      "grad_norm": 0.11251849681138992,
      "learning_rate": 9.584628535903015e-06,
      "loss": 0.2079,
      "step": 1069
    },
    {
      "epoch": 0.08315200497357787,
      "grad_norm": 0.35233932733535767,
      "learning_rate": 9.584239975132112e-06,
      "loss": 0.322,
      "step": 1070
    },
    {
      "epoch": 0.08322971712775878,
      "grad_norm": 0.3491470515727997,
      "learning_rate": 9.583851414361207e-06,
      "loss": 0.4425,
      "step": 1071
    },
    {
      "epoch": 0.0833074292819397,
      "grad_norm": 0.12149152159690857,
      "learning_rate": 9.583462853590302e-06,
      "loss": 0.0925,
      "step": 1072
    },
    {
      "epoch": 0.08338514143612061,
      "grad_norm": 0.289120078086853,
      "learning_rate": 9.583074292819397e-06,
      "loss": 0.2068,
      "step": 1073
    },
    {
      "epoch": 0.08346285359030152,
      "grad_norm": 0.12904833257198334,
      "learning_rate": 9.582685732048494e-06,
      "loss": 0.0545,
      "step": 1074
    },
    {
      "epoch": 0.08354056574448243,
      "grad_norm": 0.21513740718364716,
      "learning_rate": 9.582297171277589e-06,
      "loss": 0.452,
      "step": 1075
    },
    {
      "epoch": 0.08361827789866336,
      "grad_norm": 0.10676407814025879,
      "learning_rate": 9.581908610506683e-06,
      "loss": 0.0878,
      "step": 1076
    },
    {
      "epoch": 0.08369599005284427,
      "grad_norm": 0.19318822026252747,
      "learning_rate": 9.58152004973578e-06,
      "loss": 0.2378,
      "step": 1077
    },
    {
      "epoch": 0.08377370220702518,
      "grad_norm": 0.31059563159942627,
      "learning_rate": 9.581131488964875e-06,
      "loss": 0.1621,
      "step": 1078
    },
    {
      "epoch": 0.08385141436120609,
      "grad_norm": 0.059523068368434906,
      "learning_rate": 9.58074292819397e-06,
      "loss": 0.0191,
      "step": 1079
    },
    {
      "epoch": 0.083929126515387,
      "grad_norm": 0.26239317655563354,
      "learning_rate": 9.580354367423067e-06,
      "loss": 0.0925,
      "step": 1080
    },
    {
      "epoch": 0.08400683866956792,
      "grad_norm": 0.08543412387371063,
      "learning_rate": 9.579965806652162e-06,
      "loss": 0.0599,
      "step": 1081
    },
    {
      "epoch": 0.08408455082374884,
      "grad_norm": 0.1074119359254837,
      "learning_rate": 9.579577245881257e-06,
      "loss": 0.0682,
      "step": 1082
    },
    {
      "epoch": 0.08416226297792975,
      "grad_norm": 0.10446351021528244,
      "learning_rate": 9.579188685110352e-06,
      "loss": 0.0329,
      "step": 1083
    },
    {
      "epoch": 0.08423997513211066,
      "grad_norm": 0.20542466640472412,
      "learning_rate": 9.578800124339448e-06,
      "loss": 0.3508,
      "step": 1084
    },
    {
      "epoch": 0.08431768728629158,
      "grad_norm": 0.4007205665111542,
      "learning_rate": 9.578411563568543e-06,
      "loss": 0.3595,
      "step": 1085
    },
    {
      "epoch": 0.08439539944047249,
      "grad_norm": 0.20887082815170288,
      "learning_rate": 9.578023002797638e-06,
      "loss": 0.1227,
      "step": 1086
    },
    {
      "epoch": 0.0844731115946534,
      "grad_norm": 0.08766256272792816,
      "learning_rate": 9.577634442026735e-06,
      "loss": 0.0665,
      "step": 1087
    },
    {
      "epoch": 0.08455082374883431,
      "grad_norm": 0.2779410481452942,
      "learning_rate": 9.57724588125583e-06,
      "loss": 0.4777,
      "step": 1088
    },
    {
      "epoch": 0.08462853590301524,
      "grad_norm": 0.19125887751579285,
      "learning_rate": 9.576857320484925e-06,
      "loss": 0.218,
      "step": 1089
    },
    {
      "epoch": 0.08470624805719615,
      "grad_norm": 0.15063689649105072,
      "learning_rate": 9.576468759714021e-06,
      "loss": 0.1425,
      "step": 1090
    },
    {
      "epoch": 0.08478396021137706,
      "grad_norm": 0.08249035477638245,
      "learning_rate": 9.576080198943114e-06,
      "loss": 0.0437,
      "step": 1091
    },
    {
      "epoch": 0.08486167236555797,
      "grad_norm": 0.20261195302009583,
      "learning_rate": 9.575691638172211e-06,
      "loss": 0.2298,
      "step": 1092
    },
    {
      "epoch": 0.08493938451973888,
      "grad_norm": 0.24682651460170746,
      "learning_rate": 9.575303077401306e-06,
      "loss": 0.0684,
      "step": 1093
    },
    {
      "epoch": 0.0850170966739198,
      "grad_norm": 0.2667628824710846,
      "learning_rate": 9.574914516630401e-06,
      "loss": 0.2535,
      "step": 1094
    },
    {
      "epoch": 0.08509480882810072,
      "grad_norm": 0.8438614010810852,
      "learning_rate": 9.574525955859498e-06,
      "loss": 0.293,
      "step": 1095
    },
    {
      "epoch": 0.08517252098228163,
      "grad_norm": 0.12444233149290085,
      "learning_rate": 9.574137395088593e-06,
      "loss": 0.0709,
      "step": 1096
    },
    {
      "epoch": 0.08525023313646254,
      "grad_norm": 0.08692079782485962,
      "learning_rate": 9.573748834317688e-06,
      "loss": 0.027,
      "step": 1097
    },
    {
      "epoch": 0.08532794529064346,
      "grad_norm": 0.38211798667907715,
      "learning_rate": 9.573360273546784e-06,
      "loss": 0.1187,
      "step": 1098
    },
    {
      "epoch": 0.08540565744482437,
      "grad_norm": 0.7667893171310425,
      "learning_rate": 9.57297171277588e-06,
      "loss": 0.547,
      "step": 1099
    },
    {
      "epoch": 0.08548336959900528,
      "grad_norm": 0.15319164097309113,
      "learning_rate": 9.572583152004974e-06,
      "loss": 0.1336,
      "step": 1100
    },
    {
      "epoch": 0.0855610817531862,
      "grad_norm": 0.01390855759382248,
      "learning_rate": 9.572194591234069e-06,
      "loss": 0.0074,
      "step": 1101
    },
    {
      "epoch": 0.08563879390736712,
      "grad_norm": 0.26056674122810364,
      "learning_rate": 9.571806030463166e-06,
      "loss": 0.183,
      "step": 1102
    },
    {
      "epoch": 0.08571650606154803,
      "grad_norm": 0.1400570273399353,
      "learning_rate": 9.57141746969226e-06,
      "loss": 0.1353,
      "step": 1103
    },
    {
      "epoch": 0.08579421821572894,
      "grad_norm": 0.49299368262290955,
      "learning_rate": 9.571028908921356e-06,
      "loss": 0.3016,
      "step": 1104
    },
    {
      "epoch": 0.08587193036990985,
      "grad_norm": 0.25902751088142395,
      "learning_rate": 9.570640348150452e-06,
      "loss": 0.2044,
      "step": 1105
    },
    {
      "epoch": 0.08594964252409076,
      "grad_norm": 0.21511372923851013,
      "learning_rate": 9.570251787379547e-06,
      "loss": 0.2242,
      "step": 1106
    },
    {
      "epoch": 0.08602735467827168,
      "grad_norm": 0.268996000289917,
      "learning_rate": 9.569863226608642e-06,
      "loss": 0.3573,
      "step": 1107
    },
    {
      "epoch": 0.0861050668324526,
      "grad_norm": 0.19139650464057922,
      "learning_rate": 9.569474665837739e-06,
      "loss": 0.1231,
      "step": 1108
    },
    {
      "epoch": 0.08618277898663351,
      "grad_norm": 0.3105904161930084,
      "learning_rate": 9.569086105066834e-06,
      "loss": 0.1271,
      "step": 1109
    },
    {
      "epoch": 0.08626049114081442,
      "grad_norm": 0.2153506726026535,
      "learning_rate": 9.568697544295929e-06,
      "loss": 0.1953,
      "step": 1110
    },
    {
      "epoch": 0.08633820329499534,
      "grad_norm": 0.14628449082374573,
      "learning_rate": 9.568308983525024e-06,
      "loss": 0.0834,
      "step": 1111
    },
    {
      "epoch": 0.08641591544917625,
      "grad_norm": 0.4792179465293884,
      "learning_rate": 9.56792042275412e-06,
      "loss": 0.4907,
      "step": 1112
    },
    {
      "epoch": 0.08649362760335716,
      "grad_norm": 0.2806759476661682,
      "learning_rate": 9.567531861983215e-06,
      "loss": 0.2769,
      "step": 1113
    },
    {
      "epoch": 0.08657133975753808,
      "grad_norm": 0.07686710357666016,
      "learning_rate": 9.56714330121231e-06,
      "loss": 0.0948,
      "step": 1114
    },
    {
      "epoch": 0.086649051911719,
      "grad_norm": 0.17159368097782135,
      "learning_rate": 9.566754740441407e-06,
      "loss": 0.0566,
      "step": 1115
    },
    {
      "epoch": 0.08672676406589991,
      "grad_norm": 0.07166284322738647,
      "learning_rate": 9.566366179670502e-06,
      "loss": 0.0567,
      "step": 1116
    },
    {
      "epoch": 0.08680447622008082,
      "grad_norm": 0.45749977231025696,
      "learning_rate": 9.565977618899597e-06,
      "loss": 0.32,
      "step": 1117
    },
    {
      "epoch": 0.08688218837426173,
      "grad_norm": 0.07607363164424896,
      "learning_rate": 9.565589058128693e-06,
      "loss": 0.0359,
      "step": 1118
    },
    {
      "epoch": 0.08695990052844264,
      "grad_norm": 0.2687840759754181,
      "learning_rate": 9.565200497357787e-06,
      "loss": 0.1461,
      "step": 1119
    },
    {
      "epoch": 0.08703761268262357,
      "grad_norm": 1.2665308713912964,
      "learning_rate": 9.564811936586883e-06,
      "loss": 0.6221,
      "step": 1120
    },
    {
      "epoch": 0.08711532483680448,
      "grad_norm": 0.09042786061763763,
      "learning_rate": 9.564423375815978e-06,
      "loss": 0.0763,
      "step": 1121
    },
    {
      "epoch": 0.08719303699098539,
      "grad_norm": 0.3697170913219452,
      "learning_rate": 9.564034815045073e-06,
      "loss": 0.1552,
      "step": 1122
    },
    {
      "epoch": 0.0872707491451663,
      "grad_norm": 0.2229427844285965,
      "learning_rate": 9.56364625427417e-06,
      "loss": 0.396,
      "step": 1123
    },
    {
      "epoch": 0.08734846129934722,
      "grad_norm": 0.3272509276866913,
      "learning_rate": 9.563257693503265e-06,
      "loss": 0.1425,
      "step": 1124
    },
    {
      "epoch": 0.08742617345352813,
      "grad_norm": 0.5377213954925537,
      "learning_rate": 9.56286913273236e-06,
      "loss": 0.1381,
      "step": 1125
    },
    {
      "epoch": 0.08750388560770904,
      "grad_norm": 0.4056166410446167,
      "learning_rate": 9.562480571961455e-06,
      "loss": 0.4991,
      "step": 1126
    },
    {
      "epoch": 0.08758159776188996,
      "grad_norm": 0.21877221763134003,
      "learning_rate": 9.562092011190551e-06,
      "loss": 0.2285,
      "step": 1127
    },
    {
      "epoch": 0.08765930991607088,
      "grad_norm": 0.47091615200042725,
      "learning_rate": 9.561703450419646e-06,
      "loss": 0.6196,
      "step": 1128
    },
    {
      "epoch": 0.08773702207025179,
      "grad_norm": 0.2203252762556076,
      "learning_rate": 9.561314889648741e-06,
      "loss": 0.0812,
      "step": 1129
    },
    {
      "epoch": 0.0878147342244327,
      "grad_norm": 0.1649419367313385,
      "learning_rate": 9.560926328877838e-06,
      "loss": 0.1009,
      "step": 1130
    },
    {
      "epoch": 0.08789244637861361,
      "grad_norm": 0.3909427523612976,
      "learning_rate": 9.560537768106933e-06,
      "loss": 0.4299,
      "step": 1131
    },
    {
      "epoch": 0.08797015853279452,
      "grad_norm": 0.32315489649772644,
      "learning_rate": 9.560149207336028e-06,
      "loss": 0.3069,
      "step": 1132
    },
    {
      "epoch": 0.08804787068697545,
      "grad_norm": 0.13539013266563416,
      "learning_rate": 9.559760646565124e-06,
      "loss": 0.098,
      "step": 1133
    },
    {
      "epoch": 0.08812558284115636,
      "grad_norm": 0.07851865142583847,
      "learning_rate": 9.559372085794218e-06,
      "loss": 0.0705,
      "step": 1134
    },
    {
      "epoch": 0.08820329499533727,
      "grad_norm": 0.39601510763168335,
      "learning_rate": 9.558983525023314e-06,
      "loss": 0.2835,
      "step": 1135
    },
    {
      "epoch": 0.08828100714951818,
      "grad_norm": 0.4034166634082794,
      "learning_rate": 9.55859496425241e-06,
      "loss": 0.1898,
      "step": 1136
    },
    {
      "epoch": 0.0883587193036991,
      "grad_norm": 0.2752765417098999,
      "learning_rate": 9.558206403481504e-06,
      "loss": 0.7419,
      "step": 1137
    },
    {
      "epoch": 0.08843643145788001,
      "grad_norm": 0.16850876808166504,
      "learning_rate": 9.5578178427106e-06,
      "loss": 0.174,
      "step": 1138
    },
    {
      "epoch": 0.08851414361206093,
      "grad_norm": 0.39201653003692627,
      "learning_rate": 9.557429281939696e-06,
      "loss": 0.3335,
      "step": 1139
    },
    {
      "epoch": 0.08859185576624184,
      "grad_norm": 0.31337934732437134,
      "learning_rate": 9.557040721168792e-06,
      "loss": 0.3297,
      "step": 1140
    },
    {
      "epoch": 0.08866956792042276,
      "grad_norm": 0.2265615165233612,
      "learning_rate": 9.556652160397887e-06,
      "loss": 0.1565,
      "step": 1141
    },
    {
      "epoch": 0.08874728007460367,
      "grad_norm": 0.10699092596769333,
      "learning_rate": 9.556263599626982e-06,
      "loss": 0.033,
      "step": 1142
    },
    {
      "epoch": 0.08882499222878458,
      "grad_norm": 0.15584544837474823,
      "learning_rate": 9.555875038856079e-06,
      "loss": 0.1708,
      "step": 1143
    },
    {
      "epoch": 0.08890270438296549,
      "grad_norm": 0.37571731209754944,
      "learning_rate": 9.555486478085172e-06,
      "loss": 0.746,
      "step": 1144
    },
    {
      "epoch": 0.0889804165371464,
      "grad_norm": 0.4687831401824951,
      "learning_rate": 9.555097917314269e-06,
      "loss": 0.3938,
      "step": 1145
    },
    {
      "epoch": 0.08905812869132733,
      "grad_norm": 0.18174104392528534,
      "learning_rate": 9.554709356543364e-06,
      "loss": 0.148,
      "step": 1146
    },
    {
      "epoch": 0.08913584084550824,
      "grad_norm": 0.523868203163147,
      "learning_rate": 9.554320795772459e-06,
      "loss": 0.5559,
      "step": 1147
    },
    {
      "epoch": 0.08921355299968915,
      "grad_norm": 0.14628374576568604,
      "learning_rate": 9.553932235001555e-06,
      "loss": 0.1138,
      "step": 1148
    },
    {
      "epoch": 0.08929126515387006,
      "grad_norm": 0.19835777580738068,
      "learning_rate": 9.55354367423065e-06,
      "loss": 0.0851,
      "step": 1149
    },
    {
      "epoch": 0.08936897730805098,
      "grad_norm": 0.14179079234600067,
      "learning_rate": 9.553155113459745e-06,
      "loss": 0.1836,
      "step": 1150
    },
    {
      "epoch": 0.08944668946223189,
      "grad_norm": 0.32194796204566956,
      "learning_rate": 9.552766552688842e-06,
      "loss": 0.1006,
      "step": 1151
    },
    {
      "epoch": 0.08952440161641281,
      "grad_norm": 0.13140107691287994,
      "learning_rate": 9.552377991917937e-06,
      "loss": 0.0463,
      "step": 1152
    },
    {
      "epoch": 0.08960211377059372,
      "grad_norm": 0.2816099524497986,
      "learning_rate": 9.551989431147032e-06,
      "loss": 0.1312,
      "step": 1153
    },
    {
      "epoch": 0.08967982592477464,
      "grad_norm": 0.08229105174541473,
      "learning_rate": 9.551600870376127e-06,
      "loss": 0.0196,
      "step": 1154
    },
    {
      "epoch": 0.08975753807895555,
      "grad_norm": 0.1009383350610733,
      "learning_rate": 9.551212309605223e-06,
      "loss": 0.053,
      "step": 1155
    },
    {
      "epoch": 0.08983525023313646,
      "grad_norm": 0.804273247718811,
      "learning_rate": 9.550823748834318e-06,
      "loss": 0.225,
      "step": 1156
    },
    {
      "epoch": 0.08991296238731737,
      "grad_norm": 0.12631282210350037,
      "learning_rate": 9.550435188063413e-06,
      "loss": 0.1182,
      "step": 1157
    },
    {
      "epoch": 0.0899906745414983,
      "grad_norm": 0.2249397188425064,
      "learning_rate": 9.55004662729251e-06,
      "loss": 0.1913,
      "step": 1158
    },
    {
      "epoch": 0.09006838669567921,
      "grad_norm": 0.16635988652706146,
      "learning_rate": 9.549658066521605e-06,
      "loss": 0.096,
      "step": 1159
    },
    {
      "epoch": 0.09014609884986012,
      "grad_norm": 0.0724811851978302,
      "learning_rate": 9.5492695057507e-06,
      "loss": 0.0892,
      "step": 1160
    },
    {
      "epoch": 0.09022381100404103,
      "grad_norm": 0.24578996002674103,
      "learning_rate": 9.548880944979797e-06,
      "loss": 0.1449,
      "step": 1161
    },
    {
      "epoch": 0.09030152315822194,
      "grad_norm": 0.06792175769805908,
      "learning_rate": 9.54849238420889e-06,
      "loss": 0.025,
      "step": 1162
    },
    {
      "epoch": 0.09037923531240286,
      "grad_norm": 0.10782980918884277,
      "learning_rate": 9.548103823437986e-06,
      "loss": 0.0407,
      "step": 1163
    },
    {
      "epoch": 0.09045694746658377,
      "grad_norm": 0.20528732240200043,
      "learning_rate": 9.547715262667081e-06,
      "loss": 0.1871,
      "step": 1164
    },
    {
      "epoch": 0.0905346596207647,
      "grad_norm": 0.32014989852905273,
      "learning_rate": 9.547326701896176e-06,
      "loss": 0.1757,
      "step": 1165
    },
    {
      "epoch": 0.0906123717749456,
      "grad_norm": 0.14142386615276337,
      "learning_rate": 9.546938141125273e-06,
      "loss": 0.137,
      "step": 1166
    },
    {
      "epoch": 0.09069008392912652,
      "grad_norm": 0.24548588693141937,
      "learning_rate": 9.546549580354368e-06,
      "loss": 0.4216,
      "step": 1167
    },
    {
      "epoch": 0.09076779608330743,
      "grad_norm": 0.2688838541507721,
      "learning_rate": 9.546161019583463e-06,
      "loss": 0.2393,
      "step": 1168
    },
    {
      "epoch": 0.09084550823748834,
      "grad_norm": 0.12269497662782669,
      "learning_rate": 9.54577245881256e-06,
      "loss": 0.0727,
      "step": 1169
    },
    {
      "epoch": 0.09092322039166925,
      "grad_norm": 0.12796470522880554,
      "learning_rate": 9.545383898041654e-06,
      "loss": 0.0722,
      "step": 1170
    },
    {
      "epoch": 0.09100093254585018,
      "grad_norm": 0.6796514391899109,
      "learning_rate": 9.544995337270751e-06,
      "loss": 0.4445,
      "step": 1171
    },
    {
      "epoch": 0.09107864470003109,
      "grad_norm": 0.15444202721118927,
      "learning_rate": 9.544606776499844e-06,
      "loss": 0.052,
      "step": 1172
    },
    {
      "epoch": 0.091156356854212,
      "grad_norm": 0.17331762611865997,
      "learning_rate": 9.544218215728941e-06,
      "loss": 0.077,
      "step": 1173
    },
    {
      "epoch": 0.09123406900839291,
      "grad_norm": 0.11910835653543472,
      "learning_rate": 9.543829654958036e-06,
      "loss": 0.0484,
      "step": 1174
    },
    {
      "epoch": 0.09131178116257382,
      "grad_norm": 0.29059717059135437,
      "learning_rate": 9.543441094187131e-06,
      "loss": 0.1678,
      "step": 1175
    },
    {
      "epoch": 0.09138949331675474,
      "grad_norm": 0.2175552248954773,
      "learning_rate": 9.543052533416228e-06,
      "loss": 0.2295,
      "step": 1176
    },
    {
      "epoch": 0.09146720547093565,
      "grad_norm": 0.13878710567951202,
      "learning_rate": 9.542663972645323e-06,
      "loss": 0.1058,
      "step": 1177
    },
    {
      "epoch": 0.09154491762511657,
      "grad_norm": 0.9394898414611816,
      "learning_rate": 9.542275411874417e-06,
      "loss": 0.4351,
      "step": 1178
    },
    {
      "epoch": 0.09162262977929748,
      "grad_norm": 0.12110123783349991,
      "learning_rate": 9.541886851103514e-06,
      "loss": 0.077,
      "step": 1179
    },
    {
      "epoch": 0.0917003419334784,
      "grad_norm": 0.28348901867866516,
      "learning_rate": 9.541498290332609e-06,
      "loss": 0.1041,
      "step": 1180
    },
    {
      "epoch": 0.09177805408765931,
      "grad_norm": 0.14614221453666687,
      "learning_rate": 9.541109729561704e-06,
      "loss": 0.1649,
      "step": 1181
    },
    {
      "epoch": 0.09185576624184022,
      "grad_norm": 0.04662619158625603,
      "learning_rate": 9.540721168790799e-06,
      "loss": 0.0122,
      "step": 1182
    },
    {
      "epoch": 0.09193347839602113,
      "grad_norm": 0.22685571014881134,
      "learning_rate": 9.540332608019896e-06,
      "loss": 0.1306,
      "step": 1183
    },
    {
      "epoch": 0.09201119055020206,
      "grad_norm": 2.3578999042510986,
      "learning_rate": 9.53994404724899e-06,
      "loss": 0.6616,
      "step": 1184
    },
    {
      "epoch": 0.09208890270438297,
      "grad_norm": 0.24970602989196777,
      "learning_rate": 9.539555486478086e-06,
      "loss": 0.3138,
      "step": 1185
    },
    {
      "epoch": 0.09216661485856388,
      "grad_norm": 0.3199756145477295,
      "learning_rate": 9.539166925707182e-06,
      "loss": 0.1965,
      "step": 1186
    },
    {
      "epoch": 0.09224432701274479,
      "grad_norm": 0.18061721324920654,
      "learning_rate": 9.538778364936277e-06,
      "loss": 0.021,
      "step": 1187
    },
    {
      "epoch": 0.0923220391669257,
      "grad_norm": 0.13359223306179047,
      "learning_rate": 9.538389804165372e-06,
      "loss": 0.0945,
      "step": 1188
    },
    {
      "epoch": 0.09239975132110662,
      "grad_norm": 0.1761380434036255,
      "learning_rate": 9.538001243394469e-06,
      "loss": 0.1544,
      "step": 1189
    },
    {
      "epoch": 0.09247746347528754,
      "grad_norm": 0.40098273754119873,
      "learning_rate": 9.537612682623562e-06,
      "loss": 0.3937,
      "step": 1190
    },
    {
      "epoch": 0.09255517562946845,
      "grad_norm": 0.2567724287509918,
      "learning_rate": 9.537224121852659e-06,
      "loss": 0.2202,
      "step": 1191
    },
    {
      "epoch": 0.09263288778364936,
      "grad_norm": 0.2378484159708023,
      "learning_rate": 9.536835561081754e-06,
      "loss": 0.1156,
      "step": 1192
    },
    {
      "epoch": 0.09271059993783028,
      "grad_norm": 0.23052972555160522,
      "learning_rate": 9.536447000310848e-06,
      "loss": 0.1873,
      "step": 1193
    },
    {
      "epoch": 0.09278831209201119,
      "grad_norm": 0.06660136580467224,
      "learning_rate": 9.536058439539945e-06,
      "loss": 0.1946,
      "step": 1194
    },
    {
      "epoch": 0.0928660242461921,
      "grad_norm": 0.2180863618850708,
      "learning_rate": 9.53566987876904e-06,
      "loss": 0.1953,
      "step": 1195
    },
    {
      "epoch": 0.09294373640037301,
      "grad_norm": 0.24593250453472137,
      "learning_rate": 9.535281317998135e-06,
      "loss": 0.1918,
      "step": 1196
    },
    {
      "epoch": 0.09302144855455394,
      "grad_norm": 0.27036359906196594,
      "learning_rate": 9.534892757227232e-06,
      "loss": 0.0795,
      "step": 1197
    },
    {
      "epoch": 0.09309916070873485,
      "grad_norm": 0.3318239748477936,
      "learning_rate": 9.534504196456327e-06,
      "loss": 0.1416,
      "step": 1198
    },
    {
      "epoch": 0.09317687286291576,
      "grad_norm": 0.16444623470306396,
      "learning_rate": 9.534115635685423e-06,
      "loss": 0.2874,
      "step": 1199
    },
    {
      "epoch": 0.09325458501709667,
      "grad_norm": 0.17871610820293427,
      "learning_rate": 9.533727074914517e-06,
      "loss": 0.1301,
      "step": 1200
    },
    {
      "epoch": 0.09333229717127758,
      "grad_norm": 0.2997511327266693,
      "learning_rate": 9.533338514143613e-06,
      "loss": 0.3112,
      "step": 1201
    },
    {
      "epoch": 0.0934100093254585,
      "grad_norm": 0.2618049681186676,
      "learning_rate": 9.532949953372708e-06,
      "loss": 0.0549,
      "step": 1202
    },
    {
      "epoch": 0.09348772147963942,
      "grad_norm": 0.09671881049871445,
      "learning_rate": 9.532561392601803e-06,
      "loss": 0.0424,
      "step": 1203
    },
    {
      "epoch": 0.09356543363382033,
      "grad_norm": 0.30923229455947876,
      "learning_rate": 9.5321728318309e-06,
      "loss": 0.2903,
      "step": 1204
    },
    {
      "epoch": 0.09364314578800124,
      "grad_norm": 0.20377656817436218,
      "learning_rate": 9.531784271059995e-06,
      "loss": 0.101,
      "step": 1205
    },
    {
      "epoch": 0.09372085794218216,
      "grad_norm": 0.33426928520202637,
      "learning_rate": 9.53139571028909e-06,
      "loss": 0.0357,
      "step": 1206
    },
    {
      "epoch": 0.09379857009636307,
      "grad_norm": 0.3390169143676758,
      "learning_rate": 9.531007149518186e-06,
      "loss": 0.3968,
      "step": 1207
    },
    {
      "epoch": 0.09387628225054398,
      "grad_norm": 0.27092504501342773,
      "learning_rate": 9.530618588747281e-06,
      "loss": 0.2903,
      "step": 1208
    },
    {
      "epoch": 0.0939539944047249,
      "grad_norm": 0.20301492512226105,
      "learning_rate": 9.530230027976376e-06,
      "loss": 0.1827,
      "step": 1209
    },
    {
      "epoch": 0.09403170655890582,
      "grad_norm": 0.49619606137275696,
      "learning_rate": 9.529841467205471e-06,
      "loss": 0.1536,
      "step": 1210
    },
    {
      "epoch": 0.09410941871308673,
      "grad_norm": 0.27916356921195984,
      "learning_rate": 9.529452906434568e-06,
      "loss": 0.2418,
      "step": 1211
    },
    {
      "epoch": 0.09418713086726764,
      "grad_norm": 0.6209473609924316,
      "learning_rate": 9.529064345663663e-06,
      "loss": 0.3731,
      "step": 1212
    },
    {
      "epoch": 0.09426484302144855,
      "grad_norm": 0.5201990008354187,
      "learning_rate": 9.528675784892758e-06,
      "loss": 0.4097,
      "step": 1213
    },
    {
      "epoch": 0.09434255517562946,
      "grad_norm": 0.13871535658836365,
      "learning_rate": 9.528287224121854e-06,
      "loss": 0.1018,
      "step": 1214
    },
    {
      "epoch": 0.09442026732981038,
      "grad_norm": 0.22993755340576172,
      "learning_rate": 9.52789866335095e-06,
      "loss": 0.1824,
      "step": 1215
    },
    {
      "epoch": 0.0944979794839913,
      "grad_norm": 0.5211188197135925,
      "learning_rate": 9.527510102580044e-06,
      "loss": 0.898,
      "step": 1216
    },
    {
      "epoch": 0.09457569163817221,
      "grad_norm": 0.15023018419742584,
      "learning_rate": 9.52712154180914e-06,
      "loss": 0.129,
      "step": 1217
    },
    {
      "epoch": 0.09465340379235312,
      "grad_norm": 0.272235631942749,
      "learning_rate": 9.526732981038234e-06,
      "loss": 0.1156,
      "step": 1218
    },
    {
      "epoch": 0.09473111594653404,
      "grad_norm": 0.32755517959594727,
      "learning_rate": 9.52634442026733e-06,
      "loss": 0.3449,
      "step": 1219
    },
    {
      "epoch": 0.09480882810071495,
      "grad_norm": 0.4212915897369385,
      "learning_rate": 9.525955859496426e-06,
      "loss": 0.2836,
      "step": 1220
    },
    {
      "epoch": 0.09488654025489586,
      "grad_norm": 0.08478236943483353,
      "learning_rate": 9.52556729872552e-06,
      "loss": 0.027,
      "step": 1221
    },
    {
      "epoch": 0.09496425240907679,
      "grad_norm": 0.3505233824253082,
      "learning_rate": 9.525178737954617e-06,
      "loss": 0.136,
      "step": 1222
    },
    {
      "epoch": 0.0950419645632577,
      "grad_norm": 0.22913557291030884,
      "learning_rate": 9.524790177183712e-06,
      "loss": 0.1431,
      "step": 1223
    },
    {
      "epoch": 0.09511967671743861,
      "grad_norm": 0.1467556208372116,
      "learning_rate": 9.524401616412807e-06,
      "loss": 0.0892,
      "step": 1224
    },
    {
      "epoch": 0.09519738887161952,
      "grad_norm": 0.20646893978118896,
      "learning_rate": 9.524013055641904e-06,
      "loss": 0.1341,
      "step": 1225
    },
    {
      "epoch": 0.09527510102580043,
      "grad_norm": 0.29751133918762207,
      "learning_rate": 9.523624494870999e-06,
      "loss": 0.4445,
      "step": 1226
    },
    {
      "epoch": 0.09535281317998134,
      "grad_norm": 0.14688269793987274,
      "learning_rate": 9.523235934100094e-06,
      "loss": 0.0819,
      "step": 1227
    },
    {
      "epoch": 0.09543052533416227,
      "grad_norm": 0.15519610047340393,
      "learning_rate": 9.522847373329189e-06,
      "loss": 0.1707,
      "step": 1228
    },
    {
      "epoch": 0.09550823748834318,
      "grad_norm": 0.08439460396766663,
      "learning_rate": 9.522458812558285e-06,
      "loss": 0.0544,
      "step": 1229
    },
    {
      "epoch": 0.09558594964252409,
      "grad_norm": 0.34721073508262634,
      "learning_rate": 9.52207025178738e-06,
      "loss": 0.1442,
      "step": 1230
    },
    {
      "epoch": 0.095663661796705,
      "grad_norm": 0.20684243738651276,
      "learning_rate": 9.521681691016475e-06,
      "loss": 0.2268,
      "step": 1231
    },
    {
      "epoch": 0.09574137395088592,
      "grad_norm": 0.40441954135894775,
      "learning_rate": 9.521293130245572e-06,
      "loss": 0.4125,
      "step": 1232
    },
    {
      "epoch": 0.09581908610506683,
      "grad_norm": 0.21894827485084534,
      "learning_rate": 9.520904569474667e-06,
      "loss": 0.2769,
      "step": 1233
    },
    {
      "epoch": 0.09589679825924774,
      "grad_norm": 0.4143129289150238,
      "learning_rate": 9.520516008703762e-06,
      "loss": 0.2455,
      "step": 1234
    },
    {
      "epoch": 0.09597451041342867,
      "grad_norm": 0.04064133018255234,
      "learning_rate": 9.520127447932858e-06,
      "loss": 0.0066,
      "step": 1235
    },
    {
      "epoch": 0.09605222256760958,
      "grad_norm": 0.31500497460365295,
      "learning_rate": 9.519738887161953e-06,
      "loss": 0.1814,
      "step": 1236
    },
    {
      "epoch": 0.09612993472179049,
      "grad_norm": 0.11231385916471481,
      "learning_rate": 9.519350326391048e-06,
      "loss": 0.0623,
      "step": 1237
    },
    {
      "epoch": 0.0962076468759714,
      "grad_norm": 0.06151483952999115,
      "learning_rate": 9.518961765620143e-06,
      "loss": 0.0092,
      "step": 1238
    },
    {
      "epoch": 0.09628535903015231,
      "grad_norm": 0.23738546669483185,
      "learning_rate": 9.51857320484924e-06,
      "loss": 0.2211,
      "step": 1239
    },
    {
      "epoch": 0.09636307118433322,
      "grad_norm": 0.0745132640004158,
      "learning_rate": 9.518184644078335e-06,
      "loss": 0.0195,
      "step": 1240
    },
    {
      "epoch": 0.09644078333851415,
      "grad_norm": 0.3842211067676544,
      "learning_rate": 9.51779608330743e-06,
      "loss": 0.3402,
      "step": 1241
    },
    {
      "epoch": 0.09651849549269506,
      "grad_norm": 0.6459692120552063,
      "learning_rate": 9.517407522536526e-06,
      "loss": 0.5666,
      "step": 1242
    },
    {
      "epoch": 0.09659620764687597,
      "grad_norm": 0.06187533214688301,
      "learning_rate": 9.517018961765621e-06,
      "loss": 0.029,
      "step": 1243
    },
    {
      "epoch": 0.09667391980105688,
      "grad_norm": 0.2090577483177185,
      "learning_rate": 9.516630400994716e-06,
      "loss": 0.1033,
      "step": 1244
    },
    {
      "epoch": 0.0967516319552378,
      "grad_norm": 0.2983941435813904,
      "learning_rate": 9.516241840223813e-06,
      "loss": 0.2916,
      "step": 1245
    },
    {
      "epoch": 0.09682934410941871,
      "grad_norm": 0.25965172052383423,
      "learning_rate": 9.515853279452906e-06,
      "loss": 0.1722,
      "step": 1246
    },
    {
      "epoch": 0.09690705626359963,
      "grad_norm": 0.12790429592132568,
      "learning_rate": 9.515464718682003e-06,
      "loss": 0.0373,
      "step": 1247
    },
    {
      "epoch": 0.09698476841778055,
      "grad_norm": 0.45587778091430664,
      "learning_rate": 9.515076157911098e-06,
      "loss": 0.5074,
      "step": 1248
    },
    {
      "epoch": 0.09706248057196146,
      "grad_norm": 0.3534446656703949,
      "learning_rate": 9.514687597140193e-06,
      "loss": 0.2862,
      "step": 1249
    },
    {
      "epoch": 0.09714019272614237,
      "grad_norm": 0.40604934096336365,
      "learning_rate": 9.51429903636929e-06,
      "loss": 0.3872,
      "step": 1250
    },
    {
      "epoch": 0.09721790488032328,
      "grad_norm": 0.24946165084838867,
      "learning_rate": 9.513910475598384e-06,
      "loss": 0.0609,
      "step": 1251
    },
    {
      "epoch": 0.09729561703450419,
      "grad_norm": 0.298307865858078,
      "learning_rate": 9.51352191482748e-06,
      "loss": 0.0806,
      "step": 1252
    },
    {
      "epoch": 0.0973733291886851,
      "grad_norm": 0.18534353375434875,
      "learning_rate": 9.513133354056574e-06,
      "loss": 0.0759,
      "step": 1253
    },
    {
      "epoch": 0.09745104134286603,
      "grad_norm": 0.48862624168395996,
      "learning_rate": 9.512744793285671e-06,
      "loss": 0.2515,
      "step": 1254
    },
    {
      "epoch": 0.09752875349704694,
      "grad_norm": 0.0841854140162468,
      "learning_rate": 9.512356232514766e-06,
      "loss": 0.0641,
      "step": 1255
    },
    {
      "epoch": 0.09760646565122785,
      "grad_norm": 0.37169161438941956,
      "learning_rate": 9.51196767174386e-06,
      "loss": 0.2372,
      "step": 1256
    },
    {
      "epoch": 0.09768417780540876,
      "grad_norm": 0.1278810203075409,
      "learning_rate": 9.511579110972957e-06,
      "loss": 0.0942,
      "step": 1257
    },
    {
      "epoch": 0.09776188995958968,
      "grad_norm": 0.36402201652526855,
      "learning_rate": 9.511190550202052e-06,
      "loss": 0.1644,
      "step": 1258
    },
    {
      "epoch": 0.09783960211377059,
      "grad_norm": 0.60848069190979,
      "learning_rate": 9.510801989431147e-06,
      "loss": 0.2516,
      "step": 1259
    },
    {
      "epoch": 0.09791731426795151,
      "grad_norm": 0.356897234916687,
      "learning_rate": 9.510413428660244e-06,
      "loss": 0.7067,
      "step": 1260
    },
    {
      "epoch": 0.09799502642213243,
      "grad_norm": 0.0967707633972168,
      "learning_rate": 9.510024867889339e-06,
      "loss": 0.0426,
      "step": 1261
    },
    {
      "epoch": 0.09807273857631334,
      "grad_norm": 0.022421641275286674,
      "learning_rate": 9.509636307118434e-06,
      "loss": 0.0031,
      "step": 1262
    },
    {
      "epoch": 0.09815045073049425,
      "grad_norm": 0.23635445535182953,
      "learning_rate": 9.509247746347529e-06,
      "loss": 0.2295,
      "step": 1263
    },
    {
      "epoch": 0.09822816288467516,
      "grad_norm": 0.07130087912082672,
      "learning_rate": 9.508859185576626e-06,
      "loss": 0.0218,
      "step": 1264
    },
    {
      "epoch": 0.09830587503885607,
      "grad_norm": 0.31433889269828796,
      "learning_rate": 9.50847062480572e-06,
      "loss": 0.2185,
      "step": 1265
    },
    {
      "epoch": 0.098383587193037,
      "grad_norm": 0.6033232808113098,
      "learning_rate": 9.508082064034815e-06,
      "loss": 0.7605,
      "step": 1266
    },
    {
      "epoch": 0.09846129934721791,
      "grad_norm": 0.539399266242981,
      "learning_rate": 9.507693503263912e-06,
      "loss": 0.1098,
      "step": 1267
    },
    {
      "epoch": 0.09853901150139882,
      "grad_norm": 0.19594255089759827,
      "learning_rate": 9.507304942493007e-06,
      "loss": 0.2351,
      "step": 1268
    },
    {
      "epoch": 0.09861672365557973,
      "grad_norm": 0.2470581978559494,
      "learning_rate": 9.506916381722102e-06,
      "loss": 0.3112,
      "step": 1269
    },
    {
      "epoch": 0.09869443580976064,
      "grad_norm": 0.18199552595615387,
      "learning_rate": 9.506527820951199e-06,
      "loss": 0.0574,
      "step": 1270
    },
    {
      "epoch": 0.09877214796394156,
      "grad_norm": 0.2686227858066559,
      "learning_rate": 9.506139260180292e-06,
      "loss": 0.1649,
      "step": 1271
    },
    {
      "epoch": 0.09884986011812247,
      "grad_norm": 0.20977388322353363,
      "learning_rate": 9.505750699409388e-06,
      "loss": 0.1396,
      "step": 1272
    },
    {
      "epoch": 0.0989275722723034,
      "grad_norm": 0.2844950258731842,
      "learning_rate": 9.505362138638483e-06,
      "loss": 0.2862,
      "step": 1273
    },
    {
      "epoch": 0.0990052844264843,
      "grad_norm": 0.38594821095466614,
      "learning_rate": 9.504973577867578e-06,
      "loss": 0.2221,
      "step": 1274
    },
    {
      "epoch": 0.09908299658066522,
      "grad_norm": 0.14914558827877045,
      "learning_rate": 9.504585017096675e-06,
      "loss": 0.0527,
      "step": 1275
    },
    {
      "epoch": 0.09916070873484613,
      "grad_norm": 0.13642637431621552,
      "learning_rate": 9.50419645632577e-06,
      "loss": 0.0793,
      "step": 1276
    },
    {
      "epoch": 0.09923842088902704,
      "grad_norm": 0.31896838545799255,
      "learning_rate": 9.503807895554865e-06,
      "loss": 0.1526,
      "step": 1277
    },
    {
      "epoch": 0.09931613304320795,
      "grad_norm": 0.3855724036693573,
      "learning_rate": 9.503419334783962e-06,
      "loss": 0.2855,
      "step": 1278
    },
    {
      "epoch": 0.09939384519738888,
      "grad_norm": 1.2355021238327026,
      "learning_rate": 9.503030774013057e-06,
      "loss": 0.5871,
      "step": 1279
    },
    {
      "epoch": 0.09947155735156979,
      "grad_norm": 0.4266521632671356,
      "learning_rate": 9.502642213242151e-06,
      "loss": 0.2774,
      "step": 1280
    },
    {
      "epoch": 0.0995492695057507,
      "grad_norm": 0.1451820582151413,
      "learning_rate": 9.502253652471246e-06,
      "loss": 0.1743,
      "step": 1281
    },
    {
      "epoch": 0.09962698165993161,
      "grad_norm": 0.12434141337871552,
      "learning_rate": 9.501865091700343e-06,
      "loss": 0.0648,
      "step": 1282
    },
    {
      "epoch": 0.09970469381411252,
      "grad_norm": 0.2640962600708008,
      "learning_rate": 9.501476530929438e-06,
      "loss": 0.2959,
      "step": 1283
    },
    {
      "epoch": 0.09978240596829344,
      "grad_norm": 0.6328630447387695,
      "learning_rate": 9.501087970158533e-06,
      "loss": 0.4649,
      "step": 1284
    },
    {
      "epoch": 0.09986011812247436,
      "grad_norm": 0.3098548650741577,
      "learning_rate": 9.50069940938763e-06,
      "loss": 0.3606,
      "step": 1285
    },
    {
      "epoch": 0.09993783027665527,
      "grad_norm": 0.14304521679878235,
      "learning_rate": 9.500310848616725e-06,
      "loss": 0.1043,
      "step": 1286
    },
    {
      "epoch": 0.10001554243083619,
      "grad_norm": 0.10523908585309982,
      "learning_rate": 9.49992228784582e-06,
      "loss": 0.1712,
      "step": 1287
    },
    {
      "epoch": 0.1000932545850171,
      "grad_norm": 0.6225690841674805,
      "learning_rate": 9.499533727074916e-06,
      "loss": 0.6306,
      "step": 1288
    },
    {
      "epoch": 0.10017096673919801,
      "grad_norm": 0.03439825028181076,
      "learning_rate": 9.49914516630401e-06,
      "loss": 0.008,
      "step": 1289
    },
    {
      "epoch": 0.10024867889337892,
      "grad_norm": 0.07413963228464127,
      "learning_rate": 9.498756605533106e-06,
      "loss": 0.0317,
      "step": 1290
    },
    {
      "epoch": 0.10032639104755983,
      "grad_norm": 0.2289637178182602,
      "learning_rate": 9.498368044762201e-06,
      "loss": 0.2557,
      "step": 1291
    },
    {
      "epoch": 0.10040410320174076,
      "grad_norm": 0.4575936794281006,
      "learning_rate": 9.497979483991298e-06,
      "loss": 0.4255,
      "step": 1292
    },
    {
      "epoch": 0.10048181535592167,
      "grad_norm": 0.9397498965263367,
      "learning_rate": 9.497590923220393e-06,
      "loss": 0.6008,
      "step": 1293
    },
    {
      "epoch": 0.10055952751010258,
      "grad_norm": 0.16109046339988708,
      "learning_rate": 9.497202362449488e-06,
      "loss": 0.0612,
      "step": 1294
    },
    {
      "epoch": 0.10063723966428349,
      "grad_norm": 0.5199317336082458,
      "learning_rate": 9.496813801678584e-06,
      "loss": 0.5626,
      "step": 1295
    },
    {
      "epoch": 0.1007149518184644,
      "grad_norm": 0.39185261726379395,
      "learning_rate": 9.496425240907679e-06,
      "loss": 0.5925,
      "step": 1296
    },
    {
      "epoch": 0.10079266397264532,
      "grad_norm": 0.0755629763007164,
      "learning_rate": 9.496036680136774e-06,
      "loss": 0.0505,
      "step": 1297
    },
    {
      "epoch": 0.10087037612682624,
      "grad_norm": 0.1476200968027115,
      "learning_rate": 9.49564811936587e-06,
      "loss": 0.0724,
      "step": 1298
    },
    {
      "epoch": 0.10094808828100715,
      "grad_norm": 0.13997036218643188,
      "learning_rate": 9.495259558594964e-06,
      "loss": 0.1581,
      "step": 1299
    },
    {
      "epoch": 0.10102580043518807,
      "grad_norm": 0.2964170575141907,
      "learning_rate": 9.49487099782406e-06,
      "loss": 0.1855,
      "step": 1300
    },
    {
      "epoch": 0.10110351258936898,
      "grad_norm": 0.13418081402778625,
      "learning_rate": 9.494482437053156e-06,
      "loss": 0.0608,
      "step": 1301
    },
    {
      "epoch": 0.10118122474354989,
      "grad_norm": 0.2061980813741684,
      "learning_rate": 9.49409387628225e-06,
      "loss": 0.1526,
      "step": 1302
    },
    {
      "epoch": 0.1012589368977308,
      "grad_norm": 0.099245086312294,
      "learning_rate": 9.493705315511347e-06,
      "loss": 0.056,
      "step": 1303
    },
    {
      "epoch": 0.10133664905191173,
      "grad_norm": 0.13465942442417145,
      "learning_rate": 9.493316754740442e-06,
      "loss": 0.0686,
      "step": 1304
    },
    {
      "epoch": 0.10141436120609264,
      "grad_norm": 0.1980075240135193,
      "learning_rate": 9.492928193969537e-06,
      "loss": 0.1914,
      "step": 1305
    },
    {
      "epoch": 0.10149207336027355,
      "grad_norm": 0.17787101864814758,
      "learning_rate": 9.492539633198634e-06,
      "loss": 0.2138,
      "step": 1306
    },
    {
      "epoch": 0.10156978551445446,
      "grad_norm": 0.21950891613960266,
      "learning_rate": 9.492151072427729e-06,
      "loss": 0.1358,
      "step": 1307
    },
    {
      "epoch": 0.10164749766863537,
      "grad_norm": 0.07845785468816757,
      "learning_rate": 9.491762511656824e-06,
      "loss": 0.1054,
      "step": 1308
    },
    {
      "epoch": 0.10172520982281628,
      "grad_norm": 0.09582370519638062,
      "learning_rate": 9.491373950885919e-06,
      "loss": 0.0545,
      "step": 1309
    },
    {
      "epoch": 0.1018029219769972,
      "grad_norm": 0.6342707872390747,
      "learning_rate": 9.490985390115015e-06,
      "loss": 0.4334,
      "step": 1310
    },
    {
      "epoch": 0.10188063413117812,
      "grad_norm": 0.20995928347110748,
      "learning_rate": 9.49059682934411e-06,
      "loss": 0.1968,
      "step": 1311
    },
    {
      "epoch": 0.10195834628535903,
      "grad_norm": 0.4858623147010803,
      "learning_rate": 9.490208268573205e-06,
      "loss": 0.1235,
      "step": 1312
    },
    {
      "epoch": 0.10203605843953995,
      "grad_norm": 0.3290741741657257,
      "learning_rate": 9.489819707802302e-06,
      "loss": 0.1316,
      "step": 1313
    },
    {
      "epoch": 0.10211377059372086,
      "grad_norm": 0.1750931292772293,
      "learning_rate": 9.489431147031397e-06,
      "loss": 0.0771,
      "step": 1314
    },
    {
      "epoch": 0.10219148274790177,
      "grad_norm": 0.03925305977463722,
      "learning_rate": 9.489042586260492e-06,
      "loss": 0.0358,
      "step": 1315
    },
    {
      "epoch": 0.10226919490208268,
      "grad_norm": 0.18167158961296082,
      "learning_rate": 9.488654025489588e-06,
      "loss": 0.1589,
      "step": 1316
    },
    {
      "epoch": 0.1023469070562636,
      "grad_norm": 0.14018966257572174,
      "learning_rate": 9.488265464718682e-06,
      "loss": 0.1228,
      "step": 1317
    },
    {
      "epoch": 0.10242461921044452,
      "grad_norm": 0.15528927743434906,
      "learning_rate": 9.487876903947778e-06,
      "loss": 0.0851,
      "step": 1318
    },
    {
      "epoch": 0.10250233136462543,
      "grad_norm": 0.3150981664657593,
      "learning_rate": 9.487488343176873e-06,
      "loss": 0.3022,
      "step": 1319
    },
    {
      "epoch": 0.10258004351880634,
      "grad_norm": 0.1915651112794876,
      "learning_rate": 9.487099782405968e-06,
      "loss": 0.2616,
      "step": 1320
    },
    {
      "epoch": 0.10265775567298725,
      "grad_norm": 0.4346388876438141,
      "learning_rate": 9.486711221635065e-06,
      "loss": 0.6078,
      "step": 1321
    },
    {
      "epoch": 0.10273546782716816,
      "grad_norm": 0.1952485740184784,
      "learning_rate": 9.48632266086416e-06,
      "loss": 0.0311,
      "step": 1322
    },
    {
      "epoch": 0.10281317998134909,
      "grad_norm": 0.034554075449705124,
      "learning_rate": 9.485934100093256e-06,
      "loss": 0.0088,
      "step": 1323
    },
    {
      "epoch": 0.10289089213553,
      "grad_norm": 0.3246555030345917,
      "learning_rate": 9.485545539322351e-06,
      "loss": 0.2171,
      "step": 1324
    },
    {
      "epoch": 0.10296860428971091,
      "grad_norm": 0.31879734992980957,
      "learning_rate": 9.485156978551446e-06,
      "loss": 0.3707,
      "step": 1325
    },
    {
      "epoch": 0.10304631644389182,
      "grad_norm": 0.6439780592918396,
      "learning_rate": 9.484768417780543e-06,
      "loss": 0.9667,
      "step": 1326
    },
    {
      "epoch": 0.10312402859807274,
      "grad_norm": 0.4039216637611389,
      "learning_rate": 9.484379857009636e-06,
      "loss": 0.3581,
      "step": 1327
    },
    {
      "epoch": 0.10320174075225365,
      "grad_norm": 0.5299399495124817,
      "learning_rate": 9.483991296238733e-06,
      "loss": 0.4607,
      "step": 1328
    },
    {
      "epoch": 0.10327945290643456,
      "grad_norm": 0.15864886343479156,
      "learning_rate": 9.483602735467828e-06,
      "loss": 0.6119,
      "step": 1329
    },
    {
      "epoch": 0.10335716506061549,
      "grad_norm": 1.1104248762130737,
      "learning_rate": 9.483214174696923e-06,
      "loss": 0.6032,
      "step": 1330
    },
    {
      "epoch": 0.1034348772147964,
      "grad_norm": 0.08206180483102798,
      "learning_rate": 9.48282561392602e-06,
      "loss": 0.0574,
      "step": 1331
    },
    {
      "epoch": 0.10351258936897731,
      "grad_norm": 0.08879118412733078,
      "learning_rate": 9.482437053155114e-06,
      "loss": 0.0832,
      "step": 1332
    },
    {
      "epoch": 0.10359030152315822,
      "grad_norm": 0.21450544893741608,
      "learning_rate": 9.48204849238421e-06,
      "loss": 0.0455,
      "step": 1333
    },
    {
      "epoch": 0.10366801367733913,
      "grad_norm": 0.37717166543006897,
      "learning_rate": 9.481659931613306e-06,
      "loss": 0.2162,
      "step": 1334
    },
    {
      "epoch": 0.10374572583152004,
      "grad_norm": 0.2208140641450882,
      "learning_rate": 9.4812713708424e-06,
      "loss": 0.2719,
      "step": 1335
    },
    {
      "epoch": 0.10382343798570097,
      "grad_norm": 0.5031662583351135,
      "learning_rate": 9.480882810071496e-06,
      "loss": 0.1026,
      "step": 1336
    },
    {
      "epoch": 0.10390115013988188,
      "grad_norm": 0.4306027591228485,
      "learning_rate": 9.48049424930059e-06,
      "loss": 0.1928,
      "step": 1337
    },
    {
      "epoch": 0.1039788622940628,
      "grad_norm": 0.2877669632434845,
      "learning_rate": 9.480105688529687e-06,
      "loss": 0.1188,
      "step": 1338
    },
    {
      "epoch": 0.1040565744482437,
      "grad_norm": 0.2699955105781555,
      "learning_rate": 9.479717127758782e-06,
      "loss": 0.1355,
      "step": 1339
    },
    {
      "epoch": 0.10413428660242462,
      "grad_norm": 0.8192707300186157,
      "learning_rate": 9.479328566987877e-06,
      "loss": 0.1866,
      "step": 1340
    },
    {
      "epoch": 0.10421199875660553,
      "grad_norm": 0.13359101116657257,
      "learning_rate": 9.478940006216974e-06,
      "loss": 0.0854,
      "step": 1341
    },
    {
      "epoch": 0.10428971091078644,
      "grad_norm": 0.18317465484142303,
      "learning_rate": 9.478551445446069e-06,
      "loss": 0.0805,
      "step": 1342
    },
    {
      "epoch": 0.10436742306496737,
      "grad_norm": 0.3818958103656769,
      "learning_rate": 9.478162884675164e-06,
      "loss": 0.4658,
      "step": 1343
    },
    {
      "epoch": 0.10444513521914828,
      "grad_norm": 0.652660608291626,
      "learning_rate": 9.47777432390426e-06,
      "loss": 0.8418,
      "step": 1344
    },
    {
      "epoch": 0.10452284737332919,
      "grad_norm": 0.33304521441459656,
      "learning_rate": 9.477385763133354e-06,
      "loss": 0.2082,
      "step": 1345
    },
    {
      "epoch": 0.1046005595275101,
      "grad_norm": 0.13599269092082977,
      "learning_rate": 9.47699720236245e-06,
      "loss": 0.1507,
      "step": 1346
    },
    {
      "epoch": 0.10467827168169101,
      "grad_norm": 0.33479809761047363,
      "learning_rate": 9.476608641591545e-06,
      "loss": 0.4866,
      "step": 1347
    },
    {
      "epoch": 0.10475598383587192,
      "grad_norm": 0.3586798310279846,
      "learning_rate": 9.47622008082064e-06,
      "loss": 0.2391,
      "step": 1348
    },
    {
      "epoch": 0.10483369599005285,
      "grad_norm": 0.22105777263641357,
      "learning_rate": 9.475831520049737e-06,
      "loss": 0.1425,
      "step": 1349
    },
    {
      "epoch": 0.10491140814423376,
      "grad_norm": 0.4546751081943512,
      "learning_rate": 9.475442959278832e-06,
      "loss": 0.4116,
      "step": 1350
    },
    {
      "epoch": 0.10498912029841467,
      "grad_norm": 0.33210238814353943,
      "learning_rate": 9.475054398507928e-06,
      "loss": 0.3605,
      "step": 1351
    },
    {
      "epoch": 0.10506683245259558,
      "grad_norm": 0.12702244520187378,
      "learning_rate": 9.474665837737023e-06,
      "loss": 0.1357,
      "step": 1352
    },
    {
      "epoch": 0.1051445446067765,
      "grad_norm": 0.06448041647672653,
      "learning_rate": 9.474277276966118e-06,
      "loss": 0.013,
      "step": 1353
    },
    {
      "epoch": 0.10522225676095741,
      "grad_norm": 0.21221794188022614,
      "learning_rate": 9.473888716195215e-06,
      "loss": 0.0544,
      "step": 1354
    },
    {
      "epoch": 0.10529996891513833,
      "grad_norm": 0.2218274176120758,
      "learning_rate": 9.473500155424308e-06,
      "loss": 0.1801,
      "step": 1355
    },
    {
      "epoch": 0.10537768106931925,
      "grad_norm": 0.3316996991634369,
      "learning_rate": 9.473111594653405e-06,
      "loss": 0.5172,
      "step": 1356
    },
    {
      "epoch": 0.10545539322350016,
      "grad_norm": 0.09508152306079865,
      "learning_rate": 9.4727230338825e-06,
      "loss": 0.0666,
      "step": 1357
    },
    {
      "epoch": 0.10553310537768107,
      "grad_norm": 0.40643855929374695,
      "learning_rate": 9.472334473111595e-06,
      "loss": 0.4222,
      "step": 1358
    },
    {
      "epoch": 0.10561081753186198,
      "grad_norm": 0.36258190870285034,
      "learning_rate": 9.471945912340691e-06,
      "loss": 0.2068,
      "step": 1359
    },
    {
      "epoch": 0.10568852968604289,
      "grad_norm": 0.14151960611343384,
      "learning_rate": 9.471557351569786e-06,
      "loss": 0.2092,
      "step": 1360
    },
    {
      "epoch": 0.1057662418402238,
      "grad_norm": 0.5513757467269897,
      "learning_rate": 9.471168790798881e-06,
      "loss": 0.3311,
      "step": 1361
    },
    {
      "epoch": 0.10584395399440473,
      "grad_norm": 0.16719070076942444,
      "learning_rate": 9.470780230027978e-06,
      "loss": 0.1065,
      "step": 1362
    },
    {
      "epoch": 0.10592166614858564,
      "grad_norm": 0.33064448833465576,
      "learning_rate": 9.470391669257073e-06,
      "loss": 0.19,
      "step": 1363
    },
    {
      "epoch": 0.10599937830276655,
      "grad_norm": 0.16800056397914886,
      "learning_rate": 9.470003108486168e-06,
      "loss": 0.1628,
      "step": 1364
    },
    {
      "epoch": 0.10607709045694746,
      "grad_norm": 0.18138815462589264,
      "learning_rate": 9.469614547715263e-06,
      "loss": 0.103,
      "step": 1365
    },
    {
      "epoch": 0.10615480261112838,
      "grad_norm": 0.4863468408584595,
      "learning_rate": 9.46922598694436e-06,
      "loss": 0.126,
      "step": 1366
    },
    {
      "epoch": 0.10623251476530929,
      "grad_norm": 0.22473615407943726,
      "learning_rate": 9.468837426173454e-06,
      "loss": 0.2015,
      "step": 1367
    },
    {
      "epoch": 0.10631022691949021,
      "grad_norm": 0.5194770693778992,
      "learning_rate": 9.46844886540255e-06,
      "loss": 0.4643,
      "step": 1368
    },
    {
      "epoch": 0.10638793907367113,
      "grad_norm": 0.24523304402828217,
      "learning_rate": 9.468060304631646e-06,
      "loss": 0.1285,
      "step": 1369
    },
    {
      "epoch": 0.10646565122785204,
      "grad_norm": 0.06603182107210159,
      "learning_rate": 9.467671743860741e-06,
      "loss": 0.0834,
      "step": 1370
    },
    {
      "epoch": 0.10654336338203295,
      "grad_norm": 0.4391177296638489,
      "learning_rate": 9.467283183089836e-06,
      "loss": 0.1961,
      "step": 1371
    },
    {
      "epoch": 0.10662107553621386,
      "grad_norm": 0.09607619792222977,
      "learning_rate": 9.466894622318933e-06,
      "loss": 0.0459,
      "step": 1372
    },
    {
      "epoch": 0.10669878769039477,
      "grad_norm": 0.25513410568237305,
      "learning_rate": 9.466506061548026e-06,
      "loss": 0.2346,
      "step": 1373
    },
    {
      "epoch": 0.1067764998445757,
      "grad_norm": 0.17337347567081451,
      "learning_rate": 9.466117500777122e-06,
      "loss": 0.0349,
      "step": 1374
    },
    {
      "epoch": 0.10685421199875661,
      "grad_norm": 0.1814844161272049,
      "learning_rate": 9.465728940006217e-06,
      "loss": 0.1214,
      "step": 1375
    },
    {
      "epoch": 0.10693192415293752,
      "grad_norm": 0.19114050269126892,
      "learning_rate": 9.465340379235312e-06,
      "loss": 0.0966,
      "step": 1376
    },
    {
      "epoch": 0.10700963630711843,
      "grad_norm": 0.12625671923160553,
      "learning_rate": 9.464951818464409e-06,
      "loss": 0.0916,
      "step": 1377
    },
    {
      "epoch": 0.10708734846129934,
      "grad_norm": 0.07513228803873062,
      "learning_rate": 9.464563257693504e-06,
      "loss": 0.0337,
      "step": 1378
    },
    {
      "epoch": 0.10716506061548026,
      "grad_norm": 0.04511823505163193,
      "learning_rate": 9.464174696922599e-06,
      "loss": 0.0099,
      "step": 1379
    },
    {
      "epoch": 0.10724277276966117,
      "grad_norm": 0.21513795852661133,
      "learning_rate": 9.463786136151694e-06,
      "loss": 0.3258,
      "step": 1380
    },
    {
      "epoch": 0.1073204849238421,
      "grad_norm": 0.5928670167922974,
      "learning_rate": 9.46339757538079e-06,
      "loss": 0.2214,
      "step": 1381
    },
    {
      "epoch": 0.107398197078023,
      "grad_norm": 0.6780276298522949,
      "learning_rate": 9.463009014609885e-06,
      "loss": 0.7082,
      "step": 1382
    },
    {
      "epoch": 0.10747590923220392,
      "grad_norm": 0.04254372790455818,
      "learning_rate": 9.46262045383898e-06,
      "loss": 0.011,
      "step": 1383
    },
    {
      "epoch": 0.10755362138638483,
      "grad_norm": 0.11330091953277588,
      "learning_rate": 9.462231893068077e-06,
      "loss": 0.0762,
      "step": 1384
    },
    {
      "epoch": 0.10763133354056574,
      "grad_norm": 0.13815757632255554,
      "learning_rate": 9.461843332297172e-06,
      "loss": 0.0442,
      "step": 1385
    },
    {
      "epoch": 0.10770904569474665,
      "grad_norm": 0.2537587881088257,
      "learning_rate": 9.461454771526267e-06,
      "loss": 0.2179,
      "step": 1386
    },
    {
      "epoch": 0.10778675784892758,
      "grad_norm": 0.18621701002120972,
      "learning_rate": 9.461066210755364e-06,
      "loss": 0.0587,
      "step": 1387
    },
    {
      "epoch": 0.10786447000310849,
      "grad_norm": 0.12840060889720917,
      "learning_rate": 9.460677649984459e-06,
      "loss": 0.0657,
      "step": 1388
    },
    {
      "epoch": 0.1079421821572894,
      "grad_norm": 0.49792197346687317,
      "learning_rate": 9.460289089213554e-06,
      "loss": 0.3583,
      "step": 1389
    },
    {
      "epoch": 0.10801989431147031,
      "grad_norm": 0.47177642583847046,
      "learning_rate": 9.459900528442648e-06,
      "loss": 0.8673,
      "step": 1390
    },
    {
      "epoch": 0.10809760646565122,
      "grad_norm": 0.1284925639629364,
      "learning_rate": 9.459511967671745e-06,
      "loss": 0.0765,
      "step": 1391
    },
    {
      "epoch": 0.10817531861983214,
      "grad_norm": 0.4405793845653534,
      "learning_rate": 9.45912340690084e-06,
      "loss": 0.9251,
      "step": 1392
    },
    {
      "epoch": 0.10825303077401306,
      "grad_norm": 0.17116640508174896,
      "learning_rate": 9.458734846129935e-06,
      "loss": 0.0695,
      "step": 1393
    },
    {
      "epoch": 0.10833074292819397,
      "grad_norm": 0.08325526118278503,
      "learning_rate": 9.458346285359032e-06,
      "loss": 0.0153,
      "step": 1394
    },
    {
      "epoch": 0.10840845508237489,
      "grad_norm": 0.2653290629386902,
      "learning_rate": 9.457957724588127e-06,
      "loss": 0.0895,
      "step": 1395
    },
    {
      "epoch": 0.1084861672365558,
      "grad_norm": 0.3107433617115021,
      "learning_rate": 9.457569163817222e-06,
      "loss": 0.2979,
      "step": 1396
    },
    {
      "epoch": 0.10856387939073671,
      "grad_norm": 0.16402457654476166,
      "learning_rate": 9.457180603046318e-06,
      "loss": 0.0712,
      "step": 1397
    },
    {
      "epoch": 0.10864159154491762,
      "grad_norm": 0.26912879943847656,
      "learning_rate": 9.456792042275411e-06,
      "loss": 0.1116,
      "step": 1398
    },
    {
      "epoch": 0.10871930369909853,
      "grad_norm": 0.19822324812412262,
      "learning_rate": 9.456403481504508e-06,
      "loss": 0.1675,
      "step": 1399
    },
    {
      "epoch": 0.10879701585327946,
      "grad_norm": 0.4001806676387787,
      "learning_rate": 9.456014920733603e-06,
      "loss": 0.0866,
      "step": 1400
    },
    {
      "epoch": 0.10887472800746037,
      "grad_norm": 0.2776477336883545,
      "learning_rate": 9.455626359962698e-06,
      "loss": 0.0734,
      "step": 1401
    },
    {
      "epoch": 0.10895244016164128,
      "grad_norm": 0.3142811357975006,
      "learning_rate": 9.455237799191795e-06,
      "loss": 0.1029,
      "step": 1402
    },
    {
      "epoch": 0.10903015231582219,
      "grad_norm": 0.10197298228740692,
      "learning_rate": 9.45484923842089e-06,
      "loss": 0.0445,
      "step": 1403
    },
    {
      "epoch": 0.1091078644700031,
      "grad_norm": 0.8883069157600403,
      "learning_rate": 9.454460677649985e-06,
      "loss": 0.6636,
      "step": 1404
    },
    {
      "epoch": 0.10918557662418402,
      "grad_norm": 0.6678569316864014,
      "learning_rate": 9.454072116879081e-06,
      "loss": 0.576,
      "step": 1405
    },
    {
      "epoch": 0.10926328877836494,
      "grad_norm": 0.40571674704551697,
      "learning_rate": 9.453683556108176e-06,
      "loss": 0.7315,
      "step": 1406
    },
    {
      "epoch": 0.10934100093254585,
      "grad_norm": 0.18561023473739624,
      "learning_rate": 9.453294995337271e-06,
      "loss": 0.1338,
      "step": 1407
    },
    {
      "epoch": 0.10941871308672677,
      "grad_norm": 1.4474810361862183,
      "learning_rate": 9.452906434566366e-06,
      "loss": 0.1276,
      "step": 1408
    },
    {
      "epoch": 0.10949642524090768,
      "grad_norm": 0.2066507637500763,
      "learning_rate": 9.452517873795463e-06,
      "loss": 0.1167,
      "step": 1409
    },
    {
      "epoch": 0.10957413739508859,
      "grad_norm": 0.20066729187965393,
      "learning_rate": 9.452129313024558e-06,
      "loss": 0.2379,
      "step": 1410
    },
    {
      "epoch": 0.1096518495492695,
      "grad_norm": 0.23108389973640442,
      "learning_rate": 9.451740752253653e-06,
      "loss": 0.0357,
      "step": 1411
    },
    {
      "epoch": 0.10972956170345043,
      "grad_norm": 0.5578399300575256,
      "learning_rate": 9.45135219148275e-06,
      "loss": 0.5485,
      "step": 1412
    },
    {
      "epoch": 0.10980727385763134,
      "grad_norm": 0.5183880925178528,
      "learning_rate": 9.450963630711844e-06,
      "loss": 0.3119,
      "step": 1413
    },
    {
      "epoch": 0.10988498601181225,
      "grad_norm": 0.44037535786628723,
      "learning_rate": 9.450575069940939e-06,
      "loss": 0.3096,
      "step": 1414
    },
    {
      "epoch": 0.10996269816599316,
      "grad_norm": 0.25390294194221497,
      "learning_rate": 9.450186509170036e-06,
      "loss": 0.2394,
      "step": 1415
    },
    {
      "epoch": 0.11004041032017407,
      "grad_norm": 0.16119375824928284,
      "learning_rate": 9.44979794839913e-06,
      "loss": 0.1755,
      "step": 1416
    },
    {
      "epoch": 0.11011812247435498,
      "grad_norm": 0.15592415630817413,
      "learning_rate": 9.449409387628226e-06,
      "loss": 0.0786,
      "step": 1417
    },
    {
      "epoch": 0.1101958346285359,
      "grad_norm": 0.1169472485780716,
      "learning_rate": 9.44902082685732e-06,
      "loss": 0.1355,
      "step": 1418
    },
    {
      "epoch": 0.11027354678271682,
      "grad_norm": 0.3650616407394409,
      "learning_rate": 9.448632266086417e-06,
      "loss": 0.5151,
      "step": 1419
    },
    {
      "epoch": 0.11035125893689773,
      "grad_norm": 0.2661021649837494,
      "learning_rate": 9.448243705315512e-06,
      "loss": 0.1261,
      "step": 1420
    },
    {
      "epoch": 0.11042897109107865,
      "grad_norm": 0.4128190875053406,
      "learning_rate": 9.447855144544607e-06,
      "loss": 0.3777,
      "step": 1421
    },
    {
      "epoch": 0.11050668324525956,
      "grad_norm": 0.3369224965572357,
      "learning_rate": 9.447466583773704e-06,
      "loss": 0.3238,
      "step": 1422
    },
    {
      "epoch": 0.11058439539944047,
      "grad_norm": 0.12908092141151428,
      "learning_rate": 9.447078023002799e-06,
      "loss": 0.0885,
      "step": 1423
    },
    {
      "epoch": 0.11066210755362138,
      "grad_norm": 0.1349225491285324,
      "learning_rate": 9.446689462231894e-06,
      "loss": 0.0232,
      "step": 1424
    },
    {
      "epoch": 0.1107398197078023,
      "grad_norm": 0.1500805914402008,
      "learning_rate": 9.44630090146099e-06,
      "loss": 0.0778,
      "step": 1425
    },
    {
      "epoch": 0.11081753186198322,
      "grad_norm": 0.027194621041417122,
      "learning_rate": 9.445912340690084e-06,
      "loss": 0.011,
      "step": 1426
    },
    {
      "epoch": 0.11089524401616413,
      "grad_norm": 0.10853296518325806,
      "learning_rate": 9.44552377991918e-06,
      "loss": 0.0653,
      "step": 1427
    },
    {
      "epoch": 0.11097295617034504,
      "grad_norm": 0.16107769310474396,
      "learning_rate": 9.445135219148275e-06,
      "loss": 0.0647,
      "step": 1428
    },
    {
      "epoch": 0.11105066832452595,
      "grad_norm": 0.36365222930908203,
      "learning_rate": 9.44474665837737e-06,
      "loss": 0.174,
      "step": 1429
    },
    {
      "epoch": 0.11112838047870686,
      "grad_norm": 0.6345091462135315,
      "learning_rate": 9.444358097606467e-06,
      "loss": 0.4276,
      "step": 1430
    },
    {
      "epoch": 0.11120609263288779,
      "grad_norm": 0.4161801338195801,
      "learning_rate": 9.443969536835562e-06,
      "loss": 0.4582,
      "step": 1431
    },
    {
      "epoch": 0.1112838047870687,
      "grad_norm": 0.16088874638080597,
      "learning_rate": 9.443580976064657e-06,
      "loss": 0.0895,
      "step": 1432
    },
    {
      "epoch": 0.11136151694124961,
      "grad_norm": 0.2425779402256012,
      "learning_rate": 9.443192415293753e-06,
      "loss": 0.1585,
      "step": 1433
    },
    {
      "epoch": 0.11143922909543053,
      "grad_norm": 0.9960986971855164,
      "learning_rate": 9.442803854522848e-06,
      "loss": 0.3161,
      "step": 1434
    },
    {
      "epoch": 0.11151694124961144,
      "grad_norm": 0.09774947166442871,
      "learning_rate": 9.442415293751943e-06,
      "loss": 0.095,
      "step": 1435
    },
    {
      "epoch": 0.11159465340379235,
      "grad_norm": 0.3265124261379242,
      "learning_rate": 9.442026732981038e-06,
      "loss": 0.1729,
      "step": 1436
    },
    {
      "epoch": 0.11167236555797326,
      "grad_norm": 0.1825471818447113,
      "learning_rate": 9.441638172210135e-06,
      "loss": 0.0842,
      "step": 1437
    },
    {
      "epoch": 0.11175007771215419,
      "grad_norm": 0.14559078216552734,
      "learning_rate": 9.44124961143923e-06,
      "loss": 0.0562,
      "step": 1438
    },
    {
      "epoch": 0.1118277898663351,
      "grad_norm": 0.34515663981437683,
      "learning_rate": 9.440861050668325e-06,
      "loss": 0.3405,
      "step": 1439
    },
    {
      "epoch": 0.11190550202051601,
      "grad_norm": 0.09473621100187302,
      "learning_rate": 9.440472489897421e-06,
      "loss": 0.0269,
      "step": 1440
    },
    {
      "epoch": 0.11198321417469692,
      "grad_norm": 0.2687675356864929,
      "learning_rate": 9.440083929126516e-06,
      "loss": 0.2184,
      "step": 1441
    },
    {
      "epoch": 0.11206092632887783,
      "grad_norm": 1.2257734537124634,
      "learning_rate": 9.439695368355611e-06,
      "loss": 0.1432,
      "step": 1442
    },
    {
      "epoch": 0.11213863848305874,
      "grad_norm": 0.537552535533905,
      "learning_rate": 9.439306807584708e-06,
      "loss": 0.2639,
      "step": 1443
    },
    {
      "epoch": 0.11221635063723967,
      "grad_norm": 0.08260947465896606,
      "learning_rate": 9.438918246813803e-06,
      "loss": 0.0541,
      "step": 1444
    },
    {
      "epoch": 0.11229406279142058,
      "grad_norm": 0.14810632169246674,
      "learning_rate": 9.438529686042898e-06,
      "loss": 0.1702,
      "step": 1445
    },
    {
      "epoch": 0.1123717749456015,
      "grad_norm": 0.2544087767601013,
      "learning_rate": 9.438141125271993e-06,
      "loss": 0.1167,
      "step": 1446
    },
    {
      "epoch": 0.1124494870997824,
      "grad_norm": 0.2471875101327896,
      "learning_rate": 9.43775256450109e-06,
      "loss": 0.2597,
      "step": 1447
    },
    {
      "epoch": 0.11252719925396332,
      "grad_norm": 0.5584617257118225,
      "learning_rate": 9.437364003730184e-06,
      "loss": 0.4226,
      "step": 1448
    },
    {
      "epoch": 0.11260491140814423,
      "grad_norm": 0.27591606974601746,
      "learning_rate": 9.43697544295928e-06,
      "loss": 0.1928,
      "step": 1449
    },
    {
      "epoch": 0.11268262356232515,
      "grad_norm": 0.887904942035675,
      "learning_rate": 9.436586882188376e-06,
      "loss": 0.4864,
      "step": 1450
    },
    {
      "epoch": 0.11276033571650607,
      "grad_norm": 0.2567277252674103,
      "learning_rate": 9.436198321417471e-06,
      "loss": 0.1417,
      "step": 1451
    },
    {
      "epoch": 0.11283804787068698,
      "grad_norm": 0.1465383768081665,
      "learning_rate": 9.435809760646566e-06,
      "loss": 0.103,
      "step": 1452
    },
    {
      "epoch": 0.11291576002486789,
      "grad_norm": 0.16130073368549347,
      "learning_rate": 9.435421199875662e-06,
      "loss": 0.2007,
      "step": 1453
    },
    {
      "epoch": 0.1129934721790488,
      "grad_norm": 0.10135313868522644,
      "learning_rate": 9.435032639104756e-06,
      "loss": 0.0388,
      "step": 1454
    },
    {
      "epoch": 0.11307118433322971,
      "grad_norm": 0.20943105220794678,
      "learning_rate": 9.434644078333852e-06,
      "loss": 0.0951,
      "step": 1455
    },
    {
      "epoch": 0.11314889648741062,
      "grad_norm": 0.24725966155529022,
      "learning_rate": 9.434255517562947e-06,
      "loss": 0.1613,
      "step": 1456
    },
    {
      "epoch": 0.11322660864159155,
      "grad_norm": 0.3816598951816559,
      "learning_rate": 9.433866956792042e-06,
      "loss": 0.1697,
      "step": 1457
    },
    {
      "epoch": 0.11330432079577246,
      "grad_norm": 0.262589693069458,
      "learning_rate": 9.433478396021139e-06,
      "loss": 0.1005,
      "step": 1458
    },
    {
      "epoch": 0.11338203294995337,
      "grad_norm": 0.22225865721702576,
      "learning_rate": 9.433089835250234e-06,
      "loss": 0.3128,
      "step": 1459
    },
    {
      "epoch": 0.11345974510413429,
      "grad_norm": 0.027081552892923355,
      "learning_rate": 9.432701274479329e-06,
      "loss": 0.012,
      "step": 1460
    },
    {
      "epoch": 0.1135374572583152,
      "grad_norm": 1.43553626537323,
      "learning_rate": 9.432312713708425e-06,
      "loss": 0.7317,
      "step": 1461
    },
    {
      "epoch": 0.11361516941249611,
      "grad_norm": 0.3029078543186188,
      "learning_rate": 9.43192415293752e-06,
      "loss": 0.1147,
      "step": 1462
    },
    {
      "epoch": 0.11369288156667703,
      "grad_norm": 0.43681448698043823,
      "learning_rate": 9.431535592166615e-06,
      "loss": 0.5922,
      "step": 1463
    },
    {
      "epoch": 0.11377059372085795,
      "grad_norm": 0.11072330921888351,
      "learning_rate": 9.43114703139571e-06,
      "loss": 0.0673,
      "step": 1464
    },
    {
      "epoch": 0.11384830587503886,
      "grad_norm": 0.2617608904838562,
      "learning_rate": 9.430758470624807e-06,
      "loss": 0.2862,
      "step": 1465
    },
    {
      "epoch": 0.11392601802921977,
      "grad_norm": 0.2825285792350769,
      "learning_rate": 9.430369909853902e-06,
      "loss": 0.1481,
      "step": 1466
    },
    {
      "epoch": 0.11400373018340068,
      "grad_norm": 0.3945681154727936,
      "learning_rate": 9.429981349082997e-06,
      "loss": 0.2674,
      "step": 1467
    },
    {
      "epoch": 0.11408144233758159,
      "grad_norm": 0.17653246223926544,
      "learning_rate": 9.429592788312094e-06,
      "loss": 0.0594,
      "step": 1468
    },
    {
      "epoch": 0.11415915449176252,
      "grad_norm": 0.07784075289964676,
      "learning_rate": 9.429204227541188e-06,
      "loss": 0.0633,
      "step": 1469
    },
    {
      "epoch": 0.11423686664594343,
      "grad_norm": 0.5009628534317017,
      "learning_rate": 9.428815666770283e-06,
      "loss": 0.2804,
      "step": 1470
    },
    {
      "epoch": 0.11431457880012434,
      "grad_norm": 0.05209348350763321,
      "learning_rate": 9.42842710599938e-06,
      "loss": 0.0158,
      "step": 1471
    },
    {
      "epoch": 0.11439229095430525,
      "grad_norm": 0.15665900707244873,
      "learning_rate": 9.428038545228475e-06,
      "loss": 0.0566,
      "step": 1472
    },
    {
      "epoch": 0.11447000310848617,
      "grad_norm": 1.521529197692871,
      "learning_rate": 9.42764998445757e-06,
      "loss": 0.8656,
      "step": 1473
    },
    {
      "epoch": 0.11454771526266708,
      "grad_norm": 0.169975146651268,
      "learning_rate": 9.427261423686665e-06,
      "loss": 0.1419,
      "step": 1474
    },
    {
      "epoch": 0.11462542741684799,
      "grad_norm": 0.3733493387699127,
      "learning_rate": 9.426872862915762e-06,
      "loss": 0.1017,
      "step": 1475
    },
    {
      "epoch": 0.11470313957102891,
      "grad_norm": 0.563779890537262,
      "learning_rate": 9.426484302144857e-06,
      "loss": 0.3277,
      "step": 1476
    },
    {
      "epoch": 0.11478085172520983,
      "grad_norm": 0.34868013858795166,
      "learning_rate": 9.426095741373951e-06,
      "loss": 0.7692,
      "step": 1477
    },
    {
      "epoch": 0.11485856387939074,
      "grad_norm": 0.12371034175157547,
      "learning_rate": 9.425707180603048e-06,
      "loss": 0.0706,
      "step": 1478
    },
    {
      "epoch": 0.11493627603357165,
      "grad_norm": 0.16629190742969513,
      "learning_rate": 9.425318619832143e-06,
      "loss": 0.1086,
      "step": 1479
    },
    {
      "epoch": 0.11501398818775256,
      "grad_norm": 0.6302667856216431,
      "learning_rate": 9.424930059061238e-06,
      "loss": 0.5212,
      "step": 1480
    },
    {
      "epoch": 0.11509170034193347,
      "grad_norm": 0.3159295916557312,
      "learning_rate": 9.424541498290335e-06,
      "loss": 0.235,
      "step": 1481
    },
    {
      "epoch": 0.1151694124961144,
      "grad_norm": 0.5272226333618164,
      "learning_rate": 9.424152937519428e-06,
      "loss": 0.6216,
      "step": 1482
    },
    {
      "epoch": 0.11524712465029531,
      "grad_norm": 0.06927769631147385,
      "learning_rate": 9.423764376748525e-06,
      "loss": 0.0281,
      "step": 1483
    },
    {
      "epoch": 0.11532483680447622,
      "grad_norm": 0.3300118148326874,
      "learning_rate": 9.42337581597762e-06,
      "loss": 0.2186,
      "step": 1484
    },
    {
      "epoch": 0.11540254895865713,
      "grad_norm": 0.22898368537425995,
      "learning_rate": 9.422987255206714e-06,
      "loss": 0.2593,
      "step": 1485
    },
    {
      "epoch": 0.11548026111283805,
      "grad_norm": 0.20713818073272705,
      "learning_rate": 9.422598694435811e-06,
      "loss": 0.0958,
      "step": 1486
    },
    {
      "epoch": 0.11555797326701896,
      "grad_norm": 0.31382256746292114,
      "learning_rate": 9.422210133664906e-06,
      "loss": 0.1614,
      "step": 1487
    },
    {
      "epoch": 0.11563568542119988,
      "grad_norm": 0.3958500921726227,
      "learning_rate": 9.421821572894001e-06,
      "loss": 0.445,
      "step": 1488
    },
    {
      "epoch": 0.1157133975753808,
      "grad_norm": 0.42242804169654846,
      "learning_rate": 9.421433012123098e-06,
      "loss": 0.422,
      "step": 1489
    },
    {
      "epoch": 0.1157911097295617,
      "grad_norm": 0.45914798974990845,
      "learning_rate": 9.421044451352193e-06,
      "loss": 0.2679,
      "step": 1490
    },
    {
      "epoch": 0.11586882188374262,
      "grad_norm": 0.22841298580169678,
      "learning_rate": 9.420655890581288e-06,
      "loss": 0.2413,
      "step": 1491
    },
    {
      "epoch": 0.11594653403792353,
      "grad_norm": 0.44690483808517456,
      "learning_rate": 9.420267329810382e-06,
      "loss": 0.4321,
      "step": 1492
    },
    {
      "epoch": 0.11602424619210444,
      "grad_norm": 0.3820491433143616,
      "learning_rate": 9.419878769039479e-06,
      "loss": 0.2549,
      "step": 1493
    },
    {
      "epoch": 0.11610195834628535,
      "grad_norm": 0.16771200299263,
      "learning_rate": 9.419490208268574e-06,
      "loss": 0.0833,
      "step": 1494
    },
    {
      "epoch": 0.11617967050046628,
      "grad_norm": 0.5938539505004883,
      "learning_rate": 9.419101647497669e-06,
      "loss": 0.3822,
      "step": 1495
    },
    {
      "epoch": 0.11625738265464719,
      "grad_norm": 0.10977505147457123,
      "learning_rate": 9.418713086726766e-06,
      "loss": 0.0479,
      "step": 1496
    },
    {
      "epoch": 0.1163350948088281,
      "grad_norm": 0.12644259631633759,
      "learning_rate": 9.41832452595586e-06,
      "loss": 0.097,
      "step": 1497
    },
    {
      "epoch": 0.11641280696300901,
      "grad_norm": 0.26894164085388184,
      "learning_rate": 9.417935965184956e-06,
      "loss": 0.6865,
      "step": 1498
    },
    {
      "epoch": 0.11649051911718993,
      "grad_norm": 0.31634482741355896,
      "learning_rate": 9.41754740441405e-06,
      "loss": 0.3022,
      "step": 1499
    },
    {
      "epoch": 0.11656823127137084,
      "grad_norm": 0.10628661513328552,
      "learning_rate": 9.417158843643145e-06,
      "loss": 0.0329,
      "step": 1500
    },
    {
      "epoch": 0.11664594342555176,
      "grad_norm": 0.14291127026081085,
      "learning_rate": 9.416770282872242e-06,
      "loss": 0.0349,
      "step": 1501
    },
    {
      "epoch": 0.11672365557973267,
      "grad_norm": 0.19540710747241974,
      "learning_rate": 9.416381722101337e-06,
      "loss": 0.1042,
      "step": 1502
    },
    {
      "epoch": 0.11680136773391359,
      "grad_norm": 0.3166726529598236,
      "learning_rate": 9.415993161330434e-06,
      "loss": 0.2626,
      "step": 1503
    },
    {
      "epoch": 0.1168790798880945,
      "grad_norm": 0.18015383183956146,
      "learning_rate": 9.415604600559529e-06,
      "loss": 0.062,
      "step": 1504
    },
    {
      "epoch": 0.11695679204227541,
      "grad_norm": 0.11483360081911087,
      "learning_rate": 9.415216039788624e-06,
      "loss": 0.0876,
      "step": 1505
    },
    {
      "epoch": 0.11703450419645632,
      "grad_norm": 0.341531902551651,
      "learning_rate": 9.41482747901772e-06,
      "loss": 0.3427,
      "step": 1506
    },
    {
      "epoch": 0.11711221635063725,
      "grad_norm": 2.462860584259033,
      "learning_rate": 9.414438918246813e-06,
      "loss": 1.0093,
      "step": 1507
    },
    {
      "epoch": 0.11718992850481816,
      "grad_norm": 0.07030370086431503,
      "learning_rate": 9.41405035747591e-06,
      "loss": 0.0414,
      "step": 1508
    },
    {
      "epoch": 0.11726764065899907,
      "grad_norm": 0.16463056206703186,
      "learning_rate": 9.413661796705005e-06,
      "loss": 0.0902,
      "step": 1509
    },
    {
      "epoch": 0.11734535281317998,
      "grad_norm": 0.43511176109313965,
      "learning_rate": 9.4132732359341e-06,
      "loss": 0.1879,
      "step": 1510
    },
    {
      "epoch": 0.1174230649673609,
      "grad_norm": 0.1331603229045868,
      "learning_rate": 9.412884675163197e-06,
      "loss": 0.0638,
      "step": 1511
    },
    {
      "epoch": 0.1175007771215418,
      "grad_norm": 0.04950648546218872,
      "learning_rate": 9.412496114392292e-06,
      "loss": 0.0199,
      "step": 1512
    },
    {
      "epoch": 0.11757848927572272,
      "grad_norm": 0.3571629226207733,
      "learning_rate": 9.412107553621387e-06,
      "loss": 0.2997,
      "step": 1513
    },
    {
      "epoch": 0.11765620142990364,
      "grad_norm": 0.5292398929595947,
      "learning_rate": 9.411718992850483e-06,
      "loss": 0.1878,
      "step": 1514
    },
    {
      "epoch": 0.11773391358408455,
      "grad_norm": 0.3311581015586853,
      "learning_rate": 9.411330432079578e-06,
      "loss": 0.1974,
      "step": 1515
    },
    {
      "epoch": 0.11781162573826547,
      "grad_norm": 0.2612418234348297,
      "learning_rate": 9.410941871308673e-06,
      "loss": 0.0993,
      "step": 1516
    },
    {
      "epoch": 0.11788933789244638,
      "grad_norm": 0.31940987706184387,
      "learning_rate": 9.410553310537768e-06,
      "loss": 0.2287,
      "step": 1517
    },
    {
      "epoch": 0.11796705004662729,
      "grad_norm": 0.08244486898183823,
      "learning_rate": 9.410164749766865e-06,
      "loss": 0.0159,
      "step": 1518
    },
    {
      "epoch": 0.1180447622008082,
      "grad_norm": 0.6145244836807251,
      "learning_rate": 9.40977618899596e-06,
      "loss": 0.5457,
      "step": 1519
    },
    {
      "epoch": 0.11812247435498913,
      "grad_norm": 0.24950392544269562,
      "learning_rate": 9.409387628225055e-06,
      "loss": 0.1003,
      "step": 1520
    },
    {
      "epoch": 0.11820018650917004,
      "grad_norm": 0.49046429991722107,
      "learning_rate": 9.408999067454151e-06,
      "loss": 0.2194,
      "step": 1521
    },
    {
      "epoch": 0.11827789866335095,
      "grad_norm": 0.3232838809490204,
      "learning_rate": 9.408610506683246e-06,
      "loss": 0.4362,
      "step": 1522
    },
    {
      "epoch": 0.11835561081753186,
      "grad_norm": 0.4530041217803955,
      "learning_rate": 9.408221945912341e-06,
      "loss": 0.1972,
      "step": 1523
    },
    {
      "epoch": 0.11843332297171277,
      "grad_norm": 0.11315484344959259,
      "learning_rate": 9.407833385141438e-06,
      "loss": 0.0309,
      "step": 1524
    },
    {
      "epoch": 0.11851103512589369,
      "grad_norm": 0.1193995475769043,
      "learning_rate": 9.407444824370531e-06,
      "loss": 0.0455,
      "step": 1525
    },
    {
      "epoch": 0.1185887472800746,
      "grad_norm": 0.08341259509325027,
      "learning_rate": 9.407056263599628e-06,
      "loss": 0.0574,
      "step": 1526
    },
    {
      "epoch": 0.11866645943425552,
      "grad_norm": 0.2091815024614334,
      "learning_rate": 9.406667702828723e-06,
      "loss": 0.1433,
      "step": 1527
    },
    {
      "epoch": 0.11874417158843643,
      "grad_norm": 0.1772383451461792,
      "learning_rate": 9.406279142057818e-06,
      "loss": 0.1782,
      "step": 1528
    },
    {
      "epoch": 0.11882188374261735,
      "grad_norm": 0.1099373996257782,
      "learning_rate": 9.405890581286914e-06,
      "loss": 0.0579,
      "step": 1529
    },
    {
      "epoch": 0.11889959589679826,
      "grad_norm": 0.2793610990047455,
      "learning_rate": 9.40550202051601e-06,
      "loss": 0.2786,
      "step": 1530
    },
    {
      "epoch": 0.11897730805097917,
      "grad_norm": 0.609150767326355,
      "learning_rate": 9.405113459745104e-06,
      "loss": 0.2233,
      "step": 1531
    },
    {
      "epoch": 0.11905502020516008,
      "grad_norm": 0.14922000467777252,
      "learning_rate": 9.4047248989742e-06,
      "loss": 0.1356,
      "step": 1532
    },
    {
      "epoch": 0.119132732359341,
      "grad_norm": 0.42877599596977234,
      "learning_rate": 9.404336338203296e-06,
      "loss": 0.2654,
      "step": 1533
    },
    {
      "epoch": 0.11921044451352192,
      "grad_norm": 0.12850260734558105,
      "learning_rate": 9.403947777432392e-06,
      "loss": 0.0793,
      "step": 1534
    },
    {
      "epoch": 0.11928815666770283,
      "grad_norm": 0.20082786679267883,
      "learning_rate": 9.403559216661486e-06,
      "loss": 0.0519,
      "step": 1535
    },
    {
      "epoch": 0.11936586882188374,
      "grad_norm": 0.3279445171356201,
      "learning_rate": 9.403170655890582e-06,
      "loss": 0.1386,
      "step": 1536
    },
    {
      "epoch": 0.11944358097606465,
      "grad_norm": 0.08447213470935822,
      "learning_rate": 9.402782095119677e-06,
      "loss": 0.0411,
      "step": 1537
    },
    {
      "epoch": 0.11952129313024557,
      "grad_norm": 0.34385842084884644,
      "learning_rate": 9.402393534348772e-06,
      "loss": 0.1819,
      "step": 1538
    },
    {
      "epoch": 0.11959900528442649,
      "grad_norm": 0.22434397041797638,
      "learning_rate": 9.402004973577869e-06,
      "loss": 0.2137,
      "step": 1539
    },
    {
      "epoch": 0.1196767174386074,
      "grad_norm": 0.7026426196098328,
      "learning_rate": 9.401616412806964e-06,
      "loss": 0.3741,
      "step": 1540
    },
    {
      "epoch": 0.11975442959278831,
      "grad_norm": 0.06836152821779251,
      "learning_rate": 9.401227852036059e-06,
      "loss": 0.0364,
      "step": 1541
    },
    {
      "epoch": 0.11983214174696923,
      "grad_norm": 0.15613143146038055,
      "learning_rate": 9.400839291265155e-06,
      "loss": 0.1267,
      "step": 1542
    },
    {
      "epoch": 0.11990985390115014,
      "grad_norm": 0.16348028182983398,
      "learning_rate": 9.40045073049425e-06,
      "loss": 0.0989,
      "step": 1543
    },
    {
      "epoch": 0.11998756605533105,
      "grad_norm": 0.1355857402086258,
      "learning_rate": 9.400062169723345e-06,
      "loss": 0.086,
      "step": 1544
    },
    {
      "epoch": 0.12006527820951196,
      "grad_norm": 0.28797513246536255,
      "learning_rate": 9.39967360895244e-06,
      "loss": 0.1566,
      "step": 1545
    },
    {
      "epoch": 0.12014299036369289,
      "grad_norm": 0.5580248832702637,
      "learning_rate": 9.399285048181537e-06,
      "loss": 0.459,
      "step": 1546
    },
    {
      "epoch": 0.1202207025178738,
      "grad_norm": 0.3115694522857666,
      "learning_rate": 9.398896487410632e-06,
      "loss": 0.1902,
      "step": 1547
    },
    {
      "epoch": 0.12029841467205471,
      "grad_norm": 0.08472073078155518,
      "learning_rate": 9.398507926639727e-06,
      "loss": 0.0854,
      "step": 1548
    },
    {
      "epoch": 0.12037612682623562,
      "grad_norm": 0.1357249617576599,
      "learning_rate": 9.398119365868823e-06,
      "loss": 0.1098,
      "step": 1549
    },
    {
      "epoch": 0.12045383898041653,
      "grad_norm": 0.5400413274765015,
      "learning_rate": 9.397730805097918e-06,
      "loss": 0.2923,
      "step": 1550
    },
    {
      "epoch": 0.12053155113459744,
      "grad_norm": 0.26230597496032715,
      "learning_rate": 9.397342244327013e-06,
      "loss": 0.2526,
      "step": 1551
    },
    {
      "epoch": 0.12060926328877837,
      "grad_norm": 0.19211634993553162,
      "learning_rate": 9.39695368355611e-06,
      "loss": 0.1106,
      "step": 1552
    },
    {
      "epoch": 0.12068697544295928,
      "grad_norm": 0.427055686712265,
      "learning_rate": 9.396565122785203e-06,
      "loss": 0.771,
      "step": 1553
    },
    {
      "epoch": 0.1207646875971402,
      "grad_norm": 0.6526730060577393,
      "learning_rate": 9.3961765620143e-06,
      "loss": 0.2495,
      "step": 1554
    },
    {
      "epoch": 0.1208423997513211,
      "grad_norm": 0.2938522696495056,
      "learning_rate": 9.395788001243395e-06,
      "loss": 0.2989,
      "step": 1555
    },
    {
      "epoch": 0.12092011190550202,
      "grad_norm": 0.19015026092529297,
      "learning_rate": 9.39539944047249e-06,
      "loss": 0.0752,
      "step": 1556
    },
    {
      "epoch": 0.12099782405968293,
      "grad_norm": 0.2045445740222931,
      "learning_rate": 9.395010879701586e-06,
      "loss": 0.1594,
      "step": 1557
    },
    {
      "epoch": 0.12107553621386385,
      "grad_norm": 0.16440723836421967,
      "learning_rate": 9.394622318930681e-06,
      "loss": 0.1997,
      "step": 1558
    },
    {
      "epoch": 0.12115324836804477,
      "grad_norm": 0.6927515268325806,
      "learning_rate": 9.394233758159776e-06,
      "loss": 0.5186,
      "step": 1559
    },
    {
      "epoch": 0.12123096052222568,
      "grad_norm": 0.31557193398475647,
      "learning_rate": 9.393845197388873e-06,
      "loss": 0.2997,
      "step": 1560
    },
    {
      "epoch": 0.12130867267640659,
      "grad_norm": 0.28826332092285156,
      "learning_rate": 9.393456636617968e-06,
      "loss": 0.2167,
      "step": 1561
    },
    {
      "epoch": 0.1213863848305875,
      "grad_norm": 0.2776035666465759,
      "learning_rate": 9.393068075847063e-06,
      "loss": 0.1049,
      "step": 1562
    },
    {
      "epoch": 0.12146409698476841,
      "grad_norm": 0.09718382358551025,
      "learning_rate": 9.392679515076158e-06,
      "loss": 0.0414,
      "step": 1563
    },
    {
      "epoch": 0.12154180913894932,
      "grad_norm": 0.2714114189147949,
      "learning_rate": 9.392290954305254e-06,
      "loss": 0.1518,
      "step": 1564
    },
    {
      "epoch": 0.12161952129313025,
      "grad_norm": 0.19824053347110748,
      "learning_rate": 9.39190239353435e-06,
      "loss": 0.1259,
      "step": 1565
    },
    {
      "epoch": 0.12169723344731116,
      "grad_norm": 0.35053354501724243,
      "learning_rate": 9.391513832763444e-06,
      "loss": 0.122,
      "step": 1566
    },
    {
      "epoch": 0.12177494560149207,
      "grad_norm": 0.2943721413612366,
      "learning_rate": 9.391125271992541e-06,
      "loss": 0.2615,
      "step": 1567
    },
    {
      "epoch": 0.12185265775567299,
      "grad_norm": 0.09714964032173157,
      "learning_rate": 9.390736711221636e-06,
      "loss": 0.0372,
      "step": 1568
    },
    {
      "epoch": 0.1219303699098539,
      "grad_norm": 0.4748348295688629,
      "learning_rate": 9.390348150450731e-06,
      "loss": 0.3557,
      "step": 1569
    },
    {
      "epoch": 0.12200808206403481,
      "grad_norm": 0.06981499493122101,
      "learning_rate": 9.389959589679828e-06,
      "loss": 0.0399,
      "step": 1570
    },
    {
      "epoch": 0.12208579421821573,
      "grad_norm": 0.0701863020658493,
      "learning_rate": 9.389571028908922e-06,
      "loss": 0.0336,
      "step": 1571
    },
    {
      "epoch": 0.12216350637239665,
      "grad_norm": 0.36391010880470276,
      "learning_rate": 9.389182468138017e-06,
      "loss": 0.0708,
      "step": 1572
    },
    {
      "epoch": 0.12224121852657756,
      "grad_norm": 0.1961391717195511,
      "learning_rate": 9.388793907367112e-06,
      "loss": 0.1775,
      "step": 1573
    },
    {
      "epoch": 0.12231893068075847,
      "grad_norm": 0.3674410581588745,
      "learning_rate": 9.388405346596209e-06,
      "loss": 0.5815,
      "step": 1574
    },
    {
      "epoch": 0.12239664283493938,
      "grad_norm": 0.4582792818546295,
      "learning_rate": 9.388016785825304e-06,
      "loss": 0.2227,
      "step": 1575
    },
    {
      "epoch": 0.1224743549891203,
      "grad_norm": 0.24597737193107605,
      "learning_rate": 9.387628225054399e-06,
      "loss": 0.1925,
      "step": 1576
    },
    {
      "epoch": 0.12255206714330122,
      "grad_norm": 0.25685977935791016,
      "learning_rate": 9.387239664283496e-06,
      "loss": 0.1131,
      "step": 1577
    },
    {
      "epoch": 0.12262977929748213,
      "grad_norm": 0.2432180941104889,
      "learning_rate": 9.38685110351259e-06,
      "loss": 0.2554,
      "step": 1578
    },
    {
      "epoch": 0.12270749145166304,
      "grad_norm": 0.25247037410736084,
      "learning_rate": 9.386462542741685e-06,
      "loss": 0.1987,
      "step": 1579
    },
    {
      "epoch": 0.12278520360584395,
      "grad_norm": 0.3712048828601837,
      "learning_rate": 9.386073981970782e-06,
      "loss": 0.5276,
      "step": 1580
    },
    {
      "epoch": 0.12286291576002487,
      "grad_norm": 0.06870180368423462,
      "learning_rate": 9.385685421199875e-06,
      "loss": 0.035,
      "step": 1581
    },
    {
      "epoch": 0.12294062791420578,
      "grad_norm": 0.2399546355009079,
      "learning_rate": 9.385296860428972e-06,
      "loss": 0.1136,
      "step": 1582
    },
    {
      "epoch": 0.12301834006838669,
      "grad_norm": 0.18977616727352142,
      "learning_rate": 9.384908299658067e-06,
      "loss": 0.066,
      "step": 1583
    },
    {
      "epoch": 0.12309605222256761,
      "grad_norm": 0.2879248261451721,
      "learning_rate": 9.384519738887162e-06,
      "loss": 0.2163,
      "step": 1584
    },
    {
      "epoch": 0.12317376437674853,
      "grad_norm": 0.2932817041873932,
      "learning_rate": 9.384131178116259e-06,
      "loss": 0.1431,
      "step": 1585
    },
    {
      "epoch": 0.12325147653092944,
      "grad_norm": 0.22645123302936554,
      "learning_rate": 9.383742617345353e-06,
      "loss": 0.1446,
      "step": 1586
    },
    {
      "epoch": 0.12332918868511035,
      "grad_norm": 0.5070374608039856,
      "learning_rate": 9.383354056574448e-06,
      "loss": 0.6338,
      "step": 1587
    },
    {
      "epoch": 0.12340690083929126,
      "grad_norm": 0.15266768634319305,
      "learning_rate": 9.382965495803545e-06,
      "loss": 0.0683,
      "step": 1588
    },
    {
      "epoch": 0.12348461299347217,
      "grad_norm": 0.2527906894683838,
      "learning_rate": 9.38257693503264e-06,
      "loss": 0.196,
      "step": 1589
    },
    {
      "epoch": 0.1235623251476531,
      "grad_norm": 0.09217587113380432,
      "learning_rate": 9.382188374261735e-06,
      "loss": 0.0246,
      "step": 1590
    },
    {
      "epoch": 0.12364003730183401,
      "grad_norm": 0.9919965863227844,
      "learning_rate": 9.38179981349083e-06,
      "loss": 0.3003,
      "step": 1591
    },
    {
      "epoch": 0.12371774945601492,
      "grad_norm": 0.38927754759788513,
      "learning_rate": 9.381411252719927e-06,
      "loss": 0.292,
      "step": 1592
    },
    {
      "epoch": 0.12379546161019583,
      "grad_norm": 0.4607742726802826,
      "learning_rate": 9.381022691949022e-06,
      "loss": 0.5264,
      "step": 1593
    },
    {
      "epoch": 0.12387317376437675,
      "grad_norm": 0.23596446216106415,
      "learning_rate": 9.380634131178116e-06,
      "loss": 0.2474,
      "step": 1594
    },
    {
      "epoch": 0.12395088591855766,
      "grad_norm": 0.22497780621051788,
      "learning_rate": 9.380245570407213e-06,
      "loss": 0.092,
      "step": 1595
    },
    {
      "epoch": 0.12402859807273858,
      "grad_norm": 0.30640512704849243,
      "learning_rate": 9.379857009636308e-06,
      "loss": 0.2416,
      "step": 1596
    },
    {
      "epoch": 0.1241063102269195,
      "grad_norm": 0.9760950207710266,
      "learning_rate": 9.379468448865403e-06,
      "loss": 0.1136,
      "step": 1597
    },
    {
      "epoch": 0.1241840223811004,
      "grad_norm": 0.2674091160297394,
      "learning_rate": 9.3790798880945e-06,
      "loss": 0.2155,
      "step": 1598
    },
    {
      "epoch": 0.12426173453528132,
      "grad_norm": 0.2913026213645935,
      "learning_rate": 9.378691327323595e-06,
      "loss": 0.0544,
      "step": 1599
    },
    {
      "epoch": 0.12433944668946223,
      "grad_norm": 0.0736997202038765,
      "learning_rate": 9.37830276655269e-06,
      "loss": 0.0438,
      "step": 1600
    },
    {
      "epoch": 0.12441715884364314,
      "grad_norm": 0.23800060153007507,
      "learning_rate": 9.377914205781785e-06,
      "loss": 0.1141,
      "step": 1601
    },
    {
      "epoch": 0.12449487099782405,
      "grad_norm": 0.2429092973470688,
      "learning_rate": 9.377525645010881e-06,
      "loss": 0.134,
      "step": 1602
    },
    {
      "epoch": 0.12457258315200498,
      "grad_norm": 0.5129991173744202,
      "learning_rate": 9.377137084239976e-06,
      "loss": 0.3553,
      "step": 1603
    },
    {
      "epoch": 0.12465029530618589,
      "grad_norm": 0.11921272426843643,
      "learning_rate": 9.376748523469071e-06,
      "loss": 0.0866,
      "step": 1604
    },
    {
      "epoch": 0.1247280074603668,
      "grad_norm": 0.38691774010658264,
      "learning_rate": 9.376359962698168e-06,
      "loss": 0.4176,
      "step": 1605
    },
    {
      "epoch": 0.12480571961454771,
      "grad_norm": 0.37283894419670105,
      "learning_rate": 9.375971401927263e-06,
      "loss": 0.5031,
      "step": 1606
    },
    {
      "epoch": 0.12488343176872863,
      "grad_norm": 0.3267390727996826,
      "learning_rate": 9.375582841156358e-06,
      "loss": 0.2641,
      "step": 1607
    },
    {
      "epoch": 0.12496114392290954,
      "grad_norm": 0.2737733721733093,
      "learning_rate": 9.375194280385454e-06,
      "loss": 0.1909,
      "step": 1608
    },
    {
      "epoch": 0.12503885607709045,
      "grad_norm": 0.11461140215396881,
      "learning_rate": 9.374805719614548e-06,
      "loss": 0.0413,
      "step": 1609
    },
    {
      "epoch": 0.12511656823127137,
      "grad_norm": 0.42512062191963196,
      "learning_rate": 9.374417158843644e-06,
      "loss": 0.2356,
      "step": 1610
    },
    {
      "epoch": 0.12519428038545227,
      "grad_norm": 0.3523106873035431,
      "learning_rate": 9.374028598072739e-06,
      "loss": 0.2874,
      "step": 1611
    },
    {
      "epoch": 0.1252719925396332,
      "grad_norm": 0.6346626877784729,
      "learning_rate": 9.373640037301834e-06,
      "loss": 0.2582,
      "step": 1612
    },
    {
      "epoch": 0.12534970469381412,
      "grad_norm": 0.4901833236217499,
      "learning_rate": 9.37325147653093e-06,
      "loss": 0.2749,
      "step": 1613
    },
    {
      "epoch": 0.12542741684799502,
      "grad_norm": 0.35652294754981995,
      "learning_rate": 9.372862915760026e-06,
      "loss": 0.2349,
      "step": 1614
    },
    {
      "epoch": 0.12550512900217595,
      "grad_norm": 0.49236470460891724,
      "learning_rate": 9.37247435498912e-06,
      "loss": 0.4851,
      "step": 1615
    },
    {
      "epoch": 0.12558284115635684,
      "grad_norm": 0.47737008333206177,
      "learning_rate": 9.372085794218217e-06,
      "loss": 0.0989,
      "step": 1616
    },
    {
      "epoch": 0.12566055331053777,
      "grad_norm": 0.26015886664390564,
      "learning_rate": 9.371697233447312e-06,
      "loss": 0.1626,
      "step": 1617
    },
    {
      "epoch": 0.12573826546471867,
      "grad_norm": 0.4171718657016754,
      "learning_rate": 9.371308672676407e-06,
      "loss": 0.4884,
      "step": 1618
    },
    {
      "epoch": 0.1258159776188996,
      "grad_norm": 0.18169376254081726,
      "learning_rate": 9.370920111905502e-06,
      "loss": 0.2167,
      "step": 1619
    },
    {
      "epoch": 0.12589368977308052,
      "grad_norm": 0.1484575867652893,
      "learning_rate": 9.370531551134599e-06,
      "loss": 0.0697,
      "step": 1620
    },
    {
      "epoch": 0.12597140192726142,
      "grad_norm": 0.2728215754032135,
      "learning_rate": 9.370142990363694e-06,
      "loss": 0.1573,
      "step": 1621
    },
    {
      "epoch": 0.12604911408144234,
      "grad_norm": 0.5840156078338623,
      "learning_rate": 9.369754429592789e-06,
      "loss": 0.4011,
      "step": 1622
    },
    {
      "epoch": 0.12612682623562324,
      "grad_norm": 0.14646640419960022,
      "learning_rate": 9.369365868821885e-06,
      "loss": 0.0605,
      "step": 1623
    },
    {
      "epoch": 0.12620453838980417,
      "grad_norm": 0.29752060770988464,
      "learning_rate": 9.36897730805098e-06,
      "loss": 0.2774,
      "step": 1624
    },
    {
      "epoch": 0.1262822505439851,
      "grad_norm": 0.2576594054698944,
      "learning_rate": 9.368588747280075e-06,
      "loss": 0.1605,
      "step": 1625
    },
    {
      "epoch": 0.126359962698166,
      "grad_norm": 0.08608041703701019,
      "learning_rate": 9.36820018650917e-06,
      "loss": 0.0594,
      "step": 1626
    },
    {
      "epoch": 0.12643767485234692,
      "grad_norm": 0.4943833649158478,
      "learning_rate": 9.367811625738267e-06,
      "loss": 0.1757,
      "step": 1627
    },
    {
      "epoch": 0.1265153870065278,
      "grad_norm": 0.2603176534175873,
      "learning_rate": 9.367423064967362e-06,
      "loss": 0.0401,
      "step": 1628
    },
    {
      "epoch": 0.12659309916070874,
      "grad_norm": 0.6813678741455078,
      "learning_rate": 9.367034504196457e-06,
      "loss": 0.3659,
      "step": 1629
    },
    {
      "epoch": 0.12667081131488964,
      "grad_norm": 0.27950453758239746,
      "learning_rate": 9.366645943425553e-06,
      "loss": 0.0501,
      "step": 1630
    },
    {
      "epoch": 0.12674852346907056,
      "grad_norm": 0.130384624004364,
      "learning_rate": 9.366257382654648e-06,
      "loss": 0.0345,
      "step": 1631
    },
    {
      "epoch": 0.1268262356232515,
      "grad_norm": 0.45734331011772156,
      "learning_rate": 9.365868821883743e-06,
      "loss": 0.1997,
      "step": 1632
    },
    {
      "epoch": 0.12690394777743239,
      "grad_norm": 0.08990037441253662,
      "learning_rate": 9.36548026111284e-06,
      "loss": 0.02,
      "step": 1633
    },
    {
      "epoch": 0.1269816599316133,
      "grad_norm": 0.16154545545578003,
      "learning_rate": 9.365091700341933e-06,
      "loss": 0.0812,
      "step": 1634
    },
    {
      "epoch": 0.1270593720857942,
      "grad_norm": 0.2610047459602356,
      "learning_rate": 9.36470313957103e-06,
      "loss": 0.1478,
      "step": 1635
    },
    {
      "epoch": 0.12713708423997513,
      "grad_norm": 0.71878582239151,
      "learning_rate": 9.364314578800125e-06,
      "loss": 0.5135,
      "step": 1636
    },
    {
      "epoch": 0.12721479639415603,
      "grad_norm": 0.696296751499176,
      "learning_rate": 9.36392601802922e-06,
      "loss": 0.4349,
      "step": 1637
    },
    {
      "epoch": 0.12729250854833696,
      "grad_norm": 0.48520612716674805,
      "learning_rate": 9.363537457258316e-06,
      "loss": 0.3638,
      "step": 1638
    },
    {
      "epoch": 0.12737022070251788,
      "grad_norm": 0.18026967346668243,
      "learning_rate": 9.363148896487411e-06,
      "loss": 0.1737,
      "step": 1639
    },
    {
      "epoch": 0.12744793285669878,
      "grad_norm": 0.6090734004974365,
      "learning_rate": 9.362760335716506e-06,
      "loss": 0.6029,
      "step": 1640
    },
    {
      "epoch": 0.1275256450108797,
      "grad_norm": 0.44693922996520996,
      "learning_rate": 9.362371774945603e-06,
      "loss": 0.2602,
      "step": 1641
    },
    {
      "epoch": 0.1276033571650606,
      "grad_norm": 0.16370175778865814,
      "learning_rate": 9.361983214174698e-06,
      "loss": 0.0829,
      "step": 1642
    },
    {
      "epoch": 0.12768106931924153,
      "grad_norm": 0.0896555483341217,
      "learning_rate": 9.361594653403793e-06,
      "loss": 0.0224,
      "step": 1643
    },
    {
      "epoch": 0.12775878147342246,
      "grad_norm": 0.2713298499584198,
      "learning_rate": 9.361206092632888e-06,
      "loss": 0.1877,
      "step": 1644
    },
    {
      "epoch": 0.12783649362760335,
      "grad_norm": 0.07330712676048279,
      "learning_rate": 9.360817531861984e-06,
      "loss": 0.016,
      "step": 1645
    },
    {
      "epoch": 0.12791420578178428,
      "grad_norm": 0.17754413187503815,
      "learning_rate": 9.36042897109108e-06,
      "loss": 0.1432,
      "step": 1646
    },
    {
      "epoch": 0.12799191793596518,
      "grad_norm": 0.2002880573272705,
      "learning_rate": 9.360040410320174e-06,
      "loss": 0.3496,
      "step": 1647
    },
    {
      "epoch": 0.1280696300901461,
      "grad_norm": 0.21397365629673004,
      "learning_rate": 9.359651849549271e-06,
      "loss": 0.1152,
      "step": 1648
    },
    {
      "epoch": 0.128147342244327,
      "grad_norm": 0.39989736676216125,
      "learning_rate": 9.359263288778366e-06,
      "loss": 0.2943,
      "step": 1649
    },
    {
      "epoch": 0.12822505439850793,
      "grad_norm": 0.18334710597991943,
      "learning_rate": 9.35887472800746e-06,
      "loss": 0.0938,
      "step": 1650
    },
    {
      "epoch": 0.12830276655268885,
      "grad_norm": 0.10242019593715668,
      "learning_rate": 9.358486167236557e-06,
      "loss": 0.079,
      "step": 1651
    },
    {
      "epoch": 0.12838047870686975,
      "grad_norm": 0.2817603647708893,
      "learning_rate": 9.35809760646565e-06,
      "loss": 0.2194,
      "step": 1652
    },
    {
      "epoch": 0.12845819086105068,
      "grad_norm": 0.11327309161424637,
      "learning_rate": 9.357709045694747e-06,
      "loss": 0.0915,
      "step": 1653
    },
    {
      "epoch": 0.12853590301523157,
      "grad_norm": 0.6409659385681152,
      "learning_rate": 9.357320484923842e-06,
      "loss": 0.1683,
      "step": 1654
    },
    {
      "epoch": 0.1286136151694125,
      "grad_norm": 0.1367684155702591,
      "learning_rate": 9.356931924152939e-06,
      "loss": 0.0861,
      "step": 1655
    },
    {
      "epoch": 0.1286913273235934,
      "grad_norm": 0.30524304509162903,
      "learning_rate": 9.356543363382034e-06,
      "loss": 0.7451,
      "step": 1656
    },
    {
      "epoch": 0.12876903947777432,
      "grad_norm": 1.1974899768829346,
      "learning_rate": 9.356154802611129e-06,
      "loss": 0.2648,
      "step": 1657
    },
    {
      "epoch": 0.12884675163195525,
      "grad_norm": 0.09621545672416687,
      "learning_rate": 9.355766241840225e-06,
      "loss": 0.0398,
      "step": 1658
    },
    {
      "epoch": 0.12892446378613615,
      "grad_norm": 0.3442577123641968,
      "learning_rate": 9.35537768106932e-06,
      "loss": 0.1996,
      "step": 1659
    },
    {
      "epoch": 0.12900217594031707,
      "grad_norm": 0.21111096441745758,
      "learning_rate": 9.354989120298415e-06,
      "loss": 0.1173,
      "step": 1660
    },
    {
      "epoch": 0.12907988809449797,
      "grad_norm": 0.09778859466314316,
      "learning_rate": 9.354600559527512e-06,
      "loss": 0.0322,
      "step": 1661
    },
    {
      "epoch": 0.1291576002486789,
      "grad_norm": 0.21240432560443878,
      "learning_rate": 9.354211998756605e-06,
      "loss": 0.1758,
      "step": 1662
    },
    {
      "epoch": 0.12923531240285982,
      "grad_norm": 0.19112183153629303,
      "learning_rate": 9.353823437985702e-06,
      "loss": 0.1792,
      "step": 1663
    },
    {
      "epoch": 0.12931302455704072,
      "grad_norm": 0.17739331722259521,
      "learning_rate": 9.353434877214797e-06,
      "loss": 0.0688,
      "step": 1664
    },
    {
      "epoch": 0.12939073671122164,
      "grad_norm": 0.2504313290119171,
      "learning_rate": 9.353046316443892e-06,
      "loss": 0.1923,
      "step": 1665
    },
    {
      "epoch": 0.12946844886540254,
      "grad_norm": 0.2919565439224243,
      "learning_rate": 9.352657755672988e-06,
      "loss": 0.3864,
      "step": 1666
    },
    {
      "epoch": 0.12954616101958347,
      "grad_norm": 0.011499261483550072,
      "learning_rate": 9.352269194902083e-06,
      "loss": 0.0018,
      "step": 1667
    },
    {
      "epoch": 0.12962387317376436,
      "grad_norm": 0.5377324223518372,
      "learning_rate": 9.351880634131178e-06,
      "loss": 0.8261,
      "step": 1668
    },
    {
      "epoch": 0.1297015853279453,
      "grad_norm": 0.23143164813518524,
      "learning_rate": 9.351492073360275e-06,
      "loss": 0.1992,
      "step": 1669
    },
    {
      "epoch": 0.12977929748212622,
      "grad_norm": 0.13850471377372742,
      "learning_rate": 9.35110351258937e-06,
      "loss": 0.057,
      "step": 1670
    },
    {
      "epoch": 0.1298570096363071,
      "grad_norm": 0.22081030905246735,
      "learning_rate": 9.350714951818465e-06,
      "loss": 0.0889,
      "step": 1671
    },
    {
      "epoch": 0.12993472179048804,
      "grad_norm": 0.12124975025653839,
      "learning_rate": 9.35032639104756e-06,
      "loss": 0.0673,
      "step": 1672
    },
    {
      "epoch": 0.13001243394466894,
      "grad_norm": 0.16748198866844177,
      "learning_rate": 9.349937830276656e-06,
      "loss": 0.1408,
      "step": 1673
    },
    {
      "epoch": 0.13009014609884986,
      "grad_norm": 0.5491378307342529,
      "learning_rate": 9.349549269505751e-06,
      "loss": 0.5869,
      "step": 1674
    },
    {
      "epoch": 0.13016785825303076,
      "grad_norm": 0.09215062856674194,
      "learning_rate": 9.349160708734846e-06,
      "loss": 0.1011,
      "step": 1675
    },
    {
      "epoch": 0.13024557040721169,
      "grad_norm": 0.483199805021286,
      "learning_rate": 9.348772147963943e-06,
      "loss": 0.4254,
      "step": 1676
    },
    {
      "epoch": 0.1303232825613926,
      "grad_norm": 0.13814233243465424,
      "learning_rate": 9.348383587193038e-06,
      "loss": 0.0467,
      "step": 1677
    },
    {
      "epoch": 0.1304009947155735,
      "grad_norm": 0.12819185853004456,
      "learning_rate": 9.347995026422133e-06,
      "loss": 0.0868,
      "step": 1678
    },
    {
      "epoch": 0.13047870686975443,
      "grad_norm": 0.33449527621269226,
      "learning_rate": 9.34760646565123e-06,
      "loss": 0.2509,
      "step": 1679
    },
    {
      "epoch": 0.13055641902393533,
      "grad_norm": 0.10896866023540497,
      "learning_rate": 9.347217904880323e-06,
      "loss": 0.0614,
      "step": 1680
    },
    {
      "epoch": 0.13063413117811626,
      "grad_norm": 0.20824046432971954,
      "learning_rate": 9.34682934410942e-06,
      "loss": 0.0944,
      "step": 1681
    },
    {
      "epoch": 0.13071184333229718,
      "grad_norm": 0.18089023232460022,
      "learning_rate": 9.346440783338514e-06,
      "loss": 0.0543,
      "step": 1682
    },
    {
      "epoch": 0.13078955548647808,
      "grad_norm": 0.2624190151691437,
      "learning_rate": 9.34605222256761e-06,
      "loss": 0.1948,
      "step": 1683
    },
    {
      "epoch": 0.130867267640659,
      "grad_norm": 0.3064875602722168,
      "learning_rate": 9.345663661796706e-06,
      "loss": 0.2077,
      "step": 1684
    },
    {
      "epoch": 0.1309449797948399,
      "grad_norm": 0.2834498882293701,
      "learning_rate": 9.345275101025801e-06,
      "loss": 0.1218,
      "step": 1685
    },
    {
      "epoch": 0.13102269194902083,
      "grad_norm": 0.23739825189113617,
      "learning_rate": 9.344886540254898e-06,
      "loss": 0.2685,
      "step": 1686
    },
    {
      "epoch": 0.13110040410320173,
      "grad_norm": 0.15436071157455444,
      "learning_rate": 9.344497979483993e-06,
      "loss": 0.0855,
      "step": 1687
    },
    {
      "epoch": 0.13117811625738265,
      "grad_norm": 0.12302982807159424,
      "learning_rate": 9.344109418713087e-06,
      "loss": 0.0628,
      "step": 1688
    },
    {
      "epoch": 0.13125582841156358,
      "grad_norm": 0.08696463704109192,
      "learning_rate": 9.343720857942184e-06,
      "loss": 0.0625,
      "step": 1689
    },
    {
      "epoch": 0.13133354056574448,
      "grad_norm": 0.21548545360565186,
      "learning_rate": 9.343332297171277e-06,
      "loss": 0.1376,
      "step": 1690
    },
    {
      "epoch": 0.1314112527199254,
      "grad_norm": 0.33304113149642944,
      "learning_rate": 9.342943736400374e-06,
      "loss": 0.1623,
      "step": 1691
    },
    {
      "epoch": 0.1314889648741063,
      "grad_norm": 0.08612014353275299,
      "learning_rate": 9.342555175629469e-06,
      "loss": 0.0347,
      "step": 1692
    },
    {
      "epoch": 0.13156667702828723,
      "grad_norm": 0.11575523763895035,
      "learning_rate": 9.342166614858564e-06,
      "loss": 0.0859,
      "step": 1693
    },
    {
      "epoch": 0.13164438918246812,
      "grad_norm": 0.31438079476356506,
      "learning_rate": 9.34177805408766e-06,
      "loss": 0.3174,
      "step": 1694
    },
    {
      "epoch": 0.13172210133664905,
      "grad_norm": 0.25891485810279846,
      "learning_rate": 9.341389493316756e-06,
      "loss": 0.0719,
      "step": 1695
    },
    {
      "epoch": 0.13179981349082998,
      "grad_norm": 0.15959922969341278,
      "learning_rate": 9.34100093254585e-06,
      "loss": 0.0858,
      "step": 1696
    },
    {
      "epoch": 0.13187752564501087,
      "grad_norm": 0.2208910584449768,
      "learning_rate": 9.340612371774947e-06,
      "loss": 0.2176,
      "step": 1697
    },
    {
      "epoch": 0.1319552377991918,
      "grad_norm": 0.2014714628458023,
      "learning_rate": 9.340223811004042e-06,
      "loss": 0.2152,
      "step": 1698
    },
    {
      "epoch": 0.1320329499533727,
      "grad_norm": 0.11190977692604065,
      "learning_rate": 9.339835250233137e-06,
      "loss": 0.0482,
      "step": 1699
    },
    {
      "epoch": 0.13211066210755362,
      "grad_norm": 0.0843263491988182,
      "learning_rate": 9.339446689462232e-06,
      "loss": 0.0656,
      "step": 1700
    },
    {
      "epoch": 0.13218837426173455,
      "grad_norm": 0.14930057525634766,
      "learning_rate": 9.339058128691329e-06,
      "loss": 0.0503,
      "step": 1701
    },
    {
      "epoch": 0.13226608641591545,
      "grad_norm": 0.2845979630947113,
      "learning_rate": 9.338669567920424e-06,
      "loss": 0.2409,
      "step": 1702
    },
    {
      "epoch": 0.13234379857009637,
      "grad_norm": 0.17211927473545074,
      "learning_rate": 9.338281007149519e-06,
      "loss": 0.1378,
      "step": 1703
    },
    {
      "epoch": 0.13242151072427727,
      "grad_norm": 0.3913266956806183,
      "learning_rate": 9.337892446378615e-06,
      "loss": 0.2797,
      "step": 1704
    },
    {
      "epoch": 0.1324992228784582,
      "grad_norm": 0.25459107756614685,
      "learning_rate": 9.33750388560771e-06,
      "loss": 0.1871,
      "step": 1705
    },
    {
      "epoch": 0.1325769350326391,
      "grad_norm": 0.050238169729709625,
      "learning_rate": 9.337115324836805e-06,
      "loss": 0.0438,
      "step": 1706
    },
    {
      "epoch": 0.13265464718682002,
      "grad_norm": 0.26948291063308716,
      "learning_rate": 9.336726764065902e-06,
      "loss": 0.1794,
      "step": 1707
    },
    {
      "epoch": 0.13273235934100094,
      "grad_norm": 0.05677285045385361,
      "learning_rate": 9.336338203294995e-06,
      "loss": 0.0409,
      "step": 1708
    },
    {
      "epoch": 0.13281007149518184,
      "grad_norm": 1.1089885234832764,
      "learning_rate": 9.335949642524092e-06,
      "loss": 0.2286,
      "step": 1709
    },
    {
      "epoch": 0.13288778364936277,
      "grad_norm": 0.3043385446071625,
      "learning_rate": 9.335561081753187e-06,
      "loss": 0.1348,
      "step": 1710
    },
    {
      "epoch": 0.13296549580354367,
      "grad_norm": 0.5903640985488892,
      "learning_rate": 9.335172520982282e-06,
      "loss": 0.393,
      "step": 1711
    },
    {
      "epoch": 0.1330432079577246,
      "grad_norm": 0.26901018619537354,
      "learning_rate": 9.334783960211378e-06,
      "loss": 0.1971,
      "step": 1712
    },
    {
      "epoch": 0.1331209201119055,
      "grad_norm": 0.15258821845054626,
      "learning_rate": 9.334395399440473e-06,
      "loss": 0.0535,
      "step": 1713
    },
    {
      "epoch": 0.13319863226608641,
      "grad_norm": 0.4158936142921448,
      "learning_rate": 9.334006838669568e-06,
      "loss": 0.1491,
      "step": 1714
    },
    {
      "epoch": 0.13327634442026734,
      "grad_norm": 0.28512153029441833,
      "learning_rate": 9.333618277898665e-06,
      "loss": 0.1662,
      "step": 1715
    },
    {
      "epoch": 0.13335405657444824,
      "grad_norm": 0.015195770189166069,
      "learning_rate": 9.33322971712776e-06,
      "loss": 0.0017,
      "step": 1716
    },
    {
      "epoch": 0.13343176872862916,
      "grad_norm": 0.3997407853603363,
      "learning_rate": 9.332841156356856e-06,
      "loss": 0.2402,
      "step": 1717
    },
    {
      "epoch": 0.13350948088281006,
      "grad_norm": 0.21205879747867584,
      "learning_rate": 9.33245259558595e-06,
      "loss": 0.0638,
      "step": 1718
    },
    {
      "epoch": 0.133587193036991,
      "grad_norm": 0.8133431077003479,
      "learning_rate": 9.332064034815046e-06,
      "loss": 0.4935,
      "step": 1719
    },
    {
      "epoch": 0.1336649051911719,
      "grad_norm": 0.038210995495319366,
      "learning_rate": 9.331675474044141e-06,
      "loss": 0.0081,
      "step": 1720
    },
    {
      "epoch": 0.1337426173453528,
      "grad_norm": 0.07332731783390045,
      "learning_rate": 9.331286913273236e-06,
      "loss": 0.026,
      "step": 1721
    },
    {
      "epoch": 0.13382032949953374,
      "grad_norm": 0.23736605048179626,
      "learning_rate": 9.330898352502333e-06,
      "loss": 0.3649,
      "step": 1722
    },
    {
      "epoch": 0.13389804165371463,
      "grad_norm": 0.36186614632606506,
      "learning_rate": 9.330509791731428e-06,
      "loss": 0.3332,
      "step": 1723
    },
    {
      "epoch": 0.13397575380789556,
      "grad_norm": 0.32039347290992737,
      "learning_rate": 9.330121230960523e-06,
      "loss": 0.0986,
      "step": 1724
    },
    {
      "epoch": 0.13405346596207646,
      "grad_norm": 0.392922043800354,
      "learning_rate": 9.32973267018962e-06,
      "loss": 0.5714,
      "step": 1725
    },
    {
      "epoch": 0.13413117811625738,
      "grad_norm": 0.21540528535842896,
      "learning_rate": 9.329344109418714e-06,
      "loss": 0.1585,
      "step": 1726
    },
    {
      "epoch": 0.1342088902704383,
      "grad_norm": 0.21814124286174774,
      "learning_rate": 9.32895554864781e-06,
      "loss": 0.1975,
      "step": 1727
    },
    {
      "epoch": 0.1342866024246192,
      "grad_norm": 0.3084782361984253,
      "learning_rate": 9.328566987876904e-06,
      "loss": 0.1605,
      "step": 1728
    },
    {
      "epoch": 0.13436431457880013,
      "grad_norm": 0.11428702622652054,
      "learning_rate": 9.328178427106e-06,
      "loss": 0.0485,
      "step": 1729
    },
    {
      "epoch": 0.13444202673298103,
      "grad_norm": 0.32870933413505554,
      "learning_rate": 9.327789866335096e-06,
      "loss": 0.3101,
      "step": 1730
    },
    {
      "epoch": 0.13451973888716195,
      "grad_norm": 0.11051604896783829,
      "learning_rate": 9.32740130556419e-06,
      "loss": 0.02,
      "step": 1731
    },
    {
      "epoch": 0.13459745104134285,
      "grad_norm": 0.13087257742881775,
      "learning_rate": 9.327012744793287e-06,
      "loss": 0.0378,
      "step": 1732
    },
    {
      "epoch": 0.13467516319552378,
      "grad_norm": 0.09406747668981552,
      "learning_rate": 9.326624184022382e-06,
      "loss": 0.0407,
      "step": 1733
    },
    {
      "epoch": 0.1347528753497047,
      "grad_norm": 7.402775764465332,
      "learning_rate": 9.326235623251477e-06,
      "loss": 2.0151,
      "step": 1734
    },
    {
      "epoch": 0.1348305875038856,
      "grad_norm": 0.6983204483985901,
      "learning_rate": 9.325847062480574e-06,
      "loss": 0.6418,
      "step": 1735
    },
    {
      "epoch": 0.13490829965806653,
      "grad_norm": 0.2321220338344574,
      "learning_rate": 9.325458501709667e-06,
      "loss": 0.1701,
      "step": 1736
    },
    {
      "epoch": 0.13498601181224743,
      "grad_norm": 0.4162604510784149,
      "learning_rate": 9.325069940938764e-06,
      "loss": 0.1196,
      "step": 1737
    },
    {
      "epoch": 0.13506372396642835,
      "grad_norm": 0.28729814291000366,
      "learning_rate": 9.324681380167859e-06,
      "loss": 0.1934,
      "step": 1738
    },
    {
      "epoch": 0.13514143612060928,
      "grad_norm": 0.3409171998500824,
      "learning_rate": 9.324292819396954e-06,
      "loss": 0.2852,
      "step": 1739
    },
    {
      "epoch": 0.13521914827479017,
      "grad_norm": 0.26934048533439636,
      "learning_rate": 9.32390425862605e-06,
      "loss": 0.144,
      "step": 1740
    },
    {
      "epoch": 0.1352968604289711,
      "grad_norm": 0.3741718828678131,
      "learning_rate": 9.323515697855145e-06,
      "loss": 0.2136,
      "step": 1741
    },
    {
      "epoch": 0.135374572583152,
      "grad_norm": 0.14647404849529266,
      "learning_rate": 9.32312713708424e-06,
      "loss": 0.1106,
      "step": 1742
    },
    {
      "epoch": 0.13545228473733292,
      "grad_norm": 0.48090988397598267,
      "learning_rate": 9.322738576313337e-06,
      "loss": 1.3377,
      "step": 1743
    },
    {
      "epoch": 0.13552999689151382,
      "grad_norm": 0.11022180318832397,
      "learning_rate": 9.322350015542432e-06,
      "loss": 0.0247,
      "step": 1744
    },
    {
      "epoch": 0.13560770904569475,
      "grad_norm": 0.07265742123126984,
      "learning_rate": 9.321961454771527e-06,
      "loss": 0.0229,
      "step": 1745
    },
    {
      "epoch": 0.13568542119987567,
      "grad_norm": 0.2013673633337021,
      "learning_rate": 9.321572894000622e-06,
      "loss": 0.0653,
      "step": 1746
    },
    {
      "epoch": 0.13576313335405657,
      "grad_norm": 0.27084705233573914,
      "learning_rate": 9.321184333229718e-06,
      "loss": 0.2399,
      "step": 1747
    },
    {
      "epoch": 0.1358408455082375,
      "grad_norm": 0.9649025797843933,
      "learning_rate": 9.320795772458813e-06,
      "loss": 0.1116,
      "step": 1748
    },
    {
      "epoch": 0.1359185576624184,
      "grad_norm": 0.17620694637298584,
      "learning_rate": 9.320407211687908e-06,
      "loss": 0.1292,
      "step": 1749
    },
    {
      "epoch": 0.13599626981659932,
      "grad_norm": 0.0747591108083725,
      "learning_rate": 9.320018650917005e-06,
      "loss": 0.0638,
      "step": 1750
    },
    {
      "epoch": 0.13607398197078022,
      "grad_norm": 0.12964239716529846,
      "learning_rate": 9.3196300901461e-06,
      "loss": 0.0561,
      "step": 1751
    },
    {
      "epoch": 0.13615169412496114,
      "grad_norm": 0.32422512769699097,
      "learning_rate": 9.319241529375195e-06,
      "loss": 0.1754,
      "step": 1752
    },
    {
      "epoch": 0.13622940627914207,
      "grad_norm": 0.3594624996185303,
      "learning_rate": 9.31885296860429e-06,
      "loss": 0.595,
      "step": 1753
    },
    {
      "epoch": 0.13630711843332297,
      "grad_norm": 0.280249685049057,
      "learning_rate": 9.318464407833386e-06,
      "loss": 0.2837,
      "step": 1754
    },
    {
      "epoch": 0.1363848305875039,
      "grad_norm": 0.34848836064338684,
      "learning_rate": 9.318075847062481e-06,
      "loss": 0.2265,
      "step": 1755
    },
    {
      "epoch": 0.1364625427416848,
      "grad_norm": 0.3492041826248169,
      "learning_rate": 9.317687286291576e-06,
      "loss": 0.2489,
      "step": 1756
    },
    {
      "epoch": 0.13654025489586571,
      "grad_norm": 0.04420488327741623,
      "learning_rate": 9.317298725520673e-06,
      "loss": 0.0198,
      "step": 1757
    },
    {
      "epoch": 0.13661796705004664,
      "grad_norm": 0.3000766336917877,
      "learning_rate": 9.316910164749768e-06,
      "loss": 0.1692,
      "step": 1758
    },
    {
      "epoch": 0.13669567920422754,
      "grad_norm": 0.13442586362361908,
      "learning_rate": 9.316521603978863e-06,
      "loss": 0.073,
      "step": 1759
    },
    {
      "epoch": 0.13677339135840846,
      "grad_norm": 0.4018850326538086,
      "learning_rate": 9.31613304320796e-06,
      "loss": 0.1781,
      "step": 1760
    },
    {
      "epoch": 0.13685110351258936,
      "grad_norm": 0.5089628100395203,
      "learning_rate": 9.315744482437053e-06,
      "loss": 0.2802,
      "step": 1761
    },
    {
      "epoch": 0.1369288156667703,
      "grad_norm": 0.173419788479805,
      "learning_rate": 9.31535592166615e-06,
      "loss": 0.0487,
      "step": 1762
    },
    {
      "epoch": 0.13700652782095118,
      "grad_norm": 0.26918280124664307,
      "learning_rate": 9.314967360895244e-06,
      "loss": 0.373,
      "step": 1763
    },
    {
      "epoch": 0.1370842399751321,
      "grad_norm": 0.9563800096511841,
      "learning_rate": 9.31457880012434e-06,
      "loss": 0.8092,
      "step": 1764
    },
    {
      "epoch": 0.13716195212931304,
      "grad_norm": 0.23561610281467438,
      "learning_rate": 9.314190239353436e-06,
      "loss": 0.3309,
      "step": 1765
    },
    {
      "epoch": 0.13723966428349393,
      "grad_norm": 0.573110044002533,
      "learning_rate": 9.313801678582531e-06,
      "loss": 0.2637,
      "step": 1766
    },
    {
      "epoch": 0.13731737643767486,
      "grad_norm": 0.2833329439163208,
      "learning_rate": 9.313413117811626e-06,
      "loss": 0.1833,
      "step": 1767
    },
    {
      "epoch": 0.13739508859185576,
      "grad_norm": 0.2056998461484909,
      "learning_rate": 9.313024557040722e-06,
      "loss": 0.2675,
      "step": 1768
    },
    {
      "epoch": 0.13747280074603668,
      "grad_norm": 0.6977062225341797,
      "learning_rate": 9.312635996269817e-06,
      "loss": 0.2819,
      "step": 1769
    },
    {
      "epoch": 0.13755051290021758,
      "grad_norm": 0.21348445117473602,
      "learning_rate": 9.312247435498912e-06,
      "loss": 0.0783,
      "step": 1770
    },
    {
      "epoch": 0.1376282250543985,
      "grad_norm": 0.2199297845363617,
      "learning_rate": 9.311858874728007e-06,
      "loss": 0.062,
      "step": 1771
    },
    {
      "epoch": 0.13770593720857943,
      "grad_norm": 0.30883851647377014,
      "learning_rate": 9.311470313957104e-06,
      "loss": 0.2099,
      "step": 1772
    },
    {
      "epoch": 0.13778364936276033,
      "grad_norm": 0.13826142251491547,
      "learning_rate": 9.311081753186199e-06,
      "loss": 0.0842,
      "step": 1773
    },
    {
      "epoch": 0.13786136151694126,
      "grad_norm": 0.181211918592453,
      "learning_rate": 9.310693192415294e-06,
      "loss": 0.0395,
      "step": 1774
    },
    {
      "epoch": 0.13793907367112215,
      "grad_norm": 0.07342853397130966,
      "learning_rate": 9.31030463164439e-06,
      "loss": 0.038,
      "step": 1775
    },
    {
      "epoch": 0.13801678582530308,
      "grad_norm": 0.15029646456241608,
      "learning_rate": 9.309916070873485e-06,
      "loss": 0.1316,
      "step": 1776
    },
    {
      "epoch": 0.138094497979484,
      "grad_norm": 0.09207320958375931,
      "learning_rate": 9.30952751010258e-06,
      "loss": 0.0898,
      "step": 1777
    },
    {
      "epoch": 0.1381722101336649,
      "grad_norm": 0.29725396633148193,
      "learning_rate": 9.309138949331677e-06,
      "loss": 0.1813,
      "step": 1778
    },
    {
      "epoch": 0.13824992228784583,
      "grad_norm": 0.19456416368484497,
      "learning_rate": 9.308750388560772e-06,
      "loss": 0.0591,
      "step": 1779
    },
    {
      "epoch": 0.13832763444202673,
      "grad_norm": 0.20363663136959076,
      "learning_rate": 9.308361827789867e-06,
      "loss": 0.1361,
      "step": 1780
    },
    {
      "epoch": 0.13840534659620765,
      "grad_norm": 0.29219892621040344,
      "learning_rate": 9.307973267018962e-06,
      "loss": 0.2192,
      "step": 1781
    },
    {
      "epoch": 0.13848305875038855,
      "grad_norm": 0.4344790577888489,
      "learning_rate": 9.307584706248059e-06,
      "loss": 0.2479,
      "step": 1782
    },
    {
      "epoch": 0.13856077090456947,
      "grad_norm": 0.44513559341430664,
      "learning_rate": 9.307196145477153e-06,
      "loss": 0.3285,
      "step": 1783
    },
    {
      "epoch": 0.1386384830587504,
      "grad_norm": 0.3045533299446106,
      "learning_rate": 9.306807584706248e-06,
      "loss": 0.0718,
      "step": 1784
    },
    {
      "epoch": 0.1387161952129313,
      "grad_norm": 0.2517232596874237,
      "learning_rate": 9.306419023935345e-06,
      "loss": 0.5038,
      "step": 1785
    },
    {
      "epoch": 0.13879390736711222,
      "grad_norm": 0.2933400273323059,
      "learning_rate": 9.30603046316444e-06,
      "loss": 0.1222,
      "step": 1786
    },
    {
      "epoch": 0.13887161952129312,
      "grad_norm": 0.05452727526426315,
      "learning_rate": 9.305641902393535e-06,
      "loss": 0.0232,
      "step": 1787
    },
    {
      "epoch": 0.13894933167547405,
      "grad_norm": 0.24944035708904266,
      "learning_rate": 9.305253341622632e-06,
      "loss": 0.0525,
      "step": 1788
    },
    {
      "epoch": 0.13902704382965494,
      "grad_norm": 0.24749600887298584,
      "learning_rate": 9.304864780851725e-06,
      "loss": 0.1222,
      "step": 1789
    },
    {
      "epoch": 0.13910475598383587,
      "grad_norm": 0.5715239644050598,
      "learning_rate": 9.304476220080822e-06,
      "loss": 0.0811,
      "step": 1790
    },
    {
      "epoch": 0.1391824681380168,
      "grad_norm": 0.11647968739271164,
      "learning_rate": 9.304087659309916e-06,
      "loss": 0.0195,
      "step": 1791
    },
    {
      "epoch": 0.1392601802921977,
      "grad_norm": 0.18738137185573578,
      "learning_rate": 9.303699098539011e-06,
      "loss": 0.0968,
      "step": 1792
    },
    {
      "epoch": 0.13933789244637862,
      "grad_norm": 0.39532095193862915,
      "learning_rate": 9.303310537768108e-06,
      "loss": 0.1496,
      "step": 1793
    },
    {
      "epoch": 0.13941560460055952,
      "grad_norm": 0.3916795551776886,
      "learning_rate": 9.302921976997203e-06,
      "loss": 0.6517,
      "step": 1794
    },
    {
      "epoch": 0.13949331675474044,
      "grad_norm": 3.450090169906616,
      "learning_rate": 9.302533416226298e-06,
      "loss": 0.2006,
      "step": 1795
    },
    {
      "epoch": 0.13957102890892137,
      "grad_norm": 0.34966036677360535,
      "learning_rate": 9.302144855455395e-06,
      "loss": 0.1322,
      "step": 1796
    },
    {
      "epoch": 0.13964874106310227,
      "grad_norm": 0.16570250689983368,
      "learning_rate": 9.30175629468449e-06,
      "loss": 0.0529,
      "step": 1797
    },
    {
      "epoch": 0.1397264532172832,
      "grad_norm": 0.21037767827510834,
      "learning_rate": 9.301367733913584e-06,
      "loss": 0.0761,
      "step": 1798
    },
    {
      "epoch": 0.1398041653714641,
      "grad_norm": 0.32042670249938965,
      "learning_rate": 9.30097917314268e-06,
      "loss": 0.2505,
      "step": 1799
    },
    {
      "epoch": 0.13988187752564502,
      "grad_norm": 0.6519608497619629,
      "learning_rate": 9.300590612371776e-06,
      "loss": 0.3396,
      "step": 1800
    },
    {
      "epoch": 0.1399595896798259,
      "grad_norm": 0.2939239740371704,
      "learning_rate": 9.300202051600871e-06,
      "loss": 0.0772,
      "step": 1801
    },
    {
      "epoch": 0.14003730183400684,
      "grad_norm": 0.7027768492698669,
      "learning_rate": 9.299813490829966e-06,
      "loss": 0.8293,
      "step": 1802
    },
    {
      "epoch": 0.14011501398818776,
      "grad_norm": 0.4586414396762848,
      "learning_rate": 9.299424930059063e-06,
      "loss": 0.2265,
      "step": 1803
    },
    {
      "epoch": 0.14019272614236866,
      "grad_norm": 0.1847490668296814,
      "learning_rate": 9.299036369288158e-06,
      "loss": 0.1271,
      "step": 1804
    },
    {
      "epoch": 0.1402704382965496,
      "grad_norm": 0.16968028247356415,
      "learning_rate": 9.298647808517253e-06,
      "loss": 0.1077,
      "step": 1805
    },
    {
      "epoch": 0.14034815045073049,
      "grad_norm": 0.21773536503314972,
      "learning_rate": 9.29825924774635e-06,
      "loss": 0.212,
      "step": 1806
    },
    {
      "epoch": 0.1404258626049114,
      "grad_norm": 0.13666661083698273,
      "learning_rate": 9.297870686975444e-06,
      "loss": 0.0381,
      "step": 1807
    },
    {
      "epoch": 0.1405035747590923,
      "grad_norm": 0.15770865976810455,
      "learning_rate": 9.297482126204539e-06,
      "loss": 0.0922,
      "step": 1808
    },
    {
      "epoch": 0.14058128691327323,
      "grad_norm": 0.4358583092689514,
      "learning_rate": 9.297093565433634e-06,
      "loss": 0.3992,
      "step": 1809
    },
    {
      "epoch": 0.14065899906745416,
      "grad_norm": 0.11462303251028061,
      "learning_rate": 9.29670500466273e-06,
      "loss": 0.0716,
      "step": 1810
    },
    {
      "epoch": 0.14073671122163506,
      "grad_norm": 0.5566308498382568,
      "learning_rate": 9.296316443891826e-06,
      "loss": 0.1874,
      "step": 1811
    },
    {
      "epoch": 0.14081442337581598,
      "grad_norm": 0.3205946385860443,
      "learning_rate": 9.29592788312092e-06,
      "loss": 0.054,
      "step": 1812
    },
    {
      "epoch": 0.14089213552999688,
      "grad_norm": 0.7025822401046753,
      "learning_rate": 9.295539322350017e-06,
      "loss": 0.4068,
      "step": 1813
    },
    {
      "epoch": 0.1409698476841778,
      "grad_norm": 0.2749392092227936,
      "learning_rate": 9.295150761579112e-06,
      "loss": 0.1811,
      "step": 1814
    },
    {
      "epoch": 0.14104755983835873,
      "grad_norm": 0.2257402092218399,
      "learning_rate": 9.294762200808207e-06,
      "loss": 0.2563,
      "step": 1815
    },
    {
      "epoch": 0.14112527199253963,
      "grad_norm": 0.16186752915382385,
      "learning_rate": 9.294373640037304e-06,
      "loss": 0.0982,
      "step": 1816
    },
    {
      "epoch": 0.14120298414672056,
      "grad_norm": 0.15751080214977264,
      "learning_rate": 9.293985079266397e-06,
      "loss": 0.0845,
      "step": 1817
    },
    {
      "epoch": 0.14128069630090145,
      "grad_norm": 0.24387773871421814,
      "learning_rate": 9.293596518495494e-06,
      "loss": 0.1239,
      "step": 1818
    },
    {
      "epoch": 0.14135840845508238,
      "grad_norm": 0.32368966937065125,
      "learning_rate": 9.293207957724589e-06,
      "loss": 0.1793,
      "step": 1819
    },
    {
      "epoch": 0.14143612060926328,
      "grad_norm": 0.37853214144706726,
      "learning_rate": 9.292819396953684e-06,
      "loss": 0.2141,
      "step": 1820
    },
    {
      "epoch": 0.1415138327634442,
      "grad_norm": 0.05676068738102913,
      "learning_rate": 9.29243083618278e-06,
      "loss": 0.0297,
      "step": 1821
    },
    {
      "epoch": 0.14159154491762513,
      "grad_norm": 0.05189617723226547,
      "learning_rate": 9.292042275411875e-06,
      "loss": 0.0146,
      "step": 1822
    },
    {
      "epoch": 0.14166925707180603,
      "grad_norm": 0.43067827820777893,
      "learning_rate": 9.29165371464097e-06,
      "loss": 0.1572,
      "step": 1823
    },
    {
      "epoch": 0.14174696922598695,
      "grad_norm": 0.41860970854759216,
      "learning_rate": 9.291265153870067e-06,
      "loss": 0.8572,
      "step": 1824
    },
    {
      "epoch": 0.14182468138016785,
      "grad_norm": 0.08203002065420151,
      "learning_rate": 9.290876593099162e-06,
      "loss": 0.0319,
      "step": 1825
    },
    {
      "epoch": 0.14190239353434878,
      "grad_norm": 0.08904717117547989,
      "learning_rate": 9.290488032328257e-06,
      "loss": 0.0502,
      "step": 1826
    },
    {
      "epoch": 0.14198010568852967,
      "grad_norm": 0.1507902294397354,
      "learning_rate": 9.290099471557352e-06,
      "loss": 0.0909,
      "step": 1827
    },
    {
      "epoch": 0.1420578178427106,
      "grad_norm": 0.5729782581329346,
      "learning_rate": 9.289710910786448e-06,
      "loss": 0.1385,
      "step": 1828
    },
    {
      "epoch": 0.14213552999689152,
      "grad_norm": 0.20940634608268738,
      "learning_rate": 9.289322350015543e-06,
      "loss": 0.0451,
      "step": 1829
    },
    {
      "epoch": 0.14221324215107242,
      "grad_norm": 0.09568165242671967,
      "learning_rate": 9.288933789244638e-06,
      "loss": 0.0475,
      "step": 1830
    },
    {
      "epoch": 0.14229095430525335,
      "grad_norm": 0.17660509049892426,
      "learning_rate": 9.288545228473735e-06,
      "loss": 0.1572,
      "step": 1831
    },
    {
      "epoch": 0.14236866645943425,
      "grad_norm": 0.11117737740278244,
      "learning_rate": 9.28815666770283e-06,
      "loss": 0.1603,
      "step": 1832
    },
    {
      "epoch": 0.14244637861361517,
      "grad_norm": 0.2681070864200592,
      "learning_rate": 9.287768106931925e-06,
      "loss": 0.2381,
      "step": 1833
    },
    {
      "epoch": 0.1425240907677961,
      "grad_norm": 0.17040349543094635,
      "learning_rate": 9.287379546161021e-06,
      "loss": 0.0873,
      "step": 1834
    },
    {
      "epoch": 0.142601802921977,
      "grad_norm": 0.39741864800453186,
      "learning_rate": 9.286990985390115e-06,
      "loss": 0.1149,
      "step": 1835
    },
    {
      "epoch": 0.14267951507615792,
      "grad_norm": 0.06424900889396667,
      "learning_rate": 9.286602424619211e-06,
      "loss": 0.014,
      "step": 1836
    },
    {
      "epoch": 0.14275722723033882,
      "grad_norm": 0.31345126032829285,
      "learning_rate": 9.286213863848306e-06,
      "loss": 0.0577,
      "step": 1837
    },
    {
      "epoch": 0.14283493938451974,
      "grad_norm": 0.2807725667953491,
      "learning_rate": 9.285825303077403e-06,
      "loss": 0.1412,
      "step": 1838
    },
    {
      "epoch": 0.14291265153870064,
      "grad_norm": 0.2548278570175171,
      "learning_rate": 9.285436742306498e-06,
      "loss": 0.044,
      "step": 1839
    },
    {
      "epoch": 0.14299036369288157,
      "grad_norm": 0.17096839845180511,
      "learning_rate": 9.285048181535593e-06,
      "loss": 0.111,
      "step": 1840
    },
    {
      "epoch": 0.1430680758470625,
      "grad_norm": 0.34889280796051025,
      "learning_rate": 9.28465962076469e-06,
      "loss": 0.2387,
      "step": 1841
    },
    {
      "epoch": 0.1431457880012434,
      "grad_norm": 0.19384820759296417,
      "learning_rate": 9.284271059993784e-06,
      "loss": 0.2399,
      "step": 1842
    },
    {
      "epoch": 0.14322350015542432,
      "grad_norm": 0.33752989768981934,
      "learning_rate": 9.28388249922288e-06,
      "loss": 0.1618,
      "step": 1843
    },
    {
      "epoch": 0.1433012123096052,
      "grad_norm": 0.18322642147541046,
      "learning_rate": 9.283493938451976e-06,
      "loss": 0.1402,
      "step": 1844
    },
    {
      "epoch": 0.14337892446378614,
      "grad_norm": 0.23098158836364746,
      "learning_rate": 9.283105377681069e-06,
      "loss": 0.1106,
      "step": 1845
    },
    {
      "epoch": 0.14345663661796704,
      "grad_norm": 0.3781362473964691,
      "learning_rate": 9.282716816910166e-06,
      "loss": 0.2164,
      "step": 1846
    },
    {
      "epoch": 0.14353434877214796,
      "grad_norm": 0.20167644321918488,
      "learning_rate": 9.28232825613926e-06,
      "loss": 0.0396,
      "step": 1847
    },
    {
      "epoch": 0.1436120609263289,
      "grad_norm": 0.425446093082428,
      "learning_rate": 9.281939695368356e-06,
      "loss": 0.057,
      "step": 1848
    },
    {
      "epoch": 0.1436897730805098,
      "grad_norm": 0.20608647167682648,
      "learning_rate": 9.281551134597452e-06,
      "loss": 0.1642,
      "step": 1849
    },
    {
      "epoch": 0.1437674852346907,
      "grad_norm": 0.06563102453947067,
      "learning_rate": 9.281162573826547e-06,
      "loss": 0.027,
      "step": 1850
    },
    {
      "epoch": 0.1438451973888716,
      "grad_norm": 0.10453783720731735,
      "learning_rate": 9.280774013055642e-06,
      "loss": 0.2299,
      "step": 1851
    },
    {
      "epoch": 0.14392290954305254,
      "grad_norm": 0.2963694632053375,
      "learning_rate": 9.280385452284739e-06,
      "loss": 0.2139,
      "step": 1852
    },
    {
      "epoch": 0.14400062169723346,
      "grad_norm": 0.02916860021650791,
      "learning_rate": 9.279996891513834e-06,
      "loss": 0.0079,
      "step": 1853
    },
    {
      "epoch": 0.14407833385141436,
      "grad_norm": 0.02497541531920433,
      "learning_rate": 9.279608330742929e-06,
      "loss": 0.0108,
      "step": 1854
    },
    {
      "epoch": 0.14415604600559528,
      "grad_norm": 0.12783364951610565,
      "learning_rate": 9.279219769972024e-06,
      "loss": 0.0635,
      "step": 1855
    },
    {
      "epoch": 0.14423375815977618,
      "grad_norm": 0.15397851169109344,
      "learning_rate": 9.27883120920112e-06,
      "loss": 0.1383,
      "step": 1856
    },
    {
      "epoch": 0.1443114703139571,
      "grad_norm": 0.10091544687747955,
      "learning_rate": 9.278442648430215e-06,
      "loss": 0.0562,
      "step": 1857
    },
    {
      "epoch": 0.144389182468138,
      "grad_norm": 0.4726480543613434,
      "learning_rate": 9.27805408765931e-06,
      "loss": 0.1222,
      "step": 1858
    },
    {
      "epoch": 0.14446689462231893,
      "grad_norm": 0.10345547646284103,
      "learning_rate": 9.277665526888407e-06,
      "loss": 0.046,
      "step": 1859
    },
    {
      "epoch": 0.14454460677649986,
      "grad_norm": 0.31129077076911926,
      "learning_rate": 9.277276966117502e-06,
      "loss": 0.164,
      "step": 1860
    },
    {
      "epoch": 0.14462231893068075,
      "grad_norm": 0.10769721120595932,
      "learning_rate": 9.276888405346597e-06,
      "loss": 0.0677,
      "step": 1861
    },
    {
      "epoch": 0.14470003108486168,
      "grad_norm": 0.15343032777309418,
      "learning_rate": 9.276499844575693e-06,
      "loss": 0.0908,
      "step": 1862
    },
    {
      "epoch": 0.14477774323904258,
      "grad_norm": 0.5070023536682129,
      "learning_rate": 9.276111283804787e-06,
      "loss": 0.3829,
      "step": 1863
    },
    {
      "epoch": 0.1448554553932235,
      "grad_norm": 0.3368132710456848,
      "learning_rate": 9.275722723033883e-06,
      "loss": 0.0853,
      "step": 1864
    },
    {
      "epoch": 0.1449331675474044,
      "grad_norm": 0.2702951729297638,
      "learning_rate": 9.275334162262978e-06,
      "loss": 0.2229,
      "step": 1865
    },
    {
      "epoch": 0.14501087970158533,
      "grad_norm": 0.29187294840812683,
      "learning_rate": 9.274945601492073e-06,
      "loss": 0.1062,
      "step": 1866
    },
    {
      "epoch": 0.14508859185576625,
      "grad_norm": 0.38709503412246704,
      "learning_rate": 9.27455704072117e-06,
      "loss": 0.1871,
      "step": 1867
    },
    {
      "epoch": 0.14516630400994715,
      "grad_norm": 0.2477586567401886,
      "learning_rate": 9.274168479950265e-06,
      "loss": 0.1452,
      "step": 1868
    },
    {
      "epoch": 0.14524401616412808,
      "grad_norm": 0.2050558477640152,
      "learning_rate": 9.273779919179361e-06,
      "loss": 0.0438,
      "step": 1869
    },
    {
      "epoch": 0.14532172831830897,
      "grad_norm": 0.6941171884536743,
      "learning_rate": 9.273391358408456e-06,
      "loss": 1.0312,
      "step": 1870
    },
    {
      "epoch": 0.1453994404724899,
      "grad_norm": 0.4315735101699829,
      "learning_rate": 9.273002797637551e-06,
      "loss": 0.1931,
      "step": 1871
    },
    {
      "epoch": 0.14547715262667082,
      "grad_norm": 0.05800815299153328,
      "learning_rate": 9.272614236866646e-06,
      "loss": 0.0107,
      "step": 1872
    },
    {
      "epoch": 0.14555486478085172,
      "grad_norm": 0.3533397614955902,
      "learning_rate": 9.272225676095741e-06,
      "loss": 0.1553,
      "step": 1873
    },
    {
      "epoch": 0.14563257693503265,
      "grad_norm": 0.2591944634914398,
      "learning_rate": 9.271837115324838e-06,
      "loss": 0.248,
      "step": 1874
    },
    {
      "epoch": 0.14571028908921355,
      "grad_norm": 0.3755616843700409,
      "learning_rate": 9.271448554553933e-06,
      "loss": 0.2876,
      "step": 1875
    },
    {
      "epoch": 0.14578800124339447,
      "grad_norm": 0.2694198191165924,
      "learning_rate": 9.271059993783028e-06,
      "loss": 0.261,
      "step": 1876
    },
    {
      "epoch": 0.14586571339757537,
      "grad_norm": 0.29616275429725647,
      "learning_rate": 9.270671433012124e-06,
      "loss": 0.0592,
      "step": 1877
    },
    {
      "epoch": 0.1459434255517563,
      "grad_norm": 0.4011640250682831,
      "learning_rate": 9.27028287224122e-06,
      "loss": 0.4558,
      "step": 1878
    },
    {
      "epoch": 0.14602113770593722,
      "grad_norm": 0.19439558684825897,
      "learning_rate": 9.269894311470314e-06,
      "loss": 0.1668,
      "step": 1879
    },
    {
      "epoch": 0.14609884986011812,
      "grad_norm": 0.16178442537784576,
      "learning_rate": 9.26950575069941e-06,
      "loss": 0.2301,
      "step": 1880
    },
    {
      "epoch": 0.14617656201429904,
      "grad_norm": 0.07766834646463394,
      "learning_rate": 9.269117189928506e-06,
      "loss": 0.0273,
      "step": 1881
    },
    {
      "epoch": 0.14625427416847994,
      "grad_norm": 0.30750924348831177,
      "learning_rate": 9.268728629157601e-06,
      "loss": 0.1504,
      "step": 1882
    },
    {
      "epoch": 0.14633198632266087,
      "grad_norm": 0.25639602541923523,
      "learning_rate": 9.268340068386696e-06,
      "loss": 0.3769,
      "step": 1883
    },
    {
      "epoch": 0.14640969847684177,
      "grad_norm": 0.3501793444156647,
      "learning_rate": 9.267951507615793e-06,
      "loss": 0.0869,
      "step": 1884
    },
    {
      "epoch": 0.1464874106310227,
      "grad_norm": 0.13106469810009003,
      "learning_rate": 9.267562946844887e-06,
      "loss": 0.0551,
      "step": 1885
    },
    {
      "epoch": 0.14656512278520362,
      "grad_norm": 0.37336206436157227,
      "learning_rate": 9.267174386073982e-06,
      "loss": 0.2373,
      "step": 1886
    },
    {
      "epoch": 0.14664283493938451,
      "grad_norm": 0.3529277443885803,
      "learning_rate": 9.266785825303079e-06,
      "loss": 0.3799,
      "step": 1887
    },
    {
      "epoch": 0.14672054709356544,
      "grad_norm": 0.30495119094848633,
      "learning_rate": 9.266397264532172e-06,
      "loss": 0.2313,
      "step": 1888
    },
    {
      "epoch": 0.14679825924774634,
      "grad_norm": 0.36623483896255493,
      "learning_rate": 9.266008703761269e-06,
      "loss": 0.5066,
      "step": 1889
    },
    {
      "epoch": 0.14687597140192726,
      "grad_norm": 0.16965454816818237,
      "learning_rate": 9.265620142990364e-06,
      "loss": 0.1551,
      "step": 1890
    },
    {
      "epoch": 0.1469536835561082,
      "grad_norm": 0.3860786557197571,
      "learning_rate": 9.265231582219459e-06,
      "loss": 0.8387,
      "step": 1891
    },
    {
      "epoch": 0.1470313957102891,
      "grad_norm": 0.8293201327323914,
      "learning_rate": 9.264843021448556e-06,
      "loss": 0.3043,
      "step": 1892
    },
    {
      "epoch": 0.14710910786447,
      "grad_norm": 0.39933404326438904,
      "learning_rate": 9.26445446067765e-06,
      "loss": 0.7781,
      "step": 1893
    },
    {
      "epoch": 0.1471868200186509,
      "grad_norm": 0.6157564520835876,
      "learning_rate": 9.264065899906745e-06,
      "loss": 0.3405,
      "step": 1894
    },
    {
      "epoch": 0.14726453217283184,
      "grad_norm": 0.1961022913455963,
      "learning_rate": 9.263677339135842e-06,
      "loss": 0.1863,
      "step": 1895
    },
    {
      "epoch": 0.14734224432701273,
      "grad_norm": 0.3598031997680664,
      "learning_rate": 9.263288778364937e-06,
      "loss": 0.2583,
      "step": 1896
    },
    {
      "epoch": 0.14741995648119366,
      "grad_norm": 0.802949070930481,
      "learning_rate": 9.262900217594034e-06,
      "loss": 0.4752,
      "step": 1897
    },
    {
      "epoch": 0.14749766863537458,
      "grad_norm": 0.13168038427829742,
      "learning_rate": 9.262511656823127e-06,
      "loss": 0.1057,
      "step": 1898
    },
    {
      "epoch": 0.14757538078955548,
      "grad_norm": 0.21654751896858215,
      "learning_rate": 9.262123096052224e-06,
      "loss": 0.2312,
      "step": 1899
    },
    {
      "epoch": 0.1476530929437364,
      "grad_norm": 0.14425091445446014,
      "learning_rate": 9.261734535281318e-06,
      "loss": 0.0461,
      "step": 1900
    },
    {
      "epoch": 0.1477308050979173,
      "grad_norm": 0.29949939250946045,
      "learning_rate": 9.261345974510413e-06,
      "loss": 0.1759,
      "step": 1901
    },
    {
      "epoch": 0.14780851725209823,
      "grad_norm": 0.13137997686862946,
      "learning_rate": 9.26095741373951e-06,
      "loss": 0.0456,
      "step": 1902
    },
    {
      "epoch": 0.14788622940627913,
      "grad_norm": 0.08603712916374207,
      "learning_rate": 9.260568852968605e-06,
      "loss": 0.0275,
      "step": 1903
    },
    {
      "epoch": 0.14796394156046005,
      "grad_norm": 0.3684476912021637,
      "learning_rate": 9.2601802921977e-06,
      "loss": 0.1396,
      "step": 1904
    },
    {
      "epoch": 0.14804165371464098,
      "grad_norm": 0.44195473194122314,
      "learning_rate": 9.259791731426797e-06,
      "loss": 0.0932,
      "step": 1905
    },
    {
      "epoch": 0.14811936586882188,
      "grad_norm": 0.13824830949306488,
      "learning_rate": 9.259403170655892e-06,
      "loss": 0.0505,
      "step": 1906
    },
    {
      "epoch": 0.1481970780230028,
      "grad_norm": 0.16664499044418335,
      "learning_rate": 9.259014609884987e-06,
      "loss": 0.1242,
      "step": 1907
    },
    {
      "epoch": 0.1482747901771837,
      "grad_norm": 0.545044481754303,
      "learning_rate": 9.258626049114081e-06,
      "loss": 1.1666,
      "step": 1908
    },
    {
      "epoch": 0.14835250233136463,
      "grad_norm": 0.5355232954025269,
      "learning_rate": 9.258237488343178e-06,
      "loss": 0.0991,
      "step": 1909
    },
    {
      "epoch": 0.14843021448554555,
      "grad_norm": 0.3998416066169739,
      "learning_rate": 9.257848927572273e-06,
      "loss": 0.3936,
      "step": 1910
    },
    {
      "epoch": 0.14850792663972645,
      "grad_norm": 0.3446660041809082,
      "learning_rate": 9.257460366801368e-06,
      "loss": 0.2637,
      "step": 1911
    },
    {
      "epoch": 0.14858563879390738,
      "grad_norm": 0.3390500247478485,
      "learning_rate": 9.257071806030465e-06,
      "loss": 0.3148,
      "step": 1912
    },
    {
      "epoch": 0.14866335094808827,
      "grad_norm": 0.43450456857681274,
      "learning_rate": 9.25668324525956e-06,
      "loss": 0.4027,
      "step": 1913
    },
    {
      "epoch": 0.1487410631022692,
      "grad_norm": 0.34974732995033264,
      "learning_rate": 9.256294684488655e-06,
      "loss": 0.2705,
      "step": 1914
    },
    {
      "epoch": 0.1488187752564501,
      "grad_norm": 0.0892847403883934,
      "learning_rate": 9.255906123717751e-06,
      "loss": 0.0445,
      "step": 1915
    },
    {
      "epoch": 0.14889648741063102,
      "grad_norm": 0.19156399369239807,
      "learning_rate": 9.255517562946844e-06,
      "loss": 0.1418,
      "step": 1916
    },
    {
      "epoch": 0.14897419956481195,
      "grad_norm": 0.19393454492092133,
      "learning_rate": 9.255129002175941e-06,
      "loss": 0.1203,
      "step": 1917
    },
    {
      "epoch": 0.14905191171899285,
      "grad_norm": 0.20346124470233917,
      "learning_rate": 9.254740441405036e-06,
      "loss": 0.1418,
      "step": 1918
    },
    {
      "epoch": 0.14912962387317377,
      "grad_norm": 0.05731126293540001,
      "learning_rate": 9.254351880634131e-06,
      "loss": 0.0196,
      "step": 1919
    },
    {
      "epoch": 0.14920733602735467,
      "grad_norm": 0.4806930124759674,
      "learning_rate": 9.253963319863228e-06,
      "loss": 0.8047,
      "step": 1920
    },
    {
      "epoch": 0.1492850481815356,
      "grad_norm": 0.5761611461639404,
      "learning_rate": 9.253574759092323e-06,
      "loss": 0.5267,
      "step": 1921
    },
    {
      "epoch": 0.1493627603357165,
      "grad_norm": 0.5157683491706848,
      "learning_rate": 9.253186198321418e-06,
      "loss": 0.1962,
      "step": 1922
    },
    {
      "epoch": 0.14944047248989742,
      "grad_norm": 0.3241215944290161,
      "learning_rate": 9.252797637550514e-06,
      "loss": 0.2218,
      "step": 1923
    },
    {
      "epoch": 0.14951818464407834,
      "grad_norm": 0.2598632872104645,
      "learning_rate": 9.252409076779609e-06,
      "loss": 0.0989,
      "step": 1924
    },
    {
      "epoch": 0.14959589679825924,
      "grad_norm": 0.21452704071998596,
      "learning_rate": 9.252020516008704e-06,
      "loss": 0.0948,
      "step": 1925
    },
    {
      "epoch": 0.14967360895244017,
      "grad_norm": 0.9965200424194336,
      "learning_rate": 9.251631955237799e-06,
      "loss": 0.2863,
      "step": 1926
    },
    {
      "epoch": 0.14975132110662107,
      "grad_norm": 0.3266140818595886,
      "learning_rate": 9.251243394466896e-06,
      "loss": 0.3566,
      "step": 1927
    },
    {
      "epoch": 0.149829033260802,
      "grad_norm": 0.527350127696991,
      "learning_rate": 9.25085483369599e-06,
      "loss": 0.171,
      "step": 1928
    },
    {
      "epoch": 0.14990674541498292,
      "grad_norm": 0.3713836669921875,
      "learning_rate": 9.250466272925086e-06,
      "loss": 0.2551,
      "step": 1929
    },
    {
      "epoch": 0.14998445756916381,
      "grad_norm": 0.10647927969694138,
      "learning_rate": 9.250077712154182e-06,
      "loss": 0.1221,
      "step": 1930
    },
    {
      "epoch": 0.15006216972334474,
      "grad_norm": 0.24863849580287933,
      "learning_rate": 9.249689151383277e-06,
      "loss": 0.1845,
      "step": 1931
    },
    {
      "epoch": 0.15013988187752564,
      "grad_norm": 0.6719349026679993,
      "learning_rate": 9.249300590612372e-06,
      "loss": 0.7605,
      "step": 1932
    },
    {
      "epoch": 0.15021759403170656,
      "grad_norm": 0.3245203495025635,
      "learning_rate": 9.248912029841469e-06,
      "loss": 0.2057,
      "step": 1933
    },
    {
      "epoch": 0.15029530618588746,
      "grad_norm": 0.25649482011795044,
      "learning_rate": 9.248523469070564e-06,
      "loss": 0.2082,
      "step": 1934
    },
    {
      "epoch": 0.1503730183400684,
      "grad_norm": 0.37001606822013855,
      "learning_rate": 9.248134908299659e-06,
      "loss": 0.2015,
      "step": 1935
    },
    {
      "epoch": 0.1504507304942493,
      "grad_norm": 0.5239736437797546,
      "learning_rate": 9.247746347528754e-06,
      "loss": 0.5342,
      "step": 1936
    },
    {
      "epoch": 0.1505284426484302,
      "grad_norm": 0.2952885925769806,
      "learning_rate": 9.24735778675785e-06,
      "loss": 0.2403,
      "step": 1937
    },
    {
      "epoch": 0.15060615480261114,
      "grad_norm": 0.6196228861808777,
      "learning_rate": 9.246969225986945e-06,
      "loss": 0.6437,
      "step": 1938
    },
    {
      "epoch": 0.15068386695679203,
      "grad_norm": 0.37366724014282227,
      "learning_rate": 9.24658066521604e-06,
      "loss": 0.2164,
      "step": 1939
    },
    {
      "epoch": 0.15076157911097296,
      "grad_norm": 0.7039561867713928,
      "learning_rate": 9.246192104445137e-06,
      "loss": 1.0001,
      "step": 1940
    },
    {
      "epoch": 0.15083929126515386,
      "grad_norm": 0.12631061673164368,
      "learning_rate": 9.245803543674232e-06,
      "loss": 0.1478,
      "step": 1941
    },
    {
      "epoch": 0.15091700341933478,
      "grad_norm": 0.10630081593990326,
      "learning_rate": 9.245414982903327e-06,
      "loss": 0.0233,
      "step": 1942
    },
    {
      "epoch": 0.1509947155735157,
      "grad_norm": 0.6990630030632019,
      "learning_rate": 9.245026422132423e-06,
      "loss": 0.4099,
      "step": 1943
    },
    {
      "epoch": 0.1510724277276966,
      "grad_norm": 0.08778059482574463,
      "learning_rate": 9.244637861361517e-06,
      "loss": 0.0443,
      "step": 1944
    },
    {
      "epoch": 0.15115013988187753,
      "grad_norm": 0.05839471146464348,
      "learning_rate": 9.244249300590613e-06,
      "loss": 0.0152,
      "step": 1945
    },
    {
      "epoch": 0.15122785203605843,
      "grad_norm": 0.20738165080547333,
      "learning_rate": 9.243860739819708e-06,
      "loss": 0.1809,
      "step": 1946
    },
    {
      "epoch": 0.15130556419023936,
      "grad_norm": 0.21624387800693512,
      "learning_rate": 9.243472179048803e-06,
      "loss": 0.1462,
      "step": 1947
    },
    {
      "epoch": 0.15138327634442028,
      "grad_norm": 0.26570791006088257,
      "learning_rate": 9.2430836182779e-06,
      "loss": 0.4379,
      "step": 1948
    },
    {
      "epoch": 0.15146098849860118,
      "grad_norm": 0.2594716548919678,
      "learning_rate": 9.242695057506995e-06,
      "loss": 0.1527,
      "step": 1949
    },
    {
      "epoch": 0.1515387006527821,
      "grad_norm": 0.20613862574100494,
      "learning_rate": 9.24230649673609e-06,
      "loss": 0.1908,
      "step": 1950
    },
    {
      "epoch": 0.151616412806963,
      "grad_norm": 0.30247852206230164,
      "learning_rate": 9.241917935965186e-06,
      "loss": 0.2336,
      "step": 1951
    },
    {
      "epoch": 0.15169412496114393,
      "grad_norm": 0.2743975520133972,
      "learning_rate": 9.241529375194281e-06,
      "loss": 0.2958,
      "step": 1952
    },
    {
      "epoch": 0.15177183711532483,
      "grad_norm": 0.17903465032577515,
      "learning_rate": 9.241140814423376e-06,
      "loss": 0.1818,
      "step": 1953
    },
    {
      "epoch": 0.15184954926950575,
      "grad_norm": 0.19391697645187378,
      "learning_rate": 9.240752253652471e-06,
      "loss": 0.0942,
      "step": 1954
    },
    {
      "epoch": 0.15192726142368668,
      "grad_norm": 0.6943462491035461,
      "learning_rate": 9.240363692881568e-06,
      "loss": 0.5774,
      "step": 1955
    },
    {
      "epoch": 0.15200497357786757,
      "grad_norm": 0.225960835814476,
      "learning_rate": 9.239975132110663e-06,
      "loss": 0.0894,
      "step": 1956
    },
    {
      "epoch": 0.1520826857320485,
      "grad_norm": 0.21708732843399048,
      "learning_rate": 9.239586571339758e-06,
      "loss": 0.1716,
      "step": 1957
    },
    {
      "epoch": 0.1521603978862294,
      "grad_norm": 0.2529194951057434,
      "learning_rate": 9.239198010568854e-06,
      "loss": 0.075,
      "step": 1958
    },
    {
      "epoch": 0.15223811004041032,
      "grad_norm": 0.28446903824806213,
      "learning_rate": 9.23880944979795e-06,
      "loss": 0.3616,
      "step": 1959
    },
    {
      "epoch": 0.15231582219459122,
      "grad_norm": 0.1263846606016159,
      "learning_rate": 9.238420889027044e-06,
      "loss": 0.0339,
      "step": 1960
    },
    {
      "epoch": 0.15239353434877215,
      "grad_norm": 0.07685798406600952,
      "learning_rate": 9.238032328256141e-06,
      "loss": 0.005,
      "step": 1961
    },
    {
      "epoch": 0.15247124650295307,
      "grad_norm": 0.10128019750118256,
      "learning_rate": 9.237643767485236e-06,
      "loss": 0.0199,
      "step": 1962
    },
    {
      "epoch": 0.15254895865713397,
      "grad_norm": 0.3527381420135498,
      "learning_rate": 9.23725520671433e-06,
      "loss": 0.2401,
      "step": 1963
    },
    {
      "epoch": 0.1526266708113149,
      "grad_norm": 0.14026929438114166,
      "learning_rate": 9.236866645943426e-06,
      "loss": 0.0996,
      "step": 1964
    },
    {
      "epoch": 0.1527043829654958,
      "grad_norm": 0.3877023160457611,
      "learning_rate": 9.236478085172522e-06,
      "loss": 0.1609,
      "step": 1965
    },
    {
      "epoch": 0.15278209511967672,
      "grad_norm": 0.7001241445541382,
      "learning_rate": 9.236089524401617e-06,
      "loss": 0.767,
      "step": 1966
    },
    {
      "epoch": 0.15285980727385762,
      "grad_norm": 0.15777195990085602,
      "learning_rate": 9.235700963630712e-06,
      "loss": 0.0564,
      "step": 1967
    },
    {
      "epoch": 0.15293751942803854,
      "grad_norm": 0.39588770270347595,
      "learning_rate": 9.235312402859809e-06,
      "loss": 0.2422,
      "step": 1968
    },
    {
      "epoch": 0.15301523158221947,
      "grad_norm": 0.1712643802165985,
      "learning_rate": 9.234923842088904e-06,
      "loss": 0.0523,
      "step": 1969
    },
    {
      "epoch": 0.15309294373640037,
      "grad_norm": 0.28310689330101013,
      "learning_rate": 9.234535281317999e-06,
      "loss": 0.1861,
      "step": 1970
    },
    {
      "epoch": 0.1531706558905813,
      "grad_norm": 0.1933714896440506,
      "learning_rate": 9.234146720547096e-06,
      "loss": 0.0799,
      "step": 1971
    },
    {
      "epoch": 0.1532483680447622,
      "grad_norm": 0.2632824778556824,
      "learning_rate": 9.233758159776189e-06,
      "loss": 0.0566,
      "step": 1972
    },
    {
      "epoch": 0.15332608019894312,
      "grad_norm": 0.32546958327293396,
      "learning_rate": 9.233369599005285e-06,
      "loss": 0.5344,
      "step": 1973
    },
    {
      "epoch": 0.15340379235312404,
      "grad_norm": 0.26643410325050354,
      "learning_rate": 9.23298103823438e-06,
      "loss": 0.1593,
      "step": 1974
    },
    {
      "epoch": 0.15348150450730494,
      "grad_norm": 0.3627137839794159,
      "learning_rate": 9.232592477463475e-06,
      "loss": 0.1765,
      "step": 1975
    },
    {
      "epoch": 0.15355921666148586,
      "grad_norm": 0.08382415771484375,
      "learning_rate": 9.232203916692572e-06,
      "loss": 0.0286,
      "step": 1976
    },
    {
      "epoch": 0.15363692881566676,
      "grad_norm": 0.4682539105415344,
      "learning_rate": 9.231815355921667e-06,
      "loss": 0.2166,
      "step": 1977
    },
    {
      "epoch": 0.1537146409698477,
      "grad_norm": 0.5866514444351196,
      "learning_rate": 9.231426795150762e-06,
      "loss": 0.2939,
      "step": 1978
    },
    {
      "epoch": 0.15379235312402859,
      "grad_norm": 0.2045735865831375,
      "learning_rate": 9.231038234379858e-06,
      "loss": 0.0424,
      "step": 1979
    },
    {
      "epoch": 0.1538700652782095,
      "grad_norm": 0.1458835005760193,
      "learning_rate": 9.230649673608953e-06,
      "loss": 0.0719,
      "step": 1980
    },
    {
      "epoch": 0.15394777743239044,
      "grad_norm": 0.42883461713790894,
      "learning_rate": 9.230261112838048e-06,
      "loss": 0.4383,
      "step": 1981
    },
    {
      "epoch": 0.15402548958657133,
      "grad_norm": 0.32868796586990356,
      "learning_rate": 9.229872552067143e-06,
      "loss": 0.2679,
      "step": 1982
    },
    {
      "epoch": 0.15410320174075226,
      "grad_norm": 0.6589144468307495,
      "learning_rate": 9.22948399129624e-06,
      "loss": 0.2518,
      "step": 1983
    },
    {
      "epoch": 0.15418091389493316,
      "grad_norm": 0.33245861530303955,
      "learning_rate": 9.229095430525335e-06,
      "loss": 0.4711,
      "step": 1984
    },
    {
      "epoch": 0.15425862604911408,
      "grad_norm": 0.15101425349712372,
      "learning_rate": 9.22870686975443e-06,
      "loss": 0.0848,
      "step": 1985
    },
    {
      "epoch": 0.15433633820329498,
      "grad_norm": 0.3168770968914032,
      "learning_rate": 9.228318308983527e-06,
      "loss": 0.3301,
      "step": 1986
    },
    {
      "epoch": 0.1544140503574759,
      "grad_norm": 0.057307928800582886,
      "learning_rate": 9.227929748212621e-06,
      "loss": 0.014,
      "step": 1987
    },
    {
      "epoch": 0.15449176251165683,
      "grad_norm": 0.2870592772960663,
      "learning_rate": 9.227541187441716e-06,
      "loss": 0.0814,
      "step": 1988
    },
    {
      "epoch": 0.15456947466583773,
      "grad_norm": 0.09026439487934113,
      "learning_rate": 9.227152626670813e-06,
      "loss": 0.0585,
      "step": 1989
    },
    {
      "epoch": 0.15464718682001866,
      "grad_norm": 0.36743229627609253,
      "learning_rate": 9.226764065899908e-06,
      "loss": 0.299,
      "step": 1990
    },
    {
      "epoch": 0.15472489897419955,
      "grad_norm": 0.17502357065677643,
      "learning_rate": 9.226375505129003e-06,
      "loss": 0.1218,
      "step": 1991
    },
    {
      "epoch": 0.15480261112838048,
      "grad_norm": 0.08358846604824066,
      "learning_rate": 9.225986944358098e-06,
      "loss": 0.0377,
      "step": 1992
    },
    {
      "epoch": 0.1548803232825614,
      "grad_norm": 0.33839625120162964,
      "learning_rate": 9.225598383587195e-06,
      "loss": 0.1936,
      "step": 1993
    },
    {
      "epoch": 0.1549580354367423,
      "grad_norm": 0.2251719832420349,
      "learning_rate": 9.22520982281629e-06,
      "loss": 0.6764,
      "step": 1994
    },
    {
      "epoch": 0.15503574759092323,
      "grad_norm": 0.5197272300720215,
      "learning_rate": 9.224821262045384e-06,
      "loss": 0.1506,
      "step": 1995
    },
    {
      "epoch": 0.15511345974510413,
      "grad_norm": 0.25584548711776733,
      "learning_rate": 9.224432701274481e-06,
      "loss": 0.1354,
      "step": 1996
    },
    {
      "epoch": 0.15519117189928505,
      "grad_norm": 0.3556699752807617,
      "learning_rate": 9.224044140503576e-06,
      "loss": 0.1484,
      "step": 1997
    },
    {
      "epoch": 0.15526888405346595,
      "grad_norm": 0.26634499430656433,
      "learning_rate": 9.223655579732671e-06,
      "loss": 0.1952,
      "step": 1998
    },
    {
      "epoch": 0.15534659620764688,
      "grad_norm": 0.26759660243988037,
      "learning_rate": 9.223267018961766e-06,
      "loss": 0.1738,
      "step": 1999
    },
    {
      "epoch": 0.1554243083618278,
      "grad_norm": 0.4923156797885895,
      "learning_rate": 9.222878458190861e-06,
      "loss": 0.2807,
      "step": 2000
    },
    {
      "epoch": 0.1555020205160087,
      "grad_norm": 0.07906440645456314,
      "learning_rate": 9.222489897419958e-06,
      "loss": 0.0392,
      "step": 2001
    },
    {
      "epoch": 0.15557973267018962,
      "grad_norm": 0.13405665755271912,
      "learning_rate": 9.222101336649052e-06,
      "loss": 0.0676,
      "step": 2002
    },
    {
      "epoch": 0.15565744482437052,
      "grad_norm": 0.15917524695396423,
      "learning_rate": 9.221712775878147e-06,
      "loss": 0.114,
      "step": 2003
    },
    {
      "epoch": 0.15573515697855145,
      "grad_norm": 0.4003926217556,
      "learning_rate": 9.221324215107244e-06,
      "loss": 0.4025,
      "step": 2004
    },
    {
      "epoch": 0.15581286913273235,
      "grad_norm": 0.13268497586250305,
      "learning_rate": 9.220935654336339e-06,
      "loss": 0.0751,
      "step": 2005
    },
    {
      "epoch": 0.15589058128691327,
      "grad_norm": 0.21329855918884277,
      "learning_rate": 9.220547093565434e-06,
      "loss": 0.1783,
      "step": 2006
    },
    {
      "epoch": 0.1559682934410942,
      "grad_norm": 0.24192549288272858,
      "learning_rate": 9.220158532794529e-06,
      "loss": 0.1332,
      "step": 2007
    },
    {
      "epoch": 0.1560460055952751,
      "grad_norm": 0.2421988844871521,
      "learning_rate": 9.219769972023626e-06,
      "loss": 0.2685,
      "step": 2008
    },
    {
      "epoch": 0.15612371774945602,
      "grad_norm": 0.6063023209571838,
      "learning_rate": 9.21938141125272e-06,
      "loss": 0.7808,
      "step": 2009
    },
    {
      "epoch": 0.15620142990363692,
      "grad_norm": 0.2538151741027832,
      "learning_rate": 9.218992850481815e-06,
      "loss": 0.1447,
      "step": 2010
    },
    {
      "epoch": 0.15627914205781784,
      "grad_norm": 0.3923315107822418,
      "learning_rate": 9.218604289710912e-06,
      "loss": 0.1728,
      "step": 2011
    },
    {
      "epoch": 0.15635685421199877,
      "grad_norm": 0.11264669895172119,
      "learning_rate": 9.218215728940007e-06,
      "loss": 0.0565,
      "step": 2012
    },
    {
      "epoch": 0.15643456636617967,
      "grad_norm": 0.3336503207683563,
      "learning_rate": 9.217827168169102e-06,
      "loss": 0.1741,
      "step": 2013
    },
    {
      "epoch": 0.1565122785203606,
      "grad_norm": 0.7896547317504883,
      "learning_rate": 9.217438607398199e-06,
      "loss": 0.4572,
      "step": 2014
    },
    {
      "epoch": 0.1565899906745415,
      "grad_norm": 0.1350819319486618,
      "learning_rate": 9.217050046627292e-06,
      "loss": 0.0475,
      "step": 2015
    },
    {
      "epoch": 0.15666770282872242,
      "grad_norm": 0.2955266237258911,
      "learning_rate": 9.216661485856389e-06,
      "loss": 0.1255,
      "step": 2016
    },
    {
      "epoch": 0.1567454149829033,
      "grad_norm": 0.07099664211273193,
      "learning_rate": 9.216272925085484e-06,
      "loss": 0.0439,
      "step": 2017
    },
    {
      "epoch": 0.15682312713708424,
      "grad_norm": 0.41018110513687134,
      "learning_rate": 9.215884364314578e-06,
      "loss": 0.2397,
      "step": 2018
    },
    {
      "epoch": 0.15690083929126517,
      "grad_norm": 0.3917129337787628,
      "learning_rate": 9.215495803543675e-06,
      "loss": 0.2755,
      "step": 2019
    },
    {
      "epoch": 0.15697855144544606,
      "grad_norm": 0.4143964350223541,
      "learning_rate": 9.21510724277277e-06,
      "loss": 0.2261,
      "step": 2020
    },
    {
      "epoch": 0.157056263599627,
      "grad_norm": 0.1386731117963791,
      "learning_rate": 9.214718682001867e-06,
      "loss": 0.1068,
      "step": 2021
    },
    {
      "epoch": 0.1571339757538079,
      "grad_norm": 0.6747106909751892,
      "learning_rate": 9.214330121230962e-06,
      "loss": 0.3314,
      "step": 2022
    },
    {
      "epoch": 0.1572116879079888,
      "grad_norm": 0.11966875195503235,
      "learning_rate": 9.213941560460057e-06,
      "loss": 0.1157,
      "step": 2023
    },
    {
      "epoch": 0.1572894000621697,
      "grad_norm": 0.22504638135433197,
      "learning_rate": 9.213552999689153e-06,
      "loss": 0.4074,
      "step": 2024
    },
    {
      "epoch": 0.15736711221635064,
      "grad_norm": 0.12120970338582993,
      "learning_rate": 9.213164438918247e-06,
      "loss": 0.0238,
      "step": 2025
    },
    {
      "epoch": 0.15744482437053156,
      "grad_norm": 0.06428063660860062,
      "learning_rate": 9.212775878147343e-06,
      "loss": 0.0245,
      "step": 2026
    },
    {
      "epoch": 0.15752253652471246,
      "grad_norm": 0.2643944323062897,
      "learning_rate": 9.212387317376438e-06,
      "loss": 0.0892,
      "step": 2027
    },
    {
      "epoch": 0.15760024867889338,
      "grad_norm": 0.1462552696466446,
      "learning_rate": 9.211998756605533e-06,
      "loss": 0.1513,
      "step": 2028
    },
    {
      "epoch": 0.15767796083307428,
      "grad_norm": 0.43322256207466125,
      "learning_rate": 9.21161019583463e-06,
      "loss": 0.4647,
      "step": 2029
    },
    {
      "epoch": 0.1577556729872552,
      "grad_norm": 0.4538256525993347,
      "learning_rate": 9.211221635063725e-06,
      "loss": 0.2202,
      "step": 2030
    },
    {
      "epoch": 0.15783338514143613,
      "grad_norm": 0.30998608469963074,
      "learning_rate": 9.21083307429282e-06,
      "loss": 0.1608,
      "step": 2031
    },
    {
      "epoch": 0.15791109729561703,
      "grad_norm": 0.3040706217288971,
      "learning_rate": 9.210444513521916e-06,
      "loss": 0.2357,
      "step": 2032
    },
    {
      "epoch": 0.15798880944979796,
      "grad_norm": 0.13226783275604248,
      "learning_rate": 9.210055952751011e-06,
      "loss": 0.0496,
      "step": 2033
    },
    {
      "epoch": 0.15806652160397885,
      "grad_norm": 0.33247387409210205,
      "learning_rate": 9.209667391980106e-06,
      "loss": 0.072,
      "step": 2034
    },
    {
      "epoch": 0.15814423375815978,
      "grad_norm": 0.328368216753006,
      "learning_rate": 9.209278831209201e-06,
      "loss": 0.1575,
      "step": 2035
    },
    {
      "epoch": 0.15822194591234068,
      "grad_norm": 0.08742867410182953,
      "learning_rate": 9.208890270438298e-06,
      "loss": 0.0367,
      "step": 2036
    },
    {
      "epoch": 0.1582996580665216,
      "grad_norm": 0.44257116317749023,
      "learning_rate": 9.208501709667393e-06,
      "loss": 0.2946,
      "step": 2037
    },
    {
      "epoch": 0.15837737022070253,
      "grad_norm": 0.10075780749320984,
      "learning_rate": 9.208113148896488e-06,
      "loss": 0.0265,
      "step": 2038
    },
    {
      "epoch": 0.15845508237488343,
      "grad_norm": 0.5274208188056946,
      "learning_rate": 9.207724588125584e-06,
      "loss": 0.1194,
      "step": 2039
    },
    {
      "epoch": 0.15853279452906435,
      "grad_norm": 0.44240379333496094,
      "learning_rate": 9.20733602735468e-06,
      "loss": 0.2108,
      "step": 2040
    },
    {
      "epoch": 0.15861050668324525,
      "grad_norm": 0.18733395636081696,
      "learning_rate": 9.206947466583774e-06,
      "loss": 0.1167,
      "step": 2041
    },
    {
      "epoch": 0.15868821883742618,
      "grad_norm": 0.5801123380661011,
      "learning_rate": 9.20655890581287e-06,
      "loss": 0.9687,
      "step": 2042
    },
    {
      "epoch": 0.15876593099160707,
      "grad_norm": 0.13070477545261383,
      "learning_rate": 9.206170345041964e-06,
      "loss": 0.0325,
      "step": 2043
    },
    {
      "epoch": 0.158843643145788,
      "grad_norm": 0.10882484167814255,
      "learning_rate": 9.20578178427106e-06,
      "loss": 0.035,
      "step": 2044
    },
    {
      "epoch": 0.15892135529996892,
      "grad_norm": 0.658626914024353,
      "learning_rate": 9.205393223500156e-06,
      "loss": 0.4214,
      "step": 2045
    },
    {
      "epoch": 0.15899906745414982,
      "grad_norm": 0.19230493903160095,
      "learning_rate": 9.20500466272925e-06,
      "loss": 0.1081,
      "step": 2046
    },
    {
      "epoch": 0.15907677960833075,
      "grad_norm": 0.13924294710159302,
      "learning_rate": 9.204616101958347e-06,
      "loss": 0.1421,
      "step": 2047
    },
    {
      "epoch": 0.15915449176251165,
      "grad_norm": 0.43919384479522705,
      "learning_rate": 9.204227541187442e-06,
      "loss": 0.1692,
      "step": 2048
    },
    {
      "epoch": 0.15923220391669257,
      "grad_norm": 0.1829465627670288,
      "learning_rate": 9.203838980416539e-06,
      "loss": 0.1884,
      "step": 2049
    },
    {
      "epoch": 0.1593099160708735,
      "grad_norm": 0.3891359269618988,
      "learning_rate": 9.203450419645634e-06,
      "loss": 0.2884,
      "step": 2050
    },
    {
      "epoch": 0.1593876282250544,
      "grad_norm": 0.14638668298721313,
      "learning_rate": 9.203061858874729e-06,
      "loss": 0.1732,
      "step": 2051
    },
    {
      "epoch": 0.15946534037923532,
      "grad_norm": 0.3325358033180237,
      "learning_rate": 9.202673298103825e-06,
      "loss": 0.0723,
      "step": 2052
    },
    {
      "epoch": 0.15954305253341622,
      "grad_norm": 0.04656749218702316,
      "learning_rate": 9.202284737332919e-06,
      "loss": 0.0082,
      "step": 2053
    },
    {
      "epoch": 0.15962076468759714,
      "grad_norm": 0.27090516686439514,
      "learning_rate": 9.201896176562015e-06,
      "loss": 0.1168,
      "step": 2054
    },
    {
      "epoch": 0.15969847684177804,
      "grad_norm": 0.34614914655685425,
      "learning_rate": 9.20150761579111e-06,
      "loss": 0.5334,
      "step": 2055
    },
    {
      "epoch": 0.15977618899595897,
      "grad_norm": 0.5164764523506165,
      "learning_rate": 9.201119055020205e-06,
      "loss": 0.0414,
      "step": 2056
    },
    {
      "epoch": 0.1598539011501399,
      "grad_norm": 0.19443681836128235,
      "learning_rate": 9.200730494249302e-06,
      "loss": 0.0813,
      "step": 2057
    },
    {
      "epoch": 0.1599316133043208,
      "grad_norm": 0.38757115602493286,
      "learning_rate": 9.200341933478397e-06,
      "loss": 0.3187,
      "step": 2058
    },
    {
      "epoch": 0.16000932545850172,
      "grad_norm": 0.6869766116142273,
      "learning_rate": 9.199953372707492e-06,
      "loss": 0.4411,
      "step": 2059
    },
    {
      "epoch": 0.16008703761268261,
      "grad_norm": 0.16411060094833374,
      "learning_rate": 9.199564811936588e-06,
      "loss": 0.0456,
      "step": 2060
    },
    {
      "epoch": 0.16016474976686354,
      "grad_norm": 0.39594027400016785,
      "learning_rate": 9.199176251165683e-06,
      "loss": 0.3579,
      "step": 2061
    },
    {
      "epoch": 0.16024246192104444,
      "grad_norm": 0.16575533151626587,
      "learning_rate": 9.198787690394778e-06,
      "loss": 0.0695,
      "step": 2062
    },
    {
      "epoch": 0.16032017407522536,
      "grad_norm": 0.2979429066181183,
      "learning_rate": 9.198399129623873e-06,
      "loss": 0.5042,
      "step": 2063
    },
    {
      "epoch": 0.1603978862294063,
      "grad_norm": 0.22579054534435272,
      "learning_rate": 9.19801056885297e-06,
      "loss": 0.2865,
      "step": 2064
    },
    {
      "epoch": 0.1604755983835872,
      "grad_norm": 0.174417182803154,
      "learning_rate": 9.197622008082065e-06,
      "loss": 0.0637,
      "step": 2065
    },
    {
      "epoch": 0.1605533105377681,
      "grad_norm": 0.06111652031540871,
      "learning_rate": 9.19723344731116e-06,
      "loss": 0.0155,
      "step": 2066
    },
    {
      "epoch": 0.160631022691949,
      "grad_norm": 0.15059739351272583,
      "learning_rate": 9.196844886540256e-06,
      "loss": 0.0441,
      "step": 2067
    },
    {
      "epoch": 0.16070873484612994,
      "grad_norm": 0.3670250475406647,
      "learning_rate": 9.196456325769351e-06,
      "loss": 0.253,
      "step": 2068
    },
    {
      "epoch": 0.16078644700031086,
      "grad_norm": 0.5407605767250061,
      "learning_rate": 9.196067764998446e-06,
      "loss": 0.4289,
      "step": 2069
    },
    {
      "epoch": 0.16086415915449176,
      "grad_norm": 0.12784071266651154,
      "learning_rate": 9.195679204227543e-06,
      "loss": 0.0568,
      "step": 2070
    },
    {
      "epoch": 0.16094187130867268,
      "grad_norm": 0.2623061239719391,
      "learning_rate": 9.195290643456636e-06,
      "loss": 0.2617,
      "step": 2071
    },
    {
      "epoch": 0.16101958346285358,
      "grad_norm": 0.34213200211524963,
      "learning_rate": 9.194902082685733e-06,
      "loss": 0.4555,
      "step": 2072
    },
    {
      "epoch": 0.1610972956170345,
      "grad_norm": 0.6530295610427856,
      "learning_rate": 9.194513521914828e-06,
      "loss": 0.3084,
      "step": 2073
    },
    {
      "epoch": 0.1611750077712154,
      "grad_norm": 0.11537936329841614,
      "learning_rate": 9.194124961143923e-06,
      "loss": 0.0206,
      "step": 2074
    },
    {
      "epoch": 0.16125271992539633,
      "grad_norm": 0.2802378237247467,
      "learning_rate": 9.19373640037302e-06,
      "loss": 0.2989,
      "step": 2075
    },
    {
      "epoch": 0.16133043207957726,
      "grad_norm": 0.1449621021747589,
      "learning_rate": 9.193347839602114e-06,
      "loss": 0.0667,
      "step": 2076
    },
    {
      "epoch": 0.16140814423375816,
      "grad_norm": 0.8733662366867065,
      "learning_rate": 9.19295927883121e-06,
      "loss": 0.5608,
      "step": 2077
    },
    {
      "epoch": 0.16148585638793908,
      "grad_norm": 0.0773952305316925,
      "learning_rate": 9.192570718060306e-06,
      "loss": 0.0365,
      "step": 2078
    },
    {
      "epoch": 0.16156356854211998,
      "grad_norm": 0.13500645756721497,
      "learning_rate": 9.192182157289401e-06,
      "loss": 0.0506,
      "step": 2079
    },
    {
      "epoch": 0.1616412806963009,
      "grad_norm": 0.10193324834108353,
      "learning_rate": 9.191793596518498e-06,
      "loss": 0.0877,
      "step": 2080
    },
    {
      "epoch": 0.1617189928504818,
      "grad_norm": 0.31231433153152466,
      "learning_rate": 9.19140503574759e-06,
      "loss": 0.3475,
      "step": 2081
    },
    {
      "epoch": 0.16179670500466273,
      "grad_norm": 0.4420921206474304,
      "learning_rate": 9.191016474976687e-06,
      "loss": 0.3884,
      "step": 2082
    },
    {
      "epoch": 0.16187441715884365,
      "grad_norm": 0.3010358214378357,
      "learning_rate": 9.190627914205782e-06,
      "loss": 0.1393,
      "step": 2083
    },
    {
      "epoch": 0.16195212931302455,
      "grad_norm": 0.2511402368545532,
      "learning_rate": 9.190239353434877e-06,
      "loss": 0.0997,
      "step": 2084
    },
    {
      "epoch": 0.16202984146720548,
      "grad_norm": 0.30329978466033936,
      "learning_rate": 9.189850792663974e-06,
      "loss": 0.2805,
      "step": 2085
    },
    {
      "epoch": 0.16210755362138637,
      "grad_norm": 0.2377777248620987,
      "learning_rate": 9.189462231893069e-06,
      "loss": 0.0646,
      "step": 2086
    },
    {
      "epoch": 0.1621852657755673,
      "grad_norm": 0.06893476843833923,
      "learning_rate": 9.189073671122164e-06,
      "loss": 0.0395,
      "step": 2087
    },
    {
      "epoch": 0.16226297792974823,
      "grad_norm": 0.2587464153766632,
      "learning_rate": 9.18868511035126e-06,
      "loss": 0.1993,
      "step": 2088
    },
    {
      "epoch": 0.16234069008392912,
      "grad_norm": 0.6099798083305359,
      "learning_rate": 9.188296549580355e-06,
      "loss": 0.4947,
      "step": 2089
    },
    {
      "epoch": 0.16241840223811005,
      "grad_norm": 0.18607103824615479,
      "learning_rate": 9.18790798880945e-06,
      "loss": 0.0741,
      "step": 2090
    },
    {
      "epoch": 0.16249611439229095,
      "grad_norm": 0.27001625299453735,
      "learning_rate": 9.187519428038545e-06,
      "loss": 0.1529,
      "step": 2091
    },
    {
      "epoch": 0.16257382654647187,
      "grad_norm": 0.40133264660835266,
      "learning_rate": 9.187130867267642e-06,
      "loss": 0.2783,
      "step": 2092
    },
    {
      "epoch": 0.16265153870065277,
      "grad_norm": 0.7683300375938416,
      "learning_rate": 9.186742306496737e-06,
      "loss": 0.154,
      "step": 2093
    },
    {
      "epoch": 0.1627292508548337,
      "grad_norm": 0.32137030363082886,
      "learning_rate": 9.186353745725832e-06,
      "loss": 0.0679,
      "step": 2094
    },
    {
      "epoch": 0.16280696300901462,
      "grad_norm": 0.18042363226413727,
      "learning_rate": 9.185965184954929e-06,
      "loss": 0.1954,
      "step": 2095
    },
    {
      "epoch": 0.16288467516319552,
      "grad_norm": 0.21101854741573334,
      "learning_rate": 9.185576624184024e-06,
      "loss": 0.2265,
      "step": 2096
    },
    {
      "epoch": 0.16296238731737644,
      "grad_norm": 0.3579043447971344,
      "learning_rate": 9.185188063413118e-06,
      "loss": 0.2282,
      "step": 2097
    },
    {
      "epoch": 0.16304009947155734,
      "grad_norm": 0.5978263020515442,
      "learning_rate": 9.184799502642215e-06,
      "loss": 0.2477,
      "step": 2098
    },
    {
      "epoch": 0.16311781162573827,
      "grad_norm": 0.33687469363212585,
      "learning_rate": 9.184410941871308e-06,
      "loss": 0.1697,
      "step": 2099
    },
    {
      "epoch": 0.16319552377991917,
      "grad_norm": 0.1429223120212555,
      "learning_rate": 9.184022381100405e-06,
      "loss": 0.0623,
      "step": 2100
    },
    {
      "epoch": 0.1632732359341001,
      "grad_norm": 0.10370903462171555,
      "learning_rate": 9.1836338203295e-06,
      "loss": 0.0548,
      "step": 2101
    },
    {
      "epoch": 0.16335094808828102,
      "grad_norm": 0.19992581009864807,
      "learning_rate": 9.183245259558595e-06,
      "loss": 0.1047,
      "step": 2102
    },
    {
      "epoch": 0.16342866024246192,
      "grad_norm": 0.3773916959762573,
      "learning_rate": 9.182856698787692e-06,
      "loss": 0.2712,
      "step": 2103
    },
    {
      "epoch": 0.16350637239664284,
      "grad_norm": 0.2984198033809662,
      "learning_rate": 9.182468138016787e-06,
      "loss": 0.1206,
      "step": 2104
    },
    {
      "epoch": 0.16358408455082374,
      "grad_norm": 0.31728747487068176,
      "learning_rate": 9.182079577245881e-06,
      "loss": 0.2188,
      "step": 2105
    },
    {
      "epoch": 0.16366179670500466,
      "grad_norm": 0.8310748338699341,
      "learning_rate": 9.181691016474978e-06,
      "loss": 0.357,
      "step": 2106
    },
    {
      "epoch": 0.1637395088591856,
      "grad_norm": 0.21675226092338562,
      "learning_rate": 9.181302455704073e-06,
      "loss": 0.1979,
      "step": 2107
    },
    {
      "epoch": 0.1638172210133665,
      "grad_norm": 0.36951136589050293,
      "learning_rate": 9.180913894933168e-06,
      "loss": 0.5496,
      "step": 2108
    },
    {
      "epoch": 0.1638949331675474,
      "grad_norm": 0.1572885513305664,
      "learning_rate": 9.180525334162263e-06,
      "loss": 0.0638,
      "step": 2109
    },
    {
      "epoch": 0.1639726453217283,
      "grad_norm": 0.1932622343301773,
      "learning_rate": 9.18013677339136e-06,
      "loss": 0.0944,
      "step": 2110
    },
    {
      "epoch": 0.16405035747590924,
      "grad_norm": 0.7690970301628113,
      "learning_rate": 9.179748212620455e-06,
      "loss": 1.0446,
      "step": 2111
    },
    {
      "epoch": 0.16412806963009013,
      "grad_norm": 0.33221518993377686,
      "learning_rate": 9.17935965184955e-06,
      "loss": 0.2652,
      "step": 2112
    },
    {
      "epoch": 0.16420578178427106,
      "grad_norm": 0.20247513055801392,
      "learning_rate": 9.178971091078646e-06,
      "loss": 0.0749,
      "step": 2113
    },
    {
      "epoch": 0.16428349393845199,
      "grad_norm": 0.4416322112083435,
      "learning_rate": 9.178582530307741e-06,
      "loss": 0.3872,
      "step": 2114
    },
    {
      "epoch": 0.16436120609263288,
      "grad_norm": 0.13945713639259338,
      "learning_rate": 9.178193969536836e-06,
      "loss": 0.0579,
      "step": 2115
    },
    {
      "epoch": 0.1644389182468138,
      "grad_norm": 0.715871274471283,
      "learning_rate": 9.177805408765933e-06,
      "loss": 0.2067,
      "step": 2116
    },
    {
      "epoch": 0.1645166304009947,
      "grad_norm": 0.10623239725828171,
      "learning_rate": 9.177416847995028e-06,
      "loss": 0.0225,
      "step": 2117
    },
    {
      "epoch": 0.16459434255517563,
      "grad_norm": 0.2098347246646881,
      "learning_rate": 9.177028287224123e-06,
      "loss": 0.0993,
      "step": 2118
    },
    {
      "epoch": 0.16467205470935653,
      "grad_norm": 0.2013297826051712,
      "learning_rate": 9.176639726453218e-06,
      "loss": 0.1292,
      "step": 2119
    },
    {
      "epoch": 0.16474976686353746,
      "grad_norm": 0.19972191751003265,
      "learning_rate": 9.176251165682314e-06,
      "loss": 0.1154,
      "step": 2120
    },
    {
      "epoch": 0.16482747901771838,
      "grad_norm": 0.32549336552619934,
      "learning_rate": 9.175862604911409e-06,
      "loss": 0.1792,
      "step": 2121
    },
    {
      "epoch": 0.16490519117189928,
      "grad_norm": 0.3189406991004944,
      "learning_rate": 9.175474044140504e-06,
      "loss": 0.0916,
      "step": 2122
    },
    {
      "epoch": 0.1649829033260802,
      "grad_norm": 0.266937792301178,
      "learning_rate": 9.1750854833696e-06,
      "loss": 0.0846,
      "step": 2123
    },
    {
      "epoch": 0.1650606154802611,
      "grad_norm": 0.03153420239686966,
      "learning_rate": 9.174696922598696e-06,
      "loss": 0.0168,
      "step": 2124
    },
    {
      "epoch": 0.16513832763444203,
      "grad_norm": 0.36575499176979065,
      "learning_rate": 9.17430836182779e-06,
      "loss": 0.1614,
      "step": 2125
    },
    {
      "epoch": 0.16521603978862295,
      "grad_norm": 1.1146869659423828,
      "learning_rate": 9.173919801056886e-06,
      "loss": 0.3209,
      "step": 2126
    },
    {
      "epoch": 0.16529375194280385,
      "grad_norm": 0.24948440492153168,
      "learning_rate": 9.17353124028598e-06,
      "loss": 0.2182,
      "step": 2127
    },
    {
      "epoch": 0.16537146409698478,
      "grad_norm": 0.6907370686531067,
      "learning_rate": 9.173142679515077e-06,
      "loss": 0.4619,
      "step": 2128
    },
    {
      "epoch": 0.16544917625116567,
      "grad_norm": 0.2341638207435608,
      "learning_rate": 9.172754118744172e-06,
      "loss": 0.1001,
      "step": 2129
    },
    {
      "epoch": 0.1655268884053466,
      "grad_norm": 0.2810957729816437,
      "learning_rate": 9.172365557973267e-06,
      "loss": 0.1993,
      "step": 2130
    },
    {
      "epoch": 0.1656046005595275,
      "grad_norm": 0.1412501484155655,
      "learning_rate": 9.171976997202364e-06,
      "loss": 0.0424,
      "step": 2131
    },
    {
      "epoch": 0.16568231271370842,
      "grad_norm": 0.2794663906097412,
      "learning_rate": 9.171588436431459e-06,
      "loss": 0.1643,
      "step": 2132
    },
    {
      "epoch": 0.16576002486788935,
      "grad_norm": 0.4411197900772095,
      "learning_rate": 9.171199875660554e-06,
      "loss": 0.4948,
      "step": 2133
    },
    {
      "epoch": 0.16583773702207025,
      "grad_norm": 0.07754889130592346,
      "learning_rate": 9.170811314889649e-06,
      "loss": 0.0316,
      "step": 2134
    },
    {
      "epoch": 0.16591544917625117,
      "grad_norm": 0.2899993360042572,
      "learning_rate": 9.170422754118745e-06,
      "loss": 0.1888,
      "step": 2135
    },
    {
      "epoch": 0.16599316133043207,
      "grad_norm": 0.35284507274627686,
      "learning_rate": 9.17003419334784e-06,
      "loss": 0.3859,
      "step": 2136
    },
    {
      "epoch": 0.166070873484613,
      "grad_norm": 0.07356894016265869,
      "learning_rate": 9.169645632576935e-06,
      "loss": 0.0179,
      "step": 2137
    },
    {
      "epoch": 0.1661485856387939,
      "grad_norm": 0.1761859506368637,
      "learning_rate": 9.169257071806032e-06,
      "loss": 0.1665,
      "step": 2138
    },
    {
      "epoch": 0.16622629779297482,
      "grad_norm": 0.14920973777770996,
      "learning_rate": 9.168868511035127e-06,
      "loss": 0.1028,
      "step": 2139
    },
    {
      "epoch": 0.16630400994715575,
      "grad_norm": 0.18959324061870575,
      "learning_rate": 9.168479950264222e-06,
      "loss": 0.0381,
      "step": 2140
    },
    {
      "epoch": 0.16638172210133664,
      "grad_norm": 0.19368794560432434,
      "learning_rate": 9.168091389493318e-06,
      "loss": 0.2002,
      "step": 2141
    },
    {
      "epoch": 0.16645943425551757,
      "grad_norm": 0.7749213576316833,
      "learning_rate": 9.167702828722413e-06,
      "loss": 0.401,
      "step": 2142
    },
    {
      "epoch": 0.16653714640969847,
      "grad_norm": 0.4260440170764923,
      "learning_rate": 9.167314267951508e-06,
      "loss": 0.3253,
      "step": 2143
    },
    {
      "epoch": 0.1666148585638794,
      "grad_norm": 0.33389467000961304,
      "learning_rate": 9.166925707180603e-06,
      "loss": 0.1068,
      "step": 2144
    },
    {
      "epoch": 0.16669257071806032,
      "grad_norm": 0.16249513626098633,
      "learning_rate": 9.1665371464097e-06,
      "loss": 0.0813,
      "step": 2145
    },
    {
      "epoch": 0.16677028287224122,
      "grad_norm": 0.5741744041442871,
      "learning_rate": 9.166148585638795e-06,
      "loss": 0.0927,
      "step": 2146
    },
    {
      "epoch": 0.16684799502642214,
      "grad_norm": 0.3858785629272461,
      "learning_rate": 9.16576002486789e-06,
      "loss": 0.4245,
      "step": 2147
    },
    {
      "epoch": 0.16692570718060304,
      "grad_norm": 0.15027858316898346,
      "learning_rate": 9.165371464096986e-06,
      "loss": 0.0822,
      "step": 2148
    },
    {
      "epoch": 0.16700341933478396,
      "grad_norm": 0.4408199191093445,
      "learning_rate": 9.164982903326081e-06,
      "loss": 0.4577,
      "step": 2149
    },
    {
      "epoch": 0.16708113148896486,
      "grad_norm": 0.12593233585357666,
      "learning_rate": 9.164594342555176e-06,
      "loss": 0.0749,
      "step": 2150
    },
    {
      "epoch": 0.1671588436431458,
      "grad_norm": 0.14380000531673431,
      "learning_rate": 9.164205781784273e-06,
      "loss": 0.0605,
      "step": 2151
    },
    {
      "epoch": 0.1672365557973267,
      "grad_norm": 1.0942763090133667,
      "learning_rate": 9.163817221013366e-06,
      "loss": 0.632,
      "step": 2152
    },
    {
      "epoch": 0.1673142679515076,
      "grad_norm": 0.45868587493896484,
      "learning_rate": 9.163428660242463e-06,
      "loss": 0.2157,
      "step": 2153
    },
    {
      "epoch": 0.16739198010568854,
      "grad_norm": 0.1344098597764969,
      "learning_rate": 9.163040099471558e-06,
      "loss": 0.1477,
      "step": 2154
    },
    {
      "epoch": 0.16746969225986943,
      "grad_norm": 0.19746792316436768,
      "learning_rate": 9.162651538700653e-06,
      "loss": 0.104,
      "step": 2155
    },
    {
      "epoch": 0.16754740441405036,
      "grad_norm": 0.18080230057239532,
      "learning_rate": 9.16226297792975e-06,
      "loss": 0.0554,
      "step": 2156
    },
    {
      "epoch": 0.16762511656823126,
      "grad_norm": 0.07273130118846893,
      "learning_rate": 9.161874417158844e-06,
      "loss": 0.0105,
      "step": 2157
    },
    {
      "epoch": 0.16770282872241218,
      "grad_norm": 0.3312833905220032,
      "learning_rate": 9.16148585638794e-06,
      "loss": 0.1285,
      "step": 2158
    },
    {
      "epoch": 0.1677805408765931,
      "grad_norm": 0.3753833770751953,
      "learning_rate": 9.161097295617036e-06,
      "loss": 0.3242,
      "step": 2159
    },
    {
      "epoch": 0.167858253030774,
      "grad_norm": 0.3076525926589966,
      "learning_rate": 9.16070873484613e-06,
      "loss": 0.2415,
      "step": 2160
    },
    {
      "epoch": 0.16793596518495493,
      "grad_norm": 0.12105236947536469,
      "learning_rate": 9.160320174075226e-06,
      "loss": 0.0878,
      "step": 2161
    },
    {
      "epoch": 0.16801367733913583,
      "grad_norm": 1.3026862144470215,
      "learning_rate": 9.15993161330432e-06,
      "loss": 0.445,
      "step": 2162
    },
    {
      "epoch": 0.16809138949331676,
      "grad_norm": 0.12101494520902634,
      "learning_rate": 9.159543052533417e-06,
      "loss": 0.0911,
      "step": 2163
    },
    {
      "epoch": 0.16816910164749768,
      "grad_norm": 0.1837424784898758,
      "learning_rate": 9.159154491762512e-06,
      "loss": 0.1232,
      "step": 2164
    },
    {
      "epoch": 0.16824681380167858,
      "grad_norm": 0.12191154807806015,
      "learning_rate": 9.158765930991607e-06,
      "loss": 0.1023,
      "step": 2165
    },
    {
      "epoch": 0.1683245259558595,
      "grad_norm": 0.034654028713703156,
      "learning_rate": 9.158377370220704e-06,
      "loss": 0.0055,
      "step": 2166
    },
    {
      "epoch": 0.1684022381100404,
      "grad_norm": 0.802234411239624,
      "learning_rate": 9.157988809449799e-06,
      "loss": 0.2059,
      "step": 2167
    },
    {
      "epoch": 0.16847995026422133,
      "grad_norm": 0.1749519407749176,
      "learning_rate": 9.157600248678894e-06,
      "loss": 0.1161,
      "step": 2168
    },
    {
      "epoch": 0.16855766241840223,
      "grad_norm": 0.44200584292411804,
      "learning_rate": 9.15721168790799e-06,
      "loss": 0.1548,
      "step": 2169
    },
    {
      "epoch": 0.16863537457258315,
      "grad_norm": 0.30651727318763733,
      "learning_rate": 9.156823127137085e-06,
      "loss": 0.4692,
      "step": 2170
    },
    {
      "epoch": 0.16871308672676408,
      "grad_norm": 0.43188950419425964,
      "learning_rate": 9.15643456636618e-06,
      "loss": 0.463,
      "step": 2171
    },
    {
      "epoch": 0.16879079888094498,
      "grad_norm": 0.2880997955799103,
      "learning_rate": 9.156046005595275e-06,
      "loss": 0.2037,
      "step": 2172
    },
    {
      "epoch": 0.1688685110351259,
      "grad_norm": 0.5091960430145264,
      "learning_rate": 9.155657444824372e-06,
      "loss": 0.3755,
      "step": 2173
    },
    {
      "epoch": 0.1689462231893068,
      "grad_norm": 0.09869707375764847,
      "learning_rate": 9.155268884053467e-06,
      "loss": 0.0908,
      "step": 2174
    },
    {
      "epoch": 0.16902393534348772,
      "grad_norm": 1.0465683937072754,
      "learning_rate": 9.154880323282562e-06,
      "loss": 0.2841,
      "step": 2175
    },
    {
      "epoch": 0.16910164749766862,
      "grad_norm": 0.18924346566200256,
      "learning_rate": 9.154491762511658e-06,
      "loss": 0.1843,
      "step": 2176
    },
    {
      "epoch": 0.16917935965184955,
      "grad_norm": 0.5329694747924805,
      "learning_rate": 9.154103201740753e-06,
      "loss": 0.2937,
      "step": 2177
    },
    {
      "epoch": 0.16925707180603047,
      "grad_norm": 0.0987357497215271,
      "learning_rate": 9.153714640969848e-06,
      "loss": 0.0118,
      "step": 2178
    },
    {
      "epoch": 0.16933478396021137,
      "grad_norm": 0.08467437326908112,
      "learning_rate": 9.153326080198945e-06,
      "loss": 0.044,
      "step": 2179
    },
    {
      "epoch": 0.1694124961143923,
      "grad_norm": 0.3308868110179901,
      "learning_rate": 9.152937519428038e-06,
      "loss": 0.1134,
      "step": 2180
    },
    {
      "epoch": 0.1694902082685732,
      "grad_norm": 0.028320252895355225,
      "learning_rate": 9.152548958657135e-06,
      "loss": 0.0085,
      "step": 2181
    },
    {
      "epoch": 0.16956792042275412,
      "grad_norm": 0.4949663579463959,
      "learning_rate": 9.15216039788623e-06,
      "loss": 0.2518,
      "step": 2182
    },
    {
      "epoch": 0.16964563257693505,
      "grad_norm": 0.05572154372930527,
      "learning_rate": 9.151771837115325e-06,
      "loss": 0.0194,
      "step": 2183
    },
    {
      "epoch": 0.16972334473111594,
      "grad_norm": 0.26260995864868164,
      "learning_rate": 9.151383276344421e-06,
      "loss": 0.2079,
      "step": 2184
    },
    {
      "epoch": 0.16980105688529687,
      "grad_norm": 0.10363183915615082,
      "learning_rate": 9.150994715573516e-06,
      "loss": 0.06,
      "step": 2185
    },
    {
      "epoch": 0.16987876903947777,
      "grad_norm": 0.06354954093694687,
      "learning_rate": 9.150606154802611e-06,
      "loss": 0.0225,
      "step": 2186
    },
    {
      "epoch": 0.1699564811936587,
      "grad_norm": 0.1969197392463684,
      "learning_rate": 9.150217594031708e-06,
      "loss": 0.067,
      "step": 2187
    },
    {
      "epoch": 0.1700341933478396,
      "grad_norm": 0.46757543087005615,
      "learning_rate": 9.149829033260803e-06,
      "loss": 0.1868,
      "step": 2188
    },
    {
      "epoch": 0.17011190550202052,
      "grad_norm": 0.0200987309217453,
      "learning_rate": 9.149440472489898e-06,
      "loss": 0.007,
      "step": 2189
    },
    {
      "epoch": 0.17018961765620144,
      "grad_norm": 0.25837442278862,
      "learning_rate": 9.149051911718993e-06,
      "loss": 0.16,
      "step": 2190
    },
    {
      "epoch": 0.17026732981038234,
      "grad_norm": 0.21052232384681702,
      "learning_rate": 9.14866335094809e-06,
      "loss": 0.0708,
      "step": 2191
    },
    {
      "epoch": 0.17034504196456327,
      "grad_norm": 0.26410624384880066,
      "learning_rate": 9.148274790177184e-06,
      "loss": 0.1417,
      "step": 2192
    },
    {
      "epoch": 0.17042275411874416,
      "grad_norm": 0.11522750556468964,
      "learning_rate": 9.14788622940628e-06,
      "loss": 0.0608,
      "step": 2193
    },
    {
      "epoch": 0.1705004662729251,
      "grad_norm": 0.5503128170967102,
      "learning_rate": 9.147497668635376e-06,
      "loss": 0.0274,
      "step": 2194
    },
    {
      "epoch": 0.170578178427106,
      "grad_norm": 0.5947709679603577,
      "learning_rate": 9.147109107864471e-06,
      "loss": 0.3303,
      "step": 2195
    },
    {
      "epoch": 0.1706558905812869,
      "grad_norm": 0.3494161069393158,
      "learning_rate": 9.146720547093566e-06,
      "loss": 0.4351,
      "step": 2196
    },
    {
      "epoch": 0.17073360273546784,
      "grad_norm": 0.3333740234375,
      "learning_rate": 9.146331986322663e-06,
      "loss": 0.2032,
      "step": 2197
    },
    {
      "epoch": 0.17081131488964874,
      "grad_norm": 0.11430224031209946,
      "learning_rate": 9.145943425551756e-06,
      "loss": 0.0681,
      "step": 2198
    },
    {
      "epoch": 0.17088902704382966,
      "grad_norm": 0.5528225898742676,
      "learning_rate": 9.145554864780852e-06,
      "loss": 0.3837,
      "step": 2199
    },
    {
      "epoch": 0.17096673919801056,
      "grad_norm": 0.3541259169578552,
      "learning_rate": 9.145166304009947e-06,
      "loss": 0.2393,
      "step": 2200
    },
    {
      "epoch": 0.17104445135219148,
      "grad_norm": 0.1698918491601944,
      "learning_rate": 9.144777743239044e-06,
      "loss": 0.1215,
      "step": 2201
    },
    {
      "epoch": 0.1711221635063724,
      "grad_norm": 0.2683921456336975,
      "learning_rate": 9.144389182468139e-06,
      "loss": 0.1755,
      "step": 2202
    },
    {
      "epoch": 0.1711998756605533,
      "grad_norm": 1.0132803916931152,
      "learning_rate": 9.144000621697234e-06,
      "loss": 0.5638,
      "step": 2203
    },
    {
      "epoch": 0.17127758781473423,
      "grad_norm": 0.3028094470500946,
      "learning_rate": 9.14361206092633e-06,
      "loss": 0.2469,
      "step": 2204
    },
    {
      "epoch": 0.17135529996891513,
      "grad_norm": 0.371734619140625,
      "learning_rate": 9.143223500155426e-06,
      "loss": 0.3554,
      "step": 2205
    },
    {
      "epoch": 0.17143301212309606,
      "grad_norm": 0.27744626998901367,
      "learning_rate": 9.14283493938452e-06,
      "loss": 0.1548,
      "step": 2206
    },
    {
      "epoch": 0.17151072427727695,
      "grad_norm": 0.09615319222211838,
      "learning_rate": 9.142446378613617e-06,
      "loss": 0.0222,
      "step": 2207
    },
    {
      "epoch": 0.17158843643145788,
      "grad_norm": 0.06330125778913498,
      "learning_rate": 9.14205781784271e-06,
      "loss": 0.0153,
      "step": 2208
    },
    {
      "epoch": 0.1716661485856388,
      "grad_norm": 0.1269942969083786,
      "learning_rate": 9.141669257071807e-06,
      "loss": 0.0737,
      "step": 2209
    },
    {
      "epoch": 0.1717438607398197,
      "grad_norm": 0.2441670149564743,
      "learning_rate": 9.141280696300902e-06,
      "loss": 0.2756,
      "step": 2210
    },
    {
      "epoch": 0.17182157289400063,
      "grad_norm": 0.49726349115371704,
      "learning_rate": 9.140892135529997e-06,
      "loss": 0.6073,
      "step": 2211
    },
    {
      "epoch": 0.17189928504818153,
      "grad_norm": 0.15295177698135376,
      "learning_rate": 9.140503574759094e-06,
      "loss": 0.1451,
      "step": 2212
    },
    {
      "epoch": 0.17197699720236245,
      "grad_norm": 0.27684685587882996,
      "learning_rate": 9.140115013988189e-06,
      "loss": 0.0945,
      "step": 2213
    },
    {
      "epoch": 0.17205470935654335,
      "grad_norm": 0.11646188795566559,
      "learning_rate": 9.139726453217283e-06,
      "loss": 0.0299,
      "step": 2214
    },
    {
      "epoch": 0.17213242151072428,
      "grad_norm": 0.046573713421821594,
      "learning_rate": 9.13933789244638e-06,
      "loss": 0.0073,
      "step": 2215
    },
    {
      "epoch": 0.1722101336649052,
      "grad_norm": 0.36955177783966064,
      "learning_rate": 9.138949331675475e-06,
      "loss": 0.395,
      "step": 2216
    },
    {
      "epoch": 0.1722878458190861,
      "grad_norm": 0.1554839015007019,
      "learning_rate": 9.13856077090457e-06,
      "loss": 0.0996,
      "step": 2217
    },
    {
      "epoch": 0.17236555797326703,
      "grad_norm": 0.2548341453075409,
      "learning_rate": 9.138172210133665e-06,
      "loss": 0.1247,
      "step": 2218
    },
    {
      "epoch": 0.17244327012744792,
      "grad_norm": 0.01109880581498146,
      "learning_rate": 9.137783649362762e-06,
      "loss": 0.0025,
      "step": 2219
    },
    {
      "epoch": 0.17252098228162885,
      "grad_norm": 0.3082600235939026,
      "learning_rate": 9.137395088591857e-06,
      "loss": 0.3313,
      "step": 2220
    },
    {
      "epoch": 0.17259869443580977,
      "grad_norm": 0.18253514170646667,
      "learning_rate": 9.137006527820952e-06,
      "loss": 0.1395,
      "step": 2221
    },
    {
      "epoch": 0.17267640658999067,
      "grad_norm": 0.5458884835243225,
      "learning_rate": 9.136617967050048e-06,
      "loss": 0.3895,
      "step": 2222
    },
    {
      "epoch": 0.1727541187441716,
      "grad_norm": 0.18139231204986572,
      "learning_rate": 9.136229406279143e-06,
      "loss": 0.1684,
      "step": 2223
    },
    {
      "epoch": 0.1728318308983525,
      "grad_norm": 0.4318847358226776,
      "learning_rate": 9.135840845508238e-06,
      "loss": 0.6081,
      "step": 2224
    },
    {
      "epoch": 0.17290954305253342,
      "grad_norm": 0.5069816708564758,
      "learning_rate": 9.135452284737335e-06,
      "loss": 0.1551,
      "step": 2225
    },
    {
      "epoch": 0.17298725520671432,
      "grad_norm": 0.5608392357826233,
      "learning_rate": 9.135063723966428e-06,
      "loss": 0.2242,
      "step": 2226
    },
    {
      "epoch": 0.17306496736089524,
      "grad_norm": 0.38174551725387573,
      "learning_rate": 9.134675163195525e-06,
      "loss": 0.2648,
      "step": 2227
    },
    {
      "epoch": 0.17314267951507617,
      "grad_norm": 0.5178457498550415,
      "learning_rate": 9.13428660242462e-06,
      "loss": 0.4468,
      "step": 2228
    },
    {
      "epoch": 0.17322039166925707,
      "grad_norm": 0.49089524149894714,
      "learning_rate": 9.133898041653715e-06,
      "loss": 0.1847,
      "step": 2229
    },
    {
      "epoch": 0.173298103823438,
      "grad_norm": 0.33127638697624207,
      "learning_rate": 9.133509480882811e-06,
      "loss": 0.1291,
      "step": 2230
    },
    {
      "epoch": 0.1733758159776189,
      "grad_norm": 0.28018322587013245,
      "learning_rate": 9.133120920111906e-06,
      "loss": 0.1926,
      "step": 2231
    },
    {
      "epoch": 0.17345352813179982,
      "grad_norm": 0.7920942306518555,
      "learning_rate": 9.132732359341003e-06,
      "loss": 0.6738,
      "step": 2232
    },
    {
      "epoch": 0.17353124028598071,
      "grad_norm": 0.13648061454296112,
      "learning_rate": 9.132343798570098e-06,
      "loss": 0.0655,
      "step": 2233
    },
    {
      "epoch": 0.17360895244016164,
      "grad_norm": 0.2793799340724945,
      "learning_rate": 9.131955237799193e-06,
      "loss": 0.1324,
      "step": 2234
    },
    {
      "epoch": 0.17368666459434257,
      "grad_norm": 0.22008070349693298,
      "learning_rate": 9.13156667702829e-06,
      "loss": 0.4743,
      "step": 2235
    },
    {
      "epoch": 0.17376437674852346,
      "grad_norm": 0.32096755504608154,
      "learning_rate": 9.131178116257383e-06,
      "loss": 0.2159,
      "step": 2236
    },
    {
      "epoch": 0.1738420889027044,
      "grad_norm": 0.4245055317878723,
      "learning_rate": 9.13078955548648e-06,
      "loss": 0.2508,
      "step": 2237
    },
    {
      "epoch": 0.1739198010568853,
      "grad_norm": 0.2089424580335617,
      "learning_rate": 9.130400994715574e-06,
      "loss": 0.1116,
      "step": 2238
    },
    {
      "epoch": 0.1739975132110662,
      "grad_norm": 0.5910006165504456,
      "learning_rate": 9.130012433944669e-06,
      "loss": 0.8481,
      "step": 2239
    },
    {
      "epoch": 0.17407522536524714,
      "grad_norm": 1.6712875366210938,
      "learning_rate": 9.129623873173766e-06,
      "loss": 0.5965,
      "step": 2240
    },
    {
      "epoch": 0.17415293751942804,
      "grad_norm": 0.42100265622138977,
      "learning_rate": 9.12923531240286e-06,
      "loss": 0.2117,
      "step": 2241
    },
    {
      "epoch": 0.17423064967360896,
      "grad_norm": 0.40080899000167847,
      "learning_rate": 9.128846751631956e-06,
      "loss": 0.3779,
      "step": 2242
    },
    {
      "epoch": 0.17430836182778986,
      "grad_norm": 0.14875173568725586,
      "learning_rate": 9.128458190861052e-06,
      "loss": 0.0768,
      "step": 2243
    },
    {
      "epoch": 0.17438607398197079,
      "grad_norm": 0.16437885165214539,
      "learning_rate": 9.128069630090147e-06,
      "loss": 0.1062,
      "step": 2244
    },
    {
      "epoch": 0.17446378613615168,
      "grad_norm": 0.2951497733592987,
      "learning_rate": 9.127681069319242e-06,
      "loss": 0.1396,
      "step": 2245
    },
    {
      "epoch": 0.1745414982903326,
      "grad_norm": 0.5031413435935974,
      "learning_rate": 9.127292508548337e-06,
      "loss": 0.4909,
      "step": 2246
    },
    {
      "epoch": 0.17461921044451353,
      "grad_norm": 0.5169416069984436,
      "learning_rate": 9.126903947777434e-06,
      "loss": 0.1646,
      "step": 2247
    },
    {
      "epoch": 0.17469692259869443,
      "grad_norm": 0.2885388731956482,
      "learning_rate": 9.126515387006529e-06,
      "loss": 0.2049,
      "step": 2248
    },
    {
      "epoch": 0.17477463475287536,
      "grad_norm": 0.15909335017204285,
      "learning_rate": 9.126126826235624e-06,
      "loss": 0.0889,
      "step": 2249
    },
    {
      "epoch": 0.17485234690705626,
      "grad_norm": 0.19102679193019867,
      "learning_rate": 9.12573826546472e-06,
      "loss": 0.0337,
      "step": 2250
    },
    {
      "epoch": 0.17493005906123718,
      "grad_norm": 0.25721949338912964,
      "learning_rate": 9.125349704693815e-06,
      "loss": 0.3864,
      "step": 2251
    },
    {
      "epoch": 0.17500777121541808,
      "grad_norm": 0.19343441724777222,
      "learning_rate": 9.12496114392291e-06,
      "loss": 0.0822,
      "step": 2252
    },
    {
      "epoch": 0.175085483369599,
      "grad_norm": 0.2605023682117462,
      "learning_rate": 9.124572583152005e-06,
      "loss": 0.2209,
      "step": 2253
    },
    {
      "epoch": 0.17516319552377993,
      "grad_norm": 0.18918417394161224,
      "learning_rate": 9.1241840223811e-06,
      "loss": 0.0399,
      "step": 2254
    },
    {
      "epoch": 0.17524090767796083,
      "grad_norm": 0.3977770209312439,
      "learning_rate": 9.123795461610197e-06,
      "loss": 0.3077,
      "step": 2255
    },
    {
      "epoch": 0.17531861983214175,
      "grad_norm": 0.2739497423171997,
      "learning_rate": 9.123406900839292e-06,
      "loss": 0.2903,
      "step": 2256
    },
    {
      "epoch": 0.17539633198632265,
      "grad_norm": 0.190940722823143,
      "learning_rate": 9.123018340068387e-06,
      "loss": 0.0948,
      "step": 2257
    },
    {
      "epoch": 0.17547404414050358,
      "grad_norm": 0.1434788703918457,
      "learning_rate": 9.122629779297483e-06,
      "loss": 0.0885,
      "step": 2258
    },
    {
      "epoch": 0.1755517562946845,
      "grad_norm": 0.3639478087425232,
      "learning_rate": 9.122241218526578e-06,
      "loss": 0.2892,
      "step": 2259
    },
    {
      "epoch": 0.1756294684488654,
      "grad_norm": 0.329010933637619,
      "learning_rate": 9.121852657755673e-06,
      "loss": 0.3022,
      "step": 2260
    },
    {
      "epoch": 0.17570718060304633,
      "grad_norm": 0.3108985126018524,
      "learning_rate": 9.121464096984768e-06,
      "loss": 0.0644,
      "step": 2261
    },
    {
      "epoch": 0.17578489275722722,
      "grad_norm": 0.47841233015060425,
      "learning_rate": 9.121075536213865e-06,
      "loss": 0.6586,
      "step": 2262
    },
    {
      "epoch": 0.17586260491140815,
      "grad_norm": 0.7790050506591797,
      "learning_rate": 9.12068697544296e-06,
      "loss": 0.7392,
      "step": 2263
    },
    {
      "epoch": 0.17594031706558905,
      "grad_norm": 0.49532899260520935,
      "learning_rate": 9.120298414672055e-06,
      "loss": 0.3015,
      "step": 2264
    },
    {
      "epoch": 0.17601802921976997,
      "grad_norm": 0.3611931800842285,
      "learning_rate": 9.119909853901151e-06,
      "loss": 0.2903,
      "step": 2265
    },
    {
      "epoch": 0.1760957413739509,
      "grad_norm": 0.3913131356239319,
      "learning_rate": 9.119521293130246e-06,
      "loss": 0.5012,
      "step": 2266
    },
    {
      "epoch": 0.1761734535281318,
      "grad_norm": 0.2527029812335968,
      "learning_rate": 9.119132732359341e-06,
      "loss": 0.0549,
      "step": 2267
    },
    {
      "epoch": 0.17625116568231272,
      "grad_norm": 0.6410201191902161,
      "learning_rate": 9.118744171588438e-06,
      "loss": 0.5965,
      "step": 2268
    },
    {
      "epoch": 0.17632887783649362,
      "grad_norm": 0.35669997334480286,
      "learning_rate": 9.118355610817533e-06,
      "loss": 0.2308,
      "step": 2269
    },
    {
      "epoch": 0.17640658999067454,
      "grad_norm": 0.5612279772758484,
      "learning_rate": 9.117967050046628e-06,
      "loss": 0.1712,
      "step": 2270
    },
    {
      "epoch": 0.17648430214485544,
      "grad_norm": 0.8884523510932922,
      "learning_rate": 9.117578489275723e-06,
      "loss": 0.5135,
      "step": 2271
    },
    {
      "epoch": 0.17656201429903637,
      "grad_norm": 0.34070420265197754,
      "learning_rate": 9.11718992850482e-06,
      "loss": 0.1123,
      "step": 2272
    },
    {
      "epoch": 0.1766397264532173,
      "grad_norm": 0.2476096898317337,
      "learning_rate": 9.116801367733914e-06,
      "loss": 0.0807,
      "step": 2273
    },
    {
      "epoch": 0.1767174386073982,
      "grad_norm": 0.43137678503990173,
      "learning_rate": 9.11641280696301e-06,
      "loss": 0.4828,
      "step": 2274
    },
    {
      "epoch": 0.17679515076157912,
      "grad_norm": 0.14925815165042877,
      "learning_rate": 9.116024246192106e-06,
      "loss": 0.07,
      "step": 2275
    },
    {
      "epoch": 0.17687286291576002,
      "grad_norm": 0.12735486030578613,
      "learning_rate": 9.115635685421201e-06,
      "loss": 0.1033,
      "step": 2276
    },
    {
      "epoch": 0.17695057506994094,
      "grad_norm": 0.5940515398979187,
      "learning_rate": 9.115247124650296e-06,
      "loss": 0.4564,
      "step": 2277
    },
    {
      "epoch": 0.17702828722412187,
      "grad_norm": 0.2894716262817383,
      "learning_rate": 9.114858563879392e-06,
      "loss": 0.2965,
      "step": 2278
    },
    {
      "epoch": 0.17710599937830276,
      "grad_norm": 0.24491827189922333,
      "learning_rate": 9.114470003108486e-06,
      "loss": 0.2309,
      "step": 2279
    },
    {
      "epoch": 0.1771837115324837,
      "grad_norm": 0.24643203616142273,
      "learning_rate": 9.114081442337582e-06,
      "loss": 0.136,
      "step": 2280
    },
    {
      "epoch": 0.1772614236866646,
      "grad_norm": 0.16031745076179504,
      "learning_rate": 9.113692881566677e-06,
      "loss": 0.0432,
      "step": 2281
    },
    {
      "epoch": 0.1773391358408455,
      "grad_norm": 0.25851377844810486,
      "learning_rate": 9.113304320795772e-06,
      "loss": 0.1386,
      "step": 2282
    },
    {
      "epoch": 0.1774168479950264,
      "grad_norm": 0.3859090209007263,
      "learning_rate": 9.112915760024869e-06,
      "loss": 0.2666,
      "step": 2283
    },
    {
      "epoch": 0.17749456014920734,
      "grad_norm": 0.17880885303020477,
      "learning_rate": 9.112527199253964e-06,
      "loss": 0.1372,
      "step": 2284
    },
    {
      "epoch": 0.17757227230338826,
      "grad_norm": 0.5028280019760132,
      "learning_rate": 9.112138638483059e-06,
      "loss": 0.0884,
      "step": 2285
    },
    {
      "epoch": 0.17764998445756916,
      "grad_norm": 0.17923565208911896,
      "learning_rate": 9.111750077712155e-06,
      "loss": 0.0375,
      "step": 2286
    },
    {
      "epoch": 0.17772769661175009,
      "grad_norm": 0.1648786962032318,
      "learning_rate": 9.11136151694125e-06,
      "loss": 0.1033,
      "step": 2287
    },
    {
      "epoch": 0.17780540876593098,
      "grad_norm": 0.19658160209655762,
      "learning_rate": 9.110972956170345e-06,
      "loss": 0.1963,
      "step": 2288
    },
    {
      "epoch": 0.1778831209201119,
      "grad_norm": 0.31374675035476685,
      "learning_rate": 9.11058439539944e-06,
      "loss": 0.1619,
      "step": 2289
    },
    {
      "epoch": 0.1779608330742928,
      "grad_norm": 0.7022225260734558,
      "learning_rate": 9.110195834628537e-06,
      "loss": 0.4314,
      "step": 2290
    },
    {
      "epoch": 0.17803854522847373,
      "grad_norm": 0.26653167605400085,
      "learning_rate": 9.109807273857632e-06,
      "loss": 0.1611,
      "step": 2291
    },
    {
      "epoch": 0.17811625738265466,
      "grad_norm": 0.2507268190383911,
      "learning_rate": 9.109418713086727e-06,
      "loss": 0.238,
      "step": 2292
    },
    {
      "epoch": 0.17819396953683556,
      "grad_norm": 0.16832716763019562,
      "learning_rate": 9.109030152315823e-06,
      "loss": 0.1481,
      "step": 2293
    },
    {
      "epoch": 0.17827168169101648,
      "grad_norm": 0.2620834410190582,
      "learning_rate": 9.108641591544918e-06,
      "loss": 0.1211,
      "step": 2294
    },
    {
      "epoch": 0.17834939384519738,
      "grad_norm": 0.2611194849014282,
      "learning_rate": 9.108253030774013e-06,
      "loss": 0.2359,
      "step": 2295
    },
    {
      "epoch": 0.1784271059993783,
      "grad_norm": 0.1570557802915573,
      "learning_rate": 9.10786447000311e-06,
      "loss": 0.0247,
      "step": 2296
    },
    {
      "epoch": 0.17850481815355923,
      "grad_norm": 0.21491780877113342,
      "learning_rate": 9.107475909232205e-06,
      "loss": 0.0913,
      "step": 2297
    },
    {
      "epoch": 0.17858253030774013,
      "grad_norm": 0.1133187860250473,
      "learning_rate": 9.1070873484613e-06,
      "loss": 0.0311,
      "step": 2298
    },
    {
      "epoch": 0.17866024246192105,
      "grad_norm": 0.19716453552246094,
      "learning_rate": 9.106698787690395e-06,
      "loss": 0.1467,
      "step": 2299
    },
    {
      "epoch": 0.17873795461610195,
      "grad_norm": 0.1905510276556015,
      "learning_rate": 9.106310226919492e-06,
      "loss": 0.0433,
      "step": 2300
    },
    {
      "epoch": 0.17881566677028288,
      "grad_norm": 0.11926055699586868,
      "learning_rate": 9.105921666148586e-06,
      "loss": 0.0593,
      "step": 2301
    },
    {
      "epoch": 0.17889337892446378,
      "grad_norm": 0.23415406048297882,
      "learning_rate": 9.105533105377681e-06,
      "loss": 0.137,
      "step": 2302
    },
    {
      "epoch": 0.1789710910786447,
      "grad_norm": 0.1112125813961029,
      "learning_rate": 9.105144544606778e-06,
      "loss": 0.0576,
      "step": 2303
    },
    {
      "epoch": 0.17904880323282563,
      "grad_norm": 0.3196139335632324,
      "learning_rate": 9.104755983835873e-06,
      "loss": 0.153,
      "step": 2304
    },
    {
      "epoch": 0.17912651538700652,
      "grad_norm": 0.15191340446472168,
      "learning_rate": 9.104367423064968e-06,
      "loss": 0.1648,
      "step": 2305
    },
    {
      "epoch": 0.17920422754118745,
      "grad_norm": 0.3659508526325226,
      "learning_rate": 9.103978862294065e-06,
      "loss": 0.2617,
      "step": 2306
    },
    {
      "epoch": 0.17928193969536835,
      "grad_norm": 0.664922297000885,
      "learning_rate": 9.103590301523158e-06,
      "loss": 0.4399,
      "step": 2307
    },
    {
      "epoch": 0.17935965184954927,
      "grad_norm": 0.17362773418426514,
      "learning_rate": 9.103201740752255e-06,
      "loss": 0.0838,
      "step": 2308
    },
    {
      "epoch": 0.17943736400373017,
      "grad_norm": 0.2559375762939453,
      "learning_rate": 9.10281317998135e-06,
      "loss": 0.1606,
      "step": 2309
    },
    {
      "epoch": 0.1795150761579111,
      "grad_norm": 0.36497363448143005,
      "learning_rate": 9.102424619210444e-06,
      "loss": 0.118,
      "step": 2310
    },
    {
      "epoch": 0.17959278831209202,
      "grad_norm": 0.2061082273721695,
      "learning_rate": 9.102036058439541e-06,
      "loss": 0.0614,
      "step": 2311
    },
    {
      "epoch": 0.17967050046627292,
      "grad_norm": 0.15268167853355408,
      "learning_rate": 9.101647497668636e-06,
      "loss": 0.0711,
      "step": 2312
    },
    {
      "epoch": 0.17974821262045385,
      "grad_norm": 0.43854400515556335,
      "learning_rate": 9.101258936897731e-06,
      "loss": 0.3485,
      "step": 2313
    },
    {
      "epoch": 0.17982592477463474,
      "grad_norm": 0.257088303565979,
      "learning_rate": 9.100870376126828e-06,
      "loss": 0.1019,
      "step": 2314
    },
    {
      "epoch": 0.17990363692881567,
      "grad_norm": 0.42953696846961975,
      "learning_rate": 9.100481815355923e-06,
      "loss": 0.1987,
      "step": 2315
    },
    {
      "epoch": 0.1799813490829966,
      "grad_norm": 0.2339387834072113,
      "learning_rate": 9.100093254585017e-06,
      "loss": 0.0831,
      "step": 2316
    },
    {
      "epoch": 0.1800590612371775,
      "grad_norm": 0.3517804741859436,
      "learning_rate": 9.099704693814112e-06,
      "loss": 0.2135,
      "step": 2317
    },
    {
      "epoch": 0.18013677339135842,
      "grad_norm": 0.0952114537358284,
      "learning_rate": 9.099316133043209e-06,
      "loss": 0.0381,
      "step": 2318
    },
    {
      "epoch": 0.18021448554553932,
      "grad_norm": 0.05613226816058159,
      "learning_rate": 9.098927572272304e-06,
      "loss": 0.0478,
      "step": 2319
    },
    {
      "epoch": 0.18029219769972024,
      "grad_norm": 0.4110759198665619,
      "learning_rate": 9.098539011501399e-06,
      "loss": 0.111,
      "step": 2320
    },
    {
      "epoch": 0.18036990985390114,
      "grad_norm": 0.31642019748687744,
      "learning_rate": 9.098150450730496e-06,
      "loss": 0.235,
      "step": 2321
    },
    {
      "epoch": 0.18044762200808206,
      "grad_norm": 0.08929003775119781,
      "learning_rate": 9.09776188995959e-06,
      "loss": 0.0228,
      "step": 2322
    },
    {
      "epoch": 0.180525334162263,
      "grad_norm": 0.3559039831161499,
      "learning_rate": 9.097373329188686e-06,
      "loss": 0.6148,
      "step": 2323
    },
    {
      "epoch": 0.1806030463164439,
      "grad_norm": 0.5992337465286255,
      "learning_rate": 9.096984768417782e-06,
      "loss": 0.1381,
      "step": 2324
    },
    {
      "epoch": 0.1806807584706248,
      "grad_norm": 0.5789361596107483,
      "learning_rate": 9.096596207646877e-06,
      "loss": 0.7783,
      "step": 2325
    },
    {
      "epoch": 0.1807584706248057,
      "grad_norm": 0.4133303165435791,
      "learning_rate": 9.096207646875972e-06,
      "loss": 0.2669,
      "step": 2326
    },
    {
      "epoch": 0.18083618277898664,
      "grad_norm": 0.26585280895233154,
      "learning_rate": 9.095819086105067e-06,
      "loss": 0.1555,
      "step": 2327
    },
    {
      "epoch": 0.18091389493316754,
      "grad_norm": 0.4739589989185333,
      "learning_rate": 9.095430525334164e-06,
      "loss": 0.3162,
      "step": 2328
    },
    {
      "epoch": 0.18099160708734846,
      "grad_norm": 0.1681641787290573,
      "learning_rate": 9.095041964563259e-06,
      "loss": 0.0761,
      "step": 2329
    },
    {
      "epoch": 0.1810693192415294,
      "grad_norm": 0.20584701001644135,
      "learning_rate": 9.094653403792354e-06,
      "loss": 0.0879,
      "step": 2330
    },
    {
      "epoch": 0.18114703139571028,
      "grad_norm": 0.4494481086730957,
      "learning_rate": 9.09426484302145e-06,
      "loss": 0.2145,
      "step": 2331
    },
    {
      "epoch": 0.1812247435498912,
      "grad_norm": 0.13987362384796143,
      "learning_rate": 9.093876282250545e-06,
      "loss": 0.0499,
      "step": 2332
    },
    {
      "epoch": 0.1813024557040721,
      "grad_norm": 0.16285105049610138,
      "learning_rate": 9.09348772147964e-06,
      "loss": 0.1069,
      "step": 2333
    },
    {
      "epoch": 0.18138016785825303,
      "grad_norm": 0.17851288616657257,
      "learning_rate": 9.093099160708737e-06,
      "loss": 0.0533,
      "step": 2334
    },
    {
      "epoch": 0.18145788001243393,
      "grad_norm": 0.714428722858429,
      "learning_rate": 9.09271059993783e-06,
      "loss": 0.4338,
      "step": 2335
    },
    {
      "epoch": 0.18153559216661486,
      "grad_norm": 0.17878134548664093,
      "learning_rate": 9.092322039166927e-06,
      "loss": 0.059,
      "step": 2336
    },
    {
      "epoch": 0.18161330432079578,
      "grad_norm": 0.3466661274433136,
      "learning_rate": 9.091933478396022e-06,
      "loss": 0.2494,
      "step": 2337
    },
    {
      "epoch": 0.18169101647497668,
      "grad_norm": 0.18234646320343018,
      "learning_rate": 9.091544917625117e-06,
      "loss": 0.0532,
      "step": 2338
    },
    {
      "epoch": 0.1817687286291576,
      "grad_norm": 0.13047213852405548,
      "learning_rate": 9.091156356854213e-06,
      "loss": 0.095,
      "step": 2339
    },
    {
      "epoch": 0.1818464407833385,
      "grad_norm": 0.1492830365896225,
      "learning_rate": 9.090767796083308e-06,
      "loss": 0.0857,
      "step": 2340
    },
    {
      "epoch": 0.18192415293751943,
      "grad_norm": 0.23883101344108582,
      "learning_rate": 9.090379235312403e-06,
      "loss": 0.1216,
      "step": 2341
    },
    {
      "epoch": 0.18200186509170035,
      "grad_norm": 0.7075985074043274,
      "learning_rate": 9.0899906745415e-06,
      "loss": 0.5455,
      "step": 2342
    },
    {
      "epoch": 0.18207957724588125,
      "grad_norm": 0.10556741058826447,
      "learning_rate": 9.089602113770595e-06,
      "loss": 0.1042,
      "step": 2343
    },
    {
      "epoch": 0.18215728940006218,
      "grad_norm": 0.44074639678001404,
      "learning_rate": 9.08921355299969e-06,
      "loss": 0.3349,
      "step": 2344
    },
    {
      "epoch": 0.18223500155424308,
      "grad_norm": 0.08402089774608612,
      "learning_rate": 9.088824992228785e-06,
      "loss": 0.0296,
      "step": 2345
    },
    {
      "epoch": 0.182312713708424,
      "grad_norm": 0.04890216886997223,
      "learning_rate": 9.088436431457881e-06,
      "loss": 0.0111,
      "step": 2346
    },
    {
      "epoch": 0.1823904258626049,
      "grad_norm": 0.12164860963821411,
      "learning_rate": 9.088047870686976e-06,
      "loss": 0.0284,
      "step": 2347
    },
    {
      "epoch": 0.18246813801678582,
      "grad_norm": 0.034707602113485336,
      "learning_rate": 9.087659309916071e-06,
      "loss": 0.0126,
      "step": 2348
    },
    {
      "epoch": 0.18254585017096675,
      "grad_norm": 0.6437204480171204,
      "learning_rate": 9.087270749145168e-06,
      "loss": 0.1468,
      "step": 2349
    },
    {
      "epoch": 0.18262356232514765,
      "grad_norm": 0.26611170172691345,
      "learning_rate": 9.086882188374263e-06,
      "loss": 0.1543,
      "step": 2350
    },
    {
      "epoch": 0.18270127447932857,
      "grad_norm": 0.13753481209278107,
      "learning_rate": 9.086493627603358e-06,
      "loss": 0.0907,
      "step": 2351
    },
    {
      "epoch": 0.18277898663350947,
      "grad_norm": 0.2858622372150421,
      "learning_rate": 9.086105066832454e-06,
      "loss": 0.1834,
      "step": 2352
    },
    {
      "epoch": 0.1828566987876904,
      "grad_norm": 0.2417210340499878,
      "learning_rate": 9.08571650606155e-06,
      "loss": 0.3431,
      "step": 2353
    },
    {
      "epoch": 0.1829344109418713,
      "grad_norm": 0.20241597294807434,
      "learning_rate": 9.085327945290644e-06,
      "loss": 0.0618,
      "step": 2354
    },
    {
      "epoch": 0.18301212309605222,
      "grad_norm": 0.3326801359653473,
      "learning_rate": 9.08493938451974e-06,
      "loss": 0.486,
      "step": 2355
    },
    {
      "epoch": 0.18308983525023315,
      "grad_norm": 0.368984192609787,
      "learning_rate": 9.084550823748836e-06,
      "loss": 0.1406,
      "step": 2356
    },
    {
      "epoch": 0.18316754740441404,
      "grad_norm": 0.5565983653068542,
      "learning_rate": 9.08416226297793e-06,
      "loss": 0.597,
      "step": 2357
    },
    {
      "epoch": 0.18324525955859497,
      "grad_norm": 0.16408437490463257,
      "learning_rate": 9.083773702207026e-06,
      "loss": 0.0364,
      "step": 2358
    },
    {
      "epoch": 0.18332297171277587,
      "grad_norm": 0.11145898699760437,
      "learning_rate": 9.083385141436122e-06,
      "loss": 0.0558,
      "step": 2359
    },
    {
      "epoch": 0.1834006838669568,
      "grad_norm": 0.08643808960914612,
      "learning_rate": 9.082996580665217e-06,
      "loss": 0.0301,
      "step": 2360
    },
    {
      "epoch": 0.18347839602113772,
      "grad_norm": 0.3105628490447998,
      "learning_rate": 9.082608019894312e-06,
      "loss": 0.1142,
      "step": 2361
    },
    {
      "epoch": 0.18355610817531862,
      "grad_norm": 0.31507211923599243,
      "learning_rate": 9.082219459123409e-06,
      "loss": 0.1661,
      "step": 2362
    },
    {
      "epoch": 0.18363382032949954,
      "grad_norm": 0.295580118894577,
      "learning_rate": 9.081830898352502e-06,
      "loss": 0.1522,
      "step": 2363
    },
    {
      "epoch": 0.18371153248368044,
      "grad_norm": 0.275128573179245,
      "learning_rate": 9.081442337581599e-06,
      "loss": 0.0396,
      "step": 2364
    },
    {
      "epoch": 0.18378924463786137,
      "grad_norm": 0.2924918532371521,
      "learning_rate": 9.081053776810694e-06,
      "loss": 0.1476,
      "step": 2365
    },
    {
      "epoch": 0.18386695679204226,
      "grad_norm": 0.3431544005870819,
      "learning_rate": 9.080665216039789e-06,
      "loss": 0.3717,
      "step": 2366
    },
    {
      "epoch": 0.1839446689462232,
      "grad_norm": 0.44061312079429626,
      "learning_rate": 9.080276655268885e-06,
      "loss": 0.1211,
      "step": 2367
    },
    {
      "epoch": 0.18402238110040411,
      "grad_norm": 0.3663148283958435,
      "learning_rate": 9.07988809449798e-06,
      "loss": 0.2931,
      "step": 2368
    },
    {
      "epoch": 0.184100093254585,
      "grad_norm": 0.21106992661952972,
      "learning_rate": 9.079499533727075e-06,
      "loss": 0.1052,
      "step": 2369
    },
    {
      "epoch": 0.18417780540876594,
      "grad_norm": 0.15587612986564636,
      "learning_rate": 9.079110972956172e-06,
      "loss": 0.0708,
      "step": 2370
    },
    {
      "epoch": 0.18425551756294684,
      "grad_norm": 0.16459473967552185,
      "learning_rate": 9.078722412185267e-06,
      "loss": 0.1498,
      "step": 2371
    },
    {
      "epoch": 0.18433322971712776,
      "grad_norm": 0.32154273986816406,
      "learning_rate": 9.078333851414362e-06,
      "loss": 0.1064,
      "step": 2372
    },
    {
      "epoch": 0.18441094187130866,
      "grad_norm": 0.573003888130188,
      "learning_rate": 9.077945290643457e-06,
      "loss": 0.3286,
      "step": 2373
    },
    {
      "epoch": 0.18448865402548958,
      "grad_norm": 0.12613379955291748,
      "learning_rate": 9.077556729872553e-06,
      "loss": 0.0536,
      "step": 2374
    },
    {
      "epoch": 0.1845663661796705,
      "grad_norm": 0.21075129508972168,
      "learning_rate": 9.077168169101648e-06,
      "loss": 0.1068,
      "step": 2375
    },
    {
      "epoch": 0.1846440783338514,
      "grad_norm": 0.1833825260400772,
      "learning_rate": 9.076779608330743e-06,
      "loss": 0.0826,
      "step": 2376
    },
    {
      "epoch": 0.18472179048803233,
      "grad_norm": 0.41171425580978394,
      "learning_rate": 9.07639104755984e-06,
      "loss": 0.3213,
      "step": 2377
    },
    {
      "epoch": 0.18479950264221323,
      "grad_norm": 0.195430725812912,
      "learning_rate": 9.076002486788933e-06,
      "loss": 0.1103,
      "step": 2378
    },
    {
      "epoch": 0.18487721479639416,
      "grad_norm": 2.4033305644989014,
      "learning_rate": 9.07561392601803e-06,
      "loss": 0.166,
      "step": 2379
    },
    {
      "epoch": 0.18495492695057508,
      "grad_norm": 0.5269885659217834,
      "learning_rate": 9.075225365247125e-06,
      "loss": 0.5013,
      "step": 2380
    },
    {
      "epoch": 0.18503263910475598,
      "grad_norm": 0.43805477023124695,
      "learning_rate": 9.07483680447622e-06,
      "loss": 0.2558,
      "step": 2381
    },
    {
      "epoch": 0.1851103512589369,
      "grad_norm": 0.2508372664451599,
      "learning_rate": 9.074448243705316e-06,
      "loss": 0.1811,
      "step": 2382
    },
    {
      "epoch": 0.1851880634131178,
      "grad_norm": 0.5227019190788269,
      "learning_rate": 9.074059682934411e-06,
      "loss": 0.3919,
      "step": 2383
    },
    {
      "epoch": 0.18526577556729873,
      "grad_norm": 0.1853630691766739,
      "learning_rate": 9.073671122163508e-06,
      "loss": 0.0696,
      "step": 2384
    },
    {
      "epoch": 0.18534348772147963,
      "grad_norm": 0.2760547995567322,
      "learning_rate": 9.073282561392603e-06,
      "loss": 0.1967,
      "step": 2385
    },
    {
      "epoch": 0.18542119987566055,
      "grad_norm": 0.2918325960636139,
      "learning_rate": 9.072894000621698e-06,
      "loss": 0.3438,
      "step": 2386
    },
    {
      "epoch": 0.18549891202984148,
      "grad_norm": 0.28922751545906067,
      "learning_rate": 9.072505439850795e-06,
      "loss": 0.2995,
      "step": 2387
    },
    {
      "epoch": 0.18557662418402238,
      "grad_norm": 0.19373327493667603,
      "learning_rate": 9.072116879079888e-06,
      "loss": 0.055,
      "step": 2388
    },
    {
      "epoch": 0.1856543363382033,
      "grad_norm": 0.21159198880195618,
      "learning_rate": 9.071728318308984e-06,
      "loss": 0.0837,
      "step": 2389
    },
    {
      "epoch": 0.1857320484923842,
      "grad_norm": 0.15338295698165894,
      "learning_rate": 9.07133975753808e-06,
      "loss": 0.0485,
      "step": 2390
    },
    {
      "epoch": 0.18580976064656513,
      "grad_norm": 0.34193551540374756,
      "learning_rate": 9.070951196767174e-06,
      "loss": 0.5444,
      "step": 2391
    },
    {
      "epoch": 0.18588747280074602,
      "grad_norm": 0.5387575030326843,
      "learning_rate": 9.070562635996271e-06,
      "loss": 0.1824,
      "step": 2392
    },
    {
      "epoch": 0.18596518495492695,
      "grad_norm": 0.43604445457458496,
      "learning_rate": 9.070174075225366e-06,
      "loss": 0.1236,
      "step": 2393
    },
    {
      "epoch": 0.18604289710910787,
      "grad_norm": 0.2732410728931427,
      "learning_rate": 9.069785514454461e-06,
      "loss": 0.1192,
      "step": 2394
    },
    {
      "epoch": 0.18612060926328877,
      "grad_norm": 0.3242870569229126,
      "learning_rate": 9.069396953683557e-06,
      "loss": 0.169,
      "step": 2395
    },
    {
      "epoch": 0.1861983214174697,
      "grad_norm": 0.13703644275665283,
      "learning_rate": 9.069008392912652e-06,
      "loss": 0.0196,
      "step": 2396
    },
    {
      "epoch": 0.1862760335716506,
      "grad_norm": 0.20858623087406158,
      "learning_rate": 9.068619832141747e-06,
      "loss": 0.114,
      "step": 2397
    },
    {
      "epoch": 0.18635374572583152,
      "grad_norm": 0.4790242910385132,
      "learning_rate": 9.068231271370842e-06,
      "loss": 0.231,
      "step": 2398
    },
    {
      "epoch": 0.18643145788001245,
      "grad_norm": 0.5611975193023682,
      "learning_rate": 9.067842710599939e-06,
      "loss": 0.441,
      "step": 2399
    },
    {
      "epoch": 0.18650917003419334,
      "grad_norm": 0.015309872105717659,
      "learning_rate": 9.067454149829034e-06,
      "loss": 0.0065,
      "step": 2400
    },
    {
      "epoch": 0.18658688218837427,
      "grad_norm": 0.029690418392419815,
      "learning_rate": 9.067065589058129e-06,
      "loss": 0.0184,
      "step": 2401
    },
    {
      "epoch": 0.18666459434255517,
      "grad_norm": 0.1468675434589386,
      "learning_rate": 9.066677028287226e-06,
      "loss": 0.0323,
      "step": 2402
    },
    {
      "epoch": 0.1867423064967361,
      "grad_norm": 0.15700314939022064,
      "learning_rate": 9.06628846751632e-06,
      "loss": 0.0765,
      "step": 2403
    },
    {
      "epoch": 0.186820018650917,
      "grad_norm": 0.14839127659797668,
      "learning_rate": 9.065899906745415e-06,
      "loss": 0.1122,
      "step": 2404
    },
    {
      "epoch": 0.18689773080509792,
      "grad_norm": 0.3367871046066284,
      "learning_rate": 9.065511345974512e-06,
      "loss": 0.5615,
      "step": 2405
    },
    {
      "epoch": 0.18697544295927884,
      "grad_norm": 0.7388120889663696,
      "learning_rate": 9.065122785203605e-06,
      "loss": 0.2514,
      "step": 2406
    },
    {
      "epoch": 0.18705315511345974,
      "grad_norm": 0.32701894640922546,
      "learning_rate": 9.064734224432702e-06,
      "loss": 0.1244,
      "step": 2407
    },
    {
      "epoch": 0.18713086726764067,
      "grad_norm": 0.14967067539691925,
      "learning_rate": 9.064345663661797e-06,
      "loss": 0.0846,
      "step": 2408
    },
    {
      "epoch": 0.18720857942182156,
      "grad_norm": 0.05486588180065155,
      "learning_rate": 9.063957102890892e-06,
      "loss": 0.0324,
      "step": 2409
    },
    {
      "epoch": 0.1872862915760025,
      "grad_norm": 0.6391128897666931,
      "learning_rate": 9.063568542119989e-06,
      "loss": 0.8975,
      "step": 2410
    },
    {
      "epoch": 0.1873640037301834,
      "grad_norm": 0.7584705948829651,
      "learning_rate": 9.063179981349083e-06,
      "loss": 0.8239,
      "step": 2411
    },
    {
      "epoch": 0.1874417158843643,
      "grad_norm": 0.5752057433128357,
      "learning_rate": 9.062791420578178e-06,
      "loss": 0.0538,
      "step": 2412
    },
    {
      "epoch": 0.18751942803854524,
      "grad_norm": 0.1166321188211441,
      "learning_rate": 9.062402859807275e-06,
      "loss": 0.0764,
      "step": 2413
    },
    {
      "epoch": 0.18759714019272614,
      "grad_norm": 0.3374147415161133,
      "learning_rate": 9.06201429903637e-06,
      "loss": 0.2948,
      "step": 2414
    },
    {
      "epoch": 0.18767485234690706,
      "grad_norm": 0.3471263349056244,
      "learning_rate": 9.061625738265467e-06,
      "loss": 0.2684,
      "step": 2415
    },
    {
      "epoch": 0.18775256450108796,
      "grad_norm": 0.13160909712314606,
      "learning_rate": 9.06123717749456e-06,
      "loss": 0.0434,
      "step": 2416
    },
    {
      "epoch": 0.18783027665526889,
      "grad_norm": 0.24469421803951263,
      "learning_rate": 9.060848616723657e-06,
      "loss": 0.1119,
      "step": 2417
    },
    {
      "epoch": 0.1879079888094498,
      "grad_norm": 0.5690969824790955,
      "learning_rate": 9.060460055952752e-06,
      "loss": 0.2378,
      "step": 2418
    },
    {
      "epoch": 0.1879857009636307,
      "grad_norm": 0.3929186165332794,
      "learning_rate": 9.060071495181846e-06,
      "loss": 0.2558,
      "step": 2419
    },
    {
      "epoch": 0.18806341311781163,
      "grad_norm": 0.3580375015735626,
      "learning_rate": 9.059682934410943e-06,
      "loss": 0.2998,
      "step": 2420
    },
    {
      "epoch": 0.18814112527199253,
      "grad_norm": 0.6829167604446411,
      "learning_rate": 9.059294373640038e-06,
      "loss": 0.2743,
      "step": 2421
    },
    {
      "epoch": 0.18821883742617346,
      "grad_norm": 0.14861300587654114,
      "learning_rate": 9.058905812869133e-06,
      "loss": 0.0517,
      "step": 2422
    },
    {
      "epoch": 0.18829654958035436,
      "grad_norm": 0.34302273392677307,
      "learning_rate": 9.05851725209823e-06,
      "loss": 0.779,
      "step": 2423
    },
    {
      "epoch": 0.18837426173453528,
      "grad_norm": 0.04349001869559288,
      "learning_rate": 9.058128691327325e-06,
      "loss": 0.0334,
      "step": 2424
    },
    {
      "epoch": 0.1884519738887162,
      "grad_norm": 0.4244973659515381,
      "learning_rate": 9.05774013055642e-06,
      "loss": 0.0685,
      "step": 2425
    },
    {
      "epoch": 0.1885296860428971,
      "grad_norm": 0.05300835520029068,
      "learning_rate": 9.057351569785514e-06,
      "loss": 0.0189,
      "step": 2426
    },
    {
      "epoch": 0.18860739819707803,
      "grad_norm": 0.24238990247249603,
      "learning_rate": 9.056963009014611e-06,
      "loss": 0.1418,
      "step": 2427
    },
    {
      "epoch": 0.18868511035125893,
      "grad_norm": 0.2661239504814148,
      "learning_rate": 9.056574448243706e-06,
      "loss": 0.1391,
      "step": 2428
    },
    {
      "epoch": 0.18876282250543985,
      "grad_norm": 0.2416432499885559,
      "learning_rate": 9.056185887472801e-06,
      "loss": 0.1636,
      "step": 2429
    },
    {
      "epoch": 0.18884053465962075,
      "grad_norm": 0.3672143518924713,
      "learning_rate": 9.055797326701898e-06,
      "loss": 0.126,
      "step": 2430
    },
    {
      "epoch": 0.18891824681380168,
      "grad_norm": 0.4368913471698761,
      "learning_rate": 9.055408765930993e-06,
      "loss": 0.1898,
      "step": 2431
    },
    {
      "epoch": 0.1889959589679826,
      "grad_norm": 0.37852010130882263,
      "learning_rate": 9.055020205160088e-06,
      "loss": 0.649,
      "step": 2432
    },
    {
      "epoch": 0.1890736711221635,
      "grad_norm": 0.23340916633605957,
      "learning_rate": 9.054631644389184e-06,
      "loss": 0.1717,
      "step": 2433
    },
    {
      "epoch": 0.18915138327634443,
      "grad_norm": 0.43460771441459656,
      "learning_rate": 9.054243083618277e-06,
      "loss": 0.7394,
      "step": 2434
    },
    {
      "epoch": 0.18922909543052532,
      "grad_norm": 0.23955953121185303,
      "learning_rate": 9.053854522847374e-06,
      "loss": 0.1825,
      "step": 2435
    },
    {
      "epoch": 0.18930680758470625,
      "grad_norm": 0.19038406014442444,
      "learning_rate": 9.053465962076469e-06,
      "loss": 0.1043,
      "step": 2436
    },
    {
      "epoch": 0.18938451973888717,
      "grad_norm": 0.47958603501319885,
      "learning_rate": 9.053077401305564e-06,
      "loss": 0.6631,
      "step": 2437
    },
    {
      "epoch": 0.18946223189306807,
      "grad_norm": 0.49636808037757874,
      "learning_rate": 9.05268884053466e-06,
      "loss": 0.2267,
      "step": 2438
    },
    {
      "epoch": 0.189539944047249,
      "grad_norm": 0.881585955619812,
      "learning_rate": 9.052300279763756e-06,
      "loss": 0.8639,
      "step": 2439
    },
    {
      "epoch": 0.1896176562014299,
      "grad_norm": 0.45436182618141174,
      "learning_rate": 9.05191171899285e-06,
      "loss": 0.1909,
      "step": 2440
    },
    {
      "epoch": 0.18969536835561082,
      "grad_norm": 0.5020185112953186,
      "learning_rate": 9.051523158221947e-06,
      "loss": 0.3338,
      "step": 2441
    },
    {
      "epoch": 0.18977308050979172,
      "grad_norm": 0.14727447926998138,
      "learning_rate": 9.051134597451042e-06,
      "loss": 0.0377,
      "step": 2442
    },
    {
      "epoch": 0.18985079266397265,
      "grad_norm": 0.309489905834198,
      "learning_rate": 9.050746036680137e-06,
      "loss": 0.3619,
      "step": 2443
    },
    {
      "epoch": 0.18992850481815357,
      "grad_norm": 0.1758011430501938,
      "learning_rate": 9.050357475909232e-06,
      "loss": 0.1102,
      "step": 2444
    },
    {
      "epoch": 0.19000621697233447,
      "grad_norm": 0.4658845365047455,
      "learning_rate": 9.049968915138329e-06,
      "loss": 0.174,
      "step": 2445
    },
    {
      "epoch": 0.1900839291265154,
      "grad_norm": 0.1856066733598709,
      "learning_rate": 9.049580354367424e-06,
      "loss": 0.021,
      "step": 2446
    },
    {
      "epoch": 0.1901616412806963,
      "grad_norm": 0.5522265434265137,
      "learning_rate": 9.049191793596519e-06,
      "loss": 0.4661,
      "step": 2447
    },
    {
      "epoch": 0.19023935343487722,
      "grad_norm": 0.5537559390068054,
      "learning_rate": 9.048803232825615e-06,
      "loss": 0.1857,
      "step": 2448
    },
    {
      "epoch": 0.19031706558905812,
      "grad_norm": 4.596399307250977,
      "learning_rate": 9.04841467205471e-06,
      "loss": 1.4512,
      "step": 2449
    },
    {
      "epoch": 0.19039477774323904,
      "grad_norm": 0.3513728380203247,
      "learning_rate": 9.048026111283805e-06,
      "loss": 0.295,
      "step": 2450
    },
    {
      "epoch": 0.19047248989741997,
      "grad_norm": 0.20726566016674042,
      "learning_rate": 9.047637550512902e-06,
      "loss": 0.0826,
      "step": 2451
    },
    {
      "epoch": 0.19055020205160086,
      "grad_norm": 0.3652939796447754,
      "learning_rate": 9.047248989741997e-06,
      "loss": 0.2485,
      "step": 2452
    },
    {
      "epoch": 0.1906279142057818,
      "grad_norm": 0.2564517855644226,
      "learning_rate": 9.046860428971092e-06,
      "loss": 0.187,
      "step": 2453
    },
    {
      "epoch": 0.1907056263599627,
      "grad_norm": 0.38285067677497864,
      "learning_rate": 9.046471868200187e-06,
      "loss": 0.1602,
      "step": 2454
    },
    {
      "epoch": 0.1907833385141436,
      "grad_norm": 0.23426130414009094,
      "learning_rate": 9.046083307429283e-06,
      "loss": 0.0797,
      "step": 2455
    },
    {
      "epoch": 0.19086105066832454,
      "grad_norm": 0.18483799695968628,
      "learning_rate": 9.045694746658378e-06,
      "loss": 0.0854,
      "step": 2456
    },
    {
      "epoch": 0.19093876282250544,
      "grad_norm": 0.41384488344192505,
      "learning_rate": 9.045306185887473e-06,
      "loss": 0.1342,
      "step": 2457
    },
    {
      "epoch": 0.19101647497668636,
      "grad_norm": 0.2071608603000641,
      "learning_rate": 9.04491762511657e-06,
      "loss": 0.0796,
      "step": 2458
    },
    {
      "epoch": 0.19109418713086726,
      "grad_norm": 0.2804660201072693,
      "learning_rate": 9.044529064345665e-06,
      "loss": 0.146,
      "step": 2459
    },
    {
      "epoch": 0.19117189928504819,
      "grad_norm": 0.20828206837177277,
      "learning_rate": 9.04414050357476e-06,
      "loss": 0.0755,
      "step": 2460
    },
    {
      "epoch": 0.19124961143922908,
      "grad_norm": 0.3147679567337036,
      "learning_rate": 9.043751942803856e-06,
      "loss": 0.1468,
      "step": 2461
    },
    {
      "epoch": 0.19132732359341,
      "grad_norm": 0.9122248291969299,
      "learning_rate": 9.04336338203295e-06,
      "loss": 0.3416,
      "step": 2462
    },
    {
      "epoch": 0.19140503574759093,
      "grad_norm": 0.3186103403568268,
      "learning_rate": 9.042974821262046e-06,
      "loss": 0.3145,
      "step": 2463
    },
    {
      "epoch": 0.19148274790177183,
      "grad_norm": 0.2701641321182251,
      "learning_rate": 9.042586260491141e-06,
      "loss": 0.1701,
      "step": 2464
    },
    {
      "epoch": 0.19156046005595276,
      "grad_norm": 1.621051549911499,
      "learning_rate": 9.042197699720236e-06,
      "loss": 0.1482,
      "step": 2465
    },
    {
      "epoch": 0.19163817221013366,
      "grad_norm": 0.42727118730545044,
      "learning_rate": 9.041809138949333e-06,
      "loss": 0.1914,
      "step": 2466
    },
    {
      "epoch": 0.19171588436431458,
      "grad_norm": 0.4288618564605713,
      "learning_rate": 9.041420578178428e-06,
      "loss": 0.1224,
      "step": 2467
    },
    {
      "epoch": 0.19179359651849548,
      "grad_norm": 0.22791104018688202,
      "learning_rate": 9.041032017407523e-06,
      "loss": 0.1195,
      "step": 2468
    },
    {
      "epoch": 0.1918713086726764,
      "grad_norm": 1.078535795211792,
      "learning_rate": 9.04064345663662e-06,
      "loss": 0.2871,
      "step": 2469
    },
    {
      "epoch": 0.19194902082685733,
      "grad_norm": 0.32769376039505005,
      "learning_rate": 9.040254895865714e-06,
      "loss": 0.1361,
      "step": 2470
    },
    {
      "epoch": 0.19202673298103823,
      "grad_norm": 0.180190309882164,
      "learning_rate": 9.03986633509481e-06,
      "loss": 0.0473,
      "step": 2471
    },
    {
      "epoch": 0.19210444513521915,
      "grad_norm": 0.2286665141582489,
      "learning_rate": 9.039477774323904e-06,
      "loss": 0.0956,
      "step": 2472
    },
    {
      "epoch": 0.19218215728940005,
      "grad_norm": 0.31105005741119385,
      "learning_rate": 9.039089213553e-06,
      "loss": 0.1935,
      "step": 2473
    },
    {
      "epoch": 0.19225986944358098,
      "grad_norm": 0.6965081691741943,
      "learning_rate": 9.038700652782096e-06,
      "loss": 0.4757,
      "step": 2474
    },
    {
      "epoch": 0.1923375815977619,
      "grad_norm": 0.21367976069450378,
      "learning_rate": 9.03831209201119e-06,
      "loss": 0.2396,
      "step": 2475
    },
    {
      "epoch": 0.1924152937519428,
      "grad_norm": 0.2864733934402466,
      "learning_rate": 9.037923531240287e-06,
      "loss": 0.1604,
      "step": 2476
    },
    {
      "epoch": 0.19249300590612373,
      "grad_norm": 0.15780708193778992,
      "learning_rate": 9.037534970469382e-06,
      "loss": 0.2131,
      "step": 2477
    },
    {
      "epoch": 0.19257071806030462,
      "grad_norm": 0.33312079310417175,
      "learning_rate": 9.037146409698477e-06,
      "loss": 0.1194,
      "step": 2478
    },
    {
      "epoch": 0.19264843021448555,
      "grad_norm": 0.4551585912704468,
      "learning_rate": 9.036757848927574e-06,
      "loss": 0.2104,
      "step": 2479
    },
    {
      "epoch": 0.19272614236866645,
      "grad_norm": 0.16112539172172546,
      "learning_rate": 9.036369288156669e-06,
      "loss": 0.0281,
      "step": 2480
    },
    {
      "epoch": 0.19280385452284737,
      "grad_norm": 0.3390618562698364,
      "learning_rate": 9.035980727385764e-06,
      "loss": 0.2312,
      "step": 2481
    },
    {
      "epoch": 0.1928815666770283,
      "grad_norm": 0.19782397150993347,
      "learning_rate": 9.035592166614859e-06,
      "loss": 0.1579,
      "step": 2482
    },
    {
      "epoch": 0.1929592788312092,
      "grad_norm": 0.5278567671775818,
      "learning_rate": 9.035203605843955e-06,
      "loss": 0.285,
      "step": 2483
    },
    {
      "epoch": 0.19303699098539012,
      "grad_norm": 0.5455343127250671,
      "learning_rate": 9.03481504507305e-06,
      "loss": 0.1331,
      "step": 2484
    },
    {
      "epoch": 0.19311470313957102,
      "grad_norm": 0.279655784368515,
      "learning_rate": 9.034426484302145e-06,
      "loss": 0.2449,
      "step": 2485
    },
    {
      "epoch": 0.19319241529375195,
      "grad_norm": 0.29986172914505005,
      "learning_rate": 9.034037923531242e-06,
      "loss": 0.1711,
      "step": 2486
    },
    {
      "epoch": 0.19327012744793284,
      "grad_norm": 0.7695366144180298,
      "learning_rate": 9.033649362760337e-06,
      "loss": 0.341,
      "step": 2487
    },
    {
      "epoch": 0.19334783960211377,
      "grad_norm": 0.24869368970394135,
      "learning_rate": 9.033260801989432e-06,
      "loss": 0.2707,
      "step": 2488
    },
    {
      "epoch": 0.1934255517562947,
      "grad_norm": 0.2786684036254883,
      "learning_rate": 9.032872241218529e-06,
      "loss": 0.1218,
      "step": 2489
    },
    {
      "epoch": 0.1935032639104756,
      "grad_norm": 0.16075584292411804,
      "learning_rate": 9.032483680447622e-06,
      "loss": 0.0433,
      "step": 2490
    },
    {
      "epoch": 0.19358097606465652,
      "grad_norm": 0.3471161127090454,
      "learning_rate": 9.032095119676718e-06,
      "loss": 0.1356,
      "step": 2491
    },
    {
      "epoch": 0.19365868821883742,
      "grad_norm": 0.2991296052932739,
      "learning_rate": 9.031706558905813e-06,
      "loss": 0.1712,
      "step": 2492
    },
    {
      "epoch": 0.19373640037301834,
      "grad_norm": 0.3162631094455719,
      "learning_rate": 9.031317998134908e-06,
      "loss": 0.235,
      "step": 2493
    },
    {
      "epoch": 0.19381411252719927,
      "grad_norm": 0.8176737427711487,
      "learning_rate": 9.030929437364005e-06,
      "loss": 0.404,
      "step": 2494
    },
    {
      "epoch": 0.19389182468138016,
      "grad_norm": 0.4941086173057556,
      "learning_rate": 9.0305408765931e-06,
      "loss": 0.1808,
      "step": 2495
    },
    {
      "epoch": 0.1939695368355611,
      "grad_norm": 0.5655688047409058,
      "learning_rate": 9.030152315822195e-06,
      "loss": 0.2223,
      "step": 2496
    },
    {
      "epoch": 0.194047248989742,
      "grad_norm": 0.12590070068836212,
      "learning_rate": 9.029763755051291e-06,
      "loss": 0.0456,
      "step": 2497
    },
    {
      "epoch": 0.19412496114392291,
      "grad_norm": 0.0710759311914444,
      "learning_rate": 9.029375194280386e-06,
      "loss": 0.0298,
      "step": 2498
    },
    {
      "epoch": 0.1942026732981038,
      "grad_norm": 0.35682883858680725,
      "learning_rate": 9.028986633509481e-06,
      "loss": 0.1524,
      "step": 2499
    },
    {
      "epoch": 0.19428038545228474,
      "grad_norm": 0.3777056336402893,
      "learning_rate": 9.028598072738576e-06,
      "loss": 0.1767,
      "step": 2500
    },
    {
      "epoch": 0.19435809760646566,
      "grad_norm": 0.2579096853733063,
      "learning_rate": 9.028209511967673e-06,
      "loss": 0.1294,
      "step": 2501
    },
    {
      "epoch": 0.19443580976064656,
      "grad_norm": 0.2223297357559204,
      "learning_rate": 9.027820951196768e-06,
      "loss": 0.1011,
      "step": 2502
    },
    {
      "epoch": 0.1945135219148275,
      "grad_norm": 0.1557760238647461,
      "learning_rate": 9.027432390425863e-06,
      "loss": 0.0936,
      "step": 2503
    },
    {
      "epoch": 0.19459123406900838,
      "grad_norm": 0.2995132505893707,
      "learning_rate": 9.02704382965496e-06,
      "loss": 0.1594,
      "step": 2504
    },
    {
      "epoch": 0.1946689462231893,
      "grad_norm": 0.06629060208797455,
      "learning_rate": 9.026655268884054e-06,
      "loss": 0.0447,
      "step": 2505
    },
    {
      "epoch": 0.1947466583773702,
      "grad_norm": 0.07700177282094955,
      "learning_rate": 9.02626670811315e-06,
      "loss": 0.0193,
      "step": 2506
    },
    {
      "epoch": 0.19482437053155113,
      "grad_norm": 0.04286614805459976,
      "learning_rate": 9.025878147342244e-06,
      "loss": 0.0159,
      "step": 2507
    },
    {
      "epoch": 0.19490208268573206,
      "grad_norm": 0.2816544473171234,
      "learning_rate": 9.025489586571341e-06,
      "loss": 0.0535,
      "step": 2508
    },
    {
      "epoch": 0.19497979483991296,
      "grad_norm": 0.40745803713798523,
      "learning_rate": 9.025101025800436e-06,
      "loss": 0.1249,
      "step": 2509
    },
    {
      "epoch": 0.19505750699409388,
      "grad_norm": 0.5781682729721069,
      "learning_rate": 9.024712465029531e-06,
      "loss": 0.3723,
      "step": 2510
    },
    {
      "epoch": 0.19513521914827478,
      "grad_norm": 0.08174534142017365,
      "learning_rate": 9.024323904258628e-06,
      "loss": 0.0437,
      "step": 2511
    },
    {
      "epoch": 0.1952129313024557,
      "grad_norm": 0.25378549098968506,
      "learning_rate": 9.023935343487723e-06,
      "loss": 0.1919,
      "step": 2512
    },
    {
      "epoch": 0.19529064345663663,
      "grad_norm": 0.2905593812465668,
      "learning_rate": 9.023546782716817e-06,
      "loss": 0.1089,
      "step": 2513
    },
    {
      "epoch": 0.19536835561081753,
      "grad_norm": 0.16816015541553497,
      "learning_rate": 9.023158221945914e-06,
      "loss": 0.0582,
      "step": 2514
    },
    {
      "epoch": 0.19544606776499845,
      "grad_norm": 0.1425361931324005,
      "learning_rate": 9.022769661175007e-06,
      "loss": 0.0542,
      "step": 2515
    },
    {
      "epoch": 0.19552377991917935,
      "grad_norm": 0.27348434925079346,
      "learning_rate": 9.022381100404104e-06,
      "loss": 0.1812,
      "step": 2516
    },
    {
      "epoch": 0.19560149207336028,
      "grad_norm": 0.12992674112319946,
      "learning_rate": 9.021992539633199e-06,
      "loss": 0.0421,
      "step": 2517
    },
    {
      "epoch": 0.19567920422754118,
      "grad_norm": 0.20778487622737885,
      "learning_rate": 9.021603978862294e-06,
      "loss": 0.1264,
      "step": 2518
    },
    {
      "epoch": 0.1957569163817221,
      "grad_norm": 0.08561256527900696,
      "learning_rate": 9.02121541809139e-06,
      "loss": 0.0217,
      "step": 2519
    },
    {
      "epoch": 0.19583462853590303,
      "grad_norm": 0.34609928727149963,
      "learning_rate": 9.020826857320486e-06,
      "loss": 0.2759,
      "step": 2520
    },
    {
      "epoch": 0.19591234069008392,
      "grad_norm": 0.2454015612602234,
      "learning_rate": 9.02043829654958e-06,
      "loss": 0.0636,
      "step": 2521
    },
    {
      "epoch": 0.19599005284426485,
      "grad_norm": 0.2991766035556793,
      "learning_rate": 9.020049735778677e-06,
      "loss": 0.187,
      "step": 2522
    },
    {
      "epoch": 0.19606776499844575,
      "grad_norm": 0.5456345081329346,
      "learning_rate": 9.019661175007772e-06,
      "loss": 0.2576,
      "step": 2523
    },
    {
      "epoch": 0.19614547715262667,
      "grad_norm": 0.32841360569000244,
      "learning_rate": 9.019272614236867e-06,
      "loss": 0.3966,
      "step": 2524
    },
    {
      "epoch": 0.19622318930680757,
      "grad_norm": 0.1111655980348587,
      "learning_rate": 9.018884053465962e-06,
      "loss": 0.0452,
      "step": 2525
    },
    {
      "epoch": 0.1963009014609885,
      "grad_norm": 0.35011160373687744,
      "learning_rate": 9.018495492695059e-06,
      "loss": 0.0916,
      "step": 2526
    },
    {
      "epoch": 0.19637861361516942,
      "grad_norm": 0.12258052080869675,
      "learning_rate": 9.018106931924154e-06,
      "loss": 0.0805,
      "step": 2527
    },
    {
      "epoch": 0.19645632576935032,
      "grad_norm": 0.3515639305114746,
      "learning_rate": 9.017718371153248e-06,
      "loss": 0.1617,
      "step": 2528
    },
    {
      "epoch": 0.19653403792353125,
      "grad_norm": 0.2800404727458954,
      "learning_rate": 9.017329810382345e-06,
      "loss": 0.0593,
      "step": 2529
    },
    {
      "epoch": 0.19661175007771214,
      "grad_norm": 0.3405412435531616,
      "learning_rate": 9.01694124961144e-06,
      "loss": 0.2573,
      "step": 2530
    },
    {
      "epoch": 0.19668946223189307,
      "grad_norm": 0.21487918496131897,
      "learning_rate": 9.016552688840535e-06,
      "loss": 0.1045,
      "step": 2531
    },
    {
      "epoch": 0.196767174386074,
      "grad_norm": 0.152665913105011,
      "learning_rate": 9.016164128069632e-06,
      "loss": 0.0618,
      "step": 2532
    },
    {
      "epoch": 0.1968448865402549,
      "grad_norm": 0.4593096971511841,
      "learning_rate": 9.015775567298725e-06,
      "loss": 0.2292,
      "step": 2533
    },
    {
      "epoch": 0.19692259869443582,
      "grad_norm": 0.3103533387184143,
      "learning_rate": 9.015387006527822e-06,
      "loss": 0.2431,
      "step": 2534
    },
    {
      "epoch": 0.19700031084861672,
      "grad_norm": 0.49208977818489075,
      "learning_rate": 9.014998445756917e-06,
      "loss": 0.1911,
      "step": 2535
    },
    {
      "epoch": 0.19707802300279764,
      "grad_norm": 0.26830366253852844,
      "learning_rate": 9.014609884986013e-06,
      "loss": 0.1493,
      "step": 2536
    },
    {
      "epoch": 0.19715573515697854,
      "grad_norm": 0.30857858061790466,
      "learning_rate": 9.014221324215108e-06,
      "loss": 0.1185,
      "step": 2537
    },
    {
      "epoch": 0.19723344731115947,
      "grad_norm": 0.1705373227596283,
      "learning_rate": 9.013832763444203e-06,
      "loss": 0.0329,
      "step": 2538
    },
    {
      "epoch": 0.1973111594653404,
      "grad_norm": 0.0741996169090271,
      "learning_rate": 9.0134442026733e-06,
      "loss": 0.0277,
      "step": 2539
    },
    {
      "epoch": 0.1973888716195213,
      "grad_norm": 0.09614101052284241,
      "learning_rate": 9.013055641902395e-06,
      "loss": 0.0583,
      "step": 2540
    },
    {
      "epoch": 0.19746658377370221,
      "grad_norm": 0.22544090449810028,
      "learning_rate": 9.01266708113149e-06,
      "loss": 0.0778,
      "step": 2541
    },
    {
      "epoch": 0.1975442959278831,
      "grad_norm": 0.12986962497234344,
      "learning_rate": 9.012278520360586e-06,
      "loss": 0.1129,
      "step": 2542
    },
    {
      "epoch": 0.19762200808206404,
      "grad_norm": 0.5075795650482178,
      "learning_rate": 9.01188995958968e-06,
      "loss": 0.6787,
      "step": 2543
    },
    {
      "epoch": 0.19769972023624494,
      "grad_norm": 0.26200544834136963,
      "learning_rate": 9.011501398818776e-06,
      "loss": 0.1405,
      "step": 2544
    },
    {
      "epoch": 0.19777743239042586,
      "grad_norm": 0.4211278259754181,
      "learning_rate": 9.011112838047871e-06,
      "loss": 0.2427,
      "step": 2545
    },
    {
      "epoch": 0.1978551445446068,
      "grad_norm": 0.15581074357032776,
      "learning_rate": 9.010724277276966e-06,
      "loss": 0.1276,
      "step": 2546
    },
    {
      "epoch": 0.19793285669878768,
      "grad_norm": 0.32891708612442017,
      "learning_rate": 9.010335716506063e-06,
      "loss": 0.1347,
      "step": 2547
    },
    {
      "epoch": 0.1980105688529686,
      "grad_norm": 0.11501327157020569,
      "learning_rate": 9.009947155735158e-06,
      "loss": 0.0641,
      "step": 2548
    },
    {
      "epoch": 0.1980882810071495,
      "grad_norm": 0.10103679448366165,
      "learning_rate": 9.009558594964253e-06,
      "loss": 0.0099,
      "step": 2549
    },
    {
      "epoch": 0.19816599316133043,
      "grad_norm": 0.29648464918136597,
      "learning_rate": 9.00917003419335e-06,
      "loss": 0.143,
      "step": 2550
    },
    {
      "epoch": 0.19824370531551136,
      "grad_norm": 0.2128811776638031,
      "learning_rate": 9.008781473422444e-06,
      "loss": 0.139,
      "step": 2551
    },
    {
      "epoch": 0.19832141746969226,
      "grad_norm": 0.2609002888202667,
      "learning_rate": 9.008392912651539e-06,
      "loss": 0.3153,
      "step": 2552
    },
    {
      "epoch": 0.19839912962387318,
      "grad_norm": 0.2825939655303955,
      "learning_rate": 9.008004351880634e-06,
      "loss": 0.2094,
      "step": 2553
    },
    {
      "epoch": 0.19847684177805408,
      "grad_norm": 0.20702335238456726,
      "learning_rate": 9.00761579110973e-06,
      "loss": 0.1056,
      "step": 2554
    },
    {
      "epoch": 0.198554553932235,
      "grad_norm": 0.16146183013916016,
      "learning_rate": 9.007227230338826e-06,
      "loss": 0.0358,
      "step": 2555
    },
    {
      "epoch": 0.1986322660864159,
      "grad_norm": 0.5788896679878235,
      "learning_rate": 9.00683866956792e-06,
      "loss": 0.3568,
      "step": 2556
    },
    {
      "epoch": 0.19870997824059683,
      "grad_norm": 0.09936308115720749,
      "learning_rate": 9.006450108797017e-06,
      "loss": 0.008,
      "step": 2557
    },
    {
      "epoch": 0.19878769039477776,
      "grad_norm": 0.3380591869354248,
      "learning_rate": 9.006061548026112e-06,
      "loss": 0.244,
      "step": 2558
    },
    {
      "epoch": 0.19886540254895865,
      "grad_norm": 0.2040485441684723,
      "learning_rate": 9.005672987255207e-06,
      "loss": 0.196,
      "step": 2559
    },
    {
      "epoch": 0.19894311470313958,
      "grad_norm": 0.36537203192710876,
      "learning_rate": 9.005284426484304e-06,
      "loss": 0.3549,
      "step": 2560
    },
    {
      "epoch": 0.19902082685732048,
      "grad_norm": 0.419681191444397,
      "learning_rate": 9.004895865713397e-06,
      "loss": 0.5235,
      "step": 2561
    },
    {
      "epoch": 0.1990985390115014,
      "grad_norm": 0.731323778629303,
      "learning_rate": 9.004507304942494e-06,
      "loss": 0.2529,
      "step": 2562
    },
    {
      "epoch": 0.1991762511656823,
      "grad_norm": 0.1404866874217987,
      "learning_rate": 9.004118744171589e-06,
      "loss": 0.1208,
      "step": 2563
    },
    {
      "epoch": 0.19925396331986323,
      "grad_norm": 0.3250691592693329,
      "learning_rate": 9.003730183400684e-06,
      "loss": 0.4866,
      "step": 2564
    },
    {
      "epoch": 0.19933167547404415,
      "grad_norm": 0.3296470642089844,
      "learning_rate": 9.00334162262978e-06,
      "loss": 0.1767,
      "step": 2565
    },
    {
      "epoch": 0.19940938762822505,
      "grad_norm": 0.42576584219932556,
      "learning_rate": 9.002953061858875e-06,
      "loss": 0.173,
      "step": 2566
    },
    {
      "epoch": 0.19948709978240597,
      "grad_norm": 0.14028210937976837,
      "learning_rate": 9.002564501087972e-06,
      "loss": 0.0352,
      "step": 2567
    },
    {
      "epoch": 0.19956481193658687,
      "grad_norm": 0.15643192827701569,
      "learning_rate": 9.002175940317067e-06,
      "loss": 0.1604,
      "step": 2568
    },
    {
      "epoch": 0.1996425240907678,
      "grad_norm": 0.2229585498571396,
      "learning_rate": 9.001787379546162e-06,
      "loss": 0.0663,
      "step": 2569
    },
    {
      "epoch": 0.19972023624494872,
      "grad_norm": 0.2592657506465912,
      "learning_rate": 9.001398818775258e-06,
      "loss": 0.1392,
      "step": 2570
    },
    {
      "epoch": 0.19979794839912962,
      "grad_norm": 0.279106467962265,
      "learning_rate": 9.001010258004352e-06,
      "loss": 0.2089,
      "step": 2571
    },
    {
      "epoch": 0.19987566055331055,
      "grad_norm": 0.4462115168571472,
      "learning_rate": 9.000621697233448e-06,
      "loss": 0.2184,
      "step": 2572
    },
    {
      "epoch": 0.19995337270749144,
      "grad_norm": 0.5122783780097961,
      "learning_rate": 9.000233136462543e-06,
      "loss": 0.378,
      "step": 2573
    },
    {
      "epoch": 0.20003108486167237,
      "grad_norm": 0.30072543025016785,
      "learning_rate": 8.999844575691638e-06,
      "loss": 0.2566,
      "step": 2574
    },
    {
      "epoch": 0.20010879701585327,
      "grad_norm": 0.3400286138057709,
      "learning_rate": 8.999456014920735e-06,
      "loss": 0.1868,
      "step": 2575
    },
    {
      "epoch": 0.2001865091700342,
      "grad_norm": 0.05811328813433647,
      "learning_rate": 8.99906745414983e-06,
      "loss": 0.0127,
      "step": 2576
    },
    {
      "epoch": 0.20026422132421512,
      "grad_norm": 0.1691545993089676,
      "learning_rate": 8.998678893378925e-06,
      "loss": 0.0876,
      "step": 2577
    },
    {
      "epoch": 0.20034193347839602,
      "grad_norm": 0.725536048412323,
      "learning_rate": 8.998290332608021e-06,
      "loss": 0.1916,
      "step": 2578
    },
    {
      "epoch": 0.20041964563257694,
      "grad_norm": 0.138086199760437,
      "learning_rate": 8.997901771837116e-06,
      "loss": 0.05,
      "step": 2579
    },
    {
      "epoch": 0.20049735778675784,
      "grad_norm": 0.5615873336791992,
      "learning_rate": 8.997513211066211e-06,
      "loss": 0.3279,
      "step": 2580
    },
    {
      "epoch": 0.20057506994093877,
      "grad_norm": 0.34524258971214294,
      "learning_rate": 8.997124650295306e-06,
      "loss": 0.3601,
      "step": 2581
    },
    {
      "epoch": 0.20065278209511966,
      "grad_norm": 0.7523316144943237,
      "learning_rate": 8.996736089524403e-06,
      "loss": 0.749,
      "step": 2582
    },
    {
      "epoch": 0.2007304942493006,
      "grad_norm": 0.0803581029176712,
      "learning_rate": 8.996347528753498e-06,
      "loss": 0.0216,
      "step": 2583
    },
    {
      "epoch": 0.20080820640348152,
      "grad_norm": 0.33993634581565857,
      "learning_rate": 8.995958967982593e-06,
      "loss": 0.196,
      "step": 2584
    },
    {
      "epoch": 0.2008859185576624,
      "grad_norm": 0.4035882353782654,
      "learning_rate": 8.99557040721169e-06,
      "loss": 0.3264,
      "step": 2585
    },
    {
      "epoch": 0.20096363071184334,
      "grad_norm": 0.048758432269096375,
      "learning_rate": 8.995181846440784e-06,
      "loss": 0.0178,
      "step": 2586
    },
    {
      "epoch": 0.20104134286602424,
      "grad_norm": 0.16454418003559113,
      "learning_rate": 8.99479328566988e-06,
      "loss": 0.1025,
      "step": 2587
    },
    {
      "epoch": 0.20111905502020516,
      "grad_norm": 0.17527782917022705,
      "learning_rate": 8.994404724898976e-06,
      "loss": 0.1689,
      "step": 2588
    },
    {
      "epoch": 0.2011967671743861,
      "grad_norm": 0.1345769762992859,
      "learning_rate": 8.99401616412807e-06,
      "loss": 0.0344,
      "step": 2589
    },
    {
      "epoch": 0.20127447932856699,
      "grad_norm": 0.6088166832923889,
      "learning_rate": 8.993627603357166e-06,
      "loss": 0.5253,
      "step": 2590
    },
    {
      "epoch": 0.2013521914827479,
      "grad_norm": 0.15342922508716583,
      "learning_rate": 8.99323904258626e-06,
      "loss": 0.0627,
      "step": 2591
    },
    {
      "epoch": 0.2014299036369288,
      "grad_norm": 0.4600609838962555,
      "learning_rate": 8.992850481815356e-06,
      "loss": 0.2571,
      "step": 2592
    },
    {
      "epoch": 0.20150761579110973,
      "grad_norm": 0.16355066001415253,
      "learning_rate": 8.992461921044452e-06,
      "loss": 0.0993,
      "step": 2593
    },
    {
      "epoch": 0.20158532794529063,
      "grad_norm": 0.31387728452682495,
      "learning_rate": 8.992073360273547e-06,
      "loss": 0.2012,
      "step": 2594
    },
    {
      "epoch": 0.20166304009947156,
      "grad_norm": 0.1636538952589035,
      "learning_rate": 8.991684799502644e-06,
      "loss": 0.1211,
      "step": 2595
    },
    {
      "epoch": 0.20174075225365248,
      "grad_norm": 0.040661755949258804,
      "learning_rate": 8.991296238731739e-06,
      "loss": 0.004,
      "step": 2596
    },
    {
      "epoch": 0.20181846440783338,
      "grad_norm": 0.276142418384552,
      "learning_rate": 8.990907677960834e-06,
      "loss": 0.1463,
      "step": 2597
    },
    {
      "epoch": 0.2018961765620143,
      "grad_norm": 0.5799576640129089,
      "learning_rate": 8.99051911718993e-06,
      "loss": 0.1229,
      "step": 2598
    },
    {
      "epoch": 0.2019738887161952,
      "grad_norm": 0.40063896775245667,
      "learning_rate": 8.990130556419024e-06,
      "loss": 0.2477,
      "step": 2599
    },
    {
      "epoch": 0.20205160087037613,
      "grad_norm": 0.3551604449748993,
      "learning_rate": 8.98974199564812e-06,
      "loss": 0.1919,
      "step": 2600
    },
    {
      "epoch": 0.20212931302455703,
      "grad_norm": 0.18364672362804413,
      "learning_rate": 8.989353434877215e-06,
      "loss": 0.1508,
      "step": 2601
    },
    {
      "epoch": 0.20220702517873795,
      "grad_norm": 0.1207309365272522,
      "learning_rate": 8.98896487410631e-06,
      "loss": 0.0228,
      "step": 2602
    },
    {
      "epoch": 0.20228473733291888,
      "grad_norm": 0.3214586079120636,
      "learning_rate": 8.988576313335407e-06,
      "loss": 0.0627,
      "step": 2603
    },
    {
      "epoch": 0.20236244948709978,
      "grad_norm": 0.0991767942905426,
      "learning_rate": 8.988187752564502e-06,
      "loss": 0.0168,
      "step": 2604
    },
    {
      "epoch": 0.2024401616412807,
      "grad_norm": 0.1669052541255951,
      "learning_rate": 8.987799191793597e-06,
      "loss": 0.0498,
      "step": 2605
    },
    {
      "epoch": 0.2025178737954616,
      "grad_norm": 0.2924916446208954,
      "learning_rate": 8.987410631022694e-06,
      "loss": 0.1595,
      "step": 2606
    },
    {
      "epoch": 0.20259558594964253,
      "grad_norm": 0.15926320850849152,
      "learning_rate": 8.987022070251788e-06,
      "loss": 0.05,
      "step": 2607
    },
    {
      "epoch": 0.20267329810382345,
      "grad_norm": 0.24779146909713745,
      "learning_rate": 8.986633509480883e-06,
      "loss": 0.1241,
      "step": 2608
    },
    {
      "epoch": 0.20275101025800435,
      "grad_norm": 0.3077913224697113,
      "learning_rate": 8.986244948709978e-06,
      "loss": 0.1173,
      "step": 2609
    },
    {
      "epoch": 0.20282872241218527,
      "grad_norm": 0.33095046877861023,
      "learning_rate": 8.985856387939075e-06,
      "loss": 0.0821,
      "step": 2610
    },
    {
      "epoch": 0.20290643456636617,
      "grad_norm": 0.10993720591068268,
      "learning_rate": 8.98546782716817e-06,
      "loss": 0.0322,
      "step": 2611
    },
    {
      "epoch": 0.2029841467205471,
      "grad_norm": 0.22425223886966705,
      "learning_rate": 8.985079266397265e-06,
      "loss": 0.0552,
      "step": 2612
    },
    {
      "epoch": 0.203061858874728,
      "grad_norm": 0.36837145686149597,
      "learning_rate": 8.984690705626362e-06,
      "loss": 0.6106,
      "step": 2613
    },
    {
      "epoch": 0.20313957102890892,
      "grad_norm": 0.4005891680717468,
      "learning_rate": 8.984302144855457e-06,
      "loss": 0.3683,
      "step": 2614
    },
    {
      "epoch": 0.20321728318308985,
      "grad_norm": 0.8145164847373962,
      "learning_rate": 8.983913584084551e-06,
      "loss": 0.8422,
      "step": 2615
    },
    {
      "epoch": 0.20329499533727075,
      "grad_norm": 0.18141062557697296,
      "learning_rate": 8.983525023313648e-06,
      "loss": 0.0693,
      "step": 2616
    },
    {
      "epoch": 0.20337270749145167,
      "grad_norm": 0.27380672097206116,
      "learning_rate": 8.983136462542741e-06,
      "loss": 0.1303,
      "step": 2617
    },
    {
      "epoch": 0.20345041964563257,
      "grad_norm": 0.09457610547542572,
      "learning_rate": 8.982747901771838e-06,
      "loss": 0.0256,
      "step": 2618
    },
    {
      "epoch": 0.2035281317998135,
      "grad_norm": 0.15289820730686188,
      "learning_rate": 8.982359341000933e-06,
      "loss": 0.0255,
      "step": 2619
    },
    {
      "epoch": 0.2036058439539944,
      "grad_norm": 0.12510834634304047,
      "learning_rate": 8.981970780230028e-06,
      "loss": 0.0834,
      "step": 2620
    },
    {
      "epoch": 0.20368355610817532,
      "grad_norm": 0.3315899968147278,
      "learning_rate": 8.981582219459125e-06,
      "loss": 0.0788,
      "step": 2621
    },
    {
      "epoch": 0.20376126826235624,
      "grad_norm": 0.19079378247261047,
      "learning_rate": 8.98119365868822e-06,
      "loss": 0.0842,
      "step": 2622
    },
    {
      "epoch": 0.20383898041653714,
      "grad_norm": 0.06541573256254196,
      "learning_rate": 8.980805097917314e-06,
      "loss": 0.0122,
      "step": 2623
    },
    {
      "epoch": 0.20391669257071807,
      "grad_norm": 0.570370078086853,
      "learning_rate": 8.980416537146411e-06,
      "loss": 1.0494,
      "step": 2624
    },
    {
      "epoch": 0.20399440472489896,
      "grad_norm": 0.2809237241744995,
      "learning_rate": 8.980027976375506e-06,
      "loss": 0.2037,
      "step": 2625
    },
    {
      "epoch": 0.2040721168790799,
      "grad_norm": 0.18801873922348022,
      "learning_rate": 8.979639415604601e-06,
      "loss": 0.0544,
      "step": 2626
    },
    {
      "epoch": 0.20414982903326082,
      "grad_norm": 0.44297313690185547,
      "learning_rate": 8.979250854833696e-06,
      "loss": 0.2698,
      "step": 2627
    },
    {
      "epoch": 0.2042275411874417,
      "grad_norm": 0.44270044565200806,
      "learning_rate": 8.978862294062793e-06,
      "loss": 0.212,
      "step": 2628
    },
    {
      "epoch": 0.20430525334162264,
      "grad_norm": 0.5703525543212891,
      "learning_rate": 8.978473733291888e-06,
      "loss": 0.4908,
      "step": 2629
    },
    {
      "epoch": 0.20438296549580354,
      "grad_norm": 0.24794845283031464,
      "learning_rate": 8.978085172520983e-06,
      "loss": 0.1483,
      "step": 2630
    },
    {
      "epoch": 0.20446067764998446,
      "grad_norm": 0.0520893931388855,
      "learning_rate": 8.977696611750079e-06,
      "loss": 0.0116,
      "step": 2631
    },
    {
      "epoch": 0.20453838980416536,
      "grad_norm": 0.23993659019470215,
      "learning_rate": 8.977308050979174e-06,
      "loss": 0.081,
      "step": 2632
    },
    {
      "epoch": 0.20461610195834629,
      "grad_norm": 0.09853681921958923,
      "learning_rate": 8.976919490208269e-06,
      "loss": 0.0456,
      "step": 2633
    },
    {
      "epoch": 0.2046938141125272,
      "grad_norm": 0.1353779435157776,
      "learning_rate": 8.976530929437364e-06,
      "loss": 0.0828,
      "step": 2634
    },
    {
      "epoch": 0.2047715262667081,
      "grad_norm": 0.3023377060890198,
      "learning_rate": 8.97614236866646e-06,
      "loss": 0.358,
      "step": 2635
    },
    {
      "epoch": 0.20484923842088903,
      "grad_norm": 0.2759465277194977,
      "learning_rate": 8.975753807895556e-06,
      "loss": 0.1288,
      "step": 2636
    },
    {
      "epoch": 0.20492695057506993,
      "grad_norm": 0.5591583251953125,
      "learning_rate": 8.97536524712465e-06,
      "loss": 0.5713,
      "step": 2637
    },
    {
      "epoch": 0.20500466272925086,
      "grad_norm": 0.2325611561536789,
      "learning_rate": 8.974976686353747e-06,
      "loss": 0.093,
      "step": 2638
    },
    {
      "epoch": 0.20508237488343176,
      "grad_norm": 0.14082805812358856,
      "learning_rate": 8.974588125582842e-06,
      "loss": 0.0835,
      "step": 2639
    },
    {
      "epoch": 0.20516008703761268,
      "grad_norm": 0.3138304650783539,
      "learning_rate": 8.974199564811937e-06,
      "loss": 0.2328,
      "step": 2640
    },
    {
      "epoch": 0.2052377991917936,
      "grad_norm": 0.2843203842639923,
      "learning_rate": 8.973811004041034e-06,
      "loss": 0.1366,
      "step": 2641
    },
    {
      "epoch": 0.2053155113459745,
      "grad_norm": 0.34020957350730896,
      "learning_rate": 8.973422443270127e-06,
      "loss": 0.4489,
      "step": 2642
    },
    {
      "epoch": 0.20539322350015543,
      "grad_norm": 0.36494359374046326,
      "learning_rate": 8.973033882499224e-06,
      "loss": 0.2495,
      "step": 2643
    },
    {
      "epoch": 0.20547093565433633,
      "grad_norm": 0.328619122505188,
      "learning_rate": 8.972645321728319e-06,
      "loss": 0.0733,
      "step": 2644
    },
    {
      "epoch": 0.20554864780851725,
      "grad_norm": 0.2540226876735687,
      "learning_rate": 8.972256760957414e-06,
      "loss": 0.0537,
      "step": 2645
    },
    {
      "epoch": 0.20562635996269818,
      "grad_norm": 0.2923775613307953,
      "learning_rate": 8.97186820018651e-06,
      "loss": 0.1319,
      "step": 2646
    },
    {
      "epoch": 0.20570407211687908,
      "grad_norm": 0.4060787856578827,
      "learning_rate": 8.971479639415605e-06,
      "loss": 0.1305,
      "step": 2647
    },
    {
      "epoch": 0.20578178427106,
      "grad_norm": 0.43854421377182007,
      "learning_rate": 8.9710910786447e-06,
      "loss": 0.2673,
      "step": 2648
    },
    {
      "epoch": 0.2058594964252409,
      "grad_norm": 0.3983169496059418,
      "learning_rate": 8.970702517873797e-06,
      "loss": 0.16,
      "step": 2649
    },
    {
      "epoch": 0.20593720857942183,
      "grad_norm": 0.3289245665073395,
      "learning_rate": 8.970313957102892e-06,
      "loss": 0.1211,
      "step": 2650
    },
    {
      "epoch": 0.20601492073360272,
      "grad_norm": 0.08260288834571838,
      "learning_rate": 8.969925396331987e-06,
      "loss": 0.0266,
      "step": 2651
    },
    {
      "epoch": 0.20609263288778365,
      "grad_norm": 0.9285670518875122,
      "learning_rate": 8.969536835561082e-06,
      "loss": 0.4343,
      "step": 2652
    },
    {
      "epoch": 0.20617034504196458,
      "grad_norm": 0.47829264402389526,
      "learning_rate": 8.969148274790178e-06,
      "loss": 0.4562,
      "step": 2653
    },
    {
      "epoch": 0.20624805719614547,
      "grad_norm": 0.31491419672966003,
      "learning_rate": 8.968759714019273e-06,
      "loss": 0.0926,
      "step": 2654
    },
    {
      "epoch": 0.2063257693503264,
      "grad_norm": 0.14193156361579895,
      "learning_rate": 8.968371153248368e-06,
      "loss": 0.0906,
      "step": 2655
    },
    {
      "epoch": 0.2064034815045073,
      "grad_norm": 0.06920497119426727,
      "learning_rate": 8.967982592477465e-06,
      "loss": 0.0197,
      "step": 2656
    },
    {
      "epoch": 0.20648119365868822,
      "grad_norm": 0.1245659664273262,
      "learning_rate": 8.96759403170656e-06,
      "loss": 0.0518,
      "step": 2657
    },
    {
      "epoch": 0.20655890581286912,
      "grad_norm": 0.3546273112297058,
      "learning_rate": 8.967205470935655e-06,
      "loss": 0.1398,
      "step": 2658
    },
    {
      "epoch": 0.20663661796705005,
      "grad_norm": 0.18729938566684723,
      "learning_rate": 8.966816910164751e-06,
      "loss": 0.0902,
      "step": 2659
    },
    {
      "epoch": 0.20671433012123097,
      "grad_norm": 0.27165326476097107,
      "learning_rate": 8.966428349393846e-06,
      "loss": 0.0479,
      "step": 2660
    },
    {
      "epoch": 0.20679204227541187,
      "grad_norm": 0.22962595522403717,
      "learning_rate": 8.966039788622941e-06,
      "loss": 0.0956,
      "step": 2661
    },
    {
      "epoch": 0.2068697544295928,
      "grad_norm": 0.6008846163749695,
      "learning_rate": 8.965651227852036e-06,
      "loss": 0.5111,
      "step": 2662
    },
    {
      "epoch": 0.2069474665837737,
      "grad_norm": 0.07258561253547668,
      "learning_rate": 8.965262667081133e-06,
      "loss": 0.0452,
      "step": 2663
    },
    {
      "epoch": 0.20702517873795462,
      "grad_norm": 0.19027480483055115,
      "learning_rate": 8.964874106310228e-06,
      "loss": 0.0923,
      "step": 2664
    },
    {
      "epoch": 0.20710289089213554,
      "grad_norm": 0.49776750802993774,
      "learning_rate": 8.964485545539323e-06,
      "loss": 0.5394,
      "step": 2665
    },
    {
      "epoch": 0.20718060304631644,
      "grad_norm": 0.17160287499427795,
      "learning_rate": 8.96409698476842e-06,
      "loss": 0.0234,
      "step": 2666
    },
    {
      "epoch": 0.20725831520049737,
      "grad_norm": 0.1480548232793808,
      "learning_rate": 8.963708423997514e-06,
      "loss": 0.0716,
      "step": 2667
    },
    {
      "epoch": 0.20733602735467827,
      "grad_norm": 0.36879515647888184,
      "learning_rate": 8.96331986322661e-06,
      "loss": 0.5913,
      "step": 2668
    },
    {
      "epoch": 0.2074137395088592,
      "grad_norm": 0.03714112564921379,
      "learning_rate": 8.962931302455706e-06,
      "loss": 0.0143,
      "step": 2669
    },
    {
      "epoch": 0.2074914516630401,
      "grad_norm": 0.16210314631462097,
      "learning_rate": 8.962542741684799e-06,
      "loss": 0.0685,
      "step": 2670
    },
    {
      "epoch": 0.20756916381722101,
      "grad_norm": 0.2652318775653839,
      "learning_rate": 8.962154180913896e-06,
      "loss": 0.2533,
      "step": 2671
    },
    {
      "epoch": 0.20764687597140194,
      "grad_norm": 0.08737421035766602,
      "learning_rate": 8.96176562014299e-06,
      "loss": 0.0538,
      "step": 2672
    },
    {
      "epoch": 0.20772458812558284,
      "grad_norm": 0.1887836903333664,
      "learning_rate": 8.961377059372086e-06,
      "loss": 0.1341,
      "step": 2673
    },
    {
      "epoch": 0.20780230027976376,
      "grad_norm": 0.20676498115062714,
      "learning_rate": 8.960988498601182e-06,
      "loss": 0.1321,
      "step": 2674
    },
    {
      "epoch": 0.20788001243394466,
      "grad_norm": 0.31396251916885376,
      "learning_rate": 8.960599937830277e-06,
      "loss": 0.6245,
      "step": 2675
    },
    {
      "epoch": 0.2079577245881256,
      "grad_norm": 0.419117271900177,
      "learning_rate": 8.960211377059372e-06,
      "loss": 0.2696,
      "step": 2676
    },
    {
      "epoch": 0.20803543674230648,
      "grad_norm": 0.1987770050764084,
      "learning_rate": 8.959822816288469e-06,
      "loss": 0.0808,
      "step": 2677
    },
    {
      "epoch": 0.2081131488964874,
      "grad_norm": 0.15479806065559387,
      "learning_rate": 8.959434255517564e-06,
      "loss": 0.0664,
      "step": 2678
    },
    {
      "epoch": 0.20819086105066834,
      "grad_norm": 0.12574468553066254,
      "learning_rate": 8.959045694746659e-06,
      "loss": 0.0087,
      "step": 2679
    },
    {
      "epoch": 0.20826857320484923,
      "grad_norm": 0.2913365960121155,
      "learning_rate": 8.958657133975754e-06,
      "loss": 0.1408,
      "step": 2680
    },
    {
      "epoch": 0.20834628535903016,
      "grad_norm": 0.07791014015674591,
      "learning_rate": 8.95826857320485e-06,
      "loss": 0.0251,
      "step": 2681
    },
    {
      "epoch": 0.20842399751321106,
      "grad_norm": 0.3249799311161041,
      "learning_rate": 8.957880012433945e-06,
      "loss": 0.3495,
      "step": 2682
    },
    {
      "epoch": 0.20850170966739198,
      "grad_norm": 0.4430907964706421,
      "learning_rate": 8.95749145166304e-06,
      "loss": 0.4525,
      "step": 2683
    },
    {
      "epoch": 0.20857942182157288,
      "grad_norm": 0.1694529801607132,
      "learning_rate": 8.957102890892137e-06,
      "loss": 0.0897,
      "step": 2684
    },
    {
      "epoch": 0.2086571339757538,
      "grad_norm": 0.5964108109474182,
      "learning_rate": 8.956714330121232e-06,
      "loss": 0.2259,
      "step": 2685
    },
    {
      "epoch": 0.20873484612993473,
      "grad_norm": 0.18327359855175018,
      "learning_rate": 8.956325769350327e-06,
      "loss": 0.0662,
      "step": 2686
    },
    {
      "epoch": 0.20881255828411563,
      "grad_norm": 0.19802545011043549,
      "learning_rate": 8.955937208579423e-06,
      "loss": 0.1245,
      "step": 2687
    },
    {
      "epoch": 0.20889027043829655,
      "grad_norm": 0.15467052161693573,
      "learning_rate": 8.955548647808518e-06,
      "loss": 0.1216,
      "step": 2688
    },
    {
      "epoch": 0.20896798259247745,
      "grad_norm": 0.3852892518043518,
      "learning_rate": 8.955160087037613e-06,
      "loss": 0.382,
      "step": 2689
    },
    {
      "epoch": 0.20904569474665838,
      "grad_norm": 0.7636879682540894,
      "learning_rate": 8.954771526266708e-06,
      "loss": 0.4716,
      "step": 2690
    },
    {
      "epoch": 0.2091234069008393,
      "grad_norm": 0.1840316504240036,
      "learning_rate": 8.954382965495805e-06,
      "loss": 0.0314,
      "step": 2691
    },
    {
      "epoch": 0.2092011190550202,
      "grad_norm": 0.236551433801651,
      "learning_rate": 8.9539944047249e-06,
      "loss": 0.8365,
      "step": 2692
    },
    {
      "epoch": 0.20927883120920113,
      "grad_norm": 0.544230580329895,
      "learning_rate": 8.953605843953995e-06,
      "loss": 0.8162,
      "step": 2693
    },
    {
      "epoch": 0.20935654336338202,
      "grad_norm": 0.2867508828639984,
      "learning_rate": 8.953217283183091e-06,
      "loss": 0.2016,
      "step": 2694
    },
    {
      "epoch": 0.20943425551756295,
      "grad_norm": 0.24242573976516724,
      "learning_rate": 8.952828722412186e-06,
      "loss": 0.0716,
      "step": 2695
    },
    {
      "epoch": 0.20951196767174385,
      "grad_norm": 0.11037572473287582,
      "learning_rate": 8.952440161641281e-06,
      "loss": 0.067,
      "step": 2696
    },
    {
      "epoch": 0.20958967982592477,
      "grad_norm": 0.1496778428554535,
      "learning_rate": 8.952051600870378e-06,
      "loss": 0.1355,
      "step": 2697
    },
    {
      "epoch": 0.2096673919801057,
      "grad_norm": 0.5038899183273315,
      "learning_rate": 8.951663040099471e-06,
      "loss": 0.2798,
      "step": 2698
    },
    {
      "epoch": 0.2097451041342866,
      "grad_norm": 0.21530400216579437,
      "learning_rate": 8.951274479328568e-06,
      "loss": 0.1303,
      "step": 2699
    },
    {
      "epoch": 0.20982281628846752,
      "grad_norm": 0.3379983603954315,
      "learning_rate": 8.950885918557663e-06,
      "loss": 0.0917,
      "step": 2700
    },
    {
      "epoch": 0.20990052844264842,
      "grad_norm": 0.22858819365501404,
      "learning_rate": 8.950497357786758e-06,
      "loss": 0.1298,
      "step": 2701
    },
    {
      "epoch": 0.20997824059682935,
      "grad_norm": 0.15222637355327606,
      "learning_rate": 8.950108797015854e-06,
      "loss": 0.0607,
      "step": 2702
    },
    {
      "epoch": 0.21005595275101024,
      "grad_norm": 0.5035241842269897,
      "learning_rate": 8.94972023624495e-06,
      "loss": 0.0852,
      "step": 2703
    },
    {
      "epoch": 0.21013366490519117,
      "grad_norm": 0.23560039699077606,
      "learning_rate": 8.949331675474044e-06,
      "loss": 0.1083,
      "step": 2704
    },
    {
      "epoch": 0.2102113770593721,
      "grad_norm": 0.2760806977748871,
      "learning_rate": 8.948943114703141e-06,
      "loss": 0.3648,
      "step": 2705
    },
    {
      "epoch": 0.210289089213553,
      "grad_norm": 0.4109695553779602,
      "learning_rate": 8.948554553932236e-06,
      "loss": 0.2626,
      "step": 2706
    },
    {
      "epoch": 0.21036680136773392,
      "grad_norm": 0.33768200874328613,
      "learning_rate": 8.948165993161331e-06,
      "loss": 0.1628,
      "step": 2707
    },
    {
      "epoch": 0.21044451352191482,
      "grad_norm": 0.42697620391845703,
      "learning_rate": 8.947777432390426e-06,
      "loss": 0.5389,
      "step": 2708
    },
    {
      "epoch": 0.21052222567609574,
      "grad_norm": 0.36090049147605896,
      "learning_rate": 8.947388871619522e-06,
      "loss": 0.1294,
      "step": 2709
    },
    {
      "epoch": 0.21059993783027667,
      "grad_norm": 0.09557570517063141,
      "learning_rate": 8.947000310848617e-06,
      "loss": 0.0312,
      "step": 2710
    },
    {
      "epoch": 0.21067764998445757,
      "grad_norm": 0.19022709131240845,
      "learning_rate": 8.946611750077712e-06,
      "loss": 0.0638,
      "step": 2711
    },
    {
      "epoch": 0.2107553621386385,
      "grad_norm": 0.17786522209644318,
      "learning_rate": 8.946223189306809e-06,
      "loss": 0.0774,
      "step": 2712
    },
    {
      "epoch": 0.2108330742928194,
      "grad_norm": 0.36742889881134033,
      "learning_rate": 8.945834628535904e-06,
      "loss": 0.1419,
      "step": 2713
    },
    {
      "epoch": 0.21091078644700031,
      "grad_norm": 0.17948000133037567,
      "learning_rate": 8.945446067764999e-06,
      "loss": 0.0851,
      "step": 2714
    },
    {
      "epoch": 0.2109884986011812,
      "grad_norm": 0.055765051394701004,
      "learning_rate": 8.945057506994096e-06,
      "loss": 0.0297,
      "step": 2715
    },
    {
      "epoch": 0.21106621075536214,
      "grad_norm": 0.32983776926994324,
      "learning_rate": 8.944668946223189e-06,
      "loss": 0.4205,
      "step": 2716
    },
    {
      "epoch": 0.21114392290954306,
      "grad_norm": 0.26436647772789,
      "learning_rate": 8.944280385452285e-06,
      "loss": 0.2315,
      "step": 2717
    },
    {
      "epoch": 0.21122163506372396,
      "grad_norm": 0.4573790431022644,
      "learning_rate": 8.94389182468138e-06,
      "loss": 0.3264,
      "step": 2718
    },
    {
      "epoch": 0.2112993472179049,
      "grad_norm": 0.2507200539112091,
      "learning_rate": 8.943503263910477e-06,
      "loss": 0.1099,
      "step": 2719
    },
    {
      "epoch": 0.21137705937208578,
      "grad_norm": 0.3318750262260437,
      "learning_rate": 8.943114703139572e-06,
      "loss": 0.5166,
      "step": 2720
    },
    {
      "epoch": 0.2114547715262667,
      "grad_norm": 0.4976733922958374,
      "learning_rate": 8.942726142368667e-06,
      "loss": 0.5078,
      "step": 2721
    },
    {
      "epoch": 0.2115324836804476,
      "grad_norm": 0.20368318259716034,
      "learning_rate": 8.942337581597764e-06,
      "loss": 0.0388,
      "step": 2722
    },
    {
      "epoch": 0.21161019583462853,
      "grad_norm": 0.22354213893413544,
      "learning_rate": 8.941949020826859e-06,
      "loss": 0.0472,
      "step": 2723
    },
    {
      "epoch": 0.21168790798880946,
      "grad_norm": 0.14182348549365997,
      "learning_rate": 8.941560460055954e-06,
      "loss": 0.0583,
      "step": 2724
    },
    {
      "epoch": 0.21176562014299036,
      "grad_norm": 0.5631523132324219,
      "learning_rate": 8.94117189928505e-06,
      "loss": 0.2687,
      "step": 2725
    },
    {
      "epoch": 0.21184333229717128,
      "grad_norm": 0.15252849459648132,
      "learning_rate": 8.940783338514143e-06,
      "loss": 0.1055,
      "step": 2726
    },
    {
      "epoch": 0.21192104445135218,
      "grad_norm": 0.742526113986969,
      "learning_rate": 8.94039477774324e-06,
      "loss": 0.0982,
      "step": 2727
    },
    {
      "epoch": 0.2119987566055331,
      "grad_norm": 0.4428442418575287,
      "learning_rate": 8.940006216972335e-06,
      "loss": 0.1762,
      "step": 2728
    },
    {
      "epoch": 0.21207646875971403,
      "grad_norm": 0.2780781090259552,
      "learning_rate": 8.93961765620143e-06,
      "loss": 0.161,
      "step": 2729
    },
    {
      "epoch": 0.21215418091389493,
      "grad_norm": 0.3292301893234253,
      "learning_rate": 8.939229095430527e-06,
      "loss": 0.0895,
      "step": 2730
    },
    {
      "epoch": 0.21223189306807586,
      "grad_norm": 0.3569249212741852,
      "learning_rate": 8.938840534659622e-06,
      "loss": 0.1644,
      "step": 2731
    },
    {
      "epoch": 0.21230960522225675,
      "grad_norm": 0.42255088686943054,
      "learning_rate": 8.938451973888717e-06,
      "loss": 0.2694,
      "step": 2732
    },
    {
      "epoch": 0.21238731737643768,
      "grad_norm": 0.16607654094696045,
      "learning_rate": 8.938063413117813e-06,
      "loss": 0.1068,
      "step": 2733
    },
    {
      "epoch": 0.21246502953061858,
      "grad_norm": 0.44843271374702454,
      "learning_rate": 8.937674852346908e-06,
      "loss": 0.2475,
      "step": 2734
    },
    {
      "epoch": 0.2125427416847995,
      "grad_norm": 0.2846960425376892,
      "learning_rate": 8.937286291576003e-06,
      "loss": 0.2073,
      "step": 2735
    },
    {
      "epoch": 0.21262045383898043,
      "grad_norm": 0.5523343086242676,
      "learning_rate": 8.936897730805098e-06,
      "loss": 0.1838,
      "step": 2736
    },
    {
      "epoch": 0.21269816599316133,
      "grad_norm": 0.20992569625377655,
      "learning_rate": 8.936509170034195e-06,
      "loss": 0.0886,
      "step": 2737
    },
    {
      "epoch": 0.21277587814734225,
      "grad_norm": 0.4516139626502991,
      "learning_rate": 8.93612060926329e-06,
      "loss": 0.5773,
      "step": 2738
    },
    {
      "epoch": 0.21285359030152315,
      "grad_norm": 0.034939445555210114,
      "learning_rate": 8.935732048492385e-06,
      "loss": 0.0124,
      "step": 2739
    },
    {
      "epoch": 0.21293130245570407,
      "grad_norm": 0.1666731983423233,
      "learning_rate": 8.935343487721481e-06,
      "loss": 0.0619,
      "step": 2740
    },
    {
      "epoch": 0.21300901460988497,
      "grad_norm": 0.12808683514595032,
      "learning_rate": 8.934954926950576e-06,
      "loss": 0.0671,
      "step": 2741
    },
    {
      "epoch": 0.2130867267640659,
      "grad_norm": 0.4075765907764435,
      "learning_rate": 8.934566366179671e-06,
      "loss": 0.2632,
      "step": 2742
    },
    {
      "epoch": 0.21316443891824682,
      "grad_norm": 0.4975985884666443,
      "learning_rate": 8.934177805408768e-06,
      "loss": 0.3089,
      "step": 2743
    },
    {
      "epoch": 0.21324215107242772,
      "grad_norm": 0.10378191620111465,
      "learning_rate": 8.933789244637861e-06,
      "loss": 0.064,
      "step": 2744
    },
    {
      "epoch": 0.21331986322660865,
      "grad_norm": 0.210996612906456,
      "learning_rate": 8.933400683866958e-06,
      "loss": 0.1652,
      "step": 2745
    },
    {
      "epoch": 0.21339757538078954,
      "grad_norm": 0.20217162370681763,
      "learning_rate": 8.933012123096053e-06,
      "loss": 0.0832,
      "step": 2746
    },
    {
      "epoch": 0.21347528753497047,
      "grad_norm": 0.1964516043663025,
      "learning_rate": 8.93262356232515e-06,
      "loss": 0.111,
      "step": 2747
    },
    {
      "epoch": 0.2135529996891514,
      "grad_norm": 0.25606444478034973,
      "learning_rate": 8.932235001554244e-06,
      "loss": 0.0958,
      "step": 2748
    },
    {
      "epoch": 0.2136307118433323,
      "grad_norm": 0.40650758147239685,
      "learning_rate": 8.931846440783339e-06,
      "loss": 0.1496,
      "step": 2749
    },
    {
      "epoch": 0.21370842399751322,
      "grad_norm": 0.06466734409332275,
      "learning_rate": 8.931457880012436e-06,
      "loss": 0.0115,
      "step": 2750
    },
    {
      "epoch": 0.21378613615169412,
      "grad_norm": 1.1436970233917236,
      "learning_rate": 8.931069319241529e-06,
      "loss": 0.4214,
      "step": 2751
    },
    {
      "epoch": 0.21386384830587504,
      "grad_norm": 0.2812860906124115,
      "learning_rate": 8.930680758470626e-06,
      "loss": 0.2247,
      "step": 2752
    },
    {
      "epoch": 0.21394156046005594,
      "grad_norm": 0.14718303084373474,
      "learning_rate": 8.93029219769972e-06,
      "loss": 0.0329,
      "step": 2753
    },
    {
      "epoch": 0.21401927261423687,
      "grad_norm": 0.240385040640831,
      "learning_rate": 8.929903636928816e-06,
      "loss": 0.1277,
      "step": 2754
    },
    {
      "epoch": 0.2140969847684178,
      "grad_norm": 0.2680395841598511,
      "learning_rate": 8.929515076157912e-06,
      "loss": 0.1263,
      "step": 2755
    },
    {
      "epoch": 0.2141746969225987,
      "grad_norm": 0.24416252970695496,
      "learning_rate": 8.929126515387007e-06,
      "loss": 0.3061,
      "step": 2756
    },
    {
      "epoch": 0.21425240907677962,
      "grad_norm": 0.1884177327156067,
      "learning_rate": 8.928737954616102e-06,
      "loss": 0.0674,
      "step": 2757
    },
    {
      "epoch": 0.2143301212309605,
      "grad_norm": 0.3320513665676117,
      "learning_rate": 8.928349393845199e-06,
      "loss": 0.2224,
      "step": 2758
    },
    {
      "epoch": 0.21440783338514144,
      "grad_norm": 0.4623323678970337,
      "learning_rate": 8.927960833074294e-06,
      "loss": 0.1888,
      "step": 2759
    },
    {
      "epoch": 0.21448554553932234,
      "grad_norm": 0.44861918687820435,
      "learning_rate": 8.927572272303389e-06,
      "loss": 0.2942,
      "step": 2760
    },
    {
      "epoch": 0.21456325769350326,
      "grad_norm": 0.16570080816745758,
      "learning_rate": 8.927183711532484e-06,
      "loss": 0.1198,
      "step": 2761
    },
    {
      "epoch": 0.2146409698476842,
      "grad_norm": 0.3321544826030731,
      "learning_rate": 8.92679515076158e-06,
      "loss": 0.3779,
      "step": 2762
    },
    {
      "epoch": 0.21471868200186509,
      "grad_norm": 0.30799826979637146,
      "learning_rate": 8.926406589990675e-06,
      "loss": 0.3183,
      "step": 2763
    },
    {
      "epoch": 0.214796394156046,
      "grad_norm": 0.5553287863731384,
      "learning_rate": 8.92601802921977e-06,
      "loss": 0.2543,
      "step": 2764
    },
    {
      "epoch": 0.2148741063102269,
      "grad_norm": 0.43577051162719727,
      "learning_rate": 8.925629468448867e-06,
      "loss": 0.2247,
      "step": 2765
    },
    {
      "epoch": 0.21495181846440783,
      "grad_norm": 0.11650560796260834,
      "learning_rate": 8.925240907677962e-06,
      "loss": 0.0545,
      "step": 2766
    },
    {
      "epoch": 0.21502953061858876,
      "grad_norm": 0.12155690044164658,
      "learning_rate": 8.924852346907057e-06,
      "loss": 0.0657,
      "step": 2767
    },
    {
      "epoch": 0.21510724277276966,
      "grad_norm": 0.2007843255996704,
      "learning_rate": 8.924463786136153e-06,
      "loss": 0.0601,
      "step": 2768
    },
    {
      "epoch": 0.21518495492695058,
      "grad_norm": 0.5155991315841675,
      "learning_rate": 8.924075225365247e-06,
      "loss": 0.82,
      "step": 2769
    },
    {
      "epoch": 0.21526266708113148,
      "grad_norm": 0.2835722267627716,
      "learning_rate": 8.923686664594343e-06,
      "loss": 0.1118,
      "step": 2770
    },
    {
      "epoch": 0.2153403792353124,
      "grad_norm": 0.5257936716079712,
      "learning_rate": 8.923298103823438e-06,
      "loss": 0.1557,
      "step": 2771
    },
    {
      "epoch": 0.2154180913894933,
      "grad_norm": 0.423898845911026,
      "learning_rate": 8.922909543052533e-06,
      "loss": 0.1713,
      "step": 2772
    },
    {
      "epoch": 0.21549580354367423,
      "grad_norm": 0.20899780094623566,
      "learning_rate": 8.92252098228163e-06,
      "loss": 0.12,
      "step": 2773
    },
    {
      "epoch": 0.21557351569785516,
      "grad_norm": 0.13124172389507294,
      "learning_rate": 8.922132421510725e-06,
      "loss": 0.0676,
      "step": 2774
    },
    {
      "epoch": 0.21565122785203605,
      "grad_norm": 0.1927809864282608,
      "learning_rate": 8.92174386073982e-06,
      "loss": 0.0453,
      "step": 2775
    },
    {
      "epoch": 0.21572894000621698,
      "grad_norm": 0.3381468653678894,
      "learning_rate": 8.921355299968916e-06,
      "loss": 0.1225,
      "step": 2776
    },
    {
      "epoch": 0.21580665216039788,
      "grad_norm": 0.12744276225566864,
      "learning_rate": 8.920966739198011e-06,
      "loss": 0.0268,
      "step": 2777
    },
    {
      "epoch": 0.2158843643145788,
      "grad_norm": 0.15244446694850922,
      "learning_rate": 8.920578178427108e-06,
      "loss": 0.0766,
      "step": 2778
    },
    {
      "epoch": 0.2159620764687597,
      "grad_norm": 0.2303047776222229,
      "learning_rate": 8.920189617656201e-06,
      "loss": 0.2104,
      "step": 2779
    },
    {
      "epoch": 0.21603978862294063,
      "grad_norm": 0.19967535138130188,
      "learning_rate": 8.919801056885298e-06,
      "loss": 0.1677,
      "step": 2780
    },
    {
      "epoch": 0.21611750077712155,
      "grad_norm": 0.3674333095550537,
      "learning_rate": 8.919412496114393e-06,
      "loss": 0.1759,
      "step": 2781
    },
    {
      "epoch": 0.21619521293130245,
      "grad_norm": 0.7379575371742249,
      "learning_rate": 8.919023935343488e-06,
      "loss": 0.2929,
      "step": 2782
    },
    {
      "epoch": 0.21627292508548338,
      "grad_norm": 0.44906866550445557,
      "learning_rate": 8.918635374572584e-06,
      "loss": 0.2155,
      "step": 2783
    },
    {
      "epoch": 0.21635063723966427,
      "grad_norm": 0.15660279989242554,
      "learning_rate": 8.91824681380168e-06,
      "loss": 0.0777,
      "step": 2784
    },
    {
      "epoch": 0.2164283493938452,
      "grad_norm": 0.47878140211105347,
      "learning_rate": 8.917858253030774e-06,
      "loss": 0.8614,
      "step": 2785
    },
    {
      "epoch": 0.21650606154802612,
      "grad_norm": 0.3173692524433136,
      "learning_rate": 8.917469692259871e-06,
      "loss": 0.3946,
      "step": 2786
    },
    {
      "epoch": 0.21658377370220702,
      "grad_norm": 0.32498106360435486,
      "learning_rate": 8.917081131488966e-06,
      "loss": 0.1533,
      "step": 2787
    },
    {
      "epoch": 0.21666148585638795,
      "grad_norm": 0.14481312036514282,
      "learning_rate": 8.91669257071806e-06,
      "loss": 0.08,
      "step": 2788
    },
    {
      "epoch": 0.21673919801056885,
      "grad_norm": 0.45522579550743103,
      "learning_rate": 8.916304009947156e-06,
      "loss": 0.3113,
      "step": 2789
    },
    {
      "epoch": 0.21681691016474977,
      "grad_norm": 0.14259353280067444,
      "learning_rate": 8.915915449176252e-06,
      "loss": 0.054,
      "step": 2790
    },
    {
      "epoch": 0.21689462231893067,
      "grad_norm": 0.11953915655612946,
      "learning_rate": 8.915526888405347e-06,
      "loss": 0.0423,
      "step": 2791
    },
    {
      "epoch": 0.2169723344731116,
      "grad_norm": 0.19231943786144257,
      "learning_rate": 8.915138327634442e-06,
      "loss": 0.0668,
      "step": 2792
    },
    {
      "epoch": 0.21705004662729252,
      "grad_norm": 0.37184375524520874,
      "learning_rate": 8.914749766863539e-06,
      "loss": 0.2365,
      "step": 2793
    },
    {
      "epoch": 0.21712775878147342,
      "grad_norm": 0.34183889627456665,
      "learning_rate": 8.914361206092634e-06,
      "loss": 0.6097,
      "step": 2794
    },
    {
      "epoch": 0.21720547093565434,
      "grad_norm": 0.38300633430480957,
      "learning_rate": 8.913972645321729e-06,
      "loss": 0.2185,
      "step": 2795
    },
    {
      "epoch": 0.21728318308983524,
      "grad_norm": 0.5923925042152405,
      "learning_rate": 8.913584084550825e-06,
      "loss": 0.1674,
      "step": 2796
    },
    {
      "epoch": 0.21736089524401617,
      "grad_norm": 0.1512625366449356,
      "learning_rate": 8.913195523779919e-06,
      "loss": 0.0798,
      "step": 2797
    },
    {
      "epoch": 0.21743860739819706,
      "grad_norm": 0.3562470078468323,
      "learning_rate": 8.912806963009015e-06,
      "loss": 0.2388,
      "step": 2798
    },
    {
      "epoch": 0.217516319552378,
      "grad_norm": 0.46393322944641113,
      "learning_rate": 8.91241840223811e-06,
      "loss": 0.3206,
      "step": 2799
    },
    {
      "epoch": 0.21759403170655892,
      "grad_norm": 0.3152809739112854,
      "learning_rate": 8.912029841467205e-06,
      "loss": 0.3055,
      "step": 2800
    },
    {
      "epoch": 0.2176717438607398,
      "grad_norm": 0.15220007300376892,
      "learning_rate": 8.911641280696302e-06,
      "loss": 0.0861,
      "step": 2801
    },
    {
      "epoch": 0.21774945601492074,
      "grad_norm": 0.2191038280725479,
      "learning_rate": 8.911252719925397e-06,
      "loss": 0.1156,
      "step": 2802
    },
    {
      "epoch": 0.21782716816910164,
      "grad_norm": 0.40598630905151367,
      "learning_rate": 8.910864159154492e-06,
      "loss": 0.2836,
      "step": 2803
    },
    {
      "epoch": 0.21790488032328256,
      "grad_norm": 0.08184147626161575,
      "learning_rate": 8.910475598383588e-06,
      "loss": 0.0243,
      "step": 2804
    },
    {
      "epoch": 0.2179825924774635,
      "grad_norm": 0.319854199886322,
      "learning_rate": 8.910087037612683e-06,
      "loss": 0.1661,
      "step": 2805
    },
    {
      "epoch": 0.21806030463164439,
      "grad_norm": 0.5182945132255554,
      "learning_rate": 8.909698476841778e-06,
      "loss": 0.2943,
      "step": 2806
    },
    {
      "epoch": 0.2181380167858253,
      "grad_norm": 0.1031702309846878,
      "learning_rate": 8.909309916070873e-06,
      "loss": 0.0363,
      "step": 2807
    },
    {
      "epoch": 0.2182157289400062,
      "grad_norm": 0.16104425489902496,
      "learning_rate": 8.90892135529997e-06,
      "loss": 0.0358,
      "step": 2808
    },
    {
      "epoch": 0.21829344109418714,
      "grad_norm": 1.0520803928375244,
      "learning_rate": 8.908532794529065e-06,
      "loss": 0.4546,
      "step": 2809
    },
    {
      "epoch": 0.21837115324836803,
      "grad_norm": 0.29649102687835693,
      "learning_rate": 8.90814423375816e-06,
      "loss": 0.1088,
      "step": 2810
    },
    {
      "epoch": 0.21844886540254896,
      "grad_norm": 0.049623943865299225,
      "learning_rate": 8.907755672987257e-06,
      "loss": 0.0174,
      "step": 2811
    },
    {
      "epoch": 0.21852657755672988,
      "grad_norm": 0.2681295573711395,
      "learning_rate": 8.907367112216351e-06,
      "loss": 0.2151,
      "step": 2812
    },
    {
      "epoch": 0.21860428971091078,
      "grad_norm": 0.2275753617286682,
      "learning_rate": 8.906978551445446e-06,
      "loss": 0.2271,
      "step": 2813
    },
    {
      "epoch": 0.2186820018650917,
      "grad_norm": 0.12245944887399673,
      "learning_rate": 8.906589990674543e-06,
      "loss": 0.0856,
      "step": 2814
    },
    {
      "epoch": 0.2187597140192726,
      "grad_norm": 0.28890460729599,
      "learning_rate": 8.906201429903638e-06,
      "loss": 0.172,
      "step": 2815
    },
    {
      "epoch": 0.21883742617345353,
      "grad_norm": 0.5717937350273132,
      "learning_rate": 8.905812869132733e-06,
      "loss": 0.2712,
      "step": 2816
    },
    {
      "epoch": 0.21891513832763443,
      "grad_norm": 0.5405265688896179,
      "learning_rate": 8.905424308361828e-06,
      "loss": 0.4567,
      "step": 2817
    },
    {
      "epoch": 0.21899285048181535,
      "grad_norm": 0.23556311428546906,
      "learning_rate": 8.905035747590925e-06,
      "loss": 0.0651,
      "step": 2818
    },
    {
      "epoch": 0.21907056263599628,
      "grad_norm": 0.33069857954978943,
      "learning_rate": 8.90464718682002e-06,
      "loss": 0.1795,
      "step": 2819
    },
    {
      "epoch": 0.21914827479017718,
      "grad_norm": 0.38064777851104736,
      "learning_rate": 8.904258626049114e-06,
      "loss": 0.3447,
      "step": 2820
    },
    {
      "epoch": 0.2192259869443581,
      "grad_norm": 0.20319373905658722,
      "learning_rate": 8.903870065278211e-06,
      "loss": 0.1147,
      "step": 2821
    },
    {
      "epoch": 0.219303699098539,
      "grad_norm": 0.24838440120220184,
      "learning_rate": 8.903481504507306e-06,
      "loss": 0.2019,
      "step": 2822
    },
    {
      "epoch": 0.21938141125271993,
      "grad_norm": 0.15130124986171722,
      "learning_rate": 8.903092943736401e-06,
      "loss": 0.0871,
      "step": 2823
    },
    {
      "epoch": 0.21945912340690085,
      "grad_norm": 0.32816165685653687,
      "learning_rate": 8.902704382965498e-06,
      "loss": 0.2407,
      "step": 2824
    },
    {
      "epoch": 0.21953683556108175,
      "grad_norm": 1.0095995664596558,
      "learning_rate": 8.902315822194591e-06,
      "loss": 2.2894,
      "step": 2825
    },
    {
      "epoch": 0.21961454771526268,
      "grad_norm": 0.450610488653183,
      "learning_rate": 8.901927261423688e-06,
      "loss": 0.1311,
      "step": 2826
    },
    {
      "epoch": 0.21969225986944357,
      "grad_norm": 0.1178603395819664,
      "learning_rate": 8.901538700652782e-06,
      "loss": 0.0681,
      "step": 2827
    },
    {
      "epoch": 0.2197699720236245,
      "grad_norm": 0.1378147453069687,
      "learning_rate": 8.901150139881877e-06,
      "loss": 0.0642,
      "step": 2828
    },
    {
      "epoch": 0.2198476841778054,
      "grad_norm": 0.945774495601654,
      "learning_rate": 8.900761579110974e-06,
      "loss": 0.5095,
      "step": 2829
    },
    {
      "epoch": 0.21992539633198632,
      "grad_norm": 0.1447785198688507,
      "learning_rate": 8.900373018340069e-06,
      "loss": 0.0532,
      "step": 2830
    },
    {
      "epoch": 0.22000310848616725,
      "grad_norm": 0.029026787728071213,
      "learning_rate": 8.899984457569164e-06,
      "loss": 0.0039,
      "step": 2831
    },
    {
      "epoch": 0.22008082064034815,
      "grad_norm": 0.22105374932289124,
      "learning_rate": 8.89959589679826e-06,
      "loss": 0.0727,
      "step": 2832
    },
    {
      "epoch": 0.22015853279452907,
      "grad_norm": 0.5414027571678162,
      "learning_rate": 8.899207336027356e-06,
      "loss": 0.4987,
      "step": 2833
    },
    {
      "epoch": 0.22023624494870997,
      "grad_norm": 0.5505779385566711,
      "learning_rate": 8.89881877525645e-06,
      "loss": 0.2211,
      "step": 2834
    },
    {
      "epoch": 0.2203139571028909,
      "grad_norm": 0.3747880160808563,
      "learning_rate": 8.898430214485545e-06,
      "loss": 0.1347,
      "step": 2835
    },
    {
      "epoch": 0.2203916692570718,
      "grad_norm": 0.22609132528305054,
      "learning_rate": 8.898041653714642e-06,
      "loss": 0.0653,
      "step": 2836
    },
    {
      "epoch": 0.22046938141125272,
      "grad_norm": 0.3684242069721222,
      "learning_rate": 8.897653092943737e-06,
      "loss": 0.2003,
      "step": 2837
    },
    {
      "epoch": 0.22054709356543364,
      "grad_norm": 0.5611814260482788,
      "learning_rate": 8.897264532172832e-06,
      "loss": 0.338,
      "step": 2838
    },
    {
      "epoch": 0.22062480571961454,
      "grad_norm": 0.26604968309402466,
      "learning_rate": 8.896875971401929e-06,
      "loss": 0.4085,
      "step": 2839
    },
    {
      "epoch": 0.22070251787379547,
      "grad_norm": 0.11558260768651962,
      "learning_rate": 8.896487410631024e-06,
      "loss": 0.0321,
      "step": 2840
    },
    {
      "epoch": 0.22078023002797637,
      "grad_norm": 0.3431009352207184,
      "learning_rate": 8.896098849860119e-06,
      "loss": 0.6451,
      "step": 2841
    },
    {
      "epoch": 0.2208579421821573,
      "grad_norm": 0.060799699276685715,
      "learning_rate": 8.895710289089215e-06,
      "loss": 0.0229,
      "step": 2842
    },
    {
      "epoch": 0.22093565433633822,
      "grad_norm": 0.20640775561332703,
      "learning_rate": 8.89532172831831e-06,
      "loss": 0.0964,
      "step": 2843
    },
    {
      "epoch": 0.22101336649051911,
      "grad_norm": 0.4956195056438446,
      "learning_rate": 8.894933167547405e-06,
      "loss": 0.3753,
      "step": 2844
    },
    {
      "epoch": 0.22109107864470004,
      "grad_norm": 1.0518699884414673,
      "learning_rate": 8.8945446067765e-06,
      "loss": 0.4619,
      "step": 2845
    },
    {
      "epoch": 0.22116879079888094,
      "grad_norm": 0.34874427318573,
      "learning_rate": 8.894156046005597e-06,
      "loss": 0.2914,
      "step": 2846
    },
    {
      "epoch": 0.22124650295306186,
      "grad_norm": 0.24905407428741455,
      "learning_rate": 8.893767485234692e-06,
      "loss": 0.1104,
      "step": 2847
    },
    {
      "epoch": 0.22132421510724276,
      "grad_norm": 0.7920320630073547,
      "learning_rate": 8.893378924463787e-06,
      "loss": 0.3931,
      "step": 2848
    },
    {
      "epoch": 0.2214019272614237,
      "grad_norm": 0.17234063148498535,
      "learning_rate": 8.892990363692883e-06,
      "loss": 0.0699,
      "step": 2849
    },
    {
      "epoch": 0.2214796394156046,
      "grad_norm": 0.38638535141944885,
      "learning_rate": 8.892601802921978e-06,
      "loss": 0.1026,
      "step": 2850
    },
    {
      "epoch": 0.2215573515697855,
      "grad_norm": 0.35355043411254883,
      "learning_rate": 8.892213242151073e-06,
      "loss": 0.1831,
      "step": 2851
    },
    {
      "epoch": 0.22163506372396644,
      "grad_norm": 0.41394010186195374,
      "learning_rate": 8.89182468138017e-06,
      "loss": 0.2363,
      "step": 2852
    },
    {
      "epoch": 0.22171277587814733,
      "grad_norm": 0.4114384055137634,
      "learning_rate": 8.891436120609263e-06,
      "loss": 0.3453,
      "step": 2853
    },
    {
      "epoch": 0.22179048803232826,
      "grad_norm": 0.27843424677848816,
      "learning_rate": 8.89104755983836e-06,
      "loss": 0.2466,
      "step": 2854
    },
    {
      "epoch": 0.22186820018650916,
      "grad_norm": 0.0547521635890007,
      "learning_rate": 8.890658999067455e-06,
      "loss": 0.0432,
      "step": 2855
    },
    {
      "epoch": 0.22194591234069008,
      "grad_norm": 0.830710232257843,
      "learning_rate": 8.89027043829655e-06,
      "loss": 0.1564,
      "step": 2856
    },
    {
      "epoch": 0.222023624494871,
      "grad_norm": 0.27805665135383606,
      "learning_rate": 8.889881877525646e-06,
      "loss": 0.1793,
      "step": 2857
    },
    {
      "epoch": 0.2221013366490519,
      "grad_norm": 0.8471415638923645,
      "learning_rate": 8.889493316754741e-06,
      "loss": 0.2317,
      "step": 2858
    },
    {
      "epoch": 0.22217904880323283,
      "grad_norm": 0.4894699454307556,
      "learning_rate": 8.889104755983836e-06,
      "loss": 0.4234,
      "step": 2859
    },
    {
      "epoch": 0.22225676095741373,
      "grad_norm": 0.4249657392501831,
      "learning_rate": 8.888716195212933e-06,
      "loss": 0.24,
      "step": 2860
    },
    {
      "epoch": 0.22233447311159465,
      "grad_norm": 0.04311384633183479,
      "learning_rate": 8.888327634442028e-06,
      "loss": 0.0121,
      "step": 2861
    },
    {
      "epoch": 0.22241218526577558,
      "grad_norm": 0.13587433099746704,
      "learning_rate": 8.887939073671123e-06,
      "loss": 0.0827,
      "step": 2862
    },
    {
      "epoch": 0.22248989741995648,
      "grad_norm": 0.7033357620239258,
      "learning_rate": 8.887550512900218e-06,
      "loss": 0.5037,
      "step": 2863
    },
    {
      "epoch": 0.2225676095741374,
      "grad_norm": 0.47835397720336914,
      "learning_rate": 8.887161952129314e-06,
      "loss": 0.8933,
      "step": 2864
    },
    {
      "epoch": 0.2226453217283183,
      "grad_norm": 0.16177035868167877,
      "learning_rate": 8.88677339135841e-06,
      "loss": 0.1092,
      "step": 2865
    },
    {
      "epoch": 0.22272303388249923,
      "grad_norm": 1.1802585124969482,
      "learning_rate": 8.886384830587504e-06,
      "loss": 0.3353,
      "step": 2866
    },
    {
      "epoch": 0.22280074603668013,
      "grad_norm": 0.6252862215042114,
      "learning_rate": 8.8859962698166e-06,
      "loss": 0.0647,
      "step": 2867
    },
    {
      "epoch": 0.22287845819086105,
      "grad_norm": 0.3741028606891632,
      "learning_rate": 8.885607709045696e-06,
      "loss": 0.125,
      "step": 2868
    },
    {
      "epoch": 0.22295617034504198,
      "grad_norm": 0.3237517178058624,
      "learning_rate": 8.88521914827479e-06,
      "loss": 0.1569,
      "step": 2869
    },
    {
      "epoch": 0.22303388249922287,
      "grad_norm": 0.2905910015106201,
      "learning_rate": 8.884830587503887e-06,
      "loss": 0.0874,
      "step": 2870
    },
    {
      "epoch": 0.2231115946534038,
      "grad_norm": 0.21376462280750275,
      "learning_rate": 8.884442026732982e-06,
      "loss": 0.1182,
      "step": 2871
    },
    {
      "epoch": 0.2231893068075847,
      "grad_norm": 0.25406914949417114,
      "learning_rate": 8.884053465962077e-06,
      "loss": 0.1766,
      "step": 2872
    },
    {
      "epoch": 0.22326701896176562,
      "grad_norm": 0.4333898425102234,
      "learning_rate": 8.883664905191172e-06,
      "loss": 0.1541,
      "step": 2873
    },
    {
      "epoch": 0.22334473111594652,
      "grad_norm": 0.16110824048519135,
      "learning_rate": 8.883276344420269e-06,
      "loss": 0.0343,
      "step": 2874
    },
    {
      "epoch": 0.22342244327012745,
      "grad_norm": 0.4364791512489319,
      "learning_rate": 8.882887783649364e-06,
      "loss": 0.2025,
      "step": 2875
    },
    {
      "epoch": 0.22350015542430837,
      "grad_norm": 0.41618576645851135,
      "learning_rate": 8.882499222878459e-06,
      "loss": 0.4227,
      "step": 2876
    },
    {
      "epoch": 0.22357786757848927,
      "grad_norm": 0.2536157965660095,
      "learning_rate": 8.882110662107555e-06,
      "loss": 0.2716,
      "step": 2877
    },
    {
      "epoch": 0.2236555797326702,
      "grad_norm": 0.09065359085798264,
      "learning_rate": 8.881722101336649e-06,
      "loss": 0.0515,
      "step": 2878
    },
    {
      "epoch": 0.2237332918868511,
      "grad_norm": 0.336028516292572,
      "learning_rate": 8.881333540565745e-06,
      "loss": 0.2222,
      "step": 2879
    },
    {
      "epoch": 0.22381100404103202,
      "grad_norm": 0.1833709478378296,
      "learning_rate": 8.88094497979484e-06,
      "loss": 0.1323,
      "step": 2880
    },
    {
      "epoch": 0.22388871619521294,
      "grad_norm": 0.4644373953342438,
      "learning_rate": 8.880556419023935e-06,
      "loss": 0.3854,
      "step": 2881
    },
    {
      "epoch": 0.22396642834939384,
      "grad_norm": 0.42446330189704895,
      "learning_rate": 8.880167858253032e-06,
      "loss": 0.2969,
      "step": 2882
    },
    {
      "epoch": 0.22404414050357477,
      "grad_norm": 0.2965160608291626,
      "learning_rate": 8.879779297482127e-06,
      "loss": 0.2512,
      "step": 2883
    },
    {
      "epoch": 0.22412185265775567,
      "grad_norm": 0.31602397561073303,
      "learning_rate": 8.879390736711222e-06,
      "loss": 0.313,
      "step": 2884
    },
    {
      "epoch": 0.2241995648119366,
      "grad_norm": 0.2707935571670532,
      "learning_rate": 8.879002175940318e-06,
      "loss": 0.2616,
      "step": 2885
    },
    {
      "epoch": 0.2242772769661175,
      "grad_norm": 0.4030033349990845,
      "learning_rate": 8.878613615169413e-06,
      "loss": 0.1722,
      "step": 2886
    },
    {
      "epoch": 0.22435498912029841,
      "grad_norm": 0.3520205020904541,
      "learning_rate": 8.878225054398508e-06,
      "loss": 0.3282,
      "step": 2887
    },
    {
      "epoch": 0.22443270127447934,
      "grad_norm": 0.2753934860229492,
      "learning_rate": 8.877836493627603e-06,
      "loss": 0.1311,
      "step": 2888
    },
    {
      "epoch": 0.22451041342866024,
      "grad_norm": 0.6744310855865479,
      "learning_rate": 8.8774479328567e-06,
      "loss": 0.3228,
      "step": 2889
    },
    {
      "epoch": 0.22458812558284116,
      "grad_norm": 0.14857344329357147,
      "learning_rate": 8.877059372085795e-06,
      "loss": 0.1085,
      "step": 2890
    },
    {
      "epoch": 0.22466583773702206,
      "grad_norm": 0.16302824020385742,
      "learning_rate": 8.87667081131489e-06,
      "loss": 0.1154,
      "step": 2891
    },
    {
      "epoch": 0.224743549891203,
      "grad_norm": 0.503512978553772,
      "learning_rate": 8.876282250543986e-06,
      "loss": 0.5577,
      "step": 2892
    },
    {
      "epoch": 0.22482126204538389,
      "grad_norm": 0.043301597237586975,
      "learning_rate": 8.875893689773081e-06,
      "loss": 0.0083,
      "step": 2893
    },
    {
      "epoch": 0.2248989741995648,
      "grad_norm": 0.18742047250270844,
      "learning_rate": 8.875505129002176e-06,
      "loss": 0.1042,
      "step": 2894
    },
    {
      "epoch": 0.22497668635374574,
      "grad_norm": 0.1853688806295395,
      "learning_rate": 8.875116568231273e-06,
      "loss": 0.0839,
      "step": 2895
    },
    {
      "epoch": 0.22505439850792663,
      "grad_norm": 0.334147185087204,
      "learning_rate": 8.874728007460366e-06,
      "loss": 0.3199,
      "step": 2896
    },
    {
      "epoch": 0.22513211066210756,
      "grad_norm": 0.21384206414222717,
      "learning_rate": 8.874339446689463e-06,
      "loss": 0.0579,
      "step": 2897
    },
    {
      "epoch": 0.22520982281628846,
      "grad_norm": 0.5895418524742126,
      "learning_rate": 8.873950885918558e-06,
      "loss": 0.7128,
      "step": 2898
    },
    {
      "epoch": 0.22528753497046938,
      "grad_norm": 0.19202615320682526,
      "learning_rate": 8.873562325147654e-06,
      "loss": 0.3506,
      "step": 2899
    },
    {
      "epoch": 0.2253652471246503,
      "grad_norm": 0.08515863865613937,
      "learning_rate": 8.87317376437675e-06,
      "loss": 0.0697,
      "step": 2900
    },
    {
      "epoch": 0.2254429592788312,
      "grad_norm": 0.2291904091835022,
      "learning_rate": 8.872785203605844e-06,
      "loss": 0.0884,
      "step": 2901
    },
    {
      "epoch": 0.22552067143301213,
      "grad_norm": 0.2858107388019562,
      "learning_rate": 8.872396642834941e-06,
      "loss": 0.0687,
      "step": 2902
    },
    {
      "epoch": 0.22559838358719303,
      "grad_norm": 0.33666640520095825,
      "learning_rate": 8.872008082064036e-06,
      "loss": 0.256,
      "step": 2903
    },
    {
      "epoch": 0.22567609574137396,
      "grad_norm": 0.29191598296165466,
      "learning_rate": 8.871619521293131e-06,
      "loss": 0.1524,
      "step": 2904
    },
    {
      "epoch": 0.22575380789555485,
      "grad_norm": 0.24490056931972504,
      "learning_rate": 8.871230960522228e-06,
      "loss": 0.0748,
      "step": 2905
    },
    {
      "epoch": 0.22583152004973578,
      "grad_norm": 0.13350029289722443,
      "learning_rate": 8.87084239975132e-06,
      "loss": 0.0356,
      "step": 2906
    },
    {
      "epoch": 0.2259092322039167,
      "grad_norm": 0.12973296642303467,
      "learning_rate": 8.870453838980417e-06,
      "loss": 0.0249,
      "step": 2907
    },
    {
      "epoch": 0.2259869443580976,
      "grad_norm": 0.24925313889980316,
      "learning_rate": 8.870065278209512e-06,
      "loss": 0.2051,
      "step": 2908
    },
    {
      "epoch": 0.22606465651227853,
      "grad_norm": 0.2402043640613556,
      "learning_rate": 8.869676717438607e-06,
      "loss": 0.4632,
      "step": 2909
    },
    {
      "epoch": 0.22614236866645943,
      "grad_norm": 0.20023512840270996,
      "learning_rate": 8.869288156667704e-06,
      "loss": 0.216,
      "step": 2910
    },
    {
      "epoch": 0.22622008082064035,
      "grad_norm": 0.6434566378593445,
      "learning_rate": 8.868899595896799e-06,
      "loss": 0.5633,
      "step": 2911
    },
    {
      "epoch": 0.22629779297482125,
      "grad_norm": 0.2054518759250641,
      "learning_rate": 8.868511035125894e-06,
      "loss": 0.2042,
      "step": 2912
    },
    {
      "epoch": 0.22637550512900217,
      "grad_norm": 0.3995898962020874,
      "learning_rate": 8.86812247435499e-06,
      "loss": 0.2608,
      "step": 2913
    },
    {
      "epoch": 0.2264532172831831,
      "grad_norm": 0.7175652384757996,
      "learning_rate": 8.867733913584085e-06,
      "loss": 0.3011,
      "step": 2914
    },
    {
      "epoch": 0.226530929437364,
      "grad_norm": 1.011476993560791,
      "learning_rate": 8.86734535281318e-06,
      "loss": 0.311,
      "step": 2915
    },
    {
      "epoch": 0.22660864159154492,
      "grad_norm": 0.3396071791648865,
      "learning_rate": 8.866956792042275e-06,
      "loss": 0.2692,
      "step": 2916
    },
    {
      "epoch": 0.22668635374572582,
      "grad_norm": 0.4008466303348541,
      "learning_rate": 8.866568231271372e-06,
      "loss": 0.468,
      "step": 2917
    },
    {
      "epoch": 0.22676406589990675,
      "grad_norm": 0.43580755591392517,
      "learning_rate": 8.866179670500467e-06,
      "loss": 0.2208,
      "step": 2918
    },
    {
      "epoch": 0.22684177805408767,
      "grad_norm": 0.21375808119773865,
      "learning_rate": 8.865791109729562e-06,
      "loss": 0.121,
      "step": 2919
    },
    {
      "epoch": 0.22691949020826857,
      "grad_norm": 0.18019594252109528,
      "learning_rate": 8.865402548958659e-06,
      "loss": 0.1192,
      "step": 2920
    },
    {
      "epoch": 0.2269972023624495,
      "grad_norm": 0.22725653648376465,
      "learning_rate": 8.865013988187753e-06,
      "loss": 0.0358,
      "step": 2921
    },
    {
      "epoch": 0.2270749145166304,
      "grad_norm": 0.3439403772354126,
      "learning_rate": 8.864625427416848e-06,
      "loss": 0.1356,
      "step": 2922
    },
    {
      "epoch": 0.22715262667081132,
      "grad_norm": 0.04324064776301384,
      "learning_rate": 8.864236866645945e-06,
      "loss": 0.0083,
      "step": 2923
    },
    {
      "epoch": 0.22723033882499222,
      "grad_norm": 0.2858041524887085,
      "learning_rate": 8.863848305875038e-06,
      "loss": 0.1628,
      "step": 2924
    },
    {
      "epoch": 0.22730805097917314,
      "grad_norm": 0.20954293012619019,
      "learning_rate": 8.863459745104135e-06,
      "loss": 0.4538,
      "step": 2925
    },
    {
      "epoch": 0.22738576313335407,
      "grad_norm": 0.2847844660282135,
      "learning_rate": 8.86307118433323e-06,
      "loss": 0.2089,
      "step": 2926
    },
    {
      "epoch": 0.22746347528753497,
      "grad_norm": 0.3405908942222595,
      "learning_rate": 8.862682623562325e-06,
      "loss": 0.1244,
      "step": 2927
    },
    {
      "epoch": 0.2275411874417159,
      "grad_norm": 0.28581979870796204,
      "learning_rate": 8.862294062791422e-06,
      "loss": 0.1688,
      "step": 2928
    },
    {
      "epoch": 0.2276188995958968,
      "grad_norm": 0.1860479861497879,
      "learning_rate": 8.861905502020516e-06,
      "loss": 0.0501,
      "step": 2929
    },
    {
      "epoch": 0.22769661175007772,
      "grad_norm": 0.442779541015625,
      "learning_rate": 8.861516941249613e-06,
      "loss": 0.3739,
      "step": 2930
    },
    {
      "epoch": 0.2277743239042586,
      "grad_norm": 0.20051318407058716,
      "learning_rate": 8.861128380478708e-06,
      "loss": 0.1374,
      "step": 2931
    },
    {
      "epoch": 0.22785203605843954,
      "grad_norm": 0.16121406853199005,
      "learning_rate": 8.860739819707803e-06,
      "loss": 0.0871,
      "step": 2932
    },
    {
      "epoch": 0.22792974821262046,
      "grad_norm": 0.6753173470497131,
      "learning_rate": 8.8603512589369e-06,
      "loss": 0.1694,
      "step": 2933
    },
    {
      "epoch": 0.22800746036680136,
      "grad_norm": 0.44287094473838806,
      "learning_rate": 8.859962698165993e-06,
      "loss": 0.4724,
      "step": 2934
    },
    {
      "epoch": 0.2280851725209823,
      "grad_norm": 0.621660590171814,
      "learning_rate": 8.85957413739509e-06,
      "loss": 0.1855,
      "step": 2935
    },
    {
      "epoch": 0.22816288467516319,
      "grad_norm": 0.11023513227701187,
      "learning_rate": 8.859185576624185e-06,
      "loss": 0.0498,
      "step": 2936
    },
    {
      "epoch": 0.2282405968293441,
      "grad_norm": 0.6923023462295532,
      "learning_rate": 8.85879701585328e-06,
      "loss": 0.3326,
      "step": 2937
    },
    {
      "epoch": 0.22831830898352504,
      "grad_norm": 0.2128245234489441,
      "learning_rate": 8.858408455082376e-06,
      "loss": 0.1042,
      "step": 2938
    },
    {
      "epoch": 0.22839602113770593,
      "grad_norm": 0.24137891829013824,
      "learning_rate": 8.858019894311471e-06,
      "loss": 0.0987,
      "step": 2939
    },
    {
      "epoch": 0.22847373329188686,
      "grad_norm": 0.20871376991271973,
      "learning_rate": 8.857631333540566e-06,
      "loss": 0.1442,
      "step": 2940
    },
    {
      "epoch": 0.22855144544606776,
      "grad_norm": 0.2707158923149109,
      "learning_rate": 8.857242772769663e-06,
      "loss": 0.1312,
      "step": 2941
    },
    {
      "epoch": 0.22862915760024868,
      "grad_norm": 0.5464361906051636,
      "learning_rate": 8.856854211998758e-06,
      "loss": 0.285,
      "step": 2942
    },
    {
      "epoch": 0.22870686975442958,
      "grad_norm": 0.6631530523300171,
      "learning_rate": 8.856465651227853e-06,
      "loss": 0.2062,
      "step": 2943
    },
    {
      "epoch": 0.2287845819086105,
      "grad_norm": 0.1578250378370285,
      "learning_rate": 8.856077090456948e-06,
      "loss": 0.1846,
      "step": 2944
    },
    {
      "epoch": 0.22886229406279143,
      "grad_norm": 0.10961180180311203,
      "learning_rate": 8.855688529686044e-06,
      "loss": 0.0464,
      "step": 2945
    },
    {
      "epoch": 0.22894000621697233,
      "grad_norm": 0.5634796619415283,
      "learning_rate": 8.855299968915139e-06,
      "loss": 0.3666,
      "step": 2946
    },
    {
      "epoch": 0.22901771837115326,
      "grad_norm": 0.24071729183197021,
      "learning_rate": 8.854911408144234e-06,
      "loss": 0.0832,
      "step": 2947
    },
    {
      "epoch": 0.22909543052533415,
      "grad_norm": 0.3908432424068451,
      "learning_rate": 8.85452284737333e-06,
      "loss": 0.1829,
      "step": 2948
    },
    {
      "epoch": 0.22917314267951508,
      "grad_norm": 0.2693590521812439,
      "learning_rate": 8.854134286602426e-06,
      "loss": 0.1768,
      "step": 2949
    },
    {
      "epoch": 0.22925085483369598,
      "grad_norm": 0.1615106165409088,
      "learning_rate": 8.85374572583152e-06,
      "loss": 0.1538,
      "step": 2950
    },
    {
      "epoch": 0.2293285669878769,
      "grad_norm": 0.11491785943508148,
      "learning_rate": 8.853357165060617e-06,
      "loss": 0.0539,
      "step": 2951
    },
    {
      "epoch": 0.22940627914205783,
      "grad_norm": 0.3906961679458618,
      "learning_rate": 8.85296860428971e-06,
      "loss": 0.2583,
      "step": 2952
    },
    {
      "epoch": 0.22948399129623873,
      "grad_norm": 0.25117170810699463,
      "learning_rate": 8.852580043518807e-06,
      "loss": 0.1842,
      "step": 2953
    },
    {
      "epoch": 0.22956170345041965,
      "grad_norm": 0.3079635798931122,
      "learning_rate": 8.852191482747902e-06,
      "loss": 0.2745,
      "step": 2954
    },
    {
      "epoch": 0.22963941560460055,
      "grad_norm": 0.5040006637573242,
      "learning_rate": 8.851802921976997e-06,
      "loss": 0.4996,
      "step": 2955
    },
    {
      "epoch": 0.22971712775878148,
      "grad_norm": 0.08183317631483078,
      "learning_rate": 8.851414361206094e-06,
      "loss": 0.0322,
      "step": 2956
    },
    {
      "epoch": 0.2297948399129624,
      "grad_norm": 0.30830880999565125,
      "learning_rate": 8.851025800435189e-06,
      "loss": 0.4325,
      "step": 2957
    },
    {
      "epoch": 0.2298725520671433,
      "grad_norm": 0.05587109178304672,
      "learning_rate": 8.850637239664284e-06,
      "loss": 0.0267,
      "step": 2958
    },
    {
      "epoch": 0.22995026422132422,
      "grad_norm": 0.3867436647415161,
      "learning_rate": 8.85024867889338e-06,
      "loss": 0.2839,
      "step": 2959
    },
    {
      "epoch": 0.23002797637550512,
      "grad_norm": 0.6734097599983215,
      "learning_rate": 8.849860118122475e-06,
      "loss": 0.1952,
      "step": 2960
    },
    {
      "epoch": 0.23010568852968605,
      "grad_norm": 0.28523099422454834,
      "learning_rate": 8.849471557351572e-06,
      "loss": 0.2145,
      "step": 2961
    },
    {
      "epoch": 0.23018340068386695,
      "grad_norm": 0.8980032205581665,
      "learning_rate": 8.849082996580665e-06,
      "loss": 0.2007,
      "step": 2962
    },
    {
      "epoch": 0.23026111283804787,
      "grad_norm": 0.2548500597476959,
      "learning_rate": 8.848694435809762e-06,
      "loss": 0.1875,
      "step": 2963
    },
    {
      "epoch": 0.2303388249922288,
      "grad_norm": 0.06775437295436859,
      "learning_rate": 8.848305875038857e-06,
      "loss": 0.0448,
      "step": 2964
    },
    {
      "epoch": 0.2304165371464097,
      "grad_norm": 0.3393878638744354,
      "learning_rate": 8.847917314267952e-06,
      "loss": 0.2343,
      "step": 2965
    },
    {
      "epoch": 0.23049424930059062,
      "grad_norm": 0.13741640746593475,
      "learning_rate": 8.847528753497048e-06,
      "loss": 0.0254,
      "step": 2966
    },
    {
      "epoch": 0.23057196145477152,
      "grad_norm": 0.5440437197685242,
      "learning_rate": 8.847140192726143e-06,
      "loss": 0.4647,
      "step": 2967
    },
    {
      "epoch": 0.23064967360895244,
      "grad_norm": 0.1385585218667984,
      "learning_rate": 8.846751631955238e-06,
      "loss": 0.0362,
      "step": 2968
    },
    {
      "epoch": 0.23072738576313334,
      "grad_norm": 0.21609528362751007,
      "learning_rate": 8.846363071184335e-06,
      "loss": 0.0801,
      "step": 2969
    },
    {
      "epoch": 0.23080509791731427,
      "grad_norm": 0.32392388582229614,
      "learning_rate": 8.84597451041343e-06,
      "loss": 0.3262,
      "step": 2970
    },
    {
      "epoch": 0.2308828100714952,
      "grad_norm": 0.30243149399757385,
      "learning_rate": 8.845585949642525e-06,
      "loss": 0.0862,
      "step": 2971
    },
    {
      "epoch": 0.2309605222256761,
      "grad_norm": 0.14196282625198364,
      "learning_rate": 8.84519738887162e-06,
      "loss": 0.0585,
      "step": 2972
    },
    {
      "epoch": 0.23103823437985702,
      "grad_norm": 0.44295868277549744,
      "learning_rate": 8.844808828100716e-06,
      "loss": 0.2369,
      "step": 2973
    },
    {
      "epoch": 0.2311159465340379,
      "grad_norm": 0.38102710247039795,
      "learning_rate": 8.844420267329811e-06,
      "loss": 0.3108,
      "step": 2974
    },
    {
      "epoch": 0.23119365868821884,
      "grad_norm": 0.11564202606678009,
      "learning_rate": 8.844031706558906e-06,
      "loss": 0.0723,
      "step": 2975
    },
    {
      "epoch": 0.23127137084239976,
      "grad_norm": 0.749660313129425,
      "learning_rate": 8.843643145788003e-06,
      "loss": 0.4003,
      "step": 2976
    },
    {
      "epoch": 0.23134908299658066,
      "grad_norm": 0.30599573254585266,
      "learning_rate": 8.843254585017098e-06,
      "loss": 0.2397,
      "step": 2977
    },
    {
      "epoch": 0.2314267951507616,
      "grad_norm": 0.608277440071106,
      "learning_rate": 8.842866024246193e-06,
      "loss": 0.2322,
      "step": 2978
    },
    {
      "epoch": 0.2315045073049425,
      "grad_norm": 0.37245553731918335,
      "learning_rate": 8.84247746347529e-06,
      "loss": 0.3268,
      "step": 2979
    },
    {
      "epoch": 0.2315822194591234,
      "grad_norm": 0.24465550482273102,
      "learning_rate": 8.842088902704383e-06,
      "loss": 0.1146,
      "step": 2980
    },
    {
      "epoch": 0.2316599316133043,
      "grad_norm": 0.4879167377948761,
      "learning_rate": 8.84170034193348e-06,
      "loss": 0.1964,
      "step": 2981
    },
    {
      "epoch": 0.23173764376748524,
      "grad_norm": 0.04017097130417824,
      "learning_rate": 8.841311781162574e-06,
      "loss": 0.0066,
      "step": 2982
    },
    {
      "epoch": 0.23181535592166616,
      "grad_norm": 0.2689836323261261,
      "learning_rate": 8.84092322039167e-06,
      "loss": 0.104,
      "step": 2983
    },
    {
      "epoch": 0.23189306807584706,
      "grad_norm": 0.043625324964523315,
      "learning_rate": 8.840534659620766e-06,
      "loss": 0.0055,
      "step": 2984
    },
    {
      "epoch": 0.23197078023002798,
      "grad_norm": 0.12414416670799255,
      "learning_rate": 8.84014609884986e-06,
      "loss": 0.0675,
      "step": 2985
    },
    {
      "epoch": 0.23204849238420888,
      "grad_norm": 0.23914629220962524,
      "learning_rate": 8.839757538078956e-06,
      "loss": 0.1416,
      "step": 2986
    },
    {
      "epoch": 0.2321262045383898,
      "grad_norm": 0.3494460880756378,
      "learning_rate": 8.839368977308052e-06,
      "loss": 0.2546,
      "step": 2987
    },
    {
      "epoch": 0.2322039166925707,
      "grad_norm": 0.3425518572330475,
      "learning_rate": 8.838980416537147e-06,
      "loss": 0.0908,
      "step": 2988
    },
    {
      "epoch": 0.23228162884675163,
      "grad_norm": 0.28777262568473816,
      "learning_rate": 8.838591855766242e-06,
      "loss": 0.4394,
      "step": 2989
    },
    {
      "epoch": 0.23235934100093256,
      "grad_norm": 0.22137510776519775,
      "learning_rate": 8.838203294995337e-06,
      "loss": 0.1507,
      "step": 2990
    },
    {
      "epoch": 0.23243705315511345,
      "grad_norm": 0.48434051871299744,
      "learning_rate": 8.837814734224434e-06,
      "loss": 0.3344,
      "step": 2991
    },
    {
      "epoch": 0.23251476530929438,
      "grad_norm": 0.14264948666095734,
      "learning_rate": 8.837426173453529e-06,
      "loss": 0.0642,
      "step": 2992
    },
    {
      "epoch": 0.23259247746347528,
      "grad_norm": 0.3669559061527252,
      "learning_rate": 8.837037612682624e-06,
      "loss": 0.2986,
      "step": 2993
    },
    {
      "epoch": 0.2326701896176562,
      "grad_norm": 0.04410224407911301,
      "learning_rate": 8.83664905191172e-06,
      "loss": 0.0084,
      "step": 2994
    },
    {
      "epoch": 0.23274790177183713,
      "grad_norm": 0.23043414950370789,
      "learning_rate": 8.836260491140815e-06,
      "loss": 0.1144,
      "step": 2995
    },
    {
      "epoch": 0.23282561392601803,
      "grad_norm": 0.448192834854126,
      "learning_rate": 8.83587193036991e-06,
      "loss": 0.697,
      "step": 2996
    },
    {
      "epoch": 0.23290332608019895,
      "grad_norm": 1.2814197540283203,
      "learning_rate": 8.835483369599007e-06,
      "loss": 0.3934,
      "step": 2997
    },
    {
      "epoch": 0.23298103823437985,
      "grad_norm": 0.16855110228061676,
      "learning_rate": 8.835094808828102e-06,
      "loss": 0.1534,
      "step": 2998
    },
    {
      "epoch": 0.23305875038856078,
      "grad_norm": 0.47686097025871277,
      "learning_rate": 8.834706248057197e-06,
      "loss": 0.1305,
      "step": 2999
    },
    {
      "epoch": 0.23313646254274167,
      "grad_norm": 0.9763937592506409,
      "learning_rate": 8.834317687286292e-06,
      "loss": 0.8875,
      "step": 3000
    },
    {
      "epoch": 0.2332141746969226,
      "grad_norm": 0.29018163681030273,
      "learning_rate": 8.833929126515388e-06,
      "loss": 0.1777,
      "step": 3001
    },
    {
      "epoch": 0.23329188685110352,
      "grad_norm": 0.317708820104599,
      "learning_rate": 8.833540565744483e-06,
      "loss": 0.156,
      "step": 3002
    },
    {
      "epoch": 0.23336959900528442,
      "grad_norm": 0.240007683634758,
      "learning_rate": 8.833152004973578e-06,
      "loss": 0.1015,
      "step": 3003
    },
    {
      "epoch": 0.23344731115946535,
      "grad_norm": 0.23227116465568542,
      "learning_rate": 8.832763444202675e-06,
      "loss": 0.2212,
      "step": 3004
    },
    {
      "epoch": 0.23352502331364625,
      "grad_norm": 1.1956835985183716,
      "learning_rate": 8.832374883431768e-06,
      "loss": 0.4511,
      "step": 3005
    },
    {
      "epoch": 0.23360273546782717,
      "grad_norm": 0.27344533801078796,
      "learning_rate": 8.831986322660865e-06,
      "loss": 0.2457,
      "step": 3006
    },
    {
      "epoch": 0.23368044762200807,
      "grad_norm": 0.239047110080719,
      "learning_rate": 8.83159776188996e-06,
      "loss": 0.1745,
      "step": 3007
    },
    {
      "epoch": 0.233758159776189,
      "grad_norm": 0.6556106805801392,
      "learning_rate": 8.831209201119055e-06,
      "loss": 0.4366,
      "step": 3008
    },
    {
      "epoch": 0.23383587193036992,
      "grad_norm": 0.6619144082069397,
      "learning_rate": 8.830820640348151e-06,
      "loss": 0.5722,
      "step": 3009
    },
    {
      "epoch": 0.23391358408455082,
      "grad_norm": 0.4127400815486908,
      "learning_rate": 8.830432079577246e-06,
      "loss": 0.2276,
      "step": 3010
    },
    {
      "epoch": 0.23399129623873174,
      "grad_norm": 0.3432689607143402,
      "learning_rate": 8.830043518806341e-06,
      "loss": 0.0473,
      "step": 3011
    },
    {
      "epoch": 0.23406900839291264,
      "grad_norm": 0.2831232249736786,
      "learning_rate": 8.829654958035438e-06,
      "loss": 0.1284,
      "step": 3012
    },
    {
      "epoch": 0.23414672054709357,
      "grad_norm": 0.22562383115291595,
      "learning_rate": 8.829266397264533e-06,
      "loss": 0.1015,
      "step": 3013
    },
    {
      "epoch": 0.2342244327012745,
      "grad_norm": 0.3465140163898468,
      "learning_rate": 8.828877836493628e-06,
      "loss": 0.1766,
      "step": 3014
    },
    {
      "epoch": 0.2343021448554554,
      "grad_norm": 0.33021673560142517,
      "learning_rate": 8.828489275722723e-06,
      "loss": 0.3158,
      "step": 3015
    },
    {
      "epoch": 0.23437985700963632,
      "grad_norm": 0.3250997066497803,
      "learning_rate": 8.82810071495182e-06,
      "loss": 0.2722,
      "step": 3016
    },
    {
      "epoch": 0.23445756916381721,
      "grad_norm": 0.42219457030296326,
      "learning_rate": 8.827712154180914e-06,
      "loss": 0.2379,
      "step": 3017
    },
    {
      "epoch": 0.23453528131799814,
      "grad_norm": 1.7745237350463867,
      "learning_rate": 8.82732359341001e-06,
      "loss": 0.4639,
      "step": 3018
    },
    {
      "epoch": 0.23461299347217904,
      "grad_norm": 0.047856442630290985,
      "learning_rate": 8.826935032639106e-06,
      "loss": 0.011,
      "step": 3019
    },
    {
      "epoch": 0.23469070562635996,
      "grad_norm": 0.23500822484493256,
      "learning_rate": 8.826546471868201e-06,
      "loss": 0.171,
      "step": 3020
    },
    {
      "epoch": 0.2347684177805409,
      "grad_norm": 0.18116141855716705,
      "learning_rate": 8.826157911097296e-06,
      "loss": 0.0684,
      "step": 3021
    },
    {
      "epoch": 0.2348461299347218,
      "grad_norm": 0.09356504678726196,
      "learning_rate": 8.825769350326393e-06,
      "loss": 0.0666,
      "step": 3022
    },
    {
      "epoch": 0.2349238420889027,
      "grad_norm": 0.50616854429245,
      "learning_rate": 8.825380789555487e-06,
      "loss": 0.3124,
      "step": 3023
    },
    {
      "epoch": 0.2350015542430836,
      "grad_norm": 0.21514210104942322,
      "learning_rate": 8.824992228784582e-06,
      "loss": 0.1804,
      "step": 3024
    },
    {
      "epoch": 0.23507926639726454,
      "grad_norm": 0.18033388257026672,
      "learning_rate": 8.824603668013677e-06,
      "loss": 0.1248,
      "step": 3025
    },
    {
      "epoch": 0.23515697855144543,
      "grad_norm": 0.19054457545280457,
      "learning_rate": 8.824215107242774e-06,
      "loss": 0.1933,
      "step": 3026
    },
    {
      "epoch": 0.23523469070562636,
      "grad_norm": 0.16743624210357666,
      "learning_rate": 8.823826546471869e-06,
      "loss": 0.0504,
      "step": 3027
    },
    {
      "epoch": 0.23531240285980728,
      "grad_norm": 0.21550194919109344,
      "learning_rate": 8.823437985700964e-06,
      "loss": 0.0986,
      "step": 3028
    },
    {
      "epoch": 0.23539011501398818,
      "grad_norm": 0.16508057713508606,
      "learning_rate": 8.82304942493006e-06,
      "loss": 0.103,
      "step": 3029
    },
    {
      "epoch": 0.2354678271681691,
      "grad_norm": 0.05871710553765297,
      "learning_rate": 8.822660864159156e-06,
      "loss": 0.0197,
      "step": 3030
    },
    {
      "epoch": 0.23554553932235,
      "grad_norm": 0.1747780293226242,
      "learning_rate": 8.82227230338825e-06,
      "loss": 0.1355,
      "step": 3031
    },
    {
      "epoch": 0.23562325147653093,
      "grad_norm": 0.11267241835594177,
      "learning_rate": 8.821883742617347e-06,
      "loss": 0.0746,
      "step": 3032
    },
    {
      "epoch": 0.23570096363071186,
      "grad_norm": 0.07676882296800613,
      "learning_rate": 8.82149518184644e-06,
      "loss": 0.0234,
      "step": 3033
    },
    {
      "epoch": 0.23577867578489276,
      "grad_norm": 0.251933217048645,
      "learning_rate": 8.821106621075537e-06,
      "loss": 0.1446,
      "step": 3034
    },
    {
      "epoch": 0.23585638793907368,
      "grad_norm": 0.2526416778564453,
      "learning_rate": 8.820718060304632e-06,
      "loss": 0.0577,
      "step": 3035
    },
    {
      "epoch": 0.23593410009325458,
      "grad_norm": 0.3548762798309326,
      "learning_rate": 8.820329499533727e-06,
      "loss": 0.1967,
      "step": 3036
    },
    {
      "epoch": 0.2360118122474355,
      "grad_norm": 0.5695173740386963,
      "learning_rate": 8.819940938762824e-06,
      "loss": 0.1815,
      "step": 3037
    },
    {
      "epoch": 0.2360895244016164,
      "grad_norm": 0.40515249967575073,
      "learning_rate": 8.819552377991919e-06,
      "loss": 0.3438,
      "step": 3038
    },
    {
      "epoch": 0.23616723655579733,
      "grad_norm": 0.11932596564292908,
      "learning_rate": 8.819163817221013e-06,
      "loss": 0.0449,
      "step": 3039
    },
    {
      "epoch": 0.23624494870997825,
      "grad_norm": 0.24380774796009064,
      "learning_rate": 8.81877525645011e-06,
      "loss": 0.0892,
      "step": 3040
    },
    {
      "epoch": 0.23632266086415915,
      "grad_norm": 0.39197975397109985,
      "learning_rate": 8.818386695679205e-06,
      "loss": 0.2105,
      "step": 3041
    },
    {
      "epoch": 0.23640037301834008,
      "grad_norm": 0.17065177857875824,
      "learning_rate": 8.8179981349083e-06,
      "loss": 0.0648,
      "step": 3042
    },
    {
      "epoch": 0.23647808517252097,
      "grad_norm": 0.2810422480106354,
      "learning_rate": 8.817609574137395e-06,
      "loss": 0.1524,
      "step": 3043
    },
    {
      "epoch": 0.2365557973267019,
      "grad_norm": 0.41387680172920227,
      "learning_rate": 8.817221013366492e-06,
      "loss": 0.7393,
      "step": 3044
    },
    {
      "epoch": 0.2366335094808828,
      "grad_norm": 0.0664859488606453,
      "learning_rate": 8.816832452595587e-06,
      "loss": 0.0133,
      "step": 3045
    },
    {
      "epoch": 0.23671122163506372,
      "grad_norm": 0.3218437433242798,
      "learning_rate": 8.816443891824682e-06,
      "loss": 0.13,
      "step": 3046
    },
    {
      "epoch": 0.23678893378924465,
      "grad_norm": 0.6362038850784302,
      "learning_rate": 8.816055331053778e-06,
      "loss": 0.2585,
      "step": 3047
    },
    {
      "epoch": 0.23686664594342555,
      "grad_norm": 0.1419796347618103,
      "learning_rate": 8.815666770282873e-06,
      "loss": 0.0537,
      "step": 3048
    },
    {
      "epoch": 0.23694435809760647,
      "grad_norm": 0.6795649528503418,
      "learning_rate": 8.815278209511968e-06,
      "loss": 0.6331,
      "step": 3049
    },
    {
      "epoch": 0.23702207025178737,
      "grad_norm": 0.11521003395318985,
      "learning_rate": 8.814889648741065e-06,
      "loss": 0.0565,
      "step": 3050
    },
    {
      "epoch": 0.2370997824059683,
      "grad_norm": 0.8699342608451843,
      "learning_rate": 8.81450108797016e-06,
      "loss": 0.3642,
      "step": 3051
    },
    {
      "epoch": 0.2371774945601492,
      "grad_norm": 0.23400233685970306,
      "learning_rate": 8.814112527199255e-06,
      "loss": 0.1022,
      "step": 3052
    },
    {
      "epoch": 0.23725520671433012,
      "grad_norm": 0.3957660496234894,
      "learning_rate": 8.81372396642835e-06,
      "loss": 0.3392,
      "step": 3053
    },
    {
      "epoch": 0.23733291886851104,
      "grad_norm": 0.5034388303756714,
      "learning_rate": 8.813335405657446e-06,
      "loss": 0.3011,
      "step": 3054
    },
    {
      "epoch": 0.23741063102269194,
      "grad_norm": 0.18871209025382996,
      "learning_rate": 8.812946844886541e-06,
      "loss": 0.0502,
      "step": 3055
    },
    {
      "epoch": 0.23748834317687287,
      "grad_norm": 0.6291317939758301,
      "learning_rate": 8.812558284115636e-06,
      "loss": 0.3734,
      "step": 3056
    },
    {
      "epoch": 0.23756605533105377,
      "grad_norm": 0.27582696080207825,
      "learning_rate": 8.812169723344733e-06,
      "loss": 0.076,
      "step": 3057
    },
    {
      "epoch": 0.2376437674852347,
      "grad_norm": 0.2623122036457062,
      "learning_rate": 8.811781162573828e-06,
      "loss": 0.2386,
      "step": 3058
    },
    {
      "epoch": 0.23772147963941562,
      "grad_norm": 0.20006312429904938,
      "learning_rate": 8.811392601802923e-06,
      "loss": 0.1017,
      "step": 3059
    },
    {
      "epoch": 0.23779919179359651,
      "grad_norm": 0.5812804698944092,
      "learning_rate": 8.81100404103202e-06,
      "loss": 0.1656,
      "step": 3060
    },
    {
      "epoch": 0.23787690394777744,
      "grad_norm": 0.8198652863502502,
      "learning_rate": 8.810615480261113e-06,
      "loss": 0.3933,
      "step": 3061
    },
    {
      "epoch": 0.23795461610195834,
      "grad_norm": 0.2763974368572235,
      "learning_rate": 8.81022691949021e-06,
      "loss": 0.1157,
      "step": 3062
    },
    {
      "epoch": 0.23803232825613926,
      "grad_norm": 0.06151997298002243,
      "learning_rate": 8.809838358719304e-06,
      "loss": 0.0221,
      "step": 3063
    },
    {
      "epoch": 0.23811004041032016,
      "grad_norm": 0.3644651770591736,
      "learning_rate": 8.809449797948399e-06,
      "loss": 0.221,
      "step": 3064
    },
    {
      "epoch": 0.2381877525645011,
      "grad_norm": 0.6838482022285461,
      "learning_rate": 8.809061237177496e-06,
      "loss": 0.9366,
      "step": 3065
    },
    {
      "epoch": 0.238265464718682,
      "grad_norm": 0.45475682616233826,
      "learning_rate": 8.80867267640659e-06,
      "loss": 0.8088,
      "step": 3066
    },
    {
      "epoch": 0.2383431768728629,
      "grad_norm": 0.10513380169868469,
      "learning_rate": 8.808284115635686e-06,
      "loss": 0.24,
      "step": 3067
    },
    {
      "epoch": 0.23842088902704384,
      "grad_norm": 0.33802610635757446,
      "learning_rate": 8.807895554864782e-06,
      "loss": 0.1792,
      "step": 3068
    },
    {
      "epoch": 0.23849860118122473,
      "grad_norm": 0.0985596776008606,
      "learning_rate": 8.807506994093877e-06,
      "loss": 0.0367,
      "step": 3069
    },
    {
      "epoch": 0.23857631333540566,
      "grad_norm": 0.21107028424739838,
      "learning_rate": 8.807118433322972e-06,
      "loss": 0.1404,
      "step": 3070
    },
    {
      "epoch": 0.23865402548958656,
      "grad_norm": 0.1485813558101654,
      "learning_rate": 8.806729872552067e-06,
      "loss": 0.0528,
      "step": 3071
    },
    {
      "epoch": 0.23873173764376748,
      "grad_norm": 0.3760125935077667,
      "learning_rate": 8.806341311781164e-06,
      "loss": 0.1485,
      "step": 3072
    },
    {
      "epoch": 0.2388094497979484,
      "grad_norm": 0.6430431008338928,
      "learning_rate": 8.805952751010259e-06,
      "loss": 0.4049,
      "step": 3073
    },
    {
      "epoch": 0.2388871619521293,
      "grad_norm": 0.43952423334121704,
      "learning_rate": 8.805564190239354e-06,
      "loss": 0.1887,
      "step": 3074
    },
    {
      "epoch": 0.23896487410631023,
      "grad_norm": 0.15402604639530182,
      "learning_rate": 8.80517562946845e-06,
      "loss": 0.0728,
      "step": 3075
    },
    {
      "epoch": 0.23904258626049113,
      "grad_norm": 0.21066215634346008,
      "learning_rate": 8.804787068697545e-06,
      "loss": 0.1324,
      "step": 3076
    },
    {
      "epoch": 0.23912029841467206,
      "grad_norm": 0.18053129315376282,
      "learning_rate": 8.80439850792664e-06,
      "loss": 0.0944,
      "step": 3077
    },
    {
      "epoch": 0.23919801056885298,
      "grad_norm": 0.5876092314720154,
      "learning_rate": 8.804009947155737e-06,
      "loss": 0.5207,
      "step": 3078
    },
    {
      "epoch": 0.23927572272303388,
      "grad_norm": 0.2786107659339905,
      "learning_rate": 8.80362138638483e-06,
      "loss": 0.125,
      "step": 3079
    },
    {
      "epoch": 0.2393534348772148,
      "grad_norm": 0.24668529629707336,
      "learning_rate": 8.803232825613927e-06,
      "loss": 0.2359,
      "step": 3080
    },
    {
      "epoch": 0.2394311470313957,
      "grad_norm": 0.7570204138755798,
      "learning_rate": 8.802844264843022e-06,
      "loss": 0.3385,
      "step": 3081
    },
    {
      "epoch": 0.23950885918557663,
      "grad_norm": 0.2599862515926361,
      "learning_rate": 8.802455704072118e-06,
      "loss": 0.2733,
      "step": 3082
    },
    {
      "epoch": 0.23958657133975753,
      "grad_norm": 0.2782539129257202,
      "learning_rate": 8.802067143301213e-06,
      "loss": 0.1059,
      "step": 3083
    },
    {
      "epoch": 0.23966428349393845,
      "grad_norm": 0.42749106884002686,
      "learning_rate": 8.801678582530308e-06,
      "loss": 0.1943,
      "step": 3084
    },
    {
      "epoch": 0.23974199564811938,
      "grad_norm": 0.1730339676141739,
      "learning_rate": 8.801290021759405e-06,
      "loss": 0.1289,
      "step": 3085
    },
    {
      "epoch": 0.23981970780230027,
      "grad_norm": 0.16474194824695587,
      "learning_rate": 8.8009014609885e-06,
      "loss": 0.0622,
      "step": 3086
    },
    {
      "epoch": 0.2398974199564812,
      "grad_norm": 0.5712648630142212,
      "learning_rate": 8.800512900217595e-06,
      "loss": 0.2379,
      "step": 3087
    },
    {
      "epoch": 0.2399751321106621,
      "grad_norm": 0.8915818929672241,
      "learning_rate": 8.800124339446691e-06,
      "loss": 0.7081,
      "step": 3088
    },
    {
      "epoch": 0.24005284426484302,
      "grad_norm": 0.6637679934501648,
      "learning_rate": 8.799735778675785e-06,
      "loss": 0.3808,
      "step": 3089
    },
    {
      "epoch": 0.24013055641902392,
      "grad_norm": 0.20169079303741455,
      "learning_rate": 8.799347217904881e-06,
      "loss": 0.0889,
      "step": 3090
    },
    {
      "epoch": 0.24020826857320485,
      "grad_norm": 0.15446552634239197,
      "learning_rate": 8.798958657133976e-06,
      "loss": 0.1153,
      "step": 3091
    },
    {
      "epoch": 0.24028598072738577,
      "grad_norm": 0.2528165876865387,
      "learning_rate": 8.798570096363071e-06,
      "loss": 0.107,
      "step": 3092
    },
    {
      "epoch": 0.24036369288156667,
      "grad_norm": 0.16140523552894592,
      "learning_rate": 8.798181535592168e-06,
      "loss": 0.0933,
      "step": 3093
    },
    {
      "epoch": 0.2404414050357476,
      "grad_norm": 0.22401344776153564,
      "learning_rate": 8.797792974821263e-06,
      "loss": 0.1168,
      "step": 3094
    },
    {
      "epoch": 0.2405191171899285,
      "grad_norm": 0.2529163360595703,
      "learning_rate": 8.797404414050358e-06,
      "loss": 0.1481,
      "step": 3095
    },
    {
      "epoch": 0.24059682934410942,
      "grad_norm": 0.35095492005348206,
      "learning_rate": 8.797015853279454e-06,
      "loss": 0.235,
      "step": 3096
    },
    {
      "epoch": 0.24067454149829035,
      "grad_norm": 0.1839705854654312,
      "learning_rate": 8.79662729250855e-06,
      "loss": 0.1383,
      "step": 3097
    },
    {
      "epoch": 0.24075225365247124,
      "grad_norm": 0.31232428550720215,
      "learning_rate": 8.796238731737644e-06,
      "loss": 0.1527,
      "step": 3098
    },
    {
      "epoch": 0.24082996580665217,
      "grad_norm": 0.6059442758560181,
      "learning_rate": 8.79585017096674e-06,
      "loss": 0.4731,
      "step": 3099
    },
    {
      "epoch": 0.24090767796083307,
      "grad_norm": 0.3903593420982361,
      "learning_rate": 8.795461610195836e-06,
      "loss": 0.2117,
      "step": 3100
    },
    {
      "epoch": 0.240985390115014,
      "grad_norm": 0.024416273459792137,
      "learning_rate": 8.795073049424931e-06,
      "loss": 0.0067,
      "step": 3101
    },
    {
      "epoch": 0.2410631022691949,
      "grad_norm": 0.5682592988014221,
      "learning_rate": 8.794684488654026e-06,
      "loss": 0.5264,
      "step": 3102
    },
    {
      "epoch": 0.24114081442337582,
      "grad_norm": 0.21675275266170502,
      "learning_rate": 8.794295927883122e-06,
      "loss": 0.1583,
      "step": 3103
    },
    {
      "epoch": 0.24121852657755674,
      "grad_norm": 0.2239808440208435,
      "learning_rate": 8.793907367112217e-06,
      "loss": 0.1252,
      "step": 3104
    },
    {
      "epoch": 0.24129623873173764,
      "grad_norm": 0.21403667330741882,
      "learning_rate": 8.793518806341312e-06,
      "loss": 0.1136,
      "step": 3105
    },
    {
      "epoch": 0.24137395088591856,
      "grad_norm": 0.3242662250995636,
      "learning_rate": 8.793130245570409e-06,
      "loss": 0.1733,
      "step": 3106
    },
    {
      "epoch": 0.24145166304009946,
      "grad_norm": 0.3767741918563843,
      "learning_rate": 8.792741684799502e-06,
      "loss": 0.2184,
      "step": 3107
    },
    {
      "epoch": 0.2415293751942804,
      "grad_norm": 0.26623308658599854,
      "learning_rate": 8.792353124028599e-06,
      "loss": 0.0758,
      "step": 3108
    },
    {
      "epoch": 0.24160708734846129,
      "grad_norm": 0.5187866687774658,
      "learning_rate": 8.791964563257694e-06,
      "loss": 0.4869,
      "step": 3109
    },
    {
      "epoch": 0.2416847995026422,
      "grad_norm": 0.23292586207389832,
      "learning_rate": 8.791576002486789e-06,
      "loss": 0.0792,
      "step": 3110
    },
    {
      "epoch": 0.24176251165682314,
      "grad_norm": 0.46485188603401184,
      "learning_rate": 8.791187441715885e-06,
      "loss": 0.4555,
      "step": 3111
    },
    {
      "epoch": 0.24184022381100403,
      "grad_norm": 0.2057521939277649,
      "learning_rate": 8.79079888094498e-06,
      "loss": 0.0939,
      "step": 3112
    },
    {
      "epoch": 0.24191793596518496,
      "grad_norm": 0.43594762682914734,
      "learning_rate": 8.790410320174077e-06,
      "loss": 0.1984,
      "step": 3113
    },
    {
      "epoch": 0.24199564811936586,
      "grad_norm": 0.6409888863563538,
      "learning_rate": 8.790021759403172e-06,
      "loss": 0.5622,
      "step": 3114
    },
    {
      "epoch": 0.24207336027354678,
      "grad_norm": 0.18021957576274872,
      "learning_rate": 8.789633198632267e-06,
      "loss": 0.0671,
      "step": 3115
    },
    {
      "epoch": 0.2421510724277277,
      "grad_norm": 0.31749486923217773,
      "learning_rate": 8.789244637861364e-06,
      "loss": 0.1002,
      "step": 3116
    },
    {
      "epoch": 0.2422287845819086,
      "grad_norm": 0.06453169137239456,
      "learning_rate": 8.788856077090457e-06,
      "loss": 0.0219,
      "step": 3117
    },
    {
      "epoch": 0.24230649673608953,
      "grad_norm": 0.4321551024913788,
      "learning_rate": 8.788467516319553e-06,
      "loss": 0.3251,
      "step": 3118
    },
    {
      "epoch": 0.24238420889027043,
      "grad_norm": 0.07024185359477997,
      "learning_rate": 8.788078955548648e-06,
      "loss": 0.0233,
      "step": 3119
    },
    {
      "epoch": 0.24246192104445136,
      "grad_norm": 0.29690060019493103,
      "learning_rate": 8.787690394777743e-06,
      "loss": 0.6537,
      "step": 3120
    },
    {
      "epoch": 0.24253963319863225,
      "grad_norm": 1.2331002950668335,
      "learning_rate": 8.78730183400684e-06,
      "loss": 0.5912,
      "step": 3121
    },
    {
      "epoch": 0.24261734535281318,
      "grad_norm": 0.28702592849731445,
      "learning_rate": 8.786913273235935e-06,
      "loss": 0.0756,
      "step": 3122
    },
    {
      "epoch": 0.2426950575069941,
      "grad_norm": 0.22457058727741241,
      "learning_rate": 8.78652471246503e-06,
      "loss": 0.0614,
      "step": 3123
    },
    {
      "epoch": 0.242772769661175,
      "grad_norm": 0.7849388718605042,
      "learning_rate": 8.786136151694125e-06,
      "loss": 0.2144,
      "step": 3124
    },
    {
      "epoch": 0.24285048181535593,
      "grad_norm": 0.7030155062675476,
      "learning_rate": 8.785747590923222e-06,
      "loss": 0.9815,
      "step": 3125
    },
    {
      "epoch": 0.24292819396953683,
      "grad_norm": 0.25701162219047546,
      "learning_rate": 8.785359030152316e-06,
      "loss": 0.0531,
      "step": 3126
    },
    {
      "epoch": 0.24300590612371775,
      "grad_norm": 0.1653738170862198,
      "learning_rate": 8.784970469381411e-06,
      "loss": 0.0656,
      "step": 3127
    },
    {
      "epoch": 0.24308361827789865,
      "grad_norm": 0.2891876697540283,
      "learning_rate": 8.784581908610508e-06,
      "loss": 0.1429,
      "step": 3128
    },
    {
      "epoch": 0.24316133043207958,
      "grad_norm": 0.02112414315342903,
      "learning_rate": 8.784193347839603e-06,
      "loss": 0.0156,
      "step": 3129
    },
    {
      "epoch": 0.2432390425862605,
      "grad_norm": 0.5614455938339233,
      "learning_rate": 8.783804787068698e-06,
      "loss": 0.1085,
      "step": 3130
    },
    {
      "epoch": 0.2433167547404414,
      "grad_norm": 0.2763136327266693,
      "learning_rate": 8.783416226297795e-06,
      "loss": 0.3987,
      "step": 3131
    },
    {
      "epoch": 0.24339446689462232,
      "grad_norm": 0.39660096168518066,
      "learning_rate": 8.783027665526888e-06,
      "loss": 0.2871,
      "step": 3132
    },
    {
      "epoch": 0.24347217904880322,
      "grad_norm": 0.20579186081886292,
      "learning_rate": 8.782639104755984e-06,
      "loss": 0.0369,
      "step": 3133
    },
    {
      "epoch": 0.24354989120298415,
      "grad_norm": 0.3616730272769928,
      "learning_rate": 8.78225054398508e-06,
      "loss": 0.2298,
      "step": 3134
    },
    {
      "epoch": 0.24362760335716507,
      "grad_norm": 0.23517870903015137,
      "learning_rate": 8.781861983214174e-06,
      "loss": 0.0798,
      "step": 3135
    },
    {
      "epoch": 0.24370531551134597,
      "grad_norm": 0.5905671715736389,
      "learning_rate": 8.781473422443271e-06,
      "loss": 0.1817,
      "step": 3136
    },
    {
      "epoch": 0.2437830276655269,
      "grad_norm": 0.20023734867572784,
      "learning_rate": 8.781084861672366e-06,
      "loss": 0.0483,
      "step": 3137
    },
    {
      "epoch": 0.2438607398197078,
      "grad_norm": 0.07902077585458755,
      "learning_rate": 8.780696300901461e-06,
      "loss": 0.0239,
      "step": 3138
    },
    {
      "epoch": 0.24393845197388872,
      "grad_norm": 0.778833270072937,
      "learning_rate": 8.780307740130558e-06,
      "loss": 0.3873,
      "step": 3139
    },
    {
      "epoch": 0.24401616412806962,
      "grad_norm": 0.07290472835302353,
      "learning_rate": 8.779919179359653e-06,
      "loss": 0.0402,
      "step": 3140
    },
    {
      "epoch": 0.24409387628225054,
      "grad_norm": 0.346706360578537,
      "learning_rate": 8.779530618588747e-06,
      "loss": 0.1324,
      "step": 3141
    },
    {
      "epoch": 0.24417158843643147,
      "grad_norm": 0.3033488392829895,
      "learning_rate": 8.779142057817842e-06,
      "loss": 0.1473,
      "step": 3142
    },
    {
      "epoch": 0.24424930059061237,
      "grad_norm": 1.1859230995178223,
      "learning_rate": 8.778753497046939e-06,
      "loss": 0.6848,
      "step": 3143
    },
    {
      "epoch": 0.2443270127447933,
      "grad_norm": 0.3464723527431488,
      "learning_rate": 8.778364936276034e-06,
      "loss": 0.1236,
      "step": 3144
    },
    {
      "epoch": 0.2444047248989742,
      "grad_norm": 0.24063865840435028,
      "learning_rate": 8.777976375505129e-06,
      "loss": 0.2571,
      "step": 3145
    },
    {
      "epoch": 0.24448243705315512,
      "grad_norm": 0.4135192632675171,
      "learning_rate": 8.777587814734226e-06,
      "loss": 0.1628,
      "step": 3146
    },
    {
      "epoch": 0.24456014920733601,
      "grad_norm": 0.24338802695274353,
      "learning_rate": 8.77719925396332e-06,
      "loss": 0.2026,
      "step": 3147
    },
    {
      "epoch": 0.24463786136151694,
      "grad_norm": 0.024334250018000603,
      "learning_rate": 8.776810693192416e-06,
      "loss": 0.0519,
      "step": 3148
    },
    {
      "epoch": 0.24471557351569787,
      "grad_norm": 0.42537814378738403,
      "learning_rate": 8.776422132421512e-06,
      "loss": 0.2649,
      "step": 3149
    },
    {
      "epoch": 0.24479328566987876,
      "grad_norm": 0.39927685260772705,
      "learning_rate": 8.776033571650607e-06,
      "loss": 0.1803,
      "step": 3150
    },
    {
      "epoch": 0.2448709978240597,
      "grad_norm": 0.7884750962257385,
      "learning_rate": 8.775645010879702e-06,
      "loss": 0.5391,
      "step": 3151
    },
    {
      "epoch": 0.2449487099782406,
      "grad_norm": 0.3385779857635498,
      "learning_rate": 8.775256450108797e-06,
      "loss": 0.502,
      "step": 3152
    },
    {
      "epoch": 0.2450264221324215,
      "grad_norm": 0.39235934615135193,
      "learning_rate": 8.774867889337894e-06,
      "loss": 0.1624,
      "step": 3153
    },
    {
      "epoch": 0.24510413428660244,
      "grad_norm": 0.18558654189109802,
      "learning_rate": 8.774479328566989e-06,
      "loss": 0.1853,
      "step": 3154
    },
    {
      "epoch": 0.24518184644078334,
      "grad_norm": 0.17754128575325012,
      "learning_rate": 8.774090767796084e-06,
      "loss": 0.1424,
      "step": 3155
    },
    {
      "epoch": 0.24525955859496426,
      "grad_norm": 0.8229268193244934,
      "learning_rate": 8.77370220702518e-06,
      "loss": 0.4926,
      "step": 3156
    },
    {
      "epoch": 0.24533727074914516,
      "grad_norm": 0.20564036071300507,
      "learning_rate": 8.773313646254275e-06,
      "loss": 0.1059,
      "step": 3157
    },
    {
      "epoch": 0.24541498290332608,
      "grad_norm": 0.18621696531772614,
      "learning_rate": 8.77292508548337e-06,
      "loss": 0.1022,
      "step": 3158
    },
    {
      "epoch": 0.24549269505750698,
      "grad_norm": 0.2728096544742584,
      "learning_rate": 8.772536524712467e-06,
      "loss": 0.095,
      "step": 3159
    },
    {
      "epoch": 0.2455704072116879,
      "grad_norm": 0.1794906109571457,
      "learning_rate": 8.77214796394156e-06,
      "loss": 0.0876,
      "step": 3160
    },
    {
      "epoch": 0.24564811936586883,
      "grad_norm": 0.09753824770450592,
      "learning_rate": 8.771759403170657e-06,
      "loss": 0.0342,
      "step": 3161
    },
    {
      "epoch": 0.24572583152004973,
      "grad_norm": 0.15768256783485413,
      "learning_rate": 8.771370842399752e-06,
      "loss": 0.0454,
      "step": 3162
    },
    {
      "epoch": 0.24580354367423066,
      "grad_norm": 0.2827136218547821,
      "learning_rate": 8.770982281628847e-06,
      "loss": 0.1968,
      "step": 3163
    },
    {
      "epoch": 0.24588125582841155,
      "grad_norm": 0.2699601352214813,
      "learning_rate": 8.770593720857943e-06,
      "loss": 0.0782,
      "step": 3164
    },
    {
      "epoch": 0.24595896798259248,
      "grad_norm": 0.23400691151618958,
      "learning_rate": 8.770205160087038e-06,
      "loss": 0.132,
      "step": 3165
    },
    {
      "epoch": 0.24603668013677338,
      "grad_norm": 0.2179417461156845,
      "learning_rate": 8.769816599316133e-06,
      "loss": 0.1392,
      "step": 3166
    },
    {
      "epoch": 0.2461143922909543,
      "grad_norm": 0.15917618572711945,
      "learning_rate": 8.76942803854523e-06,
      "loss": 0.0532,
      "step": 3167
    },
    {
      "epoch": 0.24619210444513523,
      "grad_norm": 0.35150688886642456,
      "learning_rate": 8.769039477774325e-06,
      "loss": 0.1164,
      "step": 3168
    },
    {
      "epoch": 0.24626981659931613,
      "grad_norm": 0.8689576983451843,
      "learning_rate": 8.76865091700342e-06,
      "loss": 0.3339,
      "step": 3169
    },
    {
      "epoch": 0.24634752875349705,
      "grad_norm": 0.3165825605392456,
      "learning_rate": 8.768262356232515e-06,
      "loss": 0.4153,
      "step": 3170
    },
    {
      "epoch": 0.24642524090767795,
      "grad_norm": 0.511851966381073,
      "learning_rate": 8.767873795461611e-06,
      "loss": 0.3935,
      "step": 3171
    },
    {
      "epoch": 0.24650295306185888,
      "grad_norm": 0.2911279499530792,
      "learning_rate": 8.767485234690706e-06,
      "loss": 0.0655,
      "step": 3172
    },
    {
      "epoch": 0.2465806652160398,
      "grad_norm": 0.22669008374214172,
      "learning_rate": 8.767096673919801e-06,
      "loss": 0.0292,
      "step": 3173
    },
    {
      "epoch": 0.2466583773702207,
      "grad_norm": 0.11081533879041672,
      "learning_rate": 8.766708113148898e-06,
      "loss": 0.0541,
      "step": 3174
    },
    {
      "epoch": 0.24673608952440163,
      "grad_norm": 0.5610638856887817,
      "learning_rate": 8.766319552377993e-06,
      "loss": 0.3272,
      "step": 3175
    },
    {
      "epoch": 0.24681380167858252,
      "grad_norm": 0.25501927733421326,
      "learning_rate": 8.765930991607088e-06,
      "loss": 0.0858,
      "step": 3176
    },
    {
      "epoch": 0.24689151383276345,
      "grad_norm": 1.1071685552597046,
      "learning_rate": 8.765542430836184e-06,
      "loss": 0.4207,
      "step": 3177
    },
    {
      "epoch": 0.24696922598694435,
      "grad_norm": 0.11958986520767212,
      "learning_rate": 8.76515387006528e-06,
      "loss": 0.0665,
      "step": 3178
    },
    {
      "epoch": 0.24704693814112527,
      "grad_norm": 0.11702616512775421,
      "learning_rate": 8.764765309294374e-06,
      "loss": 0.0312,
      "step": 3179
    },
    {
      "epoch": 0.2471246502953062,
      "grad_norm": 0.27995240688323975,
      "learning_rate": 8.764376748523469e-06,
      "loss": 0.223,
      "step": 3180
    },
    {
      "epoch": 0.2472023624494871,
      "grad_norm": 0.33574193716049194,
      "learning_rate": 8.763988187752566e-06,
      "loss": 0.1103,
      "step": 3181
    },
    {
      "epoch": 0.24728007460366802,
      "grad_norm": 0.14936606585979462,
      "learning_rate": 8.76359962698166e-06,
      "loss": 0.1023,
      "step": 3182
    },
    {
      "epoch": 0.24735778675784892,
      "grad_norm": 0.22231976687908173,
      "learning_rate": 8.763211066210756e-06,
      "loss": 0.0425,
      "step": 3183
    },
    {
      "epoch": 0.24743549891202984,
      "grad_norm": 0.13057921826839447,
      "learning_rate": 8.762822505439852e-06,
      "loss": 0.071,
      "step": 3184
    },
    {
      "epoch": 0.24751321106621074,
      "grad_norm": 0.11772409826517105,
      "learning_rate": 8.762433944668947e-06,
      "loss": 0.0563,
      "step": 3185
    },
    {
      "epoch": 0.24759092322039167,
      "grad_norm": 0.09163752943277359,
      "learning_rate": 8.762045383898042e-06,
      "loss": 0.0358,
      "step": 3186
    },
    {
      "epoch": 0.2476686353745726,
      "grad_norm": 0.44347694516181946,
      "learning_rate": 8.761656823127139e-06,
      "loss": 0.2499,
      "step": 3187
    },
    {
      "epoch": 0.2477463475287535,
      "grad_norm": 0.6547426581382751,
      "learning_rate": 8.761268262356232e-06,
      "loss": 0.8037,
      "step": 3188
    },
    {
      "epoch": 0.24782405968293442,
      "grad_norm": 0.1247691959142685,
      "learning_rate": 8.760879701585329e-06,
      "loss": 0.021,
      "step": 3189
    },
    {
      "epoch": 0.24790177183711531,
      "grad_norm": 1.3177549839019775,
      "learning_rate": 8.760491140814424e-06,
      "loss": 0.2334,
      "step": 3190
    },
    {
      "epoch": 0.24797948399129624,
      "grad_norm": 0.11859609931707382,
      "learning_rate": 8.760102580043519e-06,
      "loss": 0.0677,
      "step": 3191
    },
    {
      "epoch": 0.24805719614547717,
      "grad_norm": 0.8636000156402588,
      "learning_rate": 8.759714019272615e-06,
      "loss": 0.7175,
      "step": 3192
    },
    {
      "epoch": 0.24813490829965806,
      "grad_norm": 0.14261355996131897,
      "learning_rate": 8.75932545850171e-06,
      "loss": 0.0674,
      "step": 3193
    },
    {
      "epoch": 0.248212620453839,
      "grad_norm": 0.15616966784000397,
      "learning_rate": 8.758936897730805e-06,
      "loss": 0.0416,
      "step": 3194
    },
    {
      "epoch": 0.2482903326080199,
      "grad_norm": 0.7371833920478821,
      "learning_rate": 8.758548336959902e-06,
      "loss": 0.1887,
      "step": 3195
    },
    {
      "epoch": 0.2483680447622008,
      "grad_norm": 0.8122747540473938,
      "learning_rate": 8.758159776188997e-06,
      "loss": 0.6998,
      "step": 3196
    },
    {
      "epoch": 0.2484457569163817,
      "grad_norm": 0.2113473117351532,
      "learning_rate": 8.757771215418092e-06,
      "loss": 0.13,
      "step": 3197
    },
    {
      "epoch": 0.24852346907056264,
      "grad_norm": 0.3337230086326599,
      "learning_rate": 8.757382654647187e-06,
      "loss": 0.1222,
      "step": 3198
    },
    {
      "epoch": 0.24860118122474356,
      "grad_norm": 0.16492265462875366,
      "learning_rate": 8.756994093876283e-06,
      "loss": 0.065,
      "step": 3199
    },
    {
      "epoch": 0.24867889337892446,
      "grad_norm": 0.1315564662218094,
      "learning_rate": 8.756605533105378e-06,
      "loss": 0.1058,
      "step": 3200
    },
    {
      "epoch": 0.24875660553310538,
      "grad_norm": 0.11534659564495087,
      "learning_rate": 8.756216972334473e-06,
      "loss": 0.0518,
      "step": 3201
    },
    {
      "epoch": 0.24883431768728628,
      "grad_norm": 0.4720132350921631,
      "learning_rate": 8.75582841156357e-06,
      "loss": 0.2618,
      "step": 3202
    },
    {
      "epoch": 0.2489120298414672,
      "grad_norm": 0.3152860403060913,
      "learning_rate": 8.755439850792665e-06,
      "loss": 0.3616,
      "step": 3203
    },
    {
      "epoch": 0.2489897419956481,
      "grad_norm": 0.5174407362937927,
      "learning_rate": 8.75505129002176e-06,
      "loss": 0.1785,
      "step": 3204
    },
    {
      "epoch": 0.24906745414982903,
      "grad_norm": 0.2983332574367523,
      "learning_rate": 8.754662729250856e-06,
      "loss": 0.1735,
      "step": 3205
    },
    {
      "epoch": 0.24914516630400996,
      "grad_norm": 0.22204086184501648,
      "learning_rate": 8.754274168479951e-06,
      "loss": 0.1371,
      "step": 3206
    },
    {
      "epoch": 0.24922287845819086,
      "grad_norm": 0.21249285340309143,
      "learning_rate": 8.753885607709046e-06,
      "loss": 0.0515,
      "step": 3207
    },
    {
      "epoch": 0.24930059061237178,
      "grad_norm": 0.5055368542671204,
      "learning_rate": 8.753497046938141e-06,
      "loss": 0.4343,
      "step": 3208
    },
    {
      "epoch": 0.24937830276655268,
      "grad_norm": 0.44498124718666077,
      "learning_rate": 8.753108486167238e-06,
      "loss": 0.4498,
      "step": 3209
    },
    {
      "epoch": 0.2494560149207336,
      "grad_norm": 0.3094707727432251,
      "learning_rate": 8.752719925396333e-06,
      "loss": 0.1685,
      "step": 3210
    },
    {
      "epoch": 0.24953372707491453,
      "grad_norm": 0.2833738327026367,
      "learning_rate": 8.752331364625428e-06,
      "loss": 0.1257,
      "step": 3211
    },
    {
      "epoch": 0.24961143922909543,
      "grad_norm": 0.5034091472625732,
      "learning_rate": 8.751942803854524e-06,
      "loss": 0.4345,
      "step": 3212
    },
    {
      "epoch": 0.24968915138327635,
      "grad_norm": 0.18023233115673065,
      "learning_rate": 8.75155424308362e-06,
      "loss": 0.1767,
      "step": 3213
    },
    {
      "epoch": 0.24976686353745725,
      "grad_norm": 0.4988015592098236,
      "learning_rate": 8.751165682312714e-06,
      "loss": 0.1453,
      "step": 3214
    },
    {
      "epoch": 0.24984457569163818,
      "grad_norm": 0.36083975434303284,
      "learning_rate": 8.750777121541811e-06,
      "loss": 0.6382,
      "step": 3215
    },
    {
      "epoch": 0.24992228784581907,
      "grad_norm": 0.99800044298172,
      "learning_rate": 8.750388560770904e-06,
      "loss": 0.6775,
      "step": 3216
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.31030863523483276,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.083,
      "step": 3217
    },
    {
      "epoch": 0.2500777121541809,
      "grad_norm": 0.819849967956543,
      "learning_rate": 8.749611439229096e-06,
      "loss": 0.3732,
      "step": 3218
    },
    {
      "epoch": 0.25015542430836185,
      "grad_norm": 0.05442260578274727,
      "learning_rate": 8.74922287845819e-06,
      "loss": 0.0149,
      "step": 3219
    },
    {
      "epoch": 0.25023313646254275,
      "grad_norm": 0.21273989975452423,
      "learning_rate": 8.748834317687287e-06,
      "loss": 0.0606,
      "step": 3220
    },
    {
      "epoch": 0.25031084861672365,
      "grad_norm": 0.39311885833740234,
      "learning_rate": 8.748445756916382e-06,
      "loss": 0.3236,
      "step": 3221
    },
    {
      "epoch": 0.25038856077090454,
      "grad_norm": 0.175133615732193,
      "learning_rate": 8.748057196145477e-06,
      "loss": 0.0435,
      "step": 3222
    },
    {
      "epoch": 0.2504662729250855,
      "grad_norm": 0.6680512428283691,
      "learning_rate": 8.747668635374574e-06,
      "loss": 0.329,
      "step": 3223
    },
    {
      "epoch": 0.2505439850792664,
      "grad_norm": 0.09990613162517548,
      "learning_rate": 8.747280074603669e-06,
      "loss": 0.0885,
      "step": 3224
    },
    {
      "epoch": 0.2506216972334473,
      "grad_norm": 0.08547071367502213,
      "learning_rate": 8.746891513832764e-06,
      "loss": 0.0286,
      "step": 3225
    },
    {
      "epoch": 0.25069940938762825,
      "grad_norm": 0.1676117330789566,
      "learning_rate": 8.746502953061859e-06,
      "loss": 0.0689,
      "step": 3226
    },
    {
      "epoch": 0.25077712154180914,
      "grad_norm": 0.12132038176059723,
      "learning_rate": 8.746114392290956e-06,
      "loss": 0.0549,
      "step": 3227
    },
    {
      "epoch": 0.25085483369599004,
      "grad_norm": 0.2487950176000595,
      "learning_rate": 8.74572583152005e-06,
      "loss": 0.1241,
      "step": 3228
    },
    {
      "epoch": 0.25093254585017094,
      "grad_norm": 0.1531788408756256,
      "learning_rate": 8.745337270749145e-06,
      "loss": 0.0633,
      "step": 3229
    },
    {
      "epoch": 0.2510102580043519,
      "grad_norm": 0.3185107111930847,
      "learning_rate": 8.744948709978242e-06,
      "loss": 0.2827,
      "step": 3230
    },
    {
      "epoch": 0.2510879701585328,
      "grad_norm": 0.24200120568275452,
      "learning_rate": 8.744560149207337e-06,
      "loss": 0.1383,
      "step": 3231
    },
    {
      "epoch": 0.2511656823127137,
      "grad_norm": 0.3856286108493805,
      "learning_rate": 8.744171588436432e-06,
      "loss": 0.3983,
      "step": 3232
    },
    {
      "epoch": 0.25124339446689464,
      "grad_norm": 0.10145042091608047,
      "learning_rate": 8.743783027665529e-06,
      "loss": 0.0112,
      "step": 3233
    },
    {
      "epoch": 0.25132110662107554,
      "grad_norm": 0.14642295241355896,
      "learning_rate": 8.743394466894624e-06,
      "loss": 0.0906,
      "step": 3234
    },
    {
      "epoch": 0.25139881877525644,
      "grad_norm": 0.13029924035072327,
      "learning_rate": 8.743005906123718e-06,
      "loss": 0.0864,
      "step": 3235
    },
    {
      "epoch": 0.25147653092943734,
      "grad_norm": 0.22328683733940125,
      "learning_rate": 8.742617345352813e-06,
      "loss": 0.073,
      "step": 3236
    },
    {
      "epoch": 0.2515542430836183,
      "grad_norm": 0.2177753746509552,
      "learning_rate": 8.74222878458191e-06,
      "loss": 0.1928,
      "step": 3237
    },
    {
      "epoch": 0.2516319552377992,
      "grad_norm": 0.28782331943511963,
      "learning_rate": 8.741840223811005e-06,
      "loss": 0.0903,
      "step": 3238
    },
    {
      "epoch": 0.2517096673919801,
      "grad_norm": 0.16678133606910706,
      "learning_rate": 8.7414516630401e-06,
      "loss": 0.1157,
      "step": 3239
    },
    {
      "epoch": 0.25178737954616104,
      "grad_norm": 0.25309109687805176,
      "learning_rate": 8.741063102269197e-06,
      "loss": 0.2452,
      "step": 3240
    },
    {
      "epoch": 0.25186509170034194,
      "grad_norm": 0.31428855657577515,
      "learning_rate": 8.740674541498292e-06,
      "loss": 0.1027,
      "step": 3241
    },
    {
      "epoch": 0.25194280385452283,
      "grad_norm": 0.26511579751968384,
      "learning_rate": 8.740285980727387e-06,
      "loss": 0.194,
      "step": 3242
    },
    {
      "epoch": 0.2520205160087038,
      "grad_norm": 0.6580858826637268,
      "learning_rate": 8.739897419956483e-06,
      "loss": 0.3155,
      "step": 3243
    },
    {
      "epoch": 0.2520982281628847,
      "grad_norm": 0.09061531722545624,
      "learning_rate": 8.739508859185576e-06,
      "loss": 0.0272,
      "step": 3244
    },
    {
      "epoch": 0.2521759403170656,
      "grad_norm": 0.062033966183662415,
      "learning_rate": 8.739120298414673e-06,
      "loss": 0.0137,
      "step": 3245
    },
    {
      "epoch": 0.2522536524712465,
      "grad_norm": 0.6954224109649658,
      "learning_rate": 8.738731737643768e-06,
      "loss": 0.4543,
      "step": 3246
    },
    {
      "epoch": 0.25233136462542743,
      "grad_norm": 0.04666152596473694,
      "learning_rate": 8.738343176872863e-06,
      "loss": 0.0056,
      "step": 3247
    },
    {
      "epoch": 0.25240907677960833,
      "grad_norm": 0.4253096580505371,
      "learning_rate": 8.73795461610196e-06,
      "loss": 0.4191,
      "step": 3248
    },
    {
      "epoch": 0.25248678893378923,
      "grad_norm": 0.06907105445861816,
      "learning_rate": 8.737566055331055e-06,
      "loss": 0.0124,
      "step": 3249
    },
    {
      "epoch": 0.2525645010879702,
      "grad_norm": 0.36357560753822327,
      "learning_rate": 8.73717749456015e-06,
      "loss": 0.1826,
      "step": 3250
    },
    {
      "epoch": 0.2526422132421511,
      "grad_norm": 0.13714364171028137,
      "learning_rate": 8.736788933789244e-06,
      "loss": 0.0574,
      "step": 3251
    },
    {
      "epoch": 0.252719925396332,
      "grad_norm": 0.16718409955501556,
      "learning_rate": 8.736400373018341e-06,
      "loss": 0.1489,
      "step": 3252
    },
    {
      "epoch": 0.2527976375505129,
      "grad_norm": 0.5614030957221985,
      "learning_rate": 8.736011812247436e-06,
      "loss": 0.7254,
      "step": 3253
    },
    {
      "epoch": 0.25287534970469383,
      "grad_norm": 0.17544178664684296,
      "learning_rate": 8.735623251476531e-06,
      "loss": 0.1005,
      "step": 3254
    },
    {
      "epoch": 0.25295306185887473,
      "grad_norm": 0.2665485143661499,
      "learning_rate": 8.735234690705628e-06,
      "loss": 0.1676,
      "step": 3255
    },
    {
      "epoch": 0.2530307740130556,
      "grad_norm": 0.16153474152088165,
      "learning_rate": 8.734846129934723e-06,
      "loss": 0.0425,
      "step": 3256
    },
    {
      "epoch": 0.2531084861672366,
      "grad_norm": 0.34706592559814453,
      "learning_rate": 8.734457569163818e-06,
      "loss": 0.4984,
      "step": 3257
    },
    {
      "epoch": 0.2531861983214175,
      "grad_norm": 0.5265898108482361,
      "learning_rate": 8.734069008392914e-06,
      "loss": 0.1025,
      "step": 3258
    },
    {
      "epoch": 0.2532639104755984,
      "grad_norm": 0.1511656492948532,
      "learning_rate": 8.733680447622007e-06,
      "loss": 0.1284,
      "step": 3259
    },
    {
      "epoch": 0.2533416226297793,
      "grad_norm": 0.34680843353271484,
      "learning_rate": 8.733291886851104e-06,
      "loss": 0.1278,
      "step": 3260
    },
    {
      "epoch": 0.2534193347839602,
      "grad_norm": 0.4855296313762665,
      "learning_rate": 8.732903326080199e-06,
      "loss": 0.2607,
      "step": 3261
    },
    {
      "epoch": 0.2534970469381411,
      "grad_norm": 0.39621561765670776,
      "learning_rate": 8.732514765309294e-06,
      "loss": 0.2859,
      "step": 3262
    },
    {
      "epoch": 0.253574759092322,
      "grad_norm": 0.11253418028354645,
      "learning_rate": 8.73212620453839e-06,
      "loss": 0.036,
      "step": 3263
    },
    {
      "epoch": 0.253652471246503,
      "grad_norm": 0.10023486614227295,
      "learning_rate": 8.731737643767486e-06,
      "loss": 0.0386,
      "step": 3264
    },
    {
      "epoch": 0.2537301834006839,
      "grad_norm": 0.3049840033054352,
      "learning_rate": 8.731349082996582e-06,
      "loss": 0.2996,
      "step": 3265
    },
    {
      "epoch": 0.25380789555486477,
      "grad_norm": 0.3867550790309906,
      "learning_rate": 8.730960522225677e-06,
      "loss": 0.1768,
      "step": 3266
    },
    {
      "epoch": 0.25388560770904567,
      "grad_norm": 0.4118008613586426,
      "learning_rate": 8.730571961454772e-06,
      "loss": 0.421,
      "step": 3267
    },
    {
      "epoch": 0.2539633198632266,
      "grad_norm": 0.7445043325424194,
      "learning_rate": 8.730183400683869e-06,
      "loss": 0.1406,
      "step": 3268
    },
    {
      "epoch": 0.2540410320174075,
      "grad_norm": 0.09090302884578705,
      "learning_rate": 8.729794839912962e-06,
      "loss": 0.0308,
      "step": 3269
    },
    {
      "epoch": 0.2541187441715884,
      "grad_norm": 0.11784712225198746,
      "learning_rate": 8.729406279142059e-06,
      "loss": 0.0257,
      "step": 3270
    },
    {
      "epoch": 0.25419645632576937,
      "grad_norm": 0.6624245047569275,
      "learning_rate": 8.729017718371154e-06,
      "loss": 0.1055,
      "step": 3271
    },
    {
      "epoch": 0.25427416847995027,
      "grad_norm": 1.644360065460205,
      "learning_rate": 8.728629157600249e-06,
      "loss": 0.5404,
      "step": 3272
    },
    {
      "epoch": 0.25435188063413117,
      "grad_norm": 0.3342156708240509,
      "learning_rate": 8.728240596829345e-06,
      "loss": 0.112,
      "step": 3273
    },
    {
      "epoch": 0.25442959278831206,
      "grad_norm": 0.3407919704914093,
      "learning_rate": 8.72785203605844e-06,
      "loss": 0.2698,
      "step": 3274
    },
    {
      "epoch": 0.254507304942493,
      "grad_norm": 0.1934661865234375,
      "learning_rate": 8.727463475287535e-06,
      "loss": 0.084,
      "step": 3275
    },
    {
      "epoch": 0.2545850170966739,
      "grad_norm": 0.45179253816604614,
      "learning_rate": 8.727074914516632e-06,
      "loss": 0.0623,
      "step": 3276
    },
    {
      "epoch": 0.2546627292508548,
      "grad_norm": 0.25506460666656494,
      "learning_rate": 8.726686353745727e-06,
      "loss": 0.1554,
      "step": 3277
    },
    {
      "epoch": 0.25474044140503577,
      "grad_norm": 0.5265932679176331,
      "learning_rate": 8.726297792974822e-06,
      "loss": 0.3909,
      "step": 3278
    },
    {
      "epoch": 0.25481815355921666,
      "grad_norm": 0.16801102459430695,
      "learning_rate": 8.725909232203917e-06,
      "loss": 0.0672,
      "step": 3279
    },
    {
      "epoch": 0.25489586571339756,
      "grad_norm": 0.4407947063446045,
      "learning_rate": 8.725520671433013e-06,
      "loss": 0.2274,
      "step": 3280
    },
    {
      "epoch": 0.2549735778675785,
      "grad_norm": 0.24876682460308075,
      "learning_rate": 8.725132110662108e-06,
      "loss": 0.2901,
      "step": 3281
    },
    {
      "epoch": 0.2550512900217594,
      "grad_norm": 0.5291720628738403,
      "learning_rate": 8.724743549891203e-06,
      "loss": 0.2868,
      "step": 3282
    },
    {
      "epoch": 0.2551290021759403,
      "grad_norm": 0.399178147315979,
      "learning_rate": 8.7243549891203e-06,
      "loss": 0.5583,
      "step": 3283
    },
    {
      "epoch": 0.2552067143301212,
      "grad_norm": 0.2349359691143036,
      "learning_rate": 8.723966428349395e-06,
      "loss": 0.3971,
      "step": 3284
    },
    {
      "epoch": 0.25528442648430216,
      "grad_norm": 0.563105046749115,
      "learning_rate": 8.72357786757849e-06,
      "loss": 0.6736,
      "step": 3285
    },
    {
      "epoch": 0.25536213863848306,
      "grad_norm": 0.07197447121143341,
      "learning_rate": 8.723189306807586e-06,
      "loss": 0.0212,
      "step": 3286
    },
    {
      "epoch": 0.25543985079266396,
      "grad_norm": 0.3890429437160492,
      "learning_rate": 8.72280074603668e-06,
      "loss": 0.4031,
      "step": 3287
    },
    {
      "epoch": 0.2555175629468449,
      "grad_norm": 0.2562018632888794,
      "learning_rate": 8.722412185265776e-06,
      "loss": 0.1978,
      "step": 3288
    },
    {
      "epoch": 0.2555952751010258,
      "grad_norm": 0.08514176309108734,
      "learning_rate": 8.722023624494871e-06,
      "loss": 0.0315,
      "step": 3289
    },
    {
      "epoch": 0.2556729872552067,
      "grad_norm": 0.705794095993042,
      "learning_rate": 8.721635063723966e-06,
      "loss": 0.507,
      "step": 3290
    },
    {
      "epoch": 0.2557506994093876,
      "grad_norm": 0.25935056805610657,
      "learning_rate": 8.721246502953063e-06,
      "loss": 0.2477,
      "step": 3291
    },
    {
      "epoch": 0.25582841156356856,
      "grad_norm": 0.44790375232696533,
      "learning_rate": 8.720857942182158e-06,
      "loss": 0.2272,
      "step": 3292
    },
    {
      "epoch": 0.25590612371774946,
      "grad_norm": 0.0555887296795845,
      "learning_rate": 8.720469381411254e-06,
      "loss": 0.0049,
      "step": 3293
    },
    {
      "epoch": 0.25598383587193035,
      "grad_norm": 0.20185410976409912,
      "learning_rate": 8.72008082064035e-06,
      "loss": 0.0652,
      "step": 3294
    },
    {
      "epoch": 0.2560615480261113,
      "grad_norm": 0.144134521484375,
      "learning_rate": 8.719692259869444e-06,
      "loss": 0.0339,
      "step": 3295
    },
    {
      "epoch": 0.2561392601802922,
      "grad_norm": 0.3929058909416199,
      "learning_rate": 8.719303699098541e-06,
      "loss": 0.1125,
      "step": 3296
    },
    {
      "epoch": 0.2562169723344731,
      "grad_norm": 0.07466192543506622,
      "learning_rate": 8.718915138327634e-06,
      "loss": 0.0145,
      "step": 3297
    },
    {
      "epoch": 0.256294684488654,
      "grad_norm": 0.16649159789085388,
      "learning_rate": 8.71852657755673e-06,
      "loss": 0.0526,
      "step": 3298
    },
    {
      "epoch": 0.25637239664283495,
      "grad_norm": 0.537823498249054,
      "learning_rate": 8.718138016785826e-06,
      "loss": 0.1764,
      "step": 3299
    },
    {
      "epoch": 0.25645010879701585,
      "grad_norm": 0.4946708679199219,
      "learning_rate": 8.71774945601492e-06,
      "loss": 0.3754,
      "step": 3300
    },
    {
      "epoch": 0.25652782095119675,
      "grad_norm": 0.4439387917518616,
      "learning_rate": 8.717360895244017e-06,
      "loss": 0.5281,
      "step": 3301
    },
    {
      "epoch": 0.2566055331053777,
      "grad_norm": 0.2100982517004013,
      "learning_rate": 8.716972334473112e-06,
      "loss": 0.0326,
      "step": 3302
    },
    {
      "epoch": 0.2566832452595586,
      "grad_norm": 0.5573500990867615,
      "learning_rate": 8.716583773702207e-06,
      "loss": 1.0735,
      "step": 3303
    },
    {
      "epoch": 0.2567609574137395,
      "grad_norm": 0.057722996920347214,
      "learning_rate": 8.716195212931304e-06,
      "loss": 0.0118,
      "step": 3304
    },
    {
      "epoch": 0.2568386695679204,
      "grad_norm": 0.22357070446014404,
      "learning_rate": 8.715806652160399e-06,
      "loss": 0.1619,
      "step": 3305
    },
    {
      "epoch": 0.25691638172210135,
      "grad_norm": 0.6972671747207642,
      "learning_rate": 8.715418091389494e-06,
      "loss": 0.1496,
      "step": 3306
    },
    {
      "epoch": 0.25699409387628225,
      "grad_norm": 0.24197079241275787,
      "learning_rate": 8.715029530618589e-06,
      "loss": 0.159,
      "step": 3307
    },
    {
      "epoch": 0.25707180603046315,
      "grad_norm": 0.3012678027153015,
      "learning_rate": 8.714640969847685e-06,
      "loss": 0.2163,
      "step": 3308
    },
    {
      "epoch": 0.2571495181846441,
      "grad_norm": 0.2389831393957138,
      "learning_rate": 8.71425240907678e-06,
      "loss": 0.0965,
      "step": 3309
    },
    {
      "epoch": 0.257227230338825,
      "grad_norm": 0.3010295629501343,
      "learning_rate": 8.713863848305875e-06,
      "loss": 0.1283,
      "step": 3310
    },
    {
      "epoch": 0.2573049424930059,
      "grad_norm": 0.024206258356571198,
      "learning_rate": 8.713475287534972e-06,
      "loss": 0.0038,
      "step": 3311
    },
    {
      "epoch": 0.2573826546471868,
      "grad_norm": 0.18962381780147552,
      "learning_rate": 8.713086726764067e-06,
      "loss": 0.1889,
      "step": 3312
    },
    {
      "epoch": 0.25746036680136775,
      "grad_norm": 0.3393409252166748,
      "learning_rate": 8.712698165993162e-06,
      "loss": 0.2007,
      "step": 3313
    },
    {
      "epoch": 0.25753807895554864,
      "grad_norm": 0.4542042016983032,
      "learning_rate": 8.712309605222258e-06,
      "loss": 0.3258,
      "step": 3314
    },
    {
      "epoch": 0.25761579110972954,
      "grad_norm": 0.499922513961792,
      "learning_rate": 8.711921044451352e-06,
      "loss": 0.231,
      "step": 3315
    },
    {
      "epoch": 0.2576935032639105,
      "grad_norm": 0.3228487968444824,
      "learning_rate": 8.711532483680448e-06,
      "loss": 0.3181,
      "step": 3316
    },
    {
      "epoch": 0.2577712154180914,
      "grad_norm": 0.540378987789154,
      "learning_rate": 8.711143922909543e-06,
      "loss": 0.7331,
      "step": 3317
    },
    {
      "epoch": 0.2578489275722723,
      "grad_norm": 0.07450249046087265,
      "learning_rate": 8.710755362138638e-06,
      "loss": 0.0288,
      "step": 3318
    },
    {
      "epoch": 0.25792663972645324,
      "grad_norm": 0.39343151450157166,
      "learning_rate": 8.710366801367735e-06,
      "loss": 0.1882,
      "step": 3319
    },
    {
      "epoch": 0.25800435188063414,
      "grad_norm": 0.25607597827911377,
      "learning_rate": 8.70997824059683e-06,
      "loss": 0.2019,
      "step": 3320
    },
    {
      "epoch": 0.25808206403481504,
      "grad_norm": 0.34937790036201477,
      "learning_rate": 8.709589679825925e-06,
      "loss": 0.0591,
      "step": 3321
    },
    {
      "epoch": 0.25815977618899594,
      "grad_norm": 0.3843088746070862,
      "learning_rate": 8.709201119055021e-06,
      "loss": 0.0994,
      "step": 3322
    },
    {
      "epoch": 0.2582374883431769,
      "grad_norm": 0.21585358679294586,
      "learning_rate": 8.708812558284116e-06,
      "loss": 0.1613,
      "step": 3323
    },
    {
      "epoch": 0.2583152004973578,
      "grad_norm": 0.44950178265571594,
      "learning_rate": 8.708423997513213e-06,
      "loss": 0.522,
      "step": 3324
    },
    {
      "epoch": 0.2583929126515387,
      "grad_norm": 0.5034496784210205,
      "learning_rate": 8.708035436742306e-06,
      "loss": 0.4294,
      "step": 3325
    },
    {
      "epoch": 0.25847062480571964,
      "grad_norm": 0.6029012799263,
      "learning_rate": 8.707646875971403e-06,
      "loss": 0.4028,
      "step": 3326
    },
    {
      "epoch": 0.25854833695990054,
      "grad_norm": 0.2611978054046631,
      "learning_rate": 8.707258315200498e-06,
      "loss": 0.1501,
      "step": 3327
    },
    {
      "epoch": 0.25862604911408144,
      "grad_norm": 0.28061044216156006,
      "learning_rate": 8.706869754429593e-06,
      "loss": 0.1708,
      "step": 3328
    },
    {
      "epoch": 0.25870376126826233,
      "grad_norm": 0.4174415171146393,
      "learning_rate": 8.70648119365869e-06,
      "loss": 0.5215,
      "step": 3329
    },
    {
      "epoch": 0.2587814734224433,
      "grad_norm": 0.28531554341316223,
      "learning_rate": 8.706092632887784e-06,
      "loss": 0.2342,
      "step": 3330
    },
    {
      "epoch": 0.2588591855766242,
      "grad_norm": 0.40085113048553467,
      "learning_rate": 8.70570407211688e-06,
      "loss": 0.2313,
      "step": 3331
    },
    {
      "epoch": 0.2589368977308051,
      "grad_norm": 0.22361986339092255,
      "learning_rate": 8.705315511345976e-06,
      "loss": 0.1658,
      "step": 3332
    },
    {
      "epoch": 0.25901460988498604,
      "grad_norm": 0.46874845027923584,
      "learning_rate": 8.704926950575071e-06,
      "loss": 0.298,
      "step": 3333
    },
    {
      "epoch": 0.25909232203916693,
      "grad_norm": 0.11365511268377304,
      "learning_rate": 8.704538389804166e-06,
      "loss": 0.0828,
      "step": 3334
    },
    {
      "epoch": 0.25917003419334783,
      "grad_norm": 0.3577476143836975,
      "learning_rate": 8.704149829033261e-06,
      "loss": 0.097,
      "step": 3335
    },
    {
      "epoch": 0.25924774634752873,
      "grad_norm": 0.3981248736381531,
      "learning_rate": 8.703761268262358e-06,
      "loss": 0.1822,
      "step": 3336
    },
    {
      "epoch": 0.2593254585017097,
      "grad_norm": 0.09445186704397202,
      "learning_rate": 8.703372707491452e-06,
      "loss": 0.0631,
      "step": 3337
    },
    {
      "epoch": 0.2594031706558906,
      "grad_norm": 0.43926310539245605,
      "learning_rate": 8.702984146720547e-06,
      "loss": 0.2746,
      "step": 3338
    },
    {
      "epoch": 0.2594808828100715,
      "grad_norm": 0.2573917806148529,
      "learning_rate": 8.702595585949644e-06,
      "loss": 0.0806,
      "step": 3339
    },
    {
      "epoch": 0.25955859496425243,
      "grad_norm": 0.3123973309993744,
      "learning_rate": 8.702207025178739e-06,
      "loss": 0.2115,
      "step": 3340
    },
    {
      "epoch": 0.25963630711843333,
      "grad_norm": 0.244545117020607,
      "learning_rate": 8.701818464407834e-06,
      "loss": 0.2283,
      "step": 3341
    },
    {
      "epoch": 0.2597140192726142,
      "grad_norm": 0.024488339200615883,
      "learning_rate": 8.70142990363693e-06,
      "loss": 0.0049,
      "step": 3342
    },
    {
      "epoch": 0.2597917314267951,
      "grad_norm": 0.5547782182693481,
      "learning_rate": 8.701041342866024e-06,
      "loss": 0.156,
      "step": 3343
    },
    {
      "epoch": 0.2598694435809761,
      "grad_norm": 0.9025100469589233,
      "learning_rate": 8.70065278209512e-06,
      "loss": 0.4092,
      "step": 3344
    },
    {
      "epoch": 0.259947155735157,
      "grad_norm": 1.0486152172088623,
      "learning_rate": 8.700264221324215e-06,
      "loss": 0.5781,
      "step": 3345
    },
    {
      "epoch": 0.2600248678893379,
      "grad_norm": 0.4392399489879608,
      "learning_rate": 8.69987566055331e-06,
      "loss": 0.177,
      "step": 3346
    },
    {
      "epoch": 0.2601025800435188,
      "grad_norm": 0.17928731441497803,
      "learning_rate": 8.699487099782407e-06,
      "loss": 0.0664,
      "step": 3347
    },
    {
      "epoch": 0.2601802921976997,
      "grad_norm": 0.22442778944969177,
      "learning_rate": 8.699098539011502e-06,
      "loss": 0.0665,
      "step": 3348
    },
    {
      "epoch": 0.2602580043518806,
      "grad_norm": 0.2882080078125,
      "learning_rate": 8.698709978240597e-06,
      "loss": 0.254,
      "step": 3349
    },
    {
      "epoch": 0.2603357165060615,
      "grad_norm": 0.315969318151474,
      "learning_rate": 8.698321417469694e-06,
      "loss": 0.0884,
      "step": 3350
    },
    {
      "epoch": 0.2604134286602425,
      "grad_norm": 0.2701258659362793,
      "learning_rate": 8.697932856698789e-06,
      "loss": 0.2653,
      "step": 3351
    },
    {
      "epoch": 0.26049114081442337,
      "grad_norm": 0.12881970405578613,
      "learning_rate": 8.697544295927884e-06,
      "loss": 0.0621,
      "step": 3352
    },
    {
      "epoch": 0.26056885296860427,
      "grad_norm": 0.30702874064445496,
      "learning_rate": 8.697155735156978e-06,
      "loss": 0.1648,
      "step": 3353
    },
    {
      "epoch": 0.2606465651227852,
      "grad_norm": 0.6419205665588379,
      "learning_rate": 8.696767174386075e-06,
      "loss": 0.2217,
      "step": 3354
    },
    {
      "epoch": 0.2607242772769661,
      "grad_norm": 0.3901556730270386,
      "learning_rate": 8.69637861361517e-06,
      "loss": 0.0521,
      "step": 3355
    },
    {
      "epoch": 0.260801989431147,
      "grad_norm": 0.2358175814151764,
      "learning_rate": 8.695990052844265e-06,
      "loss": 0.1515,
      "step": 3356
    },
    {
      "epoch": 0.26087970158532797,
      "grad_norm": 0.114377960562706,
      "learning_rate": 8.695601492073362e-06,
      "loss": 0.0278,
      "step": 3357
    },
    {
      "epoch": 0.26095741373950887,
      "grad_norm": 0.24881009757518768,
      "learning_rate": 8.695212931302457e-06,
      "loss": 0.1211,
      "step": 3358
    },
    {
      "epoch": 0.26103512589368977,
      "grad_norm": 0.30797865986824036,
      "learning_rate": 8.694824370531552e-06,
      "loss": 0.0924,
      "step": 3359
    },
    {
      "epoch": 0.26111283804787067,
      "grad_norm": 0.3303314447402954,
      "learning_rate": 8.694435809760648e-06,
      "loss": 0.1212,
      "step": 3360
    },
    {
      "epoch": 0.2611905502020516,
      "grad_norm": 0.30562078952789307,
      "learning_rate": 8.694047248989743e-06,
      "loss": 0.2299,
      "step": 3361
    },
    {
      "epoch": 0.2612682623562325,
      "grad_norm": 0.3353275656700134,
      "learning_rate": 8.693658688218838e-06,
      "loss": 0.146,
      "step": 3362
    },
    {
      "epoch": 0.2613459745104134,
      "grad_norm": 0.16844770312309265,
      "learning_rate": 8.693270127447933e-06,
      "loss": 0.073,
      "step": 3363
    },
    {
      "epoch": 0.26142368666459437,
      "grad_norm": 0.1832028031349182,
      "learning_rate": 8.69288156667703e-06,
      "loss": 0.2758,
      "step": 3364
    },
    {
      "epoch": 0.26150139881877527,
      "grad_norm": 0.49898120760917664,
      "learning_rate": 8.692493005906125e-06,
      "loss": 0.1236,
      "step": 3365
    },
    {
      "epoch": 0.26157911097295616,
      "grad_norm": 0.26452362537384033,
      "learning_rate": 8.69210444513522e-06,
      "loss": 0.1312,
      "step": 3366
    },
    {
      "epoch": 0.26165682312713706,
      "grad_norm": 0.4768025875091553,
      "learning_rate": 8.691715884364316e-06,
      "loss": 0.7877,
      "step": 3367
    },
    {
      "epoch": 0.261734535281318,
      "grad_norm": 0.5594495534896851,
      "learning_rate": 8.691327323593411e-06,
      "loss": 0.3543,
      "step": 3368
    },
    {
      "epoch": 0.2618122474354989,
      "grad_norm": 0.4019341766834259,
      "learning_rate": 8.690938762822506e-06,
      "loss": 0.2094,
      "step": 3369
    },
    {
      "epoch": 0.2618899595896798,
      "grad_norm": 0.17517173290252686,
      "learning_rate": 8.690550202051603e-06,
      "loss": 0.0432,
      "step": 3370
    },
    {
      "epoch": 0.26196767174386076,
      "grad_norm": 1.2490994930267334,
      "learning_rate": 8.690161641280696e-06,
      "loss": 0.8652,
      "step": 3371
    },
    {
      "epoch": 0.26204538389804166,
      "grad_norm": 0.44659513235092163,
      "learning_rate": 8.689773080509793e-06,
      "loss": 0.4692,
      "step": 3372
    },
    {
      "epoch": 0.26212309605222256,
      "grad_norm": 0.7406107783317566,
      "learning_rate": 8.689384519738888e-06,
      "loss": 0.4901,
      "step": 3373
    },
    {
      "epoch": 0.26220080820640346,
      "grad_norm": 0.5638347268104553,
      "learning_rate": 8.688995958967983e-06,
      "loss": 0.1759,
      "step": 3374
    },
    {
      "epoch": 0.2622785203605844,
      "grad_norm": 0.28959453105926514,
      "learning_rate": 8.68860739819708e-06,
      "loss": 0.1684,
      "step": 3375
    },
    {
      "epoch": 0.2623562325147653,
      "grad_norm": 0.37852317094802856,
      "learning_rate": 8.688218837426174e-06,
      "loss": 0.0965,
      "step": 3376
    },
    {
      "epoch": 0.2624339446689462,
      "grad_norm": 0.3192363381385803,
      "learning_rate": 8.687830276655269e-06,
      "loss": 0.0682,
      "step": 3377
    },
    {
      "epoch": 0.26251165682312716,
      "grad_norm": 0.2500675916671753,
      "learning_rate": 8.687441715884364e-06,
      "loss": 0.2099,
      "step": 3378
    },
    {
      "epoch": 0.26258936897730806,
      "grad_norm": 0.5619367957115173,
      "learning_rate": 8.68705315511346e-06,
      "loss": 0.4076,
      "step": 3379
    },
    {
      "epoch": 0.26266708113148896,
      "grad_norm": 0.32186245918273926,
      "learning_rate": 8.686664594342556e-06,
      "loss": 0.1874,
      "step": 3380
    },
    {
      "epoch": 0.26274479328566985,
      "grad_norm": 0.291474848985672,
      "learning_rate": 8.68627603357165e-06,
      "loss": 0.1222,
      "step": 3381
    },
    {
      "epoch": 0.2628225054398508,
      "grad_norm": 0.27188557386398315,
      "learning_rate": 8.685887472800747e-06,
      "loss": 0.0728,
      "step": 3382
    },
    {
      "epoch": 0.2629002175940317,
      "grad_norm": 0.23784653842449188,
      "learning_rate": 8.685498912029842e-06,
      "loss": 0.1798,
      "step": 3383
    },
    {
      "epoch": 0.2629779297482126,
      "grad_norm": 0.10303139686584473,
      "learning_rate": 8.685110351258937e-06,
      "loss": 0.0305,
      "step": 3384
    },
    {
      "epoch": 0.26305564190239356,
      "grad_norm": 0.29240185022354126,
      "learning_rate": 8.684721790488034e-06,
      "loss": 0.1177,
      "step": 3385
    },
    {
      "epoch": 0.26313335405657445,
      "grad_norm": 0.2148912400007248,
      "learning_rate": 8.684333229717129e-06,
      "loss": 0.4283,
      "step": 3386
    },
    {
      "epoch": 0.26321106621075535,
      "grad_norm": 0.3370007872581482,
      "learning_rate": 8.683944668946224e-06,
      "loss": 0.1614,
      "step": 3387
    },
    {
      "epoch": 0.26328877836493625,
      "grad_norm": 0.357604056596756,
      "learning_rate": 8.683556108175319e-06,
      "loss": 0.4031,
      "step": 3388
    },
    {
      "epoch": 0.2633664905191172,
      "grad_norm": 0.19225946068763733,
      "learning_rate": 8.683167547404415e-06,
      "loss": 0.0962,
      "step": 3389
    },
    {
      "epoch": 0.2634442026732981,
      "grad_norm": 0.42032891511917114,
      "learning_rate": 8.68277898663351e-06,
      "loss": 0.3227,
      "step": 3390
    },
    {
      "epoch": 0.263521914827479,
      "grad_norm": 0.3669973313808441,
      "learning_rate": 8.682390425862605e-06,
      "loss": 0.1257,
      "step": 3391
    },
    {
      "epoch": 0.26359962698165995,
      "grad_norm": 0.40025490522384644,
      "learning_rate": 8.682001865091702e-06,
      "loss": 0.2427,
      "step": 3392
    },
    {
      "epoch": 0.26367733913584085,
      "grad_norm": 0.28214189410209656,
      "learning_rate": 8.681613304320797e-06,
      "loss": 0.1848,
      "step": 3393
    },
    {
      "epoch": 0.26375505129002175,
      "grad_norm": 0.7205567955970764,
      "learning_rate": 8.681224743549892e-06,
      "loss": 0.4857,
      "step": 3394
    },
    {
      "epoch": 0.2638327634442027,
      "grad_norm": 0.5763928890228271,
      "learning_rate": 8.680836182778988e-06,
      "loss": 0.6999,
      "step": 3395
    },
    {
      "epoch": 0.2639104755983836,
      "grad_norm": 0.7655661702156067,
      "learning_rate": 8.680447622008082e-06,
      "loss": 0.319,
      "step": 3396
    },
    {
      "epoch": 0.2639881877525645,
      "grad_norm": 0.4144831597805023,
      "learning_rate": 8.680059061237178e-06,
      "loss": 0.6849,
      "step": 3397
    },
    {
      "epoch": 0.2640658999067454,
      "grad_norm": 0.2787758708000183,
      "learning_rate": 8.679670500466273e-06,
      "loss": 0.1846,
      "step": 3398
    },
    {
      "epoch": 0.26414361206092635,
      "grad_norm": 0.14069800078868866,
      "learning_rate": 8.679281939695368e-06,
      "loss": 0.0886,
      "step": 3399
    },
    {
      "epoch": 0.26422132421510724,
      "grad_norm": 0.39985334873199463,
      "learning_rate": 8.678893378924465e-06,
      "loss": 0.1474,
      "step": 3400
    },
    {
      "epoch": 0.26429903636928814,
      "grad_norm": 0.3188965618610382,
      "learning_rate": 8.67850481815356e-06,
      "loss": 0.0949,
      "step": 3401
    },
    {
      "epoch": 0.2643767485234691,
      "grad_norm": 0.3513151705265045,
      "learning_rate": 8.678116257382655e-06,
      "loss": 0.1704,
      "step": 3402
    },
    {
      "epoch": 0.26445446067765,
      "grad_norm": 0.3501304090023041,
      "learning_rate": 8.677727696611751e-06,
      "loss": 0.1946,
      "step": 3403
    },
    {
      "epoch": 0.2645321728318309,
      "grad_norm": 0.3200378119945526,
      "learning_rate": 8.677339135840846e-06,
      "loss": 0.2636,
      "step": 3404
    },
    {
      "epoch": 0.2646098849860118,
      "grad_norm": 0.19047768414020538,
      "learning_rate": 8.676950575069941e-06,
      "loss": 0.048,
      "step": 3405
    },
    {
      "epoch": 0.26468759714019274,
      "grad_norm": 0.278130441904068,
      "learning_rate": 8.676562014299036e-06,
      "loss": 0.1425,
      "step": 3406
    },
    {
      "epoch": 0.26476530929437364,
      "grad_norm": 0.2160927653312683,
      "learning_rate": 8.676173453528133e-06,
      "loss": 0.0968,
      "step": 3407
    },
    {
      "epoch": 0.26484302144855454,
      "grad_norm": 1.1094170808792114,
      "learning_rate": 8.675784892757228e-06,
      "loss": 0.1608,
      "step": 3408
    },
    {
      "epoch": 0.2649207336027355,
      "grad_norm": 0.3514721393585205,
      "learning_rate": 8.675396331986323e-06,
      "loss": 0.1081,
      "step": 3409
    },
    {
      "epoch": 0.2649984457569164,
      "grad_norm": 0.28772348165512085,
      "learning_rate": 8.67500777121542e-06,
      "loss": 0.0728,
      "step": 3410
    },
    {
      "epoch": 0.2650761579110973,
      "grad_norm": 0.20169509947299957,
      "learning_rate": 8.674619210444514e-06,
      "loss": 0.1089,
      "step": 3411
    },
    {
      "epoch": 0.2651538700652782,
      "grad_norm": 0.38704004883766174,
      "learning_rate": 8.67423064967361e-06,
      "loss": 0.1615,
      "step": 3412
    },
    {
      "epoch": 0.26523158221945914,
      "grad_norm": 1.113864779472351,
      "learning_rate": 8.673842088902706e-06,
      "loss": 0.537,
      "step": 3413
    },
    {
      "epoch": 0.26530929437364004,
      "grad_norm": 0.1635119915008545,
      "learning_rate": 8.6734535281318e-06,
      "loss": 0.0479,
      "step": 3414
    },
    {
      "epoch": 0.26538700652782093,
      "grad_norm": 0.2959243953227997,
      "learning_rate": 8.673064967360896e-06,
      "loss": 0.1512,
      "step": 3415
    },
    {
      "epoch": 0.2654647186820019,
      "grad_norm": 0.3004668056964874,
      "learning_rate": 8.67267640658999e-06,
      "loss": 0.2384,
      "step": 3416
    },
    {
      "epoch": 0.2655424308361828,
      "grad_norm": 0.06595171242952347,
      "learning_rate": 8.672287845819087e-06,
      "loss": 0.0177,
      "step": 3417
    },
    {
      "epoch": 0.2656201429903637,
      "grad_norm": 0.13041630387306213,
      "learning_rate": 8.671899285048182e-06,
      "loss": 0.0521,
      "step": 3418
    },
    {
      "epoch": 0.2656978551445446,
      "grad_norm": 0.2384592592716217,
      "learning_rate": 8.671510724277277e-06,
      "loss": 0.0956,
      "step": 3419
    },
    {
      "epoch": 0.26577556729872553,
      "grad_norm": 0.48880526423454285,
      "learning_rate": 8.671122163506374e-06,
      "loss": 0.2936,
      "step": 3420
    },
    {
      "epoch": 0.26585327945290643,
      "grad_norm": 0.18771256506443024,
      "learning_rate": 8.670733602735469e-06,
      "loss": 0.0655,
      "step": 3421
    },
    {
      "epoch": 0.26593099160708733,
      "grad_norm": 0.1962544023990631,
      "learning_rate": 8.670345041964564e-06,
      "loss": 0.0451,
      "step": 3422
    },
    {
      "epoch": 0.2660087037612683,
      "grad_norm": 0.35366684198379517,
      "learning_rate": 8.66995648119366e-06,
      "loss": 0.2858,
      "step": 3423
    },
    {
      "epoch": 0.2660864159154492,
      "grad_norm": 0.20858357846736908,
      "learning_rate": 8.669567920422754e-06,
      "loss": 0.0678,
      "step": 3424
    },
    {
      "epoch": 0.2661641280696301,
      "grad_norm": 0.11828119307756424,
      "learning_rate": 8.66917935965185e-06,
      "loss": 0.1023,
      "step": 3425
    },
    {
      "epoch": 0.266241840223811,
      "grad_norm": 0.1743604838848114,
      "learning_rate": 8.668790798880945e-06,
      "loss": 0.1016,
      "step": 3426
    },
    {
      "epoch": 0.26631955237799193,
      "grad_norm": 0.6753678321838379,
      "learning_rate": 8.66840223811004e-06,
      "loss": 1.0664,
      "step": 3427
    },
    {
      "epoch": 0.26639726453217283,
      "grad_norm": 0.5372357368469238,
      "learning_rate": 8.668013677339137e-06,
      "loss": 0.5506,
      "step": 3428
    },
    {
      "epoch": 0.2664749766863537,
      "grad_norm": 0.7098186612129211,
      "learning_rate": 8.667625116568232e-06,
      "loss": 0.2454,
      "step": 3429
    },
    {
      "epoch": 0.2665526888405347,
      "grad_norm": 0.2284127175807953,
      "learning_rate": 8.667236555797327e-06,
      "loss": 0.2472,
      "step": 3430
    },
    {
      "epoch": 0.2666304009947156,
      "grad_norm": 0.9486936926841736,
      "learning_rate": 8.666847995026424e-06,
      "loss": 0.5856,
      "step": 3431
    },
    {
      "epoch": 0.2667081131488965,
      "grad_norm": 0.4789370000362396,
      "learning_rate": 8.666459434255518e-06,
      "loss": 0.277,
      "step": 3432
    },
    {
      "epoch": 0.26678582530307743,
      "grad_norm": 0.7157869935035706,
      "learning_rate": 8.666070873484613e-06,
      "loss": 0.6017,
      "step": 3433
    },
    {
      "epoch": 0.2668635374572583,
      "grad_norm": 0.3524741530418396,
      "learning_rate": 8.665682312713708e-06,
      "loss": 0.1131,
      "step": 3434
    },
    {
      "epoch": 0.2669412496114392,
      "grad_norm": 0.40798547863960266,
      "learning_rate": 8.665293751942805e-06,
      "loss": 0.202,
      "step": 3435
    },
    {
      "epoch": 0.2670189617656201,
      "grad_norm": 0.30328917503356934,
      "learning_rate": 8.6649051911719e-06,
      "loss": 0.1474,
      "step": 3436
    },
    {
      "epoch": 0.2670966739198011,
      "grad_norm": 0.4760506749153137,
      "learning_rate": 8.664516630400995e-06,
      "loss": 0.4193,
      "step": 3437
    },
    {
      "epoch": 0.267174386073982,
      "grad_norm": 0.691088855266571,
      "learning_rate": 8.664128069630092e-06,
      "loss": 0.0834,
      "step": 3438
    },
    {
      "epoch": 0.26725209822816287,
      "grad_norm": 0.4696526825428009,
      "learning_rate": 8.663739508859187e-06,
      "loss": 0.1333,
      "step": 3439
    },
    {
      "epoch": 0.2673298103823438,
      "grad_norm": 0.3755817413330078,
      "learning_rate": 8.663350948088281e-06,
      "loss": 0.0916,
      "step": 3440
    },
    {
      "epoch": 0.2674075225365247,
      "grad_norm": 0.449138879776001,
      "learning_rate": 8.662962387317378e-06,
      "loss": 0.2519,
      "step": 3441
    },
    {
      "epoch": 0.2674852346907056,
      "grad_norm": 0.2278764694929123,
      "learning_rate": 8.662573826546471e-06,
      "loss": 0.2564,
      "step": 3442
    },
    {
      "epoch": 0.2675629468448865,
      "grad_norm": 0.36483660340309143,
      "learning_rate": 8.662185265775568e-06,
      "loss": 0.3462,
      "step": 3443
    },
    {
      "epoch": 0.26764065899906747,
      "grad_norm": 0.16441063582897186,
      "learning_rate": 8.661796705004663e-06,
      "loss": 0.1013,
      "step": 3444
    },
    {
      "epoch": 0.26771837115324837,
      "grad_norm": 0.3105882406234741,
      "learning_rate": 8.66140814423376e-06,
      "loss": 0.1108,
      "step": 3445
    },
    {
      "epoch": 0.26779608330742927,
      "grad_norm": 0.2417924553155899,
      "learning_rate": 8.661019583462855e-06,
      "loss": 0.0987,
      "step": 3446
    },
    {
      "epoch": 0.2678737954616102,
      "grad_norm": 0.265585720539093,
      "learning_rate": 8.66063102269195e-06,
      "loss": 0.0888,
      "step": 3447
    },
    {
      "epoch": 0.2679515076157911,
      "grad_norm": 0.2466905415058136,
      "learning_rate": 8.660242461921046e-06,
      "loss": 0.1087,
      "step": 3448
    },
    {
      "epoch": 0.268029219769972,
      "grad_norm": 0.33523109555244446,
      "learning_rate": 8.659853901150141e-06,
      "loss": 0.2204,
      "step": 3449
    },
    {
      "epoch": 0.2681069319241529,
      "grad_norm": 0.4341454803943634,
      "learning_rate": 8.659465340379236e-06,
      "loss": 0.1488,
      "step": 3450
    },
    {
      "epoch": 0.26818464407833387,
      "grad_norm": 0.33899232745170593,
      "learning_rate": 8.659076779608333e-06,
      "loss": 0.4054,
      "step": 3451
    },
    {
      "epoch": 0.26826235623251476,
      "grad_norm": 0.1471046358346939,
      "learning_rate": 8.658688218837426e-06,
      "loss": 0.0832,
      "step": 3452
    },
    {
      "epoch": 0.26834006838669566,
      "grad_norm": 0.4837466776371002,
      "learning_rate": 8.658299658066523e-06,
      "loss": 0.4072,
      "step": 3453
    },
    {
      "epoch": 0.2684177805408766,
      "grad_norm": 0.4260751008987427,
      "learning_rate": 8.657911097295618e-06,
      "loss": 0.318,
      "step": 3454
    },
    {
      "epoch": 0.2684954926950575,
      "grad_norm": 0.8384549617767334,
      "learning_rate": 8.657522536524712e-06,
      "loss": 0.2356,
      "step": 3455
    },
    {
      "epoch": 0.2685732048492384,
      "grad_norm": 0.3340362012386322,
      "learning_rate": 8.657133975753809e-06,
      "loss": 0.096,
      "step": 3456
    },
    {
      "epoch": 0.2686509170034193,
      "grad_norm": 0.13967208564281464,
      "learning_rate": 8.656745414982904e-06,
      "loss": 0.0582,
      "step": 3457
    },
    {
      "epoch": 0.26872862915760026,
      "grad_norm": 0.5128057599067688,
      "learning_rate": 8.656356854211999e-06,
      "loss": 0.7901,
      "step": 3458
    },
    {
      "epoch": 0.26880634131178116,
      "grad_norm": 0.22012749314308167,
      "learning_rate": 8.655968293441096e-06,
      "loss": 0.0972,
      "step": 3459
    },
    {
      "epoch": 0.26888405346596206,
      "grad_norm": 0.14145709574222565,
      "learning_rate": 8.65557973267019e-06,
      "loss": 0.0818,
      "step": 3460
    },
    {
      "epoch": 0.268961765620143,
      "grad_norm": 0.09029773622751236,
      "learning_rate": 8.655191171899286e-06,
      "loss": 0.0314,
      "step": 3461
    },
    {
      "epoch": 0.2690394777743239,
      "grad_norm": 0.4565448760986328,
      "learning_rate": 8.65480261112838e-06,
      "loss": 0.1679,
      "step": 3462
    },
    {
      "epoch": 0.2691171899285048,
      "grad_norm": 0.3710451126098633,
      "learning_rate": 8.654414050357477e-06,
      "loss": 0.1691,
      "step": 3463
    },
    {
      "epoch": 0.2691949020826857,
      "grad_norm": 0.4751390814781189,
      "learning_rate": 8.654025489586572e-06,
      "loss": 0.0638,
      "step": 3464
    },
    {
      "epoch": 0.26927261423686666,
      "grad_norm": 0.8492887616157532,
      "learning_rate": 8.653636928815667e-06,
      "loss": 0.2652,
      "step": 3465
    },
    {
      "epoch": 0.26935032639104756,
      "grad_norm": 0.3505918085575104,
      "learning_rate": 8.653248368044764e-06,
      "loss": 0.0639,
      "step": 3466
    },
    {
      "epoch": 0.26942803854522845,
      "grad_norm": 0.17384622991085052,
      "learning_rate": 8.652859807273859e-06,
      "loss": 0.1304,
      "step": 3467
    },
    {
      "epoch": 0.2695057506994094,
      "grad_norm": 0.2523513734340668,
      "learning_rate": 8.652471246502954e-06,
      "loss": 0.1286,
      "step": 3468
    },
    {
      "epoch": 0.2695834628535903,
      "grad_norm": 0.38518577814102173,
      "learning_rate": 8.65208268573205e-06,
      "loss": 0.2462,
      "step": 3469
    },
    {
      "epoch": 0.2696611750077712,
      "grad_norm": 0.3621896803379059,
      "learning_rate": 8.651694124961143e-06,
      "loss": 0.2445,
      "step": 3470
    },
    {
      "epoch": 0.26973888716195216,
      "grad_norm": 0.26766687631607056,
      "learning_rate": 8.65130556419024e-06,
      "loss": 0.1355,
      "step": 3471
    },
    {
      "epoch": 0.26981659931613305,
      "grad_norm": 0.5069516897201538,
      "learning_rate": 8.650917003419335e-06,
      "loss": 0.4876,
      "step": 3472
    },
    {
      "epoch": 0.26989431147031395,
      "grad_norm": 0.4389420449733734,
      "learning_rate": 8.65052844264843e-06,
      "loss": 0.2801,
      "step": 3473
    },
    {
      "epoch": 0.26997202362449485,
      "grad_norm": 0.1863439679145813,
      "learning_rate": 8.650139881877527e-06,
      "loss": 0.1309,
      "step": 3474
    },
    {
      "epoch": 0.2700497357786758,
      "grad_norm": 0.23158733546733856,
      "learning_rate": 8.649751321106622e-06,
      "loss": 0.0758,
      "step": 3475
    },
    {
      "epoch": 0.2701274479328567,
      "grad_norm": 0.44587159156799316,
      "learning_rate": 8.649362760335718e-06,
      "loss": 0.2361,
      "step": 3476
    },
    {
      "epoch": 0.2702051600870376,
      "grad_norm": 0.6150342226028442,
      "learning_rate": 8.648974199564813e-06,
      "loss": 0.5149,
      "step": 3477
    },
    {
      "epoch": 0.27028287224121855,
      "grad_norm": 0.8269214034080505,
      "learning_rate": 8.648585638793908e-06,
      "loss": 0.4338,
      "step": 3478
    },
    {
      "epoch": 0.27036058439539945,
      "grad_norm": 0.3498789966106415,
      "learning_rate": 8.648197078023005e-06,
      "loss": 0.5026,
      "step": 3479
    },
    {
      "epoch": 0.27043829654958035,
      "grad_norm": 0.23184986412525177,
      "learning_rate": 8.647808517252098e-06,
      "loss": 0.2179,
      "step": 3480
    },
    {
      "epoch": 0.27051600870376125,
      "grad_norm": 0.21683086454868317,
      "learning_rate": 8.647419956481195e-06,
      "loss": 0.1134,
      "step": 3481
    },
    {
      "epoch": 0.2705937208579422,
      "grad_norm": 0.2182929813861847,
      "learning_rate": 8.64703139571029e-06,
      "loss": 0.1959,
      "step": 3482
    },
    {
      "epoch": 0.2706714330121231,
      "grad_norm": 0.17723476886749268,
      "learning_rate": 8.646642834939385e-06,
      "loss": 0.0677,
      "step": 3483
    },
    {
      "epoch": 0.270749145166304,
      "grad_norm": 0.22619614005088806,
      "learning_rate": 8.646254274168481e-06,
      "loss": 0.0991,
      "step": 3484
    },
    {
      "epoch": 0.27082685732048495,
      "grad_norm": 0.5330379605293274,
      "learning_rate": 8.645865713397576e-06,
      "loss": 0.7106,
      "step": 3485
    },
    {
      "epoch": 0.27090456947466585,
      "grad_norm": 0.1812898963689804,
      "learning_rate": 8.645477152626671e-06,
      "loss": 0.0588,
      "step": 3486
    },
    {
      "epoch": 0.27098228162884674,
      "grad_norm": 0.23866011202335358,
      "learning_rate": 8.645088591855768e-06,
      "loss": 0.1486,
      "step": 3487
    },
    {
      "epoch": 0.27105999378302764,
      "grad_norm": 0.1855454444885254,
      "learning_rate": 8.644700031084863e-06,
      "loss": 0.081,
      "step": 3488
    },
    {
      "epoch": 0.2711377059372086,
      "grad_norm": 0.4398312270641327,
      "learning_rate": 8.644311470313958e-06,
      "loss": 0.1267,
      "step": 3489
    },
    {
      "epoch": 0.2712154180913895,
      "grad_norm": 0.28042352199554443,
      "learning_rate": 8.643922909543053e-06,
      "loss": 0.1743,
      "step": 3490
    },
    {
      "epoch": 0.2712931302455704,
      "grad_norm": 0.2768431305885315,
      "learning_rate": 8.64353434877215e-06,
      "loss": 0.1437,
      "step": 3491
    },
    {
      "epoch": 0.27137084239975134,
      "grad_norm": 0.5673483610153198,
      "learning_rate": 8.643145788001244e-06,
      "loss": 0.3664,
      "step": 3492
    },
    {
      "epoch": 0.27144855455393224,
      "grad_norm": 0.3181093633174896,
      "learning_rate": 8.64275722723034e-06,
      "loss": 0.1911,
      "step": 3493
    },
    {
      "epoch": 0.27152626670811314,
      "grad_norm": 0.4391370117664337,
      "learning_rate": 8.642368666459436e-06,
      "loss": 0.3095,
      "step": 3494
    },
    {
      "epoch": 0.27160397886229404,
      "grad_norm": 0.7250528931617737,
      "learning_rate": 8.64198010568853e-06,
      "loss": 0.292,
      "step": 3495
    },
    {
      "epoch": 0.271681691016475,
      "grad_norm": 0.9773755669593811,
      "learning_rate": 8.641591544917626e-06,
      "loss": 0.6731,
      "step": 3496
    },
    {
      "epoch": 0.2717594031706559,
      "grad_norm": 0.10870170593261719,
      "learning_rate": 8.64120298414672e-06,
      "loss": 0.024,
      "step": 3497
    },
    {
      "epoch": 0.2718371153248368,
      "grad_norm": 0.376830518245697,
      "learning_rate": 8.640814423375816e-06,
      "loss": 0.4044,
      "step": 3498
    },
    {
      "epoch": 0.27191482747901774,
      "grad_norm": 0.27142030000686646,
      "learning_rate": 8.640425862604912e-06,
      "loss": 0.2168,
      "step": 3499
    },
    {
      "epoch": 0.27199253963319864,
      "grad_norm": 0.40549996495246887,
      "learning_rate": 8.640037301834007e-06,
      "loss": 0.2042,
      "step": 3500
    },
    {
      "epoch": 0.27207025178737954,
      "grad_norm": 0.3919588327407837,
      "learning_rate": 8.639648741063102e-06,
      "loss": 0.1427,
      "step": 3501
    },
    {
      "epoch": 0.27214796394156043,
      "grad_norm": 0.3996240794658661,
      "learning_rate": 8.639260180292199e-06,
      "loss": 0.1464,
      "step": 3502
    },
    {
      "epoch": 0.2722256760957414,
      "grad_norm": 0.34459251165390015,
      "learning_rate": 8.638871619521294e-06,
      "loss": 0.7524,
      "step": 3503
    },
    {
      "epoch": 0.2723033882499223,
      "grad_norm": 0.42402949929237366,
      "learning_rate": 8.638483058750389e-06,
      "loss": 0.2148,
      "step": 3504
    },
    {
      "epoch": 0.2723811004041032,
      "grad_norm": 1.7794804573059082,
      "learning_rate": 8.638094497979484e-06,
      "loss": 0.2947,
      "step": 3505
    },
    {
      "epoch": 0.27245881255828414,
      "grad_norm": 0.12180893123149872,
      "learning_rate": 8.63770593720858e-06,
      "loss": 0.0617,
      "step": 3506
    },
    {
      "epoch": 0.27253652471246503,
      "grad_norm": 0.20357902348041534,
      "learning_rate": 8.637317376437675e-06,
      "loss": 0.1395,
      "step": 3507
    },
    {
      "epoch": 0.27261423686664593,
      "grad_norm": 0.18157915771007538,
      "learning_rate": 8.63692881566677e-06,
      "loss": 0.0696,
      "step": 3508
    },
    {
      "epoch": 0.2726919490208269,
      "grad_norm": 0.2070898413658142,
      "learning_rate": 8.636540254895867e-06,
      "loss": 0.0802,
      "step": 3509
    },
    {
      "epoch": 0.2727696611750078,
      "grad_norm": 0.3613315224647522,
      "learning_rate": 8.636151694124962e-06,
      "loss": 0.2873,
      "step": 3510
    },
    {
      "epoch": 0.2728473733291887,
      "grad_norm": 0.2530859708786011,
      "learning_rate": 8.635763133354057e-06,
      "loss": 0.1091,
      "step": 3511
    },
    {
      "epoch": 0.2729250854833696,
      "grad_norm": 0.1622982770204544,
      "learning_rate": 8.635374572583153e-06,
      "loss": 0.0779,
      "step": 3512
    },
    {
      "epoch": 0.27300279763755053,
      "grad_norm": 0.523992121219635,
      "learning_rate": 8.634986011812248e-06,
      "loss": 0.4528,
      "step": 3513
    },
    {
      "epoch": 0.27308050979173143,
      "grad_norm": 0.17425404489040375,
      "learning_rate": 8.634597451041343e-06,
      "loss": 0.0706,
      "step": 3514
    },
    {
      "epoch": 0.2731582219459123,
      "grad_norm": 0.1443803608417511,
      "learning_rate": 8.634208890270438e-06,
      "loss": 0.0441,
      "step": 3515
    },
    {
      "epoch": 0.2732359341000933,
      "grad_norm": 0.48529016971588135,
      "learning_rate": 8.633820329499535e-06,
      "loss": 0.3776,
      "step": 3516
    },
    {
      "epoch": 0.2733136462542742,
      "grad_norm": 0.6819028854370117,
      "learning_rate": 8.63343176872863e-06,
      "loss": 0.3112,
      "step": 3517
    },
    {
      "epoch": 0.2733913584084551,
      "grad_norm": 0.6117618680000305,
      "learning_rate": 8.633043207957725e-06,
      "loss": 0.0754,
      "step": 3518
    },
    {
      "epoch": 0.273469070562636,
      "grad_norm": 0.17863553762435913,
      "learning_rate": 8.632654647186821e-06,
      "loss": 0.0833,
      "step": 3519
    },
    {
      "epoch": 0.2735467827168169,
      "grad_norm": 0.1203877404332161,
      "learning_rate": 8.632266086415916e-06,
      "loss": 0.0743,
      "step": 3520
    },
    {
      "epoch": 0.2736244948709978,
      "grad_norm": 0.37159979343414307,
      "learning_rate": 8.631877525645011e-06,
      "loss": 0.3106,
      "step": 3521
    },
    {
      "epoch": 0.2737022070251787,
      "grad_norm": 0.19411379098892212,
      "learning_rate": 8.631488964874108e-06,
      "loss": 0.0739,
      "step": 3522
    },
    {
      "epoch": 0.2737799191793597,
      "grad_norm": 0.7026755809783936,
      "learning_rate": 8.631100404103201e-06,
      "loss": 0.147,
      "step": 3523
    },
    {
      "epoch": 0.2738576313335406,
      "grad_norm": 0.1461140662431717,
      "learning_rate": 8.630711843332298e-06,
      "loss": 0.0556,
      "step": 3524
    },
    {
      "epoch": 0.27393534348772147,
      "grad_norm": 0.2294112890958786,
      "learning_rate": 8.630323282561393e-06,
      "loss": 0.1087,
      "step": 3525
    },
    {
      "epoch": 0.27401305564190237,
      "grad_norm": 0.29978927969932556,
      "learning_rate": 8.629934721790488e-06,
      "loss": 0.1268,
      "step": 3526
    },
    {
      "epoch": 0.2740907677960833,
      "grad_norm": 0.35093507170677185,
      "learning_rate": 8.629546161019584e-06,
      "loss": 0.1589,
      "step": 3527
    },
    {
      "epoch": 0.2741684799502642,
      "grad_norm": 0.08218114823102951,
      "learning_rate": 8.62915760024868e-06,
      "loss": 0.0127,
      "step": 3528
    },
    {
      "epoch": 0.2742461921044451,
      "grad_norm": 0.16097447276115417,
      "learning_rate": 8.628769039477774e-06,
      "loss": 0.0807,
      "step": 3529
    },
    {
      "epoch": 0.2743239042586261,
      "grad_norm": 0.29306888580322266,
      "learning_rate": 8.628380478706871e-06,
      "loss": 0.1363,
      "step": 3530
    },
    {
      "epoch": 0.27440161641280697,
      "grad_norm": 0.35616791248321533,
      "learning_rate": 8.627991917935966e-06,
      "loss": 0.084,
      "step": 3531
    },
    {
      "epoch": 0.27447932856698787,
      "grad_norm": 0.31190934777259827,
      "learning_rate": 8.627603357165061e-06,
      "loss": 0.0769,
      "step": 3532
    },
    {
      "epoch": 0.27455704072116877,
      "grad_norm": 0.17200268805027008,
      "learning_rate": 8.627214796394156e-06,
      "loss": 0.0725,
      "step": 3533
    },
    {
      "epoch": 0.2746347528753497,
      "grad_norm": 0.12101568281650543,
      "learning_rate": 8.626826235623252e-06,
      "loss": 0.0331,
      "step": 3534
    },
    {
      "epoch": 0.2747124650295306,
      "grad_norm": 0.5570086240768433,
      "learning_rate": 8.626437674852347e-06,
      "loss": 0.1504,
      "step": 3535
    },
    {
      "epoch": 0.2747901771837115,
      "grad_norm": 0.4105927050113678,
      "learning_rate": 8.626049114081442e-06,
      "loss": 0.4393,
      "step": 3536
    },
    {
      "epoch": 0.27486788933789247,
      "grad_norm": 0.20866239070892334,
      "learning_rate": 8.625660553310539e-06,
      "loss": 0.0667,
      "step": 3537
    },
    {
      "epoch": 0.27494560149207337,
      "grad_norm": 0.7277289628982544,
      "learning_rate": 8.625271992539634e-06,
      "loss": 0.3083,
      "step": 3538
    },
    {
      "epoch": 0.27502331364625426,
      "grad_norm": 0.728655993938446,
      "learning_rate": 8.624883431768729e-06,
      "loss": 0.4578,
      "step": 3539
    },
    {
      "epoch": 0.27510102580043516,
      "grad_norm": 0.18569894134998322,
      "learning_rate": 8.624494870997826e-06,
      "loss": 0.0782,
      "step": 3540
    },
    {
      "epoch": 0.2751787379546161,
      "grad_norm": 0.44976648688316345,
      "learning_rate": 8.62410631022692e-06,
      "loss": 0.177,
      "step": 3541
    },
    {
      "epoch": 0.275256450108797,
      "grad_norm": 0.15842579305171967,
      "learning_rate": 8.623717749456015e-06,
      "loss": 0.0627,
      "step": 3542
    },
    {
      "epoch": 0.2753341622629779,
      "grad_norm": 0.27781108021736145,
      "learning_rate": 8.62332918868511e-06,
      "loss": 0.4322,
      "step": 3543
    },
    {
      "epoch": 0.27541187441715886,
      "grad_norm": 0.8110105991363525,
      "learning_rate": 8.622940627914207e-06,
      "loss": 0.1497,
      "step": 3544
    },
    {
      "epoch": 0.27548958657133976,
      "grad_norm": 0.15791217982769012,
      "learning_rate": 8.622552067143302e-06,
      "loss": 0.1134,
      "step": 3545
    },
    {
      "epoch": 0.27556729872552066,
      "grad_norm": 0.44838184118270874,
      "learning_rate": 8.622163506372397e-06,
      "loss": 0.2701,
      "step": 3546
    },
    {
      "epoch": 0.2756450108797016,
      "grad_norm": 0.23031142354011536,
      "learning_rate": 8.621774945601494e-06,
      "loss": 0.0532,
      "step": 3547
    },
    {
      "epoch": 0.2757227230338825,
      "grad_norm": 0.5120829939842224,
      "learning_rate": 8.621386384830589e-06,
      "loss": 0.4099,
      "step": 3548
    },
    {
      "epoch": 0.2758004351880634,
      "grad_norm": 0.12671403586864471,
      "learning_rate": 8.620997824059683e-06,
      "loss": 0.0866,
      "step": 3549
    },
    {
      "epoch": 0.2758781473422443,
      "grad_norm": 0.275333046913147,
      "learning_rate": 8.62060926328878e-06,
      "loss": 0.1649,
      "step": 3550
    },
    {
      "epoch": 0.27595585949642526,
      "grad_norm": 0.4034195840358734,
      "learning_rate": 8.620220702517873e-06,
      "loss": 0.1026,
      "step": 3551
    },
    {
      "epoch": 0.27603357165060616,
      "grad_norm": 0.23379576206207275,
      "learning_rate": 8.61983214174697e-06,
      "loss": 0.1272,
      "step": 3552
    },
    {
      "epoch": 0.27611128380478706,
      "grad_norm": 0.3670170307159424,
      "learning_rate": 8.619443580976065e-06,
      "loss": 0.1434,
      "step": 3553
    },
    {
      "epoch": 0.276188995958968,
      "grad_norm": 2.4051599502563477,
      "learning_rate": 8.61905502020516e-06,
      "loss": 0.0802,
      "step": 3554
    },
    {
      "epoch": 0.2762667081131489,
      "grad_norm": 0.12097039818763733,
      "learning_rate": 8.618666459434257e-06,
      "loss": 0.0639,
      "step": 3555
    },
    {
      "epoch": 0.2763444202673298,
      "grad_norm": 0.42039820551872253,
      "learning_rate": 8.618277898663352e-06,
      "loss": 0.2031,
      "step": 3556
    },
    {
      "epoch": 0.2764221324215107,
      "grad_norm": 0.8312196135520935,
      "learning_rate": 8.617889337892446e-06,
      "loss": 0.427,
      "step": 3557
    },
    {
      "epoch": 0.27649984457569166,
      "grad_norm": 0.46089574694633484,
      "learning_rate": 8.617500777121543e-06,
      "loss": 0.1326,
      "step": 3558
    },
    {
      "epoch": 0.27657755672987255,
      "grad_norm": 0.11844765394926071,
      "learning_rate": 8.617112216350638e-06,
      "loss": 0.0469,
      "step": 3559
    },
    {
      "epoch": 0.27665526888405345,
      "grad_norm": 0.26122376322746277,
      "learning_rate": 8.616723655579733e-06,
      "loss": 0.1044,
      "step": 3560
    },
    {
      "epoch": 0.2767329810382344,
      "grad_norm": 0.1838594526052475,
      "learning_rate": 8.616335094808828e-06,
      "loss": 0.1378,
      "step": 3561
    },
    {
      "epoch": 0.2768106931924153,
      "grad_norm": 0.4060819447040558,
      "learning_rate": 8.615946534037925e-06,
      "loss": 0.1372,
      "step": 3562
    },
    {
      "epoch": 0.2768884053465962,
      "grad_norm": 0.9145359992980957,
      "learning_rate": 8.61555797326702e-06,
      "loss": 0.7548,
      "step": 3563
    },
    {
      "epoch": 0.2769661175007771,
      "grad_norm": 0.4036366045475006,
      "learning_rate": 8.615169412496115e-06,
      "loss": 0.1448,
      "step": 3564
    },
    {
      "epoch": 0.27704382965495805,
      "grad_norm": 0.27679768204689026,
      "learning_rate": 8.614780851725211e-06,
      "loss": 0.2741,
      "step": 3565
    },
    {
      "epoch": 0.27712154180913895,
      "grad_norm": 0.2882368862628937,
      "learning_rate": 8.614392290954306e-06,
      "loss": 0.0991,
      "step": 3566
    },
    {
      "epoch": 0.27719925396331985,
      "grad_norm": 0.3921625018119812,
      "learning_rate": 8.614003730183401e-06,
      "loss": 0.2834,
      "step": 3567
    },
    {
      "epoch": 0.2772769661175008,
      "grad_norm": 0.061226729303598404,
      "learning_rate": 8.613615169412498e-06,
      "loss": 0.0118,
      "step": 3568
    },
    {
      "epoch": 0.2773546782716817,
      "grad_norm": 0.40907013416290283,
      "learning_rate": 8.613226608641593e-06,
      "loss": 0.132,
      "step": 3569
    },
    {
      "epoch": 0.2774323904258626,
      "grad_norm": 0.6171413064002991,
      "learning_rate": 8.612838047870688e-06,
      "loss": 0.3722,
      "step": 3570
    },
    {
      "epoch": 0.2775101025800435,
      "grad_norm": 0.32698535919189453,
      "learning_rate": 8.612449487099783e-06,
      "loss": 0.5184,
      "step": 3571
    },
    {
      "epoch": 0.27758781473422445,
      "grad_norm": 0.08980563282966614,
      "learning_rate": 8.61206092632888e-06,
      "loss": 0.0483,
      "step": 3572
    },
    {
      "epoch": 0.27766552688840535,
      "grad_norm": 0.5660918354988098,
      "learning_rate": 8.611672365557974e-06,
      "loss": 0.2292,
      "step": 3573
    },
    {
      "epoch": 0.27774323904258624,
      "grad_norm": 0.47961702942848206,
      "learning_rate": 8.611283804787069e-06,
      "loss": 0.2236,
      "step": 3574
    },
    {
      "epoch": 0.2778209511967672,
      "grad_norm": 0.1459193378686905,
      "learning_rate": 8.610895244016166e-06,
      "loss": 0.1566,
      "step": 3575
    },
    {
      "epoch": 0.2778986633509481,
      "grad_norm": 0.3536983132362366,
      "learning_rate": 8.61050668324526e-06,
      "loss": 0.0635,
      "step": 3576
    },
    {
      "epoch": 0.277976375505129,
      "grad_norm": 0.6622627377510071,
      "learning_rate": 8.610118122474356e-06,
      "loss": 0.3899,
      "step": 3577
    },
    {
      "epoch": 0.2780540876593099,
      "grad_norm": 1.289451003074646,
      "learning_rate": 8.609729561703452e-06,
      "loss": 0.42,
      "step": 3578
    },
    {
      "epoch": 0.27813179981349084,
      "grad_norm": 0.07709097862243652,
      "learning_rate": 8.609341000932546e-06,
      "loss": 0.0098,
      "step": 3579
    },
    {
      "epoch": 0.27820951196767174,
      "grad_norm": 0.0706334114074707,
      "learning_rate": 8.608952440161642e-06,
      "loss": 0.0187,
      "step": 3580
    },
    {
      "epoch": 0.27828722412185264,
      "grad_norm": 0.3043144643306732,
      "learning_rate": 8.608563879390737e-06,
      "loss": 0.072,
      "step": 3581
    },
    {
      "epoch": 0.2783649362760336,
      "grad_norm": 0.512832760810852,
      "learning_rate": 8.608175318619832e-06,
      "loss": 0.1677,
      "step": 3582
    },
    {
      "epoch": 0.2784426484302145,
      "grad_norm": 0.4722461998462677,
      "learning_rate": 8.607786757848929e-06,
      "loss": 0.3535,
      "step": 3583
    },
    {
      "epoch": 0.2785203605843954,
      "grad_norm": 0.4271574020385742,
      "learning_rate": 8.607398197078024e-06,
      "loss": 0.2641,
      "step": 3584
    },
    {
      "epoch": 0.2785980727385763,
      "grad_norm": 0.17736698687076569,
      "learning_rate": 8.607009636307119e-06,
      "loss": 0.0897,
      "step": 3585
    },
    {
      "epoch": 0.27867578489275724,
      "grad_norm": 0.1601351648569107,
      "learning_rate": 8.606621075536215e-06,
      "loss": 0.1033,
      "step": 3586
    },
    {
      "epoch": 0.27875349704693814,
      "grad_norm": 0.32555413246154785,
      "learning_rate": 8.60623251476531e-06,
      "loss": 0.1021,
      "step": 3587
    },
    {
      "epoch": 0.27883120920111903,
      "grad_norm": 1.5037897825241089,
      "learning_rate": 8.605843953994405e-06,
      "loss": 0.3236,
      "step": 3588
    },
    {
      "epoch": 0.2789089213553,
      "grad_norm": 0.8595836758613586,
      "learning_rate": 8.6054553932235e-06,
      "loss": 0.7742,
      "step": 3589
    },
    {
      "epoch": 0.2789866335094809,
      "grad_norm": 0.2139735072851181,
      "learning_rate": 8.605066832452597e-06,
      "loss": 0.0908,
      "step": 3590
    },
    {
      "epoch": 0.2790643456636618,
      "grad_norm": 0.36566635966300964,
      "learning_rate": 8.604678271681692e-06,
      "loss": 0.0789,
      "step": 3591
    },
    {
      "epoch": 0.27914205781784274,
      "grad_norm": 0.15867334604263306,
      "learning_rate": 8.604289710910787e-06,
      "loss": 0.0761,
      "step": 3592
    },
    {
      "epoch": 0.27921976997202363,
      "grad_norm": 0.46138161420822144,
      "learning_rate": 8.603901150139883e-06,
      "loss": 0.4192,
      "step": 3593
    },
    {
      "epoch": 0.27929748212620453,
      "grad_norm": 0.1542886197566986,
      "learning_rate": 8.603512589368978e-06,
      "loss": 0.112,
      "step": 3594
    },
    {
      "epoch": 0.27937519428038543,
      "grad_norm": 0.2904740571975708,
      "learning_rate": 8.603124028598073e-06,
      "loss": 0.5234,
      "step": 3595
    },
    {
      "epoch": 0.2794529064345664,
      "grad_norm": 0.14536252617835999,
      "learning_rate": 8.60273546782717e-06,
      "loss": 0.0548,
      "step": 3596
    },
    {
      "epoch": 0.2795306185887473,
      "grad_norm": 0.303545206785202,
      "learning_rate": 8.602346907056265e-06,
      "loss": 0.2467,
      "step": 3597
    },
    {
      "epoch": 0.2796083307429282,
      "grad_norm": 0.26539552211761475,
      "learning_rate": 8.60195834628536e-06,
      "loss": 0.1906,
      "step": 3598
    },
    {
      "epoch": 0.27968604289710913,
      "grad_norm": 0.10920743644237518,
      "learning_rate": 8.601569785514455e-06,
      "loss": 0.061,
      "step": 3599
    },
    {
      "epoch": 0.27976375505129003,
      "grad_norm": 0.2923983037471771,
      "learning_rate": 8.601181224743551e-06,
      "loss": 0.1509,
      "step": 3600
    },
    {
      "epoch": 0.27984146720547093,
      "grad_norm": 0.2559923231601715,
      "learning_rate": 8.600792663972646e-06,
      "loss": 0.1679,
      "step": 3601
    },
    {
      "epoch": 0.2799191793596518,
      "grad_norm": 0.10088949650526047,
      "learning_rate": 8.600404103201741e-06,
      "loss": 0.0201,
      "step": 3602
    },
    {
      "epoch": 0.2799968915138328,
      "grad_norm": 0.37914758920669556,
      "learning_rate": 8.600015542430838e-06,
      "loss": 0.0284,
      "step": 3603
    },
    {
      "epoch": 0.2800746036680137,
      "grad_norm": 0.46703633666038513,
      "learning_rate": 8.599626981659933e-06,
      "loss": 0.162,
      "step": 3604
    },
    {
      "epoch": 0.2801523158221946,
      "grad_norm": 2.117551565170288,
      "learning_rate": 8.599238420889028e-06,
      "loss": 0.7595,
      "step": 3605
    },
    {
      "epoch": 0.28023002797637553,
      "grad_norm": 0.6493442058563232,
      "learning_rate": 8.598849860118124e-06,
      "loss": 0.3432,
      "step": 3606
    },
    {
      "epoch": 0.2803077401305564,
      "grad_norm": 0.21871857345104218,
      "learning_rate": 8.598461299347218e-06,
      "loss": 0.0508,
      "step": 3607
    },
    {
      "epoch": 0.2803854522847373,
      "grad_norm": 0.12020821869373322,
      "learning_rate": 8.598072738576314e-06,
      "loss": 0.0229,
      "step": 3608
    },
    {
      "epoch": 0.2804631644389182,
      "grad_norm": 0.3605567216873169,
      "learning_rate": 8.59768417780541e-06,
      "loss": 0.2657,
      "step": 3609
    },
    {
      "epoch": 0.2805408765930992,
      "grad_norm": 0.5530945658683777,
      "learning_rate": 8.597295617034504e-06,
      "loss": 0.958,
      "step": 3610
    },
    {
      "epoch": 0.2806185887472801,
      "grad_norm": 0.22691932320594788,
      "learning_rate": 8.596907056263601e-06,
      "loss": 0.1539,
      "step": 3611
    },
    {
      "epoch": 0.28069630090146097,
      "grad_norm": 0.8279405236244202,
      "learning_rate": 8.596518495492696e-06,
      "loss": 0.5395,
      "step": 3612
    },
    {
      "epoch": 0.2807740130556419,
      "grad_norm": 0.2588904798030853,
      "learning_rate": 8.59612993472179e-06,
      "loss": 0.0982,
      "step": 3613
    },
    {
      "epoch": 0.2808517252098228,
      "grad_norm": 0.1619672179222107,
      "learning_rate": 8.595741373950887e-06,
      "loss": 0.0736,
      "step": 3614
    },
    {
      "epoch": 0.2809294373640037,
      "grad_norm": 0.2213413268327713,
      "learning_rate": 8.595352813179982e-06,
      "loss": 0.082,
      "step": 3615
    },
    {
      "epoch": 0.2810071495181846,
      "grad_norm": 0.4686155617237091,
      "learning_rate": 8.594964252409077e-06,
      "loss": 0.3999,
      "step": 3616
    },
    {
      "epoch": 0.28108486167236557,
      "grad_norm": 0.4386276602745056,
      "learning_rate": 8.594575691638172e-06,
      "loss": 0.2598,
      "step": 3617
    },
    {
      "epoch": 0.28116257382654647,
      "grad_norm": 0.44341498613357544,
      "learning_rate": 8.594187130867269e-06,
      "loss": 0.1075,
      "step": 3618
    },
    {
      "epoch": 0.28124028598072737,
      "grad_norm": 0.40836483240127563,
      "learning_rate": 8.593798570096364e-06,
      "loss": 0.1603,
      "step": 3619
    },
    {
      "epoch": 0.2813179981349083,
      "grad_norm": 0.3157438337802887,
      "learning_rate": 8.593410009325459e-06,
      "loss": 0.3982,
      "step": 3620
    },
    {
      "epoch": 0.2813957102890892,
      "grad_norm": 0.6256620287895203,
      "learning_rate": 8.593021448554555e-06,
      "loss": 0.1855,
      "step": 3621
    },
    {
      "epoch": 0.2814734224432701,
      "grad_norm": 0.23279964923858643,
      "learning_rate": 8.59263288778365e-06,
      "loss": 0.1529,
      "step": 3622
    },
    {
      "epoch": 0.281551134597451,
      "grad_norm": 0.3770030736923218,
      "learning_rate": 8.592244327012745e-06,
      "loss": 0.3804,
      "step": 3623
    },
    {
      "epoch": 0.28162884675163197,
      "grad_norm": 0.544733464717865,
      "learning_rate": 8.59185576624184e-06,
      "loss": 0.5557,
      "step": 3624
    },
    {
      "epoch": 0.28170655890581286,
      "grad_norm": 0.33922675251960754,
      "learning_rate": 8.591467205470935e-06,
      "loss": 0.4256,
      "step": 3625
    },
    {
      "epoch": 0.28178427105999376,
      "grad_norm": 0.178669735789299,
      "learning_rate": 8.591078644700032e-06,
      "loss": 0.1038,
      "step": 3626
    },
    {
      "epoch": 0.2818619832141747,
      "grad_norm": 0.24866993725299835,
      "learning_rate": 8.590690083929127e-06,
      "loss": 0.1367,
      "step": 3627
    },
    {
      "epoch": 0.2819396953683556,
      "grad_norm": 0.20738407969474792,
      "learning_rate": 8.590301523158223e-06,
      "loss": 0.0817,
      "step": 3628
    },
    {
      "epoch": 0.2820174075225365,
      "grad_norm": 0.1853523701429367,
      "learning_rate": 8.589912962387318e-06,
      "loss": 0.0782,
      "step": 3629
    },
    {
      "epoch": 0.28209511967671747,
      "grad_norm": 0.9374611973762512,
      "learning_rate": 8.589524401616413e-06,
      "loss": 0.4086,
      "step": 3630
    },
    {
      "epoch": 0.28217283183089836,
      "grad_norm": 0.1537209451198578,
      "learning_rate": 8.58913584084551e-06,
      "loss": 0.0911,
      "step": 3631
    },
    {
      "epoch": 0.28225054398507926,
      "grad_norm": 0.17993687093257904,
      "learning_rate": 8.588747280074603e-06,
      "loss": 0.181,
      "step": 3632
    },
    {
      "epoch": 0.28232825613926016,
      "grad_norm": 0.3892255425453186,
      "learning_rate": 8.5883587193037e-06,
      "loss": 0.2219,
      "step": 3633
    },
    {
      "epoch": 0.2824059682934411,
      "grad_norm": 0.45675015449523926,
      "learning_rate": 8.587970158532795e-06,
      "loss": 0.2041,
      "step": 3634
    },
    {
      "epoch": 0.282483680447622,
      "grad_norm": 0.3466733992099762,
      "learning_rate": 8.58758159776189e-06,
      "loss": 0.1032,
      "step": 3635
    },
    {
      "epoch": 0.2825613926018029,
      "grad_norm": 0.3442978262901306,
      "learning_rate": 8.587193036990986e-06,
      "loss": 0.1485,
      "step": 3636
    },
    {
      "epoch": 0.28263910475598386,
      "grad_norm": 0.4987252950668335,
      "learning_rate": 8.586804476220081e-06,
      "loss": 0.1767,
      "step": 3637
    },
    {
      "epoch": 0.28271681691016476,
      "grad_norm": 0.46841853857040405,
      "learning_rate": 8.586415915449176e-06,
      "loss": 0.5568,
      "step": 3638
    },
    {
      "epoch": 0.28279452906434566,
      "grad_norm": 0.5304543972015381,
      "learning_rate": 8.586027354678273e-06,
      "loss": 0.1574,
      "step": 3639
    },
    {
      "epoch": 0.28287224121852655,
      "grad_norm": 0.7541822195053101,
      "learning_rate": 8.585638793907368e-06,
      "loss": 0.6537,
      "step": 3640
    },
    {
      "epoch": 0.2829499533727075,
      "grad_norm": 0.4866155982017517,
      "learning_rate": 8.585250233136463e-06,
      "loss": 0.2478,
      "step": 3641
    },
    {
      "epoch": 0.2830276655268884,
      "grad_norm": 0.36529624462127686,
      "learning_rate": 8.584861672365558e-06,
      "loss": 0.1543,
      "step": 3642
    },
    {
      "epoch": 0.2831053776810693,
      "grad_norm": 0.5996958017349243,
      "learning_rate": 8.584473111594655e-06,
      "loss": 0.625,
      "step": 3643
    },
    {
      "epoch": 0.28318308983525026,
      "grad_norm": 0.09043675661087036,
      "learning_rate": 8.58408455082375e-06,
      "loss": 0.0742,
      "step": 3644
    },
    {
      "epoch": 0.28326080198943115,
      "grad_norm": 0.4887719452381134,
      "learning_rate": 8.583695990052844e-06,
      "loss": 0.2448,
      "step": 3645
    },
    {
      "epoch": 0.28333851414361205,
      "grad_norm": 0.19555923342704773,
      "learning_rate": 8.583307429281941e-06,
      "loss": 0.0576,
      "step": 3646
    },
    {
      "epoch": 0.28341622629779295,
      "grad_norm": 2.0124058723449707,
      "learning_rate": 8.582918868511036e-06,
      "loss": 0.3269,
      "step": 3647
    },
    {
      "epoch": 0.2834939384519739,
      "grad_norm": 0.6902421116828918,
      "learning_rate": 8.582530307740131e-06,
      "loss": 0.2791,
      "step": 3648
    },
    {
      "epoch": 0.2835716506061548,
      "grad_norm": 0.7385401725769043,
      "learning_rate": 8.582141746969228e-06,
      "loss": 0.7121,
      "step": 3649
    },
    {
      "epoch": 0.2836493627603357,
      "grad_norm": 0.7702925801277161,
      "learning_rate": 8.581753186198321e-06,
      "loss": 0.919,
      "step": 3650
    },
    {
      "epoch": 0.28372707491451665,
      "grad_norm": 0.14940419793128967,
      "learning_rate": 8.581364625427418e-06,
      "loss": 0.0403,
      "step": 3651
    },
    {
      "epoch": 0.28380478706869755,
      "grad_norm": 0.253435879945755,
      "learning_rate": 8.580976064656512e-06,
      "loss": 0.099,
      "step": 3652
    },
    {
      "epoch": 0.28388249922287845,
      "grad_norm": 0.130395770072937,
      "learning_rate": 8.580587503885607e-06,
      "loss": 0.1174,
      "step": 3653
    },
    {
      "epoch": 0.28396021137705935,
      "grad_norm": 0.526639997959137,
      "learning_rate": 8.580198943114704e-06,
      "loss": 0.2987,
      "step": 3654
    },
    {
      "epoch": 0.2840379235312403,
      "grad_norm": 0.31143099069595337,
      "learning_rate": 8.579810382343799e-06,
      "loss": 0.1864,
      "step": 3655
    },
    {
      "epoch": 0.2841156356854212,
      "grad_norm": 0.217710942029953,
      "learning_rate": 8.579421821572894e-06,
      "loss": 0.0684,
      "step": 3656
    },
    {
      "epoch": 0.2841933478396021,
      "grad_norm": 1.0027503967285156,
      "learning_rate": 8.57903326080199e-06,
      "loss": 0.4816,
      "step": 3657
    },
    {
      "epoch": 0.28427105999378305,
      "grad_norm": 0.4732268154621124,
      "learning_rate": 8.578644700031086e-06,
      "loss": 0.5018,
      "step": 3658
    },
    {
      "epoch": 0.28434877214796395,
      "grad_norm": 0.3992486000061035,
      "learning_rate": 8.578256139260182e-06,
      "loss": 0.416,
      "step": 3659
    },
    {
      "epoch": 0.28442648430214484,
      "grad_norm": 0.18101951479911804,
      "learning_rate": 8.577867578489275e-06,
      "loss": 0.1128,
      "step": 3660
    },
    {
      "epoch": 0.28450419645632574,
      "grad_norm": 0.1502668410539627,
      "learning_rate": 8.577479017718372e-06,
      "loss": 0.0341,
      "step": 3661
    },
    {
      "epoch": 0.2845819086105067,
      "grad_norm": 0.13378728926181793,
      "learning_rate": 8.577090456947467e-06,
      "loss": 0.0336,
      "step": 3662
    },
    {
      "epoch": 0.2846596207646876,
      "grad_norm": 0.42824336886405945,
      "learning_rate": 8.576701896176562e-06,
      "loss": 0.2367,
      "step": 3663
    },
    {
      "epoch": 0.2847373329188685,
      "grad_norm": 0.47002899646759033,
      "learning_rate": 8.576313335405659e-06,
      "loss": 0.3175,
      "step": 3664
    },
    {
      "epoch": 0.28481504507304944,
      "grad_norm": 0.6000451445579529,
      "learning_rate": 8.575924774634754e-06,
      "loss": 0.7031,
      "step": 3665
    },
    {
      "epoch": 0.28489275722723034,
      "grad_norm": 0.14558376371860504,
      "learning_rate": 8.575536213863849e-06,
      "loss": 0.0301,
      "step": 3666
    },
    {
      "epoch": 0.28497046938141124,
      "grad_norm": 0.6084781289100647,
      "learning_rate": 8.575147653092945e-06,
      "loss": 0.5976,
      "step": 3667
    },
    {
      "epoch": 0.2850481815355922,
      "grad_norm": 0.33639609813690186,
      "learning_rate": 8.57475909232204e-06,
      "loss": 0.1274,
      "step": 3668
    },
    {
      "epoch": 0.2851258936897731,
      "grad_norm": 0.45703092217445374,
      "learning_rate": 8.574370531551135e-06,
      "loss": 0.6218,
      "step": 3669
    },
    {
      "epoch": 0.285203605843954,
      "grad_norm": 0.627058744430542,
      "learning_rate": 8.57398197078023e-06,
      "loss": 0.2531,
      "step": 3670
    },
    {
      "epoch": 0.2852813179981349,
      "grad_norm": 0.29138198494911194,
      "learning_rate": 8.573593410009327e-06,
      "loss": 0.1804,
      "step": 3671
    },
    {
      "epoch": 0.28535903015231584,
      "grad_norm": 0.1249929666519165,
      "learning_rate": 8.573204849238422e-06,
      "loss": 0.0617,
      "step": 3672
    },
    {
      "epoch": 0.28543674230649674,
      "grad_norm": 0.148574098944664,
      "learning_rate": 8.572816288467517e-06,
      "loss": 0.0781,
      "step": 3673
    },
    {
      "epoch": 0.28551445446067764,
      "grad_norm": 0.24299854040145874,
      "learning_rate": 8.572427727696613e-06,
      "loss": 0.1131,
      "step": 3674
    },
    {
      "epoch": 0.2855921666148586,
      "grad_norm": 1.1528912782669067,
      "learning_rate": 8.572039166925708e-06,
      "loss": 0.243,
      "step": 3675
    },
    {
      "epoch": 0.2856698787690395,
      "grad_norm": 0.4810813367366791,
      "learning_rate": 8.571650606154803e-06,
      "loss": 0.8415,
      "step": 3676
    },
    {
      "epoch": 0.2857475909232204,
      "grad_norm": 0.3781508505344391,
      "learning_rate": 8.5712620453839e-06,
      "loss": 0.3957,
      "step": 3677
    },
    {
      "epoch": 0.2858253030774013,
      "grad_norm": 0.2119142860174179,
      "learning_rate": 8.570873484612993e-06,
      "loss": 0.1204,
      "step": 3678
    },
    {
      "epoch": 0.28590301523158224,
      "grad_norm": 0.1264050006866455,
      "learning_rate": 8.57048492384209e-06,
      "loss": 0.0663,
      "step": 3679
    },
    {
      "epoch": 0.28598072738576313,
      "grad_norm": 0.402609258890152,
      "learning_rate": 8.570096363071185e-06,
      "loss": 0.4109,
      "step": 3680
    },
    {
      "epoch": 0.28605843953994403,
      "grad_norm": 0.17451582849025726,
      "learning_rate": 8.56970780230028e-06,
      "loss": 0.0529,
      "step": 3681
    },
    {
      "epoch": 0.286136151694125,
      "grad_norm": 0.13133175671100616,
      "learning_rate": 8.569319241529376e-06,
      "loss": 0.0282,
      "step": 3682
    },
    {
      "epoch": 0.2862138638483059,
      "grad_norm": 0.20847803354263306,
      "learning_rate": 8.568930680758471e-06,
      "loss": 0.1831,
      "step": 3683
    },
    {
      "epoch": 0.2862915760024868,
      "grad_norm": 0.0814942866563797,
      "learning_rate": 8.568542119987566e-06,
      "loss": 0.0367,
      "step": 3684
    },
    {
      "epoch": 0.2863692881566677,
      "grad_norm": 1.0407072305679321,
      "learning_rate": 8.568153559216663e-06,
      "loss": 0.2415,
      "step": 3685
    },
    {
      "epoch": 0.28644700031084863,
      "grad_norm": 0.2785276472568512,
      "learning_rate": 8.567764998445758e-06,
      "loss": 0.1863,
      "step": 3686
    },
    {
      "epoch": 0.28652471246502953,
      "grad_norm": 0.27175959944725037,
      "learning_rate": 8.567376437674853e-06,
      "loss": 0.1398,
      "step": 3687
    },
    {
      "epoch": 0.2866024246192104,
      "grad_norm": 0.1822969615459442,
      "learning_rate": 8.566987876903948e-06,
      "loss": 0.0646,
      "step": 3688
    },
    {
      "epoch": 0.2866801367733914,
      "grad_norm": 0.1515205353498459,
      "learning_rate": 8.566599316133044e-06,
      "loss": 0.0711,
      "step": 3689
    },
    {
      "epoch": 0.2867578489275723,
      "grad_norm": 0.0960649698972702,
      "learning_rate": 8.56621075536214e-06,
      "loss": 0.1427,
      "step": 3690
    },
    {
      "epoch": 0.2868355610817532,
      "grad_norm": 0.17202848196029663,
      "learning_rate": 8.565822194591234e-06,
      "loss": 0.0419,
      "step": 3691
    },
    {
      "epoch": 0.2869132732359341,
      "grad_norm": 0.33300578594207764,
      "learning_rate": 8.56543363382033e-06,
      "loss": 0.4151,
      "step": 3692
    },
    {
      "epoch": 0.286990985390115,
      "grad_norm": 0.19716903567314148,
      "learning_rate": 8.565045073049426e-06,
      "loss": 0.1642,
      "step": 3693
    },
    {
      "epoch": 0.2870686975442959,
      "grad_norm": 0.05868232995271683,
      "learning_rate": 8.56465651227852e-06,
      "loss": 0.0212,
      "step": 3694
    },
    {
      "epoch": 0.2871464096984768,
      "grad_norm": 0.5319008231163025,
      "learning_rate": 8.564267951507617e-06,
      "loss": 0.6262,
      "step": 3695
    },
    {
      "epoch": 0.2872241218526578,
      "grad_norm": 0.1426212042570114,
      "learning_rate": 8.563879390736712e-06,
      "loss": 0.0407,
      "step": 3696
    },
    {
      "epoch": 0.2873018340068387,
      "grad_norm": 0.22575531899929047,
      "learning_rate": 8.563490829965807e-06,
      "loss": 0.0611,
      "step": 3697
    },
    {
      "epoch": 0.2873795461610196,
      "grad_norm": 0.9744616150856018,
      "learning_rate": 8.563102269194902e-06,
      "loss": 0.2536,
      "step": 3698
    },
    {
      "epoch": 0.28745725831520047,
      "grad_norm": 0.14842762053012848,
      "learning_rate": 8.562713708423999e-06,
      "loss": 0.0518,
      "step": 3699
    },
    {
      "epoch": 0.2875349704693814,
      "grad_norm": 0.34890878200531006,
      "learning_rate": 8.562325147653094e-06,
      "loss": 0.2203,
      "step": 3700
    },
    {
      "epoch": 0.2876126826235623,
      "grad_norm": 0.2642963230609894,
      "learning_rate": 8.561936586882189e-06,
      "loss": 0.2856,
      "step": 3701
    },
    {
      "epoch": 0.2876903947777432,
      "grad_norm": 0.15136757493019104,
      "learning_rate": 8.561548026111285e-06,
      "loss": 0.0781,
      "step": 3702
    },
    {
      "epoch": 0.2877681069319242,
      "grad_norm": 1.176329493522644,
      "learning_rate": 8.56115946534038e-06,
      "loss": 0.367,
      "step": 3703
    },
    {
      "epoch": 0.28784581908610507,
      "grad_norm": 0.6583357453346252,
      "learning_rate": 8.560770904569475e-06,
      "loss": 0.5401,
      "step": 3704
    },
    {
      "epoch": 0.28792353124028597,
      "grad_norm": 0.21801050007343292,
      "learning_rate": 8.560382343798572e-06,
      "loss": 0.066,
      "step": 3705
    },
    {
      "epoch": 0.2880012433944669,
      "grad_norm": 0.26311373710632324,
      "learning_rate": 8.559993783027665e-06,
      "loss": 0.1391,
      "step": 3706
    },
    {
      "epoch": 0.2880789555486478,
      "grad_norm": 0.30086833238601685,
      "learning_rate": 8.559605222256762e-06,
      "loss": 0.0759,
      "step": 3707
    },
    {
      "epoch": 0.2881566677028287,
      "grad_norm": 0.20507478713989258,
      "learning_rate": 8.559216661485857e-06,
      "loss": 0.0889,
      "step": 3708
    },
    {
      "epoch": 0.2882343798570096,
      "grad_norm": 0.3126210570335388,
      "learning_rate": 8.558828100714952e-06,
      "loss": 0.2557,
      "step": 3709
    },
    {
      "epoch": 0.28831209201119057,
      "grad_norm": 0.2733933627605438,
      "learning_rate": 8.558439539944048e-06,
      "loss": 0.1924,
      "step": 3710
    },
    {
      "epoch": 0.28838980416537147,
      "grad_norm": 0.27666983008384705,
      "learning_rate": 8.558050979173143e-06,
      "loss": 0.1376,
      "step": 3711
    },
    {
      "epoch": 0.28846751631955236,
      "grad_norm": 0.25921013951301575,
      "learning_rate": 8.557662418402238e-06,
      "loss": 0.7134,
      "step": 3712
    },
    {
      "epoch": 0.2885452284737333,
      "grad_norm": 0.19319739937782288,
      "learning_rate": 8.557273857631335e-06,
      "loss": 0.1364,
      "step": 3713
    },
    {
      "epoch": 0.2886229406279142,
      "grad_norm": 0.28188326954841614,
      "learning_rate": 8.55688529686043e-06,
      "loss": 0.1981,
      "step": 3714
    },
    {
      "epoch": 0.2887006527820951,
      "grad_norm": 0.24090509116649628,
      "learning_rate": 8.556496736089525e-06,
      "loss": 0.1749,
      "step": 3715
    },
    {
      "epoch": 0.288778364936276,
      "grad_norm": 0.08462836593389511,
      "learning_rate": 8.55610817531862e-06,
      "loss": 0.0116,
      "step": 3716
    },
    {
      "epoch": 0.28885607709045696,
      "grad_norm": 0.33345210552215576,
      "learning_rate": 8.555719614547716e-06,
      "loss": 0.2254,
      "step": 3717
    },
    {
      "epoch": 0.28893378924463786,
      "grad_norm": 0.29943323135375977,
      "learning_rate": 8.555331053776811e-06,
      "loss": 0.2419,
      "step": 3718
    },
    {
      "epoch": 0.28901150139881876,
      "grad_norm": 0.28433990478515625,
      "learning_rate": 8.554942493005906e-06,
      "loss": 0.0921,
      "step": 3719
    },
    {
      "epoch": 0.2890892135529997,
      "grad_norm": 0.07851436734199524,
      "learning_rate": 8.554553932235003e-06,
      "loss": 0.0233,
      "step": 3720
    },
    {
      "epoch": 0.2891669257071806,
      "grad_norm": 0.1476336568593979,
      "learning_rate": 8.554165371464098e-06,
      "loss": 0.0804,
      "step": 3721
    },
    {
      "epoch": 0.2892446378613615,
      "grad_norm": 0.31539463996887207,
      "learning_rate": 8.553776810693193e-06,
      "loss": 0.083,
      "step": 3722
    },
    {
      "epoch": 0.2893223500155424,
      "grad_norm": 0.30166396498680115,
      "learning_rate": 8.55338824992229e-06,
      "loss": 0.2087,
      "step": 3723
    },
    {
      "epoch": 0.28940006216972336,
      "grad_norm": 0.28415048122406006,
      "learning_rate": 8.552999689151384e-06,
      "loss": 0.1003,
      "step": 3724
    },
    {
      "epoch": 0.28947777432390426,
      "grad_norm": 0.1478031873703003,
      "learning_rate": 8.55261112838048e-06,
      "loss": 0.0838,
      "step": 3725
    },
    {
      "epoch": 0.28955548647808516,
      "grad_norm": 0.18135616183280945,
      "learning_rate": 8.552222567609574e-06,
      "loss": 0.0127,
      "step": 3726
    },
    {
      "epoch": 0.2896331986322661,
      "grad_norm": 0.08370565623044968,
      "learning_rate": 8.551834006838671e-06,
      "loss": 0.0367,
      "step": 3727
    },
    {
      "epoch": 0.289710910786447,
      "grad_norm": 0.10584884881973267,
      "learning_rate": 8.551445446067766e-06,
      "loss": 0.0383,
      "step": 3728
    },
    {
      "epoch": 0.2897886229406279,
      "grad_norm": 0.3157038688659668,
      "learning_rate": 8.551056885296861e-06,
      "loss": 0.1147,
      "step": 3729
    },
    {
      "epoch": 0.2898663350948088,
      "grad_norm": 0.22773411870002747,
      "learning_rate": 8.550668324525957e-06,
      "loss": 0.0813,
      "step": 3730
    },
    {
      "epoch": 0.28994404724898976,
      "grad_norm": 0.1958082914352417,
      "learning_rate": 8.550279763755052e-06,
      "loss": 0.0484,
      "step": 3731
    },
    {
      "epoch": 0.29002175940317065,
      "grad_norm": 0.6101073026657104,
      "learning_rate": 8.549891202984147e-06,
      "loss": 0.1959,
      "step": 3732
    },
    {
      "epoch": 0.29009947155735155,
      "grad_norm": 0.21766842901706696,
      "learning_rate": 8.549502642213244e-06,
      "loss": 0.0856,
      "step": 3733
    },
    {
      "epoch": 0.2901771837115325,
      "grad_norm": 0.4242600202560425,
      "learning_rate": 8.549114081442337e-06,
      "loss": 0.2747,
      "step": 3734
    },
    {
      "epoch": 0.2902548958657134,
      "grad_norm": 0.016165224835276604,
      "learning_rate": 8.548725520671434e-06,
      "loss": 0.0029,
      "step": 3735
    },
    {
      "epoch": 0.2903326080198943,
      "grad_norm": 0.19358421862125397,
      "learning_rate": 8.548336959900529e-06,
      "loss": 0.105,
      "step": 3736
    },
    {
      "epoch": 0.2904103201740752,
      "grad_norm": 0.32012853026390076,
      "learning_rate": 8.547948399129624e-06,
      "loss": 0.0963,
      "step": 3737
    },
    {
      "epoch": 0.29048803232825615,
      "grad_norm": 0.12355316430330276,
      "learning_rate": 8.54755983835872e-06,
      "loss": 0.0556,
      "step": 3738
    },
    {
      "epoch": 0.29056574448243705,
      "grad_norm": 0.2744108736515045,
      "learning_rate": 8.547171277587815e-06,
      "loss": 0.0727,
      "step": 3739
    },
    {
      "epoch": 0.29064345663661795,
      "grad_norm": 0.5616836547851562,
      "learning_rate": 8.54678271681691e-06,
      "loss": 0.1289,
      "step": 3740
    },
    {
      "epoch": 0.2907211687907989,
      "grad_norm": 0.21761205792427063,
      "learning_rate": 8.546394156046007e-06,
      "loss": 0.0784,
      "step": 3741
    },
    {
      "epoch": 0.2907988809449798,
      "grad_norm": 0.7878205180168152,
      "learning_rate": 8.546005595275102e-06,
      "loss": 0.3818,
      "step": 3742
    },
    {
      "epoch": 0.2908765930991607,
      "grad_norm": 0.4570225775241852,
      "learning_rate": 8.545617034504197e-06,
      "loss": 0.6435,
      "step": 3743
    },
    {
      "epoch": 0.29095430525334165,
      "grad_norm": 0.27880558371543884,
      "learning_rate": 8.545228473733292e-06,
      "loss": 0.1319,
      "step": 3744
    },
    {
      "epoch": 0.29103201740752255,
      "grad_norm": 0.05401545390486717,
      "learning_rate": 8.544839912962389e-06,
      "loss": 0.0287,
      "step": 3745
    },
    {
      "epoch": 0.29110972956170345,
      "grad_norm": 0.4107643663883209,
      "learning_rate": 8.544451352191483e-06,
      "loss": 0.2528,
      "step": 3746
    },
    {
      "epoch": 0.29118744171588434,
      "grad_norm": 0.27611488103866577,
      "learning_rate": 8.544062791420578e-06,
      "loss": 0.1338,
      "step": 3747
    },
    {
      "epoch": 0.2912651538700653,
      "grad_norm": 0.09858786314725876,
      "learning_rate": 8.543674230649675e-06,
      "loss": 0.0604,
      "step": 3748
    },
    {
      "epoch": 0.2913428660242462,
      "grad_norm": 0.3605402112007141,
      "learning_rate": 8.54328566987877e-06,
      "loss": 0.1695,
      "step": 3749
    },
    {
      "epoch": 0.2914205781784271,
      "grad_norm": 0.15223126113414764,
      "learning_rate": 8.542897109107865e-06,
      "loss": 0.0785,
      "step": 3750
    },
    {
      "epoch": 0.29149829033260805,
      "grad_norm": 1.1225930452346802,
      "learning_rate": 8.54250854833696e-06,
      "loss": 0.7847,
      "step": 3751
    },
    {
      "epoch": 0.29157600248678894,
      "grad_norm": 0.8533692359924316,
      "learning_rate": 8.542119987566057e-06,
      "loss": 0.2908,
      "step": 3752
    },
    {
      "epoch": 0.29165371464096984,
      "grad_norm": 0.360083669424057,
      "learning_rate": 8.541731426795152e-06,
      "loss": 0.1746,
      "step": 3753
    },
    {
      "epoch": 0.29173142679515074,
      "grad_norm": 0.0668138861656189,
      "learning_rate": 8.541342866024246e-06,
      "loss": 0.0656,
      "step": 3754
    },
    {
      "epoch": 0.2918091389493317,
      "grad_norm": 0.4315973222255707,
      "learning_rate": 8.540954305253343e-06,
      "loss": 0.0731,
      "step": 3755
    },
    {
      "epoch": 0.2918868511035126,
      "grad_norm": 0.22355544567108154,
      "learning_rate": 8.540565744482438e-06,
      "loss": 0.1005,
      "step": 3756
    },
    {
      "epoch": 0.2919645632576935,
      "grad_norm": 0.05127790570259094,
      "learning_rate": 8.540177183711533e-06,
      "loss": 0.0174,
      "step": 3757
    },
    {
      "epoch": 0.29204227541187444,
      "grad_norm": 0.16710595786571503,
      "learning_rate": 8.53978862294063e-06,
      "loss": 0.0867,
      "step": 3758
    },
    {
      "epoch": 0.29211998756605534,
      "grad_norm": 0.3496634364128113,
      "learning_rate": 8.539400062169723e-06,
      "loss": 0.1567,
      "step": 3759
    },
    {
      "epoch": 0.29219769972023624,
      "grad_norm": 0.4176861643791199,
      "learning_rate": 8.53901150139882e-06,
      "loss": 0.334,
      "step": 3760
    },
    {
      "epoch": 0.29227541187441713,
      "grad_norm": 0.3887861967086792,
      "learning_rate": 8.538622940627914e-06,
      "loss": 0.3259,
      "step": 3761
    },
    {
      "epoch": 0.2923531240285981,
      "grad_norm": 0.22268228232860565,
      "learning_rate": 8.53823437985701e-06,
      "loss": 0.0305,
      "step": 3762
    },
    {
      "epoch": 0.292430836182779,
      "grad_norm": 0.2600523829460144,
      "learning_rate": 8.537845819086106e-06,
      "loss": 0.1292,
      "step": 3763
    },
    {
      "epoch": 0.2925085483369599,
      "grad_norm": 0.3196745216846466,
      "learning_rate": 8.537457258315201e-06,
      "loss": 0.344,
      "step": 3764
    },
    {
      "epoch": 0.29258626049114084,
      "grad_norm": 0.09568420052528381,
      "learning_rate": 8.537068697544296e-06,
      "loss": 0.0201,
      "step": 3765
    },
    {
      "epoch": 0.29266397264532173,
      "grad_norm": 0.10207362473011017,
      "learning_rate": 8.536680136773393e-06,
      "loss": 0.0684,
      "step": 3766
    },
    {
      "epoch": 0.29274168479950263,
      "grad_norm": 0.431855171918869,
      "learning_rate": 8.536291576002488e-06,
      "loss": 0.2538,
      "step": 3767
    },
    {
      "epoch": 0.29281939695368353,
      "grad_norm": 0.5686521530151367,
      "learning_rate": 8.535903015231583e-06,
      "loss": 0.787,
      "step": 3768
    },
    {
      "epoch": 0.2928971091078645,
      "grad_norm": 0.4614606201648712,
      "learning_rate": 8.535514454460677e-06,
      "loss": 0.3087,
      "step": 3769
    },
    {
      "epoch": 0.2929748212620454,
      "grad_norm": 0.26890119910240173,
      "learning_rate": 8.535125893689774e-06,
      "loss": 0.2438,
      "step": 3770
    },
    {
      "epoch": 0.2930525334162263,
      "grad_norm": 0.6303085684776306,
      "learning_rate": 8.534737332918869e-06,
      "loss": 1.0145,
      "step": 3771
    },
    {
      "epoch": 0.29313024557040723,
      "grad_norm": 0.34641197323799133,
      "learning_rate": 8.534348772147964e-06,
      "loss": 0.1916,
      "step": 3772
    },
    {
      "epoch": 0.29320795772458813,
      "grad_norm": 0.4775988757610321,
      "learning_rate": 8.53396021137706e-06,
      "loss": 0.1784,
      "step": 3773
    },
    {
      "epoch": 0.29328566987876903,
      "grad_norm": 0.07124573737382889,
      "learning_rate": 8.533571650606156e-06,
      "loss": 0.0214,
      "step": 3774
    },
    {
      "epoch": 0.2933633820329499,
      "grad_norm": 0.42739537358283997,
      "learning_rate": 8.53318308983525e-06,
      "loss": 0.2174,
      "step": 3775
    },
    {
      "epoch": 0.2934410941871309,
      "grad_norm": 0.17704765498638153,
      "learning_rate": 8.532794529064347e-06,
      "loss": 0.0422,
      "step": 3776
    },
    {
      "epoch": 0.2935188063413118,
      "grad_norm": 0.4890235364437103,
      "learning_rate": 8.53240596829344e-06,
      "loss": 0.7071,
      "step": 3777
    },
    {
      "epoch": 0.2935965184954927,
      "grad_norm": 0.24432560801506042,
      "learning_rate": 8.532017407522537e-06,
      "loss": 0.2087,
      "step": 3778
    },
    {
      "epoch": 0.29367423064967363,
      "grad_norm": 0.23875249922275543,
      "learning_rate": 8.531628846751632e-06,
      "loss": 0.4169,
      "step": 3779
    },
    {
      "epoch": 0.2937519428038545,
      "grad_norm": 0.24589556455612183,
      "learning_rate": 8.531240285980729e-06,
      "loss": 0.1001,
      "step": 3780
    },
    {
      "epoch": 0.2938296549580354,
      "grad_norm": 0.1354103833436966,
      "learning_rate": 8.530851725209824e-06,
      "loss": 0.0978,
      "step": 3781
    },
    {
      "epoch": 0.2939073671122164,
      "grad_norm": 0.2247384935617447,
      "learning_rate": 8.530463164438919e-06,
      "loss": 0.0971,
      "step": 3782
    },
    {
      "epoch": 0.2939850792663973,
      "grad_norm": 0.6005281209945679,
      "learning_rate": 8.530074603668015e-06,
      "loss": 0.133,
      "step": 3783
    },
    {
      "epoch": 0.2940627914205782,
      "grad_norm": 0.3467089831829071,
      "learning_rate": 8.52968604289711e-06,
      "loss": 0.2724,
      "step": 3784
    },
    {
      "epoch": 0.29414050357475907,
      "grad_norm": 0.22918789088726044,
      "learning_rate": 8.529297482126205e-06,
      "loss": 0.2295,
      "step": 3785
    },
    {
      "epoch": 0.29421821572894,
      "grad_norm": 0.5500487089157104,
      "learning_rate": 8.528908921355302e-06,
      "loss": 0.1825,
      "step": 3786
    },
    {
      "epoch": 0.2942959278831209,
      "grad_norm": 0.234807550907135,
      "learning_rate": 8.528520360584395e-06,
      "loss": 0.0303,
      "step": 3787
    },
    {
      "epoch": 0.2943736400373018,
      "grad_norm": 0.04771874099969864,
      "learning_rate": 8.528131799813492e-06,
      "loss": 0.0101,
      "step": 3788
    },
    {
      "epoch": 0.2944513521914828,
      "grad_norm": 0.30416616797447205,
      "learning_rate": 8.527743239042587e-06,
      "loss": 0.0652,
      "step": 3789
    },
    {
      "epoch": 0.29452906434566367,
      "grad_norm": 0.8992725610733032,
      "learning_rate": 8.527354678271682e-06,
      "loss": 0.5196,
      "step": 3790
    },
    {
      "epoch": 0.29460677649984457,
      "grad_norm": 1.1048799753189087,
      "learning_rate": 8.526966117500778e-06,
      "loss": 0.3962,
      "step": 3791
    },
    {
      "epoch": 0.29468448865402547,
      "grad_norm": 0.5902193188667297,
      "learning_rate": 8.526577556729873e-06,
      "loss": 0.4821,
      "step": 3792
    },
    {
      "epoch": 0.2947622008082064,
      "grad_norm": 0.5525211691856384,
      "learning_rate": 8.526188995958968e-06,
      "loss": 1.0096,
      "step": 3793
    },
    {
      "epoch": 0.2948399129623873,
      "grad_norm": 0.13327693939208984,
      "learning_rate": 8.525800435188065e-06,
      "loss": 0.0574,
      "step": 3794
    },
    {
      "epoch": 0.2949176251165682,
      "grad_norm": 0.43531534075737,
      "learning_rate": 8.52541187441716e-06,
      "loss": 0.1906,
      "step": 3795
    },
    {
      "epoch": 0.29499533727074917,
      "grad_norm": 0.9554761052131653,
      "learning_rate": 8.525023313646255e-06,
      "loss": 1.143,
      "step": 3796
    },
    {
      "epoch": 0.29507304942493007,
      "grad_norm": 0.7003501057624817,
      "learning_rate": 8.52463475287535e-06,
      "loss": 0.2009,
      "step": 3797
    },
    {
      "epoch": 0.29515076157911097,
      "grad_norm": 0.36726856231689453,
      "learning_rate": 8.524246192104446e-06,
      "loss": 0.1802,
      "step": 3798
    },
    {
      "epoch": 0.29522847373329186,
      "grad_norm": 0.2585068643093109,
      "learning_rate": 8.523857631333541e-06,
      "loss": 0.1626,
      "step": 3799
    },
    {
      "epoch": 0.2953061858874728,
      "grad_norm": 0.2161870300769806,
      "learning_rate": 8.523469070562636e-06,
      "loss": 0.0762,
      "step": 3800
    },
    {
      "epoch": 0.2953838980416537,
      "grad_norm": 0.5750772953033447,
      "learning_rate": 8.523080509791733e-06,
      "loss": 0.2372,
      "step": 3801
    },
    {
      "epoch": 0.2954616101958346,
      "grad_norm": 0.6319131255149841,
      "learning_rate": 8.522691949020828e-06,
      "loss": 0.3363,
      "step": 3802
    },
    {
      "epoch": 0.29553932235001557,
      "grad_norm": 0.8614090085029602,
      "learning_rate": 8.522303388249923e-06,
      "loss": 0.2754,
      "step": 3803
    },
    {
      "epoch": 0.29561703450419646,
      "grad_norm": 0.2259119153022766,
      "learning_rate": 8.52191482747902e-06,
      "loss": 0.0793,
      "step": 3804
    },
    {
      "epoch": 0.29569474665837736,
      "grad_norm": 0.2716376483440399,
      "learning_rate": 8.521526266708113e-06,
      "loss": 0.3376,
      "step": 3805
    },
    {
      "epoch": 0.29577245881255826,
      "grad_norm": 0.35760900378227234,
      "learning_rate": 8.52113770593721e-06,
      "loss": 0.376,
      "step": 3806
    },
    {
      "epoch": 0.2958501709667392,
      "grad_norm": 0.1840854287147522,
      "learning_rate": 8.520749145166304e-06,
      "loss": 0.0818,
      "step": 3807
    },
    {
      "epoch": 0.2959278831209201,
      "grad_norm": 0.20165744423866272,
      "learning_rate": 8.5203605843954e-06,
      "loss": 0.0769,
      "step": 3808
    },
    {
      "epoch": 0.296005595275101,
      "grad_norm": 0.16867315769195557,
      "learning_rate": 8.519972023624496e-06,
      "loss": 0.0491,
      "step": 3809
    },
    {
      "epoch": 0.29608330742928196,
      "grad_norm": 0.19892899692058563,
      "learning_rate": 8.51958346285359e-06,
      "loss": 0.1307,
      "step": 3810
    },
    {
      "epoch": 0.29616101958346286,
      "grad_norm": 0.14966607093811035,
      "learning_rate": 8.519194902082687e-06,
      "loss": 0.0797,
      "step": 3811
    },
    {
      "epoch": 0.29623873173764376,
      "grad_norm": 0.1618364155292511,
      "learning_rate": 8.518806341311782e-06,
      "loss": 0.0946,
      "step": 3812
    },
    {
      "epoch": 0.29631644389182465,
      "grad_norm": 0.39628374576568604,
      "learning_rate": 8.518417780540877e-06,
      "loss": 0.2017,
      "step": 3813
    },
    {
      "epoch": 0.2963941560460056,
      "grad_norm": 0.40173229575157166,
      "learning_rate": 8.518029219769974e-06,
      "loss": 0.3946,
      "step": 3814
    },
    {
      "epoch": 0.2964718682001865,
      "grad_norm": 1.0199425220489502,
      "learning_rate": 8.517640658999067e-06,
      "loss": 0.3382,
      "step": 3815
    },
    {
      "epoch": 0.2965495803543674,
      "grad_norm": 0.2259185016155243,
      "learning_rate": 8.517252098228164e-06,
      "loss": 0.0543,
      "step": 3816
    },
    {
      "epoch": 0.29662729250854836,
      "grad_norm": 0.12842896580696106,
      "learning_rate": 8.516863537457259e-06,
      "loss": 0.0397,
      "step": 3817
    },
    {
      "epoch": 0.29670500466272925,
      "grad_norm": 0.31007814407348633,
      "learning_rate": 8.516474976686354e-06,
      "loss": 0.1412,
      "step": 3818
    },
    {
      "epoch": 0.29678271681691015,
      "grad_norm": 0.42372632026672363,
      "learning_rate": 8.51608641591545e-06,
      "loss": 0.1057,
      "step": 3819
    },
    {
      "epoch": 0.2968604289710911,
      "grad_norm": 0.44207751750946045,
      "learning_rate": 8.515697855144545e-06,
      "loss": 0.1483,
      "step": 3820
    },
    {
      "epoch": 0.296938141125272,
      "grad_norm": 0.4822026789188385,
      "learning_rate": 8.51530929437364e-06,
      "loss": 0.1217,
      "step": 3821
    },
    {
      "epoch": 0.2970158532794529,
      "grad_norm": 0.4541012644767761,
      "learning_rate": 8.514920733602737e-06,
      "loss": 0.1209,
      "step": 3822
    },
    {
      "epoch": 0.2970935654336338,
      "grad_norm": 0.34001511335372925,
      "learning_rate": 8.514532172831832e-06,
      "loss": 0.3639,
      "step": 3823
    },
    {
      "epoch": 0.29717127758781475,
      "grad_norm": 0.2477695792913437,
      "learning_rate": 8.514143612060927e-06,
      "loss": 0.123,
      "step": 3824
    },
    {
      "epoch": 0.29724898974199565,
      "grad_norm": 0.29619157314300537,
      "learning_rate": 8.513755051290022e-06,
      "loss": 0.2471,
      "step": 3825
    },
    {
      "epoch": 0.29732670189617655,
      "grad_norm": 0.42517775297164917,
      "learning_rate": 8.513366490519118e-06,
      "loss": 0.2494,
      "step": 3826
    },
    {
      "epoch": 0.2974044140503575,
      "grad_norm": 0.19097614288330078,
      "learning_rate": 8.512977929748213e-06,
      "loss": 0.1314,
      "step": 3827
    },
    {
      "epoch": 0.2974821262045384,
      "grad_norm": 0.2683967649936676,
      "learning_rate": 8.512589368977308e-06,
      "loss": 0.3196,
      "step": 3828
    },
    {
      "epoch": 0.2975598383587193,
      "grad_norm": 0.22507131099700928,
      "learning_rate": 8.512200808206405e-06,
      "loss": 0.1287,
      "step": 3829
    },
    {
      "epoch": 0.2976375505129002,
      "grad_norm": 0.24127943813800812,
      "learning_rate": 8.5118122474355e-06,
      "loss": 0.1361,
      "step": 3830
    },
    {
      "epoch": 0.29771526266708115,
      "grad_norm": 0.30990177392959595,
      "learning_rate": 8.511423686664595e-06,
      "loss": 0.161,
      "step": 3831
    },
    {
      "epoch": 0.29779297482126205,
      "grad_norm": 0.48272454738616943,
      "learning_rate": 8.511035125893692e-06,
      "loss": 0.2809,
      "step": 3832
    },
    {
      "epoch": 0.29787068697544294,
      "grad_norm": 0.2958794832229614,
      "learning_rate": 8.510646565122785e-06,
      "loss": 0.1595,
      "step": 3833
    },
    {
      "epoch": 0.2979483991296239,
      "grad_norm": 0.15933935344219208,
      "learning_rate": 8.510258004351881e-06,
      "loss": 0.1797,
      "step": 3834
    },
    {
      "epoch": 0.2980261112838048,
      "grad_norm": 0.3026715815067291,
      "learning_rate": 8.509869443580976e-06,
      "loss": 0.1809,
      "step": 3835
    },
    {
      "epoch": 0.2981038234379857,
      "grad_norm": 0.3484313189983368,
      "learning_rate": 8.509480882810071e-06,
      "loss": 0.2376,
      "step": 3836
    },
    {
      "epoch": 0.2981815355921666,
      "grad_norm": 0.19349674880504608,
      "learning_rate": 8.509092322039168e-06,
      "loss": 0.0829,
      "step": 3837
    },
    {
      "epoch": 0.29825924774634754,
      "grad_norm": 0.8265522122383118,
      "learning_rate": 8.508703761268263e-06,
      "loss": 0.1704,
      "step": 3838
    },
    {
      "epoch": 0.29833695990052844,
      "grad_norm": 0.1285928636789322,
      "learning_rate": 8.508315200497358e-06,
      "loss": 0.0483,
      "step": 3839
    },
    {
      "epoch": 0.29841467205470934,
      "grad_norm": 0.14965292811393738,
      "learning_rate": 8.507926639726454e-06,
      "loss": 0.0367,
      "step": 3840
    },
    {
      "epoch": 0.2984923842088903,
      "grad_norm": 0.4813317358493805,
      "learning_rate": 8.50753807895555e-06,
      "loss": 0.5166,
      "step": 3841
    },
    {
      "epoch": 0.2985700963630712,
      "grad_norm": 0.32235482335090637,
      "learning_rate": 8.507149518184646e-06,
      "loss": 0.2122,
      "step": 3842
    },
    {
      "epoch": 0.2986478085172521,
      "grad_norm": 0.3836624324321747,
      "learning_rate": 8.50676095741374e-06,
      "loss": 0.2532,
      "step": 3843
    },
    {
      "epoch": 0.298725520671433,
      "grad_norm": 0.1490897685289383,
      "learning_rate": 8.506372396642836e-06,
      "loss": 0.0408,
      "step": 3844
    },
    {
      "epoch": 0.29880323282561394,
      "grad_norm": 0.5645236968994141,
      "learning_rate": 8.505983835871931e-06,
      "loss": 0.2821,
      "step": 3845
    },
    {
      "epoch": 0.29888094497979484,
      "grad_norm": 0.18741914629936218,
      "learning_rate": 8.505595275101026e-06,
      "loss": 0.0305,
      "step": 3846
    },
    {
      "epoch": 0.29895865713397574,
      "grad_norm": 0.15131357312202454,
      "learning_rate": 8.505206714330123e-06,
      "loss": 0.0341,
      "step": 3847
    },
    {
      "epoch": 0.2990363692881567,
      "grad_norm": 0.03994891047477722,
      "learning_rate": 8.504818153559217e-06,
      "loss": 0.0121,
      "step": 3848
    },
    {
      "epoch": 0.2991140814423376,
      "grad_norm": 0.1114325299859047,
      "learning_rate": 8.504429592788312e-06,
      "loss": 0.0301,
      "step": 3849
    },
    {
      "epoch": 0.2991917935965185,
      "grad_norm": 0.15944266319274902,
      "learning_rate": 8.504041032017409e-06,
      "loss": 0.1084,
      "step": 3850
    },
    {
      "epoch": 0.2992695057506994,
      "grad_norm": 0.49763166904449463,
      "learning_rate": 8.503652471246504e-06,
      "loss": 0.424,
      "step": 3851
    },
    {
      "epoch": 0.29934721790488034,
      "grad_norm": 0.3097277581691742,
      "learning_rate": 8.503263910475599e-06,
      "loss": 0.174,
      "step": 3852
    },
    {
      "epoch": 0.29942493005906123,
      "grad_norm": 0.14632083475589752,
      "learning_rate": 8.502875349704694e-06,
      "loss": 0.0885,
      "step": 3853
    },
    {
      "epoch": 0.29950264221324213,
      "grad_norm": 0.24825800955295563,
      "learning_rate": 8.50248678893379e-06,
      "loss": 0.0864,
      "step": 3854
    },
    {
      "epoch": 0.2995803543674231,
      "grad_norm": 0.14150471985340118,
      "learning_rate": 8.502098228162886e-06,
      "loss": 0.0758,
      "step": 3855
    },
    {
      "epoch": 0.299658066521604,
      "grad_norm": 0.7796023488044739,
      "learning_rate": 8.50170966739198e-06,
      "loss": 0.3367,
      "step": 3856
    },
    {
      "epoch": 0.2997357786757849,
      "grad_norm": 0.5282775163650513,
      "learning_rate": 8.501321106621077e-06,
      "loss": 0.2524,
      "step": 3857
    },
    {
      "epoch": 0.29981349082996583,
      "grad_norm": 0.4436013102531433,
      "learning_rate": 8.500932545850172e-06,
      "loss": 0.195,
      "step": 3858
    },
    {
      "epoch": 0.29989120298414673,
      "grad_norm": 0.08313753455877304,
      "learning_rate": 8.500543985079267e-06,
      "loss": 0.0484,
      "step": 3859
    },
    {
      "epoch": 0.29996891513832763,
      "grad_norm": 0.5642619729042053,
      "learning_rate": 8.500155424308364e-06,
      "loss": 0.1774,
      "step": 3860
    },
    {
      "epoch": 0.3000466272925085,
      "grad_norm": 0.04888792335987091,
      "learning_rate": 8.499766863537457e-06,
      "loss": 0.012,
      "step": 3861
    },
    {
      "epoch": 0.3001243394466895,
      "grad_norm": 0.4752972722053528,
      "learning_rate": 8.499378302766554e-06,
      "loss": 0.2068,
      "step": 3862
    },
    {
      "epoch": 0.3002020516008704,
      "grad_norm": 0.08578724414110184,
      "learning_rate": 8.498989741995648e-06,
      "loss": 0.0208,
      "step": 3863
    },
    {
      "epoch": 0.3002797637550513,
      "grad_norm": 0.12495999038219452,
      "learning_rate": 8.498601181224743e-06,
      "loss": 0.0589,
      "step": 3864
    },
    {
      "epoch": 0.30035747590923223,
      "grad_norm": 0.3535212278366089,
      "learning_rate": 8.49821262045384e-06,
      "loss": 0.286,
      "step": 3865
    },
    {
      "epoch": 0.30043518806341313,
      "grad_norm": 0.2898671627044678,
      "learning_rate": 8.497824059682935e-06,
      "loss": 0.0542,
      "step": 3866
    },
    {
      "epoch": 0.300512900217594,
      "grad_norm": 1.0619792938232422,
      "learning_rate": 8.49743549891203e-06,
      "loss": 0.1812,
      "step": 3867
    },
    {
      "epoch": 0.3005906123717749,
      "grad_norm": 0.23930934071540833,
      "learning_rate": 8.497046938141127e-06,
      "loss": 0.1851,
      "step": 3868
    },
    {
      "epoch": 0.3006683245259559,
      "grad_norm": 0.3236173689365387,
      "learning_rate": 8.496658377370222e-06,
      "loss": 0.1436,
      "step": 3869
    },
    {
      "epoch": 0.3007460366801368,
      "grad_norm": 0.5315862894058228,
      "learning_rate": 8.496269816599317e-06,
      "loss": 0.7691,
      "step": 3870
    },
    {
      "epoch": 0.3008237488343177,
      "grad_norm": 0.22066695988178253,
      "learning_rate": 8.495881255828411e-06,
      "loss": 0.0453,
      "step": 3871
    },
    {
      "epoch": 0.3009014609884986,
      "grad_norm": 0.28014060854911804,
      "learning_rate": 8.495492695057508e-06,
      "loss": 0.0219,
      "step": 3872
    },
    {
      "epoch": 0.3009791731426795,
      "grad_norm": 0.34854692220687866,
      "learning_rate": 8.495104134286603e-06,
      "loss": 0.1395,
      "step": 3873
    },
    {
      "epoch": 0.3010568852968604,
      "grad_norm": 0.17121157050132751,
      "learning_rate": 8.494715573515698e-06,
      "loss": 0.1106,
      "step": 3874
    },
    {
      "epoch": 0.3011345974510413,
      "grad_norm": 0.1864742636680603,
      "learning_rate": 8.494327012744795e-06,
      "loss": 0.08,
      "step": 3875
    },
    {
      "epoch": 0.3012123096052223,
      "grad_norm": 0.9385573267936707,
      "learning_rate": 8.49393845197389e-06,
      "loss": 0.4221,
      "step": 3876
    },
    {
      "epoch": 0.30129002175940317,
      "grad_norm": 0.10767760127782822,
      "learning_rate": 8.493549891202985e-06,
      "loss": 0.0361,
      "step": 3877
    },
    {
      "epoch": 0.30136773391358407,
      "grad_norm": 0.1713273823261261,
      "learning_rate": 8.49316133043208e-06,
      "loss": 0.1082,
      "step": 3878
    },
    {
      "epoch": 0.301445446067765,
      "grad_norm": 0.26329952478408813,
      "learning_rate": 8.492772769661176e-06,
      "loss": 0.1736,
      "step": 3879
    },
    {
      "epoch": 0.3015231582219459,
      "grad_norm": 0.3236745297908783,
      "learning_rate": 8.492384208890271e-06,
      "loss": 0.3168,
      "step": 3880
    },
    {
      "epoch": 0.3016008703761268,
      "grad_norm": 0.5629767179489136,
      "learning_rate": 8.491995648119366e-06,
      "loss": 0.802,
      "step": 3881
    },
    {
      "epoch": 0.3016785825303077,
      "grad_norm": 0.24784046411514282,
      "learning_rate": 8.491607087348463e-06,
      "loss": 0.0377,
      "step": 3882
    },
    {
      "epoch": 0.30175629468448867,
      "grad_norm": 0.8173538446426392,
      "learning_rate": 8.491218526577558e-06,
      "loss": 0.1328,
      "step": 3883
    },
    {
      "epoch": 0.30183400683866957,
      "grad_norm": 0.24401740729808807,
      "learning_rate": 8.490829965806653e-06,
      "loss": 0.0627,
      "step": 3884
    },
    {
      "epoch": 0.30191171899285046,
      "grad_norm": 0.35153481364250183,
      "learning_rate": 8.49044140503575e-06,
      "loss": 0.0697,
      "step": 3885
    },
    {
      "epoch": 0.3019894311470314,
      "grad_norm": 0.3505316972732544,
      "learning_rate": 8.490052844264843e-06,
      "loss": 0.0888,
      "step": 3886
    },
    {
      "epoch": 0.3020671433012123,
      "grad_norm": 0.28954023122787476,
      "learning_rate": 8.489664283493939e-06,
      "loss": 0.2049,
      "step": 3887
    },
    {
      "epoch": 0.3021448554553932,
      "grad_norm": 0.21111775934696198,
      "learning_rate": 8.489275722723034e-06,
      "loss": 0.3207,
      "step": 3888
    },
    {
      "epoch": 0.3022225676095741,
      "grad_norm": 0.9034615755081177,
      "learning_rate": 8.488887161952129e-06,
      "loss": 0.6076,
      "step": 3889
    },
    {
      "epoch": 0.30230027976375506,
      "grad_norm": 0.07614974677562714,
      "learning_rate": 8.488498601181226e-06,
      "loss": 0.0147,
      "step": 3890
    },
    {
      "epoch": 0.30237799191793596,
      "grad_norm": 0.07952519506216049,
      "learning_rate": 8.48811004041032e-06,
      "loss": 0.0271,
      "step": 3891
    },
    {
      "epoch": 0.30245570407211686,
      "grad_norm": 1.491833209991455,
      "learning_rate": 8.487721479639416e-06,
      "loss": 0.5647,
      "step": 3892
    },
    {
      "epoch": 0.3025334162262978,
      "grad_norm": 0.1827460527420044,
      "learning_rate": 8.487332918868512e-06,
      "loss": 0.0339,
      "step": 3893
    },
    {
      "epoch": 0.3026111283804787,
      "grad_norm": 0.4417284429073334,
      "learning_rate": 8.486944358097607e-06,
      "loss": 0.1754,
      "step": 3894
    },
    {
      "epoch": 0.3026888405346596,
      "grad_norm": 0.19206267595291138,
      "learning_rate": 8.486555797326702e-06,
      "loss": 0.0881,
      "step": 3895
    },
    {
      "epoch": 0.30276655268884056,
      "grad_norm": 0.233834907412529,
      "learning_rate": 8.486167236555797e-06,
      "loss": 0.0582,
      "step": 3896
    },
    {
      "epoch": 0.30284426484302146,
      "grad_norm": 0.855829119682312,
      "learning_rate": 8.485778675784894e-06,
      "loss": 0.1,
      "step": 3897
    },
    {
      "epoch": 0.30292197699720236,
      "grad_norm": 0.2336421012878418,
      "learning_rate": 8.485390115013989e-06,
      "loss": 0.1044,
      "step": 3898
    },
    {
      "epoch": 0.30299968915138326,
      "grad_norm": 0.3473040759563446,
      "learning_rate": 8.485001554243084e-06,
      "loss": 0.0863,
      "step": 3899
    },
    {
      "epoch": 0.3030774013055642,
      "grad_norm": 0.013565530069172382,
      "learning_rate": 8.48461299347218e-06,
      "loss": 0.002,
      "step": 3900
    },
    {
      "epoch": 0.3031551134597451,
      "grad_norm": 0.45927438139915466,
      "learning_rate": 8.484224432701275e-06,
      "loss": 0.4208,
      "step": 3901
    },
    {
      "epoch": 0.303232825613926,
      "grad_norm": 0.8934043049812317,
      "learning_rate": 8.48383587193037e-06,
      "loss": 0.3387,
      "step": 3902
    },
    {
      "epoch": 0.30331053776810696,
      "grad_norm": 0.2767360508441925,
      "learning_rate": 8.483447311159467e-06,
      "loss": 0.1491,
      "step": 3903
    },
    {
      "epoch": 0.30338824992228786,
      "grad_norm": 0.2740464210510254,
      "learning_rate": 8.483058750388562e-06,
      "loss": 0.3395,
      "step": 3904
    },
    {
      "epoch": 0.30346596207646875,
      "grad_norm": 0.37110283970832825,
      "learning_rate": 8.482670189617657e-06,
      "loss": 0.2726,
      "step": 3905
    },
    {
      "epoch": 0.30354367423064965,
      "grad_norm": 1.0472443103790283,
      "learning_rate": 8.482281628846752e-06,
      "loss": 0.2093,
      "step": 3906
    },
    {
      "epoch": 0.3036213863848306,
      "grad_norm": 0.16963191330432892,
      "learning_rate": 8.481893068075848e-06,
      "loss": 0.1227,
      "step": 3907
    },
    {
      "epoch": 0.3036990985390115,
      "grad_norm": 0.15324273705482483,
      "learning_rate": 8.481504507304943e-06,
      "loss": 0.0706,
      "step": 3908
    },
    {
      "epoch": 0.3037768106931924,
      "grad_norm": 0.44324856996536255,
      "learning_rate": 8.481115946534038e-06,
      "loss": 0.0873,
      "step": 3909
    },
    {
      "epoch": 0.30385452284737335,
      "grad_norm": 0.14271748065948486,
      "learning_rate": 8.480727385763135e-06,
      "loss": 0.016,
      "step": 3910
    },
    {
      "epoch": 0.30393223500155425,
      "grad_norm": 0.16581448912620544,
      "learning_rate": 8.48033882499223e-06,
      "loss": 0.2159,
      "step": 3911
    },
    {
      "epoch": 0.30400994715573515,
      "grad_norm": 0.24865224957466125,
      "learning_rate": 8.479950264221325e-06,
      "loss": 0.0378,
      "step": 3912
    },
    {
      "epoch": 0.30408765930991605,
      "grad_norm": 0.3128719627857208,
      "learning_rate": 8.479561703450421e-06,
      "loss": 0.1804,
      "step": 3913
    },
    {
      "epoch": 0.304165371464097,
      "grad_norm": 0.24041664600372314,
      "learning_rate": 8.479173142679515e-06,
      "loss": 0.1863,
      "step": 3914
    },
    {
      "epoch": 0.3042430836182779,
      "grad_norm": 0.7143844366073608,
      "learning_rate": 8.478784581908611e-06,
      "loss": 0.3578,
      "step": 3915
    },
    {
      "epoch": 0.3043207957724588,
      "grad_norm": 0.33261972665786743,
      "learning_rate": 8.478396021137706e-06,
      "loss": 0.1144,
      "step": 3916
    },
    {
      "epoch": 0.30439850792663975,
      "grad_norm": 0.7172540426254272,
      "learning_rate": 8.478007460366801e-06,
      "loss": 0.8411,
      "step": 3917
    },
    {
      "epoch": 0.30447622008082065,
      "grad_norm": 0.1480429321527481,
      "learning_rate": 8.477618899595898e-06,
      "loss": 0.0849,
      "step": 3918
    },
    {
      "epoch": 0.30455393223500155,
      "grad_norm": 0.9246009588241577,
      "learning_rate": 8.477230338824993e-06,
      "loss": 0.4954,
      "step": 3919
    },
    {
      "epoch": 0.30463164438918244,
      "grad_norm": 0.2959330081939697,
      "learning_rate": 8.476841778054088e-06,
      "loss": 0.2277,
      "step": 3920
    },
    {
      "epoch": 0.3047093565433634,
      "grad_norm": 0.14507004618644714,
      "learning_rate": 8.476453217283184e-06,
      "loss": 0.0694,
      "step": 3921
    },
    {
      "epoch": 0.3047870686975443,
      "grad_norm": 0.36422765254974365,
      "learning_rate": 8.47606465651228e-06,
      "loss": 0.3312,
      "step": 3922
    },
    {
      "epoch": 0.3048647808517252,
      "grad_norm": 0.4374304711818695,
      "learning_rate": 8.475676095741374e-06,
      "loss": 0.1625,
      "step": 3923
    },
    {
      "epoch": 0.30494249300590615,
      "grad_norm": 0.3288208544254303,
      "learning_rate": 8.47528753497047e-06,
      "loss": 0.2105,
      "step": 3924
    },
    {
      "epoch": 0.30502020516008704,
      "grad_norm": 0.344582736492157,
      "learning_rate": 8.474898974199566e-06,
      "loss": 0.1358,
      "step": 3925
    },
    {
      "epoch": 0.30509791731426794,
      "grad_norm": 0.1495305746793747,
      "learning_rate": 8.47451041342866e-06,
      "loss": 0.0628,
      "step": 3926
    },
    {
      "epoch": 0.30517562946844884,
      "grad_norm": 0.03487899899482727,
      "learning_rate": 8.474121852657756e-06,
      "loss": 0.0079,
      "step": 3927
    },
    {
      "epoch": 0.3052533416226298,
      "grad_norm": 0.9197744727134705,
      "learning_rate": 8.473733291886852e-06,
      "loss": 0.678,
      "step": 3928
    },
    {
      "epoch": 0.3053310537768107,
      "grad_norm": 0.13160832226276398,
      "learning_rate": 8.473344731115947e-06,
      "loss": 0.0604,
      "step": 3929
    },
    {
      "epoch": 0.3054087659309916,
      "grad_norm": 0.515997588634491,
      "learning_rate": 8.472956170345042e-06,
      "loss": 0.2778,
      "step": 3930
    },
    {
      "epoch": 0.30548647808517254,
      "grad_norm": 0.22064867615699768,
      "learning_rate": 8.472567609574139e-06,
      "loss": 0.0712,
      "step": 3931
    },
    {
      "epoch": 0.30556419023935344,
      "grad_norm": 0.34940940141677856,
      "learning_rate": 8.472179048803234e-06,
      "loss": 0.1495,
      "step": 3932
    },
    {
      "epoch": 0.30564190239353434,
      "grad_norm": 0.3534795939922333,
      "learning_rate": 8.471790488032329e-06,
      "loss": 0.1768,
      "step": 3933
    },
    {
      "epoch": 0.30571961454771523,
      "grad_norm": 0.3526681363582611,
      "learning_rate": 8.471401927261424e-06,
      "loss": 0.1069,
      "step": 3934
    },
    {
      "epoch": 0.3057973267018962,
      "grad_norm": 0.1807919591665268,
      "learning_rate": 8.47101336649052e-06,
      "loss": 0.05,
      "step": 3935
    },
    {
      "epoch": 0.3058750388560771,
      "grad_norm": 0.43769940733909607,
      "learning_rate": 8.470624805719615e-06,
      "loss": 0.2345,
      "step": 3936
    },
    {
      "epoch": 0.305952751010258,
      "grad_norm": 0.1363351047039032,
      "learning_rate": 8.47023624494871e-06,
      "loss": 0.0417,
      "step": 3937
    },
    {
      "epoch": 0.30603046316443894,
      "grad_norm": 0.5572249293327332,
      "learning_rate": 8.469847684177807e-06,
      "loss": 0.0509,
      "step": 3938
    },
    {
      "epoch": 0.30610817531861984,
      "grad_norm": 0.24631868302822113,
      "learning_rate": 8.469459123406902e-06,
      "loss": 0.1726,
      "step": 3939
    },
    {
      "epoch": 0.30618588747280073,
      "grad_norm": 0.33176708221435547,
      "learning_rate": 8.469070562635997e-06,
      "loss": 0.1899,
      "step": 3940
    },
    {
      "epoch": 0.3062635996269817,
      "grad_norm": 0.4970443546772003,
      "learning_rate": 8.468682001865094e-06,
      "loss": 0.6928,
      "step": 3941
    },
    {
      "epoch": 0.3063413117811626,
      "grad_norm": 0.08003878593444824,
      "learning_rate": 8.468293441094187e-06,
      "loss": 0.0419,
      "step": 3942
    },
    {
      "epoch": 0.3064190239353435,
      "grad_norm": 0.2264832854270935,
      "learning_rate": 8.467904880323283e-06,
      "loss": 0.1727,
      "step": 3943
    },
    {
      "epoch": 0.3064967360895244,
      "grad_norm": 0.1859905868768692,
      "learning_rate": 8.467516319552378e-06,
      "loss": 0.0314,
      "step": 3944
    },
    {
      "epoch": 0.30657444824370533,
      "grad_norm": 0.2360266000032425,
      "learning_rate": 8.467127758781473e-06,
      "loss": 0.1295,
      "step": 3945
    },
    {
      "epoch": 0.30665216039788623,
      "grad_norm": 0.5584412813186646,
      "learning_rate": 8.46673919801057e-06,
      "loss": 0.2315,
      "step": 3946
    },
    {
      "epoch": 0.30672987255206713,
      "grad_norm": 0.42251500487327576,
      "learning_rate": 8.466350637239665e-06,
      "loss": 0.2526,
      "step": 3947
    },
    {
      "epoch": 0.3068075847062481,
      "grad_norm": 0.6646386384963989,
      "learning_rate": 8.46596207646876e-06,
      "loss": 0.252,
      "step": 3948
    },
    {
      "epoch": 0.306885296860429,
      "grad_norm": 0.48680537939071655,
      "learning_rate": 8.465573515697857e-06,
      "loss": 0.1809,
      "step": 3949
    },
    {
      "epoch": 0.3069630090146099,
      "grad_norm": 0.37846508622169495,
      "learning_rate": 8.465184954926951e-06,
      "loss": 0.0759,
      "step": 3950
    },
    {
      "epoch": 0.3070407211687908,
      "grad_norm": 0.15253911912441254,
      "learning_rate": 8.464796394156046e-06,
      "loss": 0.0775,
      "step": 3951
    },
    {
      "epoch": 0.30711843332297173,
      "grad_norm": 0.28596267104148865,
      "learning_rate": 8.464407833385141e-06,
      "loss": 0.0959,
      "step": 3952
    },
    {
      "epoch": 0.3071961454771526,
      "grad_norm": 0.5273838043212891,
      "learning_rate": 8.464019272614238e-06,
      "loss": 0.4253,
      "step": 3953
    },
    {
      "epoch": 0.3072738576313335,
      "grad_norm": 0.16940590739250183,
      "learning_rate": 8.463630711843333e-06,
      "loss": 0.0263,
      "step": 3954
    },
    {
      "epoch": 0.3073515697855145,
      "grad_norm": 0.3442215919494629,
      "learning_rate": 8.463242151072428e-06,
      "loss": 0.1661,
      "step": 3955
    },
    {
      "epoch": 0.3074292819396954,
      "grad_norm": 0.5217562913894653,
      "learning_rate": 8.462853590301525e-06,
      "loss": 0.4288,
      "step": 3956
    },
    {
      "epoch": 0.3075069940938763,
      "grad_norm": 0.14205971360206604,
      "learning_rate": 8.46246502953062e-06,
      "loss": 0.061,
      "step": 3957
    },
    {
      "epoch": 0.30758470624805717,
      "grad_norm": 0.2582542896270752,
      "learning_rate": 8.462076468759714e-06,
      "loss": 0.0379,
      "step": 3958
    },
    {
      "epoch": 0.3076624184022381,
      "grad_norm": 0.2902573347091675,
      "learning_rate": 8.461687907988811e-06,
      "loss": 0.3653,
      "step": 3959
    },
    {
      "epoch": 0.307740130556419,
      "grad_norm": 0.5569120049476624,
      "learning_rate": 8.461299347217904e-06,
      "loss": 0.2526,
      "step": 3960
    },
    {
      "epoch": 0.3078178427105999,
      "grad_norm": 0.165651336312294,
      "learning_rate": 8.460910786447001e-06,
      "loss": 0.0922,
      "step": 3961
    },
    {
      "epoch": 0.3078955548647809,
      "grad_norm": 0.18701446056365967,
      "learning_rate": 8.460522225676096e-06,
      "loss": 0.1605,
      "step": 3962
    },
    {
      "epoch": 0.30797326701896177,
      "grad_norm": 0.2829475700855255,
      "learning_rate": 8.460133664905193e-06,
      "loss": 0.0998,
      "step": 3963
    },
    {
      "epoch": 0.30805097917314267,
      "grad_norm": 0.29736557602882385,
      "learning_rate": 8.459745104134288e-06,
      "loss": 0.1672,
      "step": 3964
    },
    {
      "epoch": 0.30812869132732357,
      "grad_norm": 0.12770558893680573,
      "learning_rate": 8.459356543363383e-06,
      "loss": 0.0897,
      "step": 3965
    },
    {
      "epoch": 0.3082064034815045,
      "grad_norm": 0.25155532360076904,
      "learning_rate": 8.458967982592479e-06,
      "loss": 0.0943,
      "step": 3966
    },
    {
      "epoch": 0.3082841156356854,
      "grad_norm": 0.43126535415649414,
      "learning_rate": 8.458579421821574e-06,
      "loss": 0.2703,
      "step": 3967
    },
    {
      "epoch": 0.3083618277898663,
      "grad_norm": 0.29325130581855774,
      "learning_rate": 8.458190861050669e-06,
      "loss": 0.0812,
      "step": 3968
    },
    {
      "epoch": 0.30843953994404727,
      "grad_norm": 0.12720324099063873,
      "learning_rate": 8.457802300279766e-06,
      "loss": 0.0473,
      "step": 3969
    },
    {
      "epoch": 0.30851725209822817,
      "grad_norm": 1.1916826963424683,
      "learning_rate": 8.457413739508859e-06,
      "loss": 0.1982,
      "step": 3970
    },
    {
      "epoch": 0.30859496425240907,
      "grad_norm": 0.11051654815673828,
      "learning_rate": 8.457025178737956e-06,
      "loss": 0.0299,
      "step": 3971
    },
    {
      "epoch": 0.30867267640658996,
      "grad_norm": 0.1444278210401535,
      "learning_rate": 8.45663661796705e-06,
      "loss": 0.0642,
      "step": 3972
    },
    {
      "epoch": 0.3087503885607709,
      "grad_norm": 0.19384020566940308,
      "learning_rate": 8.456248057196145e-06,
      "loss": 0.0756,
      "step": 3973
    },
    {
      "epoch": 0.3088281007149518,
      "grad_norm": 0.15433132648468018,
      "learning_rate": 8.455859496425242e-06,
      "loss": 0.0633,
      "step": 3974
    },
    {
      "epoch": 0.3089058128691327,
      "grad_norm": 0.2651699185371399,
      "learning_rate": 8.455470935654337e-06,
      "loss": 0.0813,
      "step": 3975
    },
    {
      "epoch": 0.30898352502331367,
      "grad_norm": 0.2777637243270874,
      "learning_rate": 8.455082374883432e-06,
      "loss": 0.1916,
      "step": 3976
    },
    {
      "epoch": 0.30906123717749456,
      "grad_norm": 0.38289883732795715,
      "learning_rate": 8.454693814112529e-06,
      "loss": 0.1292,
      "step": 3977
    },
    {
      "epoch": 0.30913894933167546,
      "grad_norm": 0.2652814984321594,
      "learning_rate": 8.454305253341624e-06,
      "loss": 0.3048,
      "step": 3978
    },
    {
      "epoch": 0.3092166614858564,
      "grad_norm": 0.17469219863414764,
      "learning_rate": 8.453916692570719e-06,
      "loss": 0.0677,
      "step": 3979
    },
    {
      "epoch": 0.3092943736400373,
      "grad_norm": 0.2981250584125519,
      "learning_rate": 8.453528131799814e-06,
      "loss": 0.0977,
      "step": 3980
    },
    {
      "epoch": 0.3093720857942182,
      "grad_norm": 0.10227912664413452,
      "learning_rate": 8.45313957102891e-06,
      "loss": 0.017,
      "step": 3981
    },
    {
      "epoch": 0.3094497979483991,
      "grad_norm": 0.2781471908092499,
      "learning_rate": 8.452751010258005e-06,
      "loss": 0.2866,
      "step": 3982
    },
    {
      "epoch": 0.30952751010258006,
      "grad_norm": 0.35514745116233826,
      "learning_rate": 8.4523624494871e-06,
      "loss": 0.1999,
      "step": 3983
    },
    {
      "epoch": 0.30960522225676096,
      "grad_norm": 0.3016003668308258,
      "learning_rate": 8.451973888716197e-06,
      "loss": 0.2896,
      "step": 3984
    },
    {
      "epoch": 0.30968293441094186,
      "grad_norm": 0.16600815951824188,
      "learning_rate": 8.451585327945292e-06,
      "loss": 0.0324,
      "step": 3985
    },
    {
      "epoch": 0.3097606465651228,
      "grad_norm": 0.6997098326683044,
      "learning_rate": 8.451196767174387e-06,
      "loss": 0.2397,
      "step": 3986
    },
    {
      "epoch": 0.3098383587193037,
      "grad_norm": 0.10230081528425217,
      "learning_rate": 8.450808206403483e-06,
      "loss": 0.061,
      "step": 3987
    },
    {
      "epoch": 0.3099160708734846,
      "grad_norm": 0.13703623414039612,
      "learning_rate": 8.450419645632577e-06,
      "loss": 0.055,
      "step": 3988
    },
    {
      "epoch": 0.3099937830276655,
      "grad_norm": 0.23346388339996338,
      "learning_rate": 8.450031084861673e-06,
      "loss": 0.1636,
      "step": 3989
    },
    {
      "epoch": 0.31007149518184646,
      "grad_norm": 0.2755289077758789,
      "learning_rate": 8.449642524090768e-06,
      "loss": 0.3159,
      "step": 3990
    },
    {
      "epoch": 0.31014920733602735,
      "grad_norm": 0.24176649749279022,
      "learning_rate": 8.449253963319865e-06,
      "loss": 0.0496,
      "step": 3991
    },
    {
      "epoch": 0.31022691949020825,
      "grad_norm": 0.33794307708740234,
      "learning_rate": 8.44886540254896e-06,
      "loss": 0.549,
      "step": 3992
    },
    {
      "epoch": 0.3103046316443892,
      "grad_norm": 0.3344168961048126,
      "learning_rate": 8.448476841778055e-06,
      "loss": 0.1521,
      "step": 3993
    },
    {
      "epoch": 0.3103823437985701,
      "grad_norm": 0.23576895892620087,
      "learning_rate": 8.448088281007151e-06,
      "loss": 0.2224,
      "step": 3994
    },
    {
      "epoch": 0.310460055952751,
      "grad_norm": 0.7010406851768494,
      "learning_rate": 8.447699720236246e-06,
      "loss": 0.3164,
      "step": 3995
    },
    {
      "epoch": 0.3105377681069319,
      "grad_norm": 0.1654353141784668,
      "learning_rate": 8.447311159465341e-06,
      "loss": 0.0363,
      "step": 3996
    },
    {
      "epoch": 0.31061548026111285,
      "grad_norm": 0.460032194852829,
      "learning_rate": 8.446922598694436e-06,
      "loss": 0.2586,
      "step": 3997
    },
    {
      "epoch": 0.31069319241529375,
      "grad_norm": 0.6728562116622925,
      "learning_rate": 8.446534037923531e-06,
      "loss": 0.4096,
      "step": 3998
    },
    {
      "epoch": 0.31077090456947465,
      "grad_norm": 0.6008276343345642,
      "learning_rate": 8.446145477152628e-06,
      "loss": 0.4091,
      "step": 3999
    },
    {
      "epoch": 0.3108486167236556,
      "grad_norm": 0.426375150680542,
      "learning_rate": 8.445756916381723e-06,
      "loss": 0.4501,
      "step": 4000
    },
    {
      "epoch": 0.3109263288778365,
      "grad_norm": 0.2729197144508362,
      "learning_rate": 8.445368355610818e-06,
      "loss": 0.1526,
      "step": 4001
    },
    {
      "epoch": 0.3110040410320174,
      "grad_norm": 0.4327390789985657,
      "learning_rate": 8.444979794839914e-06,
      "loss": 0.4247,
      "step": 4002
    },
    {
      "epoch": 0.3110817531861983,
      "grad_norm": 0.3427128195762634,
      "learning_rate": 8.44459123406901e-06,
      "loss": 0.1187,
      "step": 4003
    },
    {
      "epoch": 0.31115946534037925,
      "grad_norm": 0.1801127791404724,
      "learning_rate": 8.444202673298104e-06,
      "loss": 0.0748,
      "step": 4004
    },
    {
      "epoch": 0.31123717749456015,
      "grad_norm": 0.3132201135158539,
      "learning_rate": 8.443814112527199e-06,
      "loss": 0.1024,
      "step": 4005
    },
    {
      "epoch": 0.31131488964874104,
      "grad_norm": 0.38880789279937744,
      "learning_rate": 8.443425551756296e-06,
      "loss": 0.2192,
      "step": 4006
    },
    {
      "epoch": 0.311392601802922,
      "grad_norm": 0.3960207402706146,
      "learning_rate": 8.44303699098539e-06,
      "loss": 0.1787,
      "step": 4007
    },
    {
      "epoch": 0.3114703139571029,
      "grad_norm": 0.6403278708457947,
      "learning_rate": 8.442648430214486e-06,
      "loss": 0.4994,
      "step": 4008
    },
    {
      "epoch": 0.3115480261112838,
      "grad_norm": 0.040654174983501434,
      "learning_rate": 8.442259869443582e-06,
      "loss": 0.0046,
      "step": 4009
    },
    {
      "epoch": 0.3116257382654647,
      "grad_norm": 0.11760708689689636,
      "learning_rate": 8.441871308672677e-06,
      "loss": 0.0914,
      "step": 4010
    },
    {
      "epoch": 0.31170345041964564,
      "grad_norm": 0.11657480150461197,
      "learning_rate": 8.441482747901772e-06,
      "loss": 0.1002,
      "step": 4011
    },
    {
      "epoch": 0.31178116257382654,
      "grad_norm": 0.9466031789779663,
      "learning_rate": 8.441094187130869e-06,
      "loss": 0.5718,
      "step": 4012
    },
    {
      "epoch": 0.31185887472800744,
      "grad_norm": 0.5182207226753235,
      "learning_rate": 8.440705626359962e-06,
      "loss": 0.1368,
      "step": 4013
    },
    {
      "epoch": 0.3119365868821884,
      "grad_norm": 0.720389187335968,
      "learning_rate": 8.440317065589059e-06,
      "loss": 0.469,
      "step": 4014
    },
    {
      "epoch": 0.3120142990363693,
      "grad_norm": 0.6280940175056458,
      "learning_rate": 8.439928504818154e-06,
      "loss": 0.1015,
      "step": 4015
    },
    {
      "epoch": 0.3120920111905502,
      "grad_norm": 0.31036949157714844,
      "learning_rate": 8.439539944047249e-06,
      "loss": 0.1204,
      "step": 4016
    },
    {
      "epoch": 0.31216972334473114,
      "grad_norm": 0.506953239440918,
      "learning_rate": 8.439151383276345e-06,
      "loss": 0.1724,
      "step": 4017
    },
    {
      "epoch": 0.31224743549891204,
      "grad_norm": 0.10070985555648804,
      "learning_rate": 8.43876282250544e-06,
      "loss": 0.0295,
      "step": 4018
    },
    {
      "epoch": 0.31232514765309294,
      "grad_norm": 0.4631511867046356,
      "learning_rate": 8.438374261734535e-06,
      "loss": 0.162,
      "step": 4019
    },
    {
      "epoch": 0.31240285980727384,
      "grad_norm": 0.32006382942199707,
      "learning_rate": 8.437985700963632e-06,
      "loss": 0.1854,
      "step": 4020
    },
    {
      "epoch": 0.3124805719614548,
      "grad_norm": 0.5280055999755859,
      "learning_rate": 8.437597140192727e-06,
      "loss": 0.0722,
      "step": 4021
    },
    {
      "epoch": 0.3125582841156357,
      "grad_norm": 0.5529015064239502,
      "learning_rate": 8.437208579421823e-06,
      "loss": 0.2246,
      "step": 4022
    },
    {
      "epoch": 0.3126359962698166,
      "grad_norm": 0.3927219808101654,
      "learning_rate": 8.436820018650917e-06,
      "loss": 0.1866,
      "step": 4023
    },
    {
      "epoch": 0.31271370842399754,
      "grad_norm": 0.48408809304237366,
      "learning_rate": 8.436431457880013e-06,
      "loss": 0.7024,
      "step": 4024
    },
    {
      "epoch": 0.31279142057817844,
      "grad_norm": 0.17403210699558258,
      "learning_rate": 8.436042897109108e-06,
      "loss": 0.052,
      "step": 4025
    },
    {
      "epoch": 0.31286913273235933,
      "grad_norm": 0.49433478713035583,
      "learning_rate": 8.435654336338203e-06,
      "loss": 0.2324,
      "step": 4026
    },
    {
      "epoch": 0.31294684488654023,
      "grad_norm": 0.2855342924594879,
      "learning_rate": 8.4352657755673e-06,
      "loss": 0.0854,
      "step": 4027
    },
    {
      "epoch": 0.3130245570407212,
      "grad_norm": 0.1300061196088791,
      "learning_rate": 8.434877214796395e-06,
      "loss": 0.0331,
      "step": 4028
    },
    {
      "epoch": 0.3131022691949021,
      "grad_norm": 0.2847265303134918,
      "learning_rate": 8.43448865402549e-06,
      "loss": 0.1662,
      "step": 4029
    },
    {
      "epoch": 0.313179981349083,
      "grad_norm": 0.3018880784511566,
      "learning_rate": 8.434100093254586e-06,
      "loss": 0.1423,
      "step": 4030
    },
    {
      "epoch": 0.31325769350326393,
      "grad_norm": 1.1285109519958496,
      "learning_rate": 8.433711532483681e-06,
      "loss": 0.9743,
      "step": 4031
    },
    {
      "epoch": 0.31333540565744483,
      "grad_norm": 0.5514228940010071,
      "learning_rate": 8.433322971712776e-06,
      "loss": 0.3158,
      "step": 4032
    },
    {
      "epoch": 0.31341311781162573,
      "grad_norm": 0.19648851454257965,
      "learning_rate": 8.432934410941871e-06,
      "loss": 0.1126,
      "step": 4033
    },
    {
      "epoch": 0.3134908299658066,
      "grad_norm": 0.4147305488586426,
      "learning_rate": 8.432545850170968e-06,
      "loss": 0.3816,
      "step": 4034
    },
    {
      "epoch": 0.3135685421199876,
      "grad_norm": 0.368448406457901,
      "learning_rate": 8.432157289400063e-06,
      "loss": 0.1571,
      "step": 4035
    },
    {
      "epoch": 0.3136462542741685,
      "grad_norm": 0.14485964179039001,
      "learning_rate": 8.431768728629158e-06,
      "loss": 0.0765,
      "step": 4036
    },
    {
      "epoch": 0.3137239664283494,
      "grad_norm": 0.19812485575675964,
      "learning_rate": 8.431380167858254e-06,
      "loss": 0.0582,
      "step": 4037
    },
    {
      "epoch": 0.31380167858253033,
      "grad_norm": 0.24508623778820038,
      "learning_rate": 8.43099160708735e-06,
      "loss": 0.3118,
      "step": 4038
    },
    {
      "epoch": 0.31387939073671123,
      "grad_norm": 0.34820178151130676,
      "learning_rate": 8.430603046316444e-06,
      "loss": 0.2275,
      "step": 4039
    },
    {
      "epoch": 0.3139571028908921,
      "grad_norm": 0.41687485575675964,
      "learning_rate": 8.430214485545541e-06,
      "loss": 0.2858,
      "step": 4040
    },
    {
      "epoch": 0.314034815045073,
      "grad_norm": 0.0775255337357521,
      "learning_rate": 8.429825924774634e-06,
      "loss": 0.0334,
      "step": 4041
    },
    {
      "epoch": 0.314112527199254,
      "grad_norm": 0.18294571340084076,
      "learning_rate": 8.429437364003731e-06,
      "loss": 0.127,
      "step": 4042
    },
    {
      "epoch": 0.3141902393534349,
      "grad_norm": 0.23253975808620453,
      "learning_rate": 8.429048803232826e-06,
      "loss": 0.0361,
      "step": 4043
    },
    {
      "epoch": 0.3142679515076158,
      "grad_norm": 0.7320981025695801,
      "learning_rate": 8.42866024246192e-06,
      "loss": 1.1287,
      "step": 4044
    },
    {
      "epoch": 0.3143456636617967,
      "grad_norm": 0.11351567506790161,
      "learning_rate": 8.428271681691017e-06,
      "loss": 0.0563,
      "step": 4045
    },
    {
      "epoch": 0.3144233758159776,
      "grad_norm": 0.24485436081886292,
      "learning_rate": 8.427883120920112e-06,
      "loss": 0.1697,
      "step": 4046
    },
    {
      "epoch": 0.3145010879701585,
      "grad_norm": 0.17569500207901,
      "learning_rate": 8.427494560149207e-06,
      "loss": 0.086,
      "step": 4047
    },
    {
      "epoch": 0.3145788001243394,
      "grad_norm": 0.19300037622451782,
      "learning_rate": 8.427105999378304e-06,
      "loss": 0.4794,
      "step": 4048
    },
    {
      "epoch": 0.3146565122785204,
      "grad_norm": 0.282685250043869,
      "learning_rate": 8.426717438607399e-06,
      "loss": 0.0773,
      "step": 4049
    },
    {
      "epoch": 0.31473422443270127,
      "grad_norm": 0.3792349696159363,
      "learning_rate": 8.426328877836494e-06,
      "loss": 0.2533,
      "step": 4050
    },
    {
      "epoch": 0.31481193658688217,
      "grad_norm": 0.06660416722297668,
      "learning_rate": 8.425940317065589e-06,
      "loss": 0.0064,
      "step": 4051
    },
    {
      "epoch": 0.3148896487410631,
      "grad_norm": 0.39538875222206116,
      "learning_rate": 8.425551756294685e-06,
      "loss": 0.2117,
      "step": 4052
    },
    {
      "epoch": 0.314967360895244,
      "grad_norm": 0.6104893088340759,
      "learning_rate": 8.42516319552378e-06,
      "loss": 0.3039,
      "step": 4053
    },
    {
      "epoch": 0.3150450730494249,
      "grad_norm": 0.29035767912864685,
      "learning_rate": 8.424774634752875e-06,
      "loss": 0.2202,
      "step": 4054
    },
    {
      "epoch": 0.31512278520360587,
      "grad_norm": 0.20529267191886902,
      "learning_rate": 8.424386073981972e-06,
      "loss": 0.1237,
      "step": 4055
    },
    {
      "epoch": 0.31520049735778677,
      "grad_norm": 0.7967450618743896,
      "learning_rate": 8.423997513211067e-06,
      "loss": 0.8875,
      "step": 4056
    },
    {
      "epoch": 0.31527820951196767,
      "grad_norm": 0.14790742099285126,
      "learning_rate": 8.423608952440162e-06,
      "loss": 0.049,
      "step": 4057
    },
    {
      "epoch": 0.31535592166614856,
      "grad_norm": 0.07321318984031677,
      "learning_rate": 8.423220391669259e-06,
      "loss": 0.0183,
      "step": 4058
    },
    {
      "epoch": 0.3154336338203295,
      "grad_norm": 0.5949143171310425,
      "learning_rate": 8.422831830898354e-06,
      "loss": 0.2578,
      "step": 4059
    },
    {
      "epoch": 0.3155113459745104,
      "grad_norm": 0.16088734567165375,
      "learning_rate": 8.422443270127448e-06,
      "loss": 0.0936,
      "step": 4060
    },
    {
      "epoch": 0.3155890581286913,
      "grad_norm": 0.9361542463302612,
      "learning_rate": 8.422054709356543e-06,
      "loss": 0.408,
      "step": 4061
    },
    {
      "epoch": 0.31566677028287227,
      "grad_norm": 0.3430083692073822,
      "learning_rate": 8.42166614858564e-06,
      "loss": 0.3,
      "step": 4062
    },
    {
      "epoch": 0.31574448243705316,
      "grad_norm": 0.3589290976524353,
      "learning_rate": 8.421277587814735e-06,
      "loss": 0.1164,
      "step": 4063
    },
    {
      "epoch": 0.31582219459123406,
      "grad_norm": 0.5428174734115601,
      "learning_rate": 8.42088902704383e-06,
      "loss": 0.3275,
      "step": 4064
    },
    {
      "epoch": 0.31589990674541496,
      "grad_norm": 0.16693511605262756,
      "learning_rate": 8.420500466272927e-06,
      "loss": 0.111,
      "step": 4065
    },
    {
      "epoch": 0.3159776188995959,
      "grad_norm": 0.044514209032058716,
      "learning_rate": 8.420111905502022e-06,
      "loss": 0.0063,
      "step": 4066
    },
    {
      "epoch": 0.3160553310537768,
      "grad_norm": 1.3530150651931763,
      "learning_rate": 8.419723344731117e-06,
      "loss": 0.334,
      "step": 4067
    },
    {
      "epoch": 0.3161330432079577,
      "grad_norm": 0.32305118441581726,
      "learning_rate": 8.419334783960213e-06,
      "loss": 0.1511,
      "step": 4068
    },
    {
      "epoch": 0.31621075536213866,
      "grad_norm": 0.38629600405693054,
      "learning_rate": 8.418946223189306e-06,
      "loss": 0.1383,
      "step": 4069
    },
    {
      "epoch": 0.31628846751631956,
      "grad_norm": 0.6820474863052368,
      "learning_rate": 8.418557662418403e-06,
      "loss": 0.4027,
      "step": 4070
    },
    {
      "epoch": 0.31636617967050046,
      "grad_norm": 0.2384437471628189,
      "learning_rate": 8.418169101647498e-06,
      "loss": 0.2268,
      "step": 4071
    },
    {
      "epoch": 0.31644389182468136,
      "grad_norm": 0.47652024030685425,
      "learning_rate": 8.417780540876593e-06,
      "loss": 0.1941,
      "step": 4072
    },
    {
      "epoch": 0.3165216039788623,
      "grad_norm": 0.9979799389839172,
      "learning_rate": 8.41739198010569e-06,
      "loss": 0.3017,
      "step": 4073
    },
    {
      "epoch": 0.3165993161330432,
      "grad_norm": 0.1936732977628708,
      "learning_rate": 8.417003419334785e-06,
      "loss": 0.188,
      "step": 4074
    },
    {
      "epoch": 0.3166770282872241,
      "grad_norm": 0.13858285546302795,
      "learning_rate": 8.41661485856388e-06,
      "loss": 0.052,
      "step": 4075
    },
    {
      "epoch": 0.31675474044140506,
      "grad_norm": 0.39834603667259216,
      "learning_rate": 8.416226297792976e-06,
      "loss": 0.3326,
      "step": 4076
    },
    {
      "epoch": 0.31683245259558596,
      "grad_norm": 0.5146437883377075,
      "learning_rate": 8.415837737022071e-06,
      "loss": 0.4074,
      "step": 4077
    },
    {
      "epoch": 0.31691016474976685,
      "grad_norm": 0.48609474301338196,
      "learning_rate": 8.415449176251166e-06,
      "loss": 0.2053,
      "step": 4078
    },
    {
      "epoch": 0.31698787690394775,
      "grad_norm": 0.0868285745382309,
      "learning_rate": 8.415060615480261e-06,
      "loss": 0.022,
      "step": 4079
    },
    {
      "epoch": 0.3170655890581287,
      "grad_norm": 0.4691002368927002,
      "learning_rate": 8.414672054709358e-06,
      "loss": 0.3536,
      "step": 4080
    },
    {
      "epoch": 0.3171433012123096,
      "grad_norm": 0.4725453555583954,
      "learning_rate": 8.414283493938453e-06,
      "loss": 0.1768,
      "step": 4081
    },
    {
      "epoch": 0.3172210133664905,
      "grad_norm": 0.07240729033946991,
      "learning_rate": 8.413894933167548e-06,
      "loss": 0.0363,
      "step": 4082
    },
    {
      "epoch": 0.31729872552067145,
      "grad_norm": 0.6796598434448242,
      "learning_rate": 8.413506372396644e-06,
      "loss": 0.2245,
      "step": 4083
    },
    {
      "epoch": 0.31737643767485235,
      "grad_norm": 0.26411429047584534,
      "learning_rate": 8.413117811625739e-06,
      "loss": 0.1407,
      "step": 4084
    },
    {
      "epoch": 0.31745414982903325,
      "grad_norm": 0.08019145578145981,
      "learning_rate": 8.412729250854834e-06,
      "loss": 0.0292,
      "step": 4085
    },
    {
      "epoch": 0.31753186198321415,
      "grad_norm": 0.1134994849562645,
      "learning_rate": 8.41234069008393e-06,
      "loss": 0.0465,
      "step": 4086
    },
    {
      "epoch": 0.3176095741373951,
      "grad_norm": 0.24310392141342163,
      "learning_rate": 8.411952129313026e-06,
      "loss": 0.0375,
      "step": 4087
    },
    {
      "epoch": 0.317687286291576,
      "grad_norm": 0.12108471244573593,
      "learning_rate": 8.41156356854212e-06,
      "loss": 0.0625,
      "step": 4088
    },
    {
      "epoch": 0.3177649984457569,
      "grad_norm": 0.20677931606769562,
      "learning_rate": 8.411175007771216e-06,
      "loss": 0.1047,
      "step": 4089
    },
    {
      "epoch": 0.31784271059993785,
      "grad_norm": 0.34857407212257385,
      "learning_rate": 8.410786447000312e-06,
      "loss": 0.1647,
      "step": 4090
    },
    {
      "epoch": 0.31792042275411875,
      "grad_norm": 0.2038905918598175,
      "learning_rate": 8.410397886229407e-06,
      "loss": 0.0753,
      "step": 4091
    },
    {
      "epoch": 0.31799813490829965,
      "grad_norm": 0.28427931666374207,
      "learning_rate": 8.410009325458502e-06,
      "loss": 0.0394,
      "step": 4092
    },
    {
      "epoch": 0.3180758470624806,
      "grad_norm": 0.2835398316383362,
      "learning_rate": 8.409620764687599e-06,
      "loss": 0.3471,
      "step": 4093
    },
    {
      "epoch": 0.3181535592166615,
      "grad_norm": 0.6100184321403503,
      "learning_rate": 8.409232203916694e-06,
      "loss": 0.3154,
      "step": 4094
    },
    {
      "epoch": 0.3182312713708424,
      "grad_norm": 0.2642119824886322,
      "learning_rate": 8.408843643145789e-06,
      "loss": 0.1114,
      "step": 4095
    },
    {
      "epoch": 0.3183089835250233,
      "grad_norm": 1.0384517908096313,
      "learning_rate": 8.408455082374885e-06,
      "loss": 0.51,
      "step": 4096
    },
    {
      "epoch": 0.31838669567920425,
      "grad_norm": 0.1867246925830841,
      "learning_rate": 8.408066521603979e-06,
      "loss": 0.0398,
      "step": 4097
    },
    {
      "epoch": 0.31846440783338514,
      "grad_norm": 0.8759419322013855,
      "learning_rate": 8.407677960833075e-06,
      "loss": 0.1951,
      "step": 4098
    },
    {
      "epoch": 0.31854211998756604,
      "grad_norm": 0.5329065322875977,
      "learning_rate": 8.40728940006217e-06,
      "loss": 0.2843,
      "step": 4099
    },
    {
      "epoch": 0.318619832141747,
      "grad_norm": 0.42352867126464844,
      "learning_rate": 8.406900839291265e-06,
      "loss": 0.2859,
      "step": 4100
    },
    {
      "epoch": 0.3186975442959279,
      "grad_norm": 0.5961814522743225,
      "learning_rate": 8.406512278520362e-06,
      "loss": 0.348,
      "step": 4101
    },
    {
      "epoch": 0.3187752564501088,
      "grad_norm": 0.3239152133464813,
      "learning_rate": 8.406123717749457e-06,
      "loss": 0.1564,
      "step": 4102
    },
    {
      "epoch": 0.3188529686042897,
      "grad_norm": 0.20696885883808136,
      "learning_rate": 8.405735156978552e-06,
      "loss": 0.0459,
      "step": 4103
    },
    {
      "epoch": 0.31893068075847064,
      "grad_norm": 0.2760409414768219,
      "learning_rate": 8.405346596207648e-06,
      "loss": 0.1521,
      "step": 4104
    },
    {
      "epoch": 0.31900839291265154,
      "grad_norm": 0.10606645047664642,
      "learning_rate": 8.404958035436743e-06,
      "loss": 0.0528,
      "step": 4105
    },
    {
      "epoch": 0.31908610506683244,
      "grad_norm": 0.3333532512187958,
      "learning_rate": 8.404569474665838e-06,
      "loss": 0.1273,
      "step": 4106
    },
    {
      "epoch": 0.3191638172210134,
      "grad_norm": 0.501101553440094,
      "learning_rate": 8.404180913894933e-06,
      "loss": 0.3166,
      "step": 4107
    },
    {
      "epoch": 0.3192415293751943,
      "grad_norm": 0.4319054186344147,
      "learning_rate": 8.40379235312403e-06,
      "loss": 0.2517,
      "step": 4108
    },
    {
      "epoch": 0.3193192415293752,
      "grad_norm": 0.09417571127414703,
      "learning_rate": 8.403403792353125e-06,
      "loss": 0.0133,
      "step": 4109
    },
    {
      "epoch": 0.3193969536835561,
      "grad_norm": 0.6847530603408813,
      "learning_rate": 8.40301523158222e-06,
      "loss": 0.7128,
      "step": 4110
    },
    {
      "epoch": 0.31947466583773704,
      "grad_norm": 0.5164445638656616,
      "learning_rate": 8.402626670811316e-06,
      "loss": 0.1387,
      "step": 4111
    },
    {
      "epoch": 0.31955237799191794,
      "grad_norm": 0.28888317942619324,
      "learning_rate": 8.402238110040411e-06,
      "loss": 0.0877,
      "step": 4112
    },
    {
      "epoch": 0.31963009014609883,
      "grad_norm": 0.38237541913986206,
      "learning_rate": 8.401849549269506e-06,
      "loss": 0.1815,
      "step": 4113
    },
    {
      "epoch": 0.3197078023002798,
      "grad_norm": 0.4852190315723419,
      "learning_rate": 8.401460988498603e-06,
      "loss": 0.2548,
      "step": 4114
    },
    {
      "epoch": 0.3197855144544607,
      "grad_norm": 0.4975306987762451,
      "learning_rate": 8.401072427727698e-06,
      "loss": 0.5017,
      "step": 4115
    },
    {
      "epoch": 0.3198632266086416,
      "grad_norm": 0.3182952404022217,
      "learning_rate": 8.400683866956793e-06,
      "loss": 0.1605,
      "step": 4116
    },
    {
      "epoch": 0.3199409387628225,
      "grad_norm": 0.11761541664600372,
      "learning_rate": 8.400295306185888e-06,
      "loss": 0.0616,
      "step": 4117
    },
    {
      "epoch": 0.32001865091700343,
      "grad_norm": 0.389087051153183,
      "learning_rate": 8.399906745414984e-06,
      "loss": 0.2557,
      "step": 4118
    },
    {
      "epoch": 0.32009636307118433,
      "grad_norm": 0.15128536522388458,
      "learning_rate": 8.39951818464408e-06,
      "loss": 0.0757,
      "step": 4119
    },
    {
      "epoch": 0.32017407522536523,
      "grad_norm": 0.31448042392730713,
      "learning_rate": 8.399129623873174e-06,
      "loss": 0.3533,
      "step": 4120
    },
    {
      "epoch": 0.3202517873795462,
      "grad_norm": 0.4373478591442108,
      "learning_rate": 8.398741063102271e-06,
      "loss": 0.1371,
      "step": 4121
    },
    {
      "epoch": 0.3203294995337271,
      "grad_norm": 0.3750649690628052,
      "learning_rate": 8.398352502331366e-06,
      "loss": 0.0667,
      "step": 4122
    },
    {
      "epoch": 0.320407211687908,
      "grad_norm": 0.10773109644651413,
      "learning_rate": 8.39796394156046e-06,
      "loss": 0.0541,
      "step": 4123
    },
    {
      "epoch": 0.3204849238420889,
      "grad_norm": 0.23151323199272156,
      "learning_rate": 8.397575380789556e-06,
      "loss": 0.0906,
      "step": 4124
    },
    {
      "epoch": 0.32056263599626983,
      "grad_norm": 0.5357452630996704,
      "learning_rate": 8.39718682001865e-06,
      "loss": 0.1372,
      "step": 4125
    },
    {
      "epoch": 0.3206403481504507,
      "grad_norm": 0.16234181821346283,
      "learning_rate": 8.396798259247747e-06,
      "loss": 0.1804,
      "step": 4126
    },
    {
      "epoch": 0.3207180603046316,
      "grad_norm": 0.1181323304772377,
      "learning_rate": 8.396409698476842e-06,
      "loss": 0.0338,
      "step": 4127
    },
    {
      "epoch": 0.3207957724588126,
      "grad_norm": 0.20048771798610687,
      "learning_rate": 8.396021137705937e-06,
      "loss": 0.2053,
      "step": 4128
    },
    {
      "epoch": 0.3208734846129935,
      "grad_norm": 0.3290402293205261,
      "learning_rate": 8.395632576935034e-06,
      "loss": 0.2329,
      "step": 4129
    },
    {
      "epoch": 0.3209511967671744,
      "grad_norm": 0.41040706634521484,
      "learning_rate": 8.395244016164129e-06,
      "loss": 0.1885,
      "step": 4130
    },
    {
      "epoch": 0.3210289089213553,
      "grad_norm": 0.566271960735321,
      "learning_rate": 8.394855455393224e-06,
      "loss": 0.2861,
      "step": 4131
    },
    {
      "epoch": 0.3211066210755362,
      "grad_norm": 0.18312765657901764,
      "learning_rate": 8.394466894622319e-06,
      "loss": 0.2531,
      "step": 4132
    },
    {
      "epoch": 0.3211843332297171,
      "grad_norm": 0.4944171905517578,
      "learning_rate": 8.394078333851415e-06,
      "loss": 0.3323,
      "step": 4133
    },
    {
      "epoch": 0.321262045383898,
      "grad_norm": 0.11262200027704239,
      "learning_rate": 8.39368977308051e-06,
      "loss": 0.0401,
      "step": 4134
    },
    {
      "epoch": 0.321339757538079,
      "grad_norm": 0.24837438762187958,
      "learning_rate": 8.393301212309605e-06,
      "loss": 0.1908,
      "step": 4135
    },
    {
      "epoch": 0.32141746969225987,
      "grad_norm": 0.3259756565093994,
      "learning_rate": 8.392912651538702e-06,
      "loss": 0.1391,
      "step": 4136
    },
    {
      "epoch": 0.32149518184644077,
      "grad_norm": 0.6715362071990967,
      "learning_rate": 8.392524090767797e-06,
      "loss": 0.8832,
      "step": 4137
    },
    {
      "epoch": 0.3215728940006217,
      "grad_norm": 0.08602800220251083,
      "learning_rate": 8.392135529996892e-06,
      "loss": 0.0441,
      "step": 4138
    },
    {
      "epoch": 0.3216506061548026,
      "grad_norm": 0.22761602699756622,
      "learning_rate": 8.391746969225988e-06,
      "loss": 0.0654,
      "step": 4139
    },
    {
      "epoch": 0.3217283183089835,
      "grad_norm": 0.45839834213256836,
      "learning_rate": 8.391358408455082e-06,
      "loss": 0.2435,
      "step": 4140
    },
    {
      "epoch": 0.3218060304631644,
      "grad_norm": 0.24068792164325714,
      "learning_rate": 8.390969847684178e-06,
      "loss": 0.1199,
      "step": 4141
    },
    {
      "epoch": 0.32188374261734537,
      "grad_norm": 0.11092593520879745,
      "learning_rate": 8.390581286913273e-06,
      "loss": 0.0292,
      "step": 4142
    },
    {
      "epoch": 0.32196145477152627,
      "grad_norm": 0.12856890261173248,
      "learning_rate": 8.39019272614237e-06,
      "loss": 0.0694,
      "step": 4143
    },
    {
      "epoch": 0.32203916692570717,
      "grad_norm": 0.15344548225402832,
      "learning_rate": 8.389804165371465e-06,
      "loss": 0.0306,
      "step": 4144
    },
    {
      "epoch": 0.3221168790798881,
      "grad_norm": 0.2779906094074249,
      "learning_rate": 8.38941560460056e-06,
      "loss": 0.2651,
      "step": 4145
    },
    {
      "epoch": 0.322194591234069,
      "grad_norm": 0.5487786531448364,
      "learning_rate": 8.389027043829657e-06,
      "loss": 0.3199,
      "step": 4146
    },
    {
      "epoch": 0.3222723033882499,
      "grad_norm": 0.17292800545692444,
      "learning_rate": 8.388638483058751e-06,
      "loss": 0.031,
      "step": 4147
    },
    {
      "epoch": 0.3223500155424308,
      "grad_norm": 0.2509424686431885,
      "learning_rate": 8.388249922287846e-06,
      "loss": 0.3255,
      "step": 4148
    },
    {
      "epoch": 0.32242772769661177,
      "grad_norm": 0.3137662708759308,
      "learning_rate": 8.387861361516943e-06,
      "loss": 0.1993,
      "step": 4149
    },
    {
      "epoch": 0.32250543985079266,
      "grad_norm": 0.405975878238678,
      "learning_rate": 8.387472800746036e-06,
      "loss": 0.167,
      "step": 4150
    },
    {
      "epoch": 0.32258315200497356,
      "grad_norm": 0.6739945411682129,
      "learning_rate": 8.387084239975133e-06,
      "loss": 0.2133,
      "step": 4151
    },
    {
      "epoch": 0.3226608641591545,
      "grad_norm": 0.5458751320838928,
      "learning_rate": 8.386695679204228e-06,
      "loss": 0.4032,
      "step": 4152
    },
    {
      "epoch": 0.3227385763133354,
      "grad_norm": 0.10424278676509857,
      "learning_rate": 8.386307118433323e-06,
      "loss": 0.0516,
      "step": 4153
    },
    {
      "epoch": 0.3228162884675163,
      "grad_norm": 0.12816748023033142,
      "learning_rate": 8.38591855766242e-06,
      "loss": 0.0278,
      "step": 4154
    },
    {
      "epoch": 0.3228940006216972,
      "grad_norm": 0.5046656131744385,
      "learning_rate": 8.385529996891514e-06,
      "loss": 0.2944,
      "step": 4155
    },
    {
      "epoch": 0.32297171277587816,
      "grad_norm": 0.383369117975235,
      "learning_rate": 8.38514143612061e-06,
      "loss": 0.3271,
      "step": 4156
    },
    {
      "epoch": 0.32304942493005906,
      "grad_norm": 0.2326606661081314,
      "learning_rate": 8.384752875349706e-06,
      "loss": 0.1753,
      "step": 4157
    },
    {
      "epoch": 0.32312713708423996,
      "grad_norm": 0.708329439163208,
      "learning_rate": 8.384364314578801e-06,
      "loss": 0.208,
      "step": 4158
    },
    {
      "epoch": 0.3232048492384209,
      "grad_norm": 0.3238662779331207,
      "learning_rate": 8.383975753807896e-06,
      "loss": 0.2565,
      "step": 4159
    },
    {
      "epoch": 0.3232825613926018,
      "grad_norm": 0.8488096594810486,
      "learning_rate": 8.383587193036991e-06,
      "loss": 0.3332,
      "step": 4160
    },
    {
      "epoch": 0.3233602735467827,
      "grad_norm": 0.28282323479652405,
      "learning_rate": 8.383198632266088e-06,
      "loss": 0.1245,
      "step": 4161
    },
    {
      "epoch": 0.3234379857009636,
      "grad_norm": 0.4586236774921417,
      "learning_rate": 8.382810071495182e-06,
      "loss": 0.1773,
      "step": 4162
    },
    {
      "epoch": 0.32351569785514456,
      "grad_norm": 0.157584086060524,
      "learning_rate": 8.382421510724277e-06,
      "loss": 0.0859,
      "step": 4163
    },
    {
      "epoch": 0.32359341000932546,
      "grad_norm": 0.48590394854545593,
      "learning_rate": 8.382032949953374e-06,
      "loss": 0.2277,
      "step": 4164
    },
    {
      "epoch": 0.32367112216350635,
      "grad_norm": 0.385884553194046,
      "learning_rate": 8.381644389182469e-06,
      "loss": 0.4797,
      "step": 4165
    },
    {
      "epoch": 0.3237488343176873,
      "grad_norm": 0.40720048546791077,
      "learning_rate": 8.381255828411564e-06,
      "loss": 0.2655,
      "step": 4166
    },
    {
      "epoch": 0.3238265464718682,
      "grad_norm": 0.32484978437423706,
      "learning_rate": 8.38086726764066e-06,
      "loss": 0.1,
      "step": 4167
    },
    {
      "epoch": 0.3239042586260491,
      "grad_norm": 0.3547348976135254,
      "learning_rate": 8.380478706869754e-06,
      "loss": 0.1298,
      "step": 4168
    },
    {
      "epoch": 0.32398197078023006,
      "grad_norm": 0.3425856828689575,
      "learning_rate": 8.38009014609885e-06,
      "loss": 0.0876,
      "step": 4169
    },
    {
      "epoch": 0.32405968293441095,
      "grad_norm": 0.1790419965982437,
      "learning_rate": 8.379701585327945e-06,
      "loss": 0.0898,
      "step": 4170
    },
    {
      "epoch": 0.32413739508859185,
      "grad_norm": 0.553169846534729,
      "learning_rate": 8.37931302455704e-06,
      "loss": 0.2455,
      "step": 4171
    },
    {
      "epoch": 0.32421510724277275,
      "grad_norm": 0.0774725005030632,
      "learning_rate": 8.378924463786137e-06,
      "loss": 0.0199,
      "step": 4172
    },
    {
      "epoch": 0.3242928193969537,
      "grad_norm": 0.3211708664894104,
      "learning_rate": 8.378535903015232e-06,
      "loss": 0.208,
      "step": 4173
    },
    {
      "epoch": 0.3243705315511346,
      "grad_norm": 0.643825113773346,
      "learning_rate": 8.378147342244329e-06,
      "loss": 0.2528,
      "step": 4174
    },
    {
      "epoch": 0.3244482437053155,
      "grad_norm": 0.314074844121933,
      "learning_rate": 8.377758781473424e-06,
      "loss": 0.1286,
      "step": 4175
    },
    {
      "epoch": 0.32452595585949645,
      "grad_norm": 0.3359481394290924,
      "learning_rate": 8.377370220702519e-06,
      "loss": 0.2716,
      "step": 4176
    },
    {
      "epoch": 0.32460366801367735,
      "grad_norm": 0.08846871554851532,
      "learning_rate": 8.376981659931615e-06,
      "loss": 0.0267,
      "step": 4177
    },
    {
      "epoch": 0.32468138016785825,
      "grad_norm": 0.32580310106277466,
      "learning_rate": 8.376593099160708e-06,
      "loss": 0.2197,
      "step": 4178
    },
    {
      "epoch": 0.32475909232203914,
      "grad_norm": 0.32489973306655884,
      "learning_rate": 8.376204538389805e-06,
      "loss": 0.3725,
      "step": 4179
    },
    {
      "epoch": 0.3248368044762201,
      "grad_norm": 0.41950321197509766,
      "learning_rate": 8.3758159776189e-06,
      "loss": 0.5535,
      "step": 4180
    },
    {
      "epoch": 0.324914516630401,
      "grad_norm": 0.4986903965473175,
      "learning_rate": 8.375427416847995e-06,
      "loss": 0.5344,
      "step": 4181
    },
    {
      "epoch": 0.3249922287845819,
      "grad_norm": 0.09220121800899506,
      "learning_rate": 8.375038856077092e-06,
      "loss": 0.0518,
      "step": 4182
    },
    {
      "epoch": 0.32506994093876285,
      "grad_norm": 0.2762359380722046,
      "learning_rate": 8.374650295306187e-06,
      "loss": 0.0938,
      "step": 4183
    },
    {
      "epoch": 0.32514765309294374,
      "grad_norm": 0.48306575417518616,
      "learning_rate": 8.374261734535282e-06,
      "loss": 0.6406,
      "step": 4184
    },
    {
      "epoch": 0.32522536524712464,
      "grad_norm": 0.23591348528862,
      "learning_rate": 8.373873173764378e-06,
      "loss": 0.1383,
      "step": 4185
    },
    {
      "epoch": 0.32530307740130554,
      "grad_norm": 0.49952465295791626,
      "learning_rate": 8.373484612993473e-06,
      "loss": 0.2744,
      "step": 4186
    },
    {
      "epoch": 0.3253807895554865,
      "grad_norm": 0.29412317276000977,
      "learning_rate": 8.373096052222568e-06,
      "loss": 0.3209,
      "step": 4187
    },
    {
      "epoch": 0.3254585017096674,
      "grad_norm": 0.12992015480995178,
      "learning_rate": 8.372707491451663e-06,
      "loss": 0.0513,
      "step": 4188
    },
    {
      "epoch": 0.3255362138638483,
      "grad_norm": 0.34998971223831177,
      "learning_rate": 8.37231893068076e-06,
      "loss": 0.0863,
      "step": 4189
    },
    {
      "epoch": 0.32561392601802924,
      "grad_norm": 0.059676092118024826,
      "learning_rate": 8.371930369909855e-06,
      "loss": 0.019,
      "step": 4190
    },
    {
      "epoch": 0.32569163817221014,
      "grad_norm": 0.4757991433143616,
      "learning_rate": 8.37154180913895e-06,
      "loss": 0.5539,
      "step": 4191
    },
    {
      "epoch": 0.32576935032639104,
      "grad_norm": 0.38260042667388916,
      "learning_rate": 8.371153248368046e-06,
      "loss": 0.2229,
      "step": 4192
    },
    {
      "epoch": 0.32584706248057194,
      "grad_norm": 0.15616273880004883,
      "learning_rate": 8.370764687597141e-06,
      "loss": 0.0625,
      "step": 4193
    },
    {
      "epoch": 0.3259247746347529,
      "grad_norm": 0.14177410304546356,
      "learning_rate": 8.370376126826236e-06,
      "loss": 0.0287,
      "step": 4194
    },
    {
      "epoch": 0.3260024867889338,
      "grad_norm": 0.2815546989440918,
      "learning_rate": 8.369987566055333e-06,
      "loss": 0.6559,
      "step": 4195
    },
    {
      "epoch": 0.3260801989431147,
      "grad_norm": 0.1861838847398758,
      "learning_rate": 8.369599005284426e-06,
      "loss": 0.062,
      "step": 4196
    },
    {
      "epoch": 0.32615791109729564,
      "grad_norm": 0.24917005002498627,
      "learning_rate": 8.369210444513523e-06,
      "loss": 0.2449,
      "step": 4197
    },
    {
      "epoch": 0.32623562325147654,
      "grad_norm": 0.15659458935260773,
      "learning_rate": 8.368821883742618e-06,
      "loss": 0.0363,
      "step": 4198
    },
    {
      "epoch": 0.32631333540565743,
      "grad_norm": 0.21943306922912598,
      "learning_rate": 8.368433322971713e-06,
      "loss": 0.1512,
      "step": 4199
    },
    {
      "epoch": 0.32639104755983833,
      "grad_norm": 0.8488155603408813,
      "learning_rate": 8.36804476220081e-06,
      "loss": 0.3903,
      "step": 4200
    },
    {
      "epoch": 0.3264687597140193,
      "grad_norm": 0.17087849974632263,
      "learning_rate": 8.367656201429904e-06,
      "loss": 0.0457,
      "step": 4201
    },
    {
      "epoch": 0.3265464718682002,
      "grad_norm": 0.4387754797935486,
      "learning_rate": 8.367267640658999e-06,
      "loss": 0.5396,
      "step": 4202
    },
    {
      "epoch": 0.3266241840223811,
      "grad_norm": 0.14400647580623627,
      "learning_rate": 8.366879079888096e-06,
      "loss": 0.0611,
      "step": 4203
    },
    {
      "epoch": 0.32670189617656203,
      "grad_norm": 0.1500486582517624,
      "learning_rate": 8.36649051911719e-06,
      "loss": 0.0545,
      "step": 4204
    },
    {
      "epoch": 0.32677960833074293,
      "grad_norm": 0.10790934413671494,
      "learning_rate": 8.366101958346287e-06,
      "loss": 0.1019,
      "step": 4205
    },
    {
      "epoch": 0.32685732048492383,
      "grad_norm": 0.12018119543790817,
      "learning_rate": 8.36571339757538e-06,
      "loss": 0.0715,
      "step": 4206
    },
    {
      "epoch": 0.3269350326391048,
      "grad_norm": 0.34810903668403625,
      "learning_rate": 8.365324836804477e-06,
      "loss": 0.1997,
      "step": 4207
    },
    {
      "epoch": 0.3270127447932857,
      "grad_norm": 0.36462950706481934,
      "learning_rate": 8.364936276033572e-06,
      "loss": 0.4872,
      "step": 4208
    },
    {
      "epoch": 0.3270904569474666,
      "grad_norm": 0.26939424872398376,
      "learning_rate": 8.364547715262667e-06,
      "loss": 0.1227,
      "step": 4209
    },
    {
      "epoch": 0.3271681691016475,
      "grad_norm": 0.4909588098526001,
      "learning_rate": 8.364159154491764e-06,
      "loss": 0.2237,
      "step": 4210
    },
    {
      "epoch": 0.32724588125582843,
      "grad_norm": 0.41160064935684204,
      "learning_rate": 8.363770593720859e-06,
      "loss": 0.6184,
      "step": 4211
    },
    {
      "epoch": 0.32732359341000933,
      "grad_norm": 0.6801633834838867,
      "learning_rate": 8.363382032949954e-06,
      "loss": 0.446,
      "step": 4212
    },
    {
      "epoch": 0.3274013055641902,
      "grad_norm": 0.31661614775657654,
      "learning_rate": 8.36299347217905e-06,
      "loss": 0.2985,
      "step": 4213
    },
    {
      "epoch": 0.3274790177183712,
      "grad_norm": 0.3439919352531433,
      "learning_rate": 8.362604911408145e-06,
      "loss": 0.0946,
      "step": 4214
    },
    {
      "epoch": 0.3275567298725521,
      "grad_norm": 0.12361478060483932,
      "learning_rate": 8.36221635063724e-06,
      "loss": 0.0419,
      "step": 4215
    },
    {
      "epoch": 0.327634442026733,
      "grad_norm": 0.21520408987998962,
      "learning_rate": 8.361827789866335e-06,
      "loss": 0.3835,
      "step": 4216
    },
    {
      "epoch": 0.3277121541809139,
      "grad_norm": 0.4875209629535675,
      "learning_rate": 8.361439229095432e-06,
      "loss": 0.2371,
      "step": 4217
    },
    {
      "epoch": 0.3277898663350948,
      "grad_norm": 0.17355316877365112,
      "learning_rate": 8.361050668324527e-06,
      "loss": 0.0437,
      "step": 4218
    },
    {
      "epoch": 0.3278675784892757,
      "grad_norm": 0.2947615087032318,
      "learning_rate": 8.360662107553622e-06,
      "loss": 0.5146,
      "step": 4219
    },
    {
      "epoch": 0.3279452906434566,
      "grad_norm": 0.5202538371086121,
      "learning_rate": 8.360273546782718e-06,
      "loss": 0.1626,
      "step": 4220
    },
    {
      "epoch": 0.3280230027976376,
      "grad_norm": 0.19558817148208618,
      "learning_rate": 8.359884986011813e-06,
      "loss": 0.0319,
      "step": 4221
    },
    {
      "epoch": 0.3281007149518185,
      "grad_norm": 0.2189929038286209,
      "learning_rate": 8.359496425240908e-06,
      "loss": 0.1232,
      "step": 4222
    },
    {
      "epoch": 0.32817842710599937,
      "grad_norm": 0.1576031744480133,
      "learning_rate": 8.359107864470005e-06,
      "loss": 0.0591,
      "step": 4223
    },
    {
      "epoch": 0.32825613926018027,
      "grad_norm": 0.12953481078147888,
      "learning_rate": 8.358719303699098e-06,
      "loss": 0.064,
      "step": 4224
    },
    {
      "epoch": 0.3283338514143612,
      "grad_norm": 0.7123778462409973,
      "learning_rate": 8.358330742928195e-06,
      "loss": 0.3041,
      "step": 4225
    },
    {
      "epoch": 0.3284115635685421,
      "grad_norm": 0.09519726783037186,
      "learning_rate": 8.35794218215729e-06,
      "loss": 0.026,
      "step": 4226
    },
    {
      "epoch": 0.328489275722723,
      "grad_norm": 0.5682113766670227,
      "learning_rate": 8.357553621386385e-06,
      "loss": 0.2981,
      "step": 4227
    },
    {
      "epoch": 0.32856698787690397,
      "grad_norm": 0.44494539499282837,
      "learning_rate": 8.357165060615481e-06,
      "loss": 0.4537,
      "step": 4228
    },
    {
      "epoch": 0.32864470003108487,
      "grad_norm": 0.2667052149772644,
      "learning_rate": 8.356776499844576e-06,
      "loss": 0.0978,
      "step": 4229
    },
    {
      "epoch": 0.32872241218526577,
      "grad_norm": 0.23929449915885925,
      "learning_rate": 8.356387939073671e-06,
      "loss": 0.4478,
      "step": 4230
    },
    {
      "epoch": 0.32880012433944666,
      "grad_norm": 0.40014326572418213,
      "learning_rate": 8.355999378302768e-06,
      "loss": 0.4714,
      "step": 4231
    },
    {
      "epoch": 0.3288778364936276,
      "grad_norm": 0.2441687285900116,
      "learning_rate": 8.355610817531863e-06,
      "loss": 0.0649,
      "step": 4232
    },
    {
      "epoch": 0.3289555486478085,
      "grad_norm": 0.12239795178174973,
      "learning_rate": 8.355222256760958e-06,
      "loss": 0.018,
      "step": 4233
    },
    {
      "epoch": 0.3290332608019894,
      "grad_norm": 0.21404147148132324,
      "learning_rate": 8.354833695990053e-06,
      "loss": 0.0917,
      "step": 4234
    },
    {
      "epoch": 0.32911097295617037,
      "grad_norm": 0.5764687061309814,
      "learning_rate": 8.35444513521915e-06,
      "loss": 0.0956,
      "step": 4235
    },
    {
      "epoch": 0.32918868511035126,
      "grad_norm": 0.12730953097343445,
      "learning_rate": 8.354056574448244e-06,
      "loss": 0.0332,
      "step": 4236
    },
    {
      "epoch": 0.32926639726453216,
      "grad_norm": 0.1340394914150238,
      "learning_rate": 8.35366801367734e-06,
      "loss": 0.0276,
      "step": 4237
    },
    {
      "epoch": 0.32934410941871306,
      "grad_norm": 0.16416944563388824,
      "learning_rate": 8.353279452906436e-06,
      "loss": 0.0905,
      "step": 4238
    },
    {
      "epoch": 0.329421821572894,
      "grad_norm": 0.31949687004089355,
      "learning_rate": 8.352890892135531e-06,
      "loss": 0.3123,
      "step": 4239
    },
    {
      "epoch": 0.3294995337270749,
      "grad_norm": 0.2740880250930786,
      "learning_rate": 8.352502331364626e-06,
      "loss": 0.2401,
      "step": 4240
    },
    {
      "epoch": 0.3295772458812558,
      "grad_norm": 0.3574793040752411,
      "learning_rate": 8.352113770593722e-06,
      "loss": 0.4676,
      "step": 4241
    },
    {
      "epoch": 0.32965495803543676,
      "grad_norm": 0.19663043320178986,
      "learning_rate": 8.351725209822817e-06,
      "loss": 0.1739,
      "step": 4242
    },
    {
      "epoch": 0.32973267018961766,
      "grad_norm": 0.4578710198402405,
      "learning_rate": 8.351336649051912e-06,
      "loss": 0.1019,
      "step": 4243
    },
    {
      "epoch": 0.32981038234379856,
      "grad_norm": 0.5776473879814148,
      "learning_rate": 8.350948088281007e-06,
      "loss": 0.3891,
      "step": 4244
    },
    {
      "epoch": 0.3298880944979795,
      "grad_norm": 0.36364999413490295,
      "learning_rate": 8.350559527510104e-06,
      "loss": 0.2191,
      "step": 4245
    },
    {
      "epoch": 0.3299658066521604,
      "grad_norm": 0.49447229504585266,
      "learning_rate": 8.350170966739199e-06,
      "loss": 0.3127,
      "step": 4246
    },
    {
      "epoch": 0.3300435188063413,
      "grad_norm": 0.230502188205719,
      "learning_rate": 8.349782405968294e-06,
      "loss": 0.0551,
      "step": 4247
    },
    {
      "epoch": 0.3301212309605222,
      "grad_norm": 0.1986672729253769,
      "learning_rate": 8.34939384519739e-06,
      "loss": 0.063,
      "step": 4248
    },
    {
      "epoch": 0.33019894311470316,
      "grad_norm": 0.6601620316505432,
      "learning_rate": 8.349005284426485e-06,
      "loss": 0.0745,
      "step": 4249
    },
    {
      "epoch": 0.33027665526888406,
      "grad_norm": 0.46453991532325745,
      "learning_rate": 8.34861672365558e-06,
      "loss": 0.187,
      "step": 4250
    },
    {
      "epoch": 0.33035436742306495,
      "grad_norm": 0.24072155356407166,
      "learning_rate": 8.348228162884675e-06,
      "loss": 0.1542,
      "step": 4251
    },
    {
      "epoch": 0.3304320795772459,
      "grad_norm": 0.589156448841095,
      "learning_rate": 8.34783960211377e-06,
      "loss": 0.1518,
      "step": 4252
    },
    {
      "epoch": 0.3305097917314268,
      "grad_norm": 0.15218743681907654,
      "learning_rate": 8.347451041342867e-06,
      "loss": 0.076,
      "step": 4253
    },
    {
      "epoch": 0.3305875038856077,
      "grad_norm": 0.25545236468315125,
      "learning_rate": 8.347062480571962e-06,
      "loss": 0.0566,
      "step": 4254
    },
    {
      "epoch": 0.3306652160397886,
      "grad_norm": 0.13470973074436188,
      "learning_rate": 8.346673919801057e-06,
      "loss": 0.0368,
      "step": 4255
    },
    {
      "epoch": 0.33074292819396955,
      "grad_norm": 0.08515262603759766,
      "learning_rate": 8.346285359030153e-06,
      "loss": 0.0521,
      "step": 4256
    },
    {
      "epoch": 0.33082064034815045,
      "grad_norm": 0.6361961364746094,
      "learning_rate": 8.345896798259248e-06,
      "loss": 0.7375,
      "step": 4257
    },
    {
      "epoch": 0.33089835250233135,
      "grad_norm": 0.15939879417419434,
      "learning_rate": 8.345508237488343e-06,
      "loss": 0.1669,
      "step": 4258
    },
    {
      "epoch": 0.3309760646565123,
      "grad_norm": 0.6737861633300781,
      "learning_rate": 8.345119676717438e-06,
      "loss": 0.3814,
      "step": 4259
    },
    {
      "epoch": 0.3310537768106932,
      "grad_norm": 0.33971017599105835,
      "learning_rate": 8.344731115946535e-06,
      "loss": 0.181,
      "step": 4260
    },
    {
      "epoch": 0.3311314889648741,
      "grad_norm": 0.44150879979133606,
      "learning_rate": 8.34434255517563e-06,
      "loss": 0.2622,
      "step": 4261
    },
    {
      "epoch": 0.331209201119055,
      "grad_norm": 0.4272356927394867,
      "learning_rate": 8.343953994404725e-06,
      "loss": 0.2199,
      "step": 4262
    },
    {
      "epoch": 0.33128691327323595,
      "grad_norm": 0.20107890665531158,
      "learning_rate": 8.343565433633822e-06,
      "loss": 0.0852,
      "step": 4263
    },
    {
      "epoch": 0.33136462542741685,
      "grad_norm": 0.4697668254375458,
      "learning_rate": 8.343176872862916e-06,
      "loss": 0.4205,
      "step": 4264
    },
    {
      "epoch": 0.33144233758159775,
      "grad_norm": 0.21956002712249756,
      "learning_rate": 8.342788312092011e-06,
      "loss": 0.0664,
      "step": 4265
    },
    {
      "epoch": 0.3315200497357787,
      "grad_norm": 0.3918372094631195,
      "learning_rate": 8.342399751321108e-06,
      "loss": 0.348,
      "step": 4266
    },
    {
      "epoch": 0.3315977618899596,
      "grad_norm": 0.34912171959877014,
      "learning_rate": 8.342011190550203e-06,
      "loss": 0.2195,
      "step": 4267
    },
    {
      "epoch": 0.3316754740441405,
      "grad_norm": 0.4442375600337982,
      "learning_rate": 8.341622629779298e-06,
      "loss": 0.3637,
      "step": 4268
    },
    {
      "epoch": 0.3317531861983214,
      "grad_norm": 0.24763555824756622,
      "learning_rate": 8.341234069008393e-06,
      "loss": 0.1536,
      "step": 4269
    },
    {
      "epoch": 0.33183089835250235,
      "grad_norm": 0.3305835723876953,
      "learning_rate": 8.34084550823749e-06,
      "loss": 0.474,
      "step": 4270
    },
    {
      "epoch": 0.33190861050668324,
      "grad_norm": 0.07400823384523392,
      "learning_rate": 8.340456947466585e-06,
      "loss": 0.0204,
      "step": 4271
    },
    {
      "epoch": 0.33198632266086414,
      "grad_norm": 0.1464257687330246,
      "learning_rate": 8.34006838669568e-06,
      "loss": 0.1075,
      "step": 4272
    },
    {
      "epoch": 0.3320640348150451,
      "grad_norm": 0.6280048489570618,
      "learning_rate": 8.339679825924776e-06,
      "loss": 0.528,
      "step": 4273
    },
    {
      "epoch": 0.332141746969226,
      "grad_norm": 0.8102632164955139,
      "learning_rate": 8.339291265153871e-06,
      "loss": 1.1167,
      "step": 4274
    },
    {
      "epoch": 0.3322194591234069,
      "grad_norm": 0.43007010221481323,
      "learning_rate": 8.338902704382966e-06,
      "loss": 0.1257,
      "step": 4275
    },
    {
      "epoch": 0.3322971712775878,
      "grad_norm": 0.1959446668624878,
      "learning_rate": 8.338514143612063e-06,
      "loss": 0.0485,
      "step": 4276
    },
    {
      "epoch": 0.33237488343176874,
      "grad_norm": 0.21173150837421417,
      "learning_rate": 8.338125582841156e-06,
      "loss": 0.0242,
      "step": 4277
    },
    {
      "epoch": 0.33245259558594964,
      "grad_norm": 0.38997870683670044,
      "learning_rate": 8.337737022070253e-06,
      "loss": 0.6246,
      "step": 4278
    },
    {
      "epoch": 0.33253030774013054,
      "grad_norm": 0.39494654536247253,
      "learning_rate": 8.337348461299348e-06,
      "loss": 0.1662,
      "step": 4279
    },
    {
      "epoch": 0.3326080198943115,
      "grad_norm": 0.2192380726337433,
      "learning_rate": 8.336959900528442e-06,
      "loss": 0.1244,
      "step": 4280
    },
    {
      "epoch": 0.3326857320484924,
      "grad_norm": 7.130942344665527,
      "learning_rate": 8.336571339757539e-06,
      "loss": 3.7821,
      "step": 4281
    },
    {
      "epoch": 0.3327634442026733,
      "grad_norm": 0.748449444770813,
      "learning_rate": 8.336182778986634e-06,
      "loss": 0.2741,
      "step": 4282
    },
    {
      "epoch": 0.33284115635685424,
      "grad_norm": 0.0661454126238823,
      "learning_rate": 8.335794218215729e-06,
      "loss": 0.0061,
      "step": 4283
    },
    {
      "epoch": 0.33291886851103514,
      "grad_norm": 0.5168960690498352,
      "learning_rate": 8.335405657444826e-06,
      "loss": 0.2607,
      "step": 4284
    },
    {
      "epoch": 0.33299658066521604,
      "grad_norm": 0.18079523742198944,
      "learning_rate": 8.33501709667392e-06,
      "loss": 0.1285,
      "step": 4285
    },
    {
      "epoch": 0.33307429281939693,
      "grad_norm": 0.4239809215068817,
      "learning_rate": 8.334628535903016e-06,
      "loss": 0.1067,
      "step": 4286
    },
    {
      "epoch": 0.3331520049735779,
      "grad_norm": 0.6429277062416077,
      "learning_rate": 8.33423997513211e-06,
      "loss": 0.3333,
      "step": 4287
    },
    {
      "epoch": 0.3332297171277588,
      "grad_norm": 0.6958919167518616,
      "learning_rate": 8.333851414361207e-06,
      "loss": 0.2998,
      "step": 4288
    },
    {
      "epoch": 0.3333074292819397,
      "grad_norm": 0.0726858526468277,
      "learning_rate": 8.333462853590302e-06,
      "loss": 0.0243,
      "step": 4289
    },
    {
      "epoch": 0.33338514143612064,
      "grad_norm": 0.29528456926345825,
      "learning_rate": 8.333074292819397e-06,
      "loss": 0.1328,
      "step": 4290
    },
    {
      "epoch": 0.33346285359030153,
      "grad_norm": 0.12077866494655609,
      "learning_rate": 8.332685732048494e-06,
      "loss": 0.0617,
      "step": 4291
    },
    {
      "epoch": 0.33354056574448243,
      "grad_norm": 0.47814399003982544,
      "learning_rate": 8.332297171277589e-06,
      "loss": 0.2477,
      "step": 4292
    },
    {
      "epoch": 0.33361827789866333,
      "grad_norm": 0.6543601155281067,
      "learning_rate": 8.331908610506684e-06,
      "loss": 0.3777,
      "step": 4293
    },
    {
      "epoch": 0.3336959900528443,
      "grad_norm": 0.6707369089126587,
      "learning_rate": 8.33152004973578e-06,
      "loss": 0.9485,
      "step": 4294
    },
    {
      "epoch": 0.3337737022070252,
      "grad_norm": 0.41909152269363403,
      "learning_rate": 8.331131488964875e-06,
      "loss": 0.1265,
      "step": 4295
    },
    {
      "epoch": 0.3338514143612061,
      "grad_norm": 0.20208929479122162,
      "learning_rate": 8.33074292819397e-06,
      "loss": 0.0471,
      "step": 4296
    },
    {
      "epoch": 0.33392912651538703,
      "grad_norm": 0.37570133805274963,
      "learning_rate": 8.330354367423065e-06,
      "loss": 0.0497,
      "step": 4297
    },
    {
      "epoch": 0.33400683866956793,
      "grad_norm": 0.18009498715400696,
      "learning_rate": 8.329965806652162e-06,
      "loss": 0.2176,
      "step": 4298
    },
    {
      "epoch": 0.3340845508237488,
      "grad_norm": 0.3001267611980438,
      "learning_rate": 8.329577245881257e-06,
      "loss": 0.0635,
      "step": 4299
    },
    {
      "epoch": 0.3341622629779297,
      "grad_norm": 0.206398606300354,
      "learning_rate": 8.329188685110352e-06,
      "loss": 0.1049,
      "step": 4300
    },
    {
      "epoch": 0.3342399751321107,
      "grad_norm": 0.6423159837722778,
      "learning_rate": 8.328800124339448e-06,
      "loss": 0.2909,
      "step": 4301
    },
    {
      "epoch": 0.3343176872862916,
      "grad_norm": 0.37190183997154236,
      "learning_rate": 8.328411563568543e-06,
      "loss": 0.1616,
      "step": 4302
    },
    {
      "epoch": 0.3343953994404725,
      "grad_norm": 0.21426063776016235,
      "learning_rate": 8.328023002797638e-06,
      "loss": 0.0374,
      "step": 4303
    },
    {
      "epoch": 0.3344731115946534,
      "grad_norm": 0.7703372836112976,
      "learning_rate": 8.327634442026735e-06,
      "loss": 0.1691,
      "step": 4304
    },
    {
      "epoch": 0.3345508237488343,
      "grad_norm": 0.5975857377052307,
      "learning_rate": 8.327245881255828e-06,
      "loss": 0.3451,
      "step": 4305
    },
    {
      "epoch": 0.3346285359030152,
      "grad_norm": 0.08086249977350235,
      "learning_rate": 8.326857320484925e-06,
      "loss": 0.0131,
      "step": 4306
    },
    {
      "epoch": 0.3347062480571961,
      "grad_norm": 0.17563343048095703,
      "learning_rate": 8.32646875971402e-06,
      "loss": 0.1658,
      "step": 4307
    },
    {
      "epoch": 0.3347839602113771,
      "grad_norm": 0.2812390625476837,
      "learning_rate": 8.326080198943115e-06,
      "loss": 0.155,
      "step": 4308
    },
    {
      "epoch": 0.33486167236555797,
      "grad_norm": 0.6352200508117676,
      "learning_rate": 8.325691638172211e-06,
      "loss": 0.5087,
      "step": 4309
    },
    {
      "epoch": 0.33493938451973887,
      "grad_norm": 0.3213706314563751,
      "learning_rate": 8.325303077401306e-06,
      "loss": 0.0721,
      "step": 4310
    },
    {
      "epoch": 0.3350170966739198,
      "grad_norm": 0.9647884964942932,
      "learning_rate": 8.324914516630401e-06,
      "loss": 0.2356,
      "step": 4311
    },
    {
      "epoch": 0.3350948088281007,
      "grad_norm": 0.4095231890678406,
      "learning_rate": 8.324525955859498e-06,
      "loss": 0.2768,
      "step": 4312
    },
    {
      "epoch": 0.3351725209822816,
      "grad_norm": 0.6869603395462036,
      "learning_rate": 8.324137395088593e-06,
      "loss": 0.5903,
      "step": 4313
    },
    {
      "epoch": 0.3352502331364625,
      "grad_norm": 0.33709976077079773,
      "learning_rate": 8.323748834317688e-06,
      "loss": 0.1347,
      "step": 4314
    },
    {
      "epoch": 0.33532794529064347,
      "grad_norm": 0.2860832214355469,
      "learning_rate": 8.323360273546783e-06,
      "loss": 0.0944,
      "step": 4315
    },
    {
      "epoch": 0.33540565744482437,
      "grad_norm": 0.1407582014799118,
      "learning_rate": 8.32297171277588e-06,
      "loss": 0.1132,
      "step": 4316
    },
    {
      "epoch": 0.33548336959900527,
      "grad_norm": 0.5255858302116394,
      "learning_rate": 8.322583152004974e-06,
      "loss": 0.2585,
      "step": 4317
    },
    {
      "epoch": 0.3355610817531862,
      "grad_norm": 0.0674232542514801,
      "learning_rate": 8.32219459123407e-06,
      "loss": 0.0197,
      "step": 4318
    },
    {
      "epoch": 0.3356387939073671,
      "grad_norm": 0.14079934358596802,
      "learning_rate": 8.321806030463166e-06,
      "loss": 0.0565,
      "step": 4319
    },
    {
      "epoch": 0.335716506061548,
      "grad_norm": 0.0718807727098465,
      "learning_rate": 8.32141746969226e-06,
      "loss": 0.0245,
      "step": 4320
    },
    {
      "epoch": 0.3357942182157289,
      "grad_norm": 0.2614544630050659,
      "learning_rate": 8.321028908921356e-06,
      "loss": 0.0918,
      "step": 4321
    },
    {
      "epoch": 0.33587193036990987,
      "grad_norm": 0.5255246162414551,
      "learning_rate": 8.320640348150452e-06,
      "loss": 0.2871,
      "step": 4322
    },
    {
      "epoch": 0.33594964252409076,
      "grad_norm": 0.30706652998924255,
      "learning_rate": 8.320251787379546e-06,
      "loss": 0.1354,
      "step": 4323
    },
    {
      "epoch": 0.33602735467827166,
      "grad_norm": 0.27184489369392395,
      "learning_rate": 8.319863226608642e-06,
      "loss": 0.3414,
      "step": 4324
    },
    {
      "epoch": 0.3361050668324526,
      "grad_norm": 0.2199421525001526,
      "learning_rate": 8.319474665837737e-06,
      "loss": 0.1841,
      "step": 4325
    },
    {
      "epoch": 0.3361827789866335,
      "grad_norm": 0.6310422420501709,
      "learning_rate": 8.319086105066834e-06,
      "loss": 0.3958,
      "step": 4326
    },
    {
      "epoch": 0.3362604911408144,
      "grad_norm": 0.23012791574001312,
      "learning_rate": 8.318697544295929e-06,
      "loss": 0.0625,
      "step": 4327
    },
    {
      "epoch": 0.33633820329499536,
      "grad_norm": 0.7505234479904175,
      "learning_rate": 8.318308983525024e-06,
      "loss": 0.129,
      "step": 4328
    },
    {
      "epoch": 0.33641591544917626,
      "grad_norm": 0.3320600390434265,
      "learning_rate": 8.31792042275412e-06,
      "loss": 0.316,
      "step": 4329
    },
    {
      "epoch": 0.33649362760335716,
      "grad_norm": 0.34792619943618774,
      "learning_rate": 8.317531861983215e-06,
      "loss": 0.1762,
      "step": 4330
    },
    {
      "epoch": 0.33657133975753806,
      "grad_norm": 0.343795508146286,
      "learning_rate": 8.31714330121231e-06,
      "loss": 0.272,
      "step": 4331
    },
    {
      "epoch": 0.336649051911719,
      "grad_norm": 0.10789893567562103,
      "learning_rate": 8.316754740441407e-06,
      "loss": 0.0375,
      "step": 4332
    },
    {
      "epoch": 0.3367267640658999,
      "grad_norm": 0.13639818131923676,
      "learning_rate": 8.3163661796705e-06,
      "loss": 0.0913,
      "step": 4333
    },
    {
      "epoch": 0.3368044762200808,
      "grad_norm": 0.24189545214176178,
      "learning_rate": 8.315977618899597e-06,
      "loss": 0.167,
      "step": 4334
    },
    {
      "epoch": 0.33688218837426176,
      "grad_norm": 0.21251556277275085,
      "learning_rate": 8.315589058128692e-06,
      "loss": 0.1461,
      "step": 4335
    },
    {
      "epoch": 0.33695990052844266,
      "grad_norm": 0.411130428314209,
      "learning_rate": 8.315200497357787e-06,
      "loss": 0.1073,
      "step": 4336
    },
    {
      "epoch": 0.33703761268262356,
      "grad_norm": 0.34346088767051697,
      "learning_rate": 8.314811936586883e-06,
      "loss": 0.4637,
      "step": 4337
    },
    {
      "epoch": 0.33711532483680445,
      "grad_norm": 0.534814178943634,
      "learning_rate": 8.314423375815978e-06,
      "loss": 0.5705,
      "step": 4338
    },
    {
      "epoch": 0.3371930369909854,
      "grad_norm": 0.3743421137332916,
      "learning_rate": 8.314034815045073e-06,
      "loss": 0.1417,
      "step": 4339
    },
    {
      "epoch": 0.3372707491451663,
      "grad_norm": 0.690751314163208,
      "learning_rate": 8.31364625427417e-06,
      "loss": 0.6113,
      "step": 4340
    },
    {
      "epoch": 0.3373484612993472,
      "grad_norm": 0.3854754865169525,
      "learning_rate": 8.313257693503265e-06,
      "loss": 0.2949,
      "step": 4341
    },
    {
      "epoch": 0.33742617345352816,
      "grad_norm": 0.784504771232605,
      "learning_rate": 8.31286913273236e-06,
      "loss": 0.3159,
      "step": 4342
    },
    {
      "epoch": 0.33750388560770905,
      "grad_norm": 0.503507137298584,
      "learning_rate": 8.312480571961455e-06,
      "loss": 0.3873,
      "step": 4343
    },
    {
      "epoch": 0.33758159776188995,
      "grad_norm": 0.28648263216018677,
      "learning_rate": 8.312092011190551e-06,
      "loss": 0.0684,
      "step": 4344
    },
    {
      "epoch": 0.33765930991607085,
      "grad_norm": 0.21904437243938446,
      "learning_rate": 8.311703450419646e-06,
      "loss": 0.0959,
      "step": 4345
    },
    {
      "epoch": 0.3377370220702518,
      "grad_norm": 0.28475111722946167,
      "learning_rate": 8.311314889648741e-06,
      "loss": 0.0976,
      "step": 4346
    },
    {
      "epoch": 0.3378147342244327,
      "grad_norm": 0.5750284790992737,
      "learning_rate": 8.310926328877838e-06,
      "loss": 0.4805,
      "step": 4347
    },
    {
      "epoch": 0.3378924463786136,
      "grad_norm": 0.4269523322582245,
      "learning_rate": 8.310537768106933e-06,
      "loss": 0.1224,
      "step": 4348
    },
    {
      "epoch": 0.33797015853279455,
      "grad_norm": 1.0614511966705322,
      "learning_rate": 8.310149207336028e-06,
      "loss": 0.2777,
      "step": 4349
    },
    {
      "epoch": 0.33804787068697545,
      "grad_norm": 0.3613906502723694,
      "learning_rate": 8.309760646565125e-06,
      "loss": 0.2451,
      "step": 4350
    },
    {
      "epoch": 0.33812558284115635,
      "grad_norm": 0.45882800221443176,
      "learning_rate": 8.309372085794218e-06,
      "loss": 0.1244,
      "step": 4351
    },
    {
      "epoch": 0.33820329499533724,
      "grad_norm": 0.5156020522117615,
      "learning_rate": 8.308983525023314e-06,
      "loss": 0.156,
      "step": 4352
    },
    {
      "epoch": 0.3382810071495182,
      "grad_norm": 0.24298696219921112,
      "learning_rate": 8.30859496425241e-06,
      "loss": 0.1013,
      "step": 4353
    },
    {
      "epoch": 0.3383587193036991,
      "grad_norm": 0.16327030956745148,
      "learning_rate": 8.308206403481504e-06,
      "loss": 0.1232,
      "step": 4354
    },
    {
      "epoch": 0.33843643145788,
      "grad_norm": 0.29204073548316956,
      "learning_rate": 8.307817842710601e-06,
      "loss": 0.2013,
      "step": 4355
    },
    {
      "epoch": 0.33851414361206095,
      "grad_norm": 1.2211406230926514,
      "learning_rate": 8.307429281939696e-06,
      "loss": 0.2728,
      "step": 4356
    },
    {
      "epoch": 0.33859185576624184,
      "grad_norm": 0.2920275032520294,
      "learning_rate": 8.307040721168793e-06,
      "loss": 0.0694,
      "step": 4357
    },
    {
      "epoch": 0.33866956792042274,
      "grad_norm": 0.14543281495571136,
      "learning_rate": 8.306652160397887e-06,
      "loss": 0.0471,
      "step": 4358
    },
    {
      "epoch": 0.33874728007460364,
      "grad_norm": 0.23653696477413177,
      "learning_rate": 8.306263599626982e-06,
      "loss": 0.0729,
      "step": 4359
    },
    {
      "epoch": 0.3388249922287846,
      "grad_norm": 0.3235248923301697,
      "learning_rate": 8.305875038856079e-06,
      "loss": 0.2269,
      "step": 4360
    },
    {
      "epoch": 0.3389027043829655,
      "grad_norm": 0.6480511426925659,
      "learning_rate": 8.305486478085172e-06,
      "loss": 0.3304,
      "step": 4361
    },
    {
      "epoch": 0.3389804165371464,
      "grad_norm": 0.1119370087981224,
      "learning_rate": 8.305097917314269e-06,
      "loss": 0.0321,
      "step": 4362
    },
    {
      "epoch": 0.33905812869132734,
      "grad_norm": 0.7612937092781067,
      "learning_rate": 8.304709356543364e-06,
      "loss": 0.2028,
      "step": 4363
    },
    {
      "epoch": 0.33913584084550824,
      "grad_norm": 0.3705401122570038,
      "learning_rate": 8.304320795772459e-06,
      "loss": 0.0716,
      "step": 4364
    },
    {
      "epoch": 0.33921355299968914,
      "grad_norm": 0.2854240834712982,
      "learning_rate": 8.303932235001556e-06,
      "loss": 0.1709,
      "step": 4365
    },
    {
      "epoch": 0.3392912651538701,
      "grad_norm": 0.4065142571926117,
      "learning_rate": 8.30354367423065e-06,
      "loss": 0.2355,
      "step": 4366
    },
    {
      "epoch": 0.339368977308051,
      "grad_norm": 0.39992132782936096,
      "learning_rate": 8.303155113459745e-06,
      "loss": 0.2025,
      "step": 4367
    },
    {
      "epoch": 0.3394466894622319,
      "grad_norm": 0.300880491733551,
      "learning_rate": 8.302766552688842e-06,
      "loss": 0.1613,
      "step": 4368
    },
    {
      "epoch": 0.3395244016164128,
      "grad_norm": 0.27922043204307556,
      "learning_rate": 8.302377991917937e-06,
      "loss": 0.2445,
      "step": 4369
    },
    {
      "epoch": 0.33960211377059374,
      "grad_norm": 0.1484987884759903,
      "learning_rate": 8.301989431147032e-06,
      "loss": 0.0244,
      "step": 4370
    },
    {
      "epoch": 0.33967982592477464,
      "grad_norm": 0.32424744963645935,
      "learning_rate": 8.301600870376127e-06,
      "loss": 0.1255,
      "step": 4371
    },
    {
      "epoch": 0.33975753807895553,
      "grad_norm": 0.5684611201286316,
      "learning_rate": 8.301212309605224e-06,
      "loss": 0.3838,
      "step": 4372
    },
    {
      "epoch": 0.3398352502331365,
      "grad_norm": 0.22521646320819855,
      "learning_rate": 8.300823748834319e-06,
      "loss": 0.0523,
      "step": 4373
    },
    {
      "epoch": 0.3399129623873174,
      "grad_norm": 0.22864219546318054,
      "learning_rate": 8.300435188063413e-06,
      "loss": 0.0813,
      "step": 4374
    },
    {
      "epoch": 0.3399906745414983,
      "grad_norm": 0.9241098165512085,
      "learning_rate": 8.30004662729251e-06,
      "loss": 0.5671,
      "step": 4375
    },
    {
      "epoch": 0.3400683866956792,
      "grad_norm": 0.7555936574935913,
      "learning_rate": 8.299658066521603e-06,
      "loss": 0.4211,
      "step": 4376
    },
    {
      "epoch": 0.34014609884986013,
      "grad_norm": 0.30975884199142456,
      "learning_rate": 8.2992695057507e-06,
      "loss": 0.2423,
      "step": 4377
    },
    {
      "epoch": 0.34022381100404103,
      "grad_norm": 0.516611635684967,
      "learning_rate": 8.298880944979795e-06,
      "loss": 0.19,
      "step": 4378
    },
    {
      "epoch": 0.34030152315822193,
      "grad_norm": 0.24780993163585663,
      "learning_rate": 8.29849238420889e-06,
      "loss": 0.1104,
      "step": 4379
    },
    {
      "epoch": 0.3403792353124029,
      "grad_norm": 0.31228360533714294,
      "learning_rate": 8.298103823437987e-06,
      "loss": 0.0784,
      "step": 4380
    },
    {
      "epoch": 0.3404569474665838,
      "grad_norm": 0.44285744428634644,
      "learning_rate": 8.297715262667082e-06,
      "loss": 0.2983,
      "step": 4381
    },
    {
      "epoch": 0.3405346596207647,
      "grad_norm": 0.32215434312820435,
      "learning_rate": 8.297326701896176e-06,
      "loss": 0.7131,
      "step": 4382
    },
    {
      "epoch": 0.3406123717749456,
      "grad_norm": 0.1426520198583603,
      "learning_rate": 8.296938141125273e-06,
      "loss": 0.077,
      "step": 4383
    },
    {
      "epoch": 0.34069008392912653,
      "grad_norm": 0.28609734773635864,
      "learning_rate": 8.296549580354368e-06,
      "loss": 0.3991,
      "step": 4384
    },
    {
      "epoch": 0.34076779608330743,
      "grad_norm": 0.3478125333786011,
      "learning_rate": 8.296161019583463e-06,
      "loss": 0.3056,
      "step": 4385
    },
    {
      "epoch": 0.3408455082374883,
      "grad_norm": 0.6447163224220276,
      "learning_rate": 8.295772458812558e-06,
      "loss": 0.3688,
      "step": 4386
    },
    {
      "epoch": 0.3409232203916693,
      "grad_norm": 0.39204809069633484,
      "learning_rate": 8.295383898041655e-06,
      "loss": 0.0982,
      "step": 4387
    },
    {
      "epoch": 0.3410009325458502,
      "grad_norm": 0.2541835904121399,
      "learning_rate": 8.29499533727075e-06,
      "loss": 0.1228,
      "step": 4388
    },
    {
      "epoch": 0.3410786447000311,
      "grad_norm": 0.45153120160102844,
      "learning_rate": 8.294606776499844e-06,
      "loss": 0.0919,
      "step": 4389
    },
    {
      "epoch": 0.341156356854212,
      "grad_norm": 0.7634017467498779,
      "learning_rate": 8.294218215728941e-06,
      "loss": 1.0785,
      "step": 4390
    },
    {
      "epoch": 0.3412340690083929,
      "grad_norm": 0.1054120883345604,
      "learning_rate": 8.293829654958036e-06,
      "loss": 0.0501,
      "step": 4391
    },
    {
      "epoch": 0.3413117811625738,
      "grad_norm": 0.25556403398513794,
      "learning_rate": 8.293441094187131e-06,
      "loss": 0.0539,
      "step": 4392
    },
    {
      "epoch": 0.3413894933167547,
      "grad_norm": 1.0004273653030396,
      "learning_rate": 8.293052533416228e-06,
      "loss": 0.5214,
      "step": 4393
    },
    {
      "epoch": 0.3414672054709357,
      "grad_norm": 0.6970291137695312,
      "learning_rate": 8.292663972645323e-06,
      "loss": 0.2143,
      "step": 4394
    },
    {
      "epoch": 0.3415449176251166,
      "grad_norm": 0.41256117820739746,
      "learning_rate": 8.292275411874418e-06,
      "loss": 0.4178,
      "step": 4395
    },
    {
      "epoch": 0.34162262977929747,
      "grad_norm": 0.2774294316768646,
      "learning_rate": 8.291886851103513e-06,
      "loss": 0.1285,
      "step": 4396
    },
    {
      "epoch": 0.34170034193347837,
      "grad_norm": 0.43677738308906555,
      "learning_rate": 8.29149829033261e-06,
      "loss": 0.0773,
      "step": 4397
    },
    {
      "epoch": 0.3417780540876593,
      "grad_norm": 0.6478081345558167,
      "learning_rate": 8.291109729561704e-06,
      "loss": 0.1544,
      "step": 4398
    },
    {
      "epoch": 0.3418557662418402,
      "grad_norm": 0.1501866728067398,
      "learning_rate": 8.290721168790799e-06,
      "loss": 0.0655,
      "step": 4399
    },
    {
      "epoch": 0.3419334783960211,
      "grad_norm": 0.3208141326904297,
      "learning_rate": 8.290332608019896e-06,
      "loss": 0.1948,
      "step": 4400
    },
    {
      "epoch": 0.34201119055020207,
      "grad_norm": 0.39015546441078186,
      "learning_rate": 8.28994404724899e-06,
      "loss": 0.0833,
      "step": 4401
    },
    {
      "epoch": 0.34208890270438297,
      "grad_norm": 0.3755781650543213,
      "learning_rate": 8.289555486478086e-06,
      "loss": 0.1734,
      "step": 4402
    },
    {
      "epoch": 0.34216661485856387,
      "grad_norm": 0.2820712625980377,
      "learning_rate": 8.289166925707182e-06,
      "loss": 0.0944,
      "step": 4403
    },
    {
      "epoch": 0.3422443270127448,
      "grad_norm": 0.4376765191555023,
      "learning_rate": 8.288778364936276e-06,
      "loss": 0.3039,
      "step": 4404
    },
    {
      "epoch": 0.3423220391669257,
      "grad_norm": 0.14828570187091827,
      "learning_rate": 8.288389804165372e-06,
      "loss": 0.061,
      "step": 4405
    },
    {
      "epoch": 0.3423997513211066,
      "grad_norm": 0.6142695546150208,
      "learning_rate": 8.288001243394467e-06,
      "loss": 0.3552,
      "step": 4406
    },
    {
      "epoch": 0.3424774634752875,
      "grad_norm": 0.8502823114395142,
      "learning_rate": 8.287612682623562e-06,
      "loss": 0.2802,
      "step": 4407
    },
    {
      "epoch": 0.34255517562946847,
      "grad_norm": 0.4549318253993988,
      "learning_rate": 8.287224121852659e-06,
      "loss": 0.1983,
      "step": 4408
    },
    {
      "epoch": 0.34263288778364936,
      "grad_norm": 0.20479032397270203,
      "learning_rate": 8.286835561081754e-06,
      "loss": 0.0672,
      "step": 4409
    },
    {
      "epoch": 0.34271059993783026,
      "grad_norm": 0.6225382089614868,
      "learning_rate": 8.286447000310849e-06,
      "loss": 0.5466,
      "step": 4410
    },
    {
      "epoch": 0.3427883120920112,
      "grad_norm": 0.1394294947385788,
      "learning_rate": 8.286058439539945e-06,
      "loss": 0.0552,
      "step": 4411
    },
    {
      "epoch": 0.3428660242461921,
      "grad_norm": 0.9022563695907593,
      "learning_rate": 8.28566987876904e-06,
      "loss": 0.2969,
      "step": 4412
    },
    {
      "epoch": 0.342943736400373,
      "grad_norm": 0.8957381844520569,
      "learning_rate": 8.285281317998135e-06,
      "loss": 0.7663,
      "step": 4413
    },
    {
      "epoch": 0.3430214485545539,
      "grad_norm": 2.809903144836426,
      "learning_rate": 8.28489275722723e-06,
      "loss": 1.158,
      "step": 4414
    },
    {
      "epoch": 0.34309916070873486,
      "grad_norm": 0.46782606840133667,
      "learning_rate": 8.284504196456327e-06,
      "loss": 0.6557,
      "step": 4415
    },
    {
      "epoch": 0.34317687286291576,
      "grad_norm": 0.20746774971485138,
      "learning_rate": 8.284115635685422e-06,
      "loss": 0.0884,
      "step": 4416
    },
    {
      "epoch": 0.34325458501709666,
      "grad_norm": 0.17321491241455078,
      "learning_rate": 8.283727074914517e-06,
      "loss": 0.0819,
      "step": 4417
    },
    {
      "epoch": 0.3433322971712776,
      "grad_norm": 0.47929900884628296,
      "learning_rate": 8.283338514143613e-06,
      "loss": 0.2327,
      "step": 4418
    },
    {
      "epoch": 0.3434100093254585,
      "grad_norm": 0.21587470173835754,
      "learning_rate": 8.282949953372708e-06,
      "loss": 0.0993,
      "step": 4419
    },
    {
      "epoch": 0.3434877214796394,
      "grad_norm": 1.127126693725586,
      "learning_rate": 8.282561392601803e-06,
      "loss": 0.4379,
      "step": 4420
    },
    {
      "epoch": 0.3435654336338203,
      "grad_norm": 0.5067404508590698,
      "learning_rate": 8.2821728318309e-06,
      "loss": 0.9012,
      "step": 4421
    },
    {
      "epoch": 0.34364314578800126,
      "grad_norm": 0.09188276529312134,
      "learning_rate": 8.281784271059995e-06,
      "loss": 0.0501,
      "step": 4422
    },
    {
      "epoch": 0.34372085794218216,
      "grad_norm": 0.4212089776992798,
      "learning_rate": 8.28139571028909e-06,
      "loss": 0.3733,
      "step": 4423
    },
    {
      "epoch": 0.34379857009636305,
      "grad_norm": 0.26118358969688416,
      "learning_rate": 8.281007149518185e-06,
      "loss": 0.1241,
      "step": 4424
    },
    {
      "epoch": 0.343876282250544,
      "grad_norm": 2.325502395629883,
      "learning_rate": 8.280618588747281e-06,
      "loss": 1.5226,
      "step": 4425
    },
    {
      "epoch": 0.3439539944047249,
      "grad_norm": 0.10141973197460175,
      "learning_rate": 8.280230027976376e-06,
      "loss": 0.0496,
      "step": 4426
    },
    {
      "epoch": 0.3440317065589058,
      "grad_norm": 0.09880951792001724,
      "learning_rate": 8.279841467205471e-06,
      "loss": 0.0473,
      "step": 4427
    },
    {
      "epoch": 0.3441094187130867,
      "grad_norm": 0.7684199810028076,
      "learning_rate": 8.279452906434568e-06,
      "loss": 0.4592,
      "step": 4428
    },
    {
      "epoch": 0.34418713086726765,
      "grad_norm": 0.5628560185432434,
      "learning_rate": 8.279064345663663e-06,
      "loss": 0.0641,
      "step": 4429
    },
    {
      "epoch": 0.34426484302144855,
      "grad_norm": 0.742891252040863,
      "learning_rate": 8.278675784892758e-06,
      "loss": 0.5103,
      "step": 4430
    },
    {
      "epoch": 0.34434255517562945,
      "grad_norm": 0.22531628608703613,
      "learning_rate": 8.278287224121854e-06,
      "loss": 0.0952,
      "step": 4431
    },
    {
      "epoch": 0.3444202673298104,
      "grad_norm": 0.7438414096832275,
      "learning_rate": 8.277898663350948e-06,
      "loss": 0.6681,
      "step": 4432
    },
    {
      "epoch": 0.3444979794839913,
      "grad_norm": 0.19596879184246063,
      "learning_rate": 8.277510102580044e-06,
      "loss": 0.0722,
      "step": 4433
    },
    {
      "epoch": 0.3445756916381722,
      "grad_norm": 0.28438857197761536,
      "learning_rate": 8.27712154180914e-06,
      "loss": 0.1169,
      "step": 4434
    },
    {
      "epoch": 0.3446534037923531,
      "grad_norm": 0.21871118247509003,
      "learning_rate": 8.276732981038234e-06,
      "loss": 0.0584,
      "step": 4435
    },
    {
      "epoch": 0.34473111594653405,
      "grad_norm": 0.19041472673416138,
      "learning_rate": 8.276344420267331e-06,
      "loss": 0.0949,
      "step": 4436
    },
    {
      "epoch": 0.34480882810071495,
      "grad_norm": 0.2676226794719696,
      "learning_rate": 8.275955859496426e-06,
      "loss": 0.2381,
      "step": 4437
    },
    {
      "epoch": 0.34488654025489585,
      "grad_norm": 0.055938564240932465,
      "learning_rate": 8.27556729872552e-06,
      "loss": 0.03,
      "step": 4438
    },
    {
      "epoch": 0.3449642524090768,
      "grad_norm": 0.8474403619766235,
      "learning_rate": 8.275178737954617e-06,
      "loss": 0.2841,
      "step": 4439
    },
    {
      "epoch": 0.3450419645632577,
      "grad_norm": 0.28471535444259644,
      "learning_rate": 8.274790177183712e-06,
      "loss": 0.0752,
      "step": 4440
    },
    {
      "epoch": 0.3451196767174386,
      "grad_norm": 1.134301781654358,
      "learning_rate": 8.274401616412807e-06,
      "loss": 0.6164,
      "step": 4441
    },
    {
      "epoch": 0.34519738887161955,
      "grad_norm": 0.28710025548934937,
      "learning_rate": 8.274013055641902e-06,
      "loss": 0.1707,
      "step": 4442
    },
    {
      "epoch": 0.34527510102580045,
      "grad_norm": 0.3691175878047943,
      "learning_rate": 8.273624494870999e-06,
      "loss": 0.2067,
      "step": 4443
    },
    {
      "epoch": 0.34535281317998134,
      "grad_norm": 0.3385758697986603,
      "learning_rate": 8.273235934100094e-06,
      "loss": 0.0397,
      "step": 4444
    },
    {
      "epoch": 0.34543052533416224,
      "grad_norm": 0.43446534872055054,
      "learning_rate": 8.272847373329189e-06,
      "loss": 0.6001,
      "step": 4445
    },
    {
      "epoch": 0.3455082374883432,
      "grad_norm": 0.2526013255119324,
      "learning_rate": 8.272458812558285e-06,
      "loss": 0.1218,
      "step": 4446
    },
    {
      "epoch": 0.3455859496425241,
      "grad_norm": 0.24014897644519806,
      "learning_rate": 8.27207025178738e-06,
      "loss": 0.1122,
      "step": 4447
    },
    {
      "epoch": 0.345663661796705,
      "grad_norm": 0.6344782114028931,
      "learning_rate": 8.271681691016475e-06,
      "loss": 0.4113,
      "step": 4448
    },
    {
      "epoch": 0.34574137395088594,
      "grad_norm": 0.1740349382162094,
      "learning_rate": 8.271293130245572e-06,
      "loss": 0.0422,
      "step": 4449
    },
    {
      "epoch": 0.34581908610506684,
      "grad_norm": 0.43258729577064514,
      "learning_rate": 8.270904569474667e-06,
      "loss": 0.4001,
      "step": 4450
    },
    {
      "epoch": 0.34589679825924774,
      "grad_norm": 0.16245269775390625,
      "learning_rate": 8.270516008703762e-06,
      "loss": 0.0811,
      "step": 4451
    },
    {
      "epoch": 0.34597451041342864,
      "grad_norm": 0.33964601159095764,
      "learning_rate": 8.270127447932857e-06,
      "loss": 0.2523,
      "step": 4452
    },
    {
      "epoch": 0.3460522225676096,
      "grad_norm": 0.3157428503036499,
      "learning_rate": 8.269738887161953e-06,
      "loss": 0.1794,
      "step": 4453
    },
    {
      "epoch": 0.3461299347217905,
      "grad_norm": 0.34440410137176514,
      "learning_rate": 8.269350326391048e-06,
      "loss": 0.1406,
      "step": 4454
    },
    {
      "epoch": 0.3462076468759714,
      "grad_norm": 0.6843549013137817,
      "learning_rate": 8.268961765620143e-06,
      "loss": 0.6578,
      "step": 4455
    },
    {
      "epoch": 0.34628535903015234,
      "grad_norm": 0.3835013210773468,
      "learning_rate": 8.26857320484924e-06,
      "loss": 0.1854,
      "step": 4456
    },
    {
      "epoch": 0.34636307118433324,
      "grad_norm": 0.4750764071941376,
      "learning_rate": 8.268184644078335e-06,
      "loss": 0.1372,
      "step": 4457
    },
    {
      "epoch": 0.34644078333851414,
      "grad_norm": 0.4150875210762024,
      "learning_rate": 8.26779608330743e-06,
      "loss": 0.2883,
      "step": 4458
    },
    {
      "epoch": 0.34651849549269503,
      "grad_norm": 0.45713335275650024,
      "learning_rate": 8.267407522536527e-06,
      "loss": 0.2425,
      "step": 4459
    },
    {
      "epoch": 0.346596207646876,
      "grad_norm": 0.3454197347164154,
      "learning_rate": 8.26701896176562e-06,
      "loss": 0.2284,
      "step": 4460
    },
    {
      "epoch": 0.3466739198010569,
      "grad_norm": 0.34864503145217896,
      "learning_rate": 8.266630400994716e-06,
      "loss": 0.2209,
      "step": 4461
    },
    {
      "epoch": 0.3467516319552378,
      "grad_norm": 0.2290220558643341,
      "learning_rate": 8.266241840223811e-06,
      "loss": 0.0991,
      "step": 4462
    },
    {
      "epoch": 0.34682934410941874,
      "grad_norm": 0.41673025488853455,
      "learning_rate": 8.265853279452906e-06,
      "loss": 0.3541,
      "step": 4463
    },
    {
      "epoch": 0.34690705626359963,
      "grad_norm": 0.6502739787101746,
      "learning_rate": 8.265464718682003e-06,
      "loss": 0.3835,
      "step": 4464
    },
    {
      "epoch": 0.34698476841778053,
      "grad_norm": 0.5766749382019043,
      "learning_rate": 8.265076157911098e-06,
      "loss": 0.2078,
      "step": 4465
    },
    {
      "epoch": 0.34706248057196143,
      "grad_norm": 0.2346380203962326,
      "learning_rate": 8.264687597140193e-06,
      "loss": 0.0685,
      "step": 4466
    },
    {
      "epoch": 0.3471401927261424,
      "grad_norm": 0.18845738470554352,
      "learning_rate": 8.26429903636929e-06,
      "loss": 0.0835,
      "step": 4467
    },
    {
      "epoch": 0.3472179048803233,
      "grad_norm": 0.7888187766075134,
      "learning_rate": 8.263910475598384e-06,
      "loss": 0.1782,
      "step": 4468
    },
    {
      "epoch": 0.3472956170345042,
      "grad_norm": 0.1760178506374359,
      "learning_rate": 8.26352191482748e-06,
      "loss": 0.0463,
      "step": 4469
    },
    {
      "epoch": 0.34737332918868513,
      "grad_norm": 0.22530615329742432,
      "learning_rate": 8.263133354056574e-06,
      "loss": 0.1425,
      "step": 4470
    },
    {
      "epoch": 0.34745104134286603,
      "grad_norm": 0.38053587079048157,
      "learning_rate": 8.262744793285671e-06,
      "loss": 0.1314,
      "step": 4471
    },
    {
      "epoch": 0.3475287534970469,
      "grad_norm": 0.5334651470184326,
      "learning_rate": 8.262356232514766e-06,
      "loss": 0.2923,
      "step": 4472
    },
    {
      "epoch": 0.3476064656512278,
      "grad_norm": 0.298665851354599,
      "learning_rate": 8.261967671743861e-06,
      "loss": 0.2304,
      "step": 4473
    },
    {
      "epoch": 0.3476841778054088,
      "grad_norm": 0.1488829106092453,
      "learning_rate": 8.261579110972958e-06,
      "loss": 0.0755,
      "step": 4474
    },
    {
      "epoch": 0.3477618899595897,
      "grad_norm": 0.5062716603279114,
      "learning_rate": 8.261190550202053e-06,
      "loss": 0.2964,
      "step": 4475
    },
    {
      "epoch": 0.3478396021137706,
      "grad_norm": 0.1231730505824089,
      "learning_rate": 8.260801989431147e-06,
      "loss": 0.1124,
      "step": 4476
    },
    {
      "epoch": 0.3479173142679515,
      "grad_norm": 0.20773309469223022,
      "learning_rate": 8.260413428660244e-06,
      "loss": 0.0402,
      "step": 4477
    },
    {
      "epoch": 0.3479950264221324,
      "grad_norm": 0.1958111971616745,
      "learning_rate": 8.260024867889339e-06,
      "loss": 0.0287,
      "step": 4478
    },
    {
      "epoch": 0.3480727385763133,
      "grad_norm": 0.326242595911026,
      "learning_rate": 8.259636307118434e-06,
      "loss": 0.1989,
      "step": 4479
    },
    {
      "epoch": 0.3481504507304943,
      "grad_norm": 0.31731629371643066,
      "learning_rate": 8.259247746347529e-06,
      "loss": 0.1177,
      "step": 4480
    },
    {
      "epoch": 0.3482281628846752,
      "grad_norm": 0.5029410123825073,
      "learning_rate": 8.258859185576626e-06,
      "loss": 0.4663,
      "step": 4481
    },
    {
      "epoch": 0.34830587503885607,
      "grad_norm": 0.21009773015975952,
      "learning_rate": 8.25847062480572e-06,
      "loss": 0.0752,
      "step": 4482
    },
    {
      "epoch": 0.34838358719303697,
      "grad_norm": 0.49527063965797424,
      "learning_rate": 8.258082064034816e-06,
      "loss": 0.3697,
      "step": 4483
    },
    {
      "epoch": 0.3484612993472179,
      "grad_norm": 0.24093176424503326,
      "learning_rate": 8.257693503263912e-06,
      "loss": 0.1007,
      "step": 4484
    },
    {
      "epoch": 0.3485390115013988,
      "grad_norm": 0.2717406153678894,
      "learning_rate": 8.257304942493007e-06,
      "loss": 0.123,
      "step": 4485
    },
    {
      "epoch": 0.3486167236555797,
      "grad_norm": 0.33562564849853516,
      "learning_rate": 8.256916381722102e-06,
      "loss": 0.1132,
      "step": 4486
    },
    {
      "epoch": 0.34869443580976067,
      "grad_norm": 0.5530438423156738,
      "learning_rate": 8.256527820951199e-06,
      "loss": 0.1757,
      "step": 4487
    },
    {
      "epoch": 0.34877214796394157,
      "grad_norm": 0.23442453145980835,
      "learning_rate": 8.256139260180292e-06,
      "loss": 0.095,
      "step": 4488
    },
    {
      "epoch": 0.34884986011812247,
      "grad_norm": 0.683703601360321,
      "learning_rate": 8.255750699409389e-06,
      "loss": 0.2958,
      "step": 4489
    },
    {
      "epoch": 0.34892757227230337,
      "grad_norm": 0.5253425240516663,
      "learning_rate": 8.255362138638484e-06,
      "loss": 0.4008,
      "step": 4490
    },
    {
      "epoch": 0.3490052844264843,
      "grad_norm": 1.2906088829040527,
      "learning_rate": 8.254973577867578e-06,
      "loss": 0.2118,
      "step": 4491
    },
    {
      "epoch": 0.3490829965806652,
      "grad_norm": 0.16923388838768005,
      "learning_rate": 8.254585017096675e-06,
      "loss": 0.1307,
      "step": 4492
    },
    {
      "epoch": 0.3491607087348461,
      "grad_norm": 0.3991187512874603,
      "learning_rate": 8.25419645632577e-06,
      "loss": 0.7453,
      "step": 4493
    },
    {
      "epoch": 0.34923842088902707,
      "grad_norm": 0.5281537771224976,
      "learning_rate": 8.253807895554865e-06,
      "loss": 0.1977,
      "step": 4494
    },
    {
      "epoch": 0.34931613304320797,
      "grad_norm": 0.505234956741333,
      "learning_rate": 8.253419334783962e-06,
      "loss": 0.2481,
      "step": 4495
    },
    {
      "epoch": 0.34939384519738886,
      "grad_norm": 0.6660442352294922,
      "learning_rate": 8.253030774013057e-06,
      "loss": 0.2193,
      "step": 4496
    },
    {
      "epoch": 0.34947155735156976,
      "grad_norm": 0.16847291588783264,
      "learning_rate": 8.252642213242152e-06,
      "loss": 0.1592,
      "step": 4497
    },
    {
      "epoch": 0.3495492695057507,
      "grad_norm": 0.06523403525352478,
      "learning_rate": 8.252253652471247e-06,
      "loss": 0.0362,
      "step": 4498
    },
    {
      "epoch": 0.3496269816599316,
      "grad_norm": 0.531773030757904,
      "learning_rate": 8.251865091700343e-06,
      "loss": 0.466,
      "step": 4499
    },
    {
      "epoch": 0.3497046938141125,
      "grad_norm": 0.4174346625804901,
      "learning_rate": 8.251476530929438e-06,
      "loss": 0.2384,
      "step": 4500
    },
    {
      "epoch": 0.34978240596829346,
      "grad_norm": 0.36199137568473816,
      "learning_rate": 8.251087970158533e-06,
      "loss": 0.3945,
      "step": 4501
    },
    {
      "epoch": 0.34986011812247436,
      "grad_norm": 0.34057679772377014,
      "learning_rate": 8.25069940938763e-06,
      "loss": 0.2528,
      "step": 4502
    },
    {
      "epoch": 0.34993783027665526,
      "grad_norm": 0.18643352389335632,
      "learning_rate": 8.250310848616723e-06,
      "loss": 0.0711,
      "step": 4503
    },
    {
      "epoch": 0.35001554243083616,
      "grad_norm": 0.05193823203444481,
      "learning_rate": 8.24992228784582e-06,
      "loss": 0.0083,
      "step": 4504
    },
    {
      "epoch": 0.3500932545850171,
      "grad_norm": 0.18923145532608032,
      "learning_rate": 8.249533727074915e-06,
      "loss": 0.1722,
      "step": 4505
    },
    {
      "epoch": 0.350170966739198,
      "grad_norm": 0.6036897301673889,
      "learning_rate": 8.24914516630401e-06,
      "loss": 0.2486,
      "step": 4506
    },
    {
      "epoch": 0.3502486788933789,
      "grad_norm": 0.575692355632782,
      "learning_rate": 8.248756605533106e-06,
      "loss": 0.2533,
      "step": 4507
    },
    {
      "epoch": 0.35032639104755986,
      "grad_norm": 0.1409282386302948,
      "learning_rate": 8.248368044762201e-06,
      "loss": 0.0161,
      "step": 4508
    },
    {
      "epoch": 0.35040410320174076,
      "grad_norm": 0.19780156016349792,
      "learning_rate": 8.247979483991298e-06,
      "loss": 0.0687,
      "step": 4509
    },
    {
      "epoch": 0.35048181535592166,
      "grad_norm": 0.9676075577735901,
      "learning_rate": 8.247590923220393e-06,
      "loss": 0.4312,
      "step": 4510
    },
    {
      "epoch": 0.35055952751010255,
      "grad_norm": 0.3007114827632904,
      "learning_rate": 8.247202362449488e-06,
      "loss": 0.0852,
      "step": 4511
    },
    {
      "epoch": 0.3506372396642835,
      "grad_norm": 0.2678280770778656,
      "learning_rate": 8.246813801678584e-06,
      "loss": 0.2158,
      "step": 4512
    },
    {
      "epoch": 0.3507149518184644,
      "grad_norm": 0.6045551300048828,
      "learning_rate": 8.246425240907678e-06,
      "loss": 0.2104,
      "step": 4513
    },
    {
      "epoch": 0.3507926639726453,
      "grad_norm": 0.5087646842002869,
      "learning_rate": 8.246036680136774e-06,
      "loss": 0.2831,
      "step": 4514
    },
    {
      "epoch": 0.35087037612682626,
      "grad_norm": 0.19095194339752197,
      "learning_rate": 8.245648119365869e-06,
      "loss": 0.0602,
      "step": 4515
    },
    {
      "epoch": 0.35094808828100715,
      "grad_norm": 0.811675488948822,
      "learning_rate": 8.245259558594964e-06,
      "loss": 0.1559,
      "step": 4516
    },
    {
      "epoch": 0.35102580043518805,
      "grad_norm": 0.48896104097366333,
      "learning_rate": 8.24487099782406e-06,
      "loss": 0.1844,
      "step": 4517
    },
    {
      "epoch": 0.351103512589369,
      "grad_norm": 0.40828201174736023,
      "learning_rate": 8.244482437053156e-06,
      "loss": 0.203,
      "step": 4518
    },
    {
      "epoch": 0.3511812247435499,
      "grad_norm": 0.25156399607658386,
      "learning_rate": 8.24409387628225e-06,
      "loss": 0.1047,
      "step": 4519
    },
    {
      "epoch": 0.3512589368977308,
      "grad_norm": 0.6075503826141357,
      "learning_rate": 8.243705315511347e-06,
      "loss": 0.1229,
      "step": 4520
    },
    {
      "epoch": 0.3513366490519117,
      "grad_norm": 0.39570507407188416,
      "learning_rate": 8.243316754740442e-06,
      "loss": 0.1625,
      "step": 4521
    },
    {
      "epoch": 0.35141436120609265,
      "grad_norm": 0.3096269369125366,
      "learning_rate": 8.242928193969537e-06,
      "loss": 0.1467,
      "step": 4522
    },
    {
      "epoch": 0.35149207336027355,
      "grad_norm": 0.2897239923477173,
      "learning_rate": 8.242539633198632e-06,
      "loss": 0.0696,
      "step": 4523
    },
    {
      "epoch": 0.35156978551445445,
      "grad_norm": 0.5261724591255188,
      "learning_rate": 8.242151072427729e-06,
      "loss": 0.151,
      "step": 4524
    },
    {
      "epoch": 0.3516474976686354,
      "grad_norm": 0.2879827618598938,
      "learning_rate": 8.241762511656824e-06,
      "loss": 0.2093,
      "step": 4525
    },
    {
      "epoch": 0.3517252098228163,
      "grad_norm": 0.3018302321434021,
      "learning_rate": 8.241373950885919e-06,
      "loss": 0.2119,
      "step": 4526
    },
    {
      "epoch": 0.3518029219769972,
      "grad_norm": 0.17429181933403015,
      "learning_rate": 8.240985390115015e-06,
      "loss": 0.1971,
      "step": 4527
    },
    {
      "epoch": 0.3518806341311781,
      "grad_norm": 0.5608114004135132,
      "learning_rate": 8.24059682934411e-06,
      "loss": 0.1991,
      "step": 4528
    },
    {
      "epoch": 0.35195834628535905,
      "grad_norm": 0.7103559970855713,
      "learning_rate": 8.240208268573205e-06,
      "loss": 0.6966,
      "step": 4529
    },
    {
      "epoch": 0.35203605843953995,
      "grad_norm": 0.6281055808067322,
      "learning_rate": 8.239819707802302e-06,
      "loss": 0.6316,
      "step": 4530
    },
    {
      "epoch": 0.35211377059372084,
      "grad_norm": 0.7001237869262695,
      "learning_rate": 8.239431147031395e-06,
      "loss": 0.5375,
      "step": 4531
    },
    {
      "epoch": 0.3521914827479018,
      "grad_norm": 0.08233107626438141,
      "learning_rate": 8.239042586260492e-06,
      "loss": 0.0217,
      "step": 4532
    },
    {
      "epoch": 0.3522691949020827,
      "grad_norm": 0.38253360986709595,
      "learning_rate": 8.238654025489587e-06,
      "loss": 0.3378,
      "step": 4533
    },
    {
      "epoch": 0.3523469070562636,
      "grad_norm": 0.2475496530532837,
      "learning_rate": 8.238265464718682e-06,
      "loss": 0.0717,
      "step": 4534
    },
    {
      "epoch": 0.3524246192104445,
      "grad_norm": 0.1756865531206131,
      "learning_rate": 8.237876903947778e-06,
      "loss": 0.0773,
      "step": 4535
    },
    {
      "epoch": 0.35250233136462544,
      "grad_norm": 0.18534795939922333,
      "learning_rate": 8.237488343176873e-06,
      "loss": 0.1726,
      "step": 4536
    },
    {
      "epoch": 0.35258004351880634,
      "grad_norm": 0.11834566295146942,
      "learning_rate": 8.237099782405968e-06,
      "loss": 0.0374,
      "step": 4537
    },
    {
      "epoch": 0.35265775567298724,
      "grad_norm": 0.2835242450237274,
      "learning_rate": 8.236711221635065e-06,
      "loss": 0.1562,
      "step": 4538
    },
    {
      "epoch": 0.3527354678271682,
      "grad_norm": 0.14560860395431519,
      "learning_rate": 8.23632266086416e-06,
      "loss": 0.0687,
      "step": 4539
    },
    {
      "epoch": 0.3528131799813491,
      "grad_norm": 0.25483646988868713,
      "learning_rate": 8.235934100093256e-06,
      "loss": 0.0952,
      "step": 4540
    },
    {
      "epoch": 0.35289089213553,
      "grad_norm": 0.45126792788505554,
      "learning_rate": 8.23554553932235e-06,
      "loss": 0.2619,
      "step": 4541
    },
    {
      "epoch": 0.3529686042897109,
      "grad_norm": 0.2616193890571594,
      "learning_rate": 8.235156978551446e-06,
      "loss": 0.1226,
      "step": 4542
    },
    {
      "epoch": 0.35304631644389184,
      "grad_norm": 0.19503049552440643,
      "learning_rate": 8.234768417780541e-06,
      "loss": 0.0378,
      "step": 4543
    },
    {
      "epoch": 0.35312402859807274,
      "grad_norm": 0.17263764142990112,
      "learning_rate": 8.234379857009636e-06,
      "loss": 0.0411,
      "step": 4544
    },
    {
      "epoch": 0.35320174075225363,
      "grad_norm": 0.21495530009269714,
      "learning_rate": 8.233991296238733e-06,
      "loss": 0.1163,
      "step": 4545
    },
    {
      "epoch": 0.3532794529064346,
      "grad_norm": 0.414227157831192,
      "learning_rate": 8.233602735467828e-06,
      "loss": 0.1229,
      "step": 4546
    },
    {
      "epoch": 0.3533571650606155,
      "grad_norm": 0.20034635066986084,
      "learning_rate": 8.233214174696923e-06,
      "loss": 0.0262,
      "step": 4547
    },
    {
      "epoch": 0.3534348772147964,
      "grad_norm": 0.16827115416526794,
      "learning_rate": 8.23282561392602e-06,
      "loss": 0.0457,
      "step": 4548
    },
    {
      "epoch": 0.3535125893689773,
      "grad_norm": 0.6053371429443359,
      "learning_rate": 8.232437053155114e-06,
      "loss": 0.3496,
      "step": 4549
    },
    {
      "epoch": 0.35359030152315823,
      "grad_norm": 0.8461157083511353,
      "learning_rate": 8.23204849238421e-06,
      "loss": 0.2456,
      "step": 4550
    },
    {
      "epoch": 0.35366801367733913,
      "grad_norm": 0.34672459959983826,
      "learning_rate": 8.231659931613304e-06,
      "loss": 0.1046,
      "step": 4551
    },
    {
      "epoch": 0.35374572583152003,
      "grad_norm": 0.5285590291023254,
      "learning_rate": 8.231271370842401e-06,
      "loss": 0.0785,
      "step": 4552
    },
    {
      "epoch": 0.353823437985701,
      "grad_norm": 0.5277419090270996,
      "learning_rate": 8.230882810071496e-06,
      "loss": 0.1412,
      "step": 4553
    },
    {
      "epoch": 0.3539011501398819,
      "grad_norm": 0.21171103417873383,
      "learning_rate": 8.23049424930059e-06,
      "loss": 0.2781,
      "step": 4554
    },
    {
      "epoch": 0.3539788622940628,
      "grad_norm": 0.6631761789321899,
      "learning_rate": 8.230105688529687e-06,
      "loss": 0.3602,
      "step": 4555
    },
    {
      "epoch": 0.35405657444824373,
      "grad_norm": 0.4216974973678589,
      "learning_rate": 8.229717127758782e-06,
      "loss": 0.2858,
      "step": 4556
    },
    {
      "epoch": 0.35413428660242463,
      "grad_norm": 0.6772071123123169,
      "learning_rate": 8.229328566987877e-06,
      "loss": 0.3321,
      "step": 4557
    },
    {
      "epoch": 0.35421199875660553,
      "grad_norm": 0.26034921407699585,
      "learning_rate": 8.228940006216974e-06,
      "loss": 0.1202,
      "step": 4558
    },
    {
      "epoch": 0.3542897109107864,
      "grad_norm": 0.6126654744148254,
      "learning_rate": 8.228551445446067e-06,
      "loss": 0.3381,
      "step": 4559
    },
    {
      "epoch": 0.3543674230649674,
      "grad_norm": 0.26319625973701477,
      "learning_rate": 8.228162884675164e-06,
      "loss": 0.2598,
      "step": 4560
    },
    {
      "epoch": 0.3544451352191483,
      "grad_norm": 0.26465973258018494,
      "learning_rate": 8.227774323904259e-06,
      "loss": 0.3191,
      "step": 4561
    },
    {
      "epoch": 0.3545228473733292,
      "grad_norm": 0.27241551876068115,
      "learning_rate": 8.227385763133354e-06,
      "loss": 0.0326,
      "step": 4562
    },
    {
      "epoch": 0.35460055952751013,
      "grad_norm": 0.18151773512363434,
      "learning_rate": 8.22699720236245e-06,
      "loss": 0.1679,
      "step": 4563
    },
    {
      "epoch": 0.354678271681691,
      "grad_norm": 0.6681652069091797,
      "learning_rate": 8.226608641591545e-06,
      "loss": 0.2644,
      "step": 4564
    },
    {
      "epoch": 0.3547559838358719,
      "grad_norm": 0.3160361349582672,
      "learning_rate": 8.22622008082064e-06,
      "loss": 0.1418,
      "step": 4565
    },
    {
      "epoch": 0.3548336959900528,
      "grad_norm": 0.4064631760120392,
      "learning_rate": 8.225831520049737e-06,
      "loss": 0.0663,
      "step": 4566
    },
    {
      "epoch": 0.3549114081442338,
      "grad_norm": 2.0236825942993164,
      "learning_rate": 8.225442959278832e-06,
      "loss": 0.2761,
      "step": 4567
    },
    {
      "epoch": 0.3549891202984147,
      "grad_norm": 0.13781283795833588,
      "learning_rate": 8.225054398507929e-06,
      "loss": 0.0493,
      "step": 4568
    },
    {
      "epoch": 0.35506683245259557,
      "grad_norm": 0.5112195611000061,
      "learning_rate": 8.224665837737022e-06,
      "loss": 0.3199,
      "step": 4569
    },
    {
      "epoch": 0.3551445446067765,
      "grad_norm": 0.5694904327392578,
      "learning_rate": 8.224277276966118e-06,
      "loss": 0.2516,
      "step": 4570
    },
    {
      "epoch": 0.3552222567609574,
      "grad_norm": 1.1728160381317139,
      "learning_rate": 8.223888716195213e-06,
      "loss": 0.284,
      "step": 4571
    },
    {
      "epoch": 0.3552999689151383,
      "grad_norm": 0.17552532255649567,
      "learning_rate": 8.223500155424308e-06,
      "loss": 0.0956,
      "step": 4572
    },
    {
      "epoch": 0.3553776810693192,
      "grad_norm": 0.3052450716495514,
      "learning_rate": 8.223111594653405e-06,
      "loss": 0.1206,
      "step": 4573
    },
    {
      "epoch": 0.35545539322350017,
      "grad_norm": 0.24338474869728088,
      "learning_rate": 8.2227230338825e-06,
      "loss": 0.243,
      "step": 4574
    },
    {
      "epoch": 0.35553310537768107,
      "grad_norm": 0.18021893501281738,
      "learning_rate": 8.222334473111595e-06,
      "loss": 0.0649,
      "step": 4575
    },
    {
      "epoch": 0.35561081753186197,
      "grad_norm": 0.3486904799938202,
      "learning_rate": 8.221945912340692e-06,
      "loss": 0.144,
      "step": 4576
    },
    {
      "epoch": 0.3556885296860429,
      "grad_norm": 0.3541295826435089,
      "learning_rate": 8.221557351569787e-06,
      "loss": 0.3441,
      "step": 4577
    },
    {
      "epoch": 0.3557662418402238,
      "grad_norm": 0.10768727958202362,
      "learning_rate": 8.221168790798881e-06,
      "loss": 0.0171,
      "step": 4578
    },
    {
      "epoch": 0.3558439539944047,
      "grad_norm": 2.6906914710998535,
      "learning_rate": 8.220780230027976e-06,
      "loss": 0.9507,
      "step": 4579
    },
    {
      "epoch": 0.3559216661485856,
      "grad_norm": 0.5341877341270447,
      "learning_rate": 8.220391669257073e-06,
      "loss": 0.2805,
      "step": 4580
    },
    {
      "epoch": 0.35599937830276657,
      "grad_norm": 0.1534944623708725,
      "learning_rate": 8.220003108486168e-06,
      "loss": 0.0358,
      "step": 4581
    },
    {
      "epoch": 0.35607709045694746,
      "grad_norm": 0.25906580686569214,
      "learning_rate": 8.219614547715263e-06,
      "loss": 0.1022,
      "step": 4582
    },
    {
      "epoch": 0.35615480261112836,
      "grad_norm": 0.8587820529937744,
      "learning_rate": 8.21922598694436e-06,
      "loss": 0.7404,
      "step": 4583
    },
    {
      "epoch": 0.3562325147653093,
      "grad_norm": 0.20796987414360046,
      "learning_rate": 8.218837426173455e-06,
      "loss": 0.077,
      "step": 4584
    },
    {
      "epoch": 0.3563102269194902,
      "grad_norm": 0.627761721611023,
      "learning_rate": 8.21844886540255e-06,
      "loss": 0.2378,
      "step": 4585
    },
    {
      "epoch": 0.3563879390736711,
      "grad_norm": 0.04069127142429352,
      "learning_rate": 8.218060304631646e-06,
      "loss": 0.0102,
      "step": 4586
    },
    {
      "epoch": 0.356465651227852,
      "grad_norm": 0.15222913026809692,
      "learning_rate": 8.21767174386074e-06,
      "loss": 0.0484,
      "step": 4587
    },
    {
      "epoch": 0.35654336338203296,
      "grad_norm": 0.10760928690433502,
      "learning_rate": 8.217283183089836e-06,
      "loss": 0.0279,
      "step": 4588
    },
    {
      "epoch": 0.35662107553621386,
      "grad_norm": 0.4167524576187134,
      "learning_rate": 8.216894622318931e-06,
      "loss": 0.315,
      "step": 4589
    },
    {
      "epoch": 0.35669878769039476,
      "grad_norm": 0.25232866406440735,
      "learning_rate": 8.216506061548026e-06,
      "loss": 0.075,
      "step": 4590
    },
    {
      "epoch": 0.3567764998445757,
      "grad_norm": 0.2155177742242813,
      "learning_rate": 8.216117500777123e-06,
      "loss": 0.1465,
      "step": 4591
    },
    {
      "epoch": 0.3568542119987566,
      "grad_norm": 0.44835320115089417,
      "learning_rate": 8.215728940006218e-06,
      "loss": 0.3254,
      "step": 4592
    },
    {
      "epoch": 0.3569319241529375,
      "grad_norm": 0.22702091932296753,
      "learning_rate": 8.215340379235313e-06,
      "loss": 0.0736,
      "step": 4593
    },
    {
      "epoch": 0.35700963630711846,
      "grad_norm": 0.44440484046936035,
      "learning_rate": 8.214951818464409e-06,
      "loss": 0.7152,
      "step": 4594
    },
    {
      "epoch": 0.35708734846129936,
      "grad_norm": 0.3387252390384674,
      "learning_rate": 8.214563257693504e-06,
      "loss": 0.1524,
      "step": 4595
    },
    {
      "epoch": 0.35716506061548026,
      "grad_norm": 0.2948799133300781,
      "learning_rate": 8.214174696922599e-06,
      "loss": 0.1311,
      "step": 4596
    },
    {
      "epoch": 0.35724277276966115,
      "grad_norm": 0.528024435043335,
      "learning_rate": 8.213786136151694e-06,
      "loss": 0.5635,
      "step": 4597
    },
    {
      "epoch": 0.3573204849238421,
      "grad_norm": 0.07165386527776718,
      "learning_rate": 8.21339757538079e-06,
      "loss": 0.0347,
      "step": 4598
    },
    {
      "epoch": 0.357398197078023,
      "grad_norm": 0.28869348764419556,
      "learning_rate": 8.213009014609886e-06,
      "loss": 0.2271,
      "step": 4599
    },
    {
      "epoch": 0.3574759092322039,
      "grad_norm": 0.28379660844802856,
      "learning_rate": 8.21262045383898e-06,
      "loss": 0.2438,
      "step": 4600
    },
    {
      "epoch": 0.35755362138638486,
      "grad_norm": 0.2490370124578476,
      "learning_rate": 8.212231893068077e-06,
      "loss": 0.0764,
      "step": 4601
    },
    {
      "epoch": 0.35763133354056575,
      "grad_norm": 0.8474363684654236,
      "learning_rate": 8.211843332297172e-06,
      "loss": 0.2351,
      "step": 4602
    },
    {
      "epoch": 0.35770904569474665,
      "grad_norm": 0.30170634388923645,
      "learning_rate": 8.211454771526267e-06,
      "loss": 0.1323,
      "step": 4603
    },
    {
      "epoch": 0.35778675784892755,
      "grad_norm": 0.14141251146793365,
      "learning_rate": 8.211066210755364e-06,
      "loss": 0.0707,
      "step": 4604
    },
    {
      "epoch": 0.3578644700031085,
      "grad_norm": 0.3663788139820099,
      "learning_rate": 8.210677649984459e-06,
      "loss": 0.1326,
      "step": 4605
    },
    {
      "epoch": 0.3579421821572894,
      "grad_norm": 0.2962270975112915,
      "learning_rate": 8.210289089213554e-06,
      "loss": 0.0781,
      "step": 4606
    },
    {
      "epoch": 0.3580198943114703,
      "grad_norm": 0.2991808354854584,
      "learning_rate": 8.209900528442649e-06,
      "loss": 0.0713,
      "step": 4607
    },
    {
      "epoch": 0.35809760646565125,
      "grad_norm": 0.21437960863113403,
      "learning_rate": 8.209511967671745e-06,
      "loss": 0.0565,
      "step": 4608
    },
    {
      "epoch": 0.35817531861983215,
      "grad_norm": 0.1682863086462021,
      "learning_rate": 8.20912340690084e-06,
      "loss": 0.0512,
      "step": 4609
    },
    {
      "epoch": 0.35825303077401305,
      "grad_norm": 0.10867799073457718,
      "learning_rate": 8.208734846129935e-06,
      "loss": 0.0314,
      "step": 4610
    },
    {
      "epoch": 0.35833074292819395,
      "grad_norm": 0.11874092370271683,
      "learning_rate": 8.208346285359032e-06,
      "loss": 0.011,
      "step": 4611
    },
    {
      "epoch": 0.3584084550823749,
      "grad_norm": 0.9569076895713806,
      "learning_rate": 8.207957724588127e-06,
      "loss": 0.4833,
      "step": 4612
    },
    {
      "epoch": 0.3584861672365558,
      "grad_norm": 0.39615195989608765,
      "learning_rate": 8.207569163817222e-06,
      "loss": 0.0496,
      "step": 4613
    },
    {
      "epoch": 0.3585638793907367,
      "grad_norm": 0.2682178020477295,
      "learning_rate": 8.207180603046318e-06,
      "loss": 0.2125,
      "step": 4614
    },
    {
      "epoch": 0.35864159154491765,
      "grad_norm": 0.28729248046875,
      "learning_rate": 8.206792042275412e-06,
      "loss": 0.1685,
      "step": 4615
    },
    {
      "epoch": 0.35871930369909855,
      "grad_norm": 0.6532491445541382,
      "learning_rate": 8.206403481504508e-06,
      "loss": 0.5875,
      "step": 4616
    },
    {
      "epoch": 0.35879701585327944,
      "grad_norm": 0.3133585751056671,
      "learning_rate": 8.206014920733603e-06,
      "loss": 0.1375,
      "step": 4617
    },
    {
      "epoch": 0.35887472800746034,
      "grad_norm": 0.3389909863471985,
      "learning_rate": 8.205626359962698e-06,
      "loss": 0.0401,
      "step": 4618
    },
    {
      "epoch": 0.3589524401616413,
      "grad_norm": 0.17240320146083832,
      "learning_rate": 8.205237799191795e-06,
      "loss": 0.1184,
      "step": 4619
    },
    {
      "epoch": 0.3590301523158222,
      "grad_norm": 0.219480499625206,
      "learning_rate": 8.20484923842089e-06,
      "loss": 0.0303,
      "step": 4620
    },
    {
      "epoch": 0.3591078644700031,
      "grad_norm": 1.015533208847046,
      "learning_rate": 8.204460677649985e-06,
      "loss": 0.4167,
      "step": 4621
    },
    {
      "epoch": 0.35918557662418404,
      "grad_norm": 0.08581245690584183,
      "learning_rate": 8.204072116879081e-06,
      "loss": 0.0105,
      "step": 4622
    },
    {
      "epoch": 0.35926328877836494,
      "grad_norm": 0.6159589290618896,
      "learning_rate": 8.203683556108176e-06,
      "loss": 0.294,
      "step": 4623
    },
    {
      "epoch": 0.35934100093254584,
      "grad_norm": 0.5144232511520386,
      "learning_rate": 8.203294995337271e-06,
      "loss": 0.1925,
      "step": 4624
    },
    {
      "epoch": 0.35941871308672674,
      "grad_norm": 0.12077361345291138,
      "learning_rate": 8.202906434566366e-06,
      "loss": 0.0458,
      "step": 4625
    },
    {
      "epoch": 0.3594964252409077,
      "grad_norm": 0.13760817050933838,
      "learning_rate": 8.202517873795463e-06,
      "loss": 0.0334,
      "step": 4626
    },
    {
      "epoch": 0.3595741373950886,
      "grad_norm": 0.28556060791015625,
      "learning_rate": 8.202129313024558e-06,
      "loss": 0.0523,
      "step": 4627
    },
    {
      "epoch": 0.3596518495492695,
      "grad_norm": 0.21661724150180817,
      "learning_rate": 8.201740752253653e-06,
      "loss": 0.1803,
      "step": 4628
    },
    {
      "epoch": 0.35972956170345044,
      "grad_norm": 0.2749234437942505,
      "learning_rate": 8.20135219148275e-06,
      "loss": 0.0927,
      "step": 4629
    },
    {
      "epoch": 0.35980727385763134,
      "grad_norm": 0.2631528973579407,
      "learning_rate": 8.200963630711844e-06,
      "loss": 0.0646,
      "step": 4630
    },
    {
      "epoch": 0.35988498601181224,
      "grad_norm": 0.4133315682411194,
      "learning_rate": 8.20057506994094e-06,
      "loss": 0.5337,
      "step": 4631
    },
    {
      "epoch": 0.3599626981659932,
      "grad_norm": 1.2268812656402588,
      "learning_rate": 8.200186509170034e-06,
      "loss": 0.4032,
      "step": 4632
    },
    {
      "epoch": 0.3600404103201741,
      "grad_norm": 0.40107300877571106,
      "learning_rate": 8.19979794839913e-06,
      "loss": 0.4004,
      "step": 4633
    },
    {
      "epoch": 0.360118122474355,
      "grad_norm": 0.14431360363960266,
      "learning_rate": 8.199409387628226e-06,
      "loss": 0.085,
      "step": 4634
    },
    {
      "epoch": 0.3601958346285359,
      "grad_norm": 0.09997712820768356,
      "learning_rate": 8.19902082685732e-06,
      "loss": 0.0264,
      "step": 4635
    },
    {
      "epoch": 0.36027354678271684,
      "grad_norm": 1.883919596672058,
      "learning_rate": 8.198632266086417e-06,
      "loss": 1.8579,
      "step": 4636
    },
    {
      "epoch": 0.36035125893689773,
      "grad_norm": 0.2693002223968506,
      "learning_rate": 8.198243705315512e-06,
      "loss": 0.1604,
      "step": 4637
    },
    {
      "epoch": 0.36042897109107863,
      "grad_norm": 0.12804067134857178,
      "learning_rate": 8.197855144544607e-06,
      "loss": 0.0307,
      "step": 4638
    },
    {
      "epoch": 0.3605066832452596,
      "grad_norm": 0.4169532060623169,
      "learning_rate": 8.197466583773704e-06,
      "loss": 0.7106,
      "step": 4639
    },
    {
      "epoch": 0.3605843953994405,
      "grad_norm": 0.7407878637313843,
      "learning_rate": 8.197078023002797e-06,
      "loss": 0.4732,
      "step": 4640
    },
    {
      "epoch": 0.3606621075536214,
      "grad_norm": 0.3026592433452606,
      "learning_rate": 8.196689462231894e-06,
      "loss": 0.1463,
      "step": 4641
    },
    {
      "epoch": 0.3607398197078023,
      "grad_norm": 0.5428406596183777,
      "learning_rate": 8.196300901460989e-06,
      "loss": 0.1443,
      "step": 4642
    },
    {
      "epoch": 0.36081753186198323,
      "grad_norm": 0.5986459255218506,
      "learning_rate": 8.195912340690084e-06,
      "loss": 0.181,
      "step": 4643
    },
    {
      "epoch": 0.36089524401616413,
      "grad_norm": 0.20410510897636414,
      "learning_rate": 8.19552377991918e-06,
      "loss": 0.1528,
      "step": 4644
    },
    {
      "epoch": 0.360972956170345,
      "grad_norm": 0.4879930913448334,
      "learning_rate": 8.195135219148275e-06,
      "loss": 0.4899,
      "step": 4645
    },
    {
      "epoch": 0.361050668324526,
      "grad_norm": 0.35404255986213684,
      "learning_rate": 8.19474665837737e-06,
      "loss": 0.1412,
      "step": 4646
    },
    {
      "epoch": 0.3611283804787069,
      "grad_norm": 0.5128779411315918,
      "learning_rate": 8.194358097606467e-06,
      "loss": 0.2736,
      "step": 4647
    },
    {
      "epoch": 0.3612060926328878,
      "grad_norm": 0.3592507243156433,
      "learning_rate": 8.193969536835562e-06,
      "loss": 0.4649,
      "step": 4648
    },
    {
      "epoch": 0.3612838047870687,
      "grad_norm": 0.08403503149747849,
      "learning_rate": 8.193580976064657e-06,
      "loss": 0.0265,
      "step": 4649
    },
    {
      "epoch": 0.3613615169412496,
      "grad_norm": 0.4207760691642761,
      "learning_rate": 8.193192415293752e-06,
      "loss": 0.2983,
      "step": 4650
    },
    {
      "epoch": 0.3614392290954305,
      "grad_norm": 0.05240621417760849,
      "learning_rate": 8.192803854522848e-06,
      "loss": 0.0119,
      "step": 4651
    },
    {
      "epoch": 0.3615169412496114,
      "grad_norm": 0.057679396122694016,
      "learning_rate": 8.192415293751943e-06,
      "loss": 0.0147,
      "step": 4652
    },
    {
      "epoch": 0.3615946534037924,
      "grad_norm": 0.2547418475151062,
      "learning_rate": 8.192026732981038e-06,
      "loss": 0.1078,
      "step": 4653
    },
    {
      "epoch": 0.3616723655579733,
      "grad_norm": 0.3604634702205658,
      "learning_rate": 8.191638172210135e-06,
      "loss": 0.3899,
      "step": 4654
    },
    {
      "epoch": 0.36175007771215417,
      "grad_norm": 0.2695045471191406,
      "learning_rate": 8.19124961143923e-06,
      "loss": 0.0986,
      "step": 4655
    },
    {
      "epoch": 0.36182778986633507,
      "grad_norm": 0.23993803560733795,
      "learning_rate": 8.190861050668325e-06,
      "loss": 0.0861,
      "step": 4656
    },
    {
      "epoch": 0.361905502020516,
      "grad_norm": 1.320326328277588,
      "learning_rate": 8.190472489897421e-06,
      "loss": 1.5225,
      "step": 4657
    },
    {
      "epoch": 0.3619832141746969,
      "grad_norm": 0.3806147575378418,
      "learning_rate": 8.190083929126515e-06,
      "loss": 0.346,
      "step": 4658
    },
    {
      "epoch": 0.3620609263288778,
      "grad_norm": 0.19102369248867035,
      "learning_rate": 8.189695368355611e-06,
      "loss": 0.0789,
      "step": 4659
    },
    {
      "epoch": 0.3621386384830588,
      "grad_norm": 0.34062665700912476,
      "learning_rate": 8.189306807584706e-06,
      "loss": 0.0977,
      "step": 4660
    },
    {
      "epoch": 0.36221635063723967,
      "grad_norm": 0.3957887589931488,
      "learning_rate": 8.188918246813803e-06,
      "loss": 0.1256,
      "step": 4661
    },
    {
      "epoch": 0.36229406279142057,
      "grad_norm": 0.17974580824375153,
      "learning_rate": 8.188529686042898e-06,
      "loss": 0.0377,
      "step": 4662
    },
    {
      "epoch": 0.36237177494560147,
      "grad_norm": 0.962914228439331,
      "learning_rate": 8.188141125271993e-06,
      "loss": 0.3601,
      "step": 4663
    },
    {
      "epoch": 0.3624494870997824,
      "grad_norm": 0.15390510857105255,
      "learning_rate": 8.18775256450109e-06,
      "loss": 0.0751,
      "step": 4664
    },
    {
      "epoch": 0.3625271992539633,
      "grad_norm": 0.4513295590877533,
      "learning_rate": 8.187364003730184e-06,
      "loss": 0.5113,
      "step": 4665
    },
    {
      "epoch": 0.3626049114081442,
      "grad_norm": 0.16401690244674683,
      "learning_rate": 8.18697544295928e-06,
      "loss": 0.0958,
      "step": 4666
    },
    {
      "epoch": 0.36268262356232517,
      "grad_norm": 0.18108370900154114,
      "learning_rate": 8.186586882188376e-06,
      "loss": 0.0617,
      "step": 4667
    },
    {
      "epoch": 0.36276033571650607,
      "grad_norm": 0.3839532732963562,
      "learning_rate": 8.18619832141747e-06,
      "loss": 0.1851,
      "step": 4668
    },
    {
      "epoch": 0.36283804787068696,
      "grad_norm": 0.21333768963813782,
      "learning_rate": 8.185809760646566e-06,
      "loss": 0.0284,
      "step": 4669
    },
    {
      "epoch": 0.36291576002486786,
      "grad_norm": 0.14954523742198944,
      "learning_rate": 8.185421199875661e-06,
      "loss": 0.0919,
      "step": 4670
    },
    {
      "epoch": 0.3629934721790488,
      "grad_norm": 0.47871536016464233,
      "learning_rate": 8.185032639104756e-06,
      "loss": 0.3453,
      "step": 4671
    },
    {
      "epoch": 0.3630711843332297,
      "grad_norm": 0.17760124802589417,
      "learning_rate": 8.184644078333852e-06,
      "loss": 0.0253,
      "step": 4672
    },
    {
      "epoch": 0.3631488964874106,
      "grad_norm": 0.1377326101064682,
      "learning_rate": 8.184255517562947e-06,
      "loss": 0.0296,
      "step": 4673
    },
    {
      "epoch": 0.36322660864159156,
      "grad_norm": 0.2504476010799408,
      "learning_rate": 8.183866956792042e-06,
      "loss": 0.1721,
      "step": 4674
    },
    {
      "epoch": 0.36330432079577246,
      "grad_norm": 0.2761668860912323,
      "learning_rate": 8.183478396021139e-06,
      "loss": 0.153,
      "step": 4675
    },
    {
      "epoch": 0.36338203294995336,
      "grad_norm": 0.1214287057518959,
      "learning_rate": 8.183089835250234e-06,
      "loss": 0.0335,
      "step": 4676
    },
    {
      "epoch": 0.3634597451041343,
      "grad_norm": 0.10437130182981491,
      "learning_rate": 8.182701274479329e-06,
      "loss": 0.0229,
      "step": 4677
    },
    {
      "epoch": 0.3635374572583152,
      "grad_norm": 0.3195275664329529,
      "learning_rate": 8.182312713708424e-06,
      "loss": 0.1189,
      "step": 4678
    },
    {
      "epoch": 0.3636151694124961,
      "grad_norm": 1.1572456359863281,
      "learning_rate": 8.18192415293752e-06,
      "loss": 0.905,
      "step": 4679
    },
    {
      "epoch": 0.363692881566677,
      "grad_norm": 0.27733296155929565,
      "learning_rate": 8.181535592166615e-06,
      "loss": 0.3725,
      "step": 4680
    },
    {
      "epoch": 0.36377059372085796,
      "grad_norm": 0.44161343574523926,
      "learning_rate": 8.18114703139571e-06,
      "loss": 0.329,
      "step": 4681
    },
    {
      "epoch": 0.36384830587503886,
      "grad_norm": 0.38958752155303955,
      "learning_rate": 8.180758470624807e-06,
      "loss": 0.0981,
      "step": 4682
    },
    {
      "epoch": 0.36392601802921976,
      "grad_norm": 0.065674789249897,
      "learning_rate": 8.180369909853902e-06,
      "loss": 0.0194,
      "step": 4683
    },
    {
      "epoch": 0.3640037301834007,
      "grad_norm": 0.3027344346046448,
      "learning_rate": 8.179981349082997e-06,
      "loss": 0.2319,
      "step": 4684
    },
    {
      "epoch": 0.3640814423375816,
      "grad_norm": 0.24329856038093567,
      "learning_rate": 8.179592788312094e-06,
      "loss": 0.0453,
      "step": 4685
    },
    {
      "epoch": 0.3641591544917625,
      "grad_norm": 0.31238463521003723,
      "learning_rate": 8.179204227541187e-06,
      "loss": 0.111,
      "step": 4686
    },
    {
      "epoch": 0.3642368666459434,
      "grad_norm": 0.6145371198654175,
      "learning_rate": 8.178815666770284e-06,
      "loss": 0.1319,
      "step": 4687
    },
    {
      "epoch": 0.36431457880012436,
      "grad_norm": 0.485282838344574,
      "learning_rate": 8.178427105999378e-06,
      "loss": 0.1697,
      "step": 4688
    },
    {
      "epoch": 0.36439229095430525,
      "grad_norm": 0.23373253643512726,
      "learning_rate": 8.178038545228475e-06,
      "loss": 0.1687,
      "step": 4689
    },
    {
      "epoch": 0.36447000310848615,
      "grad_norm": 0.5336052775382996,
      "learning_rate": 8.17764998445757e-06,
      "loss": 0.3843,
      "step": 4690
    },
    {
      "epoch": 0.3645477152626671,
      "grad_norm": 0.28681182861328125,
      "learning_rate": 8.177261423686665e-06,
      "loss": 0.1002,
      "step": 4691
    },
    {
      "epoch": 0.364625427416848,
      "grad_norm": 0.6400207281112671,
      "learning_rate": 8.176872862915762e-06,
      "loss": 0.5391,
      "step": 4692
    },
    {
      "epoch": 0.3647031395710289,
      "grad_norm": 0.18902726471424103,
      "learning_rate": 8.176484302144857e-06,
      "loss": 0.075,
      "step": 4693
    },
    {
      "epoch": 0.3647808517252098,
      "grad_norm": 0.24352490901947021,
      "learning_rate": 8.176095741373952e-06,
      "loss": 0.1074,
      "step": 4694
    },
    {
      "epoch": 0.36485856387939075,
      "grad_norm": 0.28015491366386414,
      "learning_rate": 8.175707180603048e-06,
      "loss": 0.2645,
      "step": 4695
    },
    {
      "epoch": 0.36493627603357165,
      "grad_norm": 0.29757899045944214,
      "learning_rate": 8.175318619832141e-06,
      "loss": 0.1196,
      "step": 4696
    },
    {
      "epoch": 0.36501398818775255,
      "grad_norm": 0.835041880607605,
      "learning_rate": 8.174930059061238e-06,
      "loss": 0.2163,
      "step": 4697
    },
    {
      "epoch": 0.3650917003419335,
      "grad_norm": 0.6389099359512329,
      "learning_rate": 8.174541498290333e-06,
      "loss": 0.8083,
      "step": 4698
    },
    {
      "epoch": 0.3651694124961144,
      "grad_norm": 0.21919652819633484,
      "learning_rate": 8.174152937519428e-06,
      "loss": 0.1404,
      "step": 4699
    },
    {
      "epoch": 0.3652471246502953,
      "grad_norm": 0.2634170353412628,
      "learning_rate": 8.173764376748525e-06,
      "loss": 0.0594,
      "step": 4700
    },
    {
      "epoch": 0.3653248368044762,
      "grad_norm": 0.19690704345703125,
      "learning_rate": 8.17337581597762e-06,
      "loss": 0.0598,
      "step": 4701
    },
    {
      "epoch": 0.36540254895865715,
      "grad_norm": 0.2875707447528839,
      "learning_rate": 8.172987255206715e-06,
      "loss": 0.5938,
      "step": 4702
    },
    {
      "epoch": 0.36548026111283805,
      "grad_norm": 0.39009585976600647,
      "learning_rate": 8.172598694435811e-06,
      "loss": 0.1681,
      "step": 4703
    },
    {
      "epoch": 0.36555797326701894,
      "grad_norm": 0.35682135820388794,
      "learning_rate": 8.172210133664906e-06,
      "loss": 0.133,
      "step": 4704
    },
    {
      "epoch": 0.3656356854211999,
      "grad_norm": 0.12699288129806519,
      "learning_rate": 8.171821572894001e-06,
      "loss": 0.0409,
      "step": 4705
    },
    {
      "epoch": 0.3657133975753808,
      "grad_norm": 0.12486189603805542,
      "learning_rate": 8.171433012123096e-06,
      "loss": 0.0622,
      "step": 4706
    },
    {
      "epoch": 0.3657911097295617,
      "grad_norm": 0.14408156275749207,
      "learning_rate": 8.171044451352193e-06,
      "loss": 0.0567,
      "step": 4707
    },
    {
      "epoch": 0.3658688218837426,
      "grad_norm": 0.15182271599769592,
      "learning_rate": 8.170655890581288e-06,
      "loss": 0.0681,
      "step": 4708
    },
    {
      "epoch": 0.36594653403792354,
      "grad_norm": 0.46018290519714355,
      "learning_rate": 8.170267329810383e-06,
      "loss": 0.2155,
      "step": 4709
    },
    {
      "epoch": 0.36602424619210444,
      "grad_norm": 0.4694400131702423,
      "learning_rate": 8.16987876903948e-06,
      "loss": 0.1141,
      "step": 4710
    },
    {
      "epoch": 0.36610195834628534,
      "grad_norm": 0.2022901326417923,
      "learning_rate": 8.169490208268574e-06,
      "loss": 0.1088,
      "step": 4711
    },
    {
      "epoch": 0.3661796705004663,
      "grad_norm": 0.25110384821891785,
      "learning_rate": 8.169101647497669e-06,
      "loss": 0.1412,
      "step": 4712
    },
    {
      "epoch": 0.3662573826546472,
      "grad_norm": 0.12538044154644012,
      "learning_rate": 8.168713086726766e-06,
      "loss": 0.0348,
      "step": 4713
    },
    {
      "epoch": 0.3663350948088281,
      "grad_norm": 0.40099799633026123,
      "learning_rate": 8.168324525955859e-06,
      "loss": 0.4207,
      "step": 4714
    },
    {
      "epoch": 0.36641280696300904,
      "grad_norm": 0.19515253603458405,
      "learning_rate": 8.167935965184956e-06,
      "loss": 0.054,
      "step": 4715
    },
    {
      "epoch": 0.36649051911718994,
      "grad_norm": 0.23364309966564178,
      "learning_rate": 8.16754740441405e-06,
      "loss": 0.1564,
      "step": 4716
    },
    {
      "epoch": 0.36656823127137084,
      "grad_norm": 0.5895026326179504,
      "learning_rate": 8.167158843643146e-06,
      "loss": 0.5072,
      "step": 4717
    },
    {
      "epoch": 0.36664594342555173,
      "grad_norm": 0.217454731464386,
      "learning_rate": 8.166770282872242e-06,
      "loss": 0.2118,
      "step": 4718
    },
    {
      "epoch": 0.3667236555797327,
      "grad_norm": 0.27731114625930786,
      "learning_rate": 8.166381722101337e-06,
      "loss": 0.043,
      "step": 4719
    },
    {
      "epoch": 0.3668013677339136,
      "grad_norm": 0.4033067226409912,
      "learning_rate": 8.165993161330434e-06,
      "loss": 0.1089,
      "step": 4720
    },
    {
      "epoch": 0.3668790798880945,
      "grad_norm": 0.6454675793647766,
      "learning_rate": 8.165604600559529e-06,
      "loss": 0.1778,
      "step": 4721
    },
    {
      "epoch": 0.36695679204227544,
      "grad_norm": 0.46241751313209534,
      "learning_rate": 8.165216039788624e-06,
      "loss": 0.0927,
      "step": 4722
    },
    {
      "epoch": 0.36703450419645633,
      "grad_norm": 0.1958845555782318,
      "learning_rate": 8.16482747901772e-06,
      "loss": 0.0458,
      "step": 4723
    },
    {
      "epoch": 0.36711221635063723,
      "grad_norm": 0.10841378569602966,
      "learning_rate": 8.164438918246814e-06,
      "loss": 0.022,
      "step": 4724
    },
    {
      "epoch": 0.36718992850481813,
      "grad_norm": 0.030398624017834663,
      "learning_rate": 8.16405035747591e-06,
      "loss": 0.0069,
      "step": 4725
    },
    {
      "epoch": 0.3672676406589991,
      "grad_norm": 0.3964315354824066,
      "learning_rate": 8.163661796705005e-06,
      "loss": 0.4615,
      "step": 4726
    },
    {
      "epoch": 0.36734535281318,
      "grad_norm": 0.5343881249427795,
      "learning_rate": 8.1632732359341e-06,
      "loss": 0.2859,
      "step": 4727
    },
    {
      "epoch": 0.3674230649673609,
      "grad_norm": 0.16626685857772827,
      "learning_rate": 8.162884675163197e-06,
      "loss": 0.0439,
      "step": 4728
    },
    {
      "epoch": 0.36750077712154183,
      "grad_norm": 0.13997919857501984,
      "learning_rate": 8.162496114392292e-06,
      "loss": 0.0466,
      "step": 4729
    },
    {
      "epoch": 0.36757848927572273,
      "grad_norm": 0.28963494300842285,
      "learning_rate": 8.162107553621387e-06,
      "loss": 0.1554,
      "step": 4730
    },
    {
      "epoch": 0.36765620142990363,
      "grad_norm": 0.2046310156583786,
      "learning_rate": 8.161718992850483e-06,
      "loss": 0.3161,
      "step": 4731
    },
    {
      "epoch": 0.3677339135840845,
      "grad_norm": 0.48170238733291626,
      "learning_rate": 8.161330432079578e-06,
      "loss": 0.183,
      "step": 4732
    },
    {
      "epoch": 0.3678116257382655,
      "grad_norm": 0.18640545010566711,
      "learning_rate": 8.160941871308673e-06,
      "loss": 0.0834,
      "step": 4733
    },
    {
      "epoch": 0.3678893378924464,
      "grad_norm": 0.3029864430427551,
      "learning_rate": 8.160553310537768e-06,
      "loss": 0.0381,
      "step": 4734
    },
    {
      "epoch": 0.3679670500466273,
      "grad_norm": 0.10067799687385559,
      "learning_rate": 8.160164749766865e-06,
      "loss": 0.0439,
      "step": 4735
    },
    {
      "epoch": 0.36804476220080823,
      "grad_norm": 0.07852394878864288,
      "learning_rate": 8.15977618899596e-06,
      "loss": 0.0389,
      "step": 4736
    },
    {
      "epoch": 0.3681224743549891,
      "grad_norm": 0.24166469275951385,
      "learning_rate": 8.159387628225055e-06,
      "loss": 0.0626,
      "step": 4737
    },
    {
      "epoch": 0.36820018650917,
      "grad_norm": 0.27459394931793213,
      "learning_rate": 8.158999067454151e-06,
      "loss": 0.126,
      "step": 4738
    },
    {
      "epoch": 0.3682778986633509,
      "grad_norm": 0.2403727024793625,
      "learning_rate": 8.158610506683246e-06,
      "loss": 0.2075,
      "step": 4739
    },
    {
      "epoch": 0.3683556108175319,
      "grad_norm": 0.499863862991333,
      "learning_rate": 8.158221945912341e-06,
      "loss": 0.445,
      "step": 4740
    },
    {
      "epoch": 0.3684333229717128,
      "grad_norm": 0.3288167715072632,
      "learning_rate": 8.157833385141438e-06,
      "loss": 0.1873,
      "step": 4741
    },
    {
      "epoch": 0.36851103512589367,
      "grad_norm": 0.4468742907047272,
      "learning_rate": 8.157444824370531e-06,
      "loss": 0.0791,
      "step": 4742
    },
    {
      "epoch": 0.3685887472800746,
      "grad_norm": 0.6985996961593628,
      "learning_rate": 8.157056263599628e-06,
      "loss": 0.5685,
      "step": 4743
    },
    {
      "epoch": 0.3686664594342555,
      "grad_norm": 0.12121181935071945,
      "learning_rate": 8.156667702828723e-06,
      "loss": 0.0312,
      "step": 4744
    },
    {
      "epoch": 0.3687441715884364,
      "grad_norm": 0.1578715592622757,
      "learning_rate": 8.156279142057818e-06,
      "loss": 0.0662,
      "step": 4745
    },
    {
      "epoch": 0.3688218837426173,
      "grad_norm": 0.11100362241268158,
      "learning_rate": 8.155890581286914e-06,
      "loss": 0.0501,
      "step": 4746
    },
    {
      "epoch": 0.36889959589679827,
      "grad_norm": 0.1626601368188858,
      "learning_rate": 8.15550202051601e-06,
      "loss": 0.0599,
      "step": 4747
    },
    {
      "epoch": 0.36897730805097917,
      "grad_norm": 0.35843947529792786,
      "learning_rate": 8.155113459745104e-06,
      "loss": 0.2121,
      "step": 4748
    },
    {
      "epoch": 0.36905502020516007,
      "grad_norm": 0.12493031471967697,
      "learning_rate": 8.1547248989742e-06,
      "loss": 0.0413,
      "step": 4749
    },
    {
      "epoch": 0.369132732359341,
      "grad_norm": 0.21364104747772217,
      "learning_rate": 8.154336338203296e-06,
      "loss": 0.1157,
      "step": 4750
    },
    {
      "epoch": 0.3692104445135219,
      "grad_norm": 0.3041357100009918,
      "learning_rate": 8.15394777743239e-06,
      "loss": 0.1024,
      "step": 4751
    },
    {
      "epoch": 0.3692881566677028,
      "grad_norm": 0.16112591326236725,
      "learning_rate": 8.153559216661486e-06,
      "loss": 0.0329,
      "step": 4752
    },
    {
      "epoch": 0.36936586882188377,
      "grad_norm": 0.142837256193161,
      "learning_rate": 8.153170655890582e-06,
      "loss": 0.0975,
      "step": 4753
    },
    {
      "epoch": 0.36944358097606467,
      "grad_norm": 0.183870330452919,
      "learning_rate": 8.152782095119677e-06,
      "loss": 0.0428,
      "step": 4754
    },
    {
      "epoch": 0.36952129313024557,
      "grad_norm": 0.4659372866153717,
      "learning_rate": 8.152393534348772e-06,
      "loss": 0.0917,
      "step": 4755
    },
    {
      "epoch": 0.36959900528442646,
      "grad_norm": 0.03822647035121918,
      "learning_rate": 8.152004973577869e-06,
      "loss": 0.0103,
      "step": 4756
    },
    {
      "epoch": 0.3696767174386074,
      "grad_norm": 0.3603190779685974,
      "learning_rate": 8.151616412806964e-06,
      "loss": 0.153,
      "step": 4757
    },
    {
      "epoch": 0.3697544295927883,
      "grad_norm": 0.4211376905441284,
      "learning_rate": 8.151227852036059e-06,
      "loss": 0.2845,
      "step": 4758
    },
    {
      "epoch": 0.3698321417469692,
      "grad_norm": 0.8101918697357178,
      "learning_rate": 8.150839291265154e-06,
      "loss": 0.4612,
      "step": 4759
    },
    {
      "epoch": 0.36990985390115017,
      "grad_norm": 0.2354288101196289,
      "learning_rate": 8.15045073049425e-06,
      "loss": 0.2513,
      "step": 4760
    },
    {
      "epoch": 0.36998756605533106,
      "grad_norm": 1.3536980152130127,
      "learning_rate": 8.150062169723345e-06,
      "loss": 0.2781,
      "step": 4761
    },
    {
      "epoch": 0.37006527820951196,
      "grad_norm": 0.08099788427352905,
      "learning_rate": 8.14967360895244e-06,
      "loss": 0.0239,
      "step": 4762
    },
    {
      "epoch": 0.37014299036369286,
      "grad_norm": 0.30491089820861816,
      "learning_rate": 8.149285048181537e-06,
      "loss": 0.6022,
      "step": 4763
    },
    {
      "epoch": 0.3702207025178738,
      "grad_norm": 0.16774386167526245,
      "learning_rate": 8.148896487410632e-06,
      "loss": 0.1031,
      "step": 4764
    },
    {
      "epoch": 0.3702984146720547,
      "grad_norm": 0.47360527515411377,
      "learning_rate": 8.148507926639727e-06,
      "loss": 0.1149,
      "step": 4765
    },
    {
      "epoch": 0.3703761268262356,
      "grad_norm": 0.19873492419719696,
      "learning_rate": 8.148119365868824e-06,
      "loss": 0.0706,
      "step": 4766
    },
    {
      "epoch": 0.37045383898041656,
      "grad_norm": 0.37789517641067505,
      "learning_rate": 8.147730805097917e-06,
      "loss": 0.1067,
      "step": 4767
    },
    {
      "epoch": 0.37053155113459746,
      "grad_norm": 0.5655208826065063,
      "learning_rate": 8.147342244327013e-06,
      "loss": 0.1044,
      "step": 4768
    },
    {
      "epoch": 0.37060926328877836,
      "grad_norm": 0.4095967411994934,
      "learning_rate": 8.146953683556108e-06,
      "loss": 0.1642,
      "step": 4769
    },
    {
      "epoch": 0.37068697544295925,
      "grad_norm": 0.3386698067188263,
      "learning_rate": 8.146565122785203e-06,
      "loss": 0.1792,
      "step": 4770
    },
    {
      "epoch": 0.3707646875971402,
      "grad_norm": 0.18043498694896698,
      "learning_rate": 8.1461765620143e-06,
      "loss": 0.0516,
      "step": 4771
    },
    {
      "epoch": 0.3708423997513211,
      "grad_norm": 0.05575263872742653,
      "learning_rate": 8.145788001243395e-06,
      "loss": 0.0096,
      "step": 4772
    },
    {
      "epoch": 0.370920111905502,
      "grad_norm": 0.2894902229309082,
      "learning_rate": 8.14539944047249e-06,
      "loss": 0.0971,
      "step": 4773
    },
    {
      "epoch": 0.37099782405968296,
      "grad_norm": 0.7381629943847656,
      "learning_rate": 8.145010879701587e-06,
      "loss": 0.2453,
      "step": 4774
    },
    {
      "epoch": 0.37107553621386385,
      "grad_norm": 0.3350391089916229,
      "learning_rate": 8.144622318930681e-06,
      "loss": 0.138,
      "step": 4775
    },
    {
      "epoch": 0.37115324836804475,
      "grad_norm": 0.8378434181213379,
      "learning_rate": 8.144233758159776e-06,
      "loss": 0.208,
      "step": 4776
    },
    {
      "epoch": 0.37123096052222565,
      "grad_norm": 0.3865618109703064,
      "learning_rate": 8.143845197388871e-06,
      "loss": 0.0861,
      "step": 4777
    },
    {
      "epoch": 0.3713086726764066,
      "grad_norm": 0.09435176849365234,
      "learning_rate": 8.143456636617968e-06,
      "loss": 0.0558,
      "step": 4778
    },
    {
      "epoch": 0.3713863848305875,
      "grad_norm": 0.11299286782741547,
      "learning_rate": 8.143068075847063e-06,
      "loss": 0.0491,
      "step": 4779
    },
    {
      "epoch": 0.3714640969847684,
      "grad_norm": 0.09924747794866562,
      "learning_rate": 8.142679515076158e-06,
      "loss": 0.0357,
      "step": 4780
    },
    {
      "epoch": 0.37154180913894935,
      "grad_norm": 0.10834002494812012,
      "learning_rate": 8.142290954305255e-06,
      "loss": 0.0184,
      "step": 4781
    },
    {
      "epoch": 0.37161952129313025,
      "grad_norm": 0.2908678948879242,
      "learning_rate": 8.14190239353435e-06,
      "loss": 0.4545,
      "step": 4782
    },
    {
      "epoch": 0.37169723344731115,
      "grad_norm": 0.23428970575332642,
      "learning_rate": 8.141513832763444e-06,
      "loss": 0.1128,
      "step": 4783
    },
    {
      "epoch": 0.37177494560149205,
      "grad_norm": 0.11817502975463867,
      "learning_rate": 8.141125271992541e-06,
      "loss": 0.019,
      "step": 4784
    },
    {
      "epoch": 0.371852657755673,
      "grad_norm": 0.151650071144104,
      "learning_rate": 8.140736711221636e-06,
      "loss": 0.0186,
      "step": 4785
    },
    {
      "epoch": 0.3719303699098539,
      "grad_norm": 0.5440642237663269,
      "learning_rate": 8.140348150450731e-06,
      "loss": 0.1958,
      "step": 4786
    },
    {
      "epoch": 0.3720080820640348,
      "grad_norm": 0.19120264053344727,
      "learning_rate": 8.139959589679826e-06,
      "loss": 0.0412,
      "step": 4787
    },
    {
      "epoch": 0.37208579421821575,
      "grad_norm": 0.2510359585285187,
      "learning_rate": 8.139571028908923e-06,
      "loss": 0.0774,
      "step": 4788
    },
    {
      "epoch": 0.37216350637239665,
      "grad_norm": 1.2208582162857056,
      "learning_rate": 8.139182468138018e-06,
      "loss": 0.4353,
      "step": 4789
    },
    {
      "epoch": 0.37224121852657754,
      "grad_norm": 0.504235565662384,
      "learning_rate": 8.138793907367112e-06,
      "loss": 0.368,
      "step": 4790
    },
    {
      "epoch": 0.3723189306807585,
      "grad_norm": 0.42102545499801636,
      "learning_rate": 8.138405346596209e-06,
      "loss": 0.1831,
      "step": 4791
    },
    {
      "epoch": 0.3723966428349394,
      "grad_norm": 0.29221171140670776,
      "learning_rate": 8.138016785825304e-06,
      "loss": 0.2453,
      "step": 4792
    },
    {
      "epoch": 0.3724743549891203,
      "grad_norm": 0.3996557295322418,
      "learning_rate": 8.137628225054399e-06,
      "loss": 0.6245,
      "step": 4793
    },
    {
      "epoch": 0.3725520671433012,
      "grad_norm": 0.3379179537296295,
      "learning_rate": 8.137239664283496e-06,
      "loss": 0.206,
      "step": 4794
    },
    {
      "epoch": 0.37262977929748214,
      "grad_norm": 0.497027188539505,
      "learning_rate": 8.136851103512589e-06,
      "loss": 0.2531,
      "step": 4795
    },
    {
      "epoch": 0.37270749145166304,
      "grad_norm": 0.22441309690475464,
      "learning_rate": 8.136462542741686e-06,
      "loss": 0.0393,
      "step": 4796
    },
    {
      "epoch": 0.37278520360584394,
      "grad_norm": 0.21771977841854095,
      "learning_rate": 8.13607398197078e-06,
      "loss": 0.1356,
      "step": 4797
    },
    {
      "epoch": 0.3728629157600249,
      "grad_norm": 0.4019004702568054,
      "learning_rate": 8.135685421199875e-06,
      "loss": 0.1061,
      "step": 4798
    },
    {
      "epoch": 0.3729406279142058,
      "grad_norm": 0.15282732248306274,
      "learning_rate": 8.135296860428972e-06,
      "loss": 0.0652,
      "step": 4799
    },
    {
      "epoch": 0.3730183400683867,
      "grad_norm": 0.30144497752189636,
      "learning_rate": 8.134908299658067e-06,
      "loss": 0.1824,
      "step": 4800
    },
    {
      "epoch": 0.3730960522225676,
      "grad_norm": 0.47768595814704895,
      "learning_rate": 8.134519738887162e-06,
      "loss": 0.2198,
      "step": 4801
    },
    {
      "epoch": 0.37317376437674854,
      "grad_norm": 0.20181904733181,
      "learning_rate": 8.134131178116259e-06,
      "loss": 0.1027,
      "step": 4802
    },
    {
      "epoch": 0.37325147653092944,
      "grad_norm": 0.24713647365570068,
      "learning_rate": 8.133742617345354e-06,
      "loss": 0.0702,
      "step": 4803
    },
    {
      "epoch": 0.37332918868511034,
      "grad_norm": 0.4590666592121124,
      "learning_rate": 8.133354056574449e-06,
      "loss": 0.2239,
      "step": 4804
    },
    {
      "epoch": 0.3734069008392913,
      "grad_norm": 0.8134438991546631,
      "learning_rate": 8.132965495803544e-06,
      "loss": 0.5768,
      "step": 4805
    },
    {
      "epoch": 0.3734846129934722,
      "grad_norm": 0.30043473839759827,
      "learning_rate": 8.13257693503264e-06,
      "loss": 0.1549,
      "step": 4806
    },
    {
      "epoch": 0.3735623251476531,
      "grad_norm": 0.3923438489437103,
      "learning_rate": 8.132188374261735e-06,
      "loss": 0.1771,
      "step": 4807
    },
    {
      "epoch": 0.373640037301834,
      "grad_norm": 0.4925355911254883,
      "learning_rate": 8.13179981349083e-06,
      "loss": 0.1795,
      "step": 4808
    },
    {
      "epoch": 0.37371774945601494,
      "grad_norm": 0.2652586102485657,
      "learning_rate": 8.131411252719927e-06,
      "loss": 0.1203,
      "step": 4809
    },
    {
      "epoch": 0.37379546161019583,
      "grad_norm": 0.1842738837003708,
      "learning_rate": 8.131022691949022e-06,
      "loss": 0.0999,
      "step": 4810
    },
    {
      "epoch": 0.37387317376437673,
      "grad_norm": 0.4370998442173004,
      "learning_rate": 8.130634131178117e-06,
      "loss": 0.363,
      "step": 4811
    },
    {
      "epoch": 0.3739508859185577,
      "grad_norm": 0.324006050825119,
      "learning_rate": 8.130245570407213e-06,
      "loss": 0.1298,
      "step": 4812
    },
    {
      "epoch": 0.3740285980727386,
      "grad_norm": 0.2965884804725647,
      "learning_rate": 8.129857009636308e-06,
      "loss": 0.2227,
      "step": 4813
    },
    {
      "epoch": 0.3741063102269195,
      "grad_norm": 0.24633583426475525,
      "learning_rate": 8.129468448865403e-06,
      "loss": 0.0124,
      "step": 4814
    },
    {
      "epoch": 0.3741840223811004,
      "grad_norm": 0.28223416209220886,
      "learning_rate": 8.129079888094498e-06,
      "loss": 0.1969,
      "step": 4815
    },
    {
      "epoch": 0.37426173453528133,
      "grad_norm": 0.5815720558166504,
      "learning_rate": 8.128691327323595e-06,
      "loss": 0.2831,
      "step": 4816
    },
    {
      "epoch": 0.37433944668946223,
      "grad_norm": 0.6956375241279602,
      "learning_rate": 8.12830276655269e-06,
      "loss": 0.1666,
      "step": 4817
    },
    {
      "epoch": 0.3744171588436431,
      "grad_norm": 0.718520998954773,
      "learning_rate": 8.127914205781785e-06,
      "loss": 0.2345,
      "step": 4818
    },
    {
      "epoch": 0.3744948709978241,
      "grad_norm": 0.3549518585205078,
      "learning_rate": 8.127525645010881e-06,
      "loss": 0.2315,
      "step": 4819
    },
    {
      "epoch": 0.374572583152005,
      "grad_norm": 0.44720742106437683,
      "learning_rate": 8.127137084239976e-06,
      "loss": 0.0715,
      "step": 4820
    },
    {
      "epoch": 0.3746502953061859,
      "grad_norm": 0.326496958732605,
      "learning_rate": 8.126748523469071e-06,
      "loss": 0.4854,
      "step": 4821
    },
    {
      "epoch": 0.3747280074603668,
      "grad_norm": 0.3185969293117523,
      "learning_rate": 8.126359962698168e-06,
      "loss": 0.0431,
      "step": 4822
    },
    {
      "epoch": 0.3748057196145477,
      "grad_norm": 0.45420005917549133,
      "learning_rate": 8.125971401927261e-06,
      "loss": 0.1226,
      "step": 4823
    },
    {
      "epoch": 0.3748834317687286,
      "grad_norm": 0.3249237835407257,
      "learning_rate": 8.125582841156358e-06,
      "loss": 0.1535,
      "step": 4824
    },
    {
      "epoch": 0.3749611439229095,
      "grad_norm": 0.5288820266723633,
      "learning_rate": 8.125194280385453e-06,
      "loss": 0.1116,
      "step": 4825
    },
    {
      "epoch": 0.3750388560770905,
      "grad_norm": 0.3731250762939453,
      "learning_rate": 8.124805719614548e-06,
      "loss": 0.1378,
      "step": 4826
    },
    {
      "epoch": 0.3751165682312714,
      "grad_norm": 0.28931641578674316,
      "learning_rate": 8.124417158843644e-06,
      "loss": 0.1597,
      "step": 4827
    },
    {
      "epoch": 0.3751942803854523,
      "grad_norm": 0.3399127721786499,
      "learning_rate": 8.12402859807274e-06,
      "loss": 0.116,
      "step": 4828
    },
    {
      "epoch": 0.3752719925396332,
      "grad_norm": 0.09981109946966171,
      "learning_rate": 8.123640037301834e-06,
      "loss": 0.0323,
      "step": 4829
    },
    {
      "epoch": 0.3753497046938141,
      "grad_norm": 0.25447389483451843,
      "learning_rate": 8.12325147653093e-06,
      "loss": 0.0462,
      "step": 4830
    },
    {
      "epoch": 0.375427416847995,
      "grad_norm": 0.3015136122703552,
      "learning_rate": 8.122862915760026e-06,
      "loss": 0.1195,
      "step": 4831
    },
    {
      "epoch": 0.3755051290021759,
      "grad_norm": 0.3149011731147766,
      "learning_rate": 8.12247435498912e-06,
      "loss": 0.194,
      "step": 4832
    },
    {
      "epoch": 0.3755828411563569,
      "grad_norm": 0.2421233355998993,
      "learning_rate": 8.122085794218216e-06,
      "loss": 0.1745,
      "step": 4833
    },
    {
      "epoch": 0.37566055331053777,
      "grad_norm": 0.19536499679088593,
      "learning_rate": 8.121697233447312e-06,
      "loss": 0.0937,
      "step": 4834
    },
    {
      "epoch": 0.37573826546471867,
      "grad_norm": 0.5431289672851562,
      "learning_rate": 8.121308672676407e-06,
      "loss": 0.2416,
      "step": 4835
    },
    {
      "epoch": 0.3758159776188996,
      "grad_norm": 0.49961984157562256,
      "learning_rate": 8.120920111905502e-06,
      "loss": 0.0996,
      "step": 4836
    },
    {
      "epoch": 0.3758936897730805,
      "grad_norm": 0.3420919179916382,
      "learning_rate": 8.120531551134599e-06,
      "loss": 0.1536,
      "step": 4837
    },
    {
      "epoch": 0.3759714019272614,
      "grad_norm": 0.04663155600428581,
      "learning_rate": 8.120142990363694e-06,
      "loss": 0.0255,
      "step": 4838
    },
    {
      "epoch": 0.3760491140814423,
      "grad_norm": 0.36568206548690796,
      "learning_rate": 8.119754429592789e-06,
      "loss": 0.2446,
      "step": 4839
    },
    {
      "epoch": 0.37612682623562327,
      "grad_norm": 0.7571645975112915,
      "learning_rate": 8.119365868821885e-06,
      "loss": 0.1912,
      "step": 4840
    },
    {
      "epoch": 0.37620453838980417,
      "grad_norm": 0.0669693723320961,
      "learning_rate": 8.11897730805098e-06,
      "loss": 0.023,
      "step": 4841
    },
    {
      "epoch": 0.37628225054398506,
      "grad_norm": 0.31481844186782837,
      "learning_rate": 8.118588747280075e-06,
      "loss": 0.1549,
      "step": 4842
    },
    {
      "epoch": 0.376359962698166,
      "grad_norm": 0.6091675758361816,
      "learning_rate": 8.11820018650917e-06,
      "loss": 0.3621,
      "step": 4843
    },
    {
      "epoch": 0.3764376748523469,
      "grad_norm": 0.25201383233070374,
      "learning_rate": 8.117811625738267e-06,
      "loss": 0.1549,
      "step": 4844
    },
    {
      "epoch": 0.3765153870065278,
      "grad_norm": 2.747710704803467,
      "learning_rate": 8.117423064967362e-06,
      "loss": 0.4226,
      "step": 4845
    },
    {
      "epoch": 0.3765930991607087,
      "grad_norm": 0.5053659677505493,
      "learning_rate": 8.117034504196457e-06,
      "loss": 0.3359,
      "step": 4846
    },
    {
      "epoch": 0.37667081131488966,
      "grad_norm": 0.2450869381427765,
      "learning_rate": 8.116645943425553e-06,
      "loss": 0.0451,
      "step": 4847
    },
    {
      "epoch": 0.37674852346907056,
      "grad_norm": 0.425479531288147,
      "learning_rate": 8.116257382654648e-06,
      "loss": 0.3356,
      "step": 4848
    },
    {
      "epoch": 0.37682623562325146,
      "grad_norm": 0.18317143619060516,
      "learning_rate": 8.115868821883743e-06,
      "loss": 0.0586,
      "step": 4849
    },
    {
      "epoch": 0.3769039477774324,
      "grad_norm": 0.2101927399635315,
      "learning_rate": 8.11548026111284e-06,
      "loss": 0.0989,
      "step": 4850
    },
    {
      "epoch": 0.3769816599316133,
      "grad_norm": 0.3235171139240265,
      "learning_rate": 8.115091700341933e-06,
      "loss": 0.1262,
      "step": 4851
    },
    {
      "epoch": 0.3770593720857942,
      "grad_norm": 0.7328769564628601,
      "learning_rate": 8.11470313957103e-06,
      "loss": 0.4675,
      "step": 4852
    },
    {
      "epoch": 0.3771370842399751,
      "grad_norm": 0.37441685795783997,
      "learning_rate": 8.114314578800125e-06,
      "loss": 0.175,
      "step": 4853
    },
    {
      "epoch": 0.37721479639415606,
      "grad_norm": 0.26102903485298157,
      "learning_rate": 8.11392601802922e-06,
      "loss": 0.0576,
      "step": 4854
    },
    {
      "epoch": 0.37729250854833696,
      "grad_norm": 0.6892828345298767,
      "learning_rate": 8.113537457258316e-06,
      "loss": 0.2243,
      "step": 4855
    },
    {
      "epoch": 0.37737022070251786,
      "grad_norm": 0.24961698055267334,
      "learning_rate": 8.113148896487411e-06,
      "loss": 0.1079,
      "step": 4856
    },
    {
      "epoch": 0.3774479328566988,
      "grad_norm": 0.28672686219215393,
      "learning_rate": 8.112760335716506e-06,
      "loss": 0.6118,
      "step": 4857
    },
    {
      "epoch": 0.3775256450108797,
      "grad_norm": 0.1727517992258072,
      "learning_rate": 8.112371774945603e-06,
      "loss": 0.0568,
      "step": 4858
    },
    {
      "epoch": 0.3776033571650606,
      "grad_norm": 0.3595626652240753,
      "learning_rate": 8.111983214174698e-06,
      "loss": 0.1917,
      "step": 4859
    },
    {
      "epoch": 0.3776810693192415,
      "grad_norm": 0.5955677628517151,
      "learning_rate": 8.111594653403793e-06,
      "loss": 0.2729,
      "step": 4860
    },
    {
      "epoch": 0.37775878147342246,
      "grad_norm": 0.44793203473091125,
      "learning_rate": 8.111206092632888e-06,
      "loss": 0.4032,
      "step": 4861
    },
    {
      "epoch": 0.37783649362760335,
      "grad_norm": 0.368502140045166,
      "learning_rate": 8.110817531861984e-06,
      "loss": 0.3231,
      "step": 4862
    },
    {
      "epoch": 0.37791420578178425,
      "grad_norm": 0.749491810798645,
      "learning_rate": 8.11042897109108e-06,
      "loss": 0.1529,
      "step": 4863
    },
    {
      "epoch": 0.3779919179359652,
      "grad_norm": 0.33705517649650574,
      "learning_rate": 8.110040410320174e-06,
      "loss": 0.535,
      "step": 4864
    },
    {
      "epoch": 0.3780696300901461,
      "grad_norm": 0.3233799934387207,
      "learning_rate": 8.109651849549271e-06,
      "loss": 0.112,
      "step": 4865
    },
    {
      "epoch": 0.378147342244327,
      "grad_norm": 0.3021874725818634,
      "learning_rate": 8.109263288778366e-06,
      "loss": 0.2981,
      "step": 4866
    },
    {
      "epoch": 0.37822505439850795,
      "grad_norm": 0.2988370358943939,
      "learning_rate": 8.108874728007461e-06,
      "loss": 0.2465,
      "step": 4867
    },
    {
      "epoch": 0.37830276655268885,
      "grad_norm": 0.2001708298921585,
      "learning_rate": 8.108486167236558e-06,
      "loss": 0.0703,
      "step": 4868
    },
    {
      "epoch": 0.37838047870686975,
      "grad_norm": 0.34324851632118225,
      "learning_rate": 8.10809760646565e-06,
      "loss": 0.1787,
      "step": 4869
    },
    {
      "epoch": 0.37845819086105065,
      "grad_norm": 0.1202830821275711,
      "learning_rate": 8.107709045694747e-06,
      "loss": 0.0205,
      "step": 4870
    },
    {
      "epoch": 0.3785359030152316,
      "grad_norm": 0.2294386327266693,
      "learning_rate": 8.107320484923842e-06,
      "loss": 0.206,
      "step": 4871
    },
    {
      "epoch": 0.3786136151694125,
      "grad_norm": 0.16659125685691833,
      "learning_rate": 8.106931924152939e-06,
      "loss": 0.0374,
      "step": 4872
    },
    {
      "epoch": 0.3786913273235934,
      "grad_norm": 0.7863404154777527,
      "learning_rate": 8.106543363382034e-06,
      "loss": 0.3622,
      "step": 4873
    },
    {
      "epoch": 0.37876903947777435,
      "grad_norm": 0.5000191330909729,
      "learning_rate": 8.106154802611129e-06,
      "loss": 0.1722,
      "step": 4874
    },
    {
      "epoch": 0.37884675163195525,
      "grad_norm": 5.33585262298584,
      "learning_rate": 8.105766241840226e-06,
      "loss": 1.8072,
      "step": 4875
    },
    {
      "epoch": 0.37892446378613615,
      "grad_norm": 0.49372273683547974,
      "learning_rate": 8.105377681069319e-06,
      "loss": 0.2329,
      "step": 4876
    },
    {
      "epoch": 0.37900217594031704,
      "grad_norm": 0.06300342082977295,
      "learning_rate": 8.104989120298415e-06,
      "loss": 0.013,
      "step": 4877
    },
    {
      "epoch": 0.379079888094498,
      "grad_norm": 0.3744194805622101,
      "learning_rate": 8.10460055952751e-06,
      "loss": 0.2743,
      "step": 4878
    },
    {
      "epoch": 0.3791576002486789,
      "grad_norm": 0.6251475811004639,
      "learning_rate": 8.104211998756605e-06,
      "loss": 0.2876,
      "step": 4879
    },
    {
      "epoch": 0.3792353124028598,
      "grad_norm": 0.06418098509311676,
      "learning_rate": 8.103823437985702e-06,
      "loss": 0.0098,
      "step": 4880
    },
    {
      "epoch": 0.37931302455704075,
      "grad_norm": 0.4929006099700928,
      "learning_rate": 8.103434877214797e-06,
      "loss": 0.6017,
      "step": 4881
    },
    {
      "epoch": 0.37939073671122164,
      "grad_norm": 0.5855623483657837,
      "learning_rate": 8.103046316443892e-06,
      "loss": 0.1368,
      "step": 4882
    },
    {
      "epoch": 0.37946844886540254,
      "grad_norm": 0.21606580913066864,
      "learning_rate": 8.102657755672989e-06,
      "loss": 0.0804,
      "step": 4883
    },
    {
      "epoch": 0.37954616101958344,
      "grad_norm": 0.1258893609046936,
      "learning_rate": 8.102269194902083e-06,
      "loss": 0.0778,
      "step": 4884
    },
    {
      "epoch": 0.3796238731737644,
      "grad_norm": 0.1687341183423996,
      "learning_rate": 8.101880634131178e-06,
      "loss": 0.0175,
      "step": 4885
    },
    {
      "epoch": 0.3797015853279453,
      "grad_norm": 0.08578096330165863,
      "learning_rate": 8.101492073360273e-06,
      "loss": 0.0259,
      "step": 4886
    },
    {
      "epoch": 0.3797792974821262,
      "grad_norm": 0.10038263350725174,
      "learning_rate": 8.10110351258937e-06,
      "loss": 0.0326,
      "step": 4887
    },
    {
      "epoch": 0.37985700963630714,
      "grad_norm": 0.1727287322282791,
      "learning_rate": 8.100714951818465e-06,
      "loss": 0.142,
      "step": 4888
    },
    {
      "epoch": 0.37993472179048804,
      "grad_norm": 0.24715043604373932,
      "learning_rate": 8.10032639104756e-06,
      "loss": 0.0811,
      "step": 4889
    },
    {
      "epoch": 0.38001243394466894,
      "grad_norm": 0.28774482011795044,
      "learning_rate": 8.099937830276657e-06,
      "loss": 0.2433,
      "step": 4890
    },
    {
      "epoch": 0.38009014609884983,
      "grad_norm": 0.35815638303756714,
      "learning_rate": 8.099549269505752e-06,
      "loss": 0.1355,
      "step": 4891
    },
    {
      "epoch": 0.3801678582530308,
      "grad_norm": 0.22295087575912476,
      "learning_rate": 8.099160708734846e-06,
      "loss": 0.0746,
      "step": 4892
    },
    {
      "epoch": 0.3802455704072117,
      "grad_norm": 0.2080841064453125,
      "learning_rate": 8.098772147963943e-06,
      "loss": 0.0703,
      "step": 4893
    },
    {
      "epoch": 0.3803232825613926,
      "grad_norm": 0.009848182089626789,
      "learning_rate": 8.098383587193036e-06,
      "loss": 0.0008,
      "step": 4894
    },
    {
      "epoch": 0.38040099471557354,
      "grad_norm": 4.006491661071777,
      "learning_rate": 8.097995026422133e-06,
      "loss": 0.7367,
      "step": 4895
    },
    {
      "epoch": 0.38047870686975443,
      "grad_norm": 0.9143891930580139,
      "learning_rate": 8.097606465651228e-06,
      "loss": 0.2547,
      "step": 4896
    },
    {
      "epoch": 0.38055641902393533,
      "grad_norm": 0.3579655587673187,
      "learning_rate": 8.097217904880323e-06,
      "loss": 0.155,
      "step": 4897
    },
    {
      "epoch": 0.38063413117811623,
      "grad_norm": 0.21663837134838104,
      "learning_rate": 8.09682934410942e-06,
      "loss": 0.0296,
      "step": 4898
    },
    {
      "epoch": 0.3807118433322972,
      "grad_norm": 0.4664693772792816,
      "learning_rate": 8.096440783338515e-06,
      "loss": 0.1981,
      "step": 4899
    },
    {
      "epoch": 0.3807895554864781,
      "grad_norm": 0.08268257975578308,
      "learning_rate": 8.09605222256761e-06,
      "loss": 0.0511,
      "step": 4900
    },
    {
      "epoch": 0.380867267640659,
      "grad_norm": 0.2289280742406845,
      "learning_rate": 8.095663661796706e-06,
      "loss": 0.0952,
      "step": 4901
    },
    {
      "epoch": 0.38094497979483993,
      "grad_norm": 0.05463741719722748,
      "learning_rate": 8.095275101025801e-06,
      "loss": 0.0067,
      "step": 4902
    },
    {
      "epoch": 0.38102269194902083,
      "grad_norm": 0.37568607926368713,
      "learning_rate": 8.094886540254898e-06,
      "loss": 0.2691,
      "step": 4903
    },
    {
      "epoch": 0.38110040410320173,
      "grad_norm": 0.41605323553085327,
      "learning_rate": 8.094497979483991e-06,
      "loss": 0.3343,
      "step": 4904
    },
    {
      "epoch": 0.3811781162573827,
      "grad_norm": 0.27988937497138977,
      "learning_rate": 8.094109418713088e-06,
      "loss": 0.1238,
      "step": 4905
    },
    {
      "epoch": 0.3812558284115636,
      "grad_norm": 0.3429948389530182,
      "learning_rate": 8.093720857942183e-06,
      "loss": 0.2236,
      "step": 4906
    },
    {
      "epoch": 0.3813335405657445,
      "grad_norm": 0.4730164408683777,
      "learning_rate": 8.093332297171278e-06,
      "loss": 0.547,
      "step": 4907
    },
    {
      "epoch": 0.3814112527199254,
      "grad_norm": 0.2885899841785431,
      "learning_rate": 8.092943736400374e-06,
      "loss": 0.1874,
      "step": 4908
    },
    {
      "epoch": 0.38148896487410633,
      "grad_norm": 0.6134086847305298,
      "learning_rate": 8.092555175629469e-06,
      "loss": 0.1591,
      "step": 4909
    },
    {
      "epoch": 0.3815666770282872,
      "grad_norm": 0.33641064167022705,
      "learning_rate": 8.092166614858564e-06,
      "loss": 0.1791,
      "step": 4910
    },
    {
      "epoch": 0.3816443891824681,
      "grad_norm": 0.6207249164581299,
      "learning_rate": 8.09177805408766e-06,
      "loss": 0.53,
      "step": 4911
    },
    {
      "epoch": 0.3817221013366491,
      "grad_norm": 0.4002520442008972,
      "learning_rate": 8.091389493316756e-06,
      "loss": 0.1213,
      "step": 4912
    },
    {
      "epoch": 0.38179981349083,
      "grad_norm": 0.3204752504825592,
      "learning_rate": 8.09100093254585e-06,
      "loss": 0.197,
      "step": 4913
    },
    {
      "epoch": 0.3818775256450109,
      "grad_norm": 0.1835228055715561,
      "learning_rate": 8.090612371774946e-06,
      "loss": 0.1067,
      "step": 4914
    },
    {
      "epoch": 0.38195523779919177,
      "grad_norm": 0.5489489436149597,
      "learning_rate": 8.090223811004042e-06,
      "loss": 0.2648,
      "step": 4915
    },
    {
      "epoch": 0.3820329499533727,
      "grad_norm": 0.8196207880973816,
      "learning_rate": 8.089835250233137e-06,
      "loss": 0.248,
      "step": 4916
    },
    {
      "epoch": 0.3821106621075536,
      "grad_norm": 0.3964884877204895,
      "learning_rate": 8.089446689462232e-06,
      "loss": 0.2165,
      "step": 4917
    },
    {
      "epoch": 0.3821883742617345,
      "grad_norm": 0.35241350531578064,
      "learning_rate": 8.089058128691329e-06,
      "loss": 0.2635,
      "step": 4918
    },
    {
      "epoch": 0.3822660864159155,
      "grad_norm": 1.3829667568206787,
      "learning_rate": 8.088669567920424e-06,
      "loss": 0.2477,
      "step": 4919
    },
    {
      "epoch": 0.38234379857009637,
      "grad_norm": 0.6320708394050598,
      "learning_rate": 8.088281007149519e-06,
      "loss": 0.2981,
      "step": 4920
    },
    {
      "epoch": 0.38242151072427727,
      "grad_norm": 0.4167127311229706,
      "learning_rate": 8.087892446378615e-06,
      "loss": 0.4271,
      "step": 4921
    },
    {
      "epoch": 0.38249922287845817,
      "grad_norm": 1.0003200769424438,
      "learning_rate": 8.087503885607709e-06,
      "loss": 1.15,
      "step": 4922
    },
    {
      "epoch": 0.3825769350326391,
      "grad_norm": 0.3147754371166229,
      "learning_rate": 8.087115324836805e-06,
      "loss": 0.1827,
      "step": 4923
    },
    {
      "epoch": 0.38265464718682,
      "grad_norm": 0.5164177417755127,
      "learning_rate": 8.0867267640659e-06,
      "loss": 0.1329,
      "step": 4924
    },
    {
      "epoch": 0.3827323593410009,
      "grad_norm": 0.30741769075393677,
      "learning_rate": 8.086338203294995e-06,
      "loss": 0.1258,
      "step": 4925
    },
    {
      "epoch": 0.38281007149518187,
      "grad_norm": 0.31636983156204224,
      "learning_rate": 8.085949642524092e-06,
      "loss": 0.1065,
      "step": 4926
    },
    {
      "epoch": 0.38288778364936277,
      "grad_norm": 0.24570995569229126,
      "learning_rate": 8.085561081753187e-06,
      "loss": 0.0824,
      "step": 4927
    },
    {
      "epoch": 0.38296549580354367,
      "grad_norm": 0.6166520118713379,
      "learning_rate": 8.085172520982282e-06,
      "loss": 0.1099,
      "step": 4928
    },
    {
      "epoch": 0.38304320795772456,
      "grad_norm": 0.16103187203407288,
      "learning_rate": 8.084783960211378e-06,
      "loss": 0.1046,
      "step": 4929
    },
    {
      "epoch": 0.3831209201119055,
      "grad_norm": 0.24080075323581696,
      "learning_rate": 8.084395399440473e-06,
      "loss": 0.0277,
      "step": 4930
    },
    {
      "epoch": 0.3831986322660864,
      "grad_norm": 0.484082967042923,
      "learning_rate": 8.084006838669568e-06,
      "loss": 0.1706,
      "step": 4931
    },
    {
      "epoch": 0.3832763444202673,
      "grad_norm": 0.3855322301387787,
      "learning_rate": 8.083618277898663e-06,
      "loss": 0.1757,
      "step": 4932
    },
    {
      "epoch": 0.38335405657444827,
      "grad_norm": 0.4868912398815155,
      "learning_rate": 8.08322971712776e-06,
      "loss": 0.3054,
      "step": 4933
    },
    {
      "epoch": 0.38343176872862916,
      "grad_norm": 0.5563400387763977,
      "learning_rate": 8.082841156356855e-06,
      "loss": 0.4696,
      "step": 4934
    },
    {
      "epoch": 0.38350948088281006,
      "grad_norm": 0.6286424398422241,
      "learning_rate": 8.08245259558595e-06,
      "loss": 0.3769,
      "step": 4935
    },
    {
      "epoch": 0.38358719303699096,
      "grad_norm": 0.20773713290691376,
      "learning_rate": 8.082064034815046e-06,
      "loss": 0.0948,
      "step": 4936
    },
    {
      "epoch": 0.3836649051911719,
      "grad_norm": 0.5310293436050415,
      "learning_rate": 8.081675474044141e-06,
      "loss": 0.2272,
      "step": 4937
    },
    {
      "epoch": 0.3837426173453528,
      "grad_norm": 0.09866724908351898,
      "learning_rate": 8.081286913273236e-06,
      "loss": 0.05,
      "step": 4938
    },
    {
      "epoch": 0.3838203294995337,
      "grad_norm": 2.5633721351623535,
      "learning_rate": 8.080898352502333e-06,
      "loss": 0.7476,
      "step": 4939
    },
    {
      "epoch": 0.38389804165371466,
      "grad_norm": 0.3456264138221741,
      "learning_rate": 8.080509791731428e-06,
      "loss": 0.1734,
      "step": 4940
    },
    {
      "epoch": 0.38397575380789556,
      "grad_norm": 0.7467876672744751,
      "learning_rate": 8.080121230960523e-06,
      "loss": 0.3485,
      "step": 4941
    },
    {
      "epoch": 0.38405346596207646,
      "grad_norm": 0.44560006260871887,
      "learning_rate": 8.079732670189618e-06,
      "loss": 0.1643,
      "step": 4942
    },
    {
      "epoch": 0.3841311781162574,
      "grad_norm": 0.17560020089149475,
      "learning_rate": 8.079344109418714e-06,
      "loss": 0.0683,
      "step": 4943
    },
    {
      "epoch": 0.3842088902704383,
      "grad_norm": 0.47273704409599304,
      "learning_rate": 8.07895554864781e-06,
      "loss": 0.3954,
      "step": 4944
    },
    {
      "epoch": 0.3842866024246192,
      "grad_norm": 0.3160091042518616,
      "learning_rate": 8.078566987876904e-06,
      "loss": 0.1566,
      "step": 4945
    },
    {
      "epoch": 0.3843643145788001,
      "grad_norm": 0.025302516296505928,
      "learning_rate": 8.078178427106001e-06,
      "loss": 0.0016,
      "step": 4946
    },
    {
      "epoch": 0.38444202673298106,
      "grad_norm": 0.15624213218688965,
      "learning_rate": 8.077789866335096e-06,
      "loss": 0.0304,
      "step": 4947
    },
    {
      "epoch": 0.38451973888716195,
      "grad_norm": 0.8258417844772339,
      "learning_rate": 8.07740130556419e-06,
      "loss": 0.5008,
      "step": 4948
    },
    {
      "epoch": 0.38459745104134285,
      "grad_norm": 0.46752235293388367,
      "learning_rate": 8.077012744793287e-06,
      "loss": 0.6151,
      "step": 4949
    },
    {
      "epoch": 0.3846751631955238,
      "grad_norm": 1.2246776819229126,
      "learning_rate": 8.07662418402238e-06,
      "loss": 0.1134,
      "step": 4950
    },
    {
      "epoch": 0.3847528753497047,
      "grad_norm": 0.18828707933425903,
      "learning_rate": 8.076235623251477e-06,
      "loss": 0.0889,
      "step": 4951
    },
    {
      "epoch": 0.3848305875038856,
      "grad_norm": 0.12897071242332458,
      "learning_rate": 8.075847062480572e-06,
      "loss": 0.013,
      "step": 4952
    },
    {
      "epoch": 0.3849082996580665,
      "grad_norm": 0.522928774356842,
      "learning_rate": 8.075458501709667e-06,
      "loss": 0.4213,
      "step": 4953
    },
    {
      "epoch": 0.38498601181224745,
      "grad_norm": 0.2877126932144165,
      "learning_rate": 8.075069940938764e-06,
      "loss": 0.3462,
      "step": 4954
    },
    {
      "epoch": 0.38506372396642835,
      "grad_norm": 0.39826861023902893,
      "learning_rate": 8.074681380167859e-06,
      "loss": 0.3937,
      "step": 4955
    },
    {
      "epoch": 0.38514143612060925,
      "grad_norm": 0.7427448630332947,
      "learning_rate": 8.074292819396954e-06,
      "loss": 0.2893,
      "step": 4956
    },
    {
      "epoch": 0.3852191482747902,
      "grad_norm": 0.3522871732711792,
      "learning_rate": 8.07390425862605e-06,
      "loss": 0.0794,
      "step": 4957
    },
    {
      "epoch": 0.3852968604289711,
      "grad_norm": 0.38466504216194153,
      "learning_rate": 8.073515697855145e-06,
      "loss": 0.1043,
      "step": 4958
    },
    {
      "epoch": 0.385374572583152,
      "grad_norm": 0.5319218635559082,
      "learning_rate": 8.07312713708424e-06,
      "loss": 0.3372,
      "step": 4959
    },
    {
      "epoch": 0.3854522847373329,
      "grad_norm": 0.24022984504699707,
      "learning_rate": 8.072738576313335e-06,
      "loss": 0.0929,
      "step": 4960
    },
    {
      "epoch": 0.38552999689151385,
      "grad_norm": 0.060726191848516464,
      "learning_rate": 8.072350015542432e-06,
      "loss": 0.0159,
      "step": 4961
    },
    {
      "epoch": 0.38560770904569475,
      "grad_norm": 0.20040149986743927,
      "learning_rate": 8.071961454771527e-06,
      "loss": 0.1478,
      "step": 4962
    },
    {
      "epoch": 0.38568542119987564,
      "grad_norm": 0.45756664872169495,
      "learning_rate": 8.071572894000622e-06,
      "loss": 0.0765,
      "step": 4963
    },
    {
      "epoch": 0.3857631333540566,
      "grad_norm": 0.1097729355096817,
      "learning_rate": 8.071184333229718e-06,
      "loss": 0.0373,
      "step": 4964
    },
    {
      "epoch": 0.3858408455082375,
      "grad_norm": 0.1542736142873764,
      "learning_rate": 8.070795772458813e-06,
      "loss": 0.0365,
      "step": 4965
    },
    {
      "epoch": 0.3859185576624184,
      "grad_norm": 0.14097237586975098,
      "learning_rate": 8.070407211687908e-06,
      "loss": 0.0265,
      "step": 4966
    },
    {
      "epoch": 0.3859962698165993,
      "grad_norm": 0.23794792592525482,
      "learning_rate": 8.070018650917005e-06,
      "loss": 0.1113,
      "step": 4967
    },
    {
      "epoch": 0.38607398197078024,
      "grad_norm": 1.7629445791244507,
      "learning_rate": 8.0696300901461e-06,
      "loss": 0.6358,
      "step": 4968
    },
    {
      "epoch": 0.38615169412496114,
      "grad_norm": 0.36800503730773926,
      "learning_rate": 8.069241529375195e-06,
      "loss": 0.2247,
      "step": 4969
    },
    {
      "epoch": 0.38622940627914204,
      "grad_norm": 0.25960904359817505,
      "learning_rate": 8.06885296860429e-06,
      "loss": 0.0767,
      "step": 4970
    },
    {
      "epoch": 0.386307118433323,
      "grad_norm": 0.11199575662612915,
      "learning_rate": 8.068464407833386e-06,
      "loss": 0.0256,
      "step": 4971
    },
    {
      "epoch": 0.3863848305875039,
      "grad_norm": 0.5286092758178711,
      "learning_rate": 8.068075847062481e-06,
      "loss": 0.1613,
      "step": 4972
    },
    {
      "epoch": 0.3864625427416848,
      "grad_norm": 0.24306125938892365,
      "learning_rate": 8.067687286291576e-06,
      "loss": 0.0978,
      "step": 4973
    },
    {
      "epoch": 0.3865402548958657,
      "grad_norm": 0.13175630569458008,
      "learning_rate": 8.067298725520673e-06,
      "loss": 0.0202,
      "step": 4974
    },
    {
      "epoch": 0.38661796705004664,
      "grad_norm": 0.4697842299938202,
      "learning_rate": 8.066910164749768e-06,
      "loss": 0.1622,
      "step": 4975
    },
    {
      "epoch": 0.38669567920422754,
      "grad_norm": 0.29951801896095276,
      "learning_rate": 8.066521603978863e-06,
      "loss": 0.4021,
      "step": 4976
    },
    {
      "epoch": 0.38677339135840844,
      "grad_norm": 1.4872114658355713,
      "learning_rate": 8.06613304320796e-06,
      "loss": 0.0793,
      "step": 4977
    },
    {
      "epoch": 0.3868511035125894,
      "grad_norm": 0.31089746952056885,
      "learning_rate": 8.065744482437053e-06,
      "loss": 0.1326,
      "step": 4978
    },
    {
      "epoch": 0.3869288156667703,
      "grad_norm": 0.08933384716510773,
      "learning_rate": 8.06535592166615e-06,
      "loss": 0.0344,
      "step": 4979
    },
    {
      "epoch": 0.3870065278209512,
      "grad_norm": 1.2321107387542725,
      "learning_rate": 8.064967360895244e-06,
      "loss": 0.296,
      "step": 4980
    },
    {
      "epoch": 0.38708423997513214,
      "grad_norm": 0.34267458319664,
      "learning_rate": 8.06457880012434e-06,
      "loss": 0.0748,
      "step": 4981
    },
    {
      "epoch": 0.38716195212931304,
      "grad_norm": 0.16195553541183472,
      "learning_rate": 8.064190239353436e-06,
      "loss": 0.0374,
      "step": 4982
    },
    {
      "epoch": 0.38723966428349393,
      "grad_norm": 0.19519822299480438,
      "learning_rate": 8.063801678582531e-06,
      "loss": 0.1348,
      "step": 4983
    },
    {
      "epoch": 0.38731737643767483,
      "grad_norm": 0.5442309379577637,
      "learning_rate": 8.063413117811626e-06,
      "loss": 0.1686,
      "step": 4984
    },
    {
      "epoch": 0.3873950885918558,
      "grad_norm": 0.19614173471927643,
      "learning_rate": 8.063024557040723e-06,
      "loss": 0.0704,
      "step": 4985
    },
    {
      "epoch": 0.3874728007460367,
      "grad_norm": 0.5094757080078125,
      "learning_rate": 8.062635996269818e-06,
      "loss": 0.342,
      "step": 4986
    },
    {
      "epoch": 0.3875505129002176,
      "grad_norm": 0.6048939824104309,
      "learning_rate": 8.062247435498912e-06,
      "loss": 0.1844,
      "step": 4987
    },
    {
      "epoch": 0.38762822505439853,
      "grad_norm": 0.13999971747398376,
      "learning_rate": 8.061858874728007e-06,
      "loss": 0.0161,
      "step": 4988
    },
    {
      "epoch": 0.38770593720857943,
      "grad_norm": 0.714468240737915,
      "learning_rate": 8.061470313957104e-06,
      "loss": 0.2265,
      "step": 4989
    },
    {
      "epoch": 0.38778364936276033,
      "grad_norm": 0.3657175898551941,
      "learning_rate": 8.061081753186199e-06,
      "loss": 0.4231,
      "step": 4990
    },
    {
      "epoch": 0.3878613615169412,
      "grad_norm": 0.12126962840557098,
      "learning_rate": 8.060693192415294e-06,
      "loss": 0.0547,
      "step": 4991
    },
    {
      "epoch": 0.3879390736711222,
      "grad_norm": 0.5264377593994141,
      "learning_rate": 8.06030463164439e-06,
      "loss": 0.1851,
      "step": 4992
    },
    {
      "epoch": 0.3880167858253031,
      "grad_norm": 0.6928036212921143,
      "learning_rate": 8.059916070873486e-06,
      "loss": 0.2854,
      "step": 4993
    },
    {
      "epoch": 0.388094497979484,
      "grad_norm": 0.16571268439292908,
      "learning_rate": 8.05952751010258e-06,
      "loss": 0.1071,
      "step": 4994
    },
    {
      "epoch": 0.38817221013366493,
      "grad_norm": 0.8454629778862,
      "learning_rate": 8.059138949331677e-06,
      "loss": 0.5612,
      "step": 4995
    },
    {
      "epoch": 0.38824992228784583,
      "grad_norm": 0.3309096395969391,
      "learning_rate": 8.058750388560772e-06,
      "loss": 0.2061,
      "step": 4996
    },
    {
      "epoch": 0.3883276344420267,
      "grad_norm": 0.4334586262702942,
      "learning_rate": 8.058361827789867e-06,
      "loss": 0.0824,
      "step": 4997
    },
    {
      "epoch": 0.3884053465962076,
      "grad_norm": 0.20132222771644592,
      "learning_rate": 8.057973267018962e-06,
      "loss": 0.0676,
      "step": 4998
    },
    {
      "epoch": 0.3884830587503886,
      "grad_norm": 0.47972381114959717,
      "learning_rate": 8.057584706248059e-06,
      "loss": 0.425,
      "step": 4999
    },
    {
      "epoch": 0.3885607709045695,
      "grad_norm": 0.15006309747695923,
      "learning_rate": 8.057196145477154e-06,
      "loss": 0.0272,
      "step": 5000
    },
    {
      "epoch": 0.3886384830587504,
      "grad_norm": 0.1342613697052002,
      "learning_rate": 8.056807584706249e-06,
      "loss": 0.0734,
      "step": 5001
    },
    {
      "epoch": 0.3887161952129313,
      "grad_norm": 0.7591637969017029,
      "learning_rate": 8.056419023935345e-06,
      "loss": 0.4752,
      "step": 5002
    },
    {
      "epoch": 0.3887939073671122,
      "grad_norm": 0.42975324392318726,
      "learning_rate": 8.056030463164438e-06,
      "loss": 0.1114,
      "step": 5003
    },
    {
      "epoch": 0.3888716195212931,
      "grad_norm": 0.26440101861953735,
      "learning_rate": 8.055641902393535e-06,
      "loss": 0.1852,
      "step": 5004
    },
    {
      "epoch": 0.388949331675474,
      "grad_norm": 0.7417724132537842,
      "learning_rate": 8.05525334162263e-06,
      "loss": 0.1892,
      "step": 5005
    },
    {
      "epoch": 0.389027043829655,
      "grad_norm": 0.7380980849266052,
      "learning_rate": 8.054864780851725e-06,
      "loss": 0.2067,
      "step": 5006
    },
    {
      "epoch": 0.38910475598383587,
      "grad_norm": 0.46729937195777893,
      "learning_rate": 8.054476220080822e-06,
      "loss": 0.1925,
      "step": 5007
    },
    {
      "epoch": 0.38918246813801677,
      "grad_norm": 0.16947077214717865,
      "learning_rate": 8.054087659309917e-06,
      "loss": 0.0527,
      "step": 5008
    },
    {
      "epoch": 0.3892601802921977,
      "grad_norm": 0.06720717251300812,
      "learning_rate": 8.053699098539012e-06,
      "loss": 0.0203,
      "step": 5009
    },
    {
      "epoch": 0.3893378924463786,
      "grad_norm": 0.7060096263885498,
      "learning_rate": 8.053310537768108e-06,
      "loss": 0.1878,
      "step": 5010
    },
    {
      "epoch": 0.3894156046005595,
      "grad_norm": 0.04064007103443146,
      "learning_rate": 8.052921976997203e-06,
      "loss": 0.0066,
      "step": 5011
    },
    {
      "epoch": 0.3894933167547404,
      "grad_norm": 0.4016024172306061,
      "learning_rate": 8.052533416226298e-06,
      "loss": 0.2238,
      "step": 5012
    },
    {
      "epoch": 0.38957102890892137,
      "grad_norm": 0.4898904860019684,
      "learning_rate": 8.052144855455393e-06,
      "loss": 0.2816,
      "step": 5013
    },
    {
      "epoch": 0.38964874106310227,
      "grad_norm": 0.19621555507183075,
      "learning_rate": 8.05175629468449e-06,
      "loss": 0.0541,
      "step": 5014
    },
    {
      "epoch": 0.38972645321728316,
      "grad_norm": 0.20996412634849548,
      "learning_rate": 8.051367733913585e-06,
      "loss": 0.0504,
      "step": 5015
    },
    {
      "epoch": 0.3898041653714641,
      "grad_norm": 0.5083997249603271,
      "learning_rate": 8.05097917314268e-06,
      "loss": 0.2085,
      "step": 5016
    },
    {
      "epoch": 0.389881877525645,
      "grad_norm": 0.31883078813552856,
      "learning_rate": 8.050590612371776e-06,
      "loss": 0.5907,
      "step": 5017
    },
    {
      "epoch": 0.3899595896798259,
      "grad_norm": 0.322751522064209,
      "learning_rate": 8.050202051600871e-06,
      "loss": 0.0793,
      "step": 5018
    },
    {
      "epoch": 0.3900373018340068,
      "grad_norm": 0.5569324493408203,
      "learning_rate": 8.049813490829966e-06,
      "loss": 0.1218,
      "step": 5019
    },
    {
      "epoch": 0.39011501398818776,
      "grad_norm": 0.12613436579704285,
      "learning_rate": 8.049424930059063e-06,
      "loss": 0.0271,
      "step": 5020
    },
    {
      "epoch": 0.39019272614236866,
      "grad_norm": 0.2025073617696762,
      "learning_rate": 8.049036369288156e-06,
      "loss": 0.1432,
      "step": 5021
    },
    {
      "epoch": 0.39027043829654956,
      "grad_norm": 0.2055363953113556,
      "learning_rate": 8.048647808517253e-06,
      "loss": 0.1901,
      "step": 5022
    },
    {
      "epoch": 0.3903481504507305,
      "grad_norm": 0.18547621369361877,
      "learning_rate": 8.048259247746348e-06,
      "loss": 0.0825,
      "step": 5023
    },
    {
      "epoch": 0.3904258626049114,
      "grad_norm": 0.30423983931541443,
      "learning_rate": 8.047870686975444e-06,
      "loss": 0.0847,
      "step": 5024
    },
    {
      "epoch": 0.3905035747590923,
      "grad_norm": 0.19318024814128876,
      "learning_rate": 8.04748212620454e-06,
      "loss": 0.0689,
      "step": 5025
    },
    {
      "epoch": 0.39058128691327326,
      "grad_norm": 0.3206501007080078,
      "learning_rate": 8.047093565433634e-06,
      "loss": 0.2736,
      "step": 5026
    },
    {
      "epoch": 0.39065899906745416,
      "grad_norm": 0.2140347957611084,
      "learning_rate": 8.04670500466273e-06,
      "loss": 0.0723,
      "step": 5027
    },
    {
      "epoch": 0.39073671122163506,
      "grad_norm": 0.16962899267673492,
      "learning_rate": 8.046316443891826e-06,
      "loss": 0.0272,
      "step": 5028
    },
    {
      "epoch": 0.39081442337581596,
      "grad_norm": 0.5556616187095642,
      "learning_rate": 8.04592788312092e-06,
      "loss": 0.2828,
      "step": 5029
    },
    {
      "epoch": 0.3908921355299969,
      "grad_norm": 0.15149183571338654,
      "learning_rate": 8.045539322350017e-06,
      "loss": 0.0464,
      "step": 5030
    },
    {
      "epoch": 0.3909698476841778,
      "grad_norm": 0.44700777530670166,
      "learning_rate": 8.04515076157911e-06,
      "loss": 0.4456,
      "step": 5031
    },
    {
      "epoch": 0.3910475598383587,
      "grad_norm": 0.30298203229904175,
      "learning_rate": 8.044762200808207e-06,
      "loss": 0.0915,
      "step": 5032
    },
    {
      "epoch": 0.39112527199253966,
      "grad_norm": 0.07290896028280258,
      "learning_rate": 8.044373640037302e-06,
      "loss": 0.0295,
      "step": 5033
    },
    {
      "epoch": 0.39120298414672056,
      "grad_norm": 0.48763370513916016,
      "learning_rate": 8.043985079266397e-06,
      "loss": 0.3198,
      "step": 5034
    },
    {
      "epoch": 0.39128069630090145,
      "grad_norm": 0.21617336571216583,
      "learning_rate": 8.043596518495494e-06,
      "loss": 0.0823,
      "step": 5035
    },
    {
      "epoch": 0.39135840845508235,
      "grad_norm": 0.3173614740371704,
      "learning_rate": 8.043207957724589e-06,
      "loss": 0.0948,
      "step": 5036
    },
    {
      "epoch": 0.3914361206092633,
      "grad_norm": 0.07843277603387833,
      "learning_rate": 8.042819396953684e-06,
      "loss": 0.0305,
      "step": 5037
    },
    {
      "epoch": 0.3915138327634442,
      "grad_norm": 0.5197681188583374,
      "learning_rate": 8.04243083618278e-06,
      "loss": 0.3363,
      "step": 5038
    },
    {
      "epoch": 0.3915915449176251,
      "grad_norm": 0.4489583373069763,
      "learning_rate": 8.042042275411875e-06,
      "loss": 0.2048,
      "step": 5039
    },
    {
      "epoch": 0.39166925707180605,
      "grad_norm": 0.22000004351139069,
      "learning_rate": 8.04165371464097e-06,
      "loss": 0.2019,
      "step": 5040
    },
    {
      "epoch": 0.39174696922598695,
      "grad_norm": 0.5735598802566528,
      "learning_rate": 8.041265153870065e-06,
      "loss": 0.491,
      "step": 5041
    },
    {
      "epoch": 0.39182468138016785,
      "grad_norm": 0.8131895065307617,
      "learning_rate": 8.040876593099162e-06,
      "loss": 0.4936,
      "step": 5042
    },
    {
      "epoch": 0.39190239353434875,
      "grad_norm": 0.02824573777616024,
      "learning_rate": 8.040488032328257e-06,
      "loss": 0.0104,
      "step": 5043
    },
    {
      "epoch": 0.3919801056885297,
      "grad_norm": 0.27394118905067444,
      "learning_rate": 8.040099471557352e-06,
      "loss": 0.193,
      "step": 5044
    },
    {
      "epoch": 0.3920578178427106,
      "grad_norm": 0.7331512570381165,
      "learning_rate": 8.039710910786448e-06,
      "loss": 0.4806,
      "step": 5045
    },
    {
      "epoch": 0.3921355299968915,
      "grad_norm": 0.448341965675354,
      "learning_rate": 8.039322350015543e-06,
      "loss": 0.1621,
      "step": 5046
    },
    {
      "epoch": 0.39221324215107245,
      "grad_norm": 0.3694121837615967,
      "learning_rate": 8.038933789244638e-06,
      "loss": 0.1514,
      "step": 5047
    },
    {
      "epoch": 0.39229095430525335,
      "grad_norm": 0.18366429209709167,
      "learning_rate": 8.038545228473735e-06,
      "loss": 0.0594,
      "step": 5048
    },
    {
      "epoch": 0.39236866645943425,
      "grad_norm": 0.7537749409675598,
      "learning_rate": 8.038156667702828e-06,
      "loss": 0.3319,
      "step": 5049
    },
    {
      "epoch": 0.39244637861361514,
      "grad_norm": 0.21954388916492462,
      "learning_rate": 8.037768106931925e-06,
      "loss": 0.1138,
      "step": 5050
    },
    {
      "epoch": 0.3925240907677961,
      "grad_norm": 0.4798330068588257,
      "learning_rate": 8.03737954616102e-06,
      "loss": 0.2819,
      "step": 5051
    },
    {
      "epoch": 0.392601802921977,
      "grad_norm": 0.24431471526622772,
      "learning_rate": 8.036990985390115e-06,
      "loss": 0.1316,
      "step": 5052
    },
    {
      "epoch": 0.3926795150761579,
      "grad_norm": 0.4402111768722534,
      "learning_rate": 8.036602424619211e-06,
      "loss": 0.3319,
      "step": 5053
    },
    {
      "epoch": 0.39275722723033885,
      "grad_norm": 0.2184937596321106,
      "learning_rate": 8.036213863848306e-06,
      "loss": 0.096,
      "step": 5054
    },
    {
      "epoch": 0.39283493938451974,
      "grad_norm": 0.4252791404724121,
      "learning_rate": 8.035825303077403e-06,
      "loss": 0.2404,
      "step": 5055
    },
    {
      "epoch": 0.39291265153870064,
      "grad_norm": 0.2604978084564209,
      "learning_rate": 8.035436742306498e-06,
      "loss": 0.0427,
      "step": 5056
    },
    {
      "epoch": 0.39299036369288154,
      "grad_norm": 0.21882036328315735,
      "learning_rate": 8.035048181535593e-06,
      "loss": 0.1054,
      "step": 5057
    },
    {
      "epoch": 0.3930680758470625,
      "grad_norm": 0.38075149059295654,
      "learning_rate": 8.03465962076469e-06,
      "loss": 0.4202,
      "step": 5058
    },
    {
      "epoch": 0.3931457880012434,
      "grad_norm": 0.3170256018638611,
      "learning_rate": 8.034271059993783e-06,
      "loss": 0.2719,
      "step": 5059
    },
    {
      "epoch": 0.3932235001554243,
      "grad_norm": 0.3479918837547302,
      "learning_rate": 8.03388249922288e-06,
      "loss": 0.0833,
      "step": 5060
    },
    {
      "epoch": 0.39330121230960524,
      "grad_norm": 1.1159290075302124,
      "learning_rate": 8.033493938451974e-06,
      "loss": 2.1418,
      "step": 5061
    },
    {
      "epoch": 0.39337892446378614,
      "grad_norm": 0.2446621060371399,
      "learning_rate": 8.03310537768107e-06,
      "loss": 0.133,
      "step": 5062
    },
    {
      "epoch": 0.39345663661796704,
      "grad_norm": 0.08185569196939468,
      "learning_rate": 8.032716816910166e-06,
      "loss": 0.0267,
      "step": 5063
    },
    {
      "epoch": 0.393534348772148,
      "grad_norm": 0.10620236396789551,
      "learning_rate": 8.032328256139261e-06,
      "loss": 0.0722,
      "step": 5064
    },
    {
      "epoch": 0.3936120609263289,
      "grad_norm": 0.1267055869102478,
      "learning_rate": 8.031939695368356e-06,
      "loss": 0.0511,
      "step": 5065
    },
    {
      "epoch": 0.3936897730805098,
      "grad_norm": 0.3274766802787781,
      "learning_rate": 8.031551134597452e-06,
      "loss": 0.621,
      "step": 5066
    },
    {
      "epoch": 0.3937674852346907,
      "grad_norm": 0.2542060613632202,
      "learning_rate": 8.031162573826547e-06,
      "loss": 0.1016,
      "step": 5067
    },
    {
      "epoch": 0.39384519738887164,
      "grad_norm": 0.25532928109169006,
      "learning_rate": 8.030774013055642e-06,
      "loss": 0.0969,
      "step": 5068
    },
    {
      "epoch": 0.39392290954305254,
      "grad_norm": 0.265011727809906,
      "learning_rate": 8.030385452284737e-06,
      "loss": 0.0333,
      "step": 5069
    },
    {
      "epoch": 0.39400062169723343,
      "grad_norm": 0.27226707339286804,
      "learning_rate": 8.029996891513834e-06,
      "loss": 0.1743,
      "step": 5070
    },
    {
      "epoch": 0.3940783338514144,
      "grad_norm": 0.29629871249198914,
      "learning_rate": 8.029608330742929e-06,
      "loss": 0.0897,
      "step": 5071
    },
    {
      "epoch": 0.3941560460055953,
      "grad_norm": 0.46613770723342896,
      "learning_rate": 8.029219769972024e-06,
      "loss": 0.1486,
      "step": 5072
    },
    {
      "epoch": 0.3942337581597762,
      "grad_norm": 0.4989273250102997,
      "learning_rate": 8.02883120920112e-06,
      "loss": 0.3375,
      "step": 5073
    },
    {
      "epoch": 0.3943114703139571,
      "grad_norm": 0.195639967918396,
      "learning_rate": 8.028442648430215e-06,
      "loss": 0.0921,
      "step": 5074
    },
    {
      "epoch": 0.39438918246813803,
      "grad_norm": 0.14595310389995575,
      "learning_rate": 8.02805408765931e-06,
      "loss": 0.0372,
      "step": 5075
    },
    {
      "epoch": 0.39446689462231893,
      "grad_norm": 0.5998244285583496,
      "learning_rate": 8.027665526888407e-06,
      "loss": 0.4119,
      "step": 5076
    },
    {
      "epoch": 0.39454460677649983,
      "grad_norm": 0.09109426289796829,
      "learning_rate": 8.0272769661175e-06,
      "loss": 0.0135,
      "step": 5077
    },
    {
      "epoch": 0.3946223189306808,
      "grad_norm": 0.23563840985298157,
      "learning_rate": 8.026888405346597e-06,
      "loss": 0.2241,
      "step": 5078
    },
    {
      "epoch": 0.3947000310848617,
      "grad_norm": 0.2828775644302368,
      "learning_rate": 8.026499844575692e-06,
      "loss": 0.0359,
      "step": 5079
    },
    {
      "epoch": 0.3947777432390426,
      "grad_norm": 0.33044561743736267,
      "learning_rate": 8.026111283804787e-06,
      "loss": 0.1072,
      "step": 5080
    },
    {
      "epoch": 0.3948554553932235,
      "grad_norm": 0.49189597368240356,
      "learning_rate": 8.025722723033883e-06,
      "loss": 0.6299,
      "step": 5081
    },
    {
      "epoch": 0.39493316754740443,
      "grad_norm": 0.21647998690605164,
      "learning_rate": 8.025334162262978e-06,
      "loss": 0.0336,
      "step": 5082
    },
    {
      "epoch": 0.3950108797015853,
      "grad_norm": 0.47144851088523865,
      "learning_rate": 8.024945601492073e-06,
      "loss": 0.1783,
      "step": 5083
    },
    {
      "epoch": 0.3950885918557662,
      "grad_norm": 0.13743028044700623,
      "learning_rate": 8.02455704072117e-06,
      "loss": 0.0574,
      "step": 5084
    },
    {
      "epoch": 0.3951663040099472,
      "grad_norm": 0.7567151188850403,
      "learning_rate": 8.024168479950265e-06,
      "loss": 0.3496,
      "step": 5085
    },
    {
      "epoch": 0.3952440161641281,
      "grad_norm": 0.12328118085861206,
      "learning_rate": 8.023779919179362e-06,
      "loss": 0.0874,
      "step": 5086
    },
    {
      "epoch": 0.395321728318309,
      "grad_norm": 0.6244256496429443,
      "learning_rate": 8.023391358408455e-06,
      "loss": 0.2667,
      "step": 5087
    },
    {
      "epoch": 0.39539944047248987,
      "grad_norm": 0.5082359313964844,
      "learning_rate": 8.023002797637552e-06,
      "loss": 0.8227,
      "step": 5088
    },
    {
      "epoch": 0.3954771526266708,
      "grad_norm": 0.16025981307029724,
      "learning_rate": 8.022614236866646e-06,
      "loss": 0.0246,
      "step": 5089
    },
    {
      "epoch": 0.3955548647808517,
      "grad_norm": 0.14052709937095642,
      "learning_rate": 8.022225676095741e-06,
      "loss": 0.0359,
      "step": 5090
    },
    {
      "epoch": 0.3956325769350326,
      "grad_norm": 0.9367546439170837,
      "learning_rate": 8.021837115324838e-06,
      "loss": 0.2007,
      "step": 5091
    },
    {
      "epoch": 0.3957102890892136,
      "grad_norm": 0.3142347037792206,
      "learning_rate": 8.021448554553933e-06,
      "loss": 0.2151,
      "step": 5092
    },
    {
      "epoch": 0.39578800124339447,
      "grad_norm": 0.19126111268997192,
      "learning_rate": 8.021059993783028e-06,
      "loss": 0.0924,
      "step": 5093
    },
    {
      "epoch": 0.39586571339757537,
      "grad_norm": 0.3001691997051239,
      "learning_rate": 8.020671433012125e-06,
      "loss": 0.1675,
      "step": 5094
    },
    {
      "epoch": 0.39594342555175627,
      "grad_norm": 0.5893726944923401,
      "learning_rate": 8.02028287224122e-06,
      "loss": 0.3284,
      "step": 5095
    },
    {
      "epoch": 0.3960211377059372,
      "grad_norm": 0.5431085824966431,
      "learning_rate": 8.019894311470314e-06,
      "loss": 0.2339,
      "step": 5096
    },
    {
      "epoch": 0.3960988498601181,
      "grad_norm": 0.15248586237430573,
      "learning_rate": 8.01950575069941e-06,
      "loss": 0.0404,
      "step": 5097
    },
    {
      "epoch": 0.396176562014299,
      "grad_norm": 0.44839417934417725,
      "learning_rate": 8.019117189928506e-06,
      "loss": 0.2503,
      "step": 5098
    },
    {
      "epoch": 0.39625427416847997,
      "grad_norm": 0.318972647190094,
      "learning_rate": 8.018728629157601e-06,
      "loss": 0.0925,
      "step": 5099
    },
    {
      "epoch": 0.39633198632266087,
      "grad_norm": 0.18405216932296753,
      "learning_rate": 8.018340068386696e-06,
      "loss": 0.051,
      "step": 5100
    },
    {
      "epoch": 0.39640969847684177,
      "grad_norm": 0.7572065591812134,
      "learning_rate": 8.017951507615793e-06,
      "loss": 0.3934,
      "step": 5101
    },
    {
      "epoch": 0.3964874106310227,
      "grad_norm": 0.2124631255865097,
      "learning_rate": 8.017562946844888e-06,
      "loss": 0.1092,
      "step": 5102
    },
    {
      "epoch": 0.3965651227852036,
      "grad_norm": 0.45716118812561035,
      "learning_rate": 8.017174386073983e-06,
      "loss": 0.2908,
      "step": 5103
    },
    {
      "epoch": 0.3966428349393845,
      "grad_norm": 0.6317610144615173,
      "learning_rate": 8.01678582530308e-06,
      "loss": 0.2301,
      "step": 5104
    },
    {
      "epoch": 0.3967205470935654,
      "grad_norm": 1.0005815029144287,
      "learning_rate": 8.016397264532172e-06,
      "loss": 0.6511,
      "step": 5105
    },
    {
      "epoch": 0.39679825924774637,
      "grad_norm": 0.3738531768321991,
      "learning_rate": 8.016008703761269e-06,
      "loss": 0.2376,
      "step": 5106
    },
    {
      "epoch": 0.39687597140192726,
      "grad_norm": 0.14267100393772125,
      "learning_rate": 8.015620142990364e-06,
      "loss": 0.0742,
      "step": 5107
    },
    {
      "epoch": 0.39695368355610816,
      "grad_norm": 0.4469051957130432,
      "learning_rate": 8.015231582219459e-06,
      "loss": 0.1747,
      "step": 5108
    },
    {
      "epoch": 0.3970313957102891,
      "grad_norm": 0.904731273651123,
      "learning_rate": 8.014843021448556e-06,
      "loss": 0.9008,
      "step": 5109
    },
    {
      "epoch": 0.39710910786447,
      "grad_norm": 0.08716368675231934,
      "learning_rate": 8.01445446067765e-06,
      "loss": 0.034,
      "step": 5110
    },
    {
      "epoch": 0.3971868200186509,
      "grad_norm": 0.2747105360031128,
      "learning_rate": 8.014065899906746e-06,
      "loss": 0.1428,
      "step": 5111
    },
    {
      "epoch": 0.3972645321728318,
      "grad_norm": 0.40884825587272644,
      "learning_rate": 8.013677339135842e-06,
      "loss": 0.1536,
      "step": 5112
    },
    {
      "epoch": 0.39734224432701276,
      "grad_norm": 0.11472778022289276,
      "learning_rate": 8.013288778364937e-06,
      "loss": 0.0253,
      "step": 5113
    },
    {
      "epoch": 0.39741995648119366,
      "grad_norm": 0.40151679515838623,
      "learning_rate": 8.012900217594034e-06,
      "loss": 0.3575,
      "step": 5114
    },
    {
      "epoch": 0.39749766863537456,
      "grad_norm": 0.19100604951381683,
      "learning_rate": 8.012511656823127e-06,
      "loss": 0.0508,
      "step": 5115
    },
    {
      "epoch": 0.3975753807895555,
      "grad_norm": 0.7000388503074646,
      "learning_rate": 8.012123096052224e-06,
      "loss": 0.2572,
      "step": 5116
    },
    {
      "epoch": 0.3976530929437364,
      "grad_norm": 0.43671998381614685,
      "learning_rate": 8.011734535281319e-06,
      "loss": 0.2999,
      "step": 5117
    },
    {
      "epoch": 0.3977308050979173,
      "grad_norm": 0.5019144415855408,
      "learning_rate": 8.011345974510414e-06,
      "loss": 0.3492,
      "step": 5118
    },
    {
      "epoch": 0.3978085172520982,
      "grad_norm": 0.258166640996933,
      "learning_rate": 8.01095741373951e-06,
      "loss": 0.1614,
      "step": 5119
    },
    {
      "epoch": 0.39788622940627916,
      "grad_norm": 0.4711824655532837,
      "learning_rate": 8.010568852968605e-06,
      "loss": 0.2114,
      "step": 5120
    },
    {
      "epoch": 0.39796394156046005,
      "grad_norm": 0.22852596640586853,
      "learning_rate": 8.0101802921977e-06,
      "loss": 0.1453,
      "step": 5121
    },
    {
      "epoch": 0.39804165371464095,
      "grad_norm": 0.2006232589483261,
      "learning_rate": 8.009791731426795e-06,
      "loss": 0.1036,
      "step": 5122
    },
    {
      "epoch": 0.3981193658688219,
      "grad_norm": 0.40970438718795776,
      "learning_rate": 8.009403170655892e-06,
      "loss": 0.2541,
      "step": 5123
    },
    {
      "epoch": 0.3981970780230028,
      "grad_norm": 0.3182395398616791,
      "learning_rate": 8.009014609884987e-06,
      "loss": 0.1136,
      "step": 5124
    },
    {
      "epoch": 0.3982747901771837,
      "grad_norm": 0.546913743019104,
      "learning_rate": 8.008626049114082e-06,
      "loss": 0.3419,
      "step": 5125
    },
    {
      "epoch": 0.3983525023313646,
      "grad_norm": 0.42441704869270325,
      "learning_rate": 8.008237488343178e-06,
      "loss": 0.4868,
      "step": 5126
    },
    {
      "epoch": 0.39843021448554555,
      "grad_norm": 0.7532647848129272,
      "learning_rate": 8.007848927572273e-06,
      "loss": 0.271,
      "step": 5127
    },
    {
      "epoch": 0.39850792663972645,
      "grad_norm": 0.26715999841690063,
      "learning_rate": 8.007460366801368e-06,
      "loss": 0.0703,
      "step": 5128
    },
    {
      "epoch": 0.39858563879390735,
      "grad_norm": 0.2268437296152115,
      "learning_rate": 8.007071806030465e-06,
      "loss": 0.0257,
      "step": 5129
    },
    {
      "epoch": 0.3986633509480883,
      "grad_norm": 0.16309182345867157,
      "learning_rate": 8.006683245259558e-06,
      "loss": 0.117,
      "step": 5130
    },
    {
      "epoch": 0.3987410631022692,
      "grad_norm": 0.4764980375766754,
      "learning_rate": 8.006294684488655e-06,
      "loss": 0.2509,
      "step": 5131
    },
    {
      "epoch": 0.3988187752564501,
      "grad_norm": 0.19925422966480255,
      "learning_rate": 8.00590612371775e-06,
      "loss": 0.0235,
      "step": 5132
    },
    {
      "epoch": 0.398896487410631,
      "grad_norm": 0.702034056186676,
      "learning_rate": 8.005517562946845e-06,
      "loss": 0.6347,
      "step": 5133
    },
    {
      "epoch": 0.39897419956481195,
      "grad_norm": 0.2092008888721466,
      "learning_rate": 8.005129002175941e-06,
      "loss": 0.0774,
      "step": 5134
    },
    {
      "epoch": 0.39905191171899285,
      "grad_norm": 0.3036535382270813,
      "learning_rate": 8.004740441405036e-06,
      "loss": 0.0418,
      "step": 5135
    },
    {
      "epoch": 0.39912962387317374,
      "grad_norm": 0.3545704185962677,
      "learning_rate": 8.004351880634131e-06,
      "loss": 0.2831,
      "step": 5136
    },
    {
      "epoch": 0.3992073360273547,
      "grad_norm": 0.3652098774909973,
      "learning_rate": 8.003963319863228e-06,
      "loss": 0.193,
      "step": 5137
    },
    {
      "epoch": 0.3992850481815356,
      "grad_norm": 0.24554020166397095,
      "learning_rate": 8.003574759092323e-06,
      "loss": 0.2215,
      "step": 5138
    },
    {
      "epoch": 0.3993627603357165,
      "grad_norm": 0.5147998332977295,
      "learning_rate": 8.003186198321418e-06,
      "loss": 0.2985,
      "step": 5139
    },
    {
      "epoch": 0.39944047248989745,
      "grad_norm": 0.16410040855407715,
      "learning_rate": 8.002797637550513e-06,
      "loss": 0.1025,
      "step": 5140
    },
    {
      "epoch": 0.39951818464407834,
      "grad_norm": 0.20686785876750946,
      "learning_rate": 8.00240907677961e-06,
      "loss": 0.0815,
      "step": 5141
    },
    {
      "epoch": 0.39959589679825924,
      "grad_norm": 0.28435400128364563,
      "learning_rate": 8.002020516008704e-06,
      "loss": 0.3749,
      "step": 5142
    },
    {
      "epoch": 0.39967360895244014,
      "grad_norm": 0.4638686776161194,
      "learning_rate": 8.0016319552378e-06,
      "loss": 0.1219,
      "step": 5143
    },
    {
      "epoch": 0.3997513211066211,
      "grad_norm": 0.19252683222293854,
      "learning_rate": 8.001243394466896e-06,
      "loss": 0.0515,
      "step": 5144
    },
    {
      "epoch": 0.399829033260802,
      "grad_norm": 0.3162948489189148,
      "learning_rate": 8.00085483369599e-06,
      "loss": 0.2087,
      "step": 5145
    },
    {
      "epoch": 0.3999067454149829,
      "grad_norm": 0.1740408092737198,
      "learning_rate": 8.000466272925086e-06,
      "loss": 0.0697,
      "step": 5146
    },
    {
      "epoch": 0.39998445756916384,
      "grad_norm": 0.48739150166511536,
      "learning_rate": 8.000077712154182e-06,
      "loss": 0.3727,
      "step": 5147
    },
    {
      "epoch": 0.40006216972334474,
      "grad_norm": 1.1450613737106323,
      "learning_rate": 7.999689151383277e-06,
      "loss": 0.5006,
      "step": 5148
    },
    {
      "epoch": 0.40013988187752564,
      "grad_norm": 0.061556097120046616,
      "learning_rate": 7.999300590612372e-06,
      "loss": 0.0485,
      "step": 5149
    },
    {
      "epoch": 0.40021759403170654,
      "grad_norm": 0.07641719281673431,
      "learning_rate": 7.998912029841467e-06,
      "loss": 0.0276,
      "step": 5150
    },
    {
      "epoch": 0.4002953061858875,
      "grad_norm": 0.5461304783821106,
      "learning_rate": 7.998523469070564e-06,
      "loss": 0.5164,
      "step": 5151
    },
    {
      "epoch": 0.4003730183400684,
      "grad_norm": 0.21054859459400177,
      "learning_rate": 7.998134908299659e-06,
      "loss": 0.0997,
      "step": 5152
    },
    {
      "epoch": 0.4004507304942493,
      "grad_norm": 0.24876071512699127,
      "learning_rate": 7.997746347528754e-06,
      "loss": 0.1448,
      "step": 5153
    },
    {
      "epoch": 0.40052844264843024,
      "grad_norm": 0.2609604597091675,
      "learning_rate": 7.99735778675785e-06,
      "loss": 0.154,
      "step": 5154
    },
    {
      "epoch": 0.40060615480261114,
      "grad_norm": 0.45766156911849976,
      "learning_rate": 7.996969225986945e-06,
      "loss": 0.2457,
      "step": 5155
    },
    {
      "epoch": 0.40068386695679203,
      "grad_norm": 1.7465660572052002,
      "learning_rate": 7.99658066521604e-06,
      "loss": 0.3957,
      "step": 5156
    },
    {
      "epoch": 0.40076157911097293,
      "grad_norm": 0.10163912922143936,
      "learning_rate": 7.996192104445137e-06,
      "loss": 0.0184,
      "step": 5157
    },
    {
      "epoch": 0.4008392912651539,
      "grad_norm": 0.22896310687065125,
      "learning_rate": 7.99580354367423e-06,
      "loss": 0.1064,
      "step": 5158
    },
    {
      "epoch": 0.4009170034193348,
      "grad_norm": 0.33360886573791504,
      "learning_rate": 7.995414982903327e-06,
      "loss": 0.1275,
      "step": 5159
    },
    {
      "epoch": 0.4009947155735157,
      "grad_norm": 0.3740141689777374,
      "learning_rate": 7.995026422132422e-06,
      "loss": 0.2596,
      "step": 5160
    },
    {
      "epoch": 0.40107242772769663,
      "grad_norm": 0.3418865203857422,
      "learning_rate": 7.994637861361517e-06,
      "loss": 0.1656,
      "step": 5161
    },
    {
      "epoch": 0.40115013988187753,
      "grad_norm": 0.30733826756477356,
      "learning_rate": 7.994249300590613e-06,
      "loss": 0.1578,
      "step": 5162
    },
    {
      "epoch": 0.40122785203605843,
      "grad_norm": 0.36315980553627014,
      "learning_rate": 7.993860739819708e-06,
      "loss": 0.1724,
      "step": 5163
    },
    {
      "epoch": 0.40130556419023933,
      "grad_norm": 0.3637665808200836,
      "learning_rate": 7.993472179048803e-06,
      "loss": 0.1231,
      "step": 5164
    },
    {
      "epoch": 0.4013832763444203,
      "grad_norm": 0.38628366589546204,
      "learning_rate": 7.9930836182779e-06,
      "loss": 0.2937,
      "step": 5165
    },
    {
      "epoch": 0.4014609884986012,
      "grad_norm": 0.3241387605667114,
      "learning_rate": 7.992695057506995e-06,
      "loss": 0.1409,
      "step": 5166
    },
    {
      "epoch": 0.4015387006527821,
      "grad_norm": 0.43944892287254333,
      "learning_rate": 7.99230649673609e-06,
      "loss": 0.1453,
      "step": 5167
    },
    {
      "epoch": 0.40161641280696303,
      "grad_norm": 0.5340015292167664,
      "learning_rate": 7.991917935965185e-06,
      "loss": 0.1554,
      "step": 5168
    },
    {
      "epoch": 0.40169412496114393,
      "grad_norm": 0.24807174503803253,
      "learning_rate": 7.991529375194281e-06,
      "loss": 0.1775,
      "step": 5169
    },
    {
      "epoch": 0.4017718371153248,
      "grad_norm": 0.20678606629371643,
      "learning_rate": 7.991140814423376e-06,
      "loss": 0.1516,
      "step": 5170
    },
    {
      "epoch": 0.4018495492695057,
      "grad_norm": 0.30535051226615906,
      "learning_rate": 7.990752253652471e-06,
      "loss": 0.2247,
      "step": 5171
    },
    {
      "epoch": 0.4019272614236867,
      "grad_norm": 0.6663866639137268,
      "learning_rate": 7.990363692881568e-06,
      "loss": 0.4995,
      "step": 5172
    },
    {
      "epoch": 0.4020049735778676,
      "grad_norm": 0.3808789551258087,
      "learning_rate": 7.989975132110663e-06,
      "loss": 0.2448,
      "step": 5173
    },
    {
      "epoch": 0.4020826857320485,
      "grad_norm": 0.11045187711715698,
      "learning_rate": 7.989586571339758e-06,
      "loss": 0.0572,
      "step": 5174
    },
    {
      "epoch": 0.4021603978862294,
      "grad_norm": 0.8884294033050537,
      "learning_rate": 7.989198010568854e-06,
      "loss": 0.3576,
      "step": 5175
    },
    {
      "epoch": 0.4022381100404103,
      "grad_norm": 0.7000548243522644,
      "learning_rate": 7.98880944979795e-06,
      "loss": 0.1945,
      "step": 5176
    },
    {
      "epoch": 0.4023158221945912,
      "grad_norm": 0.2873108983039856,
      "learning_rate": 7.988420889027044e-06,
      "loss": 0.1405,
      "step": 5177
    },
    {
      "epoch": 0.4023935343487722,
      "grad_norm": 0.3660067617893219,
      "learning_rate": 7.98803232825614e-06,
      "loss": 0.0837,
      "step": 5178
    },
    {
      "epoch": 0.4024712465029531,
      "grad_norm": 0.48462527990341187,
      "learning_rate": 7.987643767485236e-06,
      "loss": 0.1501,
      "step": 5179
    },
    {
      "epoch": 0.40254895865713397,
      "grad_norm": 0.30580711364746094,
      "learning_rate": 7.987255206714331e-06,
      "loss": 0.1221,
      "step": 5180
    },
    {
      "epoch": 0.40262667081131487,
      "grad_norm": 0.29892057180404663,
      "learning_rate": 7.986866645943426e-06,
      "loss": 0.1204,
      "step": 5181
    },
    {
      "epoch": 0.4027043829654958,
      "grad_norm": 0.38175755739212036,
      "learning_rate": 7.986478085172523e-06,
      "loss": 0.2061,
      "step": 5182
    },
    {
      "epoch": 0.4027820951196767,
      "grad_norm": 0.8226561546325684,
      "learning_rate": 7.986089524401617e-06,
      "loss": 0.4083,
      "step": 5183
    },
    {
      "epoch": 0.4028598072738576,
      "grad_norm": 0.3031638264656067,
      "learning_rate": 7.985700963630712e-06,
      "loss": 0.0642,
      "step": 5184
    },
    {
      "epoch": 0.40293751942803857,
      "grad_norm": 0.4583997428417206,
      "learning_rate": 7.985312402859809e-06,
      "loss": 0.1414,
      "step": 5185
    },
    {
      "epoch": 0.40301523158221947,
      "grad_norm": 0.1638047844171524,
      "learning_rate": 7.984923842088902e-06,
      "loss": 0.0206,
      "step": 5186
    },
    {
      "epoch": 0.40309294373640037,
      "grad_norm": 0.4674546420574188,
      "learning_rate": 7.984535281317999e-06,
      "loss": 0.1353,
      "step": 5187
    },
    {
      "epoch": 0.40317065589058126,
      "grad_norm": 0.7517274022102356,
      "learning_rate": 7.984146720547094e-06,
      "loss": 0.2564,
      "step": 5188
    },
    {
      "epoch": 0.4032483680447622,
      "grad_norm": 0.5611795783042908,
      "learning_rate": 7.983758159776189e-06,
      "loss": 0.5954,
      "step": 5189
    },
    {
      "epoch": 0.4033260801989431,
      "grad_norm": 0.10462887585163116,
      "learning_rate": 7.983369599005286e-06,
      "loss": 0.0339,
      "step": 5190
    },
    {
      "epoch": 0.403403792353124,
      "grad_norm": 0.7404597997665405,
      "learning_rate": 7.98298103823438e-06,
      "loss": 0.4475,
      "step": 5191
    },
    {
      "epoch": 0.40348150450730497,
      "grad_norm": 0.16841773688793182,
      "learning_rate": 7.982592477463475e-06,
      "loss": 0.037,
      "step": 5192
    },
    {
      "epoch": 0.40355921666148586,
      "grad_norm": 0.42995530366897583,
      "learning_rate": 7.982203916692572e-06,
      "loss": 0.1024,
      "step": 5193
    },
    {
      "epoch": 0.40363692881566676,
      "grad_norm": 0.3192594051361084,
      "learning_rate": 7.981815355921667e-06,
      "loss": 0.2842,
      "step": 5194
    },
    {
      "epoch": 0.40371464096984766,
      "grad_norm": 0.32541412115097046,
      "learning_rate": 7.981426795150762e-06,
      "loss": 0.2586,
      "step": 5195
    },
    {
      "epoch": 0.4037923531240286,
      "grad_norm": 0.24013766646385193,
      "learning_rate": 7.981038234379857e-06,
      "loss": 0.0862,
      "step": 5196
    },
    {
      "epoch": 0.4038700652782095,
      "grad_norm": 0.22725807130336761,
      "learning_rate": 7.980649673608954e-06,
      "loss": 0.2836,
      "step": 5197
    },
    {
      "epoch": 0.4039477774323904,
      "grad_norm": 0.14985619485378265,
      "learning_rate": 7.980261112838048e-06,
      "loss": 0.0812,
      "step": 5198
    },
    {
      "epoch": 0.40402548958657136,
      "grad_norm": 0.09233850985765457,
      "learning_rate": 7.979872552067143e-06,
      "loss": 0.0832,
      "step": 5199
    },
    {
      "epoch": 0.40410320174075226,
      "grad_norm": 0.037170037627220154,
      "learning_rate": 7.97948399129624e-06,
      "loss": 0.0104,
      "step": 5200
    },
    {
      "epoch": 0.40418091389493316,
      "grad_norm": 0.1679864376783371,
      "learning_rate": 7.979095430525335e-06,
      "loss": 0.0602,
      "step": 5201
    },
    {
      "epoch": 0.40425862604911406,
      "grad_norm": 0.18515081703662872,
      "learning_rate": 7.97870686975443e-06,
      "loss": 0.0484,
      "step": 5202
    },
    {
      "epoch": 0.404336338203295,
      "grad_norm": 0.17820249497890472,
      "learning_rate": 7.978318308983527e-06,
      "loss": 0.0952,
      "step": 5203
    },
    {
      "epoch": 0.4044140503574759,
      "grad_norm": 0.5211523771286011,
      "learning_rate": 7.97792974821262e-06,
      "loss": 0.4061,
      "step": 5204
    },
    {
      "epoch": 0.4044917625116568,
      "grad_norm": 0.347307026386261,
      "learning_rate": 7.977541187441717e-06,
      "loss": 0.1883,
      "step": 5205
    },
    {
      "epoch": 0.40456947466583776,
      "grad_norm": 0.4667050540447235,
      "learning_rate": 7.977152626670811e-06,
      "loss": 0.6569,
      "step": 5206
    },
    {
      "epoch": 0.40464718682001866,
      "grad_norm": 0.34169960021972656,
      "learning_rate": 7.976764065899908e-06,
      "loss": 0.1349,
      "step": 5207
    },
    {
      "epoch": 0.40472489897419955,
      "grad_norm": 0.17992913722991943,
      "learning_rate": 7.976375505129003e-06,
      "loss": 0.1121,
      "step": 5208
    },
    {
      "epoch": 0.40480261112838045,
      "grad_norm": 0.1834665834903717,
      "learning_rate": 7.975986944358098e-06,
      "loss": 0.0825,
      "step": 5209
    },
    {
      "epoch": 0.4048803232825614,
      "grad_norm": 0.6814107298851013,
      "learning_rate": 7.975598383587195e-06,
      "loss": 0.1861,
      "step": 5210
    },
    {
      "epoch": 0.4049580354367423,
      "grad_norm": 0.4617449641227722,
      "learning_rate": 7.97520982281629e-06,
      "loss": 0.2207,
      "step": 5211
    },
    {
      "epoch": 0.4050357475909232,
      "grad_norm": 0.39913424849510193,
      "learning_rate": 7.974821262045385e-06,
      "loss": 0.193,
      "step": 5212
    },
    {
      "epoch": 0.40511345974510415,
      "grad_norm": 0.1146881952881813,
      "learning_rate": 7.974432701274481e-06,
      "loss": 0.0327,
      "step": 5213
    },
    {
      "epoch": 0.40519117189928505,
      "grad_norm": 0.4274952709674835,
      "learning_rate": 7.974044140503574e-06,
      "loss": 0.3345,
      "step": 5214
    },
    {
      "epoch": 0.40526888405346595,
      "grad_norm": 0.4422767758369446,
      "learning_rate": 7.973655579732671e-06,
      "loss": 0.2675,
      "step": 5215
    },
    {
      "epoch": 0.4053465962076469,
      "grad_norm": 0.8734308481216431,
      "learning_rate": 7.973267018961766e-06,
      "loss": 0.9427,
      "step": 5216
    },
    {
      "epoch": 0.4054243083618278,
      "grad_norm": 0.13781419396400452,
      "learning_rate": 7.972878458190861e-06,
      "loss": 0.0452,
      "step": 5217
    },
    {
      "epoch": 0.4055020205160087,
      "grad_norm": 0.13137656450271606,
      "learning_rate": 7.972489897419958e-06,
      "loss": 0.0457,
      "step": 5218
    },
    {
      "epoch": 0.4055797326701896,
      "grad_norm": 0.3972918391227722,
      "learning_rate": 7.972101336649053e-06,
      "loss": 0.0907,
      "step": 5219
    },
    {
      "epoch": 0.40565744482437055,
      "grad_norm": 0.06651818752288818,
      "learning_rate": 7.971712775878148e-06,
      "loss": 0.0113,
      "step": 5220
    },
    {
      "epoch": 0.40573515697855145,
      "grad_norm": 0.28788065910339355,
      "learning_rate": 7.971324215107244e-06,
      "loss": 0.0876,
      "step": 5221
    },
    {
      "epoch": 0.40581286913273235,
      "grad_norm": 1.0428715944290161,
      "learning_rate": 7.970935654336339e-06,
      "loss": 0.6147,
      "step": 5222
    },
    {
      "epoch": 0.4058905812869133,
      "grad_norm": 0.7465882897377014,
      "learning_rate": 7.970547093565434e-06,
      "loss": 0.2164,
      "step": 5223
    },
    {
      "epoch": 0.4059682934410942,
      "grad_norm": 0.842644453048706,
      "learning_rate": 7.970158532794529e-06,
      "loss": 0.2867,
      "step": 5224
    },
    {
      "epoch": 0.4060460055952751,
      "grad_norm": 0.22854988276958466,
      "learning_rate": 7.969769972023626e-06,
      "loss": 0.0243,
      "step": 5225
    },
    {
      "epoch": 0.406123717749456,
      "grad_norm": 0.8831176161766052,
      "learning_rate": 7.96938141125272e-06,
      "loss": 0.3371,
      "step": 5226
    },
    {
      "epoch": 0.40620142990363695,
      "grad_norm": 0.17667409777641296,
      "learning_rate": 7.968992850481816e-06,
      "loss": 0.1228,
      "step": 5227
    },
    {
      "epoch": 0.40627914205781784,
      "grad_norm": 0.18924032151699066,
      "learning_rate": 7.968604289710912e-06,
      "loss": 0.0499,
      "step": 5228
    },
    {
      "epoch": 0.40635685421199874,
      "grad_norm": 0.39086541533470154,
      "learning_rate": 7.968215728940007e-06,
      "loss": 0.1164,
      "step": 5229
    },
    {
      "epoch": 0.4064345663661797,
      "grad_norm": 0.49490803480148315,
      "learning_rate": 7.967827168169102e-06,
      "loss": 0.2827,
      "step": 5230
    },
    {
      "epoch": 0.4065122785203606,
      "grad_norm": 0.24129706621170044,
      "learning_rate": 7.967438607398199e-06,
      "loss": 0.1089,
      "step": 5231
    },
    {
      "epoch": 0.4065899906745415,
      "grad_norm": 0.4549843370914459,
      "learning_rate": 7.967050046627292e-06,
      "loss": 0.2597,
      "step": 5232
    },
    {
      "epoch": 0.4066677028287224,
      "grad_norm": 0.3591702878475189,
      "learning_rate": 7.966661485856389e-06,
      "loss": 0.1799,
      "step": 5233
    },
    {
      "epoch": 0.40674541498290334,
      "grad_norm": 0.3634495735168457,
      "learning_rate": 7.966272925085484e-06,
      "loss": 0.1613,
      "step": 5234
    },
    {
      "epoch": 0.40682312713708424,
      "grad_norm": 0.662400484085083,
      "learning_rate": 7.965884364314579e-06,
      "loss": 0.2766,
      "step": 5235
    },
    {
      "epoch": 0.40690083929126514,
      "grad_norm": 0.17900338768959045,
      "learning_rate": 7.965495803543675e-06,
      "loss": 0.1243,
      "step": 5236
    },
    {
      "epoch": 0.4069785514454461,
      "grad_norm": 0.519389808177948,
      "learning_rate": 7.96510724277277e-06,
      "loss": 0.2976,
      "step": 5237
    },
    {
      "epoch": 0.407056263599627,
      "grad_norm": 0.03756837174296379,
      "learning_rate": 7.964718682001867e-06,
      "loss": 0.0037,
      "step": 5238
    },
    {
      "epoch": 0.4071339757538079,
      "grad_norm": 0.6719371676445007,
      "learning_rate": 7.964330121230962e-06,
      "loss": 0.5504,
      "step": 5239
    },
    {
      "epoch": 0.4072116879079888,
      "grad_norm": 0.3470713794231415,
      "learning_rate": 7.963941560460057e-06,
      "loss": 0.3281,
      "step": 5240
    },
    {
      "epoch": 0.40728940006216974,
      "grad_norm": 0.5768056511878967,
      "learning_rate": 7.963552999689153e-06,
      "loss": 0.6061,
      "step": 5241
    },
    {
      "epoch": 0.40736711221635064,
      "grad_norm": 0.49632591009140015,
      "learning_rate": 7.963164438918247e-06,
      "loss": 0.3255,
      "step": 5242
    },
    {
      "epoch": 0.40744482437053153,
      "grad_norm": 0.13680300116539001,
      "learning_rate": 7.962775878147343e-06,
      "loss": 0.0294,
      "step": 5243
    },
    {
      "epoch": 0.4075225365247125,
      "grad_norm": 0.38999655842781067,
      "learning_rate": 7.962387317376438e-06,
      "loss": 0.1599,
      "step": 5244
    },
    {
      "epoch": 0.4076002486788934,
      "grad_norm": 1.2274236679077148,
      "learning_rate": 7.961998756605533e-06,
      "loss": 0.5819,
      "step": 5245
    },
    {
      "epoch": 0.4076779608330743,
      "grad_norm": 0.12401372194290161,
      "learning_rate": 7.96161019583463e-06,
      "loss": 0.0089,
      "step": 5246
    },
    {
      "epoch": 0.4077556729872552,
      "grad_norm": 0.2450415939092636,
      "learning_rate": 7.961221635063725e-06,
      "loss": 0.0824,
      "step": 5247
    },
    {
      "epoch": 0.40783338514143613,
      "grad_norm": 0.3721980154514313,
      "learning_rate": 7.96083307429282e-06,
      "loss": 0.0823,
      "step": 5248
    },
    {
      "epoch": 0.40791109729561703,
      "grad_norm": 0.2303452044725418,
      "learning_rate": 7.960444513521915e-06,
      "loss": 0.1223,
      "step": 5249
    },
    {
      "epoch": 0.40798880944979793,
      "grad_norm": 0.3170677423477173,
      "learning_rate": 7.960055952751011e-06,
      "loss": 0.0871,
      "step": 5250
    },
    {
      "epoch": 0.4080665216039789,
      "grad_norm": 0.4303264319896698,
      "learning_rate": 7.959667391980106e-06,
      "loss": 0.2218,
      "step": 5251
    },
    {
      "epoch": 0.4081442337581598,
      "grad_norm": 0.9511129260063171,
      "learning_rate": 7.959278831209201e-06,
      "loss": 0.361,
      "step": 5252
    },
    {
      "epoch": 0.4082219459123407,
      "grad_norm": 0.3097671568393707,
      "learning_rate": 7.958890270438298e-06,
      "loss": 0.17,
      "step": 5253
    },
    {
      "epoch": 0.40829965806652163,
      "grad_norm": 0.10589871555566788,
      "learning_rate": 7.958501709667393e-06,
      "loss": 0.0608,
      "step": 5254
    },
    {
      "epoch": 0.40837737022070253,
      "grad_norm": 0.12912356853485107,
      "learning_rate": 7.958113148896488e-06,
      "loss": 0.024,
      "step": 5255
    },
    {
      "epoch": 0.4084550823748834,
      "grad_norm": 0.20751608908176422,
      "learning_rate": 7.957724588125584e-06,
      "loss": 0.03,
      "step": 5256
    },
    {
      "epoch": 0.4085327945290643,
      "grad_norm": 0.5530218482017517,
      "learning_rate": 7.957336027354678e-06,
      "loss": 0.2379,
      "step": 5257
    },
    {
      "epoch": 0.4086105066832453,
      "grad_norm": 0.3105661869049072,
      "learning_rate": 7.956947466583774e-06,
      "loss": 0.2582,
      "step": 5258
    },
    {
      "epoch": 0.4086882188374262,
      "grad_norm": 0.3568991422653198,
      "learning_rate": 7.95655890581287e-06,
      "loss": 0.2245,
      "step": 5259
    },
    {
      "epoch": 0.4087659309916071,
      "grad_norm": 0.4378388822078705,
      "learning_rate": 7.956170345041964e-06,
      "loss": 0.1484,
      "step": 5260
    },
    {
      "epoch": 0.408843643145788,
      "grad_norm": 0.6130912899971008,
      "learning_rate": 7.95578178427106e-06,
      "loss": 0.3684,
      "step": 5261
    },
    {
      "epoch": 0.4089213552999689,
      "grad_norm": 0.3462024927139282,
      "learning_rate": 7.955393223500156e-06,
      "loss": 0.0904,
      "step": 5262
    },
    {
      "epoch": 0.4089990674541498,
      "grad_norm": 0.5893684029579163,
      "learning_rate": 7.95500466272925e-06,
      "loss": 0.2176,
      "step": 5263
    },
    {
      "epoch": 0.4090767796083307,
      "grad_norm": 0.2445422261953354,
      "learning_rate": 7.954616101958347e-06,
      "loss": 0.4299,
      "step": 5264
    },
    {
      "epoch": 0.4091544917625117,
      "grad_norm": 0.13755005598068237,
      "learning_rate": 7.954227541187442e-06,
      "loss": 0.056,
      "step": 5265
    },
    {
      "epoch": 0.40923220391669257,
      "grad_norm": 0.5404200553894043,
      "learning_rate": 7.953838980416539e-06,
      "loss": 0.0775,
      "step": 5266
    },
    {
      "epoch": 0.40930991607087347,
      "grad_norm": 0.42647963762283325,
      "learning_rate": 7.953450419645632e-06,
      "loss": 0.1326,
      "step": 5267
    },
    {
      "epoch": 0.4093876282250544,
      "grad_norm": 0.03657729551196098,
      "learning_rate": 7.953061858874729e-06,
      "loss": 0.0086,
      "step": 5268
    },
    {
      "epoch": 0.4094653403792353,
      "grad_norm": 0.35102587938308716,
      "learning_rate": 7.952673298103824e-06,
      "loss": 0.2041,
      "step": 5269
    },
    {
      "epoch": 0.4095430525334162,
      "grad_norm": 0.29776668548583984,
      "learning_rate": 7.952284737332919e-06,
      "loss": 0.0686,
      "step": 5270
    },
    {
      "epoch": 0.4096207646875971,
      "grad_norm": 0.3538944125175476,
      "learning_rate": 7.951896176562015e-06,
      "loss": 0.2453,
      "step": 5271
    },
    {
      "epoch": 0.40969847684177807,
      "grad_norm": 0.6015125513076782,
      "learning_rate": 7.95150761579111e-06,
      "loss": 0.4197,
      "step": 5272
    },
    {
      "epoch": 0.40977618899595897,
      "grad_norm": 0.09967521578073502,
      "learning_rate": 7.951119055020205e-06,
      "loss": 0.0305,
      "step": 5273
    },
    {
      "epoch": 0.40985390115013987,
      "grad_norm": 0.10844752192497253,
      "learning_rate": 7.950730494249302e-06,
      "loss": 0.0567,
      "step": 5274
    },
    {
      "epoch": 0.4099316133043208,
      "grad_norm": 0.5197717547416687,
      "learning_rate": 7.950341933478397e-06,
      "loss": 0.1666,
      "step": 5275
    },
    {
      "epoch": 0.4100093254585017,
      "grad_norm": 0.4588817059993744,
      "learning_rate": 7.949953372707492e-06,
      "loss": 0.3589,
      "step": 5276
    },
    {
      "epoch": 0.4100870376126826,
      "grad_norm": 0.32755765318870544,
      "learning_rate": 7.949564811936587e-06,
      "loss": 0.2273,
      "step": 5277
    },
    {
      "epoch": 0.4101647497668635,
      "grad_norm": 0.21604785323143005,
      "learning_rate": 7.949176251165683e-06,
      "loss": 0.0773,
      "step": 5278
    },
    {
      "epoch": 0.41024246192104447,
      "grad_norm": 0.17833290994167328,
      "learning_rate": 7.948787690394778e-06,
      "loss": 0.0449,
      "step": 5279
    },
    {
      "epoch": 0.41032017407522536,
      "grad_norm": 0.3219108283519745,
      "learning_rate": 7.948399129623873e-06,
      "loss": 0.2581,
      "step": 5280
    },
    {
      "epoch": 0.41039788622940626,
      "grad_norm": 0.217861145734787,
      "learning_rate": 7.94801056885297e-06,
      "loss": 0.0415,
      "step": 5281
    },
    {
      "epoch": 0.4104755983835872,
      "grad_norm": 0.2710091471672058,
      "learning_rate": 7.947622008082065e-06,
      "loss": 0.1788,
      "step": 5282
    },
    {
      "epoch": 0.4105533105377681,
      "grad_norm": 0.1567518711090088,
      "learning_rate": 7.94723344731116e-06,
      "loss": 0.0655,
      "step": 5283
    },
    {
      "epoch": 0.410631022691949,
      "grad_norm": 1.2607401609420776,
      "learning_rate": 7.946844886540257e-06,
      "loss": 0.5455,
      "step": 5284
    },
    {
      "epoch": 0.4107087348461299,
      "grad_norm": 0.2877828776836395,
      "learning_rate": 7.94645632576935e-06,
      "loss": 0.1637,
      "step": 5285
    },
    {
      "epoch": 0.41078644700031086,
      "grad_norm": 0.19550077617168427,
      "learning_rate": 7.946067764998446e-06,
      "loss": 0.0758,
      "step": 5286
    },
    {
      "epoch": 0.41086415915449176,
      "grad_norm": 0.07147254794836044,
      "learning_rate": 7.945679204227541e-06,
      "loss": 0.0357,
      "step": 5287
    },
    {
      "epoch": 0.41094187130867266,
      "grad_norm": 0.04631464183330536,
      "learning_rate": 7.945290643456636e-06,
      "loss": 0.0133,
      "step": 5288
    },
    {
      "epoch": 0.4110195834628536,
      "grad_norm": 0.3768083453178406,
      "learning_rate": 7.944902082685733e-06,
      "loss": 0.2188,
      "step": 5289
    },
    {
      "epoch": 0.4110972956170345,
      "grad_norm": 0.1701553910970688,
      "learning_rate": 7.944513521914828e-06,
      "loss": 0.0645,
      "step": 5290
    },
    {
      "epoch": 0.4111750077712154,
      "grad_norm": 0.32506027817726135,
      "learning_rate": 7.944124961143923e-06,
      "loss": 0.4463,
      "step": 5291
    },
    {
      "epoch": 0.41125271992539636,
      "grad_norm": 0.19580863416194916,
      "learning_rate": 7.94373640037302e-06,
      "loss": 0.0759,
      "step": 5292
    },
    {
      "epoch": 0.41133043207957726,
      "grad_norm": 0.31265509128570557,
      "learning_rate": 7.943347839602114e-06,
      "loss": 0.1732,
      "step": 5293
    },
    {
      "epoch": 0.41140814423375816,
      "grad_norm": 0.32944247126579285,
      "learning_rate": 7.94295927883121e-06,
      "loss": 0.0977,
      "step": 5294
    },
    {
      "epoch": 0.41148585638793905,
      "grad_norm": 0.50467848777771,
      "learning_rate": 7.942570718060304e-06,
      "loss": 0.3333,
      "step": 5295
    },
    {
      "epoch": 0.41156356854212,
      "grad_norm": 0.3179946541786194,
      "learning_rate": 7.942182157289401e-06,
      "loss": 0.1731,
      "step": 5296
    },
    {
      "epoch": 0.4116412806963009,
      "grad_norm": 0.5505880117416382,
      "learning_rate": 7.941793596518496e-06,
      "loss": 0.1048,
      "step": 5297
    },
    {
      "epoch": 0.4117189928504818,
      "grad_norm": 0.22006329894065857,
      "learning_rate": 7.941405035747591e-06,
      "loss": 0.2971,
      "step": 5298
    },
    {
      "epoch": 0.41179670500466276,
      "grad_norm": 0.38257473707199097,
      "learning_rate": 7.941016474976688e-06,
      "loss": 0.2136,
      "step": 5299
    },
    {
      "epoch": 0.41187441715884365,
      "grad_norm": 0.15937967598438263,
      "learning_rate": 7.940627914205783e-06,
      "loss": 0.0739,
      "step": 5300
    },
    {
      "epoch": 0.41195212931302455,
      "grad_norm": 0.425778865814209,
      "learning_rate": 7.940239353434877e-06,
      "loss": 0.2099,
      "step": 5301
    },
    {
      "epoch": 0.41202984146720545,
      "grad_norm": 0.15393181145191193,
      "learning_rate": 7.939850792663974e-06,
      "loss": 0.0513,
      "step": 5302
    },
    {
      "epoch": 0.4121075536213864,
      "grad_norm": 0.40534508228302,
      "learning_rate": 7.939462231893069e-06,
      "loss": 0.2122,
      "step": 5303
    },
    {
      "epoch": 0.4121852657755673,
      "grad_norm": 0.1591288298368454,
      "learning_rate": 7.939073671122164e-06,
      "loss": 0.0478,
      "step": 5304
    },
    {
      "epoch": 0.4122629779297482,
      "grad_norm": 0.3459895849227905,
      "learning_rate": 7.938685110351259e-06,
      "loss": 0.2464,
      "step": 5305
    },
    {
      "epoch": 0.41234069008392915,
      "grad_norm": 1.0935100317001343,
      "learning_rate": 7.938296549580356e-06,
      "loss": 0.5816,
      "step": 5306
    },
    {
      "epoch": 0.41241840223811005,
      "grad_norm": 0.2449663281440735,
      "learning_rate": 7.93790798880945e-06,
      "loss": 0.1378,
      "step": 5307
    },
    {
      "epoch": 0.41249611439229095,
      "grad_norm": 0.4040111005306244,
      "learning_rate": 7.937519428038545e-06,
      "loss": 0.1429,
      "step": 5308
    },
    {
      "epoch": 0.41257382654647184,
      "grad_norm": 0.3385580778121948,
      "learning_rate": 7.937130867267642e-06,
      "loss": 0.1719,
      "step": 5309
    },
    {
      "epoch": 0.4126515387006528,
      "grad_norm": 0.2536506950855255,
      "learning_rate": 7.936742306496737e-06,
      "loss": 0.1541,
      "step": 5310
    },
    {
      "epoch": 0.4127292508548337,
      "grad_norm": 0.26554611325263977,
      "learning_rate": 7.936353745725832e-06,
      "loss": 0.0559,
      "step": 5311
    },
    {
      "epoch": 0.4128069630090146,
      "grad_norm": 0.28835755586624146,
      "learning_rate": 7.935965184954929e-06,
      "loss": 0.2082,
      "step": 5312
    },
    {
      "epoch": 0.41288467516319555,
      "grad_norm": 0.4825587570667267,
      "learning_rate": 7.935576624184022e-06,
      "loss": 0.2498,
      "step": 5313
    },
    {
      "epoch": 0.41296238731737644,
      "grad_norm": 0.39099687337875366,
      "learning_rate": 7.935188063413119e-06,
      "loss": 0.2,
      "step": 5314
    },
    {
      "epoch": 0.41304009947155734,
      "grad_norm": 0.07879065722227097,
      "learning_rate": 7.934799502642214e-06,
      "loss": 0.0302,
      "step": 5315
    },
    {
      "epoch": 0.41311781162573824,
      "grad_norm": 0.2096686065196991,
      "learning_rate": 7.934410941871308e-06,
      "loss": 0.0927,
      "step": 5316
    },
    {
      "epoch": 0.4131955237799192,
      "grad_norm": 0.2531166672706604,
      "learning_rate": 7.934022381100405e-06,
      "loss": 0.1851,
      "step": 5317
    },
    {
      "epoch": 0.4132732359341001,
      "grad_norm": 0.16855381429195404,
      "learning_rate": 7.9336338203295e-06,
      "loss": 0.0726,
      "step": 5318
    },
    {
      "epoch": 0.413350948088281,
      "grad_norm": 0.3392021954059601,
      "learning_rate": 7.933245259558595e-06,
      "loss": 0.0498,
      "step": 5319
    },
    {
      "epoch": 0.41342866024246194,
      "grad_norm": 0.25503212213516235,
      "learning_rate": 7.932856698787692e-06,
      "loss": 0.179,
      "step": 5320
    },
    {
      "epoch": 0.41350637239664284,
      "grad_norm": 0.3030228614807129,
      "learning_rate": 7.932468138016787e-06,
      "loss": 0.168,
      "step": 5321
    },
    {
      "epoch": 0.41358408455082374,
      "grad_norm": 0.11553756147623062,
      "learning_rate": 7.932079577245882e-06,
      "loss": 0.0278,
      "step": 5322
    },
    {
      "epoch": 0.41366179670500464,
      "grad_norm": 0.36120742559432983,
      "learning_rate": 7.931691016474977e-06,
      "loss": 0.0882,
      "step": 5323
    },
    {
      "epoch": 0.4137395088591856,
      "grad_norm": 0.2498953640460968,
      "learning_rate": 7.931302455704073e-06,
      "loss": 0.0802,
      "step": 5324
    },
    {
      "epoch": 0.4138172210133665,
      "grad_norm": 0.32901662588119507,
      "learning_rate": 7.930913894933168e-06,
      "loss": 0.1167,
      "step": 5325
    },
    {
      "epoch": 0.4138949331675474,
      "grad_norm": 0.453320175409317,
      "learning_rate": 7.930525334162263e-06,
      "loss": 0.2168,
      "step": 5326
    },
    {
      "epoch": 0.41397264532172834,
      "grad_norm": 0.562388002872467,
      "learning_rate": 7.93013677339136e-06,
      "loss": 0.2127,
      "step": 5327
    },
    {
      "epoch": 0.41405035747590924,
      "grad_norm": 0.368365615606308,
      "learning_rate": 7.929748212620455e-06,
      "loss": 0.1823,
      "step": 5328
    },
    {
      "epoch": 0.41412806963009013,
      "grad_norm": 0.7065823674201965,
      "learning_rate": 7.92935965184955e-06,
      "loss": 0.4143,
      "step": 5329
    },
    {
      "epoch": 0.4142057817842711,
      "grad_norm": 0.10178488492965698,
      "learning_rate": 7.928971091078646e-06,
      "loss": 0.0233,
      "step": 5330
    },
    {
      "epoch": 0.414283493938452,
      "grad_norm": 0.5865825414657593,
      "learning_rate": 7.928582530307741e-06,
      "loss": 0.1738,
      "step": 5331
    },
    {
      "epoch": 0.4143612060926329,
      "grad_norm": 0.24215470254421234,
      "learning_rate": 7.928193969536836e-06,
      "loss": 0.1479,
      "step": 5332
    },
    {
      "epoch": 0.4144389182468138,
      "grad_norm": 0.38369956612586975,
      "learning_rate": 7.927805408765931e-06,
      "loss": 0.1277,
      "step": 5333
    },
    {
      "epoch": 0.41451663040099473,
      "grad_norm": 0.2641570568084717,
      "learning_rate": 7.927416847995028e-06,
      "loss": 0.0673,
      "step": 5334
    },
    {
      "epoch": 0.41459434255517563,
      "grad_norm": 0.47723618149757385,
      "learning_rate": 7.927028287224123e-06,
      "loss": 0.6587,
      "step": 5335
    },
    {
      "epoch": 0.41467205470935653,
      "grad_norm": 0.567948579788208,
      "learning_rate": 7.926639726453218e-06,
      "loss": 0.3087,
      "step": 5336
    },
    {
      "epoch": 0.4147497668635375,
      "grad_norm": 0.25674283504486084,
      "learning_rate": 7.926251165682314e-06,
      "loss": 0.1052,
      "step": 5337
    },
    {
      "epoch": 0.4148274790177184,
      "grad_norm": 0.4200570285320282,
      "learning_rate": 7.92586260491141e-06,
      "loss": 0.2651,
      "step": 5338
    },
    {
      "epoch": 0.4149051911718993,
      "grad_norm": 0.9416331648826599,
      "learning_rate": 7.925474044140504e-06,
      "loss": 0.1854,
      "step": 5339
    },
    {
      "epoch": 0.4149829033260802,
      "grad_norm": 0.7356389760971069,
      "learning_rate": 7.9250854833696e-06,
      "loss": 0.1979,
      "step": 5340
    },
    {
      "epoch": 0.41506061548026113,
      "grad_norm": 0.8238320350646973,
      "learning_rate": 7.924696922598694e-06,
      "loss": 0.4552,
      "step": 5341
    },
    {
      "epoch": 0.41513832763444203,
      "grad_norm": 0.1087891086935997,
      "learning_rate": 7.92430836182779e-06,
      "loss": 0.0374,
      "step": 5342
    },
    {
      "epoch": 0.4152160397886229,
      "grad_norm": 0.20686011016368866,
      "learning_rate": 7.923919801056886e-06,
      "loss": 0.0412,
      "step": 5343
    },
    {
      "epoch": 0.4152937519428039,
      "grad_norm": 0.2135903239250183,
      "learning_rate": 7.92353124028598e-06,
      "loss": 0.2813,
      "step": 5344
    },
    {
      "epoch": 0.4153714640969848,
      "grad_norm": 0.32745590806007385,
      "learning_rate": 7.923142679515077e-06,
      "loss": 0.507,
      "step": 5345
    },
    {
      "epoch": 0.4154491762511657,
      "grad_norm": 0.7068589925765991,
      "learning_rate": 7.922754118744172e-06,
      "loss": 0.5834,
      "step": 5346
    },
    {
      "epoch": 0.4155268884053466,
      "grad_norm": 0.12616200745105743,
      "learning_rate": 7.922365557973267e-06,
      "loss": 0.0169,
      "step": 5347
    },
    {
      "epoch": 0.4156046005595275,
      "grad_norm": 0.5448500514030457,
      "learning_rate": 7.921976997202364e-06,
      "loss": 0.3056,
      "step": 5348
    },
    {
      "epoch": 0.4156823127137084,
      "grad_norm": 0.2729000747203827,
      "learning_rate": 7.921588436431459e-06,
      "loss": 0.2892,
      "step": 5349
    },
    {
      "epoch": 0.4157600248678893,
      "grad_norm": 0.6090372800827026,
      "learning_rate": 7.921199875660554e-06,
      "loss": 0.2254,
      "step": 5350
    },
    {
      "epoch": 0.4158377370220703,
      "grad_norm": 0.33151835203170776,
      "learning_rate": 7.920811314889649e-06,
      "loss": 0.2468,
      "step": 5351
    },
    {
      "epoch": 0.4159154491762512,
      "grad_norm": 0.08277596533298492,
      "learning_rate": 7.920422754118745e-06,
      "loss": 0.0325,
      "step": 5352
    },
    {
      "epoch": 0.41599316133043207,
      "grad_norm": 0.08729754388332367,
      "learning_rate": 7.92003419334784e-06,
      "loss": 0.0162,
      "step": 5353
    },
    {
      "epoch": 0.41607087348461297,
      "grad_norm": 0.1808929592370987,
      "learning_rate": 7.919645632576935e-06,
      "loss": 0.0751,
      "step": 5354
    },
    {
      "epoch": 0.4161485856387939,
      "grad_norm": 0.3070942163467407,
      "learning_rate": 7.919257071806032e-06,
      "loss": 0.1189,
      "step": 5355
    },
    {
      "epoch": 0.4162262977929748,
      "grad_norm": 0.5430571436882019,
      "learning_rate": 7.918868511035127e-06,
      "loss": 0.1043,
      "step": 5356
    },
    {
      "epoch": 0.4163040099471557,
      "grad_norm": 0.12882272899150848,
      "learning_rate": 7.918479950264222e-06,
      "loss": 0.0237,
      "step": 5357
    },
    {
      "epoch": 0.41638172210133667,
      "grad_norm": 0.25485169887542725,
      "learning_rate": 7.918091389493318e-06,
      "loss": 0.0856,
      "step": 5358
    },
    {
      "epoch": 0.41645943425551757,
      "grad_norm": 2.286402702331543,
      "learning_rate": 7.917702828722413e-06,
      "loss": 0.873,
      "step": 5359
    },
    {
      "epoch": 0.41653714640969847,
      "grad_norm": 0.0930701196193695,
      "learning_rate": 7.917314267951508e-06,
      "loss": 0.0251,
      "step": 5360
    },
    {
      "epoch": 0.41661485856387936,
      "grad_norm": 0.2817293405532837,
      "learning_rate": 7.916925707180603e-06,
      "loss": 0.0579,
      "step": 5361
    },
    {
      "epoch": 0.4166925707180603,
      "grad_norm": 0.3412818908691406,
      "learning_rate": 7.9165371464097e-06,
      "loss": 0.0586,
      "step": 5362
    },
    {
      "epoch": 0.4167702828722412,
      "grad_norm": 0.3806041479110718,
      "learning_rate": 7.916148585638795e-06,
      "loss": 0.198,
      "step": 5363
    },
    {
      "epoch": 0.4168479950264221,
      "grad_norm": 0.07803074270486832,
      "learning_rate": 7.91576002486789e-06,
      "loss": 0.0398,
      "step": 5364
    },
    {
      "epoch": 0.41692570718060307,
      "grad_norm": 0.8472108244895935,
      "learning_rate": 7.915371464096986e-06,
      "loss": 0.2381,
      "step": 5365
    },
    {
      "epoch": 0.41700341933478396,
      "grad_norm": 0.4209112524986267,
      "learning_rate": 7.914982903326081e-06,
      "loss": 0.3044,
      "step": 5366
    },
    {
      "epoch": 0.41708113148896486,
      "grad_norm": 0.5144661664962769,
      "learning_rate": 7.914594342555176e-06,
      "loss": 0.1538,
      "step": 5367
    },
    {
      "epoch": 0.41715884364314576,
      "grad_norm": 0.5372070074081421,
      "learning_rate": 7.914205781784273e-06,
      "loss": 0.6416,
      "step": 5368
    },
    {
      "epoch": 0.4172365557973267,
      "grad_norm": 0.45046138763427734,
      "learning_rate": 7.913817221013366e-06,
      "loss": 0.7408,
      "step": 5369
    },
    {
      "epoch": 0.4173142679515076,
      "grad_norm": 0.15219075977802277,
      "learning_rate": 7.913428660242463e-06,
      "loss": 0.1118,
      "step": 5370
    },
    {
      "epoch": 0.4173919801056885,
      "grad_norm": 0.2151755690574646,
      "learning_rate": 7.913040099471558e-06,
      "loss": 0.0141,
      "step": 5371
    },
    {
      "epoch": 0.41746969225986946,
      "grad_norm": 0.18221712112426758,
      "learning_rate": 7.912651538700653e-06,
      "loss": 0.0646,
      "step": 5372
    },
    {
      "epoch": 0.41754740441405036,
      "grad_norm": 0.2611260712146759,
      "learning_rate": 7.91226297792975e-06,
      "loss": 0.1208,
      "step": 5373
    },
    {
      "epoch": 0.41762511656823126,
      "grad_norm": 0.16731101274490356,
      "learning_rate": 7.911874417158844e-06,
      "loss": 0.0362,
      "step": 5374
    },
    {
      "epoch": 0.4177028287224122,
      "grad_norm": 0.09785059094429016,
      "learning_rate": 7.91148585638794e-06,
      "loss": 0.0134,
      "step": 5375
    },
    {
      "epoch": 0.4177805408765931,
      "grad_norm": 0.8306058049201965,
      "learning_rate": 7.911097295617034e-06,
      "loss": 0.312,
      "step": 5376
    },
    {
      "epoch": 0.417858253030774,
      "grad_norm": 0.47572168707847595,
      "learning_rate": 7.910708734846131e-06,
      "loss": 0.3729,
      "step": 5377
    },
    {
      "epoch": 0.4179359651849549,
      "grad_norm": 0.5066795349121094,
      "learning_rate": 7.910320174075226e-06,
      "loss": 0.2262,
      "step": 5378
    },
    {
      "epoch": 0.41801367733913586,
      "grad_norm": 0.24807412922382355,
      "learning_rate": 7.90993161330432e-06,
      "loss": 0.1311,
      "step": 5379
    },
    {
      "epoch": 0.41809138949331676,
      "grad_norm": 0.871512234210968,
      "learning_rate": 7.909543052533417e-06,
      "loss": 0.5673,
      "step": 5380
    },
    {
      "epoch": 0.41816910164749765,
      "grad_norm": 0.32429933547973633,
      "learning_rate": 7.909154491762512e-06,
      "loss": 0.1198,
      "step": 5381
    },
    {
      "epoch": 0.4182468138016786,
      "grad_norm": 0.3733876347541809,
      "learning_rate": 7.908765930991607e-06,
      "loss": 0.1428,
      "step": 5382
    },
    {
      "epoch": 0.4183245259558595,
      "grad_norm": 0.26285138726234436,
      "learning_rate": 7.908377370220704e-06,
      "loss": 0.3676,
      "step": 5383
    },
    {
      "epoch": 0.4184022381100404,
      "grad_norm": 0.5462828278541565,
      "learning_rate": 7.907988809449797e-06,
      "loss": 0.2035,
      "step": 5384
    },
    {
      "epoch": 0.4184799502642213,
      "grad_norm": 0.528670072555542,
      "learning_rate": 7.907600248678894e-06,
      "loss": 0.2117,
      "step": 5385
    },
    {
      "epoch": 0.41855766241840225,
      "grad_norm": 0.4559358060359955,
      "learning_rate": 7.907211687907989e-06,
      "loss": 0.2147,
      "step": 5386
    },
    {
      "epoch": 0.41863537457258315,
      "grad_norm": 0.4468812942504883,
      "learning_rate": 7.906823127137085e-06,
      "loss": 0.1992,
      "step": 5387
    },
    {
      "epoch": 0.41871308672676405,
      "grad_norm": 0.16025541722774506,
      "learning_rate": 7.90643456636618e-06,
      "loss": 0.039,
      "step": 5388
    },
    {
      "epoch": 0.418790798880945,
      "grad_norm": 0.36643195152282715,
      "learning_rate": 7.906046005595275e-06,
      "loss": 0.1672,
      "step": 5389
    },
    {
      "epoch": 0.4188685110351259,
      "grad_norm": 0.31434905529022217,
      "learning_rate": 7.905657444824372e-06,
      "loss": 0.1346,
      "step": 5390
    },
    {
      "epoch": 0.4189462231893068,
      "grad_norm": 0.5096296072006226,
      "learning_rate": 7.905268884053467e-06,
      "loss": 0.3043,
      "step": 5391
    },
    {
      "epoch": 0.4190239353434877,
      "grad_norm": 0.30022329092025757,
      "learning_rate": 7.904880323282562e-06,
      "loss": 0.0965,
      "step": 5392
    },
    {
      "epoch": 0.41910164749766865,
      "grad_norm": 0.31503963470458984,
      "learning_rate": 7.904491762511659e-06,
      "loss": 0.1582,
      "step": 5393
    },
    {
      "epoch": 0.41917935965184955,
      "grad_norm": 0.4705553352832794,
      "learning_rate": 7.904103201740752e-06,
      "loss": 0.1915,
      "step": 5394
    },
    {
      "epoch": 0.41925707180603045,
      "grad_norm": 0.4569406509399414,
      "learning_rate": 7.903714640969848e-06,
      "loss": 0.626,
      "step": 5395
    },
    {
      "epoch": 0.4193347839602114,
      "grad_norm": 0.20435559749603271,
      "learning_rate": 7.903326080198943e-06,
      "loss": 0.078,
      "step": 5396
    },
    {
      "epoch": 0.4194124961143923,
      "grad_norm": 0.2555345892906189,
      "learning_rate": 7.902937519428038e-06,
      "loss": 0.0796,
      "step": 5397
    },
    {
      "epoch": 0.4194902082685732,
      "grad_norm": 0.6458295583724976,
      "learning_rate": 7.902548958657135e-06,
      "loss": 0.5269,
      "step": 5398
    },
    {
      "epoch": 0.4195679204227541,
      "grad_norm": 0.44210097193717957,
      "learning_rate": 7.90216039788623e-06,
      "loss": 0.1999,
      "step": 5399
    },
    {
      "epoch": 0.41964563257693505,
      "grad_norm": 0.1205335184931755,
      "learning_rate": 7.901771837115325e-06,
      "loss": 0.0285,
      "step": 5400
    },
    {
      "epoch": 0.41972334473111594,
      "grad_norm": 0.13779671490192413,
      "learning_rate": 7.901383276344422e-06,
      "loss": 0.2474,
      "step": 5401
    },
    {
      "epoch": 0.41980105688529684,
      "grad_norm": 0.5835418701171875,
      "learning_rate": 7.900994715573517e-06,
      "loss": 0.4056,
      "step": 5402
    },
    {
      "epoch": 0.4198787690394778,
      "grad_norm": 0.4904371500015259,
      "learning_rate": 7.900606154802611e-06,
      "loss": 0.5959,
      "step": 5403
    },
    {
      "epoch": 0.4199564811936587,
      "grad_norm": 0.5095245242118835,
      "learning_rate": 7.900217594031706e-06,
      "loss": 0.2714,
      "step": 5404
    },
    {
      "epoch": 0.4200341933478396,
      "grad_norm": 0.24835701286792755,
      "learning_rate": 7.899829033260803e-06,
      "loss": 0.3708,
      "step": 5405
    },
    {
      "epoch": 0.4201119055020205,
      "grad_norm": 0.03735102340579033,
      "learning_rate": 7.899440472489898e-06,
      "loss": 0.0182,
      "step": 5406
    },
    {
      "epoch": 0.42018961765620144,
      "grad_norm": 0.1621403694152832,
      "learning_rate": 7.899051911718993e-06,
      "loss": 0.0238,
      "step": 5407
    },
    {
      "epoch": 0.42026732981038234,
      "grad_norm": 0.06721962243318558,
      "learning_rate": 7.89866335094809e-06,
      "loss": 0.0127,
      "step": 5408
    },
    {
      "epoch": 0.42034504196456324,
      "grad_norm": 0.6637813448905945,
      "learning_rate": 7.898274790177185e-06,
      "loss": 0.3422,
      "step": 5409
    },
    {
      "epoch": 0.4204227541187442,
      "grad_norm": 0.7716641426086426,
      "learning_rate": 7.89788622940628e-06,
      "loss": 0.2558,
      "step": 5410
    },
    {
      "epoch": 0.4205004662729251,
      "grad_norm": 0.3866155743598938,
      "learning_rate": 7.897497668635376e-06,
      "loss": 0.1843,
      "step": 5411
    },
    {
      "epoch": 0.420578178427106,
      "grad_norm": 0.1636730134487152,
      "learning_rate": 7.89710910786447e-06,
      "loss": 0.0521,
      "step": 5412
    },
    {
      "epoch": 0.42065589058128694,
      "grad_norm": 0.3255208730697632,
      "learning_rate": 7.896720547093566e-06,
      "loss": 0.188,
      "step": 5413
    },
    {
      "epoch": 0.42073360273546784,
      "grad_norm": 0.6029853224754333,
      "learning_rate": 7.896331986322661e-06,
      "loss": 0.3578,
      "step": 5414
    },
    {
      "epoch": 0.42081131488964874,
      "grad_norm": 1.4997608661651611,
      "learning_rate": 7.895943425551756e-06,
      "loss": 0.5171,
      "step": 5415
    },
    {
      "epoch": 0.42088902704382963,
      "grad_norm": 0.3742319941520691,
      "learning_rate": 7.895554864780853e-06,
      "loss": 0.1035,
      "step": 5416
    },
    {
      "epoch": 0.4209667391980106,
      "grad_norm": 0.7065902948379517,
      "learning_rate": 7.895166304009948e-06,
      "loss": 0.2926,
      "step": 5417
    },
    {
      "epoch": 0.4210444513521915,
      "grad_norm": 0.07664161920547485,
      "learning_rate": 7.894777743239044e-06,
      "loss": 0.0168,
      "step": 5418
    },
    {
      "epoch": 0.4211221635063724,
      "grad_norm": 0.17085659503936768,
      "learning_rate": 7.894389182468139e-06,
      "loss": 0.0433,
      "step": 5419
    },
    {
      "epoch": 0.42119987566055334,
      "grad_norm": 0.21957407891750336,
      "learning_rate": 7.894000621697234e-06,
      "loss": 0.0557,
      "step": 5420
    },
    {
      "epoch": 0.42127758781473423,
      "grad_norm": 0.07857874780893326,
      "learning_rate": 7.89361206092633e-06,
      "loss": 0.0446,
      "step": 5421
    },
    {
      "epoch": 0.42135529996891513,
      "grad_norm": 0.17641586065292358,
      "learning_rate": 7.893223500155424e-06,
      "loss": 0.055,
      "step": 5422
    },
    {
      "epoch": 0.42143301212309603,
      "grad_norm": 0.30302080512046814,
      "learning_rate": 7.89283493938452e-06,
      "loss": 0.1024,
      "step": 5423
    },
    {
      "epoch": 0.421510724277277,
      "grad_norm": 0.4710153341293335,
      "learning_rate": 7.892446378613616e-06,
      "loss": 0.7216,
      "step": 5424
    },
    {
      "epoch": 0.4215884364314579,
      "grad_norm": 0.37966009974479675,
      "learning_rate": 7.89205781784271e-06,
      "loss": 0.2002,
      "step": 5425
    },
    {
      "epoch": 0.4216661485856388,
      "grad_norm": 0.1976768523454666,
      "learning_rate": 7.891669257071807e-06,
      "loss": 0.0675,
      "step": 5426
    },
    {
      "epoch": 0.42174386073981973,
      "grad_norm": 0.13963475823402405,
      "learning_rate": 7.891280696300902e-06,
      "loss": 0.038,
      "step": 5427
    },
    {
      "epoch": 0.42182157289400063,
      "grad_norm": 0.5338717699050903,
      "learning_rate": 7.890892135529997e-06,
      "loss": 0.2531,
      "step": 5428
    },
    {
      "epoch": 0.4218992850481815,
      "grad_norm": 0.7340571880340576,
      "learning_rate": 7.890503574759094e-06,
      "loss": 0.1498,
      "step": 5429
    },
    {
      "epoch": 0.4219769972023624,
      "grad_norm": 0.14210771024227142,
      "learning_rate": 7.890115013988189e-06,
      "loss": 0.0365,
      "step": 5430
    },
    {
      "epoch": 0.4220547093565434,
      "grad_norm": 0.20003406703472137,
      "learning_rate": 7.889726453217284e-06,
      "loss": 0.1021,
      "step": 5431
    },
    {
      "epoch": 0.4221324215107243,
      "grad_norm": 0.09059534966945648,
      "learning_rate": 7.889337892446379e-06,
      "loss": 0.0142,
      "step": 5432
    },
    {
      "epoch": 0.4222101336649052,
      "grad_norm": 0.19665883481502533,
      "learning_rate": 7.888949331675475e-06,
      "loss": 0.0325,
      "step": 5433
    },
    {
      "epoch": 0.4222878458190861,
      "grad_norm": 0.4332825541496277,
      "learning_rate": 7.88856077090457e-06,
      "loss": 0.1496,
      "step": 5434
    },
    {
      "epoch": 0.422365557973267,
      "grad_norm": 0.11786848306655884,
      "learning_rate": 7.888172210133665e-06,
      "loss": 0.0414,
      "step": 5435
    },
    {
      "epoch": 0.4224432701274479,
      "grad_norm": 0.3945908546447754,
      "learning_rate": 7.887783649362762e-06,
      "loss": 0.0425,
      "step": 5436
    },
    {
      "epoch": 0.4225209822816288,
      "grad_norm": 0.28136247396469116,
      "learning_rate": 7.887395088591857e-06,
      "loss": 0.073,
      "step": 5437
    },
    {
      "epoch": 0.4225986944358098,
      "grad_norm": 0.6654068827629089,
      "learning_rate": 7.887006527820952e-06,
      "loss": 0.2245,
      "step": 5438
    },
    {
      "epoch": 0.42267640658999067,
      "grad_norm": 0.15986749529838562,
      "learning_rate": 7.886617967050048e-06,
      "loss": 0.0482,
      "step": 5439
    },
    {
      "epoch": 0.42275411874417157,
      "grad_norm": 0.27735310792922974,
      "learning_rate": 7.886229406279142e-06,
      "loss": 0.0657,
      "step": 5440
    },
    {
      "epoch": 0.4228318308983525,
      "grad_norm": 0.4650880694389343,
      "learning_rate": 7.885840845508238e-06,
      "loss": 0.1683,
      "step": 5441
    },
    {
      "epoch": 0.4229095430525334,
      "grad_norm": 0.39449596405029297,
      "learning_rate": 7.885452284737333e-06,
      "loss": 0.4228,
      "step": 5442
    },
    {
      "epoch": 0.4229872552067143,
      "grad_norm": 0.36482974886894226,
      "learning_rate": 7.885063723966428e-06,
      "loss": 0.2325,
      "step": 5443
    },
    {
      "epoch": 0.4230649673608952,
      "grad_norm": 0.30845052003860474,
      "learning_rate": 7.884675163195525e-06,
      "loss": 0.085,
      "step": 5444
    },
    {
      "epoch": 0.42314267951507617,
      "grad_norm": 0.9425726532936096,
      "learning_rate": 7.88428660242462e-06,
      "loss": 0.3341,
      "step": 5445
    },
    {
      "epoch": 0.42322039166925707,
      "grad_norm": 0.5077589154243469,
      "learning_rate": 7.883898041653715e-06,
      "loss": 0.1141,
      "step": 5446
    },
    {
      "epoch": 0.42329810382343797,
      "grad_norm": 0.07627764344215393,
      "learning_rate": 7.883509480882811e-06,
      "loss": 0.0182,
      "step": 5447
    },
    {
      "epoch": 0.4233758159776189,
      "grad_norm": 0.47910284996032715,
      "learning_rate": 7.883120920111906e-06,
      "loss": 0.5471,
      "step": 5448
    },
    {
      "epoch": 0.4234535281317998,
      "grad_norm": 0.26355627179145813,
      "learning_rate": 7.882732359341003e-06,
      "loss": 0.0815,
      "step": 5449
    },
    {
      "epoch": 0.4235312402859807,
      "grad_norm": 0.31806474924087524,
      "learning_rate": 7.882343798570096e-06,
      "loss": 0.3013,
      "step": 5450
    },
    {
      "epoch": 0.42360895244016167,
      "grad_norm": 0.5339274406433105,
      "learning_rate": 7.881955237799193e-06,
      "loss": 0.1706,
      "step": 5451
    },
    {
      "epoch": 0.42368666459434257,
      "grad_norm": 0.1811453402042389,
      "learning_rate": 7.881566677028288e-06,
      "loss": 0.0976,
      "step": 5452
    },
    {
      "epoch": 0.42376437674852346,
      "grad_norm": 0.10060413926839828,
      "learning_rate": 7.881178116257383e-06,
      "loss": 0.0221,
      "step": 5453
    },
    {
      "epoch": 0.42384208890270436,
      "grad_norm": 0.3834323287010193,
      "learning_rate": 7.88078955548648e-06,
      "loss": 0.185,
      "step": 5454
    },
    {
      "epoch": 0.4239198010568853,
      "grad_norm": 0.7473152279853821,
      "learning_rate": 7.880400994715574e-06,
      "loss": 0.2611,
      "step": 5455
    },
    {
      "epoch": 0.4239975132110662,
      "grad_norm": 0.3986910581588745,
      "learning_rate": 7.88001243394467e-06,
      "loss": 0.2417,
      "step": 5456
    },
    {
      "epoch": 0.4240752253652471,
      "grad_norm": 0.11747180670499802,
      "learning_rate": 7.879623873173766e-06,
      "loss": 0.0689,
      "step": 5457
    },
    {
      "epoch": 0.42415293751942806,
      "grad_norm": 0.25019344687461853,
      "learning_rate": 7.87923531240286e-06,
      "loss": 0.2039,
      "step": 5458
    },
    {
      "epoch": 0.42423064967360896,
      "grad_norm": 0.17488832771778107,
      "learning_rate": 7.878846751631956e-06,
      "loss": 0.0192,
      "step": 5459
    },
    {
      "epoch": 0.42430836182778986,
      "grad_norm": 0.2927516996860504,
      "learning_rate": 7.87845819086105e-06,
      "loss": 0.1223,
      "step": 5460
    },
    {
      "epoch": 0.42438607398197076,
      "grad_norm": 0.3351037800312042,
      "learning_rate": 7.878069630090147e-06,
      "loss": 0.0783,
      "step": 5461
    },
    {
      "epoch": 0.4244637861361517,
      "grad_norm": 0.5928686261177063,
      "learning_rate": 7.877681069319242e-06,
      "loss": 0.8839,
      "step": 5462
    },
    {
      "epoch": 0.4245414982903326,
      "grad_norm": 0.3757184147834778,
      "learning_rate": 7.877292508548337e-06,
      "loss": 0.3236,
      "step": 5463
    },
    {
      "epoch": 0.4246192104445135,
      "grad_norm": 0.8256353735923767,
      "learning_rate": 7.876903947777434e-06,
      "loss": 0.1239,
      "step": 5464
    },
    {
      "epoch": 0.42469692259869446,
      "grad_norm": 0.3735959827899933,
      "learning_rate": 7.876515387006529e-06,
      "loss": 0.1068,
      "step": 5465
    },
    {
      "epoch": 0.42477463475287536,
      "grad_norm": 0.3877714276313782,
      "learning_rate": 7.876126826235624e-06,
      "loss": 0.175,
      "step": 5466
    },
    {
      "epoch": 0.42485234690705626,
      "grad_norm": 0.1796521544456482,
      "learning_rate": 7.87573826546472e-06,
      "loss": 0.0643,
      "step": 5467
    },
    {
      "epoch": 0.42493005906123715,
      "grad_norm": 0.3177945613861084,
      "learning_rate": 7.875349704693814e-06,
      "loss": 0.1618,
      "step": 5468
    },
    {
      "epoch": 0.4250077712154181,
      "grad_norm": 0.12788568437099457,
      "learning_rate": 7.87496114392291e-06,
      "loss": 0.0197,
      "step": 5469
    },
    {
      "epoch": 0.425085483369599,
      "grad_norm": 0.3665510416030884,
      "learning_rate": 7.874572583152005e-06,
      "loss": 0.2271,
      "step": 5470
    },
    {
      "epoch": 0.4251631955237799,
      "grad_norm": 0.55585116147995,
      "learning_rate": 7.8741840223811e-06,
      "loss": 0.3654,
      "step": 5471
    },
    {
      "epoch": 0.42524090767796086,
      "grad_norm": 0.6536270380020142,
      "learning_rate": 7.873795461610197e-06,
      "loss": 0.5429,
      "step": 5472
    },
    {
      "epoch": 0.42531861983214175,
      "grad_norm": 0.2134547084569931,
      "learning_rate": 7.873406900839292e-06,
      "loss": 0.0654,
      "step": 5473
    },
    {
      "epoch": 0.42539633198632265,
      "grad_norm": 0.3683605492115021,
      "learning_rate": 7.873018340068387e-06,
      "loss": 0.2422,
      "step": 5474
    },
    {
      "epoch": 0.42547404414050355,
      "grad_norm": 0.23919081687927246,
      "learning_rate": 7.872629779297483e-06,
      "loss": 0.2114,
      "step": 5475
    },
    {
      "epoch": 0.4255517562946845,
      "grad_norm": 0.26164305210113525,
      "learning_rate": 7.872241218526578e-06,
      "loss": 0.1081,
      "step": 5476
    },
    {
      "epoch": 0.4256294684488654,
      "grad_norm": 0.41507917642593384,
      "learning_rate": 7.871852657755673e-06,
      "loss": 0.3978,
      "step": 5477
    },
    {
      "epoch": 0.4257071806030463,
      "grad_norm": 0.08748601377010345,
      "learning_rate": 7.871464096984768e-06,
      "loss": 0.0509,
      "step": 5478
    },
    {
      "epoch": 0.42578489275722725,
      "grad_norm": 0.4611404538154602,
      "learning_rate": 7.871075536213865e-06,
      "loss": 0.2938,
      "step": 5479
    },
    {
      "epoch": 0.42586260491140815,
      "grad_norm": 0.35500508546829224,
      "learning_rate": 7.87068697544296e-06,
      "loss": 0.3646,
      "step": 5480
    },
    {
      "epoch": 0.42594031706558905,
      "grad_norm": 0.0868111252784729,
      "learning_rate": 7.870298414672055e-06,
      "loss": 0.0312,
      "step": 5481
    },
    {
      "epoch": 0.42601802921976994,
      "grad_norm": 0.13861282169818878,
      "learning_rate": 7.869909853901151e-06,
      "loss": 0.0333,
      "step": 5482
    },
    {
      "epoch": 0.4260957413739509,
      "grad_norm": 0.15268582105636597,
      "learning_rate": 7.869521293130246e-06,
      "loss": 0.061,
      "step": 5483
    },
    {
      "epoch": 0.4261734535281318,
      "grad_norm": 0.07414014637470245,
      "learning_rate": 7.869132732359341e-06,
      "loss": 0.0383,
      "step": 5484
    },
    {
      "epoch": 0.4262511656823127,
      "grad_norm": 0.27676019072532654,
      "learning_rate": 7.868744171588438e-06,
      "loss": 0.0761,
      "step": 5485
    },
    {
      "epoch": 0.42632887783649365,
      "grad_norm": 0.43659403920173645,
      "learning_rate": 7.868355610817533e-06,
      "loss": 0.1848,
      "step": 5486
    },
    {
      "epoch": 0.42640658999067454,
      "grad_norm": 0.13068191707134247,
      "learning_rate": 7.867967050046628e-06,
      "loss": 0.0519,
      "step": 5487
    },
    {
      "epoch": 0.42648430214485544,
      "grad_norm": 0.10018861293792725,
      "learning_rate": 7.867578489275723e-06,
      "loss": 0.0472,
      "step": 5488
    },
    {
      "epoch": 0.4265620142990364,
      "grad_norm": 0.35409218072891235,
      "learning_rate": 7.86718992850482e-06,
      "loss": 0.2723,
      "step": 5489
    },
    {
      "epoch": 0.4266397264532173,
      "grad_norm": 0.35272470116615295,
      "learning_rate": 7.866801367733914e-06,
      "loss": 0.1884,
      "step": 5490
    },
    {
      "epoch": 0.4267174386073982,
      "grad_norm": 0.11844440549612045,
      "learning_rate": 7.86641280696301e-06,
      "loss": 0.1634,
      "step": 5491
    },
    {
      "epoch": 0.4267951507615791,
      "grad_norm": 0.3041606545448303,
      "learning_rate": 7.866024246192106e-06,
      "loss": 0.0781,
      "step": 5492
    },
    {
      "epoch": 0.42687286291576004,
      "grad_norm": 0.3377753496170044,
      "learning_rate": 7.865635685421201e-06,
      "loss": 0.1676,
      "step": 5493
    },
    {
      "epoch": 0.42695057506994094,
      "grad_norm": 1.109018087387085,
      "learning_rate": 7.865247124650296e-06,
      "loss": 0.4633,
      "step": 5494
    },
    {
      "epoch": 0.42702828722412184,
      "grad_norm": 0.751221776008606,
      "learning_rate": 7.864858563879391e-06,
      "loss": 0.3823,
      "step": 5495
    },
    {
      "epoch": 0.4271059993783028,
      "grad_norm": 0.1297314465045929,
      "learning_rate": 7.864470003108486e-06,
      "loss": 0.1047,
      "step": 5496
    },
    {
      "epoch": 0.4271837115324837,
      "grad_norm": 0.5201635360717773,
      "learning_rate": 7.864081442337582e-06,
      "loss": 0.1196,
      "step": 5497
    },
    {
      "epoch": 0.4272614236866646,
      "grad_norm": 0.8567744493484497,
      "learning_rate": 7.863692881566677e-06,
      "loss": 0.2022,
      "step": 5498
    },
    {
      "epoch": 0.4273391358408455,
      "grad_norm": 0.21939730644226074,
      "learning_rate": 7.863304320795772e-06,
      "loss": 0.1341,
      "step": 5499
    },
    {
      "epoch": 0.42741684799502644,
      "grad_norm": 0.4981297552585602,
      "learning_rate": 7.862915760024869e-06,
      "loss": 0.5146,
      "step": 5500
    },
    {
      "epoch": 0.42749456014920734,
      "grad_norm": 0.28955841064453125,
      "learning_rate": 7.862527199253964e-06,
      "loss": 0.0981,
      "step": 5501
    },
    {
      "epoch": 0.42757227230338823,
      "grad_norm": 0.23204462230205536,
      "learning_rate": 7.862138638483059e-06,
      "loss": 0.2016,
      "step": 5502
    },
    {
      "epoch": 0.4276499844575692,
      "grad_norm": 0.37268367409706116,
      "learning_rate": 7.861750077712154e-06,
      "loss": 0.1148,
      "step": 5503
    },
    {
      "epoch": 0.4277276966117501,
      "grad_norm": 0.2126004546880722,
      "learning_rate": 7.86136151694125e-06,
      "loss": 0.0523,
      "step": 5504
    },
    {
      "epoch": 0.427805408765931,
      "grad_norm": 0.4399271607398987,
      "learning_rate": 7.860972956170345e-06,
      "loss": 0.038,
      "step": 5505
    },
    {
      "epoch": 0.4278831209201119,
      "grad_norm": 0.2830919623374939,
      "learning_rate": 7.86058439539944e-06,
      "loss": 0.1146,
      "step": 5506
    },
    {
      "epoch": 0.42796083307429283,
      "grad_norm": 0.3471481204032898,
      "learning_rate": 7.860195834628537e-06,
      "loss": 0.2,
      "step": 5507
    },
    {
      "epoch": 0.42803854522847373,
      "grad_norm": 0.6097347736358643,
      "learning_rate": 7.859807273857632e-06,
      "loss": 0.6157,
      "step": 5508
    },
    {
      "epoch": 0.42811625738265463,
      "grad_norm": 0.17690153419971466,
      "learning_rate": 7.859418713086727e-06,
      "loss": 0.1142,
      "step": 5509
    },
    {
      "epoch": 0.4281939695368356,
      "grad_norm": 0.6224048137664795,
      "learning_rate": 7.859030152315824e-06,
      "loss": 0.4575,
      "step": 5510
    },
    {
      "epoch": 0.4282716816910165,
      "grad_norm": 0.234243243932724,
      "learning_rate": 7.858641591544919e-06,
      "loss": 0.0797,
      "step": 5511
    },
    {
      "epoch": 0.4283493938451974,
      "grad_norm": 0.19558171927928925,
      "learning_rate": 7.858253030774013e-06,
      "loss": 0.1402,
      "step": 5512
    },
    {
      "epoch": 0.4284271059993783,
      "grad_norm": 0.14959535002708435,
      "learning_rate": 7.857864470003108e-06,
      "loss": 0.026,
      "step": 5513
    },
    {
      "epoch": 0.42850481815355923,
      "grad_norm": 0.5388457179069519,
      "learning_rate": 7.857475909232205e-06,
      "loss": 0.1283,
      "step": 5514
    },
    {
      "epoch": 0.42858253030774013,
      "grad_norm": 0.5456027388572693,
      "learning_rate": 7.8570873484613e-06,
      "loss": 0.3191,
      "step": 5515
    },
    {
      "epoch": 0.428660242461921,
      "grad_norm": 0.8734795451164246,
      "learning_rate": 7.856698787690395e-06,
      "loss": 0.3767,
      "step": 5516
    },
    {
      "epoch": 0.428737954616102,
      "grad_norm": 0.08779110014438629,
      "learning_rate": 7.856310226919492e-06,
      "loss": 0.0656,
      "step": 5517
    },
    {
      "epoch": 0.4288156667702829,
      "grad_norm": 0.3284124732017517,
      "learning_rate": 7.855921666148587e-06,
      "loss": 0.0459,
      "step": 5518
    },
    {
      "epoch": 0.4288933789244638,
      "grad_norm": 0.5110110640525818,
      "learning_rate": 7.855533105377682e-06,
      "loss": 0.2658,
      "step": 5519
    },
    {
      "epoch": 0.4289710910786447,
      "grad_norm": 0.4566764235496521,
      "learning_rate": 7.855144544606778e-06,
      "loss": 0.2999,
      "step": 5520
    },
    {
      "epoch": 0.4290488032328256,
      "grad_norm": 0.33281344175338745,
      "learning_rate": 7.854755983835871e-06,
      "loss": 0.2541,
      "step": 5521
    },
    {
      "epoch": 0.4291265153870065,
      "grad_norm": 0.27304568886756897,
      "learning_rate": 7.854367423064968e-06,
      "loss": 0.1687,
      "step": 5522
    },
    {
      "epoch": 0.4292042275411874,
      "grad_norm": 0.14080333709716797,
      "learning_rate": 7.853978862294063e-06,
      "loss": 0.0335,
      "step": 5523
    },
    {
      "epoch": 0.4292819396953684,
      "grad_norm": 0.2683371901512146,
      "learning_rate": 7.853590301523158e-06,
      "loss": 0.2375,
      "step": 5524
    },
    {
      "epoch": 0.4293596518495493,
      "grad_norm": 1.2834656238555908,
      "learning_rate": 7.853201740752255e-06,
      "loss": 0.7698,
      "step": 5525
    },
    {
      "epoch": 0.42943736400373017,
      "grad_norm": 0.22951939702033997,
      "learning_rate": 7.85281317998135e-06,
      "loss": 0.2767,
      "step": 5526
    },
    {
      "epoch": 0.4295150761579111,
      "grad_norm": 0.5718129277229309,
      "learning_rate": 7.852424619210445e-06,
      "loss": 0.2895,
      "step": 5527
    },
    {
      "epoch": 0.429592788312092,
      "grad_norm": 0.3062054514884949,
      "learning_rate": 7.852036058439541e-06,
      "loss": 0.0825,
      "step": 5528
    },
    {
      "epoch": 0.4296705004662729,
      "grad_norm": 0.23770272731781006,
      "learning_rate": 7.851647497668636e-06,
      "loss": 0.0788,
      "step": 5529
    },
    {
      "epoch": 0.4297482126204538,
      "grad_norm": 0.3051416575908661,
      "learning_rate": 7.851258936897731e-06,
      "loss": 0.3297,
      "step": 5530
    },
    {
      "epoch": 0.42982592477463477,
      "grad_norm": 0.9918294548988342,
      "learning_rate": 7.850870376126826e-06,
      "loss": 0.4955,
      "step": 5531
    },
    {
      "epoch": 0.42990363692881567,
      "grad_norm": 0.2627007067203522,
      "learning_rate": 7.850481815355923e-06,
      "loss": 0.175,
      "step": 5532
    },
    {
      "epoch": 0.42998134908299657,
      "grad_norm": 0.3809431195259094,
      "learning_rate": 7.850093254585018e-06,
      "loss": 0.2064,
      "step": 5533
    },
    {
      "epoch": 0.4300590612371775,
      "grad_norm": 0.37500855326652527,
      "learning_rate": 7.849704693814113e-06,
      "loss": 0.1587,
      "step": 5534
    },
    {
      "epoch": 0.4301367733913584,
      "grad_norm": 0.48106345534324646,
      "learning_rate": 7.84931613304321e-06,
      "loss": 0.6748,
      "step": 5535
    },
    {
      "epoch": 0.4302144855455393,
      "grad_norm": 0.15417857468128204,
      "learning_rate": 7.848927572272304e-06,
      "loss": 0.0469,
      "step": 5536
    },
    {
      "epoch": 0.4302921976997202,
      "grad_norm": 0.338462769985199,
      "learning_rate": 7.848539011501399e-06,
      "loss": 0.1076,
      "step": 5537
    },
    {
      "epoch": 0.43036990985390117,
      "grad_norm": 0.49352046847343445,
      "learning_rate": 7.848150450730496e-06,
      "loss": 0.2424,
      "step": 5538
    },
    {
      "epoch": 0.43044762200808206,
      "grad_norm": 0.035632796585559845,
      "learning_rate": 7.84776188995959e-06,
      "loss": 0.0085,
      "step": 5539
    },
    {
      "epoch": 0.43052533416226296,
      "grad_norm": 0.09890581667423248,
      "learning_rate": 7.847373329188686e-06,
      "loss": 0.0759,
      "step": 5540
    },
    {
      "epoch": 0.4306030463164439,
      "grad_norm": 0.24521353840827942,
      "learning_rate": 7.84698476841778e-06,
      "loss": 0.0509,
      "step": 5541
    },
    {
      "epoch": 0.4306807584706248,
      "grad_norm": 1.6632322072982788,
      "learning_rate": 7.846596207646877e-06,
      "loss": 0.4474,
      "step": 5542
    },
    {
      "epoch": 0.4307584706248057,
      "grad_norm": 0.2466893494129181,
      "learning_rate": 7.846207646875972e-06,
      "loss": 0.0666,
      "step": 5543
    },
    {
      "epoch": 0.4308361827789866,
      "grad_norm": 0.31763797998428345,
      "learning_rate": 7.845819086105067e-06,
      "loss": 0.2537,
      "step": 5544
    },
    {
      "epoch": 0.43091389493316756,
      "grad_norm": 0.9716278314590454,
      "learning_rate": 7.845430525334164e-06,
      "loss": 0.5308,
      "step": 5545
    },
    {
      "epoch": 0.43099160708734846,
      "grad_norm": 0.48699280619621277,
      "learning_rate": 7.845041964563259e-06,
      "loss": 0.3315,
      "step": 5546
    },
    {
      "epoch": 0.43106931924152936,
      "grad_norm": 0.9607455730438232,
      "learning_rate": 7.844653403792354e-06,
      "loss": 0.3871,
      "step": 5547
    },
    {
      "epoch": 0.4311470313957103,
      "grad_norm": 0.46872174739837646,
      "learning_rate": 7.84426484302145e-06,
      "loss": 0.0534,
      "step": 5548
    },
    {
      "epoch": 0.4312247435498912,
      "grad_norm": 0.25796931982040405,
      "learning_rate": 7.843876282250544e-06,
      "loss": 0.1307,
      "step": 5549
    },
    {
      "epoch": 0.4313024557040721,
      "grad_norm": 0.2049301117658615,
      "learning_rate": 7.84348772147964e-06,
      "loss": 0.1476,
      "step": 5550
    },
    {
      "epoch": 0.431380167858253,
      "grad_norm": 0.4310629367828369,
      "learning_rate": 7.843099160708735e-06,
      "loss": 0.2473,
      "step": 5551
    },
    {
      "epoch": 0.43145788001243396,
      "grad_norm": 0.2745000123977661,
      "learning_rate": 7.84271059993783e-06,
      "loss": 0.1383,
      "step": 5552
    },
    {
      "epoch": 0.43153559216661486,
      "grad_norm": 0.19784776866436005,
      "learning_rate": 7.842322039166927e-06,
      "loss": 0.0766,
      "step": 5553
    },
    {
      "epoch": 0.43161330432079575,
      "grad_norm": 0.8505277633666992,
      "learning_rate": 7.841933478396022e-06,
      "loss": 0.2799,
      "step": 5554
    },
    {
      "epoch": 0.4316910164749767,
      "grad_norm": 0.290601909160614,
      "learning_rate": 7.841544917625117e-06,
      "loss": 0.0836,
      "step": 5555
    },
    {
      "epoch": 0.4317687286291576,
      "grad_norm": 0.5583800673484802,
      "learning_rate": 7.841156356854213e-06,
      "loss": 0.3466,
      "step": 5556
    },
    {
      "epoch": 0.4318464407833385,
      "grad_norm": 0.5542705059051514,
      "learning_rate": 7.840767796083308e-06,
      "loss": 1.3187,
      "step": 5557
    },
    {
      "epoch": 0.4319241529375194,
      "grad_norm": 0.21275866031646729,
      "learning_rate": 7.840379235312403e-06,
      "loss": 0.0902,
      "step": 5558
    },
    {
      "epoch": 0.43200186509170035,
      "grad_norm": 0.6925176382064819,
      "learning_rate": 7.839990674541498e-06,
      "loss": 0.1028,
      "step": 5559
    },
    {
      "epoch": 0.43207957724588125,
      "grad_norm": 0.21234217286109924,
      "learning_rate": 7.839602113770595e-06,
      "loss": 0.1248,
      "step": 5560
    },
    {
      "epoch": 0.43215728940006215,
      "grad_norm": 0.2363526076078415,
      "learning_rate": 7.83921355299969e-06,
      "loss": 0.0418,
      "step": 5561
    },
    {
      "epoch": 0.4322350015542431,
      "grad_norm": 0.48319053649902344,
      "learning_rate": 7.838824992228785e-06,
      "loss": 0.1822,
      "step": 5562
    },
    {
      "epoch": 0.432312713708424,
      "grad_norm": 0.600475549697876,
      "learning_rate": 7.838436431457881e-06,
      "loss": 0.7493,
      "step": 5563
    },
    {
      "epoch": 0.4323904258626049,
      "grad_norm": 0.1835509091615677,
      "learning_rate": 7.838047870686976e-06,
      "loss": 0.1087,
      "step": 5564
    },
    {
      "epoch": 0.43246813801678585,
      "grad_norm": 0.365812212228775,
      "learning_rate": 7.837659309916071e-06,
      "loss": 0.0985,
      "step": 5565
    },
    {
      "epoch": 0.43254585017096675,
      "grad_norm": 0.15348847210407257,
      "learning_rate": 7.837270749145168e-06,
      "loss": 0.0523,
      "step": 5566
    },
    {
      "epoch": 0.43262356232514765,
      "grad_norm": 0.42765671014785767,
      "learning_rate": 7.836882188374261e-06,
      "loss": 0.3138,
      "step": 5567
    },
    {
      "epoch": 0.43270127447932855,
      "grad_norm": 0.44290590286254883,
      "learning_rate": 7.836493627603358e-06,
      "loss": 0.4298,
      "step": 5568
    },
    {
      "epoch": 0.4327789866335095,
      "grad_norm": 0.3981776833534241,
      "learning_rate": 7.836105066832453e-06,
      "loss": 0.1383,
      "step": 5569
    },
    {
      "epoch": 0.4328566987876904,
      "grad_norm": 0.18357598781585693,
      "learning_rate": 7.83571650606155e-06,
      "loss": 0.1089,
      "step": 5570
    },
    {
      "epoch": 0.4329344109418713,
      "grad_norm": 0.09715556353330612,
      "learning_rate": 7.835327945290644e-06,
      "loss": 0.0199,
      "step": 5571
    },
    {
      "epoch": 0.43301212309605225,
      "grad_norm": 0.8067864179611206,
      "learning_rate": 7.83493938451974e-06,
      "loss": 0.4872,
      "step": 5572
    },
    {
      "epoch": 0.43308983525023315,
      "grad_norm": 0.032955750823020935,
      "learning_rate": 7.834550823748836e-06,
      "loss": 0.004,
      "step": 5573
    },
    {
      "epoch": 0.43316754740441404,
      "grad_norm": 0.37839633226394653,
      "learning_rate": 7.834162262977931e-06,
      "loss": 0.112,
      "step": 5574
    },
    {
      "epoch": 0.43324525955859494,
      "grad_norm": 0.4017895460128784,
      "learning_rate": 7.833773702207026e-06,
      "loss": 0.222,
      "step": 5575
    },
    {
      "epoch": 0.4333229717127759,
      "grad_norm": 0.2135610431432724,
      "learning_rate": 7.833385141436122e-06,
      "loss": 0.0549,
      "step": 5576
    },
    {
      "epoch": 0.4334006838669568,
      "grad_norm": 0.3866879343986511,
      "learning_rate": 7.832996580665216e-06,
      "loss": 0.1258,
      "step": 5577
    },
    {
      "epoch": 0.4334783960211377,
      "grad_norm": 0.7024663090705872,
      "learning_rate": 7.832608019894312e-06,
      "loss": 0.5923,
      "step": 5578
    },
    {
      "epoch": 0.43355610817531864,
      "grad_norm": 0.33364397287368774,
      "learning_rate": 7.832219459123407e-06,
      "loss": 0.4267,
      "step": 5579
    },
    {
      "epoch": 0.43363382032949954,
      "grad_norm": 0.22460800409317017,
      "learning_rate": 7.831830898352502e-06,
      "loss": 0.0868,
      "step": 5580
    },
    {
      "epoch": 0.43371153248368044,
      "grad_norm": 0.3433138132095337,
      "learning_rate": 7.831442337581599e-06,
      "loss": 0.1119,
      "step": 5581
    },
    {
      "epoch": 0.43378924463786134,
      "grad_norm": 0.1624433845281601,
      "learning_rate": 7.831053776810694e-06,
      "loss": 0.1039,
      "step": 5582
    },
    {
      "epoch": 0.4338669567920423,
      "grad_norm": 0.30136731266975403,
      "learning_rate": 7.830665216039789e-06,
      "loss": 0.0856,
      "step": 5583
    },
    {
      "epoch": 0.4339446689462232,
      "grad_norm": 0.7933450937271118,
      "learning_rate": 7.830276655268885e-06,
      "loss": 0.0832,
      "step": 5584
    },
    {
      "epoch": 0.4340223811004041,
      "grad_norm": 0.29931336641311646,
      "learning_rate": 7.82988809449798e-06,
      "loss": 0.232,
      "step": 5585
    },
    {
      "epoch": 0.43410009325458504,
      "grad_norm": 0.31341344118118286,
      "learning_rate": 7.829499533727075e-06,
      "loss": 0.2003,
      "step": 5586
    },
    {
      "epoch": 0.43417780540876594,
      "grad_norm": 0.18004456162452698,
      "learning_rate": 7.82911097295617e-06,
      "loss": 0.0805,
      "step": 5587
    },
    {
      "epoch": 0.43425551756294684,
      "grad_norm": 0.570073664188385,
      "learning_rate": 7.828722412185267e-06,
      "loss": 0.3814,
      "step": 5588
    },
    {
      "epoch": 0.43433322971712773,
      "grad_norm": 0.1403878629207611,
      "learning_rate": 7.828333851414362e-06,
      "loss": 0.0112,
      "step": 5589
    },
    {
      "epoch": 0.4344109418713087,
      "grad_norm": 0.11956460028886795,
      "learning_rate": 7.827945290643457e-06,
      "loss": 0.0843,
      "step": 5590
    },
    {
      "epoch": 0.4344886540254896,
      "grad_norm": 0.17162784934043884,
      "learning_rate": 7.827556729872553e-06,
      "loss": 0.0554,
      "step": 5591
    },
    {
      "epoch": 0.4345663661796705,
      "grad_norm": 0.11486813426017761,
      "learning_rate": 7.827168169101648e-06,
      "loss": 0.0295,
      "step": 5592
    },
    {
      "epoch": 0.43464407833385144,
      "grad_norm": 0.1551143079996109,
      "learning_rate": 7.826779608330743e-06,
      "loss": 0.0675,
      "step": 5593
    },
    {
      "epoch": 0.43472179048803233,
      "grad_norm": 0.359560489654541,
      "learning_rate": 7.82639104755984e-06,
      "loss": 0.3362,
      "step": 5594
    },
    {
      "epoch": 0.43479950264221323,
      "grad_norm": 0.45937052369117737,
      "learning_rate": 7.826002486788933e-06,
      "loss": 0.2735,
      "step": 5595
    },
    {
      "epoch": 0.43487721479639413,
      "grad_norm": 0.5819528698921204,
      "learning_rate": 7.82561392601803e-06,
      "loss": 0.1526,
      "step": 5596
    },
    {
      "epoch": 0.4349549269505751,
      "grad_norm": 0.27386540174484253,
      "learning_rate": 7.825225365247125e-06,
      "loss": 0.1067,
      "step": 5597
    },
    {
      "epoch": 0.435032639104756,
      "grad_norm": 0.25583741068840027,
      "learning_rate": 7.82483680447622e-06,
      "loss": 0.0816,
      "step": 5598
    },
    {
      "epoch": 0.4351103512589369,
      "grad_norm": 0.22942668199539185,
      "learning_rate": 7.824448243705316e-06,
      "loss": 0.1617,
      "step": 5599
    },
    {
      "epoch": 0.43518806341311783,
      "grad_norm": 0.10035838931798935,
      "learning_rate": 7.824059682934411e-06,
      "loss": 0.0447,
      "step": 5600
    },
    {
      "epoch": 0.43526577556729873,
      "grad_norm": 0.644311785697937,
      "learning_rate": 7.823671122163508e-06,
      "loss": 0.251,
      "step": 5601
    },
    {
      "epoch": 0.4353434877214796,
      "grad_norm": 0.18623992800712585,
      "learning_rate": 7.823282561392603e-06,
      "loss": 0.0963,
      "step": 5602
    },
    {
      "epoch": 0.4354211998756606,
      "grad_norm": 0.5705534219741821,
      "learning_rate": 7.822894000621698e-06,
      "loss": 0.1778,
      "step": 5603
    },
    {
      "epoch": 0.4354989120298415,
      "grad_norm": 0.2961917519569397,
      "learning_rate": 7.822505439850795e-06,
      "loss": 0.2375,
      "step": 5604
    },
    {
      "epoch": 0.4355766241840224,
      "grad_norm": 0.10481537133455276,
      "learning_rate": 7.822116879079888e-06,
      "loss": 0.0159,
      "step": 5605
    },
    {
      "epoch": 0.4356543363382033,
      "grad_norm": 0.1664341688156128,
      "learning_rate": 7.821728318308985e-06,
      "loss": 0.0378,
      "step": 5606
    },
    {
      "epoch": 0.4357320484923842,
      "grad_norm": 0.12057662755250931,
      "learning_rate": 7.82133975753808e-06,
      "loss": 0.0291,
      "step": 5607
    },
    {
      "epoch": 0.4358097606465651,
      "grad_norm": 0.3583916127681732,
      "learning_rate": 7.820951196767174e-06,
      "loss": 0.2137,
      "step": 5608
    },
    {
      "epoch": 0.435887472800746,
      "grad_norm": 0.4349517822265625,
      "learning_rate": 7.820562635996271e-06,
      "loss": 0.572,
      "step": 5609
    },
    {
      "epoch": 0.435965184954927,
      "grad_norm": 0.2580903172492981,
      "learning_rate": 7.820174075225366e-06,
      "loss": 0.1126,
      "step": 5610
    },
    {
      "epoch": 0.4360428971091079,
      "grad_norm": 0.08990988880395889,
      "learning_rate": 7.819785514454461e-06,
      "loss": 0.0402,
      "step": 5611
    },
    {
      "epoch": 0.43612060926328877,
      "grad_norm": 0.5783153772354126,
      "learning_rate": 7.819396953683558e-06,
      "loss": 0.218,
      "step": 5612
    },
    {
      "epoch": 0.43619832141746967,
      "grad_norm": 0.2131430208683014,
      "learning_rate": 7.819008392912653e-06,
      "loss": 0.0865,
      "step": 5613
    },
    {
      "epoch": 0.4362760335716506,
      "grad_norm": 0.6972929835319519,
      "learning_rate": 7.818619832141748e-06,
      "loss": 0.1232,
      "step": 5614
    },
    {
      "epoch": 0.4363537457258315,
      "grad_norm": 0.28091198205947876,
      "learning_rate": 7.818231271370842e-06,
      "loss": 0.1897,
      "step": 5615
    },
    {
      "epoch": 0.4364314578800124,
      "grad_norm": 0.3772388994693756,
      "learning_rate": 7.817842710599939e-06,
      "loss": 0.184,
      "step": 5616
    },
    {
      "epoch": 0.4365091700341934,
      "grad_norm": 0.28275322914123535,
      "learning_rate": 7.817454149829034e-06,
      "loss": 0.087,
      "step": 5617
    },
    {
      "epoch": 0.43658688218837427,
      "grad_norm": 0.3563711643218994,
      "learning_rate": 7.817065589058129e-06,
      "loss": 0.143,
      "step": 5618
    },
    {
      "epoch": 0.43666459434255517,
      "grad_norm": 0.5123684406280518,
      "learning_rate": 7.816677028287226e-06,
      "loss": 0.1975,
      "step": 5619
    },
    {
      "epoch": 0.43674230649673607,
      "grad_norm": 0.34148284792900085,
      "learning_rate": 7.81628846751632e-06,
      "loss": 0.0909,
      "step": 5620
    },
    {
      "epoch": 0.436820018650917,
      "grad_norm": 0.7822409868240356,
      "learning_rate": 7.815899906745416e-06,
      "loss": 0.4,
      "step": 5621
    },
    {
      "epoch": 0.4368977308050979,
      "grad_norm": 0.2829231917858124,
      "learning_rate": 7.81551134597451e-06,
      "loss": 0.1359,
      "step": 5622
    },
    {
      "epoch": 0.4369754429592788,
      "grad_norm": 0.23497214913368225,
      "learning_rate": 7.815122785203605e-06,
      "loss": 0.0685,
      "step": 5623
    },
    {
      "epoch": 0.43705315511345977,
      "grad_norm": 0.30065590143203735,
      "learning_rate": 7.814734224432702e-06,
      "loss": 0.1605,
      "step": 5624
    },
    {
      "epoch": 0.43713086726764067,
      "grad_norm": 0.33264869451522827,
      "learning_rate": 7.814345663661797e-06,
      "loss": 0.1802,
      "step": 5625
    },
    {
      "epoch": 0.43720857942182156,
      "grad_norm": 0.08261337876319885,
      "learning_rate": 7.813957102890892e-06,
      "loss": 0.0222,
      "step": 5626
    },
    {
      "epoch": 0.43728629157600246,
      "grad_norm": 0.27262985706329346,
      "learning_rate": 7.813568542119989e-06,
      "loss": 0.199,
      "step": 5627
    },
    {
      "epoch": 0.4373640037301834,
      "grad_norm": 0.5119444131851196,
      "learning_rate": 7.813179981349084e-06,
      "loss": 0.7525,
      "step": 5628
    },
    {
      "epoch": 0.4374417158843643,
      "grad_norm": 0.14669759571552277,
      "learning_rate": 7.812791420578179e-06,
      "loss": 0.0469,
      "step": 5629
    },
    {
      "epoch": 0.4375194280385452,
      "grad_norm": 0.8431745171546936,
      "learning_rate": 7.812402859807273e-06,
      "loss": 0.3333,
      "step": 5630
    },
    {
      "epoch": 0.43759714019272616,
      "grad_norm": 0.06730151176452637,
      "learning_rate": 7.81201429903637e-06,
      "loss": 0.0098,
      "step": 5631
    },
    {
      "epoch": 0.43767485234690706,
      "grad_norm": 0.27709832787513733,
      "learning_rate": 7.811625738265465e-06,
      "loss": 0.0943,
      "step": 5632
    },
    {
      "epoch": 0.43775256450108796,
      "grad_norm": 0.17709462344646454,
      "learning_rate": 7.81123717749456e-06,
      "loss": 0.0633,
      "step": 5633
    },
    {
      "epoch": 0.43783027665526886,
      "grad_norm": 0.7204132676124573,
      "learning_rate": 7.810848616723657e-06,
      "loss": 0.7134,
      "step": 5634
    },
    {
      "epoch": 0.4379079888094498,
      "grad_norm": 0.43107762932777405,
      "learning_rate": 7.810460055952752e-06,
      "loss": 0.2138,
      "step": 5635
    },
    {
      "epoch": 0.4379857009636307,
      "grad_norm": 0.2826685905456543,
      "learning_rate": 7.810071495181847e-06,
      "loss": 0.0825,
      "step": 5636
    },
    {
      "epoch": 0.4380634131178116,
      "grad_norm": 0.5017817616462708,
      "learning_rate": 7.809682934410943e-06,
      "loss": 0.4322,
      "step": 5637
    },
    {
      "epoch": 0.43814112527199256,
      "grad_norm": 0.9436925053596497,
      "learning_rate": 7.809294373640038e-06,
      "loss": 0.4941,
      "step": 5638
    },
    {
      "epoch": 0.43821883742617346,
      "grad_norm": 0.48679956793785095,
      "learning_rate": 7.808905812869133e-06,
      "loss": 0.3329,
      "step": 5639
    },
    {
      "epoch": 0.43829654958035436,
      "grad_norm": 0.3259842097759247,
      "learning_rate": 7.808517252098228e-06,
      "loss": 0.253,
      "step": 5640
    },
    {
      "epoch": 0.4383742617345353,
      "grad_norm": 0.25781551003456116,
      "learning_rate": 7.808128691327325e-06,
      "loss": 0.134,
      "step": 5641
    },
    {
      "epoch": 0.4384519738887162,
      "grad_norm": 0.2644049823284149,
      "learning_rate": 7.80774013055642e-06,
      "loss": 0.1516,
      "step": 5642
    },
    {
      "epoch": 0.4385296860428971,
      "grad_norm": 0.2152208685874939,
      "learning_rate": 7.807351569785515e-06,
      "loss": 0.0953,
      "step": 5643
    },
    {
      "epoch": 0.438607398197078,
      "grad_norm": 0.23507624864578247,
      "learning_rate": 7.806963009014611e-06,
      "loss": 0.0695,
      "step": 5644
    },
    {
      "epoch": 0.43868511035125896,
      "grad_norm": 0.24904420971870422,
      "learning_rate": 7.806574448243706e-06,
      "loss": 0.0892,
      "step": 5645
    },
    {
      "epoch": 0.43876282250543985,
      "grad_norm": 0.1943696290254593,
      "learning_rate": 7.806185887472801e-06,
      "loss": 0.0961,
      "step": 5646
    },
    {
      "epoch": 0.43884053465962075,
      "grad_norm": 0.13603536784648895,
      "learning_rate": 7.805797326701898e-06,
      "loss": 0.0497,
      "step": 5647
    },
    {
      "epoch": 0.4389182468138017,
      "grad_norm": 0.15415869653224945,
      "learning_rate": 7.805408765930991e-06,
      "loss": 0.0322,
      "step": 5648
    },
    {
      "epoch": 0.4389959589679826,
      "grad_norm": 0.2028251439332962,
      "learning_rate": 7.805020205160088e-06,
      "loss": 0.0611,
      "step": 5649
    },
    {
      "epoch": 0.4390736711221635,
      "grad_norm": 0.047998566180467606,
      "learning_rate": 7.804631644389183e-06,
      "loss": 0.01,
      "step": 5650
    },
    {
      "epoch": 0.4391513832763444,
      "grad_norm": 0.7118031978607178,
      "learning_rate": 7.804243083618278e-06,
      "loss": 0.0792,
      "step": 5651
    },
    {
      "epoch": 0.43922909543052535,
      "grad_norm": 0.4119691550731659,
      "learning_rate": 7.803854522847374e-06,
      "loss": 0.2008,
      "step": 5652
    },
    {
      "epoch": 0.43930680758470625,
      "grad_norm": 0.5596392154693604,
      "learning_rate": 7.80346596207647e-06,
      "loss": 0.1975,
      "step": 5653
    },
    {
      "epoch": 0.43938451973888715,
      "grad_norm": 0.13881780207157135,
      "learning_rate": 7.803077401305564e-06,
      "loss": 0.0325,
      "step": 5654
    },
    {
      "epoch": 0.4394622318930681,
      "grad_norm": 0.29907771944999695,
      "learning_rate": 7.80268884053466e-06,
      "loss": 0.0934,
      "step": 5655
    },
    {
      "epoch": 0.439539944047249,
      "grad_norm": 0.14056162536144257,
      "learning_rate": 7.802300279763756e-06,
      "loss": 0.0171,
      "step": 5656
    },
    {
      "epoch": 0.4396176562014299,
      "grad_norm": 0.08834332972764969,
      "learning_rate": 7.80191171899285e-06,
      "loss": 0.0212,
      "step": 5657
    },
    {
      "epoch": 0.4396953683556108,
      "grad_norm": 0.1228768602013588,
      "learning_rate": 7.801523158221946e-06,
      "loss": 0.0448,
      "step": 5658
    },
    {
      "epoch": 0.43977308050979175,
      "grad_norm": 0.4473601281642914,
      "learning_rate": 7.801134597451042e-06,
      "loss": 0.1605,
      "step": 5659
    },
    {
      "epoch": 0.43985079266397265,
      "grad_norm": 0.4110126495361328,
      "learning_rate": 7.800746036680137e-06,
      "loss": 0.2404,
      "step": 5660
    },
    {
      "epoch": 0.43992850481815354,
      "grad_norm": 0.19312746822834015,
      "learning_rate": 7.800357475909232e-06,
      "loss": 0.1003,
      "step": 5661
    },
    {
      "epoch": 0.4400062169723345,
      "grad_norm": 0.34736573696136475,
      "learning_rate": 7.799968915138329e-06,
      "loss": 0.1447,
      "step": 5662
    },
    {
      "epoch": 0.4400839291265154,
      "grad_norm": 0.3897961974143982,
      "learning_rate": 7.799580354367424e-06,
      "loss": 0.2175,
      "step": 5663
    },
    {
      "epoch": 0.4401616412806963,
      "grad_norm": 0.48721396923065186,
      "learning_rate": 7.799191793596519e-06,
      "loss": 0.1228,
      "step": 5664
    },
    {
      "epoch": 0.4402393534348772,
      "grad_norm": 0.21623916923999786,
      "learning_rate": 7.798803232825615e-06,
      "loss": 0.0952,
      "step": 5665
    },
    {
      "epoch": 0.44031706558905814,
      "grad_norm": 0.1982453465461731,
      "learning_rate": 7.79841467205471e-06,
      "loss": 0.0448,
      "step": 5666
    },
    {
      "epoch": 0.44039477774323904,
      "grad_norm": 0.8636532425880432,
      "learning_rate": 7.798026111283805e-06,
      "loss": 0.6859,
      "step": 5667
    },
    {
      "epoch": 0.44047248989741994,
      "grad_norm": 0.2135830968618393,
      "learning_rate": 7.7976375505129e-06,
      "loss": 0.0842,
      "step": 5668
    },
    {
      "epoch": 0.4405502020516009,
      "grad_norm": 0.3015099763870239,
      "learning_rate": 7.797248989741997e-06,
      "loss": 0.0914,
      "step": 5669
    },
    {
      "epoch": 0.4406279142057818,
      "grad_norm": 0.08528327941894531,
      "learning_rate": 7.796860428971092e-06,
      "loss": 0.0162,
      "step": 5670
    },
    {
      "epoch": 0.4407056263599627,
      "grad_norm": 0.4861958920955658,
      "learning_rate": 7.796471868200187e-06,
      "loss": 0.1486,
      "step": 5671
    },
    {
      "epoch": 0.4407833385141436,
      "grad_norm": 0.2222099006175995,
      "learning_rate": 7.796083307429283e-06,
      "loss": 0.103,
      "step": 5672
    },
    {
      "epoch": 0.44086105066832454,
      "grad_norm": 0.3245975077152252,
      "learning_rate": 7.795694746658378e-06,
      "loss": 0.1391,
      "step": 5673
    },
    {
      "epoch": 0.44093876282250544,
      "grad_norm": 0.42869001626968384,
      "learning_rate": 7.795306185887473e-06,
      "loss": 0.3034,
      "step": 5674
    },
    {
      "epoch": 0.44101647497668633,
      "grad_norm": 0.18134264647960663,
      "learning_rate": 7.79491762511657e-06,
      "loss": 0.0483,
      "step": 5675
    },
    {
      "epoch": 0.4410941871308673,
      "grad_norm": 0.2485959231853485,
      "learning_rate": 7.794529064345663e-06,
      "loss": 0.1018,
      "step": 5676
    },
    {
      "epoch": 0.4411718992850482,
      "grad_norm": 0.17225612699985504,
      "learning_rate": 7.79414050357476e-06,
      "loss": 0.0586,
      "step": 5677
    },
    {
      "epoch": 0.4412496114392291,
      "grad_norm": 0.05818630009889603,
      "learning_rate": 7.793751942803855e-06,
      "loss": 0.0103,
      "step": 5678
    },
    {
      "epoch": 0.44132732359341004,
      "grad_norm": 0.18699580430984497,
      "learning_rate": 7.79336338203295e-06,
      "loss": 0.0758,
      "step": 5679
    },
    {
      "epoch": 0.44140503574759093,
      "grad_norm": 0.32774510979652405,
      "learning_rate": 7.792974821262046e-06,
      "loss": 0.1703,
      "step": 5680
    },
    {
      "epoch": 0.44148274790177183,
      "grad_norm": 1.4338284730911255,
      "learning_rate": 7.792586260491141e-06,
      "loss": 0.822,
      "step": 5681
    },
    {
      "epoch": 0.44156046005595273,
      "grad_norm": 0.2580065131187439,
      "learning_rate": 7.792197699720236e-06,
      "loss": 0.1576,
      "step": 5682
    },
    {
      "epoch": 0.4416381722101337,
      "grad_norm": 0.4703981280326843,
      "learning_rate": 7.791809138949333e-06,
      "loss": 0.2483,
      "step": 5683
    },
    {
      "epoch": 0.4417158843643146,
      "grad_norm": 0.4212467074394226,
      "learning_rate": 7.791420578178428e-06,
      "loss": 0.2613,
      "step": 5684
    },
    {
      "epoch": 0.4417935965184955,
      "grad_norm": 0.28624099493026733,
      "learning_rate": 7.791032017407523e-06,
      "loss": 0.0789,
      "step": 5685
    },
    {
      "epoch": 0.44187130867267643,
      "grad_norm": 0.21052104234695435,
      "learning_rate": 7.790643456636618e-06,
      "loss": 0.0884,
      "step": 5686
    },
    {
      "epoch": 0.44194902082685733,
      "grad_norm": 0.21841265261173248,
      "learning_rate": 7.790254895865714e-06,
      "loss": 0.0892,
      "step": 5687
    },
    {
      "epoch": 0.44202673298103823,
      "grad_norm": 0.1562076359987259,
      "learning_rate": 7.78986633509481e-06,
      "loss": 0.088,
      "step": 5688
    },
    {
      "epoch": 0.4421044451352191,
      "grad_norm": 0.6994473338127136,
      "learning_rate": 7.789477774323904e-06,
      "loss": 0.189,
      "step": 5689
    },
    {
      "epoch": 0.4421821572894001,
      "grad_norm": 0.18416568636894226,
      "learning_rate": 7.789089213553001e-06,
      "loss": 0.0971,
      "step": 5690
    },
    {
      "epoch": 0.442259869443581,
      "grad_norm": 0.2547443211078644,
      "learning_rate": 7.788700652782096e-06,
      "loss": 0.0882,
      "step": 5691
    },
    {
      "epoch": 0.4423375815977619,
      "grad_norm": 0.5228924751281738,
      "learning_rate": 7.788312092011191e-06,
      "loss": 0.1658,
      "step": 5692
    },
    {
      "epoch": 0.44241529375194283,
      "grad_norm": 0.3215712904930115,
      "learning_rate": 7.787923531240287e-06,
      "loss": 0.0835,
      "step": 5693
    },
    {
      "epoch": 0.4424930059061237,
      "grad_norm": 0.6542723774909973,
      "learning_rate": 7.787534970469382e-06,
      "loss": 0.2046,
      "step": 5694
    },
    {
      "epoch": 0.4425707180603046,
      "grad_norm": 0.06699495017528534,
      "learning_rate": 7.787146409698477e-06,
      "loss": 0.0117,
      "step": 5695
    },
    {
      "epoch": 0.4426484302144855,
      "grad_norm": 0.36346814036369324,
      "learning_rate": 7.786757848927572e-06,
      "loss": 0.3596,
      "step": 5696
    },
    {
      "epoch": 0.4427261423686665,
      "grad_norm": 0.46917930245399475,
      "learning_rate": 7.786369288156669e-06,
      "loss": 0.21,
      "step": 5697
    },
    {
      "epoch": 0.4428038545228474,
      "grad_norm": 0.5376502275466919,
      "learning_rate": 7.785980727385764e-06,
      "loss": 0.2051,
      "step": 5698
    },
    {
      "epoch": 0.44288156667702827,
      "grad_norm": 0.06513257324695587,
      "learning_rate": 7.785592166614859e-06,
      "loss": 0.0132,
      "step": 5699
    },
    {
      "epoch": 0.4429592788312092,
      "grad_norm": 0.6540224552154541,
      "learning_rate": 7.785203605843956e-06,
      "loss": 0.208,
      "step": 5700
    },
    {
      "epoch": 0.4430369909853901,
      "grad_norm": 0.17659299075603485,
      "learning_rate": 7.78481504507305e-06,
      "loss": 0.1379,
      "step": 5701
    },
    {
      "epoch": 0.443114703139571,
      "grad_norm": 0.2512700855731964,
      "learning_rate": 7.784426484302145e-06,
      "loss": 0.1782,
      "step": 5702
    },
    {
      "epoch": 0.4431924152937519,
      "grad_norm": 0.4755041003227234,
      "learning_rate": 7.784037923531242e-06,
      "loss": 0.1286,
      "step": 5703
    },
    {
      "epoch": 0.44327012744793287,
      "grad_norm": 0.3953265845775604,
      "learning_rate": 7.783649362760335e-06,
      "loss": 0.3632,
      "step": 5704
    },
    {
      "epoch": 0.44334783960211377,
      "grad_norm": 0.4553280174732208,
      "learning_rate": 7.783260801989432e-06,
      "loss": 0.1169,
      "step": 5705
    },
    {
      "epoch": 0.44342555175629467,
      "grad_norm": 0.4884974956512451,
      "learning_rate": 7.782872241218527e-06,
      "loss": 0.1451,
      "step": 5706
    },
    {
      "epoch": 0.4435032639104756,
      "grad_norm": 0.3023937940597534,
      "learning_rate": 7.782483680447622e-06,
      "loss": 0.1759,
      "step": 5707
    },
    {
      "epoch": 0.4435809760646565,
      "grad_norm": 0.24903789162635803,
      "learning_rate": 7.782095119676719e-06,
      "loss": 0.1223,
      "step": 5708
    },
    {
      "epoch": 0.4436586882188374,
      "grad_norm": 0.27350765466690063,
      "learning_rate": 7.781706558905813e-06,
      "loss": 0.1898,
      "step": 5709
    },
    {
      "epoch": 0.4437364003730183,
      "grad_norm": 0.14822718501091003,
      "learning_rate": 7.781317998134908e-06,
      "loss": 0.0729,
      "step": 5710
    },
    {
      "epoch": 0.44381411252719927,
      "grad_norm": 0.2040875256061554,
      "learning_rate": 7.780929437364005e-06,
      "loss": 0.1556,
      "step": 5711
    },
    {
      "epoch": 0.44389182468138016,
      "grad_norm": 0.08134354650974274,
      "learning_rate": 7.7805408765931e-06,
      "loss": 0.0127,
      "step": 5712
    },
    {
      "epoch": 0.44396953683556106,
      "grad_norm": 0.33735811710357666,
      "learning_rate": 7.780152315822195e-06,
      "loss": 0.0923,
      "step": 5713
    },
    {
      "epoch": 0.444047248989742,
      "grad_norm": 0.33814939856529236,
      "learning_rate": 7.77976375505129e-06,
      "loss": 0.3863,
      "step": 5714
    },
    {
      "epoch": 0.4441249611439229,
      "grad_norm": 0.3041362166404724,
      "learning_rate": 7.779375194280387e-06,
      "loss": 0.0611,
      "step": 5715
    },
    {
      "epoch": 0.4442026732981038,
      "grad_norm": 0.05634591728448868,
      "learning_rate": 7.778986633509482e-06,
      "loss": 0.0237,
      "step": 5716
    },
    {
      "epoch": 0.44428038545228477,
      "grad_norm": 0.2545226514339447,
      "learning_rate": 7.778598072738576e-06,
      "loss": 0.1588,
      "step": 5717
    },
    {
      "epoch": 0.44435809760646566,
      "grad_norm": 0.18533039093017578,
      "learning_rate": 7.778209511967673e-06,
      "loss": 0.0406,
      "step": 5718
    },
    {
      "epoch": 0.44443580976064656,
      "grad_norm": 0.4333965480327606,
      "learning_rate": 7.777820951196768e-06,
      "loss": 0.1616,
      "step": 5719
    },
    {
      "epoch": 0.44451352191482746,
      "grad_norm": 0.5141727328300476,
      "learning_rate": 7.777432390425863e-06,
      "loss": 0.3292,
      "step": 5720
    },
    {
      "epoch": 0.4445912340690084,
      "grad_norm": 0.13420403003692627,
      "learning_rate": 7.77704382965496e-06,
      "loss": 0.028,
      "step": 5721
    },
    {
      "epoch": 0.4446689462231893,
      "grad_norm": 0.2945733666419983,
      "learning_rate": 7.776655268884055e-06,
      "loss": 0.1036,
      "step": 5722
    },
    {
      "epoch": 0.4447466583773702,
      "grad_norm": 0.7856845259666443,
      "learning_rate": 7.77626670811315e-06,
      "loss": 0.2319,
      "step": 5723
    },
    {
      "epoch": 0.44482437053155116,
      "grad_norm": 0.43506574630737305,
      "learning_rate": 7.775878147342244e-06,
      "loss": 0.1598,
      "step": 5724
    },
    {
      "epoch": 0.44490208268573206,
      "grad_norm": 0.2801841199398041,
      "learning_rate": 7.775489586571341e-06,
      "loss": 0.178,
      "step": 5725
    },
    {
      "epoch": 0.44497979483991296,
      "grad_norm": 0.35068216919898987,
      "learning_rate": 7.775101025800436e-06,
      "loss": 0.1008,
      "step": 5726
    },
    {
      "epoch": 0.44505750699409385,
      "grad_norm": 0.33559277653694153,
      "learning_rate": 7.774712465029531e-06,
      "loss": 0.2248,
      "step": 5727
    },
    {
      "epoch": 0.4451352191482748,
      "grad_norm": 0.3460739552974701,
      "learning_rate": 7.774323904258628e-06,
      "loss": 0.122,
      "step": 5728
    },
    {
      "epoch": 0.4452129313024557,
      "grad_norm": 0.6821785569190979,
      "learning_rate": 7.773935343487723e-06,
      "loss": 0.0832,
      "step": 5729
    },
    {
      "epoch": 0.4452906434566366,
      "grad_norm": 0.15732397139072418,
      "learning_rate": 7.773546782716818e-06,
      "loss": 0.0571,
      "step": 5730
    },
    {
      "epoch": 0.44536835561081756,
      "grad_norm": 0.6700318455696106,
      "learning_rate": 7.773158221945914e-06,
      "loss": 0.4366,
      "step": 5731
    },
    {
      "epoch": 0.44544606776499845,
      "grad_norm": 0.5485164523124695,
      "learning_rate": 7.772769661175007e-06,
      "loss": 0.3531,
      "step": 5732
    },
    {
      "epoch": 0.44552377991917935,
      "grad_norm": 0.2435988485813141,
      "learning_rate": 7.772381100404104e-06,
      "loss": 0.0313,
      "step": 5733
    },
    {
      "epoch": 0.44560149207336025,
      "grad_norm": 0.3620500862598419,
      "learning_rate": 7.771992539633199e-06,
      "loss": 0.3244,
      "step": 5734
    },
    {
      "epoch": 0.4456792042275412,
      "grad_norm": 0.1573552042245865,
      "learning_rate": 7.771603978862294e-06,
      "loss": 0.0811,
      "step": 5735
    },
    {
      "epoch": 0.4457569163817221,
      "grad_norm": 0.11582070589065552,
      "learning_rate": 7.77121541809139e-06,
      "loss": 0.0392,
      "step": 5736
    },
    {
      "epoch": 0.445834628535903,
      "grad_norm": 0.6754757761955261,
      "learning_rate": 7.770826857320486e-06,
      "loss": 0.2951,
      "step": 5737
    },
    {
      "epoch": 0.44591234069008395,
      "grad_norm": 0.46032872796058655,
      "learning_rate": 7.77043829654958e-06,
      "loss": 0.098,
      "step": 5738
    },
    {
      "epoch": 0.44599005284426485,
      "grad_norm": 0.0830153077840805,
      "learning_rate": 7.770049735778677e-06,
      "loss": 0.0513,
      "step": 5739
    },
    {
      "epoch": 0.44606776499844575,
      "grad_norm": 0.16361521184444427,
      "learning_rate": 7.769661175007772e-06,
      "loss": 0.095,
      "step": 5740
    },
    {
      "epoch": 0.44614547715262665,
      "grad_norm": 0.09821352362632751,
      "learning_rate": 7.769272614236867e-06,
      "loss": 0.049,
      "step": 5741
    },
    {
      "epoch": 0.4462231893068076,
      "grad_norm": 0.19248196482658386,
      "learning_rate": 7.768884053465962e-06,
      "loss": 0.0825,
      "step": 5742
    },
    {
      "epoch": 0.4463009014609885,
      "grad_norm": 0.4493378698825836,
      "learning_rate": 7.768495492695059e-06,
      "loss": 0.1947,
      "step": 5743
    },
    {
      "epoch": 0.4463786136151694,
      "grad_norm": 0.19476959109306335,
      "learning_rate": 7.768106931924154e-06,
      "loss": 0.0396,
      "step": 5744
    },
    {
      "epoch": 0.44645632576935035,
      "grad_norm": 0.47053033113479614,
      "learning_rate": 7.767718371153249e-06,
      "loss": 0.2374,
      "step": 5745
    },
    {
      "epoch": 0.44653403792353125,
      "grad_norm": 0.34592026472091675,
      "learning_rate": 7.767329810382345e-06,
      "loss": 0.2974,
      "step": 5746
    },
    {
      "epoch": 0.44661175007771214,
      "grad_norm": 0.41509032249450684,
      "learning_rate": 7.76694124961144e-06,
      "loss": 0.4072,
      "step": 5747
    },
    {
      "epoch": 0.44668946223189304,
      "grad_norm": 0.17327682673931122,
      "learning_rate": 7.766552688840535e-06,
      "loss": 0.0937,
      "step": 5748
    },
    {
      "epoch": 0.446767174386074,
      "grad_norm": 0.3200139105319977,
      "learning_rate": 7.76616412806963e-06,
      "loss": 0.0822,
      "step": 5749
    },
    {
      "epoch": 0.4468448865402549,
      "grad_norm": 0.4850757122039795,
      "learning_rate": 7.765775567298725e-06,
      "loss": 0.2404,
      "step": 5750
    },
    {
      "epoch": 0.4469225986944358,
      "grad_norm": 0.2777074873447418,
      "learning_rate": 7.765387006527822e-06,
      "loss": 0.3705,
      "step": 5751
    },
    {
      "epoch": 0.44700031084861674,
      "grad_norm": 0.3869377076625824,
      "learning_rate": 7.764998445756917e-06,
      "loss": 0.1047,
      "step": 5752
    },
    {
      "epoch": 0.44707802300279764,
      "grad_norm": 0.17241019010543823,
      "learning_rate": 7.764609884986013e-06,
      "loss": 0.058,
      "step": 5753
    },
    {
      "epoch": 0.44715573515697854,
      "grad_norm": 1.4883477687835693,
      "learning_rate": 7.764221324215108e-06,
      "loss": 0.746,
      "step": 5754
    },
    {
      "epoch": 0.44723344731115944,
      "grad_norm": 1.0688663721084595,
      "learning_rate": 7.763832763444203e-06,
      "loss": 0.2678,
      "step": 5755
    },
    {
      "epoch": 0.4473111594653404,
      "grad_norm": 0.42601466178894043,
      "learning_rate": 7.7634442026733e-06,
      "loss": 0.1481,
      "step": 5756
    },
    {
      "epoch": 0.4473888716195213,
      "grad_norm": 0.2884750962257385,
      "learning_rate": 7.763055641902393e-06,
      "loss": 0.169,
      "step": 5757
    },
    {
      "epoch": 0.4474665837737022,
      "grad_norm": 0.22554661333560944,
      "learning_rate": 7.76266708113149e-06,
      "loss": 0.1936,
      "step": 5758
    },
    {
      "epoch": 0.44754429592788314,
      "grad_norm": 1.2884279489517212,
      "learning_rate": 7.762278520360585e-06,
      "loss": 0.8797,
      "step": 5759
    },
    {
      "epoch": 0.44762200808206404,
      "grad_norm": 0.42527446150779724,
      "learning_rate": 7.76188995958968e-06,
      "loss": 0.1198,
      "step": 5760
    },
    {
      "epoch": 0.44769972023624494,
      "grad_norm": 0.5510068535804749,
      "learning_rate": 7.761501398818776e-06,
      "loss": 0.2234,
      "step": 5761
    },
    {
      "epoch": 0.4477774323904259,
      "grad_norm": 0.5734753608703613,
      "learning_rate": 7.761112838047871e-06,
      "loss": 0.3243,
      "step": 5762
    },
    {
      "epoch": 0.4478551445446068,
      "grad_norm": 0.28010520339012146,
      "learning_rate": 7.760724277276966e-06,
      "loss": 0.1981,
      "step": 5763
    },
    {
      "epoch": 0.4479328566987877,
      "grad_norm": 0.15293079614639282,
      "learning_rate": 7.760335716506063e-06,
      "loss": 0.0481,
      "step": 5764
    },
    {
      "epoch": 0.4480105688529686,
      "grad_norm": 0.47020187973976135,
      "learning_rate": 7.759947155735158e-06,
      "loss": 0.1938,
      "step": 5765
    },
    {
      "epoch": 0.44808828100714954,
      "grad_norm": 0.38226279616355896,
      "learning_rate": 7.759558594964253e-06,
      "loss": 0.4285,
      "step": 5766
    },
    {
      "epoch": 0.44816599316133043,
      "grad_norm": 0.3997914791107178,
      "learning_rate": 7.759170034193348e-06,
      "loss": 0.2647,
      "step": 5767
    },
    {
      "epoch": 0.44824370531551133,
      "grad_norm": 0.6157105565071106,
      "learning_rate": 7.758781473422444e-06,
      "loss": 0.056,
      "step": 5768
    },
    {
      "epoch": 0.4483214174696923,
      "grad_norm": 0.3435029685497284,
      "learning_rate": 7.75839291265154e-06,
      "loss": 0.2563,
      "step": 5769
    },
    {
      "epoch": 0.4483991296238732,
      "grad_norm": 0.3428694009780884,
      "learning_rate": 7.758004351880634e-06,
      "loss": 0.0511,
      "step": 5770
    },
    {
      "epoch": 0.4484768417780541,
      "grad_norm": 0.49404993653297424,
      "learning_rate": 7.757615791109731e-06,
      "loss": 0.2994,
      "step": 5771
    },
    {
      "epoch": 0.448554553932235,
      "grad_norm": 0.2531921863555908,
      "learning_rate": 7.757227230338826e-06,
      "loss": 0.0811,
      "step": 5772
    },
    {
      "epoch": 0.44863226608641593,
      "grad_norm": 0.3833353519439697,
      "learning_rate": 7.75683866956792e-06,
      "loss": 0.5485,
      "step": 5773
    },
    {
      "epoch": 0.44870997824059683,
      "grad_norm": 0.5512410402297974,
      "learning_rate": 7.756450108797017e-06,
      "loss": 0.555,
      "step": 5774
    },
    {
      "epoch": 0.4487876903947777,
      "grad_norm": 0.3851306438446045,
      "learning_rate": 7.75606154802611e-06,
      "loss": 0.5366,
      "step": 5775
    },
    {
      "epoch": 0.4488654025489587,
      "grad_norm": 0.30073148012161255,
      "learning_rate": 7.755672987255207e-06,
      "loss": 0.2473,
      "step": 5776
    },
    {
      "epoch": 0.4489431147031396,
      "grad_norm": 0.45348796248435974,
      "learning_rate": 7.755284426484302e-06,
      "loss": 0.2999,
      "step": 5777
    },
    {
      "epoch": 0.4490208268573205,
      "grad_norm": 0.5168076157569885,
      "learning_rate": 7.754895865713397e-06,
      "loss": 0.2271,
      "step": 5778
    },
    {
      "epoch": 0.4490985390115014,
      "grad_norm": 0.4494282007217407,
      "learning_rate": 7.754507304942494e-06,
      "loss": 0.499,
      "step": 5779
    },
    {
      "epoch": 0.4491762511656823,
      "grad_norm": 0.6805302500724792,
      "learning_rate": 7.754118744171589e-06,
      "loss": 0.2217,
      "step": 5780
    },
    {
      "epoch": 0.4492539633198632,
      "grad_norm": 0.09735077619552612,
      "learning_rate": 7.753730183400684e-06,
      "loss": 0.0557,
      "step": 5781
    },
    {
      "epoch": 0.4493316754740441,
      "grad_norm": 0.44483324885368347,
      "learning_rate": 7.75334162262978e-06,
      "loss": 0.1821,
      "step": 5782
    },
    {
      "epoch": 0.4494093876282251,
      "grad_norm": 0.5666873455047607,
      "learning_rate": 7.752953061858875e-06,
      "loss": 0.3447,
      "step": 5783
    },
    {
      "epoch": 0.449487099782406,
      "grad_norm": 0.5047902464866638,
      "learning_rate": 7.752564501087972e-06,
      "loss": 0.2621,
      "step": 5784
    },
    {
      "epoch": 0.44956481193658687,
      "grad_norm": 0.34589266777038574,
      "learning_rate": 7.752175940317065e-06,
      "loss": 0.0335,
      "step": 5785
    },
    {
      "epoch": 0.44964252409076777,
      "grad_norm": 0.11516598612070084,
      "learning_rate": 7.751787379546162e-06,
      "loss": 0.0511,
      "step": 5786
    },
    {
      "epoch": 0.4497202362449487,
      "grad_norm": 0.7410493493080139,
      "learning_rate": 7.751398818775257e-06,
      "loss": 0.4925,
      "step": 5787
    },
    {
      "epoch": 0.4497979483991296,
      "grad_norm": 0.48388606309890747,
      "learning_rate": 7.751010258004352e-06,
      "loss": 0.2524,
      "step": 5788
    },
    {
      "epoch": 0.4498756605533105,
      "grad_norm": 0.21100740134716034,
      "learning_rate": 7.750621697233448e-06,
      "loss": 0.0252,
      "step": 5789
    },
    {
      "epoch": 0.4499533727074915,
      "grad_norm": 0.18049457669258118,
      "learning_rate": 7.750233136462543e-06,
      "loss": 0.1216,
      "step": 5790
    },
    {
      "epoch": 0.45003108486167237,
      "grad_norm": 0.30624982714653015,
      "learning_rate": 7.749844575691638e-06,
      "loss": 0.1363,
      "step": 5791
    },
    {
      "epoch": 0.45010879701585327,
      "grad_norm": 0.3409326374530792,
      "learning_rate": 7.749456014920735e-06,
      "loss": 0.1971,
      "step": 5792
    },
    {
      "epoch": 0.45018650917003417,
      "grad_norm": 0.4193960130214691,
      "learning_rate": 7.74906745414983e-06,
      "loss": 0.1833,
      "step": 5793
    },
    {
      "epoch": 0.4502642213242151,
      "grad_norm": 0.7361227869987488,
      "learning_rate": 7.748678893378925e-06,
      "loss": 0.1947,
      "step": 5794
    },
    {
      "epoch": 0.450341933478396,
      "grad_norm": 0.2703405022621155,
      "learning_rate": 7.74829033260802e-06,
      "loss": 0.0781,
      "step": 5795
    },
    {
      "epoch": 0.4504196456325769,
      "grad_norm": 0.49423331022262573,
      "learning_rate": 7.747901771837116e-06,
      "loss": 0.5344,
      "step": 5796
    },
    {
      "epoch": 0.45049735778675787,
      "grad_norm": 2.0336151123046875,
      "learning_rate": 7.747513211066211e-06,
      "loss": 0.2462,
      "step": 5797
    },
    {
      "epoch": 0.45057506994093877,
      "grad_norm": 0.2276172637939453,
      "learning_rate": 7.747124650295306e-06,
      "loss": 0.1196,
      "step": 5798
    },
    {
      "epoch": 0.45065278209511966,
      "grad_norm": 0.6903955340385437,
      "learning_rate": 7.746736089524403e-06,
      "loss": 0.2231,
      "step": 5799
    },
    {
      "epoch": 0.4507304942493006,
      "grad_norm": 0.4429530203342438,
      "learning_rate": 7.746347528753498e-06,
      "loss": 0.1834,
      "step": 5800
    },
    {
      "epoch": 0.4508082064034815,
      "grad_norm": 0.2183530181646347,
      "learning_rate": 7.745958967982593e-06,
      "loss": 0.0862,
      "step": 5801
    },
    {
      "epoch": 0.4508859185576624,
      "grad_norm": 0.5334006547927856,
      "learning_rate": 7.74557040721169e-06,
      "loss": 0.3198,
      "step": 5802
    },
    {
      "epoch": 0.4509636307118433,
      "grad_norm": 0.5481284260749817,
      "learning_rate": 7.745181846440783e-06,
      "loss": 0.1712,
      "step": 5803
    },
    {
      "epoch": 0.45104134286602426,
      "grad_norm": 0.2865948975086212,
      "learning_rate": 7.74479328566988e-06,
      "loss": 0.1585,
      "step": 5804
    },
    {
      "epoch": 0.45111905502020516,
      "grad_norm": 0.2551043629646301,
      "learning_rate": 7.744404724898974e-06,
      "loss": 0.1073,
      "step": 5805
    },
    {
      "epoch": 0.45119676717438606,
      "grad_norm": 0.2106359452009201,
      "learning_rate": 7.74401616412807e-06,
      "loss": 0.0368,
      "step": 5806
    },
    {
      "epoch": 0.451274479328567,
      "grad_norm": 0.143976092338562,
      "learning_rate": 7.743627603357166e-06,
      "loss": 0.0574,
      "step": 5807
    },
    {
      "epoch": 0.4513521914827479,
      "grad_norm": 0.16939020156860352,
      "learning_rate": 7.743239042586261e-06,
      "loss": 0.0553,
      "step": 5808
    },
    {
      "epoch": 0.4514299036369288,
      "grad_norm": 0.2581923305988312,
      "learning_rate": 7.742850481815356e-06,
      "loss": 0.244,
      "step": 5809
    },
    {
      "epoch": 0.4515076157911097,
      "grad_norm": 0.1473090797662735,
      "learning_rate": 7.742461921044453e-06,
      "loss": 0.0365,
      "step": 5810
    },
    {
      "epoch": 0.45158532794529066,
      "grad_norm": 0.3034794330596924,
      "learning_rate": 7.742073360273547e-06,
      "loss": 0.2445,
      "step": 5811
    },
    {
      "epoch": 0.45166304009947156,
      "grad_norm": 0.2849572002887726,
      "learning_rate": 7.741684799502644e-06,
      "loss": 0.1749,
      "step": 5812
    },
    {
      "epoch": 0.45174075225365246,
      "grad_norm": 1.6940265893936157,
      "learning_rate": 7.741296238731737e-06,
      "loss": 0.657,
      "step": 5813
    },
    {
      "epoch": 0.4518184644078334,
      "grad_norm": 1.3543381690979004,
      "learning_rate": 7.740907677960834e-06,
      "loss": 0.5596,
      "step": 5814
    },
    {
      "epoch": 0.4518961765620143,
      "grad_norm": 0.8099579215049744,
      "learning_rate": 7.740519117189929e-06,
      "loss": 0.1858,
      "step": 5815
    },
    {
      "epoch": 0.4519738887161952,
      "grad_norm": 0.8326883316040039,
      "learning_rate": 7.740130556419024e-06,
      "loss": 0.1605,
      "step": 5816
    },
    {
      "epoch": 0.4520516008703761,
      "grad_norm": 0.32411763072013855,
      "learning_rate": 7.73974199564812e-06,
      "loss": 0.2053,
      "step": 5817
    },
    {
      "epoch": 0.45212931302455706,
      "grad_norm": 0.24583812057971954,
      "learning_rate": 7.739353434877216e-06,
      "loss": 0.4028,
      "step": 5818
    },
    {
      "epoch": 0.45220702517873795,
      "grad_norm": 0.05911325663328171,
      "learning_rate": 7.73896487410631e-06,
      "loss": 0.031,
      "step": 5819
    },
    {
      "epoch": 0.45228473733291885,
      "grad_norm": 0.32411253452301025,
      "learning_rate": 7.738576313335407e-06,
      "loss": 0.225,
      "step": 5820
    },
    {
      "epoch": 0.4523624494870998,
      "grad_norm": 1.3012586832046509,
      "learning_rate": 7.738187752564502e-06,
      "loss": 0.2462,
      "step": 5821
    },
    {
      "epoch": 0.4524401616412807,
      "grad_norm": 0.3496304750442505,
      "learning_rate": 7.737799191793597e-06,
      "loss": 0.1028,
      "step": 5822
    },
    {
      "epoch": 0.4525178737954616,
      "grad_norm": 0.10720917582511902,
      "learning_rate": 7.737410631022692e-06,
      "loss": 0.0778,
      "step": 5823
    },
    {
      "epoch": 0.4525955859496425,
      "grad_norm": 0.06738028675317764,
      "learning_rate": 7.737022070251789e-06,
      "loss": 0.0398,
      "step": 5824
    },
    {
      "epoch": 0.45267329810382345,
      "grad_norm": 0.3853718042373657,
      "learning_rate": 7.736633509480884e-06,
      "loss": 0.3083,
      "step": 5825
    },
    {
      "epoch": 0.45275101025800435,
      "grad_norm": 0.06941504031419754,
      "learning_rate": 7.736244948709979e-06,
      "loss": 0.0379,
      "step": 5826
    },
    {
      "epoch": 0.45282872241218525,
      "grad_norm": 0.41835492849349976,
      "learning_rate": 7.735856387939075e-06,
      "loss": 0.1535,
      "step": 5827
    },
    {
      "epoch": 0.4529064345663662,
      "grad_norm": 0.4164809584617615,
      "learning_rate": 7.73546782716817e-06,
      "loss": 0.1515,
      "step": 5828
    },
    {
      "epoch": 0.4529841467205471,
      "grad_norm": 0.13885332643985748,
      "learning_rate": 7.735079266397265e-06,
      "loss": 0.0573,
      "step": 5829
    },
    {
      "epoch": 0.453061858874728,
      "grad_norm": 0.6143588423728943,
      "learning_rate": 7.734690705626362e-06,
      "loss": 0.1971,
      "step": 5830
    },
    {
      "epoch": 0.4531395710289089,
      "grad_norm": 0.26340973377227783,
      "learning_rate": 7.734302144855455e-06,
      "loss": 0.0512,
      "step": 5831
    },
    {
      "epoch": 0.45321728318308985,
      "grad_norm": 0.2600937783718109,
      "learning_rate": 7.733913584084552e-06,
      "loss": 0.5496,
      "step": 5832
    },
    {
      "epoch": 0.45329499533727075,
      "grad_norm": 0.05065780133008957,
      "learning_rate": 7.733525023313647e-06,
      "loss": 0.0213,
      "step": 5833
    },
    {
      "epoch": 0.45337270749145164,
      "grad_norm": 0.668563723564148,
      "learning_rate": 7.733136462542741e-06,
      "loss": 0.1936,
      "step": 5834
    },
    {
      "epoch": 0.4534504196456326,
      "grad_norm": 0.16157622635364532,
      "learning_rate": 7.732747901771838e-06,
      "loss": 0.0812,
      "step": 5835
    },
    {
      "epoch": 0.4535281317998135,
      "grad_norm": 0.4039803743362427,
      "learning_rate": 7.732359341000933e-06,
      "loss": 0.0659,
      "step": 5836
    },
    {
      "epoch": 0.4536058439539944,
      "grad_norm": 0.3997746407985687,
      "learning_rate": 7.731970780230028e-06,
      "loss": 0.2141,
      "step": 5837
    },
    {
      "epoch": 0.45368355610817535,
      "grad_norm": 0.14684359729290009,
      "learning_rate": 7.731582219459125e-06,
      "loss": 0.0456,
      "step": 5838
    },
    {
      "epoch": 0.45376126826235624,
      "grad_norm": 0.19532494246959686,
      "learning_rate": 7.73119365868822e-06,
      "loss": 0.1458,
      "step": 5839
    },
    {
      "epoch": 0.45383898041653714,
      "grad_norm": 0.384421169757843,
      "learning_rate": 7.730805097917315e-06,
      "loss": 0.2029,
      "step": 5840
    },
    {
      "epoch": 0.45391669257071804,
      "grad_norm": 0.48008471727371216,
      "learning_rate": 7.73041653714641e-06,
      "loss": 0.3412,
      "step": 5841
    },
    {
      "epoch": 0.453994404724899,
      "grad_norm": 0.7666360139846802,
      "learning_rate": 7.730027976375506e-06,
      "loss": 0.2196,
      "step": 5842
    },
    {
      "epoch": 0.4540721168790799,
      "grad_norm": 0.3517744243144989,
      "learning_rate": 7.729639415604601e-06,
      "loss": 0.1625,
      "step": 5843
    },
    {
      "epoch": 0.4541498290332608,
      "grad_norm": 0.24851463735103607,
      "learning_rate": 7.729250854833696e-06,
      "loss": 0.0602,
      "step": 5844
    },
    {
      "epoch": 0.45422754118744174,
      "grad_norm": 0.48934781551361084,
      "learning_rate": 7.728862294062793e-06,
      "loss": 0.1777,
      "step": 5845
    },
    {
      "epoch": 0.45430525334162264,
      "grad_norm": 0.34718626737594604,
      "learning_rate": 7.728473733291888e-06,
      "loss": 0.1964,
      "step": 5846
    },
    {
      "epoch": 0.45438296549580354,
      "grad_norm": 0.46870946884155273,
      "learning_rate": 7.728085172520983e-06,
      "loss": 0.1394,
      "step": 5847
    },
    {
      "epoch": 0.45446067764998443,
      "grad_norm": 0.49923479557037354,
      "learning_rate": 7.72769661175008e-06,
      "loss": 0.0571,
      "step": 5848
    },
    {
      "epoch": 0.4545383898041654,
      "grad_norm": 0.4363022744655609,
      "learning_rate": 7.727308050979174e-06,
      "loss": 0.2331,
      "step": 5849
    },
    {
      "epoch": 0.4546161019583463,
      "grad_norm": 0.25956106185913086,
      "learning_rate": 7.72691949020827e-06,
      "loss": 0.1241,
      "step": 5850
    },
    {
      "epoch": 0.4546938141125272,
      "grad_norm": 0.20658724009990692,
      "learning_rate": 7.726530929437364e-06,
      "loss": 0.0605,
      "step": 5851
    },
    {
      "epoch": 0.45477152626670814,
      "grad_norm": 0.3063165545463562,
      "learning_rate": 7.72614236866646e-06,
      "loss": 0.0841,
      "step": 5852
    },
    {
      "epoch": 0.45484923842088903,
      "grad_norm": 0.5128291249275208,
      "learning_rate": 7.725753807895556e-06,
      "loss": 0.1978,
      "step": 5853
    },
    {
      "epoch": 0.45492695057506993,
      "grad_norm": 0.1541319638490677,
      "learning_rate": 7.72536524712465e-06,
      "loss": 0.0427,
      "step": 5854
    },
    {
      "epoch": 0.45500466272925083,
      "grad_norm": 0.20974136888980865,
      "learning_rate": 7.724976686353747e-06,
      "loss": 0.0695,
      "step": 5855
    },
    {
      "epoch": 0.4550823748834318,
      "grad_norm": 0.24323700368404388,
      "learning_rate": 7.724588125582842e-06,
      "loss": 0.1061,
      "step": 5856
    },
    {
      "epoch": 0.4551600870376127,
      "grad_norm": 0.3870404064655304,
      "learning_rate": 7.724199564811937e-06,
      "loss": 0.2976,
      "step": 5857
    },
    {
      "epoch": 0.4552377991917936,
      "grad_norm": 0.15179699659347534,
      "learning_rate": 7.723811004041034e-06,
      "loss": 0.043,
      "step": 5858
    },
    {
      "epoch": 0.45531551134597453,
      "grad_norm": 0.13221238553524017,
      "learning_rate": 7.723422443270127e-06,
      "loss": 0.0379,
      "step": 5859
    },
    {
      "epoch": 0.45539322350015543,
      "grad_norm": 0.7904393672943115,
      "learning_rate": 7.723033882499224e-06,
      "loss": 0.4934,
      "step": 5860
    },
    {
      "epoch": 0.45547093565433633,
      "grad_norm": 0.6750176548957825,
      "learning_rate": 7.722645321728319e-06,
      "loss": 0.5913,
      "step": 5861
    },
    {
      "epoch": 0.4555486478085172,
      "grad_norm": 0.26161128282546997,
      "learning_rate": 7.722256760957414e-06,
      "loss": 0.0911,
      "step": 5862
    },
    {
      "epoch": 0.4556263599626982,
      "grad_norm": 0.12308409810066223,
      "learning_rate": 7.72186820018651e-06,
      "loss": 0.0306,
      "step": 5863
    },
    {
      "epoch": 0.4557040721168791,
      "grad_norm": 0.1193937435746193,
      "learning_rate": 7.721479639415605e-06,
      "loss": 0.0204,
      "step": 5864
    },
    {
      "epoch": 0.45578178427106,
      "grad_norm": 0.5045771598815918,
      "learning_rate": 7.7210910786447e-06,
      "loss": 0.2643,
      "step": 5865
    },
    {
      "epoch": 0.45585949642524093,
      "grad_norm": 0.17625294625759125,
      "learning_rate": 7.720702517873797e-06,
      "loss": 0.0371,
      "step": 5866
    },
    {
      "epoch": 0.4559372085794218,
      "grad_norm": 0.437548965215683,
      "learning_rate": 7.720313957102892e-06,
      "loss": 0.2359,
      "step": 5867
    },
    {
      "epoch": 0.4560149207336027,
      "grad_norm": 0.40705400705337524,
      "learning_rate": 7.719925396331987e-06,
      "loss": 0.1912,
      "step": 5868
    },
    {
      "epoch": 0.4560926328877836,
      "grad_norm": 0.17765843868255615,
      "learning_rate": 7.719536835561082e-06,
      "loss": 0.0434,
      "step": 5869
    },
    {
      "epoch": 0.4561703450419646,
      "grad_norm": 0.2724566161632538,
      "learning_rate": 7.719148274790178e-06,
      "loss": 0.1063,
      "step": 5870
    },
    {
      "epoch": 0.4562480571961455,
      "grad_norm": 0.7936854362487793,
      "learning_rate": 7.718759714019273e-06,
      "loss": 0.2286,
      "step": 5871
    },
    {
      "epoch": 0.45632576935032637,
      "grad_norm": 0.3919124901294708,
      "learning_rate": 7.718371153248368e-06,
      "loss": 0.1069,
      "step": 5872
    },
    {
      "epoch": 0.4564034815045073,
      "grad_norm": 0.10799899697303772,
      "learning_rate": 7.717982592477465e-06,
      "loss": 0.0207,
      "step": 5873
    },
    {
      "epoch": 0.4564811936586882,
      "grad_norm": 0.1361207664012909,
      "learning_rate": 7.71759403170656e-06,
      "loss": 0.039,
      "step": 5874
    },
    {
      "epoch": 0.4565589058128691,
      "grad_norm": 0.1955263465642929,
      "learning_rate": 7.717205470935655e-06,
      "loss": 0.1904,
      "step": 5875
    },
    {
      "epoch": 0.4566366179670501,
      "grad_norm": 0.9412963390350342,
      "learning_rate": 7.71681691016475e-06,
      "loss": 0.2644,
      "step": 5876
    },
    {
      "epoch": 0.45671433012123097,
      "grad_norm": 0.2089793086051941,
      "learning_rate": 7.716428349393846e-06,
      "loss": 0.0685,
      "step": 5877
    },
    {
      "epoch": 0.45679204227541187,
      "grad_norm": 0.16179150342941284,
      "learning_rate": 7.716039788622941e-06,
      "loss": 0.0305,
      "step": 5878
    },
    {
      "epoch": 0.45686975442959277,
      "grad_norm": 0.3881005048751831,
      "learning_rate": 7.715651227852036e-06,
      "loss": 0.2214,
      "step": 5879
    },
    {
      "epoch": 0.4569474665837737,
      "grad_norm": 0.9880638718605042,
      "learning_rate": 7.715262667081133e-06,
      "loss": 0.3135,
      "step": 5880
    },
    {
      "epoch": 0.4570251787379546,
      "grad_norm": 1.6867049932479858,
      "learning_rate": 7.714874106310228e-06,
      "loss": 0.6328,
      "step": 5881
    },
    {
      "epoch": 0.4571028908921355,
      "grad_norm": 0.19753915071487427,
      "learning_rate": 7.714485545539323e-06,
      "loss": 0.0885,
      "step": 5882
    },
    {
      "epoch": 0.45718060304631647,
      "grad_norm": 0.16111308336257935,
      "learning_rate": 7.71409698476842e-06,
      "loss": 0.0818,
      "step": 5883
    },
    {
      "epoch": 0.45725831520049737,
      "grad_norm": 0.26981186866760254,
      "learning_rate": 7.713708423997513e-06,
      "loss": 0.2286,
      "step": 5884
    },
    {
      "epoch": 0.45733602735467827,
      "grad_norm": 0.2180173397064209,
      "learning_rate": 7.71331986322661e-06,
      "loss": 0.074,
      "step": 5885
    },
    {
      "epoch": 0.45741373950885916,
      "grad_norm": 0.5038893222808838,
      "learning_rate": 7.712931302455704e-06,
      "loss": 0.2996,
      "step": 5886
    },
    {
      "epoch": 0.4574914516630401,
      "grad_norm": 0.31213223934173584,
      "learning_rate": 7.7125427416848e-06,
      "loss": 0.181,
      "step": 5887
    },
    {
      "epoch": 0.457569163817221,
      "grad_norm": 0.11956214904785156,
      "learning_rate": 7.712154180913896e-06,
      "loss": 0.026,
      "step": 5888
    },
    {
      "epoch": 0.4576468759714019,
      "grad_norm": 0.7535921335220337,
      "learning_rate": 7.71176562014299e-06,
      "loss": 0.1382,
      "step": 5889
    },
    {
      "epoch": 0.45772458812558287,
      "grad_norm": 0.27202561497688293,
      "learning_rate": 7.711377059372086e-06,
      "loss": 0.0903,
      "step": 5890
    },
    {
      "epoch": 0.45780230027976376,
      "grad_norm": 0.19380085170269012,
      "learning_rate": 7.710988498601182e-06,
      "loss": 0.0472,
      "step": 5891
    },
    {
      "epoch": 0.45788001243394466,
      "grad_norm": 0.16003242135047913,
      "learning_rate": 7.710599937830277e-06,
      "loss": 0.0273,
      "step": 5892
    },
    {
      "epoch": 0.45795772458812556,
      "grad_norm": 0.8982831835746765,
      "learning_rate": 7.710211377059372e-06,
      "loss": 0.3727,
      "step": 5893
    },
    {
      "epoch": 0.4580354367423065,
      "grad_norm": 0.29547643661499023,
      "learning_rate": 7.709822816288467e-06,
      "loss": 0.127,
      "step": 5894
    },
    {
      "epoch": 0.4581131488964874,
      "grad_norm": 0.2100450098514557,
      "learning_rate": 7.709434255517564e-06,
      "loss": 0.1029,
      "step": 5895
    },
    {
      "epoch": 0.4581908610506683,
      "grad_norm": 0.3535193204879761,
      "learning_rate": 7.709045694746659e-06,
      "loss": 0.35,
      "step": 5896
    },
    {
      "epoch": 0.45826857320484926,
      "grad_norm": 0.14990369975566864,
      "learning_rate": 7.708657133975754e-06,
      "loss": 0.0544,
      "step": 5897
    },
    {
      "epoch": 0.45834628535903016,
      "grad_norm": 0.21601957082748413,
      "learning_rate": 7.70826857320485e-06,
      "loss": 0.192,
      "step": 5898
    },
    {
      "epoch": 0.45842399751321106,
      "grad_norm": 0.2908204197883606,
      "learning_rate": 7.707880012433945e-06,
      "loss": 0.365,
      "step": 5899
    },
    {
      "epoch": 0.45850170966739195,
      "grad_norm": 0.20778800547122955,
      "learning_rate": 7.70749145166304e-06,
      "loss": 0.0204,
      "step": 5900
    },
    {
      "epoch": 0.4585794218215729,
      "grad_norm": 0.36607977747917175,
      "learning_rate": 7.707102890892137e-06,
      "loss": 0.1755,
      "step": 5901
    },
    {
      "epoch": 0.4586571339757538,
      "grad_norm": 0.26537227630615234,
      "learning_rate": 7.70671433012123e-06,
      "loss": 0.0702,
      "step": 5902
    },
    {
      "epoch": 0.4587348461299347,
      "grad_norm": 0.5547257661819458,
      "learning_rate": 7.706325769350327e-06,
      "loss": 0.2825,
      "step": 5903
    },
    {
      "epoch": 0.45881255828411566,
      "grad_norm": 0.589608371257782,
      "learning_rate": 7.705937208579422e-06,
      "loss": 0.711,
      "step": 5904
    },
    {
      "epoch": 0.45889027043829655,
      "grad_norm": 0.9180530905723572,
      "learning_rate": 7.705548647808518e-06,
      "loss": 0.1104,
      "step": 5905
    },
    {
      "epoch": 0.45896798259247745,
      "grad_norm": 0.12630118429660797,
      "learning_rate": 7.705160087037613e-06,
      "loss": 0.0627,
      "step": 5906
    },
    {
      "epoch": 0.45904569474665835,
      "grad_norm": 0.2874831557273865,
      "learning_rate": 7.704771526266708e-06,
      "loss": 0.3691,
      "step": 5907
    },
    {
      "epoch": 0.4591234069008393,
      "grad_norm": 0.2005845308303833,
      "learning_rate": 7.704382965495805e-06,
      "loss": 0.1155,
      "step": 5908
    },
    {
      "epoch": 0.4592011190550202,
      "grad_norm": 0.10926477611064911,
      "learning_rate": 7.7039944047249e-06,
      "loss": 0.0404,
      "step": 5909
    },
    {
      "epoch": 0.4592788312092011,
      "grad_norm": 0.45234987139701843,
      "learning_rate": 7.703605843953995e-06,
      "loss": 0.3707,
      "step": 5910
    },
    {
      "epoch": 0.45935654336338205,
      "grad_norm": 0.35584771633148193,
      "learning_rate": 7.703217283183092e-06,
      "loss": 0.154,
      "step": 5911
    },
    {
      "epoch": 0.45943425551756295,
      "grad_norm": 0.21145281195640564,
      "learning_rate": 7.702828722412185e-06,
      "loss": 0.0926,
      "step": 5912
    },
    {
      "epoch": 0.45951196767174385,
      "grad_norm": 0.29278963804244995,
      "learning_rate": 7.702440161641281e-06,
      "loss": 0.1293,
      "step": 5913
    },
    {
      "epoch": 0.4595896798259248,
      "grad_norm": 0.3766901195049286,
      "learning_rate": 7.702051600870376e-06,
      "loss": 0.1151,
      "step": 5914
    },
    {
      "epoch": 0.4596673919801057,
      "grad_norm": 0.36171817779541016,
      "learning_rate": 7.701663040099471e-06,
      "loss": 0.1641,
      "step": 5915
    },
    {
      "epoch": 0.4597451041342866,
      "grad_norm": 0.13607774674892426,
      "learning_rate": 7.701274479328568e-06,
      "loss": 0.0732,
      "step": 5916
    },
    {
      "epoch": 0.4598228162884675,
      "grad_norm": 0.2825165092945099,
      "learning_rate": 7.700885918557663e-06,
      "loss": 0.1691,
      "step": 5917
    },
    {
      "epoch": 0.45990052844264845,
      "grad_norm": 0.12660785019397736,
      "learning_rate": 7.700497357786758e-06,
      "loss": 0.0238,
      "step": 5918
    },
    {
      "epoch": 0.45997824059682935,
      "grad_norm": 0.6530978083610535,
      "learning_rate": 7.700108797015855e-06,
      "loss": 0.2836,
      "step": 5919
    },
    {
      "epoch": 0.46005595275101024,
      "grad_norm": 0.28625810146331787,
      "learning_rate": 7.69972023624495e-06,
      "loss": 0.0742,
      "step": 5920
    },
    {
      "epoch": 0.4601336649051912,
      "grad_norm": 0.23232460021972656,
      "learning_rate": 7.699331675474044e-06,
      "loss": 0.1051,
      "step": 5921
    },
    {
      "epoch": 0.4602113770593721,
      "grad_norm": 0.1399902105331421,
      "learning_rate": 7.69894311470314e-06,
      "loss": 0.0381,
      "step": 5922
    },
    {
      "epoch": 0.460289089213553,
      "grad_norm": 0.2800557315349579,
      "learning_rate": 7.698554553932236e-06,
      "loss": 0.1481,
      "step": 5923
    },
    {
      "epoch": 0.4603668013677339,
      "grad_norm": 0.14260344207286835,
      "learning_rate": 7.698165993161331e-06,
      "loss": 0.0425,
      "step": 5924
    },
    {
      "epoch": 0.46044451352191484,
      "grad_norm": 0.12673057615756989,
      "learning_rate": 7.697777432390426e-06,
      "loss": 0.0347,
      "step": 5925
    },
    {
      "epoch": 0.46052222567609574,
      "grad_norm": 0.30806460976600647,
      "learning_rate": 7.697388871619523e-06,
      "loss": 0.1045,
      "step": 5926
    },
    {
      "epoch": 0.46059993783027664,
      "grad_norm": 0.7284033894538879,
      "learning_rate": 7.697000310848618e-06,
      "loss": 0.0712,
      "step": 5927
    },
    {
      "epoch": 0.4606776499844576,
      "grad_norm": 0.10449718683958054,
      "learning_rate": 7.696611750077713e-06,
      "loss": 0.0144,
      "step": 5928
    },
    {
      "epoch": 0.4607553621386385,
      "grad_norm": 0.06345950067043304,
      "learning_rate": 7.696223189306809e-06,
      "loss": 0.0106,
      "step": 5929
    },
    {
      "epoch": 0.4608330742928194,
      "grad_norm": 0.1561804860830307,
      "learning_rate": 7.695834628535902e-06,
      "loss": 0.061,
      "step": 5930
    },
    {
      "epoch": 0.4609107864470003,
      "grad_norm": 0.5186201930046082,
      "learning_rate": 7.695446067764999e-06,
      "loss": 0.0685,
      "step": 5931
    },
    {
      "epoch": 0.46098849860118124,
      "grad_norm": 0.11413652449846268,
      "learning_rate": 7.695057506994094e-06,
      "loss": 0.0491,
      "step": 5932
    },
    {
      "epoch": 0.46106621075536214,
      "grad_norm": 0.3435741364955902,
      "learning_rate": 7.694668946223189e-06,
      "loss": 0.158,
      "step": 5933
    },
    {
      "epoch": 0.46114392290954304,
      "grad_norm": 0.5938175916671753,
      "learning_rate": 7.694280385452286e-06,
      "loss": 0.6993,
      "step": 5934
    },
    {
      "epoch": 0.461221635063724,
      "grad_norm": 0.03861697018146515,
      "learning_rate": 7.69389182468138e-06,
      "loss": 0.0043,
      "step": 5935
    },
    {
      "epoch": 0.4612993472179049,
      "grad_norm": 0.3513447940349579,
      "learning_rate": 7.693503263910477e-06,
      "loss": 0.2264,
      "step": 5936
    },
    {
      "epoch": 0.4613770593720858,
      "grad_norm": 0.26073870062828064,
      "learning_rate": 7.693114703139572e-06,
      "loss": 0.2023,
      "step": 5937
    },
    {
      "epoch": 0.4614547715262667,
      "grad_norm": 0.3375892639160156,
      "learning_rate": 7.692726142368667e-06,
      "loss": 0.2864,
      "step": 5938
    },
    {
      "epoch": 0.46153248368044764,
      "grad_norm": 0.33941560983657837,
      "learning_rate": 7.692337581597764e-06,
      "loss": 0.1708,
      "step": 5939
    },
    {
      "epoch": 0.46161019583462853,
      "grad_norm": 0.8621644973754883,
      "learning_rate": 7.691949020826857e-06,
      "loss": 0.4296,
      "step": 5940
    },
    {
      "epoch": 0.46168790798880943,
      "grad_norm": 0.8146262764930725,
      "learning_rate": 7.691560460055954e-06,
      "loss": 0.3088,
      "step": 5941
    },
    {
      "epoch": 0.4617656201429904,
      "grad_norm": 0.14574535191059113,
      "learning_rate": 7.691171899285049e-06,
      "loss": 0.0235,
      "step": 5942
    },
    {
      "epoch": 0.4618433322971713,
      "grad_norm": 0.38396698236465454,
      "learning_rate": 7.690783338514144e-06,
      "loss": 0.0743,
      "step": 5943
    },
    {
      "epoch": 0.4619210444513522,
      "grad_norm": 12.697837829589844,
      "learning_rate": 7.69039477774324e-06,
      "loss": 0.8554,
      "step": 5944
    },
    {
      "epoch": 0.4619987566055331,
      "grad_norm": 0.6748328804969788,
      "learning_rate": 7.690006216972335e-06,
      "loss": 0.0804,
      "step": 5945
    },
    {
      "epoch": 0.46207646875971403,
      "grad_norm": 0.19361340999603271,
      "learning_rate": 7.68961765620143e-06,
      "loss": 0.0354,
      "step": 5946
    },
    {
      "epoch": 0.46215418091389493,
      "grad_norm": 0.34105661511421204,
      "learning_rate": 7.689229095430527e-06,
      "loss": 0.1302,
      "step": 5947
    },
    {
      "epoch": 0.4622318930680758,
      "grad_norm": 0.2872297465801239,
      "learning_rate": 7.688840534659622e-06,
      "loss": 0.2271,
      "step": 5948
    },
    {
      "epoch": 0.4623096052222568,
      "grad_norm": 0.14261385798454285,
      "learning_rate": 7.688451973888717e-06,
      "loss": 0.0433,
      "step": 5949
    },
    {
      "epoch": 0.4623873173764377,
      "grad_norm": 0.1088404655456543,
      "learning_rate": 7.688063413117812e-06,
      "loss": 0.0446,
      "step": 5950
    },
    {
      "epoch": 0.4624650295306186,
      "grad_norm": 0.880986750125885,
      "learning_rate": 7.687674852346908e-06,
      "loss": 0.4517,
      "step": 5951
    },
    {
      "epoch": 0.46254274168479953,
      "grad_norm": 0.43207719922065735,
      "learning_rate": 7.687286291576003e-06,
      "loss": 0.3294,
      "step": 5952
    },
    {
      "epoch": 0.4626204538389804,
      "grad_norm": 0.08446339517831802,
      "learning_rate": 7.686897730805098e-06,
      "loss": 0.0405,
      "step": 5953
    },
    {
      "epoch": 0.4626981659931613,
      "grad_norm": 0.4387670159339905,
      "learning_rate": 7.686509170034195e-06,
      "loss": 0.1957,
      "step": 5954
    },
    {
      "epoch": 0.4627758781473422,
      "grad_norm": 0.4491085708141327,
      "learning_rate": 7.68612060926329e-06,
      "loss": 0.3691,
      "step": 5955
    },
    {
      "epoch": 0.4628535903015232,
      "grad_norm": 0.2775525748729706,
      "learning_rate": 7.685732048492385e-06,
      "loss": 0.1283,
      "step": 5956
    },
    {
      "epoch": 0.4629313024557041,
      "grad_norm": 0.6859575510025024,
      "learning_rate": 7.685343487721481e-06,
      "loss": 0.2246,
      "step": 5957
    },
    {
      "epoch": 0.463009014609885,
      "grad_norm": 0.9028173089027405,
      "learning_rate": 7.684954926950575e-06,
      "loss": 0.3279,
      "step": 5958
    },
    {
      "epoch": 0.4630867267640659,
      "grad_norm": 0.17624840140342712,
      "learning_rate": 7.684566366179671e-06,
      "loss": 0.2122,
      "step": 5959
    },
    {
      "epoch": 0.4631644389182468,
      "grad_norm": 0.9697539210319519,
      "learning_rate": 7.684177805408766e-06,
      "loss": 0.1254,
      "step": 5960
    },
    {
      "epoch": 0.4632421510724277,
      "grad_norm": 0.2678942084312439,
      "learning_rate": 7.683789244637861e-06,
      "loss": 0.0987,
      "step": 5961
    },
    {
      "epoch": 0.4633198632266086,
      "grad_norm": 0.22082936763763428,
      "learning_rate": 7.683400683866958e-06,
      "loss": 0.1513,
      "step": 5962
    },
    {
      "epoch": 0.4633975753807896,
      "grad_norm": 0.44676798582077026,
      "learning_rate": 7.683012123096053e-06,
      "loss": 0.1762,
      "step": 5963
    },
    {
      "epoch": 0.46347528753497047,
      "grad_norm": 0.14530536532402039,
      "learning_rate": 7.68262356232515e-06,
      "loss": 0.0421,
      "step": 5964
    },
    {
      "epoch": 0.46355299968915137,
      "grad_norm": 0.20474979281425476,
      "learning_rate": 7.682235001554244e-06,
      "loss": 0.0433,
      "step": 5965
    },
    {
      "epoch": 0.4636307118433323,
      "grad_norm": 0.20138972997665405,
      "learning_rate": 7.68184644078334e-06,
      "loss": 0.0535,
      "step": 5966
    },
    {
      "epoch": 0.4637084239975132,
      "grad_norm": 0.5312819480895996,
      "learning_rate": 7.681457880012436e-06,
      "loss": 0.1799,
      "step": 5967
    },
    {
      "epoch": 0.4637861361516941,
      "grad_norm": 0.34010404348373413,
      "learning_rate": 7.681069319241529e-06,
      "loss": 0.159,
      "step": 5968
    },
    {
      "epoch": 0.463863848305875,
      "grad_norm": 0.37774673104286194,
      "learning_rate": 7.680680758470626e-06,
      "loss": 0.2668,
      "step": 5969
    },
    {
      "epoch": 0.46394156046005597,
      "grad_norm": 0.7112846374511719,
      "learning_rate": 7.68029219769972e-06,
      "loss": 0.7705,
      "step": 5970
    },
    {
      "epoch": 0.46401927261423687,
      "grad_norm": 0.690656840801239,
      "learning_rate": 7.679903636928816e-06,
      "loss": 0.4609,
      "step": 5971
    },
    {
      "epoch": 0.46409698476841776,
      "grad_norm": 0.4977957010269165,
      "learning_rate": 7.679515076157912e-06,
      "loss": 0.9049,
      "step": 5972
    },
    {
      "epoch": 0.4641746969225987,
      "grad_norm": 0.22940391302108765,
      "learning_rate": 7.679126515387007e-06,
      "loss": 0.117,
      "step": 5973
    },
    {
      "epoch": 0.4642524090767796,
      "grad_norm": 0.09584223479032516,
      "learning_rate": 7.678737954616102e-06,
      "loss": 0.0959,
      "step": 5974
    },
    {
      "epoch": 0.4643301212309605,
      "grad_norm": 0.0762108713388443,
      "learning_rate": 7.678349393845199e-06,
      "loss": 0.0185,
      "step": 5975
    },
    {
      "epoch": 0.4644078333851414,
      "grad_norm": 0.34918808937072754,
      "learning_rate": 7.677960833074294e-06,
      "loss": 0.3205,
      "step": 5976
    },
    {
      "epoch": 0.46448554553932236,
      "grad_norm": 1.0273817777633667,
      "learning_rate": 7.677572272303389e-06,
      "loss": 0.7568,
      "step": 5977
    },
    {
      "epoch": 0.46456325769350326,
      "grad_norm": 0.5620936155319214,
      "learning_rate": 7.677183711532484e-06,
      "loss": 0.3567,
      "step": 5978
    },
    {
      "epoch": 0.46464096984768416,
      "grad_norm": 0.19869333505630493,
      "learning_rate": 7.67679515076158e-06,
      "loss": 0.0616,
      "step": 5979
    },
    {
      "epoch": 0.4647186820018651,
      "grad_norm": 0.27610617876052856,
      "learning_rate": 7.676406589990675e-06,
      "loss": 0.1146,
      "step": 5980
    },
    {
      "epoch": 0.464796394156046,
      "grad_norm": 0.38871070742607117,
      "learning_rate": 7.67601802921977e-06,
      "loss": 0.1088,
      "step": 5981
    },
    {
      "epoch": 0.4648741063102269,
      "grad_norm": 0.23649713397026062,
      "learning_rate": 7.675629468448867e-06,
      "loss": 0.1289,
      "step": 5982
    },
    {
      "epoch": 0.4649518184644078,
      "grad_norm": 0.38569799065589905,
      "learning_rate": 7.675240907677962e-06,
      "loss": 0.169,
      "step": 5983
    },
    {
      "epoch": 0.46502953061858876,
      "grad_norm": 0.09475356340408325,
      "learning_rate": 7.674852346907057e-06,
      "loss": 0.0357,
      "step": 5984
    },
    {
      "epoch": 0.46510724277276966,
      "grad_norm": 0.15745045244693756,
      "learning_rate": 7.674463786136153e-06,
      "loss": 0.1086,
      "step": 5985
    },
    {
      "epoch": 0.46518495492695056,
      "grad_norm": 0.6669245362281799,
      "learning_rate": 7.674075225365247e-06,
      "loss": 0.8008,
      "step": 5986
    },
    {
      "epoch": 0.4652626670811315,
      "grad_norm": 0.24687257409095764,
      "learning_rate": 7.673686664594343e-06,
      "loss": 0.057,
      "step": 5987
    },
    {
      "epoch": 0.4653403792353124,
      "grad_norm": 0.16606034338474274,
      "learning_rate": 7.673298103823438e-06,
      "loss": 0.0675,
      "step": 5988
    },
    {
      "epoch": 0.4654180913894933,
      "grad_norm": 0.2026175558567047,
      "learning_rate": 7.672909543052533e-06,
      "loss": 0.1277,
      "step": 5989
    },
    {
      "epoch": 0.46549580354367426,
      "grad_norm": 0.233934685587883,
      "learning_rate": 7.67252098228163e-06,
      "loss": 0.0302,
      "step": 5990
    },
    {
      "epoch": 0.46557351569785516,
      "grad_norm": 0.4612186849117279,
      "learning_rate": 7.672132421510725e-06,
      "loss": 0.1581,
      "step": 5991
    },
    {
      "epoch": 0.46565122785203605,
      "grad_norm": 0.08257222920656204,
      "learning_rate": 7.67174386073982e-06,
      "loss": 0.0127,
      "step": 5992
    },
    {
      "epoch": 0.46572894000621695,
      "grad_norm": 1.0812116861343384,
      "learning_rate": 7.671355299968916e-06,
      "loss": 0.2589,
      "step": 5993
    },
    {
      "epoch": 0.4658066521603979,
      "grad_norm": 0.2904980778694153,
      "learning_rate": 7.670966739198011e-06,
      "loss": 0.1636,
      "step": 5994
    },
    {
      "epoch": 0.4658843643145788,
      "grad_norm": 0.4078381657600403,
      "learning_rate": 7.670578178427106e-06,
      "loss": 0.253,
      "step": 5995
    },
    {
      "epoch": 0.4659620764687597,
      "grad_norm": 0.2514244318008423,
      "learning_rate": 7.670189617656201e-06,
      "loss": 0.2009,
      "step": 5996
    },
    {
      "epoch": 0.46603978862294065,
      "grad_norm": 0.7089028358459473,
      "learning_rate": 7.669801056885298e-06,
      "loss": 0.4711,
      "step": 5997
    },
    {
      "epoch": 0.46611750077712155,
      "grad_norm": 0.34316587448120117,
      "learning_rate": 7.669412496114393e-06,
      "loss": 0.2059,
      "step": 5998
    },
    {
      "epoch": 0.46619521293130245,
      "grad_norm": 0.07762309908866882,
      "learning_rate": 7.669023935343488e-06,
      "loss": 0.0353,
      "step": 5999
    },
    {
      "epoch": 0.46627292508548335,
      "grad_norm": 0.19984987378120422,
      "learning_rate": 7.668635374572584e-06,
      "loss": 0.0251,
      "step": 6000
    },
    {
      "epoch": 0.4663506372396643,
      "grad_norm": 0.5231903791427612,
      "learning_rate": 7.66824681380168e-06,
      "loss": 0.3655,
      "step": 6001
    },
    {
      "epoch": 0.4664283493938452,
      "grad_norm": 0.4826318025588989,
      "learning_rate": 7.667858253030774e-06,
      "loss": 0.299,
      "step": 6002
    },
    {
      "epoch": 0.4665060615480261,
      "grad_norm": 0.8008408546447754,
      "learning_rate": 7.66746969225987e-06,
      "loss": 0.6319,
      "step": 6003
    },
    {
      "epoch": 0.46658377370220705,
      "grad_norm": 0.2668916583061218,
      "learning_rate": 7.667081131488966e-06,
      "loss": 0.0463,
      "step": 6004
    },
    {
      "epoch": 0.46666148585638795,
      "grad_norm": 0.41116657853126526,
      "learning_rate": 7.666692570718061e-06,
      "loss": 0.2685,
      "step": 6005
    },
    {
      "epoch": 0.46673919801056885,
      "grad_norm": 0.16692404448986053,
      "learning_rate": 7.666304009947156e-06,
      "loss": 0.1118,
      "step": 6006
    },
    {
      "epoch": 0.46681691016474974,
      "grad_norm": 0.4212568700313568,
      "learning_rate": 7.665915449176253e-06,
      "loss": 0.4606,
      "step": 6007
    },
    {
      "epoch": 0.4668946223189307,
      "grad_norm": 0.2302589863538742,
      "learning_rate": 7.665526888405347e-06,
      "loss": 0.1251,
      "step": 6008
    },
    {
      "epoch": 0.4669723344731116,
      "grad_norm": 0.523567259311676,
      "learning_rate": 7.665138327634442e-06,
      "loss": 0.1554,
      "step": 6009
    },
    {
      "epoch": 0.4670500466272925,
      "grad_norm": 0.19364164769649506,
      "learning_rate": 7.664749766863539e-06,
      "loss": 0.0732,
      "step": 6010
    },
    {
      "epoch": 0.46712775878147345,
      "grad_norm": 0.45056360960006714,
      "learning_rate": 7.664361206092632e-06,
      "loss": 0.1619,
      "step": 6011
    },
    {
      "epoch": 0.46720547093565434,
      "grad_norm": 0.21835674345493317,
      "learning_rate": 7.663972645321729e-06,
      "loss": 0.2373,
      "step": 6012
    },
    {
      "epoch": 0.46728318308983524,
      "grad_norm": 0.22956714034080505,
      "learning_rate": 7.663584084550824e-06,
      "loss": 0.0689,
      "step": 6013
    },
    {
      "epoch": 0.46736089524401614,
      "grad_norm": 0.1905064880847931,
      "learning_rate": 7.663195523779919e-06,
      "loss": 0.0859,
      "step": 6014
    },
    {
      "epoch": 0.4674386073981971,
      "grad_norm": 0.2105167955160141,
      "learning_rate": 7.662806963009015e-06,
      "loss": 0.0805,
      "step": 6015
    },
    {
      "epoch": 0.467516319552378,
      "grad_norm": 0.22830845415592194,
      "learning_rate": 7.66241840223811e-06,
      "loss": 0.0499,
      "step": 6016
    },
    {
      "epoch": 0.4675940317065589,
      "grad_norm": 0.2456602305173874,
      "learning_rate": 7.662029841467205e-06,
      "loss": 0.0436,
      "step": 6017
    },
    {
      "epoch": 0.46767174386073984,
      "grad_norm": 0.07776198536157608,
      "learning_rate": 7.661641280696302e-06,
      "loss": 0.04,
      "step": 6018
    },
    {
      "epoch": 0.46774945601492074,
      "grad_norm": 0.5009505748748779,
      "learning_rate": 7.661252719925397e-06,
      "loss": 0.3716,
      "step": 6019
    },
    {
      "epoch": 0.46782716816910164,
      "grad_norm": 0.08428385108709335,
      "learning_rate": 7.660864159154492e-06,
      "loss": 0.0199,
      "step": 6020
    },
    {
      "epoch": 0.46790488032328253,
      "grad_norm": 0.15466460585594177,
      "learning_rate": 7.660475598383587e-06,
      "loss": 0.0919,
      "step": 6021
    },
    {
      "epoch": 0.4679825924774635,
      "grad_norm": 0.3282579183578491,
      "learning_rate": 7.660087037612684e-06,
      "loss": 0.1683,
      "step": 6022
    },
    {
      "epoch": 0.4680603046316444,
      "grad_norm": 0.8245526552200317,
      "learning_rate": 7.659698476841778e-06,
      "loss": 0.1946,
      "step": 6023
    },
    {
      "epoch": 0.4681380167858253,
      "grad_norm": 0.10716897249221802,
      "learning_rate": 7.659309916070873e-06,
      "loss": 0.0211,
      "step": 6024
    },
    {
      "epoch": 0.46821572894000624,
      "grad_norm": 0.36061209440231323,
      "learning_rate": 7.65892135529997e-06,
      "loss": 0.1446,
      "step": 6025
    },
    {
      "epoch": 0.46829344109418714,
      "grad_norm": 0.22262835502624512,
      "learning_rate": 7.658532794529065e-06,
      "loss": 0.0921,
      "step": 6026
    },
    {
      "epoch": 0.46837115324836803,
      "grad_norm": 0.4407535195350647,
      "learning_rate": 7.65814423375816e-06,
      "loss": 0.7157,
      "step": 6027
    },
    {
      "epoch": 0.468448865402549,
      "grad_norm": 0.3395233154296875,
      "learning_rate": 7.657755672987257e-06,
      "loss": 0.1733,
      "step": 6028
    },
    {
      "epoch": 0.4685265775567299,
      "grad_norm": 0.5357279181480408,
      "learning_rate": 7.657367112216352e-06,
      "loss": 0.206,
      "step": 6029
    },
    {
      "epoch": 0.4686042897109108,
      "grad_norm": 1.0161570310592651,
      "learning_rate": 7.656978551445447e-06,
      "loss": 0.271,
      "step": 6030
    },
    {
      "epoch": 0.4686820018650917,
      "grad_norm": 0.2244245857000351,
      "learning_rate": 7.656589990674541e-06,
      "loss": 0.0887,
      "step": 6031
    },
    {
      "epoch": 0.46875971401927263,
      "grad_norm": 0.3254300355911255,
      "learning_rate": 7.656201429903638e-06,
      "loss": 0.1094,
      "step": 6032
    },
    {
      "epoch": 0.46883742617345353,
      "grad_norm": 0.6039347052574158,
      "learning_rate": 7.655812869132733e-06,
      "loss": 0.2613,
      "step": 6033
    },
    {
      "epoch": 0.46891513832763443,
      "grad_norm": 0.31450334191322327,
      "learning_rate": 7.655424308361828e-06,
      "loss": 0.0778,
      "step": 6034
    },
    {
      "epoch": 0.4689928504818154,
      "grad_norm": 0.4724292457103729,
      "learning_rate": 7.655035747590925e-06,
      "loss": 0.2493,
      "step": 6035
    },
    {
      "epoch": 0.4690705626359963,
      "grad_norm": 1.0958874225616455,
      "learning_rate": 7.65464718682002e-06,
      "loss": 0.3365,
      "step": 6036
    },
    {
      "epoch": 0.4691482747901772,
      "grad_norm": 0.537478506565094,
      "learning_rate": 7.654258626049115e-06,
      "loss": 0.2405,
      "step": 6037
    },
    {
      "epoch": 0.4692259869443581,
      "grad_norm": 0.7418683767318726,
      "learning_rate": 7.653870065278211e-06,
      "loss": 0.0621,
      "step": 6038
    },
    {
      "epoch": 0.46930369909853903,
      "grad_norm": 0.1072096973657608,
      "learning_rate": 7.653481504507304e-06,
      "loss": 0.0321,
      "step": 6039
    },
    {
      "epoch": 0.4693814112527199,
      "grad_norm": 1.027265191078186,
      "learning_rate": 7.653092943736401e-06,
      "loss": 0.2761,
      "step": 6040
    },
    {
      "epoch": 0.4694591234069008,
      "grad_norm": 0.16576698422431946,
      "learning_rate": 7.652704382965496e-06,
      "loss": 0.0808,
      "step": 6041
    },
    {
      "epoch": 0.4695368355610818,
      "grad_norm": 0.1920320987701416,
      "learning_rate": 7.652315822194591e-06,
      "loss": 0.0288,
      "step": 6042
    },
    {
      "epoch": 0.4696145477152627,
      "grad_norm": 0.24400998651981354,
      "learning_rate": 7.651927261423688e-06,
      "loss": 0.0857,
      "step": 6043
    },
    {
      "epoch": 0.4696922598694436,
      "grad_norm": 0.28679129481315613,
      "learning_rate": 7.651538700652783e-06,
      "loss": 0.0192,
      "step": 6044
    },
    {
      "epoch": 0.46976997202362447,
      "grad_norm": 0.3050583302974701,
      "learning_rate": 7.651150139881878e-06,
      "loss": 0.1262,
      "step": 6045
    },
    {
      "epoch": 0.4698476841778054,
      "grad_norm": 0.24542905390262604,
      "learning_rate": 7.650761579110974e-06,
      "loss": 0.1824,
      "step": 6046
    },
    {
      "epoch": 0.4699253963319863,
      "grad_norm": 0.39312925934791565,
      "learning_rate": 7.650373018340069e-06,
      "loss": 0.1792,
      "step": 6047
    },
    {
      "epoch": 0.4700031084861672,
      "grad_norm": 0.2792505919933319,
      "learning_rate": 7.649984457569164e-06,
      "loss": 0.492,
      "step": 6048
    },
    {
      "epoch": 0.4700808206403482,
      "grad_norm": 0.28301432728767395,
      "learning_rate": 7.649595896798259e-06,
      "loss": 0.1365,
      "step": 6049
    },
    {
      "epoch": 0.47015853279452907,
      "grad_norm": 0.4630777835845947,
      "learning_rate": 7.649207336027356e-06,
      "loss": 0.3857,
      "step": 6050
    },
    {
      "epoch": 0.47023624494870997,
      "grad_norm": 0.20732654631137848,
      "learning_rate": 7.64881877525645e-06,
      "loss": 0.111,
      "step": 6051
    },
    {
      "epoch": 0.47031395710289087,
      "grad_norm": 0.49691125750541687,
      "learning_rate": 7.648430214485546e-06,
      "loss": 0.2895,
      "step": 6052
    },
    {
      "epoch": 0.4703916692570718,
      "grad_norm": 2.6821258068084717,
      "learning_rate": 7.648041653714642e-06,
      "loss": 0.123,
      "step": 6053
    },
    {
      "epoch": 0.4704693814112527,
      "grad_norm": 8.533013343811035,
      "learning_rate": 7.647653092943737e-06,
      "loss": 2.6447,
      "step": 6054
    },
    {
      "epoch": 0.4705470935654336,
      "grad_norm": 0.4012466073036194,
      "learning_rate": 7.647264532172832e-06,
      "loss": 0.0871,
      "step": 6055
    },
    {
      "epoch": 0.47062480571961457,
      "grad_norm": 0.42372778058052063,
      "learning_rate": 7.646875971401929e-06,
      "loss": 0.2491,
      "step": 6056
    },
    {
      "epoch": 0.47070251787379547,
      "grad_norm": 0.624961793422699,
      "learning_rate": 7.646487410631024e-06,
      "loss": 0.3964,
      "step": 6057
    },
    {
      "epoch": 0.47078023002797637,
      "grad_norm": 0.1734859198331833,
      "learning_rate": 7.646098849860119e-06,
      "loss": 0.0536,
      "step": 6058
    },
    {
      "epoch": 0.47085794218215726,
      "grad_norm": 0.11536587029695511,
      "learning_rate": 7.645710289089214e-06,
      "loss": 0.0349,
      "step": 6059
    },
    {
      "epoch": 0.4709356543363382,
      "grad_norm": 0.19846278429031372,
      "learning_rate": 7.64532172831831e-06,
      "loss": 0.1334,
      "step": 6060
    },
    {
      "epoch": 0.4710133664905191,
      "grad_norm": 1.9370967149734497,
      "learning_rate": 7.644933167547405e-06,
      "loss": 0.1414,
      "step": 6061
    },
    {
      "epoch": 0.4710910786447,
      "grad_norm": 0.15632323920726776,
      "learning_rate": 7.6445446067765e-06,
      "loss": 0.0403,
      "step": 6062
    },
    {
      "epoch": 0.47116879079888097,
      "grad_norm": 0.12698718905448914,
      "learning_rate": 7.644156046005597e-06,
      "loss": 0.0328,
      "step": 6063
    },
    {
      "epoch": 0.47124650295306186,
      "grad_norm": 1.0203750133514404,
      "learning_rate": 7.643767485234692e-06,
      "loss": 0.4964,
      "step": 6064
    },
    {
      "epoch": 0.47132421510724276,
      "grad_norm": 0.19788624346256256,
      "learning_rate": 7.643378924463787e-06,
      "loss": 0.0791,
      "step": 6065
    },
    {
      "epoch": 0.4714019272614237,
      "grad_norm": 0.7573451399803162,
      "learning_rate": 7.642990363692883e-06,
      "loss": 0.5444,
      "step": 6066
    },
    {
      "epoch": 0.4714796394156046,
      "grad_norm": 0.2975744307041168,
      "learning_rate": 7.642601802921977e-06,
      "loss": 0.3793,
      "step": 6067
    },
    {
      "epoch": 0.4715573515697855,
      "grad_norm": 0.33327406644821167,
      "learning_rate": 7.642213242151073e-06,
      "loss": 0.2516,
      "step": 6068
    },
    {
      "epoch": 0.4716350637239664,
      "grad_norm": 0.4042165279388428,
      "learning_rate": 7.641824681380168e-06,
      "loss": 0.1996,
      "step": 6069
    },
    {
      "epoch": 0.47171277587814736,
      "grad_norm": 0.3493470251560211,
      "learning_rate": 7.641436120609263e-06,
      "loss": 0.0757,
      "step": 6070
    },
    {
      "epoch": 0.47179048803232826,
      "grad_norm": 0.23734445869922638,
      "learning_rate": 7.64104755983836e-06,
      "loss": 0.1047,
      "step": 6071
    },
    {
      "epoch": 0.47186820018650916,
      "grad_norm": 0.1056344285607338,
      "learning_rate": 7.640658999067455e-06,
      "loss": 0.0341,
      "step": 6072
    },
    {
      "epoch": 0.4719459123406901,
      "grad_norm": 0.5203769207000732,
      "learning_rate": 7.64027043829655e-06,
      "loss": 0.1608,
      "step": 6073
    },
    {
      "epoch": 0.472023624494871,
      "grad_norm": 0.05672352761030197,
      "learning_rate": 7.639881877525646e-06,
      "loss": 0.0138,
      "step": 6074
    },
    {
      "epoch": 0.4721013366490519,
      "grad_norm": 0.5685981512069702,
      "learning_rate": 7.639493316754741e-06,
      "loss": 0.5915,
      "step": 6075
    },
    {
      "epoch": 0.4721790488032328,
      "grad_norm": 0.6023061275482178,
      "learning_rate": 7.639104755983836e-06,
      "loss": 0.323,
      "step": 6076
    },
    {
      "epoch": 0.47225676095741376,
      "grad_norm": 0.3902325928211212,
      "learning_rate": 7.638716195212931e-06,
      "loss": 0.217,
      "step": 6077
    },
    {
      "epoch": 0.47233447311159465,
      "grad_norm": 0.7779473662376404,
      "learning_rate": 7.638327634442028e-06,
      "loss": 0.65,
      "step": 6078
    },
    {
      "epoch": 0.47241218526577555,
      "grad_norm": 0.18314418196678162,
      "learning_rate": 7.637939073671123e-06,
      "loss": 0.0972,
      "step": 6079
    },
    {
      "epoch": 0.4724898974199565,
      "grad_norm": 0.42616358399391174,
      "learning_rate": 7.637550512900218e-06,
      "loss": 0.1733,
      "step": 6080
    },
    {
      "epoch": 0.4725676095741374,
      "grad_norm": 0.20976559817790985,
      "learning_rate": 7.637161952129314e-06,
      "loss": 0.0732,
      "step": 6081
    },
    {
      "epoch": 0.4726453217283183,
      "grad_norm": 0.5279043316841125,
      "learning_rate": 7.63677339135841e-06,
      "loss": 0.8855,
      "step": 6082
    },
    {
      "epoch": 0.4727230338824992,
      "grad_norm": 0.322012722492218,
      "learning_rate": 7.636384830587504e-06,
      "loss": 0.1751,
      "step": 6083
    },
    {
      "epoch": 0.47280074603668015,
      "grad_norm": 0.21640124917030334,
      "learning_rate": 7.635996269816601e-06,
      "loss": 0.0611,
      "step": 6084
    },
    {
      "epoch": 0.47287845819086105,
      "grad_norm": 0.20693933963775635,
      "learning_rate": 7.635607709045696e-06,
      "loss": 0.0651,
      "step": 6085
    },
    {
      "epoch": 0.47295617034504195,
      "grad_norm": 0.11204572021961212,
      "learning_rate": 7.63521914827479e-06,
      "loss": 0.046,
      "step": 6086
    },
    {
      "epoch": 0.4730338824992229,
      "grad_norm": 0.8794181942939758,
      "learning_rate": 7.634830587503886e-06,
      "loss": 0.1905,
      "step": 6087
    },
    {
      "epoch": 0.4731115946534038,
      "grad_norm": 0.36792826652526855,
      "learning_rate": 7.634442026732982e-06,
      "loss": 0.3086,
      "step": 6088
    },
    {
      "epoch": 0.4731893068075847,
      "grad_norm": 0.0915125161409378,
      "learning_rate": 7.634053465962077e-06,
      "loss": 0.0534,
      "step": 6089
    },
    {
      "epoch": 0.4732670189617656,
      "grad_norm": 0.32806795835494995,
      "learning_rate": 7.633664905191172e-06,
      "loss": 0.1655,
      "step": 6090
    },
    {
      "epoch": 0.47334473111594655,
      "grad_norm": 0.45446717739105225,
      "learning_rate": 7.633276344420269e-06,
      "loss": 0.0848,
      "step": 6091
    },
    {
      "epoch": 0.47342244327012745,
      "grad_norm": 0.1345943808555603,
      "learning_rate": 7.632887783649364e-06,
      "loss": 0.0727,
      "step": 6092
    },
    {
      "epoch": 0.47350015542430834,
      "grad_norm": 0.28189021348953247,
      "learning_rate": 7.632499222878459e-06,
      "loss": 0.1803,
      "step": 6093
    },
    {
      "epoch": 0.4735778675784893,
      "grad_norm": 0.14507250487804413,
      "learning_rate": 7.632110662107555e-06,
      "loss": 0.0393,
      "step": 6094
    },
    {
      "epoch": 0.4736555797326702,
      "grad_norm": 0.24097280204296112,
      "learning_rate": 7.631722101336649e-06,
      "loss": 0.1979,
      "step": 6095
    },
    {
      "epoch": 0.4737332918868511,
      "grad_norm": 0.08515667915344238,
      "learning_rate": 7.631333540565745e-06,
      "loss": 0.0408,
      "step": 6096
    },
    {
      "epoch": 0.473811004041032,
      "grad_norm": 0.6448085308074951,
      "learning_rate": 7.63094497979484e-06,
      "loss": 0.3064,
      "step": 6097
    },
    {
      "epoch": 0.47388871619521294,
      "grad_norm": 0.08221354335546494,
      "learning_rate": 7.630556419023935e-06,
      "loss": 0.0636,
      "step": 6098
    },
    {
      "epoch": 0.47396642834939384,
      "grad_norm": 0.17480877041816711,
      "learning_rate": 7.630167858253032e-06,
      "loss": 0.0476,
      "step": 6099
    },
    {
      "epoch": 0.47404414050357474,
      "grad_norm": 0.9801283478736877,
      "learning_rate": 7.629779297482127e-06,
      "loss": 0.4729,
      "step": 6100
    },
    {
      "epoch": 0.4741218526577557,
      "grad_norm": 0.33123987913131714,
      "learning_rate": 7.629390736711222e-06,
      "loss": 0.1776,
      "step": 6101
    },
    {
      "epoch": 0.4741995648119366,
      "grad_norm": 0.7112501263618469,
      "learning_rate": 7.629002175940318e-06,
      "loss": 0.466,
      "step": 6102
    },
    {
      "epoch": 0.4742772769661175,
      "grad_norm": 0.39299702644348145,
      "learning_rate": 7.628613615169413e-06,
      "loss": 0.2345,
      "step": 6103
    },
    {
      "epoch": 0.4743549891202984,
      "grad_norm": 0.11698034405708313,
      "learning_rate": 7.628225054398508e-06,
      "loss": 0.0342,
      "step": 6104
    },
    {
      "epoch": 0.47443270127447934,
      "grad_norm": 0.4747954308986664,
      "learning_rate": 7.627836493627604e-06,
      "loss": 0.374,
      "step": 6105
    },
    {
      "epoch": 0.47451041342866024,
      "grad_norm": 0.45990118384361267,
      "learning_rate": 7.6274479328567e-06,
      "loss": 0.2309,
      "step": 6106
    },
    {
      "epoch": 0.47458812558284114,
      "grad_norm": 0.6809170246124268,
      "learning_rate": 7.627059372085794e-06,
      "loss": 0.2755,
      "step": 6107
    },
    {
      "epoch": 0.4746658377370221,
      "grad_norm": 0.12151064723730087,
      "learning_rate": 7.62667081131489e-06,
      "loss": 0.0332,
      "step": 6108
    },
    {
      "epoch": 0.474743549891203,
      "grad_norm": 0.47194239497184753,
      "learning_rate": 7.626282250543986e-06,
      "loss": 0.3461,
      "step": 6109
    },
    {
      "epoch": 0.4748212620453839,
      "grad_norm": 0.24084541201591492,
      "learning_rate": 7.625893689773081e-06,
      "loss": 0.0993,
      "step": 6110
    },
    {
      "epoch": 0.47489897419956484,
      "grad_norm": 0.1800742894411087,
      "learning_rate": 7.625505129002176e-06,
      "loss": 0.085,
      "step": 6111
    },
    {
      "epoch": 0.47497668635374574,
      "grad_norm": 0.37725844979286194,
      "learning_rate": 7.625116568231272e-06,
      "loss": 0.2683,
      "step": 6112
    },
    {
      "epoch": 0.47505439850792663,
      "grad_norm": 0.2988334000110626,
      "learning_rate": 7.624728007460367e-06,
      "loss": 0.1007,
      "step": 6113
    },
    {
      "epoch": 0.47513211066210753,
      "grad_norm": 0.3703744113445282,
      "learning_rate": 7.624339446689463e-06,
      "loss": 0.1266,
      "step": 6114
    },
    {
      "epoch": 0.4752098228162885,
      "grad_norm": 0.5491392612457275,
      "learning_rate": 7.623950885918559e-06,
      "loss": 0.2951,
      "step": 6115
    },
    {
      "epoch": 0.4752875349704694,
      "grad_norm": 0.5733228325843811,
      "learning_rate": 7.6235623251476545e-06,
      "loss": 0.4133,
      "step": 6116
    },
    {
      "epoch": 0.4753652471246503,
      "grad_norm": 0.18534721434116364,
      "learning_rate": 7.623173764376749e-06,
      "loss": 0.0395,
      "step": 6117
    },
    {
      "epoch": 0.47544295927883123,
      "grad_norm": 0.40907543897628784,
      "learning_rate": 7.6227852036058444e-06,
      "loss": 0.4842,
      "step": 6118
    },
    {
      "epoch": 0.47552067143301213,
      "grad_norm": 0.8734750747680664,
      "learning_rate": 7.62239664283494e-06,
      "loss": 0.6827,
      "step": 6119
    },
    {
      "epoch": 0.47559838358719303,
      "grad_norm": 0.3361126184463501,
      "learning_rate": 7.622008082064035e-06,
      "loss": 0.594,
      "step": 6120
    },
    {
      "epoch": 0.4756760957413739,
      "grad_norm": 0.8608564734458923,
      "learning_rate": 7.621619521293131e-06,
      "loss": 0.1098,
      "step": 6121
    },
    {
      "epoch": 0.4757538078955549,
      "grad_norm": 0.3261996805667877,
      "learning_rate": 7.621230960522227e-06,
      "loss": 0.2744,
      "step": 6122
    },
    {
      "epoch": 0.4758315200497358,
      "grad_norm": 0.7520728707313538,
      "learning_rate": 7.620842399751322e-06,
      "loss": 0.2548,
      "step": 6123
    },
    {
      "epoch": 0.4759092322039167,
      "grad_norm": 0.2807248532772064,
      "learning_rate": 7.6204538389804175e-06,
      "loss": 0.1417,
      "step": 6124
    },
    {
      "epoch": 0.47598694435809763,
      "grad_norm": 0.22564195096492767,
      "learning_rate": 7.620065278209513e-06,
      "loss": 0.1041,
      "step": 6125
    },
    {
      "epoch": 0.47606465651227853,
      "grad_norm": 0.20882785320281982,
      "learning_rate": 7.6196767174386074e-06,
      "loss": 0.1683,
      "step": 6126
    },
    {
      "epoch": 0.4761423686664594,
      "grad_norm": 0.5640479922294617,
      "learning_rate": 7.619288156667703e-06,
      "loss": 0.5598,
      "step": 6127
    },
    {
      "epoch": 0.4762200808206403,
      "grad_norm": 0.17164772748947144,
      "learning_rate": 7.618899595896799e-06,
      "loss": 0.1093,
      "step": 6128
    },
    {
      "epoch": 0.4762977929748213,
      "grad_norm": 0.240390345454216,
      "learning_rate": 7.618511035125894e-06,
      "loss": 0.1155,
      "step": 6129
    },
    {
      "epoch": 0.4763755051290022,
      "grad_norm": 0.239461287856102,
      "learning_rate": 7.61812247435499e-06,
      "loss": 0.045,
      "step": 6130
    },
    {
      "epoch": 0.4764532172831831,
      "grad_norm": 0.3004301190376282,
      "learning_rate": 7.6177339135840856e-06,
      "loss": 0.1557,
      "step": 6131
    },
    {
      "epoch": 0.476530929437364,
      "grad_norm": 0.3982793390750885,
      "learning_rate": 7.6173453528131805e-06,
      "loss": 0.3413,
      "step": 6132
    },
    {
      "epoch": 0.4766086415915449,
      "grad_norm": 0.1782611757516861,
      "learning_rate": 7.616956792042276e-06,
      "loss": 0.0454,
      "step": 6133
    },
    {
      "epoch": 0.4766863537457258,
      "grad_norm": 0.08908277004957199,
      "learning_rate": 7.616568231271372e-06,
      "loss": 0.0184,
      "step": 6134
    },
    {
      "epoch": 0.4767640658999067,
      "grad_norm": 0.4184317886829376,
      "learning_rate": 7.616179670500466e-06,
      "loss": 0.1734,
      "step": 6135
    },
    {
      "epoch": 0.4768417780540877,
      "grad_norm": 0.12819638848304749,
      "learning_rate": 7.615791109729562e-06,
      "loss": 0.037,
      "step": 6136
    },
    {
      "epoch": 0.47691949020826857,
      "grad_norm": 0.07792702317237854,
      "learning_rate": 7.615402548958658e-06,
      "loss": 0.0533,
      "step": 6137
    },
    {
      "epoch": 0.47699720236244947,
      "grad_norm": 0.4233514666557312,
      "learning_rate": 7.615013988187753e-06,
      "loss": 0.7263,
      "step": 6138
    },
    {
      "epoch": 0.4770749145166304,
      "grad_norm": 1.8152189254760742,
      "learning_rate": 7.6146254274168486e-06,
      "loss": 0.8538,
      "step": 6139
    },
    {
      "epoch": 0.4771526266708113,
      "grad_norm": 0.15058065950870514,
      "learning_rate": 7.614236866645944e-06,
      "loss": 0.0936,
      "step": 6140
    },
    {
      "epoch": 0.4772303388249922,
      "grad_norm": 0.33475372195243835,
      "learning_rate": 7.613848305875039e-06,
      "loss": 0.1037,
      "step": 6141
    },
    {
      "epoch": 0.4773080509791731,
      "grad_norm": 0.45632079243659973,
      "learning_rate": 7.613459745104135e-06,
      "loss": 0.2113,
      "step": 6142
    },
    {
      "epoch": 0.47738576313335407,
      "grad_norm": 0.5225318670272827,
      "learning_rate": 7.613071184333231e-06,
      "loss": 0.5752,
      "step": 6143
    },
    {
      "epoch": 0.47746347528753497,
      "grad_norm": 0.057733938097953796,
      "learning_rate": 7.612682623562325e-06,
      "loss": 0.0046,
      "step": 6144
    },
    {
      "epoch": 0.47754118744171586,
      "grad_norm": 0.358684241771698,
      "learning_rate": 7.612294062791421e-06,
      "loss": 0.1911,
      "step": 6145
    },
    {
      "epoch": 0.4776188995958968,
      "grad_norm": 0.26200705766677856,
      "learning_rate": 7.611905502020517e-06,
      "loss": 0.2498,
      "step": 6146
    },
    {
      "epoch": 0.4776966117500777,
      "grad_norm": 0.7036116719245911,
      "learning_rate": 7.611516941249612e-06,
      "loss": 0.2154,
      "step": 6147
    },
    {
      "epoch": 0.4777743239042586,
      "grad_norm": 0.26750844717025757,
      "learning_rate": 7.611128380478707e-06,
      "loss": 0.0996,
      "step": 6148
    },
    {
      "epoch": 0.47785203605843957,
      "grad_norm": 0.12094199657440186,
      "learning_rate": 7.610739819707803e-06,
      "loss": 0.0338,
      "step": 6149
    },
    {
      "epoch": 0.47792974821262046,
      "grad_norm": 0.4209313690662384,
      "learning_rate": 7.610351258936899e-06,
      "loss": 0.2233,
      "step": 6150
    },
    {
      "epoch": 0.47800746036680136,
      "grad_norm": 0.7401988506317139,
      "learning_rate": 7.609962698165994e-06,
      "loss": 0.3283,
      "step": 6151
    },
    {
      "epoch": 0.47808517252098226,
      "grad_norm": 0.2032146006822586,
      "learning_rate": 7.60957413739509e-06,
      "loss": 0.0622,
      "step": 6152
    },
    {
      "epoch": 0.4781628846751632,
      "grad_norm": 0.040659349411726,
      "learning_rate": 7.6091855766241855e-06,
      "loss": 0.0064,
      "step": 6153
    },
    {
      "epoch": 0.4782405968293441,
      "grad_norm": 0.687038004398346,
      "learning_rate": 7.6087970158532796e-06,
      "loss": 0.4421,
      "step": 6154
    },
    {
      "epoch": 0.478318308983525,
      "grad_norm": 0.07923758029937744,
      "learning_rate": 7.608408455082375e-06,
      "loss": 0.0368,
      "step": 6155
    },
    {
      "epoch": 0.47839602113770596,
      "grad_norm": 0.10996166616678238,
      "learning_rate": 7.608019894311471e-06,
      "loss": 0.0468,
      "step": 6156
    },
    {
      "epoch": 0.47847373329188686,
      "grad_norm": 0.40292468667030334,
      "learning_rate": 7.607631333540566e-06,
      "loss": 0.3424,
      "step": 6157
    },
    {
      "epoch": 0.47855144544606776,
      "grad_norm": 0.3998274505138397,
      "learning_rate": 7.607242772769662e-06,
      "loss": 0.0861,
      "step": 6158
    },
    {
      "epoch": 0.47862915760024866,
      "grad_norm": 0.4686291217803955,
      "learning_rate": 7.606854211998758e-06,
      "loss": 0.2068,
      "step": 6159
    },
    {
      "epoch": 0.4787068697544296,
      "grad_norm": 0.3903198540210724,
      "learning_rate": 7.606465651227853e-06,
      "loss": 0.1053,
      "step": 6160
    },
    {
      "epoch": 0.4787845819086105,
      "grad_norm": 0.2838238477706909,
      "learning_rate": 7.6060770904569485e-06,
      "loss": 0.1042,
      "step": 6161
    },
    {
      "epoch": 0.4788622940627914,
      "grad_norm": 0.20682187378406525,
      "learning_rate": 7.605688529686044e-06,
      "loss": 0.085,
      "step": 6162
    },
    {
      "epoch": 0.47894000621697236,
      "grad_norm": 0.23111078143119812,
      "learning_rate": 7.605299968915138e-06,
      "loss": 0.135,
      "step": 6163
    },
    {
      "epoch": 0.47901771837115326,
      "grad_norm": 0.4449721872806549,
      "learning_rate": 7.604911408144234e-06,
      "loss": 0.1429,
      "step": 6164
    },
    {
      "epoch": 0.47909543052533415,
      "grad_norm": 0.3158448040485382,
      "learning_rate": 7.60452284737333e-06,
      "loss": 0.1443,
      "step": 6165
    },
    {
      "epoch": 0.47917314267951505,
      "grad_norm": 0.4799635112285614,
      "learning_rate": 7.604134286602425e-06,
      "loss": 0.2276,
      "step": 6166
    },
    {
      "epoch": 0.479250854833696,
      "grad_norm": 0.23969215154647827,
      "learning_rate": 7.603745725831521e-06,
      "loss": 0.0528,
      "step": 6167
    },
    {
      "epoch": 0.4793285669878769,
      "grad_norm": 0.8861228227615356,
      "learning_rate": 7.6033571650606165e-06,
      "loss": 0.5673,
      "step": 6168
    },
    {
      "epoch": 0.4794062791420578,
      "grad_norm": 0.49626895785331726,
      "learning_rate": 7.6029686042897114e-06,
      "loss": 0.1241,
      "step": 6169
    },
    {
      "epoch": 0.47948399129623875,
      "grad_norm": 0.19828353822231293,
      "learning_rate": 7.602580043518807e-06,
      "loss": 0.0762,
      "step": 6170
    },
    {
      "epoch": 0.47956170345041965,
      "grad_norm": 0.1252165585756302,
      "learning_rate": 7.602191482747903e-06,
      "loss": 0.056,
      "step": 6171
    },
    {
      "epoch": 0.47963941560460055,
      "grad_norm": 0.3483944535255432,
      "learning_rate": 7.601802921976997e-06,
      "loss": 0.0622,
      "step": 6172
    },
    {
      "epoch": 0.47971712775878145,
      "grad_norm": 0.1230781078338623,
      "learning_rate": 7.601414361206093e-06,
      "loss": 0.0434,
      "step": 6173
    },
    {
      "epoch": 0.4797948399129624,
      "grad_norm": 0.713163435459137,
      "learning_rate": 7.601025800435189e-06,
      "loss": 0.5985,
      "step": 6174
    },
    {
      "epoch": 0.4798725520671433,
      "grad_norm": 0.6306192278862,
      "learning_rate": 7.600637239664284e-06,
      "loss": 0.1908,
      "step": 6175
    },
    {
      "epoch": 0.4799502642213242,
      "grad_norm": 0.21132126450538635,
      "learning_rate": 7.6002486788933795e-06,
      "loss": 0.0695,
      "step": 6176
    },
    {
      "epoch": 0.48002797637550515,
      "grad_norm": 0.10595781356096268,
      "learning_rate": 7.599860118122475e-06,
      "loss": 0.0302,
      "step": 6177
    },
    {
      "epoch": 0.48010568852968605,
      "grad_norm": 0.11918046325445175,
      "learning_rate": 7.599471557351571e-06,
      "loss": 0.0202,
      "step": 6178
    },
    {
      "epoch": 0.48018340068386695,
      "grad_norm": 0.1778651773929596,
      "learning_rate": 7.599082996580666e-06,
      "loss": 0.0738,
      "step": 6179
    },
    {
      "epoch": 0.48026111283804784,
      "grad_norm": 0.3108411729335785,
      "learning_rate": 7.598694435809762e-06,
      "loss": 0.3479,
      "step": 6180
    },
    {
      "epoch": 0.4803388249922288,
      "grad_norm": 0.20151816308498383,
      "learning_rate": 7.598305875038857e-06,
      "loss": 0.0875,
      "step": 6181
    },
    {
      "epoch": 0.4804165371464097,
      "grad_norm": 0.798265278339386,
      "learning_rate": 7.597917314267952e-06,
      "loss": 0.375,
      "step": 6182
    },
    {
      "epoch": 0.4804942493005906,
      "grad_norm": 0.8248039484024048,
      "learning_rate": 7.5975287534970475e-06,
      "loss": 0.2941,
      "step": 6183
    },
    {
      "epoch": 0.48057196145477155,
      "grad_norm": 0.28180164098739624,
      "learning_rate": 7.597140192726143e-06,
      "loss": 0.0626,
      "step": 6184
    },
    {
      "epoch": 0.48064967360895244,
      "grad_norm": 0.5293457508087158,
      "learning_rate": 7.596751631955238e-06,
      "loss": 0.1607,
      "step": 6185
    },
    {
      "epoch": 0.48072738576313334,
      "grad_norm": 0.22840654850006104,
      "learning_rate": 7.596363071184334e-06,
      "loss": 0.0981,
      "step": 6186
    },
    {
      "epoch": 0.4808050979173143,
      "grad_norm": 0.2897127568721771,
      "learning_rate": 7.59597451041343e-06,
      "loss": 0.1085,
      "step": 6187
    },
    {
      "epoch": 0.4808828100714952,
      "grad_norm": 0.48643526434898376,
      "learning_rate": 7.595585949642524e-06,
      "loss": 0.2559,
      "step": 6188
    },
    {
      "epoch": 0.4809605222256761,
      "grad_norm": 0.7331008315086365,
      "learning_rate": 7.59519738887162e-06,
      "loss": 0.9431,
      "step": 6189
    },
    {
      "epoch": 0.481038234379857,
      "grad_norm": 0.07534711807966232,
      "learning_rate": 7.5948088281007156e-06,
      "loss": 0.0255,
      "step": 6190
    },
    {
      "epoch": 0.48111594653403794,
      "grad_norm": 0.3369947373867035,
      "learning_rate": 7.5944202673298105e-06,
      "loss": 0.0693,
      "step": 6191
    },
    {
      "epoch": 0.48119365868821884,
      "grad_norm": 0.19912280142307281,
      "learning_rate": 7.594031706558906e-06,
      "loss": 0.0379,
      "step": 6192
    },
    {
      "epoch": 0.48127137084239974,
      "grad_norm": 0.5467541813850403,
      "learning_rate": 7.593643145788002e-06,
      "loss": 0.3994,
      "step": 6193
    },
    {
      "epoch": 0.4813490829965807,
      "grad_norm": 0.22594542801380157,
      "learning_rate": 7.593254585017097e-06,
      "loss": 0.0521,
      "step": 6194
    },
    {
      "epoch": 0.4814267951507616,
      "grad_norm": 0.46389755606651306,
      "learning_rate": 7.592866024246193e-06,
      "loss": 0.0865,
      "step": 6195
    },
    {
      "epoch": 0.4815045073049425,
      "grad_norm": 1.4879000186920166,
      "learning_rate": 7.592477463475289e-06,
      "loss": 1.0268,
      "step": 6196
    },
    {
      "epoch": 0.4815822194591234,
      "grad_norm": 0.12023302912712097,
      "learning_rate": 7.592088902704383e-06,
      "loss": 0.0457,
      "step": 6197
    },
    {
      "epoch": 0.48165993161330434,
      "grad_norm": 0.7168689370155334,
      "learning_rate": 7.5917003419334785e-06,
      "loss": 0.2184,
      "step": 6198
    },
    {
      "epoch": 0.48173764376748524,
      "grad_norm": 0.2683701813220978,
      "learning_rate": 7.591311781162574e-06,
      "loss": 0.1887,
      "step": 6199
    },
    {
      "epoch": 0.48181535592166613,
      "grad_norm": 0.5129011869430542,
      "learning_rate": 7.590923220391669e-06,
      "loss": 0.1662,
      "step": 6200
    },
    {
      "epoch": 0.4818930680758471,
      "grad_norm": 1.0808135271072388,
      "learning_rate": 7.590534659620765e-06,
      "loss": 0.5554,
      "step": 6201
    },
    {
      "epoch": 0.481970780230028,
      "grad_norm": 0.2888089716434479,
      "learning_rate": 7.590146098849861e-06,
      "loss": 0.0493,
      "step": 6202
    },
    {
      "epoch": 0.4820484923842089,
      "grad_norm": 0.16167253255844116,
      "learning_rate": 7.589757538078956e-06,
      "loss": 0.0376,
      "step": 6203
    },
    {
      "epoch": 0.4821262045383898,
      "grad_norm": 0.2550380825996399,
      "learning_rate": 7.589368977308052e-06,
      "loss": 0.1542,
      "step": 6204
    },
    {
      "epoch": 0.48220391669257073,
      "grad_norm": 0.3665831685066223,
      "learning_rate": 7.5889804165371474e-06,
      "loss": 0.1533,
      "step": 6205
    },
    {
      "epoch": 0.48228162884675163,
      "grad_norm": 0.32671254873275757,
      "learning_rate": 7.5885918557662415e-06,
      "loss": 0.118,
      "step": 6206
    },
    {
      "epoch": 0.48235934100093253,
      "grad_norm": 0.5440211296081543,
      "learning_rate": 7.588203294995337e-06,
      "loss": 0.4984,
      "step": 6207
    },
    {
      "epoch": 0.4824370531551135,
      "grad_norm": 0.4229818880558014,
      "learning_rate": 7.587814734224433e-06,
      "loss": 0.1696,
      "step": 6208
    },
    {
      "epoch": 0.4825147653092944,
      "grad_norm": 0.3775857090950012,
      "learning_rate": 7.587426173453529e-06,
      "loss": 0.1331,
      "step": 6209
    },
    {
      "epoch": 0.4825924774634753,
      "grad_norm": 0.4002828598022461,
      "learning_rate": 7.587037612682624e-06,
      "loss": 0.122,
      "step": 6210
    },
    {
      "epoch": 0.4826701896176562,
      "grad_norm": 0.6432350873947144,
      "learning_rate": 7.58664905191172e-06,
      "loss": 0.2978,
      "step": 6211
    },
    {
      "epoch": 0.48274790177183713,
      "grad_norm": 0.4196672737598419,
      "learning_rate": 7.5862604911408155e-06,
      "loss": 0.2527,
      "step": 6212
    },
    {
      "epoch": 0.482825613926018,
      "grad_norm": 0.4197159707546234,
      "learning_rate": 7.58587193036991e-06,
      "loss": 0.2235,
      "step": 6213
    },
    {
      "epoch": 0.4829033260801989,
      "grad_norm": 0.9118462204933167,
      "learning_rate": 7.585483369599006e-06,
      "loss": 0.5979,
      "step": 6214
    },
    {
      "epoch": 0.4829810382343799,
      "grad_norm": 0.15405429899692535,
      "learning_rate": 7.585094808828102e-06,
      "loss": 0.0531,
      "step": 6215
    },
    {
      "epoch": 0.4830587503885608,
      "grad_norm": 0.14309941232204437,
      "learning_rate": 7.584706248057196e-06,
      "loss": 0.2254,
      "step": 6216
    },
    {
      "epoch": 0.4831364625427417,
      "grad_norm": 0.08383580297231674,
      "learning_rate": 7.584317687286292e-06,
      "loss": 0.0209,
      "step": 6217
    },
    {
      "epoch": 0.48321417469692257,
      "grad_norm": 0.32194074988365173,
      "learning_rate": 7.583929126515388e-06,
      "loss": 0.0819,
      "step": 6218
    },
    {
      "epoch": 0.4832918868511035,
      "grad_norm": 0.10055040568113327,
      "learning_rate": 7.583540565744483e-06,
      "loss": 0.029,
      "step": 6219
    },
    {
      "epoch": 0.4833695990052844,
      "grad_norm": 0.552699863910675,
      "learning_rate": 7.5831520049735784e-06,
      "loss": 0.2791,
      "step": 6220
    },
    {
      "epoch": 0.4834473111594653,
      "grad_norm": 0.08326839655637741,
      "learning_rate": 7.582763444202674e-06,
      "loss": 0.0246,
      "step": 6221
    },
    {
      "epoch": 0.4835250233136463,
      "grad_norm": 0.4975249171257019,
      "learning_rate": 7.582374883431769e-06,
      "loss": 0.2017,
      "step": 6222
    },
    {
      "epoch": 0.48360273546782717,
      "grad_norm": 0.0661407932639122,
      "learning_rate": 7.581986322660865e-06,
      "loss": 0.0151,
      "step": 6223
    },
    {
      "epoch": 0.48368044762200807,
      "grad_norm": 0.4224126636981964,
      "learning_rate": 7.581597761889961e-06,
      "loss": 0.1493,
      "step": 6224
    },
    {
      "epoch": 0.483758159776189,
      "grad_norm": 0.38320687413215637,
      "learning_rate": 7.581209201119055e-06,
      "loss": 0.212,
      "step": 6225
    },
    {
      "epoch": 0.4838358719303699,
      "grad_norm": 0.38906916975975037,
      "learning_rate": 7.580820640348151e-06,
      "loss": 0.234,
      "step": 6226
    },
    {
      "epoch": 0.4839135840845508,
      "grad_norm": 0.5685698390007019,
      "learning_rate": 7.5804320795772465e-06,
      "loss": 0.3871,
      "step": 6227
    },
    {
      "epoch": 0.4839912962387317,
      "grad_norm": 0.0854402557015419,
      "learning_rate": 7.5800435188063414e-06,
      "loss": 0.0119,
      "step": 6228
    },
    {
      "epoch": 0.48406900839291267,
      "grad_norm": 0.40703701972961426,
      "learning_rate": 7.579654958035437e-06,
      "loss": 0.1459,
      "step": 6229
    },
    {
      "epoch": 0.48414672054709357,
      "grad_norm": 0.055824413895606995,
      "learning_rate": 7.579266397264533e-06,
      "loss": 0.0135,
      "step": 6230
    },
    {
      "epoch": 0.48422443270127447,
      "grad_norm": 0.22050528228282928,
      "learning_rate": 7.578877836493628e-06,
      "loss": 0.1547,
      "step": 6231
    },
    {
      "epoch": 0.4843021448554554,
      "grad_norm": 0.23705892264842987,
      "learning_rate": 7.578489275722724e-06,
      "loss": 0.0648,
      "step": 6232
    },
    {
      "epoch": 0.4843798570096363,
      "grad_norm": 0.23516906797885895,
      "learning_rate": 7.5781007149518196e-06,
      "loss": 0.1006,
      "step": 6233
    },
    {
      "epoch": 0.4844575691638172,
      "grad_norm": 0.22011706233024597,
      "learning_rate": 7.577712154180914e-06,
      "loss": 0.1155,
      "step": 6234
    },
    {
      "epoch": 0.4845352813179981,
      "grad_norm": 0.22971218824386597,
      "learning_rate": 7.5773235934100095e-06,
      "loss": 0.1205,
      "step": 6235
    },
    {
      "epoch": 0.48461299347217907,
      "grad_norm": 0.1714678704738617,
      "learning_rate": 7.576935032639105e-06,
      "loss": 0.1143,
      "step": 6236
    },
    {
      "epoch": 0.48469070562635996,
      "grad_norm": 0.2555576264858246,
      "learning_rate": 7.576546471868201e-06,
      "loss": 0.129,
      "step": 6237
    },
    {
      "epoch": 0.48476841778054086,
      "grad_norm": 0.32286447286605835,
      "learning_rate": 7.576157911097296e-06,
      "loss": 0.1052,
      "step": 6238
    },
    {
      "epoch": 0.4848461299347218,
      "grad_norm": 0.498712420463562,
      "learning_rate": 7.575769350326392e-06,
      "loss": 0.1156,
      "step": 6239
    },
    {
      "epoch": 0.4849238420889027,
      "grad_norm": 0.11278186738491058,
      "learning_rate": 7.575380789555488e-06,
      "loss": 0.0147,
      "step": 6240
    },
    {
      "epoch": 0.4850015542430836,
      "grad_norm": 0.15788350999355316,
      "learning_rate": 7.5749922287845826e-06,
      "loss": 0.2454,
      "step": 6241
    },
    {
      "epoch": 0.4850792663972645,
      "grad_norm": 0.598854660987854,
      "learning_rate": 7.574603668013678e-06,
      "loss": 0.4129,
      "step": 6242
    },
    {
      "epoch": 0.48515697855144546,
      "grad_norm": 0.05223334953188896,
      "learning_rate": 7.574215107242774e-06,
      "loss": 0.0141,
      "step": 6243
    },
    {
      "epoch": 0.48523469070562636,
      "grad_norm": 0.39190641045570374,
      "learning_rate": 7.573826546471868e-06,
      "loss": 0.2386,
      "step": 6244
    },
    {
      "epoch": 0.48531240285980726,
      "grad_norm": 0.3118574023246765,
      "learning_rate": 7.573437985700964e-06,
      "loss": 0.3136,
      "step": 6245
    },
    {
      "epoch": 0.4853901150139882,
      "grad_norm": 0.3052201271057129,
      "learning_rate": 7.57304942493006e-06,
      "loss": 0.1029,
      "step": 6246
    },
    {
      "epoch": 0.4854678271681691,
      "grad_norm": 0.403158962726593,
      "learning_rate": 7.572660864159155e-06,
      "loss": 0.134,
      "step": 6247
    },
    {
      "epoch": 0.48554553932235,
      "grad_norm": 0.15527857840061188,
      "learning_rate": 7.572272303388251e-06,
      "loss": 0.0453,
      "step": 6248
    },
    {
      "epoch": 0.4856232514765309,
      "grad_norm": 0.08421052247285843,
      "learning_rate": 7.571883742617346e-06,
      "loss": 0.0228,
      "step": 6249
    },
    {
      "epoch": 0.48570096363071186,
      "grad_norm": 0.3069544732570648,
      "learning_rate": 7.571495181846441e-06,
      "loss": 0.2245,
      "step": 6250
    },
    {
      "epoch": 0.48577867578489276,
      "grad_norm": 0.2495078444480896,
      "learning_rate": 7.571106621075537e-06,
      "loss": 0.1715,
      "step": 6251
    },
    {
      "epoch": 0.48585638793907365,
      "grad_norm": 0.3439858853816986,
      "learning_rate": 7.570718060304633e-06,
      "loss": 0.5512,
      "step": 6252
    },
    {
      "epoch": 0.4859341000932546,
      "grad_norm": 0.23793751001358032,
      "learning_rate": 7.570329499533727e-06,
      "loss": 0.0882,
      "step": 6253
    },
    {
      "epoch": 0.4860118122474355,
      "grad_norm": 0.22097530961036682,
      "learning_rate": 7.569940938762823e-06,
      "loss": 0.0621,
      "step": 6254
    },
    {
      "epoch": 0.4860895244016164,
      "grad_norm": 0.302570641040802,
      "learning_rate": 7.569552377991919e-06,
      "loss": 0.0728,
      "step": 6255
    },
    {
      "epoch": 0.4861672365557973,
      "grad_norm": 0.1585383266210556,
      "learning_rate": 7.569163817221014e-06,
      "loss": 0.0598,
      "step": 6256
    },
    {
      "epoch": 0.48624494870997825,
      "grad_norm": 0.415377140045166,
      "learning_rate": 7.568775256450109e-06,
      "loss": 0.1098,
      "step": 6257
    },
    {
      "epoch": 0.48632266086415915,
      "grad_norm": 0.2584080696105957,
      "learning_rate": 7.568386695679205e-06,
      "loss": 0.1916,
      "step": 6258
    },
    {
      "epoch": 0.48640037301834005,
      "grad_norm": 0.8263434171676636,
      "learning_rate": 7.5679981349083e-06,
      "loss": 0.3932,
      "step": 6259
    },
    {
      "epoch": 0.486478085172521,
      "grad_norm": 0.4962102472782135,
      "learning_rate": 7.567609574137396e-06,
      "loss": 0.2729,
      "step": 6260
    },
    {
      "epoch": 0.4865557973267019,
      "grad_norm": 0.0645759105682373,
      "learning_rate": 7.567221013366492e-06,
      "loss": 0.0311,
      "step": 6261
    },
    {
      "epoch": 0.4866335094808828,
      "grad_norm": 0.5762884616851807,
      "learning_rate": 7.566832452595586e-06,
      "loss": 0.1653,
      "step": 6262
    },
    {
      "epoch": 0.48671122163506375,
      "grad_norm": 0.4379007816314697,
      "learning_rate": 7.566443891824682e-06,
      "loss": 0.1866,
      "step": 6263
    },
    {
      "epoch": 0.48678893378924465,
      "grad_norm": 0.24030575156211853,
      "learning_rate": 7.566055331053777e-06,
      "loss": 0.1504,
      "step": 6264
    },
    {
      "epoch": 0.48686664594342555,
      "grad_norm": 0.2537068724632263,
      "learning_rate": 7.565666770282872e-06,
      "loss": 0.0855,
      "step": 6265
    },
    {
      "epoch": 0.48694435809760644,
      "grad_norm": 0.5885174870491028,
      "learning_rate": 7.565278209511968e-06,
      "loss": 0.4265,
      "step": 6266
    },
    {
      "epoch": 0.4870220702517874,
      "grad_norm": 0.7781051397323608,
      "learning_rate": 7.564889648741064e-06,
      "loss": 0.4897,
      "step": 6267
    },
    {
      "epoch": 0.4870997824059683,
      "grad_norm": 0.10130562633275986,
      "learning_rate": 7.56450108797016e-06,
      "loss": 0.018,
      "step": 6268
    },
    {
      "epoch": 0.4871774945601492,
      "grad_norm": 0.5387492775917053,
      "learning_rate": 7.564112527199255e-06,
      "loss": 0.2865,
      "step": 6269
    },
    {
      "epoch": 0.48725520671433015,
      "grad_norm": 0.3945004343986511,
      "learning_rate": 7.5637239664283505e-06,
      "loss": 0.1683,
      "step": 6270
    },
    {
      "epoch": 0.48733291886851104,
      "grad_norm": 0.21279199421405792,
      "learning_rate": 7.563335405657446e-06,
      "loss": 0.0237,
      "step": 6271
    },
    {
      "epoch": 0.48741063102269194,
      "grad_norm": 0.4454955756664276,
      "learning_rate": 7.56294684488654e-06,
      "loss": 0.2385,
      "step": 6272
    },
    {
      "epoch": 0.48748834317687284,
      "grad_norm": 0.2605464458465576,
      "learning_rate": 7.562558284115636e-06,
      "loss": 0.0917,
      "step": 6273
    },
    {
      "epoch": 0.4875660553310538,
      "grad_norm": 0.22761638462543488,
      "learning_rate": 7.562169723344732e-06,
      "loss": 0.1388,
      "step": 6274
    },
    {
      "epoch": 0.4876437674852347,
      "grad_norm": 0.00808383896946907,
      "learning_rate": 7.561781162573827e-06,
      "loss": 0.0022,
      "step": 6275
    },
    {
      "epoch": 0.4877214796394156,
      "grad_norm": 0.24472571909427643,
      "learning_rate": 7.561392601802923e-06,
      "loss": 0.1631,
      "step": 6276
    },
    {
      "epoch": 0.48779919179359654,
      "grad_norm": 1.5868641138076782,
      "learning_rate": 7.5610040410320185e-06,
      "loss": 0.8014,
      "step": 6277
    },
    {
      "epoch": 0.48787690394777744,
      "grad_norm": 0.50105220079422,
      "learning_rate": 7.5606154802611135e-06,
      "loss": 0.2369,
      "step": 6278
    },
    {
      "epoch": 0.48795461610195834,
      "grad_norm": 0.2973394989967346,
      "learning_rate": 7.560226919490209e-06,
      "loss": 0.1217,
      "step": 6279
    },
    {
      "epoch": 0.48803232825613924,
      "grad_norm": 0.4656396806240082,
      "learning_rate": 7.559838358719305e-06,
      "loss": 0.1784,
      "step": 6280
    },
    {
      "epoch": 0.4881100404103202,
      "grad_norm": 0.19680476188659668,
      "learning_rate": 7.559449797948399e-06,
      "loss": 0.0836,
      "step": 6281
    },
    {
      "epoch": 0.4881877525645011,
      "grad_norm": 0.4582827389240265,
      "learning_rate": 7.559061237177495e-06,
      "loss": 0.1865,
      "step": 6282
    },
    {
      "epoch": 0.488265464718682,
      "grad_norm": 0.5592995882034302,
      "learning_rate": 7.558672676406591e-06,
      "loss": 0.4553,
      "step": 6283
    },
    {
      "epoch": 0.48834317687286294,
      "grad_norm": 0.4389652609825134,
      "learning_rate": 7.558284115635686e-06,
      "loss": 0.5236,
      "step": 6284
    },
    {
      "epoch": 0.48842088902704384,
      "grad_norm": 0.10795710980892181,
      "learning_rate": 7.5578955548647815e-06,
      "loss": 0.054,
      "step": 6285
    },
    {
      "epoch": 0.48849860118122473,
      "grad_norm": 0.8215603828430176,
      "learning_rate": 7.557506994093877e-06,
      "loss": 0.377,
      "step": 6286
    },
    {
      "epoch": 0.48857631333540563,
      "grad_norm": 0.6411195397377014,
      "learning_rate": 7.557118433322972e-06,
      "loss": 0.2726,
      "step": 6287
    },
    {
      "epoch": 0.4886540254895866,
      "grad_norm": 0.7911441922187805,
      "learning_rate": 7.556729872552068e-06,
      "loss": 0.5205,
      "step": 6288
    },
    {
      "epoch": 0.4887317376437675,
      "grad_norm": 0.7352065443992615,
      "learning_rate": 7.556341311781164e-06,
      "loss": 0.1581,
      "step": 6289
    },
    {
      "epoch": 0.4888094497979484,
      "grad_norm": 0.07660841941833496,
      "learning_rate": 7.555952751010258e-06,
      "loss": 0.0192,
      "step": 6290
    },
    {
      "epoch": 0.48888716195212933,
      "grad_norm": 0.3884487450122833,
      "learning_rate": 7.555564190239354e-06,
      "loss": 0.2568,
      "step": 6291
    },
    {
      "epoch": 0.48896487410631023,
      "grad_norm": 0.5654793977737427,
      "learning_rate": 7.5551756294684496e-06,
      "loss": 0.4586,
      "step": 6292
    },
    {
      "epoch": 0.48904258626049113,
      "grad_norm": 1.0328551530838013,
      "learning_rate": 7.5547870686975445e-06,
      "loss": 0.0612,
      "step": 6293
    },
    {
      "epoch": 0.48912029841467203,
      "grad_norm": 0.2925252616405487,
      "learning_rate": 7.55439850792664e-06,
      "loss": 0.1539,
      "step": 6294
    },
    {
      "epoch": 0.489198010568853,
      "grad_norm": 0.33271127939224243,
      "learning_rate": 7.554009947155736e-06,
      "loss": 0.1002,
      "step": 6295
    },
    {
      "epoch": 0.4892757227230339,
      "grad_norm": 0.2459917664527893,
      "learning_rate": 7.553621386384831e-06,
      "loss": 0.1548,
      "step": 6296
    },
    {
      "epoch": 0.4893534348772148,
      "grad_norm": 0.3644295334815979,
      "learning_rate": 7.553232825613927e-06,
      "loss": 0.3475,
      "step": 6297
    },
    {
      "epoch": 0.48943114703139573,
      "grad_norm": 0.17672099173069,
      "learning_rate": 7.552844264843023e-06,
      "loss": 0.0323,
      "step": 6298
    },
    {
      "epoch": 0.48950885918557663,
      "grad_norm": 0.3656955063343048,
      "learning_rate": 7.5524557040721184e-06,
      "loss": 0.2437,
      "step": 6299
    },
    {
      "epoch": 0.4895865713397575,
      "grad_norm": 0.6641601920127869,
      "learning_rate": 7.5520671433012125e-06,
      "loss": 0.1964,
      "step": 6300
    },
    {
      "epoch": 0.4896642834939385,
      "grad_norm": 0.2132704257965088,
      "learning_rate": 7.551678582530308e-06,
      "loss": 0.0455,
      "step": 6301
    },
    {
      "epoch": 0.4897419956481194,
      "grad_norm": 0.5599313378334045,
      "learning_rate": 7.551290021759404e-06,
      "loss": 0.1899,
      "step": 6302
    },
    {
      "epoch": 0.4898197078023003,
      "grad_norm": 0.237041175365448,
      "learning_rate": 7.550901460988499e-06,
      "loss": 0.2622,
      "step": 6303
    },
    {
      "epoch": 0.4898974199564812,
      "grad_norm": 0.23249590396881104,
      "learning_rate": 7.550512900217595e-06,
      "loss": 0.156,
      "step": 6304
    },
    {
      "epoch": 0.4899751321106621,
      "grad_norm": 0.3408096134662628,
      "learning_rate": 7.550124339446691e-06,
      "loss": 0.1868,
      "step": 6305
    },
    {
      "epoch": 0.490052844264843,
      "grad_norm": 0.18730570375919342,
      "learning_rate": 7.549735778675786e-06,
      "loss": 0.1226,
      "step": 6306
    },
    {
      "epoch": 0.4901305564190239,
      "grad_norm": 0.6419654488563538,
      "learning_rate": 7.5493472179048814e-06,
      "loss": 0.1991,
      "step": 6307
    },
    {
      "epoch": 0.4902082685732049,
      "grad_norm": 0.14978568255901337,
      "learning_rate": 7.548958657133976e-06,
      "loss": 0.0337,
      "step": 6308
    },
    {
      "epoch": 0.4902859807273858,
      "grad_norm": 0.6890478730201721,
      "learning_rate": 7.548570096363071e-06,
      "loss": 0.3541,
      "step": 6309
    },
    {
      "epoch": 0.49036369288156667,
      "grad_norm": 0.3337981700897217,
      "learning_rate": 7.548181535592167e-06,
      "loss": 0.1435,
      "step": 6310
    },
    {
      "epoch": 0.49044140503574757,
      "grad_norm": 0.3151499330997467,
      "learning_rate": 7.547792974821263e-06,
      "loss": 0.1877,
      "step": 6311
    },
    {
      "epoch": 0.4905191171899285,
      "grad_norm": 0.5384941101074219,
      "learning_rate": 7.547404414050358e-06,
      "loss": 0.6751,
      "step": 6312
    },
    {
      "epoch": 0.4905968293441094,
      "grad_norm": 0.14399535953998566,
      "learning_rate": 7.547015853279454e-06,
      "loss": 0.0824,
      "step": 6313
    },
    {
      "epoch": 0.4906745414982903,
      "grad_norm": 0.21086685359477997,
      "learning_rate": 7.5466272925085495e-06,
      "loss": 0.1054,
      "step": 6314
    },
    {
      "epoch": 0.49075225365247127,
      "grad_norm": 0.2416694611310959,
      "learning_rate": 7.5462387317376436e-06,
      "loss": 0.1092,
      "step": 6315
    },
    {
      "epoch": 0.49082996580665217,
      "grad_norm": 0.33096009492874146,
      "learning_rate": 7.545850170966739e-06,
      "loss": 0.1644,
      "step": 6316
    },
    {
      "epoch": 0.49090767796083307,
      "grad_norm": 0.6027475595474243,
      "learning_rate": 7.545461610195835e-06,
      "loss": 0.4192,
      "step": 6317
    },
    {
      "epoch": 0.49098539011501396,
      "grad_norm": 0.21720896661281586,
      "learning_rate": 7.54507304942493e-06,
      "loss": 0.091,
      "step": 6318
    },
    {
      "epoch": 0.4910631022691949,
      "grad_norm": 0.23417054116725922,
      "learning_rate": 7.544684488654026e-06,
      "loss": 0.1551,
      "step": 6319
    },
    {
      "epoch": 0.4911408144233758,
      "grad_norm": 0.28577426075935364,
      "learning_rate": 7.544295927883122e-06,
      "loss": 0.1557,
      "step": 6320
    },
    {
      "epoch": 0.4912185265775567,
      "grad_norm": 0.6699457168579102,
      "learning_rate": 7.543907367112217e-06,
      "loss": 0.2418,
      "step": 6321
    },
    {
      "epoch": 0.49129623873173767,
      "grad_norm": 0.24769741296768188,
      "learning_rate": 7.5435188063413125e-06,
      "loss": 0.0884,
      "step": 6322
    },
    {
      "epoch": 0.49137395088591856,
      "grad_norm": 1.0499248504638672,
      "learning_rate": 7.543130245570408e-06,
      "loss": 0.4088,
      "step": 6323
    },
    {
      "epoch": 0.49145166304009946,
      "grad_norm": 0.31169989705085754,
      "learning_rate": 7.542741684799502e-06,
      "loss": 0.5309,
      "step": 6324
    },
    {
      "epoch": 0.49152937519428036,
      "grad_norm": 0.2721480429172516,
      "learning_rate": 7.542353124028598e-06,
      "loss": 0.0905,
      "step": 6325
    },
    {
      "epoch": 0.4916070873484613,
      "grad_norm": 0.14005614817142487,
      "learning_rate": 7.541964563257694e-06,
      "loss": 0.0593,
      "step": 6326
    },
    {
      "epoch": 0.4916847995026422,
      "grad_norm": 0.5872453451156616,
      "learning_rate": 7.541576002486789e-06,
      "loss": 0.4164,
      "step": 6327
    },
    {
      "epoch": 0.4917625116568231,
      "grad_norm": 0.23294441401958466,
      "learning_rate": 7.541187441715885e-06,
      "loss": 0.1225,
      "step": 6328
    },
    {
      "epoch": 0.49184022381100406,
      "grad_norm": 0.6344305276870728,
      "learning_rate": 7.5407988809449805e-06,
      "loss": 0.3029,
      "step": 6329
    },
    {
      "epoch": 0.49191793596518496,
      "grad_norm": 0.2349611222743988,
      "learning_rate": 7.540410320174076e-06,
      "loss": 0.1573,
      "step": 6330
    },
    {
      "epoch": 0.49199564811936586,
      "grad_norm": 1.445169448852539,
      "learning_rate": 7.540021759403171e-06,
      "loss": 0.4364,
      "step": 6331
    },
    {
      "epoch": 0.49207336027354676,
      "grad_norm": 0.0801519826054573,
      "learning_rate": 7.539633198632267e-06,
      "loss": 0.0212,
      "step": 6332
    },
    {
      "epoch": 0.4921510724277277,
      "grad_norm": 0.1919044554233551,
      "learning_rate": 7.539244637861363e-06,
      "loss": 0.1329,
      "step": 6333
    },
    {
      "epoch": 0.4922287845819086,
      "grad_norm": 1.7566417455673218,
      "learning_rate": 7.538856077090457e-06,
      "loss": 0.9287,
      "step": 6334
    },
    {
      "epoch": 0.4923064967360895,
      "grad_norm": 0.397868812084198,
      "learning_rate": 7.538467516319553e-06,
      "loss": 0.1679,
      "step": 6335
    },
    {
      "epoch": 0.49238420889027046,
      "grad_norm": 0.18459928035736084,
      "learning_rate": 7.5380789555486485e-06,
      "loss": 0.0738,
      "step": 6336
    },
    {
      "epoch": 0.49246192104445136,
      "grad_norm": 0.3444526195526123,
      "learning_rate": 7.5376903947777435e-06,
      "loss": 0.3199,
      "step": 6337
    },
    {
      "epoch": 0.49253963319863225,
      "grad_norm": 0.2810966968536377,
      "learning_rate": 7.537301834006839e-06,
      "loss": 0.2119,
      "step": 6338
    },
    {
      "epoch": 0.4926173453528132,
      "grad_norm": 0.44236335158348083,
      "learning_rate": 7.536913273235935e-06,
      "loss": 0.44,
      "step": 6339
    },
    {
      "epoch": 0.4926950575069941,
      "grad_norm": 0.6211532950401306,
      "learning_rate": 7.53652471246503e-06,
      "loss": 0.2894,
      "step": 6340
    },
    {
      "epoch": 0.492772769661175,
      "grad_norm": 0.4079442322254181,
      "learning_rate": 7.536136151694126e-06,
      "loss": 0.6821,
      "step": 6341
    },
    {
      "epoch": 0.4928504818153559,
      "grad_norm": 0.5235435962677002,
      "learning_rate": 7.535747590923222e-06,
      "loss": 0.5351,
      "step": 6342
    },
    {
      "epoch": 0.49292819396953685,
      "grad_norm": 0.5941757559776306,
      "learning_rate": 7.535359030152316e-06,
      "loss": 0.7475,
      "step": 6343
    },
    {
      "epoch": 0.49300590612371775,
      "grad_norm": 0.4393465518951416,
      "learning_rate": 7.5349704693814115e-06,
      "loss": 0.2173,
      "step": 6344
    },
    {
      "epoch": 0.49308361827789865,
      "grad_norm": 0.2412387728691101,
      "learning_rate": 7.534581908610507e-06,
      "loss": 0.0205,
      "step": 6345
    },
    {
      "epoch": 0.4931613304320796,
      "grad_norm": 0.38298866152763367,
      "learning_rate": 7.534193347839602e-06,
      "loss": 0.6415,
      "step": 6346
    },
    {
      "epoch": 0.4932390425862605,
      "grad_norm": 0.10872761160135269,
      "learning_rate": 7.533804787068698e-06,
      "loss": 0.0381,
      "step": 6347
    },
    {
      "epoch": 0.4933167547404414,
      "grad_norm": 0.4474833607673645,
      "learning_rate": 7.533416226297794e-06,
      "loss": 0.3382,
      "step": 6348
    },
    {
      "epoch": 0.4933944668946223,
      "grad_norm": 0.4066478908061981,
      "learning_rate": 7.533027665526889e-06,
      "loss": 0.1737,
      "step": 6349
    },
    {
      "epoch": 0.49347217904880325,
      "grad_norm": 0.12674954533576965,
      "learning_rate": 7.532639104755985e-06,
      "loss": 0.0787,
      "step": 6350
    },
    {
      "epoch": 0.49354989120298415,
      "grad_norm": 0.21261082589626312,
      "learning_rate": 7.53225054398508e-06,
      "loss": 0.1169,
      "step": 6351
    },
    {
      "epoch": 0.49362760335716505,
      "grad_norm": 0.4682393968105316,
      "learning_rate": 7.5318619832141745e-06,
      "loss": 0.3084,
      "step": 6352
    },
    {
      "epoch": 0.493705315511346,
      "grad_norm": 0.6233207583427429,
      "learning_rate": 7.53147342244327e-06,
      "loss": 0.2443,
      "step": 6353
    },
    {
      "epoch": 0.4937830276655269,
      "grad_norm": 0.15720006823539734,
      "learning_rate": 7.531084861672366e-06,
      "loss": 0.0397,
      "step": 6354
    },
    {
      "epoch": 0.4938607398197078,
      "grad_norm": 0.04000981152057648,
      "learning_rate": 7.530696300901461e-06,
      "loss": 0.0024,
      "step": 6355
    },
    {
      "epoch": 0.4939384519738887,
      "grad_norm": 0.2774297297000885,
      "learning_rate": 7.530307740130557e-06,
      "loss": 0.1529,
      "step": 6356
    },
    {
      "epoch": 0.49401616412806965,
      "grad_norm": 0.14887776970863342,
      "learning_rate": 7.529919179359653e-06,
      "loss": 0.018,
      "step": 6357
    },
    {
      "epoch": 0.49409387628225054,
      "grad_norm": 0.2967066168785095,
      "learning_rate": 7.529530618588748e-06,
      "loss": 0.0691,
      "step": 6358
    },
    {
      "epoch": 0.49417158843643144,
      "grad_norm": 0.29720404744148254,
      "learning_rate": 7.529142057817843e-06,
      "loss": 0.2506,
      "step": 6359
    },
    {
      "epoch": 0.4942493005906124,
      "grad_norm": 0.14552634954452515,
      "learning_rate": 7.528753497046939e-06,
      "loss": 0.0381,
      "step": 6360
    },
    {
      "epoch": 0.4943270127447933,
      "grad_norm": 0.360954225063324,
      "learning_rate": 7.528364936276035e-06,
      "loss": 0.155,
      "step": 6361
    },
    {
      "epoch": 0.4944047248989742,
      "grad_norm": 0.8899397850036621,
      "learning_rate": 7.527976375505129e-06,
      "loss": 0.5525,
      "step": 6362
    },
    {
      "epoch": 0.4944824370531551,
      "grad_norm": 0.5320417284965515,
      "learning_rate": 7.527587814734225e-06,
      "loss": 0.1183,
      "step": 6363
    },
    {
      "epoch": 0.49456014920733604,
      "grad_norm": 0.23041582107543945,
      "learning_rate": 7.527199253963321e-06,
      "loss": 0.0709,
      "step": 6364
    },
    {
      "epoch": 0.49463786136151694,
      "grad_norm": 0.6390089392662048,
      "learning_rate": 7.526810693192416e-06,
      "loss": 0.3401,
      "step": 6365
    },
    {
      "epoch": 0.49471557351569784,
      "grad_norm": 0.4007602632045746,
      "learning_rate": 7.526422132421511e-06,
      "loss": 0.4608,
      "step": 6366
    },
    {
      "epoch": 0.4947932856698788,
      "grad_norm": 0.2622906267642975,
      "learning_rate": 7.526033571650607e-06,
      "loss": 0.0753,
      "step": 6367
    },
    {
      "epoch": 0.4948709978240597,
      "grad_norm": 0.6272789835929871,
      "learning_rate": 7.525645010879702e-06,
      "loss": 0.1821,
      "step": 6368
    },
    {
      "epoch": 0.4949487099782406,
      "grad_norm": 0.3795579969882965,
      "learning_rate": 7.525256450108798e-06,
      "loss": 0.4679,
      "step": 6369
    },
    {
      "epoch": 0.4950264221324215,
      "grad_norm": 0.4687783718109131,
      "learning_rate": 7.524867889337894e-06,
      "loss": 0.2568,
      "step": 6370
    },
    {
      "epoch": 0.49510413428660244,
      "grad_norm": 0.20944863557815552,
      "learning_rate": 7.524479328566988e-06,
      "loss": 0.0928,
      "step": 6371
    },
    {
      "epoch": 0.49518184644078334,
      "grad_norm": 0.21116414666175842,
      "learning_rate": 7.524090767796084e-06,
      "loss": 0.0342,
      "step": 6372
    },
    {
      "epoch": 0.49525955859496423,
      "grad_norm": 0.1623811274766922,
      "learning_rate": 7.5237022070251795e-06,
      "loss": 0.0551,
      "step": 6373
    },
    {
      "epoch": 0.4953372707491452,
      "grad_norm": 0.39992430806159973,
      "learning_rate": 7.523313646254274e-06,
      "loss": 0.1836,
      "step": 6374
    },
    {
      "epoch": 0.4954149829033261,
      "grad_norm": 0.1945323646068573,
      "learning_rate": 7.52292508548337e-06,
      "loss": 0.0875,
      "step": 6375
    },
    {
      "epoch": 0.495492695057507,
      "grad_norm": 0.8207849264144897,
      "learning_rate": 7.522536524712466e-06,
      "loss": 0.2607,
      "step": 6376
    },
    {
      "epoch": 0.49557040721168794,
      "grad_norm": 1.4332395792007446,
      "learning_rate": 7.522147963941561e-06,
      "loss": 0.7022,
      "step": 6377
    },
    {
      "epoch": 0.49564811936586883,
      "grad_norm": 0.26075661182403564,
      "learning_rate": 7.521759403170657e-06,
      "loss": 0.0537,
      "step": 6378
    },
    {
      "epoch": 0.49572583152004973,
      "grad_norm": 0.2702697515487671,
      "learning_rate": 7.5213708423997525e-06,
      "loss": 0.0539,
      "step": 6379
    },
    {
      "epoch": 0.49580354367423063,
      "grad_norm": 0.47857269644737244,
      "learning_rate": 7.520982281628847e-06,
      "loss": 0.5153,
      "step": 6380
    },
    {
      "epoch": 0.4958812558284116,
      "grad_norm": 0.27601873874664307,
      "learning_rate": 7.5205937208579424e-06,
      "loss": 0.2292,
      "step": 6381
    },
    {
      "epoch": 0.4959589679825925,
      "grad_norm": 0.5283384919166565,
      "learning_rate": 7.520205160087038e-06,
      "loss": 0.2046,
      "step": 6382
    },
    {
      "epoch": 0.4960366801367734,
      "grad_norm": 0.0720367431640625,
      "learning_rate": 7.519816599316133e-06,
      "loss": 0.0269,
      "step": 6383
    },
    {
      "epoch": 0.49611439229095433,
      "grad_norm": 0.1457434743642807,
      "learning_rate": 7.519428038545229e-06,
      "loss": 0.0356,
      "step": 6384
    },
    {
      "epoch": 0.49619210444513523,
      "grad_norm": 0.3725054860115051,
      "learning_rate": 7.519039477774325e-06,
      "loss": 0.09,
      "step": 6385
    },
    {
      "epoch": 0.4962698165993161,
      "grad_norm": 0.32692697644233704,
      "learning_rate": 7.51865091700342e-06,
      "loss": 0.3479,
      "step": 6386
    },
    {
      "epoch": 0.496347528753497,
      "grad_norm": 0.23856167495250702,
      "learning_rate": 7.5182623562325155e-06,
      "loss": 0.1624,
      "step": 6387
    },
    {
      "epoch": 0.496425240907678,
      "grad_norm": 0.5578672885894775,
      "learning_rate": 7.517873795461611e-06,
      "loss": 0.1175,
      "step": 6388
    },
    {
      "epoch": 0.4965029530618589,
      "grad_norm": 0.48441603779792786,
      "learning_rate": 7.517485234690707e-06,
      "loss": 0.3517,
      "step": 6389
    },
    {
      "epoch": 0.4965806652160398,
      "grad_norm": 0.5584884881973267,
      "learning_rate": 7.517096673919801e-06,
      "loss": 0.1842,
      "step": 6390
    },
    {
      "epoch": 0.4966583773702207,
      "grad_norm": 0.4651942551136017,
      "learning_rate": 7.516708113148897e-06,
      "loss": 0.101,
      "step": 6391
    },
    {
      "epoch": 0.4967360895244016,
      "grad_norm": 0.8982315063476562,
      "learning_rate": 7.516319552377993e-06,
      "loss": 0.5207,
      "step": 6392
    },
    {
      "epoch": 0.4968138016785825,
      "grad_norm": 0.5939143896102905,
      "learning_rate": 7.515930991607088e-06,
      "loss": 0.2505,
      "step": 6393
    },
    {
      "epoch": 0.4968915138327634,
      "grad_norm": 0.5726954936981201,
      "learning_rate": 7.5155424308361836e-06,
      "loss": 0.8877,
      "step": 6394
    },
    {
      "epoch": 0.4969692259869444,
      "grad_norm": 0.12238706648349762,
      "learning_rate": 7.515153870065279e-06,
      "loss": 0.064,
      "step": 6395
    },
    {
      "epoch": 0.49704693814112527,
      "grad_norm": 0.33659282326698303,
      "learning_rate": 7.514765309294374e-06,
      "loss": 0.4504,
      "step": 6396
    },
    {
      "epoch": 0.49712465029530617,
      "grad_norm": 0.49200406670570374,
      "learning_rate": 7.51437674852347e-06,
      "loss": 0.29,
      "step": 6397
    },
    {
      "epoch": 0.4972023624494871,
      "grad_norm": 0.00321388547308743,
      "learning_rate": 7.513988187752566e-06,
      "loss": 0.0002,
      "step": 6398
    },
    {
      "epoch": 0.497280074603668,
      "grad_norm": 0.5105602145195007,
      "learning_rate": 7.51359962698166e-06,
      "loss": 0.2057,
      "step": 6399
    },
    {
      "epoch": 0.4973577867578489,
      "grad_norm": 0.13588812947273254,
      "learning_rate": 7.513211066210756e-06,
      "loss": 0.0884,
      "step": 6400
    },
    {
      "epoch": 0.4974354989120298,
      "grad_norm": 0.7414443492889404,
      "learning_rate": 7.512822505439852e-06,
      "loss": 0.2432,
      "step": 6401
    },
    {
      "epoch": 0.49751321106621077,
      "grad_norm": 0.05506543442606926,
      "learning_rate": 7.5124339446689466e-06,
      "loss": 0.0072,
      "step": 6402
    },
    {
      "epoch": 0.49759092322039167,
      "grad_norm": 0.3140079081058502,
      "learning_rate": 7.512045383898042e-06,
      "loss": 0.1874,
      "step": 6403
    },
    {
      "epoch": 0.49766863537457257,
      "grad_norm": 0.13572150468826294,
      "learning_rate": 7.511656823127138e-06,
      "loss": 0.0312,
      "step": 6404
    },
    {
      "epoch": 0.4977463475287535,
      "grad_norm": 1.077641487121582,
      "learning_rate": 7.511268262356233e-06,
      "loss": 0.6863,
      "step": 6405
    },
    {
      "epoch": 0.4978240596829344,
      "grad_norm": 0.7368242740631104,
      "learning_rate": 7.510879701585329e-06,
      "loss": 0.2842,
      "step": 6406
    },
    {
      "epoch": 0.4979017718371153,
      "grad_norm": 0.35478246212005615,
      "learning_rate": 7.510491140814425e-06,
      "loss": 0.1667,
      "step": 6407
    },
    {
      "epoch": 0.4979794839912962,
      "grad_norm": 0.14590902626514435,
      "learning_rate": 7.510102580043519e-06,
      "loss": 0.0672,
      "step": 6408
    },
    {
      "epoch": 0.49805719614547717,
      "grad_norm": 0.16724896430969238,
      "learning_rate": 7.509714019272615e-06,
      "loss": 0.0402,
      "step": 6409
    },
    {
      "epoch": 0.49813490829965806,
      "grad_norm": 0.09770605713129044,
      "learning_rate": 7.50932545850171e-06,
      "loss": 0.0337,
      "step": 6410
    },
    {
      "epoch": 0.49821262045383896,
      "grad_norm": 0.20617853105068207,
      "learning_rate": 7.508936897730805e-06,
      "loss": 0.0353,
      "step": 6411
    },
    {
      "epoch": 0.4982903326080199,
      "grad_norm": 0.38342997431755066,
      "learning_rate": 7.508548336959901e-06,
      "loss": 0.0573,
      "step": 6412
    },
    {
      "epoch": 0.4983680447622008,
      "grad_norm": 0.3912104368209839,
      "learning_rate": 7.508159776188997e-06,
      "loss": 0.1154,
      "step": 6413
    },
    {
      "epoch": 0.4984457569163817,
      "grad_norm": 0.24582087993621826,
      "learning_rate": 7.507771215418092e-06,
      "loss": 0.1115,
      "step": 6414
    },
    {
      "epoch": 0.49852346907056266,
      "grad_norm": 0.2193305939435959,
      "learning_rate": 7.507382654647188e-06,
      "loss": 0.1043,
      "step": 6415
    },
    {
      "epoch": 0.49860118122474356,
      "grad_norm": 0.17658314108848572,
      "learning_rate": 7.5069940938762835e-06,
      "loss": 0.0506,
      "step": 6416
    },
    {
      "epoch": 0.49867889337892446,
      "grad_norm": 0.23230239748954773,
      "learning_rate": 7.5066055331053776e-06,
      "loss": 0.2172,
      "step": 6417
    },
    {
      "epoch": 0.49875660553310536,
      "grad_norm": 0.0605204775929451,
      "learning_rate": 7.506216972334473e-06,
      "loss": 0.0346,
      "step": 6418
    },
    {
      "epoch": 0.4988343176872863,
      "grad_norm": 0.35337769985198975,
      "learning_rate": 7.505828411563569e-06,
      "loss": 0.5858,
      "step": 6419
    },
    {
      "epoch": 0.4989120298414672,
      "grad_norm": 0.16762126982212067,
      "learning_rate": 7.505439850792665e-06,
      "loss": 0.0713,
      "step": 6420
    },
    {
      "epoch": 0.4989897419956481,
      "grad_norm": 0.40154311060905457,
      "learning_rate": 7.50505129002176e-06,
      "loss": 0.1938,
      "step": 6421
    },
    {
      "epoch": 0.49906745414982906,
      "grad_norm": 0.6731374263763428,
      "learning_rate": 7.504662729250856e-06,
      "loss": 0.2195,
      "step": 6422
    },
    {
      "epoch": 0.49914516630400996,
      "grad_norm": 0.2874501347541809,
      "learning_rate": 7.5042741684799515e-06,
      "loss": 0.252,
      "step": 6423
    },
    {
      "epoch": 0.49922287845819086,
      "grad_norm": 1.0110526084899902,
      "learning_rate": 7.5038856077090465e-06,
      "loss": 0.6289,
      "step": 6424
    },
    {
      "epoch": 0.49930059061237175,
      "grad_norm": 0.2740022838115692,
      "learning_rate": 7.503497046938142e-06,
      "loss": 0.031,
      "step": 6425
    },
    {
      "epoch": 0.4993783027665527,
      "grad_norm": 0.6361388564109802,
      "learning_rate": 7.503108486167238e-06,
      "loss": 0.4278,
      "step": 6426
    },
    {
      "epoch": 0.4994560149207336,
      "grad_norm": 0.23758721351623535,
      "learning_rate": 7.502719925396332e-06,
      "loss": 0.1252,
      "step": 6427
    },
    {
      "epoch": 0.4995337270749145,
      "grad_norm": 0.8125579357147217,
      "learning_rate": 7.502331364625428e-06,
      "loss": 0.1661,
      "step": 6428
    },
    {
      "epoch": 0.49961143922909546,
      "grad_norm": 0.24401505291461945,
      "learning_rate": 7.501942803854524e-06,
      "loss": 0.0903,
      "step": 6429
    },
    {
      "epoch": 0.49968915138327635,
      "grad_norm": 0.4798624515533447,
      "learning_rate": 7.501554243083619e-06,
      "loss": 0.2542,
      "step": 6430
    },
    {
      "epoch": 0.49976686353745725,
      "grad_norm": 0.3578699231147766,
      "learning_rate": 7.5011656823127145e-06,
      "loss": 0.2193,
      "step": 6431
    },
    {
      "epoch": 0.49984457569163815,
      "grad_norm": 0.2653433680534363,
      "learning_rate": 7.50077712154181e-06,
      "loss": 0.1033,
      "step": 6432
    },
    {
      "epoch": 0.4999222878458191,
      "grad_norm": 0.5660281777381897,
      "learning_rate": 7.500388560770905e-06,
      "loss": 0.3466,
      "step": 6433
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4315914213657379,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.3919,
      "step": 6434
    },
    {
      "epoch": 0.500077712154181,
      "grad_norm": 6.081927299499512,
      "learning_rate": 7.499611439229096e-06,
      "loss": 2.5913,
      "step": 6435
    },
    {
      "epoch": 0.5001554243083618,
      "grad_norm": 0.1919330209493637,
      "learning_rate": 7.499222878458191e-06,
      "loss": 0.0616,
      "step": 6436
    },
    {
      "epoch": 0.5002331364625427,
      "grad_norm": 1.019830346107483,
      "learning_rate": 7.498834317687287e-06,
      "loss": 0.2138,
      "step": 6437
    },
    {
      "epoch": 0.5003108486167237,
      "grad_norm": 0.33915382623672485,
      "learning_rate": 7.4984457569163825e-06,
      "loss": 0.1211,
      "step": 6438
    },
    {
      "epoch": 0.5003885607709045,
      "grad_norm": 0.4324222207069397,
      "learning_rate": 7.4980571961454775e-06,
      "loss": 0.3114,
      "step": 6439
    },
    {
      "epoch": 0.5004662729250855,
      "grad_norm": 0.47892314195632935,
      "learning_rate": 7.497668635374573e-06,
      "loss": 0.0679,
      "step": 6440
    },
    {
      "epoch": 0.5005439850792665,
      "grad_norm": 0.5536345839500427,
      "learning_rate": 7.497280074603669e-06,
      "loss": 0.6826,
      "step": 6441
    },
    {
      "epoch": 0.5006216972334473,
      "grad_norm": 0.35647061467170715,
      "learning_rate": 7.496891513832763e-06,
      "loss": 0.2239,
      "step": 6442
    },
    {
      "epoch": 0.5006994093876282,
      "grad_norm": 0.5264776349067688,
      "learning_rate": 7.496502953061859e-06,
      "loss": 0.151,
      "step": 6443
    },
    {
      "epoch": 0.5007771215418091,
      "grad_norm": 0.3372080624103546,
      "learning_rate": 7.496114392290955e-06,
      "loss": 0.1798,
      "step": 6444
    },
    {
      "epoch": 0.50085483369599,
      "grad_norm": 0.41259363293647766,
      "learning_rate": 7.49572583152005e-06,
      "loss": 0.1972,
      "step": 6445
    },
    {
      "epoch": 0.500932545850171,
      "grad_norm": 0.2573331296443939,
      "learning_rate": 7.4953372707491455e-06,
      "loss": 0.0461,
      "step": 6446
    },
    {
      "epoch": 0.5010102580043518,
      "grad_norm": 0.21894361078739166,
      "learning_rate": 7.494948709978241e-06,
      "loss": 0.0299,
      "step": 6447
    },
    {
      "epoch": 0.5010879701585328,
      "grad_norm": 0.2250373214483261,
      "learning_rate": 7.494560149207336e-06,
      "loss": 0.1086,
      "step": 6448
    },
    {
      "epoch": 0.5011656823127137,
      "grad_norm": 0.6163913607597351,
      "learning_rate": 7.494171588436432e-06,
      "loss": 0.3403,
      "step": 6449
    },
    {
      "epoch": 0.5012433944668946,
      "grad_norm": 0.37837889790534973,
      "learning_rate": 7.493783027665528e-06,
      "loss": 0.2356,
      "step": 6450
    },
    {
      "epoch": 0.5013211066210755,
      "grad_norm": 0.45785436034202576,
      "learning_rate": 7.493394466894624e-06,
      "loss": 0.2031,
      "step": 6451
    },
    {
      "epoch": 0.5013988187752565,
      "grad_norm": 0.5038836598396301,
      "learning_rate": 7.493005906123718e-06,
      "loss": 0.3231,
      "step": 6452
    },
    {
      "epoch": 0.5014765309294373,
      "grad_norm": 0.46928027272224426,
      "learning_rate": 7.4926173453528136e-06,
      "loss": 0.1208,
      "step": 6453
    },
    {
      "epoch": 0.5015542430836183,
      "grad_norm": 0.22155524790287018,
      "learning_rate": 7.492228784581909e-06,
      "loss": 0.0658,
      "step": 6454
    },
    {
      "epoch": 0.5016319552377992,
      "grad_norm": 0.4048825204372406,
      "learning_rate": 7.491840223811004e-06,
      "loss": 0.3557,
      "step": 6455
    },
    {
      "epoch": 0.5017096673919801,
      "grad_norm": 0.48235023021698,
      "learning_rate": 7.4914516630401e-06,
      "loss": 0.7275,
      "step": 6456
    },
    {
      "epoch": 0.501787379546161,
      "grad_norm": 0.292579710483551,
      "learning_rate": 7.491063102269196e-06,
      "loss": 0.2527,
      "step": 6457
    },
    {
      "epoch": 0.5018650917003419,
      "grad_norm": 0.33716195821762085,
      "learning_rate": 7.490674541498291e-06,
      "loss": 0.1096,
      "step": 6458
    },
    {
      "epoch": 0.5019428038545228,
      "grad_norm": 0.5894354581832886,
      "learning_rate": 7.490285980727387e-06,
      "loss": 0.2164,
      "step": 6459
    },
    {
      "epoch": 0.5020205160087038,
      "grad_norm": 0.25443029403686523,
      "learning_rate": 7.4898974199564824e-06,
      "loss": 0.0307,
      "step": 6460
    },
    {
      "epoch": 0.5020982281628846,
      "grad_norm": 0.2662332355976105,
      "learning_rate": 7.4895088591855765e-06,
      "loss": 0.1399,
      "step": 6461
    },
    {
      "epoch": 0.5021759403170656,
      "grad_norm": 0.27288874983787537,
      "learning_rate": 7.489120298414672e-06,
      "loss": 0.1355,
      "step": 6462
    },
    {
      "epoch": 0.5022536524712465,
      "grad_norm": 0.3031315207481384,
      "learning_rate": 7.488731737643768e-06,
      "loss": 0.2601,
      "step": 6463
    },
    {
      "epoch": 0.5023313646254274,
      "grad_norm": 0.19838853180408478,
      "learning_rate": 7.488343176872863e-06,
      "loss": 0.0704,
      "step": 6464
    },
    {
      "epoch": 0.5024090767796083,
      "grad_norm": 0.32119348645210266,
      "learning_rate": 7.487954616101959e-06,
      "loss": 0.0848,
      "step": 6465
    },
    {
      "epoch": 0.5024867889337893,
      "grad_norm": 0.11519734561443329,
      "learning_rate": 7.487566055331055e-06,
      "loss": 0.0178,
      "step": 6466
    },
    {
      "epoch": 0.5025645010879701,
      "grad_norm": 0.4048369824886322,
      "learning_rate": 7.48717749456015e-06,
      "loss": 0.1835,
      "step": 6467
    },
    {
      "epoch": 0.5026422132421511,
      "grad_norm": 0.4750935435295105,
      "learning_rate": 7.486788933789245e-06,
      "loss": 0.2411,
      "step": 6468
    },
    {
      "epoch": 0.502719925396332,
      "grad_norm": 0.06727511435747147,
      "learning_rate": 7.486400373018341e-06,
      "loss": 0.0159,
      "step": 6469
    },
    {
      "epoch": 0.5027976375505129,
      "grad_norm": 0.07930557429790497,
      "learning_rate": 7.486011812247435e-06,
      "loss": 0.0512,
      "step": 6470
    },
    {
      "epoch": 0.5028753497046938,
      "grad_norm": 0.2060314565896988,
      "learning_rate": 7.485623251476531e-06,
      "loss": 0.0784,
      "step": 6471
    },
    {
      "epoch": 0.5029530618588747,
      "grad_norm": 0.2656661868095398,
      "learning_rate": 7.485234690705627e-06,
      "loss": 0.1008,
      "step": 6472
    },
    {
      "epoch": 0.5030307740130556,
      "grad_norm": 0.4103213846683502,
      "learning_rate": 7.484846129934722e-06,
      "loss": 0.0348,
      "step": 6473
    },
    {
      "epoch": 0.5031084861672366,
      "grad_norm": 0.08693784475326538,
      "learning_rate": 7.484457569163818e-06,
      "loss": 0.0475,
      "step": 6474
    },
    {
      "epoch": 0.5031861983214174,
      "grad_norm": 0.2990110516548157,
      "learning_rate": 7.4840690083929135e-06,
      "loss": 0.0848,
      "step": 6475
    },
    {
      "epoch": 0.5032639104755984,
      "grad_norm": 0.46700984239578247,
      "learning_rate": 7.483680447622008e-06,
      "loss": 0.1156,
      "step": 6476
    },
    {
      "epoch": 0.5033416226297793,
      "grad_norm": 0.45157602429389954,
      "learning_rate": 7.483291886851104e-06,
      "loss": 0.1086,
      "step": 6477
    },
    {
      "epoch": 0.5034193347839602,
      "grad_norm": 0.671145498752594,
      "learning_rate": 7.4829033260802e-06,
      "loss": 0.1772,
      "step": 6478
    },
    {
      "epoch": 0.5034970469381411,
      "grad_norm": 0.14104622602462769,
      "learning_rate": 7.482514765309294e-06,
      "loss": 0.0405,
      "step": 6479
    },
    {
      "epoch": 0.5035747590923221,
      "grad_norm": 0.4885302186012268,
      "learning_rate": 7.48212620453839e-06,
      "loss": 0.256,
      "step": 6480
    },
    {
      "epoch": 0.5036524712465029,
      "grad_norm": 0.08192798495292664,
      "learning_rate": 7.481737643767486e-06,
      "loss": 0.0368,
      "step": 6481
    },
    {
      "epoch": 0.5037301834006839,
      "grad_norm": 0.14524874091148376,
      "learning_rate": 7.4813490829965815e-06,
      "loss": 0.0963,
      "step": 6482
    },
    {
      "epoch": 0.5038078955548648,
      "grad_norm": 0.4359239935874939,
      "learning_rate": 7.4809605222256764e-06,
      "loss": 0.7875,
      "step": 6483
    },
    {
      "epoch": 0.5038856077090457,
      "grad_norm": 0.13112224638462067,
      "learning_rate": 7.480571961454772e-06,
      "loss": 0.1261,
      "step": 6484
    },
    {
      "epoch": 0.5039633198632266,
      "grad_norm": 0.1639743596315384,
      "learning_rate": 7.480183400683868e-06,
      "loss": 0.0368,
      "step": 6485
    },
    {
      "epoch": 0.5040410320174076,
      "grad_norm": 0.15796871483325958,
      "learning_rate": 7.479794839912963e-06,
      "loss": 0.0304,
      "step": 6486
    },
    {
      "epoch": 0.5041187441715884,
      "grad_norm": 0.6089651584625244,
      "learning_rate": 7.479406279142059e-06,
      "loss": 0.1598,
      "step": 6487
    },
    {
      "epoch": 0.5041964563257694,
      "grad_norm": 0.2522258758544922,
      "learning_rate": 7.479017718371155e-06,
      "loss": 0.0605,
      "step": 6488
    },
    {
      "epoch": 0.5042741684799502,
      "grad_norm": 0.3687066435813904,
      "learning_rate": 7.478629157600249e-06,
      "loss": 0.2073,
      "step": 6489
    },
    {
      "epoch": 0.5043518806341312,
      "grad_norm": 0.18378496170043945,
      "learning_rate": 7.4782405968293445e-06,
      "loss": 0.0349,
      "step": 6490
    },
    {
      "epoch": 0.5044295927883121,
      "grad_norm": 0.27762550115585327,
      "learning_rate": 7.47785203605844e-06,
      "loss": 0.1301,
      "step": 6491
    },
    {
      "epoch": 0.504507304942493,
      "grad_norm": 0.5178013443946838,
      "learning_rate": 7.477463475287535e-06,
      "loss": 0.3614,
      "step": 6492
    },
    {
      "epoch": 0.5045850170966739,
      "grad_norm": 0.5759729146957397,
      "learning_rate": 7.477074914516631e-06,
      "loss": 0.246,
      "step": 6493
    },
    {
      "epoch": 0.5046627292508549,
      "grad_norm": 0.06751120835542679,
      "learning_rate": 7.476686353745727e-06,
      "loss": 0.0229,
      "step": 6494
    },
    {
      "epoch": 0.5047404414050357,
      "grad_norm": 0.6483569145202637,
      "learning_rate": 7.476297792974822e-06,
      "loss": 0.2935,
      "step": 6495
    },
    {
      "epoch": 0.5048181535592167,
      "grad_norm": 0.09799972921609879,
      "learning_rate": 7.4759092322039176e-06,
      "loss": 0.0266,
      "step": 6496
    },
    {
      "epoch": 0.5048958657133976,
      "grad_norm": 0.24300409853458405,
      "learning_rate": 7.475520671433013e-06,
      "loss": 0.1894,
      "step": 6497
    },
    {
      "epoch": 0.5049735778675785,
      "grad_norm": 0.45307260751724243,
      "learning_rate": 7.4751321106621075e-06,
      "loss": 0.5968,
      "step": 6498
    },
    {
      "epoch": 0.5050512900217594,
      "grad_norm": 0.6040929555892944,
      "learning_rate": 7.474743549891203e-06,
      "loss": 0.3187,
      "step": 6499
    },
    {
      "epoch": 0.5051290021759404,
      "grad_norm": 0.2069820612668991,
      "learning_rate": 7.474354989120299e-06,
      "loss": 0.0732,
      "step": 6500
    },
    {
      "epoch": 0.5052067143301212,
      "grad_norm": 0.12138339877128601,
      "learning_rate": 7.473966428349394e-06,
      "loss": 0.0674,
      "step": 6501
    },
    {
      "epoch": 0.5052844264843022,
      "grad_norm": 0.3436395227909088,
      "learning_rate": 7.47357786757849e-06,
      "loss": 0.2295,
      "step": 6502
    },
    {
      "epoch": 0.505362138638483,
      "grad_norm": 0.23763293027877808,
      "learning_rate": 7.473189306807586e-06,
      "loss": 0.1465,
      "step": 6503
    },
    {
      "epoch": 0.505439850792664,
      "grad_norm": 0.6036723256111145,
      "learning_rate": 7.4728007460366806e-06,
      "loss": 0.3923,
      "step": 6504
    },
    {
      "epoch": 0.5055175629468449,
      "grad_norm": 0.1704818606376648,
      "learning_rate": 7.472412185265776e-06,
      "loss": 0.0533,
      "step": 6505
    },
    {
      "epoch": 0.5055952751010258,
      "grad_norm": 0.513092041015625,
      "learning_rate": 7.472023624494872e-06,
      "loss": 1.0115,
      "step": 6506
    },
    {
      "epoch": 0.5056729872552067,
      "grad_norm": 0.8155979514122009,
      "learning_rate": 7.471635063723966e-06,
      "loss": 0.2692,
      "step": 6507
    },
    {
      "epoch": 0.5057506994093877,
      "grad_norm": 0.37340500950813293,
      "learning_rate": 7.471246502953062e-06,
      "loss": 0.5344,
      "step": 6508
    },
    {
      "epoch": 0.5058284115635685,
      "grad_norm": 0.3024955689907074,
      "learning_rate": 7.470857942182158e-06,
      "loss": 0.2438,
      "step": 6509
    },
    {
      "epoch": 0.5059061237177495,
      "grad_norm": 0.34329402446746826,
      "learning_rate": 7.470469381411254e-06,
      "loss": 0.5491,
      "step": 6510
    },
    {
      "epoch": 0.5059838358719304,
      "grad_norm": 0.34942060708999634,
      "learning_rate": 7.470080820640349e-06,
      "loss": 0.1381,
      "step": 6511
    },
    {
      "epoch": 0.5060615480261113,
      "grad_norm": 0.44662097096443176,
      "learning_rate": 7.469692259869444e-06,
      "loss": 0.2988,
      "step": 6512
    },
    {
      "epoch": 0.5061392601802922,
      "grad_norm": 0.3945285677909851,
      "learning_rate": 7.46930369909854e-06,
      "loss": 0.2495,
      "step": 6513
    },
    {
      "epoch": 0.5062169723344732,
      "grad_norm": 0.2776453197002411,
      "learning_rate": 7.468915138327635e-06,
      "loss": 0.127,
      "step": 6514
    },
    {
      "epoch": 0.506294684488654,
      "grad_norm": 0.10198026150465012,
      "learning_rate": 7.468526577556731e-06,
      "loss": 0.01,
      "step": 6515
    },
    {
      "epoch": 0.506372396642835,
      "grad_norm": 0.22683297097682953,
      "learning_rate": 7.468138016785827e-06,
      "loss": 0.0569,
      "step": 6516
    },
    {
      "epoch": 0.5064501087970159,
      "grad_norm": 0.6554194092750549,
      "learning_rate": 7.467749456014921e-06,
      "loss": 0.1957,
      "step": 6517
    },
    {
      "epoch": 0.5065278209511967,
      "grad_norm": 0.8210456371307373,
      "learning_rate": 7.467360895244017e-06,
      "loss": 0.5652,
      "step": 6518
    },
    {
      "epoch": 0.5066055331053777,
      "grad_norm": 1.0095406770706177,
      "learning_rate": 7.4669723344731124e-06,
      "loss": 0.4064,
      "step": 6519
    },
    {
      "epoch": 0.5066832452595585,
      "grad_norm": 0.15979038178920746,
      "learning_rate": 7.466583773702207e-06,
      "loss": 0.0191,
      "step": 6520
    },
    {
      "epoch": 0.5067609574137395,
      "grad_norm": 0.4941154718399048,
      "learning_rate": 7.466195212931303e-06,
      "loss": 0.2076,
      "step": 6521
    },
    {
      "epoch": 0.5068386695679205,
      "grad_norm": 0.33418095111846924,
      "learning_rate": 7.465806652160399e-06,
      "loss": 0.1795,
      "step": 6522
    },
    {
      "epoch": 0.5069163817221013,
      "grad_norm": 0.4506169855594635,
      "learning_rate": 7.465418091389494e-06,
      "loss": 0.2002,
      "step": 6523
    },
    {
      "epoch": 0.5069940938762822,
      "grad_norm": 0.4971415400505066,
      "learning_rate": 7.46502953061859e-06,
      "loss": 0.1994,
      "step": 6524
    },
    {
      "epoch": 0.5070718060304632,
      "grad_norm": 1.5215412378311157,
      "learning_rate": 7.4646409698476855e-06,
      "loss": 0.4406,
      "step": 6525
    },
    {
      "epoch": 0.507149518184644,
      "grad_norm": 0.5334457755088806,
      "learning_rate": 7.46425240907678e-06,
      "loss": 0.7256,
      "step": 6526
    },
    {
      "epoch": 0.507227230338825,
      "grad_norm": 0.208576962351799,
      "learning_rate": 7.463863848305875e-06,
      "loss": 0.0881,
      "step": 6527
    },
    {
      "epoch": 0.507304942493006,
      "grad_norm": 0.6121864914894104,
      "learning_rate": 7.463475287534971e-06,
      "loss": 0.259,
      "step": 6528
    },
    {
      "epoch": 0.5073826546471868,
      "grad_norm": 0.7402744889259338,
      "learning_rate": 7.463086726764066e-06,
      "loss": 0.3209,
      "step": 6529
    },
    {
      "epoch": 0.5074603668013677,
      "grad_norm": 0.20987039804458618,
      "learning_rate": 7.462698165993162e-06,
      "loss": 0.0778,
      "step": 6530
    },
    {
      "epoch": 0.5075380789555487,
      "grad_norm": 0.12690488994121552,
      "learning_rate": 7.462309605222258e-06,
      "loss": 0.027,
      "step": 6531
    },
    {
      "epoch": 0.5076157911097295,
      "grad_norm": 0.28171536326408386,
      "learning_rate": 7.461921044451353e-06,
      "loss": 0.3624,
      "step": 6532
    },
    {
      "epoch": 0.5076935032639105,
      "grad_norm": 0.5480257272720337,
      "learning_rate": 7.4615324836804485e-06,
      "loss": 0.1706,
      "step": 6533
    },
    {
      "epoch": 0.5077712154180913,
      "grad_norm": 0.4527764916419983,
      "learning_rate": 7.461143922909544e-06,
      "loss": 0.2192,
      "step": 6534
    },
    {
      "epoch": 0.5078489275722723,
      "grad_norm": 0.7291644811630249,
      "learning_rate": 7.460755362138638e-06,
      "loss": 0.3728,
      "step": 6535
    },
    {
      "epoch": 0.5079266397264532,
      "grad_norm": 0.4806181788444519,
      "learning_rate": 7.460366801367734e-06,
      "loss": 0.1548,
      "step": 6536
    },
    {
      "epoch": 0.5080043518806341,
      "grad_norm": 0.28589800000190735,
      "learning_rate": 7.45997824059683e-06,
      "loss": 0.149,
      "step": 6537
    },
    {
      "epoch": 0.508082064034815,
      "grad_norm": 0.410429984331131,
      "learning_rate": 7.459589679825925e-06,
      "loss": 0.2058,
      "step": 6538
    },
    {
      "epoch": 0.508159776188996,
      "grad_norm": 0.21026013791561127,
      "learning_rate": 7.459201119055021e-06,
      "loss": 0.0722,
      "step": 6539
    },
    {
      "epoch": 0.5082374883431768,
      "grad_norm": 0.17659172415733337,
      "learning_rate": 7.4588125582841165e-06,
      "loss": 0.0472,
      "step": 6540
    },
    {
      "epoch": 0.5083152004973578,
      "grad_norm": 0.2914372682571411,
      "learning_rate": 7.458423997513212e-06,
      "loss": 0.228,
      "step": 6541
    },
    {
      "epoch": 0.5083929126515387,
      "grad_norm": 0.3315107524394989,
      "learning_rate": 7.458035436742307e-06,
      "loss": 0.2209,
      "step": 6542
    },
    {
      "epoch": 0.5084706248057196,
      "grad_norm": 0.8972575664520264,
      "learning_rate": 7.457646875971403e-06,
      "loss": 0.2389,
      "step": 6543
    },
    {
      "epoch": 0.5085483369599005,
      "grad_norm": 1.154090404510498,
      "learning_rate": 7.457258315200499e-06,
      "loss": 0.6455,
      "step": 6544
    },
    {
      "epoch": 0.5086260491140815,
      "grad_norm": 0.39904868602752686,
      "learning_rate": 7.456869754429593e-06,
      "loss": 0.1534,
      "step": 6545
    },
    {
      "epoch": 0.5087037612682623,
      "grad_norm": 0.7817997932434082,
      "learning_rate": 7.456481193658689e-06,
      "loss": 0.3763,
      "step": 6546
    },
    {
      "epoch": 0.5087814734224433,
      "grad_norm": 0.3387141525745392,
      "learning_rate": 7.4560926328877846e-06,
      "loss": 0.1381,
      "step": 6547
    },
    {
      "epoch": 0.5088591855766241,
      "grad_norm": 0.20276802778244019,
      "learning_rate": 7.4557040721168795e-06,
      "loss": 0.0698,
      "step": 6548
    },
    {
      "epoch": 0.5089368977308051,
      "grad_norm": 0.12508700788021088,
      "learning_rate": 7.455315511345975e-06,
      "loss": 0.0546,
      "step": 6549
    },
    {
      "epoch": 0.509014609884986,
      "grad_norm": 0.35413894057273865,
      "learning_rate": 7.454926950575071e-06,
      "loss": 0.0905,
      "step": 6550
    },
    {
      "epoch": 0.5090923220391669,
      "grad_norm": 0.11720865964889526,
      "learning_rate": 7.454538389804166e-06,
      "loss": 0.1132,
      "step": 6551
    },
    {
      "epoch": 0.5091700341933478,
      "grad_norm": 0.11696403473615646,
      "learning_rate": 7.454149829033262e-06,
      "loss": 0.0636,
      "step": 6552
    },
    {
      "epoch": 0.5092477463475288,
      "grad_norm": 0.11371244490146637,
      "learning_rate": 7.453761268262358e-06,
      "loss": 0.0384,
      "step": 6553
    },
    {
      "epoch": 0.5093254585017096,
      "grad_norm": 0.34880611300468445,
      "learning_rate": 7.453372707491452e-06,
      "loss": 0.1895,
      "step": 6554
    },
    {
      "epoch": 0.5094031706558906,
      "grad_norm": 0.3145195245742798,
      "learning_rate": 7.4529841467205476e-06,
      "loss": 0.1579,
      "step": 6555
    },
    {
      "epoch": 0.5094808828100715,
      "grad_norm": 0.18607443571090698,
      "learning_rate": 7.452595585949643e-06,
      "loss": 0.0879,
      "step": 6556
    },
    {
      "epoch": 0.5095585949642524,
      "grad_norm": 0.4891919195652008,
      "learning_rate": 7.452207025178738e-06,
      "loss": 0.0965,
      "step": 6557
    },
    {
      "epoch": 0.5096363071184333,
      "grad_norm": 0.07412626594305038,
      "learning_rate": 7.451818464407834e-06,
      "loss": 0.0085,
      "step": 6558
    },
    {
      "epoch": 0.5097140192726143,
      "grad_norm": 0.49532780051231384,
      "learning_rate": 7.45142990363693e-06,
      "loss": 0.0616,
      "step": 6559
    },
    {
      "epoch": 0.5097917314267951,
      "grad_norm": 0.3487599194049835,
      "learning_rate": 7.451041342866025e-06,
      "loss": 0.1917,
      "step": 6560
    },
    {
      "epoch": 0.5098694435809761,
      "grad_norm": 0.19478833675384521,
      "learning_rate": 7.45065278209512e-06,
      "loss": 0.0471,
      "step": 6561
    },
    {
      "epoch": 0.509947155735157,
      "grad_norm": 1.0648669004440308,
      "learning_rate": 7.450264221324216e-06,
      "loss": 0.7044,
      "step": 6562
    },
    {
      "epoch": 0.5100248678893379,
      "grad_norm": 0.17856921255588531,
      "learning_rate": 7.4498756605533105e-06,
      "loss": 0.1447,
      "step": 6563
    },
    {
      "epoch": 0.5101025800435188,
      "grad_norm": 0.3582308888435364,
      "learning_rate": 7.449487099782406e-06,
      "loss": 0.1489,
      "step": 6564
    },
    {
      "epoch": 0.5101802921976997,
      "grad_norm": 0.593994140625,
      "learning_rate": 7.449098539011502e-06,
      "loss": 0.2041,
      "step": 6565
    },
    {
      "epoch": 0.5102580043518806,
      "grad_norm": 0.2497049868106842,
      "learning_rate": 7.448709978240597e-06,
      "loss": 0.0434,
      "step": 6566
    },
    {
      "epoch": 0.5103357165060616,
      "grad_norm": 0.298492431640625,
      "learning_rate": 7.448321417469693e-06,
      "loss": 0.1117,
      "step": 6567
    },
    {
      "epoch": 0.5104134286602424,
      "grad_norm": 0.36504673957824707,
      "learning_rate": 7.447932856698789e-06,
      "loss": 0.1646,
      "step": 6568
    },
    {
      "epoch": 0.5104911408144234,
      "grad_norm": 0.533458948135376,
      "learning_rate": 7.447544295927883e-06,
      "loss": 0.6274,
      "step": 6569
    },
    {
      "epoch": 0.5105688529686043,
      "grad_norm": 0.05660143122076988,
      "learning_rate": 7.447155735156979e-06,
      "loss": 0.0121,
      "step": 6570
    },
    {
      "epoch": 0.5106465651227852,
      "grad_norm": 0.2495112121105194,
      "learning_rate": 7.446767174386074e-06,
      "loss": 0.0966,
      "step": 6571
    },
    {
      "epoch": 0.5107242772769661,
      "grad_norm": 0.46303582191467285,
      "learning_rate": 7.44637861361517e-06,
      "loss": 0.4699,
      "step": 6572
    },
    {
      "epoch": 0.5108019894311471,
      "grad_norm": 0.2598631978034973,
      "learning_rate": 7.445990052844265e-06,
      "loss": 0.3727,
      "step": 6573
    },
    {
      "epoch": 0.5108797015853279,
      "grad_norm": 0.4911995530128479,
      "learning_rate": 7.445601492073361e-06,
      "loss": 0.1939,
      "step": 6574
    },
    {
      "epoch": 0.5109574137395089,
      "grad_norm": 0.05675536021590233,
      "learning_rate": 7.445212931302457e-06,
      "loss": 0.0118,
      "step": 6575
    },
    {
      "epoch": 0.5110351258936898,
      "grad_norm": 0.34811490774154663,
      "learning_rate": 7.444824370531552e-06,
      "loss": 0.3581,
      "step": 6576
    },
    {
      "epoch": 0.5111128380478707,
      "grad_norm": 0.9762978553771973,
      "learning_rate": 7.4444358097606475e-06,
      "loss": 0.2735,
      "step": 6577
    },
    {
      "epoch": 0.5111905502020516,
      "grad_norm": 0.2320420891046524,
      "learning_rate": 7.444047248989743e-06,
      "loss": 0.1108,
      "step": 6578
    },
    {
      "epoch": 0.5112682623562325,
      "grad_norm": 1.103143334388733,
      "learning_rate": 7.443658688218837e-06,
      "loss": 0.6274,
      "step": 6579
    },
    {
      "epoch": 0.5113459745104134,
      "grad_norm": 0.5220238566398621,
      "learning_rate": 7.443270127447933e-06,
      "loss": 0.0479,
      "step": 6580
    },
    {
      "epoch": 0.5114236866645944,
      "grad_norm": 0.3227730393409729,
      "learning_rate": 7.442881566677029e-06,
      "loss": 0.5077,
      "step": 6581
    },
    {
      "epoch": 0.5115013988187752,
      "grad_norm": 0.2392839640378952,
      "learning_rate": 7.442493005906124e-06,
      "loss": 0.087,
      "step": 6582
    },
    {
      "epoch": 0.5115791109729562,
      "grad_norm": 0.2254866510629654,
      "learning_rate": 7.44210444513522e-06,
      "loss": 0.0402,
      "step": 6583
    },
    {
      "epoch": 0.5116568231271371,
      "grad_norm": 0.3397409915924072,
      "learning_rate": 7.4417158843643155e-06,
      "loss": 0.1186,
      "step": 6584
    },
    {
      "epoch": 0.511734535281318,
      "grad_norm": 0.12626484036445618,
      "learning_rate": 7.4413273235934105e-06,
      "loss": 0.0347,
      "step": 6585
    },
    {
      "epoch": 0.5118122474354989,
      "grad_norm": 0.2833932638168335,
      "learning_rate": 7.440938762822506e-06,
      "loss": 0.1502,
      "step": 6586
    },
    {
      "epoch": 0.5118899595896799,
      "grad_norm": 0.29363805055618286,
      "learning_rate": 7.440550202051602e-06,
      "loss": 0.0979,
      "step": 6587
    },
    {
      "epoch": 0.5119676717438607,
      "grad_norm": 0.25949838757514954,
      "learning_rate": 7.440161641280696e-06,
      "loss": 0.1258,
      "step": 6588
    },
    {
      "epoch": 0.5120453838980417,
      "grad_norm": 0.6214572191238403,
      "learning_rate": 7.439773080509792e-06,
      "loss": 0.295,
      "step": 6589
    },
    {
      "epoch": 0.5121230960522226,
      "grad_norm": 0.19846348464488983,
      "learning_rate": 7.439384519738888e-06,
      "loss": 0.1058,
      "step": 6590
    },
    {
      "epoch": 0.5122008082064035,
      "grad_norm": 0.16825184226036072,
      "learning_rate": 7.438995958967983e-06,
      "loss": 0.114,
      "step": 6591
    },
    {
      "epoch": 0.5122785203605844,
      "grad_norm": 0.4204633831977844,
      "learning_rate": 7.4386073981970785e-06,
      "loss": 0.4039,
      "step": 6592
    },
    {
      "epoch": 0.5123562325147654,
      "grad_norm": 0.2804533541202545,
      "learning_rate": 7.438218837426174e-06,
      "loss": 0.0772,
      "step": 6593
    },
    {
      "epoch": 0.5124339446689462,
      "grad_norm": 0.5287327766418457,
      "learning_rate": 7.437830276655269e-06,
      "loss": 0.544,
      "step": 6594
    },
    {
      "epoch": 0.5125116568231272,
      "grad_norm": 0.6522288918495178,
      "learning_rate": 7.437441715884365e-06,
      "loss": 0.2416,
      "step": 6595
    },
    {
      "epoch": 0.512589368977308,
      "grad_norm": 0.5639222860336304,
      "learning_rate": 7.437053155113461e-06,
      "loss": 0.2284,
      "step": 6596
    },
    {
      "epoch": 0.512667081131489,
      "grad_norm": 0.5050150156021118,
      "learning_rate": 7.436664594342555e-06,
      "loss": 0.3715,
      "step": 6597
    },
    {
      "epoch": 0.5127447932856699,
      "grad_norm": 0.5122460126876831,
      "learning_rate": 7.436276033571651e-06,
      "loss": 0.3574,
      "step": 6598
    },
    {
      "epoch": 0.5128225054398508,
      "grad_norm": 0.0662599578499794,
      "learning_rate": 7.4358874728007465e-06,
      "loss": 0.0117,
      "step": 6599
    },
    {
      "epoch": 0.5129002175940317,
      "grad_norm": 0.3353929817676544,
      "learning_rate": 7.4354989120298415e-06,
      "loss": 0.1796,
      "step": 6600
    },
    {
      "epoch": 0.5129779297482127,
      "grad_norm": 0.5548200607299805,
      "learning_rate": 7.435110351258937e-06,
      "loss": 0.1542,
      "step": 6601
    },
    {
      "epoch": 0.5130556419023935,
      "grad_norm": 0.8620397448539734,
      "learning_rate": 7.434721790488033e-06,
      "loss": 0.533,
      "step": 6602
    },
    {
      "epoch": 0.5131333540565745,
      "grad_norm": 0.5747686624526978,
      "learning_rate": 7.434333229717129e-06,
      "loss": 0.2831,
      "step": 6603
    },
    {
      "epoch": 0.5132110662107554,
      "grad_norm": 0.04946299269795418,
      "learning_rate": 7.433944668946224e-06,
      "loss": 0.0122,
      "step": 6604
    },
    {
      "epoch": 0.5132887783649362,
      "grad_norm": 0.3511525094509125,
      "learning_rate": 7.43355610817532e-06,
      "loss": 0.3111,
      "step": 6605
    },
    {
      "epoch": 0.5133664905191172,
      "grad_norm": 0.4370034337043762,
      "learning_rate": 7.433167547404415e-06,
      "loss": 0.0917,
      "step": 6606
    },
    {
      "epoch": 0.5134442026732982,
      "grad_norm": 0.4161568582057953,
      "learning_rate": 7.4327789866335095e-06,
      "loss": 0.3086,
      "step": 6607
    },
    {
      "epoch": 0.513521914827479,
      "grad_norm": 0.5685800313949585,
      "learning_rate": 7.432390425862605e-06,
      "loss": 0.2427,
      "step": 6608
    },
    {
      "epoch": 0.51359962698166,
      "grad_norm": 0.2672927975654602,
      "learning_rate": 7.432001865091701e-06,
      "loss": 0.0759,
      "step": 6609
    },
    {
      "epoch": 0.5136773391358408,
      "grad_norm": 0.08880040794610977,
      "learning_rate": 7.431613304320796e-06,
      "loss": 0.0326,
      "step": 6610
    },
    {
      "epoch": 0.5137550512900217,
      "grad_norm": 0.43307292461395264,
      "learning_rate": 7.431224743549892e-06,
      "loss": 0.2958,
      "step": 6611
    },
    {
      "epoch": 0.5138327634442027,
      "grad_norm": 0.4887104332447052,
      "learning_rate": 7.430836182778988e-06,
      "loss": 0.1478,
      "step": 6612
    },
    {
      "epoch": 0.5139104755983835,
      "grad_norm": 0.2805984914302826,
      "learning_rate": 7.430447622008083e-06,
      "loss": 0.2451,
      "step": 6613
    },
    {
      "epoch": 0.5139881877525645,
      "grad_norm": 0.6238688826560974,
      "learning_rate": 7.430059061237178e-06,
      "loss": 0.8168,
      "step": 6614
    },
    {
      "epoch": 0.5140658999067454,
      "grad_norm": 0.5082960724830627,
      "learning_rate": 7.429670500466274e-06,
      "loss": 0.5011,
      "step": 6615
    },
    {
      "epoch": 0.5141436120609263,
      "grad_norm": 0.5362499952316284,
      "learning_rate": 7.429281939695368e-06,
      "loss": 0.3561,
      "step": 6616
    },
    {
      "epoch": 0.5142213242151072,
      "grad_norm": 0.29158979654312134,
      "learning_rate": 7.428893378924464e-06,
      "loss": 0.0991,
      "step": 6617
    },
    {
      "epoch": 0.5142990363692882,
      "grad_norm": 0.5092712640762329,
      "learning_rate": 7.42850481815356e-06,
      "loss": 0.045,
      "step": 6618
    },
    {
      "epoch": 0.514376748523469,
      "grad_norm": 0.21333548426628113,
      "learning_rate": 7.428116257382655e-06,
      "loss": 0.3487,
      "step": 6619
    },
    {
      "epoch": 0.51445446067765,
      "grad_norm": 0.5932609438896179,
      "learning_rate": 7.427727696611751e-06,
      "loss": 0.2173,
      "step": 6620
    },
    {
      "epoch": 0.514532172831831,
      "grad_norm": 0.6806671619415283,
      "learning_rate": 7.4273391358408464e-06,
      "loss": 0.9614,
      "step": 6621
    },
    {
      "epoch": 0.5146098849860118,
      "grad_norm": 0.4078724682331085,
      "learning_rate": 7.426950575069941e-06,
      "loss": 0.193,
      "step": 6622
    },
    {
      "epoch": 0.5146875971401927,
      "grad_norm": 0.3826471269130707,
      "learning_rate": 7.426562014299037e-06,
      "loss": 0.1561,
      "step": 6623
    },
    {
      "epoch": 0.5147653092943736,
      "grad_norm": 0.18995071947574615,
      "learning_rate": 7.426173453528133e-06,
      "loss": 0.0788,
      "step": 6624
    },
    {
      "epoch": 0.5148430214485545,
      "grad_norm": 0.180681511759758,
      "learning_rate": 7.425784892757227e-06,
      "loss": 0.2131,
      "step": 6625
    },
    {
      "epoch": 0.5149207336027355,
      "grad_norm": 0.5886620879173279,
      "learning_rate": 7.425396331986323e-06,
      "loss": 0.271,
      "step": 6626
    },
    {
      "epoch": 0.5149984457569163,
      "grad_norm": 0.2529029846191406,
      "learning_rate": 7.425007771215419e-06,
      "loss": 0.0442,
      "step": 6627
    },
    {
      "epoch": 0.5150761579110973,
      "grad_norm": 0.6236647367477417,
      "learning_rate": 7.424619210444514e-06,
      "loss": 0.2098,
      "step": 6628
    },
    {
      "epoch": 0.5151538700652782,
      "grad_norm": 0.18897473812103271,
      "learning_rate": 7.424230649673609e-06,
      "loss": 0.0725,
      "step": 6629
    },
    {
      "epoch": 0.5152315822194591,
      "grad_norm": 0.23177222907543182,
      "learning_rate": 7.423842088902705e-06,
      "loss": 0.0931,
      "step": 6630
    },
    {
      "epoch": 0.51530929437364,
      "grad_norm": 0.07834338396787643,
      "learning_rate": 7.4234535281318e-06,
      "loss": 0.0158,
      "step": 6631
    },
    {
      "epoch": 0.515387006527821,
      "grad_norm": 0.39324870705604553,
      "learning_rate": 7.423064967360896e-06,
      "loss": 0.1419,
      "step": 6632
    },
    {
      "epoch": 0.5154647186820018,
      "grad_norm": 0.7332420945167542,
      "learning_rate": 7.422676406589992e-06,
      "loss": 0.1089,
      "step": 6633
    },
    {
      "epoch": 0.5155424308361828,
      "grad_norm": 1.0634342432022095,
      "learning_rate": 7.4222878458190876e-06,
      "loss": 0.1929,
      "step": 6634
    },
    {
      "epoch": 0.5156201429903637,
      "grad_norm": 0.2283046990633011,
      "learning_rate": 7.421899285048182e-06,
      "loss": 0.0417,
      "step": 6635
    },
    {
      "epoch": 0.5156978551445446,
      "grad_norm": 0.3158518373966217,
      "learning_rate": 7.4215107242772775e-06,
      "loss": 0.1515,
      "step": 6636
    },
    {
      "epoch": 0.5157755672987255,
      "grad_norm": 0.22223538160324097,
      "learning_rate": 7.421122163506373e-06,
      "loss": 0.0537,
      "step": 6637
    },
    {
      "epoch": 0.5158532794529065,
      "grad_norm": 0.3056678771972656,
      "learning_rate": 7.420733602735468e-06,
      "loss": 0.1839,
      "step": 6638
    },
    {
      "epoch": 0.5159309916070873,
      "grad_norm": 0.536034107208252,
      "learning_rate": 7.420345041964564e-06,
      "loss": 0.4288,
      "step": 6639
    },
    {
      "epoch": 0.5160087037612683,
      "grad_norm": 0.5655714273452759,
      "learning_rate": 7.41995648119366e-06,
      "loss": 0.3137,
      "step": 6640
    },
    {
      "epoch": 0.5160864159154491,
      "grad_norm": 0.13675548136234283,
      "learning_rate": 7.419567920422755e-06,
      "loss": 0.061,
      "step": 6641
    },
    {
      "epoch": 0.5161641280696301,
      "grad_norm": 0.3665125370025635,
      "learning_rate": 7.4191793596518505e-06,
      "loss": 0.2213,
      "step": 6642
    },
    {
      "epoch": 0.516241840223811,
      "grad_norm": 0.6663846969604492,
      "learning_rate": 7.418790798880946e-06,
      "loss": 0.4129,
      "step": 6643
    },
    {
      "epoch": 0.5163195523779919,
      "grad_norm": 0.1643594652414322,
      "learning_rate": 7.4184022381100404e-06,
      "loss": 0.041,
      "step": 6644
    },
    {
      "epoch": 0.5163972645321728,
      "grad_norm": 0.35852527618408203,
      "learning_rate": 7.418013677339136e-06,
      "loss": 0.0666,
      "step": 6645
    },
    {
      "epoch": 0.5164749766863538,
      "grad_norm": 0.38068217039108276,
      "learning_rate": 7.417625116568232e-06,
      "loss": 0.1268,
      "step": 6646
    },
    {
      "epoch": 0.5165526888405346,
      "grad_norm": 0.08209377527236938,
      "learning_rate": 7.417236555797327e-06,
      "loss": 0.0865,
      "step": 6647
    },
    {
      "epoch": 0.5166304009947156,
      "grad_norm": 0.2352440357208252,
      "learning_rate": 7.416847995026423e-06,
      "loss": 0.0498,
      "step": 6648
    },
    {
      "epoch": 0.5167081131488965,
      "grad_norm": 0.1046285480260849,
      "learning_rate": 7.416459434255519e-06,
      "loss": 0.0237,
      "step": 6649
    },
    {
      "epoch": 0.5167858253030774,
      "grad_norm": 0.6460424065589905,
      "learning_rate": 7.4160708734846135e-06,
      "loss": 0.2822,
      "step": 6650
    },
    {
      "epoch": 0.5168635374572583,
      "grad_norm": 0.1608012616634369,
      "learning_rate": 7.415682312713709e-06,
      "loss": 0.0394,
      "step": 6651
    },
    {
      "epoch": 0.5169412496114393,
      "grad_norm": 0.5094673037528992,
      "learning_rate": 7.415293751942805e-06,
      "loss": 0.1859,
      "step": 6652
    },
    {
      "epoch": 0.5170189617656201,
      "grad_norm": 0.462651789188385,
      "learning_rate": 7.414905191171899e-06,
      "loss": 0.2019,
      "step": 6653
    },
    {
      "epoch": 0.5170966739198011,
      "grad_norm": 0.20230674743652344,
      "learning_rate": 7.414516630400995e-06,
      "loss": 0.0403,
      "step": 6654
    },
    {
      "epoch": 0.5171743860739819,
      "grad_norm": 0.7592797875404358,
      "learning_rate": 7.414128069630091e-06,
      "loss": 0.2022,
      "step": 6655
    },
    {
      "epoch": 0.5172520982281629,
      "grad_norm": 1.0093510150909424,
      "learning_rate": 7.413739508859186e-06,
      "loss": 0.1344,
      "step": 6656
    },
    {
      "epoch": 0.5173298103823438,
      "grad_norm": 0.1008094772696495,
      "learning_rate": 7.4133509480882816e-06,
      "loss": 0.0392,
      "step": 6657
    },
    {
      "epoch": 0.5174075225365247,
      "grad_norm": 0.20569176971912384,
      "learning_rate": 7.412962387317377e-06,
      "loss": 0.0984,
      "step": 6658
    },
    {
      "epoch": 0.5174852346907056,
      "grad_norm": 0.7323092222213745,
      "learning_rate": 7.412573826546472e-06,
      "loss": 0.3087,
      "step": 6659
    },
    {
      "epoch": 0.5175629468448866,
      "grad_norm": 0.3504006564617157,
      "learning_rate": 7.412185265775568e-06,
      "loss": 0.2203,
      "step": 6660
    },
    {
      "epoch": 0.5176406589990674,
      "grad_norm": 1.078556776046753,
      "learning_rate": 7.411796705004664e-06,
      "loss": 0.6587,
      "step": 6661
    },
    {
      "epoch": 0.5177183711532484,
      "grad_norm": 0.11242593824863434,
      "learning_rate": 7.41140814423376e-06,
      "loss": 0.0485,
      "step": 6662
    },
    {
      "epoch": 0.5177960833074293,
      "grad_norm": 0.5899754166603088,
      "learning_rate": 7.411019583462854e-06,
      "loss": 0.2737,
      "step": 6663
    },
    {
      "epoch": 0.5178737954616102,
      "grad_norm": 0.72768235206604,
      "learning_rate": 7.41063102269195e-06,
      "loss": 0.7168,
      "step": 6664
    },
    {
      "epoch": 0.5179515076157911,
      "grad_norm": 0.18782708048820496,
      "learning_rate": 7.410242461921045e-06,
      "loss": 0.2506,
      "step": 6665
    },
    {
      "epoch": 0.5180292197699721,
      "grad_norm": 0.4719063341617584,
      "learning_rate": 7.40985390115014e-06,
      "loss": 0.3847,
      "step": 6666
    },
    {
      "epoch": 0.5181069319241529,
      "grad_norm": 1.7763724327087402,
      "learning_rate": 7.409465340379236e-06,
      "loss": 0.8157,
      "step": 6667
    },
    {
      "epoch": 0.5181846440783339,
      "grad_norm": 0.4498867988586426,
      "learning_rate": 7.409076779608332e-06,
      "loss": 0.1878,
      "step": 6668
    },
    {
      "epoch": 0.5182623562325148,
      "grad_norm": 0.3897418975830078,
      "learning_rate": 7.408688218837427e-06,
      "loss": 0.0836,
      "step": 6669
    },
    {
      "epoch": 0.5183400683866957,
      "grad_norm": 0.4091835618019104,
      "learning_rate": 7.408299658066523e-06,
      "loss": 0.3387,
      "step": 6670
    },
    {
      "epoch": 0.5184177805408766,
      "grad_norm": 0.12540699541568756,
      "learning_rate": 7.4079110972956185e-06,
      "loss": 0.069,
      "step": 6671
    },
    {
      "epoch": 0.5184954926950575,
      "grad_norm": 0.5119237899780273,
      "learning_rate": 7.407522536524713e-06,
      "loss": 0.0601,
      "step": 6672
    },
    {
      "epoch": 0.5185732048492384,
      "grad_norm": 0.39306923747062683,
      "learning_rate": 7.407133975753808e-06,
      "loss": 0.1148,
      "step": 6673
    },
    {
      "epoch": 0.5186509170034194,
      "grad_norm": 0.33766862750053406,
      "learning_rate": 7.406745414982904e-06,
      "loss": 0.16,
      "step": 6674
    },
    {
      "epoch": 0.5187286291576002,
      "grad_norm": 0.4178289771080017,
      "learning_rate": 7.406356854211999e-06,
      "loss": 0.4215,
      "step": 6675
    },
    {
      "epoch": 0.5188063413117812,
      "grad_norm": 0.517227053642273,
      "learning_rate": 7.405968293441095e-06,
      "loss": 0.1368,
      "step": 6676
    },
    {
      "epoch": 0.5188840534659621,
      "grad_norm": 0.11852062493562698,
      "learning_rate": 7.405579732670191e-06,
      "loss": 0.0673,
      "step": 6677
    },
    {
      "epoch": 0.518961765620143,
      "grad_norm": 0.09879559278488159,
      "learning_rate": 7.405191171899286e-06,
      "loss": 0.0153,
      "step": 6678
    },
    {
      "epoch": 0.5190394777743239,
      "grad_norm": 0.18306520581245422,
      "learning_rate": 7.4048026111283815e-06,
      "loss": 0.0345,
      "step": 6679
    },
    {
      "epoch": 0.5191171899285049,
      "grad_norm": 0.7905631065368652,
      "learning_rate": 7.404414050357477e-06,
      "loss": 0.6011,
      "step": 6680
    },
    {
      "epoch": 0.5191949020826857,
      "grad_norm": 0.2738366425037384,
      "learning_rate": 7.404025489586571e-06,
      "loss": 0.1376,
      "step": 6681
    },
    {
      "epoch": 0.5192726142368667,
      "grad_norm": 0.2103942483663559,
      "learning_rate": 7.403636928815667e-06,
      "loss": 0.0694,
      "step": 6682
    },
    {
      "epoch": 0.5193503263910476,
      "grad_norm": 0.27184563875198364,
      "learning_rate": 7.403248368044763e-06,
      "loss": 0.0575,
      "step": 6683
    },
    {
      "epoch": 0.5194280385452285,
      "grad_norm": 0.2234957367181778,
      "learning_rate": 7.402859807273858e-06,
      "loss": 0.1218,
      "step": 6684
    },
    {
      "epoch": 0.5195057506994094,
      "grad_norm": 0.14536423981189728,
      "learning_rate": 7.402471246502954e-06,
      "loss": 0.0425,
      "step": 6685
    },
    {
      "epoch": 0.5195834628535902,
      "grad_norm": 0.17044642567634583,
      "learning_rate": 7.4020826857320495e-06,
      "loss": 0.0545,
      "step": 6686
    },
    {
      "epoch": 0.5196611750077712,
      "grad_norm": 0.2555197775363922,
      "learning_rate": 7.4016941249611445e-06,
      "loss": 0.1509,
      "step": 6687
    },
    {
      "epoch": 0.5197388871619522,
      "grad_norm": 0.17483501136302948,
      "learning_rate": 7.401305564190239e-06,
      "loss": 0.047,
      "step": 6688
    },
    {
      "epoch": 0.519816599316133,
      "grad_norm": 0.36593136191368103,
      "learning_rate": 7.400917003419335e-06,
      "loss": 0.0884,
      "step": 6689
    },
    {
      "epoch": 0.519894311470314,
      "grad_norm": 0.278076171875,
      "learning_rate": 7.40052844264843e-06,
      "loss": 0.1502,
      "step": 6690
    },
    {
      "epoch": 0.5199720236244949,
      "grad_norm": 0.8250371813774109,
      "learning_rate": 7.400139881877526e-06,
      "loss": 0.3771,
      "step": 6691
    },
    {
      "epoch": 0.5200497357786757,
      "grad_norm": 0.12930722534656525,
      "learning_rate": 7.399751321106622e-06,
      "loss": 0.0859,
      "step": 6692
    },
    {
      "epoch": 0.5201274479328567,
      "grad_norm": 0.30192792415618896,
      "learning_rate": 7.3993627603357175e-06,
      "loss": 0.1881,
      "step": 6693
    },
    {
      "epoch": 0.5202051600870377,
      "grad_norm": 0.22914886474609375,
      "learning_rate": 7.3989741995648125e-06,
      "loss": 0.0594,
      "step": 6694
    },
    {
      "epoch": 0.5202828722412185,
      "grad_norm": 0.2634066939353943,
      "learning_rate": 7.398585638793908e-06,
      "loss": 0.067,
      "step": 6695
    },
    {
      "epoch": 0.5203605843953995,
      "grad_norm": 0.15004846453666687,
      "learning_rate": 7.398197078023004e-06,
      "loss": 0.0565,
      "step": 6696
    },
    {
      "epoch": 0.5204382965495804,
      "grad_norm": 0.4586781859397888,
      "learning_rate": 7.397808517252098e-06,
      "loss": 0.167,
      "step": 6697
    },
    {
      "epoch": 0.5205160087037612,
      "grad_norm": 0.3976134657859802,
      "learning_rate": 7.397419956481194e-06,
      "loss": 0.1876,
      "step": 6698
    },
    {
      "epoch": 0.5205937208579422,
      "grad_norm": 0.036940719932317734,
      "learning_rate": 7.39703139571029e-06,
      "loss": 0.012,
      "step": 6699
    },
    {
      "epoch": 0.520671433012123,
      "grad_norm": 0.24141207337379456,
      "learning_rate": 7.396642834939385e-06,
      "loss": 0.1048,
      "step": 6700
    },
    {
      "epoch": 0.520749145166304,
      "grad_norm": 0.44139397144317627,
      "learning_rate": 7.3962542741684805e-06,
      "loss": 0.7888,
      "step": 6701
    },
    {
      "epoch": 0.520826857320485,
      "grad_norm": 0.36918923258781433,
      "learning_rate": 7.395865713397576e-06,
      "loss": 0.2715,
      "step": 6702
    },
    {
      "epoch": 0.5209045694746658,
      "grad_norm": 0.11927162855863571,
      "learning_rate": 7.395477152626671e-06,
      "loss": 0.0209,
      "step": 6703
    },
    {
      "epoch": 0.5209822816288467,
      "grad_norm": 0.965154230594635,
      "learning_rate": 7.395088591855767e-06,
      "loss": 0.2914,
      "step": 6704
    },
    {
      "epoch": 0.5210599937830277,
      "grad_norm": 0.1867646425962448,
      "learning_rate": 7.394700031084863e-06,
      "loss": 0.074,
      "step": 6705
    },
    {
      "epoch": 0.5211377059372085,
      "grad_norm": 0.3462647795677185,
      "learning_rate": 7.394311470313957e-06,
      "loss": 0.2485,
      "step": 6706
    },
    {
      "epoch": 0.5212154180913895,
      "grad_norm": 0.27506810426712036,
      "learning_rate": 7.393922909543053e-06,
      "loss": 0.1287,
      "step": 6707
    },
    {
      "epoch": 0.5212931302455704,
      "grad_norm": 0.22707600891590118,
      "learning_rate": 7.3935343487721486e-06,
      "loss": 0.4628,
      "step": 6708
    },
    {
      "epoch": 0.5213708423997513,
      "grad_norm": 0.2712806165218353,
      "learning_rate": 7.3931457880012435e-06,
      "loss": 0.1288,
      "step": 6709
    },
    {
      "epoch": 0.5214485545539322,
      "grad_norm": 0.38257724046707153,
      "learning_rate": 7.392757227230339e-06,
      "loss": 0.215,
      "step": 6710
    },
    {
      "epoch": 0.5215262667081132,
      "grad_norm": 0.556212842464447,
      "learning_rate": 7.392368666459435e-06,
      "loss": 0.2217,
      "step": 6711
    },
    {
      "epoch": 0.521603978862294,
      "grad_norm": 0.426686555147171,
      "learning_rate": 7.39198010568853e-06,
      "loss": 0.2966,
      "step": 6712
    },
    {
      "epoch": 0.521681691016475,
      "grad_norm": 0.9682571887969971,
      "learning_rate": 7.391591544917626e-06,
      "loss": 0.7098,
      "step": 6713
    },
    {
      "epoch": 0.5217594031706559,
      "grad_norm": 0.4381818175315857,
      "learning_rate": 7.391202984146722e-06,
      "loss": 0.5369,
      "step": 6714
    },
    {
      "epoch": 0.5218371153248368,
      "grad_norm": 0.09208240360021591,
      "learning_rate": 7.390814423375816e-06,
      "loss": 0.0493,
      "step": 6715
    },
    {
      "epoch": 0.5219148274790177,
      "grad_norm": 0.21471813321113586,
      "learning_rate": 7.3904258626049116e-06,
      "loss": 0.0464,
      "step": 6716
    },
    {
      "epoch": 0.5219925396331986,
      "grad_norm": 0.5562453866004944,
      "learning_rate": 7.390037301834007e-06,
      "loss": 0.2504,
      "step": 6717
    },
    {
      "epoch": 0.5220702517873795,
      "grad_norm": 1.0741751194000244,
      "learning_rate": 7.389648741063102e-06,
      "loss": 0.2756,
      "step": 6718
    },
    {
      "epoch": 0.5221479639415605,
      "grad_norm": 0.16057968139648438,
      "learning_rate": 7.389260180292198e-06,
      "loss": 0.0622,
      "step": 6719
    },
    {
      "epoch": 0.5222256760957413,
      "grad_norm": 0.11765556037425995,
      "learning_rate": 7.388871619521294e-06,
      "loss": 0.02,
      "step": 6720
    },
    {
      "epoch": 0.5223033882499223,
      "grad_norm": 0.16832518577575684,
      "learning_rate": 7.388483058750389e-06,
      "loss": 0.0975,
      "step": 6721
    },
    {
      "epoch": 0.5223811004041032,
      "grad_norm": 0.3837335705757141,
      "learning_rate": 7.388094497979485e-06,
      "loss": 0.7596,
      "step": 6722
    },
    {
      "epoch": 0.5224588125582841,
      "grad_norm": 0.41693639755249023,
      "learning_rate": 7.3877059372085804e-06,
      "loss": 0.1475,
      "step": 6723
    },
    {
      "epoch": 0.522536524712465,
      "grad_norm": 0.5930354595184326,
      "learning_rate": 7.387317376437676e-06,
      "loss": 0.2513,
      "step": 6724
    },
    {
      "epoch": 0.522614236866646,
      "grad_norm": 0.09015266597270966,
      "learning_rate": 7.38692881566677e-06,
      "loss": 0.0472,
      "step": 6725
    },
    {
      "epoch": 0.5226919490208268,
      "grad_norm": 0.19739706814289093,
      "learning_rate": 7.386540254895866e-06,
      "loss": 0.1095,
      "step": 6726
    },
    {
      "epoch": 0.5227696611750078,
      "grad_norm": 0.18646414577960968,
      "learning_rate": 7.386151694124962e-06,
      "loss": 0.0711,
      "step": 6727
    },
    {
      "epoch": 0.5228473733291887,
      "grad_norm": 0.14874610304832458,
      "learning_rate": 7.385763133354057e-06,
      "loss": 0.0431,
      "step": 6728
    },
    {
      "epoch": 0.5229250854833696,
      "grad_norm": 0.38804569840431213,
      "learning_rate": 7.385374572583153e-06,
      "loss": 0.1606,
      "step": 6729
    },
    {
      "epoch": 0.5230027976375505,
      "grad_norm": 0.14998705685138702,
      "learning_rate": 7.3849860118122485e-06,
      "loss": 0.0477,
      "step": 6730
    },
    {
      "epoch": 0.5230805097917314,
      "grad_norm": 0.24763239920139313,
      "learning_rate": 7.384597451041343e-06,
      "loss": 0.096,
      "step": 6731
    },
    {
      "epoch": 0.5231582219459123,
      "grad_norm": 0.32784298062324524,
      "learning_rate": 7.384208890270439e-06,
      "loss": 0.0864,
      "step": 6732
    },
    {
      "epoch": 0.5232359341000933,
      "grad_norm": 0.24093961715698242,
      "learning_rate": 7.383820329499535e-06,
      "loss": 0.104,
      "step": 6733
    },
    {
      "epoch": 0.5233136462542741,
      "grad_norm": 0.616411030292511,
      "learning_rate": 7.383431768728629e-06,
      "loss": 0.3626,
      "step": 6734
    },
    {
      "epoch": 0.5233913584084551,
      "grad_norm": 0.16059666872024536,
      "learning_rate": 7.383043207957725e-06,
      "loss": 0.0874,
      "step": 6735
    },
    {
      "epoch": 0.523469070562636,
      "grad_norm": 0.1423359215259552,
      "learning_rate": 7.382654647186821e-06,
      "loss": 0.0785,
      "step": 6736
    },
    {
      "epoch": 0.5235467827168169,
      "grad_norm": 0.31107190251350403,
      "learning_rate": 7.382266086415916e-06,
      "loss": 0.0866,
      "step": 6737
    },
    {
      "epoch": 0.5236244948709978,
      "grad_norm": 0.5494295358657837,
      "learning_rate": 7.3818775256450115e-06,
      "loss": 0.1383,
      "step": 6738
    },
    {
      "epoch": 0.5237022070251788,
      "grad_norm": 0.06468629837036133,
      "learning_rate": 7.381488964874107e-06,
      "loss": 0.0363,
      "step": 6739
    },
    {
      "epoch": 0.5237799191793596,
      "grad_norm": 0.7169492244720459,
      "learning_rate": 7.381100404103202e-06,
      "loss": 0.1271,
      "step": 6740
    },
    {
      "epoch": 0.5238576313335406,
      "grad_norm": 0.2841266691684723,
      "learning_rate": 7.380711843332298e-06,
      "loss": 0.1573,
      "step": 6741
    },
    {
      "epoch": 0.5239353434877215,
      "grad_norm": 1.1521730422973633,
      "learning_rate": 7.380323282561394e-06,
      "loss": 1.0544,
      "step": 6742
    },
    {
      "epoch": 0.5240130556419024,
      "grad_norm": 0.01663784682750702,
      "learning_rate": 7.379934721790488e-06,
      "loss": 0.0028,
      "step": 6743
    },
    {
      "epoch": 0.5240907677960833,
      "grad_norm": 0.5826734900474548,
      "learning_rate": 7.379546161019584e-06,
      "loss": 0.3537,
      "step": 6744
    },
    {
      "epoch": 0.5241684799502643,
      "grad_norm": 0.18079166114330292,
      "learning_rate": 7.3791576002486795e-06,
      "loss": 0.1801,
      "step": 6745
    },
    {
      "epoch": 0.5242461921044451,
      "grad_norm": 0.40280070900917053,
      "learning_rate": 7.3787690394777744e-06,
      "loss": 0.4384,
      "step": 6746
    },
    {
      "epoch": 0.5243239042586261,
      "grad_norm": 0.4182835817337036,
      "learning_rate": 7.37838047870687e-06,
      "loss": 0.5013,
      "step": 6747
    },
    {
      "epoch": 0.5244016164128069,
      "grad_norm": 0.45275992155075073,
      "learning_rate": 7.377991917935966e-06,
      "loss": 0.293,
      "step": 6748
    },
    {
      "epoch": 0.5244793285669879,
      "grad_norm": 0.5629181265830994,
      "learning_rate": 7.377603357165061e-06,
      "loss": 0.5964,
      "step": 6749
    },
    {
      "epoch": 0.5245570407211688,
      "grad_norm": 0.03467004746198654,
      "learning_rate": 7.377214796394157e-06,
      "loss": 0.0091,
      "step": 6750
    },
    {
      "epoch": 0.5246347528753497,
      "grad_norm": 0.5367569327354431,
      "learning_rate": 7.376826235623253e-06,
      "loss": 0.2533,
      "step": 6751
    },
    {
      "epoch": 0.5247124650295306,
      "grad_norm": 0.20485365390777588,
      "learning_rate": 7.376437674852347e-06,
      "loss": 0.0474,
      "step": 6752
    },
    {
      "epoch": 0.5247901771837116,
      "grad_norm": 0.6945174932479858,
      "learning_rate": 7.3760491140814425e-06,
      "loss": 0.2354,
      "step": 6753
    },
    {
      "epoch": 0.5248678893378924,
      "grad_norm": 0.2300204336643219,
      "learning_rate": 7.375660553310538e-06,
      "loss": 0.1672,
      "step": 6754
    },
    {
      "epoch": 0.5249456014920734,
      "grad_norm": 0.8733893036842346,
      "learning_rate": 7.375271992539634e-06,
      "loss": 0.3586,
      "step": 6755
    },
    {
      "epoch": 0.5250233136462543,
      "grad_norm": 0.2328648716211319,
      "learning_rate": 7.374883431768729e-06,
      "loss": 0.1046,
      "step": 6756
    },
    {
      "epoch": 0.5251010258004352,
      "grad_norm": 0.3687261641025543,
      "learning_rate": 7.374494870997825e-06,
      "loss": 0.0479,
      "step": 6757
    },
    {
      "epoch": 0.5251787379546161,
      "grad_norm": 0.028659511357545853,
      "learning_rate": 7.374106310226921e-06,
      "loss": 0.0073,
      "step": 6758
    },
    {
      "epoch": 0.5252564501087971,
      "grad_norm": 0.672091007232666,
      "learning_rate": 7.3737177494560156e-06,
      "loss": 0.3949,
      "step": 6759
    },
    {
      "epoch": 0.5253341622629779,
      "grad_norm": 0.31495213508605957,
      "learning_rate": 7.373329188685111e-06,
      "loss": 0.0721,
      "step": 6760
    },
    {
      "epoch": 0.5254118744171589,
      "grad_norm": 0.5089846253395081,
      "learning_rate": 7.372940627914207e-06,
      "loss": 0.1169,
      "step": 6761
    },
    {
      "epoch": 0.5254895865713397,
      "grad_norm": 0.30196985602378845,
      "learning_rate": 7.372552067143301e-06,
      "loss": 0.1271,
      "step": 6762
    },
    {
      "epoch": 0.5255672987255207,
      "grad_norm": 0.5116668939590454,
      "learning_rate": 7.372163506372397e-06,
      "loss": 0.2067,
      "step": 6763
    },
    {
      "epoch": 0.5256450108797016,
      "grad_norm": 0.08689437806606293,
      "learning_rate": 7.371774945601493e-06,
      "loss": 0.0179,
      "step": 6764
    },
    {
      "epoch": 0.5257227230338825,
      "grad_norm": 0.33043715357780457,
      "learning_rate": 7.371386384830588e-06,
      "loss": 0.393,
      "step": 6765
    },
    {
      "epoch": 0.5258004351880634,
      "grad_norm": 0.4117586612701416,
      "learning_rate": 7.370997824059684e-06,
      "loss": 0.737,
      "step": 6766
    },
    {
      "epoch": 0.5258781473422444,
      "grad_norm": 0.17043153941631317,
      "learning_rate": 7.370609263288779e-06,
      "loss": 0.0343,
      "step": 6767
    },
    {
      "epoch": 0.5259558594964252,
      "grad_norm": 0.19762152433395386,
      "learning_rate": 7.370220702517874e-06,
      "loss": 0.0977,
      "step": 6768
    },
    {
      "epoch": 0.5260335716506062,
      "grad_norm": 0.10721781849861145,
      "learning_rate": 7.36983214174697e-06,
      "loss": 0.0445,
      "step": 6769
    },
    {
      "epoch": 0.5261112838047871,
      "grad_norm": 0.5343095660209656,
      "learning_rate": 7.369443580976066e-06,
      "loss": 0.2191,
      "step": 6770
    },
    {
      "epoch": 0.526188995958968,
      "grad_norm": 0.402372807264328,
      "learning_rate": 7.36905502020516e-06,
      "loss": 0.1848,
      "step": 6771
    },
    {
      "epoch": 0.5262667081131489,
      "grad_norm": 0.19117678701877594,
      "learning_rate": 7.368666459434256e-06,
      "loss": 0.0755,
      "step": 6772
    },
    {
      "epoch": 0.5263444202673299,
      "grad_norm": 0.11166103184223175,
      "learning_rate": 7.368277898663352e-06,
      "loss": 0.039,
      "step": 6773
    },
    {
      "epoch": 0.5264221324215107,
      "grad_norm": 0.7127689719200134,
      "learning_rate": 7.367889337892447e-06,
      "loss": 0.5655,
      "step": 6774
    },
    {
      "epoch": 0.5264998445756917,
      "grad_norm": 0.2662719488143921,
      "learning_rate": 7.367500777121542e-06,
      "loss": 0.1759,
      "step": 6775
    },
    {
      "epoch": 0.5265775567298725,
      "grad_norm": 0.19440379738807678,
      "learning_rate": 7.367112216350638e-06,
      "loss": 0.1332,
      "step": 6776
    },
    {
      "epoch": 0.5266552688840535,
      "grad_norm": 0.13381463289260864,
      "learning_rate": 7.366723655579733e-06,
      "loss": 0.0441,
      "step": 6777
    },
    {
      "epoch": 0.5267329810382344,
      "grad_norm": 0.2292655110359192,
      "learning_rate": 7.366335094808829e-06,
      "loss": 0.0305,
      "step": 6778
    },
    {
      "epoch": 0.5268106931924152,
      "grad_norm": 0.2728225588798523,
      "learning_rate": 7.365946534037925e-06,
      "loss": 0.1888,
      "step": 6779
    },
    {
      "epoch": 0.5268884053465962,
      "grad_norm": 0.12274320423603058,
      "learning_rate": 7.365557973267019e-06,
      "loss": 0.0373,
      "step": 6780
    },
    {
      "epoch": 0.5269661175007772,
      "grad_norm": 0.639750063419342,
      "learning_rate": 7.365169412496115e-06,
      "loss": 0.7016,
      "step": 6781
    },
    {
      "epoch": 0.527043829654958,
      "grad_norm": 0.3780727982521057,
      "learning_rate": 7.3647808517252104e-06,
      "loss": 0.3124,
      "step": 6782
    },
    {
      "epoch": 0.527121541809139,
      "grad_norm": 0.33905425667762756,
      "learning_rate": 7.364392290954305e-06,
      "loss": 0.186,
      "step": 6783
    },
    {
      "epoch": 0.5271992539633199,
      "grad_norm": 0.10211891680955887,
      "learning_rate": 7.364003730183401e-06,
      "loss": 0.0134,
      "step": 6784
    },
    {
      "epoch": 0.5272769661175007,
      "grad_norm": 0.3898828625679016,
      "learning_rate": 7.363615169412497e-06,
      "loss": 0.2151,
      "step": 6785
    },
    {
      "epoch": 0.5273546782716817,
      "grad_norm": 0.30490759015083313,
      "learning_rate": 7.363226608641593e-06,
      "loss": 0.0329,
      "step": 6786
    },
    {
      "epoch": 0.5274323904258627,
      "grad_norm": 0.15092335641384125,
      "learning_rate": 7.362838047870688e-06,
      "loss": 0.0315,
      "step": 6787
    },
    {
      "epoch": 0.5275101025800435,
      "grad_norm": 0.2623854875564575,
      "learning_rate": 7.3624494870997835e-06,
      "loss": 0.1232,
      "step": 6788
    },
    {
      "epoch": 0.5275878147342244,
      "grad_norm": 0.20887987315654755,
      "learning_rate": 7.362060926328879e-06,
      "loss": 0.1142,
      "step": 6789
    },
    {
      "epoch": 0.5276655268884054,
      "grad_norm": 0.33283379673957825,
      "learning_rate": 7.361672365557973e-06,
      "loss": 0.2004,
      "step": 6790
    },
    {
      "epoch": 0.5277432390425862,
      "grad_norm": 0.9144144654273987,
      "learning_rate": 7.361283804787069e-06,
      "loss": 0.4503,
      "step": 6791
    },
    {
      "epoch": 0.5278209511967672,
      "grad_norm": 0.30586180090904236,
      "learning_rate": 7.360895244016165e-06,
      "loss": 0.1113,
      "step": 6792
    },
    {
      "epoch": 0.527898663350948,
      "grad_norm": 0.1983577162027359,
      "learning_rate": 7.36050668324526e-06,
      "loss": 0.0846,
      "step": 6793
    },
    {
      "epoch": 0.527976375505129,
      "grad_norm": 0.39512884616851807,
      "learning_rate": 7.360118122474356e-06,
      "loss": 0.117,
      "step": 6794
    },
    {
      "epoch": 0.52805408765931,
      "grad_norm": 0.3010712265968323,
      "learning_rate": 7.3597295617034515e-06,
      "loss": 0.198,
      "step": 6795
    },
    {
      "epoch": 0.5281317998134908,
      "grad_norm": 0.8022851347923279,
      "learning_rate": 7.3593410009325465e-06,
      "loss": 0.109,
      "step": 6796
    },
    {
      "epoch": 0.5282095119676717,
      "grad_norm": 0.38799577951431274,
      "learning_rate": 7.358952440161642e-06,
      "loss": 0.3058,
      "step": 6797
    },
    {
      "epoch": 0.5282872241218527,
      "grad_norm": 0.05829523503780365,
      "learning_rate": 7.358563879390738e-06,
      "loss": 0.0084,
      "step": 6798
    },
    {
      "epoch": 0.5283649362760335,
      "grad_norm": 0.37478315830230713,
      "learning_rate": 7.358175318619832e-06,
      "loss": 0.0861,
      "step": 6799
    },
    {
      "epoch": 0.5284426484302145,
      "grad_norm": 1.1884607076644897,
      "learning_rate": 7.357786757848928e-06,
      "loss": 0.403,
      "step": 6800
    },
    {
      "epoch": 0.5285203605843954,
      "grad_norm": 2.890658140182495,
      "learning_rate": 7.357398197078024e-06,
      "loss": 0.6601,
      "step": 6801
    },
    {
      "epoch": 0.5285980727385763,
      "grad_norm": 0.3913528025150299,
      "learning_rate": 7.357009636307119e-06,
      "loss": 0.309,
      "step": 6802
    },
    {
      "epoch": 0.5286757848927572,
      "grad_norm": 0.19494172930717468,
      "learning_rate": 7.3566210755362145e-06,
      "loss": 0.0397,
      "step": 6803
    },
    {
      "epoch": 0.5287534970469382,
      "grad_norm": 0.6617915630340576,
      "learning_rate": 7.35623251476531e-06,
      "loss": 0.3655,
      "step": 6804
    },
    {
      "epoch": 0.528831209201119,
      "grad_norm": 0.16888874769210815,
      "learning_rate": 7.355843953994405e-06,
      "loss": 0.0536,
      "step": 6805
    },
    {
      "epoch": 0.5289089213553,
      "grad_norm": 0.6350910067558289,
      "learning_rate": 7.355455393223501e-06,
      "loss": 0.1416,
      "step": 6806
    },
    {
      "epoch": 0.5289866335094808,
      "grad_norm": 0.3058050870895386,
      "learning_rate": 7.355066832452596e-06,
      "loss": 0.1111,
      "step": 6807
    },
    {
      "epoch": 0.5290643456636618,
      "grad_norm": 0.43347877264022827,
      "learning_rate": 7.354678271681691e-06,
      "loss": 0.1952,
      "step": 6808
    },
    {
      "epoch": 0.5291420578178427,
      "grad_norm": 0.3159952461719513,
      "learning_rate": 7.354289710910787e-06,
      "loss": 0.1311,
      "step": 6809
    },
    {
      "epoch": 0.5292197699720236,
      "grad_norm": 0.23663096129894257,
      "learning_rate": 7.3539011501398826e-06,
      "loss": 0.0484,
      "step": 6810
    },
    {
      "epoch": 0.5292974821262045,
      "grad_norm": 0.5544254779815674,
      "learning_rate": 7.3535125893689775e-06,
      "loss": 0.3144,
      "step": 6811
    },
    {
      "epoch": 0.5293751942803855,
      "grad_norm": 0.5106509923934937,
      "learning_rate": 7.353124028598073e-06,
      "loss": 0.1579,
      "step": 6812
    },
    {
      "epoch": 0.5294529064345663,
      "grad_norm": 0.2859833240509033,
      "learning_rate": 7.352735467827169e-06,
      "loss": 0.0748,
      "step": 6813
    },
    {
      "epoch": 0.5295306185887473,
      "grad_norm": 0.16254150867462158,
      "learning_rate": 7.352346907056265e-06,
      "loss": 0.0219,
      "step": 6814
    },
    {
      "epoch": 0.5296083307429282,
      "grad_norm": 0.12597247958183289,
      "learning_rate": 7.351958346285359e-06,
      "loss": 0.0697,
      "step": 6815
    },
    {
      "epoch": 0.5296860428971091,
      "grad_norm": 1.1456624269485474,
      "learning_rate": 7.351569785514455e-06,
      "loss": 0.2439,
      "step": 6816
    },
    {
      "epoch": 0.52976375505129,
      "grad_norm": 0.29982197284698486,
      "learning_rate": 7.351181224743551e-06,
      "loss": 0.2712,
      "step": 6817
    },
    {
      "epoch": 0.529841467205471,
      "grad_norm": 0.34621870517730713,
      "learning_rate": 7.3507926639726456e-06,
      "loss": 0.1797,
      "step": 6818
    },
    {
      "epoch": 0.5299191793596518,
      "grad_norm": 0.24842074513435364,
      "learning_rate": 7.350404103201741e-06,
      "loss": 0.1092,
      "step": 6819
    },
    {
      "epoch": 0.5299968915138328,
      "grad_norm": 0.388852059841156,
      "learning_rate": 7.350015542430837e-06,
      "loss": 0.0711,
      "step": 6820
    },
    {
      "epoch": 0.5300746036680136,
      "grad_norm": 0.6670699715614319,
      "learning_rate": 7.349626981659932e-06,
      "loss": 0.5731,
      "step": 6821
    },
    {
      "epoch": 0.5301523158221946,
      "grad_norm": 0.22096174955368042,
      "learning_rate": 7.349238420889028e-06,
      "loss": 0.1427,
      "step": 6822
    },
    {
      "epoch": 0.5302300279763755,
      "grad_norm": 0.09837803244590759,
      "learning_rate": 7.348849860118124e-06,
      "loss": 0.0176,
      "step": 6823
    },
    {
      "epoch": 0.5303077401305564,
      "grad_norm": 1.048378825187683,
      "learning_rate": 7.348461299347218e-06,
      "loss": 0.3156,
      "step": 6824
    },
    {
      "epoch": 0.5303854522847373,
      "grad_norm": 0.487244576215744,
      "learning_rate": 7.348072738576314e-06,
      "loss": 0.2716,
      "step": 6825
    },
    {
      "epoch": 0.5304631644389183,
      "grad_norm": 0.14955109357833862,
      "learning_rate": 7.347684177805409e-06,
      "loss": 0.0505,
      "step": 6826
    },
    {
      "epoch": 0.5305408765930991,
      "grad_norm": 0.29938629269599915,
      "learning_rate": 7.347295617034504e-06,
      "loss": 0.098,
      "step": 6827
    },
    {
      "epoch": 0.5306185887472801,
      "grad_norm": 0.11180918663740158,
      "learning_rate": 7.3469070562636e-06,
      "loss": 0.0723,
      "step": 6828
    },
    {
      "epoch": 0.530696300901461,
      "grad_norm": 0.5854099988937378,
      "learning_rate": 7.346518495492696e-06,
      "loss": 0.708,
      "step": 6829
    },
    {
      "epoch": 0.5307740130556419,
      "grad_norm": 0.7885770201683044,
      "learning_rate": 7.346129934721791e-06,
      "loss": 0.1943,
      "step": 6830
    },
    {
      "epoch": 0.5308517252098228,
      "grad_norm": 0.5476531982421875,
      "learning_rate": 7.345741373950887e-06,
      "loss": 0.3335,
      "step": 6831
    },
    {
      "epoch": 0.5309294373640038,
      "grad_norm": 0.15842874348163605,
      "learning_rate": 7.3453528131799825e-06,
      "loss": 0.0303,
      "step": 6832
    },
    {
      "epoch": 0.5310071495181846,
      "grad_norm": 0.24847130477428436,
      "learning_rate": 7.344964252409077e-06,
      "loss": 0.1387,
      "step": 6833
    },
    {
      "epoch": 0.5310848616723656,
      "grad_norm": 0.6365240216255188,
      "learning_rate": 7.344575691638172e-06,
      "loss": 0.5921,
      "step": 6834
    },
    {
      "epoch": 0.5311625738265465,
      "grad_norm": 0.2891096770763397,
      "learning_rate": 7.344187130867268e-06,
      "loss": 0.31,
      "step": 6835
    },
    {
      "epoch": 0.5312402859807274,
      "grad_norm": 0.21569734811782837,
      "learning_rate": 7.343798570096363e-06,
      "loss": 0.1389,
      "step": 6836
    },
    {
      "epoch": 0.5313179981349083,
      "grad_norm": 0.18937091529369354,
      "learning_rate": 7.343410009325459e-06,
      "loss": 0.1378,
      "step": 6837
    },
    {
      "epoch": 0.5313957102890892,
      "grad_norm": 0.3193379044532776,
      "learning_rate": 7.343021448554555e-06,
      "loss": 0.0737,
      "step": 6838
    },
    {
      "epoch": 0.5314734224432701,
      "grad_norm": 0.6173467040061951,
      "learning_rate": 7.34263288778365e-06,
      "loss": 0.1601,
      "step": 6839
    },
    {
      "epoch": 0.5315511345974511,
      "grad_norm": 0.19958020746707916,
      "learning_rate": 7.3422443270127455e-06,
      "loss": 0.0951,
      "step": 6840
    },
    {
      "epoch": 0.5316288467516319,
      "grad_norm": 0.2767086625099182,
      "learning_rate": 7.341855766241841e-06,
      "loss": 0.0602,
      "step": 6841
    },
    {
      "epoch": 0.5317065589058129,
      "grad_norm": 0.8252941370010376,
      "learning_rate": 7.341467205470935e-06,
      "loss": 0.1159,
      "step": 6842
    },
    {
      "epoch": 0.5317842710599938,
      "grad_norm": 0.33685362339019775,
      "learning_rate": 7.341078644700031e-06,
      "loss": 0.1435,
      "step": 6843
    },
    {
      "epoch": 0.5318619832141747,
      "grad_norm": 0.41736072301864624,
      "learning_rate": 7.340690083929127e-06,
      "loss": 0.7739,
      "step": 6844
    },
    {
      "epoch": 0.5319396953683556,
      "grad_norm": 0.32033729553222656,
      "learning_rate": 7.340301523158223e-06,
      "loss": 0.2059,
      "step": 6845
    },
    {
      "epoch": 0.5320174075225366,
      "grad_norm": 0.3668464124202728,
      "learning_rate": 7.339912962387318e-06,
      "loss": 0.506,
      "step": 6846
    },
    {
      "epoch": 0.5320951196767174,
      "grad_norm": 0.22934836149215698,
      "learning_rate": 7.3395244016164135e-06,
      "loss": 0.0641,
      "step": 6847
    },
    {
      "epoch": 0.5321728318308984,
      "grad_norm": 0.40888863801956177,
      "learning_rate": 7.339135840845509e-06,
      "loss": 0.0986,
      "step": 6848
    },
    {
      "epoch": 0.5322505439850793,
      "grad_norm": 0.2877519130706787,
      "learning_rate": 7.338747280074604e-06,
      "loss": 0.1241,
      "step": 6849
    },
    {
      "epoch": 0.5323282561392602,
      "grad_norm": 0.13342620432376862,
      "learning_rate": 7.3383587193037e-06,
      "loss": 0.0715,
      "step": 6850
    },
    {
      "epoch": 0.5324059682934411,
      "grad_norm": 0.5825364589691162,
      "learning_rate": 7.337970158532796e-06,
      "loss": 0.3384,
      "step": 6851
    },
    {
      "epoch": 0.532483680447622,
      "grad_norm": 0.4650167226791382,
      "learning_rate": 7.33758159776189e-06,
      "loss": 1.0649,
      "step": 6852
    },
    {
      "epoch": 0.5325613926018029,
      "grad_norm": 0.4705859422683716,
      "learning_rate": 7.337193036990986e-06,
      "loss": 0.2314,
      "step": 6853
    },
    {
      "epoch": 0.5326391047559839,
      "grad_norm": 0.30747514963150024,
      "learning_rate": 7.3368044762200815e-06,
      "loss": 0.1322,
      "step": 6854
    },
    {
      "epoch": 0.5327168169101647,
      "grad_norm": 0.3927130103111267,
      "learning_rate": 7.3364159154491765e-06,
      "loss": 0.1827,
      "step": 6855
    },
    {
      "epoch": 0.5327945290643457,
      "grad_norm": 0.1908159703016281,
      "learning_rate": 7.336027354678272e-06,
      "loss": 0.0618,
      "step": 6856
    },
    {
      "epoch": 0.5328722412185266,
      "grad_norm": 0.27026090025901794,
      "learning_rate": 7.335638793907368e-06,
      "loss": 0.0583,
      "step": 6857
    },
    {
      "epoch": 0.5329499533727075,
      "grad_norm": 0.07860694080591202,
      "learning_rate": 7.335250233136463e-06,
      "loss": 0.03,
      "step": 6858
    },
    {
      "epoch": 0.5330276655268884,
      "grad_norm": 0.3350231647491455,
      "learning_rate": 7.334861672365559e-06,
      "loss": 0.2197,
      "step": 6859
    },
    {
      "epoch": 0.5331053776810694,
      "grad_norm": 0.315582275390625,
      "learning_rate": 7.334473111594655e-06,
      "loss": 0.1467,
      "step": 6860
    },
    {
      "epoch": 0.5331830898352502,
      "grad_norm": 0.1348596066236496,
      "learning_rate": 7.334084550823749e-06,
      "loss": 0.0316,
      "step": 6861
    },
    {
      "epoch": 0.5332608019894312,
      "grad_norm": 0.09808898717164993,
      "learning_rate": 7.3336959900528445e-06,
      "loss": 0.0531,
      "step": 6862
    },
    {
      "epoch": 0.5333385141436121,
      "grad_norm": 0.4082317352294922,
      "learning_rate": 7.33330742928194e-06,
      "loss": 0.0972,
      "step": 6863
    },
    {
      "epoch": 0.533416226297793,
      "grad_norm": 0.31534895300865173,
      "learning_rate": 7.332918868511035e-06,
      "loss": 0.575,
      "step": 6864
    },
    {
      "epoch": 0.5334939384519739,
      "grad_norm": 0.1647072732448578,
      "learning_rate": 7.332530307740131e-06,
      "loss": 0.0531,
      "step": 6865
    },
    {
      "epoch": 0.5335716506061549,
      "grad_norm": 1.0863912105560303,
      "learning_rate": 7.332141746969227e-06,
      "loss": 0.5403,
      "step": 6866
    },
    {
      "epoch": 0.5336493627603357,
      "grad_norm": 0.5288548469543457,
      "learning_rate": 7.331753186198322e-06,
      "loss": 0.5906,
      "step": 6867
    },
    {
      "epoch": 0.5337270749145167,
      "grad_norm": 0.1249731183052063,
      "learning_rate": 7.331364625427418e-06,
      "loss": 0.0266,
      "step": 6868
    },
    {
      "epoch": 0.5338047870686975,
      "grad_norm": 0.3442288041114807,
      "learning_rate": 7.330976064656513e-06,
      "loss": 0.0861,
      "step": 6869
    },
    {
      "epoch": 0.5338824992228784,
      "grad_norm": 0.07694362848997116,
      "learning_rate": 7.3305875038856075e-06,
      "loss": 0.0126,
      "step": 6870
    },
    {
      "epoch": 0.5339602113770594,
      "grad_norm": 0.27463409304618835,
      "learning_rate": 7.330198943114703e-06,
      "loss": 0.1118,
      "step": 6871
    },
    {
      "epoch": 0.5340379235312402,
      "grad_norm": 0.29076653718948364,
      "learning_rate": 7.329810382343799e-06,
      "loss": 0.0455,
      "step": 6872
    },
    {
      "epoch": 0.5341156356854212,
      "grad_norm": 0.2503342926502228,
      "learning_rate": 7.329421821572894e-06,
      "loss": 0.1767,
      "step": 6873
    },
    {
      "epoch": 0.5341933478396022,
      "grad_norm": 0.3882130980491638,
      "learning_rate": 7.32903326080199e-06,
      "loss": 0.9592,
      "step": 6874
    },
    {
      "epoch": 0.534271059993783,
      "grad_norm": 0.1839212030172348,
      "learning_rate": 7.328644700031086e-06,
      "loss": 0.0373,
      "step": 6875
    },
    {
      "epoch": 0.534348772147964,
      "grad_norm": 0.14152036607265472,
      "learning_rate": 7.3282561392601814e-06,
      "loss": 0.0388,
      "step": 6876
    },
    {
      "epoch": 0.5344264843021449,
      "grad_norm": 0.4812428653240204,
      "learning_rate": 7.327867578489276e-06,
      "loss": 0.1153,
      "step": 6877
    },
    {
      "epoch": 0.5345041964563257,
      "grad_norm": 0.25843334197998047,
      "learning_rate": 7.327479017718372e-06,
      "loss": 0.0976,
      "step": 6878
    },
    {
      "epoch": 0.5345819086105067,
      "grad_norm": 0.48627573251724243,
      "learning_rate": 7.327090456947468e-06,
      "loss": 0.3232,
      "step": 6879
    },
    {
      "epoch": 0.5346596207646876,
      "grad_norm": 0.3822211027145386,
      "learning_rate": 7.326701896176562e-06,
      "loss": 0.26,
      "step": 6880
    },
    {
      "epoch": 0.5347373329188685,
      "grad_norm": 0.1832762062549591,
      "learning_rate": 7.326313335405658e-06,
      "loss": 0.0656,
      "step": 6881
    },
    {
      "epoch": 0.5348150450730494,
      "grad_norm": 0.41531533002853394,
      "learning_rate": 7.325924774634754e-06,
      "loss": 0.3046,
      "step": 6882
    },
    {
      "epoch": 0.5348927572272303,
      "grad_norm": 0.3851030766963959,
      "learning_rate": 7.325536213863849e-06,
      "loss": 0.1074,
      "step": 6883
    },
    {
      "epoch": 0.5349704693814112,
      "grad_norm": 0.21615587174892426,
      "learning_rate": 7.3251476530929444e-06,
      "loss": 0.0639,
      "step": 6884
    },
    {
      "epoch": 0.5350481815355922,
      "grad_norm": 0.7607672810554504,
      "learning_rate": 7.32475909232204e-06,
      "loss": 0.4373,
      "step": 6885
    },
    {
      "epoch": 0.535125893689773,
      "grad_norm": 0.09515374153852463,
      "learning_rate": 7.324370531551135e-06,
      "loss": 0.0221,
      "step": 6886
    },
    {
      "epoch": 0.535203605843954,
      "grad_norm": 0.31378790736198425,
      "learning_rate": 7.323981970780231e-06,
      "loss": 0.2298,
      "step": 6887
    },
    {
      "epoch": 0.5352813179981349,
      "grad_norm": 0.30280137062072754,
      "learning_rate": 7.323593410009327e-06,
      "loss": 0.0687,
      "step": 6888
    },
    {
      "epoch": 0.5353590301523158,
      "grad_norm": 0.8438976407051086,
      "learning_rate": 7.323204849238421e-06,
      "loss": 0.1348,
      "step": 6889
    },
    {
      "epoch": 0.5354367423064967,
      "grad_norm": 0.47080275416374207,
      "learning_rate": 7.322816288467517e-06,
      "loss": 0.168,
      "step": 6890
    },
    {
      "epoch": 0.5355144544606777,
      "grad_norm": 0.30632004141807556,
      "learning_rate": 7.3224277276966125e-06,
      "loss": 0.239,
      "step": 6891
    },
    {
      "epoch": 0.5355921666148585,
      "grad_norm": 0.19817450642585754,
      "learning_rate": 7.322039166925707e-06,
      "loss": 0.0796,
      "step": 6892
    },
    {
      "epoch": 0.5356698787690395,
      "grad_norm": 0.12840090692043304,
      "learning_rate": 7.321650606154803e-06,
      "loss": 0.044,
      "step": 6893
    },
    {
      "epoch": 0.5357475909232204,
      "grad_norm": 0.44444212317466736,
      "learning_rate": 7.321262045383899e-06,
      "loss": 0.2962,
      "step": 6894
    },
    {
      "epoch": 0.5358253030774013,
      "grad_norm": 0.23169435560703278,
      "learning_rate": 7.320873484612994e-06,
      "loss": 0.0496,
      "step": 6895
    },
    {
      "epoch": 0.5359030152315822,
      "grad_norm": 0.41264134645462036,
      "learning_rate": 7.32048492384209e-06,
      "loss": 0.1292,
      "step": 6896
    },
    {
      "epoch": 0.5359807273857631,
      "grad_norm": 0.4640308916568756,
      "learning_rate": 7.3200963630711856e-06,
      "loss": 0.404,
      "step": 6897
    },
    {
      "epoch": 0.536058439539944,
      "grad_norm": 0.24945245683193207,
      "learning_rate": 7.31970780230028e-06,
      "loss": 0.0841,
      "step": 6898
    },
    {
      "epoch": 0.536136151694125,
      "grad_norm": 0.3300190567970276,
      "learning_rate": 7.3193192415293755e-06,
      "loss": 0.0959,
      "step": 6899
    },
    {
      "epoch": 0.5362138638483058,
      "grad_norm": 0.11741258949041367,
      "learning_rate": 7.318930680758471e-06,
      "loss": 0.0632,
      "step": 6900
    },
    {
      "epoch": 0.5362915760024868,
      "grad_norm": 0.23816607892513275,
      "learning_rate": 7.318542119987566e-06,
      "loss": 0.0798,
      "step": 6901
    },
    {
      "epoch": 0.5363692881566677,
      "grad_norm": 0.5698406100273132,
      "learning_rate": 7.318153559216662e-06,
      "loss": 0.3796,
      "step": 6902
    },
    {
      "epoch": 0.5364470003108486,
      "grad_norm": 0.36941295862197876,
      "learning_rate": 7.317764998445758e-06,
      "loss": 0.1792,
      "step": 6903
    },
    {
      "epoch": 0.5365247124650295,
      "grad_norm": 0.2715763449668884,
      "learning_rate": 7.317376437674853e-06,
      "loss": 0.1182,
      "step": 6904
    },
    {
      "epoch": 0.5366024246192105,
      "grad_norm": 0.5382817983627319,
      "learning_rate": 7.3169878769039485e-06,
      "loss": 0.3012,
      "step": 6905
    },
    {
      "epoch": 0.5366801367733913,
      "grad_norm": 0.28590115904808044,
      "learning_rate": 7.316599316133044e-06,
      "loss": 0.1981,
      "step": 6906
    },
    {
      "epoch": 0.5367578489275723,
      "grad_norm": 0.8469358682632446,
      "learning_rate": 7.31621075536214e-06,
      "loss": 0.2093,
      "step": 6907
    },
    {
      "epoch": 0.5368355610817532,
      "grad_norm": 0.23466920852661133,
      "learning_rate": 7.315822194591234e-06,
      "loss": 0.1359,
      "step": 6908
    },
    {
      "epoch": 0.5369132732359341,
      "grad_norm": 0.334492564201355,
      "learning_rate": 7.31543363382033e-06,
      "loss": 0.1591,
      "step": 6909
    },
    {
      "epoch": 0.536990985390115,
      "grad_norm": 0.20129327476024628,
      "learning_rate": 7.315045073049426e-06,
      "loss": 0.2766,
      "step": 6910
    },
    {
      "epoch": 0.537068697544296,
      "grad_norm": 0.3459753394126892,
      "learning_rate": 7.314656512278521e-06,
      "loss": 0.1392,
      "step": 6911
    },
    {
      "epoch": 0.5371464096984768,
      "grad_norm": 0.5313065648078918,
      "learning_rate": 7.3142679515076166e-06,
      "loss": 0.1243,
      "step": 6912
    },
    {
      "epoch": 0.5372241218526578,
      "grad_norm": 0.16698722541332245,
      "learning_rate": 7.313879390736712e-06,
      "loss": 0.0708,
      "step": 6913
    },
    {
      "epoch": 0.5373018340068386,
      "grad_norm": 0.37241068482398987,
      "learning_rate": 7.313490829965807e-06,
      "loss": 0.1531,
      "step": 6914
    },
    {
      "epoch": 0.5373795461610196,
      "grad_norm": 0.1206611767411232,
      "learning_rate": 7.313102269194903e-06,
      "loss": 0.0352,
      "step": 6915
    },
    {
      "epoch": 0.5374572583152005,
      "grad_norm": 0.6412609815597534,
      "learning_rate": 7.312713708423999e-06,
      "loss": 0.3748,
      "step": 6916
    },
    {
      "epoch": 0.5375349704693814,
      "grad_norm": 0.24626897275447845,
      "learning_rate": 7.312325147653093e-06,
      "loss": 0.097,
      "step": 6917
    },
    {
      "epoch": 0.5376126826235623,
      "grad_norm": 0.10386665910482407,
      "learning_rate": 7.311936586882189e-06,
      "loss": 0.0305,
      "step": 6918
    },
    {
      "epoch": 0.5376903947777433,
      "grad_norm": 0.23496654629707336,
      "learning_rate": 7.311548026111285e-06,
      "loss": 0.1296,
      "step": 6919
    },
    {
      "epoch": 0.5377681069319241,
      "grad_norm": 0.24095574021339417,
      "learning_rate": 7.3111594653403796e-06,
      "loss": 0.2114,
      "step": 6920
    },
    {
      "epoch": 0.5378458190861051,
      "grad_norm": 0.33396026492118835,
      "learning_rate": 7.310770904569475e-06,
      "loss": 0.1025,
      "step": 6921
    },
    {
      "epoch": 0.537923531240286,
      "grad_norm": 0.33062875270843506,
      "learning_rate": 7.310382343798571e-06,
      "loss": 0.1498,
      "step": 6922
    },
    {
      "epoch": 0.5380012433944669,
      "grad_norm": 0.756777286529541,
      "learning_rate": 7.309993783027666e-06,
      "loss": 0.2153,
      "step": 6923
    },
    {
      "epoch": 0.5380789555486478,
      "grad_norm": 0.11673479527235031,
      "learning_rate": 7.309605222256762e-06,
      "loss": 0.0346,
      "step": 6924
    },
    {
      "epoch": 0.5381566677028288,
      "grad_norm": 0.9006819128990173,
      "learning_rate": 7.309216661485858e-06,
      "loss": 0.6343,
      "step": 6925
    },
    {
      "epoch": 0.5382343798570096,
      "grad_norm": 0.8195324540138245,
      "learning_rate": 7.308828100714952e-06,
      "loss": 0.3805,
      "step": 6926
    },
    {
      "epoch": 0.5383120920111906,
      "grad_norm": 0.3951783776283264,
      "learning_rate": 7.308439539944048e-06,
      "loss": 0.0582,
      "step": 6927
    },
    {
      "epoch": 0.5383898041653714,
      "grad_norm": 0.3567560911178589,
      "learning_rate": 7.308050979173143e-06,
      "loss": 0.2145,
      "step": 6928
    },
    {
      "epoch": 0.5384675163195524,
      "grad_norm": 0.33243992924690247,
      "learning_rate": 7.307662418402238e-06,
      "loss": 0.2367,
      "step": 6929
    },
    {
      "epoch": 0.5385452284737333,
      "grad_norm": 0.6886011958122253,
      "learning_rate": 7.307273857631334e-06,
      "loss": 0.407,
      "step": 6930
    },
    {
      "epoch": 0.5386229406279142,
      "grad_norm": 0.9317819476127625,
      "learning_rate": 7.30688529686043e-06,
      "loss": 0.2795,
      "step": 6931
    },
    {
      "epoch": 0.5387006527820951,
      "grad_norm": 0.3657633662223816,
      "learning_rate": 7.306496736089525e-06,
      "loss": 0.0979,
      "step": 6932
    },
    {
      "epoch": 0.5387783649362761,
      "grad_norm": 0.16943718492984772,
      "learning_rate": 7.306108175318621e-06,
      "loss": 0.0468,
      "step": 6933
    },
    {
      "epoch": 0.5388560770904569,
      "grad_norm": 0.21019583940505981,
      "learning_rate": 7.305719614547716e-06,
      "loss": 0.1014,
      "step": 6934
    },
    {
      "epoch": 0.5389337892446379,
      "grad_norm": 0.25108152627944946,
      "learning_rate": 7.3053310537768114e-06,
      "loss": 0.0933,
      "step": 6935
    },
    {
      "epoch": 0.5390115013988188,
      "grad_norm": 0.2666459083557129,
      "learning_rate": 7.304942493005906e-06,
      "loss": 0.1876,
      "step": 6936
    },
    {
      "epoch": 0.5390892135529997,
      "grad_norm": 0.3944658637046814,
      "learning_rate": 7.304553932235002e-06,
      "loss": 0.2371,
      "step": 6937
    },
    {
      "epoch": 0.5391669257071806,
      "grad_norm": 0.40756112337112427,
      "learning_rate": 7.304165371464098e-06,
      "loss": 0.24,
      "step": 6938
    },
    {
      "epoch": 0.5392446378613616,
      "grad_norm": 0.4886053204536438,
      "learning_rate": 7.303776810693193e-06,
      "loss": 0.9786,
      "step": 6939
    },
    {
      "epoch": 0.5393223500155424,
      "grad_norm": 0.20264850556850433,
      "learning_rate": 7.303388249922289e-06,
      "loss": 0.0909,
      "step": 6940
    },
    {
      "epoch": 0.5394000621697234,
      "grad_norm": 0.33649295568466187,
      "learning_rate": 7.3029996891513845e-06,
      "loss": 0.6803,
      "step": 6941
    },
    {
      "epoch": 0.5394777743239043,
      "grad_norm": 0.3875511586666107,
      "learning_rate": 7.302611128380479e-06,
      "loss": 0.2873,
      "step": 6942
    },
    {
      "epoch": 0.5395554864780852,
      "grad_norm": 0.6215904951095581,
      "learning_rate": 7.302222567609574e-06,
      "loss": 0.3265,
      "step": 6943
    },
    {
      "epoch": 0.5396331986322661,
      "grad_norm": 0.07686559855937958,
      "learning_rate": 7.30183400683867e-06,
      "loss": 0.0109,
      "step": 6944
    },
    {
      "epoch": 0.539710910786447,
      "grad_norm": 0.8166471123695374,
      "learning_rate": 7.301445446067765e-06,
      "loss": 0.2729,
      "step": 6945
    },
    {
      "epoch": 0.5397886229406279,
      "grad_norm": 0.3689967095851898,
      "learning_rate": 7.301056885296861e-06,
      "loss": 0.3454,
      "step": 6946
    },
    {
      "epoch": 0.5398663350948089,
      "grad_norm": 0.45174258947372437,
      "learning_rate": 7.300668324525957e-06,
      "loss": 0.2297,
      "step": 6947
    },
    {
      "epoch": 0.5399440472489897,
      "grad_norm": 0.23442251980304718,
      "learning_rate": 7.300279763755052e-06,
      "loss": 0.1401,
      "step": 6948
    },
    {
      "epoch": 0.5400217594031707,
      "grad_norm": 0.28498852252960205,
      "learning_rate": 7.2998912029841475e-06,
      "loss": 0.1521,
      "step": 6949
    },
    {
      "epoch": 0.5400994715573516,
      "grad_norm": 0.3597448468208313,
      "learning_rate": 7.299502642213243e-06,
      "loss": 0.088,
      "step": 6950
    },
    {
      "epoch": 0.5401771837115324,
      "grad_norm": 0.6255271434783936,
      "learning_rate": 7.299114081442337e-06,
      "loss": 0.6931,
      "step": 6951
    },
    {
      "epoch": 0.5402548958657134,
      "grad_norm": 0.45739421248435974,
      "learning_rate": 7.298725520671433e-06,
      "loss": 0.2915,
      "step": 6952
    },
    {
      "epoch": 0.5403326080198944,
      "grad_norm": 0.27625396847724915,
      "learning_rate": 7.298336959900529e-06,
      "loss": 0.1828,
      "step": 6953
    },
    {
      "epoch": 0.5404103201740752,
      "grad_norm": 1.4224088191986084,
      "learning_rate": 7.297948399129624e-06,
      "loss": 0.4041,
      "step": 6954
    },
    {
      "epoch": 0.5404880323282562,
      "grad_norm": 0.302962064743042,
      "learning_rate": 7.29755983835872e-06,
      "loss": 0.0701,
      "step": 6955
    },
    {
      "epoch": 0.5405657444824371,
      "grad_norm": 0.04662388563156128,
      "learning_rate": 7.2971712775878155e-06,
      "loss": 0.0067,
      "step": 6956
    },
    {
      "epoch": 0.540643456636618,
      "grad_norm": 0.7162443995475769,
      "learning_rate": 7.2967827168169105e-06,
      "loss": 0.3491,
      "step": 6957
    },
    {
      "epoch": 0.5407211687907989,
      "grad_norm": 1.7832196950912476,
      "learning_rate": 7.296394156046006e-06,
      "loss": 0.1149,
      "step": 6958
    },
    {
      "epoch": 0.5407988809449797,
      "grad_norm": 0.08949092030525208,
      "learning_rate": 7.296005595275102e-06,
      "loss": 0.0103,
      "step": 6959
    },
    {
      "epoch": 0.5408765930991607,
      "grad_norm": 0.5447167158126831,
      "learning_rate": 7.295617034504196e-06,
      "loss": 0.4382,
      "step": 6960
    },
    {
      "epoch": 0.5409543052533416,
      "grad_norm": 0.33853843808174133,
      "learning_rate": 7.295228473733292e-06,
      "loss": 0.1832,
      "step": 6961
    },
    {
      "epoch": 0.5410320174075225,
      "grad_norm": 0.09456811845302582,
      "learning_rate": 7.294839912962388e-06,
      "loss": 0.0529,
      "step": 6962
    },
    {
      "epoch": 0.5411097295617034,
      "grad_norm": 0.4154505133628845,
      "learning_rate": 7.294451352191483e-06,
      "loss": 0.0654,
      "step": 6963
    },
    {
      "epoch": 0.5411874417158844,
      "grad_norm": 0.090024434030056,
      "learning_rate": 7.2940627914205785e-06,
      "loss": 0.0104,
      "step": 6964
    },
    {
      "epoch": 0.5412651538700652,
      "grad_norm": 0.36288580298423767,
      "learning_rate": 7.293674230649674e-06,
      "loss": 0.3156,
      "step": 6965
    },
    {
      "epoch": 0.5413428660242462,
      "grad_norm": 0.5205644965171814,
      "learning_rate": 7.29328566987877e-06,
      "loss": 0.1577,
      "step": 6966
    },
    {
      "epoch": 0.5414205781784271,
      "grad_norm": 0.48556020855903625,
      "learning_rate": 7.292897109107865e-06,
      "loss": 0.1041,
      "step": 6967
    },
    {
      "epoch": 0.541498290332608,
      "grad_norm": 0.29643726348876953,
      "learning_rate": 7.292508548336961e-06,
      "loss": 0.0984,
      "step": 6968
    },
    {
      "epoch": 0.5415760024867889,
      "grad_norm": 0.23763878643512726,
      "learning_rate": 7.292119987566057e-06,
      "loss": 0.3006,
      "step": 6969
    },
    {
      "epoch": 0.5416537146409699,
      "grad_norm": 0.06282053887844086,
      "learning_rate": 7.291731426795151e-06,
      "loss": 0.0165,
      "step": 6970
    },
    {
      "epoch": 0.5417314267951507,
      "grad_norm": 0.567679226398468,
      "learning_rate": 7.2913428660242466e-06,
      "loss": 0.2521,
      "step": 6971
    },
    {
      "epoch": 0.5418091389493317,
      "grad_norm": 0.6771328449249268,
      "learning_rate": 7.290954305253342e-06,
      "loss": 0.286,
      "step": 6972
    },
    {
      "epoch": 0.5418868511035125,
      "grad_norm": 0.5855891108512878,
      "learning_rate": 7.290565744482437e-06,
      "loss": 0.2024,
      "step": 6973
    },
    {
      "epoch": 0.5419645632576935,
      "grad_norm": 1.6095787286758423,
      "learning_rate": 7.290177183711533e-06,
      "loss": 0.4632,
      "step": 6974
    },
    {
      "epoch": 0.5420422754118744,
      "grad_norm": 0.20212799310684204,
      "learning_rate": 7.289788622940629e-06,
      "loss": 0.1708,
      "step": 6975
    },
    {
      "epoch": 0.5421199875660553,
      "grad_norm": 0.084007129073143,
      "learning_rate": 7.289400062169724e-06,
      "loss": 0.0279,
      "step": 6976
    },
    {
      "epoch": 0.5421976997202362,
      "grad_norm": 0.4176363945007324,
      "learning_rate": 7.28901150139882e-06,
      "loss": 0.1741,
      "step": 6977
    },
    {
      "epoch": 0.5422754118744172,
      "grad_norm": 0.43800878524780273,
      "learning_rate": 7.2886229406279154e-06,
      "loss": 0.1697,
      "step": 6978
    },
    {
      "epoch": 0.542353124028598,
      "grad_norm": 0.10113329440355301,
      "learning_rate": 7.2882343798570096e-06,
      "loss": 0.0219,
      "step": 6979
    },
    {
      "epoch": 0.542430836182779,
      "grad_norm": 0.36718514561653137,
      "learning_rate": 7.287845819086105e-06,
      "loss": 0.0618,
      "step": 6980
    },
    {
      "epoch": 0.5425085483369599,
      "grad_norm": 0.4428597092628479,
      "learning_rate": 7.287457258315201e-06,
      "loss": 0.0718,
      "step": 6981
    },
    {
      "epoch": 0.5425862604911408,
      "grad_norm": 0.5512232184410095,
      "learning_rate": 7.287068697544296e-06,
      "loss": 0.2866,
      "step": 6982
    },
    {
      "epoch": 0.5426639726453217,
      "grad_norm": 0.06249668821692467,
      "learning_rate": 7.286680136773392e-06,
      "loss": 0.008,
      "step": 6983
    },
    {
      "epoch": 0.5427416847995027,
      "grad_norm": 0.7414673566818237,
      "learning_rate": 7.286291576002488e-06,
      "loss": 0.3924,
      "step": 6984
    },
    {
      "epoch": 0.5428193969536835,
      "grad_norm": 0.3141951262950897,
      "learning_rate": 7.285903015231583e-06,
      "loss": 0.0733,
      "step": 6985
    },
    {
      "epoch": 0.5428971091078645,
      "grad_norm": 1.3438615798950195,
      "learning_rate": 7.2855144544606784e-06,
      "loss": 0.2788,
      "step": 6986
    },
    {
      "epoch": 0.5429748212620454,
      "grad_norm": 0.304705411195755,
      "learning_rate": 7.285125893689774e-06,
      "loss": 0.0514,
      "step": 6987
    },
    {
      "epoch": 0.5430525334162263,
      "grad_norm": 0.5672087669372559,
      "learning_rate": 7.284737332918868e-06,
      "loss": 0.5859,
      "step": 6988
    },
    {
      "epoch": 0.5431302455704072,
      "grad_norm": 0.5679364204406738,
      "learning_rate": 7.284348772147964e-06,
      "loss": 0.3041,
      "step": 6989
    },
    {
      "epoch": 0.5432079577245881,
      "grad_norm": 0.30950772762298584,
      "learning_rate": 7.28396021137706e-06,
      "loss": 0.1222,
      "step": 6990
    },
    {
      "epoch": 0.543285669878769,
      "grad_norm": 0.463556170463562,
      "learning_rate": 7.283571650606155e-06,
      "loss": 0.241,
      "step": 6991
    },
    {
      "epoch": 0.54336338203295,
      "grad_norm": 0.12714707851409912,
      "learning_rate": 7.283183089835251e-06,
      "loss": 0.0154,
      "step": 6992
    },
    {
      "epoch": 0.5434410941871308,
      "grad_norm": 0.5632147192955017,
      "learning_rate": 7.2827945290643465e-06,
      "loss": 0.1381,
      "step": 6993
    },
    {
      "epoch": 0.5435188063413118,
      "grad_norm": 0.16987445950508118,
      "learning_rate": 7.282405968293441e-06,
      "loss": 0.0647,
      "step": 6994
    },
    {
      "epoch": 0.5435965184954927,
      "grad_norm": 0.43241769075393677,
      "learning_rate": 7.282017407522537e-06,
      "loss": 0.0615,
      "step": 6995
    },
    {
      "epoch": 0.5436742306496736,
      "grad_norm": 0.9083300828933716,
      "learning_rate": 7.281628846751633e-06,
      "loss": 0.372,
      "step": 6996
    },
    {
      "epoch": 0.5437519428038545,
      "grad_norm": 0.44291213154792786,
      "learning_rate": 7.281240285980729e-06,
      "loss": 0.2164,
      "step": 6997
    },
    {
      "epoch": 0.5438296549580355,
      "grad_norm": 0.1623915284872055,
      "learning_rate": 7.280851725209823e-06,
      "loss": 0.0766,
      "step": 6998
    },
    {
      "epoch": 0.5439073671122163,
      "grad_norm": 5.65028715133667,
      "learning_rate": 7.280463164438919e-06,
      "loss": 3.3319,
      "step": 6999
    },
    {
      "epoch": 0.5439850792663973,
      "grad_norm": 0.10209880769252777,
      "learning_rate": 7.2800746036680145e-06,
      "loss": 0.0354,
      "step": 7000
    },
    {
      "epoch": 0.5440627914205782,
      "grad_norm": 0.03779303655028343,
      "learning_rate": 7.2796860428971095e-06,
      "loss": 0.0032,
      "step": 7001
    },
    {
      "epoch": 0.5441405035747591,
      "grad_norm": 0.24813294410705566,
      "learning_rate": 7.279297482126205e-06,
      "loss": 0.138,
      "step": 7002
    },
    {
      "epoch": 0.54421821572894,
      "grad_norm": 0.41834017634391785,
      "learning_rate": 7.278908921355301e-06,
      "loss": 0.1997,
      "step": 7003
    },
    {
      "epoch": 0.5442959278831209,
      "grad_norm": 0.2642455995082855,
      "learning_rate": 7.278520360584396e-06,
      "loss": 0.0314,
      "step": 7004
    },
    {
      "epoch": 0.5443736400373018,
      "grad_norm": 0.3462497293949127,
      "learning_rate": 7.278131799813492e-06,
      "loss": 0.2637,
      "step": 7005
    },
    {
      "epoch": 0.5444513521914828,
      "grad_norm": 0.17843562364578247,
      "learning_rate": 7.277743239042588e-06,
      "loss": 0.0705,
      "step": 7006
    },
    {
      "epoch": 0.5445290643456636,
      "grad_norm": 0.5151287913322449,
      "learning_rate": 7.277354678271682e-06,
      "loss": 0.0787,
      "step": 7007
    },
    {
      "epoch": 0.5446067764998446,
      "grad_norm": 0.18041573464870453,
      "learning_rate": 7.2769661175007775e-06,
      "loss": 0.0715,
      "step": 7008
    },
    {
      "epoch": 0.5446844886540255,
      "grad_norm": 0.6611024737358093,
      "learning_rate": 7.276577556729873e-06,
      "loss": 0.2243,
      "step": 7009
    },
    {
      "epoch": 0.5447622008082064,
      "grad_norm": 0.12061349302530289,
      "learning_rate": 7.276188995958968e-06,
      "loss": 0.0319,
      "step": 7010
    },
    {
      "epoch": 0.5448399129623873,
      "grad_norm": 0.32226237654685974,
      "learning_rate": 7.275800435188064e-06,
      "loss": 0.1761,
      "step": 7011
    },
    {
      "epoch": 0.5449176251165683,
      "grad_norm": 0.3702034652233124,
      "learning_rate": 7.27541187441716e-06,
      "loss": 0.1352,
      "step": 7012
    },
    {
      "epoch": 0.5449953372707491,
      "grad_norm": 0.3394857943058014,
      "learning_rate": 7.275023313646255e-06,
      "loss": 0.1813,
      "step": 7013
    },
    {
      "epoch": 0.5450730494249301,
      "grad_norm": 0.5744256973266602,
      "learning_rate": 7.274634752875351e-06,
      "loss": 0.4169,
      "step": 7014
    },
    {
      "epoch": 0.545150761579111,
      "grad_norm": 0.607558012008667,
      "learning_rate": 7.274246192104446e-06,
      "loss": 0.3879,
      "step": 7015
    },
    {
      "epoch": 0.5452284737332919,
      "grad_norm": 0.0678417980670929,
      "learning_rate": 7.2738576313335405e-06,
      "loss": 0.0252,
      "step": 7016
    },
    {
      "epoch": 0.5453061858874728,
      "grad_norm": 0.5974420309066772,
      "learning_rate": 7.273469070562636e-06,
      "loss": 0.5929,
      "step": 7017
    },
    {
      "epoch": 0.5453838980416538,
      "grad_norm": 0.4252608120441437,
      "learning_rate": 7.273080509791732e-06,
      "loss": 0.1376,
      "step": 7018
    },
    {
      "epoch": 0.5454616101958346,
      "grad_norm": 0.21509544551372528,
      "learning_rate": 7.272691949020827e-06,
      "loss": 0.1911,
      "step": 7019
    },
    {
      "epoch": 0.5455393223500156,
      "grad_norm": 0.5682011842727661,
      "learning_rate": 7.272303388249923e-06,
      "loss": 0.709,
      "step": 7020
    },
    {
      "epoch": 0.5456170345041964,
      "grad_norm": 0.5449355244636536,
      "learning_rate": 7.271914827479019e-06,
      "loss": 0.3082,
      "step": 7021
    },
    {
      "epoch": 0.5456947466583774,
      "grad_norm": 0.2847883999347687,
      "learning_rate": 7.2715262667081136e-06,
      "loss": 0.1633,
      "step": 7022
    },
    {
      "epoch": 0.5457724588125583,
      "grad_norm": 0.25917676091194153,
      "learning_rate": 7.271137705937209e-06,
      "loss": 0.0643,
      "step": 7023
    },
    {
      "epoch": 0.5458501709667392,
      "grad_norm": 0.12587065994739532,
      "learning_rate": 7.270749145166305e-06,
      "loss": 0.035,
      "step": 7024
    },
    {
      "epoch": 0.5459278831209201,
      "grad_norm": 0.3965522050857544,
      "learning_rate": 7.270360584395399e-06,
      "loss": 0.0995,
      "step": 7025
    },
    {
      "epoch": 0.5460055952751011,
      "grad_norm": 0.1696159541606903,
      "learning_rate": 7.269972023624495e-06,
      "loss": 0.0456,
      "step": 7026
    },
    {
      "epoch": 0.5460833074292819,
      "grad_norm": 0.20496952533721924,
      "learning_rate": 7.269583462853591e-06,
      "loss": 0.0756,
      "step": 7027
    },
    {
      "epoch": 0.5461610195834629,
      "grad_norm": 0.19699271023273468,
      "learning_rate": 7.269194902082687e-06,
      "loss": 0.0652,
      "step": 7028
    },
    {
      "epoch": 0.5462387317376438,
      "grad_norm": 0.5060766935348511,
      "learning_rate": 7.268806341311782e-06,
      "loss": 0.1862,
      "step": 7029
    },
    {
      "epoch": 0.5463164438918247,
      "grad_norm": 0.07402795553207397,
      "learning_rate": 7.268417780540877e-06,
      "loss": 0.0129,
      "step": 7030
    },
    {
      "epoch": 0.5463941560460056,
      "grad_norm": 0.7697686553001404,
      "learning_rate": 7.268029219769973e-06,
      "loss": 0.4374,
      "step": 7031
    },
    {
      "epoch": 0.5464718682001866,
      "grad_norm": 0.6492708921432495,
      "learning_rate": 7.267640658999068e-06,
      "loss": 0.1644,
      "step": 7032
    },
    {
      "epoch": 0.5465495803543674,
      "grad_norm": 0.4426305294036865,
      "learning_rate": 7.267252098228164e-06,
      "loss": 0.3768,
      "step": 7033
    },
    {
      "epoch": 0.5466272925085484,
      "grad_norm": 0.3698439598083496,
      "learning_rate": 7.26686353745726e-06,
      "loss": 0.2038,
      "step": 7034
    },
    {
      "epoch": 0.5467050046627292,
      "grad_norm": 0.05498431622982025,
      "learning_rate": 7.266474976686354e-06,
      "loss": 0.0129,
      "step": 7035
    },
    {
      "epoch": 0.5467827168169102,
      "grad_norm": 0.23330552875995636,
      "learning_rate": 7.26608641591545e-06,
      "loss": 0.0919,
      "step": 7036
    },
    {
      "epoch": 0.5468604289710911,
      "grad_norm": 0.36392807960510254,
      "learning_rate": 7.2656978551445454e-06,
      "loss": 0.0639,
      "step": 7037
    },
    {
      "epoch": 0.546938141125272,
      "grad_norm": 0.18023133277893066,
      "learning_rate": 7.26530929437364e-06,
      "loss": 0.0182,
      "step": 7038
    },
    {
      "epoch": 0.5470158532794529,
      "grad_norm": 0.9436032772064209,
      "learning_rate": 7.264920733602736e-06,
      "loss": 0.2151,
      "step": 7039
    },
    {
      "epoch": 0.5470935654336339,
      "grad_norm": 0.20641346275806427,
      "learning_rate": 7.264532172831832e-06,
      "loss": 0.0344,
      "step": 7040
    },
    {
      "epoch": 0.5471712775878147,
      "grad_norm": 0.0865122601389885,
      "learning_rate": 7.264143612060927e-06,
      "loss": 0.029,
      "step": 7041
    },
    {
      "epoch": 0.5472489897419957,
      "grad_norm": 0.8420761227607727,
      "learning_rate": 7.263755051290023e-06,
      "loss": 0.3638,
      "step": 7042
    },
    {
      "epoch": 0.5473267018961766,
      "grad_norm": 0.4181016683578491,
      "learning_rate": 7.2633664905191185e-06,
      "loss": 0.0988,
      "step": 7043
    },
    {
      "epoch": 0.5474044140503574,
      "grad_norm": 0.4704362750053406,
      "learning_rate": 7.262977929748213e-06,
      "loss": 0.1451,
      "step": 7044
    },
    {
      "epoch": 0.5474821262045384,
      "grad_norm": 0.09454566985368729,
      "learning_rate": 7.262589368977308e-06,
      "loss": 0.0375,
      "step": 7045
    },
    {
      "epoch": 0.5475598383587194,
      "grad_norm": 0.35847949981689453,
      "learning_rate": 7.262200808206404e-06,
      "loss": 0.107,
      "step": 7046
    },
    {
      "epoch": 0.5476375505129002,
      "grad_norm": 0.7492445707321167,
      "learning_rate": 7.261812247435499e-06,
      "loss": 0.5377,
      "step": 7047
    },
    {
      "epoch": 0.5477152626670811,
      "grad_norm": 0.35638394951820374,
      "learning_rate": 7.261423686664595e-06,
      "loss": 0.2793,
      "step": 7048
    },
    {
      "epoch": 0.547792974821262,
      "grad_norm": 0.37800970673561096,
      "learning_rate": 7.261035125893691e-06,
      "loss": 0.1274,
      "step": 7049
    },
    {
      "epoch": 0.5478706869754429,
      "grad_norm": 0.08787108957767487,
      "learning_rate": 7.260646565122786e-06,
      "loss": 0.0397,
      "step": 7050
    },
    {
      "epoch": 0.5479483991296239,
      "grad_norm": 1.0300711393356323,
      "learning_rate": 7.2602580043518815e-06,
      "loss": 0.5167,
      "step": 7051
    },
    {
      "epoch": 0.5480261112838047,
      "grad_norm": 0.2827364206314087,
      "learning_rate": 7.259869443580977e-06,
      "loss": 0.0834,
      "step": 7052
    },
    {
      "epoch": 0.5481038234379857,
      "grad_norm": 0.4352019429206848,
      "learning_rate": 7.259480882810071e-06,
      "loss": 0.2622,
      "step": 7053
    },
    {
      "epoch": 0.5481815355921666,
      "grad_norm": 0.2152174860239029,
      "learning_rate": 7.259092322039167e-06,
      "loss": 0.1065,
      "step": 7054
    },
    {
      "epoch": 0.5482592477463475,
      "grad_norm": 0.13420407474040985,
      "learning_rate": 7.258703761268263e-06,
      "loss": 0.0493,
      "step": 7055
    },
    {
      "epoch": 0.5483369599005284,
      "grad_norm": 0.14944064617156982,
      "learning_rate": 7.258315200497358e-06,
      "loss": 0.0602,
      "step": 7056
    },
    {
      "epoch": 0.5484146720547094,
      "grad_norm": 0.20722195506095886,
      "learning_rate": 7.257926639726454e-06,
      "loss": 0.0698,
      "step": 7057
    },
    {
      "epoch": 0.5484923842088902,
      "grad_norm": 0.9661616086959839,
      "learning_rate": 7.2575380789555495e-06,
      "loss": 0.4333,
      "step": 7058
    },
    {
      "epoch": 0.5485700963630712,
      "grad_norm": 0.5698450803756714,
      "learning_rate": 7.257149518184645e-06,
      "loss": 0.4308,
      "step": 7059
    },
    {
      "epoch": 0.5486478085172521,
      "grad_norm": 0.2938886880874634,
      "learning_rate": 7.25676095741374e-06,
      "loss": 0.1549,
      "step": 7060
    },
    {
      "epoch": 0.548725520671433,
      "grad_norm": 0.40970778465270996,
      "learning_rate": 7.256372396642835e-06,
      "loss": 0.1631,
      "step": 7061
    },
    {
      "epoch": 0.5488032328256139,
      "grad_norm": 0.6300449967384338,
      "learning_rate": 7.255983835871931e-06,
      "loss": 0.2252,
      "step": 7062
    },
    {
      "epoch": 0.5488809449797949,
      "grad_norm": 0.15489156544208527,
      "learning_rate": 7.255595275101026e-06,
      "loss": 0.0326,
      "step": 7063
    },
    {
      "epoch": 0.5489586571339757,
      "grad_norm": 0.410880446434021,
      "learning_rate": 7.255206714330122e-06,
      "loss": 0.3511,
      "step": 7064
    },
    {
      "epoch": 0.5490363692881567,
      "grad_norm": 0.46046558022499084,
      "learning_rate": 7.254818153559218e-06,
      "loss": 0.2678,
      "step": 7065
    },
    {
      "epoch": 0.5491140814423375,
      "grad_norm": 0.7022287845611572,
      "learning_rate": 7.2544295927883125e-06,
      "loss": 0.1055,
      "step": 7066
    },
    {
      "epoch": 0.5491917935965185,
      "grad_norm": 0.5713797211647034,
      "learning_rate": 7.254041032017408e-06,
      "loss": 0.1567,
      "step": 7067
    },
    {
      "epoch": 0.5492695057506994,
      "grad_norm": 0.4423206150531769,
      "learning_rate": 7.253652471246504e-06,
      "loss": 0.1257,
      "step": 7068
    },
    {
      "epoch": 0.5493472179048803,
      "grad_norm": 0.2288631796836853,
      "learning_rate": 7.253263910475598e-06,
      "loss": 0.1161,
      "step": 7069
    },
    {
      "epoch": 0.5494249300590612,
      "grad_norm": 0.27357760071754456,
      "learning_rate": 7.252875349704694e-06,
      "loss": 0.0757,
      "step": 7070
    },
    {
      "epoch": 0.5495026422132422,
      "grad_norm": 1.128594994544983,
      "learning_rate": 7.25248678893379e-06,
      "loss": 0.6815,
      "step": 7071
    },
    {
      "epoch": 0.549580354367423,
      "grad_norm": 0.48794451355934143,
      "learning_rate": 7.252098228162885e-06,
      "loss": 0.2885,
      "step": 7072
    },
    {
      "epoch": 0.549658066521604,
      "grad_norm": 0.5446709990501404,
      "learning_rate": 7.2517096673919806e-06,
      "loss": 0.1929,
      "step": 7073
    },
    {
      "epoch": 0.5497357786757849,
      "grad_norm": 0.2135123461484909,
      "learning_rate": 7.251321106621076e-06,
      "loss": 0.0775,
      "step": 7074
    },
    {
      "epoch": 0.5498134908299658,
      "grad_norm": 0.30692532658576965,
      "learning_rate": 7.250932545850171e-06,
      "loss": 0.2207,
      "step": 7075
    },
    {
      "epoch": 0.5498912029841467,
      "grad_norm": 0.788287878036499,
      "learning_rate": 7.250543985079267e-06,
      "loss": 0.3718,
      "step": 7076
    },
    {
      "epoch": 0.5499689151383277,
      "grad_norm": 0.7899959087371826,
      "learning_rate": 7.250155424308363e-06,
      "loss": 0.2277,
      "step": 7077
    },
    {
      "epoch": 0.5500466272925085,
      "grad_norm": 0.3922528922557831,
      "learning_rate": 7.249766863537457e-06,
      "loss": 0.228,
      "step": 7078
    },
    {
      "epoch": 0.5501243394466895,
      "grad_norm": 0.2583710849285126,
      "learning_rate": 7.249378302766553e-06,
      "loss": 0.1585,
      "step": 7079
    },
    {
      "epoch": 0.5502020516008703,
      "grad_norm": 0.11628863215446472,
      "learning_rate": 7.248989741995649e-06,
      "loss": 0.0321,
      "step": 7080
    },
    {
      "epoch": 0.5502797637550513,
      "grad_norm": 0.1476331502199173,
      "learning_rate": 7.2486011812247436e-06,
      "loss": 0.1143,
      "step": 7081
    },
    {
      "epoch": 0.5503574759092322,
      "grad_norm": 0.3724815845489502,
      "learning_rate": 7.248212620453839e-06,
      "loss": 0.1284,
      "step": 7082
    },
    {
      "epoch": 0.5504351880634131,
      "grad_norm": 0.5311188101768494,
      "learning_rate": 7.247824059682935e-06,
      "loss": 0.4245,
      "step": 7083
    },
    {
      "epoch": 0.550512900217594,
      "grad_norm": 0.17346756160259247,
      "learning_rate": 7.24743549891203e-06,
      "loss": 0.0585,
      "step": 7084
    },
    {
      "epoch": 0.550590612371775,
      "grad_norm": 0.42747777700424194,
      "learning_rate": 7.247046938141126e-06,
      "loss": 0.1812,
      "step": 7085
    },
    {
      "epoch": 0.5506683245259558,
      "grad_norm": 0.2854164242744446,
      "learning_rate": 7.246658377370222e-06,
      "loss": 0.0648,
      "step": 7086
    },
    {
      "epoch": 0.5507460366801368,
      "grad_norm": 0.42556726932525635,
      "learning_rate": 7.2462698165993175e-06,
      "loss": 0.1448,
      "step": 7087
    },
    {
      "epoch": 0.5508237488343177,
      "grad_norm": 0.3059687316417694,
      "learning_rate": 7.245881255828412e-06,
      "loss": 0.1746,
      "step": 7088
    },
    {
      "epoch": 0.5509014609884986,
      "grad_norm": 0.9675037264823914,
      "learning_rate": 7.245492695057507e-06,
      "loss": 0.2176,
      "step": 7089
    },
    {
      "epoch": 0.5509791731426795,
      "grad_norm": 0.8797789216041565,
      "learning_rate": 7.245104134286603e-06,
      "loss": 0.4008,
      "step": 7090
    },
    {
      "epoch": 0.5510568852968605,
      "grad_norm": 0.6262030005455017,
      "learning_rate": 7.244715573515698e-06,
      "loss": 0.3358,
      "step": 7091
    },
    {
      "epoch": 0.5511345974510413,
      "grad_norm": 0.3009653389453888,
      "learning_rate": 7.244327012744794e-06,
      "loss": 0.0866,
      "step": 7092
    },
    {
      "epoch": 0.5512123096052223,
      "grad_norm": 0.1359880417585373,
      "learning_rate": 7.24393845197389e-06,
      "loss": 0.0554,
      "step": 7093
    },
    {
      "epoch": 0.5512900217594032,
      "grad_norm": 0.37136656045913696,
      "learning_rate": 7.243549891202985e-06,
      "loss": 0.3084,
      "step": 7094
    },
    {
      "epoch": 0.5513677339135841,
      "grad_norm": 0.1993662714958191,
      "learning_rate": 7.2431613304320805e-06,
      "loss": 0.0175,
      "step": 7095
    },
    {
      "epoch": 0.551445446067765,
      "grad_norm": 0.1737043559551239,
      "learning_rate": 7.242772769661176e-06,
      "loss": 0.0412,
      "step": 7096
    },
    {
      "epoch": 0.5515231582219459,
      "grad_norm": 0.23141880333423615,
      "learning_rate": 7.24238420889027e-06,
      "loss": 0.0994,
      "step": 7097
    },
    {
      "epoch": 0.5516008703761268,
      "grad_norm": 0.42001858353614807,
      "learning_rate": 7.241995648119366e-06,
      "loss": 0.1783,
      "step": 7098
    },
    {
      "epoch": 0.5516785825303078,
      "grad_norm": 0.7538197636604309,
      "learning_rate": 7.241607087348462e-06,
      "loss": 0.2172,
      "step": 7099
    },
    {
      "epoch": 0.5517562946844886,
      "grad_norm": 0.22124353051185608,
      "learning_rate": 7.241218526577557e-06,
      "loss": 0.1096,
      "step": 7100
    },
    {
      "epoch": 0.5518340068386696,
      "grad_norm": 0.32833385467529297,
      "learning_rate": 7.240829965806653e-06,
      "loss": 0.3659,
      "step": 7101
    },
    {
      "epoch": 0.5519117189928505,
      "grad_norm": 0.6678447127342224,
      "learning_rate": 7.2404414050357485e-06,
      "loss": 0.1056,
      "step": 7102
    },
    {
      "epoch": 0.5519894311470314,
      "grad_norm": 0.2917563319206238,
      "learning_rate": 7.2400528442648435e-06,
      "loss": 0.2502,
      "step": 7103
    },
    {
      "epoch": 0.5520671433012123,
      "grad_norm": 0.635254442691803,
      "learning_rate": 7.239664283493939e-06,
      "loss": 0.2339,
      "step": 7104
    },
    {
      "epoch": 0.5521448554553933,
      "grad_norm": 0.29995617270469666,
      "learning_rate": 7.239275722723035e-06,
      "loss": 0.1023,
      "step": 7105
    },
    {
      "epoch": 0.5522225676095741,
      "grad_norm": 0.23470258712768555,
      "learning_rate": 7.238887161952129e-06,
      "loss": 0.0812,
      "step": 7106
    },
    {
      "epoch": 0.5523002797637551,
      "grad_norm": 0.2613818049430847,
      "learning_rate": 7.238498601181225e-06,
      "loss": 0.1068,
      "step": 7107
    },
    {
      "epoch": 0.552377991917936,
      "grad_norm": 0.2688189744949341,
      "learning_rate": 7.238110040410321e-06,
      "loss": 0.1134,
      "step": 7108
    },
    {
      "epoch": 0.5524557040721169,
      "grad_norm": 0.24970832467079163,
      "learning_rate": 7.237721479639416e-06,
      "loss": 0.1557,
      "step": 7109
    },
    {
      "epoch": 0.5525334162262978,
      "grad_norm": 0.37620437145233154,
      "learning_rate": 7.2373329188685115e-06,
      "loss": 0.1736,
      "step": 7110
    },
    {
      "epoch": 0.5526111283804787,
      "grad_norm": 0.5129480957984924,
      "learning_rate": 7.236944358097607e-06,
      "loss": 0.2065,
      "step": 7111
    },
    {
      "epoch": 0.5526888405346596,
      "grad_norm": 0.08093059808015823,
      "learning_rate": 7.236555797326702e-06,
      "loss": 0.0248,
      "step": 7112
    },
    {
      "epoch": 0.5527665526888406,
      "grad_norm": 0.4410537779331207,
      "learning_rate": 7.236167236555798e-06,
      "loss": 0.0894,
      "step": 7113
    },
    {
      "epoch": 0.5528442648430214,
      "grad_norm": 0.37542077898979187,
      "learning_rate": 7.235778675784894e-06,
      "loss": 0.1044,
      "step": 7114
    },
    {
      "epoch": 0.5529219769972024,
      "grad_norm": 0.27490925788879395,
      "learning_rate": 7.235390115013988e-06,
      "loss": 0.0819,
      "step": 7115
    },
    {
      "epoch": 0.5529996891513833,
      "grad_norm": 0.2878013551235199,
      "learning_rate": 7.235001554243084e-06,
      "loss": 0.121,
      "step": 7116
    },
    {
      "epoch": 0.5530774013055642,
      "grad_norm": 1.411228895187378,
      "learning_rate": 7.2346129934721795e-06,
      "loss": 0.3198,
      "step": 7117
    },
    {
      "epoch": 0.5531551134597451,
      "grad_norm": 0.7042560577392578,
      "learning_rate": 7.234224432701275e-06,
      "loss": 0.1514,
      "step": 7118
    },
    {
      "epoch": 0.5532328256139261,
      "grad_norm": 0.11426323652267456,
      "learning_rate": 7.23383587193037e-06,
      "loss": 0.032,
      "step": 7119
    },
    {
      "epoch": 0.5533105377681069,
      "grad_norm": 0.20021232962608337,
      "learning_rate": 7.233447311159466e-06,
      "loss": 0.0689,
      "step": 7120
    },
    {
      "epoch": 0.5533882499222879,
      "grad_norm": 0.385360985994339,
      "learning_rate": 7.233058750388562e-06,
      "loss": 0.1228,
      "step": 7121
    },
    {
      "epoch": 0.5534659620764688,
      "grad_norm": 0.5680996775627136,
      "learning_rate": 7.232670189617657e-06,
      "loss": 0.2356,
      "step": 7122
    },
    {
      "epoch": 0.5535436742306497,
      "grad_norm": 0.2178570032119751,
      "learning_rate": 7.232281628846753e-06,
      "loss": 0.0474,
      "step": 7123
    },
    {
      "epoch": 0.5536213863848306,
      "grad_norm": 0.10990578681230545,
      "learning_rate": 7.231893068075848e-06,
      "loss": 0.0077,
      "step": 7124
    },
    {
      "epoch": 0.5536990985390114,
      "grad_norm": 0.18750788271427155,
      "learning_rate": 7.2315045073049425e-06,
      "loss": 0.0658,
      "step": 7125
    },
    {
      "epoch": 0.5537768106931924,
      "grad_norm": 0.3625132739543915,
      "learning_rate": 7.231115946534038e-06,
      "loss": 0.1593,
      "step": 7126
    },
    {
      "epoch": 0.5538545228473734,
      "grad_norm": 0.16308562457561493,
      "learning_rate": 7.230727385763134e-06,
      "loss": 0.047,
      "step": 7127
    },
    {
      "epoch": 0.5539322350015542,
      "grad_norm": 0.43370357155799866,
      "learning_rate": 7.230338824992229e-06,
      "loss": 0.1157,
      "step": 7128
    },
    {
      "epoch": 0.5540099471557351,
      "grad_norm": 0.4176398813724518,
      "learning_rate": 7.229950264221325e-06,
      "loss": 0.1284,
      "step": 7129
    },
    {
      "epoch": 0.5540876593099161,
      "grad_norm": 0.40019574761390686,
      "learning_rate": 7.229561703450421e-06,
      "loss": 0.1037,
      "step": 7130
    },
    {
      "epoch": 0.554165371464097,
      "grad_norm": 0.26545462012290955,
      "learning_rate": 7.229173142679516e-06,
      "loss": 0.1244,
      "step": 7131
    },
    {
      "epoch": 0.5542430836182779,
      "grad_norm": 0.11456345021724701,
      "learning_rate": 7.228784581908611e-06,
      "loss": 0.0235,
      "step": 7132
    },
    {
      "epoch": 0.5543207957724589,
      "grad_norm": 0.4389793872833252,
      "learning_rate": 7.228396021137707e-06,
      "loss": 0.224,
      "step": 7133
    },
    {
      "epoch": 0.5543985079266397,
      "grad_norm": 0.39401865005493164,
      "learning_rate": 7.228007460366801e-06,
      "loss": 0.1335,
      "step": 7134
    },
    {
      "epoch": 0.5544762200808206,
      "grad_norm": 0.0761992484331131,
      "learning_rate": 7.227618899595897e-06,
      "loss": 0.0239,
      "step": 7135
    },
    {
      "epoch": 0.5545539322350016,
      "grad_norm": 0.3111443817615509,
      "learning_rate": 7.227230338824993e-06,
      "loss": 0.1827,
      "step": 7136
    },
    {
      "epoch": 0.5546316443891824,
      "grad_norm": 0.0789460837841034,
      "learning_rate": 7.226841778054088e-06,
      "loss": 0.0183,
      "step": 7137
    },
    {
      "epoch": 0.5547093565433634,
      "grad_norm": 0.5829523205757141,
      "learning_rate": 7.226453217283184e-06,
      "loss": 0.178,
      "step": 7138
    },
    {
      "epoch": 0.5547870686975443,
      "grad_norm": 0.22985443472862244,
      "learning_rate": 7.2260646565122794e-06,
      "loss": 0.0318,
      "step": 7139
    },
    {
      "epoch": 0.5548647808517252,
      "grad_norm": 0.5737124085426331,
      "learning_rate": 7.225676095741374e-06,
      "loss": 0.1497,
      "step": 7140
    },
    {
      "epoch": 0.5549424930059061,
      "grad_norm": 0.2461218237876892,
      "learning_rate": 7.22528753497047e-06,
      "loss": 0.0943,
      "step": 7141
    },
    {
      "epoch": 0.555020205160087,
      "grad_norm": 0.2198648899793625,
      "learning_rate": 7.224898974199566e-06,
      "loss": 0.0883,
      "step": 7142
    },
    {
      "epoch": 0.5550979173142679,
      "grad_norm": 0.26161178946495056,
      "learning_rate": 7.22451041342866e-06,
      "loss": 0.0534,
      "step": 7143
    },
    {
      "epoch": 0.5551756294684489,
      "grad_norm": 0.5067847967147827,
      "learning_rate": 7.224121852657756e-06,
      "loss": 0.5222,
      "step": 7144
    },
    {
      "epoch": 0.5552533416226297,
      "grad_norm": 0.46027639508247375,
      "learning_rate": 7.223733291886852e-06,
      "loss": 0.203,
      "step": 7145
    },
    {
      "epoch": 0.5553310537768107,
      "grad_norm": 0.3657090365886688,
      "learning_rate": 7.223344731115947e-06,
      "loss": 0.3575,
      "step": 7146
    },
    {
      "epoch": 0.5554087659309916,
      "grad_norm": 0.15874850749969482,
      "learning_rate": 7.2229561703450424e-06,
      "loss": 0.0346,
      "step": 7147
    },
    {
      "epoch": 0.5554864780851725,
      "grad_norm": 0.21173863112926483,
      "learning_rate": 7.222567609574138e-06,
      "loss": 0.0318,
      "step": 7148
    },
    {
      "epoch": 0.5555641902393534,
      "grad_norm": 0.24137382209300995,
      "learning_rate": 7.222179048803234e-06,
      "loss": 0.0884,
      "step": 7149
    },
    {
      "epoch": 0.5556419023935344,
      "grad_norm": 0.7759358882904053,
      "learning_rate": 7.221790488032329e-06,
      "loss": 0.5489,
      "step": 7150
    },
    {
      "epoch": 0.5557196145477152,
      "grad_norm": 0.22249983251094818,
      "learning_rate": 7.221401927261425e-06,
      "loss": 0.1376,
      "step": 7151
    },
    {
      "epoch": 0.5557973267018962,
      "grad_norm": 0.39138489961624146,
      "learning_rate": 7.2210133664905206e-06,
      "loss": 0.3159,
      "step": 7152
    },
    {
      "epoch": 0.5558750388560771,
      "grad_norm": 0.6289116740226746,
      "learning_rate": 7.220624805719615e-06,
      "loss": 0.7104,
      "step": 7153
    },
    {
      "epoch": 0.555952751010258,
      "grad_norm": 1.3363641500473022,
      "learning_rate": 7.2202362449487105e-06,
      "loss": 0.306,
      "step": 7154
    },
    {
      "epoch": 0.5560304631644389,
      "grad_norm": 0.20785705745220184,
      "learning_rate": 7.219847684177806e-06,
      "loss": 0.0656,
      "step": 7155
    },
    {
      "epoch": 0.5561081753186198,
      "grad_norm": 0.34395861625671387,
      "learning_rate": 7.219459123406901e-06,
      "loss": 0.1149,
      "step": 7156
    },
    {
      "epoch": 0.5561858874728007,
      "grad_norm": 0.625123918056488,
      "learning_rate": 7.219070562635997e-06,
      "loss": 0.2688,
      "step": 7157
    },
    {
      "epoch": 0.5562635996269817,
      "grad_norm": 0.22317321598529816,
      "learning_rate": 7.218682001865093e-06,
      "loss": 0.0442,
      "step": 7158
    },
    {
      "epoch": 0.5563413117811625,
      "grad_norm": 0.5334790349006653,
      "learning_rate": 7.218293441094188e-06,
      "loss": 0.7014,
      "step": 7159
    },
    {
      "epoch": 0.5564190239353435,
      "grad_norm": 0.328377366065979,
      "learning_rate": 7.2179048803232836e-06,
      "loss": 0.162,
      "step": 7160
    },
    {
      "epoch": 0.5564967360895244,
      "grad_norm": 0.20603728294372559,
      "learning_rate": 7.217516319552379e-06,
      "loss": 0.1035,
      "step": 7161
    },
    {
      "epoch": 0.5565744482437053,
      "grad_norm": 0.20920966565608978,
      "learning_rate": 7.2171277587814735e-06,
      "loss": 0.0357,
      "step": 7162
    },
    {
      "epoch": 0.5566521603978862,
      "grad_norm": 0.31459498405456543,
      "learning_rate": 7.216739198010569e-06,
      "loss": 0.0905,
      "step": 7163
    },
    {
      "epoch": 0.5567298725520672,
      "grad_norm": 0.3254846930503845,
      "learning_rate": 7.216350637239665e-06,
      "loss": 0.091,
      "step": 7164
    },
    {
      "epoch": 0.556807584706248,
      "grad_norm": 0.10303539037704468,
      "learning_rate": 7.21596207646876e-06,
      "loss": 0.0376,
      "step": 7165
    },
    {
      "epoch": 0.556885296860429,
      "grad_norm": 0.254355251789093,
      "learning_rate": 7.215573515697856e-06,
      "loss": 0.101,
      "step": 7166
    },
    {
      "epoch": 0.5569630090146099,
      "grad_norm": 0.49343881011009216,
      "learning_rate": 7.215184954926952e-06,
      "loss": 0.2611,
      "step": 7167
    },
    {
      "epoch": 0.5570407211687908,
      "grad_norm": 0.31764188408851624,
      "learning_rate": 7.2147963941560465e-06,
      "loss": 0.2051,
      "step": 7168
    },
    {
      "epoch": 0.5571184333229717,
      "grad_norm": 0.3838057816028595,
      "learning_rate": 7.214407833385142e-06,
      "loss": 0.1748,
      "step": 7169
    },
    {
      "epoch": 0.5571961454771526,
      "grad_norm": 0.1997896283864975,
      "learning_rate": 7.214019272614238e-06,
      "loss": 0.0834,
      "step": 7170
    },
    {
      "epoch": 0.5572738576313335,
      "grad_norm": 0.23099303245544434,
      "learning_rate": 7.213630711843332e-06,
      "loss": 0.0169,
      "step": 7171
    },
    {
      "epoch": 0.5573515697855145,
      "grad_norm": 0.42280521988868713,
      "learning_rate": 7.213242151072428e-06,
      "loss": 0.0722,
      "step": 7172
    },
    {
      "epoch": 0.5574292819396953,
      "grad_norm": 0.1850009709596634,
      "learning_rate": 7.212853590301524e-06,
      "loss": 0.0293,
      "step": 7173
    },
    {
      "epoch": 0.5575069940938763,
      "grad_norm": 0.3284628689289093,
      "learning_rate": 7.212465029530619e-06,
      "loss": 0.1007,
      "step": 7174
    },
    {
      "epoch": 0.5575847062480572,
      "grad_norm": 0.11881164461374283,
      "learning_rate": 7.2120764687597146e-06,
      "loss": 0.0214,
      "step": 7175
    },
    {
      "epoch": 0.5576624184022381,
      "grad_norm": 0.44747689366340637,
      "learning_rate": 7.21168790798881e-06,
      "loss": 0.2195,
      "step": 7176
    },
    {
      "epoch": 0.557740130556419,
      "grad_norm": 0.3817405104637146,
      "learning_rate": 7.211299347217905e-06,
      "loss": 0.245,
      "step": 7177
    },
    {
      "epoch": 0.5578178427106,
      "grad_norm": 0.4550885558128357,
      "learning_rate": 7.210910786447001e-06,
      "loss": 0.2906,
      "step": 7178
    },
    {
      "epoch": 0.5578955548647808,
      "grad_norm": 0.42386502027511597,
      "learning_rate": 7.210522225676097e-06,
      "loss": 0.3945,
      "step": 7179
    },
    {
      "epoch": 0.5579732670189618,
      "grad_norm": 0.18203172087669373,
      "learning_rate": 7.210133664905192e-06,
      "loss": 0.0623,
      "step": 7180
    },
    {
      "epoch": 0.5580509791731427,
      "grad_norm": 0.3477751910686493,
      "learning_rate": 7.209745104134287e-06,
      "loss": 0.1212,
      "step": 7181
    },
    {
      "epoch": 0.5581286913273236,
      "grad_norm": 0.13092732429504395,
      "learning_rate": 7.209356543363383e-06,
      "loss": 0.0154,
      "step": 7182
    },
    {
      "epoch": 0.5582064034815045,
      "grad_norm": 0.09441793709993362,
      "learning_rate": 7.208967982592478e-06,
      "loss": 0.0186,
      "step": 7183
    },
    {
      "epoch": 0.5582841156356855,
      "grad_norm": 0.35217487812042236,
      "learning_rate": 7.208579421821573e-06,
      "loss": 0.3244,
      "step": 7184
    },
    {
      "epoch": 0.5583618277898663,
      "grad_norm": 0.3787034749984741,
      "learning_rate": 7.208190861050669e-06,
      "loss": 0.1375,
      "step": 7185
    },
    {
      "epoch": 0.5584395399440473,
      "grad_norm": 0.07455563545227051,
      "learning_rate": 7.207802300279765e-06,
      "loss": 0.0063,
      "step": 7186
    },
    {
      "epoch": 0.5585172520982281,
      "grad_norm": 0.3260959982872009,
      "learning_rate": 7.207413739508859e-06,
      "loss": 0.1341,
      "step": 7187
    },
    {
      "epoch": 0.5585949642524091,
      "grad_norm": 0.504746675491333,
      "learning_rate": 7.207025178737955e-06,
      "loss": 0.0648,
      "step": 7188
    },
    {
      "epoch": 0.55867267640659,
      "grad_norm": 0.4244966506958008,
      "learning_rate": 7.206636617967051e-06,
      "loss": 0.1594,
      "step": 7189
    },
    {
      "epoch": 0.5587503885607709,
      "grad_norm": 0.20600272715091705,
      "learning_rate": 7.206248057196146e-06,
      "loss": 0.3006,
      "step": 7190
    },
    {
      "epoch": 0.5588281007149518,
      "grad_norm": 0.5081924796104431,
      "learning_rate": 7.205859496425241e-06,
      "loss": 0.0966,
      "step": 7191
    },
    {
      "epoch": 0.5589058128691328,
      "grad_norm": 0.1608932912349701,
      "learning_rate": 7.205470935654337e-06,
      "loss": 0.0877,
      "step": 7192
    },
    {
      "epoch": 0.5589835250233136,
      "grad_norm": 0.3232584595680237,
      "learning_rate": 7.205082374883432e-06,
      "loss": 0.2023,
      "step": 7193
    },
    {
      "epoch": 0.5590612371774946,
      "grad_norm": 0.34934139251708984,
      "learning_rate": 7.204693814112528e-06,
      "loss": 0.2144,
      "step": 7194
    },
    {
      "epoch": 0.5591389493316755,
      "grad_norm": 0.16442035138607025,
      "learning_rate": 7.204305253341624e-06,
      "loss": 0.0283,
      "step": 7195
    },
    {
      "epoch": 0.5592166614858564,
      "grad_norm": 0.19363467395305634,
      "learning_rate": 7.203916692570718e-06,
      "loss": 0.0549,
      "step": 7196
    },
    {
      "epoch": 0.5592943736400373,
      "grad_norm": 0.28806939721107483,
      "learning_rate": 7.203528131799814e-06,
      "loss": 0.3883,
      "step": 7197
    },
    {
      "epoch": 0.5593720857942183,
      "grad_norm": 0.5009509921073914,
      "learning_rate": 7.2031395710289094e-06,
      "loss": 0.3804,
      "step": 7198
    },
    {
      "epoch": 0.5594497979483991,
      "grad_norm": 0.4232593774795532,
      "learning_rate": 7.202751010258004e-06,
      "loss": 0.1758,
      "step": 7199
    },
    {
      "epoch": 0.5595275101025801,
      "grad_norm": 0.1515694409608841,
      "learning_rate": 7.2023624494871e-06,
      "loss": 0.0267,
      "step": 7200
    },
    {
      "epoch": 0.5596052222567609,
      "grad_norm": 0.2161010503768921,
      "learning_rate": 7.201973888716196e-06,
      "loss": 0.1087,
      "step": 7201
    },
    {
      "epoch": 0.5596829344109419,
      "grad_norm": 0.24789583683013916,
      "learning_rate": 7.201585327945291e-06,
      "loss": 0.0336,
      "step": 7202
    },
    {
      "epoch": 0.5597606465651228,
      "grad_norm": 0.09272947907447815,
      "learning_rate": 7.201196767174387e-06,
      "loss": 0.0165,
      "step": 7203
    },
    {
      "epoch": 0.5598383587193037,
      "grad_norm": 0.40019679069519043,
      "learning_rate": 7.2008082064034825e-06,
      "loss": 0.3209,
      "step": 7204
    },
    {
      "epoch": 0.5599160708734846,
      "grad_norm": 0.5540245771408081,
      "learning_rate": 7.200419645632577e-06,
      "loss": 0.5093,
      "step": 7205
    },
    {
      "epoch": 0.5599937830276656,
      "grad_norm": 0.2553774118423462,
      "learning_rate": 7.200031084861672e-06,
      "loss": 0.0818,
      "step": 7206
    },
    {
      "epoch": 0.5600714951818464,
      "grad_norm": 0.16945672035217285,
      "learning_rate": 7.199642524090768e-06,
      "loss": 0.241,
      "step": 7207
    },
    {
      "epoch": 0.5601492073360274,
      "grad_norm": 0.19419224560260773,
      "learning_rate": 7.199253963319864e-06,
      "loss": 0.0679,
      "step": 7208
    },
    {
      "epoch": 0.5602269194902083,
      "grad_norm": 0.7374812960624695,
      "learning_rate": 7.198865402548959e-06,
      "loss": 0.3166,
      "step": 7209
    },
    {
      "epoch": 0.5603046316443892,
      "grad_norm": 1.062538504600525,
      "learning_rate": 7.198476841778055e-06,
      "loss": 0.5116,
      "step": 7210
    },
    {
      "epoch": 0.5603823437985701,
      "grad_norm": 0.1182800829410553,
      "learning_rate": 7.1980882810071506e-06,
      "loss": 0.0416,
      "step": 7211
    },
    {
      "epoch": 0.5604600559527511,
      "grad_norm": 0.28835931420326233,
      "learning_rate": 7.1976997202362455e-06,
      "loss": 0.1674,
      "step": 7212
    },
    {
      "epoch": 0.5605377681069319,
      "grad_norm": 0.792715311050415,
      "learning_rate": 7.197311159465341e-06,
      "loss": 0.0869,
      "step": 7213
    },
    {
      "epoch": 0.5606154802611129,
      "grad_norm": 0.6080609560012817,
      "learning_rate": 7.196922598694437e-06,
      "loss": 0.2558,
      "step": 7214
    },
    {
      "epoch": 0.5606931924152938,
      "grad_norm": 0.2918677031993866,
      "learning_rate": 7.196534037923531e-06,
      "loss": 0.1275,
      "step": 7215
    },
    {
      "epoch": 0.5607709045694746,
      "grad_norm": 0.15999026596546173,
      "learning_rate": 7.196145477152627e-06,
      "loss": 0.0389,
      "step": 7216
    },
    {
      "epoch": 0.5608486167236556,
      "grad_norm": 0.2574193775653839,
      "learning_rate": 7.195756916381723e-06,
      "loss": 0.0351,
      "step": 7217
    },
    {
      "epoch": 0.5609263288778364,
      "grad_norm": 0.4734918475151062,
      "learning_rate": 7.195368355610818e-06,
      "loss": 0.2598,
      "step": 7218
    },
    {
      "epoch": 0.5610040410320174,
      "grad_norm": 0.22220179438591003,
      "learning_rate": 7.1949797948399135e-06,
      "loss": 0.0911,
      "step": 7219
    },
    {
      "epoch": 0.5610817531861984,
      "grad_norm": 0.3580760359764099,
      "learning_rate": 7.194591234069009e-06,
      "loss": 0.1034,
      "step": 7220
    },
    {
      "epoch": 0.5611594653403792,
      "grad_norm": 0.6265295147895813,
      "learning_rate": 7.194202673298104e-06,
      "loss": 0.1789,
      "step": 7221
    },
    {
      "epoch": 0.5612371774945601,
      "grad_norm": 0.5693360567092896,
      "learning_rate": 7.1938141125272e-06,
      "loss": 0.364,
      "step": 7222
    },
    {
      "epoch": 0.5613148896487411,
      "grad_norm": 0.4652003347873688,
      "learning_rate": 7.193425551756296e-06,
      "loss": 0.2229,
      "step": 7223
    },
    {
      "epoch": 0.5613926018029219,
      "grad_norm": 0.6939723491668701,
      "learning_rate": 7.19303699098539e-06,
      "loss": 0.8182,
      "step": 7224
    },
    {
      "epoch": 0.5614703139571029,
      "grad_norm": 0.6070755124092102,
      "learning_rate": 7.192648430214486e-06,
      "loss": 0.5434,
      "step": 7225
    },
    {
      "epoch": 0.5615480261112838,
      "grad_norm": 0.28010648488998413,
      "learning_rate": 7.192259869443582e-06,
      "loss": 0.1406,
      "step": 7226
    },
    {
      "epoch": 0.5616257382654647,
      "grad_norm": 0.203372985124588,
      "learning_rate": 7.1918713086726765e-06,
      "loss": 0.1003,
      "step": 7227
    },
    {
      "epoch": 0.5617034504196456,
      "grad_norm": 0.4910001754760742,
      "learning_rate": 7.191482747901772e-06,
      "loss": 0.2327,
      "step": 7228
    },
    {
      "epoch": 0.5617811625738266,
      "grad_norm": 0.26013419032096863,
      "learning_rate": 7.191094187130868e-06,
      "loss": 0.1337,
      "step": 7229
    },
    {
      "epoch": 0.5618588747280074,
      "grad_norm": 0.339790940284729,
      "learning_rate": 7.190705626359963e-06,
      "loss": 0.1131,
      "step": 7230
    },
    {
      "epoch": 0.5619365868821884,
      "grad_norm": 0.5180672407150269,
      "learning_rate": 7.190317065589059e-06,
      "loss": 0.3522,
      "step": 7231
    },
    {
      "epoch": 0.5620142990363692,
      "grad_norm": 0.23386046290397644,
      "learning_rate": 7.189928504818155e-06,
      "loss": 0.1026,
      "step": 7232
    },
    {
      "epoch": 0.5620920111905502,
      "grad_norm": 0.4160189926624298,
      "learning_rate": 7.189539944047249e-06,
      "loss": 0.2222,
      "step": 7233
    },
    {
      "epoch": 0.5621697233447311,
      "grad_norm": 0.4551791548728943,
      "learning_rate": 7.1891513832763446e-06,
      "loss": 0.1288,
      "step": 7234
    },
    {
      "epoch": 0.562247435498912,
      "grad_norm": 0.7355037927627563,
      "learning_rate": 7.18876282250544e-06,
      "loss": 0.3023,
      "step": 7235
    },
    {
      "epoch": 0.5623251476530929,
      "grad_norm": 0.1249561533331871,
      "learning_rate": 7.188374261734535e-06,
      "loss": 0.0107,
      "step": 7236
    },
    {
      "epoch": 0.5624028598072739,
      "grad_norm": 0.2028624564409256,
      "learning_rate": 7.187985700963631e-06,
      "loss": 0.0881,
      "step": 7237
    },
    {
      "epoch": 0.5624805719614547,
      "grad_norm": 0.12678056955337524,
      "learning_rate": 7.187597140192727e-06,
      "loss": 0.026,
      "step": 7238
    },
    {
      "epoch": 0.5625582841156357,
      "grad_norm": 0.3652637004852295,
      "learning_rate": 7.187208579421823e-06,
      "loss": 0.1878,
      "step": 7239
    },
    {
      "epoch": 0.5626359962698166,
      "grad_norm": 1.0480924844741821,
      "learning_rate": 7.186820018650918e-06,
      "loss": 0.4675,
      "step": 7240
    },
    {
      "epoch": 0.5627137084239975,
      "grad_norm": 0.47261494398117065,
      "learning_rate": 7.1864314578800134e-06,
      "loss": 0.2696,
      "step": 7241
    },
    {
      "epoch": 0.5627914205781784,
      "grad_norm": 0.4976995587348938,
      "learning_rate": 7.186042897109109e-06,
      "loss": 0.2161,
      "step": 7242
    },
    {
      "epoch": 0.5628691327323594,
      "grad_norm": 0.8576078414916992,
      "learning_rate": 7.185654336338203e-06,
      "loss": 0.0862,
      "step": 7243
    },
    {
      "epoch": 0.5629468448865402,
      "grad_norm": 0.6405326724052429,
      "learning_rate": 7.185265775567299e-06,
      "loss": 0.8965,
      "step": 7244
    },
    {
      "epoch": 0.5630245570407212,
      "grad_norm": 0.13376545906066895,
      "learning_rate": 7.184877214796395e-06,
      "loss": 0.0305,
      "step": 7245
    },
    {
      "epoch": 0.563102269194902,
      "grad_norm": 0.5957381725311279,
      "learning_rate": 7.18448865402549e-06,
      "loss": 0.3103,
      "step": 7246
    },
    {
      "epoch": 0.563179981349083,
      "grad_norm": 0.14067833125591278,
      "learning_rate": 7.184100093254586e-06,
      "loss": 0.0449,
      "step": 7247
    },
    {
      "epoch": 0.5632576935032639,
      "grad_norm": 0.28252023458480835,
      "learning_rate": 7.1837115324836815e-06,
      "loss": 0.0475,
      "step": 7248
    },
    {
      "epoch": 0.5633354056574448,
      "grad_norm": 0.17103461921215057,
      "learning_rate": 7.1833229717127764e-06,
      "loss": 0.0477,
      "step": 7249
    },
    {
      "epoch": 0.5634131178116257,
      "grad_norm": 0.4980052709579468,
      "learning_rate": 7.182934410941872e-06,
      "loss": 0.1424,
      "step": 7250
    },
    {
      "epoch": 0.5634908299658067,
      "grad_norm": 0.3989109992980957,
      "learning_rate": 7.182545850170968e-06,
      "loss": 0.3065,
      "step": 7251
    },
    {
      "epoch": 0.5635685421199875,
      "grad_norm": 0.4752289950847626,
      "learning_rate": 7.182157289400062e-06,
      "loss": 0.0913,
      "step": 7252
    },
    {
      "epoch": 0.5636462542741685,
      "grad_norm": 0.16056211292743683,
      "learning_rate": 7.181768728629158e-06,
      "loss": 0.0628,
      "step": 7253
    },
    {
      "epoch": 0.5637239664283494,
      "grad_norm": 0.19455918669700623,
      "learning_rate": 7.181380167858254e-06,
      "loss": 0.056,
      "step": 7254
    },
    {
      "epoch": 0.5638016785825303,
      "grad_norm": 0.25016433000564575,
      "learning_rate": 7.180991607087349e-06,
      "loss": 0.1404,
      "step": 7255
    },
    {
      "epoch": 0.5638793907367112,
      "grad_norm": 0.6274234056472778,
      "learning_rate": 7.1806030463164445e-06,
      "loss": 0.0554,
      "step": 7256
    },
    {
      "epoch": 0.5639571028908922,
      "grad_norm": 0.22590847313404083,
      "learning_rate": 7.18021448554554e-06,
      "loss": 0.0366,
      "step": 7257
    },
    {
      "epoch": 0.564034815045073,
      "grad_norm": 0.531113862991333,
      "learning_rate": 7.179825924774635e-06,
      "loss": 0.0713,
      "step": 7258
    },
    {
      "epoch": 0.564112527199254,
      "grad_norm": 1.1803621053695679,
      "learning_rate": 7.179437364003731e-06,
      "loss": 0.7684,
      "step": 7259
    },
    {
      "epoch": 0.5641902393534349,
      "grad_norm": 0.3377968668937683,
      "learning_rate": 7.179048803232827e-06,
      "loss": 0.1557,
      "step": 7260
    },
    {
      "epoch": 0.5642679515076158,
      "grad_norm": 0.9264997243881226,
      "learning_rate": 7.178660242461921e-06,
      "loss": 1.8653,
      "step": 7261
    },
    {
      "epoch": 0.5643456636617967,
      "grad_norm": 0.5426539182662964,
      "learning_rate": 7.178271681691017e-06,
      "loss": 0.5535,
      "step": 7262
    },
    {
      "epoch": 0.5644233758159776,
      "grad_norm": 0.2862008512020111,
      "learning_rate": 7.1778831209201125e-06,
      "loss": 0.2001,
      "step": 7263
    },
    {
      "epoch": 0.5645010879701585,
      "grad_norm": 0.5235510468482971,
      "learning_rate": 7.1774945601492075e-06,
      "loss": 0.2637,
      "step": 7264
    },
    {
      "epoch": 0.5645788001243395,
      "grad_norm": 0.2747441530227661,
      "learning_rate": 7.177105999378303e-06,
      "loss": 0.0542,
      "step": 7265
    },
    {
      "epoch": 0.5646565122785203,
      "grad_norm": 0.3246309757232666,
      "learning_rate": 7.176717438607399e-06,
      "loss": 0.5005,
      "step": 7266
    },
    {
      "epoch": 0.5647342244327013,
      "grad_norm": 0.44342148303985596,
      "learning_rate": 7.176328877836494e-06,
      "loss": 0.2094,
      "step": 7267
    },
    {
      "epoch": 0.5648119365868822,
      "grad_norm": 0.40406447649002075,
      "learning_rate": 7.17594031706559e-06,
      "loss": 0.186,
      "step": 7268
    },
    {
      "epoch": 0.5648896487410631,
      "grad_norm": 0.12254974246025085,
      "learning_rate": 7.175551756294686e-06,
      "loss": 0.0465,
      "step": 7269
    },
    {
      "epoch": 0.564967360895244,
      "grad_norm": 0.19949468970298767,
      "learning_rate": 7.175163195523781e-06,
      "loss": 0.1271,
      "step": 7270
    },
    {
      "epoch": 0.565045073049425,
      "grad_norm": 0.4351854920387268,
      "learning_rate": 7.1747746347528755e-06,
      "loss": 0.163,
      "step": 7271
    },
    {
      "epoch": 0.5651227852036058,
      "grad_norm": 0.5385388135910034,
      "learning_rate": 7.174386073981971e-06,
      "loss": 0.7462,
      "step": 7272
    },
    {
      "epoch": 0.5652004973577868,
      "grad_norm": 0.18288569152355194,
      "learning_rate": 7.173997513211067e-06,
      "loss": 0.0443,
      "step": 7273
    },
    {
      "epoch": 0.5652782095119677,
      "grad_norm": 0.0991433784365654,
      "learning_rate": 7.173608952440162e-06,
      "loss": 0.0375,
      "step": 7274
    },
    {
      "epoch": 0.5653559216661486,
      "grad_norm": 0.2315884679555893,
      "learning_rate": 7.173220391669258e-06,
      "loss": 0.1925,
      "step": 7275
    },
    {
      "epoch": 0.5654336338203295,
      "grad_norm": 0.38400405645370483,
      "learning_rate": 7.172831830898354e-06,
      "loss": 0.5889,
      "step": 7276
    },
    {
      "epoch": 0.5655113459745104,
      "grad_norm": 0.5084474682807922,
      "learning_rate": 7.172443270127449e-06,
      "loss": 0.0645,
      "step": 7277
    },
    {
      "epoch": 0.5655890581286913,
      "grad_norm": 0.1247953549027443,
      "learning_rate": 7.172054709356544e-06,
      "loss": 0.049,
      "step": 7278
    },
    {
      "epoch": 0.5656667702828723,
      "grad_norm": 0.03450434282422066,
      "learning_rate": 7.17166614858564e-06,
      "loss": 0.0043,
      "step": 7279
    },
    {
      "epoch": 0.5657444824370531,
      "grad_norm": 0.5956060886383057,
      "learning_rate": 7.171277587814734e-06,
      "loss": 0.1757,
      "step": 7280
    },
    {
      "epoch": 0.5658221945912341,
      "grad_norm": 0.32718896865844727,
      "learning_rate": 7.17088902704383e-06,
      "loss": 0.1597,
      "step": 7281
    },
    {
      "epoch": 0.565899906745415,
      "grad_norm": 0.2143392115831375,
      "learning_rate": 7.170500466272926e-06,
      "loss": 0.0834,
      "step": 7282
    },
    {
      "epoch": 0.5659776188995959,
      "grad_norm": 0.2834743857383728,
      "learning_rate": 7.170111905502021e-06,
      "loss": 0.0899,
      "step": 7283
    },
    {
      "epoch": 0.5660553310537768,
      "grad_norm": 0.3554386794567108,
      "learning_rate": 7.169723344731117e-06,
      "loss": 0.2299,
      "step": 7284
    },
    {
      "epoch": 0.5661330432079578,
      "grad_norm": 0.18253426253795624,
      "learning_rate": 7.169334783960212e-06,
      "loss": 0.1495,
      "step": 7285
    },
    {
      "epoch": 0.5662107553621386,
      "grad_norm": 0.39007940888404846,
      "learning_rate": 7.168946223189307e-06,
      "loss": 0.1735,
      "step": 7286
    },
    {
      "epoch": 0.5662884675163196,
      "grad_norm": 0.7435685992240906,
      "learning_rate": 7.168557662418403e-06,
      "loss": 0.4347,
      "step": 7287
    },
    {
      "epoch": 0.5663661796705005,
      "grad_norm": 0.014971138909459114,
      "learning_rate": 7.168169101647499e-06,
      "loss": 0.002,
      "step": 7288
    },
    {
      "epoch": 0.5664438918246814,
      "grad_norm": 0.8220958113670349,
      "learning_rate": 7.167780540876593e-06,
      "loss": 0.1224,
      "step": 7289
    },
    {
      "epoch": 0.5665216039788623,
      "grad_norm": 0.14058171212673187,
      "learning_rate": 7.167391980105689e-06,
      "loss": 0.0636,
      "step": 7290
    },
    {
      "epoch": 0.5665993161330433,
      "grad_norm": 0.3658204972743988,
      "learning_rate": 7.167003419334785e-06,
      "loss": 0.422,
      "step": 7291
    },
    {
      "epoch": 0.5666770282872241,
      "grad_norm": 0.6095520257949829,
      "learning_rate": 7.16661485856388e-06,
      "loss": 0.2321,
      "step": 7292
    },
    {
      "epoch": 0.5667547404414051,
      "grad_norm": 0.5345778465270996,
      "learning_rate": 7.166226297792975e-06,
      "loss": 0.3319,
      "step": 7293
    },
    {
      "epoch": 0.5668324525955859,
      "grad_norm": 0.5198439359664917,
      "learning_rate": 7.165837737022071e-06,
      "loss": 0.6524,
      "step": 7294
    },
    {
      "epoch": 0.5669101647497669,
      "grad_norm": 0.18327486515045166,
      "learning_rate": 7.165449176251166e-06,
      "loss": 0.0705,
      "step": 7295
    },
    {
      "epoch": 0.5669878769039478,
      "grad_norm": 0.36302250623703003,
      "learning_rate": 7.165060615480262e-06,
      "loss": 0.0675,
      "step": 7296
    },
    {
      "epoch": 0.5670655890581286,
      "grad_norm": 0.2019597738981247,
      "learning_rate": 7.164672054709358e-06,
      "loss": 0.1132,
      "step": 7297
    },
    {
      "epoch": 0.5671433012123096,
      "grad_norm": 0.28628721833229065,
      "learning_rate": 7.164283493938452e-06,
      "loss": 0.2266,
      "step": 7298
    },
    {
      "epoch": 0.5672210133664906,
      "grad_norm": 0.27511274814605713,
      "learning_rate": 7.163894933167548e-06,
      "loss": 0.0531,
      "step": 7299
    },
    {
      "epoch": 0.5672987255206714,
      "grad_norm": 0.381145179271698,
      "learning_rate": 7.1635063723966434e-06,
      "loss": 0.1158,
      "step": 7300
    },
    {
      "epoch": 0.5673764376748524,
      "grad_norm": 0.1634223461151123,
      "learning_rate": 7.163117811625739e-06,
      "loss": 0.0476,
      "step": 7301
    },
    {
      "epoch": 0.5674541498290333,
      "grad_norm": 0.6749184131622314,
      "learning_rate": 7.162729250854834e-06,
      "loss": 0.0829,
      "step": 7302
    },
    {
      "epoch": 0.5675318619832141,
      "grad_norm": 0.3576931059360504,
      "learning_rate": 7.16234069008393e-06,
      "loss": 0.2616,
      "step": 7303
    },
    {
      "epoch": 0.5676095741373951,
      "grad_norm": 0.24005763232707977,
      "learning_rate": 7.161952129313026e-06,
      "loss": 0.0606,
      "step": 7304
    },
    {
      "epoch": 0.567687286291576,
      "grad_norm": 0.449203222990036,
      "learning_rate": 7.161563568542121e-06,
      "loss": 0.2326,
      "step": 7305
    },
    {
      "epoch": 0.5677649984457569,
      "grad_norm": 0.32274171710014343,
      "learning_rate": 7.1611750077712165e-06,
      "loss": 0.1297,
      "step": 7306
    },
    {
      "epoch": 0.5678427105999378,
      "grad_norm": 0.26883381605148315,
      "learning_rate": 7.1607864470003115e-06,
      "loss": 0.1032,
      "step": 7307
    },
    {
      "epoch": 0.5679204227541187,
      "grad_norm": 0.41808903217315674,
      "learning_rate": 7.160397886229406e-06,
      "loss": 0.332,
      "step": 7308
    },
    {
      "epoch": 0.5679981349082996,
      "grad_norm": 0.3604789972305298,
      "learning_rate": 7.160009325458502e-06,
      "loss": 0.1024,
      "step": 7309
    },
    {
      "epoch": 0.5680758470624806,
      "grad_norm": 0.3415614068508148,
      "learning_rate": 7.159620764687598e-06,
      "loss": 0.281,
      "step": 7310
    },
    {
      "epoch": 0.5681535592166614,
      "grad_norm": 0.17168545722961426,
      "learning_rate": 7.159232203916693e-06,
      "loss": 0.0757,
      "step": 7311
    },
    {
      "epoch": 0.5682312713708424,
      "grad_norm": 0.5469237565994263,
      "learning_rate": 7.158843643145789e-06,
      "loss": 0.1344,
      "step": 7312
    },
    {
      "epoch": 0.5683089835250233,
      "grad_norm": 0.3665354549884796,
      "learning_rate": 7.1584550823748846e-06,
      "loss": 0.1848,
      "step": 7313
    },
    {
      "epoch": 0.5683866956792042,
      "grad_norm": 0.634752631187439,
      "learning_rate": 7.158066521603979e-06,
      "loss": 0.7471,
      "step": 7314
    },
    {
      "epoch": 0.5684644078333851,
      "grad_norm": 0.07506875693798065,
      "learning_rate": 7.1576779608330745e-06,
      "loss": 0.009,
      "step": 7315
    },
    {
      "epoch": 0.5685421199875661,
      "grad_norm": 0.8470139503479004,
      "learning_rate": 7.15728940006217e-06,
      "loss": 0.3967,
      "step": 7316
    },
    {
      "epoch": 0.5686198321417469,
      "grad_norm": 0.35220155119895935,
      "learning_rate": 7.156900839291265e-06,
      "loss": 0.1622,
      "step": 7317
    },
    {
      "epoch": 0.5686975442959279,
      "grad_norm": 0.16636691987514496,
      "learning_rate": 7.156512278520361e-06,
      "loss": 0.0535,
      "step": 7318
    },
    {
      "epoch": 0.5687752564501088,
      "grad_norm": 0.15856888890266418,
      "learning_rate": 7.156123717749457e-06,
      "loss": 0.0592,
      "step": 7319
    },
    {
      "epoch": 0.5688529686042897,
      "grad_norm": 0.18561168015003204,
      "learning_rate": 7.155735156978552e-06,
      "loss": 0.132,
      "step": 7320
    },
    {
      "epoch": 0.5689306807584706,
      "grad_norm": 0.4809854030609131,
      "learning_rate": 7.1553465962076475e-06,
      "loss": 0.2699,
      "step": 7321
    },
    {
      "epoch": 0.5690083929126515,
      "grad_norm": 0.19266672432422638,
      "learning_rate": 7.154958035436743e-06,
      "loss": 0.1137,
      "step": 7322
    },
    {
      "epoch": 0.5690861050668324,
      "grad_norm": 0.1796049326658249,
      "learning_rate": 7.1545694746658374e-06,
      "loss": 0.0486,
      "step": 7323
    },
    {
      "epoch": 0.5691638172210134,
      "grad_norm": 0.5117619037628174,
      "learning_rate": 7.154180913894933e-06,
      "loss": 0.3067,
      "step": 7324
    },
    {
      "epoch": 0.5692415293751942,
      "grad_norm": 0.6582391262054443,
      "learning_rate": 7.153792353124029e-06,
      "loss": 0.2674,
      "step": 7325
    },
    {
      "epoch": 0.5693192415293752,
      "grad_norm": 0.5477553606033325,
      "learning_rate": 7.153403792353124e-06,
      "loss": 0.1154,
      "step": 7326
    },
    {
      "epoch": 0.5693969536835561,
      "grad_norm": 0.6163071393966675,
      "learning_rate": 7.15301523158222e-06,
      "loss": 0.0849,
      "step": 7327
    },
    {
      "epoch": 0.569474665837737,
      "grad_norm": 0.30099961161613464,
      "learning_rate": 7.152626670811316e-06,
      "loss": 0.4597,
      "step": 7328
    },
    {
      "epoch": 0.5695523779919179,
      "grad_norm": 0.10128068178892136,
      "learning_rate": 7.1522381100404105e-06,
      "loss": 0.0192,
      "step": 7329
    },
    {
      "epoch": 0.5696300901460989,
      "grad_norm": 1.4552226066589355,
      "learning_rate": 7.151849549269506e-06,
      "loss": 0.6243,
      "step": 7330
    },
    {
      "epoch": 0.5697078023002797,
      "grad_norm": 0.39986318349838257,
      "learning_rate": 7.151460988498602e-06,
      "loss": 0.0944,
      "step": 7331
    },
    {
      "epoch": 0.5697855144544607,
      "grad_norm": 0.4041227400302887,
      "learning_rate": 7.151072427727698e-06,
      "loss": 0.3102,
      "step": 7332
    },
    {
      "epoch": 0.5698632266086416,
      "grad_norm": 0.47831690311431885,
      "learning_rate": 7.150683866956792e-06,
      "loss": 0.3689,
      "step": 7333
    },
    {
      "epoch": 0.5699409387628225,
      "grad_norm": 0.41026049852371216,
      "learning_rate": 7.150295306185888e-06,
      "loss": 0.1977,
      "step": 7334
    },
    {
      "epoch": 0.5700186509170034,
      "grad_norm": 0.46007686853408813,
      "learning_rate": 7.149906745414984e-06,
      "loss": 0.1061,
      "step": 7335
    },
    {
      "epoch": 0.5700963630711844,
      "grad_norm": 0.460054874420166,
      "learning_rate": 7.1495181846440786e-06,
      "loss": 0.1144,
      "step": 7336
    },
    {
      "epoch": 0.5701740752253652,
      "grad_norm": 0.18656955659389496,
      "learning_rate": 7.149129623873174e-06,
      "loss": 0.0934,
      "step": 7337
    },
    {
      "epoch": 0.5702517873795462,
      "grad_norm": 0.43411025404930115,
      "learning_rate": 7.14874106310227e-06,
      "loss": 0.1531,
      "step": 7338
    },
    {
      "epoch": 0.570329499533727,
      "grad_norm": 0.22229698300361633,
      "learning_rate": 7.148352502331365e-06,
      "loss": 0.1892,
      "step": 7339
    },
    {
      "epoch": 0.570407211687908,
      "grad_norm": 0.8791012763977051,
      "learning_rate": 7.147963941560461e-06,
      "loss": 0.4632,
      "step": 7340
    },
    {
      "epoch": 0.5704849238420889,
      "grad_norm": 0.5641108751296997,
      "learning_rate": 7.147575380789557e-06,
      "loss": 0.4039,
      "step": 7341
    },
    {
      "epoch": 0.5705626359962698,
      "grad_norm": 0.6576592922210693,
      "learning_rate": 7.147186820018651e-06,
      "loss": 0.1982,
      "step": 7342
    },
    {
      "epoch": 0.5706403481504507,
      "grad_norm": 0.18054404854774475,
      "learning_rate": 7.146798259247747e-06,
      "loss": 0.1315,
      "step": 7343
    },
    {
      "epoch": 0.5707180603046317,
      "grad_norm": 0.24692267179489136,
      "learning_rate": 7.146409698476842e-06,
      "loss": 0.073,
      "step": 7344
    },
    {
      "epoch": 0.5707957724588125,
      "grad_norm": 0.3861066401004791,
      "learning_rate": 7.146021137705937e-06,
      "loss": 0.1242,
      "step": 7345
    },
    {
      "epoch": 0.5708734846129935,
      "grad_norm": 0.5176989436149597,
      "learning_rate": 7.145632576935033e-06,
      "loss": 0.2033,
      "step": 7346
    },
    {
      "epoch": 0.5709511967671744,
      "grad_norm": 0.39475390315055847,
      "learning_rate": 7.145244016164129e-06,
      "loss": 0.1511,
      "step": 7347
    },
    {
      "epoch": 0.5710289089213553,
      "grad_norm": 0.20888656377792358,
      "learning_rate": 7.144855455393224e-06,
      "loss": 0.0816,
      "step": 7348
    },
    {
      "epoch": 0.5711066210755362,
      "grad_norm": 0.2765316069126129,
      "learning_rate": 7.14446689462232e-06,
      "loss": 0.1193,
      "step": 7349
    },
    {
      "epoch": 0.5711843332297172,
      "grad_norm": 0.163143590092659,
      "learning_rate": 7.1440783338514155e-06,
      "loss": 0.0252,
      "step": 7350
    },
    {
      "epoch": 0.571262045383898,
      "grad_norm": 0.8175726532936096,
      "learning_rate": 7.14368977308051e-06,
      "loss": 0.4726,
      "step": 7351
    },
    {
      "epoch": 0.571339757538079,
      "grad_norm": 0.06248020753264427,
      "learning_rate": 7.143301212309605e-06,
      "loss": 0.0177,
      "step": 7352
    },
    {
      "epoch": 0.5714174696922598,
      "grad_norm": 0.36561548709869385,
      "learning_rate": 7.142912651538701e-06,
      "loss": 0.3181,
      "step": 7353
    },
    {
      "epoch": 0.5714951818464408,
      "grad_norm": 0.18661461770534515,
      "learning_rate": 7.142524090767796e-06,
      "loss": 0.0452,
      "step": 7354
    },
    {
      "epoch": 0.5715728940006217,
      "grad_norm": 0.3240364193916321,
      "learning_rate": 7.142135529996892e-06,
      "loss": 0.1255,
      "step": 7355
    },
    {
      "epoch": 0.5716506061548026,
      "grad_norm": 0.4587356448173523,
      "learning_rate": 7.141746969225988e-06,
      "loss": 0.1996,
      "step": 7356
    },
    {
      "epoch": 0.5717283183089835,
      "grad_norm": 0.43078017234802246,
      "learning_rate": 7.141358408455083e-06,
      "loss": 0.27,
      "step": 7357
    },
    {
      "epoch": 0.5718060304631645,
      "grad_norm": 0.5256616473197937,
      "learning_rate": 7.1409698476841785e-06,
      "loss": 0.1811,
      "step": 7358
    },
    {
      "epoch": 0.5718837426173453,
      "grad_norm": 0.23249241709709167,
      "learning_rate": 7.140581286913274e-06,
      "loss": 0.1058,
      "step": 7359
    },
    {
      "epoch": 0.5719614547715263,
      "grad_norm": 0.23217430710792542,
      "learning_rate": 7.14019272614237e-06,
      "loss": 0.0671,
      "step": 7360
    },
    {
      "epoch": 0.5720391669257072,
      "grad_norm": 0.14973823726177216,
      "learning_rate": 7.139804165371464e-06,
      "loss": 0.0727,
      "step": 7361
    },
    {
      "epoch": 0.5721168790798881,
      "grad_norm": 0.14761941134929657,
      "learning_rate": 7.13941560460056e-06,
      "loss": 0.0408,
      "step": 7362
    },
    {
      "epoch": 0.572194591234069,
      "grad_norm": 0.3294074237346649,
      "learning_rate": 7.139027043829656e-06,
      "loss": 0.1961,
      "step": 7363
    },
    {
      "epoch": 0.57227230338825,
      "grad_norm": 0.28225284814834595,
      "learning_rate": 7.138638483058751e-06,
      "loss": 0.1617,
      "step": 7364
    },
    {
      "epoch": 0.5723500155424308,
      "grad_norm": 0.258527547121048,
      "learning_rate": 7.1382499222878465e-06,
      "loss": 0.2019,
      "step": 7365
    },
    {
      "epoch": 0.5724277276966118,
      "grad_norm": 0.13818559050559998,
      "learning_rate": 7.137861361516942e-06,
      "loss": 0.0361,
      "step": 7366
    },
    {
      "epoch": 0.5725054398507927,
      "grad_norm": 0.2571033537387848,
      "learning_rate": 7.137472800746037e-06,
      "loss": 0.0852,
      "step": 7367
    },
    {
      "epoch": 0.5725831520049736,
      "grad_norm": 0.15930567681789398,
      "learning_rate": 7.137084239975133e-06,
      "loss": 0.0517,
      "step": 7368
    },
    {
      "epoch": 0.5726608641591545,
      "grad_norm": 0.11985867470502853,
      "learning_rate": 7.136695679204229e-06,
      "loss": 0.0702,
      "step": 7369
    },
    {
      "epoch": 0.5727385763133354,
      "grad_norm": 0.16480694711208344,
      "learning_rate": 7.136307118433323e-06,
      "loss": 0.0314,
      "step": 7370
    },
    {
      "epoch": 0.5728162884675163,
      "grad_norm": 0.20755548775196075,
      "learning_rate": 7.135918557662419e-06,
      "loss": 0.0222,
      "step": 7371
    },
    {
      "epoch": 0.5728940006216973,
      "grad_norm": 0.3899576663970947,
      "learning_rate": 7.1355299968915145e-06,
      "loss": 0.1191,
      "step": 7372
    },
    {
      "epoch": 0.5729717127758781,
      "grad_norm": 0.7620049118995667,
      "learning_rate": 7.1351414361206095e-06,
      "loss": 0.4172,
      "step": 7373
    },
    {
      "epoch": 0.5730494249300591,
      "grad_norm": 0.33910155296325684,
      "learning_rate": 7.134752875349705e-06,
      "loss": 0.2756,
      "step": 7374
    },
    {
      "epoch": 0.57312713708424,
      "grad_norm": 0.32865869998931885,
      "learning_rate": 7.134364314578801e-06,
      "loss": 0.1207,
      "step": 7375
    },
    {
      "epoch": 0.5732048492384209,
      "grad_norm": 0.3348398208618164,
      "learning_rate": 7.133975753807896e-06,
      "loss": 0.1672,
      "step": 7376
    },
    {
      "epoch": 0.5732825613926018,
      "grad_norm": 0.700298547744751,
      "learning_rate": 7.133587193036992e-06,
      "loss": 0.3736,
      "step": 7377
    },
    {
      "epoch": 0.5733602735467828,
      "grad_norm": 0.12278871238231659,
      "learning_rate": 7.133198632266088e-06,
      "loss": 0.0361,
      "step": 7378
    },
    {
      "epoch": 0.5734379857009636,
      "grad_norm": 0.31629678606987,
      "learning_rate": 7.132810071495182e-06,
      "loss": 0.0576,
      "step": 7379
    },
    {
      "epoch": 0.5735156978551446,
      "grad_norm": 0.5140678286552429,
      "learning_rate": 7.1324215107242775e-06,
      "loss": 0.2615,
      "step": 7380
    },
    {
      "epoch": 0.5735934100093255,
      "grad_norm": 0.38624849915504456,
      "learning_rate": 7.132032949953373e-06,
      "loss": 0.146,
      "step": 7381
    },
    {
      "epoch": 0.5736711221635064,
      "grad_norm": 0.3518713116645813,
      "learning_rate": 7.131644389182468e-06,
      "loss": 0.1055,
      "step": 7382
    },
    {
      "epoch": 0.5737488343176873,
      "grad_norm": 0.16468274593353271,
      "learning_rate": 7.131255828411564e-06,
      "loss": 0.0369,
      "step": 7383
    },
    {
      "epoch": 0.5738265464718681,
      "grad_norm": 0.20296958088874817,
      "learning_rate": 7.13086726764066e-06,
      "loss": 0.0987,
      "step": 7384
    },
    {
      "epoch": 0.5739042586260491,
      "grad_norm": 0.5230473875999451,
      "learning_rate": 7.130478706869755e-06,
      "loss": 0.1304,
      "step": 7385
    },
    {
      "epoch": 0.57398197078023,
      "grad_norm": 0.2551025152206421,
      "learning_rate": 7.130090146098851e-06,
      "loss": 0.0941,
      "step": 7386
    },
    {
      "epoch": 0.5740596829344109,
      "grad_norm": 0.5880725383758545,
      "learning_rate": 7.129701585327946e-06,
      "loss": 0.4647,
      "step": 7387
    },
    {
      "epoch": 0.5741373950885919,
      "grad_norm": 0.7394633889198303,
      "learning_rate": 7.1293130245570405e-06,
      "loss": 0.2749,
      "step": 7388
    },
    {
      "epoch": 0.5742151072427728,
      "grad_norm": 0.31025639176368713,
      "learning_rate": 7.128924463786136e-06,
      "loss": 0.0844,
      "step": 7389
    },
    {
      "epoch": 0.5742928193969536,
      "grad_norm": 0.6407774686813354,
      "learning_rate": 7.128535903015232e-06,
      "loss": 0.317,
      "step": 7390
    },
    {
      "epoch": 0.5743705315511346,
      "grad_norm": 0.3216748535633087,
      "learning_rate": 7.128147342244328e-06,
      "loss": 0.2158,
      "step": 7391
    },
    {
      "epoch": 0.5744482437053156,
      "grad_norm": 0.26014238595962524,
      "learning_rate": 7.127758781473423e-06,
      "loss": 0.0787,
      "step": 7392
    },
    {
      "epoch": 0.5745259558594964,
      "grad_norm": 0.16099709272384644,
      "learning_rate": 7.127370220702519e-06,
      "loss": 0.043,
      "step": 7393
    },
    {
      "epoch": 0.5746036680136773,
      "grad_norm": 0.7211639881134033,
      "learning_rate": 7.1269816599316145e-06,
      "loss": 0.1902,
      "step": 7394
    },
    {
      "epoch": 0.5746813801678583,
      "grad_norm": 0.5908148884773254,
      "learning_rate": 7.126593099160709e-06,
      "loss": 0.6118,
      "step": 7395
    },
    {
      "epoch": 0.5747590923220391,
      "grad_norm": 0.1914638876914978,
      "learning_rate": 7.126204538389805e-06,
      "loss": 0.0542,
      "step": 7396
    },
    {
      "epoch": 0.5748368044762201,
      "grad_norm": 0.29108479619026184,
      "learning_rate": 7.125815977618901e-06,
      "loss": 0.1237,
      "step": 7397
    },
    {
      "epoch": 0.5749145166304009,
      "grad_norm": 0.6228750348091125,
      "learning_rate": 7.125427416847995e-06,
      "loss": 0.3775,
      "step": 7398
    },
    {
      "epoch": 0.5749922287845819,
      "grad_norm": 0.4129156470298767,
      "learning_rate": 7.125038856077091e-06,
      "loss": 0.1966,
      "step": 7399
    },
    {
      "epoch": 0.5750699409387628,
      "grad_norm": 0.11072219163179398,
      "learning_rate": 7.124650295306187e-06,
      "loss": 0.0173,
      "step": 7400
    },
    {
      "epoch": 0.5751476530929437,
      "grad_norm": 0.07702138274908066,
      "learning_rate": 7.124261734535282e-06,
      "loss": 0.0135,
      "step": 7401
    },
    {
      "epoch": 0.5752253652471246,
      "grad_norm": 0.6396448612213135,
      "learning_rate": 7.1238731737643774e-06,
      "loss": 0.341,
      "step": 7402
    },
    {
      "epoch": 0.5753030774013056,
      "grad_norm": 0.16346687078475952,
      "learning_rate": 7.123484612993473e-06,
      "loss": 0.0476,
      "step": 7403
    },
    {
      "epoch": 0.5753807895554864,
      "grad_norm": 0.22669294476509094,
      "learning_rate": 7.123096052222568e-06,
      "loss": 0.1187,
      "step": 7404
    },
    {
      "epoch": 0.5754585017096674,
      "grad_norm": 0.4688975512981415,
      "learning_rate": 7.122707491451664e-06,
      "loss": 0.3781,
      "step": 7405
    },
    {
      "epoch": 0.5755362138638483,
      "grad_norm": 1.025622010231018,
      "learning_rate": 7.12231893068076e-06,
      "loss": 0.5434,
      "step": 7406
    },
    {
      "epoch": 0.5756139260180292,
      "grad_norm": 0.6292656064033508,
      "learning_rate": 7.121930369909854e-06,
      "loss": 0.7358,
      "step": 7407
    },
    {
      "epoch": 0.5756916381722101,
      "grad_norm": 0.3541508913040161,
      "learning_rate": 7.12154180913895e-06,
      "loss": 0.1341,
      "step": 7408
    },
    {
      "epoch": 0.5757693503263911,
      "grad_norm": 0.16365036368370056,
      "learning_rate": 7.1211532483680455e-06,
      "loss": 0.0703,
      "step": 7409
    },
    {
      "epoch": 0.5758470624805719,
      "grad_norm": 0.21034418046474457,
      "learning_rate": 7.1207646875971404e-06,
      "loss": 0.1679,
      "step": 7410
    },
    {
      "epoch": 0.5759247746347529,
      "grad_norm": 0.1715903878211975,
      "learning_rate": 7.120376126826236e-06,
      "loss": 0.0304,
      "step": 7411
    },
    {
      "epoch": 0.5760024867889338,
      "grad_norm": 0.24785470962524414,
      "learning_rate": 7.119987566055332e-06,
      "loss": 0.2092,
      "step": 7412
    },
    {
      "epoch": 0.5760801989431147,
      "grad_norm": 0.6935028433799744,
      "learning_rate": 7.119599005284427e-06,
      "loss": 0.3109,
      "step": 7413
    },
    {
      "epoch": 0.5761579110972956,
      "grad_norm": 0.7457337379455566,
      "learning_rate": 7.119210444513523e-06,
      "loss": 0.3903,
      "step": 7414
    },
    {
      "epoch": 0.5762356232514765,
      "grad_norm": 0.5167370438575745,
      "learning_rate": 7.1188218837426186e-06,
      "loss": 0.3073,
      "step": 7415
    },
    {
      "epoch": 0.5763133354056574,
      "grad_norm": 0.18794943392276764,
      "learning_rate": 7.118433322971713e-06,
      "loss": 0.0556,
      "step": 7416
    },
    {
      "epoch": 0.5763910475598384,
      "grad_norm": 0.3637126386165619,
      "learning_rate": 7.1180447622008085e-06,
      "loss": 0.3395,
      "step": 7417
    },
    {
      "epoch": 0.5764687597140192,
      "grad_norm": 0.45128926634788513,
      "learning_rate": 7.117656201429904e-06,
      "loss": 0.338,
      "step": 7418
    },
    {
      "epoch": 0.5765464718682002,
      "grad_norm": 0.30331119894981384,
      "learning_rate": 7.117267640658999e-06,
      "loss": 0.053,
      "step": 7419
    },
    {
      "epoch": 0.5766241840223811,
      "grad_norm": 0.5301568508148193,
      "learning_rate": 7.116879079888095e-06,
      "loss": 0.3019,
      "step": 7420
    },
    {
      "epoch": 0.576701896176562,
      "grad_norm": 0.3617917597293854,
      "learning_rate": 7.116490519117191e-06,
      "loss": 0.1869,
      "step": 7421
    },
    {
      "epoch": 0.5767796083307429,
      "grad_norm": 0.30977481603622437,
      "learning_rate": 7.116101958346287e-06,
      "loss": 0.1911,
      "step": 7422
    },
    {
      "epoch": 0.5768573204849239,
      "grad_norm": 0.24498946964740753,
      "learning_rate": 7.1157133975753816e-06,
      "loss": 0.0717,
      "step": 7423
    },
    {
      "epoch": 0.5769350326391047,
      "grad_norm": 0.5666396021842957,
      "learning_rate": 7.115324836804477e-06,
      "loss": 0.1298,
      "step": 7424
    },
    {
      "epoch": 0.5770127447932857,
      "grad_norm": 0.13420280814170837,
      "learning_rate": 7.114936276033573e-06,
      "loss": 0.0708,
      "step": 7425
    },
    {
      "epoch": 0.5770904569474666,
      "grad_norm": 0.5894359946250916,
      "learning_rate": 7.114547715262667e-06,
      "loss": 0.3106,
      "step": 7426
    },
    {
      "epoch": 0.5771681691016475,
      "grad_norm": 0.8870980143547058,
      "learning_rate": 7.114159154491763e-06,
      "loss": 0.5951,
      "step": 7427
    },
    {
      "epoch": 0.5772458812558284,
      "grad_norm": 1.451279878616333,
      "learning_rate": 7.113770593720859e-06,
      "loss": 0.7049,
      "step": 7428
    },
    {
      "epoch": 0.5773235934100093,
      "grad_norm": 0.2141580879688263,
      "learning_rate": 7.113382032949954e-06,
      "loss": 0.168,
      "step": 7429
    },
    {
      "epoch": 0.5774013055641902,
      "grad_norm": 0.5311465263366699,
      "learning_rate": 7.11299347217905e-06,
      "loss": 0.4449,
      "step": 7430
    },
    {
      "epoch": 0.5774790177183712,
      "grad_norm": 0.1986636370420456,
      "learning_rate": 7.112604911408145e-06,
      "loss": 0.4509,
      "step": 7431
    },
    {
      "epoch": 0.577556729872552,
      "grad_norm": 0.37228041887283325,
      "learning_rate": 7.11221635063724e-06,
      "loss": 0.0957,
      "step": 7432
    },
    {
      "epoch": 0.577634442026733,
      "grad_norm": 0.6080615520477295,
      "learning_rate": 7.111827789866336e-06,
      "loss": 0.4618,
      "step": 7433
    },
    {
      "epoch": 0.5777121541809139,
      "grad_norm": 0.04889926686882973,
      "learning_rate": 7.111439229095431e-06,
      "loss": 0.0061,
      "step": 7434
    },
    {
      "epoch": 0.5777898663350948,
      "grad_norm": 0.27172836661338806,
      "learning_rate": 7.111050668324526e-06,
      "loss": 0.1459,
      "step": 7435
    },
    {
      "epoch": 0.5778675784892757,
      "grad_norm": 0.5160235166549683,
      "learning_rate": 7.110662107553622e-06,
      "loss": 0.1413,
      "step": 7436
    },
    {
      "epoch": 0.5779452906434567,
      "grad_norm": 0.21511907875537872,
      "learning_rate": 7.110273546782718e-06,
      "loss": 0.0461,
      "step": 7437
    },
    {
      "epoch": 0.5780230027976375,
      "grad_norm": 0.9284922480583191,
      "learning_rate": 7.1098849860118126e-06,
      "loss": 0.6549,
      "step": 7438
    },
    {
      "epoch": 0.5781007149518185,
      "grad_norm": 0.6461878418922424,
      "learning_rate": 7.109496425240908e-06,
      "loss": 0.1457,
      "step": 7439
    },
    {
      "epoch": 0.5781784271059994,
      "grad_norm": 0.24702997505664825,
      "learning_rate": 7.109107864470004e-06,
      "loss": 0.0909,
      "step": 7440
    },
    {
      "epoch": 0.5782561392601803,
      "grad_norm": 0.3135406970977783,
      "learning_rate": 7.108719303699098e-06,
      "loss": 0.133,
      "step": 7441
    },
    {
      "epoch": 0.5783338514143612,
      "grad_norm": 0.4367370307445526,
      "learning_rate": 7.108330742928194e-06,
      "loss": 0.3794,
      "step": 7442
    },
    {
      "epoch": 0.5784115635685422,
      "grad_norm": 0.7068729400634766,
      "learning_rate": 7.10794218215729e-06,
      "loss": 0.3152,
      "step": 7443
    },
    {
      "epoch": 0.578489275722723,
      "grad_norm": 0.6980316638946533,
      "learning_rate": 7.107553621386385e-06,
      "loss": 0.2299,
      "step": 7444
    },
    {
      "epoch": 0.578566987876904,
      "grad_norm": 0.5236710906028748,
      "learning_rate": 7.107165060615481e-06,
      "loss": 0.2726,
      "step": 7445
    },
    {
      "epoch": 0.5786447000310848,
      "grad_norm": 0.17995867133140564,
      "learning_rate": 7.106776499844576e-06,
      "loss": 0.0296,
      "step": 7446
    },
    {
      "epoch": 0.5787224121852658,
      "grad_norm": 0.07000438123941422,
      "learning_rate": 7.106387939073671e-06,
      "loss": 0.0177,
      "step": 7447
    },
    {
      "epoch": 0.5788001243394467,
      "grad_norm": 0.2964667081832886,
      "learning_rate": 7.105999378302767e-06,
      "loss": 0.0997,
      "step": 7448
    },
    {
      "epoch": 0.5788778364936276,
      "grad_norm": 0.17433373630046844,
      "learning_rate": 7.105610817531863e-06,
      "loss": 0.0587,
      "step": 7449
    },
    {
      "epoch": 0.5789555486478085,
      "grad_norm": 0.5375889539718628,
      "learning_rate": 7.105222256760957e-06,
      "loss": 0.479,
      "step": 7450
    },
    {
      "epoch": 0.5790332608019895,
      "grad_norm": 0.34091171622276306,
      "learning_rate": 7.104833695990053e-06,
      "loss": 0.2287,
      "step": 7451
    },
    {
      "epoch": 0.5791109729561703,
      "grad_norm": 0.50718754529953,
      "learning_rate": 7.104445135219149e-06,
      "loss": 0.2603,
      "step": 7452
    },
    {
      "epoch": 0.5791886851103513,
      "grad_norm": 0.2573499083518982,
      "learning_rate": 7.1040565744482444e-06,
      "loss": 0.0947,
      "step": 7453
    },
    {
      "epoch": 0.5792663972645322,
      "grad_norm": 0.9242013692855835,
      "learning_rate": 7.103668013677339e-06,
      "loss": 0.826,
      "step": 7454
    },
    {
      "epoch": 0.5793441094187131,
      "grad_norm": 0.4427626430988312,
      "learning_rate": 7.103279452906435e-06,
      "loss": 0.3386,
      "step": 7455
    },
    {
      "epoch": 0.579421821572894,
      "grad_norm": 0.06183638051152229,
      "learning_rate": 7.102890892135531e-06,
      "loss": 0.0124,
      "step": 7456
    },
    {
      "epoch": 0.579499533727075,
      "grad_norm": 0.2958483397960663,
      "learning_rate": 7.102502331364626e-06,
      "loss": 0.0739,
      "step": 7457
    },
    {
      "epoch": 0.5795772458812558,
      "grad_norm": 0.35949695110321045,
      "learning_rate": 7.102113770593722e-06,
      "loss": 0.736,
      "step": 7458
    },
    {
      "epoch": 0.5796549580354368,
      "grad_norm": 0.09892487525939941,
      "learning_rate": 7.1017252098228175e-06,
      "loss": 0.0345,
      "step": 7459
    },
    {
      "epoch": 0.5797326701896176,
      "grad_norm": 0.5571110248565674,
      "learning_rate": 7.101336649051912e-06,
      "loss": 0.2683,
      "step": 7460
    },
    {
      "epoch": 0.5798103823437986,
      "grad_norm": 0.45939597487449646,
      "learning_rate": 7.1009480882810074e-06,
      "loss": 0.2129,
      "step": 7461
    },
    {
      "epoch": 0.5798880944979795,
      "grad_norm": 0.3438897132873535,
      "learning_rate": 7.100559527510103e-06,
      "loss": 0.1885,
      "step": 7462
    },
    {
      "epoch": 0.5799658066521604,
      "grad_norm": 0.37705153226852417,
      "learning_rate": 7.100170966739198e-06,
      "loss": 0.3904,
      "step": 7463
    },
    {
      "epoch": 0.5800435188063413,
      "grad_norm": 0.5840178728103638,
      "learning_rate": 7.099782405968294e-06,
      "loss": 0.5553,
      "step": 7464
    },
    {
      "epoch": 0.5801212309605223,
      "grad_norm": 0.13712705671787262,
      "learning_rate": 7.09939384519739e-06,
      "loss": 0.0445,
      "step": 7465
    },
    {
      "epoch": 0.5801989431147031,
      "grad_norm": 0.11230053752660751,
      "learning_rate": 7.099005284426485e-06,
      "loss": 0.0723,
      "step": 7466
    },
    {
      "epoch": 0.5802766552688841,
      "grad_norm": 0.1919986605644226,
      "learning_rate": 7.0986167236555805e-06,
      "loss": 0.0946,
      "step": 7467
    },
    {
      "epoch": 0.580354367423065,
      "grad_norm": 0.24593909084796906,
      "learning_rate": 7.098228162884676e-06,
      "loss": 0.13,
      "step": 7468
    },
    {
      "epoch": 0.5804320795772459,
      "grad_norm": 0.40326836705207825,
      "learning_rate": 7.09783960211377e-06,
      "loss": 0.0788,
      "step": 7469
    },
    {
      "epoch": 0.5805097917314268,
      "grad_norm": 0.6017012000083923,
      "learning_rate": 7.097451041342866e-06,
      "loss": 0.4978,
      "step": 7470
    },
    {
      "epoch": 0.5805875038856078,
      "grad_norm": 0.0603676475584507,
      "learning_rate": 7.097062480571962e-06,
      "loss": 0.0341,
      "step": 7471
    },
    {
      "epoch": 0.5806652160397886,
      "grad_norm": 0.09597956389188766,
      "learning_rate": 7.096673919801057e-06,
      "loss": 0.0124,
      "step": 7472
    },
    {
      "epoch": 0.5807429281939696,
      "grad_norm": 0.44321519136428833,
      "learning_rate": 7.096285359030153e-06,
      "loss": 0.2122,
      "step": 7473
    },
    {
      "epoch": 0.5808206403481504,
      "grad_norm": 0.6935814023017883,
      "learning_rate": 7.0958967982592486e-06,
      "loss": 0.8134,
      "step": 7474
    },
    {
      "epoch": 0.5808983525023313,
      "grad_norm": 0.6068370938301086,
      "learning_rate": 7.0955082374883435e-06,
      "loss": 0.5717,
      "step": 7475
    },
    {
      "epoch": 0.5809760646565123,
      "grad_norm": 0.5620119571685791,
      "learning_rate": 7.095119676717439e-06,
      "loss": 0.2557,
      "step": 7476
    },
    {
      "epoch": 0.5810537768106931,
      "grad_norm": 0.24365709722042084,
      "learning_rate": 7.094731115946535e-06,
      "loss": 0.0842,
      "step": 7477
    },
    {
      "epoch": 0.5811314889648741,
      "grad_norm": 0.5343989133834839,
      "learning_rate": 7.094342555175629e-06,
      "loss": 0.1856,
      "step": 7478
    },
    {
      "epoch": 0.581209201119055,
      "grad_norm": 0.6311028599739075,
      "learning_rate": 7.093953994404725e-06,
      "loss": 0.1181,
      "step": 7479
    },
    {
      "epoch": 0.5812869132732359,
      "grad_norm": 0.198011577129364,
      "learning_rate": 7.093565433633821e-06,
      "loss": 0.0529,
      "step": 7480
    },
    {
      "epoch": 0.5813646254274168,
      "grad_norm": 0.36022132635116577,
      "learning_rate": 7.093176872862916e-06,
      "loss": 0.0611,
      "step": 7481
    },
    {
      "epoch": 0.5814423375815978,
      "grad_norm": 0.332213819026947,
      "learning_rate": 7.0927883120920115e-06,
      "loss": 0.1608,
      "step": 7482
    },
    {
      "epoch": 0.5815200497357786,
      "grad_norm": 0.1791193038225174,
      "learning_rate": 7.092399751321107e-06,
      "loss": 0.0327,
      "step": 7483
    },
    {
      "epoch": 0.5815977618899596,
      "grad_norm": 0.34022629261016846,
      "learning_rate": 7.092011190550203e-06,
      "loss": 0.0581,
      "step": 7484
    },
    {
      "epoch": 0.5816754740441406,
      "grad_norm": 0.6038248538970947,
      "learning_rate": 7.091622629779298e-06,
      "loss": 0.177,
      "step": 7485
    },
    {
      "epoch": 0.5817531861983214,
      "grad_norm": 0.46254268288612366,
      "learning_rate": 7.091234069008394e-06,
      "loss": 0.0893,
      "step": 7486
    },
    {
      "epoch": 0.5818308983525023,
      "grad_norm": 0.4326397478580475,
      "learning_rate": 7.09084550823749e-06,
      "loss": 0.5578,
      "step": 7487
    },
    {
      "epoch": 0.5819086105066833,
      "grad_norm": 0.14424148201942444,
      "learning_rate": 7.090456947466584e-06,
      "loss": 0.0516,
      "step": 7488
    },
    {
      "epoch": 0.5819863226608641,
      "grad_norm": 0.2753215730190277,
      "learning_rate": 7.0900683866956796e-06,
      "loss": 0.0931,
      "step": 7489
    },
    {
      "epoch": 0.5820640348150451,
      "grad_norm": 0.269988089799881,
      "learning_rate": 7.089679825924775e-06,
      "loss": 0.0933,
      "step": 7490
    },
    {
      "epoch": 0.5821417469692259,
      "grad_norm": 0.7460063695907593,
      "learning_rate": 7.08929126515387e-06,
      "loss": 0.2041,
      "step": 7491
    },
    {
      "epoch": 0.5822194591234069,
      "grad_norm": 0.3101147711277008,
      "learning_rate": 7.088902704382966e-06,
      "loss": 0.13,
      "step": 7492
    },
    {
      "epoch": 0.5822971712775878,
      "grad_norm": 0.49560290575027466,
      "learning_rate": 7.088514143612062e-06,
      "loss": 0.4845,
      "step": 7493
    },
    {
      "epoch": 0.5823748834317687,
      "grad_norm": 0.17186227440834045,
      "learning_rate": 7.088125582841157e-06,
      "loss": 0.0547,
      "step": 7494
    },
    {
      "epoch": 0.5824525955859496,
      "grad_norm": 0.12831854820251465,
      "learning_rate": 7.087737022070253e-06,
      "loss": 0.0238,
      "step": 7495
    },
    {
      "epoch": 0.5825303077401306,
      "grad_norm": 0.3258804380893707,
      "learning_rate": 7.0873484612993485e-06,
      "loss": 0.2003,
      "step": 7496
    },
    {
      "epoch": 0.5826080198943114,
      "grad_norm": 0.622501790523529,
      "learning_rate": 7.0869599005284426e-06,
      "loss": 0.0594,
      "step": 7497
    },
    {
      "epoch": 0.5826857320484924,
      "grad_norm": 0.20107601583003998,
      "learning_rate": 7.086571339757538e-06,
      "loss": 0.0246,
      "step": 7498
    },
    {
      "epoch": 0.5827634442026733,
      "grad_norm": 0.4603798985481262,
      "learning_rate": 7.086182778986634e-06,
      "loss": 0.0971,
      "step": 7499
    },
    {
      "epoch": 0.5828411563568542,
      "grad_norm": 0.12771295011043549,
      "learning_rate": 7.085794218215729e-06,
      "loss": 0.0443,
      "step": 7500
    },
    {
      "epoch": 0.5829188685110351,
      "grad_norm": 0.35739007592201233,
      "learning_rate": 7.085405657444825e-06,
      "loss": 0.4481,
      "step": 7501
    },
    {
      "epoch": 0.5829965806652161,
      "grad_norm": 0.48156100511550903,
      "learning_rate": 7.085017096673921e-06,
      "loss": 0.2512,
      "step": 7502
    },
    {
      "epoch": 0.5830742928193969,
      "grad_norm": 0.15066827833652496,
      "learning_rate": 7.084628535903016e-06,
      "loss": 0.0438,
      "step": 7503
    },
    {
      "epoch": 0.5831520049735779,
      "grad_norm": 0.16582472622394562,
      "learning_rate": 7.0842399751321114e-06,
      "loss": 0.0597,
      "step": 7504
    },
    {
      "epoch": 0.5832297171277587,
      "grad_norm": 0.70729660987854,
      "learning_rate": 7.083851414361207e-06,
      "loss": 0.2563,
      "step": 7505
    },
    {
      "epoch": 0.5833074292819397,
      "grad_norm": 0.11096629500389099,
      "learning_rate": 7.083462853590301e-06,
      "loss": 0.0348,
      "step": 7506
    },
    {
      "epoch": 0.5833851414361206,
      "grad_norm": 0.9871102571487427,
      "learning_rate": 7.083074292819397e-06,
      "loss": 0.444,
      "step": 7507
    },
    {
      "epoch": 0.5834628535903015,
      "grad_norm": 0.46637511253356934,
      "learning_rate": 7.082685732048493e-06,
      "loss": 0.5239,
      "step": 7508
    },
    {
      "epoch": 0.5835405657444824,
      "grad_norm": 0.1494562327861786,
      "learning_rate": 7.082297171277588e-06,
      "loss": 0.044,
      "step": 7509
    },
    {
      "epoch": 0.5836182778986634,
      "grad_norm": 0.17221908271312714,
      "learning_rate": 7.081908610506684e-06,
      "loss": 0.0671,
      "step": 7510
    },
    {
      "epoch": 0.5836959900528442,
      "grad_norm": 1.1853110790252686,
      "learning_rate": 7.0815200497357795e-06,
      "loss": 0.9484,
      "step": 7511
    },
    {
      "epoch": 0.5837737022070252,
      "grad_norm": 0.2329283356666565,
      "learning_rate": 7.081131488964875e-06,
      "loss": 0.0417,
      "step": 7512
    },
    {
      "epoch": 0.5838514143612061,
      "grad_norm": 0.9137676954269409,
      "learning_rate": 7.08074292819397e-06,
      "loss": 0.4745,
      "step": 7513
    },
    {
      "epoch": 0.583929126515387,
      "grad_norm": 0.2889324426651001,
      "learning_rate": 7.080354367423066e-06,
      "loss": 0.1008,
      "step": 7514
    },
    {
      "epoch": 0.5840068386695679,
      "grad_norm": 0.5011248588562012,
      "learning_rate": 7.079965806652162e-06,
      "loss": 0.6668,
      "step": 7515
    },
    {
      "epoch": 0.5840845508237489,
      "grad_norm": 0.24688555300235748,
      "learning_rate": 7.079577245881256e-06,
      "loss": 0.0706,
      "step": 7516
    },
    {
      "epoch": 0.5841622629779297,
      "grad_norm": 0.4833237826824188,
      "learning_rate": 7.079188685110352e-06,
      "loss": 0.3769,
      "step": 7517
    },
    {
      "epoch": 0.5842399751321107,
      "grad_norm": 0.5449920296669006,
      "learning_rate": 7.0788001243394475e-06,
      "loss": 0.2743,
      "step": 7518
    },
    {
      "epoch": 0.5843176872862915,
      "grad_norm": 0.4114447236061096,
      "learning_rate": 7.0784115635685425e-06,
      "loss": 0.1737,
      "step": 7519
    },
    {
      "epoch": 0.5843953994404725,
      "grad_norm": 0.43917179107666016,
      "learning_rate": 7.078023002797638e-06,
      "loss": 0.2273,
      "step": 7520
    },
    {
      "epoch": 0.5844731115946534,
      "grad_norm": 0.37866339087486267,
      "learning_rate": 7.077634442026734e-06,
      "loss": 0.1721,
      "step": 7521
    },
    {
      "epoch": 0.5845508237488343,
      "grad_norm": 1.1239513158798218,
      "learning_rate": 7.077245881255829e-06,
      "loss": 0.3423,
      "step": 7522
    },
    {
      "epoch": 0.5846285359030152,
      "grad_norm": 0.5570576190948486,
      "learning_rate": 7.076857320484925e-06,
      "loss": 0.2807,
      "step": 7523
    },
    {
      "epoch": 0.5847062480571962,
      "grad_norm": 0.01564977876842022,
      "learning_rate": 7.076468759714021e-06,
      "loss": 0.0015,
      "step": 7524
    },
    {
      "epoch": 0.584783960211377,
      "grad_norm": 0.4328230023384094,
      "learning_rate": 7.076080198943115e-06,
      "loss": 0.353,
      "step": 7525
    },
    {
      "epoch": 0.584861672365558,
      "grad_norm": 0.10194384306669235,
      "learning_rate": 7.0756916381722105e-06,
      "loss": 0.1641,
      "step": 7526
    },
    {
      "epoch": 0.5849393845197389,
      "grad_norm": 0.4285050332546234,
      "learning_rate": 7.075303077401306e-06,
      "loss": 0.1275,
      "step": 7527
    },
    {
      "epoch": 0.5850170966739198,
      "grad_norm": 0.08417502790689468,
      "learning_rate": 7.074914516630401e-06,
      "loss": 0.0299,
      "step": 7528
    },
    {
      "epoch": 0.5850948088281007,
      "grad_norm": 0.4070090651512146,
      "learning_rate": 7.074525955859497e-06,
      "loss": 0.133,
      "step": 7529
    },
    {
      "epoch": 0.5851725209822817,
      "grad_norm": 0.16882652044296265,
      "learning_rate": 7.074137395088593e-06,
      "loss": 0.0594,
      "step": 7530
    },
    {
      "epoch": 0.5852502331364625,
      "grad_norm": 0.45516112446784973,
      "learning_rate": 7.073748834317688e-06,
      "loss": 0.4778,
      "step": 7531
    },
    {
      "epoch": 0.5853279452906435,
      "grad_norm": 0.4897182583808899,
      "learning_rate": 7.073360273546784e-06,
      "loss": 0.2639,
      "step": 7532
    },
    {
      "epoch": 0.5854056574448244,
      "grad_norm": 0.3358844816684723,
      "learning_rate": 7.072971712775879e-06,
      "loss": 0.2163,
      "step": 7533
    },
    {
      "epoch": 0.5854833695990053,
      "grad_norm": 1.0061956644058228,
      "learning_rate": 7.0725831520049735e-06,
      "loss": 0.9893,
      "step": 7534
    },
    {
      "epoch": 0.5855610817531862,
      "grad_norm": 0.32667675614356995,
      "learning_rate": 7.072194591234069e-06,
      "loss": 0.093,
      "step": 7535
    },
    {
      "epoch": 0.5856387939073671,
      "grad_norm": 0.5605327486991882,
      "learning_rate": 7.071806030463165e-06,
      "loss": 0.1785,
      "step": 7536
    },
    {
      "epoch": 0.585716506061548,
      "grad_norm": 0.5762791037559509,
      "learning_rate": 7.07141746969226e-06,
      "loss": 0.3091,
      "step": 7537
    },
    {
      "epoch": 0.585794218215729,
      "grad_norm": 0.21106117963790894,
      "learning_rate": 7.071028908921356e-06,
      "loss": 0.0763,
      "step": 7538
    },
    {
      "epoch": 0.5858719303699098,
      "grad_norm": 0.22599732875823975,
      "learning_rate": 7.070640348150452e-06,
      "loss": 0.1807,
      "step": 7539
    },
    {
      "epoch": 0.5859496425240908,
      "grad_norm": 0.07305143028497696,
      "learning_rate": 7.070251787379547e-06,
      "loss": 0.0106,
      "step": 7540
    },
    {
      "epoch": 0.5860273546782717,
      "grad_norm": 0.8709781169891357,
      "learning_rate": 7.069863226608642e-06,
      "loss": 0.3193,
      "step": 7541
    },
    {
      "epoch": 0.5861050668324526,
      "grad_norm": 0.4195297062397003,
      "learning_rate": 7.069474665837738e-06,
      "loss": 0.2525,
      "step": 7542
    },
    {
      "epoch": 0.5861827789866335,
      "grad_norm": 0.15862233936786652,
      "learning_rate": 7.069086105066834e-06,
      "loss": 0.0325,
      "step": 7543
    },
    {
      "epoch": 0.5862604911408145,
      "grad_norm": 0.4879022240638733,
      "learning_rate": 7.068697544295928e-06,
      "loss": 0.4558,
      "step": 7544
    },
    {
      "epoch": 0.5863382032949953,
      "grad_norm": 0.6529334187507629,
      "learning_rate": 7.068308983525024e-06,
      "loss": 0.2215,
      "step": 7545
    },
    {
      "epoch": 0.5864159154491763,
      "grad_norm": 0.33393144607543945,
      "learning_rate": 7.06792042275412e-06,
      "loss": 0.2503,
      "step": 7546
    },
    {
      "epoch": 0.5864936276033572,
      "grad_norm": 0.5436006188392639,
      "learning_rate": 7.067531861983215e-06,
      "loss": 0.1041,
      "step": 7547
    },
    {
      "epoch": 0.5865713397575381,
      "grad_norm": 0.3087303638458252,
      "learning_rate": 7.06714330121231e-06,
      "loss": 0.0605,
      "step": 7548
    },
    {
      "epoch": 0.586649051911719,
      "grad_norm": 0.15391728281974792,
      "learning_rate": 7.066754740441406e-06,
      "loss": 0.044,
      "step": 7549
    },
    {
      "epoch": 0.5867267640658999,
      "grad_norm": 0.19419166445732117,
      "learning_rate": 7.066366179670501e-06,
      "loss": 0.1242,
      "step": 7550
    },
    {
      "epoch": 0.5868044762200808,
      "grad_norm": 0.7186827659606934,
      "learning_rate": 7.065977618899597e-06,
      "loss": 0.4715,
      "step": 7551
    },
    {
      "epoch": 0.5868821883742618,
      "grad_norm": 0.6180292963981628,
      "learning_rate": 7.065589058128693e-06,
      "loss": 0.5451,
      "step": 7552
    },
    {
      "epoch": 0.5869599005284426,
      "grad_norm": 0.7858127355575562,
      "learning_rate": 7.065200497357787e-06,
      "loss": 0.3857,
      "step": 7553
    },
    {
      "epoch": 0.5870376126826236,
      "grad_norm": 0.35088175535202026,
      "learning_rate": 7.064811936586883e-06,
      "loss": 0.1146,
      "step": 7554
    },
    {
      "epoch": 0.5871153248368045,
      "grad_norm": 0.12659892439842224,
      "learning_rate": 7.0644233758159784e-06,
      "loss": 0.0172,
      "step": 7555
    },
    {
      "epoch": 0.5871930369909854,
      "grad_norm": 0.39932066202163696,
      "learning_rate": 7.064034815045073e-06,
      "loss": 0.163,
      "step": 7556
    },
    {
      "epoch": 0.5872707491451663,
      "grad_norm": 0.4062567949295044,
      "learning_rate": 7.063646254274169e-06,
      "loss": 0.2764,
      "step": 7557
    },
    {
      "epoch": 0.5873484612993473,
      "grad_norm": 0.49469542503356934,
      "learning_rate": 7.063257693503265e-06,
      "loss": 0.2984,
      "step": 7558
    },
    {
      "epoch": 0.5874261734535281,
      "grad_norm": 0.23127001523971558,
      "learning_rate": 7.06286913273236e-06,
      "loss": 0.09,
      "step": 7559
    },
    {
      "epoch": 0.587503885607709,
      "grad_norm": 0.37485405802726746,
      "learning_rate": 7.062480571961455e-06,
      "loss": 0.1076,
      "step": 7560
    },
    {
      "epoch": 0.58758159776189,
      "grad_norm": 0.260996013879776,
      "learning_rate": 7.062092011190551e-06,
      "loss": 0.1163,
      "step": 7561
    },
    {
      "epoch": 0.5876593099160708,
      "grad_norm": 0.41491320729255676,
      "learning_rate": 7.061703450419646e-06,
      "loss": 0.1362,
      "step": 7562
    },
    {
      "epoch": 0.5877370220702518,
      "grad_norm": 0.11061112582683563,
      "learning_rate": 7.0613148896487414e-06,
      "loss": 0.0475,
      "step": 7563
    },
    {
      "epoch": 0.5878147342244328,
      "grad_norm": 0.21830135583877563,
      "learning_rate": 7.060926328877837e-06,
      "loss": 0.0658,
      "step": 7564
    },
    {
      "epoch": 0.5878924463786136,
      "grad_norm": 0.2769813537597656,
      "learning_rate": 7.060537768106932e-06,
      "loss": 0.2475,
      "step": 7565
    },
    {
      "epoch": 0.5879701585327946,
      "grad_norm": 0.3541744351387024,
      "learning_rate": 7.060149207336028e-06,
      "loss": 0.3232,
      "step": 7566
    },
    {
      "epoch": 0.5880478706869754,
      "grad_norm": 0.3053854703903198,
      "learning_rate": 7.059760646565124e-06,
      "loss": 0.101,
      "step": 7567
    },
    {
      "epoch": 0.5881255828411563,
      "grad_norm": 0.31418612599372864,
      "learning_rate": 7.059372085794218e-06,
      "loss": 0.1166,
      "step": 7568
    },
    {
      "epoch": 0.5882032949953373,
      "grad_norm": 0.43335407972335815,
      "learning_rate": 7.058983525023314e-06,
      "loss": 0.773,
      "step": 7569
    },
    {
      "epoch": 0.5882810071495181,
      "grad_norm": 0.37025243043899536,
      "learning_rate": 7.0585949642524095e-06,
      "loss": 0.0965,
      "step": 7570
    },
    {
      "epoch": 0.5883587193036991,
      "grad_norm": 0.19914911687374115,
      "learning_rate": 7.058206403481504e-06,
      "loss": 0.1001,
      "step": 7571
    },
    {
      "epoch": 0.58843643145788,
      "grad_norm": 0.24410440027713776,
      "learning_rate": 7.0578178427106e-06,
      "loss": 0.0508,
      "step": 7572
    },
    {
      "epoch": 0.5885141436120609,
      "grad_norm": 0.4042949080467224,
      "learning_rate": 7.057429281939696e-06,
      "loss": 0.1313,
      "step": 7573
    },
    {
      "epoch": 0.5885918557662418,
      "grad_norm": 0.15421393513679504,
      "learning_rate": 7.057040721168792e-06,
      "loss": 0.0729,
      "step": 7574
    },
    {
      "epoch": 0.5886695679204228,
      "grad_norm": 0.11831468343734741,
      "learning_rate": 7.056652160397887e-06,
      "loss": 0.0254,
      "step": 7575
    },
    {
      "epoch": 0.5887472800746036,
      "grad_norm": 0.4475204646587372,
      "learning_rate": 7.0562635996269826e-06,
      "loss": 0.157,
      "step": 7576
    },
    {
      "epoch": 0.5888249922287846,
      "grad_norm": 0.28554415702819824,
      "learning_rate": 7.055875038856078e-06,
      "loss": 0.0898,
      "step": 7577
    },
    {
      "epoch": 0.5889027043829655,
      "grad_norm": 0.27498307824134827,
      "learning_rate": 7.0554864780851725e-06,
      "loss": 0.0592,
      "step": 7578
    },
    {
      "epoch": 0.5889804165371464,
      "grad_norm": 0.07125025987625122,
      "learning_rate": 7.055097917314268e-06,
      "loss": 0.0155,
      "step": 7579
    },
    {
      "epoch": 0.5890581286913273,
      "grad_norm": 0.6509348750114441,
      "learning_rate": 7.054709356543364e-06,
      "loss": 0.706,
      "step": 7580
    },
    {
      "epoch": 0.5891358408455082,
      "grad_norm": 0.3313741683959961,
      "learning_rate": 7.054320795772459e-06,
      "loss": 0.167,
      "step": 7581
    },
    {
      "epoch": 0.5892135529996891,
      "grad_norm": 0.30934369564056396,
      "learning_rate": 7.053932235001555e-06,
      "loss": 0.0769,
      "step": 7582
    },
    {
      "epoch": 0.5892912651538701,
      "grad_norm": 0.9548863172531128,
      "learning_rate": 7.053543674230651e-06,
      "loss": 0.3662,
      "step": 7583
    },
    {
      "epoch": 0.5893689773080509,
      "grad_norm": 0.32834354043006897,
      "learning_rate": 7.0531551134597455e-06,
      "loss": 0.0888,
      "step": 7584
    },
    {
      "epoch": 0.5894466894622319,
      "grad_norm": 0.18505926430225372,
      "learning_rate": 7.052766552688841e-06,
      "loss": 0.0412,
      "step": 7585
    },
    {
      "epoch": 0.5895244016164128,
      "grad_norm": 0.2762557864189148,
      "learning_rate": 7.052377991917937e-06,
      "loss": 0.1154,
      "step": 7586
    },
    {
      "epoch": 0.5896021137705937,
      "grad_norm": 0.21040940284729004,
      "learning_rate": 7.051989431147031e-06,
      "loss": 0.0429,
      "step": 7587
    },
    {
      "epoch": 0.5896798259247746,
      "grad_norm": 0.5137932896614075,
      "learning_rate": 7.051600870376127e-06,
      "loss": 0.211,
      "step": 7588
    },
    {
      "epoch": 0.5897575380789556,
      "grad_norm": 1.083964467048645,
      "learning_rate": 7.051212309605223e-06,
      "loss": 0.3993,
      "step": 7589
    },
    {
      "epoch": 0.5898352502331364,
      "grad_norm": 0.6768204569816589,
      "learning_rate": 7.050823748834318e-06,
      "loss": 0.3303,
      "step": 7590
    },
    {
      "epoch": 0.5899129623873174,
      "grad_norm": 0.19111183285713196,
      "learning_rate": 7.050435188063414e-06,
      "loss": 0.0737,
      "step": 7591
    },
    {
      "epoch": 0.5899906745414983,
      "grad_norm": 0.16684986650943756,
      "learning_rate": 7.050046627292509e-06,
      "loss": 0.088,
      "step": 7592
    },
    {
      "epoch": 0.5900683866956792,
      "grad_norm": 0.8167971968650818,
      "learning_rate": 7.049658066521604e-06,
      "loss": 0.7099,
      "step": 7593
    },
    {
      "epoch": 0.5901460988498601,
      "grad_norm": 0.32818129658699036,
      "learning_rate": 7.0492695057507e-06,
      "loss": 0.4769,
      "step": 7594
    },
    {
      "epoch": 0.590223811004041,
      "grad_norm": 0.30057889223098755,
      "learning_rate": 7.048880944979796e-06,
      "loss": 0.1128,
      "step": 7595
    },
    {
      "epoch": 0.5903015231582219,
      "grad_norm": 0.4622868299484253,
      "learning_rate": 7.04849238420889e-06,
      "loss": 0.3045,
      "step": 7596
    },
    {
      "epoch": 0.5903792353124029,
      "grad_norm": 0.15592195093631744,
      "learning_rate": 7.048103823437986e-06,
      "loss": 0.0303,
      "step": 7597
    },
    {
      "epoch": 0.5904569474665837,
      "grad_norm": 0.4312571585178375,
      "learning_rate": 7.047715262667082e-06,
      "loss": 0.1185,
      "step": 7598
    },
    {
      "epoch": 0.5905346596207647,
      "grad_norm": 0.6655487418174744,
      "learning_rate": 7.0473267018961766e-06,
      "loss": 0.3216,
      "step": 7599
    },
    {
      "epoch": 0.5906123717749456,
      "grad_norm": 0.5251752734184265,
      "learning_rate": 7.046938141125272e-06,
      "loss": 0.3146,
      "step": 7600
    },
    {
      "epoch": 0.5906900839291265,
      "grad_norm": 0.3900584578514099,
      "learning_rate": 7.046549580354368e-06,
      "loss": 0.253,
      "step": 7601
    },
    {
      "epoch": 0.5907677960833074,
      "grad_norm": 0.4145088791847229,
      "learning_rate": 7.046161019583463e-06,
      "loss": 0.2207,
      "step": 7602
    },
    {
      "epoch": 0.5908455082374884,
      "grad_norm": 0.7034107446670532,
      "learning_rate": 7.045772458812559e-06,
      "loss": 0.3532,
      "step": 7603
    },
    {
      "epoch": 0.5909232203916692,
      "grad_norm": 0.465932160615921,
      "learning_rate": 7.045383898041655e-06,
      "loss": 0.4421,
      "step": 7604
    },
    {
      "epoch": 0.5910009325458502,
      "grad_norm": 0.39806246757507324,
      "learning_rate": 7.0449953372707505e-06,
      "loss": 0.0729,
      "step": 7605
    },
    {
      "epoch": 0.5910786447000311,
      "grad_norm": 0.39948394894599915,
      "learning_rate": 7.044606776499845e-06,
      "loss": 0.09,
      "step": 7606
    },
    {
      "epoch": 0.591156356854212,
      "grad_norm": 0.1954817771911621,
      "learning_rate": 7.04421821572894e-06,
      "loss": 0.0886,
      "step": 7607
    },
    {
      "epoch": 0.5912340690083929,
      "grad_norm": 0.4969186782836914,
      "learning_rate": 7.043829654958036e-06,
      "loss": 0.0781,
      "step": 7608
    },
    {
      "epoch": 0.5913117811625739,
      "grad_norm": 0.5017286539077759,
      "learning_rate": 7.043441094187131e-06,
      "loss": 0.5419,
      "step": 7609
    },
    {
      "epoch": 0.5913894933167547,
      "grad_norm": 0.440684050321579,
      "learning_rate": 7.043052533416227e-06,
      "loss": 0.0861,
      "step": 7610
    },
    {
      "epoch": 0.5914672054709357,
      "grad_norm": 0.45332100987434387,
      "learning_rate": 7.042663972645323e-06,
      "loss": 0.1568,
      "step": 7611
    },
    {
      "epoch": 0.5915449176251165,
      "grad_norm": 0.30178752541542053,
      "learning_rate": 7.042275411874418e-06,
      "loss": 0.1555,
      "step": 7612
    },
    {
      "epoch": 0.5916226297792975,
      "grad_norm": 0.2581969201564789,
      "learning_rate": 7.0418868511035135e-06,
      "loss": 0.0492,
      "step": 7613
    },
    {
      "epoch": 0.5917003419334784,
      "grad_norm": 0.28549614548683167,
      "learning_rate": 7.041498290332609e-06,
      "loss": 0.0491,
      "step": 7614
    },
    {
      "epoch": 0.5917780540876593,
      "grad_norm": 0.3771209418773651,
      "learning_rate": 7.041109729561703e-06,
      "loss": 0.199,
      "step": 7615
    },
    {
      "epoch": 0.5918557662418402,
      "grad_norm": 0.496676504611969,
      "learning_rate": 7.040721168790799e-06,
      "loss": 0.1036,
      "step": 7616
    },
    {
      "epoch": 0.5919334783960212,
      "grad_norm": 0.20094868540763855,
      "learning_rate": 7.040332608019895e-06,
      "loss": 0.0468,
      "step": 7617
    },
    {
      "epoch": 0.592011190550202,
      "grad_norm": 0.8026643991470337,
      "learning_rate": 7.03994404724899e-06,
      "loss": 0.2203,
      "step": 7618
    },
    {
      "epoch": 0.592088902704383,
      "grad_norm": 0.15628209710121155,
      "learning_rate": 7.039555486478086e-06,
      "loss": 0.0999,
      "step": 7619
    },
    {
      "epoch": 0.5921666148585639,
      "grad_norm": 0.2805584967136383,
      "learning_rate": 7.0391669257071815e-06,
      "loss": 0.0542,
      "step": 7620
    },
    {
      "epoch": 0.5922443270127448,
      "grad_norm": 0.38929182291030884,
      "learning_rate": 7.0387783649362765e-06,
      "loss": 0.0858,
      "step": 7621
    },
    {
      "epoch": 0.5923220391669257,
      "grad_norm": 0.48900431394577026,
      "learning_rate": 7.038389804165372e-06,
      "loss": 0.2004,
      "step": 7622
    },
    {
      "epoch": 0.5923997513211067,
      "grad_norm": 0.6908445954322815,
      "learning_rate": 7.038001243394468e-06,
      "loss": 0.3777,
      "step": 7623
    },
    {
      "epoch": 0.5924774634752875,
      "grad_norm": 0.10691192746162415,
      "learning_rate": 7.037612682623562e-06,
      "loss": 0.0533,
      "step": 7624
    },
    {
      "epoch": 0.5925551756294685,
      "grad_norm": 0.6114780902862549,
      "learning_rate": 7.037224121852658e-06,
      "loss": 0.3786,
      "step": 7625
    },
    {
      "epoch": 0.5926328877836493,
      "grad_norm": 0.6448121666908264,
      "learning_rate": 7.036835561081754e-06,
      "loss": 0.2673,
      "step": 7626
    },
    {
      "epoch": 0.5927105999378303,
      "grad_norm": 0.2502340078353882,
      "learning_rate": 7.036447000310849e-06,
      "loss": 0.2374,
      "step": 7627
    },
    {
      "epoch": 0.5927883120920112,
      "grad_norm": 0.5362331867218018,
      "learning_rate": 7.0360584395399445e-06,
      "loss": 0.1709,
      "step": 7628
    },
    {
      "epoch": 0.5928660242461921,
      "grad_norm": 0.2742405831813812,
      "learning_rate": 7.03566987876904e-06,
      "loss": 0.0634,
      "step": 7629
    },
    {
      "epoch": 0.592943736400373,
      "grad_norm": 0.5021845102310181,
      "learning_rate": 7.035281317998135e-06,
      "loss": 0.4163,
      "step": 7630
    },
    {
      "epoch": 0.593021448554554,
      "grad_norm": 0.12688779830932617,
      "learning_rate": 7.034892757227231e-06,
      "loss": 0.0286,
      "step": 7631
    },
    {
      "epoch": 0.5930991607087348,
      "grad_norm": 0.07890475541353226,
      "learning_rate": 7.034504196456327e-06,
      "loss": 0.0231,
      "step": 7632
    },
    {
      "epoch": 0.5931768728629158,
      "grad_norm": 0.2736741304397583,
      "learning_rate": 7.034115635685423e-06,
      "loss": 0.0516,
      "step": 7633
    },
    {
      "epoch": 0.5932545850170967,
      "grad_norm": 0.4415680468082428,
      "learning_rate": 7.033727074914517e-06,
      "loss": 0.4099,
      "step": 7634
    },
    {
      "epoch": 0.5933322971712776,
      "grad_norm": 0.7089345455169678,
      "learning_rate": 7.0333385141436125e-06,
      "loss": 0.2887,
      "step": 7635
    },
    {
      "epoch": 0.5934100093254585,
      "grad_norm": 0.4210244417190552,
      "learning_rate": 7.032949953372708e-06,
      "loss": 0.259,
      "step": 7636
    },
    {
      "epoch": 0.5934877214796395,
      "grad_norm": 0.1790260225534439,
      "learning_rate": 7.032561392601803e-06,
      "loss": 0.0654,
      "step": 7637
    },
    {
      "epoch": 0.5935654336338203,
      "grad_norm": 0.2047354280948639,
      "learning_rate": 7.032172831830899e-06,
      "loss": 0.1325,
      "step": 7638
    },
    {
      "epoch": 0.5936431457880013,
      "grad_norm": 0.24534323811531067,
      "learning_rate": 7.031784271059995e-06,
      "loss": 0.0873,
      "step": 7639
    },
    {
      "epoch": 0.5937208579421822,
      "grad_norm": 0.35071060061454773,
      "learning_rate": 7.03139571028909e-06,
      "loss": 0.2222,
      "step": 7640
    },
    {
      "epoch": 0.593798570096363,
      "grad_norm": 0.23328588902950287,
      "learning_rate": 7.031007149518186e-06,
      "loss": 0.0349,
      "step": 7641
    },
    {
      "epoch": 0.593876282250544,
      "grad_norm": 0.039206042885780334,
      "learning_rate": 7.0306185887472814e-06,
      "loss": 0.0039,
      "step": 7642
    },
    {
      "epoch": 0.5939539944047248,
      "grad_norm": 0.574036717414856,
      "learning_rate": 7.0302300279763755e-06,
      "loss": 0.3054,
      "step": 7643
    },
    {
      "epoch": 0.5940317065589058,
      "grad_norm": 0.17956598103046417,
      "learning_rate": 7.029841467205471e-06,
      "loss": 0.0313,
      "step": 7644
    },
    {
      "epoch": 0.5941094187130868,
      "grad_norm": 0.11403860151767731,
      "learning_rate": 7.029452906434567e-06,
      "loss": 0.0243,
      "step": 7645
    },
    {
      "epoch": 0.5941871308672676,
      "grad_norm": 1.2218420505523682,
      "learning_rate": 7.029064345663662e-06,
      "loss": 0.8126,
      "step": 7646
    },
    {
      "epoch": 0.5942648430214486,
      "grad_norm": 0.4104749262332916,
      "learning_rate": 7.028675784892758e-06,
      "loss": 0.1683,
      "step": 7647
    },
    {
      "epoch": 0.5943425551756295,
      "grad_norm": 0.2104121893644333,
      "learning_rate": 7.028287224121854e-06,
      "loss": 0.1117,
      "step": 7648
    },
    {
      "epoch": 0.5944202673298103,
      "grad_norm": 0.07938756048679352,
      "learning_rate": 7.027898663350949e-06,
      "loss": 0.0235,
      "step": 7649
    },
    {
      "epoch": 0.5944979794839913,
      "grad_norm": 0.5157926082611084,
      "learning_rate": 7.027510102580044e-06,
      "loss": 0.1268,
      "step": 7650
    },
    {
      "epoch": 0.5945756916381723,
      "grad_norm": 0.42898231744766235,
      "learning_rate": 7.02712154180914e-06,
      "loss": 0.2129,
      "step": 7651
    },
    {
      "epoch": 0.5946534037923531,
      "grad_norm": 0.5559858083724976,
      "learning_rate": 7.026732981038234e-06,
      "loss": 0.3448,
      "step": 7652
    },
    {
      "epoch": 0.594731115946534,
      "grad_norm": 0.6873824596405029,
      "learning_rate": 7.02634442026733e-06,
      "loss": 0.7988,
      "step": 7653
    },
    {
      "epoch": 0.594808828100715,
      "grad_norm": 0.6164431571960449,
      "learning_rate": 7.025955859496426e-06,
      "loss": 0.4706,
      "step": 7654
    },
    {
      "epoch": 0.5948865402548958,
      "grad_norm": 0.29513227939605713,
      "learning_rate": 7.025567298725521e-06,
      "loss": 0.0968,
      "step": 7655
    },
    {
      "epoch": 0.5949642524090768,
      "grad_norm": 0.31067323684692383,
      "learning_rate": 7.025178737954617e-06,
      "loss": 0.0123,
      "step": 7656
    },
    {
      "epoch": 0.5950419645632576,
      "grad_norm": 0.4478258788585663,
      "learning_rate": 7.0247901771837125e-06,
      "loss": 0.4305,
      "step": 7657
    },
    {
      "epoch": 0.5951196767174386,
      "grad_norm": 0.5420200228691101,
      "learning_rate": 7.024401616412807e-06,
      "loss": 0.9933,
      "step": 7658
    },
    {
      "epoch": 0.5951973888716195,
      "grad_norm": 0.6927140355110168,
      "learning_rate": 7.024013055641903e-06,
      "loss": 0.3521,
      "step": 7659
    },
    {
      "epoch": 0.5952751010258004,
      "grad_norm": 0.2636372148990631,
      "learning_rate": 7.023624494870999e-06,
      "loss": 0.0475,
      "step": 7660
    },
    {
      "epoch": 0.5953528131799813,
      "grad_norm": 0.4178749620914459,
      "learning_rate": 7.023235934100093e-06,
      "loss": 0.1512,
      "step": 7661
    },
    {
      "epoch": 0.5954305253341623,
      "grad_norm": 0.09803098440170288,
      "learning_rate": 7.022847373329189e-06,
      "loss": 0.0361,
      "step": 7662
    },
    {
      "epoch": 0.5955082374883431,
      "grad_norm": 0.2298036515712738,
      "learning_rate": 7.022458812558285e-06,
      "loss": 0.1123,
      "step": 7663
    },
    {
      "epoch": 0.5955859496425241,
      "grad_norm": 0.6024230718612671,
      "learning_rate": 7.0220702517873805e-06,
      "loss": 0.4637,
      "step": 7664
    },
    {
      "epoch": 0.595663661796705,
      "grad_norm": 0.3012263774871826,
      "learning_rate": 7.0216816910164754e-06,
      "loss": 0.2591,
      "step": 7665
    },
    {
      "epoch": 0.5957413739508859,
      "grad_norm": 0.42673638463020325,
      "learning_rate": 7.021293130245571e-06,
      "loss": 0.3098,
      "step": 7666
    },
    {
      "epoch": 0.5958190861050668,
      "grad_norm": 0.3942693769931793,
      "learning_rate": 7.020904569474667e-06,
      "loss": 0.356,
      "step": 7667
    },
    {
      "epoch": 0.5958967982592478,
      "grad_norm": 0.42814570665359497,
      "learning_rate": 7.020516008703762e-06,
      "loss": 0.1801,
      "step": 7668
    },
    {
      "epoch": 0.5959745104134286,
      "grad_norm": 0.8101379871368408,
      "learning_rate": 7.020127447932858e-06,
      "loss": 0.2142,
      "step": 7669
    },
    {
      "epoch": 0.5960522225676096,
      "grad_norm": 1.24962317943573,
      "learning_rate": 7.019738887161954e-06,
      "loss": 0.761,
      "step": 7670
    },
    {
      "epoch": 0.5961299347217904,
      "grad_norm": 0.20835354924201965,
      "learning_rate": 7.019350326391048e-06,
      "loss": 0.0949,
      "step": 7671
    },
    {
      "epoch": 0.5962076468759714,
      "grad_norm": 0.6052783131599426,
      "learning_rate": 7.0189617656201435e-06,
      "loss": 0.2748,
      "step": 7672
    },
    {
      "epoch": 0.5962853590301523,
      "grad_norm": 0.1480357050895691,
      "learning_rate": 7.018573204849239e-06,
      "loss": 0.0453,
      "step": 7673
    },
    {
      "epoch": 0.5963630711843332,
      "grad_norm": 0.33021536469459534,
      "learning_rate": 7.018184644078334e-06,
      "loss": 0.2249,
      "step": 7674
    },
    {
      "epoch": 0.5964407833385141,
      "grad_norm": 0.4626917243003845,
      "learning_rate": 7.01779608330743e-06,
      "loss": 0.4814,
      "step": 7675
    },
    {
      "epoch": 0.5965184954926951,
      "grad_norm": 0.5722681879997253,
      "learning_rate": 7.017407522536526e-06,
      "loss": 0.2592,
      "step": 7676
    },
    {
      "epoch": 0.5965962076468759,
      "grad_norm": 0.1117958128452301,
      "learning_rate": 7.017018961765621e-06,
      "loss": 0.0561,
      "step": 7677
    },
    {
      "epoch": 0.5966739198010569,
      "grad_norm": 0.21194137632846832,
      "learning_rate": 7.0166304009947166e-06,
      "loss": 0.1195,
      "step": 7678
    },
    {
      "epoch": 0.5967516319552378,
      "grad_norm": 0.3255866765975952,
      "learning_rate": 7.016241840223812e-06,
      "loss": 0.1384,
      "step": 7679
    },
    {
      "epoch": 0.5968293441094187,
      "grad_norm": 0.41855278611183167,
      "learning_rate": 7.0158532794529065e-06,
      "loss": 0.1557,
      "step": 7680
    },
    {
      "epoch": 0.5969070562635996,
      "grad_norm": 0.4887985289096832,
      "learning_rate": 7.015464718682002e-06,
      "loss": 0.1506,
      "step": 7681
    },
    {
      "epoch": 0.5969847684177806,
      "grad_norm": 0.5727244019508362,
      "learning_rate": 7.015076157911098e-06,
      "loss": 0.2519,
      "step": 7682
    },
    {
      "epoch": 0.5970624805719614,
      "grad_norm": 1.0765472650527954,
      "learning_rate": 7.014687597140193e-06,
      "loss": 0.5783,
      "step": 7683
    },
    {
      "epoch": 0.5971401927261424,
      "grad_norm": 0.23552417755126953,
      "learning_rate": 7.014299036369289e-06,
      "loss": 0.0772,
      "step": 7684
    },
    {
      "epoch": 0.5972179048803233,
      "grad_norm": 0.31163567304611206,
      "learning_rate": 7.013910475598385e-06,
      "loss": 0.1388,
      "step": 7685
    },
    {
      "epoch": 0.5972956170345042,
      "grad_norm": 0.35313260555267334,
      "learning_rate": 7.0135219148274795e-06,
      "loss": 0.1816,
      "step": 7686
    },
    {
      "epoch": 0.5973733291886851,
      "grad_norm": 0.4386555254459381,
      "learning_rate": 7.0131333540565745e-06,
      "loss": 0.2053,
      "step": 7687
    },
    {
      "epoch": 0.597451041342866,
      "grad_norm": 0.22312742471694946,
      "learning_rate": 7.01274479328567e-06,
      "loss": 0.0803,
      "step": 7688
    },
    {
      "epoch": 0.5975287534970469,
      "grad_norm": 0.28914546966552734,
      "learning_rate": 7.012356232514765e-06,
      "loss": 0.1529,
      "step": 7689
    },
    {
      "epoch": 0.5976064656512279,
      "grad_norm": 0.3965957462787628,
      "learning_rate": 7.011967671743861e-06,
      "loss": 0.1797,
      "step": 7690
    },
    {
      "epoch": 0.5976841778054087,
      "grad_norm": 1.1136236190795898,
      "learning_rate": 7.011579110972957e-06,
      "loss": 0.2456,
      "step": 7691
    },
    {
      "epoch": 0.5977618899595897,
      "grad_norm": 0.39110440015792847,
      "learning_rate": 7.011190550202052e-06,
      "loss": 0.1049,
      "step": 7692
    },
    {
      "epoch": 0.5978396021137706,
      "grad_norm": 0.5962867140769958,
      "learning_rate": 7.010801989431148e-06,
      "loss": 0.464,
      "step": 7693
    },
    {
      "epoch": 0.5979173142679515,
      "grad_norm": 0.4610554873943329,
      "learning_rate": 7.010413428660243e-06,
      "loss": 0.1326,
      "step": 7694
    },
    {
      "epoch": 0.5979950264221324,
      "grad_norm": 0.09320791810750961,
      "learning_rate": 7.010024867889339e-06,
      "loss": 0.0224,
      "step": 7695
    },
    {
      "epoch": 0.5980727385763134,
      "grad_norm": 0.14970538020133972,
      "learning_rate": 7.009636307118433e-06,
      "loss": 0.0344,
      "step": 7696
    },
    {
      "epoch": 0.5981504507304942,
      "grad_norm": 0.40233224630355835,
      "learning_rate": 7.009247746347529e-06,
      "loss": 0.1422,
      "step": 7697
    },
    {
      "epoch": 0.5982281628846752,
      "grad_norm": 1.191349983215332,
      "learning_rate": 7.008859185576625e-06,
      "loss": 1.5155,
      "step": 7698
    },
    {
      "epoch": 0.5983058750388561,
      "grad_norm": 0.5101439356803894,
      "learning_rate": 7.00847062480572e-06,
      "loss": 0.0952,
      "step": 7699
    },
    {
      "epoch": 0.598383587193037,
      "grad_norm": 0.5072318911552429,
      "learning_rate": 7.008082064034816e-06,
      "loss": 0.1131,
      "step": 7700
    },
    {
      "epoch": 0.5984612993472179,
      "grad_norm": 0.6413260698318481,
      "learning_rate": 7.007693503263911e-06,
      "loss": 0.1413,
      "step": 7701
    },
    {
      "epoch": 0.5985390115013988,
      "grad_norm": 0.2362375259399414,
      "learning_rate": 7.007304942493006e-06,
      "loss": 0.0666,
      "step": 7702
    },
    {
      "epoch": 0.5986167236555797,
      "grad_norm": 0.7041454315185547,
      "learning_rate": 7.006916381722102e-06,
      "loss": 0.5154,
      "step": 7703
    },
    {
      "epoch": 0.5986944358097607,
      "grad_norm": 0.3224240839481354,
      "learning_rate": 7.006527820951198e-06,
      "loss": 0.1507,
      "step": 7704
    },
    {
      "epoch": 0.5987721479639415,
      "grad_norm": 0.8580989241600037,
      "learning_rate": 7.006139260180292e-06,
      "loss": 0.1733,
      "step": 7705
    },
    {
      "epoch": 0.5988498601181225,
      "grad_norm": 0.9354609251022339,
      "learning_rate": 7.005750699409388e-06,
      "loss": 0.2944,
      "step": 7706
    },
    {
      "epoch": 0.5989275722723034,
      "grad_norm": 0.336575448513031,
      "learning_rate": 7.005362138638484e-06,
      "loss": 0.1013,
      "step": 7707
    },
    {
      "epoch": 0.5990052844264843,
      "grad_norm": 0.2818085551261902,
      "learning_rate": 7.004973577867579e-06,
      "loss": 0.2637,
      "step": 7708
    },
    {
      "epoch": 0.5990829965806652,
      "grad_norm": 0.7055681347846985,
      "learning_rate": 7.004585017096674e-06,
      "loss": 0.2956,
      "step": 7709
    },
    {
      "epoch": 0.5991607087348462,
      "grad_norm": 0.8232301473617554,
      "learning_rate": 7.00419645632577e-06,
      "loss": 0.4269,
      "step": 7710
    },
    {
      "epoch": 0.599238420889027,
      "grad_norm": 0.9017685651779175,
      "learning_rate": 7.003807895554865e-06,
      "loss": 0.5505,
      "step": 7711
    },
    {
      "epoch": 0.599316133043208,
      "grad_norm": 0.3048924207687378,
      "learning_rate": 7.003419334783961e-06,
      "loss": 0.0912,
      "step": 7712
    },
    {
      "epoch": 0.5993938451973889,
      "grad_norm": 0.10552497208118439,
      "learning_rate": 7.003030774013057e-06,
      "loss": 0.0209,
      "step": 7713
    },
    {
      "epoch": 0.5994715573515698,
      "grad_norm": 0.3945668339729309,
      "learning_rate": 7.002642213242151e-06,
      "loss": 0.2623,
      "step": 7714
    },
    {
      "epoch": 0.5995492695057507,
      "grad_norm": 0.7955232858657837,
      "learning_rate": 7.002253652471247e-06,
      "loss": 0.3162,
      "step": 7715
    },
    {
      "epoch": 0.5996269816599317,
      "grad_norm": 0.2518932819366455,
      "learning_rate": 7.0018650917003424e-06,
      "loss": 0.1409,
      "step": 7716
    },
    {
      "epoch": 0.5997046938141125,
      "grad_norm": 0.6555611491203308,
      "learning_rate": 7.001476530929437e-06,
      "loss": 0.4213,
      "step": 7717
    },
    {
      "epoch": 0.5997824059682935,
      "grad_norm": 0.22779038548469543,
      "learning_rate": 7.001087970158533e-06,
      "loss": 0.0869,
      "step": 7718
    },
    {
      "epoch": 0.5998601181224743,
      "grad_norm": 0.28358277678489685,
      "learning_rate": 7.000699409387629e-06,
      "loss": 0.3338,
      "step": 7719
    },
    {
      "epoch": 0.5999378302766553,
      "grad_norm": 0.6189860701560974,
      "learning_rate": 7.000310848616724e-06,
      "loss": 0.2946,
      "step": 7720
    },
    {
      "epoch": 0.6000155424308362,
      "grad_norm": 0.4153595566749573,
      "learning_rate": 6.99992228784582e-06,
      "loss": 0.2434,
      "step": 7721
    },
    {
      "epoch": 0.600093254585017,
      "grad_norm": 1.9418941736221313,
      "learning_rate": 6.9995337270749155e-06,
      "loss": 0.3894,
      "step": 7722
    },
    {
      "epoch": 0.600170966739198,
      "grad_norm": 0.12020409852266312,
      "learning_rate": 6.99914516630401e-06,
      "loss": 0.0131,
      "step": 7723
    },
    {
      "epoch": 0.600248678893379,
      "grad_norm": 0.24570687115192413,
      "learning_rate": 6.9987566055331054e-06,
      "loss": 0.0578,
      "step": 7724
    },
    {
      "epoch": 0.6003263910475598,
      "grad_norm": 0.2847144603729248,
      "learning_rate": 6.998368044762201e-06,
      "loss": 0.0599,
      "step": 7725
    },
    {
      "epoch": 0.6004041032017408,
      "grad_norm": 0.11487027257680893,
      "learning_rate": 6.997979483991297e-06,
      "loss": 0.0212,
      "step": 7726
    },
    {
      "epoch": 0.6004818153559217,
      "grad_norm": 0.2223082035779953,
      "learning_rate": 6.997590923220392e-06,
      "loss": 0.0541,
      "step": 7727
    },
    {
      "epoch": 0.6005595275101026,
      "grad_norm": 0.3367334306240082,
      "learning_rate": 6.997202362449488e-06,
      "loss": 0.0913,
      "step": 7728
    },
    {
      "epoch": 0.6006372396642835,
      "grad_norm": 0.2643873989582062,
      "learning_rate": 6.9968138016785836e-06,
      "loss": 0.2122,
      "step": 7729
    },
    {
      "epoch": 0.6007149518184645,
      "grad_norm": 0.15646623075008392,
      "learning_rate": 6.9964252409076785e-06,
      "loss": 0.1154,
      "step": 7730
    },
    {
      "epoch": 0.6007926639726453,
      "grad_norm": 0.2816087603569031,
      "learning_rate": 6.996036680136774e-06,
      "loss": 0.0529,
      "step": 7731
    },
    {
      "epoch": 0.6008703761268263,
      "grad_norm": 0.16446012258529663,
      "learning_rate": 6.99564811936587e-06,
      "loss": 0.0614,
      "step": 7732
    },
    {
      "epoch": 0.6009480882810071,
      "grad_norm": 0.3190912902355194,
      "learning_rate": 6.995259558594964e-06,
      "loss": 0.1062,
      "step": 7733
    },
    {
      "epoch": 0.601025800435188,
      "grad_norm": 0.38442549109458923,
      "learning_rate": 6.99487099782406e-06,
      "loss": 0.198,
      "step": 7734
    },
    {
      "epoch": 0.601103512589369,
      "grad_norm": 0.2342846840620041,
      "learning_rate": 6.994482437053156e-06,
      "loss": 0.0893,
      "step": 7735
    },
    {
      "epoch": 0.6011812247435498,
      "grad_norm": 0.49421852827072144,
      "learning_rate": 6.994093876282251e-06,
      "loss": 0.2782,
      "step": 7736
    },
    {
      "epoch": 0.6012589368977308,
      "grad_norm": 0.12396535277366638,
      "learning_rate": 6.9937053155113466e-06,
      "loss": 0.0242,
      "step": 7737
    },
    {
      "epoch": 0.6013366490519118,
      "grad_norm": 0.48849421739578247,
      "learning_rate": 6.993316754740442e-06,
      "loss": 0.2473,
      "step": 7738
    },
    {
      "epoch": 0.6014143612060926,
      "grad_norm": 0.44016724824905396,
      "learning_rate": 6.992928193969537e-06,
      "loss": 0.0533,
      "step": 7739
    },
    {
      "epoch": 0.6014920733602735,
      "grad_norm": 0.46470147371292114,
      "learning_rate": 6.992539633198633e-06,
      "loss": 0.6442,
      "step": 7740
    },
    {
      "epoch": 0.6015697855144545,
      "grad_norm": 0.21787571907043457,
      "learning_rate": 6.992151072427729e-06,
      "loss": 0.1732,
      "step": 7741
    },
    {
      "epoch": 0.6016474976686353,
      "grad_norm": 0.30814969539642334,
      "learning_rate": 6.991762511656823e-06,
      "loss": 0.2283,
      "step": 7742
    },
    {
      "epoch": 0.6017252098228163,
      "grad_norm": 0.15475675463676453,
      "learning_rate": 6.991373950885919e-06,
      "loss": 0.1194,
      "step": 7743
    },
    {
      "epoch": 0.6018029219769973,
      "grad_norm": 0.486246258020401,
      "learning_rate": 6.990985390115015e-06,
      "loss": 0.349,
      "step": 7744
    },
    {
      "epoch": 0.6018806341311781,
      "grad_norm": 0.27781474590301514,
      "learning_rate": 6.9905968293441095e-06,
      "loss": 0.1782,
      "step": 7745
    },
    {
      "epoch": 0.601958346285359,
      "grad_norm": 0.184611514210701,
      "learning_rate": 6.990208268573205e-06,
      "loss": 0.0758,
      "step": 7746
    },
    {
      "epoch": 0.6020360584395399,
      "grad_norm": 0.2742587924003601,
      "learning_rate": 6.989819707802301e-06,
      "loss": 0.1053,
      "step": 7747
    },
    {
      "epoch": 0.6021137705937208,
      "grad_norm": 0.22372843325138092,
      "learning_rate": 6.989431147031396e-06,
      "loss": 0.0878,
      "step": 7748
    },
    {
      "epoch": 0.6021914827479018,
      "grad_norm": 0.11477875709533691,
      "learning_rate": 6.989042586260492e-06,
      "loss": 0.018,
      "step": 7749
    },
    {
      "epoch": 0.6022691949020826,
      "grad_norm": 0.6500675678253174,
      "learning_rate": 6.988654025489588e-06,
      "loss": 0.2801,
      "step": 7750
    },
    {
      "epoch": 0.6023469070562636,
      "grad_norm": 0.412030428647995,
      "learning_rate": 6.988265464718682e-06,
      "loss": 0.1795,
      "step": 7751
    },
    {
      "epoch": 0.6024246192104445,
      "grad_norm": 0.431629478931427,
      "learning_rate": 6.9878769039477776e-06,
      "loss": 0.3046,
      "step": 7752
    },
    {
      "epoch": 0.6025023313646254,
      "grad_norm": 0.6392512321472168,
      "learning_rate": 6.987488343176873e-06,
      "loss": 0.2584,
      "step": 7753
    },
    {
      "epoch": 0.6025800435188063,
      "grad_norm": 0.10099592059850693,
      "learning_rate": 6.987099782405968e-06,
      "loss": 0.0102,
      "step": 7754
    },
    {
      "epoch": 0.6026577556729873,
      "grad_norm": 0.2810603380203247,
      "learning_rate": 6.986711221635064e-06,
      "loss": 0.0706,
      "step": 7755
    },
    {
      "epoch": 0.6027354678271681,
      "grad_norm": 0.4028412699699402,
      "learning_rate": 6.98632266086416e-06,
      "loss": 0.1339,
      "step": 7756
    },
    {
      "epoch": 0.6028131799813491,
      "grad_norm": 0.3270927369594574,
      "learning_rate": 6.985934100093256e-06,
      "loss": 0.2253,
      "step": 7757
    },
    {
      "epoch": 0.60289089213553,
      "grad_norm": 0.1946820318698883,
      "learning_rate": 6.985545539322351e-06,
      "loss": 0.0961,
      "step": 7758
    },
    {
      "epoch": 0.6029686042897109,
      "grad_norm": 0.21537569165229797,
      "learning_rate": 6.9851569785514465e-06,
      "loss": 0.0188,
      "step": 7759
    },
    {
      "epoch": 0.6030463164438918,
      "grad_norm": 0.11944117397069931,
      "learning_rate": 6.984768417780542e-06,
      "loss": 0.0179,
      "step": 7760
    },
    {
      "epoch": 0.6031240285980728,
      "grad_norm": 0.43823617696762085,
      "learning_rate": 6.984379857009636e-06,
      "loss": 0.5481,
      "step": 7761
    },
    {
      "epoch": 0.6032017407522536,
      "grad_norm": 0.3513718843460083,
      "learning_rate": 6.983991296238732e-06,
      "loss": 0.0896,
      "step": 7762
    },
    {
      "epoch": 0.6032794529064346,
      "grad_norm": 0.030889317393302917,
      "learning_rate": 6.983602735467828e-06,
      "loss": 0.0031,
      "step": 7763
    },
    {
      "epoch": 0.6033571650606154,
      "grad_norm": 0.9971172213554382,
      "learning_rate": 6.983214174696923e-06,
      "loss": 0.8194,
      "step": 7764
    },
    {
      "epoch": 0.6034348772147964,
      "grad_norm": 0.22311246395111084,
      "learning_rate": 6.982825613926019e-06,
      "loss": 0.0372,
      "step": 7765
    },
    {
      "epoch": 0.6035125893689773,
      "grad_norm": 0.3166572153568268,
      "learning_rate": 6.9824370531551145e-06,
      "loss": 0.2216,
      "step": 7766
    },
    {
      "epoch": 0.6035903015231582,
      "grad_norm": 0.0773172453045845,
      "learning_rate": 6.9820484923842094e-06,
      "loss": 0.0626,
      "step": 7767
    },
    {
      "epoch": 0.6036680136773391,
      "grad_norm": 0.0747121199965477,
      "learning_rate": 6.981659931613305e-06,
      "loss": 0.0335,
      "step": 7768
    },
    {
      "epoch": 0.6037457258315201,
      "grad_norm": 0.8391537070274353,
      "learning_rate": 6.981271370842401e-06,
      "loss": 0.4629,
      "step": 7769
    },
    {
      "epoch": 0.6038234379857009,
      "grad_norm": 0.29630613327026367,
      "learning_rate": 6.980882810071495e-06,
      "loss": 0.0983,
      "step": 7770
    },
    {
      "epoch": 0.6039011501398819,
      "grad_norm": 0.3464549779891968,
      "learning_rate": 6.980494249300591e-06,
      "loss": 0.1621,
      "step": 7771
    },
    {
      "epoch": 0.6039788622940628,
      "grad_norm": 0.26418018341064453,
      "learning_rate": 6.980105688529687e-06,
      "loss": 0.1035,
      "step": 7772
    },
    {
      "epoch": 0.6040565744482437,
      "grad_norm": 0.4021710455417633,
      "learning_rate": 6.979717127758782e-06,
      "loss": 0.2473,
      "step": 7773
    },
    {
      "epoch": 0.6041342866024246,
      "grad_norm": 0.10633065551519394,
      "learning_rate": 6.9793285669878775e-06,
      "loss": 0.0402,
      "step": 7774
    },
    {
      "epoch": 0.6042119987566056,
      "grad_norm": 0.28165197372436523,
      "learning_rate": 6.978940006216973e-06,
      "loss": 0.1326,
      "step": 7775
    },
    {
      "epoch": 0.6042897109107864,
      "grad_norm": 0.47415053844451904,
      "learning_rate": 6.978551445446068e-06,
      "loss": 0.2101,
      "step": 7776
    },
    {
      "epoch": 0.6043674230649674,
      "grad_norm": 0.19142384827136993,
      "learning_rate": 6.978162884675164e-06,
      "loss": 0.051,
      "step": 7777
    },
    {
      "epoch": 0.6044451352191482,
      "grad_norm": 0.4310964345932007,
      "learning_rate": 6.97777432390426e-06,
      "loss": 0.2017,
      "step": 7778
    },
    {
      "epoch": 0.6045228473733292,
      "grad_norm": 0.16579581797122955,
      "learning_rate": 6.977385763133354e-06,
      "loss": 0.0527,
      "step": 7779
    },
    {
      "epoch": 0.6046005595275101,
      "grad_norm": 0.08191376179456711,
      "learning_rate": 6.97699720236245e-06,
      "loss": 0.0181,
      "step": 7780
    },
    {
      "epoch": 0.604678271681691,
      "grad_norm": 0.1953570544719696,
      "learning_rate": 6.9766086415915455e-06,
      "loss": 0.0957,
      "step": 7781
    },
    {
      "epoch": 0.6047559838358719,
      "grad_norm": 0.32536977529525757,
      "learning_rate": 6.9762200808206405e-06,
      "loss": 0.0797,
      "step": 7782
    },
    {
      "epoch": 0.6048336959900529,
      "grad_norm": 0.5193600058555603,
      "learning_rate": 6.975831520049736e-06,
      "loss": 0.4799,
      "step": 7783
    },
    {
      "epoch": 0.6049114081442337,
      "grad_norm": 0.4037782847881317,
      "learning_rate": 6.975442959278832e-06,
      "loss": 0.2671,
      "step": 7784
    },
    {
      "epoch": 0.6049891202984147,
      "grad_norm": 0.3198879659175873,
      "learning_rate": 6.975054398507928e-06,
      "loss": 0.1031,
      "step": 7785
    },
    {
      "epoch": 0.6050668324525956,
      "grad_norm": 0.4149854779243469,
      "learning_rate": 6.974665837737023e-06,
      "loss": 0.2249,
      "step": 7786
    },
    {
      "epoch": 0.6051445446067765,
      "grad_norm": 0.6339626908302307,
      "learning_rate": 6.974277276966119e-06,
      "loss": 0.3363,
      "step": 7787
    },
    {
      "epoch": 0.6052222567609574,
      "grad_norm": 0.22426389157772064,
      "learning_rate": 6.973888716195214e-06,
      "loss": 0.1255,
      "step": 7788
    },
    {
      "epoch": 0.6052999689151384,
      "grad_norm": 0.15503355860710144,
      "learning_rate": 6.9735001554243085e-06,
      "loss": 0.0623,
      "step": 7789
    },
    {
      "epoch": 0.6053776810693192,
      "grad_norm": 0.3892005681991577,
      "learning_rate": 6.973111594653404e-06,
      "loss": 0.2883,
      "step": 7790
    },
    {
      "epoch": 0.6054553932235002,
      "grad_norm": 0.5324338674545288,
      "learning_rate": 6.9727230338825e-06,
      "loss": 0.2004,
      "step": 7791
    },
    {
      "epoch": 0.6055331053776811,
      "grad_norm": 0.30981484055519104,
      "learning_rate": 6.972334473111595e-06,
      "loss": 0.0273,
      "step": 7792
    },
    {
      "epoch": 0.605610817531862,
      "grad_norm": 0.3172522783279419,
      "learning_rate": 6.971945912340691e-06,
      "loss": 0.1319,
      "step": 7793
    },
    {
      "epoch": 0.6056885296860429,
      "grad_norm": 0.2300805300474167,
      "learning_rate": 6.971557351569787e-06,
      "loss": 0.0695,
      "step": 7794
    },
    {
      "epoch": 0.6057662418402238,
      "grad_norm": 0.45863163471221924,
      "learning_rate": 6.971168790798882e-06,
      "loss": 0.3333,
      "step": 7795
    },
    {
      "epoch": 0.6058439539944047,
      "grad_norm": 0.214852973818779,
      "learning_rate": 6.970780230027977e-06,
      "loss": 0.0783,
      "step": 7796
    },
    {
      "epoch": 0.6059216661485857,
      "grad_norm": 0.5167219042778015,
      "learning_rate": 6.970391669257073e-06,
      "loss": 0.1886,
      "step": 7797
    },
    {
      "epoch": 0.6059993783027665,
      "grad_norm": 0.33822596073150635,
      "learning_rate": 6.970003108486167e-06,
      "loss": 0.1676,
      "step": 7798
    },
    {
      "epoch": 0.6060770904569475,
      "grad_norm": 0.41156595945358276,
      "learning_rate": 6.969614547715263e-06,
      "loss": 0.2627,
      "step": 7799
    },
    {
      "epoch": 0.6061548026111284,
      "grad_norm": 0.5715368986129761,
      "learning_rate": 6.969225986944359e-06,
      "loss": 0.6267,
      "step": 7800
    },
    {
      "epoch": 0.6062325147653093,
      "grad_norm": 0.5177537798881531,
      "learning_rate": 6.968837426173454e-06,
      "loss": 0.6069,
      "step": 7801
    },
    {
      "epoch": 0.6063102269194902,
      "grad_norm": 0.5248385071754456,
      "learning_rate": 6.96844886540255e-06,
      "loss": 0.149,
      "step": 7802
    },
    {
      "epoch": 0.6063879390736712,
      "grad_norm": 0.19251157343387604,
      "learning_rate": 6.9680603046316454e-06,
      "loss": 0.0463,
      "step": 7803
    },
    {
      "epoch": 0.606465651227852,
      "grad_norm": 1.2488404512405396,
      "learning_rate": 6.96767174386074e-06,
      "loss": 0.2129,
      "step": 7804
    },
    {
      "epoch": 0.606543363382033,
      "grad_norm": 0.42837759852409363,
      "learning_rate": 6.967283183089836e-06,
      "loss": 0.145,
      "step": 7805
    },
    {
      "epoch": 0.6066210755362139,
      "grad_norm": 0.9563665390014648,
      "learning_rate": 6.966894622318932e-06,
      "loss": 0.2446,
      "step": 7806
    },
    {
      "epoch": 0.6066987876903948,
      "grad_norm": 0.2297266274690628,
      "learning_rate": 6.966506061548026e-06,
      "loss": 0.0897,
      "step": 7807
    },
    {
      "epoch": 0.6067764998445757,
      "grad_norm": 0.320640504360199,
      "learning_rate": 6.966117500777122e-06,
      "loss": 0.1359,
      "step": 7808
    },
    {
      "epoch": 0.6068542119987566,
      "grad_norm": 0.4797309339046478,
      "learning_rate": 6.965728940006218e-06,
      "loss": 0.1954,
      "step": 7809
    },
    {
      "epoch": 0.6069319241529375,
      "grad_norm": 0.40772268176078796,
      "learning_rate": 6.965340379235313e-06,
      "loss": 0.2634,
      "step": 7810
    },
    {
      "epoch": 0.6070096363071185,
      "grad_norm": 0.7637167572975159,
      "learning_rate": 6.964951818464408e-06,
      "loss": 0.52,
      "step": 7811
    },
    {
      "epoch": 0.6070873484612993,
      "grad_norm": 0.6020265221595764,
      "learning_rate": 6.964563257693504e-06,
      "loss": 0.2642,
      "step": 7812
    },
    {
      "epoch": 0.6071650606154803,
      "grad_norm": 0.7511947751045227,
      "learning_rate": 6.964174696922598e-06,
      "loss": 0.5488,
      "step": 7813
    },
    {
      "epoch": 0.6072427727696612,
      "grad_norm": 0.6925600171089172,
      "learning_rate": 6.963786136151694e-06,
      "loss": 0.2233,
      "step": 7814
    },
    {
      "epoch": 0.607320484923842,
      "grad_norm": 0.7432065606117249,
      "learning_rate": 6.96339757538079e-06,
      "loss": 0.7226,
      "step": 7815
    },
    {
      "epoch": 0.607398197078023,
      "grad_norm": 0.34666210412979126,
      "learning_rate": 6.963009014609886e-06,
      "loss": 0.1153,
      "step": 7816
    },
    {
      "epoch": 0.607475909232204,
      "grad_norm": 0.23604193329811096,
      "learning_rate": 6.962620453838981e-06,
      "loss": 0.1462,
      "step": 7817
    },
    {
      "epoch": 0.6075536213863848,
      "grad_norm": 0.38960379362106323,
      "learning_rate": 6.9622318930680764e-06,
      "loss": 0.1181,
      "step": 7818
    },
    {
      "epoch": 0.6076313335405658,
      "grad_norm": 0.3843914866447449,
      "learning_rate": 6.961843332297172e-06,
      "loss": 0.2366,
      "step": 7819
    },
    {
      "epoch": 0.6077090456947467,
      "grad_norm": 0.287232905626297,
      "learning_rate": 6.961454771526267e-06,
      "loss": 0.1065,
      "step": 7820
    },
    {
      "epoch": 0.6077867578489276,
      "grad_norm": 0.5204861760139465,
      "learning_rate": 6.961066210755363e-06,
      "loss": 0.1714,
      "step": 7821
    },
    {
      "epoch": 0.6078644700031085,
      "grad_norm": 0.5459835529327393,
      "learning_rate": 6.960677649984459e-06,
      "loss": 0.1501,
      "step": 7822
    },
    {
      "epoch": 0.6079421821572893,
      "grad_norm": 0.06646710634231567,
      "learning_rate": 6.960289089213553e-06,
      "loss": 0.037,
      "step": 7823
    },
    {
      "epoch": 0.6080198943114703,
      "grad_norm": 0.2218462973833084,
      "learning_rate": 6.959900528442649e-06,
      "loss": 0.1131,
      "step": 7824
    },
    {
      "epoch": 0.6080976064656513,
      "grad_norm": 0.23222406208515167,
      "learning_rate": 6.9595119676717445e-06,
      "loss": 0.1084,
      "step": 7825
    },
    {
      "epoch": 0.6081753186198321,
      "grad_norm": 0.44043704867362976,
      "learning_rate": 6.9591234069008394e-06,
      "loss": 0.2935,
      "step": 7826
    },
    {
      "epoch": 0.608253030774013,
      "grad_norm": 0.611029863357544,
      "learning_rate": 6.958734846129935e-06,
      "loss": 0.3495,
      "step": 7827
    },
    {
      "epoch": 0.608330742928194,
      "grad_norm": 1.2472286224365234,
      "learning_rate": 6.958346285359031e-06,
      "loss": 2.4318,
      "step": 7828
    },
    {
      "epoch": 0.6084084550823748,
      "grad_norm": 0.8841066360473633,
      "learning_rate": 6.957957724588126e-06,
      "loss": 0.1888,
      "step": 7829
    },
    {
      "epoch": 0.6084861672365558,
      "grad_norm": 0.14535890519618988,
      "learning_rate": 6.957569163817222e-06,
      "loss": 0.0672,
      "step": 7830
    },
    {
      "epoch": 0.6085638793907368,
      "grad_norm": 0.4831940829753876,
      "learning_rate": 6.9571806030463176e-06,
      "loss": 0.0994,
      "step": 7831
    },
    {
      "epoch": 0.6086415915449176,
      "grad_norm": 0.5517588257789612,
      "learning_rate": 6.956792042275412e-06,
      "loss": 0.4875,
      "step": 7832
    },
    {
      "epoch": 0.6087193036990985,
      "grad_norm": 0.6546921730041504,
      "learning_rate": 6.9564034815045075e-06,
      "loss": 0.3553,
      "step": 7833
    },
    {
      "epoch": 0.6087970158532795,
      "grad_norm": 0.7584652304649353,
      "learning_rate": 6.956014920733603e-06,
      "loss": 0.5286,
      "step": 7834
    },
    {
      "epoch": 0.6088747280074603,
      "grad_norm": 0.3481883704662323,
      "learning_rate": 6.955626359962698e-06,
      "loss": 0.0547,
      "step": 7835
    },
    {
      "epoch": 0.6089524401616413,
      "grad_norm": 0.3412189483642578,
      "learning_rate": 6.955237799191794e-06,
      "loss": 0.1468,
      "step": 7836
    },
    {
      "epoch": 0.6090301523158222,
      "grad_norm": 0.1347750574350357,
      "learning_rate": 6.95484923842089e-06,
      "loss": 0.0422,
      "step": 7837
    },
    {
      "epoch": 0.6091078644700031,
      "grad_norm": 0.1761961579322815,
      "learning_rate": 6.954460677649985e-06,
      "loss": 0.0301,
      "step": 7838
    },
    {
      "epoch": 0.609185576624184,
      "grad_norm": 0.6697134375572205,
      "learning_rate": 6.9540721168790806e-06,
      "loss": 0.363,
      "step": 7839
    },
    {
      "epoch": 0.6092632887783649,
      "grad_norm": 0.4034324586391449,
      "learning_rate": 6.953683556108176e-06,
      "loss": 0.2378,
      "step": 7840
    },
    {
      "epoch": 0.6093410009325458,
      "grad_norm": 0.7953391671180725,
      "learning_rate": 6.9532949953372705e-06,
      "loss": 0.1266,
      "step": 7841
    },
    {
      "epoch": 0.6094187130867268,
      "grad_norm": 0.6324636340141296,
      "learning_rate": 6.952906434566366e-06,
      "loss": 0.2296,
      "step": 7842
    },
    {
      "epoch": 0.6094964252409076,
      "grad_norm": 0.3276963531970978,
      "learning_rate": 6.952517873795462e-06,
      "loss": 0.3371,
      "step": 7843
    },
    {
      "epoch": 0.6095741373950886,
      "grad_norm": 0.041987836360931396,
      "learning_rate": 6.952129313024557e-06,
      "loss": 0.0056,
      "step": 7844
    },
    {
      "epoch": 0.6096518495492695,
      "grad_norm": 0.29320573806762695,
      "learning_rate": 6.951740752253653e-06,
      "loss": 0.0748,
      "step": 7845
    },
    {
      "epoch": 0.6097295617034504,
      "grad_norm": 0.15129336714744568,
      "learning_rate": 6.951352191482749e-06,
      "loss": 0.0908,
      "step": 7846
    },
    {
      "epoch": 0.6098072738576313,
      "grad_norm": 1.1202160120010376,
      "learning_rate": 6.950963630711844e-06,
      "loss": 0.2878,
      "step": 7847
    },
    {
      "epoch": 0.6098849860118123,
      "grad_norm": 0.17020058631896973,
      "learning_rate": 6.950575069940939e-06,
      "loss": 0.0152,
      "step": 7848
    },
    {
      "epoch": 0.6099626981659931,
      "grad_norm": 0.25759071111679077,
      "learning_rate": 6.950186509170035e-06,
      "loss": 0.1638,
      "step": 7849
    },
    {
      "epoch": 0.6100404103201741,
      "grad_norm": 0.257712185382843,
      "learning_rate": 6.949797948399131e-06,
      "loss": 0.1935,
      "step": 7850
    },
    {
      "epoch": 0.610118122474355,
      "grad_norm": 0.08103590458631516,
      "learning_rate": 6.949409387628225e-06,
      "loss": 0.0282,
      "step": 7851
    },
    {
      "epoch": 0.6101958346285359,
      "grad_norm": 0.7415699362754822,
      "learning_rate": 6.949020826857321e-06,
      "loss": 0.3618,
      "step": 7852
    },
    {
      "epoch": 0.6102735467827168,
      "grad_norm": 0.32734158635139465,
      "learning_rate": 6.948632266086417e-06,
      "loss": 0.1883,
      "step": 7853
    },
    {
      "epoch": 0.6103512589368977,
      "grad_norm": 0.31014758348464966,
      "learning_rate": 6.948243705315512e-06,
      "loss": 0.2548,
      "step": 7854
    },
    {
      "epoch": 0.6104289710910786,
      "grad_norm": 0.5371838212013245,
      "learning_rate": 6.947855144544607e-06,
      "loss": 0.8103,
      "step": 7855
    },
    {
      "epoch": 0.6105066832452596,
      "grad_norm": 0.34698981046676636,
      "learning_rate": 6.947466583773703e-06,
      "loss": 0.1462,
      "step": 7856
    },
    {
      "epoch": 0.6105843953994404,
      "grad_norm": 0.3510916531085968,
      "learning_rate": 6.947078023002798e-06,
      "loss": 0.1055,
      "step": 7857
    },
    {
      "epoch": 0.6106621075536214,
      "grad_norm": 0.5699587464332581,
      "learning_rate": 6.946689462231894e-06,
      "loss": 0.3087,
      "step": 7858
    },
    {
      "epoch": 0.6107398197078023,
      "grad_norm": 0.2758176028728485,
      "learning_rate": 6.94630090146099e-06,
      "loss": 0.1089,
      "step": 7859
    },
    {
      "epoch": 0.6108175318619832,
      "grad_norm": 0.7070013284683228,
      "learning_rate": 6.945912340690084e-06,
      "loss": 0.4419,
      "step": 7860
    },
    {
      "epoch": 0.6108952440161641,
      "grad_norm": 0.22331447899341583,
      "learning_rate": 6.94552377991918e-06,
      "loss": 0.0626,
      "step": 7861
    },
    {
      "epoch": 0.6109729561703451,
      "grad_norm": 0.12640883028507233,
      "learning_rate": 6.945135219148275e-06,
      "loss": 0.0264,
      "step": 7862
    },
    {
      "epoch": 0.6110506683245259,
      "grad_norm": 0.29756075143814087,
      "learning_rate": 6.94474665837737e-06,
      "loss": 0.0757,
      "step": 7863
    },
    {
      "epoch": 0.6111283804787069,
      "grad_norm": 0.3645961880683899,
      "learning_rate": 6.944358097606466e-06,
      "loss": 0.1112,
      "step": 7864
    },
    {
      "epoch": 0.6112060926328878,
      "grad_norm": 1.3868452310562134,
      "learning_rate": 6.943969536835562e-06,
      "loss": 0.3224,
      "step": 7865
    },
    {
      "epoch": 0.6112838047870687,
      "grad_norm": 0.5504392981529236,
      "learning_rate": 6.943580976064657e-06,
      "loss": 0.3855,
      "step": 7866
    },
    {
      "epoch": 0.6113615169412496,
      "grad_norm": 0.43973127007484436,
      "learning_rate": 6.943192415293753e-06,
      "loss": 0.366,
      "step": 7867
    },
    {
      "epoch": 0.6114392290954305,
      "grad_norm": 0.5335230827331543,
      "learning_rate": 6.9428038545228485e-06,
      "loss": 0.155,
      "step": 7868
    },
    {
      "epoch": 0.6115169412496114,
      "grad_norm": 8.123120307922363,
      "learning_rate": 6.942415293751943e-06,
      "loss": 0.4499,
      "step": 7869
    },
    {
      "epoch": 0.6115946534037924,
      "grad_norm": 0.3722376525402069,
      "learning_rate": 6.942026732981038e-06,
      "loss": 0.2345,
      "step": 7870
    },
    {
      "epoch": 0.6116723655579732,
      "grad_norm": 1.1581196784973145,
      "learning_rate": 6.941638172210134e-06,
      "loss": 0.2876,
      "step": 7871
    },
    {
      "epoch": 0.6117500777121542,
      "grad_norm": 0.5530251860618591,
      "learning_rate": 6.941249611439229e-06,
      "loss": 0.1134,
      "step": 7872
    },
    {
      "epoch": 0.6118277898663351,
      "grad_norm": 0.1824631690979004,
      "learning_rate": 6.940861050668325e-06,
      "loss": 0.1073,
      "step": 7873
    },
    {
      "epoch": 0.611905502020516,
      "grad_norm": 0.5969368815422058,
      "learning_rate": 6.940472489897421e-06,
      "loss": 0.1628,
      "step": 7874
    },
    {
      "epoch": 0.6119832141746969,
      "grad_norm": 0.24995315074920654,
      "learning_rate": 6.940083929126516e-06,
      "loss": 0.0376,
      "step": 7875
    },
    {
      "epoch": 0.6120609263288779,
      "grad_norm": 0.86856609582901,
      "learning_rate": 6.9396953683556115e-06,
      "loss": 0.3455,
      "step": 7876
    },
    {
      "epoch": 0.6121386384830587,
      "grad_norm": 0.17682401835918427,
      "learning_rate": 6.939306807584707e-06,
      "loss": 0.0423,
      "step": 7877
    },
    {
      "epoch": 0.6122163506372397,
      "grad_norm": 0.4700332581996918,
      "learning_rate": 6.938918246813803e-06,
      "loss": 0.248,
      "step": 7878
    },
    {
      "epoch": 0.6122940627914206,
      "grad_norm": 0.3561007082462311,
      "learning_rate": 6.938529686042897e-06,
      "loss": 0.1627,
      "step": 7879
    },
    {
      "epoch": 0.6123717749456015,
      "grad_norm": 0.8195615410804749,
      "learning_rate": 6.938141125271993e-06,
      "loss": 0.2155,
      "step": 7880
    },
    {
      "epoch": 0.6124494870997824,
      "grad_norm": 0.4454798996448517,
      "learning_rate": 6.937752564501089e-06,
      "loss": 0.2374,
      "step": 7881
    },
    {
      "epoch": 0.6125271992539634,
      "grad_norm": 0.810670793056488,
      "learning_rate": 6.937364003730184e-06,
      "loss": 0.4674,
      "step": 7882
    },
    {
      "epoch": 0.6126049114081442,
      "grad_norm": 0.1413133293390274,
      "learning_rate": 6.9369754429592795e-06,
      "loss": 0.0326,
      "step": 7883
    },
    {
      "epoch": 0.6126826235623252,
      "grad_norm": 0.31426021456718445,
      "learning_rate": 6.936586882188375e-06,
      "loss": 0.173,
      "step": 7884
    },
    {
      "epoch": 0.612760335716506,
      "grad_norm": 0.6037274599075317,
      "learning_rate": 6.93619832141747e-06,
      "loss": 0.1366,
      "step": 7885
    },
    {
      "epoch": 0.612838047870687,
      "grad_norm": 0.24182699620723724,
      "learning_rate": 6.935809760646566e-06,
      "loss": 0.0964,
      "step": 7886
    },
    {
      "epoch": 0.6129157600248679,
      "grad_norm": 0.1916741281747818,
      "learning_rate": 6.935421199875662e-06,
      "loss": 0.0376,
      "step": 7887
    },
    {
      "epoch": 0.6129934721790488,
      "grad_norm": 0.5516655445098877,
      "learning_rate": 6.935032639104756e-06,
      "loss": 0.3489,
      "step": 7888
    },
    {
      "epoch": 0.6130711843332297,
      "grad_norm": 0.3175024092197418,
      "learning_rate": 6.934644078333852e-06,
      "loss": 0.1147,
      "step": 7889
    },
    {
      "epoch": 0.6131488964874107,
      "grad_norm": 0.13576768338680267,
      "learning_rate": 6.9342555175629476e-06,
      "loss": 0.0782,
      "step": 7890
    },
    {
      "epoch": 0.6132266086415915,
      "grad_norm": 0.11673329025506973,
      "learning_rate": 6.9338669567920425e-06,
      "loss": 0.0361,
      "step": 7891
    },
    {
      "epoch": 0.6133043207957725,
      "grad_norm": 0.2496037632226944,
      "learning_rate": 6.933478396021138e-06,
      "loss": 0.1007,
      "step": 7892
    },
    {
      "epoch": 0.6133820329499534,
      "grad_norm": 0.1606794148683548,
      "learning_rate": 6.933089835250234e-06,
      "loss": 0.0388,
      "step": 7893
    },
    {
      "epoch": 0.6134597451041343,
      "grad_norm": 0.12805525958538055,
      "learning_rate": 6.932701274479329e-06,
      "loss": 0.0526,
      "step": 7894
    },
    {
      "epoch": 0.6135374572583152,
      "grad_norm": 0.14670388400554657,
      "learning_rate": 6.932312713708425e-06,
      "loss": 0.0392,
      "step": 7895
    },
    {
      "epoch": 0.6136151694124962,
      "grad_norm": 0.29649245738983154,
      "learning_rate": 6.931924152937521e-06,
      "loss": 0.1961,
      "step": 7896
    },
    {
      "epoch": 0.613692881566677,
      "grad_norm": 0.3220747411251068,
      "learning_rate": 6.931535592166615e-06,
      "loss": 0.1433,
      "step": 7897
    },
    {
      "epoch": 0.613770593720858,
      "grad_norm": 0.16727367043495178,
      "learning_rate": 6.9311470313957105e-06,
      "loss": 0.0608,
      "step": 7898
    },
    {
      "epoch": 0.6138483058750388,
      "grad_norm": 0.3350463807582855,
      "learning_rate": 6.930758470624806e-06,
      "loss": 0.4663,
      "step": 7899
    },
    {
      "epoch": 0.6139260180292198,
      "grad_norm": 0.12310479581356049,
      "learning_rate": 6.930369909853901e-06,
      "loss": 0.0584,
      "step": 7900
    },
    {
      "epoch": 0.6140037301834007,
      "grad_norm": 0.3213755786418915,
      "learning_rate": 6.929981349082997e-06,
      "loss": 0.172,
      "step": 7901
    },
    {
      "epoch": 0.6140814423375816,
      "grad_norm": 0.4313497543334961,
      "learning_rate": 6.929592788312093e-06,
      "loss": 0.1609,
      "step": 7902
    },
    {
      "epoch": 0.6141591544917625,
      "grad_norm": 0.24268467724323273,
      "learning_rate": 6.929204227541188e-06,
      "loss": 0.0356,
      "step": 7903
    },
    {
      "epoch": 0.6142368666459435,
      "grad_norm": 0.5005010962486267,
      "learning_rate": 6.928815666770284e-06,
      "loss": 0.2334,
      "step": 7904
    },
    {
      "epoch": 0.6143145788001243,
      "grad_norm": 0.1276828646659851,
      "learning_rate": 6.9284271059993794e-06,
      "loss": 0.0577,
      "step": 7905
    },
    {
      "epoch": 0.6143922909543053,
      "grad_norm": 0.8227999210357666,
      "learning_rate": 6.928038545228475e-06,
      "loss": 0.2069,
      "step": 7906
    },
    {
      "epoch": 0.6144700031084862,
      "grad_norm": 0.034207750111818314,
      "learning_rate": 6.927649984457569e-06,
      "loss": 0.0049,
      "step": 7907
    },
    {
      "epoch": 0.614547715262667,
      "grad_norm": 0.6951204538345337,
      "learning_rate": 6.927261423686665e-06,
      "loss": 0.3751,
      "step": 7908
    },
    {
      "epoch": 0.614625427416848,
      "grad_norm": 0.32423827052116394,
      "learning_rate": 6.926872862915761e-06,
      "loss": 0.2304,
      "step": 7909
    },
    {
      "epoch": 0.614703139571029,
      "grad_norm": 0.5138026475906372,
      "learning_rate": 6.926484302144856e-06,
      "loss": 0.3906,
      "step": 7910
    },
    {
      "epoch": 0.6147808517252098,
      "grad_norm": 0.4864175021648407,
      "learning_rate": 6.926095741373952e-06,
      "loss": 0.2729,
      "step": 7911
    },
    {
      "epoch": 0.6148585638793908,
      "grad_norm": 0.2315300703048706,
      "learning_rate": 6.9257071806030475e-06,
      "loss": 0.1082,
      "step": 7912
    },
    {
      "epoch": 0.6149362760335717,
      "grad_norm": 0.47781243920326233,
      "learning_rate": 6.925318619832142e-06,
      "loss": 0.1569,
      "step": 7913
    },
    {
      "epoch": 0.6150139881877525,
      "grad_norm": 0.10895030200481415,
      "learning_rate": 6.924930059061238e-06,
      "loss": 0.0385,
      "step": 7914
    },
    {
      "epoch": 0.6150917003419335,
      "grad_norm": 0.19734777510166168,
      "learning_rate": 6.924541498290334e-06,
      "loss": 0.024,
      "step": 7915
    },
    {
      "epoch": 0.6151694124961143,
      "grad_norm": 0.5865945816040039,
      "learning_rate": 6.924152937519428e-06,
      "loss": 0.1535,
      "step": 7916
    },
    {
      "epoch": 0.6152471246502953,
      "grad_norm": 0.08029845356941223,
      "learning_rate": 6.923764376748524e-06,
      "loss": 0.034,
      "step": 7917
    },
    {
      "epoch": 0.6153248368044762,
      "grad_norm": 0.4594275653362274,
      "learning_rate": 6.92337581597762e-06,
      "loss": 0.1168,
      "step": 7918
    },
    {
      "epoch": 0.6154025489586571,
      "grad_norm": 0.32274895906448364,
      "learning_rate": 6.922987255206715e-06,
      "loss": 0.1333,
      "step": 7919
    },
    {
      "epoch": 0.615480261112838,
      "grad_norm": 0.18760892748832703,
      "learning_rate": 6.9225986944358105e-06,
      "loss": 0.0478,
      "step": 7920
    },
    {
      "epoch": 0.615557973267019,
      "grad_norm": 0.15737329423427582,
      "learning_rate": 6.922210133664906e-06,
      "loss": 0.052,
      "step": 7921
    },
    {
      "epoch": 0.6156356854211998,
      "grad_norm": 0.7734670042991638,
      "learning_rate": 6.921821572894001e-06,
      "loss": 0.5335,
      "step": 7922
    },
    {
      "epoch": 0.6157133975753808,
      "grad_norm": 0.285022109746933,
      "learning_rate": 6.921433012123097e-06,
      "loss": 0.1474,
      "step": 7923
    },
    {
      "epoch": 0.6157911097295617,
      "grad_norm": 0.8818963170051575,
      "learning_rate": 6.921044451352193e-06,
      "loss": 0.2854,
      "step": 7924
    },
    {
      "epoch": 0.6158688218837426,
      "grad_norm": 0.40416985750198364,
      "learning_rate": 6.920655890581287e-06,
      "loss": 0.3245,
      "step": 7925
    },
    {
      "epoch": 0.6159465340379235,
      "grad_norm": 0.30636778473854065,
      "learning_rate": 6.920267329810383e-06,
      "loss": 0.213,
      "step": 7926
    },
    {
      "epoch": 0.6160242461921045,
      "grad_norm": 0.22073012590408325,
      "learning_rate": 6.9198787690394785e-06,
      "loss": 0.1601,
      "step": 7927
    },
    {
      "epoch": 0.6161019583462853,
      "grad_norm": 0.6107240915298462,
      "learning_rate": 6.9194902082685734e-06,
      "loss": 0.4709,
      "step": 7928
    },
    {
      "epoch": 0.6161796705004663,
      "grad_norm": 0.30205661058425903,
      "learning_rate": 6.919101647497669e-06,
      "loss": 0.1586,
      "step": 7929
    },
    {
      "epoch": 0.6162573826546471,
      "grad_norm": 0.7004977464675903,
      "learning_rate": 6.918713086726765e-06,
      "loss": 0.4575,
      "step": 7930
    },
    {
      "epoch": 0.6163350948088281,
      "grad_norm": 0.4167695939540863,
      "learning_rate": 6.91832452595586e-06,
      "loss": 0.191,
      "step": 7931
    },
    {
      "epoch": 0.616412806963009,
      "grad_norm": 0.09575111418962479,
      "learning_rate": 6.917935965184956e-06,
      "loss": 0.0279,
      "step": 7932
    },
    {
      "epoch": 0.6164905191171899,
      "grad_norm": 0.28913792967796326,
      "learning_rate": 6.917547404414051e-06,
      "loss": 0.0567,
      "step": 7933
    },
    {
      "epoch": 0.6165682312713708,
      "grad_norm": 0.382743775844574,
      "learning_rate": 6.917158843643146e-06,
      "loss": 0.2522,
      "step": 7934
    },
    {
      "epoch": 0.6166459434255518,
      "grad_norm": 0.30872952938079834,
      "learning_rate": 6.9167702828722415e-06,
      "loss": 0.1182,
      "step": 7935
    },
    {
      "epoch": 0.6167236555797326,
      "grad_norm": 0.5275007486343384,
      "learning_rate": 6.916381722101337e-06,
      "loss": 0.0877,
      "step": 7936
    },
    {
      "epoch": 0.6168013677339136,
      "grad_norm": 0.3596054017543793,
      "learning_rate": 6.915993161330433e-06,
      "loss": 0.1296,
      "step": 7937
    },
    {
      "epoch": 0.6168790798880945,
      "grad_norm": 0.39132243394851685,
      "learning_rate": 6.915604600559528e-06,
      "loss": 0.0781,
      "step": 7938
    },
    {
      "epoch": 0.6169567920422754,
      "grad_norm": 0.7458985447883606,
      "learning_rate": 6.915216039788624e-06,
      "loss": 0.7392,
      "step": 7939
    },
    {
      "epoch": 0.6170345041964563,
      "grad_norm": 0.373676061630249,
      "learning_rate": 6.91482747901772e-06,
      "loss": 0.2405,
      "step": 7940
    },
    {
      "epoch": 0.6171122163506373,
      "grad_norm": 0.2606737017631531,
      "learning_rate": 6.914438918246814e-06,
      "loss": 0.0625,
      "step": 7941
    },
    {
      "epoch": 0.6171899285048181,
      "grad_norm": 0.5156263113021851,
      "learning_rate": 6.9140503574759095e-06,
      "loss": 0.4471,
      "step": 7942
    },
    {
      "epoch": 0.6172676406589991,
      "grad_norm": 0.36624622344970703,
      "learning_rate": 6.913661796705005e-06,
      "loss": 0.1466,
      "step": 7943
    },
    {
      "epoch": 0.6173453528131799,
      "grad_norm": 0.2878422737121582,
      "learning_rate": 6.9132732359341e-06,
      "loss": 0.1502,
      "step": 7944
    },
    {
      "epoch": 0.6174230649673609,
      "grad_norm": 0.061584845185279846,
      "learning_rate": 6.912884675163196e-06,
      "loss": 0.0571,
      "step": 7945
    },
    {
      "epoch": 0.6175007771215418,
      "grad_norm": 0.4326474964618683,
      "learning_rate": 6.912496114392292e-06,
      "loss": 0.1349,
      "step": 7946
    },
    {
      "epoch": 0.6175784892757227,
      "grad_norm": 0.7718772888183594,
      "learning_rate": 6.912107553621387e-06,
      "loss": 0.4681,
      "step": 7947
    },
    {
      "epoch": 0.6176562014299036,
      "grad_norm": 0.4554677903652191,
      "learning_rate": 6.911718992850483e-06,
      "loss": 0.1904,
      "step": 7948
    },
    {
      "epoch": 0.6177339135840846,
      "grad_norm": 0.5780704617500305,
      "learning_rate": 6.911330432079578e-06,
      "loss": 0.2553,
      "step": 7949
    },
    {
      "epoch": 0.6178116257382654,
      "grad_norm": 0.23248977959156036,
      "learning_rate": 6.9109418713086725e-06,
      "loss": 0.1393,
      "step": 7950
    },
    {
      "epoch": 0.6178893378924464,
      "grad_norm": 1.3379191160202026,
      "learning_rate": 6.910553310537768e-06,
      "loss": 0.708,
      "step": 7951
    },
    {
      "epoch": 0.6179670500466273,
      "grad_norm": 0.8121230602264404,
      "learning_rate": 6.910164749766864e-06,
      "loss": 0.3485,
      "step": 7952
    },
    {
      "epoch": 0.6180447622008082,
      "grad_norm": 0.2048446089029312,
      "learning_rate": 6.909776188995959e-06,
      "loss": 0.2189,
      "step": 7953
    },
    {
      "epoch": 0.6181224743549891,
      "grad_norm": 1.1763592958450317,
      "learning_rate": 6.909387628225055e-06,
      "loss": 0.3672,
      "step": 7954
    },
    {
      "epoch": 0.6182001865091701,
      "grad_norm": 0.21654674410820007,
      "learning_rate": 6.908999067454151e-06,
      "loss": 0.1133,
      "step": 7955
    },
    {
      "epoch": 0.6182778986633509,
      "grad_norm": 0.21264876425266266,
      "learning_rate": 6.908610506683246e-06,
      "loss": 0.1726,
      "step": 7956
    },
    {
      "epoch": 0.6183556108175319,
      "grad_norm": 0.2030874341726303,
      "learning_rate": 6.908221945912341e-06,
      "loss": 0.1486,
      "step": 7957
    },
    {
      "epoch": 0.6184333229717128,
      "grad_norm": 0.6249318718910217,
      "learning_rate": 6.907833385141437e-06,
      "loss": 0.4469,
      "step": 7958
    },
    {
      "epoch": 0.6185110351258937,
      "grad_norm": 0.24117408692836761,
      "learning_rate": 6.907444824370531e-06,
      "loss": 0.061,
      "step": 7959
    },
    {
      "epoch": 0.6185887472800746,
      "grad_norm": 0.2210179567337036,
      "learning_rate": 6.907056263599627e-06,
      "loss": 0.0864,
      "step": 7960
    },
    {
      "epoch": 0.6186664594342555,
      "grad_norm": 0.4529935419559479,
      "learning_rate": 6.906667702828723e-06,
      "loss": 0.1307,
      "step": 7961
    },
    {
      "epoch": 0.6187441715884364,
      "grad_norm": 0.8355799913406372,
      "learning_rate": 6.906279142057818e-06,
      "loss": 0.5165,
      "step": 7962
    },
    {
      "epoch": 0.6188218837426174,
      "grad_norm": 0.2985202372074127,
      "learning_rate": 6.905890581286914e-06,
      "loss": 0.1231,
      "step": 7963
    },
    {
      "epoch": 0.6188995958967982,
      "grad_norm": 1.2084957361221313,
      "learning_rate": 6.905502020516009e-06,
      "loss": 0.4119,
      "step": 7964
    },
    {
      "epoch": 0.6189773080509792,
      "grad_norm": 0.5281904935836792,
      "learning_rate": 6.905113459745104e-06,
      "loss": 0.1958,
      "step": 7965
    },
    {
      "epoch": 0.6190550202051601,
      "grad_norm": 0.3217593729496002,
      "learning_rate": 6.9047248989742e-06,
      "loss": 0.1793,
      "step": 7966
    },
    {
      "epoch": 0.619132732359341,
      "grad_norm": 0.20132657885551453,
      "learning_rate": 6.904336338203296e-06,
      "loss": 0.1281,
      "step": 7967
    },
    {
      "epoch": 0.6192104445135219,
      "grad_norm": 0.6365290284156799,
      "learning_rate": 6.903947777432392e-06,
      "loss": 0.388,
      "step": 7968
    },
    {
      "epoch": 0.6192881566677029,
      "grad_norm": 0.3144417703151703,
      "learning_rate": 6.903559216661486e-06,
      "loss": 0.2743,
      "step": 7969
    },
    {
      "epoch": 0.6193658688218837,
      "grad_norm": 0.5032966136932373,
      "learning_rate": 6.903170655890582e-06,
      "loss": 0.4081,
      "step": 7970
    },
    {
      "epoch": 0.6194435809760647,
      "grad_norm": 0.6695296764373779,
      "learning_rate": 6.9027820951196775e-06,
      "loss": 0.5804,
      "step": 7971
    },
    {
      "epoch": 0.6195212931302456,
      "grad_norm": 0.6602448225021362,
      "learning_rate": 6.902393534348772e-06,
      "loss": 0.4234,
      "step": 7972
    },
    {
      "epoch": 0.6195990052844265,
      "grad_norm": 0.1598089188337326,
      "learning_rate": 6.902004973577868e-06,
      "loss": 0.0401,
      "step": 7973
    },
    {
      "epoch": 0.6196767174386074,
      "grad_norm": 0.4510651230812073,
      "learning_rate": 6.901616412806964e-06,
      "loss": 0.2538,
      "step": 7974
    },
    {
      "epoch": 0.6197544295927883,
      "grad_norm": 0.28777164220809937,
      "learning_rate": 6.901227852036059e-06,
      "loss": 0.0529,
      "step": 7975
    },
    {
      "epoch": 0.6198321417469692,
      "grad_norm": 0.30619847774505615,
      "learning_rate": 6.900839291265155e-06,
      "loss": 0.1307,
      "step": 7976
    },
    {
      "epoch": 0.6199098539011502,
      "grad_norm": 0.1307099461555481,
      "learning_rate": 6.9004507304942505e-06,
      "loss": 0.0158,
      "step": 7977
    },
    {
      "epoch": 0.619987566055331,
      "grad_norm": 0.48893609642982483,
      "learning_rate": 6.900062169723345e-06,
      "loss": 0.3793,
      "step": 7978
    },
    {
      "epoch": 0.620065278209512,
      "grad_norm": 0.3044881224632263,
      "learning_rate": 6.8996736089524404e-06,
      "loss": 0.0951,
      "step": 7979
    },
    {
      "epoch": 0.6201429903636929,
      "grad_norm": 0.29748454689979553,
      "learning_rate": 6.899285048181536e-06,
      "loss": 0.1738,
      "step": 7980
    },
    {
      "epoch": 0.6202207025178738,
      "grad_norm": 0.40991684794425964,
      "learning_rate": 6.898896487410631e-06,
      "loss": 0.2493,
      "step": 7981
    },
    {
      "epoch": 0.6202984146720547,
      "grad_norm": 0.5422543287277222,
      "learning_rate": 6.898507926639727e-06,
      "loss": 0.3843,
      "step": 7982
    },
    {
      "epoch": 0.6203761268262357,
      "grad_norm": 0.464738130569458,
      "learning_rate": 6.898119365868823e-06,
      "loss": 0.1245,
      "step": 7983
    },
    {
      "epoch": 0.6204538389804165,
      "grad_norm": 0.47394129633903503,
      "learning_rate": 6.897730805097918e-06,
      "loss": 0.241,
      "step": 7984
    },
    {
      "epoch": 0.6205315511345975,
      "grad_norm": 0.12219730764627457,
      "learning_rate": 6.8973422443270135e-06,
      "loss": 0.0491,
      "step": 7985
    },
    {
      "epoch": 0.6206092632887784,
      "grad_norm": 0.2854754328727722,
      "learning_rate": 6.896953683556109e-06,
      "loss": 0.1566,
      "step": 7986
    },
    {
      "epoch": 0.6206869754429593,
      "grad_norm": 0.2644743025302887,
      "learning_rate": 6.8965651227852034e-06,
      "loss": 0.0976,
      "step": 7987
    },
    {
      "epoch": 0.6207646875971402,
      "grad_norm": 0.4271593689918518,
      "learning_rate": 6.896176562014299e-06,
      "loss": 0.3679,
      "step": 7988
    },
    {
      "epoch": 0.6208423997513212,
      "grad_norm": 0.3189959228038788,
      "learning_rate": 6.895788001243395e-06,
      "loss": 0.1049,
      "step": 7989
    },
    {
      "epoch": 0.620920111905502,
      "grad_norm": 0.4461856782436371,
      "learning_rate": 6.89539944047249e-06,
      "loss": 0.1254,
      "step": 7990
    },
    {
      "epoch": 0.620997824059683,
      "grad_norm": 0.37198302149772644,
      "learning_rate": 6.895010879701586e-06,
      "loss": 0.561,
      "step": 7991
    },
    {
      "epoch": 0.6210755362138638,
      "grad_norm": 0.4375380873680115,
      "learning_rate": 6.8946223189306816e-06,
      "loss": 0.1023,
      "step": 7992
    },
    {
      "epoch": 0.6211532483680448,
      "grad_norm": 0.042463768273591995,
      "learning_rate": 6.8942337581597765e-06,
      "loss": 0.0056,
      "step": 7993
    },
    {
      "epoch": 0.6212309605222257,
      "grad_norm": 0.33498504757881165,
      "learning_rate": 6.893845197388872e-06,
      "loss": 0.3302,
      "step": 7994
    },
    {
      "epoch": 0.6213086726764065,
      "grad_norm": 0.4870308041572571,
      "learning_rate": 6.893456636617968e-06,
      "loss": 0.2371,
      "step": 7995
    },
    {
      "epoch": 0.6213863848305875,
      "grad_norm": 0.29640746116638184,
      "learning_rate": 6.893068075847062e-06,
      "loss": 0.0741,
      "step": 7996
    },
    {
      "epoch": 0.6214640969847685,
      "grad_norm": 0.3809586465358734,
      "learning_rate": 6.892679515076158e-06,
      "loss": 0.8391,
      "step": 7997
    },
    {
      "epoch": 0.6215418091389493,
      "grad_norm": 0.2826228737831116,
      "learning_rate": 6.892290954305254e-06,
      "loss": 0.1893,
      "step": 7998
    },
    {
      "epoch": 0.6216195212931303,
      "grad_norm": 0.7807154655456543,
      "learning_rate": 6.89190239353435e-06,
      "loss": 0.4473,
      "step": 7999
    },
    {
      "epoch": 0.6216972334473112,
      "grad_norm": 0.21385371685028076,
      "learning_rate": 6.8915138327634446e-06,
      "loss": 0.1297,
      "step": 8000
    },
    {
      "epoch": 0.621774945601492,
      "grad_norm": 0.14453062415122986,
      "learning_rate": 6.89112527199254e-06,
      "loss": 0.0445,
      "step": 8001
    },
    {
      "epoch": 0.621852657755673,
      "grad_norm": 0.1840858906507492,
      "learning_rate": 6.890736711221636e-06,
      "loss": 0.0607,
      "step": 8002
    },
    {
      "epoch": 0.621930369909854,
      "grad_norm": 0.24936528503894806,
      "learning_rate": 6.890348150450731e-06,
      "loss": 0.0941,
      "step": 8003
    },
    {
      "epoch": 0.6220080820640348,
      "grad_norm": 0.17137368023395538,
      "learning_rate": 6.889959589679827e-06,
      "loss": 0.0442,
      "step": 8004
    },
    {
      "epoch": 0.6220857942182157,
      "grad_norm": 0.4063761234283447,
      "learning_rate": 6.889571028908923e-06,
      "loss": 0.0446,
      "step": 8005
    },
    {
      "epoch": 0.6221635063723966,
      "grad_norm": 0.4010109007358551,
      "learning_rate": 6.889182468138017e-06,
      "loss": 0.3603,
      "step": 8006
    },
    {
      "epoch": 0.6222412185265775,
      "grad_norm": 0.47992387413978577,
      "learning_rate": 6.888793907367113e-06,
      "loss": 0.0425,
      "step": 8007
    },
    {
      "epoch": 0.6223189306807585,
      "grad_norm": 0.7440114617347717,
      "learning_rate": 6.888405346596208e-06,
      "loss": 0.157,
      "step": 8008
    },
    {
      "epoch": 0.6223966428349393,
      "grad_norm": 0.3251834213733673,
      "learning_rate": 6.888016785825303e-06,
      "loss": 0.034,
      "step": 8009
    },
    {
      "epoch": 0.6224743549891203,
      "grad_norm": 0.04830978065729141,
      "learning_rate": 6.887628225054399e-06,
      "loss": 0.013,
      "step": 8010
    },
    {
      "epoch": 0.6225520671433012,
      "grad_norm": 0.5313992500305176,
      "learning_rate": 6.887239664283495e-06,
      "loss": 0.1816,
      "step": 8011
    },
    {
      "epoch": 0.6226297792974821,
      "grad_norm": 0.5526052713394165,
      "learning_rate": 6.88685110351259e-06,
      "loss": 0.1854,
      "step": 8012
    },
    {
      "epoch": 0.622707491451663,
      "grad_norm": 0.21865223348140717,
      "learning_rate": 6.886462542741686e-06,
      "loss": 0.2218,
      "step": 8013
    },
    {
      "epoch": 0.622785203605844,
      "grad_norm": 0.18792413175106049,
      "learning_rate": 6.8860739819707815e-06,
      "loss": 0.0665,
      "step": 8014
    },
    {
      "epoch": 0.6228629157600248,
      "grad_norm": 0.2117658257484436,
      "learning_rate": 6.8856854211998756e-06,
      "loss": 0.0304,
      "step": 8015
    },
    {
      "epoch": 0.6229406279142058,
      "grad_norm": 0.22633694112300873,
      "learning_rate": 6.885296860428971e-06,
      "loss": 0.0818,
      "step": 8016
    },
    {
      "epoch": 0.6230183400683867,
      "grad_norm": 0.33624792098999023,
      "learning_rate": 6.884908299658067e-06,
      "loss": 0.0999,
      "step": 8017
    },
    {
      "epoch": 0.6230960522225676,
      "grad_norm": 0.6180820465087891,
      "learning_rate": 6.884519738887162e-06,
      "loss": 0.5329,
      "step": 8018
    },
    {
      "epoch": 0.6231737643767485,
      "grad_norm": 0.47087809443473816,
      "learning_rate": 6.884131178116258e-06,
      "loss": 0.2937,
      "step": 8019
    },
    {
      "epoch": 0.6232514765309294,
      "grad_norm": 0.5407052636146545,
      "learning_rate": 6.883742617345354e-06,
      "loss": 0.1478,
      "step": 8020
    },
    {
      "epoch": 0.6233291886851103,
      "grad_norm": 0.7607986927032471,
      "learning_rate": 6.883354056574449e-06,
      "loss": 0.1324,
      "step": 8021
    },
    {
      "epoch": 0.6234069008392913,
      "grad_norm": 0.6153647899627686,
      "learning_rate": 6.8829654958035445e-06,
      "loss": 0.2386,
      "step": 8022
    },
    {
      "epoch": 0.6234846129934721,
      "grad_norm": 0.2013670802116394,
      "learning_rate": 6.88257693503264e-06,
      "loss": 0.0865,
      "step": 8023
    },
    {
      "epoch": 0.6235623251476531,
      "grad_norm": 0.1158892884850502,
      "learning_rate": 6.882188374261734e-06,
      "loss": 0.0623,
      "step": 8024
    },
    {
      "epoch": 0.623640037301834,
      "grad_norm": 0.48020631074905396,
      "learning_rate": 6.88179981349083e-06,
      "loss": 0.1814,
      "step": 8025
    },
    {
      "epoch": 0.6237177494560149,
      "grad_norm": 0.18415489792823792,
      "learning_rate": 6.881411252719926e-06,
      "loss": 0.0762,
      "step": 8026
    },
    {
      "epoch": 0.6237954616101958,
      "grad_norm": 0.4951516389846802,
      "learning_rate": 6.881022691949021e-06,
      "loss": 0.0528,
      "step": 8027
    },
    {
      "epoch": 0.6238731737643768,
      "grad_norm": 0.6727681159973145,
      "learning_rate": 6.880634131178117e-06,
      "loss": 0.3841,
      "step": 8028
    },
    {
      "epoch": 0.6239508859185576,
      "grad_norm": 0.44673478603363037,
      "learning_rate": 6.8802455704072125e-06,
      "loss": 0.0863,
      "step": 8029
    },
    {
      "epoch": 0.6240285980727386,
      "grad_norm": 0.9406100511550903,
      "learning_rate": 6.879857009636308e-06,
      "loss": 0.181,
      "step": 8030
    },
    {
      "epoch": 0.6241063102269195,
      "grad_norm": 0.6931767463684082,
      "learning_rate": 6.879468448865403e-06,
      "loss": 0.3373,
      "step": 8031
    },
    {
      "epoch": 0.6241840223811004,
      "grad_norm": 0.15982364118099213,
      "learning_rate": 6.879079888094499e-06,
      "loss": 0.088,
      "step": 8032
    },
    {
      "epoch": 0.6242617345352813,
      "grad_norm": 0.31050118803977966,
      "learning_rate": 6.878691327323595e-06,
      "loss": 0.2132,
      "step": 8033
    },
    {
      "epoch": 0.6243394466894623,
      "grad_norm": 0.5624769926071167,
      "learning_rate": 6.878302766552689e-06,
      "loss": 0.1857,
      "step": 8034
    },
    {
      "epoch": 0.6244171588436431,
      "grad_norm": 0.4179261326789856,
      "learning_rate": 6.877914205781785e-06,
      "loss": 0.1257,
      "step": 8035
    },
    {
      "epoch": 0.6244948709978241,
      "grad_norm": 0.08825574070215225,
      "learning_rate": 6.8775256450108805e-06,
      "loss": 0.0248,
      "step": 8036
    },
    {
      "epoch": 0.6245725831520049,
      "grad_norm": 0.13734029233455658,
      "learning_rate": 6.8771370842399755e-06,
      "loss": 0.0356,
      "step": 8037
    },
    {
      "epoch": 0.6246502953061859,
      "grad_norm": 0.246944859623909,
      "learning_rate": 6.876748523469071e-06,
      "loss": 0.085,
      "step": 8038
    },
    {
      "epoch": 0.6247280074603668,
      "grad_norm": 0.13167130947113037,
      "learning_rate": 6.876359962698167e-06,
      "loss": 0.0195,
      "step": 8039
    },
    {
      "epoch": 0.6248057196145477,
      "grad_norm": 0.90585857629776,
      "learning_rate": 6.875971401927262e-06,
      "loss": 0.2141,
      "step": 8040
    },
    {
      "epoch": 0.6248834317687286,
      "grad_norm": 0.5007878541946411,
      "learning_rate": 6.875582841156358e-06,
      "loss": 0.1232,
      "step": 8041
    },
    {
      "epoch": 0.6249611439229096,
      "grad_norm": 1.0901707410812378,
      "learning_rate": 6.875194280385454e-06,
      "loss": 0.46,
      "step": 8042
    },
    {
      "epoch": 0.6250388560770904,
      "grad_norm": 0.24656443297863007,
      "learning_rate": 6.874805719614548e-06,
      "loss": 0.1443,
      "step": 8043
    },
    {
      "epoch": 0.6251165682312714,
      "grad_norm": 0.15308751165866852,
      "learning_rate": 6.8744171588436435e-06,
      "loss": 0.0423,
      "step": 8044
    },
    {
      "epoch": 0.6251942803854523,
      "grad_norm": 0.5284943580627441,
      "learning_rate": 6.874028598072739e-06,
      "loss": 0.2734,
      "step": 8045
    },
    {
      "epoch": 0.6252719925396332,
      "grad_norm": 0.18349263072013855,
      "learning_rate": 6.873640037301834e-06,
      "loss": 0.0188,
      "step": 8046
    },
    {
      "epoch": 0.6253497046938141,
      "grad_norm": 0.47173407673835754,
      "learning_rate": 6.87325147653093e-06,
      "loss": 0.481,
      "step": 8047
    },
    {
      "epoch": 0.6254274168479951,
      "grad_norm": 0.20272956788539886,
      "learning_rate": 6.872862915760026e-06,
      "loss": 0.0648,
      "step": 8048
    },
    {
      "epoch": 0.6255051290021759,
      "grad_norm": 0.24363861978054047,
      "learning_rate": 6.872474354989121e-06,
      "loss": 0.1127,
      "step": 8049
    },
    {
      "epoch": 0.6255828411563569,
      "grad_norm": 0.4355124533176422,
      "learning_rate": 6.872085794218217e-06,
      "loss": 0.1324,
      "step": 8050
    },
    {
      "epoch": 0.6256605533105377,
      "grad_norm": 0.40379250049591064,
      "learning_rate": 6.871697233447312e-06,
      "loss": 0.1847,
      "step": 8051
    },
    {
      "epoch": 0.6257382654647187,
      "grad_norm": 0.39290332794189453,
      "learning_rate": 6.8713086726764065e-06,
      "loss": 0.132,
      "step": 8052
    },
    {
      "epoch": 0.6258159776188996,
      "grad_norm": 0.45446687936782837,
      "learning_rate": 6.870920111905502e-06,
      "loss": 0.1786,
      "step": 8053
    },
    {
      "epoch": 0.6258936897730805,
      "grad_norm": 0.39586225152015686,
      "learning_rate": 6.870531551134598e-06,
      "loss": 0.1488,
      "step": 8054
    },
    {
      "epoch": 0.6259714019272614,
      "grad_norm": 0.1692977249622345,
      "learning_rate": 6.870142990363693e-06,
      "loss": 0.0894,
      "step": 8055
    },
    {
      "epoch": 0.6260491140814424,
      "grad_norm": 0.3350664973258972,
      "learning_rate": 6.869754429592789e-06,
      "loss": 0.1504,
      "step": 8056
    },
    {
      "epoch": 0.6261268262356232,
      "grad_norm": 0.5477752089500427,
      "learning_rate": 6.869365868821885e-06,
      "loss": 0.2565,
      "step": 8057
    },
    {
      "epoch": 0.6262045383898042,
      "grad_norm": 0.43976259231567383,
      "learning_rate": 6.8689773080509804e-06,
      "loss": 0.0635,
      "step": 8058
    },
    {
      "epoch": 0.6262822505439851,
      "grad_norm": 1.5741881132125854,
      "learning_rate": 6.868588747280075e-06,
      "loss": 0.3279,
      "step": 8059
    },
    {
      "epoch": 0.626359962698166,
      "grad_norm": 0.1370549350976944,
      "learning_rate": 6.86820018650917e-06,
      "loss": 0.0349,
      "step": 8060
    },
    {
      "epoch": 0.6264376748523469,
      "grad_norm": 0.42441868782043457,
      "learning_rate": 6.867811625738266e-06,
      "loss": 0.3481,
      "step": 8061
    },
    {
      "epoch": 0.6265153870065279,
      "grad_norm": 0.5459789037704468,
      "learning_rate": 6.867423064967361e-06,
      "loss": 0.1847,
      "step": 8062
    },
    {
      "epoch": 0.6265930991607087,
      "grad_norm": 0.38346949219703674,
      "learning_rate": 6.867034504196457e-06,
      "loss": 0.4541,
      "step": 8063
    },
    {
      "epoch": 0.6266708113148897,
      "grad_norm": 0.2866988480091095,
      "learning_rate": 6.866645943425553e-06,
      "loss": 0.1445,
      "step": 8064
    },
    {
      "epoch": 0.6267485234690706,
      "grad_norm": 0.29925277829170227,
      "learning_rate": 6.866257382654648e-06,
      "loss": 0.0995,
      "step": 8065
    },
    {
      "epoch": 0.6268262356232515,
      "grad_norm": 0.1076042652130127,
      "learning_rate": 6.865868821883743e-06,
      "loss": 0.0402,
      "step": 8066
    },
    {
      "epoch": 0.6269039477774324,
      "grad_norm": 0.22351562976837158,
      "learning_rate": 6.865480261112839e-06,
      "loss": 0.0905,
      "step": 8067
    },
    {
      "epoch": 0.6269816599316133,
      "grad_norm": 0.5502939820289612,
      "learning_rate": 6.865091700341933e-06,
      "loss": 0.0811,
      "step": 8068
    },
    {
      "epoch": 0.6270593720857942,
      "grad_norm": 0.16940586268901825,
      "learning_rate": 6.864703139571029e-06,
      "loss": 0.0481,
      "step": 8069
    },
    {
      "epoch": 0.6271370842399752,
      "grad_norm": 0.09717705845832825,
      "learning_rate": 6.864314578800125e-06,
      "loss": 0.0197,
      "step": 8070
    },
    {
      "epoch": 0.627214796394156,
      "grad_norm": 0.4852049648761749,
      "learning_rate": 6.86392601802922e-06,
      "loss": 0.6062,
      "step": 8071
    },
    {
      "epoch": 0.627292508548337,
      "grad_norm": 0.34166523814201355,
      "learning_rate": 6.863537457258316e-06,
      "loss": 0.3713,
      "step": 8072
    },
    {
      "epoch": 0.6273702207025179,
      "grad_norm": 0.3008907437324524,
      "learning_rate": 6.8631488964874115e-06,
      "loss": 0.0282,
      "step": 8073
    },
    {
      "epoch": 0.6274479328566988,
      "grad_norm": 0.4121682047843933,
      "learning_rate": 6.862760335716506e-06,
      "loss": 0.2308,
      "step": 8074
    },
    {
      "epoch": 0.6275256450108797,
      "grad_norm": 0.4092276394367218,
      "learning_rate": 6.862371774945602e-06,
      "loss": 0.3988,
      "step": 8075
    },
    {
      "epoch": 0.6276033571650607,
      "grad_norm": 0.42437514662742615,
      "learning_rate": 6.861983214174698e-06,
      "loss": 0.4877,
      "step": 8076
    },
    {
      "epoch": 0.6276810693192415,
      "grad_norm": 0.28713321685791016,
      "learning_rate": 6.861594653403792e-06,
      "loss": 0.2128,
      "step": 8077
    },
    {
      "epoch": 0.6277587814734225,
      "grad_norm": 0.2630797326564789,
      "learning_rate": 6.861206092632888e-06,
      "loss": 0.1648,
      "step": 8078
    },
    {
      "epoch": 0.6278364936276034,
      "grad_norm": 0.2842654585838318,
      "learning_rate": 6.860817531861984e-06,
      "loss": 0.1074,
      "step": 8079
    },
    {
      "epoch": 0.6279142057817843,
      "grad_norm": 0.33316075801849365,
      "learning_rate": 6.860428971091079e-06,
      "loss": 0.0906,
      "step": 8080
    },
    {
      "epoch": 0.6279919179359652,
      "grad_norm": 0.14821980893611908,
      "learning_rate": 6.8600404103201744e-06,
      "loss": 0.0668,
      "step": 8081
    },
    {
      "epoch": 0.628069630090146,
      "grad_norm": 0.22029592096805573,
      "learning_rate": 6.85965184954927e-06,
      "loss": 0.0991,
      "step": 8082
    },
    {
      "epoch": 0.628147342244327,
      "grad_norm": 0.3729797601699829,
      "learning_rate": 6.859263288778365e-06,
      "loss": 0.1037,
      "step": 8083
    },
    {
      "epoch": 0.628225054398508,
      "grad_norm": 0.16013242304325104,
      "learning_rate": 6.858874728007461e-06,
      "loss": 0.082,
      "step": 8084
    },
    {
      "epoch": 0.6283027665526888,
      "grad_norm": 0.455886572599411,
      "learning_rate": 6.858486167236557e-06,
      "loss": 0.1087,
      "step": 8085
    },
    {
      "epoch": 0.6283804787068697,
      "grad_norm": 0.4953717887401581,
      "learning_rate": 6.858097606465651e-06,
      "loss": 0.0918,
      "step": 8086
    },
    {
      "epoch": 0.6284581908610507,
      "grad_norm": 0.21592053771018982,
      "learning_rate": 6.857709045694747e-06,
      "loss": 0.0821,
      "step": 8087
    },
    {
      "epoch": 0.6285359030152315,
      "grad_norm": 0.22193244099617004,
      "learning_rate": 6.8573204849238425e-06,
      "loss": 0.2444,
      "step": 8088
    },
    {
      "epoch": 0.6286136151694125,
      "grad_norm": 0.12593962252140045,
      "learning_rate": 6.856931924152938e-06,
      "loss": 0.0714,
      "step": 8089
    },
    {
      "epoch": 0.6286913273235935,
      "grad_norm": 0.5813689827919006,
      "learning_rate": 6.856543363382033e-06,
      "loss": 0.6768,
      "step": 8090
    },
    {
      "epoch": 0.6287690394777743,
      "grad_norm": 0.26859018206596375,
      "learning_rate": 6.856154802611129e-06,
      "loss": 0.0665,
      "step": 8091
    },
    {
      "epoch": 0.6288467516319552,
      "grad_norm": 0.10214931517839432,
      "learning_rate": 6.855766241840225e-06,
      "loss": 0.0888,
      "step": 8092
    },
    {
      "epoch": 0.6289244637861362,
      "grad_norm": 0.426229864358902,
      "learning_rate": 6.85537768106932e-06,
      "loss": 0.3327,
      "step": 8093
    },
    {
      "epoch": 0.629002175940317,
      "grad_norm": 0.7703458666801453,
      "learning_rate": 6.8549891202984156e-06,
      "loss": 0.3692,
      "step": 8094
    },
    {
      "epoch": 0.629079888094498,
      "grad_norm": 0.29361605644226074,
      "learning_rate": 6.854600559527511e-06,
      "loss": 0.1381,
      "step": 8095
    },
    {
      "epoch": 0.6291576002486788,
      "grad_norm": 0.8535390496253967,
      "learning_rate": 6.8542119987566055e-06,
      "loss": 0.3105,
      "step": 8096
    },
    {
      "epoch": 0.6292353124028598,
      "grad_norm": 0.33957719802856445,
      "learning_rate": 6.853823437985701e-06,
      "loss": 0.1298,
      "step": 8097
    },
    {
      "epoch": 0.6293130245570407,
      "grad_norm": 0.4688704013824463,
      "learning_rate": 6.853434877214797e-06,
      "loss": 0.1892,
      "step": 8098
    },
    {
      "epoch": 0.6293907367112216,
      "grad_norm": 0.5103939771652222,
      "learning_rate": 6.853046316443892e-06,
      "loss": 0.5849,
      "step": 8099
    },
    {
      "epoch": 0.6294684488654025,
      "grad_norm": 0.2735626995563507,
      "learning_rate": 6.852657755672988e-06,
      "loss": 0.1659,
      "step": 8100
    },
    {
      "epoch": 0.6295461610195835,
      "grad_norm": 0.5621991157531738,
      "learning_rate": 6.852269194902084e-06,
      "loss": 0.1971,
      "step": 8101
    },
    {
      "epoch": 0.6296238731737643,
      "grad_norm": 0.4651581048965454,
      "learning_rate": 6.8518806341311786e-06,
      "loss": 0.3979,
      "step": 8102
    },
    {
      "epoch": 0.6297015853279453,
      "grad_norm": 0.420341432094574,
      "learning_rate": 6.851492073360274e-06,
      "loss": 0.279,
      "step": 8103
    },
    {
      "epoch": 0.6297792974821262,
      "grad_norm": 0.315762996673584,
      "learning_rate": 6.85110351258937e-06,
      "loss": 0.137,
      "step": 8104
    },
    {
      "epoch": 0.6298570096363071,
      "grad_norm": 0.33112967014312744,
      "learning_rate": 6.850714951818464e-06,
      "loss": 0.0466,
      "step": 8105
    },
    {
      "epoch": 0.629934721790488,
      "grad_norm": 0.2414301335811615,
      "learning_rate": 6.85032639104756e-06,
      "loss": 0.1637,
      "step": 8106
    },
    {
      "epoch": 0.630012433944669,
      "grad_norm": 0.16659694910049438,
      "learning_rate": 6.849937830276656e-06,
      "loss": 0.0286,
      "step": 8107
    },
    {
      "epoch": 0.6300901460988498,
      "grad_norm": 0.0922403410077095,
      "learning_rate": 6.849549269505751e-06,
      "loss": 0.0314,
      "step": 8108
    },
    {
      "epoch": 0.6301678582530308,
      "grad_norm": 0.13475431501865387,
      "learning_rate": 6.849160708734847e-06,
      "loss": 0.0461,
      "step": 8109
    },
    {
      "epoch": 0.6302455704072117,
      "grad_norm": 0.2272673100233078,
      "learning_rate": 6.848772147963942e-06,
      "loss": 0.1063,
      "step": 8110
    },
    {
      "epoch": 0.6303232825613926,
      "grad_norm": 0.2771155536174774,
      "learning_rate": 6.848383587193037e-06,
      "loss": 0.0519,
      "step": 8111
    },
    {
      "epoch": 0.6304009947155735,
      "grad_norm": 0.43721455335617065,
      "learning_rate": 6.847995026422133e-06,
      "loss": 0.2152,
      "step": 8112
    },
    {
      "epoch": 0.6304787068697544,
      "grad_norm": 0.4380464255809784,
      "learning_rate": 6.847606465651229e-06,
      "loss": 0.1264,
      "step": 8113
    },
    {
      "epoch": 0.6305564190239353,
      "grad_norm": 0.2750730514526367,
      "learning_rate": 6.847217904880323e-06,
      "loss": 0.2539,
      "step": 8114
    },
    {
      "epoch": 0.6306341311781163,
      "grad_norm": 0.08784975856542587,
      "learning_rate": 6.846829344109419e-06,
      "loss": 0.023,
      "step": 8115
    },
    {
      "epoch": 0.6307118433322971,
      "grad_norm": 0.2106064260005951,
      "learning_rate": 6.846440783338515e-06,
      "loss": 0.0543,
      "step": 8116
    },
    {
      "epoch": 0.6307895554864781,
      "grad_norm": 0.13567902147769928,
      "learning_rate": 6.84605222256761e-06,
      "loss": 0.0258,
      "step": 8117
    },
    {
      "epoch": 0.630867267640659,
      "grad_norm": 0.1290816366672516,
      "learning_rate": 6.845663661796705e-06,
      "loss": 0.0284,
      "step": 8118
    },
    {
      "epoch": 0.6309449797948399,
      "grad_norm": 0.37317728996276855,
      "learning_rate": 6.845275101025801e-06,
      "loss": 0.1858,
      "step": 8119
    },
    {
      "epoch": 0.6310226919490208,
      "grad_norm": 0.280098557472229,
      "learning_rate": 6.844886540254897e-06,
      "loss": 0.1242,
      "step": 8120
    },
    {
      "epoch": 0.6311004041032018,
      "grad_norm": 0.9786351919174194,
      "learning_rate": 6.844497979483992e-06,
      "loss": 0.3405,
      "step": 8121
    },
    {
      "epoch": 0.6311781162573826,
      "grad_norm": 0.11790578067302704,
      "learning_rate": 6.844109418713088e-06,
      "loss": 0.0772,
      "step": 8122
    },
    {
      "epoch": 0.6312558284115636,
      "grad_norm": 0.16941048204898834,
      "learning_rate": 6.8437208579421835e-06,
      "loss": 0.0666,
      "step": 8123
    },
    {
      "epoch": 0.6313335405657445,
      "grad_norm": 0.10189168900251389,
      "learning_rate": 6.843332297171278e-06,
      "loss": 0.0221,
      "step": 8124
    },
    {
      "epoch": 0.6314112527199254,
      "grad_norm": 0.16153478622436523,
      "learning_rate": 6.842943736400373e-06,
      "loss": 0.1365,
      "step": 8125
    },
    {
      "epoch": 0.6314889648741063,
      "grad_norm": 0.10996033251285553,
      "learning_rate": 6.842555175629469e-06,
      "loss": 0.064,
      "step": 8126
    },
    {
      "epoch": 0.6315666770282872,
      "grad_norm": 0.25751858949661255,
      "learning_rate": 6.842166614858564e-06,
      "loss": 0.1168,
      "step": 8127
    },
    {
      "epoch": 0.6316443891824681,
      "grad_norm": 0.42552635073661804,
      "learning_rate": 6.84177805408766e-06,
      "loss": 0.0827,
      "step": 8128
    },
    {
      "epoch": 0.6317221013366491,
      "grad_norm": 0.25030502676963806,
      "learning_rate": 6.841389493316756e-06,
      "loss": 0.0614,
      "step": 8129
    },
    {
      "epoch": 0.6317998134908299,
      "grad_norm": 0.3461381196975708,
      "learning_rate": 6.841000932545851e-06,
      "loss": 0.3532,
      "step": 8130
    },
    {
      "epoch": 0.6318775256450109,
      "grad_norm": 0.5691120028495789,
      "learning_rate": 6.8406123717749465e-06,
      "loss": 0.3396,
      "step": 8131
    },
    {
      "epoch": 0.6319552377991918,
      "grad_norm": 0.4578981101512909,
      "learning_rate": 6.840223811004042e-06,
      "loss": 0.235,
      "step": 8132
    },
    {
      "epoch": 0.6320329499533727,
      "grad_norm": 0.2831038236618042,
      "learning_rate": 6.839835250233136e-06,
      "loss": 0.0866,
      "step": 8133
    },
    {
      "epoch": 0.6321106621075536,
      "grad_norm": 0.19263799488544464,
      "learning_rate": 6.839446689462232e-06,
      "loss": 0.0537,
      "step": 8134
    },
    {
      "epoch": 0.6321883742617346,
      "grad_norm": 0.36236995458602905,
      "learning_rate": 6.839058128691328e-06,
      "loss": 0.1383,
      "step": 8135
    },
    {
      "epoch": 0.6322660864159154,
      "grad_norm": 0.6994431018829346,
      "learning_rate": 6.838669567920423e-06,
      "loss": 0.3221,
      "step": 8136
    },
    {
      "epoch": 0.6323437985700964,
      "grad_norm": 0.31951451301574707,
      "learning_rate": 6.838281007149519e-06,
      "loss": 0.1609,
      "step": 8137
    },
    {
      "epoch": 0.6324215107242773,
      "grad_norm": 0.5155263543128967,
      "learning_rate": 6.8378924463786145e-06,
      "loss": 0.2929,
      "step": 8138
    },
    {
      "epoch": 0.6324992228784582,
      "grad_norm": 0.3016098737716675,
      "learning_rate": 6.8375038856077095e-06,
      "loss": 0.0974,
      "step": 8139
    },
    {
      "epoch": 0.6325769350326391,
      "grad_norm": 0.3162769675254822,
      "learning_rate": 6.837115324836805e-06,
      "loss": 0.1256,
      "step": 8140
    },
    {
      "epoch": 0.6326546471868201,
      "grad_norm": 0.631725013256073,
      "learning_rate": 6.836726764065901e-06,
      "loss": 0.5005,
      "step": 8141
    },
    {
      "epoch": 0.6327323593410009,
      "grad_norm": 0.5293146371841431,
      "learning_rate": 6.836338203294995e-06,
      "loss": 0.1111,
      "step": 8142
    },
    {
      "epoch": 0.6328100714951819,
      "grad_norm": 0.373820424079895,
      "learning_rate": 6.835949642524091e-06,
      "loss": 0.3647,
      "step": 8143
    },
    {
      "epoch": 0.6328877836493627,
      "grad_norm": 0.45503130555152893,
      "learning_rate": 6.835561081753187e-06,
      "loss": 0.3092,
      "step": 8144
    },
    {
      "epoch": 0.6329654958035437,
      "grad_norm": 0.6052321791648865,
      "learning_rate": 6.835172520982282e-06,
      "loss": 0.4926,
      "step": 8145
    },
    {
      "epoch": 0.6330432079577246,
      "grad_norm": 0.11656685173511505,
      "learning_rate": 6.8347839602113775e-06,
      "loss": 0.0546,
      "step": 8146
    },
    {
      "epoch": 0.6331209201119055,
      "grad_norm": 0.6231552958488464,
      "learning_rate": 6.834395399440473e-06,
      "loss": 0.4232,
      "step": 8147
    },
    {
      "epoch": 0.6331986322660864,
      "grad_norm": 0.6233327388763428,
      "learning_rate": 6.834006838669568e-06,
      "loss": 0.251,
      "step": 8148
    },
    {
      "epoch": 0.6332763444202674,
      "grad_norm": 0.7122248411178589,
      "learning_rate": 6.833618277898664e-06,
      "loss": 0.3898,
      "step": 8149
    },
    {
      "epoch": 0.6333540565744482,
      "grad_norm": 0.2999494969844818,
      "learning_rate": 6.83322971712776e-06,
      "loss": 0.085,
      "step": 8150
    },
    {
      "epoch": 0.6334317687286292,
      "grad_norm": 0.3443205952644348,
      "learning_rate": 6.832841156356856e-06,
      "loss": 0.0842,
      "step": 8151
    },
    {
      "epoch": 0.6335094808828101,
      "grad_norm": 0.6474670767784119,
      "learning_rate": 6.83245259558595e-06,
      "loss": 1.1168,
      "step": 8152
    },
    {
      "epoch": 0.633587193036991,
      "grad_norm": 0.215067520737648,
      "learning_rate": 6.8320640348150456e-06,
      "loss": 0.0516,
      "step": 8153
    },
    {
      "epoch": 0.6336649051911719,
      "grad_norm": 0.5133432149887085,
      "learning_rate": 6.831675474044141e-06,
      "loss": 0.321,
      "step": 8154
    },
    {
      "epoch": 0.6337426173453529,
      "grad_norm": 0.11915026605129242,
      "learning_rate": 6.831286913273236e-06,
      "loss": 0.0187,
      "step": 8155
    },
    {
      "epoch": 0.6338203294995337,
      "grad_norm": 0.27488818764686584,
      "learning_rate": 6.830898352502332e-06,
      "loss": 0.2103,
      "step": 8156
    },
    {
      "epoch": 0.6338980416537147,
      "grad_norm": 0.4966694414615631,
      "learning_rate": 6.830509791731428e-06,
      "loss": 0.2424,
      "step": 8157
    },
    {
      "epoch": 0.6339757538078955,
      "grad_norm": 0.7304612994194031,
      "learning_rate": 6.830121230960523e-06,
      "loss": 0.2997,
      "step": 8158
    },
    {
      "epoch": 0.6340534659620765,
      "grad_norm": 0.3400779068470001,
      "learning_rate": 6.829732670189619e-06,
      "loss": 0.1759,
      "step": 8159
    },
    {
      "epoch": 0.6341311781162574,
      "grad_norm": 0.5232450366020203,
      "learning_rate": 6.8293441094187144e-06,
      "loss": 0.3698,
      "step": 8160
    },
    {
      "epoch": 0.6342088902704383,
      "grad_norm": 0.4093082547187805,
      "learning_rate": 6.8289555486478085e-06,
      "loss": 0.2456,
      "step": 8161
    },
    {
      "epoch": 0.6342866024246192,
      "grad_norm": 0.21436820924282074,
      "learning_rate": 6.828566987876904e-06,
      "loss": 0.0176,
      "step": 8162
    },
    {
      "epoch": 0.6343643145788002,
      "grad_norm": 0.2975926995277405,
      "learning_rate": 6.828178427106e-06,
      "loss": 0.0962,
      "step": 8163
    },
    {
      "epoch": 0.634442026732981,
      "grad_norm": 0.14536570012569427,
      "learning_rate": 6.827789866335095e-06,
      "loss": 0.0386,
      "step": 8164
    },
    {
      "epoch": 0.634519738887162,
      "grad_norm": 0.38858020305633545,
      "learning_rate": 6.827401305564191e-06,
      "loss": 0.2244,
      "step": 8165
    },
    {
      "epoch": 0.6345974510413429,
      "grad_norm": 0.8419873714447021,
      "learning_rate": 6.827012744793287e-06,
      "loss": 0.4947,
      "step": 8166
    },
    {
      "epoch": 0.6346751631955238,
      "grad_norm": 0.3291082978248596,
      "learning_rate": 6.826624184022382e-06,
      "loss": 0.0565,
      "step": 8167
    },
    {
      "epoch": 0.6347528753497047,
      "grad_norm": 0.23401561379432678,
      "learning_rate": 6.8262356232514774e-06,
      "loss": 0.0722,
      "step": 8168
    },
    {
      "epoch": 0.6348305875038857,
      "grad_norm": 0.4848812222480774,
      "learning_rate": 6.825847062480573e-06,
      "loss": 0.133,
      "step": 8169
    },
    {
      "epoch": 0.6349082996580665,
      "grad_norm": 0.32770419120788574,
      "learning_rate": 6.825458501709667e-06,
      "loss": 0.173,
      "step": 8170
    },
    {
      "epoch": 0.6349860118122475,
      "grad_norm": 0.42236679792404175,
      "learning_rate": 6.825069940938763e-06,
      "loss": 0.4027,
      "step": 8171
    },
    {
      "epoch": 0.6350637239664283,
      "grad_norm": 0.58482426404953,
      "learning_rate": 6.824681380167859e-06,
      "loss": 0.5326,
      "step": 8172
    },
    {
      "epoch": 0.6351414361206092,
      "grad_norm": 0.2696816921234131,
      "learning_rate": 6.824292819396954e-06,
      "loss": 0.194,
      "step": 8173
    },
    {
      "epoch": 0.6352191482747902,
      "grad_norm": 0.3209216892719269,
      "learning_rate": 6.82390425862605e-06,
      "loss": 0.2157,
      "step": 8174
    },
    {
      "epoch": 0.635296860428971,
      "grad_norm": 0.17945313453674316,
      "learning_rate": 6.8235156978551455e-06,
      "loss": 0.0608,
      "step": 8175
    },
    {
      "epoch": 0.635374572583152,
      "grad_norm": 0.083102747797966,
      "learning_rate": 6.82312713708424e-06,
      "loss": 0.0241,
      "step": 8176
    },
    {
      "epoch": 0.635452284737333,
      "grad_norm": 0.4595063030719757,
      "learning_rate": 6.822738576313336e-06,
      "loss": 0.1846,
      "step": 8177
    },
    {
      "epoch": 0.6355299968915138,
      "grad_norm": 0.5688199400901794,
      "learning_rate": 6.822350015542432e-06,
      "loss": 0.193,
      "step": 8178
    },
    {
      "epoch": 0.6356077090456947,
      "grad_norm": 0.08025798201560974,
      "learning_rate": 6.821961454771526e-06,
      "loss": 0.0179,
      "step": 8179
    },
    {
      "epoch": 0.6356854211998757,
      "grad_norm": 0.5903366208076477,
      "learning_rate": 6.821572894000622e-06,
      "loss": 0.246,
      "step": 8180
    },
    {
      "epoch": 0.6357631333540565,
      "grad_norm": 0.27143269777297974,
      "learning_rate": 6.821184333229718e-06,
      "loss": 0.1794,
      "step": 8181
    },
    {
      "epoch": 0.6358408455082375,
      "grad_norm": 0.2832929790019989,
      "learning_rate": 6.8207957724588135e-06,
      "loss": 0.1376,
      "step": 8182
    },
    {
      "epoch": 0.6359185576624184,
      "grad_norm": 0.09488286823034286,
      "learning_rate": 6.8204072116879085e-06,
      "loss": 0.0365,
      "step": 8183
    },
    {
      "epoch": 0.6359962698165993,
      "grad_norm": 0.3404251039028168,
      "learning_rate": 6.820018650917004e-06,
      "loss": 0.1465,
      "step": 8184
    },
    {
      "epoch": 0.6360739819707802,
      "grad_norm": 0.46524330973625183,
      "learning_rate": 6.8196300901461e-06,
      "loss": 0.2786,
      "step": 8185
    },
    {
      "epoch": 0.6361516941249612,
      "grad_norm": 0.9947360754013062,
      "learning_rate": 6.819241529375194e-06,
      "loss": 0.4199,
      "step": 8186
    },
    {
      "epoch": 0.636229406279142,
      "grad_norm": 0.33479321002960205,
      "learning_rate": 6.81885296860429e-06,
      "loss": 0.1106,
      "step": 8187
    },
    {
      "epoch": 0.636307118433323,
      "grad_norm": 0.18589511513710022,
      "learning_rate": 6.818464407833386e-06,
      "loss": 0.1071,
      "step": 8188
    },
    {
      "epoch": 0.6363848305875038,
      "grad_norm": 0.9534345269203186,
      "learning_rate": 6.818075847062481e-06,
      "loss": 0.5329,
      "step": 8189
    },
    {
      "epoch": 0.6364625427416848,
      "grad_norm": 0.6491418480873108,
      "learning_rate": 6.8176872862915765e-06,
      "loss": 0.2105,
      "step": 8190
    },
    {
      "epoch": 0.6365402548958657,
      "grad_norm": 0.2435401976108551,
      "learning_rate": 6.817298725520672e-06,
      "loss": 0.1608,
      "step": 8191
    },
    {
      "epoch": 0.6366179670500466,
      "grad_norm": 0.3721122145652771,
      "learning_rate": 6.816910164749767e-06,
      "loss": 0.1526,
      "step": 8192
    },
    {
      "epoch": 0.6366956792042275,
      "grad_norm": 0.13141806423664093,
      "learning_rate": 6.816521603978863e-06,
      "loss": 0.0217,
      "step": 8193
    },
    {
      "epoch": 0.6367733913584085,
      "grad_norm": 0.35410815477371216,
      "learning_rate": 6.816133043207959e-06,
      "loss": 0.1173,
      "step": 8194
    },
    {
      "epoch": 0.6368511035125893,
      "grad_norm": 0.1657269448041916,
      "learning_rate": 6.815744482437053e-06,
      "loss": 0.0738,
      "step": 8195
    },
    {
      "epoch": 0.6369288156667703,
      "grad_norm": 0.20914137363433838,
      "learning_rate": 6.815355921666149e-06,
      "loss": 0.0655,
      "step": 8196
    },
    {
      "epoch": 0.6370065278209512,
      "grad_norm": 0.5836530923843384,
      "learning_rate": 6.8149673608952445e-06,
      "loss": 0.0898,
      "step": 8197
    },
    {
      "epoch": 0.6370842399751321,
      "grad_norm": 0.056814759969711304,
      "learning_rate": 6.8145788001243395e-06,
      "loss": 0.0044,
      "step": 8198
    },
    {
      "epoch": 0.637161952129313,
      "grad_norm": 0.5309560894966125,
      "learning_rate": 6.814190239353435e-06,
      "loss": 0.236,
      "step": 8199
    },
    {
      "epoch": 0.637239664283494,
      "grad_norm": 0.2583715319633484,
      "learning_rate": 6.813801678582531e-06,
      "loss": 0.1557,
      "step": 8200
    },
    {
      "epoch": 0.6373173764376748,
      "grad_norm": 0.2905140221118927,
      "learning_rate": 6.813413117811626e-06,
      "loss": 0.0673,
      "step": 8201
    },
    {
      "epoch": 0.6373950885918558,
      "grad_norm": 0.7236936688423157,
      "learning_rate": 6.813024557040722e-06,
      "loss": 0.1116,
      "step": 8202
    },
    {
      "epoch": 0.6374728007460366,
      "grad_norm": 0.14793023467063904,
      "learning_rate": 6.812635996269818e-06,
      "loss": 0.1093,
      "step": 8203
    },
    {
      "epoch": 0.6375505129002176,
      "grad_norm": 0.574137806892395,
      "learning_rate": 6.812247435498912e-06,
      "loss": 0.23,
      "step": 8204
    },
    {
      "epoch": 0.6376282250543985,
      "grad_norm": 0.1603526473045349,
      "learning_rate": 6.8118588747280075e-06,
      "loss": 0.1134,
      "step": 8205
    },
    {
      "epoch": 0.6377059372085794,
      "grad_norm": 0.8534824252128601,
      "learning_rate": 6.811470313957103e-06,
      "loss": 0.1671,
      "step": 8206
    },
    {
      "epoch": 0.6377836493627603,
      "grad_norm": 2.3048336505889893,
      "learning_rate": 6.811081753186198e-06,
      "loss": 0.6232,
      "step": 8207
    },
    {
      "epoch": 0.6378613615169413,
      "grad_norm": 0.856950581073761,
      "learning_rate": 6.810693192415294e-06,
      "loss": 0.33,
      "step": 8208
    },
    {
      "epoch": 0.6379390736711221,
      "grad_norm": 0.07276159524917603,
      "learning_rate": 6.81030463164439e-06,
      "loss": 0.0165,
      "step": 8209
    },
    {
      "epoch": 0.6380167858253031,
      "grad_norm": 0.38263407349586487,
      "learning_rate": 6.809916070873486e-06,
      "loss": 0.1915,
      "step": 8210
    },
    {
      "epoch": 0.638094497979484,
      "grad_norm": 0.2764328420162201,
      "learning_rate": 6.809527510102581e-06,
      "loss": 0.0252,
      "step": 8211
    },
    {
      "epoch": 0.6381722101336649,
      "grad_norm": 0.48546698689460754,
      "learning_rate": 6.809138949331676e-06,
      "loss": 0.2268,
      "step": 8212
    },
    {
      "epoch": 0.6382499222878458,
      "grad_norm": 0.3617914021015167,
      "learning_rate": 6.808750388560772e-06,
      "loss": 0.5473,
      "step": 8213
    },
    {
      "epoch": 0.6383276344420268,
      "grad_norm": 0.15602616965770721,
      "learning_rate": 6.808361827789866e-06,
      "loss": 0.0362,
      "step": 8214
    },
    {
      "epoch": 0.6384053465962076,
      "grad_norm": 0.7765107154846191,
      "learning_rate": 6.807973267018962e-06,
      "loss": 0.2929,
      "step": 8215
    },
    {
      "epoch": 0.6384830587503886,
      "grad_norm": 0.4952906668186188,
      "learning_rate": 6.807584706248058e-06,
      "loss": 0.2935,
      "step": 8216
    },
    {
      "epoch": 0.6385607709045695,
      "grad_norm": 0.105675108730793,
      "learning_rate": 6.807196145477153e-06,
      "loss": 0.0675,
      "step": 8217
    },
    {
      "epoch": 0.6386384830587504,
      "grad_norm": 0.5628660917282104,
      "learning_rate": 6.806807584706249e-06,
      "loss": 0.3043,
      "step": 8218
    },
    {
      "epoch": 0.6387161952129313,
      "grad_norm": 0.28921517729759216,
      "learning_rate": 6.8064190239353444e-06,
      "loss": 0.0437,
      "step": 8219
    },
    {
      "epoch": 0.6387939073671122,
      "grad_norm": 0.6065170764923096,
      "learning_rate": 6.806030463164439e-06,
      "loss": 0.2868,
      "step": 8220
    },
    {
      "epoch": 0.6388716195212931,
      "grad_norm": 1.0554462671279907,
      "learning_rate": 6.805641902393535e-06,
      "loss": 0.8104,
      "step": 8221
    },
    {
      "epoch": 0.6389493316754741,
      "grad_norm": 0.21033412218093872,
      "learning_rate": 6.805253341622631e-06,
      "loss": 0.1173,
      "step": 8222
    },
    {
      "epoch": 0.6390270438296549,
      "grad_norm": 0.16462744772434235,
      "learning_rate": 6.804864780851725e-06,
      "loss": 0.0397,
      "step": 8223
    },
    {
      "epoch": 0.6391047559838359,
      "grad_norm": 0.5673933029174805,
      "learning_rate": 6.804476220080821e-06,
      "loss": 0.5628,
      "step": 8224
    },
    {
      "epoch": 0.6391824681380168,
      "grad_norm": 0.6223277449607849,
      "learning_rate": 6.804087659309917e-06,
      "loss": 0.5191,
      "step": 8225
    },
    {
      "epoch": 0.6392601802921977,
      "grad_norm": 0.27060776948928833,
      "learning_rate": 6.803699098539012e-06,
      "loss": 0.1751,
      "step": 8226
    },
    {
      "epoch": 0.6393378924463786,
      "grad_norm": 0.10380759835243225,
      "learning_rate": 6.803310537768107e-06,
      "loss": 0.0239,
      "step": 8227
    },
    {
      "epoch": 0.6394156046005596,
      "grad_norm": 0.11439243704080582,
      "learning_rate": 6.802921976997203e-06,
      "loss": 0.021,
      "step": 8228
    },
    {
      "epoch": 0.6394933167547404,
      "grad_norm": 0.21256078779697418,
      "learning_rate": 6.802533416226298e-06,
      "loss": 0.0883,
      "step": 8229
    },
    {
      "epoch": 0.6395710289089214,
      "grad_norm": 0.2912846803665161,
      "learning_rate": 6.802144855455394e-06,
      "loss": 0.3581,
      "step": 8230
    },
    {
      "epoch": 0.6396487410631023,
      "grad_norm": 0.6991808414459229,
      "learning_rate": 6.80175629468449e-06,
      "loss": 0.1439,
      "step": 8231
    },
    {
      "epoch": 0.6397264532172832,
      "grad_norm": 0.23628529906272888,
      "learning_rate": 6.801367733913584e-06,
      "loss": 0.1346,
      "step": 8232
    },
    {
      "epoch": 0.6398041653714641,
      "grad_norm": 0.3178115785121918,
      "learning_rate": 6.80097917314268e-06,
      "loss": 0.267,
      "step": 8233
    },
    {
      "epoch": 0.639881877525645,
      "grad_norm": 0.12968270480632782,
      "learning_rate": 6.8005906123717755e-06,
      "loss": 0.02,
      "step": 8234
    },
    {
      "epoch": 0.6399595896798259,
      "grad_norm": 0.5848005414009094,
      "learning_rate": 6.80020205160087e-06,
      "loss": 0.1664,
      "step": 8235
    },
    {
      "epoch": 0.6400373018340069,
      "grad_norm": 0.5000823736190796,
      "learning_rate": 6.799813490829966e-06,
      "loss": 0.0356,
      "step": 8236
    },
    {
      "epoch": 0.6401150139881877,
      "grad_norm": 0.6393483877182007,
      "learning_rate": 6.799424930059062e-06,
      "loss": 0.2878,
      "step": 8237
    },
    {
      "epoch": 0.6401927261423687,
      "grad_norm": 0.30914241075515747,
      "learning_rate": 6.799036369288157e-06,
      "loss": 0.1069,
      "step": 8238
    },
    {
      "epoch": 0.6402704382965496,
      "grad_norm": 0.1617969423532486,
      "learning_rate": 6.798647808517253e-06,
      "loss": 0.0719,
      "step": 8239
    },
    {
      "epoch": 0.6403481504507305,
      "grad_norm": 0.09730391949415207,
      "learning_rate": 6.7982592477463485e-06,
      "loss": 0.0112,
      "step": 8240
    },
    {
      "epoch": 0.6404258626049114,
      "grad_norm": 0.11730111390352249,
      "learning_rate": 6.797870686975444e-06,
      "loss": 0.0321,
      "step": 8241
    },
    {
      "epoch": 0.6405035747590924,
      "grad_norm": 0.2853148877620697,
      "learning_rate": 6.7974821262045384e-06,
      "loss": 0.2503,
      "step": 8242
    },
    {
      "epoch": 0.6405812869132732,
      "grad_norm": 0.1460484266281128,
      "learning_rate": 6.797093565433634e-06,
      "loss": 0.0576,
      "step": 8243
    },
    {
      "epoch": 0.6406589990674542,
      "grad_norm": 0.4080682694911957,
      "learning_rate": 6.79670500466273e-06,
      "loss": 0.1358,
      "step": 8244
    },
    {
      "epoch": 0.6407367112216351,
      "grad_norm": 0.2189202904701233,
      "learning_rate": 6.796316443891825e-06,
      "loss": 0.0259,
      "step": 8245
    },
    {
      "epoch": 0.640814423375816,
      "grad_norm": 0.7338063716888428,
      "learning_rate": 6.795927883120921e-06,
      "loss": 0.2662,
      "step": 8246
    },
    {
      "epoch": 0.6408921355299969,
      "grad_norm": 0.2971448600292206,
      "learning_rate": 6.795539322350017e-06,
      "loss": 0.2249,
      "step": 8247
    },
    {
      "epoch": 0.6409698476841778,
      "grad_norm": 0.3092885911464691,
      "learning_rate": 6.7951507615791115e-06,
      "loss": 0.1869,
      "step": 8248
    },
    {
      "epoch": 0.6410475598383587,
      "grad_norm": 0.09565669298171997,
      "learning_rate": 6.794762200808207e-06,
      "loss": 0.0265,
      "step": 8249
    },
    {
      "epoch": 0.6411252719925397,
      "grad_norm": 0.6264451742172241,
      "learning_rate": 6.794373640037303e-06,
      "loss": 0.2073,
      "step": 8250
    },
    {
      "epoch": 0.6412029841467205,
      "grad_norm": 0.5199618935585022,
      "learning_rate": 6.793985079266397e-06,
      "loss": 0.2301,
      "step": 8251
    },
    {
      "epoch": 0.6412806963009015,
      "grad_norm": 0.1627349704504013,
      "learning_rate": 6.793596518495493e-06,
      "loss": 0.0408,
      "step": 8252
    },
    {
      "epoch": 0.6413584084550824,
      "grad_norm": 0.23087622225284576,
      "learning_rate": 6.793207957724589e-06,
      "loss": 0.0781,
      "step": 8253
    },
    {
      "epoch": 0.6414361206092632,
      "grad_norm": 0.13344140350818634,
      "learning_rate": 6.792819396953684e-06,
      "loss": 0.0891,
      "step": 8254
    },
    {
      "epoch": 0.6415138327634442,
      "grad_norm": 0.25923430919647217,
      "learning_rate": 6.7924308361827796e-06,
      "loss": 0.1382,
      "step": 8255
    },
    {
      "epoch": 0.6415915449176252,
      "grad_norm": 0.49924615025520325,
      "learning_rate": 6.792042275411875e-06,
      "loss": 0.1888,
      "step": 8256
    },
    {
      "epoch": 0.641669257071806,
      "grad_norm": 0.6745517253875732,
      "learning_rate": 6.79165371464097e-06,
      "loss": 0.1664,
      "step": 8257
    },
    {
      "epoch": 0.641746969225987,
      "grad_norm": 0.2077568620443344,
      "learning_rate": 6.791265153870066e-06,
      "loss": 0.0985,
      "step": 8258
    },
    {
      "epoch": 0.6418246813801679,
      "grad_norm": 0.4139646589756012,
      "learning_rate": 6.790876593099162e-06,
      "loss": 0.3308,
      "step": 8259
    },
    {
      "epoch": 0.6419023935343487,
      "grad_norm": 0.6267724633216858,
      "learning_rate": 6.790488032328256e-06,
      "loss": 0.3536,
      "step": 8260
    },
    {
      "epoch": 0.6419801056885297,
      "grad_norm": 0.19914722442626953,
      "learning_rate": 6.790099471557352e-06,
      "loss": 0.0722,
      "step": 8261
    },
    {
      "epoch": 0.6420578178427107,
      "grad_norm": 0.22875474393367767,
      "learning_rate": 6.789710910786448e-06,
      "loss": 0.1538,
      "step": 8262
    },
    {
      "epoch": 0.6421355299968915,
      "grad_norm": 0.6432526111602783,
      "learning_rate": 6.7893223500155425e-06,
      "loss": 0.1789,
      "step": 8263
    },
    {
      "epoch": 0.6422132421510724,
      "grad_norm": 0.42208755016326904,
      "learning_rate": 6.788933789244638e-06,
      "loss": 0.2025,
      "step": 8264
    },
    {
      "epoch": 0.6422909543052533,
      "grad_norm": 0.5593858361244202,
      "learning_rate": 6.788545228473734e-06,
      "loss": 0.213,
      "step": 8265
    },
    {
      "epoch": 0.6423686664594342,
      "grad_norm": 0.4655908942222595,
      "learning_rate": 6.788156667702829e-06,
      "loss": 0.2948,
      "step": 8266
    },
    {
      "epoch": 0.6424463786136152,
      "grad_norm": 0.537858247756958,
      "learning_rate": 6.787768106931925e-06,
      "loss": 0.5086,
      "step": 8267
    },
    {
      "epoch": 0.642524090767796,
      "grad_norm": 0.18801145255565643,
      "learning_rate": 6.787379546161021e-06,
      "loss": 0.108,
      "step": 8268
    },
    {
      "epoch": 0.642601802921977,
      "grad_norm": 0.13837873935699463,
      "learning_rate": 6.786990985390115e-06,
      "loss": 0.0259,
      "step": 8269
    },
    {
      "epoch": 0.642679515076158,
      "grad_norm": 0.35626763105392456,
      "learning_rate": 6.786602424619211e-06,
      "loss": 0.4606,
      "step": 8270
    },
    {
      "epoch": 0.6427572272303388,
      "grad_norm": 0.19657763838768005,
      "learning_rate": 6.786213863848306e-06,
      "loss": 0.0397,
      "step": 8271
    },
    {
      "epoch": 0.6428349393845197,
      "grad_norm": 0.5774336457252502,
      "learning_rate": 6.785825303077402e-06,
      "loss": 0.1072,
      "step": 8272
    },
    {
      "epoch": 0.6429126515387007,
      "grad_norm": 0.5532751679420471,
      "learning_rate": 6.785436742306497e-06,
      "loss": 0.1893,
      "step": 8273
    },
    {
      "epoch": 0.6429903636928815,
      "grad_norm": 0.11852683126926422,
      "learning_rate": 6.785048181535593e-06,
      "loss": 0.0143,
      "step": 8274
    },
    {
      "epoch": 0.6430680758470625,
      "grad_norm": 0.21022818982601166,
      "learning_rate": 6.784659620764689e-06,
      "loss": 0.0277,
      "step": 8275
    },
    {
      "epoch": 0.6431457880012434,
      "grad_norm": 0.5870544910430908,
      "learning_rate": 6.784271059993784e-06,
      "loss": 0.2761,
      "step": 8276
    },
    {
      "epoch": 0.6432235001554243,
      "grad_norm": 1.2452086210250854,
      "learning_rate": 6.7838824992228795e-06,
      "loss": 0.6825,
      "step": 8277
    },
    {
      "epoch": 0.6433012123096052,
      "grad_norm": 0.3800922930240631,
      "learning_rate": 6.783493938451975e-06,
      "loss": 0.3108,
      "step": 8278
    },
    {
      "epoch": 0.6433789244637861,
      "grad_norm": 0.44653213024139404,
      "learning_rate": 6.783105377681069e-06,
      "loss": 0.2055,
      "step": 8279
    },
    {
      "epoch": 0.643456636617967,
      "grad_norm": 0.37490975856781006,
      "learning_rate": 6.782716816910165e-06,
      "loss": 0.2195,
      "step": 8280
    },
    {
      "epoch": 0.643534348772148,
      "grad_norm": 0.8710036277770996,
      "learning_rate": 6.782328256139261e-06,
      "loss": 0.3139,
      "step": 8281
    },
    {
      "epoch": 0.6436120609263288,
      "grad_norm": 0.6405338048934937,
      "learning_rate": 6.781939695368356e-06,
      "loss": 0.4565,
      "step": 8282
    },
    {
      "epoch": 0.6436897730805098,
      "grad_norm": 0.1334928423166275,
      "learning_rate": 6.781551134597452e-06,
      "loss": 0.0656,
      "step": 8283
    },
    {
      "epoch": 0.6437674852346907,
      "grad_norm": 0.16863389313220978,
      "learning_rate": 6.7811625738265475e-06,
      "loss": 0.1679,
      "step": 8284
    },
    {
      "epoch": 0.6438451973888716,
      "grad_norm": 0.34687626361846924,
      "learning_rate": 6.7807740130556425e-06,
      "loss": 0.083,
      "step": 8285
    },
    {
      "epoch": 0.6439229095430525,
      "grad_norm": 0.23249702155590057,
      "learning_rate": 6.780385452284738e-06,
      "loss": 0.1817,
      "step": 8286
    },
    {
      "epoch": 0.6440006216972335,
      "grad_norm": 0.5042385458946228,
      "learning_rate": 6.779996891513834e-06,
      "loss": 0.2611,
      "step": 8287
    },
    {
      "epoch": 0.6440783338514143,
      "grad_norm": 0.3331410884857178,
      "learning_rate": 6.779608330742928e-06,
      "loss": 0.2237,
      "step": 8288
    },
    {
      "epoch": 0.6441560460055953,
      "grad_norm": 0.1096607893705368,
      "learning_rate": 6.779219769972024e-06,
      "loss": 0.0152,
      "step": 8289
    },
    {
      "epoch": 0.6442337581597762,
      "grad_norm": 0.27916279435157776,
      "learning_rate": 6.77883120920112e-06,
      "loss": 0.3049,
      "step": 8290
    },
    {
      "epoch": 0.6443114703139571,
      "grad_norm": 0.2112460881471634,
      "learning_rate": 6.778442648430215e-06,
      "loss": 0.0955,
      "step": 8291
    },
    {
      "epoch": 0.644389182468138,
      "grad_norm": 0.5861762762069702,
      "learning_rate": 6.7780540876593105e-06,
      "loss": 0.3261,
      "step": 8292
    },
    {
      "epoch": 0.6444668946223189,
      "grad_norm": 0.3574507534503937,
      "learning_rate": 6.777665526888406e-06,
      "loss": 0.095,
      "step": 8293
    },
    {
      "epoch": 0.6445446067764998,
      "grad_norm": 0.36147162318229675,
      "learning_rate": 6.777276966117501e-06,
      "loss": 0.2141,
      "step": 8294
    },
    {
      "epoch": 0.6446223189306808,
      "grad_norm": 0.17814002931118011,
      "learning_rate": 6.776888405346597e-06,
      "loss": 0.083,
      "step": 8295
    },
    {
      "epoch": 0.6447000310848616,
      "grad_norm": 0.06672199070453644,
      "learning_rate": 6.776499844575693e-06,
      "loss": 0.0209,
      "step": 8296
    },
    {
      "epoch": 0.6447777432390426,
      "grad_norm": 0.5608132481575012,
      "learning_rate": 6.776111283804787e-06,
      "loss": 0.2131,
      "step": 8297
    },
    {
      "epoch": 0.6448554553932235,
      "grad_norm": 0.5684788227081299,
      "learning_rate": 6.775722723033883e-06,
      "loss": 0.1844,
      "step": 8298
    },
    {
      "epoch": 0.6449331675474044,
      "grad_norm": 0.6412315368652344,
      "learning_rate": 6.7753341622629785e-06,
      "loss": 0.1827,
      "step": 8299
    },
    {
      "epoch": 0.6450108797015853,
      "grad_norm": 0.5019077658653259,
      "learning_rate": 6.7749456014920735e-06,
      "loss": 0.1021,
      "step": 8300
    },
    {
      "epoch": 0.6450885918557663,
      "grad_norm": 0.39701661467552185,
      "learning_rate": 6.774557040721169e-06,
      "loss": 0.1012,
      "step": 8301
    },
    {
      "epoch": 0.6451663040099471,
      "grad_norm": 0.4946311116218567,
      "learning_rate": 6.774168479950265e-06,
      "loss": 0.3256,
      "step": 8302
    },
    {
      "epoch": 0.6452440161641281,
      "grad_norm": 0.37506335973739624,
      "learning_rate": 6.773779919179361e-06,
      "loss": 0.1667,
      "step": 8303
    },
    {
      "epoch": 0.645321728318309,
      "grad_norm": 0.14646437764167786,
      "learning_rate": 6.773391358408456e-06,
      "loss": 0.0601,
      "step": 8304
    },
    {
      "epoch": 0.6453994404724899,
      "grad_norm": 0.4153401553630829,
      "learning_rate": 6.773002797637552e-06,
      "loss": 0.1103,
      "step": 8305
    },
    {
      "epoch": 0.6454771526266708,
      "grad_norm": 0.3267606794834137,
      "learning_rate": 6.7726142368666466e-06,
      "loss": 0.1712,
      "step": 8306
    },
    {
      "epoch": 0.6455548647808518,
      "grad_norm": 0.18563906848430634,
      "learning_rate": 6.7722256760957415e-06,
      "loss": 0.0874,
      "step": 8307
    },
    {
      "epoch": 0.6456325769350326,
      "grad_norm": 0.18116851150989532,
      "learning_rate": 6.771837115324837e-06,
      "loss": 0.08,
      "step": 8308
    },
    {
      "epoch": 0.6457102890892136,
      "grad_norm": 0.14551785588264465,
      "learning_rate": 6.771448554553933e-06,
      "loss": 0.0879,
      "step": 8309
    },
    {
      "epoch": 0.6457880012433944,
      "grad_norm": 1.3102730512619019,
      "learning_rate": 6.771059993783028e-06,
      "loss": 0.4207,
      "step": 8310
    },
    {
      "epoch": 0.6458657133975754,
      "grad_norm": 0.17143502831459045,
      "learning_rate": 6.770671433012124e-06,
      "loss": 0.049,
      "step": 8311
    },
    {
      "epoch": 0.6459434255517563,
      "grad_norm": 0.20022068917751312,
      "learning_rate": 6.77028287224122e-06,
      "loss": 0.0501,
      "step": 8312
    },
    {
      "epoch": 0.6460211377059372,
      "grad_norm": 0.28646498918533325,
      "learning_rate": 6.769894311470314e-06,
      "loss": 0.0359,
      "step": 8313
    },
    {
      "epoch": 0.6460988498601181,
      "grad_norm": 0.8559104204177856,
      "learning_rate": 6.7695057506994096e-06,
      "loss": 0.3348,
      "step": 8314
    },
    {
      "epoch": 0.6461765620142991,
      "grad_norm": 0.26310908794403076,
      "learning_rate": 6.769117189928505e-06,
      "loss": 0.1147,
      "step": 8315
    },
    {
      "epoch": 0.6462542741684799,
      "grad_norm": 0.6636956930160522,
      "learning_rate": 6.7687286291576e-06,
      "loss": 0.2602,
      "step": 8316
    },
    {
      "epoch": 0.6463319863226609,
      "grad_norm": 1.0207585096359253,
      "learning_rate": 6.768340068386696e-06,
      "loss": 0.2011,
      "step": 8317
    },
    {
      "epoch": 0.6464096984768418,
      "grad_norm": 0.23090557754039764,
      "learning_rate": 6.767951507615792e-06,
      "loss": 0.0751,
      "step": 8318
    },
    {
      "epoch": 0.6464874106310227,
      "grad_norm": 0.8327046036720276,
      "learning_rate": 6.767562946844887e-06,
      "loss": 0.4835,
      "step": 8319
    },
    {
      "epoch": 0.6465651227852036,
      "grad_norm": 0.9210362434387207,
      "learning_rate": 6.767174386073983e-06,
      "loss": 0.3931,
      "step": 8320
    },
    {
      "epoch": 0.6466428349393846,
      "grad_norm": 0.02897607907652855,
      "learning_rate": 6.7667858253030784e-06,
      "loss": 0.0025,
      "step": 8321
    },
    {
      "epoch": 0.6467205470935654,
      "grad_norm": 0.30410587787628174,
      "learning_rate": 6.7663972645321725e-06,
      "loss": 0.1156,
      "step": 8322
    },
    {
      "epoch": 0.6467982592477464,
      "grad_norm": 0.14621587097644806,
      "learning_rate": 6.766008703761268e-06,
      "loss": 0.0487,
      "step": 8323
    },
    {
      "epoch": 0.6468759714019272,
      "grad_norm": 0.4357892572879791,
      "learning_rate": 6.765620142990364e-06,
      "loss": 0.2094,
      "step": 8324
    },
    {
      "epoch": 0.6469536835561082,
      "grad_norm": 0.2880233824253082,
      "learning_rate": 6.765231582219459e-06,
      "loss": 0.1178,
      "step": 8325
    },
    {
      "epoch": 0.6470313957102891,
      "grad_norm": 0.2916104793548584,
      "learning_rate": 6.764843021448555e-06,
      "loss": 0.1309,
      "step": 8326
    },
    {
      "epoch": 0.64710910786447,
      "grad_norm": 0.7185860276222229,
      "learning_rate": 6.764454460677651e-06,
      "loss": 0.2719,
      "step": 8327
    },
    {
      "epoch": 0.6471868200186509,
      "grad_norm": 0.21469056606292725,
      "learning_rate": 6.764065899906746e-06,
      "loss": 0.112,
      "step": 8328
    },
    {
      "epoch": 0.6472645321728319,
      "grad_norm": 0.255720853805542,
      "learning_rate": 6.763677339135841e-06,
      "loss": 0.1247,
      "step": 8329
    },
    {
      "epoch": 0.6473422443270127,
      "grad_norm": 0.13977083563804626,
      "learning_rate": 6.763288778364937e-06,
      "loss": 0.0298,
      "step": 8330
    },
    {
      "epoch": 0.6474199564811937,
      "grad_norm": 0.33476999402046204,
      "learning_rate": 6.762900217594033e-06,
      "loss": 0.1557,
      "step": 8331
    },
    {
      "epoch": 0.6474976686353746,
      "grad_norm": 0.153519868850708,
      "learning_rate": 6.762511656823127e-06,
      "loss": 0.0509,
      "step": 8332
    },
    {
      "epoch": 0.6475753807895555,
      "grad_norm": 0.1888766586780548,
      "learning_rate": 6.762123096052223e-06,
      "loss": 0.0409,
      "step": 8333
    },
    {
      "epoch": 0.6476530929437364,
      "grad_norm": 0.43147462606430054,
      "learning_rate": 6.761734535281319e-06,
      "loss": 0.1457,
      "step": 8334
    },
    {
      "epoch": 0.6477308050979174,
      "grad_norm": 0.41588374972343445,
      "learning_rate": 6.761345974510414e-06,
      "loss": 0.2448,
      "step": 8335
    },
    {
      "epoch": 0.6478085172520982,
      "grad_norm": 0.17920374870300293,
      "learning_rate": 6.7609574137395095e-06,
      "loss": 0.0374,
      "step": 8336
    },
    {
      "epoch": 0.6478862294062792,
      "grad_norm": 0.45021429657936096,
      "learning_rate": 6.760568852968605e-06,
      "loss": 0.3866,
      "step": 8337
    },
    {
      "epoch": 0.6479639415604601,
      "grad_norm": 0.25878670811653137,
      "learning_rate": 6.7601802921977e-06,
      "loss": 0.1168,
      "step": 8338
    },
    {
      "epoch": 0.648041653714641,
      "grad_norm": 0.1604640781879425,
      "learning_rate": 6.759791731426796e-06,
      "loss": 0.056,
      "step": 8339
    },
    {
      "epoch": 0.6481193658688219,
      "grad_norm": 0.31896302103996277,
      "learning_rate": 6.759403170655892e-06,
      "loss": 0.5416,
      "step": 8340
    },
    {
      "epoch": 0.6481970780230027,
      "grad_norm": 0.4365377128124237,
      "learning_rate": 6.759014609884986e-06,
      "loss": 0.0884,
      "step": 8341
    },
    {
      "epoch": 0.6482747901771837,
      "grad_norm": 0.36226871609687805,
      "learning_rate": 6.758626049114082e-06,
      "loss": 0.1042,
      "step": 8342
    },
    {
      "epoch": 0.6483525023313647,
      "grad_norm": 0.21967847645282745,
      "learning_rate": 6.7582374883431775e-06,
      "loss": 0.0919,
      "step": 8343
    },
    {
      "epoch": 0.6484302144855455,
      "grad_norm": 0.16195513308048248,
      "learning_rate": 6.7578489275722724e-06,
      "loss": 0.0443,
      "step": 8344
    },
    {
      "epoch": 0.6485079266397265,
      "grad_norm": 0.12223165482282639,
      "learning_rate": 6.757460366801368e-06,
      "loss": 0.0296,
      "step": 8345
    },
    {
      "epoch": 0.6485856387939074,
      "grad_norm": 0.5471470355987549,
      "learning_rate": 6.757071806030464e-06,
      "loss": 0.1373,
      "step": 8346
    },
    {
      "epoch": 0.6486633509480882,
      "grad_norm": 0.3393189311027527,
      "learning_rate": 6.756683245259559e-06,
      "loss": 0.237,
      "step": 8347
    },
    {
      "epoch": 0.6487410631022692,
      "grad_norm": 0.31381291151046753,
      "learning_rate": 6.756294684488655e-06,
      "loss": 0.0996,
      "step": 8348
    },
    {
      "epoch": 0.6488187752564502,
      "grad_norm": 1.0505695343017578,
      "learning_rate": 6.755906123717751e-06,
      "loss": 0.2708,
      "step": 8349
    },
    {
      "epoch": 0.648896487410631,
      "grad_norm": 0.3838154971599579,
      "learning_rate": 6.755517562946845e-06,
      "loss": 0.094,
      "step": 8350
    },
    {
      "epoch": 0.648974199564812,
      "grad_norm": 2.0329301357269287,
      "learning_rate": 6.7551290021759405e-06,
      "loss": 0.6716,
      "step": 8351
    },
    {
      "epoch": 0.6490519117189929,
      "grad_norm": 0.6572142839431763,
      "learning_rate": 6.754740441405036e-06,
      "loss": 0.2983,
      "step": 8352
    },
    {
      "epoch": 0.6491296238731737,
      "grad_norm": 0.09588268399238586,
      "learning_rate": 6.754351880634131e-06,
      "loss": 0.0284,
      "step": 8353
    },
    {
      "epoch": 0.6492073360273547,
      "grad_norm": 0.3325420022010803,
      "learning_rate": 6.753963319863227e-06,
      "loss": 0.1927,
      "step": 8354
    },
    {
      "epoch": 0.6492850481815355,
      "grad_norm": 0.5361099243164062,
      "learning_rate": 6.753574759092323e-06,
      "loss": 0.3356,
      "step": 8355
    },
    {
      "epoch": 0.6493627603357165,
      "grad_norm": 0.3531656861305237,
      "learning_rate": 6.753186198321418e-06,
      "loss": 0.2337,
      "step": 8356
    },
    {
      "epoch": 0.6494404724898974,
      "grad_norm": 0.7577845454216003,
      "learning_rate": 6.7527976375505136e-06,
      "loss": 0.2297,
      "step": 8357
    },
    {
      "epoch": 0.6495181846440783,
      "grad_norm": 0.5410721302032471,
      "learning_rate": 6.752409076779609e-06,
      "loss": 0.1235,
      "step": 8358
    },
    {
      "epoch": 0.6495958967982592,
      "grad_norm": 0.19249440729618073,
      "learning_rate": 6.7520205160087035e-06,
      "loss": 0.0409,
      "step": 8359
    },
    {
      "epoch": 0.6496736089524402,
      "grad_norm": 0.8502791523933411,
      "learning_rate": 6.751631955237799e-06,
      "loss": 0.4126,
      "step": 8360
    },
    {
      "epoch": 0.649751321106621,
      "grad_norm": 0.373963862657547,
      "learning_rate": 6.751243394466895e-06,
      "loss": 0.5394,
      "step": 8361
    },
    {
      "epoch": 0.649829033260802,
      "grad_norm": 0.25622686743736267,
      "learning_rate": 6.750854833695991e-06,
      "loss": 0.1491,
      "step": 8362
    },
    {
      "epoch": 0.649906745414983,
      "grad_norm": 0.4346385598182678,
      "learning_rate": 6.750466272925086e-06,
      "loss": 0.1834,
      "step": 8363
    },
    {
      "epoch": 0.6499844575691638,
      "grad_norm": 1.7715628147125244,
      "learning_rate": 6.750077712154182e-06,
      "loss": 0.3763,
      "step": 8364
    },
    {
      "epoch": 0.6500621697233447,
      "grad_norm": 0.2208007425069809,
      "learning_rate": 6.749689151383277e-06,
      "loss": 0.0678,
      "step": 8365
    },
    {
      "epoch": 0.6501398818775257,
      "grad_norm": 0.2055829018354416,
      "learning_rate": 6.749300590612372e-06,
      "loss": 0.083,
      "step": 8366
    },
    {
      "epoch": 0.6502175940317065,
      "grad_norm": 0.2392108142375946,
      "learning_rate": 6.748912029841468e-06,
      "loss": 0.0829,
      "step": 8367
    },
    {
      "epoch": 0.6502953061858875,
      "grad_norm": 0.28675007820129395,
      "learning_rate": 6.748523469070564e-06,
      "loss": 0.057,
      "step": 8368
    },
    {
      "epoch": 0.6503730183400683,
      "grad_norm": 1.2617554664611816,
      "learning_rate": 6.748134908299658e-06,
      "loss": 0.5942,
      "step": 8369
    },
    {
      "epoch": 0.6504507304942493,
      "grad_norm": 1.4360870122909546,
      "learning_rate": 6.747746347528754e-06,
      "loss": 0.3319,
      "step": 8370
    },
    {
      "epoch": 0.6505284426484302,
      "grad_norm": 0.16848993301391602,
      "learning_rate": 6.74735778675785e-06,
      "loss": 0.136,
      "step": 8371
    },
    {
      "epoch": 0.6506061548026111,
      "grad_norm": 0.500346302986145,
      "learning_rate": 6.746969225986945e-06,
      "loss": 0.3655,
      "step": 8372
    },
    {
      "epoch": 0.650683866956792,
      "grad_norm": 0.89686518907547,
      "learning_rate": 6.74658066521604e-06,
      "loss": 0.5379,
      "step": 8373
    },
    {
      "epoch": 0.650761579110973,
      "grad_norm": 0.29146048426628113,
      "learning_rate": 6.746192104445136e-06,
      "loss": 0.1337,
      "step": 8374
    },
    {
      "epoch": 0.6508392912651538,
      "grad_norm": 1.8374873399734497,
      "learning_rate": 6.745803543674231e-06,
      "loss": 0.3743,
      "step": 8375
    },
    {
      "epoch": 0.6509170034193348,
      "grad_norm": 0.48546063899993896,
      "learning_rate": 6.745414982903327e-06,
      "loss": 0.187,
      "step": 8376
    },
    {
      "epoch": 0.6509947155735157,
      "grad_norm": 0.4228585362434387,
      "learning_rate": 6.745026422132423e-06,
      "loss": 0.2435,
      "step": 8377
    },
    {
      "epoch": 0.6510724277276966,
      "grad_norm": 0.2361723780632019,
      "learning_rate": 6.744637861361517e-06,
      "loss": 0.1179,
      "step": 8378
    },
    {
      "epoch": 0.6511501398818775,
      "grad_norm": 0.2707630395889282,
      "learning_rate": 6.744249300590613e-06,
      "loss": 0.0621,
      "step": 8379
    },
    {
      "epoch": 0.6512278520360585,
      "grad_norm": 0.2830730080604553,
      "learning_rate": 6.7438607398197084e-06,
      "loss": 0.18,
      "step": 8380
    },
    {
      "epoch": 0.6513055641902393,
      "grad_norm": 0.5294950604438782,
      "learning_rate": 6.743472179048803e-06,
      "loss": 0.0956,
      "step": 8381
    },
    {
      "epoch": 0.6513832763444203,
      "grad_norm": 0.988620936870575,
      "learning_rate": 6.743083618277899e-06,
      "loss": 0.2433,
      "step": 8382
    },
    {
      "epoch": 0.6514609884986012,
      "grad_norm": 0.5385313630104065,
      "learning_rate": 6.742695057506995e-06,
      "loss": 0.2717,
      "step": 8383
    },
    {
      "epoch": 0.6515387006527821,
      "grad_norm": 0.17813703417778015,
      "learning_rate": 6.74230649673609e-06,
      "loss": 0.0606,
      "step": 8384
    },
    {
      "epoch": 0.651616412806963,
      "grad_norm": 0.20849932730197906,
      "learning_rate": 6.741917935965186e-06,
      "loss": 0.0915,
      "step": 8385
    },
    {
      "epoch": 0.6516941249611439,
      "grad_norm": 0.09358277916908264,
      "learning_rate": 6.7415293751942815e-06,
      "loss": 0.0595,
      "step": 8386
    },
    {
      "epoch": 0.6517718371153248,
      "grad_norm": 0.3007424771785736,
      "learning_rate": 6.741140814423376e-06,
      "loss": 0.2538,
      "step": 8387
    },
    {
      "epoch": 0.6518495492695058,
      "grad_norm": 0.44812995195388794,
      "learning_rate": 6.740752253652471e-06,
      "loss": 0.1064,
      "step": 8388
    },
    {
      "epoch": 0.6519272614236866,
      "grad_norm": 0.11564610153436661,
      "learning_rate": 6.740363692881567e-06,
      "loss": 0.0559,
      "step": 8389
    },
    {
      "epoch": 0.6520049735778676,
      "grad_norm": 0.2891867458820343,
      "learning_rate": 6.739975132110662e-06,
      "loss": 0.1893,
      "step": 8390
    },
    {
      "epoch": 0.6520826857320485,
      "grad_norm": 0.2983219027519226,
      "learning_rate": 6.739586571339758e-06,
      "loss": 0.0848,
      "step": 8391
    },
    {
      "epoch": 0.6521603978862294,
      "grad_norm": 0.1973293125629425,
      "learning_rate": 6.739198010568854e-06,
      "loss": 0.1805,
      "step": 8392
    },
    {
      "epoch": 0.6522381100404103,
      "grad_norm": 0.2720204293727875,
      "learning_rate": 6.7388094497979495e-06,
      "loss": 0.0826,
      "step": 8393
    },
    {
      "epoch": 0.6523158221945913,
      "grad_norm": 0.33466726541519165,
      "learning_rate": 6.7384208890270445e-06,
      "loss": 0.2798,
      "step": 8394
    },
    {
      "epoch": 0.6523935343487721,
      "grad_norm": 0.3708769977092743,
      "learning_rate": 6.73803232825614e-06,
      "loss": 0.2501,
      "step": 8395
    },
    {
      "epoch": 0.6524712465029531,
      "grad_norm": 1.4131896495819092,
      "learning_rate": 6.737643767485236e-06,
      "loss": 0.665,
      "step": 8396
    },
    {
      "epoch": 0.652548958657134,
      "grad_norm": 0.4262850880622864,
      "learning_rate": 6.73725520671433e-06,
      "loss": 0.2412,
      "step": 8397
    },
    {
      "epoch": 0.6526266708113149,
      "grad_norm": 0.6692748069763184,
      "learning_rate": 6.736866645943426e-06,
      "loss": 0.2944,
      "step": 8398
    },
    {
      "epoch": 0.6527043829654958,
      "grad_norm": 0.5156620740890503,
      "learning_rate": 6.736478085172522e-06,
      "loss": 0.1982,
      "step": 8399
    },
    {
      "epoch": 0.6527820951196767,
      "grad_norm": 0.40482351183891296,
      "learning_rate": 6.736089524401617e-06,
      "loss": 0.1479,
      "step": 8400
    },
    {
      "epoch": 0.6528598072738576,
      "grad_norm": 0.44498056173324585,
      "learning_rate": 6.7357009636307125e-06,
      "loss": 0.2528,
      "step": 8401
    },
    {
      "epoch": 0.6529375194280386,
      "grad_norm": 0.38112881779670715,
      "learning_rate": 6.735312402859808e-06,
      "loss": 0.2304,
      "step": 8402
    },
    {
      "epoch": 0.6530152315822194,
      "grad_norm": 0.12396321445703506,
      "learning_rate": 6.734923842088903e-06,
      "loss": 0.072,
      "step": 8403
    },
    {
      "epoch": 0.6530929437364004,
      "grad_norm": 0.7569522261619568,
      "learning_rate": 6.734535281317999e-06,
      "loss": 0.2423,
      "step": 8404
    },
    {
      "epoch": 0.6531706558905813,
      "grad_norm": 0.3882688879966736,
      "learning_rate": 6.734146720547095e-06,
      "loss": 0.1394,
      "step": 8405
    },
    {
      "epoch": 0.6532483680447622,
      "grad_norm": 0.4502975642681122,
      "learning_rate": 6.733758159776189e-06,
      "loss": 0.2207,
      "step": 8406
    },
    {
      "epoch": 0.6533260801989431,
      "grad_norm": 0.28364691138267517,
      "learning_rate": 6.733369599005285e-06,
      "loss": 0.041,
      "step": 8407
    },
    {
      "epoch": 0.6534037923531241,
      "grad_norm": 0.2782858610153198,
      "learning_rate": 6.7329810382343806e-06,
      "loss": 0.0862,
      "step": 8408
    },
    {
      "epoch": 0.6534815045073049,
      "grad_norm": 0.4368230104446411,
      "learning_rate": 6.7325924774634755e-06,
      "loss": 0.3563,
      "step": 8409
    },
    {
      "epoch": 0.6535592166614859,
      "grad_norm": 0.45985808968544006,
      "learning_rate": 6.732203916692571e-06,
      "loss": 0.2931,
      "step": 8410
    },
    {
      "epoch": 0.6536369288156668,
      "grad_norm": 0.13384437561035156,
      "learning_rate": 6.731815355921667e-06,
      "loss": 0.0274,
      "step": 8411
    },
    {
      "epoch": 0.6537146409698477,
      "grad_norm": 0.44472286105155945,
      "learning_rate": 6.731426795150762e-06,
      "loss": 0.083,
      "step": 8412
    },
    {
      "epoch": 0.6537923531240286,
      "grad_norm": 0.13870690762996674,
      "learning_rate": 6.731038234379858e-06,
      "loss": 0.0385,
      "step": 8413
    },
    {
      "epoch": 0.6538700652782096,
      "grad_norm": 0.3640977740287781,
      "learning_rate": 6.730649673608954e-06,
      "loss": 0.0718,
      "step": 8414
    },
    {
      "epoch": 0.6539477774323904,
      "grad_norm": 0.37487223744392395,
      "learning_rate": 6.730261112838048e-06,
      "loss": 0.2302,
      "step": 8415
    },
    {
      "epoch": 0.6540254895865714,
      "grad_norm": 0.16304725408554077,
      "learning_rate": 6.7298725520671436e-06,
      "loss": 0.0616,
      "step": 8416
    },
    {
      "epoch": 0.6541032017407522,
      "grad_norm": 0.4944838583469391,
      "learning_rate": 6.729483991296239e-06,
      "loss": 0.537,
      "step": 8417
    },
    {
      "epoch": 0.6541809138949332,
      "grad_norm": 0.28837093710899353,
      "learning_rate": 6.729095430525334e-06,
      "loss": 0.0545,
      "step": 8418
    },
    {
      "epoch": 0.6542586260491141,
      "grad_norm": 0.9908074140548706,
      "learning_rate": 6.72870686975443e-06,
      "loss": 0.3568,
      "step": 8419
    },
    {
      "epoch": 0.654336338203295,
      "grad_norm": 0.9028184413909912,
      "learning_rate": 6.728318308983526e-06,
      "loss": 0.9939,
      "step": 8420
    },
    {
      "epoch": 0.6544140503574759,
      "grad_norm": 0.3412407636642456,
      "learning_rate": 6.727929748212621e-06,
      "loss": 0.3233,
      "step": 8421
    },
    {
      "epoch": 0.6544917625116569,
      "grad_norm": 1.1127784252166748,
      "learning_rate": 6.727541187441717e-06,
      "loss": 0.153,
      "step": 8422
    },
    {
      "epoch": 0.6545694746658377,
      "grad_norm": 0.1461331993341446,
      "learning_rate": 6.7271526266708124e-06,
      "loss": 0.0247,
      "step": 8423
    },
    {
      "epoch": 0.6546471868200187,
      "grad_norm": 0.4554762542247772,
      "learning_rate": 6.726764065899908e-06,
      "loss": 0.1419,
      "step": 8424
    },
    {
      "epoch": 0.6547248989741996,
      "grad_norm": 0.5111348628997803,
      "learning_rate": 6.726375505129002e-06,
      "loss": 0.2511,
      "step": 8425
    },
    {
      "epoch": 0.6548026111283805,
      "grad_norm": 0.6961393356323242,
      "learning_rate": 6.725986944358098e-06,
      "loss": 0.3217,
      "step": 8426
    },
    {
      "epoch": 0.6548803232825614,
      "grad_norm": 0.2034188061952591,
      "learning_rate": 6.725598383587194e-06,
      "loss": 0.0267,
      "step": 8427
    },
    {
      "epoch": 0.6549580354367424,
      "grad_norm": 0.3932039141654968,
      "learning_rate": 6.725209822816289e-06,
      "loss": 0.1266,
      "step": 8428
    },
    {
      "epoch": 0.6550357475909232,
      "grad_norm": 0.46339288353919983,
      "learning_rate": 6.724821262045385e-06,
      "loss": 0.5298,
      "step": 8429
    },
    {
      "epoch": 0.6551134597451042,
      "grad_norm": 0.06115814670920372,
      "learning_rate": 6.7244327012744805e-06,
      "loss": 0.015,
      "step": 8430
    },
    {
      "epoch": 0.655191171899285,
      "grad_norm": 0.24854186177253723,
      "learning_rate": 6.7240441405035754e-06,
      "loss": 0.3473,
      "step": 8431
    },
    {
      "epoch": 0.655268884053466,
      "grad_norm": 0.29552170634269714,
      "learning_rate": 6.723655579732671e-06,
      "loss": 0.332,
      "step": 8432
    },
    {
      "epoch": 0.6553465962076469,
      "grad_norm": 0.12449148297309875,
      "learning_rate": 6.723267018961766e-06,
      "loss": 0.053,
      "step": 8433
    },
    {
      "epoch": 0.6554243083618277,
      "grad_norm": 0.20607666671276093,
      "learning_rate": 6.722878458190861e-06,
      "loss": 0.0678,
      "step": 8434
    },
    {
      "epoch": 0.6555020205160087,
      "grad_norm": 0.6509159207344055,
      "learning_rate": 6.722489897419957e-06,
      "loss": 0.2509,
      "step": 8435
    },
    {
      "epoch": 0.6555797326701897,
      "grad_norm": 0.5063977837562561,
      "learning_rate": 6.722101336649053e-06,
      "loss": 0.232,
      "step": 8436
    },
    {
      "epoch": 0.6556574448243705,
      "grad_norm": 0.8504931330680847,
      "learning_rate": 6.721712775878148e-06,
      "loss": 0.23,
      "step": 8437
    },
    {
      "epoch": 0.6557351569785514,
      "grad_norm": 0.2684851884841919,
      "learning_rate": 6.7213242151072435e-06,
      "loss": 0.0627,
      "step": 8438
    },
    {
      "epoch": 0.6558128691327324,
      "grad_norm": 0.2189171463251114,
      "learning_rate": 6.720935654336339e-06,
      "loss": 0.0998,
      "step": 8439
    },
    {
      "epoch": 0.6558905812869132,
      "grad_norm": 0.5516647100448608,
      "learning_rate": 6.720547093565433e-06,
      "loss": 0.2718,
      "step": 8440
    },
    {
      "epoch": 0.6559682934410942,
      "grad_norm": 0.5893736481666565,
      "learning_rate": 6.720158532794529e-06,
      "loss": 0.1456,
      "step": 8441
    },
    {
      "epoch": 0.6560460055952752,
      "grad_norm": 0.3728133738040924,
      "learning_rate": 6.719769972023625e-06,
      "loss": 0.413,
      "step": 8442
    },
    {
      "epoch": 0.656123717749456,
      "grad_norm": 1.1892054080963135,
      "learning_rate": 6.71938141125272e-06,
      "loss": 0.3135,
      "step": 8443
    },
    {
      "epoch": 0.656201429903637,
      "grad_norm": 0.390697181224823,
      "learning_rate": 6.718992850481816e-06,
      "loss": 0.2336,
      "step": 8444
    },
    {
      "epoch": 0.6562791420578178,
      "grad_norm": 1.4125384092330933,
      "learning_rate": 6.7186042897109115e-06,
      "loss": 0.3923,
      "step": 8445
    },
    {
      "epoch": 0.6563568542119987,
      "grad_norm": 0.23870152235031128,
      "learning_rate": 6.7182157289400064e-06,
      "loss": 0.1299,
      "step": 8446
    },
    {
      "epoch": 0.6564345663661797,
      "grad_norm": 0.17766420543193817,
      "learning_rate": 6.717827168169102e-06,
      "loss": 0.0781,
      "step": 8447
    },
    {
      "epoch": 0.6565122785203605,
      "grad_norm": 0.7221782207489014,
      "learning_rate": 6.717438607398198e-06,
      "loss": 0.5204,
      "step": 8448
    },
    {
      "epoch": 0.6565899906745415,
      "grad_norm": 0.3577917814254761,
      "learning_rate": 6.717050046627292e-06,
      "loss": 0.5325,
      "step": 8449
    },
    {
      "epoch": 0.6566677028287224,
      "grad_norm": 0.2079237997531891,
      "learning_rate": 6.716661485856388e-06,
      "loss": 0.064,
      "step": 8450
    },
    {
      "epoch": 0.6567454149829033,
      "grad_norm": 0.15025076270103455,
      "learning_rate": 6.716272925085484e-06,
      "loss": 0.0473,
      "step": 8451
    },
    {
      "epoch": 0.6568231271370842,
      "grad_norm": 0.3240734338760376,
      "learning_rate": 6.715884364314579e-06,
      "loss": 0.1198,
      "step": 8452
    },
    {
      "epoch": 0.6569008392912652,
      "grad_norm": 0.2374289482831955,
      "learning_rate": 6.7154958035436745e-06,
      "loss": 0.0895,
      "step": 8453
    },
    {
      "epoch": 0.656978551445446,
      "grad_norm": 0.48937034606933594,
      "learning_rate": 6.71510724277277e-06,
      "loss": 0.3104,
      "step": 8454
    },
    {
      "epoch": 0.657056263599627,
      "grad_norm": 0.28894415497779846,
      "learning_rate": 6.714718682001866e-06,
      "loss": 0.0223,
      "step": 8455
    },
    {
      "epoch": 0.6571339757538079,
      "grad_norm": 0.6119074821472168,
      "learning_rate": 6.714330121230961e-06,
      "loss": 0.2868,
      "step": 8456
    },
    {
      "epoch": 0.6572116879079888,
      "grad_norm": 0.4510851800441742,
      "learning_rate": 6.713941560460057e-06,
      "loss": 0.3087,
      "step": 8457
    },
    {
      "epoch": 0.6572894000621697,
      "grad_norm": 0.1528996229171753,
      "learning_rate": 6.713552999689153e-06,
      "loss": 0.0636,
      "step": 8458
    },
    {
      "epoch": 0.6573671122163507,
      "grad_norm": 0.798274040222168,
      "learning_rate": 6.713164438918247e-06,
      "loss": 0.5512,
      "step": 8459
    },
    {
      "epoch": 0.6574448243705315,
      "grad_norm": 0.6349182724952698,
      "learning_rate": 6.7127758781473425e-06,
      "loss": 0.8088,
      "step": 8460
    },
    {
      "epoch": 0.6575225365247125,
      "grad_norm": 0.6072515845298767,
      "learning_rate": 6.712387317376438e-06,
      "loss": 0.4559,
      "step": 8461
    },
    {
      "epoch": 0.6576002486788933,
      "grad_norm": 0.5394991636276245,
      "learning_rate": 6.711998756605533e-06,
      "loss": 0.5544,
      "step": 8462
    },
    {
      "epoch": 0.6576779608330743,
      "grad_norm": 0.2703033685684204,
      "learning_rate": 6.711610195834629e-06,
      "loss": 0.0487,
      "step": 8463
    },
    {
      "epoch": 0.6577556729872552,
      "grad_norm": 0.34655988216400146,
      "learning_rate": 6.711221635063725e-06,
      "loss": 0.0659,
      "step": 8464
    },
    {
      "epoch": 0.6578333851414361,
      "grad_norm": 0.18791857361793518,
      "learning_rate": 6.71083307429282e-06,
      "loss": 0.0237,
      "step": 8465
    },
    {
      "epoch": 0.657911097295617,
      "grad_norm": 0.5226200819015503,
      "learning_rate": 6.710444513521916e-06,
      "loss": 0.2086,
      "step": 8466
    },
    {
      "epoch": 0.657988809449798,
      "grad_norm": 0.23053722083568573,
      "learning_rate": 6.710055952751011e-06,
      "loss": 0.0366,
      "step": 8467
    },
    {
      "epoch": 0.6580665216039788,
      "grad_norm": 0.3769541382789612,
      "learning_rate": 6.7096673919801055e-06,
      "loss": 0.2862,
      "step": 8468
    },
    {
      "epoch": 0.6581442337581598,
      "grad_norm": 0.5667997598648071,
      "learning_rate": 6.709278831209201e-06,
      "loss": 0.2308,
      "step": 8469
    },
    {
      "epoch": 0.6582219459123407,
      "grad_norm": 0.1490623652935028,
      "learning_rate": 6.708890270438297e-06,
      "loss": 0.0396,
      "step": 8470
    },
    {
      "epoch": 0.6582996580665216,
      "grad_norm": 0.2993822693824768,
      "learning_rate": 6.708501709667392e-06,
      "loss": 0.1331,
      "step": 8471
    },
    {
      "epoch": 0.6583773702207025,
      "grad_norm": 0.4024132490158081,
      "learning_rate": 6.708113148896488e-06,
      "loss": 0.0987,
      "step": 8472
    },
    {
      "epoch": 0.6584550823748835,
      "grad_norm": 0.6402744650840759,
      "learning_rate": 6.707724588125584e-06,
      "loss": 0.4552,
      "step": 8473
    },
    {
      "epoch": 0.6585327945290643,
      "grad_norm": 0.21117530763149261,
      "learning_rate": 6.707336027354679e-06,
      "loss": 0.0875,
      "step": 8474
    },
    {
      "epoch": 0.6586105066832453,
      "grad_norm": 0.49744099378585815,
      "learning_rate": 6.706947466583774e-06,
      "loss": 0.3107,
      "step": 8475
    },
    {
      "epoch": 0.6586882188374261,
      "grad_norm": 0.21524158120155334,
      "learning_rate": 6.70655890581287e-06,
      "loss": 0.0299,
      "step": 8476
    },
    {
      "epoch": 0.6587659309916071,
      "grad_norm": 0.6132307648658752,
      "learning_rate": 6.706170345041964e-06,
      "loss": 0.3246,
      "step": 8477
    },
    {
      "epoch": 0.658843643145788,
      "grad_norm": 0.09896270185709,
      "learning_rate": 6.70578178427106e-06,
      "loss": 0.0258,
      "step": 8478
    },
    {
      "epoch": 0.6589213552999689,
      "grad_norm": 1.4159945249557495,
      "learning_rate": 6.705393223500156e-06,
      "loss": 0.6736,
      "step": 8479
    },
    {
      "epoch": 0.6589990674541498,
      "grad_norm": 0.20635442435741425,
      "learning_rate": 6.705004662729251e-06,
      "loss": 0.0661,
      "step": 8480
    },
    {
      "epoch": 0.6590767796083308,
      "grad_norm": 0.2703026235103607,
      "learning_rate": 6.704616101958347e-06,
      "loss": 0.121,
      "step": 8481
    },
    {
      "epoch": 0.6591544917625116,
      "grad_norm": 0.44920626282691956,
      "learning_rate": 6.7042275411874424e-06,
      "loss": 0.1772,
      "step": 8482
    },
    {
      "epoch": 0.6592322039166926,
      "grad_norm": 0.19594359397888184,
      "learning_rate": 6.703838980416538e-06,
      "loss": 0.1428,
      "step": 8483
    },
    {
      "epoch": 0.6593099160708735,
      "grad_norm": 0.20213823020458221,
      "learning_rate": 6.703450419645633e-06,
      "loss": 0.0256,
      "step": 8484
    },
    {
      "epoch": 0.6593876282250544,
      "grad_norm": 0.2895689904689789,
      "learning_rate": 6.703061858874729e-06,
      "loss": 0.1035,
      "step": 8485
    },
    {
      "epoch": 0.6594653403792353,
      "grad_norm": 0.4477364122867584,
      "learning_rate": 6.702673298103825e-06,
      "loss": 0.2676,
      "step": 8486
    },
    {
      "epoch": 0.6595430525334163,
      "grad_norm": 0.37587276101112366,
      "learning_rate": 6.702284737332919e-06,
      "loss": 0.1951,
      "step": 8487
    },
    {
      "epoch": 0.6596207646875971,
      "grad_norm": 0.23167820274829865,
      "learning_rate": 6.701896176562015e-06,
      "loss": 0.0148,
      "step": 8488
    },
    {
      "epoch": 0.6596984768417781,
      "grad_norm": 0.4147947132587433,
      "learning_rate": 6.7015076157911105e-06,
      "loss": 0.0917,
      "step": 8489
    },
    {
      "epoch": 0.659776188995959,
      "grad_norm": 0.1597760170698166,
      "learning_rate": 6.701119055020205e-06,
      "loss": 0.0982,
      "step": 8490
    },
    {
      "epoch": 0.6598539011501399,
      "grad_norm": 0.8462361097335815,
      "learning_rate": 6.700730494249301e-06,
      "loss": 0.429,
      "step": 8491
    },
    {
      "epoch": 0.6599316133043208,
      "grad_norm": 0.43096062541007996,
      "learning_rate": 6.700341933478397e-06,
      "loss": 0.1274,
      "step": 8492
    },
    {
      "epoch": 0.6600093254585017,
      "grad_norm": 0.33324235677719116,
      "learning_rate": 6.699953372707492e-06,
      "loss": 0.0458,
      "step": 8493
    },
    {
      "epoch": 0.6600870376126826,
      "grad_norm": 0.4108831584453583,
      "learning_rate": 6.699564811936588e-06,
      "loss": 0.3371,
      "step": 8494
    },
    {
      "epoch": 0.6601647497668636,
      "grad_norm": 0.2905310392379761,
      "learning_rate": 6.6991762511656836e-06,
      "loss": 0.035,
      "step": 8495
    },
    {
      "epoch": 0.6602424619210444,
      "grad_norm": 0.3546546697616577,
      "learning_rate": 6.698787690394778e-06,
      "loss": 0.1043,
      "step": 8496
    },
    {
      "epoch": 0.6603201740752254,
      "grad_norm": 0.4963058829307556,
      "learning_rate": 6.6983991296238735e-06,
      "loss": 0.0517,
      "step": 8497
    },
    {
      "epoch": 0.6603978862294063,
      "grad_norm": 0.5917105674743652,
      "learning_rate": 6.698010568852969e-06,
      "loss": 0.1572,
      "step": 8498
    },
    {
      "epoch": 0.6604755983835872,
      "grad_norm": 0.5605719685554504,
      "learning_rate": 6.697622008082064e-06,
      "loss": 0.2745,
      "step": 8499
    },
    {
      "epoch": 0.6605533105377681,
      "grad_norm": 0.19041503965854645,
      "learning_rate": 6.69723344731116e-06,
      "loss": 0.0795,
      "step": 8500
    },
    {
      "epoch": 0.6606310226919491,
      "grad_norm": 0.165242999792099,
      "learning_rate": 6.696844886540256e-06,
      "loss": 0.0653,
      "step": 8501
    },
    {
      "epoch": 0.6607087348461299,
      "grad_norm": 0.15202587842941284,
      "learning_rate": 6.696456325769351e-06,
      "loss": 0.101,
      "step": 8502
    },
    {
      "epoch": 0.6607864470003109,
      "grad_norm": 1.704970359802246,
      "learning_rate": 6.6960677649984465e-06,
      "loss": 0.2944,
      "step": 8503
    },
    {
      "epoch": 0.6608641591544918,
      "grad_norm": 0.7400572299957275,
      "learning_rate": 6.695679204227542e-06,
      "loss": 0.2273,
      "step": 8504
    },
    {
      "epoch": 0.6609418713086727,
      "grad_norm": 0.35993877053260803,
      "learning_rate": 6.6952906434566364e-06,
      "loss": 0.108,
      "step": 8505
    },
    {
      "epoch": 0.6610195834628536,
      "grad_norm": 0.7413418292999268,
      "learning_rate": 6.694902082685732e-06,
      "loss": 0.8611,
      "step": 8506
    },
    {
      "epoch": 0.6610972956170345,
      "grad_norm": 0.3529401123523712,
      "learning_rate": 6.694513521914828e-06,
      "loss": 0.2069,
      "step": 8507
    },
    {
      "epoch": 0.6611750077712154,
      "grad_norm": 0.05825286731123924,
      "learning_rate": 6.694124961143923e-06,
      "loss": 0.0161,
      "step": 8508
    },
    {
      "epoch": 0.6612527199253964,
      "grad_norm": 0.21046356856822968,
      "learning_rate": 6.693736400373019e-06,
      "loss": 0.0998,
      "step": 8509
    },
    {
      "epoch": 0.6613304320795772,
      "grad_norm": 0.46867668628692627,
      "learning_rate": 6.6933478396021146e-06,
      "loss": 0.2633,
      "step": 8510
    },
    {
      "epoch": 0.6614081442337582,
      "grad_norm": 0.8248688578605652,
      "learning_rate": 6.6929592788312095e-06,
      "loss": 0.9797,
      "step": 8511
    },
    {
      "epoch": 0.6614858563879391,
      "grad_norm": 0.1968010514974594,
      "learning_rate": 6.692570718060305e-06,
      "loss": 0.0689,
      "step": 8512
    },
    {
      "epoch": 0.66156356854212,
      "grad_norm": 0.046438802033662796,
      "learning_rate": 6.692182157289401e-06,
      "loss": 0.0077,
      "step": 8513
    },
    {
      "epoch": 0.6616412806963009,
      "grad_norm": 0.337048202753067,
      "learning_rate": 6.691793596518497e-06,
      "loss": 0.1029,
      "step": 8514
    },
    {
      "epoch": 0.6617189928504819,
      "grad_norm": 0.17828136682510376,
      "learning_rate": 6.691405035747591e-06,
      "loss": 0.0849,
      "step": 8515
    },
    {
      "epoch": 0.6617967050046627,
      "grad_norm": 0.5860591530799866,
      "learning_rate": 6.691016474976687e-06,
      "loss": 0.7166,
      "step": 8516
    },
    {
      "epoch": 0.6618744171588437,
      "grad_norm": 0.384976327419281,
      "learning_rate": 6.690627914205783e-06,
      "loss": 0.1865,
      "step": 8517
    },
    {
      "epoch": 0.6619521293130246,
      "grad_norm": 0.488230437040329,
      "learning_rate": 6.6902393534348776e-06,
      "loss": 0.9664,
      "step": 8518
    },
    {
      "epoch": 0.6620298414672054,
      "grad_norm": 0.06801719963550568,
      "learning_rate": 6.689850792663973e-06,
      "loss": 0.0161,
      "step": 8519
    },
    {
      "epoch": 0.6621075536213864,
      "grad_norm": 0.6754150986671448,
      "learning_rate": 6.689462231893069e-06,
      "loss": 0.1327,
      "step": 8520
    },
    {
      "epoch": 0.6621852657755672,
      "grad_norm": 0.23341645300388336,
      "learning_rate": 6.689073671122164e-06,
      "loss": 0.1161,
      "step": 8521
    },
    {
      "epoch": 0.6622629779297482,
      "grad_norm": 0.5607475638389587,
      "learning_rate": 6.68868511035126e-06,
      "loss": 0.0964,
      "step": 8522
    },
    {
      "epoch": 0.6623406900839292,
      "grad_norm": 0.33479344844818115,
      "learning_rate": 6.688296549580356e-06,
      "loss": 0.0695,
      "step": 8523
    },
    {
      "epoch": 0.66241840223811,
      "grad_norm": 0.5109893679618835,
      "learning_rate": 6.68790798880945e-06,
      "loss": 0.1628,
      "step": 8524
    },
    {
      "epoch": 0.662496114392291,
      "grad_norm": 0.5240286588668823,
      "learning_rate": 6.687519428038546e-06,
      "loss": 0.1452,
      "step": 8525
    },
    {
      "epoch": 0.6625738265464719,
      "grad_norm": 0.402281790971756,
      "learning_rate": 6.687130867267641e-06,
      "loss": 0.0906,
      "step": 8526
    },
    {
      "epoch": 0.6626515387006527,
      "grad_norm": 0.5609902739524841,
      "learning_rate": 6.686742306496736e-06,
      "loss": 0.7034,
      "step": 8527
    },
    {
      "epoch": 0.6627292508548337,
      "grad_norm": 0.45656004548072815,
      "learning_rate": 6.686353745725832e-06,
      "loss": 0.1144,
      "step": 8528
    },
    {
      "epoch": 0.6628069630090146,
      "grad_norm": 0.54449862241745,
      "learning_rate": 6.685965184954928e-06,
      "loss": 0.1524,
      "step": 8529
    },
    {
      "epoch": 0.6628846751631955,
      "grad_norm": 0.20179016888141632,
      "learning_rate": 6.685576624184023e-06,
      "loss": 0.0536,
      "step": 8530
    },
    {
      "epoch": 0.6629623873173764,
      "grad_norm": 0.24644644558429718,
      "learning_rate": 6.685188063413119e-06,
      "loss": 0.0668,
      "step": 8531
    },
    {
      "epoch": 0.6630400994715574,
      "grad_norm": 0.2366083860397339,
      "learning_rate": 6.6847995026422145e-06,
      "loss": 0.1922,
      "step": 8532
    },
    {
      "epoch": 0.6631178116257382,
      "grad_norm": 1.4308393001556396,
      "learning_rate": 6.684410941871309e-06,
      "loss": 0.5398,
      "step": 8533
    },
    {
      "epoch": 0.6631955237799192,
      "grad_norm": 0.6049496531486511,
      "learning_rate": 6.684022381100404e-06,
      "loss": 0.1603,
      "step": 8534
    },
    {
      "epoch": 0.6632732359341001,
      "grad_norm": 0.2155931293964386,
      "learning_rate": 6.6836338203295e-06,
      "loss": 0.1126,
      "step": 8535
    },
    {
      "epoch": 0.663350948088281,
      "grad_norm": 0.7438396215438843,
      "learning_rate": 6.683245259558595e-06,
      "loss": 0.2524,
      "step": 8536
    },
    {
      "epoch": 0.6634286602424619,
      "grad_norm": 0.5867747068405151,
      "learning_rate": 6.682856698787691e-06,
      "loss": 0.2633,
      "step": 8537
    },
    {
      "epoch": 0.6635063723966428,
      "grad_norm": 0.29091110825538635,
      "learning_rate": 6.682468138016787e-06,
      "loss": 0.1309,
      "step": 8538
    },
    {
      "epoch": 0.6635840845508237,
      "grad_norm": 1.5760490894317627,
      "learning_rate": 6.682079577245882e-06,
      "loss": 0.3407,
      "step": 8539
    },
    {
      "epoch": 0.6636617967050047,
      "grad_norm": 0.16777303814888,
      "learning_rate": 6.6816910164749775e-06,
      "loss": 0.0545,
      "step": 8540
    },
    {
      "epoch": 0.6637395088591855,
      "grad_norm": 0.29650697112083435,
      "learning_rate": 6.681302455704073e-06,
      "loss": 0.0233,
      "step": 8541
    },
    {
      "epoch": 0.6638172210133665,
      "grad_norm": 0.5041741728782654,
      "learning_rate": 6.680913894933167e-06,
      "loss": 0.1043,
      "step": 8542
    },
    {
      "epoch": 0.6638949331675474,
      "grad_norm": 0.23338676989078522,
      "learning_rate": 6.680525334162263e-06,
      "loss": 0.0134,
      "step": 8543
    },
    {
      "epoch": 0.6639726453217283,
      "grad_norm": 0.40262648463249207,
      "learning_rate": 6.680136773391359e-06,
      "loss": 0.148,
      "step": 8544
    },
    {
      "epoch": 0.6640503574759092,
      "grad_norm": 0.49000996351242065,
      "learning_rate": 6.679748212620455e-06,
      "loss": 0.1735,
      "step": 8545
    },
    {
      "epoch": 0.6641280696300902,
      "grad_norm": 0.5753723382949829,
      "learning_rate": 6.67935965184955e-06,
      "loss": 0.2267,
      "step": 8546
    },
    {
      "epoch": 0.664205781784271,
      "grad_norm": 0.45770782232284546,
      "learning_rate": 6.6789710910786455e-06,
      "loss": 0.1032,
      "step": 8547
    },
    {
      "epoch": 0.664283493938452,
      "grad_norm": 0.7324761748313904,
      "learning_rate": 6.678582530307741e-06,
      "loss": 0.2863,
      "step": 8548
    },
    {
      "epoch": 0.6643612060926329,
      "grad_norm": 0.21336044371128082,
      "learning_rate": 6.678193969536836e-06,
      "loss": 0.0908,
      "step": 8549
    },
    {
      "epoch": 0.6644389182468138,
      "grad_norm": 0.4035011827945709,
      "learning_rate": 6.677805408765932e-06,
      "loss": 0.2075,
      "step": 8550
    },
    {
      "epoch": 0.6645166304009947,
      "grad_norm": 0.05700848624110222,
      "learning_rate": 6.677416847995028e-06,
      "loss": 0.0071,
      "step": 8551
    },
    {
      "epoch": 0.6645943425551756,
      "grad_norm": 0.3931941092014313,
      "learning_rate": 6.677028287224122e-06,
      "loss": 0.1033,
      "step": 8552
    },
    {
      "epoch": 0.6646720547093565,
      "grad_norm": 0.4759640097618103,
      "learning_rate": 6.676639726453218e-06,
      "loss": 0.0988,
      "step": 8553
    },
    {
      "epoch": 0.6647497668635375,
      "grad_norm": 0.3460395932197571,
      "learning_rate": 6.6762511656823135e-06,
      "loss": 0.0697,
      "step": 8554
    },
    {
      "epoch": 0.6648274790177183,
      "grad_norm": 0.8892078995704651,
      "learning_rate": 6.6758626049114085e-06,
      "loss": 0.3884,
      "step": 8555
    },
    {
      "epoch": 0.6649051911718993,
      "grad_norm": 0.38519325852394104,
      "learning_rate": 6.675474044140504e-06,
      "loss": 0.1211,
      "step": 8556
    },
    {
      "epoch": 0.6649829033260802,
      "grad_norm": 0.36411142349243164,
      "learning_rate": 6.6750854833696e-06,
      "loss": 0.2891,
      "step": 8557
    },
    {
      "epoch": 0.6650606154802611,
      "grad_norm": 0.3763251006603241,
      "learning_rate": 6.674696922598695e-06,
      "loss": 0.0598,
      "step": 8558
    },
    {
      "epoch": 0.665138327634442,
      "grad_norm": 0.7448155879974365,
      "learning_rate": 6.67430836182779e-06,
      "loss": 0.1294,
      "step": 8559
    },
    {
      "epoch": 0.665216039788623,
      "grad_norm": 0.37321674823760986,
      "learning_rate": 6.673919801056886e-06,
      "loss": 0.2397,
      "step": 8560
    },
    {
      "epoch": 0.6652937519428038,
      "grad_norm": 0.3451182246208191,
      "learning_rate": 6.673531240285981e-06,
      "loss": 0.1462,
      "step": 8561
    },
    {
      "epoch": 0.6653714640969848,
      "grad_norm": 0.4907148778438568,
      "learning_rate": 6.6731426795150765e-06,
      "loss": 0.2466,
      "step": 8562
    },
    {
      "epoch": 0.6654491762511657,
      "grad_norm": 0.6267277598381042,
      "learning_rate": 6.672754118744172e-06,
      "loss": 0.6934,
      "step": 8563
    },
    {
      "epoch": 0.6655268884053466,
      "grad_norm": 0.2340271919965744,
      "learning_rate": 6.672365557973267e-06,
      "loss": 0.0442,
      "step": 8564
    },
    {
      "epoch": 0.6656046005595275,
      "grad_norm": 0.47815626859664917,
      "learning_rate": 6.671976997202363e-06,
      "loss": 0.286,
      "step": 8565
    },
    {
      "epoch": 0.6656823127137085,
      "grad_norm": 0.22917059063911438,
      "learning_rate": 6.671588436431459e-06,
      "loss": 0.0537,
      "step": 8566
    },
    {
      "epoch": 0.6657600248678893,
      "grad_norm": 0.17437930405139923,
      "learning_rate": 6.671199875660553e-06,
      "loss": 0.0632,
      "step": 8567
    },
    {
      "epoch": 0.6658377370220703,
      "grad_norm": 0.5250449776649475,
      "learning_rate": 6.670811314889649e-06,
      "loss": 0.3217,
      "step": 8568
    },
    {
      "epoch": 0.6659154491762511,
      "grad_norm": 0.5285605788230896,
      "learning_rate": 6.6704227541187446e-06,
      "loss": 0.2475,
      "step": 8569
    },
    {
      "epoch": 0.6659931613304321,
      "grad_norm": 0.3642747700214386,
      "learning_rate": 6.6700341933478395e-06,
      "loss": 0.1234,
      "step": 8570
    },
    {
      "epoch": 0.666070873484613,
      "grad_norm": 0.755668580532074,
      "learning_rate": 6.669645632576935e-06,
      "loss": 0.2862,
      "step": 8571
    },
    {
      "epoch": 0.6661485856387939,
      "grad_norm": 0.5545519590377808,
      "learning_rate": 6.669257071806031e-06,
      "loss": 0.3706,
      "step": 8572
    },
    {
      "epoch": 0.6662262977929748,
      "grad_norm": 0.19212545454502106,
      "learning_rate": 6.668868511035126e-06,
      "loss": 0.0399,
      "step": 8573
    },
    {
      "epoch": 0.6663040099471558,
      "grad_norm": 0.8244327306747437,
      "learning_rate": 6.668479950264222e-06,
      "loss": 0.2577,
      "step": 8574
    },
    {
      "epoch": 0.6663817221013366,
      "grad_norm": 0.4312945306301117,
      "learning_rate": 6.668091389493318e-06,
      "loss": 0.0544,
      "step": 8575
    },
    {
      "epoch": 0.6664594342555176,
      "grad_norm": 0.4193304777145386,
      "learning_rate": 6.6677028287224134e-06,
      "loss": 0.2916,
      "step": 8576
    },
    {
      "epoch": 0.6665371464096985,
      "grad_norm": 0.3433742821216583,
      "learning_rate": 6.6673142679515076e-06,
      "loss": 0.1148,
      "step": 8577
    },
    {
      "epoch": 0.6666148585638794,
      "grad_norm": 0.41431522369384766,
      "learning_rate": 6.666925707180603e-06,
      "loss": 0.2225,
      "step": 8578
    },
    {
      "epoch": 0.6666925707180603,
      "grad_norm": 0.445772647857666,
      "learning_rate": 6.666537146409699e-06,
      "loss": 0.1272,
      "step": 8579
    },
    {
      "epoch": 0.6667702828722413,
      "grad_norm": 0.7777922749519348,
      "learning_rate": 6.666148585638794e-06,
      "loss": 0.5344,
      "step": 8580
    },
    {
      "epoch": 0.6668479950264221,
      "grad_norm": 0.24037989974021912,
      "learning_rate": 6.66576002486789e-06,
      "loss": 0.0978,
      "step": 8581
    },
    {
      "epoch": 0.6669257071806031,
      "grad_norm": 0.36791232228279114,
      "learning_rate": 6.665371464096986e-06,
      "loss": 0.0743,
      "step": 8582
    },
    {
      "epoch": 0.6670034193347839,
      "grad_norm": 0.5506294965744019,
      "learning_rate": 6.664982903326081e-06,
      "loss": 0.6506,
      "step": 8583
    },
    {
      "epoch": 0.6670811314889649,
      "grad_norm": 0.2993450164794922,
      "learning_rate": 6.6645943425551764e-06,
      "loss": 0.1144,
      "step": 8584
    },
    {
      "epoch": 0.6671588436431458,
      "grad_norm": 0.12212710827589035,
      "learning_rate": 6.664205781784272e-06,
      "loss": 0.0275,
      "step": 8585
    },
    {
      "epoch": 0.6672365557973267,
      "grad_norm": 0.45346006751060486,
      "learning_rate": 6.663817221013366e-06,
      "loss": 0.2523,
      "step": 8586
    },
    {
      "epoch": 0.6673142679515076,
      "grad_norm": 0.5320519804954529,
      "learning_rate": 6.663428660242462e-06,
      "loss": 0.1781,
      "step": 8587
    },
    {
      "epoch": 0.6673919801056886,
      "grad_norm": 0.39168626070022583,
      "learning_rate": 6.663040099471558e-06,
      "loss": 0.1356,
      "step": 8588
    },
    {
      "epoch": 0.6674696922598694,
      "grad_norm": 0.2944878339767456,
      "learning_rate": 6.662651538700653e-06,
      "loss": 0.1862,
      "step": 8589
    },
    {
      "epoch": 0.6675474044140504,
      "grad_norm": 0.26172760128974915,
      "learning_rate": 6.662262977929749e-06,
      "loss": 0.0693,
      "step": 8590
    },
    {
      "epoch": 0.6676251165682313,
      "grad_norm": 0.6595794558525085,
      "learning_rate": 6.6618744171588445e-06,
      "loss": 0.2402,
      "step": 8591
    },
    {
      "epoch": 0.6677028287224122,
      "grad_norm": 0.45807304978370667,
      "learning_rate": 6.661485856387939e-06,
      "loss": 0.3884,
      "step": 8592
    },
    {
      "epoch": 0.6677805408765931,
      "grad_norm": 0.5578268766403198,
      "learning_rate": 6.661097295617035e-06,
      "loss": 0.1816,
      "step": 8593
    },
    {
      "epoch": 0.6678582530307741,
      "grad_norm": 0.20803266763687134,
      "learning_rate": 6.660708734846131e-06,
      "loss": 0.0719,
      "step": 8594
    },
    {
      "epoch": 0.6679359651849549,
      "grad_norm": 0.27761879563331604,
      "learning_rate": 6.660320174075225e-06,
      "loss": 0.1028,
      "step": 8595
    },
    {
      "epoch": 0.6680136773391359,
      "grad_norm": 2.3933582305908203,
      "learning_rate": 6.659931613304321e-06,
      "loss": 0.6471,
      "step": 8596
    },
    {
      "epoch": 0.6680913894933167,
      "grad_norm": 0.18624837696552277,
      "learning_rate": 6.659543052533417e-06,
      "loss": 0.0991,
      "step": 8597
    },
    {
      "epoch": 0.6681691016474977,
      "grad_norm": 0.31665900349617004,
      "learning_rate": 6.659154491762512e-06,
      "loss": 0.605,
      "step": 8598
    },
    {
      "epoch": 0.6682468138016786,
      "grad_norm": 0.6013637781143188,
      "learning_rate": 6.6587659309916075e-06,
      "loss": 0.3659,
      "step": 8599
    },
    {
      "epoch": 0.6683245259558594,
      "grad_norm": 0.22993935644626617,
      "learning_rate": 6.658377370220703e-06,
      "loss": 0.0632,
      "step": 8600
    },
    {
      "epoch": 0.6684022381100404,
      "grad_norm": 0.3689322769641876,
      "learning_rate": 6.657988809449798e-06,
      "loss": 0.1683,
      "step": 8601
    },
    {
      "epoch": 0.6684799502642214,
      "grad_norm": 0.29378542304039,
      "learning_rate": 6.657600248678894e-06,
      "loss": 0.1313,
      "step": 8602
    },
    {
      "epoch": 0.6685576624184022,
      "grad_norm": 0.7596105933189392,
      "learning_rate": 6.65721168790799e-06,
      "loss": 0.1261,
      "step": 8603
    },
    {
      "epoch": 0.6686353745725832,
      "grad_norm": 0.1720263659954071,
      "learning_rate": 6.656823127137086e-06,
      "loss": 0.0461,
      "step": 8604
    },
    {
      "epoch": 0.6687130867267641,
      "grad_norm": 0.6229261159896851,
      "learning_rate": 6.65643456636618e-06,
      "loss": 0.1742,
      "step": 8605
    },
    {
      "epoch": 0.668790798880945,
      "grad_norm": 0.9141741394996643,
      "learning_rate": 6.6560460055952755e-06,
      "loss": 0.1296,
      "step": 8606
    },
    {
      "epoch": 0.6688685110351259,
      "grad_norm": 0.33002543449401855,
      "learning_rate": 6.655657444824371e-06,
      "loss": 0.1481,
      "step": 8607
    },
    {
      "epoch": 0.6689462231893069,
      "grad_norm": 0.30300676822662354,
      "learning_rate": 6.655268884053466e-06,
      "loss": 0.0781,
      "step": 8608
    },
    {
      "epoch": 0.6690239353434877,
      "grad_norm": 0.3392607867717743,
      "learning_rate": 6.654880323282562e-06,
      "loss": 0.1054,
      "step": 8609
    },
    {
      "epoch": 0.6691016474976687,
      "grad_norm": 0.16021308302879333,
      "learning_rate": 6.654491762511658e-06,
      "loss": 0.0628,
      "step": 8610
    },
    {
      "epoch": 0.6691793596518496,
      "grad_norm": 0.19306105375289917,
      "learning_rate": 6.654103201740753e-06,
      "loss": 0.0736,
      "step": 8611
    },
    {
      "epoch": 0.6692570718060304,
      "grad_norm": 0.1372365951538086,
      "learning_rate": 6.653714640969849e-06,
      "loss": 0.0443,
      "step": 8612
    },
    {
      "epoch": 0.6693347839602114,
      "grad_norm": 0.9167267084121704,
      "learning_rate": 6.653326080198944e-06,
      "loss": 1.1678,
      "step": 8613
    },
    {
      "epoch": 0.6694124961143922,
      "grad_norm": 0.21676893532276154,
      "learning_rate": 6.6529375194280385e-06,
      "loss": 0.0238,
      "step": 8614
    },
    {
      "epoch": 0.6694902082685732,
      "grad_norm": 0.08097857981920242,
      "learning_rate": 6.652548958657134e-06,
      "loss": 0.0199,
      "step": 8615
    },
    {
      "epoch": 0.6695679204227541,
      "grad_norm": 0.4233073890209198,
      "learning_rate": 6.65216039788623e-06,
      "loss": 0.4844,
      "step": 8616
    },
    {
      "epoch": 0.669645632576935,
      "grad_norm": 0.7509973645210266,
      "learning_rate": 6.651771837115325e-06,
      "loss": 0.2253,
      "step": 8617
    },
    {
      "epoch": 0.6697233447311159,
      "grad_norm": 0.4774684011936188,
      "learning_rate": 6.651383276344421e-06,
      "loss": 0.3423,
      "step": 8618
    },
    {
      "epoch": 0.6698010568852969,
      "grad_norm": 0.4684094190597534,
      "learning_rate": 6.650994715573517e-06,
      "loss": 0.3554,
      "step": 8619
    },
    {
      "epoch": 0.6698787690394777,
      "grad_norm": 1.0165575742721558,
      "learning_rate": 6.6506061548026116e-06,
      "loss": 0.3393,
      "step": 8620
    },
    {
      "epoch": 0.6699564811936587,
      "grad_norm": 0.6334206461906433,
      "learning_rate": 6.650217594031707e-06,
      "loss": 0.4729,
      "step": 8621
    },
    {
      "epoch": 0.6700341933478396,
      "grad_norm": 0.99448561668396,
      "learning_rate": 6.649829033260803e-06,
      "loss": 0.2029,
      "step": 8622
    },
    {
      "epoch": 0.6701119055020205,
      "grad_norm": 0.3452102541923523,
      "learning_rate": 6.649440472489897e-06,
      "loss": 0.209,
      "step": 8623
    },
    {
      "epoch": 0.6701896176562014,
      "grad_norm": 0.5836358070373535,
      "learning_rate": 6.649051911718993e-06,
      "loss": 0.3275,
      "step": 8624
    },
    {
      "epoch": 0.6702673298103824,
      "grad_norm": 0.27848565578460693,
      "learning_rate": 6.648663350948089e-06,
      "loss": 0.2067,
      "step": 8625
    },
    {
      "epoch": 0.6703450419645632,
      "grad_norm": 0.577427864074707,
      "learning_rate": 6.648274790177184e-06,
      "loss": 0.2844,
      "step": 8626
    },
    {
      "epoch": 0.6704227541187442,
      "grad_norm": 0.2299208790063858,
      "learning_rate": 6.64788622940628e-06,
      "loss": 0.1501,
      "step": 8627
    },
    {
      "epoch": 0.670500466272925,
      "grad_norm": 0.25126731395721436,
      "learning_rate": 6.647497668635375e-06,
      "loss": 0.1368,
      "step": 8628
    },
    {
      "epoch": 0.670578178427106,
      "grad_norm": 0.5379416942596436,
      "learning_rate": 6.64710910786447e-06,
      "loss": 0.123,
      "step": 8629
    },
    {
      "epoch": 0.6706558905812869,
      "grad_norm": 0.1522531807422638,
      "learning_rate": 6.646720547093566e-06,
      "loss": 0.0465,
      "step": 8630
    },
    {
      "epoch": 0.6707336027354678,
      "grad_norm": 0.263115793466568,
      "learning_rate": 6.646331986322662e-06,
      "loss": 0.0769,
      "step": 8631
    },
    {
      "epoch": 0.6708113148896487,
      "grad_norm": 0.34996992349624634,
      "learning_rate": 6.645943425551756e-06,
      "loss": 0.2284,
      "step": 8632
    },
    {
      "epoch": 0.6708890270438297,
      "grad_norm": 0.19185763597488403,
      "learning_rate": 6.645554864780852e-06,
      "loss": 0.0695,
      "step": 8633
    },
    {
      "epoch": 0.6709667391980105,
      "grad_norm": 0.20414766669273376,
      "learning_rate": 6.645166304009948e-06,
      "loss": 0.1185,
      "step": 8634
    },
    {
      "epoch": 0.6710444513521915,
      "grad_norm": 0.2553451359272003,
      "learning_rate": 6.6447777432390434e-06,
      "loss": 0.0924,
      "step": 8635
    },
    {
      "epoch": 0.6711221635063724,
      "grad_norm": 0.3571516275405884,
      "learning_rate": 6.644389182468138e-06,
      "loss": 0.1501,
      "step": 8636
    },
    {
      "epoch": 0.6711998756605533,
      "grad_norm": 0.6310135722160339,
      "learning_rate": 6.644000621697234e-06,
      "loss": 0.0623,
      "step": 8637
    },
    {
      "epoch": 0.6712775878147342,
      "grad_norm": 0.7671428322792053,
      "learning_rate": 6.64361206092633e-06,
      "loss": 0.1524,
      "step": 8638
    },
    {
      "epoch": 0.6713552999689152,
      "grad_norm": 0.27284494042396545,
      "learning_rate": 6.643223500155425e-06,
      "loss": 0.0439,
      "step": 8639
    },
    {
      "epoch": 0.671433012123096,
      "grad_norm": 0.13851793110370636,
      "learning_rate": 6.642834939384521e-06,
      "loss": 0.1764,
      "step": 8640
    },
    {
      "epoch": 0.671510724277277,
      "grad_norm": 0.43067216873168945,
      "learning_rate": 6.6424463786136165e-06,
      "loss": 0.3073,
      "step": 8641
    },
    {
      "epoch": 0.6715884364314578,
      "grad_norm": 0.13827504217624664,
      "learning_rate": 6.642057817842711e-06,
      "loss": 0.0196,
      "step": 8642
    },
    {
      "epoch": 0.6716661485856388,
      "grad_norm": 0.34279876947402954,
      "learning_rate": 6.641669257071806e-06,
      "loss": 0.183,
      "step": 8643
    },
    {
      "epoch": 0.6717438607398197,
      "grad_norm": 0.3725026845932007,
      "learning_rate": 6.641280696300902e-06,
      "loss": 0.1344,
      "step": 8644
    },
    {
      "epoch": 0.6718215728940006,
      "grad_norm": 0.24674294888973236,
      "learning_rate": 6.640892135529997e-06,
      "loss": 0.0666,
      "step": 8645
    },
    {
      "epoch": 0.6718992850481815,
      "grad_norm": 0.6159960627555847,
      "learning_rate": 6.640503574759093e-06,
      "loss": 0.0851,
      "step": 8646
    },
    {
      "epoch": 0.6719769972023625,
      "grad_norm": 0.6081605553627014,
      "learning_rate": 6.640115013988189e-06,
      "loss": 0.1755,
      "step": 8647
    },
    {
      "epoch": 0.6720547093565433,
      "grad_norm": 0.45789283514022827,
      "learning_rate": 6.639726453217284e-06,
      "loss": 0.196,
      "step": 8648
    },
    {
      "epoch": 0.6721324215107243,
      "grad_norm": 0.3545853793621063,
      "learning_rate": 6.6393378924463795e-06,
      "loss": 0.1277,
      "step": 8649
    },
    {
      "epoch": 0.6722101336649052,
      "grad_norm": 0.9479762315750122,
      "learning_rate": 6.638949331675475e-06,
      "loss": 0.1245,
      "step": 8650
    },
    {
      "epoch": 0.6722878458190861,
      "grad_norm": 0.44231927394866943,
      "learning_rate": 6.638560770904569e-06,
      "loss": 0.0531,
      "step": 8651
    },
    {
      "epoch": 0.672365557973267,
      "grad_norm": 0.8100659251213074,
      "learning_rate": 6.638172210133665e-06,
      "loss": 0.6694,
      "step": 8652
    },
    {
      "epoch": 0.672443270127448,
      "grad_norm": 0.17137068510055542,
      "learning_rate": 6.637783649362761e-06,
      "loss": 0.0316,
      "step": 8653
    },
    {
      "epoch": 0.6725209822816288,
      "grad_norm": 0.41737881302833557,
      "learning_rate": 6.637395088591856e-06,
      "loss": 0.1075,
      "step": 8654
    },
    {
      "epoch": 0.6725986944358098,
      "grad_norm": 0.35299158096313477,
      "learning_rate": 6.637006527820952e-06,
      "loss": 0.0389,
      "step": 8655
    },
    {
      "epoch": 0.6726764065899907,
      "grad_norm": 0.20282666385173798,
      "learning_rate": 6.6366179670500475e-06,
      "loss": 0.0598,
      "step": 8656
    },
    {
      "epoch": 0.6727541187441716,
      "grad_norm": 0.5201209187507629,
      "learning_rate": 6.6362294062791425e-06,
      "loss": 0.1583,
      "step": 8657
    },
    {
      "epoch": 0.6728318308983525,
      "grad_norm": 0.17356079816818237,
      "learning_rate": 6.635840845508238e-06,
      "loss": 0.0422,
      "step": 8658
    },
    {
      "epoch": 0.6729095430525334,
      "grad_norm": 0.5105652809143066,
      "learning_rate": 6.635452284737334e-06,
      "loss": 0.1317,
      "step": 8659
    },
    {
      "epoch": 0.6729872552067143,
      "grad_norm": 0.4612239897251129,
      "learning_rate": 6.635063723966428e-06,
      "loss": 0.0932,
      "step": 8660
    },
    {
      "epoch": 0.6730649673608953,
      "grad_norm": 0.19616198539733887,
      "learning_rate": 6.634675163195524e-06,
      "loss": 0.1802,
      "step": 8661
    },
    {
      "epoch": 0.6731426795150761,
      "grad_norm": 1.2357596158981323,
      "learning_rate": 6.63428660242462e-06,
      "loss": 0.2411,
      "step": 8662
    },
    {
      "epoch": 0.6732203916692571,
      "grad_norm": 0.4872703552246094,
      "learning_rate": 6.633898041653715e-06,
      "loss": 0.2548,
      "step": 8663
    },
    {
      "epoch": 0.673298103823438,
      "grad_norm": 0.6169801950454712,
      "learning_rate": 6.6335094808828105e-06,
      "loss": 0.3198,
      "step": 8664
    },
    {
      "epoch": 0.6733758159776189,
      "grad_norm": 0.29198703169822693,
      "learning_rate": 6.633120920111906e-06,
      "loss": 0.055,
      "step": 8665
    },
    {
      "epoch": 0.6734535281317998,
      "grad_norm": 0.24487443268299103,
      "learning_rate": 6.632732359341002e-06,
      "loss": 0.0217,
      "step": 8666
    },
    {
      "epoch": 0.6735312402859808,
      "grad_norm": 0.12287718802690506,
      "learning_rate": 6.632343798570097e-06,
      "loss": 0.0282,
      "step": 8667
    },
    {
      "epoch": 0.6736089524401616,
      "grad_norm": 0.36512625217437744,
      "learning_rate": 6.631955237799193e-06,
      "loss": 0.2092,
      "step": 8668
    },
    {
      "epoch": 0.6736866645943426,
      "grad_norm": 0.4959144592285156,
      "learning_rate": 6.631566677028289e-06,
      "loss": 0.4425,
      "step": 8669
    },
    {
      "epoch": 0.6737643767485235,
      "grad_norm": 0.5716636180877686,
      "learning_rate": 6.631178116257383e-06,
      "loss": 0.4444,
      "step": 8670
    },
    {
      "epoch": 0.6738420889027044,
      "grad_norm": 0.46942630410194397,
      "learning_rate": 6.6307895554864786e-06,
      "loss": 0.2839,
      "step": 8671
    },
    {
      "epoch": 0.6739198010568853,
      "grad_norm": 0.15042784810066223,
      "learning_rate": 6.630400994715574e-06,
      "loss": 0.098,
      "step": 8672
    },
    {
      "epoch": 0.6739975132110662,
      "grad_norm": 0.6824290156364441,
      "learning_rate": 6.630012433944669e-06,
      "loss": 0.3272,
      "step": 8673
    },
    {
      "epoch": 0.6740752253652471,
      "grad_norm": 0.3049360513687134,
      "learning_rate": 6.629623873173765e-06,
      "loss": 0.0587,
      "step": 8674
    },
    {
      "epoch": 0.6741529375194281,
      "grad_norm": 0.38731423020362854,
      "learning_rate": 6.629235312402861e-06,
      "loss": 0.1703,
      "step": 8675
    },
    {
      "epoch": 0.6742306496736089,
      "grad_norm": 0.2645178735256195,
      "learning_rate": 6.628846751631956e-06,
      "loss": 0.1482,
      "step": 8676
    },
    {
      "epoch": 0.6743083618277899,
      "grad_norm": 0.2128526270389557,
      "learning_rate": 6.628458190861052e-06,
      "loss": 0.033,
      "step": 8677
    },
    {
      "epoch": 0.6743860739819708,
      "grad_norm": 0.15245215594768524,
      "learning_rate": 6.6280696300901475e-06,
      "loss": 0.0789,
      "step": 8678
    },
    {
      "epoch": 0.6744637861361517,
      "grad_norm": 0.5895475149154663,
      "learning_rate": 6.6276810693192416e-06,
      "loss": 0.1157,
      "step": 8679
    },
    {
      "epoch": 0.6745414982903326,
      "grad_norm": 0.275899738073349,
      "learning_rate": 6.627292508548337e-06,
      "loss": 0.1786,
      "step": 8680
    },
    {
      "epoch": 0.6746192104445136,
      "grad_norm": 0.6160717010498047,
      "learning_rate": 6.626903947777433e-06,
      "loss": 0.4293,
      "step": 8681
    },
    {
      "epoch": 0.6746969225986944,
      "grad_norm": 0.8570403456687927,
      "learning_rate": 6.626515387006528e-06,
      "loss": 0.4472,
      "step": 8682
    },
    {
      "epoch": 0.6747746347528754,
      "grad_norm": 0.3513864576816559,
      "learning_rate": 6.626126826235624e-06,
      "loss": 0.2083,
      "step": 8683
    },
    {
      "epoch": 0.6748523469070563,
      "grad_norm": 0.20383517444133759,
      "learning_rate": 6.62573826546472e-06,
      "loss": 0.2053,
      "step": 8684
    },
    {
      "epoch": 0.6749300590612372,
      "grad_norm": 0.37581777572631836,
      "learning_rate": 6.625349704693815e-06,
      "loss": 0.1231,
      "step": 8685
    },
    {
      "epoch": 0.6750077712154181,
      "grad_norm": 0.3054101765155792,
      "learning_rate": 6.62496114392291e-06,
      "loss": 0.0809,
      "step": 8686
    },
    {
      "epoch": 0.6750854833695991,
      "grad_norm": 0.402252197265625,
      "learning_rate": 6.624572583152005e-06,
      "loss": 0.1184,
      "step": 8687
    },
    {
      "epoch": 0.6751631955237799,
      "grad_norm": 0.4311560392379761,
      "learning_rate": 6.6241840223811e-06,
      "loss": 0.18,
      "step": 8688
    },
    {
      "epoch": 0.6752409076779609,
      "grad_norm": 0.34345743060112,
      "learning_rate": 6.623795461610196e-06,
      "loss": 0.2395,
      "step": 8689
    },
    {
      "epoch": 0.6753186198321417,
      "grad_norm": 0.24251848459243774,
      "learning_rate": 6.623406900839292e-06,
      "loss": 0.0398,
      "step": 8690
    },
    {
      "epoch": 0.6753963319863227,
      "grad_norm": 0.6820895075798035,
      "learning_rate": 6.623018340068387e-06,
      "loss": 0.2601,
      "step": 8691
    },
    {
      "epoch": 0.6754740441405036,
      "grad_norm": 0.6163561940193176,
      "learning_rate": 6.622629779297483e-06,
      "loss": 0.2899,
      "step": 8692
    },
    {
      "epoch": 0.6755517562946844,
      "grad_norm": 0.2859705090522766,
      "learning_rate": 6.6222412185265785e-06,
      "loss": 1.0041,
      "step": 8693
    },
    {
      "epoch": 0.6756294684488654,
      "grad_norm": 0.7360695600509644,
      "learning_rate": 6.621852657755673e-06,
      "loss": 0.6641,
      "step": 8694
    },
    {
      "epoch": 0.6757071806030464,
      "grad_norm": 0.47895458340644836,
      "learning_rate": 6.621464096984768e-06,
      "loss": 0.3169,
      "step": 8695
    },
    {
      "epoch": 0.6757848927572272,
      "grad_norm": 0.08313123136758804,
      "learning_rate": 6.621075536213864e-06,
      "loss": 0.0379,
      "step": 8696
    },
    {
      "epoch": 0.6758626049114081,
      "grad_norm": 0.3679264485836029,
      "learning_rate": 6.62068697544296e-06,
      "loss": 0.1811,
      "step": 8697
    },
    {
      "epoch": 0.6759403170655891,
      "grad_norm": 0.18763025104999542,
      "learning_rate": 6.620298414672055e-06,
      "loss": 0.0904,
      "step": 8698
    },
    {
      "epoch": 0.67601802921977,
      "grad_norm": 0.5660814046859741,
      "learning_rate": 6.619909853901151e-06,
      "loss": 0.3723,
      "step": 8699
    },
    {
      "epoch": 0.6760957413739509,
      "grad_norm": 0.039140112698078156,
      "learning_rate": 6.6195212931302465e-06,
      "loss": 0.0336,
      "step": 8700
    },
    {
      "epoch": 0.6761734535281319,
      "grad_norm": 1.1141557693481445,
      "learning_rate": 6.6191327323593415e-06,
      "loss": 0.3356,
      "step": 8701
    },
    {
      "epoch": 0.6762511656823127,
      "grad_norm": 0.18658778071403503,
      "learning_rate": 6.618744171588437e-06,
      "loss": 0.0152,
      "step": 8702
    },
    {
      "epoch": 0.6763288778364936,
      "grad_norm": 0.14096026122570038,
      "learning_rate": 6.618355610817533e-06,
      "loss": 0.1135,
      "step": 8703
    },
    {
      "epoch": 0.6764065899906745,
      "grad_norm": 0.4768494963645935,
      "learning_rate": 6.617967050046627e-06,
      "loss": 0.2662,
      "step": 8704
    },
    {
      "epoch": 0.6764843021448554,
      "grad_norm": 0.0270790196955204,
      "learning_rate": 6.617578489275723e-06,
      "loss": 0.0027,
      "step": 8705
    },
    {
      "epoch": 0.6765620142990364,
      "grad_norm": 0.5150861144065857,
      "learning_rate": 6.617189928504819e-06,
      "loss": 0.2726,
      "step": 8706
    },
    {
      "epoch": 0.6766397264532172,
      "grad_norm": 0.2684077024459839,
      "learning_rate": 6.616801367733914e-06,
      "loss": 0.0488,
      "step": 8707
    },
    {
      "epoch": 0.6767174386073982,
      "grad_norm": 0.5989211201667786,
      "learning_rate": 6.6164128069630095e-06,
      "loss": 0.3462,
      "step": 8708
    },
    {
      "epoch": 0.6767951507615791,
      "grad_norm": 0.6243364214897156,
      "learning_rate": 6.616024246192105e-06,
      "loss": 0.1835,
      "step": 8709
    },
    {
      "epoch": 0.67687286291576,
      "grad_norm": 0.6021313667297363,
      "learning_rate": 6.6156356854212e-06,
      "loss": 0.2313,
      "step": 8710
    },
    {
      "epoch": 0.6769505750699409,
      "grad_norm": 0.16522355377674103,
      "learning_rate": 6.615247124650296e-06,
      "loss": 0.0393,
      "step": 8711
    },
    {
      "epoch": 0.6770282872241219,
      "grad_norm": 0.3907441794872284,
      "learning_rate": 6.614858563879392e-06,
      "loss": 0.2734,
      "step": 8712
    },
    {
      "epoch": 0.6771059993783027,
      "grad_norm": 0.1607336699962616,
      "learning_rate": 6.614470003108486e-06,
      "loss": 0.0395,
      "step": 8713
    },
    {
      "epoch": 0.6771837115324837,
      "grad_norm": 0.6069073677062988,
      "learning_rate": 6.614081442337582e-06,
      "loss": 0.1588,
      "step": 8714
    },
    {
      "epoch": 0.6772614236866646,
      "grad_norm": 0.3664924204349518,
      "learning_rate": 6.6136928815666775e-06,
      "loss": 0.0415,
      "step": 8715
    },
    {
      "epoch": 0.6773391358408455,
      "grad_norm": 0.5597965121269226,
      "learning_rate": 6.6133043207957725e-06,
      "loss": 0.3922,
      "step": 8716
    },
    {
      "epoch": 0.6774168479950264,
      "grad_norm": 0.3973667323589325,
      "learning_rate": 6.612915760024868e-06,
      "loss": 0.3355,
      "step": 8717
    },
    {
      "epoch": 0.6774945601492073,
      "grad_norm": 0.45685678720474243,
      "learning_rate": 6.612527199253964e-06,
      "loss": 0.3858,
      "step": 8718
    },
    {
      "epoch": 0.6775722723033882,
      "grad_norm": 1.8675137758255005,
      "learning_rate": 6.612138638483059e-06,
      "loss": 0.6327,
      "step": 8719
    },
    {
      "epoch": 0.6776499844575692,
      "grad_norm": 0.23318105936050415,
      "learning_rate": 6.611750077712155e-06,
      "loss": 0.0643,
      "step": 8720
    },
    {
      "epoch": 0.67772769661175,
      "grad_norm": 0.26260101795196533,
      "learning_rate": 6.611361516941251e-06,
      "loss": 0.1443,
      "step": 8721
    },
    {
      "epoch": 0.677805408765931,
      "grad_norm": 0.07981744408607483,
      "learning_rate": 6.610972956170345e-06,
      "loss": 0.0061,
      "step": 8722
    },
    {
      "epoch": 0.6778831209201119,
      "grad_norm": 0.49951305985450745,
      "learning_rate": 6.6105843953994405e-06,
      "loss": 0.4183,
      "step": 8723
    },
    {
      "epoch": 0.6779608330742928,
      "grad_norm": 0.21035803854465485,
      "learning_rate": 6.610195834628536e-06,
      "loss": 0.0391,
      "step": 8724
    },
    {
      "epoch": 0.6780385452284737,
      "grad_norm": 0.2290169596672058,
      "learning_rate": 6.609807273857631e-06,
      "loss": 0.1381,
      "step": 8725
    },
    {
      "epoch": 0.6781162573826547,
      "grad_norm": 0.579870343208313,
      "learning_rate": 6.609418713086727e-06,
      "loss": 0.5147,
      "step": 8726
    },
    {
      "epoch": 0.6781939695368355,
      "grad_norm": 0.38609611988067627,
      "learning_rate": 6.609030152315823e-06,
      "loss": 0.0739,
      "step": 8727
    },
    {
      "epoch": 0.6782716816910165,
      "grad_norm": 0.3544537127017975,
      "learning_rate": 6.608641591544919e-06,
      "loss": 0.1256,
      "step": 8728
    },
    {
      "epoch": 0.6783493938451974,
      "grad_norm": 0.33972272276878357,
      "learning_rate": 6.608253030774014e-06,
      "loss": 0.264,
      "step": 8729
    },
    {
      "epoch": 0.6784271059993783,
      "grad_norm": 0.247079536318779,
      "learning_rate": 6.607864470003109e-06,
      "loss": 0.0525,
      "step": 8730
    },
    {
      "epoch": 0.6785048181535592,
      "grad_norm": 0.34918490052223206,
      "learning_rate": 6.607475909232205e-06,
      "loss": 0.0714,
      "step": 8731
    },
    {
      "epoch": 0.6785825303077402,
      "grad_norm": 0.1360759288072586,
      "learning_rate": 6.607087348461299e-06,
      "loss": 0.0306,
      "step": 8732
    },
    {
      "epoch": 0.678660242461921,
      "grad_norm": 0.3510873317718506,
      "learning_rate": 6.606698787690395e-06,
      "loss": 0.4631,
      "step": 8733
    },
    {
      "epoch": 0.678737954616102,
      "grad_norm": 0.2832674980163574,
      "learning_rate": 6.606310226919491e-06,
      "loss": 0.3435,
      "step": 8734
    },
    {
      "epoch": 0.6788156667702828,
      "grad_norm": 0.1806105226278305,
      "learning_rate": 6.605921666148586e-06,
      "loss": 0.0852,
      "step": 8735
    },
    {
      "epoch": 0.6788933789244638,
      "grad_norm": 0.10552587360143661,
      "learning_rate": 6.605533105377682e-06,
      "loss": 0.0186,
      "step": 8736
    },
    {
      "epoch": 0.6789710910786447,
      "grad_norm": 0.21753601729869843,
      "learning_rate": 6.6051445446067774e-06,
      "loss": 0.0509,
      "step": 8737
    },
    {
      "epoch": 0.6790488032328256,
      "grad_norm": 0.7648979425430298,
      "learning_rate": 6.604755983835872e-06,
      "loss": 0.2871,
      "step": 8738
    },
    {
      "epoch": 0.6791265153870065,
      "grad_norm": 0.20278401672840118,
      "learning_rate": 6.604367423064968e-06,
      "loss": 0.0447,
      "step": 8739
    },
    {
      "epoch": 0.6792042275411875,
      "grad_norm": 0.573919415473938,
      "learning_rate": 6.603978862294064e-06,
      "loss": 0.3043,
      "step": 8740
    },
    {
      "epoch": 0.6792819396953683,
      "grad_norm": 0.3627612888813019,
      "learning_rate": 6.603590301523158e-06,
      "loss": 0.139,
      "step": 8741
    },
    {
      "epoch": 0.6793596518495493,
      "grad_norm": 0.3643135130405426,
      "learning_rate": 6.603201740752254e-06,
      "loss": 0.1653,
      "step": 8742
    },
    {
      "epoch": 0.6794373640037302,
      "grad_norm": 0.46950939297676086,
      "learning_rate": 6.60281317998135e-06,
      "loss": 0.2574,
      "step": 8743
    },
    {
      "epoch": 0.6795150761579111,
      "grad_norm": 0.15813764929771423,
      "learning_rate": 6.602424619210445e-06,
      "loss": 0.3218,
      "step": 8744
    },
    {
      "epoch": 0.679592788312092,
      "grad_norm": 0.32978498935699463,
      "learning_rate": 6.6020360584395404e-06,
      "loss": 0.2417,
      "step": 8745
    },
    {
      "epoch": 0.679670500466273,
      "grad_norm": 0.7313450574874878,
      "learning_rate": 6.601647497668636e-06,
      "loss": 0.5046,
      "step": 8746
    },
    {
      "epoch": 0.6797482126204538,
      "grad_norm": 0.3629789352416992,
      "learning_rate": 6.601258936897731e-06,
      "loss": 0.0736,
      "step": 8747
    },
    {
      "epoch": 0.6798259247746348,
      "grad_norm": 0.3433696925640106,
      "learning_rate": 6.600870376126827e-06,
      "loss": 0.0925,
      "step": 8748
    },
    {
      "epoch": 0.6799036369288156,
      "grad_norm": 0.1400693655014038,
      "learning_rate": 6.600481815355923e-06,
      "loss": 0.0443,
      "step": 8749
    },
    {
      "epoch": 0.6799813490829966,
      "grad_norm": 0.1269451528787613,
      "learning_rate": 6.600093254585017e-06,
      "loss": 0.0825,
      "step": 8750
    },
    {
      "epoch": 0.6800590612371775,
      "grad_norm": 0.5611715316772461,
      "learning_rate": 6.599704693814113e-06,
      "loss": 0.2971,
      "step": 8751
    },
    {
      "epoch": 0.6801367733913584,
      "grad_norm": 0.29670411348342896,
      "learning_rate": 6.5993161330432085e-06,
      "loss": 0.1306,
      "step": 8752
    },
    {
      "epoch": 0.6802144855455393,
      "grad_norm": 1.0626381635665894,
      "learning_rate": 6.598927572272303e-06,
      "loss": 0.6612,
      "step": 8753
    },
    {
      "epoch": 0.6802921976997203,
      "grad_norm": 0.3745117485523224,
      "learning_rate": 6.598539011501399e-06,
      "loss": 0.176,
      "step": 8754
    },
    {
      "epoch": 0.6803699098539011,
      "grad_norm": 0.48183685541152954,
      "learning_rate": 6.598150450730495e-06,
      "loss": 0.7313,
      "step": 8755
    },
    {
      "epoch": 0.6804476220080821,
      "grad_norm": 0.09093368053436279,
      "learning_rate": 6.597761889959591e-06,
      "loss": 0.0169,
      "step": 8756
    },
    {
      "epoch": 0.680525334162263,
      "grad_norm": 0.3716789186000824,
      "learning_rate": 6.597373329188686e-06,
      "loss": 0.1538,
      "step": 8757
    },
    {
      "epoch": 0.6806030463164439,
      "grad_norm": 1.1747413873672485,
      "learning_rate": 6.5969847684177816e-06,
      "loss": 0.3944,
      "step": 8758
    },
    {
      "epoch": 0.6806807584706248,
      "grad_norm": 0.30006691813468933,
      "learning_rate": 6.596596207646877e-06,
      "loss": 0.1034,
      "step": 8759
    },
    {
      "epoch": 0.6807584706248058,
      "grad_norm": 0.43835434317588806,
      "learning_rate": 6.5962076468759715e-06,
      "loss": 0.1946,
      "step": 8760
    },
    {
      "epoch": 0.6808361827789866,
      "grad_norm": 0.24105481803417206,
      "learning_rate": 6.595819086105067e-06,
      "loss": 0.0664,
      "step": 8761
    },
    {
      "epoch": 0.6809138949331676,
      "grad_norm": 0.1261577159166336,
      "learning_rate": 6.595430525334163e-06,
      "loss": 0.0886,
      "step": 8762
    },
    {
      "epoch": 0.6809916070873485,
      "grad_norm": 0.8299633860588074,
      "learning_rate": 6.595041964563258e-06,
      "loss": 0.2593,
      "step": 8763
    },
    {
      "epoch": 0.6810693192415294,
      "grad_norm": 0.2134762704372406,
      "learning_rate": 6.594653403792354e-06,
      "loss": 0.0476,
      "step": 8764
    },
    {
      "epoch": 0.6811470313957103,
      "grad_norm": 0.13403114676475525,
      "learning_rate": 6.59426484302145e-06,
      "loss": 0.024,
      "step": 8765
    },
    {
      "epoch": 0.6812247435498912,
      "grad_norm": 1.2828885316848755,
      "learning_rate": 6.5938762822505445e-06,
      "loss": 0.7343,
      "step": 8766
    },
    {
      "epoch": 0.6813024557040721,
      "grad_norm": 0.8374665379524231,
      "learning_rate": 6.59348772147964e-06,
      "loss": 0.3046,
      "step": 8767
    },
    {
      "epoch": 0.6813801678582531,
      "grad_norm": 0.14224810898303986,
      "learning_rate": 6.593099160708736e-06,
      "loss": 0.0521,
      "step": 8768
    },
    {
      "epoch": 0.6814578800124339,
      "grad_norm": 0.6686403751373291,
      "learning_rate": 6.59271059993783e-06,
      "loss": 0.7345,
      "step": 8769
    },
    {
      "epoch": 0.6815355921666149,
      "grad_norm": 0.38545793294906616,
      "learning_rate": 6.592322039166926e-06,
      "loss": 0.1402,
      "step": 8770
    },
    {
      "epoch": 0.6816133043207958,
      "grad_norm": 1.1934431791305542,
      "learning_rate": 6.591933478396022e-06,
      "loss": 0.4096,
      "step": 8771
    },
    {
      "epoch": 0.6816910164749767,
      "grad_norm": 1.9912934303283691,
      "learning_rate": 6.591544917625117e-06,
      "loss": 0.8668,
      "step": 8772
    },
    {
      "epoch": 0.6817687286291576,
      "grad_norm": 0.4544554650783539,
      "learning_rate": 6.5911563568542126e-06,
      "loss": 0.2015,
      "step": 8773
    },
    {
      "epoch": 0.6818464407833386,
      "grad_norm": 0.8282092809677124,
      "learning_rate": 6.590767796083308e-06,
      "loss": 0.3818,
      "step": 8774
    },
    {
      "epoch": 0.6819241529375194,
      "grad_norm": 0.6713985204696655,
      "learning_rate": 6.590379235312403e-06,
      "loss": 0.4566,
      "step": 8775
    },
    {
      "epoch": 0.6820018650917004,
      "grad_norm": 0.2159106731414795,
      "learning_rate": 6.589990674541499e-06,
      "loss": 0.0658,
      "step": 8776
    },
    {
      "epoch": 0.6820795772458813,
      "grad_norm": 0.19188660383224487,
      "learning_rate": 6.589602113770595e-06,
      "loss": 0.1097,
      "step": 8777
    },
    {
      "epoch": 0.6821572894000622,
      "grad_norm": 1.2382310628890991,
      "learning_rate": 6.589213552999689e-06,
      "loss": 0.4076,
      "step": 8778
    },
    {
      "epoch": 0.6822350015542431,
      "grad_norm": 0.6362093091011047,
      "learning_rate": 6.588824992228785e-06,
      "loss": 0.3688,
      "step": 8779
    },
    {
      "epoch": 0.682312713708424,
      "grad_norm": 0.15931910276412964,
      "learning_rate": 6.588436431457881e-06,
      "loss": 0.0579,
      "step": 8780
    },
    {
      "epoch": 0.6823904258626049,
      "grad_norm": 0.1847277134656906,
      "learning_rate": 6.5880478706869756e-06,
      "loss": 0.1029,
      "step": 8781
    },
    {
      "epoch": 0.6824681380167859,
      "grad_norm": 0.23956981301307678,
      "learning_rate": 6.587659309916071e-06,
      "loss": 0.1803,
      "step": 8782
    },
    {
      "epoch": 0.6825458501709667,
      "grad_norm": 0.8616998791694641,
      "learning_rate": 6.587270749145167e-06,
      "loss": 0.226,
      "step": 8783
    },
    {
      "epoch": 0.6826235623251476,
      "grad_norm": 0.2247752845287323,
      "learning_rate": 6.586882188374262e-06,
      "loss": 0.0634,
      "step": 8784
    },
    {
      "epoch": 0.6827012744793286,
      "grad_norm": 0.7869512438774109,
      "learning_rate": 6.586493627603358e-06,
      "loss": 0.2589,
      "step": 8785
    },
    {
      "epoch": 0.6827789866335094,
      "grad_norm": 0.49586033821105957,
      "learning_rate": 6.586105066832454e-06,
      "loss": 0.1652,
      "step": 8786
    },
    {
      "epoch": 0.6828566987876904,
      "grad_norm": 0.7556073665618896,
      "learning_rate": 6.5857165060615495e-06,
      "loss": 0.3166,
      "step": 8787
    },
    {
      "epoch": 0.6829344109418714,
      "grad_norm": 0.4683530926704407,
      "learning_rate": 6.585327945290644e-06,
      "loss": 0.2917,
      "step": 8788
    },
    {
      "epoch": 0.6830121230960522,
      "grad_norm": 0.41021594405174255,
      "learning_rate": 6.584939384519739e-06,
      "loss": 0.1791,
      "step": 8789
    },
    {
      "epoch": 0.6830898352502331,
      "grad_norm": 0.28186798095703125,
      "learning_rate": 6.584550823748835e-06,
      "loss": 0.122,
      "step": 8790
    },
    {
      "epoch": 0.6831675474044141,
      "grad_norm": 0.7661469578742981,
      "learning_rate": 6.58416226297793e-06,
      "loss": 0.3972,
      "step": 8791
    },
    {
      "epoch": 0.6832452595585949,
      "grad_norm": 0.6767887473106384,
      "learning_rate": 6.583773702207026e-06,
      "loss": 0.1686,
      "step": 8792
    },
    {
      "epoch": 0.6833229717127759,
      "grad_norm": 0.31708043813705444,
      "learning_rate": 6.583385141436122e-06,
      "loss": 0.1215,
      "step": 8793
    },
    {
      "epoch": 0.6834006838669567,
      "grad_norm": 0.21133577823638916,
      "learning_rate": 6.582996580665217e-06,
      "loss": 0.1044,
      "step": 8794
    },
    {
      "epoch": 0.6834783960211377,
      "grad_norm": 0.5882697701454163,
      "learning_rate": 6.5826080198943125e-06,
      "loss": 0.2646,
      "step": 8795
    },
    {
      "epoch": 0.6835561081753186,
      "grad_norm": 0.2890307307243347,
      "learning_rate": 6.582219459123408e-06,
      "loss": 0.162,
      "step": 8796
    },
    {
      "epoch": 0.6836338203294995,
      "grad_norm": 0.6383262276649475,
      "learning_rate": 6.581830898352502e-06,
      "loss": 1.4676,
      "step": 8797
    },
    {
      "epoch": 0.6837115324836804,
      "grad_norm": 0.20150329172611237,
      "learning_rate": 6.581442337581598e-06,
      "loss": 0.0423,
      "step": 8798
    },
    {
      "epoch": 0.6837892446378614,
      "grad_norm": 0.8992252349853516,
      "learning_rate": 6.581053776810694e-06,
      "loss": 0.0895,
      "step": 8799
    },
    {
      "epoch": 0.6838669567920422,
      "grad_norm": 0.22486187517642975,
      "learning_rate": 6.580665216039789e-06,
      "loss": 0.0983,
      "step": 8800
    },
    {
      "epoch": 0.6839446689462232,
      "grad_norm": 1.1312872171401978,
      "learning_rate": 6.580276655268885e-06,
      "loss": 0.3498,
      "step": 8801
    },
    {
      "epoch": 0.6840223811004041,
      "grad_norm": 0.3444242477416992,
      "learning_rate": 6.5798880944979805e-06,
      "loss": 0.0426,
      "step": 8802
    },
    {
      "epoch": 0.684100093254585,
      "grad_norm": 0.05225048214197159,
      "learning_rate": 6.5794995337270755e-06,
      "loss": 0.0104,
      "step": 8803
    },
    {
      "epoch": 0.6841778054087659,
      "grad_norm": 0.21456582844257355,
      "learning_rate": 6.579110972956171e-06,
      "loss": 0.1053,
      "step": 8804
    },
    {
      "epoch": 0.6842555175629469,
      "grad_norm": 0.4887799322605133,
      "learning_rate": 6.578722412185267e-06,
      "loss": 0.4017,
      "step": 8805
    },
    {
      "epoch": 0.6843332297171277,
      "grad_norm": 0.6736348867416382,
      "learning_rate": 6.578333851414361e-06,
      "loss": 0.4483,
      "step": 8806
    },
    {
      "epoch": 0.6844109418713087,
      "grad_norm": 0.4192206561565399,
      "learning_rate": 6.577945290643457e-06,
      "loss": 0.3729,
      "step": 8807
    },
    {
      "epoch": 0.6844886540254896,
      "grad_norm": 0.24176663160324097,
      "learning_rate": 6.577556729872553e-06,
      "loss": 0.065,
      "step": 8808
    },
    {
      "epoch": 0.6845663661796705,
      "grad_norm": 0.2725326716899872,
      "learning_rate": 6.577168169101648e-06,
      "loss": 0.2523,
      "step": 8809
    },
    {
      "epoch": 0.6846440783338514,
      "grad_norm": 0.3175467848777771,
      "learning_rate": 6.5767796083307435e-06,
      "loss": 0.0459,
      "step": 8810
    },
    {
      "epoch": 0.6847217904880323,
      "grad_norm": 0.41659441590309143,
      "learning_rate": 6.576391047559839e-06,
      "loss": 0.1454,
      "step": 8811
    },
    {
      "epoch": 0.6847995026422132,
      "grad_norm": 0.49012699723243713,
      "learning_rate": 6.576002486788933e-06,
      "loss": 0.1336,
      "step": 8812
    },
    {
      "epoch": 0.6848772147963942,
      "grad_norm": 0.9350881576538086,
      "learning_rate": 6.575613926018029e-06,
      "loss": 0.6683,
      "step": 8813
    },
    {
      "epoch": 0.684954926950575,
      "grad_norm": 0.24695567786693573,
      "learning_rate": 6.575225365247125e-06,
      "loss": 0.1246,
      "step": 8814
    },
    {
      "epoch": 0.685032639104756,
      "grad_norm": 0.3013632595539093,
      "learning_rate": 6.57483680447622e-06,
      "loss": 0.5857,
      "step": 8815
    },
    {
      "epoch": 0.6851103512589369,
      "grad_norm": 1.0783973932266235,
      "learning_rate": 6.574448243705316e-06,
      "loss": 0.3969,
      "step": 8816
    },
    {
      "epoch": 0.6851880634131178,
      "grad_norm": 0.44769638776779175,
      "learning_rate": 6.5740596829344115e-06,
      "loss": 0.0948,
      "step": 8817
    },
    {
      "epoch": 0.6852657755672987,
      "grad_norm": 0.22058816254138947,
      "learning_rate": 6.573671122163507e-06,
      "loss": 0.052,
      "step": 8818
    },
    {
      "epoch": 0.6853434877214797,
      "grad_norm": 0.7653341889381409,
      "learning_rate": 6.573282561392602e-06,
      "loss": 0.0691,
      "step": 8819
    },
    {
      "epoch": 0.6854211998756605,
      "grad_norm": 0.38391244411468506,
      "learning_rate": 6.572894000621698e-06,
      "loss": 0.2089,
      "step": 8820
    },
    {
      "epoch": 0.6854989120298415,
      "grad_norm": 0.5265660881996155,
      "learning_rate": 6.572505439850794e-06,
      "loss": 0.2313,
      "step": 8821
    },
    {
      "epoch": 0.6855766241840224,
      "grad_norm": 0.32159343361854553,
      "learning_rate": 6.572116879079888e-06,
      "loss": 0.1932,
      "step": 8822
    },
    {
      "epoch": 0.6856543363382033,
      "grad_norm": 0.3292803466320038,
      "learning_rate": 6.571728318308984e-06,
      "loss": 0.1771,
      "step": 8823
    },
    {
      "epoch": 0.6857320484923842,
      "grad_norm": 0.28421512246131897,
      "learning_rate": 6.57133975753808e-06,
      "loss": 0.1619,
      "step": 8824
    },
    {
      "epoch": 0.6858097606465651,
      "grad_norm": 0.49873799085617065,
      "learning_rate": 6.5709511967671745e-06,
      "loss": 0.1621,
      "step": 8825
    },
    {
      "epoch": 0.685887472800746,
      "grad_norm": 0.5393561124801636,
      "learning_rate": 6.57056263599627e-06,
      "loss": 0.1817,
      "step": 8826
    },
    {
      "epoch": 0.685965184954927,
      "grad_norm": 0.3267759680747986,
      "learning_rate": 6.570174075225366e-06,
      "loss": 0.5697,
      "step": 8827
    },
    {
      "epoch": 0.6860428971091078,
      "grad_norm": 0.8048359751701355,
      "learning_rate": 6.569785514454461e-06,
      "loss": 0.1423,
      "step": 8828
    },
    {
      "epoch": 0.6861206092632888,
      "grad_norm": 0.3560897409915924,
      "learning_rate": 6.569396953683557e-06,
      "loss": 0.1651,
      "step": 8829
    },
    {
      "epoch": 0.6861983214174697,
      "grad_norm": 0.32056570053100586,
      "learning_rate": 6.569008392912653e-06,
      "loss": 0.1148,
      "step": 8830
    },
    {
      "epoch": 0.6862760335716506,
      "grad_norm": 0.38744738698005676,
      "learning_rate": 6.568619832141747e-06,
      "loss": 0.0243,
      "step": 8831
    },
    {
      "epoch": 0.6863537457258315,
      "grad_norm": 0.24330642819404602,
      "learning_rate": 6.5682312713708426e-06,
      "loss": 0.1394,
      "step": 8832
    },
    {
      "epoch": 0.6864314578800125,
      "grad_norm": 0.29021793603897095,
      "learning_rate": 6.567842710599938e-06,
      "loss": 0.0803,
      "step": 8833
    },
    {
      "epoch": 0.6865091700341933,
      "grad_norm": 0.49307936429977417,
      "learning_rate": 6.567454149829033e-06,
      "loss": 0.3048,
      "step": 8834
    },
    {
      "epoch": 0.6865868821883743,
      "grad_norm": 0.3069915473461151,
      "learning_rate": 6.567065589058129e-06,
      "loss": 0.0889,
      "step": 8835
    },
    {
      "epoch": 0.6866645943425552,
      "grad_norm": 0.5616492629051208,
      "learning_rate": 6.566677028287225e-06,
      "loss": 0.3443,
      "step": 8836
    },
    {
      "epoch": 0.6867423064967361,
      "grad_norm": 0.48895642161369324,
      "learning_rate": 6.56628846751632e-06,
      "loss": 0.0717,
      "step": 8837
    },
    {
      "epoch": 0.686820018650917,
      "grad_norm": 0.6392238140106201,
      "learning_rate": 6.565899906745416e-06,
      "loss": 0.6005,
      "step": 8838
    },
    {
      "epoch": 0.686897730805098,
      "grad_norm": 0.2655833065509796,
      "learning_rate": 6.5655113459745114e-06,
      "loss": 0.1628,
      "step": 8839
    },
    {
      "epoch": 0.6869754429592788,
      "grad_norm": 0.19497936964035034,
      "learning_rate": 6.5651227852036055e-06,
      "loss": 0.0944,
      "step": 8840
    },
    {
      "epoch": 0.6870531551134598,
      "grad_norm": 0.616308331489563,
      "learning_rate": 6.564734224432701e-06,
      "loss": 0.4122,
      "step": 8841
    },
    {
      "epoch": 0.6871308672676406,
      "grad_norm": 0.18225938081741333,
      "learning_rate": 6.564345663661797e-06,
      "loss": 0.027,
      "step": 8842
    },
    {
      "epoch": 0.6872085794218216,
      "grad_norm": 0.1034620925784111,
      "learning_rate": 6.563957102890892e-06,
      "loss": 0.0229,
      "step": 8843
    },
    {
      "epoch": 0.6872862915760025,
      "grad_norm": 0.7480934262275696,
      "learning_rate": 6.563568542119988e-06,
      "loss": 0.2714,
      "step": 8844
    },
    {
      "epoch": 0.6873640037301834,
      "grad_norm": 0.2491568922996521,
      "learning_rate": 6.563179981349084e-06,
      "loss": 0.0891,
      "step": 8845
    },
    {
      "epoch": 0.6874417158843643,
      "grad_norm": 0.19502198696136475,
      "learning_rate": 6.562791420578179e-06,
      "loss": 0.0063,
      "step": 8846
    },
    {
      "epoch": 0.6875194280385453,
      "grad_norm": 0.414331316947937,
      "learning_rate": 6.5624028598072744e-06,
      "loss": 0.6354,
      "step": 8847
    },
    {
      "epoch": 0.6875971401927261,
      "grad_norm": 0.174555703997612,
      "learning_rate": 6.56201429903637e-06,
      "loss": 0.0719,
      "step": 8848
    },
    {
      "epoch": 0.6876748523469071,
      "grad_norm": 0.3570862114429474,
      "learning_rate": 6.561625738265466e-06,
      "loss": 0.0813,
      "step": 8849
    },
    {
      "epoch": 0.687752564501088,
      "grad_norm": 0.5431459546089172,
      "learning_rate": 6.56123717749456e-06,
      "loss": 0.4816,
      "step": 8850
    },
    {
      "epoch": 0.6878302766552689,
      "grad_norm": 0.30810391902923584,
      "learning_rate": 6.560848616723656e-06,
      "loss": 0.0989,
      "step": 8851
    },
    {
      "epoch": 0.6879079888094498,
      "grad_norm": 1.1904600858688354,
      "learning_rate": 6.560460055952752e-06,
      "loss": 0.3954,
      "step": 8852
    },
    {
      "epoch": 0.6879857009636308,
      "grad_norm": 0.4577496349811554,
      "learning_rate": 6.560071495181847e-06,
      "loss": 0.3933,
      "step": 8853
    },
    {
      "epoch": 0.6880634131178116,
      "grad_norm": 0.7427164912223816,
      "learning_rate": 6.5596829344109425e-06,
      "loss": 0.122,
      "step": 8854
    },
    {
      "epoch": 0.6881411252719926,
      "grad_norm": 0.6740557551383972,
      "learning_rate": 6.559294373640038e-06,
      "loss": 0.4107,
      "step": 8855
    },
    {
      "epoch": 0.6882188374261734,
      "grad_norm": 0.4536590278148651,
      "learning_rate": 6.558905812869133e-06,
      "loss": 0.0947,
      "step": 8856
    },
    {
      "epoch": 0.6882965495803544,
      "grad_norm": 0.07092607766389847,
      "learning_rate": 6.558517252098229e-06,
      "loss": 0.0074,
      "step": 8857
    },
    {
      "epoch": 0.6883742617345353,
      "grad_norm": 0.22777479887008667,
      "learning_rate": 6.558128691327325e-06,
      "loss": 0.0805,
      "step": 8858
    },
    {
      "epoch": 0.6884519738887162,
      "grad_norm": 0.6696509718894958,
      "learning_rate": 6.557740130556419e-06,
      "loss": 0.1458,
      "step": 8859
    },
    {
      "epoch": 0.6885296860428971,
      "grad_norm": 0.09226587414741516,
      "learning_rate": 6.557351569785515e-06,
      "loss": 0.0264,
      "step": 8860
    },
    {
      "epoch": 0.6886073981970781,
      "grad_norm": 0.14865073561668396,
      "learning_rate": 6.5569630090146105e-06,
      "loss": 0.1275,
      "step": 8861
    },
    {
      "epoch": 0.6886851103512589,
      "grad_norm": 0.3702983558177948,
      "learning_rate": 6.5565744482437055e-06,
      "loss": 0.2206,
      "step": 8862
    },
    {
      "epoch": 0.6887628225054399,
      "grad_norm": 0.15894025564193726,
      "learning_rate": 6.556185887472801e-06,
      "loss": 0.0489,
      "step": 8863
    },
    {
      "epoch": 0.6888405346596208,
      "grad_norm": 0.5732749700546265,
      "learning_rate": 6.555797326701897e-06,
      "loss": 0.0447,
      "step": 8864
    },
    {
      "epoch": 0.6889182468138016,
      "grad_norm": 0.40181097388267517,
      "learning_rate": 6.555408765930992e-06,
      "loss": 0.4983,
      "step": 8865
    },
    {
      "epoch": 0.6889959589679826,
      "grad_norm": 0.3851180970668793,
      "learning_rate": 6.555020205160088e-06,
      "loss": 0.0849,
      "step": 8866
    },
    {
      "epoch": 0.6890736711221636,
      "grad_norm": 0.24050353467464447,
      "learning_rate": 6.554631644389184e-06,
      "loss": 0.1458,
      "step": 8867
    },
    {
      "epoch": 0.6891513832763444,
      "grad_norm": 0.5588659644126892,
      "learning_rate": 6.554243083618278e-06,
      "loss": 0.9736,
      "step": 8868
    },
    {
      "epoch": 0.6892290954305254,
      "grad_norm": 0.2932495176792145,
      "learning_rate": 6.5538545228473735e-06,
      "loss": 0.1525,
      "step": 8869
    },
    {
      "epoch": 0.6893068075847062,
      "grad_norm": 0.20386630296707153,
      "learning_rate": 6.553465962076469e-06,
      "loss": 0.0458,
      "step": 8870
    },
    {
      "epoch": 0.6893845197388871,
      "grad_norm": 0.058660585433244705,
      "learning_rate": 6.553077401305564e-06,
      "loss": 0.0131,
      "step": 8871
    },
    {
      "epoch": 0.6894622318930681,
      "grad_norm": 0.42668822407722473,
      "learning_rate": 6.55268884053466e-06,
      "loss": 0.0828,
      "step": 8872
    },
    {
      "epoch": 0.6895399440472489,
      "grad_norm": 0.37161949276924133,
      "learning_rate": 6.552300279763756e-06,
      "loss": 0.1403,
      "step": 8873
    },
    {
      "epoch": 0.6896176562014299,
      "grad_norm": 0.3011918365955353,
      "learning_rate": 6.551911718992851e-06,
      "loss": 0.1238,
      "step": 8874
    },
    {
      "epoch": 0.6896953683556108,
      "grad_norm": 0.32810401916503906,
      "learning_rate": 6.551523158221947e-06,
      "loss": 0.1245,
      "step": 8875
    },
    {
      "epoch": 0.6897730805097917,
      "grad_norm": 0.2868918776512146,
      "learning_rate": 6.551134597451042e-06,
      "loss": 0.0635,
      "step": 8876
    },
    {
      "epoch": 0.6898507926639726,
      "grad_norm": 0.3549686670303345,
      "learning_rate": 6.5507460366801365e-06,
      "loss": 0.1306,
      "step": 8877
    },
    {
      "epoch": 0.6899285048181536,
      "grad_norm": 0.33203285932540894,
      "learning_rate": 6.550357475909232e-06,
      "loss": 0.2719,
      "step": 8878
    },
    {
      "epoch": 0.6900062169723344,
      "grad_norm": 0.9596408009529114,
      "learning_rate": 6.549968915138328e-06,
      "loss": 0.4823,
      "step": 8879
    },
    {
      "epoch": 0.6900839291265154,
      "grad_norm": 0.11524076759815216,
      "learning_rate": 6.549580354367424e-06,
      "loss": 0.0304,
      "step": 8880
    },
    {
      "epoch": 0.6901616412806963,
      "grad_norm": 0.6248058080673218,
      "learning_rate": 6.549191793596519e-06,
      "loss": 0.1975,
      "step": 8881
    },
    {
      "epoch": 0.6902393534348772,
      "grad_norm": 0.4489060044288635,
      "learning_rate": 6.548803232825615e-06,
      "loss": 0.3357,
      "step": 8882
    },
    {
      "epoch": 0.6903170655890581,
      "grad_norm": 0.4227389395236969,
      "learning_rate": 6.54841467205471e-06,
      "loss": 0.1832,
      "step": 8883
    },
    {
      "epoch": 0.6903947777432391,
      "grad_norm": 0.7311251759529114,
      "learning_rate": 6.548026111283805e-06,
      "loss": 0.2286,
      "step": 8884
    },
    {
      "epoch": 0.6904724898974199,
      "grad_norm": 0.2856210172176361,
      "learning_rate": 6.547637550512901e-06,
      "loss": 0.2852,
      "step": 8885
    },
    {
      "epoch": 0.6905502020516009,
      "grad_norm": 0.29048988223075867,
      "learning_rate": 6.547248989741997e-06,
      "loss": 0.2706,
      "step": 8886
    },
    {
      "epoch": 0.6906279142057817,
      "grad_norm": 0.5591618418693542,
      "learning_rate": 6.546860428971091e-06,
      "loss": 0.6427,
      "step": 8887
    },
    {
      "epoch": 0.6907056263599627,
      "grad_norm": 0.16567060351371765,
      "learning_rate": 6.546471868200187e-06,
      "loss": 0.0617,
      "step": 8888
    },
    {
      "epoch": 0.6907833385141436,
      "grad_norm": 0.5686455368995667,
      "learning_rate": 6.546083307429283e-06,
      "loss": 0.1475,
      "step": 8889
    },
    {
      "epoch": 0.6908610506683245,
      "grad_norm": 0.10620749741792679,
      "learning_rate": 6.545694746658378e-06,
      "loss": 0.0156,
      "step": 8890
    },
    {
      "epoch": 0.6909387628225054,
      "grad_norm": 0.501184344291687,
      "learning_rate": 6.545306185887473e-06,
      "loss": 0.0959,
      "step": 8891
    },
    {
      "epoch": 0.6910164749766864,
      "grad_norm": 0.6103346347808838,
      "learning_rate": 6.544917625116569e-06,
      "loss": 0.1977,
      "step": 8892
    },
    {
      "epoch": 0.6910941871308672,
      "grad_norm": 0.036371588706970215,
      "learning_rate": 6.544529064345664e-06,
      "loss": 0.0147,
      "step": 8893
    },
    {
      "epoch": 0.6911718992850482,
      "grad_norm": 0.44062548875808716,
      "learning_rate": 6.54414050357476e-06,
      "loss": 0.2242,
      "step": 8894
    },
    {
      "epoch": 0.6912496114392291,
      "grad_norm": 0.3771819770336151,
      "learning_rate": 6.543751942803856e-06,
      "loss": 0.5078,
      "step": 8895
    },
    {
      "epoch": 0.69132732359341,
      "grad_norm": 0.38993972539901733,
      "learning_rate": 6.54336338203295e-06,
      "loss": 0.2679,
      "step": 8896
    },
    {
      "epoch": 0.6914050357475909,
      "grad_norm": 0.35209178924560547,
      "learning_rate": 6.542974821262046e-06,
      "loss": 0.0807,
      "step": 8897
    },
    {
      "epoch": 0.6914827479017719,
      "grad_norm": 0.2857613265514374,
      "learning_rate": 6.5425862604911414e-06,
      "loss": 0.1564,
      "step": 8898
    },
    {
      "epoch": 0.6915604600559527,
      "grad_norm": 0.6026773452758789,
      "learning_rate": 6.542197699720236e-06,
      "loss": 0.2236,
      "step": 8899
    },
    {
      "epoch": 0.6916381722101337,
      "grad_norm": 0.37349820137023926,
      "learning_rate": 6.541809138949332e-06,
      "loss": 0.102,
      "step": 8900
    },
    {
      "epoch": 0.6917158843643145,
      "grad_norm": 0.11595946550369263,
      "learning_rate": 6.541420578178428e-06,
      "loss": 0.0386,
      "step": 8901
    },
    {
      "epoch": 0.6917935965184955,
      "grad_norm": 0.2625123858451843,
      "learning_rate": 6.541032017407523e-06,
      "loss": 0.0931,
      "step": 8902
    },
    {
      "epoch": 0.6918713086726764,
      "grad_norm": 0.15370136499404907,
      "learning_rate": 6.540643456636619e-06,
      "loss": 0.1063,
      "step": 8903
    },
    {
      "epoch": 0.6919490208268573,
      "grad_norm": 0.2878384292125702,
      "learning_rate": 6.5402548958657145e-06,
      "loss": 0.1036,
      "step": 8904
    },
    {
      "epoch": 0.6920267329810382,
      "grad_norm": 0.2866138517856598,
      "learning_rate": 6.539866335094809e-06,
      "loss": 0.17,
      "step": 8905
    },
    {
      "epoch": 0.6921044451352192,
      "grad_norm": 0.32415077090263367,
      "learning_rate": 6.539477774323904e-06,
      "loss": 0.0844,
      "step": 8906
    },
    {
      "epoch": 0.6921821572894,
      "grad_norm": 0.44239336252212524,
      "learning_rate": 6.539089213553e-06,
      "loss": 0.4767,
      "step": 8907
    },
    {
      "epoch": 0.692259869443581,
      "grad_norm": 0.28239181637763977,
      "learning_rate": 6.538700652782096e-06,
      "loss": 0.0597,
      "step": 8908
    },
    {
      "epoch": 0.6923375815977619,
      "grad_norm": 0.8797467350959778,
      "learning_rate": 6.538312092011191e-06,
      "loss": 0.5104,
      "step": 8909
    },
    {
      "epoch": 0.6924152937519428,
      "grad_norm": 0.5240907669067383,
      "learning_rate": 6.537923531240287e-06,
      "loss": 0.2655,
      "step": 8910
    },
    {
      "epoch": 0.6924930059061237,
      "grad_norm": 0.5939412117004395,
      "learning_rate": 6.5375349704693826e-06,
      "loss": 0.2147,
      "step": 8911
    },
    {
      "epoch": 0.6925707180603047,
      "grad_norm": 0.20785744488239288,
      "learning_rate": 6.5371464096984775e-06,
      "loss": 0.1145,
      "step": 8912
    },
    {
      "epoch": 0.6926484302144855,
      "grad_norm": 0.18096014857292175,
      "learning_rate": 6.536757848927573e-06,
      "loss": 0.0759,
      "step": 8913
    },
    {
      "epoch": 0.6927261423686665,
      "grad_norm": 0.8355162739753723,
      "learning_rate": 6.536369288156669e-06,
      "loss": 0.3188,
      "step": 8914
    },
    {
      "epoch": 0.6928038545228474,
      "grad_norm": 1.3275467157363892,
      "learning_rate": 6.535980727385763e-06,
      "loss": 0.3323,
      "step": 8915
    },
    {
      "epoch": 0.6928815666770283,
      "grad_norm": 0.22831743955612183,
      "learning_rate": 6.535592166614859e-06,
      "loss": 0.0594,
      "step": 8916
    },
    {
      "epoch": 0.6929592788312092,
      "grad_norm": 0.3252299427986145,
      "learning_rate": 6.535203605843955e-06,
      "loss": 0.1093,
      "step": 8917
    },
    {
      "epoch": 0.6930369909853901,
      "grad_norm": 0.5587537288665771,
      "learning_rate": 6.53481504507305e-06,
      "loss": 0.2388,
      "step": 8918
    },
    {
      "epoch": 0.693114703139571,
      "grad_norm": 0.06844550371170044,
      "learning_rate": 6.5344264843021455e-06,
      "loss": 0.0144,
      "step": 8919
    },
    {
      "epoch": 0.693192415293752,
      "grad_norm": 0.3365388512611389,
      "learning_rate": 6.534037923531241e-06,
      "loss": 0.1902,
      "step": 8920
    },
    {
      "epoch": 0.6932701274479328,
      "grad_norm": 0.4090500771999359,
      "learning_rate": 6.533649362760336e-06,
      "loss": 0.2824,
      "step": 8921
    },
    {
      "epoch": 0.6933478396021138,
      "grad_norm": 0.4043755829334259,
      "learning_rate": 6.533260801989432e-06,
      "loss": 0.0865,
      "step": 8922
    },
    {
      "epoch": 0.6934255517562947,
      "grad_norm": 0.3068282902240753,
      "learning_rate": 6.532872241218528e-06,
      "loss": 0.0694,
      "step": 8923
    },
    {
      "epoch": 0.6935032639104756,
      "grad_norm": 0.2830961048603058,
      "learning_rate": 6.532483680447622e-06,
      "loss": 0.1971,
      "step": 8924
    },
    {
      "epoch": 0.6935809760646565,
      "grad_norm": 0.3029167950153351,
      "learning_rate": 6.532095119676718e-06,
      "loss": 0.2418,
      "step": 8925
    },
    {
      "epoch": 0.6936586882188375,
      "grad_norm": 0.025997593998908997,
      "learning_rate": 6.531706558905814e-06,
      "loss": 0.0039,
      "step": 8926
    },
    {
      "epoch": 0.6937364003730183,
      "grad_norm": 0.3498612940311432,
      "learning_rate": 6.5313179981349085e-06,
      "loss": 0.1563,
      "step": 8927
    },
    {
      "epoch": 0.6938141125271993,
      "grad_norm": 0.3013472259044647,
      "learning_rate": 6.530929437364004e-06,
      "loss": 0.1329,
      "step": 8928
    },
    {
      "epoch": 0.6938918246813802,
      "grad_norm": 0.3164326250553131,
      "learning_rate": 6.5305408765931e-06,
      "loss": 0.099,
      "step": 8929
    },
    {
      "epoch": 0.6939695368355611,
      "grad_norm": 0.20695236325263977,
      "learning_rate": 6.530152315822195e-06,
      "loss": 0.0501,
      "step": 8930
    },
    {
      "epoch": 0.694047248989742,
      "grad_norm": 0.5485718250274658,
      "learning_rate": 6.529763755051291e-06,
      "loss": 0.3951,
      "step": 8931
    },
    {
      "epoch": 0.6941249611439229,
      "grad_norm": 0.1952078938484192,
      "learning_rate": 6.529375194280386e-06,
      "loss": 0.0944,
      "step": 8932
    },
    {
      "epoch": 0.6942026732981038,
      "grad_norm": 0.47547560930252075,
      "learning_rate": 6.528986633509481e-06,
      "loss": 0.2804,
      "step": 8933
    },
    {
      "epoch": 0.6942803854522848,
      "grad_norm": 0.2941899597644806,
      "learning_rate": 6.5285980727385766e-06,
      "loss": 0.2132,
      "step": 8934
    },
    {
      "epoch": 0.6943580976064656,
      "grad_norm": 0.49129989743232727,
      "learning_rate": 6.528209511967672e-06,
      "loss": 0.1339,
      "step": 8935
    },
    {
      "epoch": 0.6944358097606466,
      "grad_norm": 0.8909105658531189,
      "learning_rate": 6.527820951196767e-06,
      "loss": 0.3226,
      "step": 8936
    },
    {
      "epoch": 0.6945135219148275,
      "grad_norm": 0.19561804831027985,
      "learning_rate": 6.527432390425863e-06,
      "loss": 0.1398,
      "step": 8937
    },
    {
      "epoch": 0.6945912340690084,
      "grad_norm": 0.28777480125427246,
      "learning_rate": 6.527043829654959e-06,
      "loss": 0.1989,
      "step": 8938
    },
    {
      "epoch": 0.6946689462231893,
      "grad_norm": 0.5806780457496643,
      "learning_rate": 6.526655268884055e-06,
      "loss": 0.3937,
      "step": 8939
    },
    {
      "epoch": 0.6947466583773703,
      "grad_norm": 0.4562702178955078,
      "learning_rate": 6.526266708113149e-06,
      "loss": 0.2492,
      "step": 8940
    },
    {
      "epoch": 0.6948243705315511,
      "grad_norm": 0.20833146572113037,
      "learning_rate": 6.525878147342245e-06,
      "loss": 0.139,
      "step": 8941
    },
    {
      "epoch": 0.6949020826857321,
      "grad_norm": 0.1970571130514145,
      "learning_rate": 6.52548958657134e-06,
      "loss": 0.1106,
      "step": 8942
    },
    {
      "epoch": 0.694979794839913,
      "grad_norm": 0.6239151954650879,
      "learning_rate": 6.525101025800435e-06,
      "loss": 0.2586,
      "step": 8943
    },
    {
      "epoch": 0.6950575069940939,
      "grad_norm": 0.3777054250240326,
      "learning_rate": 6.524712465029531e-06,
      "loss": 0.1959,
      "step": 8944
    },
    {
      "epoch": 0.6951352191482748,
      "grad_norm": 0.3247683048248291,
      "learning_rate": 6.524323904258627e-06,
      "loss": 0.1043,
      "step": 8945
    },
    {
      "epoch": 0.6952129313024557,
      "grad_norm": 1.4458259344100952,
      "learning_rate": 6.523935343487722e-06,
      "loss": 0.7025,
      "step": 8946
    },
    {
      "epoch": 0.6952906434566366,
      "grad_norm": 0.3684687614440918,
      "learning_rate": 6.523546782716818e-06,
      "loss": 0.2331,
      "step": 8947
    },
    {
      "epoch": 0.6953683556108176,
      "grad_norm": 0.5006905198097229,
      "learning_rate": 6.5231582219459135e-06,
      "loss": 0.1563,
      "step": 8948
    },
    {
      "epoch": 0.6954460677649984,
      "grad_norm": 0.5046784281730652,
      "learning_rate": 6.522769661175008e-06,
      "loss": 0.3568,
      "step": 8949
    },
    {
      "epoch": 0.6955237799191794,
      "grad_norm": 0.3740144968032837,
      "learning_rate": 6.522381100404103e-06,
      "loss": 0.1458,
      "step": 8950
    },
    {
      "epoch": 0.6956014920733603,
      "grad_norm": 0.5231555104255676,
      "learning_rate": 6.521992539633199e-06,
      "loss": 0.1147,
      "step": 8951
    },
    {
      "epoch": 0.6956792042275411,
      "grad_norm": 0.21766997873783112,
      "learning_rate": 6.521603978862294e-06,
      "loss": 0.0779,
      "step": 8952
    },
    {
      "epoch": 0.6957569163817221,
      "grad_norm": 0.8288713693618774,
      "learning_rate": 6.52121541809139e-06,
      "loss": 0.2318,
      "step": 8953
    },
    {
      "epoch": 0.695834628535903,
      "grad_norm": 0.3254689574241638,
      "learning_rate": 6.520826857320486e-06,
      "loss": 0.131,
      "step": 8954
    },
    {
      "epoch": 0.6959123406900839,
      "grad_norm": 0.3542357087135315,
      "learning_rate": 6.520438296549581e-06,
      "loss": 0.1329,
      "step": 8955
    },
    {
      "epoch": 0.6959900528442649,
      "grad_norm": 0.32862141728401184,
      "learning_rate": 6.5200497357786765e-06,
      "loss": 0.3311,
      "step": 8956
    },
    {
      "epoch": 0.6960677649984458,
      "grad_norm": 0.46731188893318176,
      "learning_rate": 6.519661175007772e-06,
      "loss": 0.2241,
      "step": 8957
    },
    {
      "epoch": 0.6961454771526266,
      "grad_norm": 0.3474076986312866,
      "learning_rate": 6.519272614236866e-06,
      "loss": 0.147,
      "step": 8958
    },
    {
      "epoch": 0.6962231893068076,
      "grad_norm": 0.9550470113754272,
      "learning_rate": 6.518884053465962e-06,
      "loss": 0.2652,
      "step": 8959
    },
    {
      "epoch": 0.6963009014609886,
      "grad_norm": 0.3063863515853882,
      "learning_rate": 6.518495492695058e-06,
      "loss": 0.1032,
      "step": 8960
    },
    {
      "epoch": 0.6963786136151694,
      "grad_norm": 0.29307159781455994,
      "learning_rate": 6.518106931924153e-06,
      "loss": 0.192,
      "step": 8961
    },
    {
      "epoch": 0.6964563257693503,
      "grad_norm": 0.36701148748397827,
      "learning_rate": 6.517718371153249e-06,
      "loss": 0.1545,
      "step": 8962
    },
    {
      "epoch": 0.6965340379235312,
      "grad_norm": 0.19962731003761292,
      "learning_rate": 6.5173298103823445e-06,
      "loss": 0.1525,
      "step": 8963
    },
    {
      "epoch": 0.6966117500777121,
      "grad_norm": 0.4802618622779846,
      "learning_rate": 6.5169412496114395e-06,
      "loss": 0.2394,
      "step": 8964
    },
    {
      "epoch": 0.6966894622318931,
      "grad_norm": 0.1328406184911728,
      "learning_rate": 6.516552688840535e-06,
      "loss": 0.0728,
      "step": 8965
    },
    {
      "epoch": 0.6967671743860739,
      "grad_norm": 0.35887378454208374,
      "learning_rate": 6.516164128069631e-06,
      "loss": 0.1248,
      "step": 8966
    },
    {
      "epoch": 0.6968448865402549,
      "grad_norm": 0.5543833374977112,
      "learning_rate": 6.515775567298725e-06,
      "loss": 0.2234,
      "step": 8967
    },
    {
      "epoch": 0.6969225986944358,
      "grad_norm": 0.27439141273498535,
      "learning_rate": 6.515387006527821e-06,
      "loss": 0.0626,
      "step": 8968
    },
    {
      "epoch": 0.6970003108486167,
      "grad_norm": 0.3475908935070038,
      "learning_rate": 6.514998445756917e-06,
      "loss": 0.3181,
      "step": 8969
    },
    {
      "epoch": 0.6970780230027976,
      "grad_norm": 0.3604920506477356,
      "learning_rate": 6.5146098849860125e-06,
      "loss": 0.2574,
      "step": 8970
    },
    {
      "epoch": 0.6971557351569786,
      "grad_norm": 0.21724244952201843,
      "learning_rate": 6.5142213242151075e-06,
      "loss": 0.0545,
      "step": 8971
    },
    {
      "epoch": 0.6972334473111594,
      "grad_norm": 1.3713874816894531,
      "learning_rate": 6.513832763444203e-06,
      "loss": 0.1966,
      "step": 8972
    },
    {
      "epoch": 0.6973111594653404,
      "grad_norm": 0.6758919954299927,
      "learning_rate": 6.513444202673299e-06,
      "loss": 0.1895,
      "step": 8973
    },
    {
      "epoch": 0.6973888716195213,
      "grad_norm": 0.7479397654533386,
      "learning_rate": 6.513055641902394e-06,
      "loss": 0.4582,
      "step": 8974
    },
    {
      "epoch": 0.6974665837737022,
      "grad_norm": 0.3846904933452606,
      "learning_rate": 6.51266708113149e-06,
      "loss": 0.3654,
      "step": 8975
    },
    {
      "epoch": 0.6975442959278831,
      "grad_norm": 0.501406729221344,
      "learning_rate": 6.512278520360586e-06,
      "loss": 0.1311,
      "step": 8976
    },
    {
      "epoch": 0.697622008082064,
      "grad_norm": 1.244860053062439,
      "learning_rate": 6.51188995958968e-06,
      "loss": 0.4595,
      "step": 8977
    },
    {
      "epoch": 0.6976997202362449,
      "grad_norm": 0.38150352239608765,
      "learning_rate": 6.5115013988187755e-06,
      "loss": 0.2216,
      "step": 8978
    },
    {
      "epoch": 0.6977774323904259,
      "grad_norm": 0.07872665673494339,
      "learning_rate": 6.511112838047871e-06,
      "loss": 0.0133,
      "step": 8979
    },
    {
      "epoch": 0.6978551445446067,
      "grad_norm": 0.6380438804626465,
      "learning_rate": 6.510724277276966e-06,
      "loss": 0.4054,
      "step": 8980
    },
    {
      "epoch": 0.6979328566987877,
      "grad_norm": 0.7386038899421692,
      "learning_rate": 6.510335716506062e-06,
      "loss": 0.274,
      "step": 8981
    },
    {
      "epoch": 0.6980105688529686,
      "grad_norm": 0.06382904201745987,
      "learning_rate": 6.509947155735158e-06,
      "loss": 0.009,
      "step": 8982
    },
    {
      "epoch": 0.6980882810071495,
      "grad_norm": 0.14515157043933868,
      "learning_rate": 6.509558594964253e-06,
      "loss": 0.0288,
      "step": 8983
    },
    {
      "epoch": 0.6981659931613304,
      "grad_norm": 0.7288029193878174,
      "learning_rate": 6.509170034193349e-06,
      "loss": 0.4827,
      "step": 8984
    },
    {
      "epoch": 0.6982437053155114,
      "grad_norm": 0.3085695803165436,
      "learning_rate": 6.508781473422444e-06,
      "loss": 0.1792,
      "step": 8985
    },
    {
      "epoch": 0.6983214174696922,
      "grad_norm": 0.3380044400691986,
      "learning_rate": 6.5083929126515385e-06,
      "loss": 0.1684,
      "step": 8986
    },
    {
      "epoch": 0.6983991296238732,
      "grad_norm": 0.2105288803577423,
      "learning_rate": 6.508004351880634e-06,
      "loss": 0.0278,
      "step": 8987
    },
    {
      "epoch": 0.6984768417780541,
      "grad_norm": 0.34445446729660034,
      "learning_rate": 6.50761579110973e-06,
      "loss": 0.132,
      "step": 8988
    },
    {
      "epoch": 0.698554553932235,
      "grad_norm": 0.4208880066871643,
      "learning_rate": 6.507227230338825e-06,
      "loss": 0.2512,
      "step": 8989
    },
    {
      "epoch": 0.6986322660864159,
      "grad_norm": 0.6944780349731445,
      "learning_rate": 6.506838669567921e-06,
      "loss": 0.1948,
      "step": 8990
    },
    {
      "epoch": 0.6987099782405968,
      "grad_norm": 0.5434215068817139,
      "learning_rate": 6.506450108797017e-06,
      "loss": 0.3223,
      "step": 8991
    },
    {
      "epoch": 0.6987876903947777,
      "grad_norm": 0.45156270265579224,
      "learning_rate": 6.506061548026112e-06,
      "loss": 0.0976,
      "step": 8992
    },
    {
      "epoch": 0.6988654025489587,
      "grad_norm": 0.13805243372917175,
      "learning_rate": 6.505672987255207e-06,
      "loss": 0.02,
      "step": 8993
    },
    {
      "epoch": 0.6989431147031395,
      "grad_norm": 0.5128412246704102,
      "learning_rate": 6.505284426484303e-06,
      "loss": 0.3728,
      "step": 8994
    },
    {
      "epoch": 0.6990208268573205,
      "grad_norm": 0.5526968240737915,
      "learning_rate": 6.504895865713397e-06,
      "loss": 0.1029,
      "step": 8995
    },
    {
      "epoch": 0.6990985390115014,
      "grad_norm": 0.7243157029151917,
      "learning_rate": 6.504507304942493e-06,
      "loss": 0.1662,
      "step": 8996
    },
    {
      "epoch": 0.6991762511656823,
      "grad_norm": 0.1283111274242401,
      "learning_rate": 6.504118744171589e-06,
      "loss": 0.0735,
      "step": 8997
    },
    {
      "epoch": 0.6992539633198632,
      "grad_norm": 0.15362125635147095,
      "learning_rate": 6.503730183400684e-06,
      "loss": 0.0904,
      "step": 8998
    },
    {
      "epoch": 0.6993316754740442,
      "grad_norm": 0.28150758147239685,
      "learning_rate": 6.50334162262978e-06,
      "loss": 0.1291,
      "step": 8999
    },
    {
      "epoch": 0.699409387628225,
      "grad_norm": 0.33597737550735474,
      "learning_rate": 6.5029530618588754e-06,
      "loss": 0.0415,
      "step": 9000
    },
    {
      "epoch": 0.699487099782406,
      "grad_norm": 0.36488279700279236,
      "learning_rate": 6.502564501087971e-06,
      "loss": 0.5807,
      "step": 9001
    },
    {
      "epoch": 0.6995648119365869,
      "grad_norm": 0.2584059238433838,
      "learning_rate": 6.502175940317066e-06,
      "loss": 0.1589,
      "step": 9002
    },
    {
      "epoch": 0.6996425240907678,
      "grad_norm": 0.14201577007770538,
      "learning_rate": 6.501787379546162e-06,
      "loss": 0.0478,
      "step": 9003
    },
    {
      "epoch": 0.6997202362449487,
      "grad_norm": 0.23529799282550812,
      "learning_rate": 6.501398818775258e-06,
      "loss": 0.0392,
      "step": 9004
    },
    {
      "epoch": 0.6997979483991297,
      "grad_norm": 0.503034234046936,
      "learning_rate": 6.501010258004352e-06,
      "loss": 0.1511,
      "step": 9005
    },
    {
      "epoch": 0.6998756605533105,
      "grad_norm": 0.03362620994448662,
      "learning_rate": 6.500621697233448e-06,
      "loss": 0.0033,
      "step": 9006
    },
    {
      "epoch": 0.6999533727074915,
      "grad_norm": 0.5868703722953796,
      "learning_rate": 6.5002331364625435e-06,
      "loss": 0.2401,
      "step": 9007
    },
    {
      "epoch": 0.7000310848616723,
      "grad_norm": 0.4787524938583374,
      "learning_rate": 6.4998445756916384e-06,
      "loss": 0.6108,
      "step": 9008
    },
    {
      "epoch": 0.7001087970158533,
      "grad_norm": 0.76264488697052,
      "learning_rate": 6.499456014920734e-06,
      "loss": 0.374,
      "step": 9009
    },
    {
      "epoch": 0.7001865091700342,
      "grad_norm": 0.1091107651591301,
      "learning_rate": 6.49906745414983e-06,
      "loss": 0.0426,
      "step": 9010
    },
    {
      "epoch": 0.7002642213242151,
      "grad_norm": 0.08134670555591583,
      "learning_rate": 6.498678893378925e-06,
      "loss": 0.0108,
      "step": 9011
    },
    {
      "epoch": 0.700341933478396,
      "grad_norm": 0.2890060245990753,
      "learning_rate": 6.498290332608021e-06,
      "loss": 0.1097,
      "step": 9012
    },
    {
      "epoch": 0.700419645632577,
      "grad_norm": 0.726491391658783,
      "learning_rate": 6.4979017718371166e-06,
      "loss": 0.3893,
      "step": 9013
    },
    {
      "epoch": 0.7004973577867578,
      "grad_norm": 0.24732640385627747,
      "learning_rate": 6.497513211066211e-06,
      "loss": 0.0998,
      "step": 9014
    },
    {
      "epoch": 0.7005750699409388,
      "grad_norm": 0.22199764847755432,
      "learning_rate": 6.4971246502953065e-06,
      "loss": 0.0618,
      "step": 9015
    },
    {
      "epoch": 0.7006527820951197,
      "grad_norm": 0.5656129717826843,
      "learning_rate": 6.496736089524402e-06,
      "loss": 0.5433,
      "step": 9016
    },
    {
      "epoch": 0.7007304942493006,
      "grad_norm": 0.13199099898338318,
      "learning_rate": 6.496347528753497e-06,
      "loss": 0.0528,
      "step": 9017
    },
    {
      "epoch": 0.7008082064034815,
      "grad_norm": 0.22207432985305786,
      "learning_rate": 6.495958967982593e-06,
      "loss": 0.0828,
      "step": 9018
    },
    {
      "epoch": 0.7008859185576625,
      "grad_norm": 0.8058146238327026,
      "learning_rate": 6.495570407211689e-06,
      "loss": 0.2663,
      "step": 9019
    },
    {
      "epoch": 0.7009636307118433,
      "grad_norm": 0.032290488481521606,
      "learning_rate": 6.495181846440784e-06,
      "loss": 0.0141,
      "step": 9020
    },
    {
      "epoch": 0.7010413428660243,
      "grad_norm": 0.4472505748271942,
      "learning_rate": 6.4947932856698796e-06,
      "loss": 0.4437,
      "step": 9021
    },
    {
      "epoch": 0.7011190550202051,
      "grad_norm": 0.4106238782405853,
      "learning_rate": 6.494404724898975e-06,
      "loss": 0.3863,
      "step": 9022
    },
    {
      "epoch": 0.7011967671743861,
      "grad_norm": 0.24318906664848328,
      "learning_rate": 6.4940161641280694e-06,
      "loss": 0.0462,
      "step": 9023
    },
    {
      "epoch": 0.701274479328567,
      "grad_norm": 0.1561947911977768,
      "learning_rate": 6.493627603357165e-06,
      "loss": 0.0383,
      "step": 9024
    },
    {
      "epoch": 0.7013521914827479,
      "grad_norm": 0.6064570546150208,
      "learning_rate": 6.493239042586261e-06,
      "loss": 0.1497,
      "step": 9025
    },
    {
      "epoch": 0.7014299036369288,
      "grad_norm": 0.2763828635215759,
      "learning_rate": 6.492850481815356e-06,
      "loss": 0.0915,
      "step": 9026
    },
    {
      "epoch": 0.7015076157911098,
      "grad_norm": 0.1036391630768776,
      "learning_rate": 6.492461921044452e-06,
      "loss": 0.0573,
      "step": 9027
    },
    {
      "epoch": 0.7015853279452906,
      "grad_norm": 0.6327958703041077,
      "learning_rate": 6.492073360273548e-06,
      "loss": 0.1059,
      "step": 9028
    },
    {
      "epoch": 0.7016630400994716,
      "grad_norm": 0.12260280549526215,
      "learning_rate": 6.491684799502643e-06,
      "loss": 0.0334,
      "step": 9029
    },
    {
      "epoch": 0.7017407522536525,
      "grad_norm": 0.4905236065387726,
      "learning_rate": 6.491296238731738e-06,
      "loss": 0.3073,
      "step": 9030
    },
    {
      "epoch": 0.7018184644078334,
      "grad_norm": 0.3736186921596527,
      "learning_rate": 6.490907677960834e-06,
      "loss": 0.0767,
      "step": 9031
    },
    {
      "epoch": 0.7018961765620143,
      "grad_norm": 0.24229392409324646,
      "learning_rate": 6.49051911718993e-06,
      "loss": 0.1346,
      "step": 9032
    },
    {
      "epoch": 0.7019738887161953,
      "grad_norm": 0.2607622742652893,
      "learning_rate": 6.490130556419024e-06,
      "loss": 0.1884,
      "step": 9033
    },
    {
      "epoch": 0.7020516008703761,
      "grad_norm": 1.297323226928711,
      "learning_rate": 6.48974199564812e-06,
      "loss": 0.4917,
      "step": 9034
    },
    {
      "epoch": 0.7021293130245571,
      "grad_norm": 0.5696485638618469,
      "learning_rate": 6.489353434877216e-06,
      "loss": 0.1672,
      "step": 9035
    },
    {
      "epoch": 0.702207025178738,
      "grad_norm": 0.08703126758337021,
      "learning_rate": 6.4889648741063106e-06,
      "loss": 0.0203,
      "step": 9036
    },
    {
      "epoch": 0.7022847373329189,
      "grad_norm": 0.1758357137441635,
      "learning_rate": 6.488576313335406e-06,
      "loss": 0.0296,
      "step": 9037
    },
    {
      "epoch": 0.7023624494870998,
      "grad_norm": 0.3820842206478119,
      "learning_rate": 6.488187752564502e-06,
      "loss": 0.2752,
      "step": 9038
    },
    {
      "epoch": 0.7024401616412806,
      "grad_norm": 0.06613068282604218,
      "learning_rate": 6.487799191793597e-06,
      "loss": 0.0152,
      "step": 9039
    },
    {
      "epoch": 0.7025178737954616,
      "grad_norm": 0.17603766918182373,
      "learning_rate": 6.487410631022693e-06,
      "loss": 0.0384,
      "step": 9040
    },
    {
      "epoch": 0.7025955859496426,
      "grad_norm": 0.3668345510959625,
      "learning_rate": 6.487022070251789e-06,
      "loss": 0.2639,
      "step": 9041
    },
    {
      "epoch": 0.7026732981038234,
      "grad_norm": 0.962863564491272,
      "learning_rate": 6.486633509480883e-06,
      "loss": 0.8597,
      "step": 9042
    },
    {
      "epoch": 0.7027510102580043,
      "grad_norm": 0.5453013777732849,
      "learning_rate": 6.486244948709979e-06,
      "loss": 0.261,
      "step": 9043
    },
    {
      "epoch": 0.7028287224121853,
      "grad_norm": 0.20096589624881744,
      "learning_rate": 6.485856387939074e-06,
      "loss": 0.0307,
      "step": 9044
    },
    {
      "epoch": 0.7029064345663661,
      "grad_norm": 0.7109890580177307,
      "learning_rate": 6.485467827168169e-06,
      "loss": 0.8736,
      "step": 9045
    },
    {
      "epoch": 0.7029841467205471,
      "grad_norm": 0.29499512910842896,
      "learning_rate": 6.485079266397265e-06,
      "loss": 0.2694,
      "step": 9046
    },
    {
      "epoch": 0.703061858874728,
      "grad_norm": 0.3263031840324402,
      "learning_rate": 6.484690705626361e-06,
      "loss": 0.223,
      "step": 9047
    },
    {
      "epoch": 0.7031395710289089,
      "grad_norm": 0.39868247509002686,
      "learning_rate": 6.484302144855456e-06,
      "loss": 0.1373,
      "step": 9048
    },
    {
      "epoch": 0.7032172831830898,
      "grad_norm": 0.4174307882785797,
      "learning_rate": 6.483913584084552e-06,
      "loss": 0.1856,
      "step": 9049
    },
    {
      "epoch": 0.7032949953372708,
      "grad_norm": 0.38911381363868713,
      "learning_rate": 6.4835250233136475e-06,
      "loss": 0.1904,
      "step": 9050
    },
    {
      "epoch": 0.7033727074914516,
      "grad_norm": 0.710059642791748,
      "learning_rate": 6.483136462542742e-06,
      "loss": 0.1859,
      "step": 9051
    },
    {
      "epoch": 0.7034504196456326,
      "grad_norm": 0.5837097764015198,
      "learning_rate": 6.482747901771837e-06,
      "loss": 0.1287,
      "step": 9052
    },
    {
      "epoch": 0.7035281317998134,
      "grad_norm": 0.22330419719219208,
      "learning_rate": 6.482359341000933e-06,
      "loss": 0.1144,
      "step": 9053
    },
    {
      "epoch": 0.7036058439539944,
      "grad_norm": 0.4527314603328705,
      "learning_rate": 6.481970780230028e-06,
      "loss": 0.2814,
      "step": 9054
    },
    {
      "epoch": 0.7036835561081753,
      "grad_norm": 0.21414059400558472,
      "learning_rate": 6.481582219459124e-06,
      "loss": 0.2379,
      "step": 9055
    },
    {
      "epoch": 0.7037612682623562,
      "grad_norm": 0.48007574677467346,
      "learning_rate": 6.48119365868822e-06,
      "loss": 0.2938,
      "step": 9056
    },
    {
      "epoch": 0.7038389804165371,
      "grad_norm": 0.08953489363193512,
      "learning_rate": 6.480805097917315e-06,
      "loss": 0.0217,
      "step": 9057
    },
    {
      "epoch": 0.7039166925707181,
      "grad_norm": 0.5581997036933899,
      "learning_rate": 6.4804165371464105e-06,
      "loss": 0.3925,
      "step": 9058
    },
    {
      "epoch": 0.7039944047248989,
      "grad_norm": 0.1783318817615509,
      "learning_rate": 6.4800279763755054e-06,
      "loss": 0.0669,
      "step": 9059
    },
    {
      "epoch": 0.7040721168790799,
      "grad_norm": 0.12671996653079987,
      "learning_rate": 6.479639415604601e-06,
      "loss": 0.0219,
      "step": 9060
    },
    {
      "epoch": 0.7041498290332608,
      "grad_norm": 0.25495654344558716,
      "learning_rate": 6.479250854833696e-06,
      "loss": 0.045,
      "step": 9061
    },
    {
      "epoch": 0.7042275411874417,
      "grad_norm": 0.26717156171798706,
      "learning_rate": 6.478862294062792e-06,
      "loss": 0.2095,
      "step": 9062
    },
    {
      "epoch": 0.7043052533416226,
      "grad_norm": 0.09426505118608475,
      "learning_rate": 6.478473733291888e-06,
      "loss": 0.0455,
      "step": 9063
    },
    {
      "epoch": 0.7043829654958036,
      "grad_norm": 0.39023858308792114,
      "learning_rate": 6.478085172520983e-06,
      "loss": 0.1574,
      "step": 9064
    },
    {
      "epoch": 0.7044606776499844,
      "grad_norm": 0.3963751494884491,
      "learning_rate": 6.4776966117500785e-06,
      "loss": 0.0988,
      "step": 9065
    },
    {
      "epoch": 0.7045383898041654,
      "grad_norm": 0.40765300393104553,
      "learning_rate": 6.477308050979174e-06,
      "loss": 0.2286,
      "step": 9066
    },
    {
      "epoch": 0.7046161019583462,
      "grad_norm": 0.7022320032119751,
      "learning_rate": 6.476919490208268e-06,
      "loss": 0.4785,
      "step": 9067
    },
    {
      "epoch": 0.7046938141125272,
      "grad_norm": 0.27451983094215393,
      "learning_rate": 6.476530929437364e-06,
      "loss": 0.0912,
      "step": 9068
    },
    {
      "epoch": 0.7047715262667081,
      "grad_norm": 0.24207918345928192,
      "learning_rate": 6.47614236866646e-06,
      "loss": 0.0608,
      "step": 9069
    },
    {
      "epoch": 0.704849238420889,
      "grad_norm": 0.31998804211616516,
      "learning_rate": 6.475753807895555e-06,
      "loss": 0.1665,
      "step": 9070
    },
    {
      "epoch": 0.7049269505750699,
      "grad_norm": 0.47251299023628235,
      "learning_rate": 6.475365247124651e-06,
      "loss": 0.1733,
      "step": 9071
    },
    {
      "epoch": 0.7050046627292509,
      "grad_norm": 0.3323753774166107,
      "learning_rate": 6.4749766863537466e-06,
      "loss": 0.1331,
      "step": 9072
    },
    {
      "epoch": 0.7050823748834317,
      "grad_norm": 0.3065641522407532,
      "learning_rate": 6.4745881255828415e-06,
      "loss": 0.1507,
      "step": 9073
    },
    {
      "epoch": 0.7051600870376127,
      "grad_norm": 0.5829104781150818,
      "learning_rate": 6.474199564811937e-06,
      "loss": 0.254,
      "step": 9074
    },
    {
      "epoch": 0.7052377991917936,
      "grad_norm": 0.06827632337808609,
      "learning_rate": 6.473811004041033e-06,
      "loss": 0.0036,
      "step": 9075
    },
    {
      "epoch": 0.7053155113459745,
      "grad_norm": 0.09092966467142105,
      "learning_rate": 6.473422443270127e-06,
      "loss": 0.0249,
      "step": 9076
    },
    {
      "epoch": 0.7053932235001554,
      "grad_norm": 0.5130257606506348,
      "learning_rate": 6.473033882499223e-06,
      "loss": 0.2776,
      "step": 9077
    },
    {
      "epoch": 0.7054709356543364,
      "grad_norm": 0.32275697588920593,
      "learning_rate": 6.472645321728319e-06,
      "loss": 0.1997,
      "step": 9078
    },
    {
      "epoch": 0.7055486478085172,
      "grad_norm": 0.16583116352558136,
      "learning_rate": 6.472256760957414e-06,
      "loss": 0.0437,
      "step": 9079
    },
    {
      "epoch": 0.7056263599626982,
      "grad_norm": 0.6813598275184631,
      "learning_rate": 6.4718682001865095e-06,
      "loss": 0.4499,
      "step": 9080
    },
    {
      "epoch": 0.7057040721168791,
      "grad_norm": 0.5417726039886475,
      "learning_rate": 6.471479639415605e-06,
      "loss": 0.4201,
      "step": 9081
    },
    {
      "epoch": 0.70578178427106,
      "grad_norm": 0.3973937928676605,
      "learning_rate": 6.4710910786447e-06,
      "loss": 0.2472,
      "step": 9082
    },
    {
      "epoch": 0.7058594964252409,
      "grad_norm": 0.12317456305027008,
      "learning_rate": 6.470702517873796e-06,
      "loss": 0.0958,
      "step": 9083
    },
    {
      "epoch": 0.7059372085794218,
      "grad_norm": 0.47816333174705505,
      "learning_rate": 6.470313957102892e-06,
      "loss": 0.1957,
      "step": 9084
    },
    {
      "epoch": 0.7060149207336027,
      "grad_norm": 0.17765839397907257,
      "learning_rate": 6.469925396331986e-06,
      "loss": 0.0497,
      "step": 9085
    },
    {
      "epoch": 0.7060926328877837,
      "grad_norm": 0.7161638140678406,
      "learning_rate": 6.469536835561082e-06,
      "loss": 0.182,
      "step": 9086
    },
    {
      "epoch": 0.7061703450419645,
      "grad_norm": 0.1332271546125412,
      "learning_rate": 6.4691482747901776e-06,
      "loss": 0.0599,
      "step": 9087
    },
    {
      "epoch": 0.7062480571961455,
      "grad_norm": 0.2956225872039795,
      "learning_rate": 6.4687597140192725e-06,
      "loss": 0.1031,
      "step": 9088
    },
    {
      "epoch": 0.7063257693503264,
      "grad_norm": 0.19517584145069122,
      "learning_rate": 6.468371153248368e-06,
      "loss": 0.0401,
      "step": 9089
    },
    {
      "epoch": 0.7064034815045073,
      "grad_norm": 0.22198033332824707,
      "learning_rate": 6.467982592477464e-06,
      "loss": 0.0793,
      "step": 9090
    },
    {
      "epoch": 0.7064811936586882,
      "grad_norm": 0.2093142420053482,
      "learning_rate": 6.46759403170656e-06,
      "loss": 0.1054,
      "step": 9091
    },
    {
      "epoch": 0.7065589058128692,
      "grad_norm": 0.09318490326404572,
      "learning_rate": 6.467205470935655e-06,
      "loss": 0.043,
      "step": 9092
    },
    {
      "epoch": 0.70663661796705,
      "grad_norm": 0.4755590558052063,
      "learning_rate": 6.466816910164751e-06,
      "loss": 0.1278,
      "step": 9093
    },
    {
      "epoch": 0.706714330121231,
      "grad_norm": 0.40264374017715454,
      "learning_rate": 6.4664283493938465e-06,
      "loss": 0.3038,
      "step": 9094
    },
    {
      "epoch": 0.7067920422754119,
      "grad_norm": 0.7306391596794128,
      "learning_rate": 6.4660397886229406e-06,
      "loss": 0.0839,
      "step": 9095
    },
    {
      "epoch": 0.7068697544295928,
      "grad_norm": 0.2999635934829712,
      "learning_rate": 6.465651227852036e-06,
      "loss": 0.0807,
      "step": 9096
    },
    {
      "epoch": 0.7069474665837737,
      "grad_norm": 0.4750116467475891,
      "learning_rate": 6.465262667081132e-06,
      "loss": 0.2581,
      "step": 9097
    },
    {
      "epoch": 0.7070251787379546,
      "grad_norm": 0.3467879891395569,
      "learning_rate": 6.464874106310227e-06,
      "loss": 0.2287,
      "step": 9098
    },
    {
      "epoch": 0.7071028908921355,
      "grad_norm": 0.1896616369485855,
      "learning_rate": 6.464485545539323e-06,
      "loss": 0.0839,
      "step": 9099
    },
    {
      "epoch": 0.7071806030463165,
      "grad_norm": 0.481565922498703,
      "learning_rate": 6.464096984768419e-06,
      "loss": 0.0945,
      "step": 9100
    },
    {
      "epoch": 0.7072583152004973,
      "grad_norm": 0.2612563669681549,
      "learning_rate": 6.463708423997514e-06,
      "loss": 0.1782,
      "step": 9101
    },
    {
      "epoch": 0.7073360273546783,
      "grad_norm": 0.5800377130508423,
      "learning_rate": 6.4633198632266094e-06,
      "loss": 0.0891,
      "step": 9102
    },
    {
      "epoch": 0.7074137395088592,
      "grad_norm": 0.3644218146800995,
      "learning_rate": 6.462931302455705e-06,
      "loss": 0.0368,
      "step": 9103
    },
    {
      "epoch": 0.7074914516630401,
      "grad_norm": 0.1897997409105301,
      "learning_rate": 6.462542741684799e-06,
      "loss": 0.0952,
      "step": 9104
    },
    {
      "epoch": 0.707569163817221,
      "grad_norm": 0.38448411226272583,
      "learning_rate": 6.462154180913895e-06,
      "loss": 0.1008,
      "step": 9105
    },
    {
      "epoch": 0.707646875971402,
      "grad_norm": 0.2641686797142029,
      "learning_rate": 6.461765620142991e-06,
      "loss": 0.1066,
      "step": 9106
    },
    {
      "epoch": 0.7077245881255828,
      "grad_norm": 0.5941731333732605,
      "learning_rate": 6.461377059372086e-06,
      "loss": 0.2882,
      "step": 9107
    },
    {
      "epoch": 0.7078023002797638,
      "grad_norm": 0.303330659866333,
      "learning_rate": 6.460988498601182e-06,
      "loss": 0.3065,
      "step": 9108
    },
    {
      "epoch": 0.7078800124339447,
      "grad_norm": 0.5891902446746826,
      "learning_rate": 6.4605999378302775e-06,
      "loss": 0.3398,
      "step": 9109
    },
    {
      "epoch": 0.7079577245881256,
      "grad_norm": 0.10208668559789658,
      "learning_rate": 6.4602113770593724e-06,
      "loss": 0.0069,
      "step": 9110
    },
    {
      "epoch": 0.7080354367423065,
      "grad_norm": 0.25519704818725586,
      "learning_rate": 6.459822816288468e-06,
      "loss": 0.087,
      "step": 9111
    },
    {
      "epoch": 0.7081131488964875,
      "grad_norm": 0.40202978253364563,
      "learning_rate": 6.459434255517564e-06,
      "loss": 0.4343,
      "step": 9112
    },
    {
      "epoch": 0.7081908610506683,
      "grad_norm": 0.5010877847671509,
      "learning_rate": 6.459045694746658e-06,
      "loss": 0.251,
      "step": 9113
    },
    {
      "epoch": 0.7082685732048493,
      "grad_norm": 0.6972230672836304,
      "learning_rate": 6.458657133975754e-06,
      "loss": 0.0917,
      "step": 9114
    },
    {
      "epoch": 0.7083462853590301,
      "grad_norm": 0.19986948370933533,
      "learning_rate": 6.45826857320485e-06,
      "loss": 0.151,
      "step": 9115
    },
    {
      "epoch": 0.7084239975132111,
      "grad_norm": 0.343914657831192,
      "learning_rate": 6.457880012433945e-06,
      "loss": 0.4369,
      "step": 9116
    },
    {
      "epoch": 0.708501709667392,
      "grad_norm": 0.1419014185667038,
      "learning_rate": 6.4574914516630405e-06,
      "loss": 0.0369,
      "step": 9117
    },
    {
      "epoch": 0.7085794218215729,
      "grad_norm": 0.8020851612091064,
      "learning_rate": 6.457102890892136e-06,
      "loss": 0.5095,
      "step": 9118
    },
    {
      "epoch": 0.7086571339757538,
      "grad_norm": 0.1520562469959259,
      "learning_rate": 6.456714330121231e-06,
      "loss": 0.0874,
      "step": 9119
    },
    {
      "epoch": 0.7087348461299348,
      "grad_norm": 0.4290810525417328,
      "learning_rate": 6.456325769350327e-06,
      "loss": 0.1685,
      "step": 9120
    },
    {
      "epoch": 0.7088125582841156,
      "grad_norm": 0.06036140024662018,
      "learning_rate": 6.455937208579423e-06,
      "loss": 0.01,
      "step": 9121
    },
    {
      "epoch": 0.7088902704382966,
      "grad_norm": 0.30856865644454956,
      "learning_rate": 6.455548647808519e-06,
      "loss": 0.1649,
      "step": 9122
    },
    {
      "epoch": 0.7089679825924775,
      "grad_norm": 0.6653785705566406,
      "learning_rate": 6.455160087037613e-06,
      "loss": 0.0592,
      "step": 9123
    },
    {
      "epoch": 0.7090456947466584,
      "grad_norm": 0.4213942885398865,
      "learning_rate": 6.4547715262667085e-06,
      "loss": 0.1518,
      "step": 9124
    },
    {
      "epoch": 0.7091234069008393,
      "grad_norm": 0.6226230263710022,
      "learning_rate": 6.454382965495804e-06,
      "loss": 0.4257,
      "step": 9125
    },
    {
      "epoch": 0.7092011190550203,
      "grad_norm": 0.4337562322616577,
      "learning_rate": 6.453994404724899e-06,
      "loss": 0.0868,
      "step": 9126
    },
    {
      "epoch": 0.7092788312092011,
      "grad_norm": 0.3486676812171936,
      "learning_rate": 6.453605843953995e-06,
      "loss": 0.0609,
      "step": 9127
    },
    {
      "epoch": 0.709356543363382,
      "grad_norm": 0.182813361287117,
      "learning_rate": 6.453217283183091e-06,
      "loss": 0.0219,
      "step": 9128
    },
    {
      "epoch": 0.7094342555175629,
      "grad_norm": 1.0197577476501465,
      "learning_rate": 6.452828722412186e-06,
      "loss": 0.41,
      "step": 9129
    },
    {
      "epoch": 0.7095119676717438,
      "grad_norm": 0.35256415605545044,
      "learning_rate": 6.452440161641282e-06,
      "loss": 0.0677,
      "step": 9130
    },
    {
      "epoch": 0.7095896798259248,
      "grad_norm": 0.11091099679470062,
      "learning_rate": 6.452051600870377e-06,
      "loss": 0.0238,
      "step": 9131
    },
    {
      "epoch": 0.7096673919801056,
      "grad_norm": 0.16689617931842804,
      "learning_rate": 6.4516630400994715e-06,
      "loss": 0.0506,
      "step": 9132
    },
    {
      "epoch": 0.7097451041342866,
      "grad_norm": 0.15436312556266785,
      "learning_rate": 6.451274479328567e-06,
      "loss": 0.0478,
      "step": 9133
    },
    {
      "epoch": 0.7098228162884676,
      "grad_norm": 0.4474184513092041,
      "learning_rate": 6.450885918557663e-06,
      "loss": 0.1869,
      "step": 9134
    },
    {
      "epoch": 0.7099005284426484,
      "grad_norm": 0.5913756489753723,
      "learning_rate": 6.450497357786758e-06,
      "loss": 0.2635,
      "step": 9135
    },
    {
      "epoch": 0.7099782405968293,
      "grad_norm": 0.7531731724739075,
      "learning_rate": 6.450108797015854e-06,
      "loss": 0.2069,
      "step": 9136
    },
    {
      "epoch": 0.7100559527510103,
      "grad_norm": 0.3221485912799835,
      "learning_rate": 6.44972023624495e-06,
      "loss": 0.0912,
      "step": 9137
    },
    {
      "epoch": 0.7101336649051911,
      "grad_norm": 0.19899427890777588,
      "learning_rate": 6.449331675474045e-06,
      "loss": 0.0413,
      "step": 9138
    },
    {
      "epoch": 0.7102113770593721,
      "grad_norm": 0.5007355809211731,
      "learning_rate": 6.44894311470314e-06,
      "loss": 0.9153,
      "step": 9139
    },
    {
      "epoch": 0.710289089213553,
      "grad_norm": 0.38600191473960876,
      "learning_rate": 6.448554553932236e-06,
      "loss": 0.06,
      "step": 9140
    },
    {
      "epoch": 0.7103668013677339,
      "grad_norm": 0.4294167160987854,
      "learning_rate": 6.44816599316133e-06,
      "loss": 0.0931,
      "step": 9141
    },
    {
      "epoch": 0.7104445135219148,
      "grad_norm": 0.32531940937042236,
      "learning_rate": 6.447777432390426e-06,
      "loss": 0.1172,
      "step": 9142
    },
    {
      "epoch": 0.7105222256760957,
      "grad_norm": 0.40507620573043823,
      "learning_rate": 6.447388871619522e-06,
      "loss": 0.3757,
      "step": 9143
    },
    {
      "epoch": 0.7105999378302766,
      "grad_norm": 0.28752246499061584,
      "learning_rate": 6.447000310848617e-06,
      "loss": 0.1109,
      "step": 9144
    },
    {
      "epoch": 0.7106776499844576,
      "grad_norm": 0.07888040691614151,
      "learning_rate": 6.446611750077713e-06,
      "loss": 0.0335,
      "step": 9145
    },
    {
      "epoch": 0.7107553621386384,
      "grad_norm": 0.19615377485752106,
      "learning_rate": 6.446223189306808e-06,
      "loss": 0.0612,
      "step": 9146
    },
    {
      "epoch": 0.7108330742928194,
      "grad_norm": 0.7125004529953003,
      "learning_rate": 6.445834628535903e-06,
      "loss": 0.2138,
      "step": 9147
    },
    {
      "epoch": 0.7109107864470003,
      "grad_norm": 0.2481493055820465,
      "learning_rate": 6.445446067764999e-06,
      "loss": 0.1259,
      "step": 9148
    },
    {
      "epoch": 0.7109884986011812,
      "grad_norm": 0.1765667349100113,
      "learning_rate": 6.445057506994095e-06,
      "loss": 0.0705,
      "step": 9149
    },
    {
      "epoch": 0.7110662107553621,
      "grad_norm": 0.3851664066314697,
      "learning_rate": 6.444668946223189e-06,
      "loss": 0.0596,
      "step": 9150
    },
    {
      "epoch": 0.7111439229095431,
      "grad_norm": 0.364145427942276,
      "learning_rate": 6.444280385452285e-06,
      "loss": 0.1248,
      "step": 9151
    },
    {
      "epoch": 0.7112216350637239,
      "grad_norm": 0.07878939807415009,
      "learning_rate": 6.443891824681381e-06,
      "loss": 0.0159,
      "step": 9152
    },
    {
      "epoch": 0.7112993472179049,
      "grad_norm": 0.5799891948699951,
      "learning_rate": 6.4435032639104764e-06,
      "loss": 0.3043,
      "step": 9153
    },
    {
      "epoch": 0.7113770593720858,
      "grad_norm": 0.616610050201416,
      "learning_rate": 6.443114703139571e-06,
      "loss": 0.4335,
      "step": 9154
    },
    {
      "epoch": 0.7114547715262667,
      "grad_norm": 0.30921638011932373,
      "learning_rate": 6.442726142368667e-06,
      "loss": 0.1023,
      "step": 9155
    },
    {
      "epoch": 0.7115324836804476,
      "grad_norm": 0.44670817255973816,
      "learning_rate": 6.442337581597763e-06,
      "loss": 0.1178,
      "step": 9156
    },
    {
      "epoch": 0.7116101958346286,
      "grad_norm": 0.35205671191215515,
      "learning_rate": 6.441949020826858e-06,
      "loss": 0.0959,
      "step": 9157
    },
    {
      "epoch": 0.7116879079888094,
      "grad_norm": 0.41627177596092224,
      "learning_rate": 6.441560460055954e-06,
      "loss": 0.3529,
      "step": 9158
    },
    {
      "epoch": 0.7117656201429904,
      "grad_norm": 1.0737519264221191,
      "learning_rate": 6.4411718992850495e-06,
      "loss": 0.4373,
      "step": 9159
    },
    {
      "epoch": 0.7118433322971712,
      "grad_norm": 1.8622993230819702,
      "learning_rate": 6.440783338514144e-06,
      "loss": 0.2458,
      "step": 9160
    },
    {
      "epoch": 0.7119210444513522,
      "grad_norm": 0.9161126017570496,
      "learning_rate": 6.4403947777432394e-06,
      "loss": 0.2089,
      "step": 9161
    },
    {
      "epoch": 0.7119987566055331,
      "grad_norm": 0.2902635931968689,
      "learning_rate": 6.440006216972335e-06,
      "loss": 0.1098,
      "step": 9162
    },
    {
      "epoch": 0.712076468759714,
      "grad_norm": 0.29008713364601135,
      "learning_rate": 6.43961765620143e-06,
      "loss": 0.1219,
      "step": 9163
    },
    {
      "epoch": 0.7121541809138949,
      "grad_norm": 0.5389124751091003,
      "learning_rate": 6.439229095430526e-06,
      "loss": 0.2863,
      "step": 9164
    },
    {
      "epoch": 0.7122318930680759,
      "grad_norm": 0.3327699601650238,
      "learning_rate": 6.438840534659622e-06,
      "loss": 0.1231,
      "step": 9165
    },
    {
      "epoch": 0.7123096052222567,
      "grad_norm": 0.46736940741539,
      "learning_rate": 6.438451973888717e-06,
      "loss": 0.1806,
      "step": 9166
    },
    {
      "epoch": 0.7123873173764377,
      "grad_norm": 0.30568966269493103,
      "learning_rate": 6.4380634131178125e-06,
      "loss": 0.1679,
      "step": 9167
    },
    {
      "epoch": 0.7124650295306186,
      "grad_norm": 0.2341775745153427,
      "learning_rate": 6.437674852346908e-06,
      "loss": 0.1156,
      "step": 9168
    },
    {
      "epoch": 0.7125427416847995,
      "grad_norm": 0.1765265315771103,
      "learning_rate": 6.437286291576002e-06,
      "loss": 0.0479,
      "step": 9169
    },
    {
      "epoch": 0.7126204538389804,
      "grad_norm": 0.3168044090270996,
      "learning_rate": 6.436897730805098e-06,
      "loss": 0.1639,
      "step": 9170
    },
    {
      "epoch": 0.7126981659931614,
      "grad_norm": 0.36896631121635437,
      "learning_rate": 6.436509170034194e-06,
      "loss": 0.1655,
      "step": 9171
    },
    {
      "epoch": 0.7127758781473422,
      "grad_norm": 0.17584389448165894,
      "learning_rate": 6.436120609263289e-06,
      "loss": 0.1297,
      "step": 9172
    },
    {
      "epoch": 0.7128535903015232,
      "grad_norm": 0.1064726710319519,
      "learning_rate": 6.435732048492385e-06,
      "loss": 0.0159,
      "step": 9173
    },
    {
      "epoch": 0.712931302455704,
      "grad_norm": 0.5337567329406738,
      "learning_rate": 6.4353434877214806e-06,
      "loss": 0.5342,
      "step": 9174
    },
    {
      "epoch": 0.713009014609885,
      "grad_norm": 0.4844302237033844,
      "learning_rate": 6.4349549269505755e-06,
      "loss": 0.2272,
      "step": 9175
    },
    {
      "epoch": 0.7130867267640659,
      "grad_norm": 0.2381022423505783,
      "learning_rate": 6.434566366179671e-06,
      "loss": 0.0948,
      "step": 9176
    },
    {
      "epoch": 0.7131644389182468,
      "grad_norm": 0.38304615020751953,
      "learning_rate": 6.434177805408767e-06,
      "loss": 0.4327,
      "step": 9177
    },
    {
      "epoch": 0.7132421510724277,
      "grad_norm": 0.5016589760780334,
      "learning_rate": 6.433789244637861e-06,
      "loss": 0.3118,
      "step": 9178
    },
    {
      "epoch": 0.7133198632266087,
      "grad_norm": 0.46673300862312317,
      "learning_rate": 6.433400683866957e-06,
      "loss": 0.3484,
      "step": 9179
    },
    {
      "epoch": 0.7133975753807895,
      "grad_norm": 1.1114189624786377,
      "learning_rate": 6.433012123096053e-06,
      "loss": 0.097,
      "step": 9180
    },
    {
      "epoch": 0.7134752875349705,
      "grad_norm": 0.1882772296667099,
      "learning_rate": 6.432623562325149e-06,
      "loss": 0.0435,
      "step": 9181
    },
    {
      "epoch": 0.7135529996891514,
      "grad_norm": 0.3917831480503082,
      "learning_rate": 6.4322350015542435e-06,
      "loss": 0.3277,
      "step": 9182
    },
    {
      "epoch": 0.7136307118433323,
      "grad_norm": 0.315126895904541,
      "learning_rate": 6.431846440783339e-06,
      "loss": 0.0969,
      "step": 9183
    },
    {
      "epoch": 0.7137084239975132,
      "grad_norm": 0.23607385158538818,
      "learning_rate": 6.431457880012435e-06,
      "loss": 0.1459,
      "step": 9184
    },
    {
      "epoch": 0.7137861361516942,
      "grad_norm": 0.449033260345459,
      "learning_rate": 6.431069319241529e-06,
      "loss": 0.2043,
      "step": 9185
    },
    {
      "epoch": 0.713863848305875,
      "grad_norm": 0.4107237458229065,
      "learning_rate": 6.430680758470625e-06,
      "loss": 0.2521,
      "step": 9186
    },
    {
      "epoch": 0.713941560460056,
      "grad_norm": 0.44187772274017334,
      "learning_rate": 6.430292197699721e-06,
      "loss": 0.212,
      "step": 9187
    },
    {
      "epoch": 0.7140192726142369,
      "grad_norm": 0.20612704753875732,
      "learning_rate": 6.429903636928816e-06,
      "loss": 0.0339,
      "step": 9188
    },
    {
      "epoch": 0.7140969847684178,
      "grad_norm": 0.4694828689098358,
      "learning_rate": 6.429515076157912e-06,
      "loss": 0.3277,
      "step": 9189
    },
    {
      "epoch": 0.7141746969225987,
      "grad_norm": 1.6282298564910889,
      "learning_rate": 6.429126515387007e-06,
      "loss": 0.7153,
      "step": 9190
    },
    {
      "epoch": 0.7142524090767796,
      "grad_norm": 0.5925331711769104,
      "learning_rate": 6.428737954616102e-06,
      "loss": 0.3761,
      "step": 9191
    },
    {
      "epoch": 0.7143301212309605,
      "grad_norm": 0.538412868976593,
      "learning_rate": 6.428349393845198e-06,
      "loss": 0.6547,
      "step": 9192
    },
    {
      "epoch": 0.7144078333851415,
      "grad_norm": 0.2597061097621918,
      "learning_rate": 6.427960833074294e-06,
      "loss": 0.0656,
      "step": 9193
    },
    {
      "epoch": 0.7144855455393223,
      "grad_norm": 0.6144047379493713,
      "learning_rate": 6.427572272303388e-06,
      "loss": 0.7056,
      "step": 9194
    },
    {
      "epoch": 0.7145632576935033,
      "grad_norm": 0.2696804404258728,
      "learning_rate": 6.427183711532484e-06,
      "loss": 0.1111,
      "step": 9195
    },
    {
      "epoch": 0.7146409698476842,
      "grad_norm": 0.6316996216773987,
      "learning_rate": 6.42679515076158e-06,
      "loss": 0.617,
      "step": 9196
    },
    {
      "epoch": 0.7147186820018651,
      "grad_norm": 0.4081341624259949,
      "learning_rate": 6.4264065899906746e-06,
      "loss": 0.0857,
      "step": 9197
    },
    {
      "epoch": 0.714796394156046,
      "grad_norm": 0.5480274558067322,
      "learning_rate": 6.42601802921977e-06,
      "loss": 0.2299,
      "step": 9198
    },
    {
      "epoch": 0.714874106310227,
      "grad_norm": 0.34397637844085693,
      "learning_rate": 6.425629468448866e-06,
      "loss": 0.1613,
      "step": 9199
    },
    {
      "epoch": 0.7149518184644078,
      "grad_norm": 0.6175308227539062,
      "learning_rate": 6.425240907677961e-06,
      "loss": 0.0421,
      "step": 9200
    },
    {
      "epoch": 0.7150295306185888,
      "grad_norm": 0.030677367001771927,
      "learning_rate": 6.424852346907057e-06,
      "loss": 0.0046,
      "step": 9201
    },
    {
      "epoch": 0.7151072427727697,
      "grad_norm": 0.4692745506763458,
      "learning_rate": 6.424463786136153e-06,
      "loss": 0.1509,
      "step": 9202
    },
    {
      "epoch": 0.7151849549269506,
      "grad_norm": 0.460761159658432,
      "learning_rate": 6.424075225365247e-06,
      "loss": 0.0426,
      "step": 9203
    },
    {
      "epoch": 0.7152626670811315,
      "grad_norm": 1.07296884059906,
      "learning_rate": 6.423686664594343e-06,
      "loss": 0.4668,
      "step": 9204
    },
    {
      "epoch": 0.7153403792353124,
      "grad_norm": 0.13665823638439178,
      "learning_rate": 6.423298103823438e-06,
      "loss": 0.0447,
      "step": 9205
    },
    {
      "epoch": 0.7154180913894933,
      "grad_norm": 0.42313915491104126,
      "learning_rate": 6.422909543052533e-06,
      "loss": 0.1465,
      "step": 9206
    },
    {
      "epoch": 0.7154958035436743,
      "grad_norm": 0.20703375339508057,
      "learning_rate": 6.422520982281629e-06,
      "loss": 0.2442,
      "step": 9207
    },
    {
      "epoch": 0.7155735156978551,
      "grad_norm": 0.1534310132265091,
      "learning_rate": 6.422132421510725e-06,
      "loss": 0.0391,
      "step": 9208
    },
    {
      "epoch": 0.715651227852036,
      "grad_norm": 0.26680830121040344,
      "learning_rate": 6.42174386073982e-06,
      "loss": 0.0261,
      "step": 9209
    },
    {
      "epoch": 0.715728940006217,
      "grad_norm": 0.19801901280879974,
      "learning_rate": 6.421355299968916e-06,
      "loss": 0.0624,
      "step": 9210
    },
    {
      "epoch": 0.7158066521603978,
      "grad_norm": 0.5533384680747986,
      "learning_rate": 6.4209667391980115e-06,
      "loss": 0.0965,
      "step": 9211
    },
    {
      "epoch": 0.7158843643145788,
      "grad_norm": 0.29301953315734863,
      "learning_rate": 6.420578178427107e-06,
      "loss": 0.0681,
      "step": 9212
    },
    {
      "epoch": 0.7159620764687598,
      "grad_norm": 0.2710164487361908,
      "learning_rate": 6.420189617656201e-06,
      "loss": 0.0806,
      "step": 9213
    },
    {
      "epoch": 0.7160397886229406,
      "grad_norm": 0.4961026608943939,
      "learning_rate": 6.419801056885297e-06,
      "loss": 0.3272,
      "step": 9214
    },
    {
      "epoch": 0.7161175007771216,
      "grad_norm": 0.5441402196884155,
      "learning_rate": 6.419412496114393e-06,
      "loss": 0.3542,
      "step": 9215
    },
    {
      "epoch": 0.7161952129313025,
      "grad_norm": 0.2603145241737366,
      "learning_rate": 6.419023935343488e-06,
      "loss": 0.1293,
      "step": 9216
    },
    {
      "epoch": 0.7162729250854833,
      "grad_norm": 0.30521589517593384,
      "learning_rate": 6.418635374572584e-06,
      "loss": 0.0529,
      "step": 9217
    },
    {
      "epoch": 0.7163506372396643,
      "grad_norm": 0.8651229739189148,
      "learning_rate": 6.4182468138016795e-06,
      "loss": 0.4422,
      "step": 9218
    },
    {
      "epoch": 0.7164283493938451,
      "grad_norm": 0.5575742721557617,
      "learning_rate": 6.4178582530307745e-06,
      "loss": 0.2221,
      "step": 9219
    },
    {
      "epoch": 0.7165060615480261,
      "grad_norm": 0.713954746723175,
      "learning_rate": 6.41746969225987e-06,
      "loss": 0.134,
      "step": 9220
    },
    {
      "epoch": 0.716583773702207,
      "grad_norm": 0.3105071783065796,
      "learning_rate": 6.417081131488966e-06,
      "loss": 0.3688,
      "step": 9221
    },
    {
      "epoch": 0.7166614858563879,
      "grad_norm": 0.16311994194984436,
      "learning_rate": 6.41669257071806e-06,
      "loss": 0.0606,
      "step": 9222
    },
    {
      "epoch": 0.7167391980105688,
      "grad_norm": 0.26374760270118713,
      "learning_rate": 6.416304009947156e-06,
      "loss": 0.22,
      "step": 9223
    },
    {
      "epoch": 0.7168169101647498,
      "grad_norm": 0.25519928336143494,
      "learning_rate": 6.415915449176252e-06,
      "loss": 0.0272,
      "step": 9224
    },
    {
      "epoch": 0.7168946223189306,
      "grad_norm": 0.4116423428058624,
      "learning_rate": 6.415526888405347e-06,
      "loss": 0.2646,
      "step": 9225
    },
    {
      "epoch": 0.7169723344731116,
      "grad_norm": 0.4083043336868286,
      "learning_rate": 6.4151383276344425e-06,
      "loss": 0.2083,
      "step": 9226
    },
    {
      "epoch": 0.7170500466272925,
      "grad_norm": 0.6158797144889832,
      "learning_rate": 6.414749766863538e-06,
      "loss": 0.1787,
      "step": 9227
    },
    {
      "epoch": 0.7171277587814734,
      "grad_norm": 0.7187532186508179,
      "learning_rate": 6.414361206092633e-06,
      "loss": 0.2354,
      "step": 9228
    },
    {
      "epoch": 0.7172054709356543,
      "grad_norm": 0.6292282938957214,
      "learning_rate": 6.413972645321729e-06,
      "loss": 0.1348,
      "step": 9229
    },
    {
      "epoch": 0.7172831830898353,
      "grad_norm": 0.6826763153076172,
      "learning_rate": 6.413584084550825e-06,
      "loss": 0.252,
      "step": 9230
    },
    {
      "epoch": 0.7173608952440161,
      "grad_norm": 0.5794870853424072,
      "learning_rate": 6.413195523779919e-06,
      "loss": 0.2497,
      "step": 9231
    },
    {
      "epoch": 0.7174386073981971,
      "grad_norm": 0.48046445846557617,
      "learning_rate": 6.412806963009015e-06,
      "loss": 0.2989,
      "step": 9232
    },
    {
      "epoch": 0.717516319552378,
      "grad_norm": 0.36757516860961914,
      "learning_rate": 6.4124184022381105e-06,
      "loss": 0.1537,
      "step": 9233
    },
    {
      "epoch": 0.7175940317065589,
      "grad_norm": 0.5448726415634155,
      "learning_rate": 6.4120298414672055e-06,
      "loss": 0.2381,
      "step": 9234
    },
    {
      "epoch": 0.7176717438607398,
      "grad_norm": 0.3751591444015503,
      "learning_rate": 6.411641280696301e-06,
      "loss": 0.069,
      "step": 9235
    },
    {
      "epoch": 0.7177494560149207,
      "grad_norm": 0.1909884214401245,
      "learning_rate": 6.411252719925397e-06,
      "loss": 0.1283,
      "step": 9236
    },
    {
      "epoch": 0.7178271681691016,
      "grad_norm": 0.5270954370498657,
      "learning_rate": 6.410864159154492e-06,
      "loss": 0.5224,
      "step": 9237
    },
    {
      "epoch": 0.7179048803232826,
      "grad_norm": 0.4739324152469635,
      "learning_rate": 6.410475598383588e-06,
      "loss": 0.2073,
      "step": 9238
    },
    {
      "epoch": 0.7179825924774634,
      "grad_norm": 0.19512873888015747,
      "learning_rate": 6.410087037612684e-06,
      "loss": 0.0744,
      "step": 9239
    },
    {
      "epoch": 0.7180603046316444,
      "grad_norm": 0.20091520249843597,
      "learning_rate": 6.409698476841778e-06,
      "loss": 0.052,
      "step": 9240
    },
    {
      "epoch": 0.7181380167858253,
      "grad_norm": 0.3274540305137634,
      "learning_rate": 6.4093099160708735e-06,
      "loss": 0.1156,
      "step": 9241
    },
    {
      "epoch": 0.7182157289400062,
      "grad_norm": 0.46559154987335205,
      "learning_rate": 6.408921355299969e-06,
      "loss": 0.1554,
      "step": 9242
    },
    {
      "epoch": 0.7182934410941871,
      "grad_norm": 0.3293936848640442,
      "learning_rate": 6.408532794529065e-06,
      "loss": 0.1215,
      "step": 9243
    },
    {
      "epoch": 0.7183711532483681,
      "grad_norm": 0.3416482210159302,
      "learning_rate": 6.40814423375816e-06,
      "loss": 0.1017,
      "step": 9244
    },
    {
      "epoch": 0.7184488654025489,
      "grad_norm": 0.3256933093070984,
      "learning_rate": 6.407755672987256e-06,
      "loss": 0.162,
      "step": 9245
    },
    {
      "epoch": 0.7185265775567299,
      "grad_norm": 0.5753457546234131,
      "learning_rate": 6.407367112216352e-06,
      "loss": 0.3092,
      "step": 9246
    },
    {
      "epoch": 0.7186042897109108,
      "grad_norm": 0.3470522165298462,
      "learning_rate": 6.406978551445447e-06,
      "loss": 0.1998,
      "step": 9247
    },
    {
      "epoch": 0.7186820018650917,
      "grad_norm": 0.49283212423324585,
      "learning_rate": 6.406589990674542e-06,
      "loss": 0.1242,
      "step": 9248
    },
    {
      "epoch": 0.7187597140192726,
      "grad_norm": 0.4837401211261749,
      "learning_rate": 6.406201429903638e-06,
      "loss": 0.3054,
      "step": 9249
    },
    {
      "epoch": 0.7188374261734535,
      "grad_norm": 1.5204097032546997,
      "learning_rate": 6.405812869132732e-06,
      "loss": 0.0906,
      "step": 9250
    },
    {
      "epoch": 0.7189151383276344,
      "grad_norm": 0.511172890663147,
      "learning_rate": 6.405424308361828e-06,
      "loss": 0.0633,
      "step": 9251
    },
    {
      "epoch": 0.7189928504818154,
      "grad_norm": 0.44204986095428467,
      "learning_rate": 6.405035747590924e-06,
      "loss": 0.1376,
      "step": 9252
    },
    {
      "epoch": 0.7190705626359962,
      "grad_norm": 0.6721327900886536,
      "learning_rate": 6.404647186820019e-06,
      "loss": 0.2093,
      "step": 9253
    },
    {
      "epoch": 0.7191482747901772,
      "grad_norm": 0.3602766990661621,
      "learning_rate": 6.404258626049115e-06,
      "loss": 0.0891,
      "step": 9254
    },
    {
      "epoch": 0.7192259869443581,
      "grad_norm": 0.2113366574048996,
      "learning_rate": 6.4038700652782105e-06,
      "loss": 0.0831,
      "step": 9255
    },
    {
      "epoch": 0.719303699098539,
      "grad_norm": 0.3038579821586609,
      "learning_rate": 6.403481504507305e-06,
      "loss": 0.0971,
      "step": 9256
    },
    {
      "epoch": 0.7193814112527199,
      "grad_norm": 0.38625600934028625,
      "learning_rate": 6.403092943736401e-06,
      "loss": 0.0875,
      "step": 9257
    },
    {
      "epoch": 0.7194591234069009,
      "grad_norm": 0.2577105164527893,
      "learning_rate": 6.402704382965497e-06,
      "loss": 0.1393,
      "step": 9258
    },
    {
      "epoch": 0.7195368355610817,
      "grad_norm": 0.25087791681289673,
      "learning_rate": 6.402315822194591e-06,
      "loss": 0.0879,
      "step": 9259
    },
    {
      "epoch": 0.7196145477152627,
      "grad_norm": 0.6042596101760864,
      "learning_rate": 6.401927261423687e-06,
      "loss": 0.6963,
      "step": 9260
    },
    {
      "epoch": 0.7196922598694436,
      "grad_norm": 0.4649706482887268,
      "learning_rate": 6.401538700652783e-06,
      "loss": 0.2097,
      "step": 9261
    },
    {
      "epoch": 0.7197699720236245,
      "grad_norm": 0.33744239807128906,
      "learning_rate": 6.401150139881878e-06,
      "loss": 0.1732,
      "step": 9262
    },
    {
      "epoch": 0.7198476841778054,
      "grad_norm": 0.5878356695175171,
      "learning_rate": 6.4007615791109734e-06,
      "loss": 0.4004,
      "step": 9263
    },
    {
      "epoch": 0.7199253963319864,
      "grad_norm": 0.32708796858787537,
      "learning_rate": 6.400373018340069e-06,
      "loss": 0.0913,
      "step": 9264
    },
    {
      "epoch": 0.7200031084861672,
      "grad_norm": 0.11401144415140152,
      "learning_rate": 6.399984457569164e-06,
      "loss": 0.038,
      "step": 9265
    },
    {
      "epoch": 0.7200808206403482,
      "grad_norm": 0.29865652322769165,
      "learning_rate": 6.39959589679826e-06,
      "loss": 0.0596,
      "step": 9266
    },
    {
      "epoch": 0.720158532794529,
      "grad_norm": 0.05041207745671272,
      "learning_rate": 6.399207336027356e-06,
      "loss": 0.0201,
      "step": 9267
    },
    {
      "epoch": 0.72023624494871,
      "grad_norm": 0.3814220428466797,
      "learning_rate": 6.39881877525645e-06,
      "loss": 0.068,
      "step": 9268
    },
    {
      "epoch": 0.7203139571028909,
      "grad_norm": 0.7774017453193665,
      "learning_rate": 6.398430214485546e-06,
      "loss": 0.1522,
      "step": 9269
    },
    {
      "epoch": 0.7203916692570718,
      "grad_norm": 0.5075650811195374,
      "learning_rate": 6.3980416537146415e-06,
      "loss": 0.2006,
      "step": 9270
    },
    {
      "epoch": 0.7204693814112527,
      "grad_norm": 0.016949066892266273,
      "learning_rate": 6.3976530929437364e-06,
      "loss": 0.0015,
      "step": 9271
    },
    {
      "epoch": 0.7205470935654337,
      "grad_norm": 0.113042913377285,
      "learning_rate": 6.397264532172832e-06,
      "loss": 0.0295,
      "step": 9272
    },
    {
      "epoch": 0.7206248057196145,
      "grad_norm": 0.08198549598455429,
      "learning_rate": 6.396875971401928e-06,
      "loss": 0.0257,
      "step": 9273
    },
    {
      "epoch": 0.7207025178737955,
      "grad_norm": 0.16199548542499542,
      "learning_rate": 6.396487410631024e-06,
      "loss": 0.0238,
      "step": 9274
    },
    {
      "epoch": 0.7207802300279764,
      "grad_norm": 0.2196868658065796,
      "learning_rate": 6.396098849860119e-06,
      "loss": 0.0526,
      "step": 9275
    },
    {
      "epoch": 0.7208579421821573,
      "grad_norm": 0.1782405525445938,
      "learning_rate": 6.3957102890892146e-06,
      "loss": 0.0526,
      "step": 9276
    },
    {
      "epoch": 0.7209356543363382,
      "grad_norm": 0.36251217126846313,
      "learning_rate": 6.39532172831831e-06,
      "loss": 0.2089,
      "step": 9277
    },
    {
      "epoch": 0.7210133664905192,
      "grad_norm": 0.19085793197155,
      "learning_rate": 6.3949331675474045e-06,
      "loss": 0.1291,
      "step": 9278
    },
    {
      "epoch": 0.7210910786447,
      "grad_norm": 0.09957756102085114,
      "learning_rate": 6.3945446067765e-06,
      "loss": 0.0254,
      "step": 9279
    },
    {
      "epoch": 0.721168790798881,
      "grad_norm": 0.11685451120138168,
      "learning_rate": 6.394156046005596e-06,
      "loss": 0.0374,
      "step": 9280
    },
    {
      "epoch": 0.7212465029530618,
      "grad_norm": 0.31809309124946594,
      "learning_rate": 6.393767485234691e-06,
      "loss": 0.2263,
      "step": 9281
    },
    {
      "epoch": 0.7213242151072428,
      "grad_norm": 0.13541996479034424,
      "learning_rate": 6.393378924463787e-06,
      "loss": 0.0213,
      "step": 9282
    },
    {
      "epoch": 0.7214019272614237,
      "grad_norm": 0.6193782091140747,
      "learning_rate": 6.392990363692883e-06,
      "loss": 0.5151,
      "step": 9283
    },
    {
      "epoch": 0.7214796394156046,
      "grad_norm": 0.46246805787086487,
      "learning_rate": 6.3926018029219775e-06,
      "loss": 0.5378,
      "step": 9284
    },
    {
      "epoch": 0.7215573515697855,
      "grad_norm": 0.4556540250778198,
      "learning_rate": 6.392213242151073e-06,
      "loss": 0.1598,
      "step": 9285
    },
    {
      "epoch": 0.7216350637239665,
      "grad_norm": 0.48458927869796753,
      "learning_rate": 6.391824681380169e-06,
      "loss": 0.0831,
      "step": 9286
    },
    {
      "epoch": 0.7217127758781473,
      "grad_norm": 0.7486373782157898,
      "learning_rate": 6.391436120609263e-06,
      "loss": 0.2417,
      "step": 9287
    },
    {
      "epoch": 0.7217904880323283,
      "grad_norm": 0.809614360332489,
      "learning_rate": 6.391047559838359e-06,
      "loss": 0.5902,
      "step": 9288
    },
    {
      "epoch": 0.7218682001865092,
      "grad_norm": 0.37215790152549744,
      "learning_rate": 6.390658999067455e-06,
      "loss": 0.2527,
      "step": 9289
    },
    {
      "epoch": 0.72194591234069,
      "grad_norm": 0.16704817116260529,
      "learning_rate": 6.39027043829655e-06,
      "loss": 0.0418,
      "step": 9290
    },
    {
      "epoch": 0.722023624494871,
      "grad_norm": 0.47037896513938904,
      "learning_rate": 6.389881877525646e-06,
      "loss": 0.3586,
      "step": 9291
    },
    {
      "epoch": 0.722101336649052,
      "grad_norm": 0.44592979550361633,
      "learning_rate": 6.389493316754741e-06,
      "loss": 0.2617,
      "step": 9292
    },
    {
      "epoch": 0.7221790488032328,
      "grad_norm": 0.10530481487512589,
      "learning_rate": 6.389104755983836e-06,
      "loss": 0.0824,
      "step": 9293
    },
    {
      "epoch": 0.7222567609574138,
      "grad_norm": 0.16551125049591064,
      "learning_rate": 6.388716195212932e-06,
      "loss": 0.0523,
      "step": 9294
    },
    {
      "epoch": 0.7223344731115946,
      "grad_norm": 0.22269093990325928,
      "learning_rate": 6.388327634442028e-06,
      "loss": 0.0449,
      "step": 9295
    },
    {
      "epoch": 0.7224121852657756,
      "grad_norm": 0.8415801525115967,
      "learning_rate": 6.387939073671122e-06,
      "loss": 0.5353,
      "step": 9296
    },
    {
      "epoch": 0.7224898974199565,
      "grad_norm": 0.7198399901390076,
      "learning_rate": 6.387550512900218e-06,
      "loss": 0.5876,
      "step": 9297
    },
    {
      "epoch": 0.7225676095741373,
      "grad_norm": 0.2273285984992981,
      "learning_rate": 6.387161952129314e-06,
      "loss": 0.0627,
      "step": 9298
    },
    {
      "epoch": 0.7226453217283183,
      "grad_norm": 0.24764949083328247,
      "learning_rate": 6.3867733913584086e-06,
      "loss": 0.1323,
      "step": 9299
    },
    {
      "epoch": 0.7227230338824993,
      "grad_norm": 0.11654191464185715,
      "learning_rate": 6.386384830587504e-06,
      "loss": 0.0177,
      "step": 9300
    },
    {
      "epoch": 0.7228007460366801,
      "grad_norm": 0.09812045097351074,
      "learning_rate": 6.3859962698166e-06,
      "loss": 0.0495,
      "step": 9301
    },
    {
      "epoch": 0.722878458190861,
      "grad_norm": 0.8833188414573669,
      "learning_rate": 6.385607709045696e-06,
      "loss": 0.4715,
      "step": 9302
    },
    {
      "epoch": 0.722956170345042,
      "grad_norm": 0.3585314452648163,
      "learning_rate": 6.385219148274791e-06,
      "loss": 0.1762,
      "step": 9303
    },
    {
      "epoch": 0.7230338824992228,
      "grad_norm": 0.26012101769447327,
      "learning_rate": 6.384830587503887e-06,
      "loss": 0.124,
      "step": 9304
    },
    {
      "epoch": 0.7231115946534038,
      "grad_norm": 0.32712194323539734,
      "learning_rate": 6.384442026732982e-06,
      "loss": 0.1253,
      "step": 9305
    },
    {
      "epoch": 0.7231893068075848,
      "grad_norm": 0.26649919152259827,
      "learning_rate": 6.384053465962077e-06,
      "loss": 0.1528,
      "step": 9306
    },
    {
      "epoch": 0.7232670189617656,
      "grad_norm": 0.4382365047931671,
      "learning_rate": 6.383664905191172e-06,
      "loss": 0.2665,
      "step": 9307
    },
    {
      "epoch": 0.7233447311159465,
      "grad_norm": 0.11471716314554214,
      "learning_rate": 6.383276344420268e-06,
      "loss": 0.0712,
      "step": 9308
    },
    {
      "epoch": 0.7234224432701275,
      "grad_norm": 0.34214577078819275,
      "learning_rate": 6.382887783649363e-06,
      "loss": 0.1655,
      "step": 9309
    },
    {
      "epoch": 0.7235001554243083,
      "grad_norm": 0.7822505831718445,
      "learning_rate": 6.382499222878459e-06,
      "loss": 0.3265,
      "step": 9310
    },
    {
      "epoch": 0.7235778675784893,
      "grad_norm": 0.39965522289276123,
      "learning_rate": 6.382110662107555e-06,
      "loss": 0.0619,
      "step": 9311
    },
    {
      "epoch": 0.7236555797326701,
      "grad_norm": 0.22047245502471924,
      "learning_rate": 6.381722101336649e-06,
      "loss": 0.0942,
      "step": 9312
    },
    {
      "epoch": 0.7237332918868511,
      "grad_norm": 0.3098160922527313,
      "learning_rate": 6.381333540565745e-06,
      "loss": 0.1373,
      "step": 9313
    },
    {
      "epoch": 0.723811004041032,
      "grad_norm": 0.23198950290679932,
      "learning_rate": 6.3809449797948404e-06,
      "loss": 0.1404,
      "step": 9314
    },
    {
      "epoch": 0.7238887161952129,
      "grad_norm": 0.2413424253463745,
      "learning_rate": 6.380556419023935e-06,
      "loss": 0.0709,
      "step": 9315
    },
    {
      "epoch": 0.7239664283493938,
      "grad_norm": 0.3323928117752075,
      "learning_rate": 6.380167858253031e-06,
      "loss": 0.3228,
      "step": 9316
    },
    {
      "epoch": 0.7240441405035748,
      "grad_norm": 0.14643898606300354,
      "learning_rate": 6.379779297482127e-06,
      "loss": 0.0244,
      "step": 9317
    },
    {
      "epoch": 0.7241218526577556,
      "grad_norm": 0.11357004940509796,
      "learning_rate": 6.379390736711222e-06,
      "loss": 0.0217,
      "step": 9318
    },
    {
      "epoch": 0.7241995648119366,
      "grad_norm": 0.08922266960144043,
      "learning_rate": 6.379002175940318e-06,
      "loss": 0.043,
      "step": 9319
    },
    {
      "epoch": 0.7242772769661175,
      "grad_norm": 0.27186527848243713,
      "learning_rate": 6.3786136151694135e-06,
      "loss": 0.0578,
      "step": 9320
    },
    {
      "epoch": 0.7243549891202984,
      "grad_norm": 0.6141354441642761,
      "learning_rate": 6.378225054398508e-06,
      "loss": 0.1961,
      "step": 9321
    },
    {
      "epoch": 0.7244327012744793,
      "grad_norm": 0.31315210461616516,
      "learning_rate": 6.3778364936276034e-06,
      "loss": 0.0945,
      "step": 9322
    },
    {
      "epoch": 0.7245104134286603,
      "grad_norm": 0.27532848715782166,
      "learning_rate": 6.377447932856699e-06,
      "loss": 0.1962,
      "step": 9323
    },
    {
      "epoch": 0.7245881255828411,
      "grad_norm": 0.17332132160663605,
      "learning_rate": 6.377059372085794e-06,
      "loss": 0.0355,
      "step": 9324
    },
    {
      "epoch": 0.7246658377370221,
      "grad_norm": 0.663307249546051,
      "learning_rate": 6.37667081131489e-06,
      "loss": 0.2519,
      "step": 9325
    },
    {
      "epoch": 0.7247435498912029,
      "grad_norm": 0.5079185962677002,
      "learning_rate": 6.376282250543986e-06,
      "loss": 0.5217,
      "step": 9326
    },
    {
      "epoch": 0.7248212620453839,
      "grad_norm": 0.39871731400489807,
      "learning_rate": 6.375893689773081e-06,
      "loss": 0.2819,
      "step": 9327
    },
    {
      "epoch": 0.7248989741995648,
      "grad_norm": 0.37106627225875854,
      "learning_rate": 6.3755051290021765e-06,
      "loss": 0.1908,
      "step": 9328
    },
    {
      "epoch": 0.7249766863537457,
      "grad_norm": 0.7782737016677856,
      "learning_rate": 6.375116568231272e-06,
      "loss": 0.2708,
      "step": 9329
    },
    {
      "epoch": 0.7250543985079266,
      "grad_norm": 0.09297884255647659,
      "learning_rate": 6.374728007460366e-06,
      "loss": 0.0221,
      "step": 9330
    },
    {
      "epoch": 0.7251321106621076,
      "grad_norm": 0.6136407852172852,
      "learning_rate": 6.374339446689462e-06,
      "loss": 0.1448,
      "step": 9331
    },
    {
      "epoch": 0.7252098228162884,
      "grad_norm": 0.09817945212125778,
      "learning_rate": 6.373950885918558e-06,
      "loss": 0.0301,
      "step": 9332
    },
    {
      "epoch": 0.7252875349704694,
      "grad_norm": 0.7954661846160889,
      "learning_rate": 6.373562325147654e-06,
      "loss": 0.9505,
      "step": 9333
    },
    {
      "epoch": 0.7253652471246503,
      "grad_norm": 0.31495949625968933,
      "learning_rate": 6.373173764376749e-06,
      "loss": 0.2458,
      "step": 9334
    },
    {
      "epoch": 0.7254429592788312,
      "grad_norm": 0.47460752725601196,
      "learning_rate": 6.3727852036058446e-06,
      "loss": 0.2771,
      "step": 9335
    },
    {
      "epoch": 0.7255206714330121,
      "grad_norm": 0.3673475384712219,
      "learning_rate": 6.37239664283494e-06,
      "loss": 0.3368,
      "step": 9336
    },
    {
      "epoch": 0.7255983835871931,
      "grad_norm": 0.339735746383667,
      "learning_rate": 6.372008082064035e-06,
      "loss": 0.0814,
      "step": 9337
    },
    {
      "epoch": 0.7256760957413739,
      "grad_norm": 0.5043866634368896,
      "learning_rate": 6.371619521293131e-06,
      "loss": 0.1457,
      "step": 9338
    },
    {
      "epoch": 0.7257538078955549,
      "grad_norm": 0.5484844446182251,
      "learning_rate": 6.371230960522227e-06,
      "loss": 0.4333,
      "step": 9339
    },
    {
      "epoch": 0.7258315200497357,
      "grad_norm": 0.2981368601322174,
      "learning_rate": 6.370842399751321e-06,
      "loss": 0.1739,
      "step": 9340
    },
    {
      "epoch": 0.7259092322039167,
      "grad_norm": 0.2465665489435196,
      "learning_rate": 6.370453838980417e-06,
      "loss": 0.1159,
      "step": 9341
    },
    {
      "epoch": 0.7259869443580976,
      "grad_norm": 0.27927646040916443,
      "learning_rate": 6.370065278209513e-06,
      "loss": 0.0502,
      "step": 9342
    },
    {
      "epoch": 0.7260646565122785,
      "grad_norm": 0.013500122353434563,
      "learning_rate": 6.3696767174386075e-06,
      "loss": 0.001,
      "step": 9343
    },
    {
      "epoch": 0.7261423686664594,
      "grad_norm": 0.3900493383407593,
      "learning_rate": 6.369288156667703e-06,
      "loss": 0.4598,
      "step": 9344
    },
    {
      "epoch": 0.7262200808206404,
      "grad_norm": 0.5073949694633484,
      "learning_rate": 6.368899595896799e-06,
      "loss": 0.3095,
      "step": 9345
    },
    {
      "epoch": 0.7262977929748212,
      "grad_norm": 0.5056535601615906,
      "learning_rate": 6.368511035125894e-06,
      "loss": 0.9665,
      "step": 9346
    },
    {
      "epoch": 0.7263755051290022,
      "grad_norm": 0.44310158491134644,
      "learning_rate": 6.36812247435499e-06,
      "loss": 0.2963,
      "step": 9347
    },
    {
      "epoch": 0.7264532172831831,
      "grad_norm": 0.5675112009048462,
      "learning_rate": 6.367733913584086e-06,
      "loss": 0.2068,
      "step": 9348
    },
    {
      "epoch": 0.726530929437364,
      "grad_norm": 0.10521941632032394,
      "learning_rate": 6.36734535281318e-06,
      "loss": 0.0187,
      "step": 9349
    },
    {
      "epoch": 0.7266086415915449,
      "grad_norm": 0.20471617579460144,
      "learning_rate": 6.3669567920422756e-06,
      "loss": 0.0622,
      "step": 9350
    },
    {
      "epoch": 0.7266863537457259,
      "grad_norm": 0.4269197881221771,
      "learning_rate": 6.366568231271371e-06,
      "loss": 0.1938,
      "step": 9351
    },
    {
      "epoch": 0.7267640658999067,
      "grad_norm": 0.23531071841716766,
      "learning_rate": 6.366179670500466e-06,
      "loss": 0.071,
      "step": 9352
    },
    {
      "epoch": 0.7268417780540877,
      "grad_norm": 0.5365087985992432,
      "learning_rate": 6.365791109729562e-06,
      "loss": 0.2,
      "step": 9353
    },
    {
      "epoch": 0.7269194902082686,
      "grad_norm": 0.5767698884010315,
      "learning_rate": 6.365402548958658e-06,
      "loss": 0.288,
      "step": 9354
    },
    {
      "epoch": 0.7269972023624495,
      "grad_norm": 0.8079546093940735,
      "learning_rate": 6.365013988187753e-06,
      "loss": 0.5603,
      "step": 9355
    },
    {
      "epoch": 0.7270749145166304,
      "grad_norm": 0.24217277765274048,
      "learning_rate": 6.364625427416849e-06,
      "loss": 0.1829,
      "step": 9356
    },
    {
      "epoch": 0.7271526266708113,
      "grad_norm": 0.22848063707351685,
      "learning_rate": 6.3642368666459445e-06,
      "loss": 0.12,
      "step": 9357
    },
    {
      "epoch": 0.7272303388249922,
      "grad_norm": 0.07818193733692169,
      "learning_rate": 6.3638483058750386e-06,
      "loss": 0.0094,
      "step": 9358
    },
    {
      "epoch": 0.7273080509791732,
      "grad_norm": 0.19276222586631775,
      "learning_rate": 6.363459745104134e-06,
      "loss": 0.0574,
      "step": 9359
    },
    {
      "epoch": 0.727385763133354,
      "grad_norm": 0.3999217748641968,
      "learning_rate": 6.36307118433323e-06,
      "loss": 0.1352,
      "step": 9360
    },
    {
      "epoch": 0.727463475287535,
      "grad_norm": 0.774151086807251,
      "learning_rate": 6.362682623562325e-06,
      "loss": 0.6085,
      "step": 9361
    },
    {
      "epoch": 0.7275411874417159,
      "grad_norm": 0.22940295934677124,
      "learning_rate": 6.362294062791421e-06,
      "loss": 0.1059,
      "step": 9362
    },
    {
      "epoch": 0.7276188995958968,
      "grad_norm": 0.6181452870368958,
      "learning_rate": 6.361905502020517e-06,
      "loss": 0.3676,
      "step": 9363
    },
    {
      "epoch": 0.7276966117500777,
      "grad_norm": 0.4341946840286255,
      "learning_rate": 6.3615169412496125e-06,
      "loss": 0.1878,
      "step": 9364
    },
    {
      "epoch": 0.7277743239042587,
      "grad_norm": 0.2099849283695221,
      "learning_rate": 6.3611283804787074e-06,
      "loss": 0.0665,
      "step": 9365
    },
    {
      "epoch": 0.7278520360584395,
      "grad_norm": 0.2820607125759125,
      "learning_rate": 6.360739819707803e-06,
      "loss": 0.0679,
      "step": 9366
    },
    {
      "epoch": 0.7279297482126205,
      "grad_norm": 0.25523507595062256,
      "learning_rate": 6.360351258936899e-06,
      "loss": 0.1125,
      "step": 9367
    },
    {
      "epoch": 0.7280074603668014,
      "grad_norm": 0.590411365032196,
      "learning_rate": 6.359962698165993e-06,
      "loss": 0.4729,
      "step": 9368
    },
    {
      "epoch": 0.7280851725209823,
      "grad_norm": 0.166794091463089,
      "learning_rate": 6.359574137395089e-06,
      "loss": 0.0647,
      "step": 9369
    },
    {
      "epoch": 0.7281628846751632,
      "grad_norm": 0.3001183271408081,
      "learning_rate": 6.359185576624185e-06,
      "loss": 0.225,
      "step": 9370
    },
    {
      "epoch": 0.7282405968293441,
      "grad_norm": 0.31755638122558594,
      "learning_rate": 6.35879701585328e-06,
      "loss": 0.4351,
      "step": 9371
    },
    {
      "epoch": 0.728318308983525,
      "grad_norm": 0.2682448923587799,
      "learning_rate": 6.3584084550823755e-06,
      "loss": 0.0976,
      "step": 9372
    },
    {
      "epoch": 0.728396021137706,
      "grad_norm": 0.3442012369632721,
      "learning_rate": 6.358019894311471e-06,
      "loss": 0.1584,
      "step": 9373
    },
    {
      "epoch": 0.7284737332918868,
      "grad_norm": 0.08130670338869095,
      "learning_rate": 6.357631333540566e-06,
      "loss": 0.0146,
      "step": 9374
    },
    {
      "epoch": 0.7285514454460678,
      "grad_norm": 0.11580844223499298,
      "learning_rate": 6.357242772769662e-06,
      "loss": 0.0295,
      "step": 9375
    },
    {
      "epoch": 0.7286291576002487,
      "grad_norm": 0.30312177538871765,
      "learning_rate": 6.356854211998758e-06,
      "loss": 0.0562,
      "step": 9376
    },
    {
      "epoch": 0.7287068697544296,
      "grad_norm": 0.34931260347366333,
      "learning_rate": 6.356465651227852e-06,
      "loss": 0.1961,
      "step": 9377
    },
    {
      "epoch": 0.7287845819086105,
      "grad_norm": 0.3952127695083618,
      "learning_rate": 6.356077090456948e-06,
      "loss": 0.104,
      "step": 9378
    },
    {
      "epoch": 0.7288622940627915,
      "grad_norm": 0.3261202573776245,
      "learning_rate": 6.3556885296860435e-06,
      "loss": 0.1745,
      "step": 9379
    },
    {
      "epoch": 0.7289400062169723,
      "grad_norm": 0.22495342791080475,
      "learning_rate": 6.3552999689151385e-06,
      "loss": 0.0293,
      "step": 9380
    },
    {
      "epoch": 0.7290177183711533,
      "grad_norm": 0.42815470695495605,
      "learning_rate": 6.354911408144234e-06,
      "loss": 0.2772,
      "step": 9381
    },
    {
      "epoch": 0.7290954305253342,
      "grad_norm": 0.17754366993904114,
      "learning_rate": 6.35452284737333e-06,
      "loss": 0.0487,
      "step": 9382
    },
    {
      "epoch": 0.729173142679515,
      "grad_norm": 0.1889573484659195,
      "learning_rate": 6.354134286602425e-06,
      "loss": 0.0884,
      "step": 9383
    },
    {
      "epoch": 0.729250854833696,
      "grad_norm": 0.24418996274471283,
      "learning_rate": 6.353745725831521e-06,
      "loss": 0.1567,
      "step": 9384
    },
    {
      "epoch": 0.729328566987877,
      "grad_norm": 0.6099909543991089,
      "learning_rate": 6.353357165060617e-06,
      "loss": 0.253,
      "step": 9385
    },
    {
      "epoch": 0.7294062791420578,
      "grad_norm": 0.15461832284927368,
      "learning_rate": 6.352968604289711e-06,
      "loss": 0.0554,
      "step": 9386
    },
    {
      "epoch": 0.7294839912962388,
      "grad_norm": 0.2118372619152069,
      "learning_rate": 6.3525800435188065e-06,
      "loss": 0.025,
      "step": 9387
    },
    {
      "epoch": 0.7295617034504196,
      "grad_norm": 0.23096351325511932,
      "learning_rate": 6.352191482747902e-06,
      "loss": 0.0597,
      "step": 9388
    },
    {
      "epoch": 0.7296394156046005,
      "grad_norm": 0.4853539764881134,
      "learning_rate": 6.351802921976997e-06,
      "loss": 0.3885,
      "step": 9389
    },
    {
      "epoch": 0.7297171277587815,
      "grad_norm": 0.21267354488372803,
      "learning_rate": 6.351414361206093e-06,
      "loss": 0.0705,
      "step": 9390
    },
    {
      "epoch": 0.7297948399129623,
      "grad_norm": 0.8507888317108154,
      "learning_rate": 6.351025800435189e-06,
      "loss": 0.5771,
      "step": 9391
    },
    {
      "epoch": 0.7298725520671433,
      "grad_norm": 0.21779395639896393,
      "learning_rate": 6.350637239664284e-06,
      "loss": 0.0698,
      "step": 9392
    },
    {
      "epoch": 0.7299502642213243,
      "grad_norm": 0.43537697196006775,
      "learning_rate": 6.35024867889338e-06,
      "loss": 0.2196,
      "step": 9393
    },
    {
      "epoch": 0.7300279763755051,
      "grad_norm": 0.4887353181838989,
      "learning_rate": 6.349860118122475e-06,
      "loss": 0.1482,
      "step": 9394
    },
    {
      "epoch": 0.730105688529686,
      "grad_norm": 0.7444263696670532,
      "learning_rate": 6.349471557351571e-06,
      "loss": 1.1195,
      "step": 9395
    },
    {
      "epoch": 0.730183400683867,
      "grad_norm": 0.35288766026496887,
      "learning_rate": 6.349082996580665e-06,
      "loss": 0.3729,
      "step": 9396
    },
    {
      "epoch": 0.7302611128380478,
      "grad_norm": 0.36010104417800903,
      "learning_rate": 6.348694435809761e-06,
      "loss": 0.0271,
      "step": 9397
    },
    {
      "epoch": 0.7303388249922288,
      "grad_norm": 0.585501492023468,
      "learning_rate": 6.348305875038857e-06,
      "loss": 0.524,
      "step": 9398
    },
    {
      "epoch": 0.7304165371464098,
      "grad_norm": 0.6823042035102844,
      "learning_rate": 6.347917314267952e-06,
      "loss": 0.6492,
      "step": 9399
    },
    {
      "epoch": 0.7304942493005906,
      "grad_norm": 0.6030614376068115,
      "learning_rate": 6.347528753497048e-06,
      "loss": 0.263,
      "step": 9400
    },
    {
      "epoch": 0.7305719614547715,
      "grad_norm": 0.8098104596138,
      "learning_rate": 6.3471401927261434e-06,
      "loss": 0.4316,
      "step": 9401
    },
    {
      "epoch": 0.7306496736089524,
      "grad_norm": 0.20345932245254517,
      "learning_rate": 6.346751631955238e-06,
      "loss": 0.0441,
      "step": 9402
    },
    {
      "epoch": 0.7307273857631333,
      "grad_norm": 0.06834468990564346,
      "learning_rate": 6.346363071184334e-06,
      "loss": 0.0189,
      "step": 9403
    },
    {
      "epoch": 0.7308050979173143,
      "grad_norm": 1.3118137121200562,
      "learning_rate": 6.34597451041343e-06,
      "loss": 0.5913,
      "step": 9404
    },
    {
      "epoch": 0.7308828100714951,
      "grad_norm": 0.27688655257225037,
      "learning_rate": 6.345585949642524e-06,
      "loss": 0.1834,
      "step": 9405
    },
    {
      "epoch": 0.7309605222256761,
      "grad_norm": 0.16690629720687866,
      "learning_rate": 6.34519738887162e-06,
      "loss": 0.0456,
      "step": 9406
    },
    {
      "epoch": 0.731038234379857,
      "grad_norm": 0.1977728009223938,
      "learning_rate": 6.344808828100716e-06,
      "loss": 0.0527,
      "step": 9407
    },
    {
      "epoch": 0.7311159465340379,
      "grad_norm": 0.3135935366153717,
      "learning_rate": 6.344420267329811e-06,
      "loss": 0.1628,
      "step": 9408
    },
    {
      "epoch": 0.7311936586882188,
      "grad_norm": 0.5826968550682068,
      "learning_rate": 6.344031706558906e-06,
      "loss": 0.1597,
      "step": 9409
    },
    {
      "epoch": 0.7312713708423998,
      "grad_norm": 0.09834003448486328,
      "learning_rate": 6.343643145788002e-06,
      "loss": 0.0149,
      "step": 9410
    },
    {
      "epoch": 0.7313490829965806,
      "grad_norm": 0.12852321565151215,
      "learning_rate": 6.343254585017097e-06,
      "loss": 0.0484,
      "step": 9411
    },
    {
      "epoch": 0.7314267951507616,
      "grad_norm": 0.29755207896232605,
      "learning_rate": 6.342866024246193e-06,
      "loss": 0.0515,
      "step": 9412
    },
    {
      "epoch": 0.7315045073049425,
      "grad_norm": 0.20423762500286102,
      "learning_rate": 6.342477463475289e-06,
      "loss": 0.0485,
      "step": 9413
    },
    {
      "epoch": 0.7315822194591234,
      "grad_norm": 0.2814704477787018,
      "learning_rate": 6.342088902704383e-06,
      "loss": 0.2044,
      "step": 9414
    },
    {
      "epoch": 0.7316599316133043,
      "grad_norm": 0.2741870582103729,
      "learning_rate": 6.341700341933479e-06,
      "loss": 0.0522,
      "step": 9415
    },
    {
      "epoch": 0.7317376437674852,
      "grad_norm": 0.750478208065033,
      "learning_rate": 6.3413117811625744e-06,
      "loss": 0.4638,
      "step": 9416
    },
    {
      "epoch": 0.7318153559216661,
      "grad_norm": 0.2629527151584625,
      "learning_rate": 6.340923220391669e-06,
      "loss": 0.2058,
      "step": 9417
    },
    {
      "epoch": 0.7318930680758471,
      "grad_norm": 0.3929104208946228,
      "learning_rate": 6.340534659620765e-06,
      "loss": 0.1735,
      "step": 9418
    },
    {
      "epoch": 0.7319707802300279,
      "grad_norm": 0.7434266209602356,
      "learning_rate": 6.340146098849861e-06,
      "loss": 0.495,
      "step": 9419
    },
    {
      "epoch": 0.7320484923842089,
      "grad_norm": 1.7423292398452759,
      "learning_rate": 6.339757538078956e-06,
      "loss": 0.4082,
      "step": 9420
    },
    {
      "epoch": 0.7321262045383898,
      "grad_norm": 0.38803166151046753,
      "learning_rate": 6.339368977308052e-06,
      "loss": 0.2282,
      "step": 9421
    },
    {
      "epoch": 0.7322039166925707,
      "grad_norm": 0.21096189320087433,
      "learning_rate": 6.3389804165371475e-06,
      "loss": 0.1562,
      "step": 9422
    },
    {
      "epoch": 0.7322816288467516,
      "grad_norm": 0.09059617668390274,
      "learning_rate": 6.338591855766242e-06,
      "loss": 0.0479,
      "step": 9423
    },
    {
      "epoch": 0.7323593410009326,
      "grad_norm": 0.39347824454307556,
      "learning_rate": 6.3382032949953374e-06,
      "loss": 0.3674,
      "step": 9424
    },
    {
      "epoch": 0.7324370531551134,
      "grad_norm": 0.16958896815776825,
      "learning_rate": 6.337814734224433e-06,
      "loss": 0.0325,
      "step": 9425
    },
    {
      "epoch": 0.7325147653092944,
      "grad_norm": 0.20002028346061707,
      "learning_rate": 6.337426173453529e-06,
      "loss": 0.0556,
      "step": 9426
    },
    {
      "epoch": 0.7325924774634753,
      "grad_norm": 0.4841836392879486,
      "learning_rate": 6.337037612682624e-06,
      "loss": 0.2326,
      "step": 9427
    },
    {
      "epoch": 0.7326701896176562,
      "grad_norm": 0.1132848784327507,
      "learning_rate": 6.33664905191172e-06,
      "loss": 0.0391,
      "step": 9428
    },
    {
      "epoch": 0.7327479017718371,
      "grad_norm": 0.32205304503440857,
      "learning_rate": 6.3362604911408156e-06,
      "loss": 0.1162,
      "step": 9429
    },
    {
      "epoch": 0.7328256139260181,
      "grad_norm": 0.07038603723049164,
      "learning_rate": 6.3358719303699105e-06,
      "loss": 0.0114,
      "step": 9430
    },
    {
      "epoch": 0.7329033260801989,
      "grad_norm": 0.5939540266990662,
      "learning_rate": 6.335483369599006e-06,
      "loss": 0.1463,
      "step": 9431
    },
    {
      "epoch": 0.7329810382343799,
      "grad_norm": 0.700639545917511,
      "learning_rate": 6.335094808828101e-06,
      "loss": 0.4074,
      "step": 9432
    },
    {
      "epoch": 0.7330587503885607,
      "grad_norm": 0.5623716711997986,
      "learning_rate": 6.334706248057196e-06,
      "loss": 0.2851,
      "step": 9433
    },
    {
      "epoch": 0.7331364625427417,
      "grad_norm": 0.3140455484390259,
      "learning_rate": 6.334317687286292e-06,
      "loss": 0.1343,
      "step": 9434
    },
    {
      "epoch": 0.7332141746969226,
      "grad_norm": 0.44951942563056946,
      "learning_rate": 6.333929126515388e-06,
      "loss": 0.2393,
      "step": 9435
    },
    {
      "epoch": 0.7332918868511035,
      "grad_norm": 0.3167326748371124,
      "learning_rate": 6.333540565744483e-06,
      "loss": 0.1598,
      "step": 9436
    },
    {
      "epoch": 0.7333695990052844,
      "grad_norm": 0.4634277820587158,
      "learning_rate": 6.3331520049735786e-06,
      "loss": 0.1559,
      "step": 9437
    },
    {
      "epoch": 0.7334473111594654,
      "grad_norm": 0.9474496245384216,
      "learning_rate": 6.332763444202674e-06,
      "loss": 1.1654,
      "step": 9438
    },
    {
      "epoch": 0.7335250233136462,
      "grad_norm": 0.5872187614440918,
      "learning_rate": 6.3323748834317685e-06,
      "loss": 0.2062,
      "step": 9439
    },
    {
      "epoch": 0.7336027354678272,
      "grad_norm": 0.23584584891796112,
      "learning_rate": 6.331986322660864e-06,
      "loss": 0.1642,
      "step": 9440
    },
    {
      "epoch": 0.7336804476220081,
      "grad_norm": 0.4980463981628418,
      "learning_rate": 6.33159776188996e-06,
      "loss": 0.1561,
      "step": 9441
    },
    {
      "epoch": 0.733758159776189,
      "grad_norm": 0.11676077544689178,
      "learning_rate": 6.331209201119055e-06,
      "loss": 0.0064,
      "step": 9442
    },
    {
      "epoch": 0.7338358719303699,
      "grad_norm": 0.3561374843120575,
      "learning_rate": 6.330820640348151e-06,
      "loss": 0.1664,
      "step": 9443
    },
    {
      "epoch": 0.7339135840845509,
      "grad_norm": 0.6704502701759338,
      "learning_rate": 6.330432079577247e-06,
      "loss": 0.9394,
      "step": 9444
    },
    {
      "epoch": 0.7339912962387317,
      "grad_norm": 0.4188297688961029,
      "learning_rate": 6.3300435188063415e-06,
      "loss": 0.3795,
      "step": 9445
    },
    {
      "epoch": 0.7340690083929127,
      "grad_norm": 0.1692536324262619,
      "learning_rate": 6.329654958035437e-06,
      "loss": 0.1126,
      "step": 9446
    },
    {
      "epoch": 0.7341467205470935,
      "grad_norm": 0.07291290163993835,
      "learning_rate": 6.329266397264533e-06,
      "loss": 0.02,
      "step": 9447
    },
    {
      "epoch": 0.7342244327012745,
      "grad_norm": 0.21819841861724854,
      "learning_rate": 6.328877836493627e-06,
      "loss": 0.1623,
      "step": 9448
    },
    {
      "epoch": 0.7343021448554554,
      "grad_norm": 1.2235097885131836,
      "learning_rate": 6.328489275722723e-06,
      "loss": 0.6819,
      "step": 9449
    },
    {
      "epoch": 0.7343798570096363,
      "grad_norm": 0.5098469257354736,
      "learning_rate": 6.328100714951819e-06,
      "loss": 0.3068,
      "step": 9450
    },
    {
      "epoch": 0.7344575691638172,
      "grad_norm": 0.21376456320285797,
      "learning_rate": 6.327712154180914e-06,
      "loss": 0.1115,
      "step": 9451
    },
    {
      "epoch": 0.7345352813179982,
      "grad_norm": 0.6218850016593933,
      "learning_rate": 6.32732359341001e-06,
      "loss": 0.1563,
      "step": 9452
    },
    {
      "epoch": 0.734612993472179,
      "grad_norm": 1.1035025119781494,
      "learning_rate": 6.326935032639105e-06,
      "loss": 0.3471,
      "step": 9453
    },
    {
      "epoch": 0.73469070562636,
      "grad_norm": 0.413622111082077,
      "learning_rate": 6.326546471868201e-06,
      "loss": 0.1179,
      "step": 9454
    },
    {
      "epoch": 0.7347684177805409,
      "grad_norm": 0.12897999584674835,
      "learning_rate": 6.326157911097296e-06,
      "loss": 0.0264,
      "step": 9455
    },
    {
      "epoch": 0.7348461299347218,
      "grad_norm": 0.31889069080352783,
      "learning_rate": 6.325769350326392e-06,
      "loss": 0.109,
      "step": 9456
    },
    {
      "epoch": 0.7349238420889027,
      "grad_norm": 0.09997084736824036,
      "learning_rate": 6.325380789555488e-06,
      "loss": 0.0497,
      "step": 9457
    },
    {
      "epoch": 0.7350015542430837,
      "grad_norm": 0.20196844637393951,
      "learning_rate": 6.324992228784582e-06,
      "loss": 0.0449,
      "step": 9458
    },
    {
      "epoch": 0.7350792663972645,
      "grad_norm": 0.4055446982383728,
      "learning_rate": 6.324603668013678e-06,
      "loss": 0.1548,
      "step": 9459
    },
    {
      "epoch": 0.7351569785514455,
      "grad_norm": 0.6454036831855774,
      "learning_rate": 6.324215107242773e-06,
      "loss": 0.2692,
      "step": 9460
    },
    {
      "epoch": 0.7352346907056264,
      "grad_norm": 0.8605245351791382,
      "learning_rate": 6.323826546471868e-06,
      "loss": 0.4549,
      "step": 9461
    },
    {
      "epoch": 0.7353124028598073,
      "grad_norm": 0.16795656085014343,
      "learning_rate": 6.323437985700964e-06,
      "loss": 0.0586,
      "step": 9462
    },
    {
      "epoch": 0.7353901150139882,
      "grad_norm": 0.3949059844017029,
      "learning_rate": 6.32304942493006e-06,
      "loss": 0.2102,
      "step": 9463
    },
    {
      "epoch": 0.735467827168169,
      "grad_norm": 1.4179143905639648,
      "learning_rate": 6.322660864159155e-06,
      "loss": 0.167,
      "step": 9464
    },
    {
      "epoch": 0.73554553932235,
      "grad_norm": 1.026891827583313,
      "learning_rate": 6.322272303388251e-06,
      "loss": 0.6979,
      "step": 9465
    },
    {
      "epoch": 0.735623251476531,
      "grad_norm": 0.32037192583084106,
      "learning_rate": 6.3218837426173465e-06,
      "loss": 0.144,
      "step": 9466
    },
    {
      "epoch": 0.7357009636307118,
      "grad_norm": 0.22931401431560516,
      "learning_rate": 6.321495181846441e-06,
      "loss": 0.0439,
      "step": 9467
    },
    {
      "epoch": 0.7357786757848928,
      "grad_norm": 0.9637518525123596,
      "learning_rate": 6.321106621075536e-06,
      "loss": 0.3346,
      "step": 9468
    },
    {
      "epoch": 0.7358563879390737,
      "grad_norm": 1.2755730152130127,
      "learning_rate": 6.320718060304632e-06,
      "loss": 0.3663,
      "step": 9469
    },
    {
      "epoch": 0.7359341000932546,
      "grad_norm": 0.3919222950935364,
      "learning_rate": 6.320329499533727e-06,
      "loss": 0.1194,
      "step": 9470
    },
    {
      "epoch": 0.7360118122474355,
      "grad_norm": 0.1606338620185852,
      "learning_rate": 6.319940938762823e-06,
      "loss": 0.0156,
      "step": 9471
    },
    {
      "epoch": 0.7360895244016165,
      "grad_norm": 0.5992616415023804,
      "learning_rate": 6.319552377991919e-06,
      "loss": 0.5811,
      "step": 9472
    },
    {
      "epoch": 0.7361672365557973,
      "grad_norm": 0.8167959451675415,
      "learning_rate": 6.319163817221014e-06,
      "loss": 0.4979,
      "step": 9473
    },
    {
      "epoch": 0.7362449487099783,
      "grad_norm": 0.6413429379463196,
      "learning_rate": 6.3187752564501095e-06,
      "loss": 0.1111,
      "step": 9474
    },
    {
      "epoch": 0.7363226608641592,
      "grad_norm": 0.5162666440010071,
      "learning_rate": 6.318386695679205e-06,
      "loss": 0.3138,
      "step": 9475
    },
    {
      "epoch": 0.73640037301834,
      "grad_norm": 0.38827845454216003,
      "learning_rate": 6.317998134908299e-06,
      "loss": 0.1087,
      "step": 9476
    },
    {
      "epoch": 0.736478085172521,
      "grad_norm": 0.28324899077415466,
      "learning_rate": 6.317609574137395e-06,
      "loss": 0.0911,
      "step": 9477
    },
    {
      "epoch": 0.7365557973267018,
      "grad_norm": 0.3034546375274658,
      "learning_rate": 6.317221013366491e-06,
      "loss": 0.1322,
      "step": 9478
    },
    {
      "epoch": 0.7366335094808828,
      "grad_norm": 0.23170873522758484,
      "learning_rate": 6.316832452595586e-06,
      "loss": 0.0496,
      "step": 9479
    },
    {
      "epoch": 0.7367112216350638,
      "grad_norm": 0.42674365639686584,
      "learning_rate": 6.316443891824682e-06,
      "loss": 0.1313,
      "step": 9480
    },
    {
      "epoch": 0.7367889337892446,
      "grad_norm": 0.497383177280426,
      "learning_rate": 6.3160553310537775e-06,
      "loss": 0.0604,
      "step": 9481
    },
    {
      "epoch": 0.7368666459434255,
      "grad_norm": 0.8107370138168335,
      "learning_rate": 6.3156667702828725e-06,
      "loss": 0.1398,
      "step": 9482
    },
    {
      "epoch": 0.7369443580976065,
      "grad_norm": 0.13483691215515137,
      "learning_rate": 6.315278209511968e-06,
      "loss": 0.0263,
      "step": 9483
    },
    {
      "epoch": 0.7370220702517873,
      "grad_norm": 0.21870861947536469,
      "learning_rate": 6.314889648741064e-06,
      "loss": 0.0628,
      "step": 9484
    },
    {
      "epoch": 0.7370997824059683,
      "grad_norm": 0.6018611192703247,
      "learning_rate": 6.31450108797016e-06,
      "loss": 0.3024,
      "step": 9485
    },
    {
      "epoch": 0.7371774945601492,
      "grad_norm": 0.4531461298465729,
      "learning_rate": 6.314112527199254e-06,
      "loss": 0.1628,
      "step": 9486
    },
    {
      "epoch": 0.7372552067143301,
      "grad_norm": 0.8167621493339539,
      "learning_rate": 6.31372396642835e-06,
      "loss": 0.4476,
      "step": 9487
    },
    {
      "epoch": 0.737332918868511,
      "grad_norm": 0.7271184325218201,
      "learning_rate": 6.3133354056574456e-06,
      "loss": 0.7306,
      "step": 9488
    },
    {
      "epoch": 0.737410631022692,
      "grad_norm": 0.9229701161384583,
      "learning_rate": 6.3129468448865405e-06,
      "loss": 0.1241,
      "step": 9489
    },
    {
      "epoch": 0.7374883431768728,
      "grad_norm": 1.2124640941619873,
      "learning_rate": 6.312558284115636e-06,
      "loss": 0.6064,
      "step": 9490
    },
    {
      "epoch": 0.7375660553310538,
      "grad_norm": 0.26516416668891907,
      "learning_rate": 6.312169723344732e-06,
      "loss": 0.061,
      "step": 9491
    },
    {
      "epoch": 0.7376437674852346,
      "grad_norm": 0.43550050258636475,
      "learning_rate": 6.311781162573827e-06,
      "loss": 0.3404,
      "step": 9492
    },
    {
      "epoch": 0.7377214796394156,
      "grad_norm": 0.45325276255607605,
      "learning_rate": 6.311392601802923e-06,
      "loss": 0.6408,
      "step": 9493
    },
    {
      "epoch": 0.7377991917935965,
      "grad_norm": 0.44354483485221863,
      "learning_rate": 6.311004041032019e-06,
      "loss": 0.1328,
      "step": 9494
    },
    {
      "epoch": 0.7378769039477774,
      "grad_norm": 0.6028764247894287,
      "learning_rate": 6.310615480261113e-06,
      "loss": 0.3562,
      "step": 9495
    },
    {
      "epoch": 0.7379546161019583,
      "grad_norm": 0.2780090868473053,
      "learning_rate": 6.3102269194902085e-06,
      "loss": 0.115,
      "step": 9496
    },
    {
      "epoch": 0.7380323282561393,
      "grad_norm": 0.4635671079158783,
      "learning_rate": 6.309838358719304e-06,
      "loss": 0.2042,
      "step": 9497
    },
    {
      "epoch": 0.7381100404103201,
      "grad_norm": 0.2946094572544098,
      "learning_rate": 6.309449797948399e-06,
      "loss": 0.0911,
      "step": 9498
    },
    {
      "epoch": 0.7381877525645011,
      "grad_norm": 0.23520591855049133,
      "learning_rate": 6.309061237177495e-06,
      "loss": 0.0852,
      "step": 9499
    },
    {
      "epoch": 0.738265464718682,
      "grad_norm": 0.2035246193408966,
      "learning_rate": 6.308672676406591e-06,
      "loss": 0.1132,
      "step": 9500
    },
    {
      "epoch": 0.7383431768728629,
      "grad_norm": 0.24167537689208984,
      "learning_rate": 6.308284115635686e-06,
      "loss": 0.0897,
      "step": 9501
    },
    {
      "epoch": 0.7384208890270438,
      "grad_norm": 0.2675844430923462,
      "learning_rate": 6.307895554864782e-06,
      "loss": 0.1462,
      "step": 9502
    },
    {
      "epoch": 0.7384986011812248,
      "grad_norm": 0.19523227214813232,
      "learning_rate": 6.3075069940938774e-06,
      "loss": 0.0877,
      "step": 9503
    },
    {
      "epoch": 0.7385763133354056,
      "grad_norm": 0.06130805239081383,
      "learning_rate": 6.3071184333229715e-06,
      "loss": 0.0193,
      "step": 9504
    },
    {
      "epoch": 0.7386540254895866,
      "grad_norm": 0.21979175508022308,
      "learning_rate": 6.306729872552067e-06,
      "loss": 0.2013,
      "step": 9505
    },
    {
      "epoch": 0.7387317376437675,
      "grad_norm": 0.29052528738975525,
      "learning_rate": 6.306341311781163e-06,
      "loss": 0.1321,
      "step": 9506
    },
    {
      "epoch": 0.7388094497979484,
      "grad_norm": 0.8359785079956055,
      "learning_rate": 6.305952751010258e-06,
      "loss": 0.4208,
      "step": 9507
    },
    {
      "epoch": 0.7388871619521293,
      "grad_norm": 0.2602595388889313,
      "learning_rate": 6.305564190239354e-06,
      "loss": 0.066,
      "step": 9508
    },
    {
      "epoch": 0.7389648741063102,
      "grad_norm": 0.05653649568557739,
      "learning_rate": 6.30517562946845e-06,
      "loss": 0.0119,
      "step": 9509
    },
    {
      "epoch": 0.7390425862604911,
      "grad_norm": 0.11359487473964691,
      "learning_rate": 6.304787068697545e-06,
      "loss": 0.0771,
      "step": 9510
    },
    {
      "epoch": 0.7391202984146721,
      "grad_norm": 0.4206623435020447,
      "learning_rate": 6.30439850792664e-06,
      "loss": 0.2434,
      "step": 9511
    },
    {
      "epoch": 0.7391980105688529,
      "grad_norm": 0.5288529992103577,
      "learning_rate": 6.304009947155736e-06,
      "loss": 0.1814,
      "step": 9512
    },
    {
      "epoch": 0.7392757227230339,
      "grad_norm": 0.05991778522729874,
      "learning_rate": 6.30362138638483e-06,
      "loss": 0.0064,
      "step": 9513
    },
    {
      "epoch": 0.7393534348772148,
      "grad_norm": 0.4864424765110016,
      "learning_rate": 6.303232825613926e-06,
      "loss": 0.1922,
      "step": 9514
    },
    {
      "epoch": 0.7394311470313957,
      "grad_norm": 0.5781259536743164,
      "learning_rate": 6.302844264843022e-06,
      "loss": 0.4406,
      "step": 9515
    },
    {
      "epoch": 0.7395088591855766,
      "grad_norm": 0.1332097351551056,
      "learning_rate": 6.302455704072118e-06,
      "loss": 0.0238,
      "step": 9516
    },
    {
      "epoch": 0.7395865713397576,
      "grad_norm": 0.4004949927330017,
      "learning_rate": 6.302067143301213e-06,
      "loss": 0.2522,
      "step": 9517
    },
    {
      "epoch": 0.7396642834939384,
      "grad_norm": 1.028490662574768,
      "learning_rate": 6.3016785825303085e-06,
      "loss": 0.6657,
      "step": 9518
    },
    {
      "epoch": 0.7397419956481194,
      "grad_norm": 0.5541740655899048,
      "learning_rate": 6.301290021759404e-06,
      "loss": 0.3135,
      "step": 9519
    },
    {
      "epoch": 0.7398197078023003,
      "grad_norm": 0.6755937933921814,
      "learning_rate": 6.300901460988499e-06,
      "loss": 0.6762,
      "step": 9520
    },
    {
      "epoch": 0.7398974199564812,
      "grad_norm": 0.20696420967578888,
      "learning_rate": 6.300512900217595e-06,
      "loss": 0.0925,
      "step": 9521
    },
    {
      "epoch": 0.7399751321106621,
      "grad_norm": 0.16844645142555237,
      "learning_rate": 6.300124339446691e-06,
      "loss": 0.0651,
      "step": 9522
    },
    {
      "epoch": 0.740052844264843,
      "grad_norm": 0.22489449381828308,
      "learning_rate": 6.299735778675785e-06,
      "loss": 0.1256,
      "step": 9523
    },
    {
      "epoch": 0.7401305564190239,
      "grad_norm": 0.4335392415523529,
      "learning_rate": 6.299347217904881e-06,
      "loss": 0.2835,
      "step": 9524
    },
    {
      "epoch": 0.7402082685732049,
      "grad_norm": 0.38244593143463135,
      "learning_rate": 6.2989586571339765e-06,
      "loss": 0.2945,
      "step": 9525
    },
    {
      "epoch": 0.7402859807273857,
      "grad_norm": 0.16752280294895172,
      "learning_rate": 6.2985700963630714e-06,
      "loss": 0.0371,
      "step": 9526
    },
    {
      "epoch": 0.7403636928815667,
      "grad_norm": 0.33217015862464905,
      "learning_rate": 6.298181535592167e-06,
      "loss": 0.0553,
      "step": 9527
    },
    {
      "epoch": 0.7404414050357476,
      "grad_norm": 0.11890891194343567,
      "learning_rate": 6.297792974821263e-06,
      "loss": 0.0819,
      "step": 9528
    },
    {
      "epoch": 0.7405191171899285,
      "grad_norm": 0.8048269152641296,
      "learning_rate": 6.297404414050358e-06,
      "loss": 0.5108,
      "step": 9529
    },
    {
      "epoch": 0.7405968293441094,
      "grad_norm": 0.1526738405227661,
      "learning_rate": 6.297015853279454e-06,
      "loss": 0.0328,
      "step": 9530
    },
    {
      "epoch": 0.7406745414982904,
      "grad_norm": 0.43793198466300964,
      "learning_rate": 6.2966272925085496e-06,
      "loss": 0.1113,
      "step": 9531
    },
    {
      "epoch": 0.7407522536524712,
      "grad_norm": 0.33657869696617126,
      "learning_rate": 6.296238731737644e-06,
      "loss": 0.1462,
      "step": 9532
    },
    {
      "epoch": 0.7408299658066522,
      "grad_norm": 1.6299866437911987,
      "learning_rate": 6.2958501709667395e-06,
      "loss": 0.7206,
      "step": 9533
    },
    {
      "epoch": 0.7409076779608331,
      "grad_norm": 0.4949595332145691,
      "learning_rate": 6.295461610195835e-06,
      "loss": 0.2544,
      "step": 9534
    },
    {
      "epoch": 0.740985390115014,
      "grad_norm": 0.09490900486707687,
      "learning_rate": 6.29507304942493e-06,
      "loss": 0.0121,
      "step": 9535
    },
    {
      "epoch": 0.7410631022691949,
      "grad_norm": 0.7983739972114563,
      "learning_rate": 6.294684488654026e-06,
      "loss": 0.4182,
      "step": 9536
    },
    {
      "epoch": 0.7411408144233759,
      "grad_norm": 0.2293778657913208,
      "learning_rate": 6.294295927883122e-06,
      "loss": 0.088,
      "step": 9537
    },
    {
      "epoch": 0.7412185265775567,
      "grad_norm": 0.2575339376926422,
      "learning_rate": 6.293907367112217e-06,
      "loss": 0.0682,
      "step": 9538
    },
    {
      "epoch": 0.7412962387317377,
      "grad_norm": 0.28153195977211,
      "learning_rate": 6.2935188063413126e-06,
      "loss": 0.1665,
      "step": 9539
    },
    {
      "epoch": 0.7413739508859185,
      "grad_norm": 0.295634001493454,
      "learning_rate": 6.293130245570408e-06,
      "loss": 0.1244,
      "step": 9540
    },
    {
      "epoch": 0.7414516630400995,
      "grad_norm": 0.15302234888076782,
      "learning_rate": 6.2927416847995025e-06,
      "loss": 0.0392,
      "step": 9541
    },
    {
      "epoch": 0.7415293751942804,
      "grad_norm": 0.592488706111908,
      "learning_rate": 6.292353124028598e-06,
      "loss": 0.541,
      "step": 9542
    },
    {
      "epoch": 0.7416070873484613,
      "grad_norm": 0.3124680519104004,
      "learning_rate": 6.291964563257694e-06,
      "loss": 0.1228,
      "step": 9543
    },
    {
      "epoch": 0.7416847995026422,
      "grad_norm": 0.1253156065940857,
      "learning_rate": 6.291576002486789e-06,
      "loss": 0.04,
      "step": 9544
    },
    {
      "epoch": 0.7417625116568232,
      "grad_norm": 0.31308993697166443,
      "learning_rate": 6.291187441715885e-06,
      "loss": 0.2028,
      "step": 9545
    },
    {
      "epoch": 0.741840223811004,
      "grad_norm": 0.9180815815925598,
      "learning_rate": 6.290798880944981e-06,
      "loss": 0.2626,
      "step": 9546
    },
    {
      "epoch": 0.741917935965185,
      "grad_norm": 0.8454011082649231,
      "learning_rate": 6.290410320174076e-06,
      "loss": 0.8885,
      "step": 9547
    },
    {
      "epoch": 0.7419956481193659,
      "grad_norm": 0.6387682557106018,
      "learning_rate": 6.290021759403171e-06,
      "loss": 0.6432,
      "step": 9548
    },
    {
      "epoch": 0.7420733602735468,
      "grad_norm": 0.5267034769058228,
      "learning_rate": 6.289633198632267e-06,
      "loss": 0.3953,
      "step": 9549
    },
    {
      "epoch": 0.7421510724277277,
      "grad_norm": 0.6602770686149597,
      "learning_rate": 6.289244637861363e-06,
      "loss": 0.3503,
      "step": 9550
    },
    {
      "epoch": 0.7422287845819087,
      "grad_norm": 0.6077340841293335,
      "learning_rate": 6.288856077090457e-06,
      "loss": 0.1496,
      "step": 9551
    },
    {
      "epoch": 0.7423064967360895,
      "grad_norm": 0.2694939374923706,
      "learning_rate": 6.288467516319553e-06,
      "loss": 0.1389,
      "step": 9552
    },
    {
      "epoch": 0.7423842088902705,
      "grad_norm": 0.514105498790741,
      "learning_rate": 6.288078955548649e-06,
      "loss": 0.2734,
      "step": 9553
    },
    {
      "epoch": 0.7424619210444513,
      "grad_norm": 0.3305545449256897,
      "learning_rate": 6.287690394777744e-06,
      "loss": 0.093,
      "step": 9554
    },
    {
      "epoch": 0.7425396331986323,
      "grad_norm": 0.48475635051727295,
      "learning_rate": 6.287301834006839e-06,
      "loss": 0.2935,
      "step": 9555
    },
    {
      "epoch": 0.7426173453528132,
      "grad_norm": 0.07230403274297714,
      "learning_rate": 6.286913273235935e-06,
      "loss": 0.0142,
      "step": 9556
    },
    {
      "epoch": 0.742695057506994,
      "grad_norm": 0.5113726854324341,
      "learning_rate": 6.28652471246503e-06,
      "loss": 0.1363,
      "step": 9557
    },
    {
      "epoch": 0.742772769661175,
      "grad_norm": 0.31895577907562256,
      "learning_rate": 6.286136151694125e-06,
      "loss": 0.131,
      "step": 9558
    },
    {
      "epoch": 0.742850481815356,
      "grad_norm": 0.3267918825149536,
      "learning_rate": 6.285747590923221e-06,
      "loss": 0.1504,
      "step": 9559
    },
    {
      "epoch": 0.7429281939695368,
      "grad_norm": 0.17361941933631897,
      "learning_rate": 6.285359030152316e-06,
      "loss": 0.0313,
      "step": 9560
    },
    {
      "epoch": 0.7430059061237178,
      "grad_norm": 0.552908182144165,
      "learning_rate": 6.284970469381412e-06,
      "loss": 0.2131,
      "step": 9561
    },
    {
      "epoch": 0.7430836182778987,
      "grad_norm": 0.36734989285469055,
      "learning_rate": 6.284581908610507e-06,
      "loss": 0.1535,
      "step": 9562
    },
    {
      "epoch": 0.7431613304320795,
      "grad_norm": 0.16976840794086456,
      "learning_rate": 6.284193347839602e-06,
      "loss": 0.0806,
      "step": 9563
    },
    {
      "epoch": 0.7432390425862605,
      "grad_norm": 0.42125511169433594,
      "learning_rate": 6.283804787068698e-06,
      "loss": 0.2993,
      "step": 9564
    },
    {
      "epoch": 0.7433167547404415,
      "grad_norm": 0.27952006459236145,
      "learning_rate": 6.283416226297794e-06,
      "loss": 0.0892,
      "step": 9565
    },
    {
      "epoch": 0.7433944668946223,
      "grad_norm": 0.37682434916496277,
      "learning_rate": 6.283027665526888e-06,
      "loss": 0.1389,
      "step": 9566
    },
    {
      "epoch": 0.7434721790488033,
      "grad_norm": 0.36140263080596924,
      "learning_rate": 6.282639104755984e-06,
      "loss": 0.0891,
      "step": 9567
    },
    {
      "epoch": 0.7435498912029841,
      "grad_norm": 0.36380040645599365,
      "learning_rate": 6.28225054398508e-06,
      "loss": 0.0992,
      "step": 9568
    },
    {
      "epoch": 0.743627603357165,
      "grad_norm": 0.3701314628124237,
      "learning_rate": 6.281861983214175e-06,
      "loss": 0.1653,
      "step": 9569
    },
    {
      "epoch": 0.743705315511346,
      "grad_norm": 0.21471205353736877,
      "learning_rate": 6.28147342244327e-06,
      "loss": 0.1044,
      "step": 9570
    },
    {
      "epoch": 0.7437830276655268,
      "grad_norm": 0.20784592628479004,
      "learning_rate": 6.281084861672366e-06,
      "loss": 0.1055,
      "step": 9571
    },
    {
      "epoch": 0.7438607398197078,
      "grad_norm": 0.13231027126312256,
      "learning_rate": 6.280696300901461e-06,
      "loss": 0.0461,
      "step": 9572
    },
    {
      "epoch": 0.7439384519738887,
      "grad_norm": 0.31512555480003357,
      "learning_rate": 6.280307740130557e-06,
      "loss": 0.1746,
      "step": 9573
    },
    {
      "epoch": 0.7440161641280696,
      "grad_norm": 0.1342865526676178,
      "learning_rate": 6.279919179359653e-06,
      "loss": 0.0331,
      "step": 9574
    },
    {
      "epoch": 0.7440938762822505,
      "grad_norm": 0.517657458782196,
      "learning_rate": 6.279530618588747e-06,
      "loss": 0.2906,
      "step": 9575
    },
    {
      "epoch": 0.7441715884364315,
      "grad_norm": 0.14938171207904816,
      "learning_rate": 6.279142057817843e-06,
      "loss": 0.0256,
      "step": 9576
    },
    {
      "epoch": 0.7442493005906123,
      "grad_norm": 0.17362380027770996,
      "learning_rate": 6.2787534970469384e-06,
      "loss": 0.0671,
      "step": 9577
    },
    {
      "epoch": 0.7443270127447933,
      "grad_norm": 0.4156543016433716,
      "learning_rate": 6.278364936276034e-06,
      "loss": 0.1391,
      "step": 9578
    },
    {
      "epoch": 0.7444047248989742,
      "grad_norm": 0.2140892893075943,
      "learning_rate": 6.277976375505129e-06,
      "loss": 0.0882,
      "step": 9579
    },
    {
      "epoch": 0.7444824370531551,
      "grad_norm": 0.47169026732444763,
      "learning_rate": 6.277587814734225e-06,
      "loss": 0.4798,
      "step": 9580
    },
    {
      "epoch": 0.744560149207336,
      "grad_norm": 0.7737600803375244,
      "learning_rate": 6.277199253963321e-06,
      "loss": 0.2723,
      "step": 9581
    },
    {
      "epoch": 0.744637861361517,
      "grad_norm": 0.17810359597206116,
      "learning_rate": 6.276810693192416e-06,
      "loss": 0.079,
      "step": 9582
    },
    {
      "epoch": 0.7447155735156978,
      "grad_norm": 0.6671358346939087,
      "learning_rate": 6.2764221324215115e-06,
      "loss": 0.2868,
      "step": 9583
    },
    {
      "epoch": 0.7447932856698788,
      "grad_norm": 0.30707865953445435,
      "learning_rate": 6.276033571650607e-06,
      "loss": 0.0844,
      "step": 9584
    },
    {
      "epoch": 0.7448709978240596,
      "grad_norm": 0.3363092541694641,
      "learning_rate": 6.2756450108797014e-06,
      "loss": 0.0621,
      "step": 9585
    },
    {
      "epoch": 0.7449487099782406,
      "grad_norm": 0.48418623208999634,
      "learning_rate": 6.275256450108797e-06,
      "loss": 0.0519,
      "step": 9586
    },
    {
      "epoch": 0.7450264221324215,
      "grad_norm": 0.15404680371284485,
      "learning_rate": 6.274867889337893e-06,
      "loss": 0.0597,
      "step": 9587
    },
    {
      "epoch": 0.7451041342866024,
      "grad_norm": 0.8359521627426147,
      "learning_rate": 6.274479328566988e-06,
      "loss": 0.6172,
      "step": 9588
    },
    {
      "epoch": 0.7451818464407833,
      "grad_norm": 0.27255427837371826,
      "learning_rate": 6.274090767796084e-06,
      "loss": 0.409,
      "step": 9589
    },
    {
      "epoch": 0.7452595585949643,
      "grad_norm": 0.5131583213806152,
      "learning_rate": 6.2737022070251796e-06,
      "loss": 0.1068,
      "step": 9590
    },
    {
      "epoch": 0.7453372707491451,
      "grad_norm": 0.7435267567634583,
      "learning_rate": 6.2733136462542745e-06,
      "loss": 0.1657,
      "step": 9591
    },
    {
      "epoch": 0.7454149829033261,
      "grad_norm": 0.47720664739608765,
      "learning_rate": 6.27292508548337e-06,
      "loss": 0.2491,
      "step": 9592
    },
    {
      "epoch": 0.745492695057507,
      "grad_norm": 0.08051855862140656,
      "learning_rate": 6.272536524712466e-06,
      "loss": 0.0473,
      "step": 9593
    },
    {
      "epoch": 0.7455704072116879,
      "grad_norm": 0.35320529341697693,
      "learning_rate": 6.27214796394156e-06,
      "loss": 0.1955,
      "step": 9594
    },
    {
      "epoch": 0.7456481193658688,
      "grad_norm": 0.608851969242096,
      "learning_rate": 6.271759403170656e-06,
      "loss": 0.3285,
      "step": 9595
    },
    {
      "epoch": 0.7457258315200498,
      "grad_norm": 0.6657785177230835,
      "learning_rate": 6.271370842399752e-06,
      "loss": 0.1376,
      "step": 9596
    },
    {
      "epoch": 0.7458035436742306,
      "grad_norm": 0.1969166249036789,
      "learning_rate": 6.270982281628847e-06,
      "loss": 0.0924,
      "step": 9597
    },
    {
      "epoch": 0.7458812558284116,
      "grad_norm": 0.10714453458786011,
      "learning_rate": 6.2705937208579426e-06,
      "loss": 0.0337,
      "step": 9598
    },
    {
      "epoch": 0.7459589679825924,
      "grad_norm": 0.3880767226219177,
      "learning_rate": 6.270205160087038e-06,
      "loss": 0.582,
      "step": 9599
    },
    {
      "epoch": 0.7460366801367734,
      "grad_norm": 0.3233720064163208,
      "learning_rate": 6.269816599316133e-06,
      "loss": 0.2739,
      "step": 9600
    },
    {
      "epoch": 0.7461143922909543,
      "grad_norm": 0.22614097595214844,
      "learning_rate": 6.269428038545229e-06,
      "loss": 0.1375,
      "step": 9601
    },
    {
      "epoch": 0.7461921044451352,
      "grad_norm": 0.23824049532413483,
      "learning_rate": 6.269039477774325e-06,
      "loss": 0.1067,
      "step": 9602
    },
    {
      "epoch": 0.7462698165993161,
      "grad_norm": 0.6503025889396667,
      "learning_rate": 6.268650917003419e-06,
      "loss": 0.1702,
      "step": 9603
    },
    {
      "epoch": 0.7463475287534971,
      "grad_norm": 0.17637965083122253,
      "learning_rate": 6.268262356232515e-06,
      "loss": 0.0424,
      "step": 9604
    },
    {
      "epoch": 0.7464252409076779,
      "grad_norm": 0.5421866774559021,
      "learning_rate": 6.267873795461611e-06,
      "loss": 0.5235,
      "step": 9605
    },
    {
      "epoch": 0.7465029530618589,
      "grad_norm": 0.41095203161239624,
      "learning_rate": 6.267485234690706e-06,
      "loss": 0.1458,
      "step": 9606
    },
    {
      "epoch": 0.7465806652160398,
      "grad_norm": 0.24330414831638336,
      "learning_rate": 6.267096673919801e-06,
      "loss": 0.1011,
      "step": 9607
    },
    {
      "epoch": 0.7466583773702207,
      "grad_norm": 0.2733047902584076,
      "learning_rate": 6.266708113148897e-06,
      "loss": 0.0643,
      "step": 9608
    },
    {
      "epoch": 0.7467360895244016,
      "grad_norm": 0.2332746684551239,
      "learning_rate": 6.266319552377993e-06,
      "loss": 0.0277,
      "step": 9609
    },
    {
      "epoch": 0.7468138016785826,
      "grad_norm": 0.5081865787506104,
      "learning_rate": 6.265930991607088e-06,
      "loss": 0.1558,
      "step": 9610
    },
    {
      "epoch": 0.7468915138327634,
      "grad_norm": 0.38875284790992737,
      "learning_rate": 6.265542430836184e-06,
      "loss": 0.0496,
      "step": 9611
    },
    {
      "epoch": 0.7469692259869444,
      "grad_norm": 0.4803680181503296,
      "learning_rate": 6.2651538700652795e-06,
      "loss": 0.2335,
      "step": 9612
    },
    {
      "epoch": 0.7470469381411253,
      "grad_norm": 0.22315271198749542,
      "learning_rate": 6.2647653092943736e-06,
      "loss": 0.05,
      "step": 9613
    },
    {
      "epoch": 0.7471246502953062,
      "grad_norm": 0.4325036406517029,
      "learning_rate": 6.264376748523469e-06,
      "loss": 0.1375,
      "step": 9614
    },
    {
      "epoch": 0.7472023624494871,
      "grad_norm": 0.15309645235538483,
      "learning_rate": 6.263988187752565e-06,
      "loss": 0.0688,
      "step": 9615
    },
    {
      "epoch": 0.747280074603668,
      "grad_norm": 0.22475899755954742,
      "learning_rate": 6.26359962698166e-06,
      "loss": 0.0957,
      "step": 9616
    },
    {
      "epoch": 0.7473577867578489,
      "grad_norm": 0.5725080370903015,
      "learning_rate": 6.263211066210756e-06,
      "loss": 0.3053,
      "step": 9617
    },
    {
      "epoch": 0.7474354989120299,
      "grad_norm": 0.5900141000747681,
      "learning_rate": 6.262822505439852e-06,
      "loss": 0.0886,
      "step": 9618
    },
    {
      "epoch": 0.7475132110662107,
      "grad_norm": 0.11077432334423065,
      "learning_rate": 6.262433944668947e-06,
      "loss": 0.0131,
      "step": 9619
    },
    {
      "epoch": 0.7475909232203917,
      "grad_norm": 0.3142118453979492,
      "learning_rate": 6.2620453838980425e-06,
      "loss": 0.4812,
      "step": 9620
    },
    {
      "epoch": 0.7476686353745726,
      "grad_norm": 0.32611802220344543,
      "learning_rate": 6.261656823127138e-06,
      "loss": 0.1627,
      "step": 9621
    },
    {
      "epoch": 0.7477463475287535,
      "grad_norm": 0.3161340355873108,
      "learning_rate": 6.261268262356232e-06,
      "loss": 0.133,
      "step": 9622
    },
    {
      "epoch": 0.7478240596829344,
      "grad_norm": 0.14787767827510834,
      "learning_rate": 6.260879701585328e-06,
      "loss": 0.0567,
      "step": 9623
    },
    {
      "epoch": 0.7479017718371154,
      "grad_norm": 0.3784210979938507,
      "learning_rate": 6.260491140814424e-06,
      "loss": 0.1213,
      "step": 9624
    },
    {
      "epoch": 0.7479794839912962,
      "grad_norm": 0.31516122817993164,
      "learning_rate": 6.260102580043519e-06,
      "loss": 0.1226,
      "step": 9625
    },
    {
      "epoch": 0.7480571961454772,
      "grad_norm": 0.06434004753828049,
      "learning_rate": 6.259714019272615e-06,
      "loss": 0.0105,
      "step": 9626
    },
    {
      "epoch": 0.7481349082996581,
      "grad_norm": 0.14804184436798096,
      "learning_rate": 6.2593254585017105e-06,
      "loss": 0.0393,
      "step": 9627
    },
    {
      "epoch": 0.748212620453839,
      "grad_norm": 0.19487926363945007,
      "learning_rate": 6.2589368977308054e-06,
      "loss": 0.0613,
      "step": 9628
    },
    {
      "epoch": 0.7482903326080199,
      "grad_norm": 0.2609430253505707,
      "learning_rate": 6.258548336959901e-06,
      "loss": 0.1378,
      "step": 9629
    },
    {
      "epoch": 0.7483680447622008,
      "grad_norm": 0.8387916684150696,
      "learning_rate": 6.258159776188997e-06,
      "loss": 0.3822,
      "step": 9630
    },
    {
      "epoch": 0.7484457569163817,
      "grad_norm": 0.21355988085269928,
      "learning_rate": 6.257771215418091e-06,
      "loss": 0.0511,
      "step": 9631
    },
    {
      "epoch": 0.7485234690705627,
      "grad_norm": 0.7858293056488037,
      "learning_rate": 6.257382654647187e-06,
      "loss": 0.7191,
      "step": 9632
    },
    {
      "epoch": 0.7486011812247435,
      "grad_norm": 0.2327311933040619,
      "learning_rate": 6.256994093876283e-06,
      "loss": 0.0878,
      "step": 9633
    },
    {
      "epoch": 0.7486788933789245,
      "grad_norm": 0.3537049889564514,
      "learning_rate": 6.256605533105378e-06,
      "loss": 0.0992,
      "step": 9634
    },
    {
      "epoch": 0.7487566055331054,
      "grad_norm": 0.5590578317642212,
      "learning_rate": 6.2562169723344735e-06,
      "loss": 0.185,
      "step": 9635
    },
    {
      "epoch": 0.7488343176872863,
      "grad_norm": 0.9735933542251587,
      "learning_rate": 6.255828411563569e-06,
      "loss": 0.3385,
      "step": 9636
    },
    {
      "epoch": 0.7489120298414672,
      "grad_norm": 0.6457675099372864,
      "learning_rate": 6.255439850792665e-06,
      "loss": 0.3573,
      "step": 9637
    },
    {
      "epoch": 0.7489897419956482,
      "grad_norm": 0.5686675310134888,
      "learning_rate": 6.25505129002176e-06,
      "loss": 0.2741,
      "step": 9638
    },
    {
      "epoch": 0.749067454149829,
      "grad_norm": 0.17377939820289612,
      "learning_rate": 6.254662729250856e-06,
      "loss": 0.0801,
      "step": 9639
    },
    {
      "epoch": 0.74914516630401,
      "grad_norm": 0.4414513409137726,
      "learning_rate": 6.254274168479952e-06,
      "loss": 0.1193,
      "step": 9640
    },
    {
      "epoch": 0.7492228784581909,
      "grad_norm": 0.7632251977920532,
      "learning_rate": 6.253885607709046e-06,
      "loss": 0.4288,
      "step": 9641
    },
    {
      "epoch": 0.7493005906123718,
      "grad_norm": 0.24553504586219788,
      "learning_rate": 6.2534970469381415e-06,
      "loss": 0.0486,
      "step": 9642
    },
    {
      "epoch": 0.7493783027665527,
      "grad_norm": 0.1455463021993637,
      "learning_rate": 6.253108486167237e-06,
      "loss": 0.0366,
      "step": 9643
    },
    {
      "epoch": 0.7494560149207335,
      "grad_norm": 0.336818128824234,
      "learning_rate": 6.252719925396332e-06,
      "loss": 0.1657,
      "step": 9644
    },
    {
      "epoch": 0.7495337270749145,
      "grad_norm": 0.43561574816703796,
      "learning_rate": 6.252331364625428e-06,
      "loss": 0.188,
      "step": 9645
    },
    {
      "epoch": 0.7496114392290955,
      "grad_norm": 0.175770103931427,
      "learning_rate": 6.251942803854524e-06,
      "loss": 0.0701,
      "step": 9646
    },
    {
      "epoch": 0.7496891513832763,
      "grad_norm": 0.22594307363033295,
      "learning_rate": 6.251554243083619e-06,
      "loss": 0.0427,
      "step": 9647
    },
    {
      "epoch": 0.7497668635374573,
      "grad_norm": 0.2327282875776291,
      "learning_rate": 6.251165682312715e-06,
      "loss": 0.1034,
      "step": 9648
    },
    {
      "epoch": 0.7498445756916382,
      "grad_norm": 0.21900111436843872,
      "learning_rate": 6.25077712154181e-06,
      "loss": 0.2111,
      "step": 9649
    },
    {
      "epoch": 0.749922287845819,
      "grad_norm": 0.29889434576034546,
      "learning_rate": 6.2503885607709045e-06,
      "loss": 0.0515,
      "step": 9650
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2428969293832779,
      "learning_rate": 6.25e-06,
      "loss": 0.0368,
      "step": 9651
    },
    {
      "epoch": 0.750077712154181,
      "grad_norm": 0.3010861575603485,
      "learning_rate": 6.249611439229096e-06,
      "loss": 0.17,
      "step": 9652
    },
    {
      "epoch": 0.7501554243083618,
      "grad_norm": 0.15328578650951385,
      "learning_rate": 6.249222878458191e-06,
      "loss": 0.0533,
      "step": 9653
    },
    {
      "epoch": 0.7502331364625427,
      "grad_norm": 0.24336589872837067,
      "learning_rate": 6.248834317687287e-06,
      "loss": 0.159,
      "step": 9654
    },
    {
      "epoch": 0.7503108486167237,
      "grad_norm": 0.12204301357269287,
      "learning_rate": 6.248445756916383e-06,
      "loss": 0.0552,
      "step": 9655
    },
    {
      "epoch": 0.7503885607709045,
      "grad_norm": 0.5068897008895874,
      "learning_rate": 6.248057196145478e-06,
      "loss": 0.5412,
      "step": 9656
    },
    {
      "epoch": 0.7504662729250855,
      "grad_norm": 0.6203166246414185,
      "learning_rate": 6.247668635374573e-06,
      "loss": 0.0811,
      "step": 9657
    },
    {
      "epoch": 0.7505439850792665,
      "grad_norm": 0.40772882103919983,
      "learning_rate": 6.247280074603669e-06,
      "loss": 0.1476,
      "step": 9658
    },
    {
      "epoch": 0.7506216972334473,
      "grad_norm": 0.4291817843914032,
      "learning_rate": 6.246891513832763e-06,
      "loss": 0.1906,
      "step": 9659
    },
    {
      "epoch": 0.7506994093876282,
      "grad_norm": 0.24264004826545715,
      "learning_rate": 6.246502953061859e-06,
      "loss": 0.052,
      "step": 9660
    },
    {
      "epoch": 0.7507771215418091,
      "grad_norm": 1.1875091791152954,
      "learning_rate": 6.246114392290955e-06,
      "loss": 0.7144,
      "step": 9661
    },
    {
      "epoch": 0.75085483369599,
      "grad_norm": 0.47971802949905396,
      "learning_rate": 6.24572583152005e-06,
      "loss": 0.3334,
      "step": 9662
    },
    {
      "epoch": 0.750932545850171,
      "grad_norm": 0.4173450469970703,
      "learning_rate": 6.245337270749146e-06,
      "loss": 0.0729,
      "step": 9663
    },
    {
      "epoch": 0.7510102580043518,
      "grad_norm": 0.5508922338485718,
      "learning_rate": 6.244948709978241e-06,
      "loss": 0.2862,
      "step": 9664
    },
    {
      "epoch": 0.7510879701585328,
      "grad_norm": 0.3784453570842743,
      "learning_rate": 6.244560149207336e-06,
      "loss": 0.3418,
      "step": 9665
    },
    {
      "epoch": 0.7511656823127137,
      "grad_norm": 0.22440436482429504,
      "learning_rate": 6.244171588436432e-06,
      "loss": 0.0956,
      "step": 9666
    },
    {
      "epoch": 0.7512433944668946,
      "grad_norm": 0.2305096834897995,
      "learning_rate": 6.243783027665528e-06,
      "loss": 0.2096,
      "step": 9667
    },
    {
      "epoch": 0.7513211066210755,
      "grad_norm": 0.6508302688598633,
      "learning_rate": 6.243394466894624e-06,
      "loss": 0.5503,
      "step": 9668
    },
    {
      "epoch": 0.7513988187752565,
      "grad_norm": 0.3577042520046234,
      "learning_rate": 6.243005906123718e-06,
      "loss": 0.1028,
      "step": 9669
    },
    {
      "epoch": 0.7514765309294373,
      "grad_norm": 0.28776785731315613,
      "learning_rate": 6.242617345352814e-06,
      "loss": 0.1451,
      "step": 9670
    },
    {
      "epoch": 0.7515542430836183,
      "grad_norm": 0.620743989944458,
      "learning_rate": 6.2422287845819095e-06,
      "loss": 0.179,
      "step": 9671
    },
    {
      "epoch": 0.7516319552377992,
      "grad_norm": 0.24622732400894165,
      "learning_rate": 6.241840223811004e-06,
      "loss": 0.0676,
      "step": 9672
    },
    {
      "epoch": 0.7517096673919801,
      "grad_norm": 0.19708706438541412,
      "learning_rate": 6.2414516630401e-06,
      "loss": 0.0419,
      "step": 9673
    },
    {
      "epoch": 0.751787379546161,
      "grad_norm": 0.028091173619031906,
      "learning_rate": 6.241063102269196e-06,
      "loss": 0.011,
      "step": 9674
    },
    {
      "epoch": 0.7518650917003419,
      "grad_norm": 0.3394460380077362,
      "learning_rate": 6.240674541498291e-06,
      "loss": 0.0371,
      "step": 9675
    },
    {
      "epoch": 0.7519428038545228,
      "grad_norm": 0.32497933506965637,
      "learning_rate": 6.240285980727387e-06,
      "loss": 0.1741,
      "step": 9676
    },
    {
      "epoch": 0.7520205160087038,
      "grad_norm": 0.5835596323013306,
      "learning_rate": 6.2398974199564825e-06,
      "loss": 0.14,
      "step": 9677
    },
    {
      "epoch": 0.7520982281628846,
      "grad_norm": 0.25693777203559875,
      "learning_rate": 6.239508859185577e-06,
      "loss": 0.0626,
      "step": 9678
    },
    {
      "epoch": 0.7521759403170656,
      "grad_norm": 0.2924472987651825,
      "learning_rate": 6.2391202984146724e-06,
      "loss": 0.2553,
      "step": 9679
    },
    {
      "epoch": 0.7522536524712465,
      "grad_norm": 0.27610543370246887,
      "learning_rate": 6.238731737643768e-06,
      "loss": 0.0929,
      "step": 9680
    },
    {
      "epoch": 0.7523313646254274,
      "grad_norm": 0.1762172430753708,
      "learning_rate": 6.238343176872863e-06,
      "loss": 0.0475,
      "step": 9681
    },
    {
      "epoch": 0.7524090767796083,
      "grad_norm": 0.08685192465782166,
      "learning_rate": 6.237954616101959e-06,
      "loss": 0.0573,
      "step": 9682
    },
    {
      "epoch": 0.7524867889337893,
      "grad_norm": 1.4847509860992432,
      "learning_rate": 6.237566055331055e-06,
      "loss": 0.3784,
      "step": 9683
    },
    {
      "epoch": 0.7525645010879701,
      "grad_norm": 3.3305580615997314,
      "learning_rate": 6.23717749456015e-06,
      "loss": 0.7053,
      "step": 9684
    },
    {
      "epoch": 0.7526422132421511,
      "grad_norm": 0.4025964140892029,
      "learning_rate": 6.236788933789245e-06,
      "loss": 0.069,
      "step": 9685
    },
    {
      "epoch": 0.752719925396332,
      "grad_norm": 0.9098169803619385,
      "learning_rate": 6.2364003730183405e-06,
      "loss": 0.8047,
      "step": 9686
    },
    {
      "epoch": 0.7527976375505129,
      "grad_norm": 0.084477998316288,
      "learning_rate": 6.2360118122474354e-06,
      "loss": 0.0322,
      "step": 9687
    },
    {
      "epoch": 0.7528753497046938,
      "grad_norm": 0.2274809181690216,
      "learning_rate": 6.235623251476531e-06,
      "loss": 0.085,
      "step": 9688
    },
    {
      "epoch": 0.7529530618588747,
      "grad_norm": 0.9496597051620483,
      "learning_rate": 6.235234690705627e-06,
      "loss": 0.5323,
      "step": 9689
    },
    {
      "epoch": 0.7530307740130556,
      "grad_norm": 1.0599777698516846,
      "learning_rate": 6.234846129934722e-06,
      "loss": 0.4178,
      "step": 9690
    },
    {
      "epoch": 0.7531084861672366,
      "grad_norm": 0.439797967672348,
      "learning_rate": 6.234457569163818e-06,
      "loss": 0.2654,
      "step": 9691
    },
    {
      "epoch": 0.7531861983214174,
      "grad_norm": 0.20717753469944,
      "learning_rate": 6.2340690083929136e-06,
      "loss": 0.0763,
      "step": 9692
    },
    {
      "epoch": 0.7532639104755984,
      "grad_norm": 0.11214342713356018,
      "learning_rate": 6.233680447622008e-06,
      "loss": 0.0234,
      "step": 9693
    },
    {
      "epoch": 0.7533416226297793,
      "grad_norm": 0.16538327932357788,
      "learning_rate": 6.2332918868511035e-06,
      "loss": 0.0291,
      "step": 9694
    },
    {
      "epoch": 0.7534193347839602,
      "grad_norm": 0.2002219706773758,
      "learning_rate": 6.232903326080199e-06,
      "loss": 0.0466,
      "step": 9695
    },
    {
      "epoch": 0.7534970469381411,
      "grad_norm": 0.6110411286354065,
      "learning_rate": 6.232514765309294e-06,
      "loss": 0.7359,
      "step": 9696
    },
    {
      "epoch": 0.7535747590923221,
      "grad_norm": 0.7054957747459412,
      "learning_rate": 6.23212620453839e-06,
      "loss": 0.1569,
      "step": 9697
    },
    {
      "epoch": 0.7536524712465029,
      "grad_norm": 0.1284344643354416,
      "learning_rate": 6.231737643767486e-06,
      "loss": 0.0252,
      "step": 9698
    },
    {
      "epoch": 0.7537301834006839,
      "grad_norm": 0.2975548505783081,
      "learning_rate": 6.231349082996582e-06,
      "loss": 0.1862,
      "step": 9699
    },
    {
      "epoch": 0.7538078955548648,
      "grad_norm": 0.7806007862091064,
      "learning_rate": 6.2309605222256766e-06,
      "loss": 0.7726,
      "step": 9700
    },
    {
      "epoch": 0.7538856077090457,
      "grad_norm": 1.0136890411376953,
      "learning_rate": 6.230571961454772e-06,
      "loss": 0.2327,
      "step": 9701
    },
    {
      "epoch": 0.7539633198632266,
      "grad_norm": 0.42888209223747253,
      "learning_rate": 6.230183400683868e-06,
      "loss": 0.2236,
      "step": 9702
    },
    {
      "epoch": 0.7540410320174076,
      "grad_norm": 0.29497405886650085,
      "learning_rate": 6.229794839912962e-06,
      "loss": 0.1823,
      "step": 9703
    },
    {
      "epoch": 0.7541187441715884,
      "grad_norm": 0.3818705677986145,
      "learning_rate": 6.229406279142058e-06,
      "loss": 0.1862,
      "step": 9704
    },
    {
      "epoch": 0.7541964563257694,
      "grad_norm": 0.7467488646507263,
      "learning_rate": 6.229017718371154e-06,
      "loss": 0.2731,
      "step": 9705
    },
    {
      "epoch": 0.7542741684799502,
      "grad_norm": 1.1752854585647583,
      "learning_rate": 6.228629157600249e-06,
      "loss": 0.2403,
      "step": 9706
    },
    {
      "epoch": 0.7543518806341312,
      "grad_norm": 0.2954389452934265,
      "learning_rate": 6.228240596829345e-06,
      "loss": 0.0872,
      "step": 9707
    },
    {
      "epoch": 0.7544295927883121,
      "grad_norm": 0.6340541243553162,
      "learning_rate": 6.22785203605844e-06,
      "loss": 0.1515,
      "step": 9708
    },
    {
      "epoch": 0.754507304942493,
      "grad_norm": 0.2624635100364685,
      "learning_rate": 6.227463475287535e-06,
      "loss": 0.1024,
      "step": 9709
    },
    {
      "epoch": 0.7545850170966739,
      "grad_norm": 0.5199684500694275,
      "learning_rate": 6.227074914516631e-06,
      "loss": 0.0967,
      "step": 9710
    },
    {
      "epoch": 0.7546627292508549,
      "grad_norm": 0.4574873149394989,
      "learning_rate": 6.226686353745727e-06,
      "loss": 0.6666,
      "step": 9711
    },
    {
      "epoch": 0.7547404414050357,
      "grad_norm": 0.08584572374820709,
      "learning_rate": 6.226297792974821e-06,
      "loss": 0.0269,
      "step": 9712
    },
    {
      "epoch": 0.7548181535592167,
      "grad_norm": 0.19645807147026062,
      "learning_rate": 6.225909232203917e-06,
      "loss": 0.0466,
      "step": 9713
    },
    {
      "epoch": 0.7548958657133976,
      "grad_norm": 0.22948923707008362,
      "learning_rate": 6.225520671433013e-06,
      "loss": 0.0301,
      "step": 9714
    },
    {
      "epoch": 0.7549735778675785,
      "grad_norm": 0.36869126558303833,
      "learning_rate": 6.225132110662108e-06,
      "loss": 0.1263,
      "step": 9715
    },
    {
      "epoch": 0.7550512900217594,
      "grad_norm": 0.5683587193489075,
      "learning_rate": 6.224743549891203e-06,
      "loss": 0.3653,
      "step": 9716
    },
    {
      "epoch": 0.7551290021759404,
      "grad_norm": 0.4672756791114807,
      "learning_rate": 6.224354989120299e-06,
      "loss": 0.3054,
      "step": 9717
    },
    {
      "epoch": 0.7552067143301212,
      "grad_norm": 0.5100484490394592,
      "learning_rate": 6.223966428349394e-06,
      "loss": 0.07,
      "step": 9718
    },
    {
      "epoch": 0.7552844264843022,
      "grad_norm": 0.12323366105556488,
      "learning_rate": 6.22357786757849e-06,
      "loss": 0.0846,
      "step": 9719
    },
    {
      "epoch": 0.755362138638483,
      "grad_norm": 0.41067931056022644,
      "learning_rate": 6.223189306807586e-06,
      "loss": 0.2677,
      "step": 9720
    },
    {
      "epoch": 0.755439850792664,
      "grad_norm": 0.4797130227088928,
      "learning_rate": 6.22280074603668e-06,
      "loss": 0.1335,
      "step": 9721
    },
    {
      "epoch": 0.7555175629468449,
      "grad_norm": 1.0112279653549194,
      "learning_rate": 6.222412185265776e-06,
      "loss": 0.2866,
      "step": 9722
    },
    {
      "epoch": 0.7555952751010258,
      "grad_norm": 0.07940809428691864,
      "learning_rate": 6.222023624494871e-06,
      "loss": 0.0175,
      "step": 9723
    },
    {
      "epoch": 0.7556729872552067,
      "grad_norm": 1.2000341415405273,
      "learning_rate": 6.221635063723966e-06,
      "loss": 0.4327,
      "step": 9724
    },
    {
      "epoch": 0.7557506994093877,
      "grad_norm": 0.5165931582450867,
      "learning_rate": 6.221246502953062e-06,
      "loss": 0.3598,
      "step": 9725
    },
    {
      "epoch": 0.7558284115635685,
      "grad_norm": 0.1414135843515396,
      "learning_rate": 6.220857942182158e-06,
      "loss": 0.0257,
      "step": 9726
    },
    {
      "epoch": 0.7559061237177495,
      "grad_norm": 0.29564404487609863,
      "learning_rate": 6.220469381411254e-06,
      "loss": 0.1107,
      "step": 9727
    },
    {
      "epoch": 0.7559838358719304,
      "grad_norm": 0.47835230827331543,
      "learning_rate": 6.220080820640349e-06,
      "loss": 0.2178,
      "step": 9728
    },
    {
      "epoch": 0.7560615480261113,
      "grad_norm": 0.4179871380329132,
      "learning_rate": 6.2196922598694445e-06,
      "loss": 0.1576,
      "step": 9729
    },
    {
      "epoch": 0.7561392601802922,
      "grad_norm": 0.208018958568573,
      "learning_rate": 6.21930369909854e-06,
      "loss": 0.0949,
      "step": 9730
    },
    {
      "epoch": 0.7562169723344732,
      "grad_norm": 0.23269331455230713,
      "learning_rate": 6.218915138327634e-06,
      "loss": 0.2041,
      "step": 9731
    },
    {
      "epoch": 0.756294684488654,
      "grad_norm": 0.43065938353538513,
      "learning_rate": 6.21852657755673e-06,
      "loss": 0.2449,
      "step": 9732
    },
    {
      "epoch": 0.756372396642835,
      "grad_norm": 0.15037693083286285,
      "learning_rate": 6.218138016785826e-06,
      "loss": 0.068,
      "step": 9733
    },
    {
      "epoch": 0.7564501087970159,
      "grad_norm": 0.3623899817466736,
      "learning_rate": 6.217749456014921e-06,
      "loss": 0.1588,
      "step": 9734
    },
    {
      "epoch": 0.7565278209511967,
      "grad_norm": 0.1038777306675911,
      "learning_rate": 6.217360895244017e-06,
      "loss": 0.0666,
      "step": 9735
    },
    {
      "epoch": 0.7566055331053777,
      "grad_norm": 0.46000489592552185,
      "learning_rate": 6.2169723344731125e-06,
      "loss": 0.214,
      "step": 9736
    },
    {
      "epoch": 0.7566832452595585,
      "grad_norm": 0.6100439429283142,
      "learning_rate": 6.2165837737022075e-06,
      "loss": 0.1251,
      "step": 9737
    },
    {
      "epoch": 0.7567609574137395,
      "grad_norm": 0.5671730041503906,
      "learning_rate": 6.216195212931303e-06,
      "loss": 0.7916,
      "step": 9738
    },
    {
      "epoch": 0.7568386695679205,
      "grad_norm": 0.25164586305618286,
      "learning_rate": 6.215806652160399e-06,
      "loss": 0.1244,
      "step": 9739
    },
    {
      "epoch": 0.7569163817221013,
      "grad_norm": 0.16262464225292206,
      "learning_rate": 6.215418091389493e-06,
      "loss": 0.06,
      "step": 9740
    },
    {
      "epoch": 0.7569940938762822,
      "grad_norm": 0.8136019110679626,
      "learning_rate": 6.215029530618589e-06,
      "loss": 0.5419,
      "step": 9741
    },
    {
      "epoch": 0.7570718060304632,
      "grad_norm": 0.8315140008926392,
      "learning_rate": 6.214640969847685e-06,
      "loss": 0.7734,
      "step": 9742
    },
    {
      "epoch": 0.757149518184644,
      "grad_norm": 1.1378173828125,
      "learning_rate": 6.21425240907678e-06,
      "loss": 0.5058,
      "step": 9743
    },
    {
      "epoch": 0.757227230338825,
      "grad_norm": 0.19754207134246826,
      "learning_rate": 6.2138638483058755e-06,
      "loss": 0.099,
      "step": 9744
    },
    {
      "epoch": 0.757304942493006,
      "grad_norm": 0.3220736086368561,
      "learning_rate": 6.213475287534971e-06,
      "loss": 0.1066,
      "step": 9745
    },
    {
      "epoch": 0.7573826546471868,
      "grad_norm": 8.811224937438965,
      "learning_rate": 6.213086726764066e-06,
      "loss": 3.0602,
      "step": 9746
    },
    {
      "epoch": 0.7574603668013677,
      "grad_norm": 0.22961106896400452,
      "learning_rate": 6.212698165993162e-06,
      "loss": 0.1116,
      "step": 9747
    },
    {
      "epoch": 0.7575380789555487,
      "grad_norm": 0.11755594611167908,
      "learning_rate": 6.212309605222258e-06,
      "loss": 0.3598,
      "step": 9748
    },
    {
      "epoch": 0.7576157911097295,
      "grad_norm": 0.5856717824935913,
      "learning_rate": 6.211921044451352e-06,
      "loss": 0.2302,
      "step": 9749
    },
    {
      "epoch": 0.7576935032639105,
      "grad_norm": 0.5261949300765991,
      "learning_rate": 6.211532483680448e-06,
      "loss": 0.2513,
      "step": 9750
    },
    {
      "epoch": 0.7577712154180913,
      "grad_norm": 0.21009120345115662,
      "learning_rate": 6.2111439229095436e-06,
      "loss": 0.0495,
      "step": 9751
    },
    {
      "epoch": 0.7578489275722723,
      "grad_norm": 0.7884668707847595,
      "learning_rate": 6.2107553621386385e-06,
      "loss": 0.2579,
      "step": 9752
    },
    {
      "epoch": 0.7579266397264532,
      "grad_norm": 0.4019503891468048,
      "learning_rate": 6.210366801367734e-06,
      "loss": 0.1518,
      "step": 9753
    },
    {
      "epoch": 0.7580043518806341,
      "grad_norm": 0.5569010972976685,
      "learning_rate": 6.20997824059683e-06,
      "loss": 0.3443,
      "step": 9754
    },
    {
      "epoch": 0.758082064034815,
      "grad_norm": 0.34846511483192444,
      "learning_rate": 6.209589679825925e-06,
      "loss": 0.0796,
      "step": 9755
    },
    {
      "epoch": 0.758159776188996,
      "grad_norm": 0.4327085018157959,
      "learning_rate": 6.209201119055021e-06,
      "loss": 0.2099,
      "step": 9756
    },
    {
      "epoch": 0.7582374883431768,
      "grad_norm": 0.07327872514724731,
      "learning_rate": 6.208812558284117e-06,
      "loss": 0.0147,
      "step": 9757
    },
    {
      "epoch": 0.7583152004973578,
      "grad_norm": 0.3696885108947754,
      "learning_rate": 6.2084239975132124e-06,
      "loss": 0.1074,
      "step": 9758
    },
    {
      "epoch": 0.7583929126515387,
      "grad_norm": 0.5512406229972839,
      "learning_rate": 6.2080354367423065e-06,
      "loss": 0.5253,
      "step": 9759
    },
    {
      "epoch": 0.7584706248057196,
      "grad_norm": 0.4596499800682068,
      "learning_rate": 6.207646875971402e-06,
      "loss": 0.1822,
      "step": 9760
    },
    {
      "epoch": 0.7585483369599005,
      "grad_norm": 0.2973122000694275,
      "learning_rate": 6.207258315200498e-06,
      "loss": 0.1444,
      "step": 9761
    },
    {
      "epoch": 0.7586260491140815,
      "grad_norm": 0.0034170320723205805,
      "learning_rate": 6.206869754429593e-06,
      "loss": 0.0002,
      "step": 9762
    },
    {
      "epoch": 0.7587037612682623,
      "grad_norm": 0.24052608013153076,
      "learning_rate": 6.206481193658689e-06,
      "loss": 0.0625,
      "step": 9763
    },
    {
      "epoch": 0.7587814734224433,
      "grad_norm": 0.43875908851623535,
      "learning_rate": 6.206092632887785e-06,
      "loss": 0.4241,
      "step": 9764
    },
    {
      "epoch": 0.7588591855766241,
      "grad_norm": 0.4580762982368469,
      "learning_rate": 6.20570407211688e-06,
      "loss": 0.2462,
      "step": 9765
    },
    {
      "epoch": 0.7589368977308051,
      "grad_norm": 0.3461390733718872,
      "learning_rate": 6.2053155113459754e-06,
      "loss": 0.1197,
      "step": 9766
    },
    {
      "epoch": 0.759014609884986,
      "grad_norm": 0.3031083941459656,
      "learning_rate": 6.204926950575071e-06,
      "loss": 0.1275,
      "step": 9767
    },
    {
      "epoch": 0.7590923220391669,
      "grad_norm": 0.1805441528558731,
      "learning_rate": 6.204538389804165e-06,
      "loss": 0.0458,
      "step": 9768
    },
    {
      "epoch": 0.7591700341933478,
      "grad_norm": 0.31377875804901123,
      "learning_rate": 6.204149829033261e-06,
      "loss": 0.0646,
      "step": 9769
    },
    {
      "epoch": 0.7592477463475288,
      "grad_norm": 0.3647797703742981,
      "learning_rate": 6.203761268262357e-06,
      "loss": 0.2545,
      "step": 9770
    },
    {
      "epoch": 0.7593254585017096,
      "grad_norm": 0.06278152018785477,
      "learning_rate": 6.203372707491452e-06,
      "loss": 0.0334,
      "step": 9771
    },
    {
      "epoch": 0.7594031706558906,
      "grad_norm": 0.24759890139102936,
      "learning_rate": 6.202984146720548e-06,
      "loss": 0.0962,
      "step": 9772
    },
    {
      "epoch": 0.7594808828100715,
      "grad_norm": 0.2287963181734085,
      "learning_rate": 6.2025955859496435e-06,
      "loss": 0.1222,
      "step": 9773
    },
    {
      "epoch": 0.7595585949642524,
      "grad_norm": 0.5816222429275513,
      "learning_rate": 6.202207025178738e-06,
      "loss": 0.4005,
      "step": 9774
    },
    {
      "epoch": 0.7596363071184333,
      "grad_norm": 0.22745493054389954,
      "learning_rate": 6.201818464407834e-06,
      "loss": 0.0418,
      "step": 9775
    },
    {
      "epoch": 0.7597140192726143,
      "grad_norm": 0.21251602470874786,
      "learning_rate": 6.20142990363693e-06,
      "loss": 0.1138,
      "step": 9776
    },
    {
      "epoch": 0.7597917314267951,
      "grad_norm": 0.24921384453773499,
      "learning_rate": 6.201041342866024e-06,
      "loss": 0.0986,
      "step": 9777
    },
    {
      "epoch": 0.7598694435809761,
      "grad_norm": 0.3082484006881714,
      "learning_rate": 6.20065278209512e-06,
      "loss": 0.0821,
      "step": 9778
    },
    {
      "epoch": 0.759947155735157,
      "grad_norm": 0.6634477376937866,
      "learning_rate": 6.200264221324216e-06,
      "loss": 0.3522,
      "step": 9779
    },
    {
      "epoch": 0.7600248678893379,
      "grad_norm": 0.2717632055282593,
      "learning_rate": 6.199875660553311e-06,
      "loss": 0.0845,
      "step": 9780
    },
    {
      "epoch": 0.7601025800435188,
      "grad_norm": 0.5868081450462341,
      "learning_rate": 6.1994870997824065e-06,
      "loss": 0.2511,
      "step": 9781
    },
    {
      "epoch": 0.7601802921976997,
      "grad_norm": 0.5041119456291199,
      "learning_rate": 6.199098539011502e-06,
      "loss": 0.1625,
      "step": 9782
    },
    {
      "epoch": 0.7602580043518806,
      "grad_norm": 0.5256944298744202,
      "learning_rate": 6.198709978240597e-06,
      "loss": 0.4667,
      "step": 9783
    },
    {
      "epoch": 0.7603357165060616,
      "grad_norm": 0.1653665453195572,
      "learning_rate": 6.198321417469693e-06,
      "loss": 0.0215,
      "step": 9784
    },
    {
      "epoch": 0.7604134286602424,
      "grad_norm": 0.3659491240978241,
      "learning_rate": 6.197932856698789e-06,
      "loss": 0.2937,
      "step": 9785
    },
    {
      "epoch": 0.7604911408144234,
      "grad_norm": 0.1541675627231598,
      "learning_rate": 6.197544295927883e-06,
      "loss": 0.0937,
      "step": 9786
    },
    {
      "epoch": 0.7605688529686043,
      "grad_norm": 0.08909625560045242,
      "learning_rate": 6.197155735156979e-06,
      "loss": 0.0117,
      "step": 9787
    },
    {
      "epoch": 0.7606465651227852,
      "grad_norm": 0.24534016847610474,
      "learning_rate": 6.1967671743860745e-06,
      "loss": 0.415,
      "step": 9788
    },
    {
      "epoch": 0.7607242772769661,
      "grad_norm": 0.4025653302669525,
      "learning_rate": 6.19637861361517e-06,
      "loss": 0.16,
      "step": 9789
    },
    {
      "epoch": 0.7608019894311471,
      "grad_norm": 0.5171073079109192,
      "learning_rate": 6.195990052844265e-06,
      "loss": 0.1053,
      "step": 9790
    },
    {
      "epoch": 0.7608797015853279,
      "grad_norm": 0.5530803203582764,
      "learning_rate": 6.195601492073361e-06,
      "loss": 0.1943,
      "step": 9791
    },
    {
      "epoch": 0.7609574137395089,
      "grad_norm": 0.30331626534461975,
      "learning_rate": 6.195212931302457e-06,
      "loss": 0.0991,
      "step": 9792
    },
    {
      "epoch": 0.7610351258936898,
      "grad_norm": 0.5445823669433594,
      "learning_rate": 6.194824370531552e-06,
      "loss": 0.2113,
      "step": 9793
    },
    {
      "epoch": 0.7611128380478707,
      "grad_norm": 0.49006983637809753,
      "learning_rate": 6.1944358097606476e-06,
      "loss": 0.1813,
      "step": 9794
    },
    {
      "epoch": 0.7611905502020516,
      "grad_norm": 0.2655077576637268,
      "learning_rate": 6.194047248989743e-06,
      "loss": 0.0161,
      "step": 9795
    },
    {
      "epoch": 0.7612682623562325,
      "grad_norm": 0.21146593987941742,
      "learning_rate": 6.1936586882188375e-06,
      "loss": 0.1395,
      "step": 9796
    },
    {
      "epoch": 0.7613459745104134,
      "grad_norm": 0.525596022605896,
      "learning_rate": 6.193270127447933e-06,
      "loss": 0.6959,
      "step": 9797
    },
    {
      "epoch": 0.7614236866645944,
      "grad_norm": 0.6718057990074158,
      "learning_rate": 6.192881566677029e-06,
      "loss": 0.4861,
      "step": 9798
    },
    {
      "epoch": 0.7615013988187752,
      "grad_norm": 0.7015610337257385,
      "learning_rate": 6.192493005906124e-06,
      "loss": 0.3293,
      "step": 9799
    },
    {
      "epoch": 0.7615791109729562,
      "grad_norm": 0.3647081255912781,
      "learning_rate": 6.19210444513522e-06,
      "loss": 0.1248,
      "step": 9800
    },
    {
      "epoch": 0.7616568231271371,
      "grad_norm": 0.4113152325153351,
      "learning_rate": 6.191715884364316e-06,
      "loss": 0.3768,
      "step": 9801
    },
    {
      "epoch": 0.761734535281318,
      "grad_norm": 1.4339208602905273,
      "learning_rate": 6.1913273235934106e-06,
      "loss": 0.2996,
      "step": 9802
    },
    {
      "epoch": 0.7618122474354989,
      "grad_norm": 0.6270542740821838,
      "learning_rate": 6.190938762822506e-06,
      "loss": 0.2055,
      "step": 9803
    },
    {
      "epoch": 0.7618899595896799,
      "grad_norm": 0.10110518336296082,
      "learning_rate": 6.190550202051602e-06,
      "loss": 0.0378,
      "step": 9804
    },
    {
      "epoch": 0.7619676717438607,
      "grad_norm": 0.15083114802837372,
      "learning_rate": 6.190161641280696e-06,
      "loss": 0.0104,
      "step": 9805
    },
    {
      "epoch": 0.7620453838980417,
      "grad_norm": 0.5213402509689331,
      "learning_rate": 6.189773080509792e-06,
      "loss": 0.2234,
      "step": 9806
    },
    {
      "epoch": 0.7621230960522226,
      "grad_norm": 0.3907281458377838,
      "learning_rate": 6.189384519738888e-06,
      "loss": 0.3593,
      "step": 9807
    },
    {
      "epoch": 0.7622008082064035,
      "grad_norm": 0.4845482409000397,
      "learning_rate": 6.188995958967983e-06,
      "loss": 0.1801,
      "step": 9808
    },
    {
      "epoch": 0.7622785203605844,
      "grad_norm": 0.30412083864212036,
      "learning_rate": 6.188607398197079e-06,
      "loss": 0.1335,
      "step": 9809
    },
    {
      "epoch": 0.7623562325147654,
      "grad_norm": 0.2551381587982178,
      "learning_rate": 6.188218837426174e-06,
      "loss": 0.1403,
      "step": 9810
    },
    {
      "epoch": 0.7624339446689462,
      "grad_norm": 0.15223346650600433,
      "learning_rate": 6.1878302766552685e-06,
      "loss": 0.1116,
      "step": 9811
    },
    {
      "epoch": 0.7625116568231272,
      "grad_norm": 0.16800038516521454,
      "learning_rate": 6.187441715884364e-06,
      "loss": 0.0216,
      "step": 9812
    },
    {
      "epoch": 0.762589368977308,
      "grad_norm": 0.17484426498413086,
      "learning_rate": 6.18705315511346e-06,
      "loss": 0.1181,
      "step": 9813
    },
    {
      "epoch": 0.762667081131489,
      "grad_norm": 0.26053255796432495,
      "learning_rate": 6.186664594342555e-06,
      "loss": 0.0377,
      "step": 9814
    },
    {
      "epoch": 0.7627447932856699,
      "grad_norm": 0.5139129161834717,
      "learning_rate": 6.186276033571651e-06,
      "loss": 0.1659,
      "step": 9815
    },
    {
      "epoch": 0.7628225054398508,
      "grad_norm": 0.3907630443572998,
      "learning_rate": 6.185887472800747e-06,
      "loss": 0.2989,
      "step": 9816
    },
    {
      "epoch": 0.7629002175940317,
      "grad_norm": 0.6694589853286743,
      "learning_rate": 6.185498912029842e-06,
      "loss": 0.2932,
      "step": 9817
    },
    {
      "epoch": 0.7629779297482127,
      "grad_norm": 0.465486079454422,
      "learning_rate": 6.185110351258937e-06,
      "loss": 0.1137,
      "step": 9818
    },
    {
      "epoch": 0.7630556419023935,
      "grad_norm": 0.19815708696842194,
      "learning_rate": 6.184721790488033e-06,
      "loss": 0.118,
      "step": 9819
    },
    {
      "epoch": 0.7631333540565745,
      "grad_norm": 0.32935112714767456,
      "learning_rate": 6.184333229717129e-06,
      "loss": 0.2507,
      "step": 9820
    },
    {
      "epoch": 0.7632110662107554,
      "grad_norm": 0.20984913408756256,
      "learning_rate": 6.183944668946223e-06,
      "loss": 0.1687,
      "step": 9821
    },
    {
      "epoch": 0.7632887783649362,
      "grad_norm": 0.4172383248806,
      "learning_rate": 6.183556108175319e-06,
      "loss": 0.1675,
      "step": 9822
    },
    {
      "epoch": 0.7633664905191172,
      "grad_norm": 0.3193334639072418,
      "learning_rate": 6.183167547404415e-06,
      "loss": 0.1605,
      "step": 9823
    },
    {
      "epoch": 0.7634442026732982,
      "grad_norm": 0.7669640183448792,
      "learning_rate": 6.18277898663351e-06,
      "loss": 0.7955,
      "step": 9824
    },
    {
      "epoch": 0.763521914827479,
      "grad_norm": 0.037151072174310684,
      "learning_rate": 6.182390425862605e-06,
      "loss": 0.0079,
      "step": 9825
    },
    {
      "epoch": 0.76359962698166,
      "grad_norm": 0.3716298043727875,
      "learning_rate": 6.182001865091701e-06,
      "loss": 0.2963,
      "step": 9826
    },
    {
      "epoch": 0.7636773391358408,
      "grad_norm": 0.16667109727859497,
      "learning_rate": 6.181613304320796e-06,
      "loss": 0.052,
      "step": 9827
    },
    {
      "epoch": 0.7637550512900217,
      "grad_norm": 0.16217853128910065,
      "learning_rate": 6.181224743549892e-06,
      "loss": 0.0976,
      "step": 9828
    },
    {
      "epoch": 0.7638327634442027,
      "grad_norm": 0.5034480690956116,
      "learning_rate": 6.180836182778988e-06,
      "loss": 0.3272,
      "step": 9829
    },
    {
      "epoch": 0.7639104755983835,
      "grad_norm": 0.30738338828086853,
      "learning_rate": 6.180447622008082e-06,
      "loss": 0.1955,
      "step": 9830
    },
    {
      "epoch": 0.7639881877525645,
      "grad_norm": 0.3277333676815033,
      "learning_rate": 6.180059061237178e-06,
      "loss": 0.1989,
      "step": 9831
    },
    {
      "epoch": 0.7640658999067454,
      "grad_norm": 0.4234452247619629,
      "learning_rate": 6.1796705004662735e-06,
      "loss": 0.2184,
      "step": 9832
    },
    {
      "epoch": 0.7641436120609263,
      "grad_norm": 0.26789364218711853,
      "learning_rate": 6.179281939695368e-06,
      "loss": 0.097,
      "step": 9833
    },
    {
      "epoch": 0.7642213242151072,
      "grad_norm": 0.2282755970954895,
      "learning_rate": 6.178893378924464e-06,
      "loss": 0.0723,
      "step": 9834
    },
    {
      "epoch": 0.7642990363692882,
      "grad_norm": 0.5586677193641663,
      "learning_rate": 6.17850481815356e-06,
      "loss": 0.2438,
      "step": 9835
    },
    {
      "epoch": 0.764376748523469,
      "grad_norm": 0.4240688681602478,
      "learning_rate": 6.178116257382655e-06,
      "loss": 0.5244,
      "step": 9836
    },
    {
      "epoch": 0.76445446067765,
      "grad_norm": 0.15469145774841309,
      "learning_rate": 6.177727696611751e-06,
      "loss": 0.192,
      "step": 9837
    },
    {
      "epoch": 0.764532172831831,
      "grad_norm": 0.5589159727096558,
      "learning_rate": 6.1773391358408465e-06,
      "loss": 0.3327,
      "step": 9838
    },
    {
      "epoch": 0.7646098849860118,
      "grad_norm": 0.5187126398086548,
      "learning_rate": 6.176950575069941e-06,
      "loss": 0.4922,
      "step": 9839
    },
    {
      "epoch": 0.7646875971401927,
      "grad_norm": 0.03951018676161766,
      "learning_rate": 6.1765620142990364e-06,
      "loss": 0.0091,
      "step": 9840
    },
    {
      "epoch": 0.7647653092943736,
      "grad_norm": 0.48533812165260315,
      "learning_rate": 6.176173453528132e-06,
      "loss": 0.2306,
      "step": 9841
    },
    {
      "epoch": 0.7648430214485545,
      "grad_norm": 0.36382484436035156,
      "learning_rate": 6.175784892757227e-06,
      "loss": 0.2299,
      "step": 9842
    },
    {
      "epoch": 0.7649207336027355,
      "grad_norm": 0.3063971996307373,
      "learning_rate": 6.175396331986323e-06,
      "loss": 0.1501,
      "step": 9843
    },
    {
      "epoch": 0.7649984457569163,
      "grad_norm": 0.3144893944263458,
      "learning_rate": 6.175007771215419e-06,
      "loss": 0.1271,
      "step": 9844
    },
    {
      "epoch": 0.7650761579110973,
      "grad_norm": 0.3553449809551239,
      "learning_rate": 6.174619210444514e-06,
      "loss": 0.1258,
      "step": 9845
    },
    {
      "epoch": 0.7651538700652782,
      "grad_norm": 0.2128422111272812,
      "learning_rate": 6.1742306496736095e-06,
      "loss": 0.0783,
      "step": 9846
    },
    {
      "epoch": 0.7652315822194591,
      "grad_norm": 0.9609646201133728,
      "learning_rate": 6.173842088902705e-06,
      "loss": 0.9177,
      "step": 9847
    },
    {
      "epoch": 0.76530929437364,
      "grad_norm": 0.7416816353797913,
      "learning_rate": 6.1734535281317994e-06,
      "loss": 0.3904,
      "step": 9848
    },
    {
      "epoch": 0.765387006527821,
      "grad_norm": 0.1675727367401123,
      "learning_rate": 6.173064967360895e-06,
      "loss": 0.084,
      "step": 9849
    },
    {
      "epoch": 0.7654647186820018,
      "grad_norm": 0.2867663502693176,
      "learning_rate": 6.172676406589991e-06,
      "loss": 0.1616,
      "step": 9850
    },
    {
      "epoch": 0.7655424308361828,
      "grad_norm": 0.2662132978439331,
      "learning_rate": 6.172287845819087e-06,
      "loss": 0.269,
      "step": 9851
    },
    {
      "epoch": 0.7656201429903637,
      "grad_norm": 0.897462010383606,
      "learning_rate": 6.171899285048182e-06,
      "loss": 0.2853,
      "step": 9852
    },
    {
      "epoch": 0.7656978551445446,
      "grad_norm": 0.28404244780540466,
      "learning_rate": 6.1715107242772776e-06,
      "loss": 0.0601,
      "step": 9853
    },
    {
      "epoch": 0.7657755672987255,
      "grad_norm": 0.37016400694847107,
      "learning_rate": 6.171122163506373e-06,
      "loss": 0.2557,
      "step": 9854
    },
    {
      "epoch": 0.7658532794529065,
      "grad_norm": 0.4211127460002899,
      "learning_rate": 6.170733602735468e-06,
      "loss": 0.17,
      "step": 9855
    },
    {
      "epoch": 0.7659309916070873,
      "grad_norm": 0.09245249629020691,
      "learning_rate": 6.170345041964564e-06,
      "loss": 0.1827,
      "step": 9856
    },
    {
      "epoch": 0.7660087037612683,
      "grad_norm": 0.17389996349811554,
      "learning_rate": 6.16995648119366e-06,
      "loss": 0.0663,
      "step": 9857
    },
    {
      "epoch": 0.7660864159154491,
      "grad_norm": 0.3479177951812744,
      "learning_rate": 6.169567920422754e-06,
      "loss": 0.1255,
      "step": 9858
    },
    {
      "epoch": 0.7661641280696301,
      "grad_norm": 0.0833846777677536,
      "learning_rate": 6.16917935965185e-06,
      "loss": 0.0523,
      "step": 9859
    },
    {
      "epoch": 0.766241840223811,
      "grad_norm": 0.5360109210014343,
      "learning_rate": 6.168790798880946e-06,
      "loss": 0.2842,
      "step": 9860
    },
    {
      "epoch": 0.7663195523779919,
      "grad_norm": 0.32286444306373596,
      "learning_rate": 6.1684022381100405e-06,
      "loss": 0.4653,
      "step": 9861
    },
    {
      "epoch": 0.7663972645321728,
      "grad_norm": 0.5085211396217346,
      "learning_rate": 6.168013677339136e-06,
      "loss": 0.2148,
      "step": 9862
    },
    {
      "epoch": 0.7664749766863538,
      "grad_norm": 0.09559427946805954,
      "learning_rate": 6.167625116568232e-06,
      "loss": 0.018,
      "step": 9863
    },
    {
      "epoch": 0.7665526888405346,
      "grad_norm": 0.16857892274856567,
      "learning_rate": 6.167236555797327e-06,
      "loss": 0.0714,
      "step": 9864
    },
    {
      "epoch": 0.7666304009947156,
      "grad_norm": 0.2241077870130539,
      "learning_rate": 6.166847995026423e-06,
      "loss": 0.1247,
      "step": 9865
    },
    {
      "epoch": 0.7667081131488965,
      "grad_norm": 0.7114509344100952,
      "learning_rate": 6.166459434255519e-06,
      "loss": 0.393,
      "step": 9866
    },
    {
      "epoch": 0.7667858253030774,
      "grad_norm": 0.6330536603927612,
      "learning_rate": 6.166070873484613e-06,
      "loss": 0.2025,
      "step": 9867
    },
    {
      "epoch": 0.7668635374572583,
      "grad_norm": 0.13478563725948334,
      "learning_rate": 6.165682312713709e-06,
      "loss": 0.0224,
      "step": 9868
    },
    {
      "epoch": 0.7669412496114393,
      "grad_norm": 0.5372985601425171,
      "learning_rate": 6.165293751942804e-06,
      "loss": 0.1372,
      "step": 9869
    },
    {
      "epoch": 0.7670189617656201,
      "grad_norm": 0.19596324861049652,
      "learning_rate": 6.164905191171899e-06,
      "loss": 0.0795,
      "step": 9870
    },
    {
      "epoch": 0.7670966739198011,
      "grad_norm": 0.41918155550956726,
      "learning_rate": 6.164516630400995e-06,
      "loss": 0.1836,
      "step": 9871
    },
    {
      "epoch": 0.7671743860739819,
      "grad_norm": 0.322108656167984,
      "learning_rate": 6.164128069630091e-06,
      "loss": 0.2468,
      "step": 9872
    },
    {
      "epoch": 0.7672520982281629,
      "grad_norm": 0.3013375699520111,
      "learning_rate": 6.163739508859186e-06,
      "loss": 0.0835,
      "step": 9873
    },
    {
      "epoch": 0.7673298103823438,
      "grad_norm": 0.48650166392326355,
      "learning_rate": 6.163350948088282e-06,
      "loss": 0.1735,
      "step": 9874
    },
    {
      "epoch": 0.7674075225365247,
      "grad_norm": 0.5289751887321472,
      "learning_rate": 6.1629623873173775e-06,
      "loss": 0.1751,
      "step": 9875
    },
    {
      "epoch": 0.7674852346907056,
      "grad_norm": 0.36783367395401,
      "learning_rate": 6.1625738265464716e-06,
      "loss": 0.1528,
      "step": 9876
    },
    {
      "epoch": 0.7675629468448866,
      "grad_norm": 0.9921346306800842,
      "learning_rate": 6.162185265775567e-06,
      "loss": 0.2558,
      "step": 9877
    },
    {
      "epoch": 0.7676406589990674,
      "grad_norm": 0.6208308339118958,
      "learning_rate": 6.161796705004663e-06,
      "loss": 0.0802,
      "step": 9878
    },
    {
      "epoch": 0.7677183711532484,
      "grad_norm": 0.5415660738945007,
      "learning_rate": 6.161408144233759e-06,
      "loss": 0.8478,
      "step": 9879
    },
    {
      "epoch": 0.7677960833074293,
      "grad_norm": 0.7228766679763794,
      "learning_rate": 6.161019583462854e-06,
      "loss": 0.4271,
      "step": 9880
    },
    {
      "epoch": 0.7678737954616102,
      "grad_norm": 0.05408831685781479,
      "learning_rate": 6.16063102269195e-06,
      "loss": 0.0198,
      "step": 9881
    },
    {
      "epoch": 0.7679515076157911,
      "grad_norm": 0.12826141715049744,
      "learning_rate": 6.1602424619210455e-06,
      "loss": 0.0205,
      "step": 9882
    },
    {
      "epoch": 0.7680292197699721,
      "grad_norm": 0.6152331829071045,
      "learning_rate": 6.1598539011501405e-06,
      "loss": 0.2647,
      "step": 9883
    },
    {
      "epoch": 0.7681069319241529,
      "grad_norm": 0.543217122554779,
      "learning_rate": 6.159465340379236e-06,
      "loss": 0.2396,
      "step": 9884
    },
    {
      "epoch": 0.7681846440783339,
      "grad_norm": 0.07927931845188141,
      "learning_rate": 6.159076779608332e-06,
      "loss": 0.0269,
      "step": 9885
    },
    {
      "epoch": 0.7682623562325148,
      "grad_norm": 0.49613362550735474,
      "learning_rate": 6.158688218837426e-06,
      "loss": 0.1966,
      "step": 9886
    },
    {
      "epoch": 0.7683400683866957,
      "grad_norm": 0.40607750415802,
      "learning_rate": 6.158299658066522e-06,
      "loss": 0.1967,
      "step": 9887
    },
    {
      "epoch": 0.7684177805408766,
      "grad_norm": 0.5777968168258667,
      "learning_rate": 6.157911097295618e-06,
      "loss": 0.4449,
      "step": 9888
    },
    {
      "epoch": 0.7684954926950575,
      "grad_norm": 0.7420596480369568,
      "learning_rate": 6.157522536524713e-06,
      "loss": 0.2721,
      "step": 9889
    },
    {
      "epoch": 0.7685732048492384,
      "grad_norm": 0.269130676984787,
      "learning_rate": 6.1571339757538085e-06,
      "loss": 0.0726,
      "step": 9890
    },
    {
      "epoch": 0.7686509170034194,
      "grad_norm": 0.06518443673849106,
      "learning_rate": 6.156745414982904e-06,
      "loss": 0.0295,
      "step": 9891
    },
    {
      "epoch": 0.7687286291576002,
      "grad_norm": 0.1792456954717636,
      "learning_rate": 6.156356854211999e-06,
      "loss": 0.1131,
      "step": 9892
    },
    {
      "epoch": 0.7688063413117812,
      "grad_norm": 0.17983181774616241,
      "learning_rate": 6.155968293441095e-06,
      "loss": 0.0468,
      "step": 9893
    },
    {
      "epoch": 0.7688840534659621,
      "grad_norm": 0.45928794145584106,
      "learning_rate": 6.155579732670191e-06,
      "loss": 0.1185,
      "step": 9894
    },
    {
      "epoch": 0.768961765620143,
      "grad_norm": 0.15516620874404907,
      "learning_rate": 6.155191171899285e-06,
      "loss": 0.0476,
      "step": 9895
    },
    {
      "epoch": 0.7690394777743239,
      "grad_norm": 0.4475342631340027,
      "learning_rate": 6.154802611128381e-06,
      "loss": 0.2496,
      "step": 9896
    },
    {
      "epoch": 0.7691171899285049,
      "grad_norm": 0.48991259932518005,
      "learning_rate": 6.1544140503574765e-06,
      "loss": 0.2245,
      "step": 9897
    },
    {
      "epoch": 0.7691949020826857,
      "grad_norm": 0.3514789938926697,
      "learning_rate": 6.1540254895865715e-06,
      "loss": 0.1678,
      "step": 9898
    },
    {
      "epoch": 0.7692726142368667,
      "grad_norm": 0.1599634736776352,
      "learning_rate": 6.153636928815667e-06,
      "loss": 0.1403,
      "step": 9899
    },
    {
      "epoch": 0.7693503263910476,
      "grad_norm": 0.583683431148529,
      "learning_rate": 6.153248368044763e-06,
      "loss": 0.3288,
      "step": 9900
    },
    {
      "epoch": 0.7694280385452285,
      "grad_norm": 0.5125074982643127,
      "learning_rate": 6.152859807273858e-06,
      "loss": 0.378,
      "step": 9901
    },
    {
      "epoch": 0.7695057506994094,
      "grad_norm": 0.6139487624168396,
      "learning_rate": 6.152471246502954e-06,
      "loss": 0.5873,
      "step": 9902
    },
    {
      "epoch": 0.7695834628535902,
      "grad_norm": 0.47135329246520996,
      "learning_rate": 6.15208268573205e-06,
      "loss": 0.2185,
      "step": 9903
    },
    {
      "epoch": 0.7696611750077712,
      "grad_norm": 0.8806114792823792,
      "learning_rate": 6.151694124961144e-06,
      "loss": 0.571,
      "step": 9904
    },
    {
      "epoch": 0.7697388871619522,
      "grad_norm": 0.5455019474029541,
      "learning_rate": 6.1513055641902395e-06,
      "loss": 0.2615,
      "step": 9905
    },
    {
      "epoch": 0.769816599316133,
      "grad_norm": 0.43698325753211975,
      "learning_rate": 6.150917003419335e-06,
      "loss": 0.1548,
      "step": 9906
    },
    {
      "epoch": 0.769894311470314,
      "grad_norm": 0.5988690853118896,
      "learning_rate": 6.15052844264843e-06,
      "loss": 0.5116,
      "step": 9907
    },
    {
      "epoch": 0.7699720236244949,
      "grad_norm": 0.6229397058486938,
      "learning_rate": 6.150139881877526e-06,
      "loss": 0.2328,
      "step": 9908
    },
    {
      "epoch": 0.7700497357786757,
      "grad_norm": 0.5731216669082642,
      "learning_rate": 6.149751321106622e-06,
      "loss": 0.114,
      "step": 9909
    },
    {
      "epoch": 0.7701274479328567,
      "grad_norm": 1.445824146270752,
      "learning_rate": 6.149362760335718e-06,
      "loss": 0.5726,
      "step": 9910
    },
    {
      "epoch": 0.7702051600870377,
      "grad_norm": 0.4699871242046356,
      "learning_rate": 6.148974199564813e-06,
      "loss": 0.1811,
      "step": 9911
    },
    {
      "epoch": 0.7702828722412185,
      "grad_norm": 0.5140647888183594,
      "learning_rate": 6.148585638793908e-06,
      "loss": 0.4598,
      "step": 9912
    },
    {
      "epoch": 0.7703605843953995,
      "grad_norm": 0.3435814082622528,
      "learning_rate": 6.148197078023004e-06,
      "loss": 0.3096,
      "step": 9913
    },
    {
      "epoch": 0.7704382965495804,
      "grad_norm": 0.6769190430641174,
      "learning_rate": 6.147808517252098e-06,
      "loss": 0.284,
      "step": 9914
    },
    {
      "epoch": 0.7705160087037612,
      "grad_norm": 0.5039507150650024,
      "learning_rate": 6.147419956481194e-06,
      "loss": 0.4237,
      "step": 9915
    },
    {
      "epoch": 0.7705937208579422,
      "grad_norm": 0.2917407155036926,
      "learning_rate": 6.14703139571029e-06,
      "loss": 0.1195,
      "step": 9916
    },
    {
      "epoch": 0.770671433012123,
      "grad_norm": 0.16597701609134674,
      "learning_rate": 6.146642834939385e-06,
      "loss": 0.0484,
      "step": 9917
    },
    {
      "epoch": 0.770749145166304,
      "grad_norm": 0.3089151680469513,
      "learning_rate": 6.146254274168481e-06,
      "loss": 0.4455,
      "step": 9918
    },
    {
      "epoch": 0.770826857320485,
      "grad_norm": 0.3720223605632782,
      "learning_rate": 6.1458657133975764e-06,
      "loss": 0.5664,
      "step": 9919
    },
    {
      "epoch": 0.7709045694746658,
      "grad_norm": 0.3029153048992157,
      "learning_rate": 6.145477152626671e-06,
      "loss": 0.1078,
      "step": 9920
    },
    {
      "epoch": 0.7709822816288467,
      "grad_norm": 0.0902336984872818,
      "learning_rate": 6.145088591855767e-06,
      "loss": 0.0267,
      "step": 9921
    },
    {
      "epoch": 0.7710599937830277,
      "grad_norm": 0.04418591782450676,
      "learning_rate": 6.144700031084863e-06,
      "loss": 0.0129,
      "step": 9922
    },
    {
      "epoch": 0.7711377059372085,
      "grad_norm": 0.547080397605896,
      "learning_rate": 6.144311470313957e-06,
      "loss": 0.1506,
      "step": 9923
    },
    {
      "epoch": 0.7712154180913895,
      "grad_norm": 0.27016836404800415,
      "learning_rate": 6.143922909543053e-06,
      "loss": 0.1628,
      "step": 9924
    },
    {
      "epoch": 0.7712931302455704,
      "grad_norm": 0.49061551690101624,
      "learning_rate": 6.143534348772149e-06,
      "loss": 0.4267,
      "step": 9925
    },
    {
      "epoch": 0.7713708423997513,
      "grad_norm": 0.5120593905448914,
      "learning_rate": 6.143145788001244e-06,
      "loss": 0.2949,
      "step": 9926
    },
    {
      "epoch": 0.7714485545539322,
      "grad_norm": 0.20185323059558868,
      "learning_rate": 6.142757227230339e-06,
      "loss": 0.0739,
      "step": 9927
    },
    {
      "epoch": 0.7715262667081132,
      "grad_norm": 0.5580629706382751,
      "learning_rate": 6.142368666459435e-06,
      "loss": 0.3504,
      "step": 9928
    },
    {
      "epoch": 0.771603978862294,
      "grad_norm": 0.5179423093795776,
      "learning_rate": 6.14198010568853e-06,
      "loss": 0.6985,
      "step": 9929
    },
    {
      "epoch": 0.771681691016475,
      "grad_norm": 0.47577935457229614,
      "learning_rate": 6.141591544917626e-06,
      "loss": 0.1203,
      "step": 9930
    },
    {
      "epoch": 0.7717594031706559,
      "grad_norm": 0.19256076216697693,
      "learning_rate": 6.141202984146721e-06,
      "loss": 0.0478,
      "step": 9931
    },
    {
      "epoch": 0.7718371153248368,
      "grad_norm": 0.3441421389579773,
      "learning_rate": 6.140814423375816e-06,
      "loss": 0.1512,
      "step": 9932
    },
    {
      "epoch": 0.7719148274790177,
      "grad_norm": 0.09619026631116867,
      "learning_rate": 6.140425862604912e-06,
      "loss": 0.0151,
      "step": 9933
    },
    {
      "epoch": 0.7719925396331986,
      "grad_norm": 0.3225681781768799,
      "learning_rate": 6.1400373018340075e-06,
      "loss": 0.1172,
      "step": 9934
    },
    {
      "epoch": 0.7720702517873795,
      "grad_norm": 0.2889392375946045,
      "learning_rate": 6.139648741063102e-06,
      "loss": 0.1461,
      "step": 9935
    },
    {
      "epoch": 0.7721479639415605,
      "grad_norm": 0.4054872393608093,
      "learning_rate": 6.139260180292198e-06,
      "loss": 0.1342,
      "step": 9936
    },
    {
      "epoch": 0.7722256760957413,
      "grad_norm": 0.318177729845047,
      "learning_rate": 6.138871619521294e-06,
      "loss": 0.1938,
      "step": 9937
    },
    {
      "epoch": 0.7723033882499223,
      "grad_norm": 0.37373337149620056,
      "learning_rate": 6.138483058750388e-06,
      "loss": 0.1576,
      "step": 9938
    },
    {
      "epoch": 0.7723811004041032,
      "grad_norm": 0.3158607482910156,
      "learning_rate": 6.138094497979484e-06,
      "loss": 0.177,
      "step": 9939
    },
    {
      "epoch": 0.7724588125582841,
      "grad_norm": 0.2857041656970978,
      "learning_rate": 6.13770593720858e-06,
      "loss": 0.0587,
      "step": 9940
    },
    {
      "epoch": 0.772536524712465,
      "grad_norm": 0.6835955381393433,
      "learning_rate": 6.1373173764376755e-06,
      "loss": 0.395,
      "step": 9941
    },
    {
      "epoch": 0.772614236866646,
      "grad_norm": 0.5322921276092529,
      "learning_rate": 6.1369288156667704e-06,
      "loss": 0.4617,
      "step": 9942
    },
    {
      "epoch": 0.7726919490208268,
      "grad_norm": 1.2870299816131592,
      "learning_rate": 6.136540254895866e-06,
      "loss": 0.235,
      "step": 9943
    },
    {
      "epoch": 0.7727696611750078,
      "grad_norm": 0.984150767326355,
      "learning_rate": 6.136151694124962e-06,
      "loss": 0.5684,
      "step": 9944
    },
    {
      "epoch": 0.7728473733291887,
      "grad_norm": 0.2431003600358963,
      "learning_rate": 6.135763133354057e-06,
      "loss": 0.1442,
      "step": 9945
    },
    {
      "epoch": 0.7729250854833696,
      "grad_norm": 0.2781786322593689,
      "learning_rate": 6.135374572583153e-06,
      "loss": 0.1801,
      "step": 9946
    },
    {
      "epoch": 0.7730027976375505,
      "grad_norm": 0.47933557629585266,
      "learning_rate": 6.134986011812249e-06,
      "loss": 0.3059,
      "step": 9947
    },
    {
      "epoch": 0.7730805097917314,
      "grad_norm": 0.7624344825744629,
      "learning_rate": 6.134597451041343e-06,
      "loss": 0.0689,
      "step": 9948
    },
    {
      "epoch": 0.7731582219459123,
      "grad_norm": 0.27332040667533875,
      "learning_rate": 6.1342088902704385e-06,
      "loss": 0.1157,
      "step": 9949
    },
    {
      "epoch": 0.7732359341000933,
      "grad_norm": 0.33400529623031616,
      "learning_rate": 6.133820329499534e-06,
      "loss": 0.1695,
      "step": 9950
    },
    {
      "epoch": 0.7733136462542741,
      "grad_norm": 0.3150028586387634,
      "learning_rate": 6.133431768728629e-06,
      "loss": 0.0632,
      "step": 9951
    },
    {
      "epoch": 0.7733913584084551,
      "grad_norm": 0.02678738161921501,
      "learning_rate": 6.133043207957725e-06,
      "loss": 0.0064,
      "step": 9952
    },
    {
      "epoch": 0.773469070562636,
      "grad_norm": 0.5154533386230469,
      "learning_rate": 6.132654647186821e-06,
      "loss": 0.1879,
      "step": 9953
    },
    {
      "epoch": 0.7735467827168169,
      "grad_norm": 0.3833705484867096,
      "learning_rate": 6.132266086415916e-06,
      "loss": 0.1101,
      "step": 9954
    },
    {
      "epoch": 0.7736244948709978,
      "grad_norm": 0.1805797517299652,
      "learning_rate": 6.1318775256450116e-06,
      "loss": 0.0212,
      "step": 9955
    },
    {
      "epoch": 0.7737022070251788,
      "grad_norm": 1.2021763324737549,
      "learning_rate": 6.131488964874107e-06,
      "loss": 0.4116,
      "step": 9956
    },
    {
      "epoch": 0.7737799191793596,
      "grad_norm": 0.06079649552702904,
      "learning_rate": 6.1311004041032015e-06,
      "loss": 0.0225,
      "step": 9957
    },
    {
      "epoch": 0.7738576313335406,
      "grad_norm": 0.3965153992176056,
      "learning_rate": 6.130711843332297e-06,
      "loss": 0.0623,
      "step": 9958
    },
    {
      "epoch": 0.7739353434877215,
      "grad_norm": 0.34622281789779663,
      "learning_rate": 6.130323282561393e-06,
      "loss": 0.1608,
      "step": 9959
    },
    {
      "epoch": 0.7740130556419024,
      "grad_norm": 0.2833993434906006,
      "learning_rate": 6.129934721790488e-06,
      "loss": 0.1258,
      "step": 9960
    },
    {
      "epoch": 0.7740907677960833,
      "grad_norm": 0.16860049962997437,
      "learning_rate": 6.129546161019584e-06,
      "loss": 0.1072,
      "step": 9961
    },
    {
      "epoch": 0.7741684799502643,
      "grad_norm": 0.19387027621269226,
      "learning_rate": 6.12915760024868e-06,
      "loss": 0.0693,
      "step": 9962
    },
    {
      "epoch": 0.7742461921044451,
      "grad_norm": 0.05153191089630127,
      "learning_rate": 6.1287690394777746e-06,
      "loss": 0.0121,
      "step": 9963
    },
    {
      "epoch": 0.7743239042586261,
      "grad_norm": 0.19045913219451904,
      "learning_rate": 6.12838047870687e-06,
      "loss": 0.0926,
      "step": 9964
    },
    {
      "epoch": 0.7744016164128069,
      "grad_norm": 0.349979430437088,
      "learning_rate": 6.127991917935966e-06,
      "loss": 0.1429,
      "step": 9965
    },
    {
      "epoch": 0.7744793285669879,
      "grad_norm": 0.477872759103775,
      "learning_rate": 6.12760335716506e-06,
      "loss": 0.2812,
      "step": 9966
    },
    {
      "epoch": 0.7745570407211688,
      "grad_norm": 0.6071822047233582,
      "learning_rate": 6.127214796394156e-06,
      "loss": 0.499,
      "step": 9967
    },
    {
      "epoch": 0.7746347528753497,
      "grad_norm": 0.18007095158100128,
      "learning_rate": 6.126826235623252e-06,
      "loss": 0.0637,
      "step": 9968
    },
    {
      "epoch": 0.7747124650295306,
      "grad_norm": 0.18573828041553497,
      "learning_rate": 6.126437674852347e-06,
      "loss": 0.0201,
      "step": 9969
    },
    {
      "epoch": 0.7747901771837116,
      "grad_norm": 0.568230152130127,
      "learning_rate": 6.126049114081443e-06,
      "loss": 0.0803,
      "step": 9970
    },
    {
      "epoch": 0.7748678893378924,
      "grad_norm": 0.3302776515483856,
      "learning_rate": 6.125660553310538e-06,
      "loss": 0.3645,
      "step": 9971
    },
    {
      "epoch": 0.7749456014920734,
      "grad_norm": 0.13444198668003082,
      "learning_rate": 6.125271992539634e-06,
      "loss": 0.034,
      "step": 9972
    },
    {
      "epoch": 0.7750233136462543,
      "grad_norm": 0.22748108208179474,
      "learning_rate": 6.124883431768729e-06,
      "loss": 0.0514,
      "step": 9973
    },
    {
      "epoch": 0.7751010258004352,
      "grad_norm": 0.16824376583099365,
      "learning_rate": 6.124494870997825e-06,
      "loss": 0.0308,
      "step": 9974
    },
    {
      "epoch": 0.7751787379546161,
      "grad_norm": 0.6758188009262085,
      "learning_rate": 6.124106310226921e-06,
      "loss": 0.4256,
      "step": 9975
    },
    {
      "epoch": 0.7752564501087971,
      "grad_norm": 0.2073763608932495,
      "learning_rate": 6.123717749456015e-06,
      "loss": 0.0487,
      "step": 9976
    },
    {
      "epoch": 0.7753341622629779,
      "grad_norm": 0.23385439813137054,
      "learning_rate": 6.123329188685111e-06,
      "loss": 0.0474,
      "step": 9977
    },
    {
      "epoch": 0.7754118744171589,
      "grad_norm": 0.08860302716493607,
      "learning_rate": 6.1229406279142064e-06,
      "loss": 0.0402,
      "step": 9978
    },
    {
      "epoch": 0.7754895865713397,
      "grad_norm": 0.3774886131286621,
      "learning_rate": 6.122552067143301e-06,
      "loss": 0.1243,
      "step": 9979
    },
    {
      "epoch": 0.7755672987255207,
      "grad_norm": 0.2189732789993286,
      "learning_rate": 6.122163506372397e-06,
      "loss": 0.1561,
      "step": 9980
    },
    {
      "epoch": 0.7756450108797016,
      "grad_norm": 0.4621480703353882,
      "learning_rate": 6.121774945601493e-06,
      "loss": 0.2456,
      "step": 9981
    },
    {
      "epoch": 0.7757227230338825,
      "grad_norm": 0.5232741832733154,
      "learning_rate": 6.121386384830588e-06,
      "loss": 0.0798,
      "step": 9982
    },
    {
      "epoch": 0.7758004351880634,
      "grad_norm": 0.3072409927845001,
      "learning_rate": 6.120997824059684e-06,
      "loss": 0.0664,
      "step": 9983
    },
    {
      "epoch": 0.7758781473422444,
      "grad_norm": 0.4023606479167938,
      "learning_rate": 6.1206092632887795e-06,
      "loss": 0.1112,
      "step": 9984
    },
    {
      "epoch": 0.7759558594964252,
      "grad_norm": 0.368389368057251,
      "learning_rate": 6.120220702517874e-06,
      "loss": 0.2358,
      "step": 9985
    },
    {
      "epoch": 0.7760335716506062,
      "grad_norm": 0.2041987031698227,
      "learning_rate": 6.119832141746969e-06,
      "loss": 0.1477,
      "step": 9986
    },
    {
      "epoch": 0.7761112838047871,
      "grad_norm": 0.45252570509910583,
      "learning_rate": 6.119443580976065e-06,
      "loss": 0.102,
      "step": 9987
    },
    {
      "epoch": 0.776188995958968,
      "grad_norm": 0.30545809864997864,
      "learning_rate": 6.11905502020516e-06,
      "loss": 0.0543,
      "step": 9988
    },
    {
      "epoch": 0.7762667081131489,
      "grad_norm": 0.09264355897903442,
      "learning_rate": 6.118666459434256e-06,
      "loss": 0.0219,
      "step": 9989
    },
    {
      "epoch": 0.7763444202673299,
      "grad_norm": 0.23269829154014587,
      "learning_rate": 6.118277898663352e-06,
      "loss": 0.0919,
      "step": 9990
    },
    {
      "epoch": 0.7764221324215107,
      "grad_norm": 0.2766501307487488,
      "learning_rate": 6.117889337892447e-06,
      "loss": 0.1928,
      "step": 9991
    },
    {
      "epoch": 0.7764998445756917,
      "grad_norm": 0.0485641248524189,
      "learning_rate": 6.1175007771215425e-06,
      "loss": 0.0141,
      "step": 9992
    },
    {
      "epoch": 0.7765775567298725,
      "grad_norm": 0.1464722454547882,
      "learning_rate": 6.117112216350638e-06,
      "loss": 0.0233,
      "step": 9993
    },
    {
      "epoch": 0.7766552688840535,
      "grad_norm": 0.7737910747528076,
      "learning_rate": 6.116723655579732e-06,
      "loss": 0.1642,
      "step": 9994
    },
    {
      "epoch": 0.7767329810382344,
      "grad_norm": 0.1747787892818451,
      "learning_rate": 6.116335094808828e-06,
      "loss": 0.0484,
      "step": 9995
    },
    {
      "epoch": 0.7768106931924152,
      "grad_norm": 0.3433472812175751,
      "learning_rate": 6.115946534037924e-06,
      "loss": 0.17,
      "step": 9996
    },
    {
      "epoch": 0.7768884053465962,
      "grad_norm": 0.3597218692302704,
      "learning_rate": 6.115557973267019e-06,
      "loss": 0.1391,
      "step": 9997
    },
    {
      "epoch": 0.7769661175007772,
      "grad_norm": 0.5662817358970642,
      "learning_rate": 6.115169412496115e-06,
      "loss": 0.3479,
      "step": 9998
    },
    {
      "epoch": 0.777043829654958,
      "grad_norm": 0.13496725261211395,
      "learning_rate": 6.1147808517252105e-06,
      "loss": 0.0171,
      "step": 9999
    },
    {
      "epoch": 0.777121541809139,
      "grad_norm": 0.5780426263809204,
      "learning_rate": 6.1143922909543055e-06,
      "loss": 0.1915,
      "step": 10000
    }
  ],
  "logging_steps": 1,
  "max_steps": 25736,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 10000,
  "total_flos": 1.4061435398992282e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
